-            'title': 'Carlo Ambrosio & Fabio Di Bari, Carlo Ambrosio - Gypsy Eyes 1',
+            'title': 'Carlo Ambrosio, Carlo Ambrosio & Fabio Di Bari - Gypsy Eyes 1',
-            'release_year': '2009',
+            'artist': 'Carlo Ambrosio, Carlo Ambrosio & Fabio Di Bari',
-                    'release_year': compat_str(year) if year else None,
+                    'release_year': int_or_none(year),
-    def _download_webpage(self, *args, **kwargs):
+    def _download_webpage_handle(self, *args, **kwargs):
-        return super(UdemyIE, self)._download_webpage(
+        return super(UdemyIE, self)._download_webpage_handle(
-        webpage = super(XiamiBaseIE, self)._download_webpage(*args, **kwargs)
+    def _download_webpage_handle(self, *args, **kwargs):
-        webpage = super(YandexMusicBaseIE, self)._download_webpage(*args, **kwargs)
+    def _download_webpage_handle(self, *args, **kwargs):
-    def _download_webpage(self, *args, **kwargs):
+    def _download_webpage_handle(self, *args, **kwargs):
-        return super(YoutubeBaseInfoExtractor, self)._download_webpage(
+        return super(YoutubeBaseInfoExtractor, self)._download_webpage_handle(
-            next_url = xpath_text(it, 'link', fatal=False)
+            next_url = None
-                        break
+                next_url = xpath_text(it, 'link', fatal=False)
-    _VALID_URL = r'(?P<url>https?://(?:www\.)?reddit\.com/r/[^/]+/comments/(?P<id>[^/?#&]+))'
+    _VALID_URL = r'(?P<url>https?://(?:(?:www|old)\.)?reddit\.com/r/[^/]+/comments/(?P<id>[^/?#&]+))'
-    _API_HOST = 'psapi-ne.nrk.no'
+    _API_HOST = 'psapi-we.nrk.no'
-        stream.close()
+        try:
-                if ctx['fragment_index'] > 0 and resume_len == 0:
+                is_corrupt = ctx.get('ytdl_corrupt') is True
-                        'Restarting from the beginning...')
+                        '%s. Restarting from the beginning...' % message)
-            })
+            for video_info in video_info_list:
-        formats.extend(info_dict['formats'])
+        info_dict_config = self._parse_config(config, video_id)
-        info_dict.update({
+        info_dict = {
-        })
+        }
-
+def merge_dicts(*dicts):
-        json_string = self._download_webpage(
+    def _download_json_handle(
-            return None
+        if res is False:
-            json_string, video_id, transform_source=transform_source, fatal=fatal)
+            json_string, video_id, transform_source=transform_source,
-from ..utils import int_or_none
+from ..utils import (
-            })['result']
+        headers = {
-        video = next(r for r in results if r.get('alias') == alias)
+        video = None
-data = urllib.request.urlopen(URL).read()
+version_dict = versions_info['versions'][version]
-template = template.replace('@TAR_SHA256SUM@', versions_info['versions'][version]['tar'][1])
+template = template.replace('@PROGRAM_URL@', version_dict['bin'][0])
-__version__ = '2018.04.16'
+__version__ = '2018.04.25'
-                           r'>\s*([\w~-]+~\d+\.\d+\.\d+\.\d+~[\w~-]+)'), webpage,
+                           r'>\s*([\w~-]+~\d+\.\d+\.\d+\.\d+~[\w~-]+)',
-        '!': lambda v: v is None,
+        '': lambda v: (v is True) if isinstance(v, bool) else (v is not None),
-    _VALID_URL = r'https?://(?:www\.)?pornflip\.com/(?:v|embed)/(?P<id>[0-9A-Za-z-]{11})'
+    _VALID_URL = r'https?://(?:www\.)?pornflip\.com/(?:v|embed)/(?P<id>[^/?#&]+)'
-from .etonline import ETOnlineIE
+from .youtube import YoutubeIE
-)
+from ..utils import int_or_none
-    _VALID_URL = r'https?://(?:www\.)?(?P<site>break|screenjunkies)\.com/video/(?P<display_id>[^/]+?)(?:-(?P<id>\d+))?(?:[/?#&]|$)'
+    _VALID_URL = r'https?://(?:www\.)?break\.com/video/(?P<display_id>[^/]+?)(?:-(?P<id>\d+))?(?:[/?#&]|$)'
-        'url': 'http://www.screenjunkies.com/video/knocking-dead-ep-1-the-show-so-far-3003285',
+        # youtube embed
-            'display_id': 'knocking-dead-ep-1-the-show-so-far',
+            'id': 'RrrDLdeL2HQ',
-            'tags': list,
+            'title': 'Whale Watching Boat Crashing Into San Diego Dock',
-        site, display_id, video_id = re.match(self._VALID_URL, url).groups()
+        display_id, video_id = re.match(self._VALID_URL, url).groups()
-                webpage, 'video id')
+        webpage = self._download_webpage(url, display_id)
-        embed_vars = self._parse_json(
+        youtube_url = YoutubeIE._extract_url(webpage)
-                r'(?s)embedVars\s*=\s*({.+?})\s*</script>', webpage, 'embed vars'),
+                r'(?s)content["\']\s*:\s*(\[.+?\])\s*[,\n]', webpage,
-            if not f.get('uri') or f.get('mediaPurpose') != 'play':
+        for video in content:
-                bitrates.append(bitrate)
+            bitrate = int_or_none(self._search_regex(
-                'url': f['uri'],
+                'url': video_url,
-                'format': 'mp4',
+        self._sort_formats(formats)
-        auth_token = embed_vars.get('AuthToken')
+        title = self._search_regex(
-            return ','.join(pieces)
+        def get(key, name):
-        self._sort_formats(formats)
+        age_limit = get('ratings', 'age limit')
-            'tags': embed_vars.get('tags', '').split(','),
+            'thumbnail': self._og_search_thumbnail(webpage),
-            if self._LOGIN_REQUIRED:
+            if self._LOGIN_REQUIRED and self._downloader.params.get('cookiefile') is None:
-
+    def _entries(self, page):
-            new_ids = filter(lambda video_id: video_id not in ids, orderedSet(matches))
+            new_ids = list(filter(lambda video_id: video_id not in ids, orderedSet(matches)))
-            self._ids_to_results(ids), playlist_title=self._PLAYLIST_TITLE)
+            self._entries(page), playlist_title=self._PLAYLIST_TITLE)
-    _VALID_URL = r'https?://(?:www\.)?(?:svtplay|oppetarkiv)\.se/(?:video|klipp|kanaler)/(?P<id>\w+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:svtplay|oppetarkiv)\.se/(?:video|klipp|kanaler)/(?P<id>[^/?#&]+)'
-                    info_dict['title'] = self._live_title(info_dict['title'])
+                adjust_title(info_dict)
-                info_dict['title'] = self._live_title(info_dict['title'])
+            adjust_title(info_dict)
-                    ext='mp4', entry_protocol='m3u8_native',
+                    ext='mp4', entry_protocol=m3u8_protocol,
-    _VALID_URL = r'https?://(?:www\.)?(?:svtplay|oppetarkiv)\.se/(?:video|klipp)/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:svtplay|oppetarkiv)\.se/(?:video|klipp|kanaler)/(?P<id>\w+)'
-        video_id= self._search_regex([r'(?:=|%26)pcid%3D(\d+)', r'embedVideo(?:Container)?_(\d+)'], webpage, 'video id')
+        video_id = self._search_regex(
-    clean_html,
+    parse_resolution,
-            md = self._download_json('http://dinamics.ccma.cat/pvideo/media.jsp', media_id, query={
+
-                    })
+            })
-        informacio = media_data['informacio']
+        informacio = media['informacio']
-        subtitols = media_data.get('subtitols', {})
+        subtitols = media.get('subtitols', {})
-        imatges = media_data.get('imatges', {})
+        imatges = media.get('imatges', {})
-            'title': 'ÐÐ¾ÐºÑÐ¼ÐµÐ½ÑÐ°Ð»ÑÐ½ÑÐ¹ ÑÐ¿ÐµÑÐ¿ÑÐ¾ÐµÐºÑ: "ÐÑÐ¾Ð¼ÑÐ²ÐºÐ° Ð¼Ð¾Ð·Ð³Ð¾Ð². Ð¢ÐµÑÐ½Ð¾Ð»Ð¾Ð³Ð¸Ð¸ XXI Ð²ÐµÐºÐ°"'
+            'title': 'ÐÐ¾ÐºÑÐ¼ÐµÐ½ÑÐ°Ð»ÑÐ½ÑÐ¹ ÑÐ¿ÐµÑÐ¿ÑÐ¾ÐµÐºÑ: "ÐÑÐ¾Ð¼ÑÐ²ÐºÐ° Ð¼Ð¾Ð·Ð³Ð¾Ð². Ð¢ÐµÑÐ½Ð¾Ð»Ð¾Ð³Ð¸Ð¸ XXI Ð²ÐµÐºÐ°"',
-            r'config\s*=\s*({.+});', webpage, 'config'), video_id)
+            r'config\s*=\s*({.+})\s*;', webpage, 'config'), video_id)
-            })
+        for video in config['src']:
-        return self._parse_jwplayer_data(jw_config, video_id, m3u8_id='hls')
+        config = self._parse_json(self._search_regex(
-    _VALID_URL = r'https?://(?P<domain>(?:www\.)?nickjr|mundonick\.uol)\.com\.br/(?:programas/)?[^/]+/videos/(?:episodios/)?(?P<id>[^/?#.]+)'
+    _VALID_URL = r'''(?x)
-        'md5': '39a15853632b7b2e5679f92f69b78e91',
+        'md5': '558fcdafbb63a87c019218d6e49daf8a',
-        'md5': '1fb9228f5e3332ec8c057d6ac36f33e0',
+        'md5': '92feaafa4b58e82f261e5419f39c60cb',
-            'uploader': 'unknown',
+            'uploader': 'anonim',
-            r'Uploaded by:\s*</strong>\s*(.+?)\s*</div>',
+            r'Uploaded by:\s*</[^>]+>\s*<a[^>]+>(.+?)</a>',
-            r'Views:\s*</strong>\s*<span>([\d,\.]+)</span>',
+            r'Views:\s*</[^>]+>\s*<[^>]+>([\d,\.]+)</',
-        'md5': '1c1e75d22ffa53320f45eeb07bc4cdc0',
+        'url': 'https://www.keezmovies.com/video/arab-wife-want-it-so-bad-i-see-she-thirsty-and-has-tiny-money-18070681',
-            'display_id': 'petite-asian-lady-mai-playing-in-bathtub',
+            'id': '18070681',
-            'thumbnail': r're:^https?://.*\.jpg$',
+            'title': 'Arab wife want it so bad I see she thirsty and has tiny money.',
-        'url': 'http://www.keezmovies.com/video/1214711',
+        'url': 'http://www.keezmovies.com/video/18070681',
-    def _extract_info(self, url):
+    def _extract_info(self, url, fatal=True):
-            if not isinstance(format_url, compat_str) or not format_url.startswith('http'):
+            if not isinstance(format_url, compat_str) or not format_url.startswith(('http', '//')):
-        self._sort_formats(formats)
+        try:
-        webpage, info = self._extract_info(url)
+        webpage, info = self._extract_info(url, fatal=False)
-                        video_ext, audio_ext = audio.get('ext'), video.get('ext')
+                        video_ext, audio_ext = video.get('ext'), audio.get('ext')
-        def get_cdn_shield_base(shield_type='', prefix='-p'):
+        def get_cdn_shield_base(shield_type='', static=False):
-                return AZURE_URL % (prefix, int(stream_data['azureAccount'].replace('nexxplayplus', '')))
+                if 'fb' in stream_data['azureAccount']:
-        azure_progressive_base = get_cdn_shield_base('Prog', '-d')
+        azure_progressive_base = get_cdn_shield_base('Prog', True)
-    _VALID_URL = r'https?://(?:www\.)?cbssports\.com/video/player/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?cbssports\.com/[^/]+/(?:video|news)/(?P<id>[^/?#&]+)'
-        'url': 'http://www.cbssports.com/video/player/videos/708337219968/0/ben-simmons-the-next-lebron?-not-so-fast',
+        'url': 'https://www.cbssports.com/nba/video/donovan-mitchell-flashes-star-potential-in-game-2-victory-over-thunder/',
-            'id': '708337219968',
+            'id': '1214315075735',
-            'upload_date': '20160618',
+            'title': 'Donovan Mitchell flashes star potential in Game 2 victory over Thunder',
-        video_id = self._match_id(url)
+        display_id = self._match_id(url)
-                'first': 100,
+                'first': 12,
-                'uploader_id': 'batchUser',
+                'uploader_id': 'cplapp@learn360.com',
-                      (?:https?:)?//(?:www\.)?kaltura\.com/(?:(?!(?P=q1)).)*\b(?:p|partner_id)/(?P<partner_id>\d+)
+                    <(?:iframe[^>]+src|meta[^>]+\bcontent)=(?P<q1>["'])
-                      [?&]entry_id=(?P<id>(?:(?!(?P=q1))[^&])+)
+                      [?&;]entry_id=(?P<id>(?:(?!(?P=q1))[^&])+)
-    url = 'http://www.cc.com/video-clips/kllhuv/stand-up-greg-fitzsimmons--uncensored---too-good-of-a-mother'
+    url = 'http://www.cc.com/video-clips/p63lk0/adam-devine-s-house-party-chasing-white-swans'
-        self.assertEqual(md5(subtitles['en']), 'b9f6ca22a6acf597ec76f61749765e65')
+        self.assertEqual(md5(subtitles['en']), '78206b8d8a0cfa9da64dc026eea48961')
-        result = ie.extract('https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re')
+        result = ie.extract('https://www.youtube.com/playlist?list=PL-KKIb8rvtMSrAO9YFbeM6UQrAqoFTUWv')
-from ..compat import compat_str
+from ..compat import (
-                })['data']['user']['edge_owner_to_timeline_media']
+
-            if not asset_type or asset_type in asset_types:
+            if not asset_type or asset_type in asset_types or asset_type in ('HLS_FPS', 'DASH_CENC'):
-__version__ = '2018.04.09'
+__version__ = '2018.04.16'
-            broadcast_page, 'broadcast ticket')
+            (r'data-user-file=(["\'])(?P<ticket>(?!\1).+)\1',
-        url = 'http://smotri.com/broadcast/view/url/?ticket=%s' % ticket
+        broadcast_url = 'http://smotri.com/broadcast/view/url/?ticket=%s' % ticket
-            url += '&pass=%s' % hashlib.md5(broadcast_password.encode('utf-8')).hexdigest()
+            broadcast_url += '&pass=%s' % hashlib.md5(broadcast_password.encode('utf-8')).hexdigest()
-            url, broadcast_id, 'Downloading broadcast JSON')
+            broadcast_url, broadcast_id, 'Downloading broadcast JSON')
-    PicartoVodIE,
+    PicartoVodIE,
-from ..utils import ExtractorError, js_to_json, urlencode_postdata
+from ..compat import compat_str
-    _VALID_URL = r'https?://(?:www.)?picarto\.tv/(?P<id>[a-zA-Z0-9]+)[^/]*$'
+    _VALID_URL = r'https?://(?:www.)?picarto\.tv/(?P<id>[a-zA-Z0-9]+)'
-        }
+        'skip': 'Stream is offline',
-            raise ExtractorError('Channel does not exist', expected=True)
+        if '>This channel does not exist' in stream_page:
-        if not player_settings.get('online'):
+        player = self._parse_json(
-        cdn_data = self._download_json('https://picarto.tv/process/channel', channel_id,
+        cdn_data = self._download_json(
-        edge = [edge['ep'] for edge in cdn_data['edges'] if edge['id'] == cdn_data['preferedEdge']][0]
+            note='Downloading load balancing info')
-        formats.append({'url': 'https://%s/mp4/%s.mp4' % (edge, channel_id)})
+        params = {
-            'age_limit': 18 if player_settings.get('mature') else None,
+            'thumbnail': player.get('vodThumb'),
-        'md5': '80765b67813053ff31d4df2bd5e900ce',
+    _VALID_URL = r'https?://(?:www.)?picarto\.tv/videopopout/(?P<id>[^/?#&]+)'
-            'id': 'Carrot_2018.01.11.07.55.12',
+            'id': 'ArtofZod_2017.12.12.00.13.23.flv',
-    }
+            'title': 'ArtofZod_2017.12.12.00.13.23.flv',
-        vod_info = self._parse_json(vod_info_js, video_id, transform_source=js_to_json)
+        vod_info = self._parse_json(
-            'url': vod_info['vod'],
+            'formats': formats,
-    _VALID_URL = r'(?:https?://)?vine\.co/(?P<u>u/)?(?P<user>[^/]+)/?(\?.*)?$'
+    _VALID_URL = r'https?://vine\.co/(?P<u>u/)?(?P<user>[^/]+)'
-            'only_matching': True,
+    _TESTS = [{
-    ]
+        'playlist_mincount': 611,
-        user_archive = self._download_json(
+        data = profile_data['data']
-        return self.playlist_result(entries, user)
+            self.url_result(
-            'url': 'https://vine.co/Visa',
+            'url': 'https://vine.co/itsruthb',
-                'id': 'Visa',
+                'id': 'itsruthb',
-            'playlist_mincount': 46,
+            'playlist_mincount': 611,
-            'url': 'https://vine.co/u/941705360593584128',
+            'url': 'https://vine.co/u/942914934646415360',
-
+        user_archive = self._download_json(
-            self.url_result(e['permalinkUrl'], 'Vine') for e in timeline_data]
+            self.url_result('https://vine.co/v/%s' % post_id, 'Vine')
-            s = '%s:%s:%s:%s' % (rhx_gis, csrf_token, std_headers['User-Agent'], variables)
+            s = '%s:%s:%s' % (rhx_gis, csrf_token, variables)
-                            (?:[a-z]+\.)?pornhub\.com/(?:(?:view_video\.php|video/show)\?viewkey=|embed/)|
+                            (?:[^/]+\.)?pornhub\.com/(?:(?:view_video\.php|video/show)\?viewkey=|embed/)|
-    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/playlist/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:[^/]+\.)?pornhub\.com/playlist/(?P<id>\d+)'
-    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/(?:user|channel)s/(?P<id>[^/]+)/videos'
+    _VALID_URL = r'https?://(?:[^/]+\.)?pornhub\.com/(?:user|channel)s/(?P<id>[^/]+)/videos'
-from ..compat import compat_str
+from ..compat import (
-        })
+        for _ in range(2):
-                    })
+        if self._valid_device_token():
-            r'(<a.+?rel="http://link\.theplatform\.com/s/.+?</a>)', webpage, 'video data'))
+            r'(<a.+?rel="https?://link\.theplatform\.com/s/.+?</a>)', webpage, 'video data'))
-                % (rhx_gis, csrf_token, std_headers['User-Agent'], variables))
+            s = '%s:%s:%s:%s' % (rhx_gis, csrf_token, std_headers['User-Agent'], variables)
-                    'X-Instagram-GIS': gis,
+                    'X-Instagram-GIS': hashlib.md5(s.encode('utf-8')).hexdigest(),
-
+import os
-    def _entries(self, uploader_id):
+    _SIGN_CODE = '''
-                'Downloading JSON page %d' % page_num, query={
+                'Downloading JSON page %d' % page_num, headers={
-                    })
+                    'variables': variables,
-            })['graphql']['user']['id']
+
-            self._entries(uploader_id), username, username)
+            self._entries(data), username, username)
-    _VALID_URL_BASE = r'https?://(?:(?:www|go)\.)?twitch\.tv'
+    _VALID_URL_BASE = r'https?://(?:(?:www|go|m)\.)?twitch\.tv'
-                            (?:(?:www|go)\.)?twitch\.tv/(?:[^/]+/v|videos)/|
+                            (?:(?:www|go|m)\.)?twitch\.tv/(?:[^/]+/v|videos)/|
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                            (?:(?:www|go)\.)?twitch\.tv/|
+                            (?:(?:www|go|m)\.)?twitch\.tv/|
-__version__ = '2018.04.03'
+__version__ = '2018.04.09'
-        }
+            },
-
+        },
-    _VALID_URL = r'https?://(?:(?:www|m|mobile)\.)?(?:odnoklassniki|ok)\.ru/(?:video(?:embed)?/|web-api/video/moviePlayer/|live/|dk\?.*?st\.mvId=)(?P<id>[\d-]+)'
+    _VALID_URL = r'''(?x)
-    _VALID_URL = r'https?://(?:(?:www|m|mobile)\.)?(?:odnoklassniki|ok)\.ru/(?:video(?:embed)?|web-api/video/moviePlayer|live)/(?P<id>[\d-]+)'
+    _VALID_URL = r'https?://(?:(?:www|m|mobile)\.)?(?:odnoklassniki|ok)\.ru/(?:video(?:embed)?/|web-api/video/moviePlayer/|live/|dk\?.*?st\.mvId=)(?P<id>[\d-]+)'
-            if e.get('@context') == 'http://schema.org':
+            if isinstance(e.get('@context'), compat_str) and re.match(r'^https?://schema.org/?$', e.get('@context')):
-            'description': 'md5:a0b4ef3634e63866b542e5b1199a1a0e',
+            'creator': 'Concierge',
-        'md5': 'e87d5b8516cd04c0d81b6ee1caca28d0',
+        'md5': 'a02393c74f3bdb1801c3ec2695577ce0',
-            'duration': 2766,
+            'duration': 2766.602563,
-        e = cast_data['result']['episode']
+            'https://play-api.acast.com/splash/%s/%s' % (channel, display_id),
-            'description': e.get('description'),
+            'title': title,
-    int_or_none,
+    float_or_none,
-            'url': e['mediaUrl'],
+            'url': media_url,
-            'duration': int_or_none(e.get('duration')),
+            'duration': float_or_none(s.get('duration') or e.get('duration')),
-            (r'class="title_watch"[^>]*><(?:p|h\d+)[^>]*>([^<]+)<',
+            (r'<h1[^>]+class=["\']title[^>]+>([^<]+)',
-    _VALID_URL = r'https?://(?:\w+\.)?liveleak\.com/view\?(?:.*?)i=(?P<id>[\w_]+)(?:.*)'
+    _VALID_URL = r'https?://(?:\w+\.)?liveleak\.com/view\?.*?\b[it]=(?P<id>[\w_]+)'
-    _VALID_URL = r'https?://(?:www\.)?(?:openload\.(?:co|io|link)|oload\.(?:tv|stream|site))/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:openload\.(?:co|io|link)|oload\.(?:tv|stream|site|xyz))/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
-                           r'>\s*([\w~]+~\d+\.\d+\.\d+\.\d+~[\w~]+)'), webpage,
+                          (r'>\s*([\w-]+~\d{10,}~\d+\.\d+\.0\.0~[\w-]+)\s*<',
-            raise ExtractorError('Can\'t find stream URL', video_id=video_id)
+                      get_element_by_id('streamurj', webpage) or
-class SVTPlayIE(SVTBaseIE):
+class SVTPlayBaseIE(SVTBaseIE):
-                webpage, 'embedded data', default='{}'),
+                self._SVTPLAY_RE, webpage, 'embedded data', default='{}',
-class SVTSeriesIE(InfoExtractor):
+class SVTSeriesIE(SVTPlayBaseIE):
-                webpage, 'content', group='json'),
+                self._SVTPLAY_RE, webpage, 'content', group='json'),
-        video_id = self._match_id(url)
+        series_id = self._match_id(url)
-            url, video_id, 'Downloading serie page')
+            url, series_id, 'Downloading series page')
-            video_id)
+            series_id)
-            metadata.get('description'))
+            entries, series_id, title, metadata.get('description'))
-    SVTPlaylistIE,
+    SVTSeriesIE,
-    IE_DESC = 'SVT Play serie'
+class SVTSeriesIE(InfoExtractor):
-        return False if SVTIE.suitable(url) or SVTPlayIE.suitable(url) else super(SVTPlaylistIE, cls).suitable(url)
+        return False if SVTIE.suitable(url) or SVTPlayIE.suitable(url) else super(SVTSeriesIE, cls).suitable(url)
-            errnote='unable to fetch serie page')
+        webpage = self._download_webpage(
-        related_videos_accordion = root['relatedVideoContent']['relatedVideosAccordion']
+        root = self._parse_json(
-        for season in related_videos_accordion:
+        for season in root['relatedVideoContent']['relatedVideosAccordion']:
-                if not isinstance(content_url, compat_str):
+                if not content_url or not isinstance(content_url, compat_str):
-            entries, video_id, metadata.get('title'), metadata.get('description'))
+            entries, video_id, metadata.get('title'),
-__version__ = '2018.03.26.1'
+__version__ = '2018.04.03'
-    TVNowListChannelIE,
+    TVNowShowIE,
-        'format.defaultImage169Logo', 'replaceMovieInformation')
+        'format.defaultImage169Logo')
-        thumbnail = ('https://aistvnow-a.akamaihd.net/tvnow/movie/%s' % info.get('replaceMovieInformation')) or f.get('defaultImage169Format') or f.get('defaultImage169Logo')
+
-            'thumbnail': thumbnail,
+            'thumbnails': thumbnails,
-    _VALID_URL = r'https?://(?:www\.)?tvnow\.(?:de|at|ch)/(?:rtl(?:2|plus)?|nitro|superrtl|ntv|vox)/(?P<show_id>[^/]+)/(?:(?:list/[^/]+|jahr/\d{4}/\d{1,2})/)?(?P<id>[^/]+)/(?:player|preview)'
+    _VALID_URL = r'''(?x)
-        'only_matching': 'True',
+        'only_matching': True,
-        'only_matching': 'True',
+        'only_matching': True,
-        'only_matching': 'True',
+        'only_matching': True,
-        'only_matching': 'True',
+        'only_matching': True,
-        'only_matching': 'True',
+        'only_matching': True,
-        'only_matching': 'True',
+        'only_matching': True,
-    def _tvnow_list_info(self, list_id, show_id, fields):
+    _SHOW_VALID_URL = r'''(?x)
-            'formats/seo', list_id, query={
+            'formats/seo', display_id, query={
-    _VALID_URL = r'(?P<base_url>https?://(?:www\.)?tvnow\.(?:de|at|ch)/(?:rtl(?:2|plus)?|nitro|superrtl|ntv|vox)/(?P<show_id>[^/]+)/)list/(?P<id>[^?/#&]+)$'
+    _VALID_URL = r'%s/(?:list|jahr)/(?P<id>[^?\#&]+)' % TVNowListBaseIE._SHOW_VALID_URL
-        list_info = self._tvnow_list_info(season_id, show_id, self._extend_query(self._SHOW_FIELDS, self._SEASON_FIELDS, self._VIDEO_FIELDS))
+        list_info = self._extract_list_info(season_id, show_id)
-        title = '%s - %s' % (list_info['title'], season['headline'])
+        title = list_info.get('title')
-            for info in ((container.get('container') or {}).get('movies') or {}).get('items') or []:
+            items = try_get(
-
+                video_id = info.get('id')
-                    base_url + seo_url + '/player', 'TVNow', str(info.get('id', seo_url))))
+                    '%s/%s/player' % (base_url, seo_url), TVNowIE.ie_key(),
-    _VALID_URL = r'(?P<base_url>https?://(?:www\.)?tvnow\.(?:de|at|ch)/(?:rtl(?:2|plus)?|nitro|superrtl|ntv|vox)/(?P<show_id>[^/]+))'
+class TVNowShowIE(TVNowListBaseIE):
-        'only_matching': 'True',
+        'info_dict': {
-        return False if TVNowIE.suitable(url) or TVNowListIE.suitable(url) else super(TVNowListChannelIE, cls).suitable(url)
+        return (False if TVNowIE.suitable(url) or TVNowListIE.suitable(url)
-        list_info = self._tvnow_list_info(show_id, show_id, self._extend_query(self._SHOW_FIELDS, self._SEASON_FIELDS))
+        list_info = self._extract_list_info(show_id, show_id)
-                base_url + "/list/" + season_url, 'TVNowList', compat_str(season_info.get('id')), season_info.get('headline')))
+                '%s/list/%s' % (base_url, season_url), TVNowListIE.ie_key(),
-        return self.playlist_result(entries)
+        return self.playlist_result(entries, show_id, list_info.get('title'))
-        'format.defaultImage169Logo')
+        'format.defaultImage169Logo', 'replaceMovieInformation')
-        thumbnail = f.get('defaultImage169Format') or f.get('defaultImage169Logo')
+        thumbnail = ('https://aistvnow-a.akamaihd.net/tvnow/movie/%s' % info.get('replaceMovieInformation')) or f.get('defaultImage169Format') or f.get('defaultImage169Logo')
-class TVNowListIE(TVNowBaseIE):
+class TVNowListBaseIE(TVNowBaseIE):
-            })
+        list_info = self._tvnow_list_info(season_id, show_id, self._extend_query(self._SHOW_FIELDS, self._SEASON_FIELDS, self._VIDEO_FIELDS))
-                    base_url + seo_url + '/player', 'TVNow', info.get('id')))
+                    base_url + seo_url + '/player', 'TVNow', str(info.get('id', seo_url))))
-        self._login()
+        self._login()
-            raise ExtractorError('Unable to log in')
+        try:
-        'url': 'http://vod.afreecatv.com/PLAYER/STATION/26542731',
+        # PARTIAL_ADULT
-            'id': '20171001_F1AE1711_196617479_1',
+            'id': '20180327_27901457_202289533_1',
-            'title': '[ì]ìì ì´ì¬ ì°¾ê¸° ë°©ì¡ (part 1)',
+            'title': '[ì]ë¹¨ê°ìâ¥ (part 1)',
-            'uploader': 'BJìì',
+            'uploader': '[SA]ìì',
-            'age_limit': 18,
+            'upload_date': '20180327',
-            }, query={
+        partial_view = False
-            })
+            }
-        if flag and flag != 'SUCCEED':
+            flag = xpath_text(video_xml, './track/flag', 'flag', default=None)
-                '%s said: %s' % (self.IE_NAME, flag), expected=True)
+                '%s said: %s' % (self.IE_NAME, error), expected=True)
-        print(video_id, station_id, bbs_id)
+
-    _VALID_URL = r'https?://channel\.nationalgeographic\.com/(?:(?:wild/)?[^/]+/)?(?:videos|episodes)/(?P<id>[^/?]+)'
+    _VALID_URL = r'https?://channel\.nationalgeographic\.com/(?:(?:(?:wild/)?[^/]+/)?(?:videos|episodes)|u)/(?P<id>[^/?]+)'
-            'url': 'http://channel.nationalgeographic.com/the-story-of-god-with-morgan-freeman/videos/uncovering-a-universal-knowledge/',
+            'url': 'http://channel.nationalgeographic.com/u/kdi9Ld0PN2molUUIMSBGxoeDhD729KRjQcnxtetilWPMevo8ZwUBIDuPR0Q3D2LVaTsk0MPRkRWDB8ZhqWVeyoxfsZZm36yRp1j-zPfsHEyI_EgAeFY/',
-            'url': 'http://channel.nationalgeographic.com/wild/destination-wild/videos/the-stunning-red-bird-of-paradise/',
+            'url': 'http://channel.nationalgeographic.com/u/kdvOstqYaBY-vSBPyYgAZRUL4sWUJ5XUUPEhc7ISyBHqoIO4_dzfY3K6EjHIC0hmFXoQ7Cpzm6RkET7S3oMlm6CFnrQwSUwo/',
-                 r'1<iframe[^>]+src="https://secure\.bilibili\.com/secure,([^"]+)"'],
+                [r'EmbedPlayer\([^)]+,\s*"([^"]+)"\)',
-            r'url_bigthumb=(.+?)&amp', webpage, 'thumbnail', fatal=False)
+            (r'setThumbUrl\(\s*(["\'])(?P<thumbnail>(?:(?!\1).)+)\1',
-    _VALID_URL = r'https?://(?:www\.)?(?:openload\.(?:co|io|link)|oload\.(?:tv|stream))/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:openload\.(?:co|io|link)|oload\.(?:tv|stream|site))/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
-        if m_id is None:
+        vid = self._search_regex(
-            'http://play.rmcnmv.naver.com/vod/play/v2.0/' + m_id.group(1),
+            'http://play.rmcnmv.naver.com/vod/play/v2.0/' + vid,
-                'key': m_id.group(2),
+                'key': in_key,
-from .amp import AMPIE
+from .common import InfoExtractor
-    compat_HTTPError,
+    compat_str,
-    ExtractorError,
+    ExtractorError,
-    remove_end,
+    parse_age_limit,
-class DramaFeverBaseIE(AMPIE):
+class DramaFeverBaseIE(InfoExtractor):
-        'url': 'http://www.dramafever.com/drama/4512/1/Cooking_with_Shin/',
+        'url': 'https://www.dramafever.com/drama/4274/1/Heirs/',
-            'description': 'md5:a8eec7942e1664a6896fcd5e1287bfd0',
+            'id': '4274.1',
-            'duration': 344,
+    def _call_api(self, path, video_id, note, fatal=False):
-            raise
+        series_id, episode_number = video_id.split('.')
-            info['title'] = remove_end(info['title'], video_id).strip()
+        formats = []
-        return info
+        stream = self._call_api(
-        help='File containing URLs to download (\'-\' for stdin)')
+        help="File containing URLs to download ('-' for stdin), one URL per line. "
-        'url': 'http://iview.abc.net.au/programs/call-the-midwife/ZW0898A003S00',
+        'url': 'https://iview.abc.net.au/programs/ben-and-hollys-little-kingdom/ZY9247A021S00',
-            'id': 'ZW0898A003S00',
+            'id': 'ZY9247A021S00',
-            'timestamp': 1514499187,
+            'title': "Gaston's Visit",
-            'title': title,
+            'title': unescapeHTML(title),
-            'series': video_params.get('seriesTitle'),
+            'series': unescapeHTML(video_params.get('seriesTitle')),
-                        videa\.hu/
+                        videa(?:kid)?\.hu/
-            'thumbnail': 'http://videa.hu/static/still/1.4.1.1007274.1204470.3',
+            'thumbnail': r're:^https?://.*',
-__version__ = '2018.03.26'
+__version__ = '2018.03.26.1'
-__version__ = '2018.03.20'
+__version__ = '2018.03.26'
-import re
+import time
-            else:
+            status = {
-                self._hook_progress({
+                status.update({
-                    'status': 'finished',
+            self._hook_progress(status)
-                    msg_template = 'Completed'
+                    msg_template += ' of %(_total_bytes_str)s'
-                s['_total_bytes_str'] = format_bytes(s['total_bytes'])
+                if s.get('total_bytes') is not None:
-                    msg_template = '100%% of %(_total_bytes_str)s'
+                    msg_template += ' in %(_elapsed_str)s'
-            })
+            if filename == '-':
-        fsize = os.path.getsize(encodeFilename(ctx['filename']))
+
-            'total_bytes': fsize,
+            'downloaded_bytes': downloaded_bytes,
-    compat_urlparse,
+    compat_urllib_parse,
-        base_string = '&'.join([method, compat_urlparse.quote(base_url, ''), compat_urlparse.quote(encoded_query, '')])
+        base_string = '&'.join([method, compat_urllib_parse.quote(base_url, ''), compat_urllib_parse.quote(encoded_query, '')])
-        encoded_query += '&oauth_signature=' + compat_urlparse.quote(oauth_signature, '')
+        encoded_query += '&oauth_signature=' + compat_urllib_parse.quote(oauth_signature, '')
-
+        print(video_id, station_id, bbs_id)
-                'Referer': 'http://vod.afreecatv.com/embed.php',
+                'Referer': url,
-    _VALID_URL = r'https?://(?P<host>(?:www\.)?24video\.(?:net|me|xxx|sex|tube|adult))/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?P<host>(?:www\.)?24video\.(?:net|me|xxx|sexy?|tube|adult))/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
-from ..compat import compat_str
+from ..compat import (
-    _GEO_COUNTRIES = ['US']
+        # geo restricted to CA
-            })
+        country_code = self._downloader.params.get('geo_bypass_country', None)
-        title = media['Title']
+        last_e = None
-                if not isinstance(cc_file, dict):
+        for country in countries:
-                if not cc_url or not isinstance(cc_url, compat_str):
+                raise
-                if not mobj:
+                format_url = e.get('Path')
-        }
+                ext = determine_ext(format_url)
-from ..utils import int_or_none
+from ..compat import compat_str
-        'url': 'http://www.crackle.com/comedians-in-cars-getting-coffee/2498934',
+        'url': 'https://www.crackle.com/andromeda/2502343',
-            'id': '2498934',
+            'id': '2502343',
-            },
+            'title': 'Under The Night',
-            video_id, 'Downloading config')
+        media = self._download_json(
-        title = item.attrib['t']
+        description = media.get('Description')
-            video_id, 'mp4', m3u8_id='hls', fatal=None)
+        cc_files = media.get('ClosedCaptionFiles')
-                res = '%dx%d' % (width, height)
+        images = media.get('Images')
-                    'height': mfs_info['height'],
+                    'url': image_url,
-            'episode_number': int_or_none(item.attrib.get('ep')),
+            'description': description,
-from .lemonde import LemondeIE
+from .lego import LEGOIE
-        },
+# coding: utf-8
-                    'first': 999999999,
+        cursor = ''
-            yield info
+
-            'ccode': '0507',
+            'ccode': '0590',
-from ..utils import unified_strdate
+from ..utils import (
-        'md5': '443360ee1b58007bc3dcf09b41d093bb',
+        'url': 'http://html5-player.libsyn.com/embed/episode/id/6385796/',
-            'id': '3377616',
+            'id': '6385796',
-            'upload_date': '20150220',
+            'title': "Champion Minded - Developing a Growth Mindset",
-            r'<h2>([^<]+)</h2>', webpage, 'podcast title', default=None)
+            r'<h3>([^<]+)</h3>', webpage, 'podcast title', default=None)
-            r'(?:<div class="episode-title">|<h3>)([^<]+)</', webpage, 'episode title')
+            r'(?:<div class="episode-title">|<h4>)([^<]+)</', webpage, 'episode title')
-            r'<div id="info_text_body">(.+?)</div>', webpage,
+            r'<p\s+id="info_text_body">(.+?)</p>', webpage,
-            webpage, 'thumbnail', fatal=False)
+        if description:
-__version__ = '2018.03.14'
+__version__ = '2018.03.20'
-from ..utils import update_url_query
+from ..compat import compat_str
-        'url': 'https://7plus.com.au/BEAT?episode-id=BEAT-001',
+        'url': 'https://7plus.com.au/MTYS?episode-id=MTYS7-003',
-            'id': 'BEAT-001',
+            'id': 'MTYS7-003',
-            'description': 'md5:37718bea20a8eedaca7f7361af566131',
+            'title': 'S7 E3 - Wind Surf',
-            'timestamp': 1509440068,
+            'upload_date': '20171201',
-    ExtractorError,
+    smuggle_url,
-            'url': self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id,
+            'url': smuggle_url(
-                'Downloading %s SMIL data' % asset_type)
+            try:
-            return compat_urlparse.urljoin(base_url, video_url)
+        def absolute_url(item_url):
-            media_info['thumbnail'] = media_attributes.get('poster')
+            media_info['thumbnail'] = absolute_url(media_attributes.get('poster'))
-            webpage, 'duration', fatal=False))
+        if formats:
-        return {
+        info.update({
-        }
+            'duration': parse_duration(self._search_regex(
-            webpage, 'iframe player url', group='url'))
+        data_url = update_url_query(unescapeHTML(self._search_regex(
-                            ran\.de|fem\.com|advopedia\.de
+                            ran\.de|fem\.com|advopedia\.de|galileo\.tv/video
-        r'clip[iI]d\s*=\s*["\'](\d+)',
+        r'clip[iI][dD]\s*=\s*["\'](\d+)',
-                'https://example.org/src/',
+                'https://example.org/src/foo_xspf.xspf',
-                    'formats': [{'url': 'https://example.org/src/cd1/track%201.mp3'}],
+                    'formats': [{
-                {
+                    'title': 'Final Cartridge (Nichico Twelve Remix)',
-                    'formats': [{'url': 'https://example.org/%E3%83%88%E3%83%A9%E3%83%83%E3%82%AF%E3%80%80%EF%BC%92.mp3'}],
+                    'formats': [{
-                {
+                    'title': 'Rebuilding Nightingale',
-                    'title': 'Rebuilding Nightingale'
+                    'formats': [{
-        for xspf_file, xspf_base_url, expected_entries in _TEST_CASES:
+        for xspf_file, xspf_url, expected_entries in _TEST_CASES:
-                        xspf_file, xspf_base_url)
+                    xspf_file, xspf_url=xspf_url, xspf_base_url=xspf_url)
-    def _extract_xspf_playlist(self, playlist_url, playlist_id, fatal=True):
+    def _extract_xspf_playlist(self, xspf_url, playlist_id, fatal=True):
-            playlist_url, playlist_id, 'Downloading xpsf playlist',
+            xspf_url, playlist_id, 'Downloading xpsf playlist',
-        return self._parse_xspf(xspf, playlist_id, base_url(playlist_url))
+        return self._parse_xspf(
-    def _parse_xspf(self, playlist, playlist_id, playlist_base_url=''):
+    def _parse_xspf(self, xspf_doc, playlist_id, xspf_url=None, xspf_base_url=None):
-        for track in playlist.findall(xpath_with_ns('./xspf:trackList/xspf:track', NS_MAP)):
+        for track in xspf_doc.findall(xpath_with_ns('./xspf:trackList/xspf:track', NS_MAP)):
-            } for location in track.findall(xpath_with_ns('./xspf:location', NS_MAP))]
+            formats = []
-        res = self._download_webpage_handle(
+        res = self._download_xml_handle(
-        mpd, urlh = res
+        mpd_doc, urlh = res
-            compat_etree_fromstring(mpd.encode('utf-8')), mpd_id, mpd_base_url,
+            mpd_doc, mpd_id=mpd_id, mpd_base_url=mpd_base_url,
-        res = self._download_webpage_handle(
+        res = self._download_xml_handle(
-        ism, urlh = res
+        ism_doc, urlh = res
-            compat_etree_fromstring(ism.encode('utf-8')), urlh.geturl(), ism_id)
+        return self._parse_ism_formats(ism_doc, urlh.geturl(), ism_id)
-                    self._parse_xspf(doc, video_id, compat_str(full_response.geturl())),
+                    self._parse_xspf(
-            fatal=fatal)
+        res = self._download_xml_handle(
-        return self._parse_xspf(xspf, playlist_id)
+        return self._parse_xspf(xspf, playlist_id, base_url(playlist_url))
-    def _parse_xspf(self, playlist, playlist_id):
+    def _parse_xspf(self, playlist, playlist_id, playlist_base_url=''):
-                'url': location.text,
+                'url': urljoin(playlist_base_url, location.text),
-                return self.playlist_result(self._parse_xspf(doc, video_id), video_id)
+                return self.playlist_result(
-                'http://interface.bilibili.com/playurl?%s&sign=%s' % (payload, sign),
+                'http://interface.bilibili.com/v2/playurl?%s&sign=%s' % (payload, sign),
-        'md5': '9fa226fe2b8a9a4d5a69b4c6a183417e',
+        'md5': '5f7d29e1a2872f3df0cf76b1f87d3788',
-            'ext': 'mp4',
+            'ext': 'flv',
-            'timestamp': 1398012660,
+            'duration': 308.067,
-            'skip_download': True,  # Test metadata only
+        'playlist': [{
-                 r'<iframe[^>]+src="https://secure\.bilibili\.com/secure,([^"]+)"'],
+            cid = self._search_regex(
-                    'preference': -2 if 'hd.mp4' in backup_url else -3,
+        RENDITIONS = ('qn=80&quality=80&type=', 'quality=2&type=mp4')
-        title = self._html_search_regex('<h1[^>]*>([^<]+)</h1>', webpage, 'title')
+        title = self._html_search_regex(
-            r'<time[^>]+datetime="([^"]+)"', webpage, 'upload time', default=None))
+            r'<time[^>]+datetime="([^"]+)"', webpage, 'upload time',
-            r'<a[^>]+href="(?:https?:)?//space\.bilibili\.com/(?P<id>\d+)"[^>]+title="(?P<name>[^"]+)"',
+            r'<a[^>]+href="(?:https?:)?//space\.bilibili\.com/(?P<id>\d+)"[^>]*>(?P<name>[^<]+)',
-            'id': '2404147',
+            'id': '1_kkrq94sm',
-            'upload_date': '20140927',
+            'timestamp': 1512734959,
-        }
+        },
-        'md5': '4b58058b46625bdbd841fc2804df95fc',
+            'ext': 'mp4',
-            'title': 'ct10 nachgehakt hos restrictor',
+            'title': "c't uplink 20.8: Staubsaugerroboter Xiaomi Vacuum 2, AR-Brille Meta 2 und Android rooten",
-                webpage, 'title')
+        def extract_title(default=NO_DEFAULT):
-            return self.playlist_from_matches(yt_urls, video_id, title, ie=YoutubeIE.ie_key())
+        title = extract_title(default=None)
-            return self.url_result(smuggle_url(kaltura_url, {'source_url': url}), KalturaIE.ie_key())
+            return {
-import itertools
+import json
-        def get_count(kind):
+        def get_count(suffix):
-                    'view_count': view_count,
+                node, lambda x: x['edge_media_' + suffix]['count']))
-            query['max_id'] = max_id
+            })['data']['user']['edge_owner_to_timeline_media']['edges']
-        uploader_id = self._match_id(url)
+        username = self._match_id(url)
-            self._entries(uploader_id), uploader_id, uploader_id)
+            self._entries(uploader_id), username, username)
-__version__ = '2018.03.10'
+__version__ = '2018.03.14'
-    _CLIENT_ID = 'DQskPX1pntALRzMp4HSxya3Mc0AO66Ro'
+    _CLIENT_ID = 'LvWovRaJZlWCHql0bISuum8Bd2KX79mb'
-        login_json = json.dumps(login_form)
+        login_json = json.dumps(login_form).encode('utf-8')
-        check_json = json.dumps(check_data)
+        check_json = json.dumps(check_data).encode('utf-8')
-        
+
-        
+
-from ..compat import compat_urllib_parse_unquote
+from ..utils import (
-        'md5': 'ef7ecee5af78f8b03dca2cf31341d3a0',
+        'md5': '7583e96c15c0f21e9da3453d9920fbba',
-            'ext': 'flv',
+            'ext': 'mp4',
-        video_url = compat_urllib_parse_unquote(video_url)
+        def get(meta, default=NO_DEFAULT, fatal=True):
-                                              webpage, 'title')
+        formats = []
-                                             webpage, 'thumbnail', fatal=False)
+        thumbnail = self._og_search_thumbnail(webpage, default=None) or get(
-            'thumbnail': video_thumbnail,
+            'title': title,
-            data=urlencode_postdata({'login_id': username, 'pw': password}))
+            data=urlencode_postdata({'login_id': username, 'pw': password}),
-__version__ = '2018.03.03'
+__version__ = '2018.03.10'
-        lesson_ids = [lesson_id]
+        lesson_ids = set((lesson_id, ))
-            lesson_ids.append(lesson_id)
+            lesson_ids.add(lesson_id)
-        for lesson_id in orderedSet(lesson_ids):
+        for lesson_id in sorted(lesson_ids):
-                })
+                video_id)
-                            nexx:(?P<domain_id_s>\d+)?:|
+                            nexx:(?:(?P<domain_id_s>\d+):)?|
-from .funk import FunkIE
+from .funk import (
-from ..utils import extract_attributes
+from ..utils import int_or_none
-    _VALID_URL = r'https?://(?:www\.)?funk\.net/(?:mix|channel)/(?:[^/]+/)*(?P<id>[^?/#]+)'
+class FunkChannelIE(FunkBaseIE):
-        'md5': '4d40974481fa3475f8bccfd20c5361f8',
+        'url': 'https://www.funk.net/channel/ba/die-lustigsten-instrumente-aus-dem-internet-teil-2',
-            'id': '716599',
+            'id': '1155821',
-            'upload_date': '20170729',
+            'title': 'Die LUSTIGSTEN INSTRUMENTE aus dem Internet - Teil 2',
-        'url': 'https://www.funk.net/channel/59d5149841dca100012511e3/0/59d52049999264000182e79d/',
+        'url': 'https://www.funk.net/channel/59d5149841dca100012511e3/mein-erster-job-lovemilla-folge-1/lovemilla/',
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        webpage = self._download_webpage(url, video_id)
+        results = self._download_json(
-            webpage, 'media player'))['data-id']
+        video = next(r for r in results if r.get('alias') == alias)
-            video_id=nexx_id)
+        return self._make_url_result(video)
-                            nexx:(?:\d+:)?|
+                            https?://api\.nexx(?:\.cloud|cdn\.com)/v3/(?P<domain_id>\d+)/videos/byid/|
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        video = self._download_json(
+        response = self._download_json(
-            video_id)['result']
+            video_id, fatal=False)
-        'format.defaultImage169Format', 'format.defaultImage169Logo')
+        'broadcastStartDate', 'isDrm', 'duration', 'season', 'episode',
-        'url': 'https://www.tvnow.de/rtl/alarm-fuer-cobra-11/freier-fall/player?return=/rtl',
+        'url': 'https://www.tvnow.de/rtl2/grip-das-motormagazin/der-neue-porsche-911-gt-3/player',
-            'display_id': 'alarm-fuer-cobra-11/freier-fall',
+            'id': '331082',
-            'description': 'md5:8c2d8f727261adf7e0dc18366124ca02',
+            'title': 'Der neue Porsche 911 GT 3',
-            'duration': 2862.0,
+            'timestamp': 1495994400,
-                        return
+                        continue
-        webpage = self._download_webpage(url, display_id)
+        webpage, urlh = self._download_webpage_handle(url, display_id)
-        clean_url = url.split('?')[0].split('#')[0].strip('/')
+        clean_url = urlh.geturl().split('?')[0].split('#')[0].strip('/')
-        webpage = self._download_webpage(self._LOGIN_URL, None, False)
+        webpage = self._download_webpage(
-        data = urlencode_postdata({
+        data = {
-        login_request.add_header('Referer', self._LOGIN_URL)
+        }
-        self._download_webpage(login_request, None, False, 'Wrong login info')
+        try:
-            r"(?s)Play\('[^']+'\s*,\s*(\[.+\])\s*,\s*{.*?}\);",
+            r"(?s)Play\('[^']+'\s*,\s*(\[.+\])\s*,\s*{.*?}\)",
-            'proxy': '192.99.245.228:3128',
+from .hidive import HiDiveIE
-                                 expected=True)
+            raise ExtractorError(
-        video_element = video_xml.findall(compat_xpath('./track/video'))[1]
+        video_element = video_xml.findall(compat_xpath('./track/video'))[-1]
-from .viceland import VicelandIE
+from .vice import ViceIE
-from ..compat import compat_HTTPError
+from ..compat import (
-    extract_attributes,
+    try_get,
-        title = watch_hub_data['video-title']
+class ViceIE(AdobePassIE):
-                watch_hub_data.get('video-rating'))
+                'VICELAND', title, video_id, rating)
-        exp = int(time.time()) + 14400
+        # new JS is located here https://vice-web-statics-cdn.vice.com/vice-player/player-embed.js
-                'https://%s.com/%s/preplay/%s' % (host, locale, video_id),
+                'https://%s.com/%s/video/preplay/%s' % (host, locale, video_id),
-            if isinstance(e.cause, compat_HTTPError) and e.cause.code == 400:
+            if isinstance(e.cause, compat_HTTPError) and e.cause.code in (400, 401):
-                    self.IE_NAME, error['details']), expected=True)
+                    self.IE_NAME, error_message), expected=True)
-            'duration': int_or_none(video_data.get('video_duration')) or parse_duration(watch_hub_data.get('video-duration')),
+            'thumbnail': thumbnail,
-            'episode_number': int_or_none(episode.get('episode_number') or watch_hub_data.get('episode')),
+            'series': video_data.get('show_title') or series,
-            'season_number': int_or_none(watch_hub_data.get('season')),
+            'season_number': int_or_none(season_number),
-            'uploader': channel.get('base', {}).get('title') or watch_hub_data.get('channel-title'),
+            'uploader': channel.get('base', {}).get('title') or channel.get('name') or uploader,
-            'id': '58dc0a3dee202d2a0ccfcbd8',
+            'id': '41eae2a47b174a1398357cec55f1f6fc',
-            'upload_date': '20170310',
+            'description': 'md5:6394a8398506581d0346b9ab89093fef',
-        'md5': 'a7ecf64ee4fa19b916c16f4b56184ae2',
+        'md5': '7fe8ebc4fa3323efafc127b82bd821d9',
-            'uploader_id': 'MotherboardTV',
+            'uploader_id': 'MotherboardTV',
-            webpage, 'prefetch data'), display_id)
+            r'__APP_STATE\s*=\s*({.+?})(?:\s*\|\|\s*{}\s*)?;\s*\n',
-    _VALID_URL = r'https?://(?:www\.)?vidzi\.(?:tv|cc)/(?:embed-)?(?P<id>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?vidzi\.(?:tv|cc|si)/(?:embed-)?(?P<id>[0-9a-zA-Z]+)'
-            return s.startswith('#ANVATO-SEGMENT-INFO') and 'type=ad' in s
+        def is_ad_fragment(s):
-                if anvato_ad(line):
+                if is_ad_fragment(line):
-                elif anvato_ad(line):
+                elif is_ad_fragment(line):
-                    quality, f_id = None
+                    quality, f_id = [None] * 2
-__version__ = '2018.02.26'
+__version__ = '2018.03.03'
-from ..utils import ExtractorError
+from ..utils import (
-            'description': 'Watch fantasy solo free HD porn video - 05 minutes -  Babe,Masturbation,Solo,Toy  - dillion harper masturbates on a bed free adult movies sexy clips.',
+            'description': 'dillion harper masturbates on a bed',
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, video_id, headers={
-        self._check_formats(formats, video_id)
+        formats = []
-        description = self._og_search_description(webpage)
+        description = self._search_regex(
-            bytes_to_intlist(b'\x1b\xe0\x29\x61\x38\x94\x24\x00\x12\xbd\xc5\x80\xac\xce\xbe\xb0'),
+            bytes_to_intlist(b'\xc8\x6e\x06\xbc\xbe\xc6\x49\xf5\x88\x0d\xc8\x47\xc4\x27\x0c\x60'),
-        title = metas.get('title') or video_info['title']
+        sub_path = player_config.get('subtitles')
-            links_url = player_config['linksurl']
+            links_url = player_config.get('linksurl') or options['videoUrl']
-            'subtitles': self.extract_subtitles(player_config.get('subtitles'), video_id),
+            'subtitles': self.extract_subtitles(sub_path, video_id),
-            if not video_url or not vid_format:
+            if not video_url or video_url == 'NA' or not vid_format:
-            update_self(ydl.to_screen, opts.verbose, ydl._opener, opts.prefer_insecure)
+            update_self(ydl.to_screen, opts.verbose, ydl._opener)
-        help='Use an unencrypted connection to retrieve information whenever possible')
+        help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')
-def update_self(to_screen, verbose, opener, prefer_insecure=False):
+def update_self(to_screen, verbose, opener):
-    UPDATE_URL = '//rg3.github.io/youtube-dl/update/'
+    UPDATE_URL = 'https://rg3.github.io/youtube-dl/update/'
-            VERSION_URL, prefer_insecure)).read().decode('utf-8').strip()
+        newversion = opener.open(VERSION_URL).read().decode('utf-8').strip()
-            JSON_URL, prefer_insecure)).read().decode('utf-8')
+        versions_info = opener.open(JSON_URL).read().decode('utf-8')
-    _VALID_URL = r'https?://(?:www\.)nickelodeon\.(?:ru|fr|es|pt|ro|hu)/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)nickelodeon\.(?:ru|fr|es|pt|ro|hu|com\.tr)/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-            if not item_url or item_url in urls:
+            if not is_legal_url(item_url):
-                if not stream_url or stream_url in urls:
+                if not is_legal_url(stream_url):
-__version__ = '2018.02.25'
+__version__ = '2018.02.26'
-__version__ = '2018.02.22'
+__version__ = '2018.02.25'
-            raise EmbedThumbnailPPError('Thumbnail was not found. Nothing to do.')
+            self._downloader.to_screen('[embedthumbnail] There aren\'t any thumbnails to embed')
-            src = ''
+        def decrypt_src(encoded, val):
-            str_len = len(str_)
+            str_len = len(encoded)
-                    sm[j % 4] = k.index(str_[i])
+                    sm[j % 4] = ALPHABET.index(encoded[i])
-            return src
+                char_code = ((sm[0] << 0x2) | (sm[1] >> 0x4)) ^ val
-            mobj = re.search(r'(src\s*:\s*[^(]\(([^)]*)\)[\s,]*)', format_)
+        for format_ in re.findall(r'({[^}]*\bsrc\s*:\s*[^}]*})', webpage):
-                continue
+                format_, video_id, transform_source=js_to_json,
-            mobj = re.search(r'[\'"](?P<src>[^\'"]+)[\'"]\s*,\s*(?P<val>\d+)', mobj.group(1))
+            mobj = re.search(
-        for format_ in re.findall(r'({[^}]*\bsrc\s*:\s*[^}]*})', webpage):
+        for format_ in re.findall(r'\(\s*({[^}]*\bsrc\s*:\s*[^}]*})', webpage):
-            if not src:
+
-        'skip': 'HTTP Error 404: Not Found',
+        'only_matching': True,
-        'skip': 'Video is no longer available',
+        'only_matching': True,
-    {
+    }, {
-        'skip': 'HTTP Error 404: Not Found',
+        'only_matching': True,
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-    _VALID_URL = r'https?://[^/]+\.telequebec\.tv/emissions/(?P<id>[^?#&]+)'
+    _VALID_URL = r'''(?x)
-class TeleQuebecIE(InfoExtractor):
+class TeleQuebecBaseIE(InfoExtractor):
-        'md5': 'fe95a0957e5707b1b01f5013e725c90f',
+        # available till 01.01.2023
-            'id': '20984',
+            'id': '577116881b4b439084e6b1cf4ef8b1b3',
-        }
+            'title': 'Un petit choc et puis repart!',
-            'title': media_data['title'],
+
-        }
+        })
-                    if track.get('kind') != 'captions':
+                    track_kind = track.get('kind')
-from .telequebec import TeleQuebecIE
+from .telequebec import (
-            'id': '10498713',
+            'id': '10505354',
-            'id': '39125818',
+            'id': '38897857',
-from .mailru import MailRuIE
+from .mailru import (
-            'assetTypes': 'high_video_s3'
+            'assetTypes': 'high_video_ak',
-class YoutubeSearchIE(SearchInfoExtractor, YoutubePlaylistIE):
+class YoutubeSearchBaseInfoExtractor(YoutubePlaylistBaseInfoExtractor):
-                r'href="/watch\?v=(.{11})', html_content)))
+            new_videos = list(self._process_page(html_content))
-class YoutubeSearchURLIE(YoutubePlaylistBaseInfoExtractor):
+class YoutubeSearchURLIE(YoutubeSearchBaseInfoExtractor):
-__version__ = '2018.02.11'
+__version__ = '2018.02.22'
-            webpage, 'hls url')
+            r'data(?:-vjs)?-clip-hls-url=(["\'])(?P<url>(?:(?!\1).)+)\1',
-                            nexx:(?:\d+:)?
+                            nexx:(?:\d+:)?|
-                            nexx:(?P<domain_id_s>\d+):
+                            https?://api\.nexx(?:\.cloud|cdn\.com)/v3/\d+/videos/byid/|
-            })
+        video_id = self._match_id(url)
-        'url': 'https://www.zdf.de/service-und-hilfe/die-neue-zdf-mediathek/zdfmediathek-trailer-100.html',
+        'url': 'https://www.zdf.de/dokumentation/terra-x/die-magie-der-farben-von-koenigspurpur-und-jeansblau-100.html',
-            'id': 'zdfmediathek-trailer-100',
+            'id': 'die-magie-der-farben-von-koenigspurpur-und-jeansblau-100',
-        }
+            'title': 'Die Magie der Farben (2/2)',
-        'md5': '7b8c22b5e7098a3e1c09709df1126d2d',
+        'md5': 'fc08071233725f26b8f014dba9590005',
-            'upload_date': '20120831',
+            'upload_date': '20110811',
-            r'videoDuration\s*:\s*(\d+)', webpage, 'duration', default=None))
+        duration = int_or_none(self._og_search_property(
-        'md5': '655d06ace653ea3b87bccfb1b27ec99d',
+        'md5': '0a070c53eba7ec4534d95a5a1259e253',
-            'id': 'Kk2X5',
+            'id': 'kXzwOKyGlSA',
-            'md5': '0deae91935c54e00003c2a00646315f0',
+            'md5': '7babad3b85ea2e91948005b1b8b0cb84',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'description': 'md5:2d3305bad981a06ff79f027f19865021',
+                'description': 'md5:509a9ad5c9bf97c60faee9203aca4479',
-            'categories': ['Fake Hub', 'Amateur', 'MILFs', 'POV', 'Boss', 'Office', 'Oral', 'Reality', 'Sexy'],
+            'categories': ['Fake Hub', 'Amateur', 'MILFs', 'POV', 'Beauti', 'Beauties', 'Beautiful', 'Boss', 'Office', 'Oral', 'Reality', 'Sexy', 'Taking'],
-    return 'http:%s' % url if url.startswith('//') else url
+    # Prepend protocol-less URLs with `http:` scheme in order to mitigate
-            smuggle_url(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, {'geo_countries': ['IN']}),
+            smuggle_url(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, {
-    def _parse_brightcove_metadata(self, json_data, video_id):
+    def _parse_brightcove_metadata(self, json_data, video_id, headers={}):
-        return self._parse_brightcove_metadata(json_data, video_id)
+        return self._parse_brightcove_metadata(
-    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20150101 Firefox/47.0 (Chrome)',
+    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:59.0) Gecko/20100101 Firefox/59.0 (Chrome)',
-            update_self(ydl.to_screen, opts.verbose, ydl._opener)
+            update_self(ydl.to_screen, opts.verbose, ydl._opener, opts.prefer_insecure)
-        help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')
+        help='Use an unencrypted connection to retrieve information whenever possible')
-def update_self(to_screen, verbose, opener):
+def update_self(to_screen, verbose, opener, prefer_insecure=False):
-    UPDATE_URL = 'https://rg3.github.io/youtube-dl/update/'
+    UPDATE_URL = '//rg3.github.io/youtube-dl/update/'
-        newversion = opener.open(VERSION_URL).read().decode('utf-8').strip()
+        newversion = opener.open(guess_scheme(
-        versions_info = opener.open(JSON_URL).read().decode('utf-8')
+        versions_info = opener.open(guess_scheme(
-    _VALID_URL = r'https?://(?:www\.)?fusion\.net/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?fusion\.(?:net|tv)/video/(?P<id>\d+)'
-        'url': 'http://fusion.net/video/201781/u-s-and-panamanian-forces-work-together-to-stop-a-vessel-smuggling-drugs/',
+        'url': 'http://fusion.tv/video/201781/u-s-and-panamanian-forces-work-together-to-stop-a-vessel-smuggling-drugs/',
-        'url': 'http://fusion.net/video/201781',
+        'url': 'http://fusion.tv/video/201781',
-        quality = qualities(['adaptive', 'wmv_sb', 'h264_sb', 'wmv_bb', 'h264_bb', 'wvc1_std', 'h264_std'])
+        QUALITY_LABELS = ('Laag', 'Normaal', 'Hoog')
-                    'quality': quality(format_id),
+                    'format_id': f_id,
-                    % item.get('label') or item.get('format') or format_id or num)
+                    % item_label or item.get('format') or format_id or num)
-                                (?:zapp|npo3)\.nl/(?:[^/]+/){2}
+                                (?:zapp|npo3)\.nl/(?:[^/]+/){2,}
-    http_chunk_size:    Size of a chunk for chunk-based HTTP downloading.May be
+    http_chunk_size:    Size of a chunk for chunk-based HTTP downloading. May be
-    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/users/(?P<id>[^/]+)/videos'
+    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/(?:user|channel)s/(?P<id>[^/]+)/videos'
-    _VALID_URL = r'(?:(?:https?://(?:\w+\.)?youtube\.com/(?:(?P<user>user|c)/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:https?://(?:\w+\.)?youtube\.com/(?:(?P<user>user|c)/)?(?!(?:attribution_link|watch|results|shared)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'
-        # france-3 live
+    }, {
-__version__ = '2018.02.08'
+__version__ = '2018.02.11'
-    determine_ext,
+    try_get,
-            'title': title,
+            'title': self._live_title(title) if is_live else title,
-        if catalog:
+    def _make_url_result(self, video_or_full_id, catalog=None):
-            full_id, ie=FranceTVIE.ie_key(), video_id=video_id)
+            full_id, ie=FranceTVIE.ie_key(),
-class FranceTVIE(FranceTVBaseInfoExtractor):
+class FranceTVSiteIE(FranceTVBaseInfoExtractor):
-            'id': '157550144',
+            'id': '162311093',
-            'upload_date': '20170507',
+            'timestamp': 1502623500,
-            # m3u8 downloads
+        'add_ie': [FranceTVIE.ie_key()],
-        return self._extract_video(video_id, catalogue)
+
-    _TEST = {
+    _TESTS = [{
-    }
+        'params': {
-        return self._extract_video(video['video_id'], video.get('catalog'))
+        return self._make_url_result(video['video_id'], video.get('catalog'))
-    _VALID_URL = r'https?://(?:www|mobile|france3-regions)\.francetvinfo\.fr/(?:[^/]+/)*(?P<title>[^/?#&.]+)'
+    _VALID_URL = r'https?://(?:www|mobile|france3-regions)\.francetvinfo\.fr/(?:[^/]+/)*(?P<id>[^/?#&.]+)'
-            # m3u8 downloads
+        'add_ie': [FranceTVIE.ie_key()],
-        'skip': 'Ce direct est terminÃ© et sera disponible en rattrapage dans quelques minutes.',
+        'only_matching': True,
-        },
+        'only_matching': True,
-        },
+        'only_matching': True,
-        webpage = self._download_webpage(url, page_title)
+        display_id = self._match_id(url)
-        return self._extract_video(video_id, catalogue)
+
-    _VALID_URL = r'https?://generation-what\.francetv\.fr/[^/]+/video/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://generation-what\.francetv\.fr/[^/]+/video/(?P<id>[^/?#&]+)'
-        return self.url_result(youtube_id, 'Youtube', youtube_id)
+
-    _VALID_URL = r'https?://(?:m\.)?culturebox\.francetvinfo\.fr/(?P<name>.*?)(\?|$)'
+    _VALID_URL = r'https?://(?:m\.)?culturebox\.francetvinfo\.fr/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-        'md5': '9b88dc156781c4dbebd4c3e066e0b1d6',
+    _TESTS = [{
-            'duration': 2760.9,
+            'id': 'EV_134885',
-    }
+        'params': {
-        name = mobj.group('name')
+        display_id = self._match_id(url)
-        webpage = self._download_webpage(url, name)
+        webpage = self._download_webpage(url, display_id)
-            raise ExtractorError('Video %s is not available' % name, expected=True)
+            raise ExtractorError(
-        return self._extract_video(video_id, catalogue)
+        return self._make_url_result(video_id, catalogue)
-from ..compat import compat_urlparse
+from ..compat import (
-                '%s returned error: %s' % (self.IE_NAME, info['message']), expected=True)
+                '%s returned error: %s' % (self.IE_NAME, info['message']),
-                        video_id, f4m_id=format_id, fatal=False))
+                formats.extend(self._extract_f4m_formats(
-                        m3u8_id=format_id, fatal=False))
+                formats.extend(self._extract_m3u8_formats(
-                    m3u8_id=format_id, fatal=False))
+                m3u8_url = self._download_webpage(
-    _VALID_URL = r'https?://(?:www\.)?veoh\.com/(?:watch|iphone/#_Watch)/(?P<id>(?:v|e|yapi-)[\da-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?veoh\.com/(?:watch|embed|iphone/#_Watch)/(?P<id>(?:v|e|yapi-)[\da-zA-Z]+)'
-        status = broadcast['status']
+        stream = self._call_api(
-        user = broadcast_data.get('user', {})
+        broadcast = stream['broadcast']
-                       broadcast.get('user_id') or user.get('id'))
+        uploader = broadcast.get('user_display_name') or broadcast.get('username')
-        title = '%s - %s' % (uploader, status) if uploader else status
+        title = '%s - %s' % (uploader, title) if uploader else title
-            (?P<key>width|height|tbr|abr|vbr|asr|filesize|fps)
+            (?P<key>width|height|tbr|abr|vbr|asr|filesize|filesize_approx|fps)
-    update_url_query,
+    try_get,
-    _VALID_URL = r'''(?x)https?://(?:www\.)?(?:
+    _VALID_URL = r'''(?x)https?://(?:www\.)?(?P<site>
-        path, display_id = re.match(self._VALID_URL, url).groups()
+        site, path, display_id = re.match(self._VALID_URL, url).groups()
-                    })
+            'https://www.%s.com/anonymous' % site, display_id, query={
-            r'(?:Author|Writer)\s*<a[^>]+>([^<]+)', webpage, 'uploader',
+        uploader = self._html_search_regex(
-            r'<dt>Uploaded</dt>\s*<dd>([^<]+)', webpage, 'timestamp',
+        timestamp = unified_timestamp(self._html_search_regex(
-            default=None))
+            r'(?s)<dd>\s*Song\s*</dd>\s*<dd>.+?</dd>\s*<dd>([^<]+)', webpage,
-            r'<dd>Song\s*</dd><dd>(.+?)</dd>', webpage, 'filesize',
+            r'(?s)<dd>\s*Song\s*</dd>\s*<dd>(.+?)</dd>', webpage, 'filesize',
-                self._parse_json(live_js, video_id, transform_source=js_to_json))
+            data.update(self._parse_json(
-            webpage, 'video', default=None, fatal=False)
+            webpage, 'video', default=None)
-            webpage, 'video', default=None, fatal=False)
+            webpage, 'video', default=None)
-            'title': 'DVTV 16. 12. 2014: Ãºtok Talibanu, boj o kliniku, uprchlÃ­ci',
+            'title': r're:^DVTV 16\. 12\. 2014: Ãºtok Talibanu, boj o kliniku, uprchlÃ­ci',
-    def _parse_video_metadata(self, js, video_id):
+    def _parse_video_metadata(self, js, video_id, live_js=None):
-            return self._parse_video_metadata(item, video_id)
+            return self._parse_video_metadata(item, video_id, live_item)
-__version__ = '2018.02.04'
+__version__ = '2018.02.08'
-from .myvi import MyviIE
+from .myvi import (
-            'pkm-title', webpage,' title', default=None) or self._search_regex(
+            'pkm-title', webpage, ' title', default=None) or self._search_regex(
-                                myvi\.(?:ru/player|tv)/
+                                myvi\.
-                                    content/preloader\.swf\?.*\bid=
+                                        (?:
-                            (?:
+                        (?:
-                            (?P<id>[\da-zA-Z_-]+)
+                                    (?:
-    _VALID_URL = r'https?://(?:www\.)?pokemon\.com/[a-z]{2}(?:.*?play=(?P<id>[a-z0-9]{32})|/[^/]+/\d+_\d+-(?P<display_id>[^/?#]+))'
+    _VALID_URL = r'https?://(?:www\.)?pokemon\.com/[a-z]{2}(?:.*?play=(?P<id>[a-z0-9]{32})|/(?:[^/]+/)+(?P<display_id>[^/?#&]+))'
-        'md5': '9fb209ae3a569aac25de0f5afc4ee08f',
+        'url': 'https://www.pokemon.com/us/pokemon-episodes/20_30-the-ol-raise-and-switch/',
-            'id': 'd0436c00c3ce4071ac6cee8130ac54a1',
+            'id': 'afe22e30f01c41f49d4f1d9eab5cd9a4',
-            'upload_date': '20160412',
+            'title': 'The Olâ Raise and Switch!',
-        title = video_data['data-video-title']
+        title = video_data.get('data-video-title') or self._html_search_meta(
-        webpage = self._download_webpage(url, display_id)
+        webpage = self._download_webpage(
-            self._search_regex(r'videoLa7\(({[^;]+})\);', webpage, 'player data'),
+            self._search_regex(
-        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)
+        brightcove_id = self._search_regex(
-            video_id, query={
+            video_id, headers={
-    _VALID_URL = r'https?://(?:www\.)?(?:telebruxelles|bx1)\.be/(news|sport|dernier-jt|emission)/?(?P<id>[^/#?]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:telebruxelles|bx1)\.be/(?:[^/]+/)*(?P<id>[^/#?]+)'
-            r'file\s*:\s*"(rtmps?://[^/]+/vod/mp4:"\s*\+\s*"[^"]+"\s*\+\s*".mp4)"',
+            r'file["\']?\s*:\s*"(r(?:tm|mt)ps?://[^/]+/(?:vod/mp4:"\s*\+\s*"[^"]+"\s*\+\s*"\.mp4|stream/live))"',
-            'title': title,
+            'title': self._live_title(title) if is_live else title,
-            r"<article id=\"post-(\d+)\"", webpage, 'article ID', default=None)
+            r'<article[^>]+\bid=["\']post-(\d+)', webpage, 'article ID', default=None)
-            r'<h1 class=\"entry-title\">(.*?)</h1>', webpage, 'title')
+            r'<h1[^>]*>(.+?)</h1>', webpage, 'title',
-            r'file\s*:\s*"(rtmp://[^/]+/vod/mp4:"\s*\+\s*"[^"]+"\s*\+\s*".mp4)"',
+            r'file\s*:\s*"(rtmps?://[^/]+/vod/mp4:"\s*\+\s*"[^"]+"\s*\+\s*".mp4)"',
-        http_base_url = '%s:%s' % ('http', url_base)
+        mobj = re.search(
-__version__ = '2018.02.03'
+__version__ = '2018.02.04'
-                'Accept': 'application/json;pk=%s' % policy_key
+        headers = {
-            return self.playlist_from_matches(bc_urls, video_id, video_title, ie='BrightcoveNew')
+            return self.playlist_from_matches(
-            elif chunk_size > 0:
+            elif ctx.chunk_size > 0:
-            range_end = range_start + chunk_size - 1 if chunk_size else None
+            range_end = range_start + ctx.chunk_size - 1 if ctx.chunk_size else None
-                                    not chunk_size or
+                                    not ctx.chunk_size or
-            if not is_test and chunk_size and ctx.data_len is not None and byte_counter < ctx.data_len:
+            if not is_test and ctx.chunk_size and ctx.data_len is not None and byte_counter < ctx.data_len:
-        request = sanitized_Request(url, None, headers)
+            request = sanitized_Request(url, None, headers)
-                        ctx.data = self.ydl.urlopen(basic_request)
+                        ctx.data = self.ydl.urlopen(
-    xattr_set_filesize, external_downloader_args, hls_use_mpegts.
+    xattr_set_filesize, external_downloader_args, hls_use_mpegts,
-__version__ = '2018.01.27'
+__version__ = '2018.02.03'
-        os.remove(encodeFilename(filename))
+        try_rm(encodeFilename(filename))
-            new_url = 'http://localhost:%d/ä¸­æ.html' % http_server_port(self.server)
+            new_url = 'http://127.0.0.1:%d/ä¸­æ.html' % http_server_port(self.server)
-            ('localhost', 0), HTTPTestRequestHandler)
+            ('127.0.0.1', 0), HTTPTestRequestHandler)
-        self.assertEqual(r['entries'][0]['url'], 'http://localhost:%d/vid.mp4' % self.port)
+        r = ydl.extract_info('http://127.0.0.1:%d/302' % self.port)
-            ('localhost', 0), HTTPTestRequestHandler)
+            ('127.0.0.1', 0), HTTPTestRequestHandler)
-                ydl.extract_info, 'https://localhost:%d/video.html' % self.port)
+                ydl.extract_info, 'https://127.0.0.1:%d/video.html' % self.port)
-        self.assertEqual(r['entries'][0]['url'], 'https://localhost:%d/vid.mp4' % self.port)
+        r = ydl.extract_info('https://127.0.0.1:%d/video.html' % self.port)
-            ('localhost', 0), _build_proxy_handler('normal'))
+            ('127.0.0.1', 0), _build_proxy_handler('normal'))
-            ('localhost', 0), _build_proxy_handler('geo'))
+            ('127.0.0.1', 0), _build_proxy_handler('geo'))
-        geo_proxy = 'localhost:{0}'.format(self.geo_port)
+        geo_proxy = '127.0.0.1:{0}'.format(self.geo_port)
-            'proxy': 'localhost:{0}'.format(self.port),
+            'proxy': '127.0.0.1:{0}'.format(self.port),
-            'proxy': 'localhost:{0}'.format(self.port),
+            'proxy': '127.0.0.1:{0}'.format(self.port),
-from ..compat import compat_urllib_error
+from ..compat import (
-            request.add_header('Range', 'bytes=0-%s' % str(self._TEST_FILE_SIZE - 1))
+        chunk_size = self._TEST_FILE_SIZE if is_test else (
-                ctx.resume_len = os.path.getsize(encodeFilename(ctx.tmpfilename))
+                ctx.resume_len = os.path.getsize(
-                request.add_header('Range', 'bytes=%d-' % ctx.resume_len)
+            if ctx.resume_len > 0:
-                if ctx.resume_len > 0:
+                if has_range:
-                        content_range_m = re.search(r'bytes (\d+)-', content_range)
+                        content_range_m = re.search(r'bytes (\d+)-(\d+)?(?:/(\d+))?', content_range)
-                            return
+                        if content_range_m:
-                elif err.code == 416:
+                if err.code == 416:
-            block_size = self.params.get('buffersize', 1024)
+            block_size = ctx.block_size
-                if data_len is None:
+                if ctx.data_len is None:
-                    eta = self.calc_eta(start, time.time(), data_len - ctx.resume_len, byte_counter - ctx.resume_len)
+                    eta = self.calc_eta(start, time.time(), ctx.data_len - ctx.resume_len, byte_counter - ctx.resume_len)
-                    'total_bytes': data_len,
+                    'total_bytes': ctx.data_len,
-                    'elapsed': now - start,
+                    'elapsed': now - ctx.start_time,
-                'elapsed': time.time() - start,
+                'elapsed': time.time() - ctx.start_time,
-    _VALID_URL = r'https?://(?:www\.)?redbull\.tv/(?:video|film|live)/(?:AP-\w+/segment/)?(?P<id>AP-\w+)'
+    _VALID_URL = r'https?://(?:www\.)?redbull\.tv/video/(?P<id>AP-\w+)'
-        'url': 'https://www.redbull.tv/video/AP-1Q756YYX51W11/abc-of-wrc',
+        'url': 'https://www.redbull.tv/video/AP-1Q6XCDTAN1W11',
-            'id': 'AP-1Q756YYX51W11',
+            'id': 'AP-1Q6XCDTAN1W11',
-            'title': 'ABC of...WRC',
+            'title': 'ABC of... WRC - ABC of... S1E6',
-        'url': 'https://www.redbull.tv/video/AP-1PMT5JCWH1W11/grime?playlist=shows:shows-playall:web',
+        'url': 'https://www.redbull.tv/video/AP-1PMHKJFCW1W11',
-            'id': 'AP-1PMT5JCWH1W11',
+            'id': 'AP-1PMHKJFCW1W11',
-            'description': 'md5:334b741c8c1ce65be057eab6773c1cf5',
+            'title': 'Grime - Hashtags S2E4',
-            'https://api-v2.redbull.tv/session', video_id,
+            'https://api.redbull.tv/v3/session', video_id,
-        auth = '%s %s' % (session.get('token_type', 'Bearer'), session['access_token'])
+        token = session['token']
-                'https://api-v2.redbull.tv/content/%s' % video_id,
+            video = self._download_json(
-                headers={'Authorization': auth}
+                headers={'Authorization': token}
-                    e.cause.read().decode(), video_id)['message']
+                    e.cause.read().decode(), video_id)['error']
-        title = info['title'].strip()
+        title = video['title'].strip()
-            m3u8_id='hls')
+            'https://dms.redbull.tv/v3/%s/%s/playlist.m3u8' % (video_id, token),
-                })
+        for resource in video.get('resources', []):
-        subheading = info.get('subheading')
+        subheading = video.get('subheading')
-            'description': info.get('long_description') or info.get(
+            'description': video.get('long_description') or video.get(
-            webpage, 'title', group='title')
+            (r'<h(\d)[^>]+class="(?:video_title_text|videoTitle)[^"]*">(?P<title>(?:(?!\1).)+)</h\1>',
-            r'<span[^>]+class="added-time"[^>]*>ADDED ([^<]+)<',
+            r'<span[^>]+>ADDED ([^<]+)<',
-            r'<span[^>]*>VIEWS</span></td>\s*<td>([\d,.]+)',
+            (r'<div[^>]*>Views</div>\s*<div[^>]*>\s*([\d,.]+)',
-                    string = buffer(string)
+                if not isinstance(string, buffer):  # noqa: F821
-        'md5': '61f37b575dd27f1bb2e1854777fe31f4',
+        'url': 'https://out.pladform.ru/player?pl=64471&videoid=3777899&vk_puid15=0&vk_puid34=0',
-            'id': '100183293',
+            'id': '3777899',
-            'description': 'ÐÐ¾ÐºÑÐ¼ÐµÐ½ÑÐ°Ð»ÑÐ½ÑÐ¹ ÑÐµÑÐ¸Ð°Ð»-ÑÐ°ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¾Ð´Ð½Ð¾Ð¹ Ð¸Ð· ÑÐ°Ð¼ÑÑ Ð¶ÑÑÐºÐ¸Ñ ÑÐ°Ð¹Ð½ Ð¥Ð¥ Ð²ÐµÐºÐ°',
+            'title': 'Ð¡Ð¢Ð£ÐÐÐ¯ Ð¡ÐÐ®Ð â¢ Ð¨Ð¾Ñ Ð¡ÑÑÐ´Ð¸Ñ Ð¡Ð¾ÑÐ·, 24 Ð²ÑÐ¿ÑÑÐº (01.02.2018) ÐÑÑÐ»Ð°Ð½ Ð¡Ð°Ð±ÑÑÐ¾Ð² Ð¸ Ð¡Ð»Ð°Ð²Ð° ÐÐ¾Ð¼Ð¸ÑÑÐ°ÑÐµÐ½ÐºÐ¾',
-            'age_limit': 0,
+            'duration': 3190,
-            video_id)
+            'http://out.pladform.ru/getVideo', video_id, query={
-        if video.tag == 'error':
+        def fail(text):
-                '%s returned error: %s' % (self.IE_NAME, video.text),
+                '%s returned error: %s' % (self.IE_NAME, text),
-        } for src in video.findall('./src')]
+        formats = []
-from ..compat import compat_str
+from ..compat import (
-                if protocol == 'usp':
+                if protocol == 'usp' and not compat_parse_qs(compat_urllib_parse_urlparse(asset_url).query).get('token', [None])[0]:
-    _VALID_URL = r'https?://channel\.nationalgeographic\.com/(?:wild/)?[^/]+/(?:videos|episodes)/(?P<id>[^/?]+)'
+    _VALID_URL = r'https?://channel\.nationalgeographic\.com/(?:(?:wild/)?[^/]+/)?(?:videos|episodes)/(?P<id>[^/?]+)'
-    _VALID_URL = r'https?://(?P<domain>www\.(?P<host>dplay\.(?P<country>dk|se|no)))/(?:videoer/)?(?P<id>[^/]+/[^/?#]+)'
+    _VALID_URL = r'https?://(?P<domain>www\.(?P<host>dplay\.(?P<country>dk|se|no)))/(?:video(?:er|s)/)?(?P<id>[^/]+/[^/?#]+)'
-        # geo restricted, bypassable via X-Forwarded-For
+
-            r"data-(?:cnet|zdnet)-video(?:-uvp(?:js)?)?-options='([^']+)'",
+            r"data(?:-(?:cnet|zdnet))?-video(?:-(?:uvp(?:js)?|player))?-options='([^']+)'",
-        vdata = data.get('video') or data['videos'][0]
+        vdata = data.get('video') or (data.get('videos') or data.get('playlist'))[0]
-    _VALID_URL = r'https?://(?:www\.)?(?:amc|bbcamerica|ifc|wetv)\.com/(?:movies|shows(?:/[^/]+)+)/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:amc|bbcamerica|ifc|(?:we|sundance)tv)\.com/(?:movies|shows(?:/[^/]+)+)/(?P<id>[^/?#]+)'
-s32 = struct.Struct(b'>i')
+from ..compat import (
-    hc = http_class(*args, **kwargs)
+        kwargs['strict'] = True
-        codec_private_data = binascii.unhexlify(params['codec_private_data'])
+        codec_private_data = binascii.unhexlify(params['codec_private_data'].encode('utf-8'))
-__version__ = '2018.01.21'
+__version__ = '2018.01.27'
-    _VALID_URL = r'https?://(?:www\.)?(?:seznam\.cz/zpravy|seznamzpravy\.cz)/iframe/player\?.*\bsrc='
+    _VALID_URL = r'https?://(?:www\.)?seznamzpravy\.cz/iframe/player\?.*\bsrc='
-        'params': {'skip_download': True},  # 'file_minsize': 1586 seems to get killed in test_download.py
+        'url': 'https://www.seznamzpravy.cz/iframe/player?duration=241&serviceSlug=zpravy&src=https%3A%2F%2Fv39-a.sdn.szn.cz%2Fv_39%2Fvmd%2F5999c902ea707c67d8e267a9%3Ffl%3Dmdk%2C432f65a0%7C&itemType=video&autoPlay=false&title=Sv%C4%9Bt%20bez%20obalu%3A%20%C4%8Ce%C5%A1t%C3%AD%20voj%C3%A1ci%20na%20mis%C3%ADch%20(kr%C3%A1tk%C3%A1%20verze)&series=Sv%C4%9Bt%20bez%20obalu&serviceName=Seznam%20Zpr%C3%A1vy&poster=%2F%2Fd39-a.sdn.szn.cz%2Fd_39%2Fc_img_F_I%2FR5puJ.jpeg%3Ffl%3Dcro%2C0%2C0%2C1920%2C1080%7Cres%2C1200%2C%2C1%7Cjpg%2C80%2C%2C1&width=1920&height=1080&cutFrom=0&cutTo=0&splVersion=VOD&contentId=170889&contextId=35990&showAdvert=true&collocation=&autoplayPossible=true&embed=&isVideoTooShortForPreroll=false&isVideoTooLongForPostroll=true&videoCommentOpKey=&videoCommentId=&version=4.0.76&dotService=zpravy&gemiusPrismIdentifier=bVc1ZIb_Qax4W2v5xOPGpMeCP31kFfrTzj0SqPTLh_b.Z7&zoneIdPreroll=seznam.pack.videospot&skipOffsetPreroll=5&sectionPrefixPreroll=%2Fzpravy',
-        }
+            'thumbnail': r're:^https?://.*\.jpe?g',
-            relative_url = fmtdata.get('url')
+        for format_id, format_data in mp4_formats.items():
-                width, height = fmtdata.get('resolution')
+                width, height = format_data.get('resolution')
-                'format_id': fmt,
+            f = {
-            })
+            }
-        dash_rel_url = try_get(playlists, lambda x: x['dash']['url'], compat_str)
+        def get_url(format_id):
-            formats.extend(self._extract_mpd_formats(urljoin(sdn_url, dash_rel_url), video_id, mpd_id='dash', fatal=False))
+            formats.extend(self._extract_mpd_formats(
-        hls_rel_url = try_get(playlists, lambda x: x['hls']['url'], compat_str)
+        hls_rel_url = get_url('hls')
-            formats.extend(self._extract_m3u8_formats(urljoin(sdn_url, hls_rel_url), video_id, ext='mp4', m3u8_id='hls', fatal=False))
+            formats.extend(self._extract_m3u8_formats(
-            'formats': self._extract_sdn_formats(src + 'spl2,2,VOD', video_id),
+            'title': title,
-    _VALID_URL = r'https?://(?:www\.)?(?:seznam\.cz/zpravy|seznamzpravy\.cz)/clanek/(?:[-a-z0-9]+)-(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:seznam\.cz/zpravy|seznamzpravy\.cz)/clanek/(?:[^/?#&]+)-(?P<id>\d+)'
-        }
+            'id': '35990',
-        }
+            'id': '38489',
-                continue
+    def _real_extract(self, url):
-            })
+        webpage = self._download_webpage(url, article_id)
-        return entries
+        info = self._search_json_ld(webpage, article_id, default={})
-        return self.url_result(url, ie='SeznamZpravy', video_id=video_id, video_title=info_dict['title'])
+        title = info.get('title') or self._og_search_title(webpage, fatal=False)
-            )
+        return self.playlist_result([
-                elif item_type == 'Article':
+                elif item_type in ('Article', 'NewsArticle'):
-    _VALID_URL = r'https?://(?P<domain>www\.(?P<host>dplay\.(?:dk|se|no)))/(?:videoer/)?(?P<id>[^/]+/[^/?#]+)'
+    _VALID_URL = r'https?://(?P<domain>www\.(?P<host>dplay\.(?P<country>dk|se|no)))/(?:videoer/)?(?P<id>[^/]+/[^/?#]+)'
-    _VALID_URL = r'https?://(?P<domain>www\.dplay\.(?:dk|se|no))/[^/]+/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?P<domain>www\.(?P<host>dplay\.(?:dk|se|no)))/(?:videoer/)?(?P<id>[^/]+/[^/?#]+)'
-            'display_id': 'season-1-svensken-lar-sig-njuta-av-livet',
+            'display_id': 'nugammalt-77-handelser-som-format-sverige/season-1-svensken-lar-sig-njuta-av-livet',
-            'display_id': 'season-6-episode-12',
+            'display_id': 'mig-og-min-mor/season-6-episode-12',
-            r'data-video-id=["\'](\d+)', webpage, 'video id')
+            r'data-video-id=["\'](\d+)', webpage, 'video id', default=None)
-                    'YouTube said: %s' % video_info['reason'][0],
+                    'YouTube said: %s' % reason,
-                video_webpage, 'unavailable message', default=None)
+            unavailable_message = extract_unavailable_message()
-    qualities,
+    ExtractorError,
-            'thumbnail': r're:http://.*\.jpg',
+            'thumbnail': r're:https?://.*\.(?:jpg|png)',
-        },
+        'only_matching': True,
-            'formats': formats,
+            'thumbnail': thumbnail,
-                    'http://www.%s.com/service/token_spe' % site,
+                    'http://token.vgtf.net/token/token_spe',
-import base64
+from .compat import compat_b64decode
-    data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))
+    data = bytes_to_intlist(compat_b64decode(data))
-import base64
+    compat_b64decode,
-            bootstrap = base64.b64decode(node.text.encode('ascii'))
+            bootstrap = compat_b64decode(node.text)
-            metadata = base64.b64decode(metadata_node.text.encode('ascii'))
+            metadata = compat_b64decode(metadata_node.text)
-from ..compat import compat_ord
+from ..compat import (
-            bytes_to_intlist(base64.b64decode(enc_subtitles[24:])),
+            bytes_to_intlist(compat_b64decode(enc_subtitles[24:])),
-            bytes_to_intlist(base64.b64decode(enc_subtitles[:24]))
+            bytes_to_intlist(compat_b64decode(enc_subtitles[:24]))
-from ..compat import compat_urllib_parse_unquote
+from ..compat import (
-                quoted_b64_url).encode('ascii')).decode('utf-8')
+            return compat_b64decode(compat_urllib_parse_unquote(
-import base64
+from ..compat import compat_b64decode
-        decoded_video_info = base64.b64decode(base64_video_info.encode('utf-8')).decode('utf-8')
+        decoded_video_info = compat_b64decode(base64_video_info).decode('utf-8')
-import base64
+from ..compat import compat_b64decode
-            data_fd[::-1].encode('ascii')).decode('utf-8')
+        audio_url = compat_b64decode(data_fd[::-1]).decode('utf-8')
-import base64
+    compat_b64decode,
-        iv = bytes_to_intlist(base64.b64decode(iv.encode('utf-8')))
+        data = bytes_to_intlist(compat_b64decode(data))
-                base64.b64decode(encrypted_rtn)),
+                compat_b64decode(encrypted_rtn)),
-import base64
+from ..compat import compat_b64decode
-            base64.b64decode(files_base64.encode('utf-8')).decode('utf-8'),
+            compat_b64decode(files_base64).decode('utf-8'),
-    compat_urlparse,
+    compat_b64decode,
-        return self._parse_json(base64.b64decode((
+        return self._parse_json(compat_b64decode((
-        ).encode('ascii')).decode('utf-8'), video_id)
+        )).decode('utf-8'), video_id)
-
+from ..compat import compat_b64decode
-        redirect_url = base64.b64decode(video_url_base64).decode('utf-8')
+        redirect_url = compat_b64decode(video_url_base64).decode('utf-8')
-
+    compat_b64decode,
-        real_id = compat_urllib_parse_unquote(base64.b64decode(encoded_id.encode('ascii')).decode('utf-8'))
+        real_id = compat_urllib_parse_unquote(compat_b64decode(encoded_id).decode('utf-8'))
-import base64
+    compat_b64decode,
-            return base64.b64decode(s.encode('utf-8')).decode('utf-8')
+            return compat_b64decode(s).decode('utf-8')
-    int_or_none,
+from ..compat import (
-        return base64.b64decode(compat_urllib_parse_unquote(page_id).encode()).decode()
+        return compat_b64decode(compat_urllib_parse_unquote(page_id)).decode()
-import base64
+
-from ..compat import compat_str
+from ..compat import (
-                s_url = base64.b64decode(url_data.encode('ascii')).decode('utf-8')
+                s_url = compat_b64decode(url_data).decode('utf-8')
-import base64
+    compat_b64decode,
-        data, iv = base64.b64decode(stream_data['streamUrl']).decode().split(':')
+        data, iv = compat_b64decode(stream_data['streamUrl']).decode().split(':')
-            bytes_to_intlist(base64.b64decode(data)),
+            bytes_to_intlist(compat_b64decode(data)),
-            bytes_to_intlist(base64.b64decode(iv))
+            bytes_to_intlist(compat_b64decode(iv))
-    encrypted_data = base64.b64decode(png.encode('utf-8'))
+    encrypted_data = compat_b64decode(png)
-
+from ..compat import compat_b64decode
-            'full:title', webpage, 'title').encode('utf-8')).decode('utf-8')
+        title = compat_b64decode(self._html_search_meta(
-                x.encode('ascii')).decode('utf-8'))[0]
+            transform_source=lambda x: compat_b64decode(x).decode('utf-8'))[0]
-import base64
+from ..compat import (
-                    raw_data = base64.b64decode(cur_sequence)
+                    raw_data = compat_b64decode(cur_sequence)
-from ..compat import compat_parse_qs
+from ..compat import (
-        video_url = base64.b64decode(compat_parse_qs(data_content)['kpt'][0].encode('utf-8')).decode('utf-8')
+        video_url = compat_b64decode(compat_parse_qs(data_content)['kpt'][0]).decode('utf-8')
-            encrypted_play_info = base64.b64decode(encrypted_play_info)
+            encrypted_play_info = compat_b64decode(encrypted_play_info)
-            kpa_target = base64.b64decode(info_json['streamInfo']['url'])
+            kpa_target = compat_b64decode(info_json['streamInfo']['url'])
-                decrypted = self._decrypt_xor_cipher(key, base64.b64decode(format_url))
+                decrypted = self._decrypt_xor_cipher(key, compat_b64decode(format_url))
-__version__ = '2018.01.18'
+__version__ = '2018.01.21'
-        r'proMamsId&quot;:&quot;(\d+)',
+        r'proMamsId&quot;\s*:\s*&quot;(\d+)',
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>southparkstudios\.dk/(?:clips|full-episodes|collections)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southparkstudios\.(?:dk|nu)/(?:clips|full-episodes|collections)/(?P<id>.+?)(\?|#|$))'
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.cc\.com/(?:clips|(?:full-)?episodes)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.cc\.com/(?:clips|(?:full-)?episodes|collections)/(?P<id>.+?)(\?|#|$))'
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.de/(?:clips|alle-episoden)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.de/(?:clips|alle-episoden|collections)/(?P<id>.+?)(\?|#|$))'
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.nl/(?:clips|(?:full-)?episodes)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.nl/(?:clips|(?:full-)?episodes|collections)/(?P<id>.+?)(\?|#|$))'
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>southparkstudios\.dk/(?:clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southparkstudios\.dk/(?:clips|full-episodes|collections)/(?P<id>.+?)(\?|#|$))'
-        other_ies = [get_info_extractor(ie_key) for ie_key in test_case.get('add_ie', [])]
+        ie = youtube_dl.extractor.get_info_extractor(test_case['name'])()
-            r'class=["\']cover-emission-period["\'][^>]*>[^<]+\s+(\d{1,2}\s+[^\s]+\s+\d{4})<',
+            r'class=["\']\s*cover-emission-period\s*["\'][^>]*>[^<]+\s+(\d{1,2}\s+[^\s]+\s+\d{4})<',
-            elif ext == 'mpd':
+            elif source_type == 'dash' or ext == 'mpd':
-    _TEST = {
+    _VALID_URL = r'https?://(?:(?:www|portal)\.)?restudy\.dk/video/[^/]+/id/(?P<id>[0-9]+)'
-    }
+    }, {
-            'https://www.restudy.dk/awsmedia/SmilDirectory/video_%s.xml' % video_id,
+            'https://cdn.portal.restudy.dk/dynamic/themes/front/awsmedia/SmilDirectory/video_%s.xml' % video_id,
-        [a-zA-Z_][.a-zA-Z_0-9]*|
+        (?:(?<![0-9])[eE]|[a-df-zA-DF-Z_])[.a-zA-Z_0-9]*|
-                'type', webpage, 'page type', default=None)
+                'type', webpage, 'page type', default='')
-            if page_type == 'video' and video_id and re.match(r'^[0-9A-Za-z_-]{11}$', video_id):
+            if page_type.startswith('video') and video_id and re.match(
-__version__ = '2018.01.14'
+__version__ = '2018.01.18'
-    _CLIENT_ID = 'c6CU49JDMapyrQo06UxU9xouB9ZVzqCn'
+    _CLIENT_ID = 'DQskPX1pntALRzMp4HSxya3Mc0AO66Ro'
-from .nexx import NexxEmbedIE
+from .nexx import (
-                    fail(response['message'])
+                    fail(response.get('message') or response['errors'][0])
-            redirect_url = urljoin(post_url, response['redirect'])
+            if 'Authenticated successfully' in response.get('message', ''):
-            'Video %s has been removed from public access due to rightholder complaint.',
+            ERROR_COPYRIGHT,
-__version__ = '2018.01.07'
+__version__ = '2018.01.14'
-        elif len(video_info.get('url_encoded_fmt_stream_map', [''])[0]) >= 1 or len(video_info.get('adaptive_fmts', [''])[0]) >= 1:
+        elif not is_live and (len(video_info.get('url_encoded_fmt_stream_map', [''])[0]) >= 1 or len(video_info.get('adaptive_fmts', [''])[0]) >= 1):
-            'display_id': 'dfb-team-geht-gut-gelaunt-ins-spiel-gegen-polen-100',
+            'id': 'mdb-1557833',
-            'upload_date': '20160615',
+            'title': 'Biathlon-Staffel verpasst Podest bei Olympia-Generalprobe',
-        'skip': 'Geo-restricted to Germany',
+    _GEO_COUNTRIES = ['DE']
-from .sportschau import SportschauIE
+    WDRPageIE,
-        return info
+from ..compat import (
-            return
+class WDRIE(InfoExtractor):
-        return media_link_obj['mediaObj']['url']
+    def _real_extract(self, url):
-            jsonp_url, display_id, transform_source=strip_jsonp)
+            url, video_id, transform_source=strip_jsonp)
-        metadata_media_resource = metadata['mediaResource']
+        is_live = metadata.get('mediaType') == 'live'
-        for kind, media_resource in metadata_media_resource.items():
+        for kind, media_resource in media_resource.items():
-                        medium_url, display_id, 'mp4', 'm3u8_native',
+                        medium_url, video_id, 'mp4', 'm3u8_native',
-                        manifest_url, display_id, f4m_id='hds', fatal=False))
+                        manifest_url, video_id, f4m_id='hds', fatal=False))
-                            medium_url, display_id, note='Determining extension')
+                            medium_url, video_id, note='Determining extension')
-        caption_url = metadata_media_resource.get('captionURL')
+        caption_url = media_resource.get('captionURL')
-        title = metadata_tracker_data['trackerClipTitle']
+        title = tracker_data['trackerClipTitle']
-            'alt_title': metadata_tracker_data.get('trackerClipSubcategory'),
+            'id': tracker_data.get('trackerClipId', video_id),
-            'upload_date': unified_strdate(metadata_tracker_data.get('trackerClipAirTime')),
+            'upload_date': unified_strdate(tracker_data.get('trackerClipAirTime')),
-class WDRIE(WDRBaseIE):
+class WDRPageIE(InfoExtractor):
-    _VALID_URL = r'(?P<page_url>https?://(?:www\d\.)?wdr\d?\.de)' + _PAGE_REGEX + '|' + _CURRENT_MAUS_URL
+    _PAGE_REGEX = r'/(?:mediathek/)?(?:[^/]+/)*(?P<display_id>[^/]+)\.html'
-                'id': 'mdb-103364',
+                'id': 'mdb-1406149',
-                'title': r're:^WDR Fernsehen im Livestream [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
+                'title': r're:^WDR Fernsehen im Livestream \(nur in Deutschland erreichbar\) [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-                'description': 'md5:ae2ff888510623bf8d4b115f95a9b7c9',
+                'upload_date': '20150101',
-            'playlist_mincount': 8,
+            'playlist_mincount': 7,
-                'id': 'aktuelle-stunde/aktuelle-stunde-120',
+                'id': 'aktuelle-stunde-120',
-                'id': 'mdb-1323501',
+                'id': 'mdb-1552552',
-                'description': 'md5:2309992a6716c347891c045be50992e4',
+                'ext': 'mp4',
-        is_live = url_type == 'live'
+        entries = []
-            info_dict['upload_date'] = unified_strdate(self._html_search_meta('DC.Date', webpage, 'upload date'))
+        # Article with several videos
-        })
+        # for wdr.de the data-extension is in a tag with the class "mediaLink"
-        return info_dict
+        # Playlist (e.g. https://www1.wdr.de/mediathek/video/sendungen/aktuelle-stunde/aktuelle-stunde-120.html)
-            },
+class WDRElefantIE(InfoExtractor):
-    ]
+        'params': {
-        display_id = mobj.group('display_id')
+        display_id = self._match_id(url)
-            'https://www.wdrmaus.de/elefantenseite/data/tableOfContentsJS.php5', display_id)
+            'https://www.wdrmaus.de/elefantenseite/data/tableOfContentsJS.php5',
-            'https://www.wdrmaus.de/elefantenseite/' + xml_metadata_path, display_id)
+            'https://www.wdrmaus.de/elefantenseite/' + xml_metadata_path,
-        return info_dict
+                '%s is not a video' % display_id, expected=True)
-    def _extract_wdr_video(self, webpage, display_id):
+    def _extract_jsonp_url(self, webpage, display_id):
-        jsonp_url = media_link_obj['mediaObj']['url']
+        return media_link_obj['mediaObj']['url']
-        info_dict = self._extract_wdr_video(webpage, display_id)
+        jsonp_url = self._extract_jsonp_url(webpage, display_id)
-    ]
+    _VALID_URL = r'https?://(?:www\.)?game(?P<site>pro|star)\.de/videos/.*,(?P<id>[0-9]+)\.html'
-        webpage = self._download_webpage(url, video_id)
+        mobj = re.match(self._VALID_URL, url)
-        url = 'http://gamestar.de/_misc/videos/portal/getVideoUrl.cfm?premium=0&videoId=' + video_id
+        webpage = self._download_webpage(url, video_id)
-        info_dict['title'] = remove_end(info_dict['title'], ' - GamePro')
+        info_dict['title'] = remove_end(
-            webpage, 'comment_count', fatal=False))
+            r'<span>Kommentare</span>\s*<span[^>]+class=["\']count[^>]+>\s*\(\s*([0-9]+)',
-            'url': url,
+            'url': 'http://gamestar.de/_misc/videos/portal/getVideoUrl.cfm?premium=0&videoId=' + video_id,
-    }
+    _VALID_URL = r'https?://(?:www\.)?game(?:pro|star)\.de/videos/.*,(?P<id>[0-9]+)\.html'
-        view_count = json_ld.get('interactionCount')
+        view_count = int_or_none(json_ld.get('interactionCount'))
-            fatal=False))
+            r'<span>Kommentare</span><span class="count">\(([0-9]+)\)</span>',
-                    compat_urlparse.urlparse(url).netloc.rsplit('.', 1)[-1]]}),
+                {
-                                (?:.+?\.)?channel\.pandora\.tv/channel/video\.ptv\?         # old format
+                                (?:.+?\.)?channel\.pandora\.tv/channel/video\.ptv\?|        # old format
-    _VALID_URL = r'https?://(?:.+?\.)?channel\.pandora\.tv/channel/video\.ptv\?'
+    _VALID_URL = r'''(?x)
-            raise ExtractorError('Invalid URL', expected=True)
+        mobj = re.match(self._VALID_URL, url)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        }
+        info = self._parse_json(
-            metadata)
+        return self._extract_info_helper(pc, mobile, 0, metadata)
-                medias['media_list'][i])
+            self._extract_info_helper(pc, mobile, i, medias['media_list'][i])
-                    src + '?hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id, f4m_id='hds'))
+                    src + '?hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id,
-                    src, video_id, 'mp4', m3u8_id='hls', entry_protocol='m3u8_native'))
+                    src, video_id, 'mp4', m3u8_id='hls',
-    compat_urlparse,
+    compat_parse_qs,
-        webpage, urlh = self._download_webpage_handle(url, video_id, note="first visit the page")
+        webpage, urlh = self._download_webpage_handle(url, video_id)
-        self._download_webpage(gencallback_url, video_id, note="gen callback", query=query)
+        if 'passport.weibo.com' in visitor_url:
-        webpage = self._download_webpage(url, video_id, note="retry to visit the page")
+        formats = []
-        title = self._html_search_regex(r'<title>(.+?)</title>', webpage, 'title')
+            vid_url = vid_urls[0]
-        video_sources_text = self._search_regex(r'video-sources=\\\"(.+?)\"', webpage, 'video_sources')
+        self._sort_formats(formats)
-        video_formats = compat_urlparse.parse_qs(video_sources_text)
+        uploader = self._og_search_property(
-        uploader = weibo_info.get('status').get('user').get('screen_name')
+        webpage = self._download_webpage(url, video_id, note='visit the page')
-    _VALID_URL = r'https?://(?:(?:www|m|mobile)\.)?(?:odnoklassniki|ok)\.ru/(?:video(?:embed)?|web-api/video/moviePlayer)/(?P<id>[\d-]+)'
+    _VALID_URL = r'https?://(?:(?:www|m|mobile)\.)?(?:odnoklassniki|ok)\.ru/(?:video(?:embed)?|web-api/video/moviePlayer|live)/(?P<id>[\d-]+)'
-        'md5': '6ba728d85d60aa2e6dd37c9e70fdc6bc',
+        'md5': '0b62089b479e06681abaaca9d204f152',
-        'skip': 'Video has been blocked',
+    }, {
-                    '''
+    IE_DESC = 'mycanal.fr and piwiplus.fr'
-        'canalplus': 'cplus',
+        'mycanal': 'cplus',
-        'url': 'http://www.canalplus.fr/c-emissions/pid1830-c-zapping.html?vid=1192814',
+        'url': 'https://www.mycanal.fr/d17-emissions/lolywood/p/1397061',
-            'display_id': 'pid1830-c-zapping',
+            'id': '1397061',
-            'upload_date': '20160702',
+            'title': 'Euro 2016 : Je prÃ©fÃ¨re te prÃ©venir - Lolywood - Episode 34',
-        display_id = remove_end(dict_get(mobj.groupdict(), ('display_id', 'id', 'vid')), '.html')
+        site, display_id, video_id = re.match(self._VALID_URL, url).groups()
-            webpage, 'video id', default=mobj.group('vid'), group='id')
+        site_id = self._SITE_ID_MAP[site]
-                    # the secret extracted ya function in http://player.canalplus.fr/common/js/canalPlayer.js
+                    # the secret extracted from ya function in http://player.canalplus.fr/common/js/canalPlayer.js
-            headers=self.geo_verification_headers())
+            headers=headers)
-__version__ = '2017.12.31'
+__version__ = '2018.01.07'
-            return self.url_result(jwplatform_url, 'JWPlatform')
+        jwplatform_urls = JWPlatformIE._extract_urls(webpage)
-            r'<(?:script|iframe)[^>]+?src=["\'](?P<url>(?:https?:)?//content.jwplatform.com/players/[a-zA-Z0-9]{8})',
+        urls = JWPlatformIE._extract_urls(webpage)
-        ]
+        entries = []
-                r'href="/([^"]+)"[^>]+>\s+<img[^>]+alt="[^-]+-\s([^"]+)"',
+                r'href="(/[^"]+)"[^>]+>\s+<img[^>]+alt="[^-]+-\s([^"]+)"',
-                loc = location.get('loc')
+                gcp = location.get('gcp')
-                if None in (gat, bas, loc, ogn):
+                if None in (gat, gcp, ogn):
-                    'icd': loc,
+                    'gcp': gcp,
-                    'sta': '0',
+                    'sta': 0,
-                if not file_:
+                    gat, video_id, data=json.dumps(token_data).encode('utf-8'),
-                ext = determine_ext(file_)
+                ext = determine_ext(stream)
-                        file_ + '&hdcore=3.2.0&plugin=aasp-3.2.0.77.18',
+                        stream + '&hdcore=3.2.0&plugin=aasp-3.2.0.77.18',
-                        file_, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+                        stream, video_id, 'mp4', 'm3u8_native',
-from .motherless import MotherlessIE
+from .motherless import (
-    _VALID_URL = r'https?://(?:www\.)?(?:lynda\.com|educourse\.ga)/(?:[^/]+/[^/]+/(?P<course_id>\d+)|player/embed)/(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-    _VALID_URL = r'https?://(?:www|m)\.(?:lynda\.com|educourse\.ga)/(?P<coursepath>[^/]+/[^/]+/(?P<courseid>\d+))-\d\.html'
+    _VALID_URL = r'https?://(?:www|m)\.(?:lynda\.com|educourse\.ga)/(?P<coursepath>(?:[^/]+/){2,3}(?P<courseid>\d+))-2\.html'
-        thumbnail = info.get('artwork_url')
+        thumbnail = info.get('artwork_url') or info.get('user', {}).get('avatar_url')
-            transform_source=lambda s: js_to_json(strip_jsonp(s)))['html']
+            transform_source=lambda s: js_to_json(strip_jsonp(s))).get('html')
-
+            if new_entries is not None:
-                      get_element_by_id('streamuri', webpage))
+                      get_element_by_id('streamuri', webpage) or
-            return {'en': [{'ext': 'srt', 'data': self._fix_subtitles(subs)}]}
+        fixed_subs = self._fix_subtitles(subs)
-            [self.url_result(entry) for entry in orderedSet(entries)],
+            [self._make_url_result(entry) for entry in orderedSet(entries)],
-    parse_iso8601,
+    unified_timestamp,
-        'md5': '55c0097badd7095f494c99a172f86501',
+        'md5': 'e87d5b8516cd04c0d81b6ee1caca28d0',
-            'duration': 2797,
+            'duration': 2766,
-            'https://embed.acast.com/api/acasts/%s/%s' % (channel, display_id), display_id)
+            'https://play-api.acast.com/splash/%s/%s' % (channel, display_id), display_id)
-            'id': compat_str(cast_data['id']),
+            'id': compat_str(e['id']),
-            'duration': int_or_none(cast_data.get('duration')),
+            'url': e['mediaUrl'],
-    GetStdHandle = ctypes.WINFUNCTYPE(
+    GetStdHandle = compat_ctypes_WINFUNCTYPE(
-        (b'GetStdHandle', ctypes.windll.kernel32))
+        ('GetStdHandle', ctypes.windll.kernel32))
-    WriteConsoleW = ctypes.WINFUNCTYPE(
+    WriteConsoleW = compat_ctypes_WINFUNCTYPE(
-        ctypes.wintypes.LPVOID)((b'WriteConsoleW', ctypes.windll.kernel32))
+        ctypes.wintypes.LPVOID)(('WriteConsoleW', ctypes.windll.kernel32))
-    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)((b'GetFileType', ctypes.windll.kernel32))
+    GetFileType = compat_ctypes_WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)(('GetFileType', ctypes.windll.kernel32))
-    GetConsoleMode = ctypes.WINFUNCTYPE(
+    GetConsoleMode = compat_ctypes_WINFUNCTYPE(
-        (b'GetConsoleMode', ctypes.windll.kernel32))
+        ('GetConsoleMode', ctypes.windll.kernel32))
-            platform.python_version(), platform_name()))
+
-        page_info = weibo_info['status']['page_info']
+        page_info = weibo_info.get('status').get('page_info')
-__version__ = '2017.12.28'
+__version__ = '2017.12.31'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        webpage = self._download_webpage(url, video_id)
+
-        'url': 'http://iview.abc.net.au/programs/diaries-of-a-broken-mind/ZX9735A001S00',
+        'url': 'http://iview.abc.net.au/programs/call-the-midwife/ZW0898A003S00',
-            'id': 'ZX9735A001S00',
+            'id': 'ZW0898A003S00',
-            'timestamp': 1476064920,
+            'title': 'Series 5 Ep 3',
-        format_urls = []
+            int(time.time()), house_number)
-                    self._extract_m3u8_formats(format_url, video_id, 'mp4'))
+            return update_url_query(url, {
-            try_get(stream, lambda x: x['hds-unmetered'], compat_str)]
+        key = 'android.content.res.Resources'.encode('utf-8')
-            stream, lambda x: x['streams']['hds']['sd'], compat_str)
+            stream, lambda x: x['streams']['hls']['sd'], compat_str)
-            format_urls.append(sd_url.replace('metered', 'um'))
+            format_urls.append(tokenize_url(sd_url, token))
-                    self._extract_akamai_formats(format_url, video_id))
+                    self._extract_m3u8_formats(format_url, video_id, 'mp4'))
-                        decrypt_info['KEY'] = decrypt_info.get('KEY') or self.ydl.urlopen(decrypt_info['URI']).read()
+                        decrypt_info['KEY'] = decrypt_info.get('KEY') or self.ydl.urlopen(
-        decoded_id = get_element_by_id('streamurl', webpage)
+        decoded_id = (get_element_by_id('streamurl', webpage) or
-                { 'UrlReferrer': url }), 'Livestream')
+        mediasite_urls = MediasiteIE._extract_urls(webpage)
-from ..compat import compat_urlparse
+from ..compat import (
-    mimetype2ext,
+    mimetype2ext,
-    '''
+    _VALID_URL = r'(?xi)https?://[^/]+/Mediasite/Play/(?P<id>[0-9a-f]{32,34})(?P<query>\?[^#]+|)'
-        0: 'video1', # the main video
+        0: 'video1',  # the main video
-        4: 'video2', # screencast?
+        4: 'video2',  # screencast?
-        QueryString = mobj.group('QueryString')
+        resource_id = mobj.group('id')
-        webpage = self._download_webpage(url, ResourceId) # XXX: add UrlReferrer?
+        webpage, urlh = self._download_webpage_handle(url, resource_id)  # XXX: add UrlReferrer?
-            r'<div id="ServicePath">(.+?)</div>', webpage, ResourceId,
+        service_path = compat_urlparse.urljoin(redirect_url, self._html_search_regex(
-            '%s/GetPlayerOptions' % (ServicePath), ResourceId,
+        player_options = self._download_json(
-                    'QueryString': QueryString,
+                    'ResourceId': resource_id,
-                (PlayerOptions['d']['PlayerPresentationStatusMessage'],),
+            }).encode('utf-8'))['d']
-                Stream['StreamType'], 'type%u' % Stream['StreamType'])
+        for snum, Stream in enumerate(presentation['Streams']):
-                url = VideoUrl['Location']
+            for unum, VideoUrl in enumerate(video_urls):
-                if VideoUrl['MediaType'] == 'SS':
+                media_type = VideoUrl.get('MediaType')
-                })
+                        video_url, resource_id,
-            if Stream['StreamType'] != 0:
+            if stream_type != 0:
-            if ThumbnailUrl:
+            thumbnail_url = Stream.get('ThumbnailUrl')
-                    'preference': -1 if Stream['StreamType'] != 0 else 0,
+                    'id': '%s-%u' % (stream_id, snum),
-            'timestamp': float_or_none(Presentation.get('UnixTime'), 1000),
+            'id': resource_id,
-from .collegerama import CollegeRamaIE
+from .mediasite import MediasiteIE
-from .sandia import SandiaIE
+        # Look for Mediasite embeds
-                fourcc = track.get('FourCC')
+                fourcc = track.get('FourCC', 'AACL' if track.get('AudioTag') == '255' else None)
-                float_or_none(dict_get(current, TIME_OFFSET_KEYS)),
+                float_or_none(dict_get(current, TIME_OFFSET_KEYS, skip_false_values=False)),
-                dict_get(subs[num + 1], TIME_OFFSET_KEYS))
+                dict_get(subs[num + 1], TIME_OFFSET_KEYS, skip_false_values=False))
-        url = 'https://openload.co/embed/%s/' % video_id
+        url_pattern = 'https://openload.co/%%s/%s/' % video_id
-            raise ExtractorError('File not found', expected=True, video_id=video_id)
+        for path in ('embed', 'f'):
-        webpage, _ = phantom.get(url, html=webpage, video_id=video_id, headers=headers)
+        webpage, _ = phantom.get(page_url, html=webpage, video_id=video_id, headers=headers)
-        entries = self._parse_html5_media_entries(url, webpage, video_id)
+        entries = self._parse_html5_media_entries(page_url, webpage, video_id)
-                return self.url_result(urlh.geturl(), VimeoOndemandIE.ie_key())
+            if VimeoOndemandIE.suitable(redirect_url):
-                self._verify_video_password(url, video_id, webpage)
+                self._verify_video_password(redirect_url, video_id, webpage)
-                    smuggle_url(url, {'_video_password_verified': 'verified'}))
+                    smuggle_url(redirect_url, {'_video_password_verified': 'verified'}))
-                config = self._verify_player_video_password(url, video_id)
+                config = self._verify_player_video_password(redirect_url, video_id)
-        webpage, _ = self._download_webpage_handle(genvisitor_url, video_id, data=data, headers=headers, note="gen visitor")
+        webpage = self._download_webpage(genvisitor_url, video_id, data=data, headers=headers, note="gen visitor")
-        self._download_webpage_handle(gencallback_url, video_id, note="gen callback", query=query)
+        self._download_webpage(gencallback_url, video_id, note="gen callback", query=query)
-        webpage, _ = self._download_webpage_handle(url, video_id, note="retry to visit the page")
+        webpage = self._download_webpage(url, video_id, note="retry to visit the page")
-        webpage, _ = self._download_webpage_handle(url, video_id, note="visit the page")
+        webpage = self._download_webpage(url, video_id, note="visit the page")
-        p = webpage.split("&&")[1]  # split "gen_callback && gen_callback(...)"
+        p = strip_jsonp(webpage)
-    compat_urllib_parse_urlencode,
+    urlencode_postdata,
-        data = compat_urllib_parse_urlencode({
+        data = urlencode_postdata({
-        }).encode()
+        })
-                            existing_format.update(f)
+                        # According to [1, 5.3.5.2, Table 7, page 35] @id of Representation
-        for header_name, header_value in headers.items():
+        for header_name, header_value in sorted(headers.items()):
-        signed_headers = ';'.join([header.lower() for header in headers.keys()])
+        signed_headers = ';'.join([header.lower() for header in sorted(headers.keys())])
-__version__ = '2017.12.23'
+__version__ = '2017.12.28'
-    _TESTS = [{
+    _VALID_URL = r'https?://(?:www\.)?internazionale\.it/video/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-        'md5': '11b54a3d3333e455c00684e50a65c58e',
+        'md5': '3e39d32b66882c1218e305acbf8348ca',
-            'description': 'md5:efb7e5bbfb1a54ae2ed5a4a015f0e665',
+            'description': 'md5:efb7e5bbfb1a54ae2ed5a4a015f0e665',
-    }]
+        },
-        webpage = self._download_webpage(url, video_id)
+        display_id = self._match_id(url)
-        data_video_path = self._html_search_regex(r'data-video-path="([^"]+)"', webpage, 'data-video-path')
+        webpage = self._download_webpage(url, display_id)
-        formats = []
+        DATA_RE = r'data-%s=(["\'])(?P<value>(?:(?!\1).)+)\1'
-            video_id))
+        title = self._search_regex(
-            video_id))
+        video_id = self._search_regex(
-            'title': self._og_search_title(webpage),
+            'id': video_id,
-            'description': 'md5:f93d398691044d303bc4a3de62f3e976',
+            'description': 'md5:4436e61b7df227a093778efb7e373571',
-            'title': 're:^PÅÃ­mÃ½ pÅenos iDNES.cz [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
+            'title': 're:^Planespotting [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-            'thumbnail': r're:(?i)^https?://.*\.(?:jpg|png)$',
+            'is_live': True,
-            r'Misc\.videoFLV\(\s*{\s*data\s*:\s*"([^"]+)"', webpage, 'info url')
+            r'Misc\.video(?:FLV)?\(\s*{\s*data\s*:\s*"([^"]+)"', webpage, 'info url')
-            'description', webpage, 'description')
+            'description', webpage, 'description', default=None)
-from .twentythreevideo import TwentyThreeVideoIE
+import re
-    _VALID_URL = r'https?://(?:www\.)?filmweb\.no/trailere/article(?P<id>\d+).ece'
+
-            'title': 'Det som en gang var',
+            'id': '13033574',
-            'description': 'Trailer: Scener fra et vennskap',
+            'title': 'Det som en gang var',
-        self._sort_formats(formats)
+        article_type, article_id = re.match(self._VALID_URL, url).groups()
-            'description': self._og_search_description(webpage),
+            'url': iframe_url,
-            'height': 180,
+    _VALID_URL = r'https?://video\.(?P<domain>twentythree\.net|23video\.com|filmweb\.no)/v\.ihtml/player\.html\?(?P<query>.*?\bphoto(?:_|%5f)id=(?P<id>\d+).*)'
-        token = self._search_regex(r'token=([^?&]+)', url, 'token')
+    def _real_extract(self, url):
-        for format_key in self._FORMATS.keys():
+
-                'height': self._FORMATS.get(format_key, {}).get('height'),
+                'format_id': 'audio',
-        return formats
+        for f in ('mobile_high', 'medium', 'hd', '1080p', '4k'):
-        raise NotImplementedError('Not able to extract the `client_id`')
+        thumbnails = []
-import random as rnd
+import random
-    compat_urlparse as parse,
+    compat_urllib_parse_urlencode,
-        webpage, urlh = self._download_webpage_handle(url, video_id, headers=headers, note="first visit the page")
+        webpage, urlh = self._download_webpage_handle(url, video_id, note="first visit the page")
-        data = urlencode({
+        fp = {
-            "fp": '{"os":"2","browser":"Gecko57,0,0,0","fonts":"undefined","screenInfo":"1440*900*24","plugins":""}',
+            "fp": json.dumps(fp),
-        webpage, urlh = self._download_webpage_handle(r_genvisitor, video_id, note="gen visitor")
+        genvisitor_url = 'https://passport.weibo.com/visitor/genvisitor'
-        param = urlencode({
+        query = {
-        webpage, urlh = self._download_webpage_handle(gencallback_url, video_id, note="gen callback")
+            '_rand': random.random()
-        webpage, urlh = self._download_webpage_handle(url, video_id, headers=headers, note="retry to visit the page")
+        webpage, _ = self._download_webpage_handle(url, video_id, note="retry to visit the page")
-        video_formats = parse.parse_qs(video_sources_text)
+        video_formats = compat_urlparse.parse_qs(video_sources_text)
-        supported_resolutions = ['720', '480']
+        supported_resolutions = ('720', '480')
-    _VALID_URL = r'https?://m.weibo.cn/status/(?P<id>[0-9]+)(\?.+)?'
+    _VALID_URL = r'https?://m\.weibo\.cn/status/(?P<id>[0-9]+)(\?.+)?'
-        webpage, urlh = self._download_webpage_handle(url, video_id, headers=headers, note="visit the page")
+        webpage, _ = self._download_webpage_handle(url, video_id, note="visit the page")
-        uploader = weibo_info['status']['user']['screen_name']
+        title = weibo_info.get('status').get('status_title')
-            # TODO more properties (see youtube_dl/extractor/common.py)
+            'url': page_info['media_info']['stream_url']
-    compat_urllib_request as Request,
+    compat_urllib_request as request,
-        r_genvisitor = Request(
+        r_genvisitor = request.Request(
-        video_sources_text = self._search_regex("video-sources=\\\\\"(.+?)\"", webpage, 'video_sources')
+        video_sources_text = self._search_regex(r'video-sources=\\\"(.+?)\"', webpage, 'video_sources')
-from os import path
+
-            }
+        'url': 'https://weibo.com/6275294458/Fp6RGfbff?type=comment',
-        webpage,urlh = self._download_webpage_handle(url, video_id, headers=headers, note="first visit the page")
+        webpage, urlh = self._download_webpage_handle(url, video_id, headers=headers, note="first visit the page")
-            }).encode()
+        }).encode()
-                }
+            'Accept-Encoding': 'gzip, deflate, br',
-        webpage,urlh = self._download_webpage_handle(r_genvisitor, video_id, note="gen visitor")
+            data=data,
-        p = webpage.split("&&")[1] # split "gen_callback && gen_callback(...)"
+        p = webpage.split("&&")[1]  # split "gen_callback && gen_callback(...)"
-        j = p[i1:i2+1] # get JSON object
+        j = p[i1:i2 + 1]  # get JSON object
-            })
+        })
-        webpage,urlh = self._download_webpage_handle(gencallback_url, video_id, note="gen callback")
+        webpage, urlh = self._download_webpage_handle(gencallback_url, video_id, note="gen callback")
-        webpage,urlh = self._download_webpage_handle(url, video_id, headers=headers, note="retry to visit the page")
+        webpage, urlh = self._download_webpage_handle(url, video_id, headers=headers, note="retry to visit the page")
-        
+
-                        })
+                    })
-        uploader = self._og_search_property('nick-name', webpage, 'uploader', default = None)
+        uploader = self._og_search_property('nick-name', webpage, 'uploader', default=None)
-                }
+            'id': video_id,
-            }
+        'url': 'https://m.weibo.cn/status/4189191225395228?wm=3333_2001&sourcetype=weixin&featurecode=newtitle&from=singlemessage&isappinstalled=0',
-        js_code = self._search_regex(r'var\s+\$render_data\s*=\s*\[({.*})\]\[0\] \|\| {};', webpage, 'js_code', flags = re.DOTALL)
+        webpage, urlh = self._download_webpage_handle(url, video_id, headers=headers, note="visit the page")
-                  }
+            'format': 'mp4',
-                }
+            'id': video_id,
-from urllib import parse
+from ..compat import (
-from .weibo import WeiboIE
+from .weibo import (
-class ESPNIE(InfoExtractor):
+class ESPNIE(OnceIE):
-                            )
+                                (?:
-                if isinstance(source, compat_str):
+                if source_id == 'alert':
-            if ext == 'smil':
+            if OnceIE.suitable(source_url):
-                formats.append({
+                f = {
-        traverse_source(clip['links']['source'])
+                }
-    }, {
+    }, {
-                entries.extend(initial_entries)
+        self._TMP_FILES = {}
-            except (IOError, OSError):
+            except (IOError, OSError, KeyError):
-    _VALID_URL = r'https?://(?:www\.)?(?:openload\.(?:co|io|link)|oload\.tv)/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:openload\.(?:co|io|link)|oload\.(?:tv|stream))/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
-            'ccode': '0501',
+            'ccode': '0507',
-__version__ = '2017.12.14'
+__version__ = '2017.12.23'
-                        \[\s*(?P<q2_1>["'])entry_?[Ii]d(?P=q2_1)\s*\]?\s*=\s*
+                        \[\s*(?P<q2_1>["'])entry_?[Ii]d(?P=q2_1)\s*\]\s*=\s*
-                    )\s*:\s*
+                        (?:
-            'id': '441353',
+            'id': '0_8ledb18o',
-            'https://cdnapisec.kaltura.com/p/1982551/playManifest/pt/https/f/applehttp/t/web/e/' + media['EntryId'],
+            'https://cdnapisec.kaltura.com/p/1982551/playManifest/pt/https/f/applehttp/t/web/e/' + entry_id,
-            'id': video_id,
+            'extractor_key': 'Kaltura',
-            'formats': 'mincount:22',
+            'formats': 'mincount:20',
-            'formats': 'mincount:41',
+            'formats': 'mincount:39',
-
+    def _parse_brightcove_metadata(self, json_data, video_id):
-            'uploader_id': account_id,
+            'uploader_id': json_data.get('account_id'),
-                r'<p[^>]+\bclass=(["\'])(?:(?!\1).)*\balert\s(?:(?!\1).)*\1[^>]*>(?P<error>.+?)</p>',
+                r'<p[^>]+\bclass=(["\'])(?:(?!\1).)*\balert\b(?:(?!\1).)*\1[^>]*>(?P<error>.+?)</p>',
-                response, 'error', default=None)
+                r'<p[^>]+\bclass=(["\'])(?:(?!\1).)*\balert\s(?:(?!\1).)*\1[^>]*>(?P<error>.+?)</p>',
-from .shahid import ShahidIE
+from .shahid import (
-from .common import InfoExtractor
+from .aws import AWSIE
-class ScrippsNetworksWatchIE(InfoExtractor):
+class ScrippsNetworksWatchIE(AWSIE):
-x-api-key:%(key)s
+    _AWS_PROXY_HOST = 'web.api.video.snidigital.com'
-%(payload_hash)s'''
+    _AWS_USER_AGENT = 'aws-sdk-js/2.80.0 callback'
-
+        aws_identity_id_json = json.dumps({
-            data=self._AWS_IDENTITY_ID_JSON.encode('utf-8'),
+            'https://cognito-identity.%s.amazonaws.com/' % self._AWS_REGION, video_id,
-                'X-Amz-Content-Sha256': aws_hash(self._AWS_IDENTITY_ID_JSON),
+                'X-Amz-Content-Sha256': hashlib.sha256(aws_identity_id_json).hexdigest(),
-            })['results'][0]['mcpId']
+        mcp_id = self._aws_execute_api({
-import re
+import math
-from .common import InfoExtractor
+from .aws import AWSIE
-class ShahidIE(InfoExtractor):
+class ShahidBaseIE(AWSIE):
-            })['user']
+        try:
-            video_id, 'Downloading player JSON')['playout']
+        playout = self._call_api(
-        video = self._get_api_data(self._download_json(
+        # video = self._call_api(
-            }))[page_type]
+            })
-        return has_videos, self.playlist_result(
+        playlist = self.playlist_result(
-    with the same semantics as videos (see above).
+    Additionally, playlists can have "id", "title", "description", "uploader",
-                    note='Downloading part %d m3u8 information' % file_num)
+                if determine_ext(file_url) == 'm3u8':
-                os.remove(ctx['fragment_filename_sanitized'])
+                os.remove(encodeFilename(ctx['fragment_filename_sanitized']))
-    smuggle_url,
+    find_xpath_attr,
-            for quality in f['qualities']:
+            for quality in f.get('qualities', []):
-    _VALID_URL = r'https?://(?:(?:www|m)\.)?my\.mail\.ru/(?:video/.*#video=/?(?P<idv1>(?:[^/]+/){3}\d+)|(?:(?P<idv2prefix>(?:[^/]+/){2})video/(?P<idv2suffix>[^/]+/\d+))\.html|video/embed/(?P<meta_id>\d+))'
+    _VALID_URL = r'''(?x)
-                'timestamp': 1393232740,
+                'timestamp': 1393235077,
-                'uploader': 'hitech@corp.mail.ru',
+                'uploader': 'hitech',
-        video_data = None
+        meta_id = mobj.group('metaid')
-        if not meta_id:
+        if meta_id:
-                    meta_url, video_id, 'Downloading video meta JSON', fatal=False)
+            else:
-
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?my\.mail\.ru/(?:video/.*#video=/?(?P<idv1>(?:[^/]+/){3}\d+)|(?:(?P<idv2prefix>(?:[^/]+/){2})video/(?P<idv2suffix>[^/]+/\d+))\.html|video/embed/(?P<meta_id>\d+))'
-
+        meta_id = mobj.group('meta_id')
-            meta_url = page_config.get('metaUrl') or page_config.get('video', {}).get('metaUrl')
+        video_id = None
-            if not sub_doc:
+            if sub_doc is None:
-            if streamdata:
+            if streamdata is not None:
-                if stream_info:
+                if stream_info is not None:
-            if stream_info:
+            if stream_info is not None:
-            timestamp = parse_iso8601(self._html_search_meta('uploadDate', webpage))
+        timestamp = unified_timestamp(self._html_search_regex(
-                subtitles.setdefault(lang, []).append({'url': subtitle_url})
+                ext = determine_ext(subtitle_url)
-            info_page, 'view count', fatal=False))
+            info_page, 'view count', default=None))
-                formats.extend(self._extract_m3u8_formats(
+                # wrong ks(Kaltura Signature) causes 404 Error
-                    m3u8_id=flavor_format, fatal=False))
+                    m3u8_id=flavor_format, fatal=False)
-            video_id, 'mp4', m3u8_id='hls', fatal=False)
+            video_id, 'mp4', m3u8_id='hls')
-            'id': '0_8ledb18o',
+            'id': '441353',
-        entry_id = media['EntryId']
+        formats = self._extract_m3u8_formats(
-            'ie_key': KalturaIE.ie_key(),
+            'id': video_id,
-__version__ = '2017.12.10'
+__version__ = '2017.12.14'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        rtmp_url = media_files.attrib['base']
+            elif fault_code != 'InvalidEntity':
-            formats.append(f)
+            for media_file in media_files.findall('MediaFile'):
-        self._sort_formats(formats)
+                subs = video_data.get('Subtitles')
-            })
+        self._sort_formats(formats)
-            'duartion': parse_duration(xpath_text(playlist, 'Duration')),
+            num_written = 0
-                    'Extended attributes are not written.')
+                    'There\'s no disk space left, disk quota exceeded or filesystem xattr limit exceeded. ' +
-                'x-byutv-context': 'web$Global',
+                'channel': 'byutv',
-                'x-byutv-context': 'web$Global',
+                'x-byutv-context': 'web$US',
-                return True
+                return download()
-    _VALID_URL = r'https?://(?:www\.)?byutv\.org/watch/(?!event/)(?P<id>[0-9a-f-]+)(?:/(?P<display_id>[^/?#&]+))?'
+    _VALID_URL = r'https?://(?:www\.)?byutv\.org/(?:watch|player)/(?!event/)(?P<id>[0-9a-f-]+)(?:/(?P<display_id>[^/?#&]+))?'
-            'id': '6587b9a3-89d2-42a6-a7f7-fd2f81840a7d',
+            'id': 'ZvanRocTpW-G5_yZFeltTAMv6jxOU9KH',
-            'thumbnail': r're:^https?://.*\.jpg$',
+            'description': 'md5:1d31dc18ef4f075b28f6a65937d22c65',
-            raise ExtractorError('Unsupported provider %s' % ep['provider'])
+        ep = self._download_json(
-            'title': ep['title'],
+            'title': ep.get('title'),
-)
+from .byutv import BYUtvIE
-        site = domain[:3]
+        site, display_id = re.match(self._VALID_URL, url).groups()
-                        'site_name': site.upper(),
+                        'site_name': site[:3].upper(),
-                                re.sub(self._USP_RE, r'/\1\.ism/\1\.m3u8', href),
+                                re.sub(self._USP_RE, r'/\1.ism/\1.m3u8', href),
-    _VALID_URL = r'https?://ici\.tou\.tv/(?P<id>[a-zA-Z0-9_-]+(?:/S[0-9]+E[0-9]+)?)'
+    _VALID_URL = r'https?://ici\.tou\.tv/(?P<id>[a-zA-Z0-9_-]+(?:/S[0-9]+[EC][0-9]+)?)'
-from .common import InfoExtractor
+import random
-    parse_iso8601,
+    ExtractorError,
-from ..compat import compat_str
+from ..compat import compat_HTTPError
-class DiscoveryIE(InfoExtractor):
+class DiscoveryIE(DiscoveryGoBaseIE):
-        )\.com/(?:[^/]+/)*(?P<id>[^./?#]+)'''
+        )\.com(?P<path>/tv-shows/[^/]+/(?:video|full-episode)s/(?P<id>[^./?#]+))'''
-        'url': 'http://www.discovery.com/tv-shows/mythbusters/videos/mission-impossible-outtakes.htm',
+        'url': 'https://www.discovery.com/tv-shows/cash-cab/videos/dave-foley',
-            'id': '20769',
+            'id': '5a2d9b4d6b66d17a5026e1fd',
-            'uploader_id': '103207',
+            'title': 'Dave Foley',
-        }
+        'url': 'https://www.investigationdiscovery.com/tv-shows/final-vision/full-episodes/final-vision',
-        video_title = info.get('playlist_title') or info.get('video_title')
+        path, display_id = re.match(self._VALID_URL, url).groups()
-        entries = []
+        react_data = self._parse_json(self._search_regex(
-                }
+        access_token = self._download_json(
-            })
+        try:
-        return self.playlist_result(entries, display_id, video_title)
+        return self._extract_video_info(video, stream, display_id)
-
+    def _extract_video_info(self, video, stream, display_id):
-        stream = video.get('stream')
+class DiscoveryGoIE(DiscoveryGoBaseIE):
-)
+from .tvnow import (
-            entries, compat_str(season.get('id') or season_id), title)
+# coding: utf-8
-    NickBeIE,
+    NickBrIE,
-class NickBeIE(MTVServicesInfoExtractor):
+class NickBrIE(MTVServicesInfoExtractor):
-    _VALID_URL = r'https?://(?:(?:www|beta)\.)?nick(?:jr)?\.com/(?:[^/]+/)?(?:videos/clip|[^/]+/videos)/(?P<id>[^/?#.]+)'
+    _VALID_URL = r'https?://(?P<domain>(?:(?:www|beta)\.)?nick(?:jr)?\.com)/(?:[^/]+/)?(?:videos/clip|[^/]+/videos)/(?P<id>[^/?#.]+)'
-        return self._search_regex(r'data-contenturi="([^"]+)', webpage, 'mgid')
+    def _real_extract(self, url):
-from ..utils import extract_attributes
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?(?P<site>tbs|tntdrama)\.com/videos/(?:[^/]+/)+(?P<id>[^/?#]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?(?P<site>tbs|tntdrama)\.com/(?:movies|shows/[^/]+/(?:clips|season-\d+/episode-\d+))/(?P<id>[^/?#]+)'
-        'md5': '9e61d680e2285066ade7199e6408b2ee',
+        'url': 'http://www.tntdrama.com/shows/the-alienist/clips/monster',
-            'id': '2007318',
+            'id': '8d384cde33b89f3a43ce5329de42903ed5099887',
-            'description': 'Catch the latest comedy from TBS, People of Earth, premiering Halloween night--Monday, October 31, at 9/8c.',
+            'title': 'Monster',
-        'skip': 'TBS videos are deleted after a while',
+        'params': {
-        'skip': 'TBS videos are deleted after a while',
+        'url': 'http://www.tbs.com/shows/search-party/season-1/episode-1/explicit-the-mysterious-disappearance-of-the-girl-no-one-knew',
-            })
+        video_data = self._parse_json(self._search_regex(
-                video_url = video_url + '?hdnea=' + token
+                video_url = self._add_akamai_spe_token(
-                        'url': vid_url
+                        'url': vid_url,
-        print(title, uploader)
+from urllib import parse
-            'md5': 'TODO: md5 sum of the first 10241 bytes of the video file (use --test)',
+            'url': 'https://weibo.com/6275294458/Fp6RGfbff?type=comment',
-                'id': '42',
+                'id': 'Fp6RGfbff',
-                # * Any Python type (for example int or float)
+                'title': 'You should have servants to massage you,... æ¥èªHosico_ç« - å¾®å',
-        print("video_sources:", video_sources)
+        video_sources_text = self._search_regex("video-sources=\\\\\"(.+?)\"", webpage, 'video_sources')
-                'uploader': self._search_regex(r'<div[^>]+id="uploader"[^>]*>([^<]+)<', webpage, 'uploader', fatal=False),
+                'uploader': uploader,
-__version__ = '2017.12.02'
+__version__ = '2017.12.10'
-            r'"https?://videos\.francetv\.fr/video/([^@]+@[^"]+)"', webpage, 'video id').split('@')
+            r'["\'>]https?://videos\.francetv\.fr/video/([^@]+@.+?)["\'<]',
-    _VALID_URL = r'https?://(?:www\.)?twitter\.com/i/(?:cards/tfw/v1|videos(?:/tweet)?)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?twitter\.com/i/(?P<path>cards/tfw/v1|videos(?:/tweet)?)/(?P<id>\d+)'
-                'title': 'Twitter Card',
+                'title': 'Twitter web player',
-                'duration': 80.155,
+                'title': 'Twitter web player',
-                vbr = int_or_none(dict_get(media_variant, ('bitRate', 'bitrate')), scale=1000)
+                tbr = int_or_none(dict_get(media_variant, ('bitRate', 'bitrate')), scale=1000)
-                    'vbr': vbr,
+                    'format_id': 'http-%d' % tbr if tbr else 'http',
-                    del a_format['vbr']
+                if not a_format['tbr']:
-            webpage, 'guest token')
+        # https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/get-statuses-show-id
-            video_id, 'Downloading mobile API data',
+            'https://api.twitter.com/1.1/statuses/show/%s.json' % video_id,
-                                                  ['extended_entities']['media'][0]['video_info']) or {}
+        media_info = try_get(api_data, lambda o: o['extended_entities']['media'][0]['video_info']) or {}
-        video_id = self._match_id(url)
+        path, video_id = re.search(self._VALID_URL, url).groups()
-        webpage = self._download_webpage(url, video_id)
+        urls = [url]
-            return self.url_result(iframe_url)
+        for u in urls:
-            video_id)
+            iframe_url = self._html_search_regex(
-            return self.url_result(config['player_url'], 'Vine')
+            config = self._parse_json(self._html_search_regex(
-            return self.url_result(periscope_url, PeriscopeIE.ie_key())
+            if config.get('source_type') == 'vine':
-        video_url = config.get('video_url') or config.get('playlist', [{}])[0].get('source')
+            periscope_url = PeriscopeIE._extract_url(webpage)
-                }
+            video_url = config.get('video_url') or config.get('playlist', [{}])[0].get('source')
-                self._search_dimensions_in_video_url(f, video_url)
+                    formats.append(f)
-                formats.append(f)
+            vmap_url = config.get('vmapUrl') or config.get('vmap_url')
-                self._extract_formats_from_vmap_url(vmap_url, video_id))
+            media_info = None
-        media_info = None
+            for entity in config.get('status', {}).get('entities', []):
-                media_info = entity['mediaInfo']
+            if media_info:
-            duration = float_or_none(media_info.get('duration', {}).get('nanos'), scale=1e9)
+            username = config.get('user', {}).get('screen_name')
-            formats.extend(self._extract_mobile_formats(username, video_id))
+            if formats:
-            'description': 'ããã on Twitter: "BEAT PROD: @suhmeduh  https://t.co/HBrQ4AfpvZ #Damndaniel https://t.co/byBooq2ejZ"',
+            'title': 'JG - BEAT PROD: @suhmeduh #Damndaniel',
-            'uploader': 'ããã',
+            'uploader': 'JG',
-        },
+                if source.get('type') == 'application/x-mpegURL' or determine_ext(video_url) == 'm3u8':
-                r'ng-init=["\'].*\bcourse=({.+?});', webpage, 'course', default='{}')),
+                r'ng-init=["\'].*\bcourse=({.+?})[;"\']',
-            webpage, 'course id')
+            r'data-course-id=["\'](\d+)', webpage, 'course id')
-# coding: utf-8
+from ..utils import int_or_none
-    _VALID_URL = r'https?://.*?stretchinternet\.com/[^/_?].*(?<=eventId=)(?P<id>.*)(?=&).*'
+    _VALID_URL = r'https?://portal\.stretchinternet\.com/[^/]+/portal\.htm\?.*?\beventId=(?P<id>\d+)'
-            'title': 'StretchInternet'
+            'title': 'Augustana (S.D.) Baseball vs University of Mary',
-        stream_url = stream.get('source')
+
-            'title': 'StretchInternet'
+            'title': title,
-    }]
+class EllenTubeBaseIE(InfoExtractor):
-            'https://api-prod.ellentube.com/ellenapi/api/item/%s' % video_id, video_id)
+    def _extract_video(self, data, video_id):
-                    entry.get('url'), video_id, 'mp4', entry_protocol='m3u8_native', m3u8_id='hls')
+                    entry['url'], video_id, 'mp4',
-            'description': description,
+            'description': data.get('description'),
-            'timestamp': publish_time,
+            'thumbnail': data.get('thumbnail'),
-        'url': 'https://www.ellentube.com/video/ellen-meets-las-vegas-survivors-jesus-campos-and-stephen-schuck.html',
+class EllenTubeIE(EllenTubeBaseIE):
-            'thumbnail': 'https://warnerbros-h.assetsadobe.com/is/image/content/dam/ellen/videos/episodes/season15/32/video--2728751654987218111',
+            'timestamp': 1508505120,
-    }
+    }, {
-        return self.url_result('ellentube:%s' % video_id, 'EllenTube')
+        video_id = self._match_id(url)
-                for elem in data if elem.get('type') == 'VIDEO']
+class EllenTubeVideoIE(EllenTubeBaseIE):
-    def _extract_playlist(self, url, display_id, extract_description=True):
+    def _real_extract(self, url):
-            display_id, playlist_title, playlist_description)
+        video_id = self._extract_data_config(webpage, display_id)['id']
-    _TEST = {
+class EllenTubePlaylistIE(EllenTubeBaseIE):
-            'description': 'md5:aed85d42892f6126e71ec5ed2aea2a0d'
+            'title': "Dax Shepard, 'DWTS' Team Jordan Fisher & Lindsay Arnold, HAIM",
-    _TEST = {
+    }, {
-    }
+        'only_matching': True,
-        return self._extract_playlist(url, display_id, False)
+        webpage = self._download_webpage(url, display_id)
-    EllenTubeStudioIE,
+    EllenTubePlaylistIE,
-    EllenTVClipsIE,
+from .ellentube import (
-    RaiPlaylistIE,
+    unescapeHTML,
-        return self.playlist_result(entries, playlist_id, title)
+    RaiPlaylistIE,
-            'id': '5024612095001',
+            'id': 'ref:5024612095001',
-            'upload_date': '20160707',
+            'upload_date': '20170923',
-            'timestamp': 1467870968,
+            'uploader_id': '5182475815001',
-    BRIGHTCOVE_URL_TEMPLATE = 'http://players.brightcove.net/4338955589001/default_default/index.html?videoId=%s'
+    # BRIGHTCOVE_URL_TEMPLATE = 'http://players.brightcove.net/4338955589001/default_default/index.html?videoId=%s'
-            self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)
+            smuggle_url(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, {'geo_countries': ['IN']}),
-        age_limit = parse_age_limit(video.get('contentRating'))
+        rating = video.get('contentRating')
-            pass
+            resource = self._get_mvpd_resource(
-)
+from .dailymotion import DailymotionIE
-)
+from .dailymotion import DailymotionIE
-
+        # mobile site
-        webpage = self._download_webpage(url, video_id)
+        desktop_url = re.sub(r'^(https?://(?:.+?\.)?)m\.', r'\1', url)
-             r'''<video[^>]+poster=(?P<q>["'])(?P<thumbnail>.+?)(?P=q)[^>]*>'''],
+            [r'''["']thumbUrl["']\s*:\s*(?P<q>["'])(?P<thumbnail>.+?)(?P=q)''',
-    _VALID_URL = r'https?://(?:www\.)?xhamster\.com/xembed\.php\?video=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:.+?\.)?xhamster\.com/xembed\.php\?video=(?P<id>\d+)'
-            'uploader_id': 'anonymous',
+            'uploader': 'ManyakisArt',
-                    doc, video_id,
+                    doc,
-                        elif stream_url.startswith('http'):
+                        else:
-            r'class=["\']views["\'][^>]*><p>([\d,.]+)', webpage,
+            (r'Views:\s*</span>\s*<span>\s*([\d,.]+)',
-                r'(?s)<p[^>]*>%s:(.+?)</p>' % kind.capitalize(),
+                (r'(?s)%s:\s*</span>\s*<span>(.+?)</span>' % kind.capitalize(),
-        state = 'http://ici.tou.tv//'
+        state = 'http://ici.tou.tv/'
-        form_data = self._hidden_inputs(login_form)
+
-        _, urlh = self._download_webpage_handle(
+        consent_webpage = self._download_webpage(
-__version__ = '2017.11.26'
+__version__ = '2017.12.02'
-                                fragments.append({
+                                fragment = {
-                                })
+                                }
-            ),
+            ), (
-                    r'^(\d+)[pP]', format_id, 'height', default=None))
+                'height': get_height(format_id),
-            'ccode': '0502',
+            'ccode': '0501',
-            video_id, 'Downloading vod config JSON')['data']['info']
+            'http://content.api.mnet.com/player/vodConfig',
-        }]
+        cdn_data = self._download_json(
-    def _extract_tracks(self, item_id, typ=None):
+    def _extract_tracks(self, item_id, referer, typ=None):
-            '%s/%s%s' % (self._API_BASE_URL, item_id, '/type/%s' % typ if typ else ''), item_id)
+            '%s/%s%s' % (self._API_BASE_URL, item_id, '/type/%s' % typ if typ else ''),
-        return self._extract_tracks(self._match_id(url))[0]
+        return self._extract_tracks(self._match_id(url), url)[0]
-        return self.playlist_result(self._extract_tracks(item_id, self._TYPE), item_id)
+        return self.playlist_result(self._extract_tracks(item_id, url, self._TYPE), item_id)
-            } for typographic in transcript.findall('./typographic')]
+            for typographic in transcript.findall('./typographic'):
-                    embed_code, video_id))
+                embed_code = re.sub(r'https?://([^/]+)/z/', r'https://\1/i/', embed_code).replace('/manifest.f4m', '/master.m3u8')
-    IE_DESC = 'Bayerischer Rundfunk Mediathek'
+    IE_DESC = 'Bayerischer Rundfunk'
-            if asset_type == 'HDS':
+            if asset_type.startswith('HDS'):
-            elif asset_type == 'HLS':
+            elif asset_type.startswith('HLS'):
-from .br import BRIE
+from .br import (
-    clean_html,
+    extract_attributes,
-    _VALID_URL = r'https?://(?:www\.)?daisuki\.net/[^/]+/[^/]+/[^/]+/watch\.[^.]+\.(?P<id>\d+)\.html'
+class DaisukiMottoIE(InfoExtractor):
-        'url': 'http://www.daisuki.net/tw/en/anime/watch.TheIdolMasterCG.11213.html',
+        'url': 'http://motto.daisuki.net/framewatch/embed/embedDRAGONBALLSUPERUniverseSurvivalsaga/V2e/760/428',
-            'id': '11213',
+            'id': 'V2e',
-            'title': '#01 Who is in the pumpkin carriage? - THE IDOLM@STER CINDERELLA GIRLS',
+            'title': '#117 SHOWDOWN OF LOVE! ANDROIDS VS UNIVERSE 2!!',
-            }, note='Downloading JSON metadata' + (' (try #%d)' % (idx + 1) if idx > 0 else ''))
+            init_data = self._download_json(
-    _VALID_URL = r'https?://(?:www\.)daisuki\.net/[^/]+/[^/]+/[^/]+/detail\.(?P<id>[a-zA-Z0-9]+)\.html'
+class DaisukiMottoPlaylistIE(InfoExtractor):
-        'url': 'http://www.daisuki.net/tw/en/anime/detail.TheIdolMasterCG.html',
+        'url': 'http://motto.daisuki.net/information/',
-            'description': 'md5:0f2c028a9339f7a2c7fbf839edc5c5d8',
+            'title': 'DRAGON BALL SUPER',
-        'playlist_count': 26,
+        'playlist_mincount': 117,
-        return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)
+        entries = []
-    DaisukiPlaylistIE,
+    DaisukiMottoIE,
-            'id': '64211978996595-1',
+            'id': 'V_VztHT5BzY',
-                video_id, 'Downloading metadata JSON')
+                video_id, 'Downloading metadata JSON',
-        ios_playlist_url = params.get('data-video-playlist')
+        ios_playlist_url = params.get('data-video-playlist') or params.get('data-video-id')
-        if ios_playlist_url and hmac:
+        if ios_playlist_url and hmac and re.match(r'https?://', ios_playlist_url):
-                        'model': 'iPad',
+                        'manufacturer': 'Safari',
-                            'type': 'ios'
+                            'name': 'Windows NT',
-                            'max': ['hls', 'aes']
+                            'min': ['hls', 'aes', 'outband-webvtt'],
-                        'platformTag': 'mobile'
+                        'platformTag': 'dotcom'
-        if codec in ('avc1', 'avc2', 'avc3', 'avc4', 'vp9', 'vp8', 'hev1', 'hev2', 'h263', 'h264', 'mp4v'):
+        if codec in ('avc1', 'avc2', 'avc3', 'avc4', 'vp9', 'vp8', 'hev1', 'hev2', 'h263', 'h264', 'mp4v', 'hvc1'):
-__version__ = '2017.11.15'
+__version__ = '2017.11.26'
-        self.assertEqual(ydl._default_format_spec({}), 'best/bestvideo+bestaudio')
+        ydl = YDL({})
-        self.assertEqual(ydl._default_format_spec({}), 'bestvideo+bestaudio/best')
+        ydl = YDL({'simulate': True})
-        '_skip': 'Blocked outside of Austria / Germany',
+        'skip': 'Blocked outside of Austria / Germany',
-        'skip_download': True,
+        'only_matching': True,
-        'skip_download': True,
+        'only_matching': True,
-        'skip_download': True,
+        'only_matching': True,
-        'skip_download': True,
+        'only_matching': True,
-        'skip_download': True,
+        'only_matching': True,
-        'only_matchine': True,
+        'only_matching': True,
-from ..compat import compat_urlparse
+from ..utils import (
-            r'<[^>]+class=\"photoalbum__title\">([^<]+)', webpage, 'title')
+        msi_id = self._search_regex(
-            return ret
+        msi_data = self._download_json(
-        } for tbr, video_url in merge_dicts(*video_items).items()]
+            'format_id': q.get('label'),
-            'title': video_title,
+            'title': title,
-            azure_base = None
+        def get_cdn_shield_base(shield_type='', prefix='-p'):
-                cdn_shield = stream_data.get('cdn%sHTTP%s' % (cdn, secure.upper()))
+                cdn_shield = stream_data.get('cdnShield%sHTTP%s' % (shield_type, secure.upper()))
-                    break
+                    return 'http%s://%s' % (secure, cdn_shield)
-            return azure_base
+                return AZURE_URL % (prefix, int(stream_data['azureAccount'].replace('nexxplayplus', '')))
-        azure_stream_base = get_cdn_base('Shield')
+        azure_stream_base = get_cdn_shield_base()
-        azure_progressive_base = get_cdn_base('ShieldProg', '-d')
+        azure_progressive_base = get_cdn_shield_base('Prog', '-d')
-                                'format_id': 'http-%d' % tbr,
+                                'format_id': '%s-http-%d' % (cdn, tbr),
-    _VALID_URL = r'https?://(?:www\.)?freespeech\.org/video/(?P<title>.+)'
+    _VALID_URL = r'https?://(?:www\.)?freespeech\.org/stories/(?P<id>.+)'
-        'url': 'https://www.freespeech.org/video/obama-romney-campaign-colorado-ahead-debate-0',
+        'url': 'http://www.freespeech.org/stories/fcc-announces-net-neutrality-rollback-whats-stake/',
-            'uploader': 'freespeechtv',
+            'id': 'waRk6IPqyWM',
-            'upload_date': '20121002',
+            'uploader': 'freespeechtv',
-        info = json.loads(info_json)
+        display_id = self._match_id(url)
-            'url': info['jw_player']['basic_video_node_player']['file'],
+            'url': youtube_url,
-        'md5': '16746bfc28c42049492385c989b26c4a',
+        'md5': '828cea195be04e66057b846288295ba1',
-        # TODO: reverse more cdns and formats
+        # TODO: reverse more cdns
-        AZURE_URL = 'http://nx-p%02d.akamaized.net/'
+        AZURE_URL = 'http://nx%s%02d.akamaized.net/'
-            azure_base = AZURE_URL % int(stream_data['azureAccount'].replace('nexxplayplus', ''))
+        def get_cdn_base(cdn, prefix='-p'):
-            azure_base, azure_locator, video_id, ('_manifest' if is_ml else ''))
+        azure_manifest_url = '%s%s/%s_src%s.ism/Manifest' % (
-            azure_m3u8_url += '?hdnts=%s' % protection_token
+            azure_manifest_url += '?hdnts=%s' % protection_token
-            m3u8_id='%s-hls' % cdn)
+            azure_manifest_url % '(format=m3u8-aapl)',
-            except:
+            except (IOError, OSError):
-    _VALID_URL = r'https?://(?:openload\.(?:co|io)|oload\.tv)/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:openload\.(?:co|io|link)|oload\.tv)/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
-class TNAFlixIE(TNAFlixNetworkBaseIE):
+class TNAEMPFlixBaseIE(TNAFlixNetworkBaseIE):
-        'md5': 'ecf3498417d09216374fc5907f9c6ec0',
+        'md5': '7e569419fe6d69543d01e6be22f5f7c4',
-            'categories': ['Amateur Porn', 'Squirting Videos', 'Teen Girls 18+'],
+            'categories': list,
-class EMPFlixIE(TNAFlixNetworkBaseIE):
+class EMPFlixIE(TNAEMPFlixBaseIE):
-        'md5': 'b1bc15b6412d33902d6e5952035fcabc',
+        'md5': 'bc30d48b91a7179448a0bda465114676',
-        display_id = mobj.group('display_id') if 'display_id' in mobj.groupdict() else video_id
+        for display_id_key in ('display_id', 'display_id_2'):
-    _VALID_URL = r'https?://(?:www\.)?empflix\.com/videos/(?P<display_id>.+?)-(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?empflix\.com/(?:videos/(?P<display_id>.+?)-|[^/]+/(?P<display_id_2>[^/]+)/video)(?P<id>[0-9]+)'
-                       % (inputs['vkey'], inputs['nkey'], video_id))
+            cfg_url = ('https://cdn-fck.%sflix.com/%sflix/%s%s.fid?key=%s&VID=%s&premium=1&vip=1&alpha'
-            return re.sub(r'speed=\d+', 'speed=', unescapeHTML(vl.text))
+            # Any URL modification now results in HTTP Error 403: Forbidden
-    GenerationQuoiIE,
+    GenerationWhatIE,
-    _VALID_URL = r'https?://generation-quoi\.france2\.fr/portrait/(?P<id>[^/?#]+)'
+class GenerationWhatIE(InfoExtractor):
-        'url': 'http://generation-quoi.france2.fr/portrait/garde-a-vous',
+    _TESTS = [{
-            'id': 'k7FJX8VBcvvLmX4wA5Q',
+            'id': 'wtvKYUG45iw',
-            'skip_download': True,
+            'title': 'Generation What - Garde Ã  vous - FRA',
-    }
+    }, {
-                               ie='Dailymotion')
+        webpage = self._download_webpage(url, display_id)
-from .fktv import FKTVIE
+from .massengeschmacktv import MassengeschmackTVIE
-        }
+from __future__ import unicode_literals
-                r'AnvatoPlaylist\s*\(\s*(\[.+?\])\s*\)\s*;',
+                r"this\.videosJson\s*=\s*'(\[.+?\])';",
-            video_id, transform_source=js_to_json)[0]['video']
+            video_id)[0]['video']
-            config_xml_url, video_id, 'Downloading config xml')
+        media = self._html_search_regex(
-                    formats.append({
+                    tbr = xpath_text(encoding, 'AVERAGEBITRATE', 1000)
-                    })
+                        'tbr': tbr,
-            r'<(script|iframe)[^>]+?src=["\'](?P<url>(?:https?:)?//content.jwplatform.com/players/[a-zA-Z0-9]{8})',
+            r'<(?:script|iframe)[^>]+?src=["\'](?P<url>(?:https?:)?//content.jwplatform.com/players/[a-zA-Z0-9]{8})',
-            'url': 'http://www.suffolk.edu/sjc/',
+            'url': 'http://www.suffolk.edu/sjc/live.php',
-                'id': 'sjclive',
+                'id': 'live',
-            'skip': 'does not contain a video anymore',
+            'skip': 'Only has video a few mornings per month, see http://www.suffolk.edu/sjc/',
-            r'<script[^>]+?src=["\'](?P<url>(?:https?:)?//content.jwplatform.com/players/[a-zA-Z0-9]{8})',
+            r'<(script|iframe)[^>]+?src=["\'](?P<url>(?:https?:)?//content.jwplatform.com/players/[a-zA-Z0-9]{8})',
-            r'"http://videos\.francetv\.fr/video/([^@]+@[^"]+)"', webpage, 'video id').split('@')
+            r'"https?://videos\.francetv\.fr/video/([^@]+@[^"]+)"', webpage, 'video id').split('@')
-            'ccode': '0402' if 'tudou.com' in url else '0401',
+            'ccode': '0502',
-            formats.extend(self._extract_smil_formats(smil_url, video_id))
+            formats.extend(self._extract_smil_formats(smil_url, video_id, fatal=False))
-            self.to_screen('Dumping request to ' + url)
+            self.to_screen('Dumping request to ' + urlh.geturl())
-            basen = '%s_%s' % (video_id, url)
+            basen = '%s_%s' % (video_id, urlh.geturl())
-    _VALID_URL = r'https?://(?:www\.)?drtuber\.com/(?:video|embed)/(?P<id>\d+)(?:/(?P<display_id>[\w-]+))?'
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?drtuber\.com/(?:video|embed)/(?P<id>\d+)(?:/(?P<display_id>[\w-]+))?'
-    _VALID_URL = r'https?://(?:(?:www|[a-z]{2})\.)?spankbang\.com/(?P<id>[\da-z]+)/video'
+    _VALID_URL = r'https?://(?:(?:www|m|[a-z]{2})\.)?spankbang\.com/(?P<id>[\da-z]+)/video'
-            'description': 'Watch fantasy solo free HD porn video - 05 minutes - dillion harper masturbates on a bed free adult movies.',
+            'description': 'Watch fantasy solo free HD porn video - 05 minutes -  Babe,Masturbation,Solo,Toy  - dillion harper masturbates on a bed free adult movies sexy clips.',
-                description = media.get('caption')
+                description = try_get(
-                timestamp = int_or_none(media.get('date'))
+                timestamp = int_or_none(media.get('taken_at_timestamp') or media.get('date'))
-                comment_count = int_or_none(media.get('comments', {}).get('count'))
+
-__version__ = '2017.11.06'
+__version__ = '2017.11.15'
-        packed = self._search_regex(r'(eval\(function.+)', webpage, 'packed code')
+        packed = self._search_regex(
-        key_digit = self._search_regex(r'fromCharCode\(.+?(\d+)\)}', unpacked, 'key digit')
+        digits = [int(digit) for digit in digits.split(',')]
-            'https://vshare.io/v/%s/width-650/height-430/1' % video_id, video_id)
+            'https://vshare.io/v/%s/width-650/height-430/1' % video_id,
-        title = self._html_search_regex(r'<title>([^<]+)</title>', webpage, 'title')
+        title = self._html_search_regex(
-        return {
+        info = self._parse_html5_media_entries(
-        }
+        })
-            webpage)
+        return info
-from ..utils import decode_packed_codes
+from ..utils import (
-        'md5': '16d7b8fef58846db47419199ff1ab3e7',
+        'md5': '17b39f55b5497ae8b59f5fbce8e35886',
-            'https://vshare.io/d/%s' % video_id, video_id)
+            'https://vshare.io/v/%s/width-650/height-430/1' % video_id, video_id)
-            webpage, 'video url', group='url')
+        title = self._html_search_regex(r'<title>([^<]+)</title>', webpage, 'title')
-            'url': video_url,
+            'formats': formats,
-                    entries = make_playlistitems_entries(list(ie_entries))
+                    entries = make_playlistitems_entries(list(itertools.islice(
-            if not id or not iv or not data:
+            sub_doc = self._call_rpc_api(
-            subtitle = self._decrypt_subtitles(data, iv, id).decode('utf-8')
+            sid = sub_doc.get('id')
-                    formats.append(format_info)
+            stream_infos = []
-        self._sort_formats(formats)
+                video_file = xpath_text(stream_info, './file')
-                'req': 'RpcApiVideoPlayer_GetMediaMetadata',
+                video_url = xpath_text(stream_info, './host')
-                    skip_http_formats=True))
+                    http_formats_preference=-1))
-    def _extract_once_formats(self, url, skip_http_formats=False):
+    def _extract_once_formats(self, url, http_formats_preference=None):
-            if rendition_id and not skip_http_formats:
+            if rendition_id:
-    _VALID_URL = r'https?://(?:www\.)?instagram\.com/(?P<username>[^/]{2,})/?(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?instagram\.com/(?P<id>[^/]{2,})/?(?:$|[?#])'
-        }],
+        'playlist_count': 5,
-        uploader_id = mobj.group('username')
+    def _entries(self, uploader_id):
-        while True:
+        for page_num in itertools.count(1):
-            page_count += 1
+                'https://instagram.com/%s/' % uploader_id, uploader_id,
-                if it.get('type') != 'video':
+            max_id = None
-                    'formats': formats,
+
-                    'uploader_id': user.get('username'),
+                    'timestamp': timestamp,
-                    'timestamp': int_or_none(it.get('created_time')),
+                    'view_count': view_count,
-            if not page['items']:
+                yield info
-        }
+            query['max_id'] = max_id
-            'thumnails': thumbnails,
+            'thumbnails': thumbnails,
-            post_url, None, 'Logging in as %s' % username,
+            post_url, None, 'Logging in',
-            request, None, 'Logging in as %s' % username)
+            request, None, 'Logging in')
-            request, None, 'Logging in as %s' % username)
+            request, None, 'Logging in')
-            request, None, 'Logging in as %s' % username)
+            request, None, 'Logging in')
-                None, 'Logging in as %s' % username, data=urlencode_postdata({
+                None, 'Logging in', data=urlencode_postdata({
-            self._LOGIN_URL, None, 'Logging in as %s' % username,
+            self._LOGIN_URL, None, 'Logging in',
-        login_page = self._download_webpage(request, None, note='Logging in as %s' % username)
+        login_page = self._download_webpage(request, None, note='Logging in')
-            post_url, None, 'Logging in as %s' % username,
+            post_url, None, 'Logging in',
-            note='Logging in as %s' % username,
+            note='Logging in',
-            request, None, 'Logging in as %s' % username)
+            request, None, 'Logging in')
-            login_page, handle, 'Logging in as %s' % username, {
+            login_page, handle, 'Logging in', {
-            self._LOGIN_URL, None, 'Logging in as %s' % username,
+            self._LOGIN_URL, None, 'Logging in',
-            'Logging in as %s' % username, post_data=login_form)
+            'Logging in', post_data=login_form)
-            note='Logging in as %s' % username,
+            note='Logging in',
-    _VALID_URL = r'https?://(?:www\.)?gamespot\.com/videos/(?:[^/]+/\d+-|embed/)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?gamespot\.com/(?:video|article)s/(?:[^/]+/\d+-|embed/)(?P<id>\d+)'
-                    r'https?://[^/]+', 'http://once.unicornmedia.com', onceux_url)))
+                    r'https?://[^/]+', 'http://once.unicornmedia.com', onceux_url),
-    def _extract_once_formats(self, url):
+    def _extract_once_formats(self, url, skip_http_formats=False):
-            if rendition_id:
+            if rendition_id and not skip_http_formats:
-                    'tokenizer_src': 'http://www.cartoonnetwork.com/cntv/mvpd/processors/services/token_ipadAdobe.do',
+                    'tokenizer_src': 'https://token.vgtf.net/token/token_mobile',
-                            https?://(?:www\.)?(?:wsj|barrons)\.com/video/[^/]+/|
+                            https?://(?:www\.)?(?:wsj|barrons)\.com/video/(?:[^/]+/)+|
-        rid = plflag_auth["auth"]["rid"]
+        plflag_auth = self._parse_json(video_info['plflag_list'], video_id)
-            'https://www.panda.tv/api_room?roomid=%s' % video_id, video_id)
+            'https://www.panda.tv/api_room_v2?roomid=%s' % video_id, video_id)
-                    % (pl, plflag1, room_key, live_panda, suffix[quality], ext),
+                    'url': 'https://pl%s%s.live.panda.tv/live_panda/%s%s%s.%s?sign=%s&ts=%s&rid=%s'
-__version__ = '2017.10.29'
+__version__ = '2017.11.06'
-    ExtractorError,
+    ExtractorError,
-    _VALID_URL = r'https?://(?:www\.)?hotstar\.com/(?:.+?[/-])?(?P<id>\d{10})'
+class HotStarBaseIE(InfoExtractor):
-            })['contentInfo'][0]
+
-class HotStarPlaylistIE(InfoExtractor):
+class HotStarPlaylistIE(HotStarBaseIE):
-
+    _VALID_URL = r'(?P<url>https?://(?:www\.)?hotstar\.com/tv/[^/]+/(?P<content_id>\d+))/(?P<type>[^/]+)/(?P<id>\d+)'
-        'url': 'http://www.hotstar.com/tv/pow-bandi-yuddh-ke/10999/episodes/10856/9993',
+        'url': 'http://www.hotstar.com/tv/pratidaan/14982/episodes/14812/9993',
-            'title': 'pow-bandi-yuddh-ke',
+            'id': '14812',
-        'playlist_mincount': 0,
+        'playlist_mincount': 75,
-        'url': 'http://www.hotstar.com/tv/pow-bandi-yuddh-ke/10999/episodes/10856/9993',
+        'url': 'http://www.hotstar.com/tv/pratidaan/14982/popular-clips/9998/9998',
-        return info_dict
+    _ITEM_TYPES = {
-        playlist_title = mobj.group('playlist_title')
+        base_url = mobj.group('url')
-        )
+            'https://search.hotstar.com/AVS/besc', playlist_id, query={
-        return self.playlist_result(entries, playlist_id, playlist_title)
+            self.url_result(
-from .hotstar import HotStarIE
+from .hotstar import (
-            'title': 'On Air With AIB - English',
+            'title': 'On Air With AIB',
-    return '{http://ns.adobe.com/f4m/1.0}%s' % prop
+def _add_ns(prop, ver=1):
-        base_url = compat_urlparse.urljoin(man_url, media.attrib['url'])
+        # Prefer baseURL for relative URLs as per 11.2 of F4M 3.0 spec.
-        boot_info, bootstrap_url = self._parse_bootstrap_node(bootstrap_node, man_url)
+        boot_info, bootstrap_url = self._parse_bootstrap_node(
-from ..downloader.f4m import remove_encrypted_media
+from ..downloader.f4m import (
-            base_url = base_url.strip()
+
-                    else ((base_url or '/'.join(manifest_url.split('/')[:-1])) + '/' + media_url))
+                    else ((manifest_base_url or '/'.join(manifest_url.split('/')[:-1])) + '/' + media_url))
-from ..utils import strip_or_none
+from ..utils import (
-                r'data-video-id="([^"]+)"', webpage, 'ooyala id'),
+            'url': video_url,
-    _VALID_URL = r'https?://(?:www\.)?gamespot\.com/.*-(?P<id>\d+)/?'
+    _VALID_URL = r'https?://(?:www\.)?gamespot\.com/videos/(?:[^/]+/\d+-|embed/)(?P<id>\d+)'
-        m3u8_url = streams.get('m3u8_stream')
+        m3u8_url = dict_get(streams, ('m3u8_stream', 'adaptive_stream'))
-            streams, ('progressive_hd', 'progressive_high', 'progressive_low'))
+            streams, ('progressive_hd', 'progressive_high', 'progressive_low', 'other_lr'))
-                http_base_url + '/playlist.m3u8', video_id, 'mp4',
+                manifest_url('playlist.m3u8'), video_id, 'mp4',
-                http_base_url + '/manifest.f4m',
+                manifest_url('manifest.f4m'),
-                http_base_url + '/manifest.mpd',
+                manifest_url('manifest.mpd'),
-                    http_base_url + '/jwplayer.smil',
+                    manifest_url('jwplayer.smil'),
-__version__ = '2017.10.20'
+__version__ = '2017.10.29'
-            'id': 'professor-frisby-introduces-composable-functional-javascript',
+            'id': '72',
-            'https://egghead.io/api/v1/series/%s' % playlist_id, playlist_id)
+            'https://egghead.io/api/v1/series/%s' % playlist_id,
-            for lesson in course['lessons'] if lesson.get('wistia_id')]
+        playlist_id = course.get('id')
-    _TEST = {
+    _VALID_URL = r'https://egghead\.io/(?:api/v1/)?lessons/(?P<id>[^/?#&]+)'
-            'id': 'fv5yotjxcg',
+            'id': '1196',
-    }
+    }, {
-        lesson_id = self._match_id(url)
+        display_id = self._match_id(url)
-            'https://egghead.io/api/v1/lessons/%s' % lesson_id, lesson_id)
+            'https://egghead.io/api/v1/lessons/%s' % display_id, display_id)
-            'title': lesson.get('title'),
+            'id': lesson_id,
-                for v in (group_id, name):
+                for v in (m3u8_id, group_id, name):
-            r'''(?ix)(?:P?T)?
+            r'''(?ix)(?:P?
-    update_url_query,
+    int_or_none,
-        'md5': '1447d4722e42ebca19e5232ab93abb22',
+        'url': 'http://www.fxnetworks.com/video/1032565827847',
-            'id': '719841347694',
+            'id': 'dRzwHC_MMqIv',
-            'description': 'F*ck settling down. You\'re the Worst returns for an all new season August 31st on FXX.',
+            'title': 'First Look: Better Things - Season 2',
-            'timestamp': 1467844741,
+            'upload_date': '20170825',
-    YouNowIE,
+    YouNowLiveIE,
-from datetime import date, datetime
+
-from ..utils import int_or_none, UnsupportedError
+from ..utils import (
-STREAM_URL_FORMAT = 'https://hls.younow.com/momentsplaylists/live/%s/%s.m3u8'
+CDN_API_BASE = 'https://cdn.younow.com/php/api'
-    _VALID_URL = r'https?://(?:www\.)?younow\.com/(?P<id>[^/]+)'
+class YouNowLiveIE(InfoExtractor):
-            'thumbnail': 'https://ynassets.s3.amazonaws.com/broadcast/live/157869188/157869188.jpg',
+            'thumbnail': r're:^https?://.*\.jpg$',
-        }
+        },
-            title = date.today().strftime('%B %d, %Y')
+
-            'description': self._og_search_description(webpage),
+            'title': self._live_title(uploader),
-            'uploader_url': 'https://www.younow.com/%s' % (data['user']['profileUrlString'],),
+            'uploader_url': 'https://www.younow.com/%s' % username,
-                'url': stream_url,
+                'url': '%s/broadcast/videoPath/hls=1/broadcastId=%s/channelId=%s'
-def _moment_to_entry(item):
+def _extract_moment(item, fatal=True):
-            title = 'YouNow moment'
+        title = 'YouNow %s' % (
-        'id': compat_str(item['momentId']),
+        'extractor_key': 'YouNowMoment',
-            'url': STREAM_URL_FORMAT % (item['momentId'], item['momentId']),
+            'url': 'https://hls.younow.com/momentsplaylists/live/%s/%s.m3u8'
-            'protocol': 'm3u8',
+            'protocol': 'm3u8_native',
-        'url': 'https://www.younow.com/Kate_Swiz/channel',
+        'url': 'https://www.younow.com/its_Kateee_/channel',
-            'title': 'Kate_Swiz moments'
+            'id': '14629760',
-        'playlist_count': 6,
+        'playlist_mincount': 8,
-        channel_id = user_info['userId']
+    def _entries(self, username, channel_id):
-                    not info['items']):
+        for page_num in itertools.count(1):
-        return self.playlist_result(entries, playlist_title='%s moments' % (username))
+    def _real_extract(self, url):
-    _VALID_URL = r'https?://(?:www\.)?younow\.com/[^/]+/(?P<id>[^/]+)/[^/]+'
+    _VALID_URL = r'https?://(?:www\.)?younow\.com/[^/]+/(?P<id>[^/?#&]+)'
-            'like_count': 0,
+            'view_count': int,
-            }],
+    @classmethod
-        return _moment_to_entry(item['item'])
+        video_id = self._match_id(url)
-from ..utils import unified_strdate
+from ..compat import compat_str
-    _VALID_URL = r'https?://(?:www\.)?dctp\.tv/(#/)?filme/(?P<id>.+?)/$'
+    _VALID_URL = r'https?://(?:www\.)?dctp\.tv/(?:#/)?filme/(?P<id>[^/?#&]+)'
-            'ext': 'mp4',
+            'ext': 'flv',
-        webpage = self._download_webpage(url, video_id)
+        display_id = self._match_id(url)
-        object_id = self._html_search_meta('DC.identifier', webpage)
+        webpage = self._download_webpage(url, display_id)
-            entry_protocol='m3u8_native')
+        video_id = self._html_search_meta(
-            'id': object_id,
+            'id': video_id,
-            'display_id': video_id,
+            'display_id': display_id,
-                (?:embed|v|p)/.+?)
+                (?:embed|v|p)/[0-9A-Za-z_-]{11}.*?)
-                r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//player\.vimeo\.com/video/.+?)\1',
+                r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//player\.vimeo\.com/video/\d+.*?)\1',
-    _VALID_URL = r'https?://(?:www\.)?soundgasm\.net/u/(?P<user>[0-9a-zA-Z_\-]+)/(?P<title>[0-9a-zA-Z_\-]+)'
+    _VALID_URL = r'https?://(?:www\.)?soundgasm\.net/u/(?P<user>[0-9a-zA-Z_-]+)/(?P<display_id>[0-9a-zA-Z_-]+)'
-            'description': 'Royalty Free Sample Music'
+            'title': 'Piano sample',
-        audio_title = mobj.group('user') + '_' + mobj.group('title')
+        display_id = mobj.group('display_id')
-        audio_id = re.split(r'\/|\.', audio_url)[-2]
+            r'(?s)m4a\s*:\s*(["\'])(?P<url>(?:(?!\1).)+)\1', webpage,
-            fatal=False)
+            (r'(?s)<div[^>]+\bclass=["\']jp-description[^>]+>(.+?)</div>',
-            'description': description
+            'vcodec': 'none',
-    _VALID_URL = r'https?(?P<permalink>://(?:www\.)?nbc\.com/[^/]+/video/[^/]+/(?P<id>n?\d+))'
+    _VALID_URL = r'https?(?P<permalink>://(?:www\.)?nbc\.com/(?:classic-tv/)?[^/]+/video/[^/]+/(?P<id>n?\d+))'
-        }
+        },
-        # 'skip': 'This video is only available for registered users'
+        'skip': 'This video is only available for registered users'
-            self.raise_login_required()
+            return
-        json = self._download_json(securevideo_url, display_id)
+        try:
-        redirect_url = json.get('url')
+        redirect_url = video.get('url')
-            video_id = list(json.values())[0].get('videoid')
+            return self.url_result(self._proto_relative_url(redirect_url, 'https:'))
-    float_or_none,
+    ExtractorError,
-    _VALID_URL = r'https?://mediazone\.vrt\.be/api/v1/(?P<site_id>canvas|een|ketnet)/assets/(?P<id>m[dz]-ast-[^/?#&]+)'
+    _VALID_URL = r'https?://mediazone\.vrt\.be/api/v1/(?P<site_id>canvas|een|ketnet|vrtvideo)/assets/(?P<id>[^/?#&]+)'
-from .common import InfoExtractor
+from .gigya import GigyaBaseIE
-class MedialaanIE(InfoExtractor):
+class MedialaanIE(GigyaBaseIE):
-                'Unable to login: %s' % error_message, expected=True)
+        auth_info = self._gigya_login(auth_data)
-        title = clip.get('channel_title') or self._og_search_title(webpage)
+        title = clip.get('title') or clip.get('channel_title') or self._og_search_title(webpage)
-    int_or_none,
+    parse_duration,
-    }
+    _VALID_URL = r'https?://(?:[^/]+\.)?ndtv\.com/(?:[^/]+/)*videos?/?(?:[^/]+/)*[^/?^&]+-(?P<id>\d+)'
-        title = remove_end(self._og_search_title(webpage), ' - NDTV')
+        # '__title' does not contain extra words such as sub-site name, "Video" etc.
-        video_url = 'http://bitcast-b.bitgravity.com/ndtvod/23372/ndtv/%s' % filename
+            r"(?:__)?filename\s*[:=]\s*'([^']+)'", webpage, 'video filename')
-            r"__duration='([^']+)'", webpage, 'duration', fatal=False))
+        # "doctor" sub-site has MM:SS format
-            'publish-date', webpage, 'upload date', fatal=False))
+            'publish-date', webpage, 'upload date', default=None) or self._html_search_meta(
-                r'(?s)class="hidden-xs prompt"[^>]*>(.+?)<',
+                r'(?s)<h\d[^>]+\bclass="hidden-xs prompt"[^>]*>(.+?)</h\d',
-    _VALID_URL = r'https?://(?:www\.)nickelodeon\.ru/(?:playlist|shows|videos)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)nickelodeon\.(?:ru|fr|es|pt|ro|hu)/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.(?:de|com\.pl|ch)|nickelodeon\.(?:nl|at|dk|no|se))/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.(?:de|com\.pl|ch)|nickelodeon\.(?:nl|be|at|dk|no|se))/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.(?:de|com\.pl)|nickelodeon\.(?:nl|at|dk|no|se))/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.(?:de|com\.pl|ch)|nickelodeon\.(?:nl|at|dk|no|se))/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.(?:de|com\.pl)|nickelodeon\.(?:nl|at))/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.(?:de|com\.pl)|nickelodeon\.(?:nl|at|dk|no|se))/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-            'ext': 'mov',
+            'ext': 'mp4',
-__version__ = '2017.10.15.1'
+__version__ = '2017.10.20'
-            'id': 'c1e9d44d-fd6c-4263-b50f-97ed26cc998b',
+            'id': '1_af9nv9ym',
-            r'kWidgetConfig\s*=\s*({.+});',
+            r'(?s)kWidgetConfig\s*=\s*({.+});',
-        kaltura_url = 'kaltura:%s:%s' % (widget_config['wid'][1:], widget_config['entry_id'])
+        kaltura_url = 'kaltura:%s:%s' % (
-    _CLIENT_ID = 'JlZIsxg2hY5WnBgtn3jfS0UYCl0K8DOg'
+    _CLIENT_ID = 'c6CU49JDMapyrQo06UxU9xouB9ZVzqCn'
-                    self.report_error(
+                    self.report_warning(
-            ''', lambda m: compat_urlparse.urljoin(url, m.group(1)), video_description)
+            ''', replace_url, video_description)
-           (?:%s)/(?:viralplayer|video)/(?P<id>[0-9]+)/? |
+           (?:%s)/(?:(?:vir|port)alplayer|video)/(?P<id>[0-9]+)(?:[?/]|$) |
-            'thumbnail': 're:^https://.*\.png.*$',
+            'thumbnail': r're:^https://.*\.png.*$',
-    _VALID_URL = r'https?://(?:www\.)?eporner\.com/hd-porn/(?P<id>\w+)(?:/(?P<display_id>[\w-]+))?'
+    _VALID_URL = r'https?://(?:www\.)?eporner\.com/(?:hd-porn|embed)/(?P<id>\w+)(?:/(?P<display_id>[\w-]+))?'
-
+        vsr = try_get(player_info, lambda x: x['VSR'], dict)
-                expected=True)
+            error = None
-            'timestamp': 1385182762,
+            'timestamp': int,  # timestamp is unstable
-            'uploader': 'ã²ã¹',
+            'uploader': 'ã²ã¹ã',
-        owner = api_data.get('owner', {})
+        # Note: cannot use api_data.get('owner', {}) because owner may be set to "null"
-__version__ = '2017.10.15'
+__version__ = '2017.10.15.1'
-        total_frags = 0
+        def anvato_ad(s):
-                total_frags += 1
+            if not line:
-            'total_frags': total_frags,
+            'total_frags': media_frags,
-            % (self.FD_NAME, ctx['total_frags'] if not ctx['live'] else 'unknown (live)'))
+            '[%s] Total fragments: %s' % (self.FD_NAME, total_frags_str))
-            'anvato:anvato_scripps_app_web_prod_0837996dbe373629133857ae9eb72e740424d80a:%s' % mcp_id,
+            smuggle_url(
-    _VALID_URL = r'https?://(?:www\.)?reddit\.com/r/[^/]+/comments/(?P<id>[^/]+)'
+    _VALID_URL = r'(?P<url>https?://(?:www\.)?reddit\.com/r/[^/]+/comments/(?P<id>[^/?#&]+))'
-            url + '.json', video_id)[0]['data']['children'][0]['data']
+            url + '/.json', video_id)[0]['data']['children'][0]['data']
-__version__ = '2017.10.12'
+__version__ = '2017.10.15'
-                        (?P<site>hgtv|foodnetwork|travelchannel|diynetwork|cookingchanneltv)\.com/
+                        (?P<site>hgtv|foodnetwork|travelchannel|diynetwork|cookingchanneltv|geniuskitchen)\.com/
-                            show/(?:[^/]+/){2}
+                            show/(?:[^/]+/){2}|
-        'geniuskitchen': 'geniuskitchen',
+        'geniuskitchen': 'genius',
-from .adobepass import AdobePassIE
+import datetime
-    update_url_query,
+    urlencode_postdata,
-class ScrippsNetworksWatchIE(AdobePassIE):
+class ScrippsNetworksWatchIE(InfoExtractor):
-        'url': 'http://watch.hgtv.com/player.HNT.html#0256538',
+    _VALID_URL = r'''(?x)
-            'id': '0256538',
+            'id': '4173834',
-            'timestamp': 1486450493,
+            'title': 'Best Ever Treehouses',
-        'skip': 'requires TV provider authentication',
+        'add_ie': [AnvatoIE.ie_key()],
-            'ie_key': 'ThePlatform',
+        mobj = re.match(self._VALID_URL, url)
-                    })
+            if media_format == 'm3u8' and tbr is not None:
-            ''', r'\1', video_description)
+            ''', lambda m: compat_urlparse.urljoin(url, m.group(1)), video_description)
-    _VALID_URL = r'https?://[\da-z-]+\.howstuffworks\.com/(?:[^/]+/)*(?:\d+-)?(?P<id>.+?)-video\.htm'
+    _VALID_URL = r'https?://[\da-z-]+\.(?:howstuffworks|stuff(?:(?:youshould|theydontwantyouto)know|toblowyourmind|momnevertoldyou)|(?:brain|car)stuffshow|fwthinking|geniusstuff)\.com/(?:[^/]+/)*(?:\d+-)?(?P<id>.+?)-video\.htm'
-            'url': 'http://adventure.howstuffworks.com/5266-cool-jobs-iditarod-musher-video.htm',
+            'url': 'http://www.stufftoblowyourmind.com/videos/optical-illusions-video.htm',
-                'id': '440011',
+                'id': '855410',
-                'thumbnail': r're:^https?://.*\.jpg$',
+                'title': 'Your Trickster Brain: Optical Illusions -- Science on the Web',
-            'url': 'http://shows.howstuffworks.com/stuff-to-blow-your-mind/optical-illusions-video.htm',
+            'url': 'http://shows.howstuffworks.com/more-shows/why-does-balloon-stick-to-hair-video.htm',
-from ..utils import determine_ext
+from ..utils import (
-    def _extract_cookies(self, webpage):
+    def _extract_cf_auth(self, webpage):
-            policy, signature, key_pair_id)
+        return {
-
+        http_audio_url = update_url_query(http_audio_url, self._extract_cf_auth(webpage))
-        if not self._is_valid_url(http_audio_url, video_id, headers=cookies_header):
+        if not self._is_valid_url(http_audio_url, video_id):
-                'description': 'md5:a236581cd2449dd2df4f93412f3f01c6',
+                'description': 'md5:8078af856dca76edc42910b61273dbbf',
-            }
+            },
-                'title': 'Aanslagen Kopenhagen | RTL Nieuws',
+                'title': 'Aanslagen Kopenhagen',
-                'id': '701714499682',
+                'id': 'x_dtl_oa_LettermanliftPR_160608',
-                'title': 'PREVIEW: On Assignment: David Letterman',
+                'title': 'David Letterman: A Preview',
-                'description': 'VIDEO: INDEX/MATCH versus VLOOKUP.',
+                'description': 'Index/Match versus VLOOKUP.',
-            }
+            },
-            r'<iframe[^>]+?src="((?:https?:)?//(?:www\.)?rtl\.nl/system/videoplayer/[^"]+(?:video_)?embed[^"]+)"',
+            r'<iframe[^>]+?src="((?:https?:)?//(?:(?:www|static)\.)?rtl\.nl/(?:system/videoplayer/[^"]+(?:video_)?)?embed[^"]+)"',
-            r'<iframe[^>]+src="(?P<url>%s)"' % UDNEmbedIE._PROTOCOL_RELATIVE_VALID_URL, webpage)
+            r'<iframe[^>]+src="(?:https?:)?(?P<url>%s)"' % UDNEmbedIE._PROTOCOL_RELATIVE_VALID_URL, webpage)
-            entries.append({
+            entry = {
-                'title': video_data['title'] if require_title else video_data.get('title'),
+                'title': unescapeHTML(video_data['title'] if require_title else video_data.get('title')),
-            })
+            }
-        https?://(?:www\.)?
+        https?://(?:(?:www|static)\.)?
-            rtl\.nl/(?:system/videoplayer/(?:[^/]+/)+(?:video_)?embed\.html\b.+?\buuid=|video/)
+            rtl\.nl/(?:(?:system/videoplayer/(?:[^/]+/)+(?:video_)?embed\.html|embed)\b.+?\buuid=|video/)
-    _VALID_URL = r'https?://(?:www\.)?onionstudios\.com/(?:videos/[^/]+-|embed\?.*\bid=)(?P<id>\d+)(?!-)'
+    _VALID_URL = r'https?://(?:www\.)?onionstudios\.com/(?:video(?:s/[^/]+-|/)|embed\?.*\bid=)(?P<id>\d+)(?!-)'
-        'md5': 'e49f947c105b8a78a675a0ee1bddedfe',
+        'md5': '719d1f8c32094b8c33902c17bcae5e34',
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?onionstudios\.com/embed.+?)\1', webpage)
+            r'(?s)<(?:iframe|bulbs-video)[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?onionstudios\.com/(?:embed.+?|video/\d+\.json))\1', webpage)
-import json
+        'expected_warnings': ['Failed to parse JSON Expecting value'],
-        video_urls = options['video']
+        options_str = self._html_search_regex(
-                mobj = re.search(r'_(?P<height>\d+)p_(?P<tbr>\d+).mp4', video_url)
+                mobj = re.search(r'_(?P<height>\d+)p_(?P<tbr>\d+)\.mp4', video_url)
-            'thumbnails': thumbnails,
+            'title': title,
-    _VALID_URL = r'https?://shahid\.mbc\.net/ar/(?P<type>episode|movie)/(?P<id>\d+)'
+    _VALID_URL = r'https?://shahid\.mbc\.net/ar/(?:serie|show|movie)s/[^/]+/(?P<type>episode|clip|movie)-(?P<id>\d+)'
-        'url': 'https://shahid.mbc.net/ar/episode/90574/%D8%A7%D9%84%D9%85%D9%84%D9%83-%D8%B9%D8%A8%D8%AF%D8%A7%D9%84%D9%84%D9%87-%D8%A7%D9%84%D8%A5%D9%86%D8%B3%D8%A7%D9%86-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%85-1-%D9%83%D9%84%D9%8A%D8%A8-3.html',
+        'url': 'https://shahid.mbc.net/ar/shows/%D9%85%D8%AC%D9%84%D8%B3-%D8%A7%D9%84%D8%B4%D8%A8%D8%A7%D8%A8-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%85-1-%D9%83%D9%84%D9%8A%D8%A8-1/clip-275286',
-            'id': '90574',
+            'id': '275286',
-            'upload_date': '20150123',
+            'title': 'ÙØ¬ÙØ³ Ø§ÙØ´Ø¨Ø§Ø¨ Ø§ÙÙÙØ³Ù 1 ÙÙÙØ¨ 1',
-        'url': 'https://shahid.mbc.net/ar/movie/151746/%D8%A7%D9%84%D9%82%D9%86%D8%A7%D8%B5%D8%A9.html',
+        'url': 'https://shahid.mbc.net/ar/movies/%D8%A7%D9%84%D9%82%D9%86%D8%A7%D8%B5%D8%A9/movie-151746',
-        'url': 'https://shahid.mbc.net/ar/episode/90511/%D9%85%D8%B1%D8%A7%D9%8A%D8%A7-2011-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%85-1-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-1.html',
+        'url': 'https://shahid.mbc.net/ar/series/%D9%85%D8%B1%D8%A7%D9%8A%D8%A7-2011-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%85-1-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-1/episode-90511',
-
+    def _api2_request(self, *args, **kwargs):
-                })['user']
+            return self._download_json(*args, **kwargs)
-            video_id, 'Downloading player JSON'))
+        playout = self._api2_request(
-        if player.get('drm'):
+        if playout.get('drm'):
-        formats = self._extract_m3u8_formats(player['url'], video_id, 'mp4')
+        formats = self._extract_m3u8_formats(playout['url'], video_id, 'mp4')
-from .mtv import MTVIE
+from .mtv import MTVServicesInfoExtractor
-class VH1IE(MTVIE):
+class VH1IE(MTVServicesInfoExtractor):
-    _FEED_URL = 'http://www.vh1.com/player/embed/AS3/fullepisode/rss/'
+    _FEED_URL = 'http://www.vh1.com/feeds/mrss/'
-        'md5': '7d67cf6d9cdc6b4f3d3ac97a55403844',
+        'url': 'http://www.vh1.com/episodes/0umwpq/hip-hop-squares-kent-jones-vs-nick-young-season-1-ep-120',
-            'description': 'The greatest documentary ever made about Heavy Metal begins as our host Sam Dunn travels the globe to seek out the origins and influences that helped create Heavy Metal. Sam speaks to legends like Kirk Hammett, Alice Cooper, Slash, Bill Ward, Geezer Butler, Tom Morello, Ace Frehley, Lemmy Kilmister, Dave Davies, and many many more. This episode is the prologue for the 11 hour series, and Sam goes back to the very beginning to reveal how Heavy Metal was created.'
+            'title': 'Kent Jones vs. Nick Young',
-        'skip': 'Blocked outside the US',
+        'playlist_mincount': 4,
-        'md5': '853192b87ad978732b67dd8e549b266a',
+        # Clip
-            'id': '730355',
+            'id': '0a50c2d2-a86b-4141-9565-911c7e2d0b92',
-            'description': 'In Metal Evolution\'s finale sneak, Sam sits with Michael Giles of King Crimson and gets feedback from Metallica guitarist Kirk Hammett on why the group was influential.'
+            'title': 'Scared Famous|October 9, 2017|1|NO-EPISODE#|Scared Famous + Extended Preview',
-            'description': 'The Heist'
+        'params': {
-    '''
+    _VALID_URL = r'https?://(?:www\.)?vh1\.com/(?:video-clips|episodes)/(?P<id>[^/?#.]+)'
-        return self.playlist_result(entries, playlist_id=video_id)
+        playlist_id = self._match_id(url)
-__version__ = '2017.10.07'
+__version__ = '2017.10.12'
-    unescapeHTML,
+    get_element_by_class,
-                'md5': 'f870007cee7065d7c76b88f0a45ecc07',
+                'md5': '6a294ee0c4b1f47f5bb76a65e31e3592',
-                    'title': 'Terraria 1.1 Trailer',
+                    'id': '2040428',
-                'md5': '61aaf31a5c5c3041afb58fb83cbb5751',
+                'md5': '911672b20064ca3263fa89650ba5a7aa',
-                    'title': 'Terraria Trailer',
+                    'id': '2029566',
-            'id': 'WB5DvDOOvAY',
+            'id': 'X8kpJBlzD2E',
-            'description': 'md5:dc96a773669d0ca1b36c13c1f30250d9',
+            'upload_date': '20140617',
-            } for vid in mweb]
+            playlist_title = get_element_by_class('workshopItemTitle', webpage)
-                videos.append({
+            playlist_title = get_element_by_class('apphub_AppName', webpage)
-        if not videos:
+                    'title': title.replace('+', ' '),
-        return self.playlist_result(videos, playlist_id, playlist_title)
+        return self.playlist_result(entries, playlist_id, playlist_title)
-    _VALID_URL = r'https?://api\.nexx(?:\.cloud|cdn\.com)/v3/(?P<domain_id>\d+)/videos/byid/(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-            domain_id = mobj.group('id')
+        domain_id = NexxIE._extract_domain_id(webpage)
-        domain_id, video_id = mobj.group('domain_id', 'id')
+        domain_id = mobj.group('domain_id') or mobj.group('domain_id_s')
-        self.assertEqual(ydl._default_format_spec({}), 'best')
+        self.assertEqual(ydl._default_format_spec({}), 'best/bestvideo+bestaudio')
-        self.assertEqual(ydl._default_format_spec({'is_live': True}), 'best')
+        self.assertEqual(ydl._default_format_spec({'is_live': True}), 'best/bestvideo+bestaudio')
-        def can_have_partial_formats():
+        def can_merge():
-                return True
+                return False
-            if self.params.get('outtmpl', DEFAULT_OUTTMPL) == '-':
+            if self.params.get('outtmpl', DEFAULT_OUTTMPL) == '-':
-        req_format_list.append('best')
+                return True
-from .voxmedia import VoxMediaIE
+from .voxmedia import (
-    _VALID_URL = r'https?://(?:www\.)?(?:theverge|vox|sbnation|eater|polygon|curbed|racked)\.com/(?:[^/]+/)*(?P<id>[^/?]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:theverge|vox|sbnation|eater|polygon|curbed|racked)\.com|recode\.net)/(?:[^/]+/)*(?P<id>[^/?]+)'
-                'url': provider_video_id if provider_video_type == 'youtube' else '%s:%s' % (provider_video_type, provider_video_id),
+                'url': video_url,
-                    break
+            entries.append(create_entry(volume_uuid, 'volume'))
-                    r'https?://[^/]+', 'http://once.unicornmedia.com', onceux_url).replace('ads/vmap/', '')))
+                    r'https?://[^/]+', 'http://once.unicornmedia.com', onceux_url)))
-    _VALID_URL = r'https?://.+?\.unicornmedia\.com/now/[^/]+/[^/]+/(?P<domain_id>[^/]+)/(?P<application_id>[^/]+)/(?:[^/]+/)?(?P<media_item_id>[^/]+)/content\.(?:once|m3u8|mp4)'
+    _VALID_URL = r'https?://.+?\.unicornmedia\.com/now/(?:ads/vmap/)?[^/]+/[^/]+/(?P<domain_id>[^/]+)/(?P<application_id>[^/]+)/(?:[^/]+/)?(?P<media_item_id>[^/]+)/content\.(?:once|m3u8|mp4)'
-    parse_iso8601,
+    float_or_none,
-    _VALID_URL = r'https?://videos\.tva\.ca/episode/(?P<id>\d+)'
+    _VALID_URL = r'https?://videos\.tva\.ca/details/_(?P<id>\d+)'
-        'url': 'http://videos.tva.ca/episode/85538',
+        'url': 'https://videos.tva.ca/details/_5596811470001',
-            'id': '85538',
+            'id': '5596811470001',
-            'timestamp': 1485442329,
+            'title': 'Un extrait de l\'Ã©pisode du dimanche 8 octobre 2017 !',
-                '$format': 'json',
+            'https://videos.tva.ca/proxy/item/_' + video_id, video_id, headers={
-        metadata = video_data.get('Metadata', {})
+
-            'ie_key': 'Ooyala',
+            'title': get_attribute('title'),
-    _VALID_URL = r'https?://(?:www\.)?tubitv\.com/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?tubitv\.com/(?:video|movies|tv-shows)/(?P<id>[0-9]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-)
+from .afreecatv import AfreecaTVIE
-
+from .slideslive import SlidesLiveIE
-        }
+        },
-        'note': 'Video without discernible title',
+            'thumbnail': r're:^https?://.*',
-            'title': 'Facebook video #10153664894881749',
+            'title': 'Average time to confirm recent Supreme Court nominees: 67 days Longest it\'s t...',
-            'title': 'Holocaust survivor becomes US citizen',
+            'title': 'She survived the holocaust â and years later, sheâs getting her citizenship s...',
-            'epidode_number': int_or_none(video_data.get('number')),
+            'episode_number': int_or_none(video_data.get('number')),
-    _VALID_URL = r'https?://hrti\.hrt\.hr/#/video/list/category/(?P<id>[0-9]+)/(?P<display_id>[^/]+)?'
+    _VALID_URL = r'https?://hrti\.hrt\.hr/(?:#/)?video/list/category/(?P<id>[0-9]+)/(?P<display_id>[^/]+)?'
-            r'https?://link.theplatform.com/s/([^?]+)', media_url, 'theplatform_path'), video_id)
+            r'https?://link\.theplatform\.com/s/([^?]+)', media_url, 'theplatform_path'), video_id)
-                            'url': re.sub(r'_(\d+p.mov)', r'_h\1', src),
+                            'url': re.sub(r'_(\d+p\.mov)', r'_h\1', src),
-                format_url = re.sub(r'_(\d*p.mov)', r'_h\1', format['src'])
+                format_url = re.sub(r'_(\d*p\.mov)', r'_h\1', format['src'])
-             r'<meta name="dcterms.title" content="(.*?)"/>',
+             r'<meta name="dcterms\.title" content="(.*?)"/>',
-                                re.sub(self._USP_RE, r'/\1.ism/\1.m3u8', href),
+                                re.sub(self._USP_RE, r'/\1\.ism/\1\.m3u8', href),
-            r'<link rel="video_src" href="[^"]*?vevo.com[^"]*?video=(?P<id>[\w]*)',
+            r'<link rel="video_src" href="[^"]*?vevo\.com[^"]*?video=(?P<id>[\w]*)',
-            'thumbnail': r're:^https?://cdn-images.deezer.com/images/cover/.*\.jpg$',
+            'thumbnail': r're:^https?://cdn-images\.deezer\.com/images/cover/.*\.jpg$',
-        info_json = self._search_regex(r'jQuery.extend\(Drupal.settings, ({.*?})\);', webpage, 'info')
+        info_json = self._search_regex(r'jQuery\.extend\(Drupal\.settings, ({.*?})\);', webpage, 'info')
-            r'Proudly Labeled <a href="http://www.rtalabel.org/" title="Restricted to Adults">RTA</a>',
+            r'Proudly Labeled <a href="http://www\.rtalabel\.org/" title="Restricted to Adults">RTA</a>',
-            r'\d+,(\d+),(\d+),"(https?://[^.]+\.googleusercontent.com.*?)"', webpage)]
+            r'\d+,(\d+),(\d+),"(https?://[^.]+\.googleusercontent\.com.*?)"', webpage)]
-    _VALID_URL = r'https?://hrti.hrt.hr/#/video/list/category/(?P<id>[0-9]+)/(?P<display_id>[^/]+)?'
+    _VALID_URL = r'https?://hrti\.hrt\.hr/#/video/list/category/(?P<id>[0-9]+)/(?P<display_id>[^/]+)?'
-    _EMBED_RE = r'iframe.setAttribute\("src",\s*__util.objToUrlString\("http://widgets\.ign\.com/video/embed/content.html?[^"]*url=([^"]+)["&]'
+    _EMBED_RE = r'iframe\.setAttribute\("src",\s*__util.objToUrlString\("http://widgets\.ign\.com/video/embed/content\.html?[^"]*url=([^"]+)["&]'
-        key_pair_id = self._search_regex(r'InfoQConstants.sck\s*=\s*\'([^\']+)\'', webpage, 'key-pair-id')
+        policy = self._search_regex(r'InfoQConstants\.scp\s*=\s*\'([^\']+)\'', webpage, 'policy')
-            r'data-src(?:set-video)?="(/contenu/medias/video.php.*?)"',
+            r'data-src(?:set-video)?="(/contenu/medias/video\.php.*?)"',
-                    'thumbnail': self._search_regex(r'channelLogo.src\s*=\s*"([^"]+)"', webpage, 'thumbnail', None),
+                    'thumbnail': self._search_regex(r'channelLogo\.src\s*=\s*"([^"]+)"', webpage, 'thumbnail', None),
-    _VALID_URL = r'https?://(?:(?:www\.)?maker\.tv/(?:[^/]+/)*video|makerplayer.com/embed/maker)/(?P<id>[a-zA-Z0-9]{12})'
+    _VALID_URL = r'https?://(?:(?:www\.)?maker\.tv/(?:[^/]+/)*video|makerplayer\.com/embed/maker)/(?P<id>[a-zA-Z0-9]{12})'
-                r'file\s*:\s*"(https?://[^"]+?/playlist.m3u8)',
+                r'file\s*:\s*"(https?://[^"]+?/playlist\.m3u8)',
-    _VALID_URL = r'https?://(?:www\.)?meipai.com/media/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?meipai\.com/media/(?P<id>[0-9]+)'
-                [r'data-mgid="(.*?)"', r'swfobject.embedSWF\(".*?(mgid:.*?)"'],
+                [r'data-mgid="(.*?)"', r'swfobject\.embedSWF\(".*?(mgid:.*?)"'],
-        video_swfobj = self._search_regex(r'swfobject.embedSWF\(\'(.+?)\'', webpage, 'swfobj')
+        video_swfobj = self._search_regex(r'swfobject\.embedSWF\(\'(.+?)\'', webpage, 'swfobj')
-        theplatform_path = self._search_regex(r'https?://link.theplatform.com/s/([^?]+)', release_url, 'theplatform path')
+        theplatform_path = self._search_regex(r'https?://link\.theplatform\.com/s/([^?]+)', release_url, 'theplatform path')
-        m_id = re.search(r'var rmcPlayer = new nhn.rmcnmv.RMCVideoPlayer\("(.+?)", "(.+?)"',
+        m_id = re.search(r'var rmcPlayer = new nhn\.rmcnmv\.RMCVideoPlayer\("(.+?)", "(.+?)"',
-    _VALID_URL = r'https?://(?:www\.)?hetklokhuis.nl/[^/]+/\d+/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?hetklokhuis\.nl/[^/]+/\d+/(?P<id>[^/?#&]+)'
-            r'<title>([^<]+)&nbsp;&nbsp; RUHD.ru - ÐÐ¸Ð´ÐµÐ¾ ÐÑÑÐ¾ÐºÐ¾Ð³Ð¾ ÐºÐ°ÑÐµÑÑÐ²Ð° â1 Ð² Ð Ð¾ÑÑÐ¸Ð¸!</title>',
+            r'<title>([^<]+)&nbsp;&nbsp; RUHD\.ru - ÐÐ¸Ð´ÐµÐ¾ ÐÑÑÐ¾ÐºÐ¾Ð³Ð¾ ÐºÐ°ÑÐµÑÑÐ²Ð° â1 Ð² Ð Ð¾ÑÑÐ¸Ð¸!</title>',
-            links = orderedSet(re.findall(r'<a href="(VideoPage.php\?[^"]+)">', coursepage))
+            links = orderedSet(re.findall(r'<a href="(VideoPage\.php\?[^"]+)">', coursepage))
-            links = orderedSet(re.findall(r'<a href="(CoursePage.php\?[^"]+)">', rootpage))
+            links = orderedSet(re.findall(r'<a href="(CoursePage\.php\?[^"]+)">', rootpage))
-        relative_path = re.match(r'https?://link.theplatform.com/s/([^?]+)', url).group(1)
+        relative_path = re.match(r'https?://link\.theplatform\.com/s/([^?]+)', url).group(1)
-            r': <a href="http://www.thisav.com/user/[0-9]+/(?:[^"]+)">([^<]+)</a>',
+            r': <a href="http://www\.thisav\.com/user/[0-9]+/(?:[^"]+)">([^<]+)</a>',
-            r': <a href="http://www.thisav.com/user/[0-9]+/([^"]+)">(?:[^<]+)</a>',
+            r': <a href="http://www\.thisav\.com/user/[0-9]+/([^"]+)">(?:[^<]+)</a>',
-            r'<iframe[^>]+src="((?:https?:)?//(?:www.youtube.com/embed/[^"]+|(?:www\.)?vine\.co/v/\w+/card))"',
+            r'<iframe[^>]+src="((?:https?:)?//(?:www\.youtube\.com/embed/[^"]+|(?:www\.)?vine\.co/v/\w+/card))"',
-    _VALID_URL = r'https://www.vice.com/[^/]+/article/(?P<id>[^?#]+)'
+    _VALID_URL = r'https://www\.vice\.com/[^/]+/article/(?P<id>[^?#]+)'
-        if re.match(r'^<html><head><script[^>]*>window.location\s*=', webpage):
+        if re.match(r'^<html><head><script[^>]*>window\.location\s*=', webpage):
-            r'<link itemprop="url" href="(?P<uploader_url>https?://www.youtube.com/(?:user|channel)/(?P<uploader_id>[^"]+))">',
+            r'<link itemprop="url" href="(?P<uploader_url>https?://www\.youtube\.com/(?:user|channel)/(?P<uploader_id>[^"]+))">',
-            webpage, 'media link', default=None, flags=re.MULTILINE)
+            r'''(?sx)class=
-                                hrti\.hrt\.hr/\#/video/show/(?P<id>[0-9]+)/(?P<display_id>[^/]+)?
+                                hrti\.hrt\.hr/(?:\#/)?video/show/(?P<id>[0-9]+)/(?P<display_id>[^/]+)?
-        self._sort_formats(formats)
+        release_url = video['videoRelease']['url']
-        return {
+        info = {
-            'formats': formats,
+
-__version__ = '2017.10.01'
+__version__ = '2017.10.07'
-    _VALID_URL = r'https?://(?:www\.)?lnkgo\.alfa\.lt/visi-video/(?P<show>[^/]+)/ziurek-(?P<id>[A-Za-z0-9-]+)'
+    _VALID_URL = r'https?://(?:www\.)?lnkgo\.(?:alfa\.)?lt/visi-video/(?P<show>[^/]+)/ziurek-(?P<id>[A-Za-z0-9-]+)'
-    _VALID_URL = r'https?://(?:www\.)?pornflip\.com/(?:v|embed)/(?P<id>[0-9A-Za-z]{11})'
+    _VALID_URL = r'https?://(?:www\.)?pornflip\.com/(?:v|embed)/(?P<id>[0-9A-Za-z-]{11})'
-                            https?://(?:www\.)?xtube\.com/(?:watch\.php\?.*\bv=|video-watch/(?P<display_id>[^/]+)-)
+                            https?://(?:www\.)?xtube\.com/(?:watch\.php\?.*\bv=|video-watch/(?:embedded/)?(?P<display_id>[^/]+)-)
-                playlistitems = iter_playlistitems(playlistitems_str)
+                playlistitems = orderedSet(iter_playlistitems(playlistitems_str))
-                        if -n_all_entries <= i - 1 < n_all_entries]
+                    entries = make_playlistitems_entries(ie_entries)
-                    (ie_result['extractor'], playlist, n_entries))
+                report_download(n_entries)
-                    entries = [entry_list[i - 1] for i in playlistitems]
+                    entries = make_playlistitems_entries(list(ie_entries))
-                    (ie_result['extractor'], playlist, n_entries))
+                report_download(n_entries)
-            self._PAGE_SIZE, use_cache=True)
+            self._PAGE_SIZE)
-            self._PAGE_SIZE, use_cache=True)
+            self._PAGE_SIZE)
-    def __init__(self, pagefunc, pagesize, use_cache=False):
+    def __init__(self, pagefunc, pagesize, use_cache=True):
-    _TEST = {
+    _VALID_URL = r'''(?x)
-    }
+    }, {
-        webpage = self._download_webpage(url, video_id)
+
-        video_thumbnail = self._search_regex(
+        title = self._html_search_regex(
-        video_duration = int_or_none(self._og_search_property(
+        duration = int_or_none(self._og_search_property(
-            'thumbnail': video_thumbnail,
+            'title': title,
-    _VALID_URL = r'^:(?P<id>tds|thedailyshow)$'
+    _VALID_URL = r'^:(?P<id>tds|thedailyshow|theopposition)$'
-            video_id)
+        for api_path in ('', 'api.'):
-                                if 'total_number' not in representation_ms_info and 'segment_duration':
+                                if 'total_number' not in representation_ms_info and 'segment_duration' in representation_ms_info:
-    _VALID_URL = r'https?://(?:(?:[^/]+)\.)?tvn24(?:bis)?\.pl/(?:[^/]+/)*(?P<id>[^/]+)\.html'
+    _VALID_URL = r'https?://(?:(?:[^/]+)\.)?tvn24(?:bis)?\.pl/(?:[^/]+/)*(?P<id>[^/]+)'
-            'thumbnail': 're:http://.*[.]jpeg',
+            'thumbnail': 're:https?://.*[.]jpeg',
-    _VALID_URL = r'(?P<permalink>https?://(?:www\.)?nbc\.com/[^/]+/video/[^/]+/(?P<id>n?\d+))'
+    _VALID_URL = r'https?(?P<permalink>://(?:www\.)?nbc\.com/[^/]+/video/[^/]+/(?P<id>n?\d+))'
-    'opus': 'opus',
+    'opus': 'libopus',
-        'md5': 'd907f7b1814ef0fa285c0475d9994ed7',
+        'md5': '6bdeb65998930251bbd1c510750edba9',
-from ..utils import float_or_none
+from ..utils import (
-        'md5': 'ea838375a547ac787d4064d8c7860a6c',
+        'md5': 'ed66976748d12350b118455979cca293',
-            'ext': 'mp4',
+            'ext': 'flv',
-        }
+        },
-        }
+        },
-        }
+        },
-        title = (self._search_regex(
+        title = strip_or_none(self._search_regex(
-            webpage)).strip()
+            webpage, default=None))
-                    subtitles.setdefault('nl', []).append({'url': subtitle_url})
+            r'data-video=(["\'])(?P<id>(?:(?!\1).)+)\1', webpage, 'video id',
-from .canvas import CanvasIE
+from .canvas import (
-            video_id, query={'nTitleNo': video_id})
+            video_id, query={
-__version__ = '2017.09.24'
+__version__ = '2017.10.01'
-    _VALID_URL = r'https?://[^/]+\.tvp\.(?:pl|info)/(?:(?!\d+/)[^/]+/)*(?P<id>\d+)'
+    _VALID_URL = r'https?://[^/]+\.tvp\.(?:pl|info)/(?:video/(?:[^,\s]*,)*|(?:(?!\d+/)[^/]+/)*)(?P<id>\d+)'
-        'url': 'http://vod.tvp.pl/194536/i-seria-odc-13',
+        'url': 'https://vod.tvp.pl/video/czas-honoru,i-seria-odc-13,194536',
-            'description': 'md5:76649d2014f65c99477be17f23a4dead',
+            'description': 'md5:381afa5bca72655fe94b05cfe82bf53d',
-        'md5': 'cf6a4705dfd1489aef8deb168d6ba742',
+        'url': 'https://wiadomosci.tvp.pl/33908820/28092017-1930',
-            'id': '22680786',
+            'id': '33908820',
-            'title': 'WiadomoÅci, 08.12.2015, 15:00',
+            'title': 'WiadomoÅci, 28.09.2017, 19:30',
-            # Video.js embed
+            # Video.js embed, multiple formats
-            r'(?s)\bvideojs\s*\(.+?\bplayer\.src\s*\(\s*(\[.+?\])\s*\)\s*;',
+            r'(?s)\bvideojs\s*\(.+?\.src\s*\(\s*((?:\[.+?\]|{.+?}))\s*\)\s*;',
-    _VALID_URL = r'(?P<host>https?://(?:[a-zA-Z]{2}\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?:(?P<display_id>.+)?-)?(?P<id>[0-9]+)(?:-[a-z]+)?(?:\.html)?'
+    _VALID_URL = r'(?P<host>https?://(?:(?P<country>[a-zA-Z]{2})\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?:(?P<display_id>.+)?-)?(?P<id>[0-9]+)(?:-[a-z]+)?(?:\.html)?'
-            return self.url_result(bc_url, BrightcoveNewIE.ie_key())
+            return brightcove_url_result(bc_url)
-                        BrightcoveNewIE.ie_key())
+                    return brightcove_url_result(
-    unescapeHTML,
+    determine_ext,
-    determine_ext,
+    unescapeHTML,
-                BrightcoveNewIE.ie_key())
+        brightcove_iframe = self._search_regex(
-        if not video_url.endswith('.f4m'):
+        ext = determine_ext(video_url)
-            'url': video_url,
+            'title': title,
-                        
+
-            'md5': '2a9752f74cb898af5d1083ea9f661b58',
+            'md5': '989396ae73d20c6f057746fb226aa215',
-    _VALID_URL = r'(?P<url>(?P<host>https?://(?:[a-zA-Z]{2}\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?P<display_id>.+)?-(?P<id>[0-9]+)(?:-[a-z]+)?(?:\.html)?)'
+    _VALID_URL = r'(?P<host>https?://(?:[a-zA-Z]{2}\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?:(?P<display_id>.+)?-)?(?P<id>[0-9]+)(?:-[a-z]+)?(?:\.html)?'
-        url = mobj.group('url')
+        display_id = mobj.group('display_id') or page_id
-    _VALID_URL = r'https?://(?:www\.)?gfycat\.com/(?:ifr/)?(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?gfycat\.com/(?:ifr/|gifs/detail/)?(?P<id>[^/?#]+)'
-            if embed_url:
+            if embed_url and embed_url != url:
-            r'href="(https?://xhamster\.com/movies/%s/[^"]*\.html[^"]*)"' % video_id,
+            r'href="(https?://xhamster\.com/(?:movies/{0}/[^"]*\.html|videos/[^/]*-{0})[^"]*)"'.format(video_id),
-__version__ = '2017.09.15'
+__version__ = '2017.09.24'
-    _VALID_URL = r'https?://tv.kakao.com/channel/(?P<channel>\d+)/cliplink/(?P<id>\d+)'
+    _VALID_URL = r'https?://tv\.kakao\.com/channel/(?P<channel>\d+)/cliplink/(?P<id>\d+)'
-from ..compat import compat_urlparse
+from ..compat import (
-            self.extractor._set_cookie(**cookie)
+            self.extractor._set_cookie(**compat_kwargs(cookie))
-    PhantomJSwrapper,
+from .extractor.openload import PhantomJSwrapper
-    PhantomJSwrapper,
+    get_exe_version,
-            webpage, 'upload date'))
+            r'<time[^>]+\bdatetime="([^"]+)"[^>]+itemprop="uploadDate"',
-            webpage, 'comment count', fatal=False))
+            webpage, 'comment count', default=None))
-    _VALID_URL = r'https?://(?P<host>(?:www\.)?24video\.(?:net|me|xxx|sex|tube))/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?P<host>(?:www\.)?24video\.(?:net|me|xxx|sex|tube|adult))/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
-                    webpage, 'title')
+                r'<div[^>]+class="videoplayerjw"[^>]+data-title="([^"]+)"',
-    compat_str,
+    update_url_query,
-    IE_NAME = 'kakao.com'
+    _API_BASE = 'http://tv.kakao.com/api/v1/ft/cliplinks'
-        player_header = {'Referer': player_url}
+        player_header = {
-            'http://tv.kakao.com/api/v1/ft/cliplinks/%s/impress' % video_id,
+            '%s/%s/impress' % (self._API_BASE, video_id),
-        }
+            query=query, headers=player_header)
-            'http://tv.kakao.com/api/v1/ft/cliplinks/%s/raw' % video_id,
+            '%s/%s/raw' % (self._API_BASE, video_id),
-            }, headers=player_header, fatal=False)
+            query=query, headers=player_header)
-                    video_id, 'Downloading video URL for profile %s' % profile_name,
+                    '%s/%s/raw/videolocation' % (self._API_BASE, video_id),
-        video_info['timestamp'] = upload_date
+        top_thumbnail = clip.get('thumbnailUrl')
-        return video_info
+        return {
-    _VALID_URL = r'https?://(?:www\.|m\.|mobile\.)?twitter\.com/(?P<user_id>[^/]+)/status/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.|m\.|mobile\.)?twitter\.com/(?:i/web|(?P<user_id>[^/]+))/status/(?P<id>\d+)'
-            'uploader': 'FilmDrunk',
+            'title': 'Vince Mancini - Vine of the day',
-            self._TEMPLATE_URL % (user_id, twid), twid)
+            self._TEMPLATE_STATUSES_URL % twid, twid)
-
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?americastestkitchen\.com/episode/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?americastestkitchen\.com/(?:episode|videos)/(?P<id>\d+)'
-        'https://www.americastestkitchen.com/episode/548-summer-dinner-party',
+        'url': 'https://www.americastestkitchen.com/episode/548-summer-dinner-party',
-            'title': 'atk_s17_e24.mp4',
+            'title': 'Summer Dinner Party',
-            'description': '<p>Host Julia Collin Davison goes into the test kitchen with test cook Dan Souza to learn how to make the ultimate Grill-Roasted Beef Tenderloin. Next, equipment expert Adam Ried reviews gas grills in the Equipment Corner. Then, gadget guru Lisa McManus uncovers the best quirky gadgets. Finally, test cook Erin McMurrer shows host Bridget Lancaster how to make an elegant Pear-Walnut Upside-Down Cake.</p>',
+            'description': 'md5:858d986e73a4826979b6a5d9f8f6a1ec',
-            'episode_number': 24,
+            'release_date': '20170617',
-            'season_number': 17
+            'episode_number': 24,
-        True,
+        'url': 'https://www.americastestkitchen.com/videos/3420-pan-seared-salmon',
-            group='partner_id')
+            r'src=["\'](?:https?:)?//(?:[^/]+\.)kaltura\.com/(?:[^/]+/)*(?:p|partner_id)/(\d+)',
-                r'window\.__INITIAL_STATE__\s*=\s*({.+?});\s*</script>',
+                r'window\.__INITIAL_STATE__\s*=\s*({.+?})\s*;\s*</script>',
-        external_id = episode_content_meta['external_id']
+        ep_data = try_get(
-        thumbnail = photo_data.get('image_url') if photo_data else None
+        title = ep_data.get('title') or ep_meta.get('title')
-        season_number = int(episode_content_meta.get('season_number'))
+        season_number = int_or_none(ep_meta.get('season_number'))
-            'thumbnail': thumbnail,
+            'title': title,
-            'episode_number': episode_number,
+            'thumbnail': thumbnail,
-            'season_number': season_number
+            'episode_number': episode_number,
-                entry.update({
+            if len(entries) == 1:
-            return self.playlist_result(entries)
+            return self.playlist_result(entries, video_id, video_title)
-    try_get)
+    try_get,
-                r'<script id="relay-data" type="text/x-mixcloud">([^<]+)</script>', webpage, 'play info'), 'play info')
+                r'<script id="relay-data" type="text/x-mixcloud">([^<]+)</script>',
-                item_data = try_get(item, lambda x: x['cloudcast']['data']['cloudcastLookup'])
+                item_data = try_get(
-        js = self._download_webpage(js_url, track_id)
+            r'<script[^>]+\bsrc=["\"](https://(?:www\.)?mixcloud\.com/media/(?:js2/www_js_4|js/www)\.[^>]+\.js)',
-                                         "encryption key", default=None)
+                key = self._search_regex(
-                                lambda x: 'https://thumbnailer.mixcloud.com/unsafe/600x600/' + x['picture']['urlRoot'])
+            thumbnail = urljoin(
-            view_count = try_get(info_json, lambda x: x['plays'])
+            view_count = int_or_none(try_get(info_json, lambda x: x['plays']))
-                                     formats)
+
-import itertools
+try:
-    compat_str,
+    compat_zip
-)
+    try_get)
-                    raise
+    @staticmethod
-                            self._current_key = key
+        # Legacy path
-            webpage, 'play count', default=None))
+        js_url = self._search_regex(
-            'url': song_url,
+            'formats': formats,
-        if opts.convertsubtitles not in ['srt', 'vtt', 'ass']:
+        if opts.convertsubtitles not in ['srt', 'vtt', 'ass', 'lrc']:
-        help='Convert the subtitles to other format (currently supported: srt|ass|vtt)')
+        help='Convert the subtitles to other format (currently supported: srt|ass|vtt|lrc)')
-    _VALID_URL = r'https?://(?:www\.)?lynda\.com/(?:[^/]+/[^/]+/(?P<course_id>\d+)|player/embed)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:lynda\.com|educourse\.ga)/(?:[^/]+/[^/]+/(?P<course_id>\d+)|player/embed)/(?P<id>\d+)'
-    _VALID_URL = r'https?://(?:www|m)\.lynda\.com/(?P<coursepath>[^/]+/[^/]+/(?P<courseid>\d+))-\d\.html'
+    _VALID_URL = r'https?://(?:www|m)\.(?:lynda\.com|educourse\.ga)/(?P<coursepath>[^/]+/[^/]+/(?P<courseid>\d+))-\d\.html'
-            r'<script[^>]+src=(["\'])(?P<url>(?:https?:)?//static\.beeg\.com/cpl/\d+\.js.*?)\1',
+            r'<script[^>]+src=(["\'])(?P<url>(?:/static|(?:https?:)?//static\.beeg\.com)/cpl/\d+\.js.*?)\1',
-        beeg_version = beeg_version or '2000'
+        beeg_version = beeg_version or '2185'
-        'url': 'https://vplayer.nbcsports.com/p/BxmELC/nbcsports_share/select/9CsDKds0kvHI',
+        'url': 'https://vplayer.nbcsports.com/p/BxmELC/nbcsports_embed/select/9CsDKds0kvHI',
-            'ext': 'flv',
+            'ext': 'mp4',
-        'url': 'http://vplayer.nbcsports.com/p/BxmELC/nbc_embedshare/select/_hqLjQ95yx8Z',
+        'url': 'https://vplayer.nbcsports.com/p/BxmELC/nbcsports_embed/select/media/_hqLjQ95yx8Z',
-        theplatform_url = self._og_search_video_url(webpage)
+        theplatform_url = self._og_search_video_url(webpage).replace(
-        duration = float_or_none(config.get('duration')) or duration
+        duration = float_or_none(config.get('duration'), scale=1000) or duration
-            'description': 'Donte on Twitter: "BEAT PROD: @suhmeduh  https://t.co/HBrQ4AfpvZ #Damndaniel https://t.co/byBooq2ejZ"',
+            'title': 'ããã - BEAT PROD: @suhmeduh #Damndaniel',
-            'uploader': 'Donte',
+            'uploader': 'ããã',
-        return self.url_result('mtg:%s' % video_id, TVPlayIE.ie_key())
+        return self.url_result(
-from test.helper import get_testcases
+from test.helper import gettestcases
-for test in get_testcases():
+for test in gettestcases():
-
+from .popcorntv import PopcornTVIE
-            0, name, value, port, not port is None, domain, True,
+            0, name, value, port, port is not None, domain, True,
-    };
+    }
-    if not cookie.expires is None:
+    if cookie.expires is not None:
-    if not cookie.secure is None:
+    if cookie.secure is not None:
-    if not cookie.discard is None:
+    if cookie.discard is not None:
-            cookie.has_nonstandard_attr('HttpOnly')):
+                cookie.has_nonstandard_attr('httponly') or
-                cookie['rest'] = { 'httpOnly': None }
+                cookie['rest'] = {'httpOnly': None}
-        
+
-        
+
-        
+
-            
+
-            stderr=subprocess.PIPE)
+        p = subprocess.Popen([
-                                 + encodeArgument(err))
+            raise ExtractorError(
-    _APP = '65535a'
+    _APP = '100005a'
-    _APP_SECRET = '-$iJ}@p7!G@SyU/je1bEyWg}upLu-6V6-Lg9VD(]siH,r.,m-r|ulZ,U4LC/SeR)'
+    _APP_SECRET = 'MM_d*yP@`&1@]@!AVrXf_o-HVEnoTnm$O-ti4[G~$JDI/Dc-&piU&z&5.;:}95=Iad'
-    _TEST = {
+    _VALID_URL = r'https?://(?:(?:www|news)\.)morningstar\.com/[cC]over/video[cC]enter\.aspx\?id=(?P<id>[0-9]+)'
-    }
+    }, {
-            </tt>'''
+            </tt>'''.encode('utf-8')
-            </tt>'''
+            </tt>'''.encode('utf-8')
-</tt>'''
+</tt>'''.encode('utf-8')
-                with io.open(dfxp_file, 'rt', encoding='utf-8') as f:
+                with open(dfxp_file, 'rb') as f:
-            'http://www.w3.org/2006/10/ttaf1',
+        (b'http://www.w3.org/ns/ttml', [
-            'http://www.w3.org/ns/ttml#style',
+        (b'http://www.w3.org/ns/ttml#styling', [
-    dfxp = compat_etree_fromstring(dfxp_data.encode('utf-8'))
+    dfxp = compat_etree_fromstring(dfxp_data)
-            'description': 'md5:336d5ebc5436534e61d16e63ddfca327',
+            'description': 'md5:888c3330f0c1b4476c5bc99a1c040473',
-            video_id)['data']
+        webpage = self._download_webpage(url, video_id)
-        content = try_get(data, lambda x: x['contents'][0])
+        bc_url = BrightcoveNewIE._extract_url(self, webpage)
-        brightcove_id = data.get('brightcoveId') or content['brightcoveId']
+        data = self._parse_json(
-            compat_str)
+            data, lambda x: x['emission']['nom']) or self._search_regex(
-            episode = og.get('title')
+        season_el = try_get(data, lambda x: x['emission']['saison'], dict) or {}
-        video = content or data
+        episode_el = try_get(season_el, lambda x: x['episode'], dict) or {}
-            'view_count': int_or_none(video.get('viewsCount')),
+            'url': smuggle_url(bc_url, {'geo_countries': ['CA']}),
-                data, lambda x: x['season']['seasonNumber'])),
+            'season': season,
-            'episode_number': int_or_none(data.get('episodeNumber')),
+            'episode_number': episode_number,
-    _VALID_URL = r'(?:https?://)?(?:www\.)?dailymotion\.[a-z]{2,3}/playlist/(?P<id>.+?)/'
+    _VALID_URL = r'(?:https?://)?(?:www\.)?dailymotion\.[a-z]{2,3}/playlist/(?P<id>[^/?#&]+)'
-    _VALID_URL_BASE = r'https?://(?:www\.)?twitch\.tv'
+    _VALID_URL_BASE = r'https?://(?:(?:www|go)\.)?twitch\.tv'
-                            (?:www\.)?twitch\.tv/(?:[^/]+/v|videos)/|
+                            (?:(?:www|go)\.)?twitch\.tv/(?:[^/]+/v|videos)/|
-                            (?:www\.)?twitch\.tv/|
+                            (?:(?:www|go)\.)?twitch\.tv/|
-                        \#!/(?:video|live)/|
+                        (?:\#!/)?(?:video|live)/|
-        }
+        },
-__version__ = '2017.09.11'
+__version__ = '2017.09.15'
-            })
+    def _extract_video_params(self, webpage, display_id):
-        else:
+
-            params = self._extract_video_params(webpage)
+            params = self._extract_video_params(webpage, display_id)
-            'url': ' http://www.tv4play.se/program/farang/3922081',
+            'url': 'http://www.tv4play.se/program/farang/3922081',
-    determine_ext,
+    orderedSet,
-                (?:program|barn)/(?:[^\?]+)\?video_id=|
+                (?:program|barn)/(?:[^/]+/|(?:[^\?]+)\?video_id=)|
-                assert resume_len > 0
+                assert ctx['fragment_index'] == 0
-)
+from ..compat import compat_str
-    sanitized_Request,
+    urljoin,
-        request.add_header('Referer', self._LOGIN_URL)
+            post_url = urljoin(self._LOGIN_URL, post_url)
-            request, None, 'Logging in as %s' % username)
+            post_url, None, 'Logging in as %s' % username,
-                        compat_urlparse.urljoin(url, playlist_url),
+                    item_id_list = []
-                        fatal=False)
+                        }, fatal=False)
-                        'url': compat_urlparse.urljoin(url, m.group('href')),
+                        'url': urljoin(url, m.group('href')),
-                    r'<input[^>]+class=["\'].*?streamstarter_html5[^>]+>', html):
+                    r'<input[^>]+class=["\'].*?streamstarter[^>]+>', html):
-                for playlist_key in ('data-playlist', 'data-otherplaylist'):
+                for playlist_key in ('data-playlist', 'data-otherplaylist', 'data-stream'):
-__version__ = '2017.09.10'
+__version__ = '2017.09.11'
-    def suitable(url):
+    @classmethod
-__version__ = '2017.09.02'
+__version__ = '2017.09.10'
-    update_url_query,
+    int_or_none,
-        'url': 'http://www.fox.com/watch/255180355939/7684182528',
+    _VALID_URL = r'https?://(?:www\.)?fox\.com/watch/(?P<id>[\da-fA-F]+)'
-            'id': '255180355939',
+            'id': '4b765a60490325103ea69888fb2bd4e8',
-            'uploader': 'NEWA-FNG-FOXCOM',
+            'title': 'Aftermath: Bruce Wayne Develops Into The Dark Knight',
-    }
+        'params': {
-        return info
+        video = self._download_json(
-    try_get,
+    bool_or_none,
-            'is_live': video.get('is_livestream'),
+            'is_live': bool_or_none(video.get('is_livestream')),
-    unified_strdate,
+    unified_timestamp,
-class RutubeIE(InfoExtractor):
+class RutubeBaseIE(InfoExtractor):
-            'ext': 'mp4',
+            'ext': 'flv',
-        },
+    }, {
-        return res
+        return False if RutubePlaylistIE.suitable(url) else super(RutubeIE, cls).suitable(url)
-        author = video.get('author') or {}
+        info = self._extract_video(video, video_id)
-        }
+        info['formats'] = formats
-            'ext': 'mp4',
+            'ext': 'flv',
-            'skip_download': 'Requires ffmpeg',
+            'skip_download': True,
-        return self.url_result(canonical_url, 'Rutube')
+        return self.url_result(canonical_url, RutubeIE.ie_key())
-class RutubeChannelIE(InfoExtractor):
+class RutubePlaylistBaseIE(RutubeBaseIE):
-class RutubeMovieIE(RutubeChannelIE):
+class RutubeMovieIE(RutubePlaylistBaseIE):
-        return self._extract_videos(movie_id, movie_name)
+        return self._extract_playlist(
-class RutubePersonIE(RutubeChannelIE):
+class RutubePersonIE(RutubePlaylistBaseIE):
-class RutubePlaylistIE(InfoExtractor):
+class RutubePlaylistIE(RutubePlaylistBaseIE):
-        'url': 'https://rutube.ru/video/10b3a03fc01d5bbcc632a2f3514e8aab/?pl_id=4252&pl_type=source',
+        'url': 'https://rutube.ru/video/cecd58ed7d531fc0f3d795d51cee9026/?pl_id=3097&pl_type=tag',
-            'id': '4252',
+            'id': '3097',
-        'playlist_count': 25,
+        'playlist_count': 27,
-    _PAGE_TEMPLATE = 'http://rutube.ru/api/playlist/source/%s/?page=%s'
+    _PAGE_TEMPLATE = 'http://rutube.ru/api/playlist/%s/%s/?page=%s&format=json'
-                break
+        return params.get('pl_type', [None])[0] and int_or_none(params.get('pl_id', [None])[0])
-                entries.append(entry)
+    def _next_page_url(self, page_num, playlist_id, item_kind):
-        return self.playlist_result(entries, playlist_id, page['name'])
+    def _real_extract(self, url):
-            'skip_download': True,
+    _TESTS = [
-    }
+        {
-            'title': get_meta('Title'),
+            'title': get_meta('Title') or get_meta('AV-nomEmission'),
-            webpage, 'YouTube URL', default=None)
+        youtube_url = YoutubeIE._extract_url(webpage)
-            entries = [entry, self.url_result(youtube_url, 'Youtube')]
+            entries = [entry, self.url_result(youtube_url, ie=YoutubeIE.ie_key())]
-                return self.url_result(youtube_url, ie='Youtube')
+            youtube_url = YoutubeIE._extract_url(webpage)
-            webpage, 'youtube url', default=None)
+        youtube_url = YoutubeIE._extract_url(webpage)
-            return self.url_result(youtube_url, 'Youtube')
+            return self.url_result(youtube_url, ie=YoutubeIE.ie_key())
-            body, 'YouTube URL', default=None)
+        youtube_url = YoutubeIE._extract_url(body)
-            return _url_res(youtube_url, 'Youtube')
+            return _url_res(youtube_url, YoutubeIE.ie_key())
-            info_page, 'youtube iframe', default=None)
+        youtube_url = YoutubeIE._extract_url(info_page)
-            return self.url_result(youtube_url, 'Youtube')
+            return self.url_result(youtube_url, ie=YoutubeIE.ie_key())
-        if matches:
+        # Look for YouTube embeds
-            return self.playlist_from_matches(matches, video_id, video_title, lambda m: m[-1])
+                youtube_urls, video_id, video_title, ie=YoutubeIE.ie_key())
-            self.report_error('unable to create directory ' + error_to_compat_str(err))
+        def ensure_dir_exists(path):
-                            fname = prepend_extension(fname, 'f%s' % f['format_id'], new_info['ext'])
+                            fname = prepend_extension(
-        else:
+        medias = self._parse_json(
-            r'videoDuration\s*:\s*(\d+)', webpage, 'duration', fatal=False))
+            r'videoDuration\s*:\s*(\d+)', webpage, 'duration', default=None))
-        if not vsr and not player_info.get('VRU'):
+        if not vsr:
-from ..compat import compat_urllib_parse_unquote
+from ..utils import int_or_none
-    _VALID_URL = r'https?://www.manyvids\.com/Video/(?P<id>[0-9]+)'
+    _VALID_URL = r'(?i)https?://(?:www\.)?manyvids\.com/video/(?P<id>\d+)'
-        }
+            'title': 'everthing about me (Preview)',
-        formats = []
+
-        })
+        video_url = self._search_regex(
-            'formats': formats,
+            'view_count': view_count,
-        'playlist_mincount': 73,
+        'only_matching': True,
-        'playlist_mincount': 43,
+        'only_matching': True,
-    _VALID_URL = r'https?://vid\.me/(?:e/)?(?P<id>[\da-zA-Z]{6,})(?!/likes)(?:[^\da-zA-Z]|$)'
+    _VALID_URL = r'https?://vid\.me/(?:e/)?(?P<id>[\da-zA-Z_-]{6,})(?!/likes)(?:[^\da-zA-Z_-]|$)'
-        'url': 'https://vid.me/EFARCHIVE',
+    _TESTS = [{
-            'title': 'EFARCHIVE - %s' % _TITLE,
+            'id': '16112341',
-    }
+        'playlist_mincount': 191,
-    _VALID_URL = r'https?://vid\.me/(?:e/)?(?P<id>[\da-zA-Z]{6,})/likes'
+    _VALID_URL = r'https?://vid\.me/(?:e/)?(?P<id>[\da-zA-Z_-]{6,})/likes'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r"({\s*src\s*:\s*'https://film\.bpb\.de/[^}]+})", webpage)
+            r"({\s*src\s*:\s*'https?://film\.bpb\.de/[^}]+})", webpage)
-            quality = 'high' if re.search(r'_high\.', video_url) else 'low'
+            video_info = self._parse_json(
-            r"({\s*src:\s*'http://film\.bpb\.de/[^}]+})", webpage)
+            r"({\s*src\s*:\s*'https://film\.bpb\.de/[^}]+})", webpage)
-            quality = video_info['quality']
+            quality = 'high' if re.search(r'_high\.', video_url) else 'low'
-    update_url_query)
+    update_url_query,
-                'https://api.soundcloud.com/tracks/{0}/download'.format(track_id), query)
+                'https://api.soundcloud.com/tracks/%s/download' % track_id, query)
-import re
+import re
-)
+    update_url_query)
-                    track_id, self._CLIENT_ID))
+            format_url = update_url_query(
-            })
+            track_id, 'Downloading track url', query=query)
-                'url': info['stream_url'] + '?client_id=' + self._CLIENT_ID,
+                'url': update_url_query(info['stream_url'], query),
-from ..utils import try_get, float_or_none
+from ..utils import (
-    _VALID_URL = r'https?://live\.aliexpress\.com/live/(?P<id>[0-9]{16})'
+    _VALID_URL = r'https?://live\.aliexpress\.com/live/(?P<id>\d+)'
-        'md5': '7ac2bc46afdd18f0b45a0a340fc47ffe',
+        'md5': 'e729e25d47c5e557f2630eaf99b740a5',
-            'ext': 'm3u8',
+            'ext': 'mp4',
-            'timestamp': 1500027138,
+            'timestamp': 1500717600,
-        run_params = self._parse_json(run_params_json, video_id)
+
-            'timestamp': float_or_none(try_get(run_params, lambda x: x['followBar']['createTime']) / 1000),
+            'title': title,
-    compat_urlparse,
+    compat_HTTPError,
-    parse_duration,
+    ExtractorError,
-            lecture_id)['lecture'][0]
+        try:
-                    self.IE_NAME, xpath_text(v_data, 'message')), expected=True)
+                error = xpath_text(v_data, 'message')
-__version__ = '2017.08.27.1'
+__version__ = '2017.09.02'
-    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s&disable_polymer=true'
+    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s'
-                 r'id="watch-uploader-info".*?>.*?(?:Published|Uploaded|Streamed live|Started) on (.+?)</strong>'],
+                 r'(?:id="watch-uploader-info".*?>.*?|["\']simpleText["\']\s*:\s*["\'])(?:Published|Uploaded|Streamed live|Started) on (.+?)[<"\']'],
-    _VALID_URL = r'https?://(?:www\.)?charlierose\.com/video(?:s|/player)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?charlierose\.com/(?:video|episode)(?:s|/player)/(?P<id>\d+)'
-    _ID_REGEX = r'[pb][\da-z]{7}'
+    _ID_REGEX = r'[pbw][\da-z]{7}'
-    _VALID_URL = r'https?://(?:(?:docs|drive)\.google\.com/(?:uc\?.*?id=|file/d/)|video\.google\.com/get_player\?.*?docid=)(?P<id>[a-zA-Z0-9_-]{28,})'
+    _VALID_URL = r'''(?x)
-        'only_matching': True
+        'only_matching': True,
-        'md5': 'd109872761f7e7ecf353fa108c0dbe1e',
+        'md5': '5c602afbbf2c1db91831f5d82f678554',
-        title = self._search_regex(r'"title"\s*,\s*"([^"]+)', webpage, 'title')
+        title = self._search_regex(
-            'fmt stream map').split(',')
+            'fmt stream map', default='').split(',')
-            r'"fmt_list"\s*,\s*"([^"]+)', webpage, 'fmt_list').split(',')
+            r'"fmt_list"\s*,\s*"([^"]+)', webpage,
-                    int(mobj.group('width')), int(mobj.group('height')))
+            for fmt_stream in fmt_stream_map:
-                    'height': resolution[1],
+        source_url = update_url_query(
-            formats.append(f)
+            if urlh.headers.get('Content-Disposition'):
-            r"(?s)sources'?\s*:\s*(\{.+?\})\s*\}[;,)]",
+            r"(?s)sources'?\s*[:=]\s*(\{.+?\})",
-            r"'poster'\s*:\s*'([^']+)'", webpage, 'thumbnail', fatal=False)
+            r"poster'?\s*:\s*([\"'])(?P<url>(?:(?!\1).)+)\1", webpage,
-__version__ = '2017.08.27'
+__version__ = '2017.08.27.1'
-            view_count = extract_view_count(get_video_info)
+            view_count = extract_view_count(video_info)
-__version__ = '2017.08.23'
+__version__ = '2017.08.27'
-
+        # Looking for http://schema.org/VideoObject
-                        f['height'] = int_or_none(source_attributes.get('res'))
+                        f.update({
-    def report_retry(self, count, retries):
+    def report_retry(self, err, count, retries):
-            % (count, self.format_retries(retries)))
+            '[download] Got server HTTP error: %s. Retrying (attempt %d of %s)...'
-        stream = None
+
-                resume_len = 0
+        ctx.open_mode = 'wb'
-        while count <= retries:
+
-                data = self.ydl.urlopen(request)
+                ctx.data = self.ydl.urlopen(request)
-                    content_range = data.headers.get('Content-Range')
+                if ctx.resume_len > 0:
-                            break
+                        if content_range_m and ctx.resume_len == int(content_range_m.group(1)):
-                break
+                    ctx.resume_len = 0
-                        content_length = data.info()['Content-Length']
+                        ctx.data = self.ydl.urlopen(basic_request)
-                                (resume_len - 100 < int(content_length) < resume_len + 100)):
+                                (ctx.resume_len - 100 < int(content_length) < ctx.resume_len + 100)):
-                            self.try_rename(tmpfilename, filename)
+                            self.report_file_already_downloaded(ctx.filename)
-                                'filename': filename,
+                                'filename': ctx.filename,
-                                'total_bytes': resume_len,
+                                'downloaded_bytes': ctx.resume_len,
-                            return True
+                            raise SucceedDownload()
-                if e.errno != errno.ECONNRESET:
+                            ctx.resume_len = 0
-        start = time.time()
+            byte_counter = 0 + ctx.resume_len
-        while True:
+            # measure time over whole while-loop, so slow_down() and best_block_size() work together properly
-            byte_counter += len(data_block)
+            def retry(e):
-                break
+            while True:
-                    self.report_error('unable to open for writing: %s' % str(err))
+                    ctx.stream.write(data_block)
-            except (IOError, OSError) as err:
+                # Apply rate limit
-                self.report_error('unable to write data: %s' % str(err))
+                self.report_error('Did not get any data blocks')
-            self.slow_down(start, now, byte_counter - resume_len)
+            if data_len is not None and byte_counter != data_len:
-            after = now
+            self.try_rename(ctx.tmpfilename, ctx.filename)
-                eta = self.calc_eta(start, time.time(), data_len - resume_len, byte_counter - resume_len)
+            # Update file modification time
-                'elapsed': now - start,
+                'total_bytes': byte_counter,
-        return True
+            return True
-                'formats': {
+                'formats': [{
-                }
+                }]
-                    for key_name in ('value', 'key_value', 'key_value_two'):
+                    for key_name in ('value', 'key_value', 'key_value.*?', '.*?value.*?'):
-        is_live = None
+                    if view_count is None:
-            view_count = None
+        if view_count is None:
-                    for key_name in ('value', 'key_value'):
+                    for key_name in ('value', 'key_value', 'key_value_two'):
-__version__ = '2017.08.18'
+__version__ = '2017.08.23'
-    ExtractorError,
+    _GEO_COUNTRIES = ['CA']
-            'id': '38e815a-009e3ab12e4',
+            'id': '9673749a-5e77-484c-8b62-a1092a6b5168',
-        'skip': 'Geo-restricted to Canada',
+        # geo-restricted to Canada, bypassable
-        'skip': 'Geo-restricted to Canada',
+        # IsDrm does not necessarily mean the video is DRM protected (see
-            raise ExtractorError('This video is DRM protected.', expected=True)
+            self.report_warning('This video is probably DRM protected.', path)
-    _captions_by_country_xml = None
+    _captions_xml = None
-            self._captions_by_country_xml = self._download_xml(self._BASE_URL_CAPTIONS, video_id, query={
+    def _download_subtitles_xml(self, video_id, subtitles_id, hl):
-                'vid': video_subtitles_id,
+                'vid': subtitles_id,
-            return None
+            }, note='Downloading subtitles XML',
-        for caption_entry in self._captions_by_country_xml.findall(self._CAPTIONS_ENTRY_TAG[caption_type]):
+        for caption_entry in self._captions_xml.findall(
-                    'vid': video_subtitles_id,
+                    'vid': subtitles_id,
-                    'lang': caption_lang_code if caption_original_lang_code is None else caption_original_lang_code,
+                    'lang': (caption_lang_code if origin_lang_code is None
-                if caption_original_lang_code is not None:
+                if origin_lang_code is not None:
-        return self._get_captions_by_type(video_id, video_subtitles_id, 'automatic_captions', subtitle_original_lang_code)
+    def _get_subtitles(self, video_id, subtitles_id, hl):
-        reason = self._search_regex(r'"reason"\s*,\s*"([^"]+)', webpage, 'reason', default=None)
+        reason = self._search_regex(
-            r'"length_seconds"\s*,\s*"([^"]+)', webpage, 'length seconds', default=None))
+            r'"length_seconds"\s*,\s*"([^"]+)', webpage, 'length seconds',
-        fmt_list = self._search_regex(r'"fmt_list"\s*,\s*"([^"]+)', webpage, 'fmt_list').split(',')
+            r'"fmt_stream_map"\s*,\s*"([^"]+)', webpage,
-        video_subtitles_id = None
+        subtitles_id = None
-            video_subtitles_id = ttsurl.encode('utf-8').decode('unicode_escape').split('=')[-1]
+            # the video Id for subtitles will be the last value in the ttsurl
-            'automatic_captions': self.extract_automatic_captions(video_id, video_subtitles_id, hl),
+            'subtitles': self.extract_subtitles(video_id, subtitles_id, hl),
-                      transform_source=None, fatal=True, encoding=None, data=None, headers={}, query={}):
+                      transform_source=None, fatal=True, encoding=None,
-            url_or_request, video_id, note, errnote, fatal=fatal, encoding=encoding, data=data, headers=headers, query=query)
+            url_or_request, video_id, note, errnote, fatal=fatal,
-        return compat_etree_fromstring(xml_string.encode('utf-8'))
+        try:
-        'only_matching': True,
+        'md5': 'c230c67252874fddd8170e3fd1a45886',
-            r'(?s)From:&nbsp;.+?<(?:a href="/users/|a href="/channels/|span class="username)[^>]+>(.+?)<',
+            r'(?s)From:&nbsp;.+?<(?:a\b[^>]+\bhref=["\']/(?:user|channel)s/|span\b[^>]+\bclass=["\']username)[^>]+>(.+?)<',
-            self.url_result(compat_urlparse.urljoin(url, t_path), ie=BandcampIE.ie_key())
+            self.url_result(
-                    preference=preference)
+                    preference=preference, fatal=False)
-                    full_url, video_id, mpd_id=mpd_id)
+                    full_url, video_id, mpd_id=mpd_id, fatal=False)
-                            radio/player/
+                            radio/player/|
-        info_dict = entries[0]
+        for idx, info_dict in enumerate(entries):
-                    default=None))
+            self._sort_formats(info_dict['formats'])
-        self._sort_formats(info_dict['formats'])
+            # Don't append entry ID for one-video pages to keep backward compatibility
-        })
+            info_dict.update({
-        return info_dict
+        return self.playlist_result(entries, video_id, video_title)
-from .liveleak import LiveLeakIE
+from .liveleak import (
-            'md5': 'ace83b9ed19b21f68e1b50e844fdf95d',
+            'md5': '7619da8c820e835bef21a1efa2a0fc71',
-            }
+            },
-            return self.url_result(liveleak_url, 'LiveLeak')
+        liveleak_urls = LiveLeakIE._extract_urls(webpage)
-            r'<iframe[^>]+src="https?://(?:\w+\.)?liveleak\.com/ll_embed\?(?:.*?)i=(?P<id>[\w_]+)(?:.*)',
+    def _extract_urls(webpage):
-            return 'http://www.liveleak.com/view?i=%s' % mobj.group('id')
+
-            json_str = self._search_regex(
+            json_str = self._html_search_regex(
-        r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)
+        r'&([^&;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)
-                        self._current_key = key
+                    KEY_RE_TEMPLATE = r'player\s*:\s*{.*?\b%s\s*:\s*(["\'])(?P<key>(?:(?!\1).)+)\1'
-__version__ = '2017.08.13'
+__version__ = '2017.08.18'
-
+    ExtractorError,
-    unified_strdate,
+    unified_strdate,
-        for format_id, format_dict in player_info['VSR'].items():
+        for format_id, format_dict in vsr.items():
-            if not valid_url:
+            if not url:
-            return valid_url
+                return False
-            new_url = head_response.geturl()
+            new_url = compat_str(head_response.geturl())
-                    mpd_base_url=full_response.geturl().rpartition('/')[0],
+                    mpd_base_url=compat_str(full_response.geturl()).rpartition('/')[0],
-            r'href=(["\'])(?P<url>(?:https?://(?:www\.)?udemy\.com)?/payment/checkout/.+?)\1',
+            r'href=(["\'])(?P<url>(?:https?://(?:www\.)?udemy\.com)?/(?:payment|cart)/checkout/.+?)\1',
-            headers={'Referer': url})
+        course = self._download_course(course_name, url, display_id)
-            })['payload']['course']
+        course = self._download_course(course_id, url, course_id)
-    unescapeHTML,
+    strip_jsonp,
-        'md5': '9ce1c1c8445f561506d2e3cfb0255705',
+        'md5': '5f1e6cea39e182857da7ffc5ef5e6bb8',
-            'description': 'md5:d327722d0361576fde558f1ac68a7065',
+            'description': 'md5:d85afb3051952ecc50a1ee8a286d1eac',
-            'description': 'md5:ed14d5bd7ecec19609108052c25b2c11',
+            'description': 'md5:c9b20210587cbcd6836a1c597bab4525',
-            thumbnail_url = "http://i.gtimg.cn/music/photo/mid_album_500/%s/%s/%s.jpg" \
+            thumbnail_url = 'http://i.gtimg.cn/music/photo/mid_album_500/%s/%s/%s.jpg' \
-            (singmid, num), singmid)
+            r'https://c.y.qq.com/v8/fcg-bin/fcg_v8_singer_track_cp.fcg', singmid,
-                entries.append(self.url_result(r'https://y.qq.com/n/yqq/song/%s.html' % songmid, 'QQMusic', songmid))
+                entries.append(self.url_result(
-        'playlist_count': 12,
+        'playlist_mincount': 12,
-        singer_name = self._html_search_regex(r"singername : '(.*?)'", singer_page, 'singer name', default=None)
+        singer_name = self._html_search_regex(
-                req, mid, 'Donwload singer description XML')
+                'http://s.plcloud.music.qq.com/fcgi-bin/fcg_get_singer_desc.fcg', mid,
-            'id': 'global_123',
+            'id': '123',
-        'playlist_count': 10,
+        'playlist_count': 100,
-            'id': 'top_3',
+            'id': '3',
-                           'ç»å½ç¨æ·å®æ´æ­æ¾ä¸é¦æ­æ²ï¼è®°ä¸ºä¸æ¬¡æææ­æ¾ï¼åä¸ç¨æ·æ¶å¬åä¸é¦æ­æ²ï¼æ¯å¤©è®°å½ä¸º1æ¬¡æææ­æ¾'
+            'description': 'md5:5a600d42c01696b26b71f8c4d43407da',
-            'id': 'global_106',
+            'id': '106',
-            list_id, 'Download toplist page')
+            'http://i.y.qq.com/v8/fcg-bin/fcg_v8_toplist_cp.fcg', list_id,
-        ]
+        entries = [self.url_result(
-            % list_id, list_id, 'Download list page',
+            'http://i.y.qq.com/qzone-music/fcg-bin/fcg_ucc_getcdinfo_byids_cp.fcg',
-        ]
+        entries = [self.url_result(
-        for format_id in ('replay', 'rtmp', 'hls', 'https_hls'):
+        for format_id in ('replay', 'rtmp', 'hls', 'https_hls', 'lhls', 'lhlsweb'):
-            if not video_url:
+            if not video_url or video_url in video_urls:
-            f = {
+            video_urls.add(video_url)
-            formats.append(f)
+            })
-                    ms_info['segment_duration'] = int(segment_duration)
+                    ms_info['segment_duration'] = float(segment_duration)
-        json_obj = self._parse_json(json_text, singmid)
+        json_obj_all_songs = self._parse_json(json_text, singmid)
-            total = json_obj['data']['total']
+        if json_obj_all_songs['code'] == 0:
-            json_obj = self._parse_json(json_text, singmid)
+            json_obj_all_songs = self._parse_json(json_text, singmid)
-            if not (item['musicData'].get('songmid') is None):
+        for item in json_obj_all_songs['data']['list']:
-                'https://y.qq.com/n/yqq/song/' + song['songmid'] + ".html", 'QQMusic', song['songmid']
+                'https://y.qq.com/n/yqq/song/' + song['songmid'] + '.html', 'QQMusic', song['songmid']
-        list_type = "toplist"
+        list_type = 'toplist'
-                'https://y.qq.com/n/yqq/song/' + song['data']['songmid'] + ".html", 'QQMusic',
+                'https://y.qq.com/n/yqq/song/' + song['data']['songmid'] + '.html', 'QQMusic',
-                'https://y.qq.com/n/yqq/song/' + song['songmid'] + ".html", 'QQMusic', song['songmid']
+                'https://y.qq.com/n/yqq/song/' + song['songmid'] + '.html', 'QQMusic', song['songmid']
-    def get_entries_from_page(cls, page):
+    def get_singer_all_songs(self, singmid, num):
-                song_mid))
+        default_num = 1
-
+        entries = self.get_entries_from_page(mid)
-        if singer_id:
+        if mid:
-                'http://s.plcloud.music.qq.com/fcgi-bin/fcg_get_singer_desc.fcg?utf8=1&outCharset=utf-8&format=xml&singerid=%s' % singer_id)
+                'http://s.plcloud.music.qq.com/fcgi-bin/fcg_get_singer_desc.fcg?utf8=1&outCharset=utf-8&format=xml&singermid=%s' % mid)
-                'Referer', 'http://s.plcloud.music.qq.com/xhr_proxy_utf8.html')
+                'Referer', 'https://y.qq.com/n/yqq/singer/')
-                'https://y.qq.com/n/yqq/song/' + song['data']['songmid'] + ".html", 'QQMusic', song['data']['songmid']
+                'https://y.qq.com/n/yqq/song/' + song['data']['songmid'] + ".html", 'QQMusic',
-    _VALID_URL = r'https?://y\.qq\.com/n/yqq/toplist/(?P<id>(top|global)_[0-9]+)\.html'
+    _VALID_URL = r'https?://y\.qq\.com/n/yqq/toplist/(?P<id>[0-9]+)\.html'
-        list_type, num_id = list_id.split("_")
+        # list_type, num_id = list_id.split("_")
-import time
+import time
-    _VALID_URL = r'https?://y\.qq\.com/#type=song&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y\.qq\.com/n/yqq/song/(?P<id>[0-9A-Za-z]+)\.html'
-        'url': 'http://y.qq.com/#type=song&mid=004295Et37taLD',
+        'url': 'https://y.qq.com/n/yqq/song/004295Et37taLD.html',
-        'url': 'http://y.qq.com/#type=song&mid=004MsGEo3DdNxV',
+        'url': 'https://y.qq.com/n/yqq/song/004MsGEo3DdNxV.html',
-        'url': 'http://y.qq.com/#type=song&mid=001JyApY11tIp6',
+        'url': 'https://y.qq.com/n/yqq/song/001JyApY11tIp6.html',
-                'http://y.qq.com/#type=song&mid=' + song_mid, 'QQMusic',
+                # https://y.qq.com/n/yqq/song/004Dbsoo1yCbNZ.html
-    _VALID_URL = r'https?://y\.qq\.com/#type=singer&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y\.qq\.com/n/yqq/singer/(?P<id>[0-9A-Za-z]+)\.html'
-        'url': 'http://y.qq.com/#type=singer&mid=001BLpXF2DyJe2',
+        'url': 'https://y.qq.com/n/yqq/singer/001BLpXF2DyJe2.html',
-    _VALID_URL = r'https?://y\.qq\.com/#type=album&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y\.qq\.com/n/yqq/album/(?P<id>[0-9A-Za-z]+)\.html'
-        'url': 'http://y.qq.com/#type=album&mid=000gXCTb2AhRR1',
+        'url': 'https://y.qq.com/n/yqq/album/000gXCTb2AhRR1.html',
-        'url': 'http://y.qq.com/#type=album&mid=002Y5a3b3AlCu3',
+        'url': 'https://y.qq.com/n/yqq/album/002Y5a3b3AlCu3.html',
-                'http://y.qq.com/#type=song&mid=' + song['songmid'], 'QQMusic', song['songmid']
+                'https://y.qq.com/n/yqq/song/' + song['songmid'] + ".html", 'QQMusic', song['songmid']
-    _VALID_URL = r'https?://y\.qq\.com/#type=toplist&p=(?P<id>(top|global)_[0-9]+)'
+    _VALID_URL = r'https?://y\.qq\.com/n/yqq/toplist/(?P<id>(top|global)_[0-9]+)\.html'
-        'url': 'http://y.qq.com/#type=toplist&p=global_123',
+        'url': 'https://y.qq.com/n/yqq/toplist/123.html',
-        'url': 'http://y.qq.com/#type=toplist&p=top_3',
+        'url': 'https://y.qq.com/n/yqq/toplist/3.html',
-        'url': 'http://y.qq.com/#type=toplist&p=global_106',
+        'url': 'https://y.qq.com/n/yqq/toplist/106.html',
-                'http://y.qq.com/#type=song&mid=' + song['data']['songmid'], 'QQMusic', song['data']['songmid']
+                'https://y.qq.com/n/yqq/song/' + song['data']['songmid'] + ".html", 'QQMusic', song['data']['songmid']
-    _VALID_URL = r'https?://y\.qq\.com/#type=taoge&id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://y\.qq\.com/n/yqq/playlist/(?P<id>[0-9]+)\.html'
-        'url': 'http://y.qq.com/#type=taoge&id=3462654915',
+        'url': 'http://y.qq.com/n/yqq/playlist/3462654915.html',
-        'url': 'http://y.qq.com/#type=taoge&id=1374105607',
+        'url': 'https://y.qq.com/n/yqq/playlist/1374105607.html',
-                'http://y.qq.com/#type=song&mid=' + song['songmid'], 'QQMusic', song['songmid']
+                'https://y.qq.com/n/yqq/song/' + song['songmid'] + ".html", 'QQMusic', song['songmid']
-        for num, key in enumerate(KEYS, start=1):
+        for num, key in enumerate(self._keys, start=1):
-                if num == len(KEYS):
+                if num == len(self._keys):
-__version__ = '2017.08.09'
+__version__ = '2017.08.13'
-                webpage))
+                container))
-        entries = self._extract_entries(container)
+        entries = self._extract_entries(webpage)
-from .fourtube import FourTubeIE
+from .fourtube import (
-    _VALID_URL = r'https?://(?:www\.)?4tube\.com/videos/(?P<id>\d+)'
+class FourTubeBaseIE(InfoExtractor):
-    }
+        if kind == 'm' or not display_id:
-            r'<a class="item-to-subscribe" href="[^"]+/channels/([^/"]+)" title="Go to [^"]+ page">',
+            r'<a class="item-to-subscribe" href="[^"]+/(?:channel|user)s?/([^/"]+)" title="Go to [^"]+ page">',
-            r'<a class="item-to-subscribe" href="[^"]+/channels/[^/"]+" title="Go to ([^"]+) page">',
+            r'<a class="item-to-subscribe" href="[^"]+/(?:channel|user)s?/[^/"]+" title="Go to ([^"]+) page">',
-            webpage, 'view count', fatal=False))
+            webpage, 'view count', default=None))
-            webpage, 'like count', fatal=False))
+            webpage, 'like count', default=None))
-        tokens = self._download_json(token_req, video_id)
+
-                    {'source_url': source_url}),
+                smuggle('limelight:%s:%s' % (lm[kind], video_id)),
-                    {'source_url': source_url}),
+                smuggle('limelight:%s:%s' % (kind, video_id)),
-        def _media_formats(src, type_info, cur_media_type):
+        def _media_formats(src, cur_media_type, type_info={}):
-                    is_plain_url, formats = _media_formats(src, f, media_type)
+                    is_plain_url, formats = _media_formats(src, media_type, f)
-    HEADRequest,
+    int_or_none,
-    _VALID_URL = r'^https?://(?:www\.)?aparat\.com/(?:v/|video/video/embed/videohash/)(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?aparat\.com/(?:v/|video/video/embed/videohash/)(?P<id>[a-zA-Z0-9]+)'
-            raise ExtractorError('No working video URLs found')
+        webpage = self._download_webpage(
-            'ext': 'mp4',
+            'formats': formats,
-            if format.get('format_id') is None:
+            if not format.get('format_id'):
-        family_friendly = self._html_search_meta('isFamilyFriendly', html)
+        family_friendly = self._html_search_meta(
-        def _media_formats(src, cur_media_type):
+        def _media_formats(src, type_info, cur_media_type):
-            ext = determine_ext(full_url)
+            ext = type_info.get('ext') or determine_ext(full_url)
-                    is_plain_url, formats = _media_formats(src, media_type)
+                    f = parse_content_type(source_attributes.get('type'))
-            '(function() { return new Date().toLocaleDateString(); })()'
+            'window.addEventListener = window.addEventListener || function() {};',
-            'md5': 'cddc9fb8a8644a0a7742149eee95080b',
+            'url': 'http://help.vzaar.com/article/165-embedding-video',
-                'id': '11002506',
+                'id': '8707641',
-                'title': 'XR-U SHOW: Ready Player Fuck - EP. 61',
+                'title': 'Building A Business Online: Principal Chairs Q & A',
-
+        # Look for vzaar embeds
-__version__ = '2017.08.06'
+__version__ = '2017.08.09'
-             r'<title>(.*?)\s*-\s*XXXYMovies\.com</title>'],
+            [r'<div[^>]+\bclass="block_header"[^>]*>\s*<h1>([^<]+)<',
-    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.de|nickelodeon\.(?:nl|at))/(?:playlist|shows)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.(?:de|com\.pl)|nickelodeon\.(?:nl|at))/[^/]+/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-
+    def _decrypt_play_info(self, play_info, video_id):
-            for idx, ch in enumerate(play_info)])
+        for num, key in enumerate(KEYS, start=1):
-            self._decrypt_play_info(encrypted_play_info), track_id)
+
-            r'<iframe[^>]+src=(["\'])(?P<url>(?:https?://)?(?:www\.)?20min\.ch/videoplayer/videoplayer.html\?.*?\bvideoId@\d+.*?)\1',
+            r'<iframe[^>]+src=(["\'])(?P<url>(?:(?:https?:)?//)?(?:www\.)?20min\.ch/videoplayer/videoplayer.html\?.*?\bvideoId@\d+.*?)\1',
-    compat_urlparse,
+    compat_str,
-    unified_strdate,
+    try_get,
-            raise
+        video_id = None
-            'id': info_url.rpartition('/')[-1],
+            'id': compat_str(video_id or display_id),
-        # video not available via `getflv`
+        # video not available via `getflv`; "old" HTML5 video
-            'ext': 'flv',
+            'ext': 'mp4',
-        else:
+        def _format_id_from_url(video_url):
-
+            video_real_url = flv_info['url'][0]
-            'format_id': 'economy' if video_real_url.endswith('low') else 'normal',
+            'formats': formats,
-        video_real_url = flv_info['url'][0]
+        api_data = self._parse_json(self._html_search_regex(
-        title = xpath_text(video_info, './/title')
+        title = get_video_info('title')
-        extension = xpath_text(video_info, './/movie_type')
+        extension = get_video_info(['movie_type', 'movieType'])
-            xpath_text(video_info, './/thumbnail_url') or
+            get_video_info(['thumbnail_url', 'thumbnailURL']) or
-        description = xpath_text(video_info, './/description')
+        description = get_video_info('description')
-        timestamp = parse_iso8601(xpath_text(video_info, './/first_retrieve'))
+        timestamp = (parse_iso8601(get_video_info('first_retrieve')) or
-        view_count = int_or_none(xpath_text(video_info, './/view_counter'))
+        view_count = int_or_none(get_video_info(['view_counter', 'viewCount']))
-        comment_count = int_or_none(xpath_text(video_info, './/comment_num'))
+        comment_count = (int_or_none(get_video_info('comment_num')) or
-            xpath_text(video_info, './/length') or
+            get_video_info('length') or
-            video_detail.get('length'))
+            video_detail.get('length') or
-        webpage_url = xpath_text(video_info, './/watch_url') or url
+        webpage_url = get_video_info('watch_url') or url
-            uploader_id = uploader = None
+        owner = api_data.get('owner', {})
-__version__ = '2017.07.30.1'
+__version__ = '2017.08.06'
-        }
+from .voot import VootIE
-from .voot import VootIE
+from .kaltura import KalturaIE
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?voot\.com/(?:[^/]+/)+(?P<id>\d+)'
-            'id': '441353',
+            'id': '0_8ledb18o',
-        return json_data['assets']
+            'description': 'md5:06291fbbbc4dcbe21235c40c262507c1',
-        formats = []
+        media_info = self._download_json(
-            formats.extend(self._extract_m3u8_formats(format_url, video_id, 'mp4', m3u8_id='hls', fatal=False))
+        entry_id = media['EntryId']
-                break
+        description, series, season_number, episode, episode_number = [None] * 5
-        self._sort_formats(formats)
+        for meta in try_get(media, lambda x: x['Metas'], list) or []:
-            'formats':formats,
+            '_type': 'url_transparent',
-                    'maxNumOfRows': 1000,
+                    # Large values of maxNumOfRows (~300 or above) may cause
-    _VALID_URL = r'^(?P<proto>https?)://(?P<channel>[^.]+)\.podomatic\.com/entry/(?P<id>[^?]+)'
+    _VALID_URL = r'''(?x)
-    ]
+    _TESTS = [{
-        channel = mobj.group('channel')
+        channel = mobj.group('channel') or mobj.group('channel_2')
-    _TEST = {
+    _VALID_URL = r'https?://player\.cinchcast\.com/.*?(?:assetId|show_id)=(?P<id>[0-9]+)'
-    }
+    }]
-        segments = info_dict['fragments'][:1] if self.params.get(
+        fragment_base_url = info_dict.get('fragment_base_url')
-            'total_frags': len(segments),
+            'total_frags': len(fragments),
-        for i, segment in enumerate(segments):
+        for i, fragment in enumerate(fragments):
-                    success, frag_content = self._download_fragment(ctx, segment['url'], info_dict)
+                    fragment_url = fragment.get('url')
-                                    'url': media_template % {
+                                    media_location_key: media_template % {
-                                        'url': segment_url,
+                                        media_location_key: segment_url,
-                                        'url': representation_ms_info['segment_urls'][segment_index],
+                                        location_key(segment_uri): segment_uri,
-                                f['fragments'].append({'url': initialization_url})
+                                f['fragments'].append({location_key(initialization_url): initialization_url})
-    _VALID_URL = r'https?://yadi\.sk/i/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://yadi\.sk/[di]/(?P<id>[^/?#&]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'md5': 'b190e70141fb9a1552a85426b4da1b5d',
+            'md5': 'aafaf5b0186fee8f32f20508092f8111',
-from ..compat import compat_HTTPError
+from ..compat import (
-        } for f in video.get('formats', []) if f.get('uri')]
+        formats = []
-            r"(?s)'sources'\s*:\s*(\{.+?\})\s*\}[;,)]",
+            r"(?s)sources'?\s*:\s*(\{.+?\})\s*\}[;,)]",
-                        })
+                extract_subtitles(data.get('tracks'))
-                                (?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|
+                                (?:.*?/)?video/(?:topic/[\da-z_-]+/)?(?:v|.*?/c-)|
-           (?:www\.)?pbs\.org/(?:[^/]+/){2,5}(?P<presumptive_id>[^/]+?)(?:\.html)?/?(?:$|[?\#]) |
+           (?:www\.)?pbs\.org/(?:[^/]+/){1,5}(?P<presumptive_id>[^/]+?)(?:\.html)?/?(?:$|[?\#]) |
-            version = get_exe_version(self.exe, version_re=r'([0-9.]+)')
+            version = self._version()
-    _API_HOST = 'psapi-we.nrk.no'
+    _API_HOST = 'psapi-ne.nrk.no'
-__version__ = '2017.07.23'
+__version__ = '2017.07.30.1'
-from .clipfish import ClipfishIE
+import re
-    _VALID_URL = r'https?://(?:\w+\.)?youjizz\.com/videos/(?:[^/#?]+)?-(?P<id>[0-9]+)\.html(?:$|[?#])'
+    _VALID_URL = r'https?://(?:\w+\.)?youjizz\.com/videos/(?:[^/#?]*-(?P<id>\d+)\.html|embed/(?P<embed_id>\d+))'
-        'md5': '78fc1901148284c69af12640e01c6310',
+        'md5': 'b1e1dfaa8bb9537d8b84eeda9cf4acf4',
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]
+        title = self._html_search_regex(
-            'age_limit': age_limit,
+            'title': title,
-            video_id = numid.group(1)
+            document_id = video_id = numid.group(1)
-                'http://www.ardmediathek.de/play/media/%s' % video_id, webpage, video_id)
+                'http://www.ardmediathek.de/play/media/%s' % video_id,
-            'title': title,
+            'title': self._live_title(title) if info.get('is_live') else title,
-    _CLIENT_ID = '2t9loNQH90kzJcsFCODdigxfp325aq4z'
+    _CLIENT_ID = 'JlZIsxg2hY5WnBgtn3jfS0UYCl0K8DOg'
-    SoundcloudSearchIE
+    SoundcloudSearchIE,
-class SoundcloudUserIE(SoundcloudPlaylistBaseIE):
+class SoundcloudPagedPlaylistBaseIE(SoundcloudPlaylistBaseIE):
-        'spotlight': '%s/users/%%s/spotlight' % _API_V2_BASE,
+        'all': '%s/profile/soundcloud:users:%%s' % SoundcloudPagedPlaylistBaseIE._API_V2_BASE,
-        }
+        return self._extract_playlist(
-                            return permalink_url, entry_id
+class SoundcloudTrackStationIE(SoundcloudPagedPlaylistBaseIE):
-                    entries.append(self.url_result(permalink_url, video_id=entry_id))
+    def _real_extract(self, url):
-                break
+        webpage = self._download_webpage(url, track_name)
-                parsed_next_href._replace(query=compat_urllib_parse_urlencode(qs, True)))
+        track_id = self._search_regex(
-        }
+        return self._extract_playlist(
-                'https://api.svt.se/videoplayer-api/video/%s' % video_id, video_id)
+                'https://api.svt.se/videoplayer-api/video/%s' % video_id,
-                'http://www.svt.se/videoplayer-api/video/%s' % video_id, video_id)
+                'https://api.svt.se/videoplayer-api/video/%s' % video_id, video_id)
-
+from .yandexdisk import YandexDiskIE
-        s = manifest.decode('utf-8', 'ignore')
+        urlh = self.ydl.urlopen(self._prepare_url(info_dict, man_url))
-    parse_age_limit,
+    parse_age_limit,
-        rating = theplatform_metadata['ratings'][0]['rating']
+        rating = try_get(
-            'http://www.cloudy.ec/embed.php?id=%s' % video_id, video_id)
+            'https://www.cloudy.ec/embed.php', video_id, query={
-            return thumb_node.attrib['url']
+        return thumb_node.get('url') or thumb_node.text or None
-    def test_hide_login_inf(self):
+    def test_hide_login_info(self):
-__version__ = '2017.07.15'
+__version__ = '2017.07.23'
-        _add_sub_element(request, 'itv:ProductionId').text = params['data-video-id']
+        _add_sub_element(request, 'itv:ProductionId').text = production_id
-            r'data-video-duration=(["\'])(?P<duartion>\d+)\1', webpage, 'duration'))
+            r'data-video-duration=(["\'])(?P<duration>\d+)\1', webpage,
-                    m3u8_id='hls'))
+                    m3u8_id='hls', fatal=False))
-        self._sort_formats(formats)
+        if formats:
-                                          'Downloading video urls')
+        mediagen_doc = self._download_xml(
-            playlist_title=title, playlist_description=description)
+            entries, playlist_title=title, playlist_description=description)
-        )
+
-            req_format = '/'.join(req_format_list)
+            req_format = self._default_format_spec(info_dict, download=download)
-from ..utils import js_to_json
+from ..utils import (
-            'title': 'Ð ÐÐ¾Ð²Ð¾ÑÐ¾ÑÑÐ¸Ð¹ÑÐºÐµ Ð¿ÑÐ¾ÑÐµÐ» Ð´ÐµÑÑÐºÐ¸Ð¹ ÑÑÑÐ½Ð¸Ñ Â«ÐÐ¾Ð»Ðµ ÑÐ»Ð°Ð²Ñ Ð±Ð¾ÐµÐ²Ð¾Ð¹Â»',
+            'title': '211355',
-            })
+        wjplayer_data = self._parse_json(
-        thumbnail = jwplayer_data.get('image_url')
+        view_count = int_or_none(self._search_regex(
-            'thumbnail': thumbnail,
+            'title': video_id,
-    IE_DESC = 'npo.nl and ntr.nl'
+    IE_DESC = 'npo.nl, ntr.nl, omroepwnl.nl, zapp.nl and npo3.nl'
-                                zapp\.nl/[^/]+/[^/]+/
+                                (?:zapp|npo3)\.nl/(?:[^/]+/){2}
-            'ext': 'mp4',
+            'ext': 'flv',
-            'duration': 343,
+            'duration': 344,
-            'ext': 'mp4',
+            'ext': 'flv',
-            'duration': 5602,
+            'duration': 5359,
-            'title': 'Cooking with Shin 4512.1',
+            'title': 'Cooking with Shin',
-            'title': 'Mnet Asian Music Awards 2015 4826.4',
+            'title': 'Mnet Asian Music Awards 2015',
-                    'title': 'foo1 title'
+                    'title': 'foo1 title',
-            for f in ('_type', 'url', 'ie_key'):
+            for f in ('_type', 'url', 'id', 'extractor', 'extractor_key', 'ie_key'):
-from .egghead import EggheadCourseIE
+from .egghead import (
-from ..utils import ExtractorError
+from ..utils import (
-        post = json.loads(post_json)
+        timestamp = unified_timestamp(self._html_search_meta(
-            'thumbnail': post.get('picture'),
+            'title': title,
-    urljoin,
+    }, {
-    def _extract_entries(self, playlist_data_url, show_id, idx, query, url):
+    def _extract_entries(self, playlist_data_url, show_id, note, query):
-            note='Downloading playlist data page %d' % (idx + 1),
+            playlist_data_url, show_id, query=query, note=note,
-            self.url_result(urljoin(url, video_url), YoukuIE.ie_key())
+            self.url_result(self._proto_relative_url(video_url, 'http:'), YoukuIE.ie_key())
-            'http://list.youku.com/show/module', show_id, 0, {
+        first_page, initial_entries = self._extract_entries(
-            }, url)
+            })
-        reload_ids = re.findall('<li[^>]+data-id="([^"]+)">', first_page)[1:]
+        reload_ids = re.findall('<li[^>]+data-id="([^"]+)">', first_page)
-                'http://list.youku.com/show/episode', show_id, idx + 1, {
+                'http://list.youku.com/show/episode', show_id,
-                }, url)
+                })
-    _TEST = {
+    _TESTS = [{
-            'title': 'è±åéª¨ æªå åç',
+            'title': 'è±åéª¨ DVDç',
-    }
+    }, {
-    _PAGE_SIZE = 40
+    def _extract_entries(self, playlist_data_url, show_id, idx, query, url):
-                query = {
+        first_page, entries = self._extract_entries(
-                for video_url in video_urls]
+                    'stage': reload_id,
-                break
+    # https://github.com/rg3/youtube-dl/issues/13658
-        }
+        },
-        }
+        },
-    _VALID_URL = r'https?://(?:evt\.dispeak|events\.digitallyspeaking)\.com/(?:[^/]+/)+xml/(?P<id>[^.]+)\.xml'
+    _VALID_URL = r'https?://(?:s?evt\.dispeak|events\.digitallyspeaking)\.com/(?:[^/]+/)+xml/(?P<id>[^.]+)\.xml'
-        },
+    }, {
-        error = options.get('error')
+        if not error:
-            r'id=["\']showmedia_about_episode_num[^>]+>\s*<a[^>]+>([^<]+)',
+            r'(?s)<h\d[^>]+\bid=["\']showmedia_about_episode_num[^>]+>(.+?)</h\d',
-            r'(?s)<h4[^>]+id=["\']showmedia_about_episode_num[^>]+>.+?</h4>\s*<h4>\s*Season (\d+)',
+            r'(?s)<h\d[^>]+id=["\']showmedia_about_episode_num[^>]+>.+?</h\d>\s*<h4>\s*Season (\d+)',
-                r'<iframe[^>]+\bsrc=(["\'])(?P<url>(?:https?:)?//embed\.nexx(?:\.cloud|cdn\.com)/\d+/(?:(?!\1).)+)\1',
+            r'<iframe[^>]+\bsrc=(["\'])(?P<url>(?:https?:)?//embed\.nexx(?:\.cloud|cdn\.com)/\d+/(?:(?!\1).)+)\1',
-        return self.playlist_result(entries)
+            for embed_path in embeds]
-        urlrs = orderedSet(
+    def playlist_from_matches(self, matches, playlist_id=None, playlist_title=None, getter=None, ie=None):
-            urlrs, playlist_id=video_id, playlist_title=video_title)
+            urls, playlist_id=playlist_id, playlist_title=playlist_title)
-from .nexx import NexxIE
+from .nexx import (
-from .nexx import NexxIE
+from .nexx import (
-            entries.append('https://api.nexx.cloud/v3/%s/videos/byid/%s' % (domain_id, video_id))
+        mobj = re.search(
-from .pear import PearIE
+from .pearvideo import PearVideoIE
-        }
+# coding: utf-8
-__version__ = '2017.07.09'
+__version__ = '2017.07.15'
-import string
+from string import ascii_letters
-            sep = ''.join([random.choice(string.ascii_letters) for _ in range(32)])
+            sep = ''.join([random.choice(ascii_letters) for _ in range(32)])
-                            >\s*Listen ad-free with YouTube Red # YouTube Red ad 
+                            >\s*Listen ad-free with YouTube Red # YouTube Red ad
-)
+from .nexx import NexxIE
-        'url': 'http://www.spiegel.tv/#/filme/alleskino-die-wahrheit-ueber-maenner/',
+    _VALID_URL = r'https?://(?:www\.)?spiegel\.tv/videos/(?P<id>\d+)'
-    }]
+    }
-        }
+        return self.url_result(
-        smhd_payload = u16.pack(0)  # reserved
+        smhd_payload += u16.pack(0)  # reserved
-                clip.get(field)
+                return clip.get(field)
-                rutube_urls, ie=RutubeIE.ie_key())
+                rutube_urls, video_id, video_title, ie=RutubeIE.ie_key())
-                 self._search_regex(r'<h1 class="title">([^<]+)</h1>'))
+                 self._search_regex(r'<h1 class="title">([^<]+)</h1>', webpage, 'video title'))
-            r'<h4[^>]+class="title"[^>]*>\s*Music\s*</h4>\s*<ul[^>]*>\s*<li>(?P<title>.+?) by (?P<creator>.+?)(?:\(.+?\))?</li',
+            r'''(?x)
-            r'\$\.extend\(slideshare_object,\s*(\{.*?\})\);',
+            r'\$\.extend\(.*?slideshare_object,\s*(\{.*?\})\);',
-            'title': 'ÐÑÐ¾Ð³Ð¸ Ð½ÐµÐ´ÐµÐ»Ð¸ Ñ 8 Ð¿Ð¾ 14 Ð¸ÑÐ½Ñ 2015 Ð³Ð¾Ð´Ð°',
+            'title': r're:^ÐÑÐ¾Ð³Ð¸ Ð½ÐµÐ´ÐµÐ»Ð¸ ÑÂ \d+ Ð¿Ð¾Â \d+Â \w+Â \d{4}Â Ð³Ð¾Ð´Ð°$',
-            r'<a[^>]+?href="([^"]+)"[^>]+?class="videoplayer"',
+            [r'<div[^>]+?class="flowplayer[^>]+?data-href="([^"]+)"',
-            filename = expand_path(outtmpl % template_dict)
+            # expand_path translates '%%' into '%' and '$$' into '$'
-                            video_id, preference, f4m_id=format_id)
+                            video_id, preference, f4m_id=format_id, fatal=False)
-                            preference=preference, m3u8_id=format_id))
+                            preference=preference, m3u8_id=format_id,
-            return {}
+        sub_lang_list = {}
-            }
+            },
-            'md5': 'ab2745d0b0ce53319a534fccaa986439',
+            'md5': '6dabeaca9e68cbb71c99c322a4b42a11',
-            'md5': '3846d0a07109b5ab622425449b59049d',
+            'md5': '884812a2adc8aaf6fe52b15ccbfa3b88',
-                'thumbnail': r're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*',
-            'description': 'JG on Twitter: "BEAT PROD: @suhmeduh  https://t.co/HBrQ4AfpvZ #Damndaniel https://t.co/byBooq2ejZ"',
+            'title': 'Donte - BEAT PROD: @suhmeduh #Damndaniel',
-            'uploader': 'JG',
+            'uploader': 'Donte',
-            'uploader_id': '1004126642786242560',
+            'title': 'FilmDrunk - Vine of the day',
-            'alt_title': 'Vine by %s' % username if username else None,
+            'title': data.get('description') or alt_title or 'Vine video',
-    def _get_vmap_video_url(self, vmap_url, video_id):
+    def _extract_formats_from_vmap_url(self, vmap_url, video_id):
-        return xpath_text(vmap_data, './/MediaFile').strip()
+        video_url = xpath_text(vmap_data, './/MediaFile').strip()
-            })
+            formats.extend(
-        video_url = self._get_vmap_video_url(vmap_url, video_id)
+        formats = self._extract_formats_from_vmap_url(vmap_url, video_id)
-            'url': video_url,
+        formats[0].update({
-        }]
+        })
-            r'<iframe[^>]+src=([\'"])(?P<url>(?:https?:)?//(?:www\.)?periscope\.tv/(?:(?!\1).)+)\1', webpage)
+            r'<iframe[^>]+src=([\'"])(?P<url>(?:https?:)?//(?:www\.)?(?:periscope|pscp)\.tv/(?:(?!\1).)+)\1', webpage)
-            'title': 'Sgt Kerry Schmidt - Ontario Provincial Police - Road rage, mischief, assault, rollover and fire in one occurrence',
+            'title': 'Sgt Kerry Schmidt - LIVE on #Periscope: Road rage, mischief, assault, rollover and fire in one occurrence',
-            'uploader': 'Sgt Kerry Schmidt - Ontario Provincial Police',
+            'uploader': 'Sgt Kerry Schmidt',
-    ExtractorError,
+    remove_end,
-                _search_dimensions_in_video_url(f, video_url)
+                self._search_dimensions_in_video_url(f, video_url)
-
+            formats.extend(self._parse_media_info(media_info, video_id))
-import re
+    compat_parse_qs,
-    determine_ext,
+    xpath_text,
-            'mail': username,
+            'mail_tel': username,
-        if re.search(r'(?i)<h1 class="mb8p4">Log in error</h1>', login_results) is not None:
+        urlh = self._request_webpage(
-        return True
+        return login_ok
-    qualities,
+    determine_ext,
-        'md5': '57badeface303ecf6b98b812de1b9018',
+        'md5': 'c8ea694254a59246a42831155dec57ac',
-            if video_url.endswith('.f4m'):
+            ext = determine_ext(video_url)
-        video_id = compat_str(video_id_match.group('video_id'))
+        mobj = re.match(self._VALID_URL, url)
-            'Downloading playlist %s - add --no-playlist to just download video' % playlist_id)
+            'Downloading playlist %s - add --no-playlist to just download video'
-            'http://www.vlive.tv/video/%s/playlist/%s' % (video_id, playlist_id), video_id)
+            'http://www.vlive.tv/video/%s/playlist/%s'
-            webpage, 'playlist name', fatal=False)
+        item_ids = self._parse_json(
-            webpage, 'playlist item ids')
+        entries = [
-                    ie=VLiveIE.ie_key(), video_id=item_id))
+        playlist_name = self._html_search_regex(
-            entries, playlist_id, playlist_name)
+        return self.playlist_result(entries, playlist_id, playlist_name)
-    VLiveChannelIE
+    VLiveChannelIE,
-        'url': 'tvrainru.media.eagleplatform.com:582306',
+        'url': 'eagleplatform:tvrainru.media.eagleplatform.com:582306',
-__version__ = '2017.07.02'
+__version__ = '2017.07.09'
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?dailymail\.co\.uk/(?:video/[^/]+/video-|embed/video/)(?P<id>[0-9]+)'
-    }
+    }, {
-from .common import InfoExtractor
+from .common import InfoExtractor
-    _VALID_URL = r'https?://[a-z0-9]+\.joj\.sk/([^/]+/)*(?P<title_query>(?P<release_date>[0-9]{4}(-[0-9]{2}){2}).*)' # noqa
+    _VALID_URL = r'''(?x)
-        'url': 'https://www.joj.sk/nove-byvanie/archiv/2017-05-28-nove-byvanie', # noqa
+        'url': 'https://media.joj.sk/embed/a388ec4c-6019-4a4a-9312-b1bee194e932',
-            'release_date': '20170528'
+            'title': 'NOVÃ BÃVANIE',
-        }
+        'url': 'joj:a388ec4c-6019-4a4a-9312-b1bee194e932',
-    xml_source_url = 'https://media.joj.sk/services/Video.php?clip='
+    @staticmethod
-        xml_playlist_et = self._download_xml(xml_playlist_url, 'XML playlist')
+        video_id = self._match_id(url)
-                                'dat/', '', 1)})
+        for format_url in try_get(bitrates, lambda x: x['mp4'], list) or []:
-            'title': self._og_search_title(webpage).title(),
+            'title': title,
-            'release_date': release_date
+from .joj import JojIE
-        formats = self._extract_akamai_formats(stream['hds-unmetered'], video_id)
+        format_urls = [
-    _VALID_URL = r'https://egghead\.io/courses/(?P<id>[a-zA-Z_0-9-]+)'
+    _VALID_URL = r'https://egghead\.io/courses/(?P<id>[^/?#&]+)'
-        entries = [{'_type': 'url', 'ie_key': 'Wistia', 'url': 'wistia:' + l.get('wistia_id')} for l in lessons]
+        course = self._download_json(
-        }
+        entries = [
-        ul = self._search_regex(r'(?s)<ul class="series-lessons-list">(.*?)</ul>', webpage, 'session list')
+        api_url = 'https://egghead.io/api/v1/series/' + playlist_id
-        entries = [self.url_result(m) for m in found]
+        lessons = course.get('lessons')
-            'description': self._og_search_description(webpage),
+            'description': description,
-                        self.report_warning('%s: malformated aac bitstream.' % (
+                        self.report_warning('%s: malformed AAC bitstream detected.' % (
-                                '%s: malformated aac bitstream. %s'
+                                '%s: malformed AAC bitstream detected. %s'
-            self._downloader.to_screen('[ffmpeg] Fixing malformated aac bitstream in "%s"' % filename)
+            self._downloader.to_screen('[ffmpeg] Fixing malformed AAC bitstream in "%s"' % filename)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r'<p>(?P<description>.+?)</p>', webpage, 'description', fatal=False)
+            r'<p>(?P<description>.+?)</p>', webpage, 'description',
-# coding: utf-8
+import re
-    IE_NAME = 'cjsw'
+    _VALID_URL = r'https?://(?:www\.)?cjsw\.com/program/(?P<program>[^/]+)/episode/(?P<id>\d+)'
-            'id': '20170620',
+            'id': '91d9f016-a2e7-46c5-8dcb-7cbcd7437c41',
-        }
+            'title': 'Freshly Squeezed â Episode June 20, 2017',
-        episode_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            r'<p>(?P<description>.+?)</p>', webpage, 'description', fatal=False)
+        title = unescapeHTML(self._search_regex(
-            'ext': 'mp3',
+            'url': audio_url,
-            'id': episode_id,
+            'id': audio_id,
-                      in re.findall(r'(?s)(<(video|audio)[^>]*/>)', webpage)]
+                      in re.findall(r'(?s)(<(?:amp-)?(video|audio)[^>]*/>)', webpage)]
-            r'(?s)(<(?P<tag>video|audio)(?:\s+[^>]*)?>)(.*?)</(?P=tag)>', webpage))
+            r'(?s)(<(?P<tag>(?:amp-)?(?:video|audio))(?:\s+[^>]*)?>)(.*?)</(?P=tag)>', webpage))
-    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata', *args, **kwargs):
+    def _download_json(self, url_or_request, video_id, *args, **kwargs):
-            response = super(EaglePlatformIE, self)._download_json(url_or_request, video_id, note)
+            response = super(EaglePlatformIE, self)._download_json(
-            'http://%s/api/player_data?id=%s' % (host, video_id), video_id)
+            'http://%s/api/player_data' % host, video_id,
-        # Eagle.Platform embed (generic URL)
+        # EaglePlatform embed (generic URL)
-        # ClipYou (Eagle.Platform) embed (custom URL)
+        # ClipYou (EaglePlatform) embed (custom URL)
-        # Look for Eagle.Platform embeds
+        # Look for EaglePlatform embeds
-            return self.url_result(eagleplatform_url, EaglePlatformIE.ie_key())
+            return self.url_result(smuggle_url(eagleplatform_url, {'referrer': url}), EaglePlatformIE.ie_key())
-        # Look for ClipYou (uses Eagle.Platform) embeds
+        # Look for ClipYou (uses EaglePlatform) embeds
-        # Basic usage embedding (see http://dultonmedia.github.io/eplayer/)
+        PLAYER_JS_RE = r'''
-                    .+?
+                    %s
-                        class=(?P<q2>["\'])eagleplayer(?P=q2)[^>]+
+                        class=(?P<qclass>["\'])eagleplayer(?P=qclass)[^>]+
-            ''', webpage)
+            ''' % PLAYER_JS_RE, webpage)
-    _VALID_URL = r'https?://(?:www\.)?veoh\.com/(?:watch|iphone/#_Watch)/(?P<id>(?:v|yapi-)[\da-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?veoh\.com/(?:watch|iphone/#_Watch)/(?P<id>(?:v|e|yapi-)[\da-zA-Z]+)'
-            },
+    _TESTS = [{
-            'skip': 'This video has been deleted.',
+    }, {
-            'skip': 'This video has been deleted.',
+        'skip': 'This video has been deleted.',
-    ]
+        'skip': 'This video has been deleted.',
-            r'data-prid="([^"]+)"', webpage, 'live id')
+            [r'media-id="([^"]+)"', r'data-prid="([^"]+)"'], webpage, 'live id')
-                    'height': resolution[0],
+                    'height': resolution[1],
-            webpage, 'view count', fatal=False)
+            webpage, 'view count', default=None)
-             r'var\s+config\s*=\s*({.+?});'],
+             r'var\s+config\s*=\s*({.+?});',
-        }
+from ..compat import compat_str
-
+        formats = []
-            r'Runtime:\s*</span>\s*([\d:]+)', webpage,
+            [r'<[^<]+\bitemprop=["\']duration["\'][^<]+\bcontent=["\'](.+?)["\']',
-
+            'display_id': display_id,
-    _VALID_URL = r'(?P<proto>https?)://(?:.+?\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.*?)\.html(?:\?.*)?'
+    _VALID_URL = r'''(?x)
-        webpage = self._download_webpage(mrss_url, video_id)
+        video_id = mobj.group('id') or mobj.group('id_2')
-    _VALID_URL = r'https?://(?:espn\.go|(?:www\.)?espn)\.com/video/clip(?:\?.*?\bid=|/_/id/)(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-        'url': 'http://espn.go.com/video/clip?id=2743663',
+        'url': 'https://broadband.espn.go.com/video/clip?id=18910086',
-            'id': '2743663',
+            'id': '18910086',
-            'upload_date': '20151207',
+            'title': 'Kyrie spins around defender for two',
-        self.assertEqual(shell_quote(args), """ffmpeg -i 'Ã±â¬Ã'"'"'.mp4'""")
+        self.assertEqual(
-            'foo ba/r -baz \'2 be\' \'\''
+            'foo ba/r -baz \'2 be\' \'\'' if compat_os_name != 'nt' else 'foo ba/r -baz "2 be" ""'
-                if f.get('status') != 2:
+                if caption.get('status') != 2:
-    _VALID_URL = r'https?://(?:www\.)?(?P<site>vier|vijf)\.be/(?:[^/]+/videos/(?P<display_id>[^/]+)(?:/(?P<id>\d+))?|video/v3/embed/(?P<embed_id>\d+))'
+    _VALID_URL = r'''(?x)
-        playlist_url = 'http://vod.streamcloud.be/%s/_definst_/mp4:%s.mp4/playlist.m3u8' % (application, filename)
+
-from ..compat import compat_urllib_parse_unquote
+    float_or_none,
-    parse_duration,
+    remove_end,
-            'uploader': 'yan12125',
+            'uploader': 'å±å§¥',
-            'id': 'cE1xbENoLTI3NDQ3MzM2LmZsdg==',
+            'id': '27447336',
-            'description': 'md5:f0abdcb69df300f522a5442ef3146f2a',
+            'description': 'md5:1223810fa123b179083a3aed53574706',
-
+        # /play/ URLs provide embedded video URL and more metadata
-        flv_config = self._extract_flv_config(encoded_media_id)
+        media_info = self._parse_json(self._search_regex(
-        }
+        video_id = media_info['MEDIA_ID']
-            video_url = flv_config.get(format_tag)
+        for key in ('html5Url', 'html5HQUrl'):
-                r'\bq=(.+?)\b', video_url, 'format id', default=format_tag)
+                r'\bq=(.+?)\b', video_url, 'format id', default=None)
-                'ext': FORMATS.get(flv_config['type'], 'mp4'),
+                'ext': 'mp4' if format_id.isnumeric() else format_id,
-        timestamp = flv_config.get('publish_datetime')
+        timestamp = media_info.get('PUBLISH_DATETIME')
-        category = flv_config.get('category')
+        category = media_info.get('catName')
-            'thumbnail': flv_config.get('thumb'),
+            'title': media_info['TITLE'],
-            'duration': parse_duration(flv_config.get('duration')),
+            'uploader': uploader,
-         (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?
+         (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'|))*?
-         (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?
+         (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'|))*?
-__version__ = '2017.06.25'
+__version__ = '2017.07.02'
-        video_id = list(drupal_settings['comScore'])[0]
+        video_id = self._search_regex(
-        'md5': '946f05bbaa12a33f9ae35580d2dfcfe3',
+        'md5': '568acf9ca25a639f0c4ff905826b662f',
-        video_id = drupal_settings['jwplatform']['video_id']
+        video_id = list(drupal_settings['comScore'])[0]
-                    r'file\s*:\s*(["\'])(?P<url>http(?:(?!\1).)+\.(?:m3u8|mp4|flv)(?:(?!\1).)*)\1',
+                    r'(?:file|src)\s*:\s*(["\'])(?P<url>http(?:(?!\1).)+\.(?:m3u8|mp4|flv)(?:(?!\1).)*)\1',
-from ..utils import int_or_none
+from ..utils import (
-                                       webpage, 'info json')
+        info_json = self._search_regex(
-        playlist_info = info['playlist']
+
-            for talk in info['talks']
+            for talk in try_get(
-        talk_info = self._extract_info(webpage)['talks'][0]
+        info = self._extract_info(webpage)
-        } for (format_id, format_url) in talk_info['nativeDownloads'].items() if format_url is not None]
+        } for (format_id, format_url) in native_downloads.items() if format_url is not None]
-        for format_id, resources in talk_info['resources'].items():
+        for format_id, resources in resources_.items():
-            'thumbnail': thumbnail,
+            'title': title,
-                if item_type == 'TVEpisode':
+                if item_type in ('TVEpisode', 'Episode'):
-                    if isinstance(part_of_season, dict) and part_of_season.get('@type') == 'TVSeason':
+                    if isinstance(part_of_season, dict) and part_of_season.get('@type') in ('TVSeason', 'Season', 'CreativeWorkSeason'):
-                    if isinstance(part_of_series, dict) and part_of_series.get('@type') == 'TVSeries':
+                    if isinstance(part_of_series, dict) and part_of_series.get('@type') in ('TVSeries', 'Series', 'CreativeWorkSeries'):
-                        extract_video_object(video)
+                    continue
-            r'url\s*:\s*["\']((?:https?:)?//[^/]+/playback/videoPlaybackInfo/\d+)',
+            r'url\s*[:=]\s*["\']((?:https?:)?//[^/]+/playback/videoPlaybackInfo/\d+)',
-            return info_dict
+            return merge_dicts(json_ld, info_dict)
-            return info
+            return merge_dicts(info, info_dict)
-                            music/clips[/#]|
+                            music/(?:clips|audiovideo/popular)[/#]|
-    ]
+        }, {
-            'url': 'http://www.cbsnews.com/news/tesla-and-spacex-elon-musks-industrial-empire/',
+            # 60 minutes
-                'duration': 791,
+                'id': '_B6Ga3VJrI4iQNKsir_cdFo9Re_YJHE_',
-                # rtmp download
+                # m3u8 download
-            'skip': 'Subscribers only',
+            # 48 hours
-            r'(?:<ul class="media-list items" id="media-related-items"><li data-video-info|<div id="cbsNewsVideoPlayer" data-video-player-options)=\'({.+?})\'',
+            r'(?:<ul class="media-list items" id="media-related-items"[^>]*><li data-video-info|<div id="cbsNewsVideoPlayer" data-video-player-options)=\'({.+?})\'',
-            entries.append(self.url_result(facebook_url))
+        facebook_urls = FacebookIE._extract_urls(webpage)
-
+    def _extract_urls(webpage):
-        mobj = re.search(r'''(?x)<div[^>]+
+        for mobj in re.finditer(r'''(?x)<div[^>]+
-            return mobj.group('url')
+                data-href=(?P<q2>[\'"])(?P<url>(?:https?:)?//(?:www\.)?facebook.com/.+?)(?P=q2)''', webpage):
-            return self.url_result(facebook_url, 'Facebook')
+        facebook_urls = FacebookIE._extract_urls(webpage)
-        'playlist_mincount': 6,
+        'playlist_mincount': 5,
-            'title': 'GRYNPYRET (Spotlight)',
+            'title': 'Grynpyret (Spotlight)',
-        return 'http://api.soundcloud.com/resolve.json?url=' + url + '&client_id=' + cls._CLIENT_ID
+        return 'https://api.soundcloud.com/resolve.json?url=' + url + '&client_id=' + cls._CLIENT_ID
-            'http://api.soundcloud.com/i1/tracks/%s/streams' % track_id,
+            'https://api.soundcloud.com/i1/tracks/%s/streams' % track_id,
-            info_json_url = 'http://api.soundcloud.com/tracks/' + track_id + '.json?client_id=' + self._CLIENT_ID
+            info_json_url = 'https://api.soundcloud.com/tracks/' + track_id + '.json?client_id=' + self._CLIENT_ID
-            url = 'http://soundcloud.com/%s' % resolve_title
+            url = 'https://soundcloud.com/%s' % resolve_title
-        url = 'http://soundcloud.com/%s/sets/%s' % (uploader, slug_title)
+        url = 'https://soundcloud.com/%s/sets/%s' % (uploader, slug_title)
-        url = 'http://soundcloud.com/%s/' % uploader
+        url = 'https://soundcloud.com/%s/' % uploader
-        'url': 'http://api.soundcloud.com/playlists/4110309',
+        'url': 'https://api.soundcloud.com/playlists/4110309',
-            'http://www.panda.tv/api_room?roomid=%s' % video_id, video_id)
+            'https://www.panda.tv/api_room?roomid=%s' % video_id, video_id)
-                    'url': 'http://pl%s%s.live.panda.tv/live_panda/%s%s%s.%s'
+                    'url': 'https://pl%s%s.live.panda.tv/live_panda/%s%s%s.%s'
-        'url': 'http://www.panda.tv/10091',
+    _VALID_URL = r'https?://(?:www\.)?panda\.tv/(?P<id>[0-9]+)'
-            'id': '10091',
+            'id': '66666',
-            'uploader': 'åå¾',
+            'uploader': 'åæé¸¡',
-    }
+    }, {
-    _VALID_URL = r'https?://(?:www\.|secure\.)?nicovideo\.jp/watch/(?P<id>(?:[a-z]{2})?[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.|secure\.|sp\.)?nicovideo\.jp/watch/(?P<id>(?:[a-z]{2})?[0-9]+)'
-__version__ = '2017.06.23'
+__version__ = '2017.06.25'
-                                provider_redirect_page, 'meta refresh redirect')
+                            oauth_redirect_url = extract_redirect_url(
-                                'Downloading Provider Login Page')
+                                self._DOWNLOADING_LOGIN_PAGE)
-                                'Downloading Provider Login Page')
+                                self._DOWNLOADING_LOGIN_PAGE)
-                        provider_redirect_page_res, 'Downloading Provider Login Page')
+                        provider_redirect_page_res, self._DOWNLOADING_LOGIN_PAGE)
-                            https?://(?:www\.)?wsj\.com/video/[^/]+/|
+                            https?://(?:www\.)?(?:wsj|barrons)\.com/video/[^/]+/|
-            'title': title,
+            'title': self._live_title(title) if relinker_info.get(
-            'creator': media.get('editor'),
+            'uploader': strip_or_none(media.get('channel')),
-    _VALID_URL = r'https?://(?:www\.)?raiplay\.it/dirette/(?P<id>\w*)'
+    _VALID_URL = r'https?://(?:www\.)?raiplay\.it/dirette/(?P<id>[^/?#&]+)'
-        'only_matching': True,
+        'url': 'http://www.raiplay.it/dirette/rainews24',
-        channel = self._match_id(url)
+        display_id = self._match_id(url)
-        video_id = self._html_search_regex(re_id, webpage, 'livestream-id', group='id')
+        video_id = self._search_regex(
-                               RaiPlayIE.ie_key(), video_id)
+        return {
-
+class RaiPlayLiveIE(RaiBaseIE):
-            video['url'], video_id, 'mp4', 'm3u8_native')
+            video['url'], video_id, 'mp4', entry_protocol='m3u8_native',
-    _VALID_URL = r'https?://(?:www\.)?redbull\.tv/(?:video|film)/(?P<id>AP-\w+)'
+    _VALID_URL = r'https?://(?:www\.)?redbull\.tv/(?:video|film|live)/(?:AP-\w+/segment/)?(?P<id>AP-\w+)'
-            r'data-params-mvp=["\'](\d+\.\d+)', webpage, 'mvp id')
+        mvp_id = self._search_mvp_id(webpage, default=None)
-
+        },
-    float_or_none,
+    determine_ext,
-                    stream['url']['data'].encode('ascii')).decode('utf-8')
+                url_data = try_get(stream, lambda x: x['url']['data'], compat_str)
-                delivery_type = stream['delivery_type']
+                delivery_type = stream.get('delivery_type')
-                        'ext': ext or stream.get('delivery_type'),
+                        'ext': ext or delivery_type,
-                if s_url in urls:
+                if not s_url or s_url in urls:
-                r'(?s)data-(?:deferred)?-module=["\']video["\'][^>]*>.*?<script[^>]+type=["\']text/x-config["\'][^>]*>(.+?)</script',
+                r'(?s)data-(?:deferred-)?module=["\']video["\'][^>]*>.*?<script[^>]+type=["\']text/x-config["\'][^>]*>(.+?)</script',
-__version__ = '2017.06.18'
+__version__ = '2017.06.23'
-            sub_lang_list = {}
+            sub_lang_list = []
-            return sub_lang_list
+                if sub_lang:
-        except (KeyError, ExtractorError):
+        except (KeyError, IndexError, ExtractorError):
-        'url': 'http://www.hgtv.com/shows/flip-or-flop/flip-or-flop-full-episodes-videos',
+    _TESTS = [{
-            'id': 'flip-or-flop-full-episodes-videos',
+            'id': 'flip-or-flop-full-episodes-season-4-videos',
-    }
+    }, {
-                r'(?s)data-module=["\']video["\'][^>]*>.*?<script[^>]+type=["\']text/x-config["\'][^>]*>(.+?)</script',
+                r'(?s)data-(?:deferred)?-module=["\']video["\'][^>]*>.*?<script[^>]+type=["\']text/x-config["\'][^>]*>(.+?)</script',
-            r'<source src="([^"]+)"', webpage, 'video URL')
+        video_data = self._download_json(
-            'url': video_url,
+            'formats': formats,
-            'upload_date': '20101221',
+            'upload_date': '20101217',
-            'upload_date': '20111125',
+            'upload_date': '20110418',
-            r'(?s)<div[^>]+class=["\']videoInfo(?:Date|Time)["\'][^>]*>(.+?)</div>',
+            [r'Date\s+[Aa]dded:\s*<span>([^<]+)',
-            [r'(?:video_titles|videoTitle|title)\s*[:=]\s*(["\'])(?P<title>(?:(?!\1).)+)\1',
+            [r'(?:video_titles|videoTitle)\s*[:=]\s*(["\'])(?P<title>(?:(?!\1).)+)\1',
-        # Fallback #1
+        # Fallback #3 (unavailable as at 22.06.2017)
-        for _, link in re.findall(r'<a[^>]+href=(["\'])(http.+?)\1[^>]+title=["\']Download [Vv]ideo', webpage):
+                r'(?:videoSrc|videoIpadUrl|html5PlayerSrc)\s*[:=]\s*(["\'])(http.+?)\1', webpage):
-        # Fallback #3, encrypted links
+        # Fallback #4, encrypted links (unavailable as at 22.06.2017)
-            webpage, 'title', group='title')
+            [r'(?:video_titles|videoTitle|title)\s*[:=]\s*(["\'])(?P<title>(?:(?!\1).)+)\1',
-            })
+        for fmt_stream in fmt_stream_map:
-)
+from ..utils import parse_duration
-            r"url: escape\('([^']+)'\)", webpage, 'url')
+        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]
-            r'Added: <strong>(.+?)</strong>', webpage, 'upload date', fatal=False))
+        title = self._html_search_regex((
-            r'<td>Time:\s*</td>\s*<td align="right"><span>\s*(.+?)\s*</span>',
+            r'Time:\s*<strong>\s*(.+?)\s*</strong>',
-            r'<td>Views:\s*</td>\s*<td align="right"><span>\s*(\d+)\s*</span>',
+        view_count = int(self._search_regex(
-            r'<a href="[^"]+/search/video/desi"><span>([^<]+)</span></a>',
+            r'<a[^>]+class=[\'"]categories[\'"][^>]*>\s*([^<]+)\s*</a>',
-        return {
+        info_dict.update({
-        }
+        })
-                'description': 'md5:a4f10fb2f2a02565c1749d4adbab4b10',
+                'description': 'md5:24ed2bd527096ec2a5c67b9d5a9005f3',
-                        ext = source_file.get('extension', determine_ext(download_url)).lower()
+                        ext = (try_get(
-        'md5': 'a07ea1ebaba64082d90323b1c96f264b',
+    _VALID_URL = r'https?://(?:www\.)?ruv\.is/(?:sarpurinn/[^/]+|node)/(?P<id>[^/]+(?:/\d+)?)'
-            'id': '20170614',
+            'id': '1144499',
-    }
+            'title': 'FH - Valur',
-        webpage = self._download_webpage(url, video_id)
+        display_id = self._match_id(url)
-        video_url = self._html_search_regex(r'video\.src\s*=\s*["\'](.+?)["\']', webpage, 'video URL')
+
-            'ext': 'mp4'
+            'description': description,
-from ..compat import compat_str
+from ..compat import (
-            'https://www.viu.com/api/' + path, *args, **kwargs)['response']
+            'https://www.viu.com/api/' + path, *args,
-from ..compat import compat_urlparse
+from ..compat import (
-        return super(AdobePassIE, self)._download_webpage_handle(*args, **kwargs)
+        return super(AdobePassIE, self)._download_webpage_handle(
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'upload_date': info['fid'][:8] if isinstance(info.get('fid'), compat_str) else None,
+            'upload_date': info['fid'].split('/')[-1][:8] if isinstance(info.get('fid'), compat_str) else None,
-__version__ = '2017.06.12'
+__version__ = '2017.06.18'
-    decodeArgument,
+    shell_quote,
-        quoted_args.append(pipes.quote(a))
+        quoted_args.append(compat_shlex_quote(a))
-from ..utils import PostProcessingError
+from ..utils import (
-        retCode = subprocess.call(cmd, shell=True)
+        retCode = subprocess.call(encodeArgument(cmd), shell=True)
-except ImportError:  # Python < 3.3
+
-            return "'" + s.replace("'", "'\"'\"'") + "'"
+        return s if re.match(r'^[-_\w./]+$', s) else '"%s"' % s.replace('"', '\\"')
-            self._downloader.to_screen('[fromtitle] Could not interpret title of video as "%s"' % self._titleformat)
+            self._downloader.to_screen(
-            self._downloader.to_screen('[fromtitle] parsed ' + attribute + ': ' + value)
+            self._downloader.to_screen(
-PREFIX = '''%YOUTUBE-DL(1)
+PREFIX = r'''%YOUTUBE-DL(1)
-            r'(?s)<div[^>]+class="audio atarticle"[^>]*>(.+?)<script>',
+            r'(?s)<div[^>]+class="\s*this-article\s*"[^>]*>(.+?)<div[^>]+class="tags"[^>]*>',
-                    self._downloader.to_stdout(
+                    self._downloader.to_screen(
-        title = self._html_search_regex('<h1[^>]+title="([^"]+)">', webpage, 'title')
+        title = self._html_search_regex('<h1[^>]*>([^<]+)</h1>', webpage, 'title')
-        token_url = 'http://tkn.4tube.com/{0}/desktop/{1}'.format(
+        token_url = 'https://tkn.kodicdn.com/{0}/desktop/{1}'.format(
-            b'Origin': b'http://www.4tube.com',
+            b'Origin': b'https://www.4tube.com',
-        https?://(?P<domain>(?:[^/]+\.)?(?:disney\.[a-z]{2,3}(?:\.[a-z]{2})?|disney(?:(?:me|latino)\.com|turkiye\.com\.tr)|(?:starwars|marvelkids)\.com))/(?:(?:embed/|(?:[^/]+/)+[\w-]+-)(?P<id>[a-z0-9]{24})|(?:[^/]+/)?(?P<display_id>[^/?#]+))'''
+        https?://(?P<domain>(?:[^/]+\.)?(?:disney\.[a-z]{2,3}(?:\.[a-z]{2})?|disney(?:(?:me|latino)\.com|turkiye\.com\.tr|channel\.de)|(?:starwars|marvelkids)\.com))/(?:(?:embed/|(?:[^/]+/)+[\w-]+-)(?P<id>[a-z0-9]{24})|(?:[^/]+/)?(?P<display_id>[^/?#]+))'''
-                                npo\.nl/(?!live|radio)(?:[^/]+/){2}|
+                                npo\.nl/(?!(?:live|radio)/)(?:[^/]+/){2}|
-                            (?:hgtv|foodnetwork|slice|history)\.ca
+                            (?:hgtv|foodnetwork|slice|history|showcase)\.ca
-    _VALID_URL = r'https?://(?:www\.)?(?P<domain>(?:globaltv|etcanada)\.com|(?:hgtv|foodnetwork|slice)\.ca)/(?:video/|(?:[^/]+/)+(?:videos/[a-z0-9-]+-|video\.html\?.*?\bv=))(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-__version__ = '2017.06.05'
+__version__ = '2017.06.12'
-    sanitized_Request,
+        # Malformed HTML should not break attributes extraction on older Python
-    parser.close()
+    try:
-            webpage = self._download_webpage(req, video_id, 'Downloading video page')
+            webpage = self._download_webpage(
-            (?P<id>\d+)'''
+                    https?://
-            r'<iframe[^>]+?src=(["\'])(?P<url>https?://player\.(?:rutv\.ru|vgtrk\.com)/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>https?://(?:test)?player\.(?:rutv\.ru|vgtrk\.com)/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\1', webpage)
-            r'<meta[^>]+?property=(["\'])og:video\1[^>]+?content=(["\'])(?P<url>https?://player\.(?:rutv\.ru|vgtrk\.com)/flash\d+v/container\.swf\?id=.+?\2)',
+            r'<meta[^>]+?property=(["\'])og:video\1[^>]+?content=(["\'])(?P<url>https?://(?:test)?player\.(?:rutv\.ru|vgtrk\.com)/flash\d+v/container\.swf\?id=.+?\2)',
-        }
+            'timestamp': 1378878540,
-        video_url = self._parse_json(self._search_regex(
+        media_url = self._parse_json(self._search_regex(
-            'url': video_url,
+            'url': media_url,
-            url_base = video_url.rpartition('.')[0]
+            url_base = media_url.rpartition('.')[0]
-        uploader = self._html_search_regex(
+        uploader = self._search_regex(
-    date_str = date_str.replace(',', ' ')
+    date_str = re.sub(r'[,|]', '', date_str)
-from .newgrounds import NewgroundsIE
+from .newgrounds import (
-from ..utils import int_or_none
+from ..utils import (
-            r'Author\s*<a[^>]+>([^<]+)', webpage, 'uploader', fatal=False)
+        video_url = self._parse_json(self._search_regex(
-            r'"url":("[^"]+"),', webpage, ''), media_id)
+        self._check_formats(formats, media_id)
-            'url': music_url,
+            'formats': formats,
-                    format_url + '/Manifest', display_id, 'mss', fatal=False))
+            elif determine_ext(format_url) == 'ism':
-            format_id = m.group('format_id')
+            format_id = compat_str(m.group('format_id'))
-                    'format_id': m.group('format_id'),
+                    'format_id': format_id,
-        return m.group('id')
+        return compat_str(m.group('id'))
-                quality = m.group('quality')
+                quality = compat_str(m.group('quality'))
-                r'^(\d+)[pP]', source.get('label', ''), 'height', default=None),
+            'height': int(self._search_regex(
-        comment_count = self._html_search_regex(
+        comment_count = int(self._html_search_regex(
-            webpage, 'comment count', fatal=False)
+            webpage, 'comment count', fatal=False))
-                'format_id': e.tag,
+                'format_id': compat_str(e.tag),
-            filesize = gfy.get('%sSize' % format_id)
+            filesize = int_or_none(gfy.get('%sSize' % format_id))
-            'height': resolution,
+            'height': int_or_none(resolution),
-from ..compat import compat_urllib_parse_urlencode
+from ..compat import (
-                stream_type = str(stream.get('type'))
+                stream_type = compat_str(stream.get('type'))
-from ..utils import ExtractorError
+from ..utils import (
-                    'fps': data['fps'],
+                    'filesize': int_or_none(
-            'Downloading login form')
+            self._LOGIN_URL, None, 'Downloading login form', headers=headers)
-        if re.search(self._SUCCESSFUL_LOGIN_REGEX, login_page) is None:
+        if not is_logged(login_page):
-                    r'([0-9]+)p\.mp4', a_format['url'], 'height label', default=None)
+                a_format['height'] = int_or_none(self._search_regex(
-            for numeric_field in NUMERIC_FIELDS:
+            for numeric_field in self._NUMERIC_FIELDS:
-            info_dict['id'] = compat_str(info_dict['id'])
+        def report_force_conversion(field, field_not, conversion):
-            'Specify any key (see help for -o for a list of available keys) to '
+            'Specify any key (see the "OUTPUT TEMPLATE" for a list of available keys) to '
-        help='Simulate, quiet but print JSON information. See --output for a description of available keys.')
+        help='Simulate, quiet but print JSON information. See the "OUTPUT TEMPLATE" for a description of available keys.')
-        }
+        },
-        title = self._og_search_title(webpage)
+        title = self._og_search_title(webpage, default=video_id)
-            rtl\.nl/system/videoplayer/(?:[^/]+/)+(?:video_)?embed\.html\b.+?\buuid=
+            rtl\.nl/(?:system/videoplayer/(?:[^/]+/)+(?:video_)?embed\.html\b.+?\buuid=|video/)
-                'nonce': token,
+                'gen': token,
-__version__ = '2017.05.29'
+__version__ = '2017.06.05'
-    _VALID_URL = r'https?://.*?\.bandcamp\.com/track/(?P<title>.*)'
+    _VALID_URL = r'https?://.*?\.bandcamp\.com/track/(?P<title>[^/?#&]+)'
-    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<album_id>[^?#]+)|/?(?:$|[?#]))'
+    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<album_id>[^/?#&]+))?'
-        return False if BandcampWeeklyIE.suitable(url) else super(BandcampAlbumIE, cls).suitable(url)
+        return (False
-    _VALID_URL = r'https?://(?:www\.)?bandcamp\.com/?\?(?:.*&)?show=(?P<id>\d+)(?:$|[&#])'
+    IE_NAME = 'Bandcamp:weekly'
-            'description': 'Stones Throw\'s Vex Ruffin, plus up and coming singer Salami Rose Joe Louis, in conversation about their fantastic DIY albums.',
+            'title': 'BC Weekly April 4th 2017 - Magic Moments',
-        video_id = compat_str(show['show_id'])
+        show_id = int_or_none(show.get('show_id')) or int_or_none(video_id)
-            known_extensions = ['mp3', 'opus']
+        formats = []
-                        break
+        title = show.get('audio_title') or 'Bandcamp Weekly'
-            return dictionaries
+        episode_number = None
-        self._sort_formats(formats)
+        if seq and isinstance(seq, list):
-            'description': show.get('desc'),
+            'title': title,
-            'webpage_url': 'https://bandcamp.com/?show=' + video_id,
+            'episode': show.get('subtitle'),
-from .bandcamp import BandcampIE, BandcampAlbumIE
+from .bandcamp import BandcampIE, BandcampAlbumIE, BandcampWeeklyIE
-            playlist_id)
+                r'(?:playlistObject|PLAYLIST_VIEW)\s*=\s*({.+?});', webpage,
-            entries, playlist_id, playlist.get('title'), playlist.get('description'))
+            entries, playlist_id, title, playlist.get('description'))
-            ctypes.windll.kernel32.SetConsoleTitleW(ctypes.c_wchar_p(message))
+        if compat_os_name == 'nt':
-        if 'TERM' in os.environ:
+        if compat_os_name != 'nt' and 'TERM' in os.environ:
-        if 'TERM' in os.environ:
+        if compat_os_name != 'nt' and 'TERM' in os.environ:
-        SafariBaseIE.LOGGED_IN = True
+        self.LOGGED_IN = True
-    _VALID_URL = r'https?://(?:(?:www\.)?france\.tv|mobile\.france\.tv)/(?:[^/]+/)+(?P<id>[^/]+)\.html'
+    _VALID_URL = r'https?://(?:(?:www\.)?france\.tv|mobile\.france\.tv)/(?:[^/]+/)*(?P<id>[^/]+)\.html'
-    parse_iso8601,
+    js_to_json,
-        'url': 'http://www.dr.dk/bonanza/serie/portraetter/Talkshowet.htm?assetId=65517',
+    _VALID_URL = r'https?://(?:www\.)?dr\.dk/bonanza/[^/]+/\d+/[^/]+/(?P<id>\d+)/(?P<display_id>[^/?#&]+)'
-            'id': '65517',
+            'id': '40312',
-            'description': 'md5:501e5a195749480552e214fbbed16c4e',
+            'title': 'MATADOR - 08:24. "Komme fremmede".',
-            'duration': 7369,
+            'duration': 4613,
-    }]
+    }
-            return {}
+        mobj = re.match(self._VALID_URL, url)
-        }
+        webpage = self._download_webpage(url, display_id)
-                    thumbnail = file['Location']
+        info = self._parse_html5_media_entries(
-            info['Description'], info['Actors'], info['Colophon'])
+        asset = self._parse_json(
-        self._sort_formats(formats)
+        title = unescapeHTML(asset['AssetTitle']).strip()
-        display_id = re.sub(r'-+', '-', display_id)
+        def extract(field):
-            'id': asset_id,
+        info.update({
-        }
+            'description': extract('Programinfo'),
-                'Downloading Authorization Token')['data']['token']
+                self._MAPT_REST + '/users/tokens', None,
-            if isinstance(e.cause, compat_HTTPError) and e.cause.code in (401, 404):
+            if isinstance(e.cause, compat_HTTPError) and e.cause.code in (400, 401, 404):
-            headers['Authorization'] = self._TOKEN
+            headers['Authorization'] = 'Bearer ' + self._TOKEN
-__version__ = '2017.05.26'
+__version__ = '2017.05.29'
-                    encrypted_sig = url_data['s'][0]
+                if 's' in url_data or self._downloader.params.get('youtube_include_dash_manifest', True):
-
+                if 'sig' in url_data:
-            r'<span[^>]+?itemprop=["\']author[^>]+?><a[^>]+?href=["\'][^>]+?><span[^>]+?itemprop=["\']name[^>]+?>(.+?)</span',
+            r'<span[^>]+itemprop=["\']author[^>]+><a[^>]+><span[^>]+>([^<]+)',
-        mobj = re.search(r'hint=[\'"](?P<likecount>\d+) Likes / (?P<dislikecount>\d+) Dislikes[\'"]', webpage)
+        mobj = re.search(r'hint=[\'"](?P<likecount>\d+) Likes / (?P<dislikecount>\d+) Dislikes', webpage)
-            r'<span[^>]+itemprop=["\']author[^>]+><a[^>]+href=["\'].+?xhamster\.com/user/[^>]+>(?P<uploader>.+?)</a>',
+            r'<span[^>]+?itemprop=["\']author[^>]+?><a[^>]+?href=["\'][^>]+?><span[^>]+?itemprop=["\']name[^>]+?>(.+?)</span',
-        mobj = re.search(r"hint='(?P<likecount>\d+) Likes / (?P<dislikecount>\d+) Dislikes'", webpage)
+        mobj = re.search(r'hint=[\'"](?P<likecount>\d+) Likes / (?P<dislikecount>\d+) Dislikes[\'"]', webpage)
-       (?P<id>\d+)'''
+                    https?://
-        },
+        'only_matching': True,
-    _VALID_URL = r'https?://abcnews\.go\.com/[^/]+/video/(?P<display_id>[0-9a-z-]+)-(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-            }
+    _VALID_URL = r'https?://(?:www\.)?gaskrank\.tv/tv/(?P<categories>[^/]+)/(?P<id>[^/]+)\.htm'
-    ]
+    }, {
-
+
-        title = self._og_search_title(webpage, default=None) or self._html_search_meta(
+
-            webpage, 'video id')
+            webpage, 'video id', default=display_id)
-            webpage, 'thumbnail', default=None)
+        title = self._og_search_title(webpage, default=None) or self._html_search_meta(
-        self._sort_formats(formats, field_preference=['format_id'])
+            webpage, 'video id')
-        return {
+        entry = self._parse_html5_media_entries(url, webpage, video_id)[0]
-        }
+        })
-                'skip_download': True,
+            'skip_download': True,
-                        (?:www\.)?
+                        (?:www\.|nieuws\.)?
-            'title': 'StropnickÃ½: Policie VrbÄtice preventivnÄ nekontrolovala',
+            'duration': 1484,
-                'title': 'DrtinovÃ¡ VeselovskÃ½ TV 16. 12. 2014: TÃ©mata dne'
+                'title': 'DrtinovÃ¡ VeselovskÃ½ TV 16. 12. 2014: TÃ©mata dne',
-                'title': 'Å kolnÃ­ masakr moÅ¾nÃ¡ zmÄnÃ­ boj s Talibanem, ÅÃ­kÃ¡ novinÃ¡Åka'
+                'title': 'Å kolnÃ­ masakr moÅ¾nÃ¡ zmÄnÃ­ boj s Talibanem, ÅÃ­kÃ¡ novinÃ¡Åka',
-                'title': 'Boj o kliniku: VeÅejnÃ½ zÃ¡jem, nebo prÃ¡vo na majetek?'
+                'title': 'Boj o kliniku: VeÅejnÃ½ zÃ¡jem, nebo prÃ¡vo na majetek?',
-                'title': 'PÃ¡nek: OdmÃ­tÃ¡nÃ­ syrskÃ½ch uprchlÃ­kÅ¯ je ostudou ÄeskÃ© vlÃ¡dy'
+                'title': 'PÃ¡nek: OdmÃ­tÃ¡nÃ­ syrskÃ½ch uprchlÃ­kÅ¯ je ostudou ÄeskÃ© vlÃ¡dy',
-            'ext': 'm3u8',
+            'ext': 'mp4',
-        }
+            'duration': 1103,
-        metadata = self._parse_json(js, video_id, transform_source=js_to_json)
+        data = self._parse_json(js, video_id, transform_source=js_to_json)
-            if video['label'] != 'adaptive':
+        for video in data['sources']:
-                    'fps': 25,
+                    'url': video_url,
-            'thumbnail': self._proto_relative_url(metadata['image'], 'http:'),
+            'id': data.get('mediaid') or video_id,
-            r"(?s)embedData[0-9a-f]{32}\['asset'\]\s*=\s*(\{.+?\});",
+            r'(?s)embedData[0-9a-f]{32}\[["\']asset["\']\]\s*=\s*(\{.+?\});',
-            })
+            if video['label'] != 'adaptive':
-    _VALID_URL = r'https?://(?:\w+\.)?beam\.pro/(?P<id>[^/?#&]+)'
+    IE_NAME = 'Mixer:live'
-        'url': 'http://www.beam.pro/niterhayven',
+        'url': 'http://mixer.com/niterhayven',
-            'https://beam.pro/api/v1/channels/%s' % channel_name, channel_name)
+            '%s/channels/%s' % (self._API_BASE, channel_name), channel_name)
-            channel_name, ext='mp4', m3u8_id='hls', fatal=False)
+            manifest_url('m3u8'), channel_name, ext='mp4', m3u8_id='hls',
-            'thumbnail': try_get(chan, lambda x: x['thumbnail']['url'], compat_str),
+            'thumbnail': try_get(
-    _VALID_URL = r'https?://(?:\w+\.)?beam\.pro/[^/?#&]+.*[?&]vod=(?P<id>\d+)'
+    IE_NAME = 'Mixer:vod'
-        'url': 'https://beam.pro/willow8714?vod=2259830',
+        'url': 'https://mixer.com/willow8714?vod=2259830',
-    def _extract_format(self, vod, vod_type):
+    @staticmethod
-            filename, protocol = 'manifest.m3u8', 'm3u8'
+            filename, protocol = 'manifest.m3u8', 'm3u8_native'
-            return []
+            assert False
-        data = vod.get('data') or {}
+        data = vod.get('data') if isinstance(vod.get('data'), dict) else {}
-        if 'Height' in data:
+        if isinstance(data.get('Height'), compat_str):
-            'https://beam.pro/api/v1/recordings/%s' % vod_id, vod_id)
+            '%s/recordings/%s' % (self._API_BASE, vod_id), vod_id)
-                'VOD %s is not available (state: %s)' % (vod_id, state), expected=True)
+                'VOD %s is not available (state: %s)' % (vod_id, state),
-        info.update(self._extract_channel_info(chan))
+        info.update(self._extract_channel_info(vod_info.get('channel') or {}))
-class BeamProLiveIE(InfoExtractor):
+class BeamProBaseIE(InfoExtractor):
-    _RATINGS = {'family': 0, 'teen': 13, '18+': 18}
+    @classmethod
-        return {
+        info = {
-            'age_limit': self._RATINGS.get(chan.get('audience')),
+        info.update(self._extract_channel_info(chan))
-from .beampro import BeamProLiveIE
+from .beampro import (
-    _VALID_URL = r'https?://(?:www\.)?(?P<site>cnet|zdnet)\.com/(?:videos|video/share)/(?P<id>[^/?]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<site>cnet|zdnet)\.com/(?:videos|video(?:/share)?)/(?P<id>[^/?]+)'
-            resp = self.addinfourl_wrapper(uncompressed, old_resp.headers, old_resp.url, old_resp.code)
+            resp = compat_urllib_request.addinfourl(uncompressed, old_resp.headers, old_resp.url, old_resp.code)
-            resp = self.addinfourl_wrapper(gz, old_resp.headers, old_resp.url, old_resp.code)
+            resp = compat_urllib_request.addinfourl(gz, old_resp.headers, old_resp.url, old_resp.code)
-            video_id, fatal=False)
+            urljoin(self._BASE_URL, sub_path),
-            bytes_to_intlist(b'\nd\xaf\xd2J\xd0\xfc\xe1\xfc\xdf\xb61\xe8\xe1\xf0\xcc'),
+            bytes_to_intlist(b'\x1b\xe0\x29\x61\x38\x94\x24\x00\x12\xbd\xc5\x80\xac\xce\xbe\xb0'),
-            dec_subtitles[:-compat_ord(dec_subtitles[-1])],
+            dec_subtitles[:-compat_ord(dec_subtitles[-1])].decode(),
-        title = data['video']['title']
+        video_data = data['video']
-            webpage, 'video JSON info'), video_id)
+            webpage, 'video JSON info', default='{}'), video_id, fatal=False)
-        return self._extract_video_info(guid, 'cbsnews')
+        if video_info:
-__version__ = '2017.05.23'
+__version__ = '2017.05.26'
-                        add_dash_mpd(get_video_info)
+                    add_dash_mpd(get_video_info)
-            http://(?:v|player)\.youku\.com/(?:v_show/id_|player\.php/sid/)|
+            https?://(
-            'ccode': '0401',
+            'ccode': '0402' if 'tudou.com' in url else '0401',
-    get_element_by_attribute,
+    get_element_by_class,
-    _VALID_URL = r'https?://(?:www\.)?youku\.com/show_page/id_(?P<id>[0-9a-z]+)\.html'
+    _VALID_URL = r'https?://list\.youku\.com/show/id_(?P<id>[0-9a-z]+)\.html'
-        'url': 'http://www.youku.com/show_page/id_zc7c670be07ff11e48b3f.html',
+        'url': 'http://list.youku.com/show/id_zc7c670be07ff11e48b3f.html',
-            'description': 'md5:578d4f2145ae3f9128d9d4d863312910',
+            'description': 'md5:a1ae6f5618571bbeb5c9821f9c81b558',
-            new_entries = self._find_videos_in_page(episodes_page)
+        entries = []
-        return self.playlist_result(entries, show_id, playlist_title, playlist_description)
+        desc = self._html_search_meta('description', webpage, fatal=False)
-        r'(?s)^[a-zA-Z0-9_.$]+\s*\(\s*(.*)\);?\s*?(?://[^\n]*)*$', r'\1', code)
+        r'''(?sx)^
-            'id': 'XMTc1ODE5Njcy_part1',
+            'id': 'XMTc1ODE5Njcy',
-            'ext': 'flv'
+            'ext': 'mp4',
-        'skip': 'Available in China only',
+            'ext': 'mp4',
-        'playlist_count': 13,
+            'ext': 'mp4',
-        'playlist_count': 19,
+            'ext': 'mp4',
-        return _dict[fm]
+        return _dict.get(fm)
-            raw_data = self._download_json(req_url, video_id, note=note, headers=headers)
+        _, urlh = self._download_webpage_handle(
-            return raw_data['data']
+        # request basic data
-            basic_data_url += '&pwd=%s' % video_password
+            basic_data_params['password'] = video_password
-        data = retrieve_data(basic_data_url, 'Downloading JSON metadata')
+        headers = {
-                })
+        formats = [{
-            'entries': entries,
+            'formats': formats,
-                'url': src['url'],
+                'url': src.get('url'),
-            metadata_filename = encodeFilename(replace_extension(filename, 'meta'))
+            metadata_filename = replace_extension(filename, 'meta')
-                        formats.extend(self._extract_mpd_formats(
+                        mpd_formats = self._extract_mpd_formats(
-                            fatal=False))
+                            fatal=False)
-        return self._extract_video_info(guid)
+        return self._extract_video_info(guid, 'cbsnews')
-__version__ = '2017.05.18.1'
+__version__ = '2017.05.23'
-        'md5': '6d3ca61a8d0633c9c542b92fcb936b0c',
+        'md5': '934bb6a6d220d99c010783c9719960d5',
-        'md5': 'e54a254fb8b871968fd8403255f28589',
+        'md5': '849a88c1e1ca47d41403c2ba5e59e261',
-            sts = ''
+            sts = None
-                sts = ytplayer_config.get('sts', '')
+                sts = ytplayer_config.get('sts')
-                        % (proto, video_id, el_type, sts))
+                for el in ('info', 'embedded', 'detailpage', 'vevo', ''):
-                        video_info_url,
+                        '%s://www.youtube.com/get_video_info' % proto,
-                        errnote='unable to download video info webpage')
+                        errnote='unable to download video info webpage',
-                        % (proto, video_id, el_type))
+                        '%s://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en&sts=%s'
-    _VALID_URL = r'https?://video\.toggle\.sg/(?:en|zh)/(?:series|clips|movies)/(?:[^/]+/)+(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://video\.toggle\.sg/(?:en|zh)/(?:[^/]+/){2,}(?P<id>[0-9]+)'
-    _VALID_URL = r'https?://videos\.toypics\.net/view/(?P<id>[0-9]+)/.*'
+    IE_DESC = 'Toypics video'
-            'title': 'Chance-Bulge\'d, 2',
+            'title': "Chance-Bulge'd, 2",
-        formats = self._parse_html5_media_entries(url, page, video_id)[0]['formats']
+        video_id = self._match_id(url)
-            r'More videos from <strong>([^<]+)</strong>', page, 'username')
+        ], webpage, 'title')
-            'uploader': username,
+            'uploader': uploader,
-    _VALID_URL = r'https?://videos\.toypics\.net/(?P<username>[^/?]+)(?:$|[?#])'
+    _VALID_URL = r'https?://videos\.toypics\.net/(?!view)(?P<id>[^/?#&]+)'
-        username = mobj.group('username')
+        username = self._match_id(url)
-                    r'<div[^>]+class=["\']preview[^>]+>\s*<a[^>]+href="(https?://videos.toypics.net/view/[^"]+)"',
+                    r'<div[^>]+class=["\']preview[^>]+>\s*<a[^>]+href="(https?://videos\.toypics\.net/view/[^"]+)"',
-            r'<title>Toypics - ([^<]+)</title>', page, 'title')
+        formats = self._parse_html5_media_entries(url, page, video_id)[0]['formats']
-            r'toypics.net/([^/"]+)" class="user-name">', page, 'username')
+            r'More videos from <strong>([^<]+)</strong>', page, 'username')
-            'url': video_url,
+            'formats': formats,
-                    r'<p class="video-entry-title">\s+<a href="(https?://videos.toypics.net/view/[^"]+)">',
+                    r'<div[^>]+class=["\']preview[^>]+>\s*<a[^>]+href="(https?://videos.toypics.net/view/[^"]+)"',
-
+        for mobj in re.finditer(r'<a[^>]+\bhref=(["\'])/player.+?[^>]*>', webpage):
-            formats.extend(entries[0]['formats'])
+                m3u8_entry_protocol='m3u8_native')
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?(?:hitbox|smashcast)\.tv/(?:[^/]+/)*videos?/(?P<id>[0-9]+)'
-    }
+    }, {
-            'Downloading metadata JSON')
+            '%s/%s' % (url, video_id), video_id, 'Downloading metadata JSON')
-        ]
+        thumbs = [{
-            'https://www.hitbox.tv/api/player/config/video/%s' % video_id,
+            'https://www.smashcast.tv/api/player/config/video/%s' % video_id,
-            video_id)
+            'https://www.smashcast.tv/api/media/video', video_id)
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?(?:hitbox|smashcast)\.tv/(?P<id>[^/?#&]+)'
-    }
+    }, {
-            'https://www.hitbox.tv/api/player/config/live/%s' % video_id,
+            'https://www.smashcast.tv/api/player/config/live/%s' % video_id,
-            video_id)
+            'https://www.smashcast.tv/api/media/live', video_id)
-            r'var\s+%s\s*=\s*["\']([0-9a-f]+)' % appKey_var, gigya_sc, 'appKey')
+            r'constant\s*\(\s*["\']_appGridApplicationKey["\']\s*,\s*["\']([0-9a-f]+)',
-__version__ = '2017.05.18'
+__version__ = '2017.05.18.1'
-            r'\}\s*;' % _FUNC_NAME_RE,
+            r'''(?x)
-            r'\((?P<args>[a-z,]+)\){(?P<code>[^}]+)}' % _FUNC_NAME_RE,
+            r'''(?x)
-__version__ = '2017.05.14'
+__version__ = '2017.05.18'
-            r'(?P<var>%s)\.(?P<member>[^(]+)(?:\(+(?P<args>[^()]*)\))?$' % _NAME_RE,
+            r'(?P<in>%s)\[(?P<idx>.+)\]$' % _NAME_RE, expr)
-            member = m.group('member')
+            member = remove_quotes(m.group('member') or m.group('member2'))
-
+        _FUNC_NAME_RE = r'''(?:[a-zA-Z$0-9]+|"[a-zA-Z$0-9]+"|'[a-zA-Z$0-9]+')'''
-            r'\}\s*;',
+            r'\s*(?P<fields>(%s\s*:\s*function\(.*?\)\s*\{.*?\}(?:,\s*)?)*)' +
-            r'\((?P<args>[a-z,]+)\){(?P<code>[^}]+)}',
+            r'(?P<key>%s)\s*:\s*function'
-            obj[f.group('key')] = self.build_function(argnames, f.group('code'))
+            obj[remove_quotes(f.group('key'))] = self.build_function(argnames, f.group('code'))
-        formats = self._extract_wowza_formats(playlist_url, display_id, skip_protocols=['dash'])
+        formats = self._extract_wowza_formats(
-            fatal=False))
+            r'(?s)<div\b[^>]+\bclass=(["\'])[^>]*?\bfield-type-text-with-summary\b[^>]*?\1[^>]*>.*?<p>(?P<value>.+?)</p>',
-            webpage, 'upload_date', default=None))
+            r'(?s)<div\b[^>]+\bclass=(["\'])[^>]*?\bfield-name-post-date\b[^>]*?\1[^>]*>.*?(?P<value>\d{2}/\d{2}/\d{4})',
-            'upload_date': upload_date,
+            'upload_date': upload_date,
-from ..utils import urlencode_postdata
+from ..utils import (
-            'description': 'md5:2d169e8186ae4247e50c99aaef97f7b2',
+            'description': 'md5:aa8d611541db6ae9e863125704511f88',
-        description = self._og_search_description(webpage, default=None)
+        description = self._html_search_regex(
-        http_base_url = self._proto_relative_url(url_base, scheme='http:')
+        http_base_url = '%s:%s' % ('http', url_base)
-                        'url': protocol + url_base,
+                        'url': '%s:%s' % (protocol, url_base),
-        http_base_url = 'http' + url_base
+        url_base = self._search_regex(
-)
+from ..utils import urlencode_postdata
-            'description': 'Het spel is simpel: Annelien Coorevits en Rick Brandsteder krijgen telkens 2 dilemma\'s voorgeschoteld en ze MOETEN een keuze maken.',
+            'title': 'md5:84f45fe48b8c1fa296a7f6d208d080a7',
-            'description': 'Bekijk hier de volledige vierde aflevering van het 2de seizoen van Jani gaat...',
+            'description': 'md5:2d169e8186ae4247e50c99aaef97f7b2',
-            # m3u8 download
+        # Requires account credentials but bypassed extraction via v3/embed page
-        'url': 'http://www.vier.be/planb/videos/mieren-herders-van-de-bladluizen',
+        # Without video id in URL
-            webpage, 'video id', default=video_id)
+            webpage, 'video id', default=video_id or display_id)
-            'title': 'ZO grappig: Temptation Island hosts moeten kiezen tussen onmogelijke dilemma\'s',
+            'title': 'EXTRA: Temptation Island hosts moeten kiezen tussen onmogelijke dilemma\'s',
-            webpage, 'video id')
+            webpage, 'video id', default=video_id)
-            'sources', {}).get('url') or 'http://www.dailymail.co.uk/api/player/%s/video-sources.json' % video_id, video_id)
+
-        elif codec in ('mp4a', 'opus', 'vorbis', 'mp3', 'aac', 'ac-3'):
+        elif codec in ('mp4a', 'opus', 'vorbis', 'mp3', 'aac', 'ac-3', 'ec-3', 'eac3', 'dtsc', 'dtse', 'dtsh', 'dtsl'):
-            write_string('WARNING: Unknown codec %s' % full_codec, sys.stderr)
+            write_string('WARNING: Unknown codec %s\n' % full_codec, sys.stderr)
-    _VALID_URL = r'(?i)(?:https?://)?(?:(www|touch)\.)?dailymotion\.[a-z]{2,3}/(?:(?:embed|swf|#)/)?video/(?P<id>[^/?_]+)'
+    _VALID_URL = r'(?i)https?://(?:(www|touch)\.)?dailymotion\.[a-z]{2,3}/(?:(?:(?:embed|swf|#)/)?video|swf)/(?P<id>[^/?_]+)'
-            },
+    _TESTS = [{
-            'skip': 'video gone',
+    }, {
-            'skip': 'VEVO is only available in some countries',
+        'url': 'http://www.dailymotion.com/video/x149uew_katy-perry-roar-official_musi',
-            'skip': 'video gone',
+        'url': 'http://www.dailymotion.com/video/xyh2zz_leanna-decker-cyber-girl-of-the-year-desires-nude-playboy-plus_redband',
-        },
+        'url': 'http://www.dailymotion.com/video/xhza0o',
-    ]
+        'url': 'http://www.dailymotion.com/video/x20su5f_the-power-of-nightmares-1-the-rise-of-the-politics-of-fear-bbc-2004_news',
-__version__ = '2017.05.09'
+__version__ = '2017.05.14'
-             'Example: --metadata-from-title "%(artist)s - %(title)s" matches a title like ' 
+             'Example: --metadata-from-title "%(artist)s - %(title)s" matches a title like '
-            'release_date': '20161107',
+            'upload_date': '20161107',
-            'release_date': unified_strdate(mediainfo.get('production-date')),
+            'upload_date': unified_strdate(mediainfo.get('production-date')),
-                        )(?P<id>[0-9]+)
+                    (?:
-
+        """
-                height = int_or_none(track.get('MaxHeight'))
+                # [1] does not mention Width and Height attributes. However,
-)
+from .common import InfoExtractor
-    unified_strdate
+    try_get,
-    _VALID_URL = r'https?://www\.video\.mediaset\.it/(?:(?:video|on-demand)/(?:.+)_|player/playerIFrame(?:Twitter)?\.shtml\?id=)(?P<id>[0-9]+)(?:.html|&.+)'
+    _VALID_URL = r'''(?x)
-        }
+            'thumbnail': r're:^https?://.*\.jpg$',
-        }
+        'only_matching': True,
-        }
+        'only_matching': True,
-        }
+        'only_matching': True,
-            video_id, 'Downloading video info JSON').get('video')
+        video_list = self._download_json(
-            categories = [mediainfo.get('brand-info').get('category')]
+        formats = []
-            video_id, 'Downloading video CND JSON')
+        mediainfo = self._download_json(
-            raise ExtractorError('Video not found')
+        title = mediainfo['title']
-        self._sort_formats(formats)
+        creator = try_get(
-            'formats': formats,
+            'title': title,
-            'uploader': uploader,
+            'creator': creator,
-            'categories': categories
+            'series': mediainfo.get('brand-value'),
-    _VALID_URL = r'https?://(?P<station>fm4)\.orf\.at/(?:7tage/?#|player/)(?P<date>[0-9]+)/(?P<show>\w+)'
+    _VALID_URL = r'https?://(?P<station>fm4)\.orf\.at/player/(?P<date>[0-9]+)/(?P<show>\w+)'
-    ]
+    _TEST = {
-    _VALID_URL = r'https?://(?P<station>oe1)\.orf\.at/(?:7tage/?#|player/)(?P<date>[0-9]+)/(?P<show>\w+)'
+    _VALID_URL = r'https?://(?P<station>oe1)\.orf\.at/player/(?P<date>[0-9]+)/(?P<show>\w+)'
-    ]
+    _TEST = {
-    ORFOE1IE,
+    ORFOE1IE,
-
+class ORFRadioIE(InfoExtractor):
-            'http://audioapi.orf.at/fm4/json/2.0/broadcasts/%s/4%s' % (show_date, show_id),
+            'http://audioapi.orf.at/%s/api/json/current/broadcast/%s/%s' % (station, show_id, show_date),
-                'url': 'http://loopstream01.apa.at/?channel=fm4&id=%s' % info['loopStreamId'],
+                'url': 'http://loopstream01.apa.at/?channel=%s&id=%s' % (station, info['loopStreamId']),
-    _VALID_URL = r'https?://(?:www\.)?aljazeera\.com/programmes/.*?/(?P<id>[^/]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?aljazeera\.com/(?:programmes|video)/.*?/(?P<id>[^/]+)\.html'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/(?:video/[^/]+/|title/tt\d+.*?#lb-|videoplayer/)vi(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/(?:video|title).+?[/-]vi(?P<id>\d+)'
-             '"Coldplay - Paradise"')
+             'The format syntax is the same as --output. Regular expression with '
-        self._titleregex = self.format_to_regex(titleformat)
+        self._titleregex = (self.format_to_regex(titleformat)
-    _VALID_URL = r'https?://(?:www\.)?france\.tv/(?:[^/]+/)+(?P<id>[^/]+)\.html'
+    _VALID_URL = r'https?://(?:(?:www\.)?france\.tv|mobile\.france\.tv)/(?:[^/]+/)+(?P<id>[^/]+)\.html'
-                unescapeHTML(match.group('url')))
+        wistia_url = WistiaIE._extract_url(webpage)
-                'ie_key': 'Wistia',
+                'url': self._proto_relative_url(wistia_url),
-
+import re
-)
+            'upload_date': '20120913',
-            'id': video_id,
+            '_type': 'url_transparent',
-            'categories': info.get('categories'),
+            'url': player_url,
-    _VALID_URL = r'https?://(?:video|www|player)\.(?P<site>%s)\.com/(?P<type>watch|series|video|embed(?:js)?)/(?P<id>[^/?#]+)' % '|'.join(_SITES.keys())
+    _VALID_URL = r'''(?x)https?://(?:video|www|player(?:-backend)?)\.(?:%s)\.com/
-    EMBED_URL = r'(?:https?:)?//player\.(?P<site>%s)\.com/(?P<type>embed(?:js)?)/.+?' % '|'.join(_SITES.keys())
+    EMBED_URL = r'(?:https?:)?//player(?:-backend)?\.(?:%s)\.com/(?:embed(?:js)?|(?:script|inline)/video)/.+?' % '|'.join(_SITES.keys())
-    def _extract_video(self, webpage, url_type):
+    def _extract_video_params(self, webpage):
-        video_id = query['videoId']
+        return query
-        if not video_info:
+        if params.get('playerId'):
-                video_id, 'Downloading loader info', query=query)
+                'https://player.cnevids.com/inline/video/%s.js' % video_id,
-        info.update({
+        return {
-        return info
+            'categories': video_info.get('categories'),
-        site, url_type, item_id = re.match(self._VALID_URL, url).groups()
+        video_id, player_id, target, url_type, display_id = re.match(self._VALID_URL, url).groups()
-            url_type = 'embed'
+        if video_id:
-        webpage = self._download_webpage(url, item_id)
+        webpage = self._download_webpage(url, display_id)
-            return self._extract_video(webpage, url_type)
+            params = self._extract_video_params(webpage)
-        'md5': '50f79e05ba149149c1b4ea961223d5b3',
+        'md5': '0813c2430bea7a46bf13acf3406992f4',
-            'ext': 'flv',
+            'ext': 'mp4',
-        'md5': 'b13a29626183c9d33944e6a04f41aafc',
+        'md5': 'd3f1367d14cc3c15bf24fbfbe04b9abf',
-        }
+        },
-        'md5': '0b3bec2d888c20728ca2ad3642f0ef15',
+        'md5': 'c3a449dbaca5c0d1825caecd52a57d7b',
-                }
+        entries = self._parse_html5_media_entries(url, webpage, video_id)
-        sources = json.loads(sources_json)
+        info_dict = entries[0]
-        } for i, s in enumerate(sources)]
+        for a_format in info_dict['formats']:
-        self._sort_formats(formats)
+        self._sort_formats(info_dict['formats'])
-        return {
+        info_dict.update({
-        }
+        })
-from .douyutv import DouyuTVIE
+from .douyutv import (
-    _VALID_URL = r'https?://myspace\.com/([^/]+)/(?P<mediatype>video/[^/]+/|music/song/.*?)(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-            },
+    _TESTS = [{
-            }
+        'url': 'https://myspace.com/killsorrow/music/song/of-weakened-soul...-93388656-103880681',
-    ]
+    }, {
-        video_id = mobj.group('id')
+        video_id = mobj.group('video_id') or mobj.group('song_id')
-            'http://www.adultswim.com/videos/api/v0/assets?id=' + video_id,
+            'http://www.adultswim.com/videos/api/v0/assets?platform=desktop&id=' + video_id,
-__version__ = '2017.05.07'
+__version__ = '2017.05.09'
-    FranceTvInfoIE,
+    FranceTVEmbedIE,
-    def _extract_video(self, video_id, catalogue):
+    def _extract_video(self, video_id, catalogue=None):
-            video_id, 'Downloading video JSON')
+            'https://sivideo.webservices.francetelevisions.fr/tools/getInfosOeuvre/v2/',
-    _VALID_URL = r'https?://(?:m\.)?pluzz\.francetv\.fr/videos/(?P<id>.+?)\.html'
+class FranceTVIE(FranceTVBaseInfoExtractor):
-    # Can't use tests, videos expire in 7 days
+    _TESTS = [{
-            'id_video', webpage, 'video id', default=None)
+        catalogue = None
-                r'data-diffusion=["\'](\d+)', webpage, 'video id')
+            video_id, catalogue = self._html_search_regex(
-        return self._extract_video(video_id, 'Pluzz')
+class FranceTVEmbedIE(FranceTVBaseInfoExtractor):
-class FranceTvInfoIE(FranceTVBaseInfoExtractor):
+    _TEST = {
-from ..compat import compat_str
+from ..compat import (
-            'Downloading JSON video')['data']
+            'Downloading JSON video', headers=headers)['data']
-            raise ExtractorError('This video is locked', expected=True)
+            self.raise_login_required('This video is locked')
-        'md5': '25e659cccc9a2ed956110a299fdf5983',
+        'md5': '7ae17b4e18eb5d29212f424a7511c184',
-        },
+        # embed
-            'description': '- Det er det fedeste, der er sket i 20 Ã¥r, fortÃ¦ller christianit til DR Nyheder.',
+            'description': 'md5:2a71898b15057e9b97334f61d04e6eb5',
-            'description': 'Ãn fascinerende historie om tusindvis af Ã¥r, hvor vores land bliver skabt ud af is og vand, og hvor de fÃ¸rste danskere ankommer til vores egn. Det bliver en rejse ind i urtiden og det liv, som urtidsjÃ¦gerne har levet i skovene og ved havet og helt frem til bondestenalderen. Gennem skeletfund afslÃ¸rer eksperter, hvordan vores forfÃ¦dre har set ud i stenalderen og hvorfor stenaldermennesket byggede de imponerende jÃ¦ttestuer, som ligger overalt i det danske.',
+            'description': 'md5:8c66dcbc1669bbc6f873879880f37f2a',
-            if kind in ('VideoResource', 'AudioResource'):
+            elif kind in ('VideoResource', 'AudioResource'):
-                spoken_subtitles = asset.get('Target') == 'SpokenSubtitles'
+                asset_target = asset.get('Target')
-                    if sign_language:
+                    preference = None
-                        format_id += "-sign-language"
+                        format_id += '-%s' % asset_target
-            elif kind in ('VideoResource', 'AudioResource'):
+            preference = 0
-                    preference = None
+                    if sign_language:
-class BrightcoveNewIE(InfoExtractor):
+class BrightcoveNewIE(AdobePassIE):
-        if duration and duration < 0:
+        if duration is not None and duration <= 0:
-            formats.extend(m3u8_formats)
+        for stream_type, streams in streams_json.get('streams', {}).items():
-        if (sys.version_info >= (3,) and sys.platform != 'win32' and
+        if (sys.platform != 'win32' and
-            # On Python 3, the Unicode filesystem API will throw errors (#1474)
+            # Unicode filesystem API will throw errors (#1474, #13027)
-)
+from ..compat import compat_HTTPError
-            'id': '9635',
+            'id': '210051',
-        'skip': 'Access without user interaction is forbidden by CloudFlare',
+        'params': {
-
+    _TOKEN = None
-        raise ExtractorError('Unable to log in')
+        try:
-                video_id)['items']
+                video_id, headers=headers)['items']
-    ExtractorError,
+    strip_or_none,
-    _VALID_URL = r'https?://(?:www\.)?adultswim\.com/videos/(?P<is_playlist>playlists/)?(?P<show_path>[^/]+)/(?P<episode_path>[^/?#]+)/?'
+    _VALID_URL = r'https?://(?:www\.)?adultswim\.com/videos/(?P<show_path>[^/?#]+)(?:/(?P<episode_path>[^/?#]+))?'
-        ],
+            'ext': 'mp4',
-            'description': "Rick moves in with his daughter's family and establishes himself as a bad influence on his grandson, Morty. "
+            'description': 'Rick moves in with his daughter\'s family and establishes himself as a bad influence on his grandson, Morty.',
-            'description': 'Stan hatches a plan to get Francine out of the real estate business.Watch more American Dad on [adult swim].'
+        'params': {
-        ],
+            'ext': 'mp4',
-            'description': 'Dr. Brule reports live from Wine Country with a special report on wines.  \r\nWatch Tim and Eric Awesome Show Great Job! episode #20, "Embarrassed" on Adult Swim.\r\n\r\n',
+            'description': 'Dr. Brule reports live from Wine Country with a special report on wines.  \nWatch Tim and Eric Awesome Show Great Job! episode #20, "Embarrassed" on Adult Swim.',
-        }
+        },
-            'duration': 249.008,
+            'description': 'The guys recap the conclusion of the season. They announce a new hero, take a peek into the Victorville Film Archive and welcome back the talented James Dean.',
-        'url': 'http://www.adultswim.com/videos/toonami/friday-october-14th-2016/',
+        'url': 'http://www.adultswim.com/videos/attack-on-titan',
-            'description': 'md5:99892c96ffc85e159a428de85c30acde',
+            'id': 'd8DEBj7QRfetLsRgFnGEyg',
-            segment_ids = [video_info['videoPlaybackID']]
+        show_path, episode_path = re.match(self._VALID_URL, url).groups()
-        view_count = int_or_none(video_info.get('views'))
+            show_data = initial_data['show']
-                'description': episode_description,
+        info.update({
-        }
+            info['series'] = video_data.get('collection_title') or info.get('series')
-            'title': title,
+            'title': self._live_title(title) if is_live else title,
-            'description': xpath_text(video_data, 'description'),
+            'thumbnail': xpath_text(video_data, 'poster'),
-        })
+            'https://www.nonktube.com/media/nuevo/econfig.php?key=%s'
-    def _extract_nuevo(self, config_url, video_id):
+    def _extract_nuevo(self, config_url, video_id, headers={}):
-            config_url, video_id, transform_source=lambda s: s.strip())
+            config_url, video_id, transform_source=lambda s: s.strip(),
-    _VALID_URL = r'https?://(?:www\.)?nbc\.com/[^/]+/video/[^/]+/(?P<id>n?\d+)'
+    _VALID_URL = r'(?P<permalink>https?://(?:www\.)?nbc\.com/[^/]+/video/[^/]+/(?P<id>n?\d+))'
-        video_id = self._match_id(url)
+        permalink, video_id = re.match(self._VALID_URL, url).groups()
-                'filter[permalink]': url,
+                'filter[permalink]': permalink,
-    _VALID_URL = r'https?://(?:www\.)?nbc\.com/(?:[^/]+/)+(?P<id>n?\d+)'
+    _VALID_URL = r'https?://(?:www\.)?nbc\.com/[^/]+/video/[^/]+/(?P<id>n?\d+)'
-        info = {
+        video_data = self._download_json(
-            'ie_key': 'ThePlatform',
+            'title': title,
-__version__ = '2017.05.01'
+__version__ = '2017.05.07'
-    # remove_start,
+    remove_start,
-    _TFA_REQ_TEMPLATE = '["{0}",null,2,null,[9,null,null,null,null,null,null,null,[null,"{1}",false,2]]]'
+    _CHALLENGE_URL = 'https://accounts.google.com/_/signin/sl/challenge'
-                'f.req': f_req,
+                'f.req': json.dumps(f_req),
-            self._LOOKUP_URL, self._LOOKUP_REQ_TEMPLATE.format(username),
+            self._LOOKUP_URL, lookup_req,
-        user_hash = lookup_results[0][2]
+        user_hash = try_get(lookup_results, lambda x: x[0][2], compat_str)
-            'Logging in', 'Unable to log in')[0]
+        challenge_results = req(
-        if password_challenge_results is False:
+        if challenge_results is False:
-        #     TODO
+        login_res = try_get(challenge_results, lambda x: x[0][5], list)
-            password_challenge_results[2], None, 'Checking cookie')
+            check_cookie_url, None, 'Checking cookie', fatal=False)
-            self._downloader.report_warning('Unable to log in')
+        if 'https://myaccount.google.com/' not in check_cookie_results:
-# coding: utf-8
+# coding: utf-8
-    sanitized_Request,
+    # remove_start,
-    _PASSWORD_CHALLENGE_URL = 'https://accounts.google.com/signin/challenge/sl/password'
+
-                'TrustDevice': 'on',
+        def req(url, f_req, note, errnote):
-            tfa_data = urlencode_postdata(tfa_form_strs)
+        lookup_results = req(
-                note='Submitting TFA code', errnote='unable to submit tfa', fatal=False)
+        if lookup_results is False:
-                return False
+        user_hash = lookup_results[0][2]
-                return False
+        password_challenge_results = req(
-            self._downloader.report_warning('unable to log in: bad username or password')
+        if password_challenge_results is False:
-def try_multipart_encode(data, boundary):
+def _multipart_encode_impl(data, boundary):
-            out, content_type = try_multipart_encode(data, boundary)
+            out, content_type = _multipart_encode_impl(data, boundary)
-        'url': 'http://rmcdecouverte.bfmtv.com/mediaplayer-replay/?id=16548',
+        'url': 'http://rmcdecouverte.bfmtv.com/mediaplayer-replay/?id=13502&title=AQUAMEN:LES%20ROIS%20DES%20AQUARIUMS%20:UN%20DELICIEUX%20PROJET',
-            'id': '5411254766001',
+            'id': '5419055995001',
-            'description': 'ic Brunet propose un nouvel \u00e9pisode des Grains de sable de l\'Histoire sur la plus grosse affaire de contrefa\u00e7on de la Seconde Guerre mondiale.',
+            'title': 'UN DELICIEUX PROJET',
-            'timestamp': 1493166610,
+            'upload_date': '20170502',
-        'skip': 'Only works from France',
+        'skip': 'only available for a week',
-            brightcove_id = compat_parse_qs(compat_urlparse.urlparse(brightcove_legacy_url).query)['@videoPlayer'][0]
+            brightcove_id = compat_parse_qs(compat_urlparse.urlparse(
-        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)
+            brightcove_id = self._search_regex(
-        'url': 'http://rmcdecouverte.bfmtv.com/mediaplayer-replay/?id=1430&title=LES%20HEROS%20DU%2088e%20ETAGE',
+        'url': 'http://rmcdecouverte.bfmtv.com/mediaplayer-replay/?id=16548',
-            'id': '5111223049001',
+            'id': '5411254766001',
-            'description': 'DÃ©couvrez comment la bravoure de deux hommes dans la Tour Nord du World Trade Center a sauvÃ©  la vie d\'innombrables personnes le 11 septembre 2001.',
+            'title': '39/45:LE RESEAU DES FAUX BILLETS',
-            'timestamp': 1472951103,
+            'upload_date': '20170426',
-        brightcove_id = compat_parse_qs(compat_urlparse.urlparse(brightcove_legacy_url).query)['@videoPlayer'][0]
+        if brightcove_legacy_url:
-            'duration': int_or_none(info.get('duration'), 1000),
+            'duration': float_or_none(duration, 1000),
-                }]
+                'en-US': [
-            'thumbnail': info.get('thumb_url'),
+            'thumbnail': info.get('thumb_url') or thumbnail,
-                            (?:[a-z]+\.)?pornhub\.com/(?:view_video\.php\?viewkey=|embed/)|
+                            (?:[a-z]+\.)?pornhub\.com/(?:(?:view_video\.php|video/show)\?viewkey=|embed/)|
-        video_description = get_element_by_id("eow-description", video_webpage)
+        description_original = video_description = get_element_by_id("eow-description", video_webpage)
-            video_description = re.sub(r'''(?x)
+            description_original = video_description = re.sub(r'''(?x)
-
+        points = data.get('shortIndexPoints')
-            query['tvetoken'] = self._extract_mvpd_auth(url, video_id, 'VICELAND', resource)
+            query['tvetoken'] = self._extract_mvpd_auth(
-            preplay = self._download_json('https://%s.com/%s/preplay/%s' % (host, locale, video_id), video_id, query=query)
+            preplay = self._download_json(
-                raise ExtractorError('%s said: %s' % (self.IE_NAME, error['details']), expected=True)
+                raise ExtractorError('%s said: %s' % (
-    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/(?P<locale>[^/]+)/(?:[^/]+/)?videos?/(?P<id>[^/?#&]+)'
+    IE_NAME = 'vice'
-        'md5': 'e9d77741f9e42ba583e683cd170660f7',
+        'url': 'https://news.vice.com/video/experimenting-on-animals-inside-the-monkey-lab',
-            'id': '43cW1mYzpia9IlestBjVpd23Yu3afAfp',
+            'id': 'N2bzkydjraWDGwnt8jAttCF6Y0PDv4Zj',
-            'duration': 725.983,
+            'title': 'Monkey Labs of Holland',
-        'url': 'https://munchies.vice.com/en/videos/watch-the-trailer-for-our-new-series-the-pizza-show',
+        'url': 'https://video.vice.com/en_us/video/pizza-show-trailer/56d8c9a54d286ed92f7f30e4',
-        video_id = self._match_id(url)
+        locale, video_id = re.match(self._VALID_URL, url).groups()
-        description = self._html_search_meta('description', webpage, 'description')
+        description = self._html_search_meta(
-        'url': 'http://www.vice.com/video/how-to-hack-a-car',
+        'url': 'https://www.vice.com/en_us/article/how-to-hack-a-car',
-        if youtube_url:
+
-                'url': youtube_url,
+                'url': video_url,
-                'ie_key': 'Youtube',
+                'ie_key': ie_key,
-            r'data-video-url="([^"]+)"', prefetch_data['embed_code'], 'video URL')
+            r'data-video-url="([^"]+)"',
-        }
+        return _url_res(video_url, ViceIE.ie_key())
-        content = b'Content-Disposition: form-data; name="%s"\r\n\r\n' % k + v + b'\r\n'
+        content = b'Content-Disposition: form-data; name="' + k + b'"\r\n\r\n' + v + b'\r\n'
-    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/(?P<locale>[^/]+/)(?:[^/]+/)?videos?/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/(?P<locale>[^/]+)/(?:[^/]+/)?videos?/(?P<id>[^/?#&]+)'
-    }, {
+
-    def _extract_preplay_video(self, url, webpage):
+    def _extract_preplay_video(self, url, locale, webpage):
-            preplay = self._download_json('https://%s.com/en_us/preplay/%s' % (host, video_id), video_id, query=query)
+            preplay = self._download_json('https://%s.com/%s/preplay/%s' % (host, locale, video_id), video_id, query=query)
-    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/(?:[^/]+/)?videos?/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/(?P<locale>[^/]+/)(?:[^/]+/)?videos?/(?P<id>[^/?#&]+)'
-        'md5': '',
+            'description': 'md5:3927e3c79f9e8094606a2b3c5b5e55d5',
-            'timestamp': 1477941983938,
+            'timestamp': 1477941983,
-        return self._extract_preplay_video(urlh.geturl(), webpage)
+        return self._extract_preplay_video(urlh.geturl(), locale, webpage)
-    _VALID_URL = r'https?://(?:www\.)?viceland\.com/[^/]+/video/[^/]+/(?P<id>[a-f0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?viceland\.com/(?P<locale>[^/]+)/video/[^/]+/(?P<id>[a-f0-9]+)'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        return self._extract_preplay_video(url, webpage)
+        return self._extract_preplay_video(url, locale, webpage)
-        PLAYER_REGEX = r'<iframe src="(?P<xml_root>.+?)/player.*?\.html.*?".*?</iframe>'
+        PLAYER_REGEX = r'<iframe src="(?P<xml_root>.+?)/(?:gdc-)?player.*?\.html.*?".*?</iframe>'
-                r'<a[^>]+href=["\']#video-\d+["\'][^>]+data-coveid=["\'](\d+)',
+                r'<a[^>]+href=["\']#(?:video-|part)\d+["\'][^>]+data-cove[Ii]d=["\'](\d+)',
-                tabbed_videos = re.findall(p, webpage)
+                tabbed_videos = orderedSet(re.findall(p, webpage))
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-                video_id, query={
+            stream_access_url = update_url_query(
-                'Token error: %s' % token_attrib['comment'], expected=True)
+                })
-        self._sort_formats(formats)
+        formats = self._extract_formats(token_url, video_id)
-class Laola1TvIE(InfoExtractor):
+class Laola1TvIE(Laola1TvEmbedIE):
-            webpage, 'iframe url'))
+        conf = self._parse_json(self._search_regex(
-            '_type': 'url',
+            'id': video_id,
-            'ie_key': 'Laola1TvEmbed',
+            'title': self._live_title(title) if is_live else title,
-        f4m_url = re.sub(r'(https?://[^/+])/i/', r'\1/z/', manifest_url).replace('/master.m3u8', '/manifest.f4m')
+        f4m_url = re.sub(r'(https?://[^/]+)/i/', r'\1/z/', manifest_url).replace('/master.m3u8', '/manifest.f4m')
-            'duration': 39
+            'duration': 39,
-            'duration': 137
+            'duration': 137,
-            webpage = self._download_webpage(
+            if need_confirm_age:
-import random
+    random_birthday,
-            })
+            video_id, query=query)
-            'description': 'md5:f88573d9d7225ada1359eaf0dbf8bcda',
+            'description': 'md5:28942e650e82ed4fcc8e4de919ee854d',
-    # ror() and calc_time_key() are reversed from a embedded swf file in KLetvPlayer.swf
+    # ror() and calc_time_key() are reversed from a embedded swf file in LetvPlayer.swf
-        return self.ror(time, 8) ^ 185025305
+        _loc2_ = 185025305
-        playstatus = play_json['playstatus']
+        playstatus = play_json['msgs']['playstatus']
-            'http://api.le.com/mms/out/video/playJson',
+            'http://player-pc.le.com/mms/out/video/playJson',
-                'Download JSON metadata for format %s' % format_id)
+                'Download JSON metadata for format %s' % format_id,
-                    formats.append(f)
+        playurl = play_json_flash['msgs']['playurl']
-            options = ['-vn', '-acodec', 'copy']
+            options.extend(['-vn', '-acodec', 'copy'])
-            options = ['-c', 'copy']
+            options.extend(['-c', 'copy'])
-        self.run_ffmpeg(filename, temp_filename, options)
+        self.run_ffmpeg_multiple_files(in_filenames, temp_filename, options)
-                thumbnail = thumbnail_data['@attributes']
+                thumbnail = thumbnail_data.get('@attributes', {})
-                    'url': self._proto_relative_url(thumbnail['url'], 'http:'),
+                    'url': self._proto_relative_url(thumbnail_url, 'http:'),
-                subtitles[lang] = [{'url': subtitle['href']}]
+                subtitle = subtitle_data.get('@attributes', {})
-            'title': 're:^æ¸æ¨éèï¼T-ARAæ ¹æ¬åä¸ä¸æ¥ï¼ [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
+            'title': 're:^æ¸æ¨éèï¼æ ¹æ¬åä¸ä¸æ¥ï¼ [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-            'title': 're:^æ¸æ¨éèï¼T-ARAæ ¹æ¬åä¸ä¸æ¥ï¼ [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
+            'title': 're:^æ¸æ¨éèï¼æ ¹æ¬åä¸ä¸æ¥ï¼ [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-            'upload_date': '20160525',
+            'upload_date': '20161018',
-            'title': 'Daily Show',
+            'title': 'Daily Show for July 03, 2015',
-            }
+            },
-            'title': "KONOSUBA -God's blessing on this wonderful world! 2 Episode 1 â Give Me Deliverance from this Judicial Injustice!",
+            'title': "KONOSUBA -God's blessing on this wonderful world! 2 Episode 1 â Give Me Deliverance From This Judicial Injustice!",
-            'episode': 'Give Me Deliverance from this Judicial Injustice!',
+            'episode': 'Give Me Deliverance From This Judicial Injustice!',
-        'url': 'http://www.foxsports.com/video?vid=432609859715',
+        'url': 'http://www.foxsports.com/tennessee/video/432609859715',
-            'id': 'i0qKWsk3qJaM',
+            'id': 'bwduI3X_TgUB',
-                r"data-player-config='([^']+)'", webpage, 'data player config'),
+            self._html_search_regex(
-            'uploader': 'ÐÑÑÑÐ¼ ÐÐ¾ÑÐºÑÑÐ½Ð¸ÐºÐ¾Ð²',
+            'uploader': 'Artyom Loskutnikov',
-__version__ = '2017.04.28'
+__version__ = '2017.05.01'
-        if http_audio_url is None:
+        http_audio_url = fields.get('filename')
-                    (<video\s+[^>]*data-video-id=['"]?[^>]+>)
+                    (<video\s+[^>]*\bdata-video-id\s*=\s*['"]?[^>]+>)
-    
+
-                
+
-    int_or_none
+    int_or_none,
-    _VALID_URL = r'http://(?:www\.)?zaq1\.pl/video/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?zaq1\.pl/video/(?P<id>[^/?#&]+)'
-        'md5': '1245973520adc78139928a820959d9c5',
+        # malformed JSON-LD
-            'title': 'DIY Inspiration Challenge #86 | koraliki | gwiazdka na choinkÄ z koralikÃ³w i drutu',
+            'id': 'x81vn',
-            'duration': 438,
+            'duration': 6234,
-        }
+            'upload_date': '20170429',
-            r'(?s)<h1>\s*<span.+class="watch-title".+title="([^"]+)">\1\s*</span>\s*</h1>', webpage, 'title')
+        video_url = self._search_regex(
-        video_url = self._search_regex(r'data-video-url="(http[^"]+)"', div, 'video url')
+        if not info.get('thumbnail'):
-        thumbnail = self._search_regex(r'data-photo-url="([^"]+)"', div, 'thumbnail', None, False)
+        if not info.get('timestamp'):
-        uploader = self._search_regex(r'<div\s+id="watch7-user-header">.*Wideo dodaÅ:\s*<a[^>]*>\s*([^<]+)\s*</a>', webpage, 'uploader')
+        if not info.get('interactionCount'):
-        return {
+        uploader = self._html_search_regex(
-                'http_headers': {'Referer': url},
+                'width': width,
-        }
+        })
-    ExtractorError,
+    ExtractorError,
-            'duration': 120,
+            'duration': 108,
-            r'<span class="duration">.*?(\d[^<]+)', webpage, 'duration', fatal=False))
+        video_duration = int_or_none(self._og_search_property(
-            req, None,
+            'https://accounts.vevo.com/token', None,
-            errnote='Unable to retrieve oauth token')
+            errnote='Unable to retrieve oauth token',
-            'http://www.vevo.com/auth', data=b'')
+            'https://accounts.vevo.com/token', post_data, headers)
-        self._api_url_template = self.http_scheme() + '//apiv2.vevo.com/%s?token=' + auth_info['access_token']
+        self._api_url_template = self.http_scheme() + '//apiv2.vevo.com/%s?token=' + auth_info['legacy_token']
-        'f4m': 'f4m',
+        'mp2t': 'ts',
-                    sub_data = sub_info['data']
+                sub_filename = subtitles_filename(filename, sub_lang, sub_format)
-                        self.to_screen('[info] Video subtitle %s.%s is already_present' % (sub_lang, sub_format))
+                    self.to_screen('[info] Writing video subtitles to: ' + sub_filename)
-                    return
+                        try:
-    _EMBED_URL = 'https?://(?:www\.)?washingtonpost\.com/video/c/embed/[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12}'
+    _EMBED_URL = r'https?://(?:www\.)?washingtonpost\.com/video/c/embed/[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12}'
-    _VALID_URL = r'https?://(?:[a-z0-9-]+\.)?noovo\.ca/videos/(?P<id>[a-z0-9-]+/[a-z0-9-]+)'
+    _VALID_URL = r'https?://(?:[^/]+\.)?noovo\.ca/videos/(?P<id>[^/]+/[^/?#&]+)'
-            'timestamp': 1491399228,
+            'description': 'md5:de3c898d1eb810f3e6243e08c8b4a056',
-        }
+            'uploader_id': '618566855001',
-        'md5': '1199e96fbb93f2d42717115f72097b6b',
+            'title': 'Ãpisode 13 : Les retrouvailles',
-        'only_matching': True
+            'uploader_id': '618566855001',
-            brightcove_id = api_content.get('data').get('contents')[0].get('brightcoveId')
+        data = self._download_json(
-        )
+        content = try_get(data, lambda x: x['contents'][0])
-        tracks, track_ids = playlist['tracks'], map(compat_str, playlist['trackIds'])
+        tracks = playlist['tracks']
-            'Anvato player data'), video_id)
+        anvplayer_data = self._parse_json(
-        phantom = PhantomJSwrapper(self)
+        phantom = PhantomJSwrapper(self, required_version='2.0')
-    def __init__(self, extractor, timeout=10000):
+    def __init__(self, extractor, required_version=None, timeout=10000):
-        webpage, _ = phantom.get(url, video_id=video_id, headers=headers)
+        webpage = self._download_webpage(url, video_id, headers=headers)
-            webpage, 'sources', group='sources'), video_id)
+            r'(["\'])?sources\1?\s*:\s*(?P<sources>{.+?}),',
-        retval = self._call_downloader(tmpfilename, info_dict)
+        try:
-from ..compat import compat_HTTPError
+from ..compat import (
-            r'platform\s*=\s*"([^"]+)"', webpage, 'platform')
+        resource_id = current_channel['data-id']
-            r'validate\s*=\s*"([^"]+)"', webpage, 'validate', default='null')
+            r'data-token=(["\'])(?P<token>(?!\1).+)\1', webpage,
-                resource_id, headers={
+                display_id, 'Downloading JSON stream', headers={
-        formats = self._extract_m3u8_formats(response['stream'], resource_id, 'mp4')
+        formats = self._extract_m3u8_formats(response['stream'], display_id, 'mp4')
-    html = re.sub(r'<\s*/\s*p\s*>\s*<\s*p[^>]*>', '\n', html)
+    html = re.sub(r'(?u)\s*<\s*br\s*/?\s*>\s*', '\n', html)
-__version__ = '2017.04.26'
+__version__ = '2017.04.28'
-            elif url_parts_len == 2:
+                if entries:
-                        episode_attributes['data-videoid']))
+                        episode_attributes.get('data-videoid') or episode_attributes.get('data-video-id')))
-    _VALID_URL = r'https?://(?:(?P<sub_domain>%s)\.)?go\.com/(?:[^/]+/)*(?:vdka(?P<id>\w+)|(?:[^/]+/)*(?P<display_id>[^/?#]+))' % '|'.join(_SITE_INFO.keys())
+    _VALID_URL = r'https?://(?:(?P<sub_domain>%s)\.)?go\.com/(?:(?:[^/]+/)*(?P<id>vdka\w+)|(?:[^/]+/)*(?P<display_id>[^/?#]+))' % '|'.join(_SITE_INFO.keys())
-        'url': 'http://abc.go.com/shows/castle/video/most-recent/vdka0_g86w5onx',
+        'url': 'http://abc.go.com/shows/designated-survivor/video/most-recent/VDKA3807643',
-            'id': '0_g86w5onx',
+            'id': 'VDKA3807643',
-            'description': 'md5:7dcdab3b2d17e5217c953256af964e9c',
+            'title': 'The Traitor in the White House',
-        'only_matching': True,
+        'url': 'http://watchdisneyxd.go.com/doraemon',
-            video_id)['video'][0]
+                r'data-video-id=["\']*(VDKA\w+)', webpage, 'video id', default=None)
-                    video_id, data=urlencode_postdata(data), headers=self.geo_verification_headers())
+                    video_id, data=urlencode_postdata(data))
-                                    [r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\.js', r'(?:www|player)-([^/]+)/base\.js'],
+                                    [r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\.js',
-            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?|/base)?\.(?P<ext>[a-z]+)$',
+            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?|(?:/[a-z]{2}_[A-Z]{2})?/base)?\.(?P<ext>[a-z]+)$',
-            'upload_date': '20161124',
+            'timestamp': int,
-                'thumbnail': r're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg(?:\?.*?)?$',
-                    'title': title,
+                    'title': title if one else '%s (part %d)' % (title, file_num),
-        'md5': 'bc73c8ab3838b5a8fc6c6651fa7b58ba',
+        'md5': '0869000b4ce265e8ca62738b336b268a',
-            'description': 'md5:b4544662605877edd99df22f9620d858',
+            'description': 'md5:89e7c77bf5d965dd5c0372cfb49470f6',
-        'md5': '10d0f2799111df4cb1c924520ca78f98',
+        'md5': 'e7c38568a01ea45402570e6029206723',
-            'thumbnail': 'http://is5.mzstatic.com/image/thumb/Video5/v4/78/61/c5/7861c5fa-ad6d-294b-1464-cf7605b911d6/source/1920x1080sr.jpg',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'uploader': 'Steve Czaban',
+            'uploader': 'SB Nation A.M.',
-            'md5': '0d0e918533bbd4b263f2de4d197d4aac',
+            'md5': '6e52cbb513c405e403dbacb7aacf8747',
-            'description': 'md5:825e94e0f3521df52fa83b2ed198fa20',
+            'description': 'md5:b1601e2314c4d8eec23b6eafe086a757',
-        'md5': '8c2c12e3af7805152675446c905d159b',
+        'md5': '2e4b0a997f9228ffa31fada5c53d1ed1',
-            'ext': 'mp4',
+            'ext': 'flv',
-        'md5': '46c384def73b33dbc581262e5ee67cef',
+        'md5': 'a1a1b1a8bc70a89e49ccfd113aed0820',
-        'md5': '73d0b3171568232574e45652f8720b5c',
+        'md5': '0369ace6b939f0927e62c67a1a8d9fa7',
-            'uploader': 'Ben Prunty Music',
+            'ext': 'aiff',
-            'ext': 'flv',
+            'ext': 'mp4',
-                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/index_0_av.m3u8?null=0',
+                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/master.m3u8?caption=2017%2F16%2F156589847-1492488987.m3u8%3Afra%3AFrancais&audiotrack=0%3Afra%3AFrancais',
-                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/index_1_av.m3u8?null=0',
+                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/master.m3u8?caption=2017%2F16%2F156589847-1492488987.m3u8%3Afra%3AFrancais&audiotrack=0%3Afra%3AFrancais',
-                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/index_2_av.m3u8?null=0',
+                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/master.m3u8?caption=2017%2F16%2F156589847-1492488987.m3u8%3Afra%3AFrancais&audiotrack=0%3Afra%3AFrancais',
-                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/index_3_av.m3u8?null=0',
+                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/master.m3u8?caption=2017%2F16%2F156589847-1492488987.m3u8%3Afra%3AFrancais&audiotrack=0%3Afra%3AFrancais',
-                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/index_4_av.m3u8?null=0',
+                    'manifest_url': 'http://replayftv-vh.akamaihd.net/i/streaming-adaptatif_france-dom-tom/2017/S16/J2/156589847-58f59130c1f52-,standard1,standard2,standard3,standard4,standard5,.mp4.csmil/master.m3u8?caption=2017%2F16%2F156589847-1492488987.m3u8%3Afra%3AFrancais&audiotrack=0%3Afra%3AFrancais',
-                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/hls/CONAN_020217_Highlight_show-audio-64k_v4.m3u8',
+                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/main.m3u8',
-                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/hls/CONAN_020217_Highlight_show-400k_v4.m3u8',
+                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/main.m3u8',
-                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/hls/CONAN_020217_Highlight_show-400k_v4.m3u8',
+                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/main.m3u8',
-                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/hls/CONAN_020217_Highlight_show-1m_v4.m3u8',
+                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/main.m3u8',
-                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/hls/CONAN_020217_Highlight_show-2m_v4.m3u8',
+                    'manifest_url': 'http://ak.storage-w.teamcococdn.com/cdn/2017-02/98599/ed8f/main.m3u8',
-                    'manifest_url': 'http://k.toggle.sg/fhls/p/2082311/sp/208231100/serveFlavor/entryId/0_89q6e8ku/v/2/pv/1/flavorId/0_qlk9hlzr/name/a.mp4/index.m3u8',
+                    'manifest_url': 'http://cdnapi.kaltura.com/p/2082311/sp/208231100/playManifest/protocol/http/entryId/0_89q6e8ku/format/applehttp/tags/mobile_sd/f/a.m3u8',
-                    'manifest_url': 'http://k.toggle.sg/fhls/p/2082311/sp/208231100/serveFlavor/entryId/0_89q6e8ku/v/2/pv/1/flavorId/0_oefackmi/name/a.mp4/index.m3u8',
+                    'manifest_url': 'http://cdnapi.kaltura.com/p/2082311/sp/208231100/playManifest/protocol/http/entryId/0_89q6e8ku/format/applehttp/tags/mobile_sd/f/a.m3u8',
-                    'manifest_url': 'http://k.toggle.sg/fhls/p/2082311/sp/208231100/serveFlavor/entryId/0_89q6e8ku/v/12/pv/1/flavorId/0_vyg9pj7k/name/a.mp4/index.m3u8',
+                    'manifest_url': 'http://cdnapi.kaltura.com/p/2082311/sp/208231100/playManifest/protocol/http/entryId/0_89q6e8ku/format/applehttp/tags/mobile_sd/f/a.m3u8',
-                    'manifest_url': 'http://k.toggle.sg/fhls/p/2082311/sp/208231100/serveFlavor/entryId/0_89q6e8ku/v/12/pv/1/flavorId/0_50n4psvx/name/a.mp4/index.m3u8',
+                    'manifest_url': 'http://cdnapi.kaltura.com/p/2082311/sp/208231100/playManifest/protocol/http/entryId/0_89q6e8ku/format/applehttp/tags/mobile_sd/f/a.m3u8',
-                    'manifest_url': 'https://vod.edgecast.hls.ttvnw.net/e5da31ab49_riotgames_15001215120_261543898/audio_only/index-muted-HM49I092CC.m3u8',
+                    'manifest_url': 'https://usher.ttvnw.net/vod/6528877?allow_source=true&allow_audio_only=true&allow_spectre=true&player=twitchweb&nauth=%7B%22user_id%22%3Anull%2C%22vod_id%22%3A6528877%2C%22expires%22%3A1492887874%2C%22chansub%22%3A%7B%22restricted_bitrates%22%3A%5B%5D%7D%2C%22privileged%22%3Afalse%2C%22https_required%22%3Afalse%7D&nauthsig=3e29296a6824a0f48f9e731383f77a614fc79bee',
-                    'manifest_url': 'https://vod.edgecast.hls.ttvnw.net/e5da31ab49_riotgames_15001215120_261543898/mobile/index-muted-HM49I092CC.m3u8',
+                    'manifest_url': 'https://usher.ttvnw.net/vod/6528877?allow_source=true&allow_audio_only=true&allow_spectre=true&player=twitchweb&nauth=%7B%22user_id%22%3Anull%2C%22vod_id%22%3A6528877%2C%22expires%22%3A1492887874%2C%22chansub%22%3A%7B%22restricted_bitrates%22%3A%5B%5D%7D%2C%22privileged%22%3Afalse%2C%22https_required%22%3Afalse%7D&nauthsig=3e29296a6824a0f48f9e731383f77a614fc79bee',
-                    'manifest_url': 'https://vod.edgecast.hls.ttvnw.net/e5da31ab49_riotgames_15001215120_261543898/low/index-muted-HM49I092CC.m3u8',
+                    'manifest_url': 'https://usher.ttvnw.net/vod/6528877?allow_source=true&allow_audio_only=true&allow_spectre=true&player=twitchweb&nauth=%7B%22user_id%22%3Anull%2C%22vod_id%22%3A6528877%2C%22expires%22%3A1492887874%2C%22chansub%22%3A%7B%22restricted_bitrates%22%3A%5B%5D%7D%2C%22privileged%22%3Afalse%2C%22https_required%22%3Afalse%7D&nauthsig=3e29296a6824a0f48f9e731383f77a614fc79bee',
-                    'manifest_url': 'https://vod.edgecast.hls.ttvnw.net/e5da31ab49_riotgames_15001215120_261543898/medium/index-muted-HM49I092CC.m3u8',
+                    'manifest_url': 'https://usher.ttvnw.net/vod/6528877?allow_source=true&allow_audio_only=true&allow_spectre=true&player=twitchweb&nauth=%7B%22user_id%22%3Anull%2C%22vod_id%22%3A6528877%2C%22expires%22%3A1492887874%2C%22chansub%22%3A%7B%22restricted_bitrates%22%3A%5B%5D%7D%2C%22privileged%22%3Afalse%2C%22https_required%22%3Afalse%7D&nauthsig=3e29296a6824a0f48f9e731383f77a614fc79bee',
-                    'manifest_url': 'https://vod.edgecast.hls.ttvnw.net/e5da31ab49_riotgames_15001215120_261543898/high/index-muted-HM49I092CC.m3u8',
+                    'manifest_url': 'https://usher.ttvnw.net/vod/6528877?allow_source=true&allow_audio_only=true&allow_spectre=true&player=twitchweb&nauth=%7B%22user_id%22%3Anull%2C%22vod_id%22%3A6528877%2C%22expires%22%3A1492887874%2C%22chansub%22%3A%7B%22restricted_bitrates%22%3A%5B%5D%7D%2C%22privileged%22%3Afalse%2C%22https_required%22%3Afalse%7D&nauthsig=3e29296a6824a0f48f9e731383f77a614fc79bee',
-                    'manifest_url': 'https://vod.edgecast.hls.ttvnw.net/e5da31ab49_riotgames_15001215120_261543898/chunked/index-muted-HM49I092CC.m3u8',
+                    'manifest_url': 'https://usher.ttvnw.net/vod/6528877?allow_source=true&allow_audio_only=true&allow_spectre=true&player=twitchweb&nauth=%7B%22user_id%22%3Anull%2C%22vod_id%22%3A6528877%2C%22expires%22%3A1492887874%2C%22chansub%22%3A%7B%22restricted_bitrates%22%3A%5B%5D%7D%2C%22privileged%22%3Afalse%2C%22https_required%22%3Afalse%7D&nauthsig=3e29296a6824a0f48f9e731383f77a614fc79bee',
-                    'manifest_url': 'https://cdn1-a.production.vidio.static6.com/uploads/165683/dj_ambred-4383-b300.mp4.m3u8',
+                    'manifest_url': 'https://www.vidio.com/videos/165683/playlist.m3u8',
-                    'manifest_url': 'https://cdn1-a.production.vidio.static6.com/uploads/165683/dj_ambred-4383-b600.mp4.m3u8',
+                    'manifest_url': 'https://www.vidio.com/videos/165683/playlist.m3u8',
-                    'manifest_url': 'https://cdn1-a.production.vidio.static6.com/uploads/165683/dj_ambred-4383-b1200.mp4.m3u8',
+                    'manifest_url': 'https://www.vidio.com/videos/165683/playlist.m3u8',
-                'upload_date': '20140117',
+                'upload_date': '20170208',
-        'md5': '720563e467b86374c194bdead08d207d',
+        'md5': 'b9a5dc46294154c1193e2d10e0c95693',
-    def _extract_video_info(self, content_id):
+    def _extract_video_info(self, content_id, site='cbs', mpx_acc=2198311517):
-            content_id, query={'partner': 'cbs', 'contentId': content_id})
+            content_id, query={'partner': site, 'contentId': content_id})
-        tp_path = 'dJ5BDC/media/guid/2198311517/%s' % content_id
+        tp_path = 'dJ5BDC/media/guid/%d/%s' % (mpx_acc, content_id)
-from ..compat import compat_urllib_parse
+from .cbs import CBSIE
-class CBSInteractiveIE(ThePlatformIE):
+class CBSInteractiveIE(CBSIE):
-            'id': '56f4ea68-bd21-4852-b08c-4de5b8354c60',
+            'id': 'R49SYt__yAfmlXR85z4f7gNmCBDcN_00',
-            'format': 'mp4',
+            # m3u8 download
-        'md5': 'f2b16d73e08d69591dd9e25564695c0c',
+        'md5': 'f11d27b2fa18597fbf92444d2a9ed386',
-            'id': '56527b93-d25d-44e3-b738-f989ce2e49ba',
+            'id': 'kjOJd_OoVJqbg_ZD8MZCOk8Wekb9QccK',
-            'description': 'Khail and Ashley wonder what other civic woes can be solved by self-tweeting objects, investigate a new kind of VR camera and watch an origami robot self-assemble, walk, climb, dig and dissolve. #TDPothole',
+            'description': 'md5:d2b9a95a5ffe978ae6fbd4cf944d618f',
-            'id': 'bc1af9f0-a2b5-4e54-880d-0d95525781c0',
+            'id': 'k0r4T_ehht4xW_hAOqiVQPuBDPZ8SRjt',
-        }
+        },
-    TP_RELEASE_URL_TEMPLATE = 'http://link.theplatform.com/s/kYEXFC/%s?mbr=true'
+
-        'cnet': 2288573011,
+        'cnet': 2198311517,
-        video_id = vdata['id']
+        video_id = vdata['mpxRefId']
-        info = self._extract_theplatform_metadata('kYEXFC/%s' % media_guid_path, video_id)
+        info = self._extract_video_info(video_id, site, self.MPX_ACCOUNTS[site])
-            'formats': formats,
+            'description': 'md5:c18552e41726ee95bd75210d1ca9194c',
-        'md5': '17a61eb813539abea40618d6323a7f82',
+        'md5': '33fcd8f6719b9dd60a5e73adcb83b9f6',
-            'ext': 'flv',
+            'ext': 'mp4',
-                        self.assertEqual(md5_for_file, tc['md5'])
+                        self.assertEqual(tc['md5'], md5_for_file)
-                else:
+                if tbr is not None:
-        formats = [self._m3u8_meta_format(m3u8_url, ext, preference, m3u8_id)]
+        formats = []
-                    'manifest_url': manifest_url,
+                    'manifest_url': m3u8_url,
-            m3u8_formats))
+            lambda f: f.get('vcodec') != 'none', m3u8_formats))
-                            m3u8_formats))
+                            lambda f: f.get('vcodec') != 'none', m3u8_formats))
-            lambda f: f.get('protocol') == 'm3u8_native' and f.get('vcodec') != 'none' and f.get('resolution') != 'multiple',
+            lambda f: f.get('protocol') == 'm3u8_native' and f.get('vcodec') != 'none',
-            lambda f: f.get('protocol') == 'm3u8' and f.get('vcodec') != 'none' and f.get('resolution') != 'multiple',
+            lambda f: f.get('protocol') == 'm3u8' and f.get('vcodec') != 'none',
-                formats))
+                lambda f: f.get('vcodec') != 'none', formats))
-            lambda f: f.get('protocol') == 'm3u8' and f.get('vcodec') != 'none' and f.get('resolution') != 'multiple',
+            lambda f: f.get('protocol') == 'm3u8' and f.get('vcodec') != 'none',
-                m3u8_formats))
+                lambda f: f.get('vcodec') != 'none', m3u8_formats))
-                            m3u8_formats))
+                            lambda f: f.get('vcodec') != 'none', m3u8_formats))
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'upload_date': '20151201',
+            'timestamp': 1449129925,
-        for (fkey, vid) in vdata['files'].items():
+        for (fkey, vid) in vdata.get('files', {}).items():
-            'id': 'blackthorn',
+            'id': '4489',
-        'playlist_mincount': 80,
+        'playlist_mincount': 30,
-    _VALID_URL = r'https?://streamable\.com/(?:e/)?(?P<id>\w+)'
+    _VALID_URL = r'https?://streamable\.com/(?:[es]/)?(?P<id>\w+)'
-    _VALID_URL = r'https?://(?:(?:www|sites)\.)?arte\.tv/[^/]+/(?P<lang>fr|de|en|es)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:(?:www|sites)\.)?arte\.tv/(?:[^/]+/)?(?P<lang>fr|de|en|es)/(?:videos/)?(?:[^/]+/)*(?P<id>[^/?#&]+)'
-__version__ = '2017.04.17'
+__version__ = '2017.04.26'
-            r'(?s)jwplayer\((?P<quote>[\'"])[^\'" ]+(?P=quote)\).*?\.setup\s*\((?P<options>[^)]+)\)',
+            r'(?s)jwplayer\((?P<quote>[\'"])[^\'" ]+(?P=quote)\)(?!</script>).*?\.setup\s*\((?P<options>[^)]+)\)',
-                index:  Index of current fragment among all fragments
+                index:  0-based index of current fragment among all fragments
-        'only_matching': True,
+        'info_dict': {
-            r'data-player-tvid\s*=\s*[\'"](\d+)', webpage, 'tvid', default=None)
+            r'data-(?:player|shareplattrigger)-tvid\s*=\s*[\'"](\d+)', webpage, 'tvid', default=None)
-            r'data-player-videoid\s*=\s*[\'"]([a-f\d]+)', webpage, 'video_id')
+            r'data-(?:player|shareplattrigger)-videoid\s*=\s*[\'"]([a-f\d]+)', webpage, 'video_id')
-                 clean_html(get_element_by_attribute('class', 'mod-play-tit', webpage)))
+                 clean_html(get_element_by_attribute('class', 'mod-play-tit', webpage)) or
-    def _set_cookie(self, domain, name, value, expire_time=None):
+    def _set_cookie(self, domain, name, value, expire_time=None, port=None,
-            None, '/', True, False, expire_time, '', None, None, None)
+            0, name, value, port, not port is None, domain, True,
-    _TMP_FILE_NAMES = ['script', 'html']
+    _TMP_FILE_NAMES = ['script', 'html', 'cookies']
-    encodeArgument,
+    get_element_by_id,
-        });'''
+    _USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'
-        webpage = self._download_webpage(url, video_id)
+        headers = {
-        os.remove(script_file.name)
+        decoded_id = get_element_by_id('streamurl', webpage)
-        ctx['fragment_index'] = json.loads(stream.read())['download']['current_fragment_index']
+        ctx['fragment_index'] = json.loads(stream.read())['downloader']['current_fragment']['index']
-                'current_fragment_index': ctx['fragment_index']
+        downloader = {
-        }))
+        }
-            if not (ctx.get('live') or ctx['tmpfilename'] == '-'):
+            if self.__do_ytdl_file(ctx):
-            self._write_ytdl_file(ctx)
+        # Should be initialized before ytdl file check
-            assert resume_len == 0
+        if self.__do_ytdl_file(ctx):
-            os.remove(ytdl_filename)
+        if self.__do_ytdl_file(ctx):
-            os.remove(ctx['fragment_filename_sanitized'])
+            if not self.params.get('keep_fragments', False):
-import io
+    def _read_ytdl_file(self, ctx):
-        success = ctx['dl'].download(down, {
+        fragment_filename = '%s-Frag%d' % (ctx['tmpfilename'], ctx['fragment_index'])
-        frag_content = down.getvalue()
+        down, frag_sanitized = sanitize_open(fragment_filename, 'rb')
-            frag_index_stream.close()
+        try:
-        frag_index = 0
+
-                frag_index_stream.close()
+
-    def real_download(self, filename_or_stream, info_dict):
+    def real_download(self, filename, info_dict):
-            filename = '-'
+        stream = None
-                'upload_year', 'upload_month', 'upload_day',
+                'timestamp', 'upload_year', 'upload_month', 'upload_day',
-            # test_parse_m3u8_formats) it still sometimes may be present
+            # EXT-X-STREAM-INF tag it still sometimes may be present (see [1]
-                    'tbr': 155,
+                    'tbr': 155.648,
-                    'tbr': 502,
+                    'tbr': 502.784,
-                    'tbr': 827,
+                    'tbr': 827.392,
-                    'tbr': 1396,
+                    'tbr': 1396.736,
-                    'tbr': 182,
+                    'tbr': 182.725,
-                    'tbr': 280,
+                    'tbr': 280.474,
-                    'tbr': 628,
+                    'tbr': 628.347,
-                    'tbr': 893,
+                    'tbr': 893.387,
-                    'tbr': 1603,
+                    'tbr': 1603.789,
-                    'tbr': 3214,
+                    'tbr': 3214.134,
-            # EXT-X-STREAM-INF it still sometimes may be present
+            # EXT-X-STREAM-INF tag (see [1] or vidio test in
-        formats = self._extract_m3u8_formats(m3u8_url, display_id, 'mp4', entry_protocol='m3u8_native')
+            r'data(?:-vjs)?-clip-hls-url=(["\'])(?P<url>(?!\1).+)\1',
-                tbr = int_or_none(last_stream_inf.get('AVERAGE-BANDWIDTH') or last_stream_inf.get('BANDWIDTH'), scale=1000)
+                tbr = float_or_none(
-                            'tbr': int_or_none(bandwidth, 1000),
+                            'tbr': float_or_none(bandwidth, 1000),
-                    (<video\s+[^>]+>)
+                    (<video\s+[^>]*data-video-id=['"]?[^>]+>)
-            if frag_index <= ctx['frag_index']:
+            if frag_index <= ctx['fragment_index']:
-            if frag_index <= ctx['frag_index']:
+            if frag_index <= ctx['fragment_index']:
-                'frag_index': ctx['frag_index']
+                'download': {
-                frag_index = json.loads(frag_index_stream.read())['frag_index']
+                frag_index = json.loads(frag_index_stream.read())['download']['last_fragment_index']
-            'frag_index': frag_index,
+            'fragment_index': frag_index,
-            'frag_count': total_frags,
+            'fragment_index': ctx['fragment_index'],
-                    (state['frag_index'] + 1) * total_frags)
+                    (state['fragment_index'] + 1) * total_frags)
-                ctx['frag_index'] = state['frag_index']
+                state['fragment_index'] += 1
-                    if frag_index <= ctx['frag_index']:
+                    if frag_index <= ctx['fragment_index']:
-            if frag_index <= ctx['frag_index']:
+            if frag_index <= ctx['fragment_index']:
-
+        # Sometimes there are playlist links in individual videos, so treat it
-            r'data-player-tvid\s*=\s*[\'"](\d+)', webpage, 'tvid')
+            r'data-player-tvid\s*=\s*[\'"](\d+)', webpage, 'tvid', default=None)
-        if method == Socks5Auth.AUTH_NO_ACCEPTABLE:
+        if method == Socks5Auth.AUTH_NO_ACCEPTABLE or (
-            raise Socks5Error(method)
+            raise Socks5Error(Socks5Auth.AUTH_NO_ACCEPTABLE)
-        'md5': '6df8f6d028bc8b14f5dbd73af742fb20',
+        'md5': '7fcdb5349354f40d41689bd0fa8db05a',
-            r'file=([^&]+)&', info_cn, 'url'))
+        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]
-        return {
+        info_dict.update({
-        }
+        })
-from test.helper import FakeYDL, expect_dict
+from test.helper import FakeYDL, expect_dict, expect_value
-
+
-        # without qualities renditions.
+        # References:
-        # 3. https://tools.ietf.org/html/draft-pantos-http-live-streaming-17#section-4.3.3.1
+        # playlist based on particular tags availability. As of [1, 4.3.3, 4.3.4]
-        last_media = {}
+
-                last_info = parse_m3u8_attributes(line)
+                last_stream_inf = parse_m3u8_attributes(line)
-                            audio_in_video_stream[group_id] = True
+                extract_media(line)
-                tbr = int_or_none(last_info.get('AVERAGE-BANDWIDTH') or last_info.get('BANDWIDTH'), scale=1000)
+                tbr = int_or_none(last_stream_inf.get('AVERAGE-BANDWIDTH') or last_stream_inf.get('BANDWIDTH'), scale=1000)
-                stream_name = last_info.get('NAME') or last_media.get('NAME')
+                stream_name = build_stream_name()
-                    'fps': float_or_none(last_info.get('FRAME-RATE')),
+                    'fps': float_or_none(last_stream_inf.get('FRAME-RATE')),
-                resolution = last_info.get('RESOLUTION')
+                resolution = last_stream_inf.get('RESOLUTION')
-                    f['acodec'] = 'none'
+                codecs = parse_codecs(last_stream_inf.get('CODECS'))
-                last_media = {}
+                last_stream_inf = {}
-            code = decode_packed_codes(pc).replace('\\\'', '\'')
+        codes = [webpage]
-                    default=NO_DEFAULT if num == len(packed_codes) else '{}'),
+                    default=NO_DEFAULT if num == len(codes) else '{}'),
-        item = self._download_json(
+        feed = self._download_json(
-            'Unable to download Akamai AMP feed')['channel']['item']
+            'Unable to download Akamai AMP feed')
-            frag_index_stream.write(compat_str(ctx['frag_index']))
+            frag_index_stream, _ = sanitize_open(self.ytdl_filename(ctx['filename']), 'w')
-                frag_index = int(frag_index_stream.read())
+            ytdl_filename = encodeFilename(self.ytdl_filename(ctx['filename']))
-            os.remove(encodeFilename(ctx['tmpfilename'] + '.fragindex'))
+        ytdl_filename = encodeFilename(self.ytdl_filename(ctx['filename']))
-        return [url for _, url in re.findall(
+        return [src for _, src in re.findall(
-        'ttaf1_0604': 'http://www.w3.org/2006/04/ttaf1',
+        'tts': 'http://www.w3.org/ns/ttml#styling',
-        out = ''
+        _out = ''
-                self.out += '\n'
+            if tag in (_x('ttml:br'), 'br'):
-            pass
+            if tag not in (_x('ttml:br'), 'br'):
-            self.out += data
+            self._out += data
-            return self.out.strip()
+            return self._out.strip()
-    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall(_x('.//ttaf1:p')) or dfxp.findall(_x('.//ttaf1_0604:p')) or dfxp.findall('.//p')
+    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall('.//p')
-            return True
+        if not hasattr(filename, 'write'):
-            target_filename = '%s-%s' % (tmp_filename, segment_name)
+        frag_index = 0
-            fatal = num == 0 or not skip_unavailable_fragments
+            fatal = i == 0 or not skip_unavailable_fragments
-                    })
+                    success, frag_content = self._download_fragment(ctx, segment['url'], info_dict)
-                    segments_filenames.append(target_sanitized)
+                    self._append_fragment(ctx, frag_content)
-                        self.report_retry_fragment(err, segment_name, count, fragment_retries)
+                        self.report_retry_fragment(err, frag_index, count, fragment_retries)
-                    return True
+                    self.report_skip_fragment(frag_index)
-            write_metadata_tag(dest_stream, metadata)
+        if ctx['complete_frags_downloaded_bytes'] == 0:
-        frags_filenames = []
+        frag_index = 0
-                })
+                success, down_data = self._download_fragment(ctx, url_parsed.geturl(), info_dict)
-                        dest_stream.write(box_data)
+                        self._append_fragment(ctx, box_data)
-
+import io
-    def report_retry_fragment(self, err, fragment_name, count, retries):
+    def report_retry_fragment(self, err, frag_index, count, retries):
-            % (error_to_compat_str(err), fragment_name, count, self.format_retries(retries)))
+            '[download] Got server HTTP error: %s. Retrying fragment %d (attempt %d of %s)...'
-        self.to_screen('[download] Skipping fragment %s...' % fragment_name)
+    def report_skip_fragment(self, frag_index):
-        dest_stream, tmpfilename = sanitize_open(tmpfilename, 'wb')
+        open_mode = 'wb'
-            'frag_index': 0,
+            'downloaded_bytes': ctx['complete_frags_downloaded_bytes'],
-            'complete_frags_downloaded_bytes': 0,
+                ctx['frag_index'] = state['frag_index']
-        frags_filenames = []
+        frag_index = 0
-                            })
+                            success, frag_content = self._download_fragment(
-                                self.report_retry_fragment(err, frag_name, count, fragment_retries)
+                                self.report_retry_fragment(err, frag_index, count, fragment_retries)
-                            self.report_skip_fragment(frag_name)
+                            self.report_skip_fragment(frag_index)
-                    frags_filenames.append(frag_sanitized)
+                    self._append_fragment(ctx, frag_content)
-                        decrypt_info['KEY'] = self.ydl.urlopen(decrypt_info['URI']).read()
+                        if decrypt_url != decrypt_info['URI']:
-    def real_download(self, filename, info_dict):
+    def real_download(self, filename_or_stream, info_dict):
-        tmpfilename = self.temp_name(filename)
+        filename = filename_or_stream
-
+        frag_index = 0
-            target_filename = '%s-%s' % (ctx['tmpfilename'], segment_name)
+            frag_index += 1
-                        tfhd_data = extract_box_data(down_data, [b'moof', b'traf', b'tfhd'])
+                        tfhd_data = extract_box_data(frag_content, [b'moof', b'traf', b'tfhd'])
-                    segments_filenames.append(target_sanitized)
+                    self._append_fragment(ctx, frag_content)
-                        self.report_retry_fragment(err, segment_name, count, fragment_retries)
+                        self.report_retry_fragment(err, frag_index, count, fragment_retries)
-                    self.report_skip_fragment(segment_name)
+                    self.report_skip_fragment(frag_index)
-        'md5': '9676cf86eff5391d35dea675d224e131',
+        'md5': '6ff470ea2dd51d5d18c295a355b0b6bc',
-        'md5': '5d7475d428845cd2e13bae6f1a992278',
+        'md5': '2f206894ffb5dbfcce2c5a14b909eea5',
-            'uploader': 'ÐÐ»Ð¸Ð½Ð° Ð',
+            'uploader_id': 'tvroscosmos',
-        ('vidlo.us', 'vidlo'),
+        (r'daclips\.(?:in|com)', 'DaClips'),
-                  % '|'.join(re.escape(site) for site in list(zip(*_SITES))[0]))
+                  % '|'.join(site for site in list(zip(*_SITES))[0]))
-         uploader_id, like_count, comment_count, height, width) = [None] * 10
+         uploader_id, like_count, comment_count, comments, height,
-                shared_data, lambda x: x['entry_data']['PostPage'][0]['media'], dict)
+                shared_data,
-            return v
+    if not isinstance(getter, (list, tuple)):
-                    })
+                    extract_video_object(e)
-            for custom_bc in re.findall(r'(customBC\.createVideo\(.+?\);)', webpage)]))
+        matches = re.findall(r'(customBC\.createVideo\(.+?\);)', webpage)
-        urls = BrightcoveNewIE._extract_urls(webpage)
+    def _extract_url(ie, webpage):
-                        bc_url = BrightcoveNewIE._extract_url(player_code)
+                        bc_url = BrightcoveNewIE._extract_url(self, player_code)
-        bc_url = BrightcoveNewIE._extract_url(webpage)
+        bc_url = BrightcoveNewIE._extract_url(self, webpage)
-            r'jwplayer\((?P<quote>[\'"])[^\'" ]+(?P=quote)\)\.setup\s*\((?P<options>[^)]+)\)',
+            r'(?s)jwplayer\((?P<quote>[\'"])[^\'" ]+(?P=quote)\).*?\.setup\s*\((?P<options>[^)]+)\)',
-            source_url = self._proto_relative_url(source['file'])
+            source_url = self._proto_relative_url(source.get('file'))
-        quality = qualities(('mobile', 'lowest', 'low', 'sd', 'hd', 'full'))
+        quality = qualities(('4', '0', '1', '2', '3', '5'))
-            'quality': quality(f['name']),
+
-__version__ = '2017.04.16'
+__version__ = '2017.04.17'
-                            value=(["\'])(?:(?!\3).)*mediaId=(?P<id>[a-z0-9]{32})
+                            value=(["\'])(?:(?!\3).)*(?P<kind>media|channel(?:List)?)Id=(?P<id>[a-z0-9]{32})
-                    'limelight:media:%s' % mobj.group('id'),
+                    'limelight:%s:%s' % (kind, video_id),
-                'LimelightMedia', mobj.group('id')))
+                'Limelight%s' % kind.capitalize(), video_id))
-        return {
+        info = self._search_json_ld(webpage, video_id, default={})
-        }
+        })
-            formats.append({
+            f = {
-                'url': rtmp_url,
+                # Providing this swfVfy allows to avoid truncated downloads
-            })
+            }
-                        formats.extend(self._extract_m3u8_formats(href, video_id, 'mp4', m3u8_id='hls', fatal=False))
+                        formats.extend(self._extract_m3u8_formats(
-from ..compat import compat_chr
+    check_executable,
-        webpage = self._download_webpage('https://openload.co/embed/%s/' % video_id, video_id)
+        url = 'https://openload.co/embed/%s/' % video_id
-            'description', webpage, 'title', fatal=True)
+            raise ExtractorError('File not found', expected=True, video_id=video_id)
-        subtitles = entries[0]['subtitles'] if entries else None
+        entry = entries[0] if entries else {}
-            'thumbnail': self._og_search_thumbnail(webpage, default=None),
+            'thumbnail': entry.get('thumbnail') or self._og_search_thumbnail(webpage, default=None),
-            'title': 'Inside The Utah Coalition Against Pornography Convention',
+            'title': 'Daily VICE - Inside The Utah Coalition Against Pornography Convention',
-        title = video_data['title']
+        episode_number = int_or_none(video_data.get('episode_number'))
-__version__ = '2017.04.15'
+__version__ = '2017.04.16'
-            filename = tmpl % template_dict
+            filename = expand_path(outtmpl % template_dict)
-                return _make_result([{'url': TEST_URL}])
+                return _make_result([{'url': TEST_URL}], title='foo3 title')
-            assert new_result.get('_type') != 'url_transparent'
+            # Extracted info may not be a video result (i.e.
-                '_type': 'url',
+                '_type': 'url_transparent',
-    _VALID_URL = r'https?://(?:www\.)?streamango\.com/(?:f|embed)/(?P<id>.+?)/(?:.+)'
+    _VALID_URL = r'https?://(?:www\.)?streamango\.com/(?:f|embed)/(?P<id>[^/?#&]+)'
-
+
-            dashurl, video_id, mpd_id='dash', fatal=False))
+        formats = []
-        (?P<id>[a-zA-Z0-9-]+)'''
+                        (?:
-        info = self._download_json(api_url, video_id)['items'][0]
+        info = self._download_json(
-    _TESTS = [{
+    _VALID_URL = r'(?i)https?://(?:www\.)?wsj\.com/articles/(?P<id>[^/?#&]+)'
-    }]
+    }
-                                      webpage, 'video id')
+        video_id = self._search_regex(
-from .wsj import WSJIE
+from .wsj import (
-    _VALID_URL = r'''(?x)https?://
+    _VALID_URL = r'''(?x)
-            (?:www\.)?wsj\.com/video/[^/]+/
+            https?://video-api\.wsj\.com/api-video/player/iframe\.html\?guid=|
-    def _extract_urls(webpage):
+    def _extract_urls(ie, webpage):
-        ):
+                r'''(?isx)
-            # See PR#12099/bostonglobe.py for 'data-brightcove-video-id' variant
+            if not video_id:
-                    % (account_id, player_id, embed, video_id))
+                continue
-        bc_urls = BrightcoveNewIE._extract_urls(webpage)
+        bc_urls = BrightcoveNewIE._extract_urls(self, webpage)
-        # 4. https://support.brightcove.com/en/video-cloud/docs/dynamically-assigning-videos-player
+        # 2. http://docs.brightcove.com/en/video-cloud/brightcove-player/guides/publish-video.html#tag
-                % (account_id, player_id, embed, video_id))
+        # Look for <video> tags [2] and embed_in_page embeds [3]
-            self.to_screen('Brightcove video detected.')
+        subtitles = {}
-        def extract_output_format(src):
+        def extract_output_format(src, f_id):
-                'format_id': '%sp' % (src.get('height') or format_id),
+                'format_id': '%sp' % (src.get('height') or f_id),
-                output_format = extract_output_format(output)
+                output_format = extract_output_format(output, key)
-                    formats.append(f)
+            extract_formats(download_urls.get('Video'))
-            'formats': formats
+            'formats': formats,
-    HEADRequest,
+    # ExtractorError,
-__version__ = '2017.04.14'
+__version__ = '2017.04.15'
-    compat_urllib_parse_urlencode,
+    compat_str,
-            fileid = stream['segs'][0]['fileid']
+            fileid = try_get(
-            fileid = stream['stream_fileid']
+            fileid = stream['segs'][0]['fileid']
-__version__ = '2017.04.11'
+__version__ = '2017.04.14'
-    _VALID_URL = r'https?://(?:www\.)?(?P<domain>(?:history|aetv|mylifetime|lifetimemovieclub)\.com|fyi\.tv)/(?:shows/(?P<show_path>[^/]+(?:/[^/]+){0,2})|movies/(?P<movie_display_id>[^/]+)(?:/full-movie)?)'
+    _VALID_URL = r'''(?x)
-        display_id = show_path or movie_display_id
+        domain, show_path, movie_display_id, special_display_id = re.match(self._VALID_URL, url).groups()
-                    continue
+                    m3u8_formats = self._extract_m3u8_formats(
-        self._sort_formats(formats, ('width', 'height', 'tbr', 'format_id'))
+        self._sort_formats(formats)
-            r'#EXT-X-BYTERANGE',  # playlists composed of byte ranges of media files [2]
+            # r'#EXT-X-BYTERANGE',  # playlists composed of byte ranges of media files [2]
-        check_results.append(can_decrypt_frag or '#EXT-X-KEY:METHOD=AES-128' not in manifest)
+        is_aes128_enc = '#EXT-X-KEY:METHOD=AES-128' in manifest
-                                'http_headers': info_dict.get('http_headers'),
+                                'http_headers': headers,
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': r're:^https?://.*\.jpg$'
-        elif result_type == 'playlist' or result_type == 'multi_video':
+        elif result_type in ('playlist', 'multi_video'):
-    elif compat_os_name == 'nt' or compat_os_name == 'ce':
+    elif compat_os_name in ('nt', 'ce'):
-        while (retval == RD_INCOMPLETE or retval == RD_FAILED) and not test and not live:
+        while retval in (RD_INCOMPLETE, RD_FAILED) and not test and not live:
-                    if kind != 'programme' and kind != 'radioProgramme':
+                    if kind not in ('programme', 'radioProgramme'):
-            if kind != 'programme' and kind != 'radioProgramme':
+            if kind not in ('programme', 'radioProgramme'):
-                    elif content_type == 'video' or content_type == 'audio':
+                    elif content_type in ('video', 'audio'):
-    def _extract_url(self, webpage):
+    def _extract_url(cls, webpage):
-            if all(v == 'm3u8' or v == 'hls' for v in (type_, ext)):
+            if all(v in ('m3u8', 'hls') for v in (type_, ext)):
-        if status == 'LIVE_ON_AIR' or status == 'BIG_EVENT_ON_AIR':
+        if status in ('LIVE_ON_AIR', 'BIG_EVENT_ON_AIR'):
-        elif status == 'VOD_ON_AIR' or status == 'BIG_EVENT_INTRO':
+        elif status in ('VOD_ON_AIR', 'BIG_EVENT_INTRO'):
-            if ext == 'dfxp' or ext == 'ttml' or ext == 'tt':
+            if ext in ('dfxp', 'ttml', 'tt'):
-            regex += re.escape(fmt[lastpos:len(fmt)])
+            regex += re.escape(fmt[lastpos:])
-from .tv2hu import TV2HUIE
+from .tv2hu import TV2HuIE
-
+from ..utils import int_or_none
-    _JSON_URL = r'(?P<json_url>https?://.+?\.tv2\.hu/vod/(?P<upload_date>\d+)/id_(?P<upload_id>\d+).+?&type=json)'
+class TV2HuIE(InfoExtractor):
-
+        webpage = self._download_webpage(url, video_id)
-            'formats': formats
+            'thumbnail': self._og_search_thumbnail(webpage),
-            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml', 'js')
+            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml', 'js', 'xml')
-                                video_id, 'Downloading Provider Login Page')
+                                oauth_redirect_url, video_id,
-                                provider_redirect_page_res, 'Downloading Provider Login Page')
+                                provider_redirect_page_res,
-                        })
+                        mvpd_confirm_page_res = post_form(
-                        # https://signin.verizon.com/sso/choice/tvpHandler.jsp?loginType=vzRedirect&partner=<snip>
+                            provider_redirect_page,
-                        )
+                            saml_redirect_url, video_id,
-                        })
+                        saml_login_page_res = post_form(
-                    # https://signin.verizon.com/sso/TVPHandlerServlet?loginType=vzRedirect&partner=<snip>
+                            raise ExtractorError(
-
+                        headers={'Content-Type': 'text/xml'})
-                    # Normal, non-Comcast flow
+    'Verizon': {
-            for a_format in formats:
+            formats = []
-                'id': '10481652_1',
+                'id': '20160502_c4c62b9d_174361386_1',
-                'id': '10481652_2',
+                'id': '20160502_39e739bb_174361386_2',
-                    video_element.findall(compat_xpath('./file')), start=1):
+            file_elements = video_element.findall(compat_xpath('./file'))
-                    continue
+                key = file_element.get('key', '')
-                format_id = '%s_%s' % (video_id, part)
+                format_id = key if key else '%s_%s' % (video_id, file_num)
-                    'upload_date': video_key.get('upload_date'),
+                    'title': title,
-        '266': {'ext': 'mp4', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'h264', 'preference': -40},
+        '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'h264'},
-        '328': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'ec-3', 'preference': -50, 'container': 'm4a_dash'},
+        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 48, 'container': 'm4a_dash'},
-        '271': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9', 'preference': -40},
+        '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
-        '315': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60, 'preference': -40},
+        '272': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},
-        '172': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 256, 'preference': -50},
+        '171': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 128},
-        '251': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 160, 'preference': -50},
+        '249': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 50},
-        'skip': 'Only works from France',
+        'expected_warnings': ['HTTP Error 403: Forbidden'],
-        'md5': '4b47b12b4ee43002626b97fad8fb1de5',
+        # geo restricted, bypassed
-            'id': '1420213',
+            'id': '1443684',
-            'upload_date': '20161014',
+            'title': 'Guess my iep ! - TPMP - 07/04/2017',
-        'skip': 'Only works from France',
+        'expected_warnings': ['HTTP Error 403: Forbidden'],
-                    expected=True)
+        # _, fmt_url = next(iter(media['VIDEOS'].items()))
-__version__ = '2017.04.09'
+__version__ = '2017.04.11'
-            'ext': 'flv',
+            'ext': 'mp4',
-            'title': 'ì¤ëì ë¤ë¥´ë¤! ìëì ì°ìí ììë~ ëì¤ë¦¬ì¡ì!',
+            'duration': 107,
-            'skip_download': True,  # requires rtmpdump
+            'skip_download': True,
-            video_key['part'] = m.group('part')
+            video_key['part'] = int(m.group('part'))
-        app, playpath = video_url_raw.split('mp4:')
+        video_url = video_element.text.strip()
-                                          'duration'))
+        duration = int_or_none(xpath_text(
-        return {
+        common_entry = {
-            'rtmp_live': True,  # downloading won't end without this
+        if determine_ext(video_url) == 'm3u8':
-                tc_res_dict = res_dict['entries'][tc_num] if is_playlist else res_dict
+                tc_res_dict = res_dict['entries'][tc_num]
-                                'vbr': bitrate,
+                                'tbr': bitrate,
-                        if protocol == 'http':
+                        if protocol in ('http', 'https'):
-            'url': 'limelight:media:' + limelight_media_id,
+            'formats': formats,
-        'md5': 'a0074c190e6cddaf86900b28d3e9ee7a',
+        'md5': '262bb2f257ff301115f1973540de8983',
-        'playlist_mincount': 17,
+        'playlist_mincount': 12,
-            bytes_to_intlist(b'\xb5@\xcfq\xa3\x98"N\xe4\xf3\x12\x98}}\x16\xd8'),
+            bytes_to_intlist(b'\nd\xaf\xd2J\xd0\xfc\xe1\xfc\xdf\xb61\xe8\xe1\xf0\xcc'),
-            r'hlsSource(?P<id>.+?)\s*=\s*(?P<q>["\'])(?P<url>http.+?)(?P=q)', webpage)]
+        m3u8_urls = []
-        if not m3u8_formats:
+        for m in re.finditer(
-        for m3u8_id, m3u8_url in m3u8_formats:
+        for m3u8_url in m3u8_urls:
-__version__ = '2017.04.03'
+__version__ = '2017.04.09'
-    _VALID_URL = r'https?://(?:www\.)?rbmaradio\.com/shows/(?P<show_id>[^/]+)/episodes/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:rbmaradio|redbullradio)\.com/shows/(?P<show_id>[^/]+)/episodes/(?P<id>[^/?#&]+)'
-            'description': 'md5:4f340fb48426423530af5a9d87bd7b91',
+            'title': 'Main Stage - Ford & Lopatin at Primavera Sound',
-    _VALID_URL = r'https?://(?:www\.)?npo\.nl/live(/(?P<id>[^/?#&]+))?'
+    _VALID_URL = r'https?://(?:www\.)?npo\.nl/live(?:/(?P<id>[^/?#&]+))?'
-        }
+        'only_matching': True,
-    _VALID_URL = r'https?://(?:www\.)?npo\.nl/live/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?npo\.nl/live(/(?P<id>[^/?#&]+))?'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        display_id = self._match_id(url)
+        display_id = self._match_id(url) or 'npo-1'
-             r'm-tooltip=["\']([\d,.]+) plays'],
+             r'(?:m|data)-tooltip=["\']([\d,.]+) plays'],
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?mixcloud\.com/(?P<user>[^/]+)/(?P<type>uploads|favorites|listens)?/?$'
+    _VALID_URL = r'https?://(?:www\.)?mixcloud\.com/(?P<user>[^/]+)/(?P<type>uploads|favorites|listens)?/?$'
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?mixcloud\.com/(?P<user>[^/]+)/playlists/(?P<playlist>[^/]+)/?$'
+    _VALID_URL = r'https?://(?:www\.)?mixcloud\.com/(?P<user>[^/]+)/playlists/(?P<playlist>[^/]+)/?$'
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?mixcloud\.com/(?P<id>[^/]+)/stream/?$'
+    _VALID_URL = r'https?://(?:www\.)?mixcloud\.com/(?P<id>[^/]+)/stream/?$'
-            r'<div[^>]+class="description-text"[^>]*>(.+?)</div>',
+            r'<div[^>]+class="profile-bio"[^>]*>(.+?)</div>',
-            'description': 'md5:327af72d1efeb404a8216c27240d1370',
+            'description': 'md5:def36060ac8747b3aabca54924897e47',
-            'description': 'md5:327af72d1efeb404a8216c27240d1370',
+            'description': 'md5:def36060ac8747b3aabca54924897e47',
-            'description': 'md5:327af72d1efeb404a8216c27240d1370',
+            'description': 'md5:def36060ac8747b3aabca54924897e47',
-            'description': 'md5:327af72d1efeb404a8216c27240d1370',
+            'description': 'md5:def36060ac8747b3aabca54924897e47',
-        'playlist_mincount': 23
+        'only_matching': True,
-        profile = self._download_webpage(
+        webpage = self._download_webpage(
-            profile, 'playlist title')
+        title = self._html_search_regex(
-        return self.playlist_result(entries, video_id, playlist_title, description)
+        return self.playlist_result(entries, video_id, title, description)
-            r'<span[^>]+class="[^"]*list-playlist-title[^"]*"[^>]*>(.*?)</span>',
+            r'<a class="parent active" href="[^"]*"><b>\d+</b><span title="[^"]*">([^</]*?)</span></a>',
-    _VALID_URL = r'https://(?:www\.)?thesun\.co\.uk/\w+/(?P<id>\d+)/[\w-]'
+    _VALID_URL = r'https://(?:www\.)?thesun\.co\.uk/[^/]+/(?P<id>\d+)'
-        }
+            'id': '2261604',
-        video_id = self._match_id(url)
+        article_id = self._match_id(url)
-        ooyala_id = self._search_regex(r'id\s*=\s*"thesun-ooyala-player-([^"]+)"', webpage, 'ooyala id')
+        entries = []
-        return OoyalaIE._build_url_result(ooyala_id)
+        return self.playlist_result(
-from .ceskatelevize import CeskaTelevizeIE
+from .ceskatelevize import (
-    _VALID_URL = r'https?://(?:www\.)?ceskatelevize\.cz/(porady|ivysilani)/(?:[^/]+/)*(?P<id>[^/#?]+)/*(?:[#?].*)?$'
+    _VALID_URL = r'https?://(?:www\.)?ceskatelevize\.cz/ivysilani/(?:[^/?#&]+/)*(?P<id>[^/#?]+)'
-        },
+        'url': 'http://www.ceskatelevize.cz/ivysilani/embed/iFramePlayer.php?hash=d6a3e1370d2e4fa76296b90bad4dfc19673b641e&IDEC=217 562 22150/0004&channelID=1&width=100%25',
-        playlist_id = mobj.group('id')
+        playlist_id = self._match_id(url)
-            r'getPlaylistUrl\(\[\{"type":".+?","id":"(.+?)"\}\],', webpage, 'episode_id')
+        type_ = None
-            'playlist[0][type]': typ,
+            'playlist[0][type]': type_,
-                        (?P<q4>['\"])(?P<id>(?:(?!(?P=q4)).)+)(?P=q4)(?:,|\s*\})
+                        (?P<q1>['"])wid(?P=q1)\s*:\s*
-                    (?P<q1>["\'])
+                    (?P<q1>["'])
-                        (?P<q2>["\'])entry_?[Ii]d(?P=q2)
+                        (?P<q2>["'])entry_?[Ii]d(?P=q2)
-                    (?P<q3>["\'])(?P<id>(?:(?!(?P=q3)).)+)(?P=q3)
+                    (?P<q3>["'])(?P<id>(?:(?!(?P=q3)).)+)(?P=q3)
-                      (?:https?:)?//(?:www\.)?kaltura\.com/p/(?P<partner_id>\d+)/
+                    <iframe[^>]+src=(?P<q1>["'])
-                      [\?&]entry_id=(?P<id>(?:(?!(?P=q1))[^&])+)
+                      [?&]entry_id=(?P<id>(?:(?!(?P=q1))[^&])+)
-                ''', webpage))
+                ''', webpage) or
-    _VALID_URL = r'https?://(?:www|m)\.worldstar(?:candy|hiphop)\.com/(?:videos|android)/video\.php\?v=(?P<id>.*)'
+    _VALID_URL = r'https?://(?:www|m)\.worldstar(?:candy|hiphop)\.com/(?:videos|android)/video\.php\?.*?\bv=(?P<id>[^&]+)'
-        }
+        'only_matching': True,
-            webpage, 'video URL')
+        entries = self._parse_html5_media_entries(url, webpage, video_id)
-            return self.url_result(video_url, ie='Youtube')
+        if not entries:
-        video_title = self._html_search_regex(
+        title = self._html_search_regex(
-        return {
+        info = entries[0]
-        }
+            'title': title,
-        'md5': '2e3e7486ba5d180e829d453875b9b8bf',
+        'md5': '8d02f53ee39cf006009180e21df1f3ba',
-            'thumbnail': r're:https?://vid\.ly/(?P<id>[0-9a-z-]+)/poster',
+            'thumbnail': r're:https?://.*/poster\.jpg',
-        video_id = self._html_search_regex(r'//vid.ly/(.*?)/embed', webpage, 'id')
+        video_id = self._html_search_regex(r'//vid\.ly/(.*?)/embed', webpage, 'id')
-        self._sort_formats(formats)
+        jwconfig = self._parse_json(self._search_regex(
-        return {
+        info_dict.update({
-        }
+        })
-    RaiTVIE,
+    RaiPlayIE,
-    IE = RaiTVIE
+class TestRaiPlaySubtitles(BaseTestSubtitles):
-            }]
+        subtitles = self._extract_subtitles(url, media.get('subtitlesUrl'))
-                expect_value(self, res_dict['id'], tc['info_dict']['id'], 'id')
+            for tc_num, tc in enumerate(test_cases):
-                    # We're not using .download here sine that is just a shim
+                    # We're not using .download here since that is just a shim
-            r"media_url\s*=\s*'([^']+)'", webpage, 'video url')
+            [r"media_url\s*=\s*'(?P<url>[^']+)'",
-        quality = qualities(('mobile', 'lowest', 'low', 'sd', 'hd'))
+        quality = qualities(('mobile', 'lowest', 'low', 'sd', 'hd', 'full'))
-from .rtl2 import RTL2IE
+from .rtl2 import (
-from ..utils import int_or_none
+from ..aes import aes_cbc_decrypt
-__version__ = '2017.04.02'
+__version__ = '2017.04.03'
-            'id': '0a774110-dc60-4037-f769-996439514f1f',
+            'id': 'tdah-mon-amour-tele-quebec-tdah-mon-amour-ep001-enfants',
-            'description': 'md5:b65f0cc50e46947e62e5d352e9916cc4',
+            'description': 'md5:230e3aca23115afcf8006d1bece6df74',
-            'id': vpl_data.get('data-guid') or display_id,
+            'id': display_id,
-            'description': get_element_by_class('video-detail__description', webpage),
+            'description': clean_html(get_element_by_class('video-detail__description', webpage)),
-            raise ExtractorError(msg, expected=True)
+        self.__check_blocked(content)
-    _VALID_URL = r'https?://(?:www\.)?periscope\.tv/[^/]+/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:periscope|pscp)\.tv/[^/]+/(?P<id>[^/?#]+)'
-    _VALID_URL = r'https?://(?:www\.)?periscope\.tv/(?P<id>[^/]+)/?$'
+    _VALID_URL = r'https?://(?:www\.)?(?:periscope|pscp)\.tv/(?P<id>[^/]+)/?$'
-__version__ = '2017.03.26'
+__version__ = '2017.04.02'
-        content_item_ids.add(content_item_id)
+        if content_item_id:
-from ..compat import compat_urlparse
+from ..compat import (
-    def _extract_relinker_formats(self, relinker_url, video_id):
+    _UUID_RE = r'[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12}'
-            media_url = find_xpath_attr(relinker, './url', 'type', 'content').text
+            if not geoprotection:
-                self.raise_geo_restricted()
+                continue
-        return formats
+        if not formats and geoprotection is True:
-    _VALID_URL = r'https?://(?:www\.)?raiplay\.it/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})\.html'
+    _VALID_URL = r'(?P<url>https?://(?:www\.)?raiplay\.it/.+?-(?P<id>%s)\.html)' % RaiBaseIE._UUID_RE
-        }
+            'uploader': 'Rai 3',
-            'title': 'Report - Report del 07/04/2014',
+            'title': 'Report del 07/04/2014',
-        }
+            'uploader': 'Rai 5',
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        webpage = self._download_webpage(canonical_url, video_id)
+        media = self._download_json(
-                                    video_id, 'Downloading video JSON')
+        title = media['name']
-                        'url': value.replace('[RESOLUTION]', self._RESOLUTION)
+                        'url': value.replace('[RESOLUTION]', '600x400')
-            raise ExtractorError('No video found')
+        timestamp = unified_timestamp(try_get(
-        return {
+        info = {
-            'description': self._og_search_description(webpage),
+            'title': title,
-            'duration': duration,
+            'creator': media.get('editor'),
-            'formats': formats
+            'series': try_get(
-    _VALID_URL = r'https?://.+\.(?:rai|rainews)\.it/dl/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html'
+    _VALID_URL = r'https?://[^/]+\.(?:rai\.(?:it|tv)|rainews\.it)/dl/.+?-(?P<id>%s)(?:-.+?)?\.html' % RaiBaseIE._UUID_RE
-        # subdomain test case
+        # var uniquename = "ContentItem-..."
-            'upload_date': '20140612',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': r're:^https?://.*\.jpg$'
+            'upload_date': '20140612',
-        # rainews test case
+        # with ContentItem in many metas
-            'upload_date': '20161103',
+            'title': 'Weekend al cinema, da Hollywood arriva il thriller di Tate Taylor "La ragazza del treno"',
-            'description': r're:^[A-Za-z]+'
+            'duration': 833,
-        # with media information
+        # with ContentItem in og:url
-        # drawMediaRaiTV test case
+        # drawMediaRaiTV(...)
-        # Direct relinker URL
+        # initEdizione('ContentItem-...'
-            'description': r're:.+',
+        'params': {
-        # HDS live stream, MD5 is unstable
+        'params': {
-
+        title = media['name'].strip()
-        return {
+        info = {
-            'description': media.get('desc'),
+            'title': title,
-            'formats': formats,
+
-    RaiTVIE,
+    RaiPlayIE,
-    determine_ext,
+    determine_ext,
-                })
+class RaiPlayIE(RaiBaseIE):
-            raise ExtractorError('not a media file')
+    def _real_extract(self, url):
-            }]
+        # remove query and fragment part from url
-        }
+        media = self._download_json('%s?json' % canonical_url,
-    ]
+        if 'video' not in media:
-        video_id = self._match_id(url)
+        video = media.get('video')
-        return self._extract_from_content_id(video_id, url)
+        return {
-            },
+    _VALID_URL = r'https?://.+\.(?:rai|rainews)\.it/dl/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html'
-            'skip': 'Geo-restricted to Italy',
+    }, {
-            },
+    }, {
-            },
+    }, {
-        return False if RaiTVIE.suitable(url) else super(RaiIE, cls).suitable(url)
+    }]
-from .vrv import VRVIE
+from .vrv import (
-    }
+class VRVBaseIE(InfoExtractor):
-            self._CMS_SIGNING = self._call_api('index', video_id, 'CMS Signing')['cms_signing']
+    def _get_cms_resource(self, resource_key, video_id):
-            self._set_cms_signing(video_id)
+            episode_path = self._get_cms_resource(
-            self._set_cms_signing(video_id)
+
-                rtmp = re.search(r'^(?P<url>rtmpe?://(?P<host>[^/]+)/(?P<app>.+))/(?P<playpath>mp4:.+)$', stream_url)
+                width = int_or_none(stream.get('videoWidthInPixels'))
-    clean_html,
+    js_to_json,
-    _VALID_URL = r'https?://(?:www\.)?funimation\.com/shows/[^/]+/videos/(?:official|promotional)/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?funimation(?:\.com|now\.uk)/shows/[^/]+/(?P<id>[^/?#&]+)'
-        'url': 'http://www.funimation.com/shows/air/videos/official/breeze',
+        'url': 'https://www.funimation.com/shows/hacksign/role-play/',
-            'id': '31128',
+            'id': '91144',
-            'title': '.hack//SIGN - 1 - Role Play',
+            'title': '.hack//SIGN - Role Play',
-        'skip': 'Access without user interaction is forbidden by CloudFlare',
+        'params': {
-        'url': 'http://www.funimation.com/shows/attack-on-titan-junior-high/videos/promotional/broadcast-dub-preview',
+        'url': 'https://www.funimation.com/shows/attack-on-titan-junior-high/broadcast-dub-preview/',
-
+        webpage = self._download_webpage(url, display_id)
-        }
+        def _search_kane(name):
-                expected=True)
+        try:
-            'thumbnail': thumbnail,
+            'thumbnail': self._og_search_thumbnail(webpage),
-        if not video_url:
+        def extract_formats(default=NO_DEFAULT):
-            video_url = extract_video_url()
+            formats = extract_formats()
-        webpage = self._download_webpage(self._add_skip_wall(webpage_url), video_id, 'Downloading webpage')
+        webpage = self._download_webpage(
-        webpage = self._download_webpage(self._add_skip_wall(url), show_id)
+        webpage = self._download_webpage(
-
+        geo_country = self._search_regex(
-                jwplayer_data, video_id, require_title=False)
+                jwplayer_data, video_id, require_title=False, base_url=url)
-    remove_end,
+    int_or_none,
-            for video_url in model_data['videos'][0]['sources'].values():
+            video = model_data['videos'][0]
-            title = model_data['videos'][0]['title']
+            duration = int_or_none(video.get('duration'))
-            ).strip(), ' - AlloCinÃ©')
+            duration, view_count, timestamp = [None] * 3
-            for video_url in model_data['sources'].values():
+            for video_url in model_data['videos'][0]['sources'].values():
-            title = model_data['title']
+            title = model_data['videos'][0]['title']
-        help='Number of retries for a fragment (default is %default), or "infinite" (DASH and hlsnative only)')
+        help='Number of retries for a fragment (default is %default), or "infinite" (DASH, hlsnative and ISM)')
-        help='Skip unavailable fragments (DASH and hlsnative only)')
+        help='Skip unavailable fragments (DASH, hlsnative and ISM)')
-            H += 1
+        decoded = ''
-        video_url = video_url % (''.join(video_url_chars))
+        video_url = video_url % decoded
-__version__ = '2017.03.24'
+__version__ = '2017.03.26'
-
+        check_results.append(not info_dict.get('is_live'))
-            return self._delegate_to_ffmpeg(filename, info_dict)
+            self.report_warning(
-        self.assertEqual(compat_getenv('YOUTUBE-DL-TEST'), test_str)
+        compat_setenv('YOUTUBE_DL_COMPAT_GETENV', test_str)
-        test_var = 'YOUTUBE-DL-TEST'
+        test_var = 'YOUTUBE_DL_COMPAT_SETENV'
-        self.assertEqual(expand_path(env('HOMEPATH')), compat_getenv('HOMEPATH'))
+        compat_setenv('YOUTUBE_DL_EXPATH_PATH', 'expanded')
-            expand_path('~/%s' % env('YOUTUBE-DL-EXPATH-PATH')),
+            expand_path('~/%s' % env('YOUTUBE_DL_EXPATH_PATH')),
-        self.assertEqual(expand_path('%HOMEPATH%'), compat_getenv('HOMEPATH'))
+        self.assertEqual(expand_path(env('YOUTUBE-DL-EXPATH-PATH')), 'expanded')
-        self.assertEqual(expand_path('~/%YOUTUBE-DL-EXPATH-PATH%'), '%s/expanded' % compat_getenv('HOME'))
+        self.assertEqual(
-        module, clip = None, None
+        clip = None
-                f4m_url = 'http://drg.antena3.com/{0}hds/es/sd.f4m'.format(f4m_path)
+                # f4m_path = video_url.split('smil:', 1)[-1].split('free_', 1)[0]
-    compat_expanduser,
+    expand_path,
-            tmpl = compat_expanduser(outtmpl)
+            tmpl = expand_path(outtmpl)
-            opts_cookiefile = compat_expanduser(opts_cookiefile)
+            opts_cookiefile = expand_path(opts_cookiefile)
-    compat_expanduser,
+    expand_path,
-                    compat_expanduser(opts.batchfile),
+                    expand_path(opts.batchfile),
-    download_archive_fn = compat_expanduser(opts.download_archive) if opts.download_archive is not None else opts.download_archive
+    download_archive_fn = expand_path(opts.download_archive) if opts.download_archive is not None else opts.download_archive
-                retcode = ydl.download_with_info_file(compat_expanduser(opts.load_info_filename))
+                retcode = ydl.download_with_info_file(expand_path(opts.load_info_filename))
-from .utils import write_json_file
+from .compat import compat_getenv
-        return compat_expanduser(res)
+        return expand_path(res)
-    def _find_jwplayer_data(webpage):
+    def _find_jwplayer_data(self, webpage, video_id=None, transform_source=js_to_json):
-            return mobj.group('options')
+            try:
-            transform_source=js_to_json)
+        jwplayer_data = self._find_jwplayer_data(
-                pass
+        jwplayer_data = self._find_jwplayer_data(
-            video_id, transform_source=js_to_json)
+        jwplayer_data = self._find_jwplayer_data(
-        check_results.append(not info_dict.get('is_live'))
+        if info_dict.get('is_live'):
-            return fd.real_download(filename, info_dict)
+            return self._delegate_to_ffmpeg(filename, info_dict)
-                        entry_protocol='m3u8' if is_live else 'm3u8_native',
+                        f_url, video_id, 'mp4', 'm3u8_native',
-                            entry_protocol='m3u8' if is_live else 'm3u8_native',
+                            stream_url, playlist_id, 'mp4', 'm3u8_native',
-                m3u8_url, video_id, 'mp4', 'm3u8' if is_live else 'm3u8_native'),
+                m3u8_url, video_id, 'mp4', 'm3u8_native'),
-            m3u8_id='hls')
+            stream_url, video_id, 'mp4',
-                m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+                m3u8_url, video_id, 'mp4', 'm3u8_native',
-                m3u8_url, broadcast_id, 'mp4', entry_protocol, m3u8_id='hls', fatal=False))
+                m3u8_url, broadcast_id, 'mp4', 'm3u8_native',
-    def _extract_video_formats(self, video_data, video_id, entry_protocol):
+    def _extract_video_formats(self, video_data, video_id):
-                m3u8_url, video_id, 'mp4', entry_protocol, m3u8_id='hls', fatal=False))
+                m3u8_url, video_id, 'mp4', 'm3u8_native',
-                'formats': self._extract_video_formats(video_data, content_id, entry_protocol),
+                'formats': self._extract_video_formats(video_data, content_id),
-                    entry_protocol='m3u8' if is_live else 'm3u8_native',
+                    format_url, video_id, 'mp4', 'm3u8_native',
-)
+from ..compat import compat_xpath
-        }
+        },
-            update_url_query(info_url, {'nTitleNo': video_id}), video_id)
+            'http://afbbs.afreecatv.com:8080/api/video/get_video_info.php',
-        if xpath_element(video_xml, './track/video/file') is None:
+        video_element = video_xml.findall(compat_xpath('./track/video'))[1]
-        title = xpath_text(video_xml, './track/title', 'title')
+        video_url_raw = video_element.text
-        info = {
+        return {
-
+# coding: utf-8
-                video_url_hd, video_id, ism_id='mss', fatal=False))
+    def __str__(self):
-    int_or_none,
+    int_or_none,
-        return {
+        info = self._search_json_ld(webpage, video_id, fatal=False)
-        }
+        })
-            'url': 'http://discourse.ubuntu.com/t/unity-8-desktop-mode-windows-on-mir/1986',
+            'url': 'https://skiplagged.com/',
-                'title': 'Unity 8 desktop-mode windows on Mir! - Ubuntu Discourse',
+                'id': 'skiplagged',
-            'playlist_mincount': 2,
+            'playlist_mincount': 1,
-            formats.extend(self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False))
+            video_url_hd = video_url.replace('free_es', 'es')
-                f4m_url = video_url[:-9] + '/manifest.f4m'
+                video_url_hd = video_url.replace('free_es', 'es')
-            r'(?s)<ul class="list_error">(.+?)</ul>', response, 'error', default=None)
+            r'(?s)<ul[^>]+class="[^"]*\blist_error\b[^"]*">(.+?)</ul>',
-            webpage, 'video path')
+        video_data = extract_attributes(self._search_regex(
-        title = self._og_search_title(webpage)
+        video_url = video_data['data-asset-source']
-            webpage, 'upload date', fatal=False))
+        description = self._html_search_regex(
-            r'(?s)<figure[^>]+itemtype="https://schema.org/ImageObject"[^>]*>.*?<img[^>]+data-dejavu-src="([^"]+)"',
+            r'(?s)<figure[^>]+itemtype="https://schema.org/ImageObject"[^>]*>.*?<img[^>]+(?:data-dejavu-)?src="([^"]+)"',
-            r'(?s)<div id="emission".*?<span class="author">(.*?)</span>',
+            r'(?s)<span class="author">(.*?)</span>',
-        vcodec = 'none' if determine_ext(video_url.lower()) == 'mp3' else None
+        ext = determine_ext(video_url.lower())
-            'vcodec': vcodec,
+            'ext': ext,
-            'upload_date': upload_date,
+            'timestamp': int_or_none(video_data.get('data-asset-created-date')),
-                     (?!.*?\blist=)                                            # combined list/video URLs are handled by the playlist IE
+                     (?!.*?\blist=
-                     $"""
+                     $""" % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}
-                     )"""
+                        (%(playlist_id)s)
-                }
+                if new_url != url:
-__version__ = '2017.03.22'
+__version__ = '2017.03.24'
-    clean_html,
+    unescapeHTML,
-    '''
+    qualities,
-                if not q_url:
+            urls = set()
-                    'format_id': q,
+                    'format_id': q,
-                space
+                space|
-        )/.*?(?:\bvid=|-vid|~|%7E|/(?:episode)?)(?P<id>[0-9]{6,})'''
+        )/.*?(?:\bvid(?:eoid)?=|-vid|~|%7E|/(?:episode)?)(?P<id>[0-9]{6,})'''
-    qualities,
+    unescapeHTML,
-    _VALID_URL = r'https?://(?:www\.)?channel9\.msdn\.com/(?P<contentpath>.+?)(?P<rss>/RSS)?/?(?:[?#&]|$)'
+    _VALID_URL = r'https?://(?:www\.)?(?:channel9\.msdn\.com|s\.ch9\.ms)/(?P<contentpath>.+?)(?P<rss>/RSS)?/?(?:[?#&]|$)'
-        'md5': 'bbd75296ba47916b754e73c3a4bbdf10',
+        'md5': '32083d4eaf1946db6d454313f44510ca',
-            'ext': 'mp4',
+            'id': '6c413323-383a-49dc-88f9-a22800cab024',
-            'description': 'md5:c08d72240b7c87fcecafe2692f80e35f',
+            'description': 'md5:b80bf9355a503c193aff7ec6cd5a7731',
-            'thumbnail': r're:http://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-                                 'Mads Kristensen'],
+            'session_speakers': ['Andrew Coates', 'Brady Gaster', 'Mads Kristensen', 'Ed Blankenship', 'Patrick Klug'],
-        'md5': 'b43ee4529d111bc37ba7ee4f34813e68',
+        'md5': 'dcf983ee6acd2088e7188c3cf79b46bc',
-            'ext': 'mp4',
+            'id': 'fe8e435f-bb93-4e01-8e97-a28c01887024',
-            'description': 'md5:d1e6ecaafa7fb52a2cacdf9599829f5b',
+            'description': 'md5:2d17fec927fc91e9e17783b3ecc88f54',
-            'thumbnail': r're:http://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-            'id': 'Events/CPP/CppCon-2015/Ranges-for-the-Standard-Library',
+            'id': '33ad69d2-6a4e-4172-83a1-a523013dec76',
-            'description': 'md5:2e6b4917677af3728c5f6d63784c4c5d',
+            'description': 'md5:9895e0a9fd80822d2f01c454b8f4a372',
-            'thumbnail': r're:http://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-        'playlist_count': 2,
+        'playlist_mincount': 100,
-        rss = mobj.group('rss')
+        content_path, rss = re.match(self._VALID_URL, url).groups()
-                return self._extract_list(content_path)
+        episode_data = self._search_regex(
-        else:  # Assuming list
+                authors = []
-    remove_end,
+    str_to_int,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?cloudy\.ec/(?:v/|embed\.php\?.*?\bid=)(?P<id>[A-Za-z0-9]+)'
-        'md5': '5cb253ace826a42f35b4740539bedf07',
+        'md5': '29832b05028ead1b58be86bf319397ca',
-            'ext': 'flv',
+            'ext': 'mp4',
-            })
+    }, {
-                expected=True)
+    def _real_extract(self, url):
-            title = remove_end(title, '&asdasdas').strip()
+        webpage = self._download_webpage(
-        video_url = data.get('url', [None])[0]
+        info = self._parse_html5_media_entries(url, webpage, video_id)[0]
-                    return self._extract_video(video_id, file_key, video_url, try_num)
+        webpage = self._download_webpage(
-        video_id = mobj.group('id')
+        if webpage:
-        webpage = self._download_webpage(url, video_id)
+        if not info.get('title'):
-            webpage, 'file_key')
+        info['id'] = video_id
-        return self._extract_video(video_id, file_key)
+        return info
-        'md5': '1c33253f0c7782142c993c0ba62a8753',
+        'md5': '2c6a6bc1222c7e91cb3334dad1746e5a',
-    _VALID_URL = r'https?://(?:www\.)?hbo\.com/(?!video)([^/]+/)+video/(?P<id>[0-9a-z-]+)\.html'
+    IE_NAME = 'hbo:episode'
-        'md5': '689132b253cc0ab7434237fc3a293210',
+        'md5': '61ead79b9c0dfa8d3d4b07ef4ac556fb',
-        display_id = self._match_id(url)
+        path, display_id = re.match(self._VALID_URL, url).groups()
-        webpage = self._download_webpage(url, display_id)
+        content = self._download_json(
-            webpage, 'video ID', group='video_id')
+        video_id = compat_str((content.get('parsed', {}).get(
-    mimetype2ext,
+    extract_attributes,
-        info_page = self._download_webpage(
+        info_page = self._download_json(
-            video_id, 'Downloading video info', query=query, fatal=False)
+            video_id, 'Downloading video info', fatal=False, query=query)
-        else:
+            video_info = info_page.get('video')
-                r'var\s+video\s*=\s*({.+?});', info_page, 'video info'), video_id)
+            video_info = self._parse_json(
-        for fdata in video_info.get('sources', [{}])[0]:
+        for fdata in video_info['sources']:
-    _VALID_URL = r'(?:viu:|https?://www\.viu\.com/[a-z]{2}/media/)(?P<id>\d+)'
+    _VALID_URL = r'(?:viu:|https?://[^/]+\.viu\.com/[a-z]{2}/media/)(?P<id>\d+)'
-__version__ = '2017.03.20'
+__version__ = '2017.03.22'
-            'title': 'Management of SQL Server - Demo Monitoring',
+            'title': 'Demo Monitoring',
-        title = '%s - %s' % (module['title'], clip['title'])
+        title = clip['title']
-        assignments = encoded_url.split(";")
+        assignments = self._search_regex(
-
+            inp = re.sub(r'/\*(?:(?!\*/).)*?\*/', '', inp)
-            return inp[1:-1]
+            return remove_quotes(inp)
-            if len(assn) == 0:
+            if not assn:
-
+            assn = re.sub(r'var\s+', '', assn)
-        video_url = js_vars["mediastring"]
+        video_url = js_vars['mediastring']
-            'video url', group='url')
+        encoded_url = self._search_regex(r'(var.*mediastring.*)</script>',
-            r"<iframe[^>]+src=['\"](?P<url>http://www\.senate\.gov/isvp/?\?[^'\"]+)['\"]",
+            r"<iframe[^>]+src=['\"](?P<url>https?://www\.senate\.gov/isvp/?\?[^'\"]+)['\"]",
-            index = H % 12
+            index = H % 7
-__version__ = '2017.03.16'
+__version__ = '2017.03.20'
-    sanitize_filename,
+    sanitize_filename,
-    urljoin,
+    def playlist_from_matches(self, matches, video_id, video_title, getter=None, ie=None):
-            return _playlist_from_matches(bc_urls, ie='BrightcoveNew')
+            return self.playlist_from_matches(bc_urls, video_id, video_title, ie='BrightcoveNew')
-            return _playlist_from_matches(tp_urls, ie='ThePlatform')
+            return self.playlist_from_matches(tp_urls, video_id, video_title, ie='ThePlatform')
-            return _playlist_from_matches(vessel_urls, ie=VesselIE.ie_key())
+            return self.playlist_from_matches(vessel_urls, video_id, video_title, ie=VesselIE.ie_key())
-            return _playlist_from_matches(matches, ie='RtlNl')
+            return self.playlist_from_matches(matches, video_id, video_title, ie='RtlNl')
-            return _playlist_from_matches(vimeo_urls, ie=VimeoIE.ie_key())
+            return self.playlist_from_matches(vimeo_urls, video_id, video_title, ie=VimeoIE.ie_key())
-                matches, lambda m: unescapeHTML(m[1]))
+            return self.playlist_from_matches(
-            return _playlist_from_matches(matches, lambda m: unescapeHTML(m))
+            return self.playlist_from_matches(matches, video_id, video_title, lambda m: unescapeHTML(m))
-            return _playlist_from_matches(matches, lambda m: m[-1])
+            return self.playlist_from_matches(matches, video_id, video_title, lambda m: m[-1])
-            return _playlist_from_matches(matches)
+            return self.playlist_from_matches(matches, video_id, video_title)
-                    playlists, lambda p: '//dailymotion.com/playlist/%s' % p)
+                return self.playlist_from_matches(
-                    embeds, getter=lambda v: OoyalaIE._url_for_embed_code(smuggle_url(v['provider_video_id'], {'domain': url})), ie='Ooyala')
+                return self.playlist_from_matches(
-                matches, getter=unescapeHTML, ie='FunnyOrDie')
+            return self.playlist_from_matches(
-            return _playlist_from_matches(matches, ie='BBCCoUk')
+            return self.playlist_from_matches(matches, video_id, video_title, ie='BBCCoUk')
-            return _playlist_from_matches(sportbox_urls, ie='SportBoxEmbed')
+            return self.playlist_from_matches(sportbox_urls, video_id, video_title, ie='SportBoxEmbed')
-            return _playlist_from_matches(xhamster_urls, ie='XHamsterEmbed')
+            return self.playlist_from_matches(xhamster_urls, video_id, video_title, ie='XHamsterEmbed')
-            return _playlist_from_matches(tnaflix_urls, ie=TNAFlixNetworkEmbedIE.ie_key())
+            return self.playlist_from_matches(tnaflix_urls, video_id, video_title, ie=TNAFlixNetworkEmbedIE.ie_key())
-            return _playlist_from_matches(pornhub_urls, ie=PornHubIE.ie_key())
+            return self.playlist_from_matches(pornhub_urls, video_id, video_title, ie=PornHubIE.ie_key())
-            return _playlist_from_matches(drtuber_urls, ie=DrTuberIE.ie_key())
+            return self.playlist_from_matches(drtuber_urls, video_id, video_title, ie=DrTuberIE.ie_key())
-            return _playlist_from_matches(redtube_urls, ie=RedTubeIE.ie_key())
+            return self.playlist_from_matches(redtube_urls, video_id, video_title, ie=RedTubeIE.ie_key())
-            return _playlist_from_matches(soundcloud_urls, getter=unescapeHTML, ie=SoundcloudIE.ie_key())
+            return self.playlist_from_matches(soundcloud_urls, video_id, video_title, getter=unescapeHTML, ie=SoundcloudIE.ie_key())
-            return _playlist_from_matches(tunein_urls)
+            return self.playlist_from_matches(tunein_urls, video_id, video_title)
-            return _playlist_from_matches(dbtv_urls, ie=DBTVIE.ie_key())
+            return self.playlist_from_matches(dbtv_urls, video_id, video_title, ie=DBTVIE.ie_key())
-            return _playlist_from_matches(videa_urls, ie=VideaIE.ie_key())
+            return self.playlist_from_matches(videa_urls, video_id, video_title, ie=VideaIE.ie_key())
-                twentymin_urls, ie=TwentyMinutenIE.ie_key())
+            return self.playlist_from_matches(
-                openload_urls, ie=OpenloadIE.ie_key())
+            return self.playlist_from_matches(
-                videopress_urls, ie=VideoPressIE.ie_key())
+            return self.playlist_from_matches(
-            return _playlist_from_matches(
+            return self.playlist_from_matches(
-        # clip
+                if '<error' in authorize:
-        t = ol_id[key:key + 24]
+        key = min(maxKey, len(ol_id) - 38)
-            index = H % 8
+            index = H % 12
-from .vtm import VTMIE
+from .medialaan import MedialaanIE
-        }
+from .vtm import VTMIE
-    _VALID_URL = r'https?://(?:www\.)?tlc\.de/(?:[^/]+/)*videos/(?P<title>[^/?#]+)?(?:.*#(?P<id>\d+))?'
+class DiscoveryNetworksDeIE(InfoExtractor):
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)
+            brightcove_id = compat_parse_qs(compat_urlparse.urlparse(
-        key = first_char - 50
+        key = first_char - 55
-        t = ol_id[key:key + 20]
+        key = min(maxKey, len(ol_id) - 26)
-        v = ol_id.replace(t, "")
+        v = ol_id.replace(t, '')
-            h += 2
+            f = t[h:h + 3]
-
+        H = 0
-            B = v[h:h + 3]
+            B = ''
-            index = (h / 3) % 10
+            h += 2
-            i = i ^ A
+            i ^= 213
-            h += 3
+            H += 1
-from test.helper import FakeYDL
+from test.helper import FakeYDL, expect_dict
-__version__ = '2017.03.15'
+__version__ = '2017.03.16'
-        help='Specify audio format: "best", "aac", "vorbis", "mp3", "m4a", "opus", or "wav"; "%default" by default; No effect without -x')
+        help='Specify audio format: "best", "aac", "flac", "mp3", "m4a", "opus", "vorbis", or "wav"; "%default" by default; No effect without -x')
-        if opts.audioformat not in ['best', 'aac', 'mp3', 'm4a', 'opus', 'vorbis', 'wav']:
+        if opts.audioformat not in ['best', 'aac', 'flac', 'mp3', 'm4a', 'opus', 'vorbis', 'wav']:
-    "wmv": "asf",
+    'aac': 'adts',
-            elif filecodec in ['aac', 'mp3', 'vorbis', 'opus']:
+            elif filecodec in ['aac', 'flac', 'mp3', 'vorbis', 'opus']:
-            acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'opus': 'opus', 'vorbis': 'libvorbis', 'wav': None}[self._preferredcodec]
+            # We convert the audio (lossy if codec is lossy)
-    unified_timestamp,
+    # unified_timestamp,
-        'md5': '78e860f631d7a846e712fab8c5fe2c38',
+        'md5': 'fb0445b98aa4394e504b413d98031d1f',
-            'upload_date': '20170301',
+            # 'timestamp': 1488405786,
-            'upload_date': '20170217',
+            # 'timestamp': 1487290093,
-            'https://api-v2.redbull.tv/start', video_id,
+        session = self._download_json(
-            })['auth']['access_token']
+                'build': '4.370.0',
-        )['blocks'][0]['top'][0]
+        try:
-            m3u8_id='hls')
+            video['url'], video_id, 'mp4', 'm3u8_native')
-                    'ext': caption.get('format'),
+                    'ext': ext,
-            'timestamp': unified_timestamp(info.get('published')),
+            # 'timestamp': unified_timestamp(info.get('published')),
-__version__ = '2017.03.10'
+__version__ = '2017.03.15'
-            B = v[h:h + 2]
+            B = v[h:h + 3]
-            index = (h / 2) % 10
+            if (h / 3) % 3 == 0:
-            i = i ^ 96
+            i = i ^ 47
-            h += 2
+            h += 3
-            default=None)
+            r'<h2\s+[^>]*class="uiHeaderTitle"[^>]*>([^<]*)</h2>', webpage,
-                'description', webpage, 'title')
+                'description', webpage, 'title', default=None)
-            i = i ^ 137
+            i = i ^ 96
-            'https://streamable.com/ajax/videos/%s' % video_id, video_id)
+            'https://ajax.streamable.com/videos/%s' % video_id, video_id)
-            webpage, 'series', default=xpath_text(metadata, 'series_title'))
+            webpage, 'series', fatal=False)
-        'url': 'https://www.discoverygo.com/love-at-first-kiss/kiss-first-ask-questions-later/',
+        'url': 'https://www.discoverygo.com/bering-sea-gold/reaper-madness/',
-            'id': '57a33c536b66d1cd0345eeb1',
+            'id': '58c167d86b66d12f2addeb01',
-            'episode_number': 1,
+            'title': 'Reaper Madness',
-    ExtractorError,
+    remove_end,
-    _VALID_URL = r'''(?x)https?://(?:www\.)?(?:
+class DiscoveryGoBaseIE(InfoExtractor):
-        )go\.com/(?:[^/]+/)*(?P<id>[^/?#&]+)'''
+        )go\.com/%s(?P<id>[^/?#&]+)'''
-from .discoverygo import DiscoveryGoIE
+from .discoverygo import (
-__version__ = '2017.03.07'
+__version__ = '2017.03.10'
-                return self._parse_jwplayer_data(jwplayer_data, video_id)
+                info = self._parse_jwplayer_data(
-        # for wdrmaus it is in a link to the page in a multiline "videoLink"-tag
+        # for wdrmaus, in a tag with the class "videoButton" (previously a link
-            jsonp_url, 'metadata', transform_source=strip_jsonp)
+            jsonp_url, display_id, transform_source=strip_jsonp)
-        # for wdrmaus its in a link to the page in a multiline "videoLink"-tag
+        # for wdrmaus it is in a link to the page in a multiline "videoLink"-tag
-            r'class=(?:"(?:mediaLink|wdrrPlayerPlayBtn)\b[^"]*"[^>]+|"videoLink\b[^"]*"[\s]*>\n[^\n]*)data-extension="([^"]+)"',
+            r'class=(?:"(?:mediaLink|wdrrPlayerPlayBtn|videoButton)\b[^"]*"[^>]+|"videoLink\b[^"]*"[\s]*>\n[^\n]*)data-extension="([^"]+)"',
-                'ext': 'flv',
+                'id': 'mdb-1323501',
-                'description': '- Die Sendung mit der Maus -',
+                'description': 'Die Seite mit der Maus -',
-            'url': 'http://www.wdrmaus.de/sachgeschichten/sachgeschichten/achterbahn.php5',
+            'url': 'http://www.wdrmaus.de/filme/sachgeschichten/achterbahn.php5',
-                'description': '- Die Sendung mit der Maus -',
+                'description': 'Die Seite mit der Maus -',
-                'title': 'Funkhaus Europa Livestream',
+                'title': 'COSMO Livestream',
-            title = self._og_search_title(webpage)
+        title = self._html_search_regex(
-        title = self._html_search_regex(self._TITLE_REGEXES, webpage, 'title')
+        title = self._html_search_regex(self._TITLE_REGEXES, webpage, 'title', default=None)
-            r'url\s*:\s*["\']https://dplay-south-prod\.disco-api\.com/playback/videoPlaybackInfo/(\d+)',
+        info_url = self._search_regex(
-                display_id, headers={
+                info_url, display_id, headers={
-            'id': video_id,
+            'id': info_url.rpartition('/')[-1],
-from ..compat import compat_urlparse
+from ..compat import (
-    _VALID_URL = r'https?://(?P<domain>it\.dplay\.com|www\.dplay\.(?:dk|se|no))/[^/]+/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?P<domain>www\.dplay\.(?:dk|se|no))/[^/]+/(?P<id>[^/?#]+)'
-    }, {
+
-from .dplay import DPlayIE
+from .dplay import (
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_chinese_webpage(
-            player_webpage = self._download_webpage(
+            player_webpage = self._download_chinese_webpage(
-    _TEST = {
+    _TESTS = [{
-            'timestamp': 1455965438,
+            'upload_date': '20170201',
-    }
+    }, {
-            'url': smuggle_url('limelight:media:' + media_data['streamInfo']['sourceId'], {'geo_countries': ['CA']}),
+            'url': smuggle_url(
-            'duration': int_or_none(media_data.get('durationInMilliseconds'), 1000),
+            'description': try_get(
-        key = first_char - 55
+        key = first_char - 50
-        t = ol_id[key:key + 12]
+        key = min(maxKey, len(ol_id) - 22)
-            index = (h / 2) % 6
+            index = (h / 2) % 10
-            if not (videoPlayer.isdigit() or videoPlayer.startswith('ref:')):
+            videoPlayer = videoPlayer.strip()
-        })
+            })
-__version__ = '2017.03.06'
+__version__ = '2017.03.07'
-    _CLIENT_ID = 'fDoItMDbsbZz8dY16ZzARCZmzgHBPotA'
+    _CLIENT_ID = '2t9loNQH90kzJcsFCODdigxfp325aq4z'
-        postprocessors.append({'key': 'FFmpegMetadata'})
+    # FFmpegMetadataPP should be run after FFmpegVideoConvertorPP and
-            [value for _, value in sorted(urlcode, key=lambda x: x[0])])
+        video_url_chars = []
-__version__ = '2017.03.05'
+__version__ = '2017.03.06'
-    if not isinstance(base, compat_str) or not re.match(r'^(?:https?:)?//', base):
+    if isinstance(base, bytes):
-                expected=True)
+                countries=self._GEO_COUNTRIES)
-        }
+        },
-            formats = self._parse_jwplayer_formats(video_data['sources'], this_video_id)
+            formats = self._parse_jwplayer_formats(
-        for source in jwplayer_sources_data :
+        for source in jwplayer_sources_data:
-                    source_url, video_id, 'mp4', 'm3u8_native', m3u8_id=m3u8_id, fatal=False))
+                    source_url, video_id, 'mp4', entry_protocol='m3u8_native',
-            elif source_type.startswith('audio') or ext in ('oga', 'aac', 'mp3', 'mpeg', 'vorbis'):
+            elif source_type.startswith('audio') or ext in (
-                    # format like 1080p.
+                    # format like "1080p", "720p SD", or 1080.
-                        r'^(\d{3,})[pP]$', source.get('label') or '',
+                        r'^(\d{3,4})[pP]?(?:\b|$)', compat_str(source.get('label') or ''),
-                    formats.append(a_format)
+            formats = self._parse_jwplayer_formats(video_data['sources'], this_video_id)
-from ..compat import compat_setenv
+from ..compat import (
-            args += ['-fs', compat_str(self._TEST_FILE_SIZE)] # -fs limit_size (output), expressed in bytes
+            args += ['-fs', compat_str(self._TEST_FILE_SIZE)]
-__version__ = '2017.03.02'
+__version__ = '2017.03.05'
-        def post_login_form(page, urlh, note, data):
+        def login_step(page, urlh, note, data):
-                    headers=headers)
+            redirect_url = urljoin(post_url, response['redirect'])
-        redirect_page, handle = redirect_res
+        redirect_page, handle = login_step(
-            tfa_data = {
+            login_step(redirect_page, handle, 'Submitting TFA token', {
-            post_login_form(redirect_page, handle, 'Submitting TFA token', tfa_data)
+            })
-    compat_urlparse,
+    urljoin,
-    _LOGIN_URL = 'http://www.twitch.tv/login'
+    _LOGIN_URL = 'https://www.twitch.tv/login'
-        login_form.update({
+        login_data = {
-        headers = {'Referer': redirect_url}
+        }
-                headers=headers)
+        if not redirect_res:
-    _VALID_URL = r'https?://(?:www\.)?vier\.be/(?:[^/]+/videos/(?P<display_id>[^/]+)(?:/(?P<id>\d+))?|video/v3/embed/(?P<embed_id>\d+))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<site>vier|vijf)\.be/(?:[^/]+/videos/(?P<display_id>[^/]+)(?:/(?P<id>\d+))?|video/v3/embed/(?P<embed_id>\d+))'
-            webpage, 'application', default='vier_vod')
+            webpage, 'application', default=site + '_vod')
-    _VALID_URL = r'https?://(?:www\.)?vier\.be/(?P<program>[^/]+)/videos(?:\?.*\bpage=(?P<page>\d+)|$)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<site>vier|vijf)\.be/(?P<program>[^/]+)/videos(?:\?.*\bpage=(?P<page>\d+)|$)'
-                'http://www.vier.be/%s/videos?page=%d' % (program, current_page_id),
+                'http://www.%s.be/%s/videos?page=%d' % (site, program, current_page_id),
-                self.url_result('http://www.vier.be' + video_url, 'Vier')
+                self.url_result('http://www.' + site + '.be' + video_url, 'Vier')
-                    r'<h3><a href="(/[^/]+/videos/[^/]+(?:/\d+)?)">', current_page)]
+                    r'<h[23]><a href="(/[^/]+/videos/[^/]+(?:/\d+)?)">', current_page)]
-from .redbull import RedBullIE
+from .redbulltv import RedBullTVIE
-        }
+# coding: utf-8
-            'ext': 'mp4',
+            'ext': 'flv',
-            'ext': 'mp4',
+            'ext': 'flv',
-            'ext': 'mp4',
+            'ext': 'flv',
-
+        # Grab metadata from mobile API
-            room['hls_url'], video_id, ext='mp4')
+        # Grab the URL from PC client API
-            'formats': formats,
+            'url': video_url,
-    _VALID_URL = r'https?://rutube\.ru/(?:video|play/embed)/(?P<id>[\da-z]{32})'
+    _VALID_URL = r'https?://rutube\.ru/(?:video|(?:play/)?embed)/(?P<id>[\da-z]{32})'
-
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?vrak\.tv/videos\?.*?target=(?P<id>[0-9\.]+).*'
+    _VALID_URL = r'https?://(?:www\.)?vrak\.tv/videos\?.*?\btarget=(?P<id>[\d.]+)'
-        'md5': 'c5d5ce237bca3b1e990ce1b48d1f0948',
+        'url': 'http://www.vrak.tv/videos?target=1.2306782&filtre=emission&id=1.1806721',
-            'id': '5231040869001',
+            'id': '5345661243001',
-            'timestamp': 1480628425,
+            'title': 'ObÃ©sitÃ©, film de hockey et Roseline Filion',
-        }
+            'creator': 'VRAK.TV',
-        webpage = self._download_webpage(url, url_id)
+        video_id = self._match_id(url)
-            r'<h3 class="videoTitle">(.+?)</h3>', webpage, 'title')
+        webpage = self._download_webpage(url, video_id)
-                ''', webpage):
+        title = self._html_search_regex(
-                % (account_id, player_id, 'default', video_id))
+        content = self._parse_json(
-            result = self.url_result(entries[0], BrightcoveNewIE.ie_key())
+        ref_id = content.get('refId') or self._search_regex(
-        return result
+        brightcove_id = self._search_regex(
-                    json_data.get('message') or json_data['error_code'], expected=True)
+                message = json_data.get('message') or json_data['error_code']
-    _VALID_URL = r'https?://(?:(?P<sub_domain>%s)\.)?go\.com/(?:[^/]+/)*(?:vdka(?P<id>\w+)|season-\d+/\d+-(?P<display_id>[^/?#]+))' % '|'.join(_SITE_INFO.keys())
+    _VALID_URL = r'https?://(?:(?P<sub_domain>%s)\.)?go\.com/(?:[^/]+/)*(?:vdka(?P<id>\w+)|(?:[^/]+/)*(?P<display_id>[^/?#]+))' % '|'.join(_SITE_INFO.keys())
-    _VALID_URL = r'https?://(?:www\.)?24video\.(?:net|me|xxx|sex|tube)/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?P<host>(?:www\.)?24video\.(?:net|me|xxx|sex|tube))/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            'http://www.24video.sex/video/view/%s' % video_id, video_id)
+            'http://%s/video/view/%s' % (host, video_id), video_id)
-            r'http://www.24video.sex/video/xml/%s?mode=init' % video_id,
+            r'http://%s/video/xml/%s?mode=init' % (host, video_id),
-            'http://www.24video.sex/video/xml/%s?mode=play' % video_id,
+            'http://%s/video/xml/%s?mode=play' % (host, video_id),
-__version__ = '2017.02.28'
+__version__ = '2017.03.02'
-                    r'bigPipe\.onPageletArrive\(({.+?})\)\s*;\s*}\s*\)\s*,\s*["\']onPageletArrive\s+(?:stream_pagelet|pagelet_group_mall)',
+                    r'bigPipe\.onPageletArrive\(({.+?})\)\s*;\s*}\s*\)\s*,\s*["\']onPageletArrive\s+(?:stream_pagelet|pagelet_group_mall|permalink_video_pagelet)',
-            raise ExtractorError('"rental" videos not supported')
+            raise ExtractorError('"rental" videos not supported. See https://github.com/rg3/youtube-dl/issues/359 for more information.', expected=True)
-    Set is_id if this is not an arbitrary string, but an ID that should be kept if possible
+    Set is_id if this is not an arbitrary string, but an ID that should be kept
-                is_id=(k == 'id'))
+                is_id=(k == 'id' or k.endswith('_id')))
-            if item.get('contentType') == 'url':
+            if item.get('contentType') in ('url', 'audio'):
-                    % item.get('label') or format_id or num)
+                    % item.get('label') or item.get('format') or format_id or num)
-from ..compat import compat_HTTPError
+from ..compat import (
-            },
+    _TESTS = [{
-            },
+    }, {
-            },
+    }, {
-            }
+    }, {
-            },
+        'url': 'http://www.npo.nl/hoe-gaat-europa-verder-na-parijs/10-01-2015/WO_NOS_762771',
-            'only_matching': True,
+        'params': {
-            'only_matching': True,
+        'params': {
-            'only_matching': True,
+        'params': {
-    ]
+    }, {
-                if stream_info.get('error_code', 0) or stream_info.get('errorcode', 0):
+            # Example: http://www.npo.nl/de-nieuwe-mens-deel-1/21-07-2010/WO_VPRO_043706
-                if not video_url:
+            if not video_url or video_url in urls:
-                if stream_info.get('family') == 'adaptive':
+                if stream_type == 'hds':
-                else:
+                        stream_url, video_id, ext='mp4', fatal=False))
-                        'quality': quality(format_id),
+                        'ext': stream.get('formaat', 'asf'),
-                if '.asf' not in stream_url:
+                else:
-            'title': title,
+            'title': self._live_title(title) if is_live else title,
-    _VALID_URL = r'https?://(?:www\.)?npo\.nl/live/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?npo\.nl/live/(?P<id>[^/?#&]+)'
-            'id': 'LI_NEDERLAND1_136692',
+            'id': 'LI_NL1_4188102',
-            'description': 'Livestream',
+            'title': 're:^NPO 1 [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-
+            '_type': 'url_transparent',
-        return ''.join(token_l)
+        return self._download_json(
-                if format_info.get('error_code', 0) or format_info.get('errorcode', 0):
+            items = self._download_json(
-                video_url = video_info.get('url')
+                format_id = self._search_regex(
-                    formats.extend(self._extract_m3u8_formats(video_url, video_id, 'mp4'))
+                if stream_info.get('family') == 'adaptive':
-__version__ = '2017.02.27'
+__version__ = '2017.02.28'
-    IE_DESC = 'AZ Medien Show playlists'
+    IE_DESC = 'AZ Medien show playlists'
-                        )
+                        )/
-            'id': 'telezueri.ch/all-episodes/astrotalk',
+            'id': 'astrotalk',
-        title = self._og_search_title(webpage)
+                r'<a[^>]+href=(["\'])(?P<url>(?:(?!\1).)+)\1', episodes)]
-            playlist_description=description)
+        return self.playlist_result(entries, playlist_id, title, description)
-                               (?:course|view_play_list|my_playlists|artist|playlist|watch|embed/videoseries)
+                               (?:course|view_play_list|my_playlists|artist|playlist|watch|embed/(?:videoseries|[0-9A-Za-z_-]{11}))
-            r'(?:^|//)youtu\.be/([0-9A-Za-z_-]{11})', url,
+            r'(?:(?:^|//)youtu\.be/|youtube\.com/embed/(?!videoseries))([0-9A-Za-z_-]{11})', url,
-from youtube_dl.aes import aes_decrypt, aes_encrypt, aes_cbc_decrypt, aes_decrypt_text
+from youtube_dl.aes import aes_decrypt, aes_encrypt, aes_cbc_decrypt, aes_cbc_encrypt, aes_decrypt_text
-            'title': 're:^æ¸æ¨éèï¼T-araæ ¹æ¬åä¸ä¸æ¥ï¼ [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'title': 're:^æ¸æ¨éèï¼T-araæ ¹æ¬åä¸ä¸æ¥ï¼ [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
+            'ext': 'mp4',
-        video_url = '%s/%s' % (base_url, live_path)
+        formats = self._extract_m3u8_formats(
-        description = room.get('notice')
+        description = room.get('show_details')
-            'url': video_url,
+            'formats': formats,
-__version__ = '2017.02.24.1'
+__version__ = '2017.02.27'
-                                zapp\.nl/[^/]+/(?:gemist|filmpjes)/
+                                zapp\.nl/[^/]+/[^/]+/
-    IE_NAME = 'schooltv'
+    IE_NAME = 'hetklokhuis'
-                                omroepwnl\.nl/video/fragment/[^/]+__
+                                omroepwnl\.nl/video/fragment/[^/]+__|
-class SchoolTVIE(InfoExtractor):
+class NPODataMidEmbedIE(InfoExtractor):
-            'display_id': display_id
+
-        # This channel is not available.
+        # This channel is not available, geo restricted to JP
-        }
+import codecs
-            'video_uploader', fatal=False)
+            # try looking for both an uploader that's a link and one that's not
-    ISO3166Utils,
+    _GEO_BYPASS = False
-        }
+        },
-                            expected=True)
+                    regions_allowed = self._html_search_meta(
-                '%s said: %s' % (self.IE_NAME, info['error']['title']), expected=True)
+                '%s said: %s' % (self.IE_NAME, title), expected=True)
-    _VALID_URL = r'https?://(?:www\.)?(?:mdr|kika)\.de/(?:.*)/[a-z]+-?(?P<id>\d+)(?:_.+?)?\.html'
+    _VALID_URL = r'https?://(?:www\.)?(?:mdr|kika)\.de/(?:.*)/[a-z-]+-?(?P<id>\d+)(?:_.+?)?\.html'
-            'upload_date': '20151224',
+            'timestamp': 1482541200,
-            r'(?:dataURL|playerXml(?:["\'])?)\s*:\s*(["\'])(?P<url>.+/(?:video|audio)-?[0-9]+-avCustom\.xml)\1',
+            r'(?:dataURL|playerXml(?:["\'])?)\s*:\s*(["\'])(?P<url>.+?-avCustom\.xml)\1',
-                '%s returned error: %s' % (self.IE_NAME, error_message), expected=True)
+            if item.get('isGeoBlocked') is True:
-    def _extract_json(self, webpage, video_id, item):
+    def _extract_json(self, webpage, video_id):
-            video_id)['default'][item]
+            video_id)
-            video_versions = self._extract_json(webpage, video_id, 'streams')[video_id][0]
+            json_data = self._extract_json(webpage, video_id)
-            version = self._VERSIONS.get(video_version['version'])
+            version = self._VERSIONS.get(video_version.get('version'), 'generic')
-        playlists = self._extract_json(webpage, playlist_id, '%ss' % playlist_kind)
+        playlists = self._extract_json(webpage, playlist_id)['default']['%ss' % playlist_kind]
-from .freshlive import FreshliveIE
+from .freshlive import FreshLiveIE
-
+from ..compat import compat_str
-    parse_iso8601
+    try_get,
-    _VALID_URL = r'https?://freshlive\.tv/(?P<streamer>[^/]+)/(?P<id>[0-9]+)'
+
-        'md5': '224f50d268b6b9f94e4198deccd55d6d',
+        'md5': '9f0cf5516979c4454ce982df3d97f352',
-            'timestamp': 1483621764,
+            'description': 'ãã¹ã',
-        info = programs.get(video_id, {})
+        info = options['context']['dispatcher']['stores']['ProgramStore']['programs'][video_id]
-            raise ExtractorError('%s not a valid broadcast ID' % video_id, expected=True)
+        title = info['title']
-            video_url, video_id, ext='mp4', m3u8_id='hls')
+            stream_url, video_id, ext='mp4',
-            'title': info.get('title'),
+            'title': title,
-            'timestamp': parse_iso8601(info.get('startAt')),
+            'duration': int_or_none(info.get('airTime')),
-        }
+            'comment_count': int_or_none(info.get('commentCount')),
-            self.to_screen('[download] Sleeping %s seconds...' % sleep_interval)
+            self.to_screen(
-                        else (int, float, complex))
+try:
-    def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None, m3u8_entry_protocol='m3u8', mpd_id=None):
+    def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None, m3u8_entry_protocol='m3u8', mpd_id=None, preference=None):
-                    entry_protocol=m3u8_entry_protocol, m3u8_id=m3u8_id)
+                    entry_protocol=m3u8_entry_protocol, m3u8_id=m3u8_id,
-    _VALID_URL = r'https?://(?:www\.)?(?:amc|bbcamerica|ifc|wetv)\.com/(?:movies/|shows/[^/]+/(?:full-episodes/)?[^/]+/episode-\d+(?:-(?:[^/]+/)?|/))(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:amc|bbcamerica|ifc|wetv)\.com/(?:movies|shows(?:/[^/]+)+)/(?P<id>[^/?#]+)'
-__version__ = '2017.02.24'
+__version__ = '2017.02.24.1'
-        login = self._download_json(request, None, 'Logging in as %s' % username)
+        login = self._download_json(
-    _LOGIN_URL = 'http://noco.tv/do.php'
+    _LOGIN_URL = 'https://noco.tv/do.php'
-from ..utils import qualities
+from ..utils import (
-            'id': info['id'],
+            'id': video_id,
-            'title': info['title'],
+            'title': title,
-                r'(?m)var\s+video\s+=\s+({.+?});$', player, 'info json'),
+                r'(?m)video\s*:\s*({.+?}),$', player, 'info json'),
-        } for f in info['sources'][0]]
+        } for f in info['sources']]
-            '<span[^>]+id="[^"]+"[^>]*>([0-9]+)</span>',
+            '<span[^>]+id="[^"]+"[^>]*>([0-9A-Za-z]+)</span>',
-        first_two_chars = int(float(ol_id[0:][:2]))
+        first_char = int(ol_id[0])
-        num = 2
+        num = 1
-            urlcode.append((key, compat_chr(int(float(ol_id[num:][:3])) - first_two_chars)))
+            i = ord(ol_id[num])
-            if error['origin'] == 'NoRedisValidData':
+            origin = error['origin']
-__version__ = '2017.02.22'
+__version__ = '2017.02.24'
-            self.report_warning('--cn-verification-proxy is deprecated. Use --geo-verification-proxy instead.')
+        def check_deprecated(param, option, suggestion):
-             'in output filename template or --auto-number option is given (default is %default)')
+        dest='autonumber_size', metavar='NUMBER', type=int,
-        help='[deprecated; use -o "%(autonumber)s-%(title)s.%(ext)s" ] Number downloaded files starting from 00000')
+        help=optparse.SUPPRESS_HELP)
-        help='[deprecated] Use title in file name (default)')
+        help=optparse.SUPPRESS_HELP)
-        help='[deprecated] Alias of --title')
+        help=optparse.SUPPRESS_HELP)
-            course_id, 'Downloading course JSON')
+            course_id, 'Downloading course JSON', fatal=False)
-                        'url': 'https://www.lynda.com/%s/%s-4.html' % (course_path, video_id),
+                        'url': item_template % video_id,
-                    'format' % new_ext)
+                    '[ffmpeg] Subtitle file for %s is already in the requested format' % new_ext)
-with open(lazy_extractors_filename, 'wt') as f:
+with io.open(lazy_extractors_filename, 'wt', encoding='utf-8') as f:
-                    asset_url += '?' + entitlement['uplynkData']['sessionKey']
+                data = {
-                formats.append({
+                f = {
-                })
+                }
-        help='Specify the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given (default is %default)')
+        help='[deprecated; use output template with %(autonumber)0Nd, where N in the number of digits] '
-                template_dict['playlist_index'] = '%0*d' % (len(str(template_dict['n_entries'])), template_dict['playlist_index'])
+            template_dict['autonumber'] = self.params.get('autonumber_start', 1) - 1 + self._num_downloads
-            template_dict = dict((k, sanitize(k, v))
+            template_dict = dict((k, v if isinstance(v, compat_numeric_types) else sanitize(k, v))
-            r'(?s)<li id="showview_videos_media_[0-9]+"[^>]+>.*?<a href="([^"]+)"',
+            r'(?s)<li id="showview_videos_media_(\d+)"[^>]+>.*?<a href="([^"]+)"',
-            for ep in episode_paths
+            self.url_result('http://www.crunchyroll.com' + ep, 'Crunchyroll', ep_id)
-    _VALID_URL = r'https?://(?:www\.)?mgtv\.com/v/(?:[^/]+/)*(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?mgtv\.com/(v|b)/(?:[^/]+/)*(?P<id>\d+)\.html'
-        'md5': '1bdadcf760a0b90946ca68ee9a2db41a',
+        'md5': 'b1ffc0fc163152acf6beaa81832c9ee7',
-        'url': 'http://www.mgtv.com/v/1/1/f/3324755.html',
+        'url': 'http://www.mgtv.com/b/301817/3826653.html',
-            'http://v.api.mgtv.com/player/video', video_id,
+            'http://pcweb.api.mgtv.com/player/video', video_id,
-            if not stream_url:
+            stream_path = stream.get('url')
-                '/playlist.m3u8', ''), 'http-%d' % tbr if tbr else None, idx * 2 + 1, {'pno': 1031}))
+                r'_(\d+)_mp4/', format_url, 'tbr', default=None))
-            'title': info['title'].strip(),
+            'title': title,
-                    'Sohu said: There\'s something wrong in the video.',
+                    '%s said: There\'s something wrong in the video.' % self.IE_NAME,
-                    expected=True)
+                self.raise_geo_restricted(
-
+    _GEO_COUNTRIES = ['CN']
-                msg = 'Country %s auth error' % playstatus['country']
+                self.raise_geo_restricted()
-            raise ExtractorError(msg, expected=True)
+                raise ExtractorError('Generic error. flag = %d' % flag, expected=True)
-__version__ = '2017.02.21'
+__version__ = '2017.02.22'
-            'ext': 'flv',
+            'ext': 'mp4',
-            webpage, 'description', default=None)
+        video_description = self._parse_json(self._html_search_regex(
-            webpage, 'comment count', fatal=False))
+            webpage, 'comment count', default=None))
-    _VALID_URL = r'https?://(?:www\.)?vidzi\.tv/(?:embed-)?(?P<id>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?vidzi\.(?:tv|cc)/(?:embed-)?(?P<id>[0-9a-zA-Z]+)'
-    _VALID_URL = r'https?://(?:www\.)?24video\.(?:net|me|xxx|sex)/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?24video\.(?:net|me|xxx|sex|tube)/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
-    maintainer_email='phihag@phihag.de',
+    maintainer='Sergey M.',
-        self._request_webpage(HEADRequest('http://www.viewster.com/'), video_id)
+        self._request_webpage(
-    _GEO_COUNTRIES = ['CA']
+    clean_html,
-            raise ExtractorError('%s said: %s' % (self.IE_NAME, infos['msg']), expected=True)
+            if infos.get('code') == 'ErrGeoBlocked':
-from ..utils import int_or_none
+from ..utils import (
-            'url': 'limelight:media:' + media_data['streamInfo']['sourceId'],
+            'url': smuggle_url('limelight:media:' + media_data['streamInfo']['sourceId'], {'geo_countries': ['CA']}),
-            item_id, 'Downloading PlaylistService %s JSON' % method, fatal=fatal, headers=headers)
+        try:
-__version__ = '2017.02.17'
+__version__ = '2017.02.21'
-                        '[debug] Using fake %s IP as X-Forwarded-For.' % self._x_forwarded_for_ip)
+                        '[debug] Using fake IP %s (%s) as X-Forwarded-For.'
-            self._x_forwarded_for_ip = GeoUtils.random_ipv4(random.choice(countries))
+            country_code = random.choice(countries)
-                    'Video is geo restricted. Retrying extraction with fake %s IP as X-Forwarded-For.' % self._x_forwarded_for_ip)
+                    'Video is geo restricted. Retrying extraction with fake IP %s (%s) as X-Forwarded-For.'
-        is selected and a random IP brlonging to this country is generated. This
+        is selected and a random IP belonging to this country is generated. This
-        self.__initialize_geo_bypass()
+        self._initialize_geo_bypass(self._GEO_COUNTRIES)
-    def __initialize_geo_bypass(self):
+    def _initialize_geo_bypass(self, countries):
-                country_code = random.choice(self._GEO_COUNTRIES)
+                    countries):
-            webpage, 'uploader', fatal=False)
+            webpage, 'uploader', default=None)
-            self.raise_geo_restricted()
+            self.raise_geo_restricted(countries=['CZ'])
-        playerpage = self._download_webpage(req, video_id, note='Downloading player')
+        playerpage = self._download_webpage(
-        _TESTS = [{
+        # Disable test for python 3.2 since BOM is broken in re in this version
-                                    v8-psapi\.nrk\.no/mediaelement/
+                                    v8[-.]psapi\.nrk\.no/mediaelement/
-                            (?P<id>[^/?#&]+)
+                            (?P<id>[^?#&]+)
-    _API_HOST = 'v8.psapi.nrk.no'
+    _API_HOST = 'v8-psapi.nrk.no'
-def generator(test_case):
+def generator(test_case, tname):
-                        report_warning('Failed due to network errors, skipping...')
+                        report_warning('%s failed due to network errors, skipping...' % tname)
-    test_method = generator(test_case)
+    test_method = generator(test_case, tname)
-
+
-        for kind in ('hls', ''):
+        for kind in ('hls3', ''):
-                    success = ctx['dl'].download(target_filename, {'url': segment_url})
+                    success = ctx['dl'].download(target_filename, {
-                    success = ctx['dl'].download(target_filename, {'url': segment_url})
+                    success = ctx['dl'].download(target_filename, {
-    network.add_option(
+
-    network.add_option(
+        'The default proxy specified by --proxy (or none, if the options is not present) is used for the actual downloading.')
-    )
+        help=optparse.SUPPRESS_HELP)
-        help='Force bypass geographic restriction with explicitly provided two-letter ISO 3166-2 country code (experimental)')
+    parser.add_option_group(geo)
-    _BYPASS_GEO attribute may be set to False in order to disable
+    _GEO_BYPASS attribute may be set to False in order to disable
-    country code provided with geo_bypass_country.
+    country code provided with geo_bypass_country. (experimental)
-    _BYPASS_GEO = True
+    _GEO_BYPASS = True
-            self._ready = True
+                if self._downloader.params.get('verbose', False):
-                            continue
+                    if self.__maybe_fake_ip_and_retry(e.countries):
-                    countries=['US', 'CA'])
+                    countries=self._GEO_COUNTRIES)
-                                    error['message'], countries=['US'])
+                                    error['message'], countries=self._GEO_COUNTRIES)
-                self.raise_geo_restricted(msg=fault_string, countries=['GB'])
+                self.raise_geo_restricted(
-                    msg=MESSAGES.get('ProgramIsGeoBlocked'), countries=['NO'])
+                    msg=MESSAGES.get('ProgramIsGeoBlocked'),
-                countries=['US', 'CA'])
+                countries=self._GEO_COUNTRIES)
-                    self.raise_geo_restricted(msg=message, countries=['US'])
+                    self.raise_geo_restricted(
-    _BYPASS_GEO = False
+    _GEO_BYPASS = False
-                self.raise_geo_restricted(msg=message, countries=['CH'])
+                self.raise_geo_restricted(
-                'This video is only available in Sweden', countries=['SE'])
+                'This video is only available in Sweden',
-            self.raise_geo_restricted(countries=['BG'])
+            self.raise_geo_restricted(countries=self._GEO_COUNTRIES)
-    _BYPASS_GEO = False
+    _GEO_BYPASS = False
-                raise self.raise_geo_restricted(countries=['NO'])
+                raise self.raise_geo_restricted(
-    _BYPASS_GEO = False
+    _GEO_BYPASS = False
-            compat_struct_pack('!I', random.randint(addr_min, addr_max))))
+            compat_struct_pack('!L', random.randint(addr_min, addr_max))))
-                       Bypass geographic restriction via faking X-Forwarded-For
+    geo_bypass:        Bypass geographic restriction via faking X-Forwarded-For
-    bypass_geo_restriction_as_country:
+    geo_bypass_country:
-        'bypass_geo_restriction_as_country': opts.bypass_geo_restriction_as_country,
+        'geo_bypass': opts.geo_bypass,
-    country code provided with bypass_geo_restriction_as_country.
+    country code provided with geo_bypass_country.
-            country_code = self._downloader.params.get('bypass_geo_restriction_as_country', None)
+            country_code = self._downloader.params.get('geo_bypass_country', None)
-                    if (not self._downloader.params.get('bypass_geo_restriction_as_country', None) and
+                    if (not self._downloader.params.get('geo_bypass_country', None) and
-                            self._downloader.params.get('bypass_geo_restriction', True) and
+                            self._downloader.params.get('geo_bypass', True) and
-        action='store_true', dest='bypass_geo_restriction', default=True,
+        '--geo-bypass',
-        action='store_false', dest='bypass_geo_restriction', default=True,
+        '--no-geo-bypass',
-        dest='bypass_geo_restriction_as_country', default=None,
+        '--geo-bypass-country', metavar='CODE',
-                    return self._real_extract(url)
+                    ie_result = self._real_extract(url)
-            compat_struct_pack('!I', random.randint(addr_min, addr_max)))
+        return compat_str(socket.inet_ntoa(
-                    self.IE_NAME, self._ERRORS[reason]), expected=True)
+                    self.IE_NAME, message), expected=True)
-                raise self.raise_geo_restricted()
+                raise self.raise_geo_restricted(countries=['NO'])
-                self.IE_NAME, self._ERRORS[media_data['block']]), expected=True)
+            message = self._ERRORS[media_data['block']]
-            self.raise_geo_restricted()
+            self.raise_geo_restricted(countries=['BG'])
-            self.raise_geo_restricted('This video is only available in Sweden')
+            self.raise_geo_restricted(
-                    expected=True)
+                    '%s said: %s' % (self.IE_NAME, message), expected=True)
-                'This content is not available in your region')
+                msg='This content is not available in your region',
-
+            message_type = data.get('messageType', '')
-                    'Currently unavailable in your country.', expected=True)
+                self.raise_geo_restricted(
-            return self._real_extract(url)
+            for _ in range(2):
-            expected=True)
+    def raise_geo_restricted(msg='This video is not available from your location due to geo restriction', countries=None):
-class ExtractorError(Exception):
+class YoutubeDLError(Exception):
-class DownloadError(Exception):
+class DownloadError(YoutubeDLError):
-class SameFileError(Exception):
+class SameFileError(YoutubeDLError):
-class PostProcessingError(Exception):
+class PostProcessingError(YoutubeDLError):
-class MaxDownloadsReached(Exception):
+class MaxDownloadsReached(YoutubeDLError):
-class UnavailableVideoError(Exception):
+class UnavailableVideoError(YoutubeDLError):
-class ContentTooShortError(Exception):
+class ContentTooShortError(YoutubeDLError):
-class XAttrMetadataError(Exception):
+class XAttrMetadataError(YoutubeDLError):
-class XAttrUnavailableError(Exception):
+class XAttrUnavailableError(YoutubeDLError):
-            '& to require multiple matches. '
+            '>=, <, <=, !=, =) to compare against a number, '
-    _TEST = {
+    _VALID_URL = r'https?://(?:(?:[^/]+)\.)?tvn24(?:bis)?\.pl/(?:[^/]+/)*(?P<id>[^/]+)\.html'
-    }
+    }, {
-        webpage = self._download_webpage(url, page_id)
+        video_id = self._match_id(url)
-        quality_data = self._parse_json(quality_data, page_id)
+
-                'ext': 'mp4',
+                'format_id': format_id,
-                webpage, video_id, require_title=False)
+            entries = self._parse_html5_media_entries(url, webpage, video_id)
-            }
+                'title': 'Adult Art By David Hart 156',
-        # self._confirm_age()
+        headers = {
-            headers['Cookie'] += ' flashVersion=0;'
+            headers['Cookie'] += 'flashVersion=0; '
-            headers['Cookie'] = 'flashVersion=0;'
+            headers['Cookie'] += ' flashVersion=0;'
-            'description': base.get('body'),
+            'description': base.get('body') or base.get('display_body'),
-            'timestamp': int_or_none(video_data.get('created_at')),
+            'duration': int_or_none(video_data.get('video_duration')) or parse_duration(watch_hub_data.get('video-duration')),
-        'url': 'https://www.viceland.com/en_us/video/cyberwar-trailer/57608447973ee7705f6fbd4e',
+        'url': 'https://www.viceland.com/en_us/video/trapped/588a70d0dba8a16007de7316',
-            'id': '57608447973ee7705f6fbd4e',
+            'id': '588a70d0dba8a16007de7316',
-            'description': 'Tapping into the geopolitics of hacking and surveillance, Ben Makuch travels the world to meet with hackers, government officials, and dissidents to investigate the ecosystem of cyberwarfare.',
+            'title': 'TRAPPED (Series Trailer)',
-            'uploader_id': '11',
+            'timestamp': 1485474122,
-__version__ = '2017.02.16'
+__version__ = '2017.02.17'
-            '!key to check if the key is not present,'
+            'Specify any key (see help for -o for a list of available keys) to '
-            ' put a question mark (?) after the operator.'
+            'Values which are not known are excluded unless you '
-    ]
+    _VALID_URL = r'https?://(?:www\.)?heise\.de/(?:[^/]+/)+[^/]+-(?P<id>[0-9]+)\.html'
-            r'<div class="videoplayerjw"[^>]*data-container="([0-9]+)"',
+            r'<div class="videoplayerjw"[^>]+data-container="([0-9]+)"',
-            r'<div class="videoplayerjw"[^>]*data-sequenz="([0-9]+)"',
+            r'<div class="videoplayerjw"[^>]+data-sequenz="([0-9]+)"',
-        info['title'] = title
+                r'<div[^>]+class="videoplayerjw"[^>]+data-title="([^"]+)"',
-        info['description'] = desc
+        doc = self._download_xml(
-        return info
+        description = self._og_search_description(
-        .+?(?P<id>[0-9]+)\.html(?:$|[?#])
+        https?://(?:www\.)?heise\.de/.+?(?P<id>[0-9]+)\.html(?:$|[?#])
-                "Podcast: c't uplink 3.3 â Owncloud / Tastaturen / Peilsender Smartphone"
+    _TESTS = [
-    }
+            'md5': 'ffed432483e922e88545ad9f2f15d30e',
-            r'<div class="videoplayerjw".*?data-container="([0-9]+)"',
+            r'<div class="videoplayerjw"[^>]*data-container="([0-9]+)"',
-            r'<div class="videoplayerjw".*?data-sequenz="([0-9]+)"',
+            r'<div class="videoplayerjw"[^>]*data-sequenz="([0-9]+)"',
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': doc.find('.//{http://rss.jwpcdn.com/}image').text,
-            'description': self._og_search_description(webpage),
+                self._html_search_meta('date', webpage))
-            info['title'] = self._og_search_title(webpage)
+        title = self._html_search_meta('fulltitle', webpage, default=None)
-)
+from .kaltura import KalturaIE
-        return self.url_result('kaltura:%s:%s' % (partner_id, kaltura_id), 'Kaltura')
+        return self.url_result('kaltura:%s:%s' % (partner_id, kaltura_id), KalturaIE.ie_key())
-        'playlist_mincount': 7,
+        'playlist_mincount': 5,
-        playlist = self._extract_playlist(webpage)
+        playlist = self._extract_playlist(webpage, playlist_id)
-    def _extract_playlist(self, webpage):
+    def _extract_playlist(self, webpage, playlist_id):
-            raise ExtractorError('Failed to download JSON', cause=ve)
+        return self._parse_json('[{' + json_string + '}]', playlist_id)
-                'Kaltura')
+                KalturaIE.ie_key(), video_id=item['kaltura_entry_id'])
-        urlcode = {}
+        urlcode = []
-            urlcode[key] = compat_chr(int(float(ol_id[num:][:3])) - first_two_chars)
+            urlcode.append((key, compat_chr(int(float(ol_id[num:][:3])) - first_two_chars)))
-        video_url = 'https://openload.co/stream/' + urllink
+        video_url = 'https://openload.co/stream/' + ''.join(
-        num = 5
+        first_two_chars = int(float(ol_id[0:][:2]))
-                                  first_three_chars - fifth_char * int(float(ol_id[num + 3:][:2])))
+            key = int(float(ol_id[num + 3:][:2]))
-        video_url = 'https://openload.co/stream/' + urlcode
+        urllink = ''.join(['%s' % (value) for (key, value) in urlcode.items()])
-        }
+        },
-            r'<(?:iframe|script)[^>]+src=(["\'])((?:https?:)?//player\.theplatform\.com/p/.+?)\1', webpage)
+            r'(?s)<(?:iframe|script)[^>]+src=(["\'])((?:https?:)?//player\.theplatform\.com/p/.+?)\1', webpage)
-            return list(zip(*matches))[1]
+            return [re.sub(r'\s', '', list(zip(*matches))[1][0])]
-    _TEST = {
+    _VALID_URL = r'https?://einthusan\.tv/movie/watch/(?P<id>[^/?#&]+)'
-    }
+    }, {
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class ArchiveOrgIE(JWPlatformBaseIE):
+class ArchiveOrgIE(InfoExtractor):
-class JWPlatformIE(JWPlatformBaseIE):
+class JWPlatformIE(InfoExtractor):
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class OnDemandKoreaIE(JWPlatformBaseIE):
+class OnDemandKoreaIE(InfoExtractor):
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class PornoXOIE(JWPlatformBaseIE):
+class PornoXOIE(InfoExtractor):
-class RENTVIE(JWPlatformBaseIE):
+class RENTVIE(InfoExtractor):
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class RudoIE(JWPlatformBaseIE):
+class RudoIE(InfoExtractor):
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class ScreencastOMaticIE(JWPlatformBaseIE):
+class ScreencastOMaticIE(InfoExtractor):
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class SendtoNewsIE(JWPlatformBaseIE):
+class SendtoNewsIE(InfoExtractor):
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class ThisAVIE(JWPlatformBaseIE):
+class ThisAVIE(InfoExtractor):
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class TVNoeIE(JWPlatformBaseIE):
+class TVNoeIE(InfoExtractor):
-from .jwplatform import JWPlatformBaseIE
+from .common import InfoExtractor
-class VidziIE(JWPlatformBaseIE):
+class VidziIE(InfoExtractor):
-class WimpIE(JWPlatformBaseIE):
+class WimpIE(InfoExtractor):
-            webpage, 'thumbnail URL', fatal=False)
+            webpage, 'thumbnail URL', default=None)
-            else prefix + thumbnail_suffix)
+            else prefix + thumbnail_suffix) or self._og_search_thumbnail(webpage)
-            webpage, 'title')
+            (r"tituloVideo\s*=\s*'([^']+)'",
-__version__ = '2017.02.14'
+__version__ = '2017.02.16'
-                        formats.extend(self._extract_m3u8_formats(
+                        stream_formats = self._extract_m3u8_formats(
-                            m3u8_id='hls', fatal=False))
+                            m3u8_id='hls-%s' % format_id, fatal=False)
-                            stream_url, playlist_id, mpd_id='dash', fatal=False))
+                        stream_formats = self._extract_mpd_formats(
-                            fatal=False))
+                            m3u8_id='hls', fatal=False))
-                            stream_url, playlist_id, fatal=False))
+                            stream_url, playlist_id, mpd_id='dash', fatal=False))
-        }), '^\s*10k$')
+        }), r'^\s*10k$')
-        }), '^30fps$')
+        }), r'^30fps$')
-        if (m.group('strval') is not None or
+        if (m.group('quotedstrval') is not None or
-            comparison_value = m.group('strval') or m.group('intval')
+            comparison_value = m.group('quotedstrval') or m.group('strval') or m.group('intval')
-        media_url = self._search_regex(r'window\.platformLinkURL\s*=\s*[\'"]([^\'"]+)', webpage, 'media url')
+        media_url = self._search_regex(
-            r'https?://link.theplatform.com/s/([^?]+)', media_url, 'theplatform_path'), display_id)
+            r'link\.theplatform\.com/s/([^?]+)',
-        auth_required = self._search_regex(r'window\.authRequired\s*=\s*(true|false);', webpage, 'auth required')
+        auth_required = self._search_regex(
-            query['auth'] = self._extract_mvpd_auth(url, video_id, requestor_id, resource)
+            requestor_id = self._search_regex(
-        formats, subtitles = self._extract_theplatform_smil(media_url, video_id)
+        formats, subtitles = self._extract_theplatform_smil(
-            season_number = int_or_none(theplatform_metadata.get(ns + '$season'))
+            season_number = int_or_none(
-            episode_number = int_or_none(theplatform_metadata.get(ns + '$episode'))
+            episode_number = int_or_none(
-            r'un:\s*"([^"]+)"', webpage, 'uploader', fatal=False)
+            r'<a[^>]+\brel=["\']author[^>]+>([^<]+)', webpage,
-    _VALID_URL = r'https?://(?:[^/]+\.)?onet\.pl/(?:[^/]+/)+(?P<id>[0-9a-z]+)'
+    _VALID_URL = r'https?://(?:[^/]+\.)?(?:onet|businessinsider\.com|plejada)\.pl/(?:[^/]+/)+(?P<id>[0-9a-z]+)'
-    def _extract_from_id(self, video_id, webpage):
+    def _extract_from_id(self, video_id, webpage=None):
-        description = self._og_search_description(webpage, default=None) or meta.get('description')
+        title = (self._og_search_title(
-    _VALID_URL = r'https?://vod\.pl/(?:.*/)?(?P<id>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://vod\.pl/(?:[^/]+/)+(?P<id>[0-9a-zA-Z]+)'
-    _TEST = {
+    _TESTS = [{
-            'description': 'Kuba Brenner aby pomÃ³c swojemu nieÅmiaÅemu przyjacielowi Oskarowi wynajmuje w agencji towarzyskiej dwie panie. Po upojnej nocy okazuje siÄ, Å¼e chÅopcy nie byli przygotowani finansowo. "Opiekun artystyczny" dziewczyn zabiera w ramach rekompensaty drogocennÄ rzeÅºbÄ naleÅ¼ÄcÄ do wujka Oskara. KÅopoty chÅopcÃ³w zaczynajÄ siÄ, gdy Kuba udaje siÄ do agencji aby wykupiÄ figurkÄ i trafia w sam Årodek mafijnej transakcji... Idiotyczny przypadek sprawia, Å¼e w klubie dochodzi do strzelaniny podczas ktÃ³rej Grucha i Bolec zostajÄ ranni, ginie rÃ³wnieÅ¼ walizka z pieniÄdzmi... Podejrzenie pada na KubÄ.',
+            'description': 'md5:f5f03b84712e55f5ac9f0a3f94445224',
-    }
+    }, {
-
+        info_dict = self._extract_from_id(self._search_mvp_id(webpage), webpage)
-import os
+# import os
-    compat_urllib_parse_urlparse,
+    # compat_urllib_parse_unquote,
-    sanitized_Request,
+    # sanitized_Request,
-)
+# from ..aes import (
-        webpage = self._download_webpage(req, video_id)
+        def dl_webpage(platform):
-        title = self._html_search_meta(
+        title = title or self._html_search_meta(
-            'formats': formats,
+            # 'formats': formats,
-            })
+
-            'id': '61924494876951776',
+            'id': '61924494877246241',
-            'description': 'md5:fe93f6eda372d150759d11644ebbfb4a',
+            'title': 'Hyde Park Civilizace: Å½ivot v GrÃ³nsku',
-__version__ = '2017.02.11'
+__version__ = '2017.02.14'
-    def _call_api(self, url, player, referrer, video_id):
+    def _call_api(self, url, player, referrer, video_id, item):
-            url, video_id, 'Downloading JSON content',
+            url, video_id, 'Downloading JSON %s' % item,
-    def _extract_entry(self, url, content, video_id):
+    def _extract_entry(self, url, player, content, video_id):
-        ptmd = self._download_json(urljoin(url, ptmd_path), video_id)
+        ptmd = self._call_api(
-        return self._extract_entry(player['content'], content, video_id)
+        content = self._call_api(
-        webpage = self._download_webpage(req, display_id)
+        if video_id.isdigit() and len(video_id) < 11:
-            url = 'http://www.xtube.com/video-watch/-%s' % video_id
+            url = 'http://www.xtube.com/watch.php?v=%s' % video_id
-            (r'<h1>(?P<title>[^<]+)</h1>', r'videoTitle\s*:\s*(["\'])(?P<title>.+?)\1'),
+            (r'<h1>\s*(?P<title>[^<]+?)\s*</h1>', r'videoTitle\s*:\s*(["\'])(?P<title>.+?)\1'),
-        'md5': '01fb3c92de4c12c573343d63e163d302',
+        'md5': 'da120c8722d8632eec6ced937536cc98',
-            'duration': 320,
+            'duration': 309,
-        return self.url_result(digiteka_url, 'Digiteka')
+            webpage, 'digiteka url', group='url', default=None))
-        )/.*?(?:\bvid=|-vid|~|%7E|/(?:episode)?)(?P<id>[0-9]{6})'''
+        )/.*?(?:\bvid=|-vid|~|%7E|/(?:episode)?)(?P<id>[0-9]{6,})'''
-                lm[mobj.group(1)], mobj.group(2)), 'Limelight%s' % mobj.group(1), mobj.group(2))
+            return self.url_result(smuggle_url('limelight:%s:%s' % (
-            return self.url_result('limelight:media:%s' % mobj.group('id'))
+            return self.url_result(smuggle_url(
-    def _call_playlist_service(self, item_id, method, fatal=True):
+    def _call_playlist_service(self, item_id, method, fatal=True, referer=None):
-            item_id, 'Downloading PlaylistService %s JSON' % method, fatal=fatal)
+            item_id, 'Downloading PlaylistService %s JSON' % method, fatal=fatal, headers=headers)
-        pc = self._call_playlist_service(item_id, pc_method)
+    def _extract(self, item_id, pc_method, mobile_method, meta_method, referer=None):
-        mobile = self._call_playlist_service(item_id, mobile_method, fatal=False)
+        mobile = self._call_playlist_service(item_id, mobile_method, fatal=False, referer=referer)
-            video_id, 'getPlaylistByMediaId', 'getMobilePlaylistByMediaId', 'properties')
+            video_id, 'getPlaylistByMediaId',
-            'getMobilePlaylistWithNItemsByChannelId?begin=0&count=-1', 'media')
+            'getMobilePlaylistWithNItemsByChannelId?begin=0&count=-1',
-        https?://(?P<domain>(?:[^/]+\.)?(?:disney\.[a-z]{2,3}(?:\.[a-z]{2})?|disney(?:(?:me|latino)\.com|turkiye\.com\.tr)|starwars\.com))/(?:embed/|(?:[^/]+/)+[\w-]+-)(?P<id>[a-z0-9]{24})'''
+        https?://(?P<domain>(?:[^/]+\.)?(?:disney\.[a-z]{2,3}(?:\.[a-z]{2})?|disney(?:(?:me|latino)\.com|turkiye\.com\.tr)|(?:starwars|marvelkids)\.com))/(?:(?:embed/|(?:[^/]+/)+[\w-]+-)(?P<id>[a-z0-9]{24})|(?:[^/]+/)?(?P<display_id>[^/?#]+))'''
-            r'Disney\.EmbedVideo=({.+});', webpage, 'embed data'), video_id)['video']
+        domain, video_id, display_id = re.match(self._VALID_URL, url).groups()
-            if not flavor_url or not re.match(r'https?://', flavor_url):
+            if not flavor_url or not re.match(r'https?://', flavor_url) or flavor_format == 'mp4_access':
-                    flavor_url, video_id, 'mp4', m3u8_id=flavor_format, fatal=False))
+                    flavor_url, video_id, 'mp4',
-        json_data = super(HotStarIE, self)._download_json(url_or_request, video_id, note, fatal=fatal)
+    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata', fatal=True, query=None):
-            video_id)['contentInfo'][0]
+            'http://account.hotstar.com/AVS/besc', video_id, query={
-        for f in ('TABLET',):
+        for f in ('JIO',):
-                video_id, 'Downloading %s JSON metadata' % f, fatal=False)
+                'http://getcdn.hotstar.com/AVS/besc',
-                format_url = format_data['src']
+                format_url = format_data.get('src')
-                    formats.extend(self._extract_m3u8_formats(format_url, video_id, 'mp4', m3u8_id='hls', fatal=False))
+                    formats.extend(self._extract_m3u8_formats(
-            'title': video_data['episodeTitle'],
+            'title': title,
-from ..compat import compat_urlparse
+from ..compat import (
-    sanitized_Request,
+    extract_attributes,
-    ]
+    _VALID_URL = r'https?://einthusan\.tv/movie/watch/(?P<id>[0-9]+)'
-        webpage = self._download_webpage(request, video_id)
+        webpage = self._download_webpage(url, video_id)
-            webpage, 'title')
+        m3u8_url = ej_links.get('HLSLink')
-            r'data-movieid=["\'](\d+)', webpage, 'video id', default=video_id)
+        mp4_url = ej_links.get('MP4Link')
-            m3u8_url, video_id, ext='mp4', entry_protocol='m3u8_native')
+        self._sort_formats(formats)
-        description = self._html_search_meta('description', webpage)
+        description = get_elements_by_class('synopsis', webpage)[0]
-            webpage, "thumbnail url", fatal=False)
+            r'''<img[^>]+src=(["'])(?P<url>(?!\1).+?/moviecovers/(?!\1).+?)\1''',
-            thumbnail = compat_urlparse.urljoin(url, remove_start(thumbnail, '..'))
+            thumbnail = compat_urlparse.urljoin(url, thumbnail)
-    _VALID_URL = r'https?://(?:www\.)?(?P<domain>(?:history|aetv|mylifetime)\.com|fyi\.tv)/(?:shows/(?P<show_path>[^/]+(?:/[^/]+){0,2})|movies/(?P<movie_display_id>[^/]+)/full-movie)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<domain>(?:history|aetv|mylifetime|lifetimemovieclub)\.com|fyi\.tv)/(?:shows/(?P<show_path>[^/]+(?:/[^/]+){0,2})|movies/(?P<movie_display_id>[^/]+)(?:/full-movie)?)'
-                                })
+                                dct.update(parse_codecs(codecs))
-        'md5': '667171934041350c5de3f5015f7f1152',
+        'md5': 'b7dc800a4004b1b57749d9abae0472da',
-            'title': 'åä¾¦æ¢æ¯å å½è¯­çï¼ç¬¬752é è¿«è¿ç°åç§å¯çé»å½± ä¸ç¯',
+            # This can be either Simplified Chinese or Traditional Chinese
-__version__ = '2017.02.10'
+__version__ = '2017.02.11'
-            course_id, 'Downloading course JSON')
+            '%s/player/functions/rpc' % self._API_BASE, course_id,
-
+            author = module.get('author')
-                if not player_parameters:
+                clip_index = int_or_none(clip.get('index'))
-                    'url': '%s/training/player?%s' % (self._API_BASE, player_parameters),
+                    'url': clip_url,
-    return get_element_by_attribute(
+    """Return the content of the first tag with the specified class in the passed HTML document"""
-def get_element_by_attribute(attribute, value, html, escape_value=True):
+def get_elements_by_attribute(attribute, value, html, escape_value=True):
-    m = re.search(r'''(?xs)
+    retlist = []
-    ''' % (re.escape(attribute), value), html)
+    ''' % (re.escape(attribute), value), html):
-    res = m.group('content')
+        if res.startswith('"') or res.startswith("'"):
-        res = res[1:-1]
+        retlist.append(unescapeHTML(res))
-    return unescapeHTML(res)
+    return retlist
-                    if video_item.get('video_id') == video_id:
+                    if video_item.get('video_id'):
-)
+from .hgtv import HGTVComShowIE
-    def _extract_feed_info(self, provider_id, feed_id, filter_query, video_id, custom_fields=None, asset_types_query={}):
+    def _extract_feed_info(self, provider_id, feed_id, filter_query, video_id, custom_fields=None, asset_types_query={}, account_id=None):
-                    smil_url, query), video_id, 'Downloading SMIL data for %s' % asset_type)
+                    main_smil_url or smil_url, query), video_id, 'Downloading SMIL data for %s' % asset_type)
-            webpage, 'id', group='url', default=None)
+            (r'["\']bmmrId["\']\s*:\s*(["\'])(?P<id>(?:(?!\1).)+)\1',
-                        re.sub('/[^/]+\.m3u8', '/Manifest', asset_url),
+                        re.sub(r'/[^/]+\.m3u8', '/Manifest', asset_url),
-        (?:url|URL)
+        (?:url|URL)$
-__version__ = '2017.02.07'
+__version__ = '2017.02.10'
-                        (:?(?:www|cdnapi(?:sec)?)\.)?kaltura\.com/
+                        (:?(?:www|cdnapi(?:sec)?)\.)?kaltura\.com(?::\d+)?/
-                        (?:https?:)?//cdnapi(?:sec)?\.kaltura\.com(?:(?!(?P=q1)).)*/(?:p|partner_id)/(?P<partner_id>\d+)(?:(?!(?P=q1)).)*
+                        (?:https?:)?//cdnapi(?:sec)?\.kaltura\.com(?::\d+)?/(?:(?!(?P=q1)).)*\b(?:p|partner_id)/(?P<partner_id>\d+)(?:(?!(?P=q1)).)*
-            url = 'http://www.xtube.com/watch.php?v=%s' % video_id
+            url = 'http://www.xtube.com/video-watch/-%s' % video_id
-            r'sources\s*:\s*({.+?}),', webpage, 'sources'), video_id)
+            r'(["\'])sources\1\s*:\s*(?P<sources>{.+?}),',
-            r'<dt>Runtime:</dt>\s*<dd>([^<]+)</dd>',
+            r'<dt>Runtime:?</dt>\s*<dd>([^<]+)</dd>',
-            r'<dt>Views:</dt>\s*<dd>([\d,\.]+)</dd>',
+            r'<dt>Views:?</dt>\s*<dd>([\d,\.]+)</dd>',
-                r'(player_quality_[0-9]{3,4}p[0-9a-z]+?)=\s*(["\'])(.*?)\2;', webpage):
+                r'(player_quality_[0-9]{3,4}p\w+)\s*=\s*(["\'])(.+?)\2;', webpage):
-        for url in encoded_video_urls:
+        for encoded_video_url in re.findall(
-            video_urls.append(url)
+                encoded_video_url = encoded_video_url.replace(varname, varval)
-                r'{0}\s*\+\s*{0}'.format(quote), '', video_url)))
+        for url in encoded_video_urls:
-                    r'bigPipe\.onPageletArrive\(({.+?})\)\s*;\s*}\s*\)\s*,\s*["\']onPageletArrive\s+stream_pagelet',
+                    r'bigPipe\.onPageletArrive\(({.+?})\)\s*;\s*}\s*\)\s*,\s*["\']onPageletArrive\s+(?:stream_pagelet|pagelet_group_mall)',
-                if (ffpp.basename == 'ffmpeg' and is_outdated_version(ffpp._versions['ffmpeg'], '3.2')) and (not info_dict.get('acodec') or info_dict['acodec'].split('.')[0] in ('aac', 'mp4a')):
+                if (ffpp.basename == 'ffmpeg' and is_outdated_version(ffpp._versions['ffmpeg'], '3.2', False)) and (not info_dict.get('acodec') or info_dict['acodec'].split('.')[0] in ('aac', 'mp4a')):
-                                index\.php/kwidget|
+                                index\.php/(?:kwidget|extwidget/preview)|
-                        (?:https?:)?//cdnapi(?:sec)?\.kaltura\.com/(?:(?!(?P=q1)).)*(?:p|partner_id)/(?P<partner_id>\d+)(?:(?!(?P=q1)).)*
+                        (?:https?:)?//cdnapi(?:sec)?\.kaltura\.com(?:(?!(?P=q1)).)*/(?:p|partner_id)/(?P<partner_id>\d+)(?:(?!(?P=q1)).)*
-            if not asset_url:
+            protocol = asset.get('protocol')
-                    video_id, f4m_id='hds', fatal=False))
+                if protocol == 'usp':
-from .common import InfoExtractor
+from .adobepass import AdobePassIE
-        'watchdisneyxd': '009',
+class GoIE(AdobePassIE):
-    _VALID_URL = r'https?://(?:(?P<sub_domain>%s)\.)?go\.com/(?:[^/]+/)*(?:vdka(?P<id>\w+)|season-\d+/\d+-(?P<display_id>[^/?#]+))' % '|'.join(_BRANDS.keys())
+    _VALID_URL = r'https?://(?:(?P<sub_domain>%s)\.)?go\.com/(?:[^/]+/)*(?:vdka(?P<id>\w+)|season-\d+/\d+-(?P<display_id>[^/?#]+))' % '|'.join(_SITE_INFO.keys())
-        brand = self._BRANDS[sub_domain]
+        site_info = self._SITE_INFO[sub_domain]
-                        }))
+                        video_id, data=urlencode_postdata(data), headers=self.geo_verification_headers())
-    mimetype2ext,
+    int_or_none,
-        'url': 'http://www.6play.fr/jamel-et-ses-amis-au-marrakech-du-rire-p_1316/jamel-et-ses-amis-au-marrakech-du-rire-2015-c_11495320',
+        'url': 'http://www.6play.fr/le-meilleur-patissier-p_1807/le-meilleur-patissier-special-fetes-mercredi-a-21-00-sur-m6-c_11638450',
-            'id': '11495320',
+            'id': '11638450',
-            'description': 'md5:ba2149d5c321d5201b78070ee839d872',
+            'title': 'Le Meilleur PÃ¢tissier, spÃ©cial fÃªtes mercredi Ã  21:00 sur M6',
-        video_data = clip_data['videoInfo']
+
-            if not source_url or source_type == 'hls/primetime':
+        for asset in clip_data['assets']:
-            if ext == 'm3u8':
+            container = asset.get('video_container')
-                    source_url, video_id, 'mp4', 'm3u8_native',
+                    asset_url, video_id, 'mp4', 'm3u8_native',
-                    source_url.replace('.m3u8', '.f4m'),
+                    asset_url.replace('.m3u8', '.f4m'),
-                quality = source.get('quality')
+            elif container == 'mp4' or ext == 'mp4':
-                    'url': source_url,
+                    'url': asset_url,
-            'series': video_data.get('titlePgm'),
+            'title': title,
-class NBCIE(InfoExtractor):
+class NBCIE(AdobePassIE):
-            'url': 'http://www.nbc.com/the-tonight-show/segments/112966',
+            'url': 'http://www.nbc.com/the-tonight-show/video/jimmy-fallon-surprises-fans-at-ben-jerrys/2848237',
-                'id': '112966',
+                'id': '2848237',
-                'id': 'n1806',
+                'id': '101528f5a9e8127b107e98c5e6ce4638',
-        return {
+        info = {
-            'url': smuggle_url(theplatform_url, {'source_url': url}),
+        video_data = None
-__version__ = '2017.02.04.1'
+__version__ = '2017.02.07'
-        video_urls = list(map(compat_urllib_parse_unquote, re.findall(r"player_quality_[0-9]{3}p\s*=\s*'([^']+)'", webpage)))
+        video_urls = []
-                    # TODO: update acodec for for audio only formats with the same GROUP-ID
+                if audio_in_video_stream.get(last_info.get('AUDIO')) is False and f['vcodec'] != 'none':
-
+            if RtmpIE.suitable(video_url):
-        media_tags.extend(re.findall(r'(?s)(<(?P<tag>video|audio)[^>]*>)(.*?)</(?P=tag)>', webpage))
+        media_tags.extend(re.findall(
-from ..utils import unified_strdate
+from ..utils import (
-        if not tracks_paths:
+        track_elements = re.findall(
-            for t_path in tracks_paths]
+            for elem_content, t_path in track_elements
-from ..utils import remove_end
+from ..utils import (
-        'md5': '1d53866b2c514b23ed69e4352fdc9839',
+        # md5 is unstable
-            'title': '[3D Hentai] Kyonyu Ã\x97 Genkai Ã\x97 Emaki Shinobi Girls.mp4',
+            'title': '[3D Hentai] Kyonyu Ã Genkai Ã Emaki Shinobi Girls.mp4',
-        'md5': '1d85f1e5217d2791626cff5ec83bb189',
+        # md5 is unstable
-            'age_limit': 0,
+            'age_limit': 18,
-        entries = self._parse_html5_media_entries(url, webpage, video_id)
+        video_data = self._download_json('http://www.iwara.tv/api/video/%s' % video_id, video_id)
-        if not entries:
+        if not video_data:
-        info_dict.update({
+        formats = []
-        return info_dict
+            'formats': formats,
-        'md5': '881f7700aec4f538571fa1e0eed4a7b6',
+        'md5': 'd109872761f7e7ecf353fa108c0dbe1e',
-            'duration': 46,
+            'duration': 45,
-            'http://docs.google.com/file/d/%s' % video_id, video_id, encoding='unicode_escape')
+            'http://docs.google.com/file/d/%s' % video_id, video_id)
-                'url': fmt_url,
+                'url': lowercase_escape(fmt_url),
-)
+from ..utils import js_to_json
-                if s.get('stype') == 'HLS':
+                stype = s.get('stype')
-                        s_url, channel_id, 'mp4', fatal=False))
+                        s_url, channel_id, 'mp4', m3u8_id=stype, fatal=False))
-__version__ = '2017.02.04'
+__version__ = '2017.02.04.1'
-    _VALID_URL = r'%s/(?P<id>[^/#?]+)/?(?:\#.*)?$' % TwitchBaseIE._VALID_URL_BASE
+    _VALID_URL = r'''(?x)
-            device_types.append('flash')
+            device_types.append('flash')
-                    formats.append({
+                    f = {
-                    })
+                    }
-__version__ = '2017.02.01'
+__version__ = '2017.02.04'
-            'upload_date': '20160606',
+    _TESTS = [
-    }
+    ]
-            r'clientAPI\s*:\s*"([^"]+)"', webpage, 'app token')
+        app_token = self._search_regex([
-                formats.extend(self._extract_m3u8_formats(
+                m3u8_formats = self._extract_m3u8_formats(
-                    m3u8_id=format_id or 'hls', fatal=False))
+                    m3u8_id=format_id or 'hls', fatal=False)
-
+    _VALID_URL = r'https?://(?:www\.)?dr\.dk/(?:tv/se|nyheder|radio/ondemand)/(?:[^/]+/)*(?P<id>[\da-z-]+)(?:[/#?]|$)'
-            if asset.get('Kind') == 'Image':
+            kind = asset.get('Kind')
-            elif asset.get('Kind') == 'VideoResource':
+            elif kind in ('VideoResource', 'AudioResource'):
-                        formats.extend(self._extract_f4m_formats(
+                        f4m_formats = self._extract_f4m_formats(
-                            video_id, preference, f4m_id=format_id))
+                            video_id, preference, f4m_id=format_id)
-from .drtv import DRTVIE
+from .drtv import (
-                'ext': 'flv',
+                'ext': 'mp4',
-            },
+            'md5': '1d7ee4604a3da226dd69a123f748b262',
-                'ext': 'flv',
+                'ext': 'm4a',
-            'add_ie': ['Vevo'],
+            'add_ie': ['Youtube'],
-                'upload_date': '20060502',
+                'id': 'xqds0B_meys',
-            'skip': 'VEVO is only available in some countries',
+        is_song = mobj.group('mediatype').startswith('music/song')
-            r'playerSwf":"([^"?]*)', webpage, 'player URL')
+            r'videoSwf":"([^"?]*)', webpage, 'player URL', fatal=False)
-            }
+        def formats_from_stream_urls(stream_url, hls_stream_url, http_stream_url, width=None, height=None):
-        if mobj.group('mediatype').startswith('music/song'):
+        if is_song:
-            if not stream_url:
+            formats = formats_from_stream_urls(
-                'formats': [rtmp_format_from_stream_url(stream_url)]
+                'formats': formats,
-                    int_or_none(video.get('height'))))
+            formats = formats_from_stream_urls(
-    unified_strdate,
+    unified_timestamp,
-            'alt_title': 'Vine by Jack Dorsey',
+            'alt_title': 'Vine by Jack',
-            'uploader': 'Jack Dorsey',
+            'uploader': 'Jack',
-    }, {
+            'timestamp': 1436057405,
-        } for f in data['videoUrls'] if f.get('videoUrl')]
+        data = self._download_json(
-            'alt_title': 'Vine by %s' % username if username else self._og_search_description(webpage, default=None),
+            'title': data.get('description'),
-            'upload_date': unified_strdate(data.get('created')),
+            'timestamp': unified_timestamp(data.get('created')),
-            'repost_count': int_or_none(data.get('reposts', {}).get('count')),
+            'view_count': int_or_none(data.get('loops')),
-)
+from .sportbox import SportBoxEmbedIE
-from .filmon import FilmOnIE, FilmOnVODIE
+from .filmon import (
-_QUALITY = qualities(('low', 'high'))
+from ..compat import (
-    _VALID_URL = r'https?://(?:www\.)?filmon\.com/(?:tv|channel)/(?P<id>[a-z0-9-]+)'
+    IE_NAME = 'filmon'
-        'only_matching': True,
+        'url': 'https://www.filmon.com/vod/view/24869-0-plan-9-from-outer-space',
-        'only_matching': True,
+        'url': 'https://www.filmon.com/vod/view/2825-1-popeye-series-1',
-        channel_id = self._match_id(url)
+        video_id = self._match_id(url)
-        now_playing = channel_info['now_playing']
+        try:
-            })
+        title = response['title']
-        formats = []
+        if response.get('type_id') == 1:
-        for stream in channel_info['streams']:
+        QUALITY = qualities(('low', 'high'))
-                'format_note': 'expires after %u seconds' % int(stream['watch-timeout']),
+                'format_id': format_id,
-                'preference': int(stream['watch-timeout']),
+                'quality': QUALITY(stream.get('quality')),
-            'display_id': channel_info['alias'],
+            'id': video_id,
-            'description': now_playing.get('programme_description'),
+            'description': description,
-    _VALID_URL = r'https?://(?:www\.)?filmon\.com/vod/view/(?P<id>\d+)'
+class FilmOnChannelIE(InfoExtractor):
-        'url': 'https://www.filmon.com/vod/view/24869-0-plan-9-from-outer-space',
+        # VOD
-            'id': '24869',
+            'id': '4190',
-            'description': 'Dead human, zombies and vampires',
+            'title': 'Sports Haters',
-        'playlist_count': 8,
+        # LIVE
-        video_id = self._match_id(url)
+    _THUMBNAIL_RES = [
-            raise ExtractorError('FilmOn said: %s' % (result['reason']), expected=True)
+    def _real_extract(self, url):
-        response = result['response']
+        try:
-            }
+        channel_id = compat_str(channel_data['id'])
-        for (id, stream) in response['streams'].items():
+        for stream in channel_data.get('streams', []):
-                'format_note': 'expires after %u seconds' % int(stream['watch-timeout']),
+                'format_id': quality,
-                'preference': int(stream['watch-timeout']),
+                'quality': QUALITY(quality),
-        for (id, thumb) in poster['thumbs'].items():
+        thumbnails = []
-                'height': thumb['height'],
+                'id': name,
-            'description': response['description'],
+            'id': channel_id,
-    def _is_valid_url(self, url, video_id, item='video'):
+    def _is_valid_url(self, url, video_id, item='video', headers={}):
-            self._request_webpage(url, video_id, 'Checking %s URL' % item)
+            self._request_webpage(url, video_id, 'Checking %s URL' % item, headers=headers)
-from ..compat import compat_urllib_parse_unquote
+from ..compat import (
-    def _extract_rtmp_videos(self, webpage):
+    def _extract_rtmp_video(self, webpage):
-            'format_id': 'rtmp',
+            'format_id': 'rtmp_video',
-
+    def _extract_cookies(self, webpage):
-            'format_id': 'http',
+            'format_id': 'http_video',
-                    policy, signature, key_pair_id),
+                'Cookie': self._extract_cookies(webpage)
-            formats = self._extract_rtmp_videos(webpage) + self._extract_http_videos(webpage)
+            formats = (
-    _VALID_URL = r'https?://(?:www\.)?douyu(?:tv)?\.com/(?P<id>[A-Za-z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?douyu(?:tv)?\.com/(?:[^/]+/)*(?P<id>[A-Za-z0-9]+)'
-                r'"room_id"\s*:\s*(\d+),', page, 'room id')
+                r'"room_id\\?"\s*:\s*(\d+),', page, 'room id')
-        /\*.*?\*/|//[^\n]*|,(?=\s*[\]}])|
+        {comment}|,(?={skip}[\]}}])|
-        ''', fix_kv, code)
+        \b(?:0[xX][0-9a-fA-F]+|0+[0-7]+)(?:{skip}:)?|
-                r'(?s)var\s+playerOptions\s*=\s*({.+?});',
+                r'(?s)(?:TDIPlayerOptions|playerOptions)\s*=\s*({.+?});\s*\]\]',
-        elif v.startswith('/*') or v == ',':
+        elif v.startswith('/*') or v.startswith('//') or v == ',':
-        /\*.*?\*/|,(?=\s*[\]}])|
+        /\*.*?\*/|//[^\n]*|,(?=\s*[\]}])|
-                errnote='Unable to download API page')
+                errnote='Unable to download API page',
-            video_id = self._search_regex(r'data-video-id=["\']VDKA(\w+)', webpage, 'video id')
+            video_id = self._search_regex(
-            'title': 'Facebook video #274175099429670',
+            'title': 'Asif Nawab Butt posted a video to his Timeline.',
-            video_title = limit_length(video_title, 80)
+            video_title = self._html_search_meta(
-        uploader = clean_html(get_element_by_id('fbPhotoPageAuthorName', webpage))
+        uploader = clean_html(get_element_by_id(
-                            (?:PL|LL|EC|UU|FL|RD|UL)?[0-9A-Za-z-_]{10,}
+                            (?:PL|LL|EC|UU|FL|RD|UL|TL)?[0-9A-Za-z-_]{10,}
-                        ((?:PL|LL|EC|UU|FL|RD|UL)[0-9A-Za-z-_]{10,})
+                        ((?:PL|LL|EC|UU|FL|RD|UL|TL)[0-9A-Za-z-_]{10,})
-from ..compat import compat_parse_qs
+from ..compat import (
-    _VALID_URL = r'https?://(?:www\.|bangumi\.|)bilibili\.(?:tv|com)/(?:video/av|anime/v/)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.|bangumi\.|)bilibili\.(?:tv|com)/(?:video/av|anime/(?P<anime_id>\d+)/play#)(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        video_id = self._match_id(url)
+        url, smuggled_data = unsmuggle_url(url, {})
-        if 'anime/v' not in url:
+        if 'anime/' not in url:
-                headers={'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8'})
+                headers=headers)
-            video_id, note='Downloading video info page')
+            video_id, note='Downloading video info page',
-            r'<time[^>]+datetime="([^"]+)"', webpage, 'upload time', fatal=False))
+            r'<time[^>]+datetime="([^"]+)"', webpage, 'upload time', default=None))
-            r'<a[^>]+href="https?://space\.bilibili\.com/(?P<id>\d+)"[^>]+title="(?P<name>[^"]+)"',
+            r'<a[^>]+href="(?:https?:)?//space\.bilibili\.com/(?P<id>\d+)"[^>]+title="(?P<name>[^"]+)"',
-from .bilibili import BiliBiliIE
+from .bilibili import (
-                args += ['-f', 'mp4', '-bsf:a', 'aac_adtstoasc']
+                args += ['-f', 'mp4']
-from ..utils import unified_strdate
+from ..utils import strip_jsonp, unified_strdate
-            r"(?:URLMediaFile|urlVideo_\d+)\s*=\s*url_cache\s*\+\s*'([^']+)'", webpage, 'video URL')
+        id_multimedia = self._search_regex(
-__version__ = '2017.01.31'
+__version__ = '2017.02.01'
-    clean_html,
+        def extract_video_data(instances):
-                    break
+            r'handleServerJS\(({.+})(?:\);|,")', webpage,
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-        if description is None: 
+        if description is None:
-            self._DESCRIPTION_REGEXES, webpage, 'description', fatal=False)
+            self._DESCRIPTION_REGEXES, webpage, 'description', default=None)
-
+        output += """
-    try_get,
+    try_get,
-                'upload_date': '20130927',
+                'timestamp': 1380339469,
-            video_upload_date = unified_strdate(mobj.group(1))
+        if not timestamp:
-            'upload_date': video_upload_date,
+            'timestamp': unified_timestamp(timestamp),
-                        vimeo_clip_page_config, video_id)['player']['config_url']
+                    page_config = self._parse_json(vimeo_clip_page_config, video_id)
-                r'/sesong-(?P<season>\d+)/episode-(?P<episode>\d+)',
+                r'/s(?P<season>\d{,2})e(?P<episode>\d{,2})\.',
-            episode_number = int_or_none(self._search_regex(EPISODENUM_RE, _season_episode, "S##E##", fatal=False, group='episode'))
+            season_number = int_or_none(self._search_regex(
-        'md5': '43d0be26663d380603a9cf0c24366531',
+            'series': 'Kunnskapskanalen',
-        'skip': 'Only works from Norway',
+        'params': {
-                'description': 'md5:238b67b97a4ac7d7b4bf0edf8cc57d26',
+                'id': 'MSPO40010515AH',
-                'description': 'md5:238b67b97a4ac7d7b4bf0edf8cc57d26',
+                'id': 'MSPO40010515BH',
-            'duration': 6947.52,
+            'title': 'Sprint fri teknikk, kvinner og menn 06.01.2015',
-    _ITEM_RE = r'data-season=["\'](?P<id>\d+)["\']'
+    _VALID_URL = r'https?://(?:tv|radio)\.nrk(?:super)?\.no/serie/(?P<id>[^/]+)'
-        'playlist_count': 1,
+        'only_matching': True,
-        'playlist_count': 1,
+        'only_matching': True,
-        'playlist_count': 9,
+        'only_matching': True,
-            ))
+            self.url_result(
-        return self.playlist_result(entries)
+        title = self._html_search_meta(
-__version__ = '2017.01.29'
+__version__ = '2017.01.31'
-            'Initial JS player signature function name')
+            (r'(["\'])signature\1\s*,\s*(?P<sig>[a-zA-Z0-9$]+)\(',
-                        fatal=False))
+                    mpd_pattern = r'/%s/(?:sep/)?video/' % video_id
-from ..compat import compat_str
+from ..compat import (
-            etree.register_namespace(ns, full_ns)
+            compat_etree_register_namespace(ns, full_ns)
-__version__ = '2017.01.28'
+__version__ = '2017.01.29'
-    get_element_by_class,
+    get_element_by_id,
-    IE_DESC = 'AZ Medien shows'
+class AZMedienPlaylistIE(AZMedienBaseIE):
-                        (?P<id>[0-9]+-show-[^/\#]+
+                        (?P<id>[0-9]+-
-                'title-block-cell', webpage)), group='title')
+            default=strip_or_none(get_element_by_id(
-    AZMedienShowIE,
+    AZMedienPlaylistIE,
-                        ms_info['media_template'] = media_template
+                    media = segment_template.get('media')
-                        ms_info['initialization_url'] = initialization
+                        ms_info['initialization'] = initialization
-                            'tbr': int_or_none(representation_attrib.get('bandwidth'), 1000),
+                            'tbr': int_or_none(bandwidth, 1000),
-                            media_template.replace('$$', '$')
+                        def prepare_template(template_name, identifiers):
-                                        'Bandwidth': int_or_none(representation_attrib.get('bandwidth')),
+                                        'Bandwidth': bandwidth,
-                                        'Bandwidth': int_or_none(representation_attrib.get('bandwidth')),
+                                        'Bandwidth': bandwidth,
-                                initialization_url = representation_ms_info['initialization_url'].replace('$RepresentationID$', representation_id)
+                                initialization_url = representation_ms_info['initialization_url']
-                                 * "url" (mandatory) - fragment's URL
+                    * fragment_base_url
-                                s = representation_ms_info['s'][s_num]
+                            segment_index = 0
-                                        'duration': float_or_none(s['d'], representation_ms_info['timescale']),
+                                        'url': representation_ms_info['segment_urls'][segment_index],
-                'url': 'http://e.omroep.nl/tt888/%s' % video_id,
+                'url': 'http://tt888.omroep.nl/tt888/%s' % video_id,
-        help='Specify the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given')
+        dest='autonumber_size', metavar='NUMBER', default=5, type=int,
-        help='Specify the start value for the %(autonumber)s counter. Defaults to 1.')
+        dest='autonumber_start', metavar='NUMBER', default=1, type=int,
-            template_dict['autonumber'] = autonumber_templ % self._num_downloads
+            template_dict['autonumber'] = autonumber_templ % (self.params.get('autonumber_start', 1) - 1 + self._num_downloads)
-                'url': caption_url,
+                'url': caption_url.text,
-    _VALID_URL = r'https?://(?:www\.)?itv\.com/hub/[^/]+/(?P<id>[0-9a-z]+)'
+    _VALID_URL = r'https?://(?:www\.)?itv\.com/hub/[^/]+/(?P<id>[0-9a-zA-Z]+)'
-        media_files = xpath_element(playlist, 'VideoEntries/Video/MediaFiles', fatal=True)
+        video_element = xpath_element(playlist, 'VideoEntries/Video', fatal=True)
-        help='Client-side IP address to bind to (experimental)',
+        help='Client-side IP address to bind to',
-        help='Make all connections via IPv4 (experimental)',
+        help='Make all connections via IPv4',
-        help='Make all connections via IPv6 (experimental)',
+        help='Make all connections via IPv6',
-        'The default proxy specified by --proxy (or none, if the options is not present) is used for the actual downloading. (experimental)'
+        'The default proxy specified by --proxy (or none, if the options is not present) is used for the actual downloading.'
-            'Generic video filter (experimental). '
+            'Generic video filter. '
-    general.add_option(
+    downloader.add_option(
-    _VALID_URL = r'https?://channels\.vlive\.tv/(?P<id>[0-9A-Z]+)/video'
+    _VALID_URL = r'https?://channels\.vlive\.tv/(?P<id>[0-9A-Z]+)'
-        'url': 'http://channels.vlive.tv/FCD4B/video',
+        'url': 'http://channels.vlive.tv/FCD4B',
-            r'(http[^\'\"\s]+app\.js)', webpage, 'app js', default='')
+            r'<script[^>]+src=(["\'])(?P<url>http.+?/app\.js.*?)\1',
-            app_id = self._APP_ID
+            app_js = self._download_webpage(
-            query={'app_id': app_id, 'channelCode': channel_code, '_': int(time.time())})
+            channel_code, note='Downloading decode channel code',
-                channel_code, note='channel list %d' % page_num,
+                channel_code, note='Downloading channel list page #%d' % page_num,
-            if not video_list['result'].get('videoList'):
+            if not channel_name:
-                video_id = str(video['videoSeq'])
+            for video in videos:
-                        'http://www.vlive.tv/video/%s' % video_id, 'Vlive', video_id))
+                        'http://www.vlive.tv/video/%s' % video_id,
-from .vlive import VLiveIE
+from .vlive import (
-            if not f.get('fileExt') and f.get('containerFormat') == 'qt':
+            if not f.get('fileExt'):
-                f['fileExt'] = 'mov'
+                if f.get('containerFormat') == 'qt':
-            'uploader_id': info.get('userId'),
+            'uploader_id': info.get('userId') if info.get('userId') != 'None' else None,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?(?:konserthusetplay|rspoplay)\.se/\?.*\bm=(?P<id>[^&]+)'
-            'ext': 'flv',
+            'ext': 'mp4',
-            'duration': 398.8,
+            'duration': 398.76,
-    }
+    }, {
-__version__ = '2017.01.25'
+__version__ = '2017.01.28'
-            'episode_number': int_or_none(xpath_text(metadata, 'episode_number')),
+            'series': series,
-                formats.append({
+                stream_formats = [{
-                })
+                }]
-                formats.append({
+                stream_formats = [{
-                })
+                }]
-                m3u8_formats = self._extract_m3u8_formats(
+                stream_formats = self._extract_m3u8_formats(
-                    f['protocol'] = 'rtmp'
+            else:
-            track_id, 'Downloading track url')
+            'http://api.soundcloud.com/i1/tracks/%s/streams' % track_id,
-                            (?:www\.)?twitch\.tv/[^/]+/v/|
+                            (?:www\.)?twitch\.tv/(?:[^/]+/v|videos)/|
-                for episode_item in re.findall(r'(?s)<div[^>]+class="[^"]*episode-item[^"]*"[^>]*>', webpage):
+                for episode_item in re.findall(r'(?s)<[^>]+class="[^"]*(?:episode|program)-item[^"]*"[^>]*>', webpage):
-class JamendoIE(InfoExtractor):
+from ..utils import parse_duration
-        title = self._search_regex(r'<title>(.*?)\ \|\ Jamendo\ Music\ .*</title>', webpage, 'title')
+        title, artist, track = self._extract_meta(webpage)
-class JamendoAlbumIE(InfoExtractor):
+class JamendoAlbumIE(JamendoBaseIE):
-                'title': 'Shearer - Warmachine'
+                'title': 'Shearer - Warmachine',
-                'title': 'Shearer - Without Your Ghost'
+                'title': 'Shearer - Without Your Ghost',
-        ]
+        title, artist, album = self._extract_meta(webpage, fatal=False)
-    m = re.match(r'(?:(?:(?:(?P<days>[0-9]+):)?(?P<hours>[0-9]+):)?(?P<mins>[0-9]+):)?(?P<secs>[0-9]+)(?P<ms>\.[0-9]+)?$', s)
+    m = re.match(r'(?:(?:(?:(?P<days>[0-9]+):)?(?P<hours>[0-9]+):)?(?P<mins>[0-9]+):)?(?P<secs>[0-9]+)(?P<ms>\.[0-9]+)?Z?$', s)
-                )?$''', s)
+                )?Z?$''', s)
-            m = re.match(r'(?i)(?:(?P<hours>[0-9.]+)\s*(?:hours?)|(?P<mins>[0-9.]+)\s*(?:mins?\.?|minutes?)\s*)$', s)
+            m = re.match(r'(?i)(?:(?P<hours>[0-9.]+)\s*(?:hours?)|(?P<mins>[0-9.]+)\s*(?:mins?\.?|minutes?)\s*)Z?$', s)
-            'title': 'Stories from Emona I',
+            'title': 'Maya FilipiÄ - Stories from Emona I',
-        title = self._html_search_meta('name', webpage, 'title')
+        title = self._search_regex(r'<title>(.*?)\ \|\ Jamendo\ Music\ .*</title>', webpage, 'title')
-            'title': 'Duck On Cover'
+            'title': 'Shearer - Duck On Cover'
-                'title': 'Warmachine'
+                'title': 'Shearer - Warmachine'
-                'title': 'Without Your Ghost'
+                'title': 'Shearer - Without Your Ghost'
-        title = self._html_search_meta('name', webpage, 'title')
+        title = self._search_regex(r'<title>(.*?)\ \|\ Jamendo\ Music\ .*</title>', webpage, 'title')
-    compat_etree_fromstring,
+    compat_HTTPError,
-        return self._download_json(self._api_url_template % path, *args, **kwargs)
+        try:
-        video_info = response.get('video') or {}
+        self._initialize_api(video_id)
-        view_count = None
+        artists = video_info.get('artists')
-                if not version_url:
+            if '.ism' in version_url:
-                        smil_parsed = True
+                formats.append({
-            'timestamp': timestamp,
+            'timestamp': parse_iso8601(video_info.get('releaseDate')),
-            'view_count': view_count,
+            'duration': int_or_none(video_info.get('duration')),
-    _VALID_URL = r'https?://(?:www\.)?cmt\.com/(?:videos|shows|full-episodes|video-clips)/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?cmt\.com/(?:videos|shows|(?:full-)?episodes|video-clips)/(?P<id>[^/]+)'
-    _VALID_URL = r'https?://(?:www\.)?mtv\.com/(?:video-clips|full-episodes)/(?P<id>[^/?#.]+)'
+    _VALID_URL = r'https?://(?:www\.)?mtv\.com/(?:video-clips|(?:full-)?episodes)/(?P<id>[^/?#.]+)'
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.cc\.com/(?:clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.cc\.com/(?:clips|(?:full-)?episodes)/(?P<id>.+?)(\?|#|$))'
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.nl/(?:clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.nl/(?:clips|(?:full-)?episodes)/(?P<id>.+?)(\?|#|$))'
-                'uploader': 'BerkmanCenter',
+                'uploader': 'The Berkman Klein Center for Internet & Society',
-                'description': 'md5:3a72f23c086a1496c9e2c54a25fa0822',
+                'description': 'md5:8013b7ddea787342608f63a13ddc9492',
-            video_duration = int(compat_urllib_parse_unquote_plus(video_info['length_seconds'][0]))
+        video_duration = try_get(
-__version__ = '2017.01.24'
+__version__ = '2017.01.25'
-            'ext': determine_ext(title),
+            'ext': determine_ext(title, 'mp4'),
-
+    IE_NAME = 'afreecatv'
-from .afreecatv import AfreecaTVIE
+from .afreecatv import (
-    _VALID_URL = r'(?:crackle:|https?://(?:www\.)?crackle\.com/(?:playlist/\d+/|(?:[^/]+/)+))(?P<id>\d+)'
+    _VALID_URL = r'(?:crackle:|https?://(?:(?:www|m)\.)?crackle\.com/(?:playlist/\d+/|(?:[^/]+/)+))(?P<id>\d+)'
-            video_id).find('i')
+            video_id, headers=self.geo_verification_headers()).find('i')
-        thumbnail = None
+        thumbnails = []
-            thumbnail = self._THUMBNAIL_TEMPLATE % path
+            for width, height in self._THUMBNAIL_RES:
-                    }]
+                    for url_ext, ext in (('vtt', 'vtt'), ('xml', 'tt')):
-            'thumbnail': thumbnail,
+            'thumbnails': thumbnails,
-        source = next(f for f in playlist if f.get('bitrates'))
+        source = next(f for f in playlist if f.get('bitrates') or f.get('provider'))
-        config_url = data.get('vimeo_esi', {}).get('config', {}).get('configUrl')
+        config_url = self._html_search_regex(
-__version__ = '2017.01.22'
+__version__ = '2017.01.24'
-            payload_url, display_id, headers={'Referer': url})['payload']['course']
+            'https://app.pluralsight.com/player/user/api/v1/player/payload',
-from ..utils import parse_iso8601
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?24video\.(?:net|me|xxx)/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?24video\.(?:net|me|xxx|sex)/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
-            'http://www.24video.net/video/view/%s' % video_id, video_id)
+            'http://www.24video.sex/video/view/%s' % video_id, video_id)
-            r'http://www.24video.net/video/xml/%s?mode=init' % video_id,
+            r'http://www.24video.sex/video/xml/%s?mode=init' % video_id,
-            'http://www.24video.net/video/xml/%s?mode=play' % video_id,
+            'http://www.24video.sex/video/xml/%s?mode=play' % video_id,
-                    expected=True)
+            mobj = re.match(r'[^<]*(?:The|This) playlist (?P<reason>does not exist|is private)[^<]*', match)
-        for match in re.findall(r'<div class="yt-alert-message">([^<]+)</div>', page):
+        # the yt-alert-message now has tabindex attribute (see https://github.com/rg3/youtube-dl/issues/11604)
-    _VALID_URL = r'https?://(?:www\.)?(?:telezueri\.ch|telebaern\.tv|telem1\.ch)/(?P<id>[0-9]+-show-[^/#]+(?:/[0-9]+-episode-[^/#]+)?)$'
+    _VALID_URL = r'''(?x)
-__version__ = '2017.01.18'
+__version__ = '2017.01.22'
-    RegexNotFoundError,
+    unified_timestamp,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?pornflip\.com/(?:v|embed)/(?P<id>[0-9A-Za-z]{11})'
-            'uploader': 'figifoto',
+            'duration': 112,
-    }
+    }, {
-            webpage, 'flashvars'))
+
-                })
+        def flashvar(kind):
-            'thumbnail': thumbnail,
+            'view_count': int_or_none(flashvar('views')),
-            r'var hlsSource.+? = (["\'])(?P<url>http.+?\.m3u8)', webpage)
+        m3u8_formats = [(m.group('id').lower(), m.group('url')) for m in re.finditer(
-        if not m3u8_urls:
+        if not m3u8_formats:
-
+        for m3u8_id, m3u8_url in m3u8_formats:
-            'playlist', default=None, group='url')
+        m3u8_urls = re.findall(
-        if not m3u8_url:
+        if not m3u8_urls:
-                if any(p not in webpage for p in (
+                if any(p in webpage for p in (
-        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')
+        formats = []
-            'thumbnail': 'https://cdn-s.highwebmedia.com/uHK3McUtGCG3SMFcd4ZJsRv8/roomimage/%s.jpg' % video_id,
+            'thumbnail': 'https://roomimg.stream.highwebmedia.com/ri/%s.jpg' % video_id,
-    AZMedienTVShowIE,
+from .azmedien import (
-    _VALID_URL = r'https?://(www|ent)\.appledaily\.com\.tw/(?:animation|appledaily|enews|realtimenews|actionnews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
+    _VALID_URL = r'https?://(www|ent)\.appledaily\.com\.tw/[^/]+/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
-                r'id="clip_(\d+)"[^>]*>\s*<a[^>]+href="(/(?:[^/]+/)*\1)', webpage)
+                r'id="clip_(\d+)"[^>]*>\s*<a[^>]+href="(/(?:[^/]+/)*\1)(?:[^>]+\btitle="([^"]+)")?', webpage)
-                for video_id, video_url in clips:
+                for video_id, video_url, video_title in clips:
-                        VimeoIE.ie_key(), video_id=video_id)
+                        VimeoIE.ie_key(), video_id=video_id, video_title=video_title)
-        help='Specify audio format: "best", "aac", "vorbis", "mp3", "m4a", "opus", or "wav"; "%default" by default')
+        help='Specify audio format: "best", "aac", "vorbis", "mp3", "m4a", "opus", or "wav"; "%default" by default; No effect without -x')
-            'description': 'Attorney General Eric Holder speaks to reporters following the Supreme Court decision in [Shelby County v. Holder], in which the court ruled that the preclearance provisions of the Voting Rights Act could not be enforced.',
+        'playlist_mincount': 2,
-        'md5': '8e5fbfabe6ad0f89f3012a7943c1287b',
+        # md5 is unstable
-            'description': 'md5:118081aedd24bf1d3b68b3803344e7f3'
+        'playlist_mincount': 6,
-        },
+from .ustream import UstreamIE
-            return self.url_result(mobj.group('url'), 'Ustream')
+        ustream_url = UstreamIE._extract_url(webpage)
-                    'quality': quality(f.get('name')),
+                    'source_preference': quality(f.get('name')),
-        # Note that this only retrieves comments that are initally loaded.
+        # Note that this only retrieves comments that are initially loaded.
-            # redirects to ondemand extractor and should be passed throught it
+            # redirects to ondemand extractor and should be passed through it
-            video_id = self._search_regex(r'mediaId=(\d+)', embed_page, 'media id')
+        media_id = None
-            video_id)['item']
+            'http://mais.uol.com.br/apiuol/v3/player/getMedia/%s.json' % media_id,
-            'id': video_id,
+            'id': media_id,
-            r'triforceManifestFeed\s*=\s*(\{.+?\});\n', webpage,
+            r'triforceManifestFeed\s*=\s*({.+?})\s*;\s*\n', webpage,
-__version__ = '2017.01.16'
+__version__ = '2017.01.18'
-    _BILIBILI_KEY = '0bfd84cc3940035173f35e6777508326'
+    _APP_KEY = '84956560bc028eb7'
-            webpage, 'video id', group='id')
+            webpage, 'video id', default=mobj.group('vid'), group='id')
-from ..utils import remove_end
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?20min\.ch/(?:videotv/*\?.*\bvid=(?P<id>\d+)|(?:[^/]+/)*(?P<display_id>[^/#?]+))'
+    _VALID_URL = r'''(?x)
-            'thumbnail': 'http://www.20min.ch/images/content/2/2/0/22050469/10/teaserbreit.jpg'
+            'thumbnail': r're:https?://.*\.jpg$',
-        'md5': '372917ba85ed969e176d287ae54b2f94',
+        'url': 'http://www.20min.ch/videoplayer/videoplayer.html?params=client@twentyDE|videoId@523629',
-            'uploader_id': 'RTVCM',
+            'description': 'md5:117c212f64b25e3d95747e5276863f7d',
-        'only_matching': True,
+    @staticmethod
-        display_id = mobj.group('display_id') or video_id
+        video_id = self._match_id(url)
-        webpage = self._download_webpage(url, display_id)
+        video = self._download_json(
-            return self.url_result(youtube_url, 'Youtube')
+        title = video['title']
-                r'^20 [Mm]inuten.*? -', '', self._og_search_title(webpage)), ' - News')
+        formats = [{
-                params, 'Video Id')
+        description = video.get('lead')
-        thumbnail = self._og_search_thumbnail(webpage)
+        def extract_count(kind):
-            })
+        like_count = extract_count('up')
-            'display_id': display_id,
+            'like_count': like_count,
-        'md5': 'b52d6bc6ea6398e6a38f12cfd418149c',
+        'md5': 'e7264320db31eed8c38364150c12496e',
-            'ext': 'flv',
+            'ext': 'mp4',
-        'md5': 'cec64d59aa01c0ed9dbba9cf639dd82f',
+        'md5': 'e7e237fd98da2a3cc1422ce683df234d',
-            'uploader': 'RTVCM Castilla-La Mancha',
+            'uploader': 'CMM Castilla-La Mancha Media',
-                r'"file\d?"\s*,\s*\"(\d+)', webpage, 'video id')
+                r'.*videoId@(\d+)',
-            'url': 'http://speed.20min-tv.ch/%sm.flv' % video_id,
+            'formats': formats,
-    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/(?:video/[^/]+/|title/tt\d+.*?#lb-)vi(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/(?:video/[^/]+/|title/tt\d+.*?#lb-|videoplayer/)vi(?P<id>\d+)'
-        'url': 'http://tvcast.naver.com/v/81652',
+        'url': 'http://tv.naver.com/v/81652',
-        'url': 'http://tvcast.naver.com/v/395837',
+        'url': 'http://tv.naver.com/v/395837',
-    _VALID_URL = r'https?://(?:m\.)?tvcast\.naver\.com/v/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:m\.)?tv(?:cast)?\.naver\.com/v/(?P<id>\d+)'
-__version__ = '2017.01.14'
+__version__ = '2017.01.16'
-        title = track['title']
+        track_name = track.get('songName') or track.get('name') or track['subName']
-            'artist': track.get('artist'),
+            'track': track_name,
-    _VALID_URL = r'https?://(?:www\.)?xiami\.com/song/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?xiami\.com/song/(?P<id>[^/?#&]+)'
-            'title': 'Woman',
+            'title': 'HONNE - Woman',
-            'title': 'æç©º',
+            'title': 'æ´è - æç©º',
-    _VALID_URL = r'https?://(?:www\.)?xiami\.com/album/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?xiami\.com/album/(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://(?:www\.)?xiami\.com/artist/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?xiami\.com/artist/(?P<id>[^/?#&]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'https?://(?:www\.)?xiami\.com/collect/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?xiami\.com/collect/(?P<id>[^/?#&]+)'
-        argv = system_conf + user_conf + command_line_conf
+        argv = system_conf + user_conf + custom_conf + command_line_conf
-                    formats.append(http_fmt)
+                    http_format_id = format_id.replace('rtmp', 'http')
-        playerID = find_param('playerID')
+        playerID = find_param('playerID') or find_param('playerId')
-            raise ExtractorError('Niconico videos now require logging in', expected=True)
+        # Get flv info
-    compat_urllib_parse_urlencode,
+        'skip': 'Requires an account',
-            'timestamp': 1198527840,  # timestamp field has different value if logged in
+            'timestamp': int,  # timestamp field has different value if logged in
-        }
+        },
-                note='Downloading flv info', errnote='Unable to download flv info')
+            raise ExtractorError('Niconico videos now require logging in', expected=True)
-    ]
+    _VALID_URL = r'https?://(?:www\.)?(?:yourupload\.com/(?:watch|embed)|embed\.yourupload\.com)/(?P<id>[A-Za-z0-9]+)'
-        embed_url = 'http://embed.yucache.net/{0:}'.format(video_id)
+        embed_url = 'http://www.yourupload.com/embed/%s' % video_id
-        video_url = self._og_search_video_url(webpage)
+        video_url = urljoin(embed_url, self._og_search_video_url(webpage))
-            if 'protocol' not in format:
+            if format.get('protocol') is None:
-    _API_MANIFEST = 'https://beam.pro/api/v1/channels/{0}/manifest.m3u8'
+    _VALID_URL = r'https?://(?:\w+\.)?beam\.pro/(?P<id>[^/?#&]+)'
-            'age_limit': 18,
+            'description': 'md5:0b161ac080f15fe05d18a07adb44a74d',
-            'description': 'md5:0b161ac080f15fe05d18a07adb44a74d',
+            'uploader': 'niterhayven',
-        chan_data = self._download_json(self._API_CHANNEL.format(channel_id), channel_id)
+        channel_name = self._match_id(url)
-            raise ExtractorError('{0} is offline'.format(channel_id), expected=True)
+        chan = self._download_json(
-            self._API_MANIFEST.format(chan_data.get('id')), channel_id, ext='mp4')
+        if chan.get('online') is False:
-            info['id'] = compat_str(abs(hash(channel_id)) % (10 ** 8))
+        channel_id = chan['id']
-        return info
+        formats = self._extract_m3u8_formats(
-        rating = info.get('audience')
+        user_id = chan.get('userId') or try_get(chan, lambda x: x['user']['id'])
-            'thumbnail': thumbnail,
+            'id': compat_str(chan.get('id') or channel_name),
-        if 'THIS PAGE IS CURRENTLY UNAVAILABLE IN YOUR REGION' in webpage:
+        if re.search(r'(?i)THIS PAGE IS CURRENTLY UNAVAILABLE IN YOUR REGION', webpage):
-    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+/[0-9]+)(?:/|$)'
+    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/(?:[^/]+/)?drama/(?P<id>[0-9]+/[0-9]+)(?:/|$)'
-    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+)(?:/(?:(?!\d+(?:/|$)).+)?)?$'
+    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/(?:[^/]+/)?drama/(?P<id>[0-9]+)(?:/(?:(?!\d+(?:/|$)).+)?)?$'
-                elif delivery_type == 'hds' or ext == 'mpd':
+                elif delivery_type == 'dash' or ext == 'mpd':
-            return self.playlist_result(entries)
+        entries = [
-__version__ = '2017.01.10'
+__version__ = '2017.01.14'
-            r'''(?x)customBC.\createVideo\(
+            r'''(?x)customBC\.createVideo\(
-    _VALID_URL = r'https?://(?:www\.)?cmt\.com/(?:videos|shows|full-episodes)/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?cmt\.com/(?:videos|shows|full-episodes|video-clips)/(?P<id>[^/]+)'
-    _FEED_URL = 'http://www.cmt.com/sitewide/apps/player/embed/rss/'
+    _VALID_URL = r'https?://(?:www\.)?cmt\.com/(?:videos|shows|full-episodes)/(?P<id>[^/]+)'
-        return self._search_regex(
+        mgid = self._search_regex(
-            webpage, 'mgid', group='mgid')
+            webpage, 'mgid', group='mgid', default=None)
-
+        mgid = self._extract_triforce_mgid(webpage, data_zone='t2_lc_promo1')
-    NO_DEFAULT,
+    try_get,
-                    hls_url, video_id, ext='mp4', entry_protocol='m3u8_native'))
+                    hls_url, video_id, ext='mp4', entry_protocol='m3u8_native',
-                        'format_id': '-'.join(filter(None, [kind, rendition.get('bitrate')])),
+                        'ext': 'flv' if rtmp_video_url.startswith('rtmp') else ext,
-                    } for kind, new_url in new_urls.items()])
+                    }])
-    def _extract_mgid(self, webpage, default=NO_DEFAULT):
+    def _extract_triforce_mgid(self, webpage, data_zone=None, video_id=None):
-                r'embed/(mgid:.+?)["\'&?/]', sm4_embed, 'mgid', default=default)
+                r'embed/(mgid:.+?)["\'&?/]', sm4_embed, 'mgid', default=None)
-        mgid = super(SpikeIE, self)._extract_mgid(webpage, default=None)
+        mgid = super(SpikeIE, self)._extract_mgid(webpage)
-            'url': smuggle_url('ooyala:' + embedCode, {'supportedformats': 'm3u8'}),
+            'url': smuggle_url('ooyala:' + embedCode, {'supportedformats': 'm3u8,dash'}),
-            return OoyalaIE._build_url_result(smuggle_url(mobj.group('ec'), {'domain': url}))
+            embed_token = self._search_regex(
-    def _extract(self, content_tree_url, video_id, domain='example.org', supportedformats=None):
+    def _extract(self, content_tree_url, video_id, domain='example.org', supportedformats=None, embed_token=None):
-                'supportedFormats': supportedformats or 'mp4,rtmp,m3u8,hds',
+                'supportedFormats': supportedformats or 'mp4,rtmp,m3u8,hds,dash,smooth',
-        return self._extract(content_tree_url, embed_code, domain, supportedformats)
+        return self._extract(content_tree_url, embed_code, domain, supportedformats, embed_token)
-            PREFIX + r'm-title="([^"]+)"', webpage, 'title')
+        title = self._html_search_regex(r'm-title="([^"]+)"', webpage, 'title')
-            fatal=False))
+            r'm-thumbnail-url="([^"]+)"', webpage, 'thumbnail', fatal=False))
-            webpage, 'uploader', fatal=False)
+            r'm-owner-name="([^"]+)"', webpage, 'uploader', fatal=False)
-             r'/listeners/?">([0-9,.]+)</a>'],
+             r'/listeners/?">([0-9,.]+)</a>',
-            '<span[^>]+id="[a-zA-Z0-9]+x"[^>]*>([0-9]+)</span>',
+            '<span[^>]+id="[^"]+"[^>]*>([0-9]+)</span>',
-        first_two_chars = int(float(ol_id[0:][:2]))
+        first_three_chars = int(float(ol_id[0:][:3]))
-        num = 2
+        num = 5
-                                  first_two_chars * int(float(ol_id[num + 3:][:2])))
+            urlcode += compat_chr(int(float(ol_id[num:][:3])) +
-    update_url_query,
+    determine_ext,
-            'md5': '909d6454b87b10a25aa04c4bdd416a9b',
+            'md5': 'cb837212f342d77cec06e6dad190e96d',
-            'md5': '77f851c55139ffe0ebd41b6a5552489b',
+            'md5': 'cb837212f342d77cec06e6dad190e96d',
-            raise ExtractorError('This content requires subscription.', expected=True)
+        subtitles = {}
-                    'videoFormat': 'MP4+WEBVTTS+WEBVTT',
+                    'videoFormat': 'MP4+WEBVTT',
-            if not isinstance(manifest_url, compat_str):
+            items = try_get(data, lambda x: x['playback']['items']['item'])
-                    video_id, f4m_id='hds', fatal=False))
+            if isinstance(items, dict):
-    def _extract_akamai_formats(self, manifest_url, video_id):
+    def _extract_akamai_formats(self, manifest_url, video_id, hosts={}):
-        f4m_url = re.sub(r'(https?://.+?)/i/', r'\1/z/', manifest_url).replace('/master.m3u8', '/manifest.f4m')
+        f4m_url = re.sub(r'(https?://[^/+])/i/', r'\1/z/', manifest_url).replace('/master.m3u8', '/manifest.f4m')
-        m3u8_url = re.sub(r'(https?://.+?)/z/', r'\1/i/', manifest_url).replace('/manifest.f4m', '/master.m3u8')
+        m3u8_url = re.sub(r'(https?://[^/]+)/z/', r'\1/i/', manifest_url).replace('/manifest.f4m', '/master.m3u8')
-    _VALID_URL = r'https?://(?:www\.)?freesound\.org/people/([^/]+)/sounds/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?freesound\.org/people/[^/]+/sounds/(?P<id>[^/]+)'
-            'uploader': 'miklovan',
+            'duration': 130.233,
-        webpage = self._download_webpage(url, music_id)
+        audio_id = self._match_id(url)
-            fatal=False, flags=re.DOTALL)
+            r'(?s)id=["\']sound_description["\'][^>]*>(.+?)</div>',
-            r'Downloaded.*>(\d+)<', webpage, 'downloaded', fatal=False))
+        duration = float_or_none(
-            r'Filesize</dt><dd>(.*)</dd>', sound_info, 'file size (approx)', fatal=False)))
+        upload_date = unified_strdate(get_element_by_id('sound_date', webpage))
-            release_date = unified_strdate(release_date.replace('th', ''))
+        channels = self._html_search_regex(
-            r'Bitdepth</dt><dd>(.*)</dd>', sound_info, 'Bitdepth', fatal=False)
+        tags_str = get_element_by_class('tags', webpage)
-            r'Channels</dt><dd>(.*)</dd>', sound_info, 'Channels info', fatal=False)
+        audio_urls = [audio_url]
-        }]
+            'url': format_url,
-            'id': music_id,
+            'id': audio_id,
-                     for t in tags.split('\n') if t.strip()],
+            'uploader': uploader,
-            'likes_count': download_count,
+        self.assertEqual(unified_strdate('July 15th, 2013'), '20130715')
-            webpage, 'music title', flags=re.DOTALL)
+
-            'uploader': self._og_search_property('audio:artist', webpage, 'music uploader'),
+            'uploader': self._og_search_property('audio:artist', webpage, 'music uploader', fatal=False),
-                'description': 'This is "youtube-dl password protected test video" by  on Vimeo, the home for high quality videos and the people who love them.',
+                'description': 'md5:dca3ea23adb29ee387127bc4ddfce63f',
-            'md5': '2d9f5475e0537f013d0073e812ab89e6',
+            'md5': '53c688fa95a55bf4b7293d37a89c5c53',
-                'ext': 'mp4',
+                'ext': 'mov',
-    _VALID_URL = r'https?://(?:www\.)?nick(?:jr)?\.com/(?:videos/clip|[^/]+/videos)/(?P<id>[^/?#.]+)'
+    _VALID_URL = r'https?://(?:(?:www|beta)\.)?nick(?:jr)?\.com/(?:[^/]+/)?(?:videos/clip|[^/]+/videos)/(?P<id>[^/?#.]+)'
-                formats.extend(self._extract_m3u8_formats(hls_url, video_id, ext='mp4'))
+                formats.extend(self._extract_m3u8_formats(
-        videos_info = self._get_videos_info(mgid, use_hls=True)
+        videos_info = self._get_videos_info(mgid)
-    def _get_video_info(self, itemdoc, use_hls=False):
+    def _get_video_info(self, itemdoc, use_hls=True):
-    def _get_videos_info(self, uri, use_hls=False):
+    def _get_videos_info(self, uri, use_hls=True):
-    def _get_videos_info_from_url(self, url, video_id, use_hls=False):
+    def _get_videos_info_from_url(self, url, video_id, use_hls=True):
-            if rendition.attrib['method'] == 'hls':
+            if rendition.get('method') == 'hls':
-    def _get_video_info(self, itemdoc, use_hls):
+    def _get_video_info(self, itemdoc, use_hls=False):
-    def _get_videos_info_from_url(self, url, video_id, use_hls):
+    def _get_videos_info_from_url(self, url, video_id, use_hls=False):
-__version__ = '2017.01.08'
+__version__ = '2017.01.10'
-            (r'(?:var\s+)?%s\s*=\s*\{' % re.escape(objname)) +
+            (r'(?<!this\.)%s\s*=\s*\{' % re.escape(objname)) +
-    _VALID_URL = r'https?://(?:www\.)?inc\.com(?:/[\w-]+)+/(?P<id>[\w-]+)(?:\.html)?'
+    _VALID_URL = r'https?://(?:www\.)?inc\.com/(?:[^/]+/)+(?P<id>[^.]+).html'
-            'partner id')
+            r'var\s+_?bizo_data_partner_id\s*=\s*["\'](\d+)', webpage, 'partner id')
-            'kaltura id'),
+            r'pageInfo\.videos\s*=\s*\[(.+)\];', webpage, 'kaltura id'),
-        return self.url_result('kaltura:%s:%s' % (partner_id, kaltura_id), 'Kaltura')
+        return self.url_result(
-__version__ = '2017.01.05'
+__version__ = '2017.01.08'
-    unified_strdate,
+    try_get,
-            'release_date': '20160818',
+            'duration': 139.327,
-        user_info = video_info.get('user', {})
+
-            'tags': [tag.get('text') for tag in video_info.get('tags', [])],
+            'url': video_url,
-        '_skip': 'redirect to http://swrmediathek.de/index.htm?hinweis=swrlink',
+        'skip': 'redirect to http://swrmediathek.de/index.htm?hinweis=swrlink',
-        '_skip': 'redirect to http://swrmediathek.de/index.htm?hinweis=swrlink',
+        'skip': 'redirect to http://swrmediathek.de/index.htm?hinweis=swrlink',
-from ..utils import parse_duration
+from ..utils import (
-        }
+        },
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            'http://swrmediathek.de/AjaxEntry?ekey=%s' % video_id, video_id, 'Downloading video JSON')
+            'http://swrmediathek.de/AjaxEntry?ekey=%s' % video_id,
-        media_type = attr['entry_etype']
+        title = attr['entry_title']
-            if entry['name'] != 'entry_media':
+        for entry in video.get('sub', []):
-                    'acodec': codec,
+            entry_attr = entry.get('attr', {})
-
+        upload_date = None
-            'uploader_id': attr['channel_idkey'],
+            'title': title,
-    _VALID_URL = r'(?:aol-video:|https?://on\.aol\.com/(?:[^/]+/)*(?:[^/?#&]+-)?)(?P<id>[^/?#&]+)'
+    _VALID_URL = r'(?:aol-video:|https?://(?:(?:www|on)\.)?aol\.com/(?:[^/]+/)*(?:[^/?#&]+-)?)(?P<id>[^/?#&]+)'
-        'url': 'http://on.aol.com/video/netflix-is-raising-rates-5707d6b8e4b090497b04f706?context=PC:homepage:PL1944:1460189336183',
+        'url': 'http://www.aol.com/video/view/netflix-is-raising-rates/5707d6b8e4b090497b04f706/',
-)
+from .aol import AolIE
-import json
+from ..compat import compat_str
-    _VALID_URL = r'https?://(?:www\.)?break\.com/video/(?:[^/]+/)*.+-(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<site>break|screenjunkies)\.com/video/(?P<display_id>[^/]+?)(?:-(?P<id>\d+))?(?:[/?#&]|$)'
-        video_id = self._match_id(url)
+        site, display_id, video_id = re.match(self._VALID_URL, url).groups()
-            webpage, 'info json', flags=re.DOTALL))
+            'http://www.%s.com/embed/%s' % (site, video_id),
-        youtube_id = info.get('youtubeId')
+        youtube_id = embed_vars.get('youtubeId')
-        } for media in info['media'] if media.get('mediaPurpose') == 'play']
+        title = embed_vars['contentName']
-        if not formats:
+        formats = []
-                'url': info['videoUri']
+                'url': f['uri'],
-        self._sort_formats(formats)
+        if not bitrates:
-        age_limit = parse_age_limit(info.get('audienceRating'))
+        def construct_manifest_url(base_url, ext):
-            'age_limit': age_limit,
+            'display_id': display_id,
-        }
+    int_or_none,
-        'playlist_count': 9,
+        'playlist_count': 8,
-                'id': '198180',
+                'id': '240385',
-                'duration': 57.343,
+                'title': 'Indians introduce Encarnacion',
-                'timestamp': 1471221961,
+                'upload_date': '20170105',
-                require_title=False, rtmp_params={'no_resume': True})
+                require_title=False, m3u8_id='hls', rtmp_params={'no_resume': True})
-                'description': video.get('S_fullStory'),
+                'title': video['S_headLine'].strip(),
-        'md5': 'c44a1db29f27daf9a0003e010af82100',
+        'md5': '77d59166cddc8d3cb7b13e35eaf0f5ec',
-            'description': 'md5:9fd1de3614d525f5addda32ac3c482c9',
+            'ext': 'mp4',
-            'description': self._og_search_description(webpage),
+            'description': strip_or_none(self._og_search_description(webpage)),
-from .zdf import ZDFIE
+from .common import InfoExtractor
-class DreiSatIE(ZDFIE):
+class DreiSatIE(InfoExtractor):
-from .zdf import ZDFIE
+from .dreisat import DreiSatIE
-class PhoenixIE(ZDFIE):
+class PhoenixIE(DreiSatIE):
-        videos_info = self._get_videos_info(mgid)
+        videos_info = self._get_videos_info(mgid, use_hls=True)
-    def _extract_video_formats(self, mdoc, mtvn_id):
+    def _extract_video_formats(self, mdoc, mtvn_id, video_id):
-                raise ExtractorError('Invalid rendition field.')
+            if rendition.attrib['method'] == 'hls':
-    def _get_video_info(self, itemdoc):
+    def _get_video_info(self, itemdoc, use_hls):
-            mediagen_url += 'acceptMethods=fms'
+            mediagen_url += 'acceptMethods='
-            'formats': self._extract_video_formats(mediagen_doc, mtvn_id),
+            'formats': formats,
-    def _get_videos_info(self, uri):
+    def _get_videos_info(self, uri, use_hls=False):
-        return self._get_videos_info_from_url(info_url, video_id)
+        return self._get_videos_info_from_url(info_url, video_id, use_hls)
-    def _get_videos_info_from_url(self, url, video_id):
+    def _get_videos_info_from_url(self, url, video_id, use_hls):
-            [self._get_video_info(item) for item in idoc.findall('.//item')],
+            [self._get_video_info(item, use_hls) for item in idoc.findall('.//item')],
-                format['format_id'] = re.sub('[\s,/+\[\]()]', '_', format['format_id'])
+                format['format_id'] = re.sub(r'[\s,/+\[\]()]', '_', format['format_id'])
-                else re.compile('([\x00-\x7f]+)'))
+                else re.compile(r'([\x00-\x7f]+)'))
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://vid\.ly/(?P<id>[0-9a-z-]+)/poster',
+            'thumbnail': r're:https?://vid\.ly/(?P<id>[0-9a-z-]+)/poster',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'uploader_url': 're:https?://(?:www\.)?audioboom\.com/channel/steveczabanyahoosportsradio',
+            'uploader_url': r're:https?://(?:www\.)?audioboom\.com/channel/steveczabanyahoosportsradio',
-                'thumbnail': 're:^https?://.*\.jpe?g',
+                'thumbnail': r're:^https?://.*\.jpe?g',
-                'thumbnail': 're:^https?://.*\.jpe?g',
+                'thumbnail': r're:^https?://.*\.jpe?g',
-                'thumbnail': 're:(?i)^https?://.*\.jpg$',
+                'thumbnail': r're:(?i)^https?://.*\.jpg$',
-                'thumbnail': 're:(?i)^https?://.*\.jpg$',
+                'thumbnail': r're:(?i)^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.+\.jpg',
+            'thumbnail': r're:^https?://.+\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-        event_id = self._search_regex("data-id='(\d+)'", webpage, 'event id')
+        event_id = self._search_regex(r"data-id='(\d+)'", webpage, 'event id')
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'title': 're:^ÄT Sport \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
+            'title': r're:^ÄT Sport \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg\?\d+',
+            'thumbnail': r're:^https?://.*\.jpg\?\d+',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.+\.jpg',
+            'thumbnail': r're:^https?://.+\.jpg',
-            'thumbnail': 're:^http://img\.clubic\.com/.*\.jpg$',
+            'thumbnail': r're:^http://img\.clubic\.com/.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?:.*\.(?:jpg|png)$',
+                'thumbnail': r're:^https?:.*\.(?:jpg|png)$',
-            'thumbnail': 're:^https?://.*\.(?:jpg|png)',
+            'thumbnail': r're:^https?://.*\.(?:jpg|png)',
-            'thumbnail': 're:^https?://.*\.(?:jpg|png)',
+            'thumbnail': r're:^https?://.*\.(?:jpg|png)',
-            'thumbnail': 're:^https?://.*\.(?:jpg|png)',
+            'thumbnail': r're:^https?://.*\.(?:jpg|png)',
-            'thumbnail': 're:^https?://.*\.(?:jpg|png)',
+            'thumbnail': r're:^https?://.*\.(?:jpg|png)',
-            'thumbnail': 're:https?://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://cdn-images.deezer.com/images/cover/.*\.jpg$',
+            'thumbnail': r're:^https?://cdn-images.deezer.com/images/cover/.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'description': r're:.*m7show@163\.com.*',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'description': r're:.*m7show@163\.com.*',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.(?:gif|jpg)$',
+            'thumbnail': r're:^https?://.*\.(?:gif|jpg)$',
-            'thumbnail': 're:^https?://.*\.(?:gif|jpg)$',
+            'thumbnail': r're:^https?://.*\.(?:gif|jpg)$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-            'thumbnail': 're:https?://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.(?:jpg|JPG)$',
+            'thumbnail': r're:^https?://.*\.(?:jpg|JPG)$',
-            'thumbnail': 're:^https?://.*\.(?:jpg|JPG)$',
+            'thumbnail': r're:^https?://.*\.(?:jpg|JPG)$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpe?g$',
+            'thumbnail': r're:^https?://.*\.jpe?g$',
-            'thumbnail': 're:^https?://.*\.jpe?g$',
+            'thumbnail': r're:^https?://.*\.jpe?g$',
-            'thumbnail': 're:https?://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-            'thumbnail': 're:https?://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-            'thumbnail': 're:https?://.*\.(?:jpg|png)',
+            'thumbnail': r're:https?://.*\.(?:jpg|png)',
-            'thumbnail': 're:^http:.*\.jpg$',
+            'thumbnail': r're:^http:.*\.jpg$',
-            'thumbnail': 're:^http:.*\.jpg$',
+            'thumbnail': r're:^http:.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                '/([^/]+)\.csmil/',
+                r'/([^/]+)\.csmil/',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'description': 're:^Chris Ziegler takes a look at the\.*',
+                'description': r're:^Chris Ziegler takes a look at the\.*',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.png$',
+                'thumbnail': r're:^https?://.*\.png$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpe?g$',
+                'thumbnail': r're:^https?://.*\.jpe?g$',
-                'thumbnail': 're:^https?://.*\.jpe?g$',
+                'thumbnail': r're:^https?://.*\.jpe?g$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*?\.cloudfront\.net/.*\.jpg$',
+            'thumbnail': r're:^https?://.*?\.cloudfront\.net/.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^http://.*\.jpg$',
+            'thumbnail': r're:^http://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpe?g$',
+            'thumbnail': r're:^https?://.*\.jpe?g$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            host = re.search('.+\.([^\.]+\.[^\./]+)/.+', base_url).group(1)
+            host = re.search(r'.+\.([^\.]+\.[^\./]+)/.+', base_url).group(1)
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            m = re.match('.*-([0-9]+x[0-9]+)\.', url)
+            m = re.match(r'.*-([0-9]+x[0-9]+)\.', url)
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https://.*\.jpg',
+                'thumbnail': r're:^https://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg'
+            'thumbnail': r're:^https?://.*\.jpg'
-                'thumbnail': 're:^https?://.*\.png$',
+                'thumbnail': r're:^https?://.*\.png$',
-                'thumbnail': 're:^https?://.*\.png$',
+                'thumbnail': r're:^https?://.*\.png$',
-            'thumbnail': 're:^http://.*\.png',
+            'thumbnail': r're:^http://.*\.png',
-            'thumbnail': 're:^http://.*\.png',
+            'thumbnail': r're:^http://.*\.png',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': r're:^https?://.*\.jpg$'
-        vu_mobj = re.search('vu=([\w]+)', url)
+        uu_mobj = re.search(r'uu=([\w]+)', url)
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-        } for media_url in set(re.findall('var\s+mediaURL(?:Libsyn)?\s*=\s*"([^"]+)"', webpage))]
+        } for media_url in set(re.findall(r'var\s+mediaURL(?:Libsyn)?\s*=\s*"([^"]+)"', webpage))]
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpeg$',
+            'thumbnail': r're:^https?://.*\.jpeg$',
-            'thumbnail': 're:^https?://.*\.jpeg$',
+            'thumbnail': r're:^https?://.*\.jpeg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'var\s+programInfo\s*=\s*([^;]+)', webpage, 'VOD data', default='{}'),
+            r'var\s+programInfo\s*=\s*([^;]+)', webpage, 'VOD data', default='{}'),
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': r're:^https?://.*\.jpg$'
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': r're:^https?://.*\.jpg$'
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': r're:^https?://.*\.jpg$'
-            'thumbnail': 're:^http://.*\.jpg$'
+            'thumbnail': r're:^http://.*\.jpg$'
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': r're:^https?://.*\.jpg$'
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': r're:^https?://.*\.jpg$'
-                'isLoggedIn\s*:\s*true', r'logout\.aspx', r'>Log out<')):
+                r'isLoggedIn\s*:\s*true', r'logout\.aspx', r'>Log out<')):
-            'title': 're:^ÐÐ°ÑÑ Ð¢Ð - ÐÑÑÐ¼Ð¾Ð¹ ÑÑÐ¸Ñ \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
+            'title': r're:^ÐÐ°ÑÑ Ð¢Ð - ÐÑÑÐ¼Ð¾Ð¹ ÑÑÐ¸Ñ \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
-            webpage, 'data url', group='url').replace('\/', '/')
+            webpage, 'data url', group='url').replace(r'\/', '/')
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-        m_external = re.match('^(\w{2})-(.*)$', video_id)
+        m_external = re.match(r'^(\w{2})-(.*)$', video_id)
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:(?i)^https?://.*\.jpg$',
+            'thumbnail': r're:(?i)^https?://.*\.jpg$',
-            'thumbnail': 're:(?i)^https?://.*\.jpg$',
+            'thumbnail': r're:(?i)^https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^http://.*\.jpg$',
+            'thumbnail': r're:^http://.*\.jpg$',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': r're:^https?://.*\.jpg$'
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-        video_swfobj = self._search_regex('swfobject.embedSWF\(\'(.+?)\'', webpage, 'swfobj')
+        video_swfobj = self._search_regex(r'swfobject.embedSWF\(\'(.+?)\'', webpage, 'swfobj')
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'title': 're:^NDR Fernsehen Niedersachsen \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
+            'title': r're:^NDR Fernsehen Niedersachsen \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
-            'title': 're:^N-JOY Weltweit \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
+            'title': r're:^N-JOY Weltweit \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
-            'thumbnail': 're:https?://.*\.jpg',
+            'thumbnail': r're:https?://.*\.jpg',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                 '(?:embed/|\?v=)(?P<id>[A-Za-z0-9]{12})/?'
+                 r'(?:embed/|\?v=)(?P<id>[A-Za-z0-9]{12})/?'
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.(?:jpg)',
+            'thumbnail': r're:^https?://.*\.(?:jpg)',
-            'thumbnail': 're:^https?://.*\.(?:jpg)',
+            'thumbnail': r're:^https?://.*\.(?:jpg)',
-            'thumbnail': 're:^https?://.*\.(?:jpg)',
+            'thumbnail': r're:^https?://.*\.(?:jpg)',
-            'thumbnail': 're:^https?://.*\.(?:jpg)',
+            'thumbnail': r're:^https?://.*\.(?:jpg)',
-            'thumbnail': 're:https?://.*\.jpg(\?.*)?',
+            'thumbnail': r're:https?://.*\.jpg(\?.*)?',
-    _VALID_URL = _VALID_URL_TEMPLATE % {'host': 'novamov\.com'}
+    _VALID_URL = _VALID_URL_TEMPLATE % {'host': r'novamov\.com'}
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': '(?:wholecloud\.net|movshare\.(?:net|sx|ag))'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': r'(?:wholecloud\.net|movshare\.(?:net|sx|ag))'}
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:to|ch|ec|sx|eu|at|ag|co|li)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': r'nowvideo\.(?:to|ch|ec|sx|eu|at|ag|co|li)'}
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'videoweed\.(?:es|com)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': r'videoweed\.(?:es|com)'}
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'cloudtime\.to'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': r'cloudtime\.to'}
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'auroravid\.to'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': r'auroravid\.to'}
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^http://.*\.jpg',
+            'thumbnail': r're:^http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^http://.*\.jpg',
+            'thumbnail': r're:^http://.*\.jpg',
-            'thumbnail': 're:^http://.*\.jpg',
+            'thumbnail': r're:^http://.*\.jpg',
-            'thumbnail': 're:^http://.*\.jpg',
+            'thumbnail': r're:^http://.*\.jpg',
-            'thumbnail': 're:^http://.*\.jpg',
+            'thumbnail': r're:^http://.*\.jpg',
-            'thumbnail': 're:^http://.*\.jpg',
+            'thumbnail': r're:^http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            info['title'] = alt_title + ' - ' + re.sub(r'^' + alt_title + '[\s\-:]+', '', info['title'])
+            info['title'] = alt_title + ' - ' + re.sub(r'^' + alt_title + r'[\s\-:]+', '', info['title'])
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:(?i)^https?://.*\.(?:jpg|png)$',
+            'thumbnail': r're:(?i)^https?://.*\.(?:jpg|png)$',
-            'thumbnail': 're:(?i)^https?://.*\.(?:jpg|png)$',
+            'thumbnail': r're:(?i)^https?://.*\.(?:jpg|png)$',
-            'thumbnail': 're:(?i)^https?://.*\.(?:jpg|png)$',
+            'thumbnail': r're:(?i)^https?://.*\.(?:jpg|png)$',
-            'thumbnail': 're:(?i)^https?://.*\.(?:jpg|png)$',
+            'thumbnail': r're:(?i)^https?://.*\.(?:jpg|png)$',
-            'thumbnail': 're:(?i)^https?://.*\.(?:jpg|png)$',
+            'thumbnail': r're:(?i)^https?://.*\.(?:jpg|png)$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.png$',
+            'thumbnail': r're:^https?://.*\.png$',
-                'thumbnail': 're:^https?://static\.prsa\.pl/images/.*\.jpg$'
+                'thumbnail': r're:^https?://static\.prsa\.pl/images/.*\.jpg$'
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'var\s+contentResources\s*=\s*(\[.+?\]);\s*</script',
+                r'var\s+contentResources\s*=\s*(\[.+?\]);\s*</script',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.png',
+            'thumbnail': r're:^https?://.*\.png',
-            'thumbnail': 're:^https?://.*\.jpe?g$',
+            'thumbnail': r're:^https?://.*\.jpe?g$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            return self._search_regex('"%s"\s*:\s*"([^"]+)"' % key, video_data, key, fatal=fatal)
+            return self._search_regex(r'"%s"\s*:\s*"([^"]+)"' % key, video_data, key, fatal=fatal)
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'description': 're:^Iata-ne reveniti dupa o binemeritata vacanta\. +Va astept si pe Facebook cu pareri si comentarii.$',
+            'description': r're:^Iata-ne reveniti dupa o binemeritata vacanta\. +Va astept si pe Facebook cu pareri si comentarii.$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.png$',
+            'thumbnail': r're:^https?://.*\.png$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://screenshots\.rtl\.nl/(?:[^/]+/)*sz=[0-9]+x[0-9]+/uuid=84ae5571-ac25-4225-ae0c-ef8d9efb2aed$',
+            'thumbnail': r're:^https?://screenshots\.rtl\.nl/(?:[^/]+/)*sz=[0-9]+x[0-9]+/uuid=84ae5571-ac25-4225-ae0c-ef8d9efb2aed$',
-            'thumbnail': 're:^https?://screenshots\.rtl\.nl/(?:[^/]+/)*sz=[0-9]+x[0-9]+/uuid=f536aac0-1dc3-4314-920e-3bd1c5b3811a$',
+            'thumbnail': r're:^https?://screenshots\.rtl\.nl/(?:[^/]+/)*sz=[0-9]+x[0-9]+/uuid=f536aac0-1dc3-4314-920e-3bd1c5b3811a$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.image',
+                'thumbnail': r're:^https?://.*\.image',
-                'thumbnail': 're:^https?://.*\.image',
+                'thumbnail': r're:^https?://.*\.image',
-                'thumbnail': 're:^https?://.*\.image',
+                'thumbnail': r're:^https?://.*\.image',
-            'thumbnail': 're:^https?:.*\.jpg$'
+            'thumbnail': r're:^https?:.*\.jpg$'
-            '<iframe[^>]+src=(?P<q1>[\'"])(?P<url>(?:https?:)?//rudo\.video/vod/[0-9a-zA-Z]+)(?P=q1)',
+            r'<iframe[^>]+src=(?P<q1>[\'"])(?P<url>(?:https?:)?//rudo\.video/vod/[0-9a-zA-Z]+)(?P=q1)',
-            'thumbnail': 're:^http://.*\.jpg$',
+            'thumbnail': r're:^http://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'description': 're:(?s).* Hi, my name is Rene Dreifuss\. And I\'m here to show you some MMA.*',
+            'description': r're:(?s).* Hi, my name is Rene Dreifuss\. And I\'m here to show you some MMA.*',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.(?:gif|jpg)$',
+            'thumbnail': r're:^https?://.*\.(?:gif|jpg)$',
-            'thumbnail': 're:^https?://.*\.(?:gif|jpg)$',
+            'thumbnail': r're:^https?://.*\.(?:gif|jpg)$',
-            'thumbnail': 're:^https?://.*\.(?:gif|jpg)$',
+            'thumbnail': r're:^https?://.*\.(?:gif|jpg)$',
-            'thumbnail': 're:^https?://.*\.(?:gif|jpg)$',
+            'thumbnail': r're:^https?://.*\.(?:gif|jpg)$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.(?:jpg|png)$',
+            'thumbnail': r're:^https?://.*\.(?:jpg|png)$',
-                'thumbnail': 're:https?://.*\.jpg$',
+                'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*?\.jpg'
+            'thumbnail': r're:https?://.*?\.jpg'
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-        audio_id = re.split('\/|\.', audio_url)[-2]
+        audio_id = re.split(r'\/|\.', audio_url)[-2]
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-        if webpage.find('flashvars\.encrypted = "true"') != -1:
+        if webpage.find(r'flashvars\.encrypted = "true"') != -1:
-            'thumbnail': 're:http://.*\.jpg$',
+            'thumbnail': r're:http://.*\.jpg$',
-        video_id = self._html_search_regex('clipId=([\w-]+)', webpage, 'video id')
+        video_id = self._html_search_regex(r'clipId=([\w-]+)', webpage, 'video id')
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'description': 're:Die Badminton-WM 2014 aus Kopenhagen bei Sportdeutschland\.TV',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.image',
+            'thumbnail': r're:^https?://.*\.image',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            links = orderedSet(re.findall('<a href="(VideoPage.php\?[^"]+)">', coursepage))
+            links = orderedSet(re.findall(r'<a href="(VideoPage.php\?[^"]+)">', coursepage))
-            links = orderedSet(re.findall('<a href="(CoursePage.php\?[^"]+)">', rootpage))
+            links = orderedSet(re.findall(r'<a href="(CoursePage.php\?[^"]+)">', rootpage))
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:https?://.*\.jpg$',
+                'thumbnail': r're:https?://.*\.jpg$',
-                'thumbnail': 're:https?://.*\.jpg$',
+                'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*[\.-]jpg$',
+            'thumbnail': r're:^https?://.*[\.-]jpg$',
-            'thumbnail': 're:^http:.*\.jpg$',
+            'thumbnail': r're:^http:.*\.jpg$',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?:.*\.jpg$',
+            'thumbnail': r're:^https?:.*\.jpg$',
-            'thumbnail': 're:^https?:.*\.jpg$',
+            'thumbnail': r're:^https?:.*\.jpg$',
-            'thumbnail': 're:^https?:.*\.jpg$',
+            'thumbnail': r're:^https?:.*\.jpg$',
-            'thumbnail': 're:^https?:.*\.jpg$',
+            'thumbnail': r're:^https?:.*\.jpg$',
-            'thumbnail': 're:^https?:.*\.jpg$',
+            'thumbnail': r're:^https?:.*\.jpg$',
-            'thumbnail': 're:^https?:.*\.jpg$',
+            'thumbnail': r're:^https?:.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.+\.jpg',
+            'thumbnail': r're:^https?://.+\.jpg',
-                    if re.search('\d+k', h264_url):
+                    if re.search(r'\d+k', h264_url):
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^http://.*\.(?:jpg|png)$',
+                'thumbnail': r're:^http://.*\.(?:jpg|png)$',
-                'thumbnail': 're:^http://.*\.(?:jpg|png)$',
+                'thumbnail': r're:^http://.*\.(?:jpg|png)$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                         '\s+fo\.addVariable\("s",\s"(?P<serverid>\d+)"\);', webpage)
+                         r'\s+fo\.addVariable\("s",\s"(?P<serverid>\d+)"\);', webpage)
-            return re.sub('speed=\d+', 'speed=', unescapeHTML(vl.text))
+            return re.sub(r'speed=\d+', 'speed=', unescapeHTML(vl.text))
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg'
+            'thumbnail': r're:^https?://.*\.jpg'
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            for v in re.findall('TV2ContentboxVideo\(({.+?})\)', webpage):
+            for v in re.findall(r'TV2ContentboxVideo\(({.+?})\)', webpage):
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpe?g$',
+            'thumbnail': r're:^https?://.*\.jpe?g$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.png',
+            'thumbnail': r're:^https?://.*\.png',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.+\.jpg',
+            'thumbnail': r're:^https?://.+\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'var\s+VideoId\s*=\s*(\d+);', webpage, 'video id',
+                r'var\s+VideoId\s*=\s*(\d+);', webpage, 'video id',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            '<iframe[^>]+src=(?P<q>["\'])(?P<url>(?:https?:)?//vbox7\.com/emb/external\.php.+?)(?P=q)',
+            r'<iframe[^>]+src=(?P<q>["\'])(?P<url>(?:https?:)?//vbox7\.com/emb/external\.php.+?)(?P=q)',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-            mobj = re.search('(\d+)_(\d+)_(\d+)', mp4_url)
+            mobj = re.search(r'(\d+)_(\d+)_(\d+)', mp4_url)
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': r're:https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-    _DOMAINS_REGEX = '(?:snagfilms|snagxtreme|funnyforfree|kiddovid|winnersview|monumentalsportsnetwork|vayafilm)\.com|kesari\.tv'
+    _DOMAINS_REGEX = r'(?:snagfilms|snagxtreme|funnyforfree|kiddovid|winnersview|monumentalsportsnetwork|vayafilm)\.com|kesari\.tv'
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-                'Snag\.page\.data\s*=\s*(\[.+?\]);', webpage, 'snag'),
+                r'Snag\.page\.data\s*=\s*(\[.+?\]);', webpage, 'snag'),
-                        '/([^/]+)\.csmil/',
+                        r'/([^/]+)\.csmil/',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-                'thumbnail': 're:http://.*\.jpg',
+                'thumbnail': r're:http://.*\.jpg',
-                'thumbnail': 're:http://.*\.jpg',
+                'thumbnail': r're:http://.*\.jpg',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/user7108434',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/user7108434',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/openstreetmapus',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/openstreetmapus',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/theblnbusinessofsoftware',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/theblnbusinessofsoftware',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/user18948128',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/user18948128',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/atencio',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/atencio',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/staff',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/staff',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/user28849593',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/user28849593',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/dmci',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/dmci',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/caseydonahue',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/caseydonahue',
-                'uploader_url': 're:https?://(?:www\.)?vimeo\.com/tenfootfilms',
+                'uploader_url': r're:https?://(?:www\.)?vimeo\.com/tenfootfilms',
-                m_variable_name = re.search('(\w)\.video\.id', webpage)
+                m_variable_name = re.search(r'(\w)\.video\.id', webpage)
-            'uploader_url': 're:https?://(?:www\.)?vimeo\.com/gumfilms',
+            'uploader_url': r're:https?://(?:www\.)?vimeo\.com/gumfilms',
-            'uploader_url': 're:https?://(?:www\.)?vimeo\.com/user14430847',
+            'uploader_url': r're:https?://(?:www\.)?vimeo\.com/user14430847',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:https?://.*?\.jpg',
+            'thumbnail': r're:https?://.*?\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.(?:png|jpg)$',
+            'thumbnail': r're:^https?://.*\.(?:png|jpg)$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^http://frame\.thestaticvube\.com/snap/[0-9x]+/102e7e63057-5ebc-4f5c-4065-6ce4ebde131f\.jpg$',
+                'thumbnail': r're:^http://frame\.thestaticvube\.com/snap/[0-9x]+/102e7e63057-5ebc-4f5c-4065-6ce4ebde131f\.jpg$',
-                'thumbnail': 're:^http://frame\.thestaticvube\.com/snap/[0-9x]+/102265d5a9f-0f17-4f6b-5753-adf08484ee1e\.jpg$',
+                'thumbnail': r're:^http://frame\.thestaticvube\.com/snap/[0-9x]+/102265d5a9f-0f17-4f6b-5753-adf08484ee1e\.jpg$',
-                'thumbnail': 're:^http://frame\.thestaticvube\.com/snap/[0-9x]+/10283ab622a-86c9-4681-51f2-30d1f65774af\.jpg$',
+                'thumbnail': r're:^http://frame\.thestaticvube\.com/snap/[0-9x]+/10283ab622a-86c9-4681-51f2-30d1f65774af\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            for video_number in set(re.findall('href="/playAll/%s\?sId=(\d+)"' % playlist_id, webpage))
+            for video_number in set(re.findall(r'href="/playAll/%s\?sId=(\d+)"' % playlist_id, webpage))
-            'var\s+video\s*=\s*(.+});', page, 'info json str')
+            r'var\s+video\s*=\s*(.+});', page, 'info json str')
-            'var\s+letvurl\s*=\s*"([^"]+)', page, 'letvcloud url')
+            r'var\s+letvurl\s*=\s*"([^"]+)', page, 'letvcloud url')
-            'thumbnail': 're:^http://.*\.jpg',
+            'thumbnail': r're:^http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': r're:http://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-                'thumbnail': 're:^https?://.*\.jpg',
+                'thumbnail': r're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-                'thumbnail': 're:^https?://.*\.jpe?g',
+                'thumbnail': r're:^https?://.*\.jpe?g',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/phihag',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/phihag',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/IconaPop',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/IconaPop',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/justintimberlakeVEVO',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/justintimberlakeVEVO',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/setindia',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/setindia',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/phihag',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/phihag',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/8KVIDEO',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/8KVIDEO',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/TheAmazingAtheist',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/TheAmazingAtheist',
-                'description': 're:(?s).{100,}About the Game\n.*?The Witcher 3: Wild Hunt.{100,}',
+                'description': r're:(?s).{100,}About the Game\n.*?The Witcher 3: Wild Hunt.{100,}',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/WitcherGame',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/WitcherGame',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/LloydVEVO',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/LloydVEVO',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/deadmau5',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/deadmau5',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/olympic',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/olympic',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/AllenMeow',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/AllenMeow',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/dorappi2000',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/dorappi2000',
-                    'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/beergamesbeer',
+                    'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/beergamesbeer',
-                    'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/beergamesbeer',
+                    'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/beergamesbeer',
-                    'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/beergamesbeer',
+                    'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/beergamesbeer',
-                    'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/beergamesbeer',
+                    'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/beergamesbeer',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/IronSoulElf',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/IronSoulElf',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/BerkmanCenter',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/BerkmanCenter',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/channel/UCH1dpzjCEiGAt8CXkryhkZg',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCH1dpzjCEiGAt8CXkryhkZg',
-                'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/FlixMatrixKaravan',
+                'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/FlixMatrixKaravan',
-            'uploader_url': 're:https?://(?:www\.)?youtube\.com/channel/UCyPhqAZgwYWZfxElWVbVJng',
+            'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCyPhqAZgwYWZfxElWVbVJng',
-            'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/backuspagemuseum',
+            'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/backuspagemuseum',
-            'uploader_url': 're:https?://(?:www\.)?youtube\.com/user/TheYoungTurks',
+            'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/TheYoungTurks',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'thumbnail': r're:^https?://.*\.jpg$',
-        """
+        r"""
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': r're:^https?://.*\.jpg$',
-        """
+        r"""
-        path_part if path_part in ['.', '..'] else re.sub('(?:[/<>:"\\|\\\\?\\*]|[\s.]$)', '#', path_part)
+        path_part if path_part in ['.', '..'] else re.sub(r'(?:[/<>:"\|\\?\*]|[\s.]$)', '#', path_part)
-    match = re.match('(now|today)(?P<sign>[+-])(?P<time>\d+)(?P<unit>day|week|month|year)(s)?', date_str)
+    match = re.match(r'(now|today)(?P<sign>[+-])(?P<time>\d+)(?P<unit>day|week|month|year)(s)?', date_str)
-            unescapeHTML(container.get('data-video') or container.get('data-json')),
+            container.get('data-video') or container.get('data-json'),
-__version__ = '2017.01.02'
+__version__ = '2017.01.05'
-import functools
+from ..compat import compat_str
-    ExtractorError
+    int_or_none,
-    _VALID_URL = r'https?://www\.zdf\.de/.*?/(?P<id>[^/?]*?)\.html'
+
-            'title': 'Trailer ZDFmediathek Supermarkt',
+            'title': 'Die neue ZDFmediathek',
-    def _real_extract(self):
+    @staticmethod
-            if not video_url:
+        track_uris = set()
-        self.parent._sort_formats(formats)
+            for f in formitaeten:
-            'title': self._get_title(),
+            'id': video_id,
-            return parse_iso8601(meta.get('editorialDate'))
+    def _extract_regular(self, url, player, video_id):
-            return teaser_images[max_res].get('url')
+    def _extract_mobile(self, video_id):
-    """Extraction method that requires downloads of several pages.
+        title = document['titel']
-        ZDFExtractor.__init__(self, parent, url, video_id)
+        formats = []
-        webpage = self.parent._download_webpage(self.url, self.video_id)
+        return {
-        jsb_json = self.parent._parse_json(jsb, self.video_id)
+    def _real_extract(self, url):
-        api_token = configuration_json['apiToken']
+        webpage = self._download_webpage(url, video_id, fatal=False)
-        self.meta_data = self.parent._download_json(meta_data_url, self.video_id, note='Downloading meta data')
+        return self._extract_mobile(video_id)
-    _VALID_URL = r'(?:zdf:topic:|https?://www\.zdf\.de/ZDFmediathek(?:#)?/.*kanaluebersicht/(?:[^/]+/)?)(?P<id>[0-9]+)'
+class ZDFChannelIE(ZDFBaseIE):
-        'url': 'http://www.zdf.de/ZDFmediathek#/kanaluebersicht/1586442/sendung/Titanic',
+        'url': 'https://www.zdf.de/sport/das-aktuelle-sportstudio',
-            'id': '1586442',
+            'id': 'das-aktuelle-sportstudio',
-        'playlist_count': 3,
+        'playlist_count': 21,
-        'only_matching': True,
+        'url': 'https://www.zdf.de/dokumentation/planet-e',
-        'url': 'http://www.zdf.de/ZDFmediathek/kanaluebersicht/_/1798716?bc=nrt;nrm?flash=off',
+        'url': 'https://www.zdf.de/filme/taunuskrimi/',
-            }
+
-        }
+        webpage = self._download_webpage(url, channel_id)
-    ExtractorError,
+    parse_iso8601,
-
+from ..compat import compat_str
-    _VALID_URL = r'(?:zdf:|zdf:video:|https?://www\.zdf\.de/ZDFmediathek(?:#)?/(.*beitrag/(?:video/)?))(?P<id>[0-9]+)(?:/[^/?]+)?(?:\?.*)?'
+    _VALID_URL = r'https?://www\.zdf\.de/.*?/(?P<id>[^/?]*?)\.html'
-        'url': 'http://www.zdf.de/ZDFmediathek/beitrag/video/2037704/ZDFspezial---Ende-des-Machtpokers--?bc=sts;stt',
+        'url': 'https://www.zdf.de/service-und-hilfe/die-neue-zdf-mediathek/zdfmediathek-trailer-100.html',
-        'skip': 'Videos on ZDF.de are depublicised in short order',
+            'id': 'zdfmediathek-trailer-100',
-        self._sort_formats(formats)
+    def _real_extract(self, url):
-            raise ExtractorError(message, expected=True)
+class ZDFExtractor:
-        format_ids = []
+    def _real_extract(self):
-            if not is_available:
+        for entry in self._fetch_entries():
-
+            format_id = self._get_format_id(entry)
-                    video_url, video_id, 'mp4', m3u8_id=format_id, fatal=False))
+            if ext == 'm3u8':
-                    video_url, video_id, f4m_id=format_id, fatal=False))
+                formats.extend(self.parent._extract_f4m_formats(
-                    '_available': is_available,
+                    'format_note': self._get_format_note(entry)
-        self._sort_formats(formats)
+        self.parent._sort_formats(formats)
-            'upload_date': upload_date,
+            'id': self.video_id,
-            'subtitles': subtitles,
+            'subtitles': self._get_subtitles(),
-        return self.extract_from_xml_url(video_id, xml_url)
+class ZDFExtractorMobile(ZDFExtractor):
-        entries = self._extract_entries(webpage)
+        # Only process container div with main playlist content skipping
-        'url': 'http://www.pornhub.com/playlist/6201671',
+        'url': 'http://www.pornhub.com/playlist/4667351',
-            'title': 'P0p4',
+            'id': '4667351',
-        'playlist_mincount': 35,
+        'playlist_mincount': 2,
-    _VALID_URL = r'https?://(?:[^/]+)\.(?:cntv|cctv)\.(?:com|cn)/(?:[^/]+/)*?(?P<id>[^/?#&]+?)(?:/index)?(?:\.s?html|[?#&]|$)'
+    _VALID_URL = r'https?://(?:(?:[^/]+)\.(?:cntv|cctv)\.(?:com|cn)|(?:www\.)?ncpa-classic\.com)/(?:[^/]+/)*?(?P<id>[^/?#&]+?)(?:/index)?(?:\.s?html|[?#&]|$)'
-        'only_matching': True
+        'only_matching': True,
-             r'load[Vv]ideo\s*\(\s*["\']([\da-fA-F]+)'],
+             r'load[Vv]ideo\s*\(\s*["\']([\da-fA-F]+)',
-        description = self._html_search_meta('description', webpage)
+        description = self._html_search_meta(
-            },
+    _TESTS = [{
-    ]
+    }]
-    _VALID_URL = r'https?://(?:www\.)?tunein\.com/(?:radio/.*?-s|station/.*?StationId\=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tunein\.com/(?:radio/.*?-s|station/.*?StationId=|embed/player/s)(?P<id>\d+)'
-            },
+    _TESTS = [{
-    ]
+    }, {
-    _VALID_URL = r'https?://(?:www\.)?tunein\.com/(?:radio/.*?-p|program/.*?ProgramId\=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tunein\.com/(?:radio/.*?-p|program/.*?ProgramId=|embed/player/p)(?P<id>\d+)'
-            },
+    _TESTS = [{
-    ]
+        'params': {
-    _VALID_URL = r'https?://(?:www\.)?tunein\.com/topic/.*?TopicId\=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tunein\.com/(?:topic/.*?TopicId=|embed/player/t)(?P<id>\d+)'
-            },
+    _TESTS = [{
-    ]
+    }, {
-             r'"load[Vv]ideo\s*\(\s*["\']([\da-fA-F]+)'],
+             r'changePlayer\s*\(\s*["\']([\da-fA-F]+)',
-__version__ = '2016.12.31'
+__version__ = '2017.01.02'
-    _VALID_URL = r'https?://(?:[^/]+)\.(?:cntv|cctv)\.(?:com|cn)/(?:[^/]+/)*?(?P<id>[^/?#&]+?)(?:/index)?\.s?html'
+    _VALID_URL = r'https?://(?:[^/]+)\.(?:cntv|cctv)\.(?:com|cn)/(?:[^/]+/)*?(?P<id>[^/?#&]+?)(?:/index)?(?:\.s?html|[?#&]|$)'
-            webpage, 'video id', default=video_id)
+            webpage, 'video id')
-from ..utils import float_or_none
+from ..compat import compat_str
-        )'''
+    IE_DESC = 'å¤®è§ç½'
-        'md5': '819c7b49fc3927d529fb4cd555621823',
+        'url': 'http://sports.cntv.cn/2016/02/12/ARTIaBRxv4rTT1yWf1frW2wi160212.shtml',
-            'id': '454368eb19ad44a1925bf1eb96140a61',
+            'id': '5ecdbeab623f4973b40ff25f18b174e8',
-        }
+            'title': '[NBA]äºå°èæç ä¸46å é·éä¸»åºå»è´¥é¹é¹ï¼å¿«è®¯ï¼',
-        m3u8_url = re.sub(r'maxbr=\d+&?', '', api_data['hls_url'])
+        video_id = self._match_id(url)
-            'duration': float_or_none(api_data.get('video', {}).get('totalLength')),
+            'title': title,
-from .cntv import CntvIE
+# coding: utf-8
-    _VALID_URL = r'https?://(?:tv|radio)\.nrk(?:super)?\.no/(?:serie/[^/]+|program)/(?P<id>[a-zA-Z]{4}\d{8})(?:/\d{2}-\d{2}-\d{4})?(?:#del=(?P<part_id>\d+))?'
+    _EPISODE_RE = r'(?P<id>[a-zA-Z]{4}\d{8})'
-    _VALID_URL = r'https?://(?:www\.)?nrk\.no/(?!video|skole)(?:[^/]+/)+(?P<id>[^/]+)'
+class NRKPlaylistBaseIE(InfoExtractor):
-        playlist_id = self._match_id(url)
+    def _extract_title(self, webpage):
-        webpage = self._download_webpage(url, playlist_id)
+    def _extract_description(self, webpage):
-        playlist_description = self._og_search_description(webpage)
+class NRKTVEpisodesIE(NRKPlaylistBaseIE):
-            entries, playlist_id, playlist_title, playlist_description)
+    def _extract_title(self, webpage):
-    _VALID_URL = r'https?://play\.arkena\.com/(?:config|embed)/avp/v\d/player/media/(?P<id>[^/]+)/[^/]+/(?P<account_id>\d+)'
+    _VALID_URL = r'''(?x)
-__version__ = '2016.12.22'
+__version__ = '2016.12.31'
-
+        'config_location': opts.config_location,
-        help='File to read configuration from.')
+        '--config-location',
-
+        system_conf = user_conf = custom_conf = []
-            else:
+            if '--ignore-config' not in system_conf:
-            write_string('[debug] Command-line args: ' + repr(_hide_login_info(command_line_conf)) + '\n')
+            for conf_label, conf in (
-    _VALID_URL = r'%s/(?:[^/]+/v/|\?video=v)(?P<id>\d+)' % _VALID_URL_BASE
+    _VALID_URL = r'''(?x)
-    }, {
+    }, {
-    _VALID_URL = r'%s/[^/]+/v/(?P<id>\d+)' % TwitchBaseIE._VALID_URL_BASE
+    _VALID_URL_BASE = r'https?://(?:www\.|player\.)?twitch\.tv'
-        help='Two-factor auth code')
+        help='Two-factor authentication code')
-        help='Set file xattribute ytdl.filesize with expected filesize (experimental)')
+        help='Set file xattribute ytdl.filesize with expected file size (experimental)')
-)
+from .videa import VideaIE
-    parse_duration,
+    mimetype2ext,
-    _VALID_URL = r'https?://(?:.+?\.)?videa\.hu/videok/(?P<id>[^#?]+)'
+    _VALID_URL = r'''(?x)
-            'display_id': '8YfIAjxwWGwT8HVQ',
+    }, {
-            r'src="(.+?)"', video_data.get('html'), 'embed url')
+        info = self._download_xml(
-        }
+        video = xpath_element(info, './/video', 'video', fatal=True)
-    }];
+        title = xpath_text(video, './title', fatal=True)
-            return mobj.group('url')
+        formats = []
-        xml = self._download_xml(protocol + base_url + "/flvplayer_get_video_xml.php?v=" + display_id, display_id)
+        thumbnail = xpath_text(video, './poster_src')
-            medias.append(media)
+        age_limit = None
-        return medias[0]
+        return {
-            # finished live stream, live_mp4
+            # finished live stream, postlive_mp4
-            # live stream, hls and rtmp links,most likely already finished live
+            # live stream, hls and rtmp links, most likely already finished live
-            if format_id.startswith(('url', 'cache')) or format_id in ('extra_data', 'live_mp4'):
+            if (format_id.startswith(('url', 'cache')) or
-                video_id)['player']['params'][0]
+                    r'<!json>\s*({.+?})\s*<!>', info_page, 'json', default='{}'),
-        if data.get('live') == 2:
+        is_live = data.get('live') == 2
-                    fatal=False, live=True))
+                    format_url, video_id, 'mp4',
-from .showroomlive import ShowroomLiveIE
+from .showroomlive import ShowRoomLiveIE
-from ..utils import ExtractorError, compat_urlparse
+from ..compat import compat_str
-    _VALID_URL = r'https?://(?:www\.)?showroom-live\.com/(?P<id>[0-9a-zA-Z_]+)'
+class ShowRoomLiveIE(InfoExtractor):
-        }
+        'only_matching': True,
-            raise ExtractorError('%s their showroom is not live' % broadcaster_id)
+        room_id = self._search_regex(
-        title = room.get('room_name', room.get('main_name', "%s's Showroom" % uploader))
+        room = self._download_json(
-        }
+        is_live = room.get('is_onlive')
-        formats = []
+        uploader = room.get('performer_name') or broadcaster_id
-        streaming_url_list = self._download_json(stream_url, broadcaster_id).get('streaming_url_list', [])
+        streaming_url_list = self._download_json(
-                url = stream.get('url') + '/' + stream.get('stream_name')
+            stream_url = stream.get('url')
-                    'protocol': 'rtmp',
+                    'url': stream_url,
-                    'format_note': stream.get('label')
+                    'format_id': 'rtmp',
-        return formats
+
-    float_or_none,
+    parse_duration,
-            'duration': 893.52,
+            'duration': 893,
-            'duration': 200.48,
+            'duration': 200,
-            'duration': 72.0,
+            'duration': 72,
-            webpage, 'duration', fatal=False, group='duration'))
+        duration = parse_duration(self._search_regex(
-            r'playerId=player([0-9]+)', webpage, 'internal video ID')
+            (r'playerId=player([0-9]+)',
-                    with the "ext" entry and one of:
+                    {tag: subformats}. "tag" is usually a language code, and
-            webpage)
+            r'''(?x)
-            url = unescapeHTML(url_m.group(1))
+            url = unescapeHTML(url_m.group('url'))
-            if 'playerKey' in url or 'videoId' in url:
+            if 'playerKey' in url or 'videoId' in url or 'idVideo' in url:
-        url = re.sub(r'(?<=[?&])(videoI(d|D)|bctid)', '%40videoPlayer', url)
+        url = re.sub(r'(?<=[?&])(videoI(d|D)|idVideo|bctid)', '%40videoPlayer', url)
-        # http requests
+            # embedded brightcove video
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'timestamp': 1196172000000,
+            'timestamp': 1196172000,
-            'url': cast_data['blings'][0]['audio'],
+            'url': [b['audio'] for b in cast_data['blings'] if b['type'] == 'BlingAudio'][0],
-            'timestamp': int_or_none(cast_data.get('publishingDate')),
+            'timestamp': parse_iso8601(cast_data.get('publishingDate')),
-__version__ = '2016.12.20'
+__version__ = '2016.12.22'
-        audio_groups = set()
+        audio_in_video_stream = {}
-                        for v in (media.get('GROUP-ID'), media.get('NAME')):
+                        for v in (group_id, media.get('NAME')):
-                            audio_groups.add(media['GROUP-ID'])
+                            if group_id and not audio_in_video_stream.get(group_id):
-                if last_info.get('AUDIO') in audio_groups:
+                if audio_in_video_stream.get(last_info.get('AUDIO')) is False:
-        meta = self._download_xml(smil_url, video_id, note=note, query={'format': 'SMIL'})
+        meta = self._download_xml(
-            })
+            }, headers=self.geo_verification_headers())
-            'description': 'Matthias, Det und Helge treten gegeneinander an.'
+            'description': 'md5:e3adbb940fd3c6e76fa341b8748b562f'
-            'description': 'Anna ist Alex\' Tochter bei KÃ¶ln 50667.'
+            'description': 'Anna nimmt ihrem Vater nicht ab, dass er nicht spielt. Und tatsÃ¤chlich erwischt sie ihn auf frischer Tat.'
-        info = self._download_json(info_url, video_id)
+        info = self._download_json(
-        rtmp_conn = ['S:connect', 'O:1', 'NS:pageUrl:' + url, 'NB:fpad:0', 'NN:videoFunction:1', 'O:0']
+        formats = []
-            'description': description,
+            'thumbnail': video_info.get('image'),
-                webpage.replace('"/*@context"', '"@context"'), video_id)
+                webpage.replace('"/*@context"', '"@context"'), video_id,
-        formats = self._extract_m3u8_formats('http://content.uplynk.com/%s.m3u8' % path, display_id, 'mp4')
+        formats = self._extract_m3u8_formats(
-        get_flashvar = lambda x: self._search_regex(r'%s\s*:\s*"([^"]+)"' % x, flash_vars, x)
+
-            }, data=data_abo)['data']['stream-access'][0]
+        token_url = None
-__version__ = '2016.12.18'
+__version__ = '2016.12.20'
-from ..utils import urlencode_postdata
+from ..utils import ExtractorError
-    _VALID_URL = r'https?://(?:www\.)?vbox7\.com/(?:play:|emb/external\.php\?.*?\bvid=)(?P<id>[\da-fA-F]+)'
+    _VALID_URL = r'''(?x)
-            r'<title>(.+?)</title>', webpage, 'title').split('/')[0].strip()
+        response = self._download_json(
-            webpage, 'video url', default=None, group='url')
+        if 'error' in response:
-        thumbnail_url = self._og_search_thumbnail(webpage)
+        video = response['options']
-                lambda x: x.split('=')[1], info_response.split('&'))
+        title = video['title']
-        return {
+        uploader = video.get('uploader')
-        }
+            'url': video_url,
-        self._sort_formats(formats, field_preference=('preference', 'height', 'width', 'fps', 'format_id'))
+        self._sort_formats(formats, field_preference=('preference', 'height', 'width', 'fps', 'tbr', 'format_id'))
-        video_title = config['video']['title']
+        video_title = video_data['title']
-        video_uploader_url = config['video'].get('owner', {}).get('url')
+        video_uploader = video_data.get('owner', {}).get('name')
-        video_thumbnail = config['video'].get('thumbnail')
+        video_thumbnail = video_data.get('thumbnail')
-            video_thumbs = config['video'].get('thumbs')
+            video_thumbs = video_data.get('thumbs')
-        video_duration = int_or_none(config['video'].get('duration'))
+        video_duration = int_or_none(video_data.get('duration'))
-        config_files = config['video'].get('files') or config['request'].get('files', {})
+        config_files = video_data.get('files') or config['request'].get('files', {})
-                m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+
-                            'acodec': 'none' if content_type == 'video' else representation_attrib.get('codecs'),
+                        f.update(parse_codecs(representation_attrib.get('codecs')))
-                                fragment['url'] = combine_url(base_url, fragment['url'])
+                                fragment['url'] = urljoin(base_url, fragment['url'])
-                        (?P<q4>['\"])(?P<id>(?:(?!(?P=q4)).)+)(?P=q4),
+                        (?P<q4>['\"])(?P<id>(?:(?!(?P=q4)).)+)(?P=q4)(?:,|\s*\})
-                    'title': entry_title,
+                    'title': make_title(entry_title),
-                    'title': title,
+                    'title': make_title(title),
-        conviva = data.get('convivaStatistics') or {}
+class NRKTVDirekteIE(NRKTVIE):
-                'Downloading %s video url info' % (redirect_id or num))
+                'Downloading %s video url info' % (redirect_id or num),
-            if ext == 'ism':
+            if ext == 'ism' or container == 'WVM':
-        hls_file = video_data.get('hlsfile')
+        # #EXT-X-BYTERANGE is not supported by native hls downloader
-                r'\1whe\2', video_data['href'])
+            # m3u8_url = re.sub(
-    def _get_viu_auth(self, video_id):
+    def _real_initialize(self):
-                'userid': 'guest', 'useridtype': 'guest', 'ver': '1.0'
+            'https://www.viu.com/api/apps/v2/authenticate', None,
-        return viu_auth_res.info().get('X-VIU-AUTH')
+        self._auth_token = viu_auth_res.info()['X-VIU-AUTH']
-    _VALID_URL = r'https?://www\.viu\.com/.+/(?:vod|media)/(?P<id>[0-9]+)'
+    _VALID_URL = r'(?:viu:|https?://www\.viu\.com/[a-z]{2}/media/)(?P<id>\d+)'
-            'title': 'Citizen Khan - Episode 1',
+            'title': 'Citizen Khan - Ep 1',
-            })
+        video_data = self._call_api(
-        episode_num = int_or_none(episode_info.get('number'))
+        for key, value in video_data.items():
-            'thumbnail': thumbnail,
+            'description': video_data.get('description'),
-    _VALID_URL = r'https?://www\.viu\.com/.+/listing/(?P<id>playlist\-[0-9]+)'
+    _VALID_URL = r'https?://www\.viu\.com/[^/]+/listing/playlist-(?P<id>\d+)'
-            'id': 'playlist-22461380',
+            'id': '22461380',
-        return self.playlist_result(entries, playlist_id, name)
+        playlist_data = self._call_api(
-__version__ = '2016.12.15'
+__version__ = '2016.12.18'
-from .laola1tv import Laola1TvIE
+from .laola1tv import (
-    sanitized_Request,
+    urljoin,
-    _VALID_URL = r'https?://(?:www\.)?laola1\.tv/(?P<lang>[a-z]+)-(?P<portal>[a-z]+)/(?P<kind>[^/]+)/(?P<slug>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?laola1\.tv/[a-z]+-[a-z]+/[^/]+/(?P<id>[^/?#&]+)'
-        portal = mobj.group('portal')
+        display_id = self._match_id(url)
-        iframe_url = self._search_regex(
+        iframe_url = urljoin(url, self._search_regex(
-        categories = categories_str.split(',') if categories_str else []
+            webpage, 'iframe url'))
-            'id': video_id,
+            '_type': 'url',
-            'formats': formats,
+            'url': iframe_url,
-                'id': '269389891880',
+                'id': 'p_tweet_snow_140529',
-                'id': '394064451844',
+                'id': 'nn_netcast_150204',
-                'id': '529953347624',
+                'id': 'x_lon_vwhorn_150922',
-                'id': '669831235788',
+                'id': 'tdy_al_space_160420',
-                'id': '314487875924',
+                'id': 'n_hayes_Aimm_140801_272214',
-                    webpage, 'bootstrap json', default=None)
+            webpage = self._download_webpage(url, video_id)
-                video_id = info['mpxId']
+
-                'url': 'http://feed.theplatform.com/f/2E2eJC/nnd_NBCNews?byId=%s' % video_id,
+                'url': update_url_query('http://feed.theplatform.com/f/2E2eJC/nnd_NBCNews', {filter_param: video_id}),
-    def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None, m3u8_entry_protocol='m3u8'):
+    def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None, m3u8_entry_protocol='m3u8', mpd_id=None):
-            if determine_ext(full_url) == 'm3u8':
+            ext = determine_ext(full_url)
-                'Downloading %s videos JSON page %s'
+                'Downloading %s JSON page %s'
-    _PLAYLIST_PATH = TwitchPlaylistBaseIE._PLAYLIST_PATH + '&broadcasts=true'
+class TwitchVideosBaseIE(TwitchPlaylistBaseIE):
-        'url': 'http://www.twitch.tv/spamfish/profile/past_broadcasts',
+        'url': 'https://www.twitch.tv/spamfish/videos/past-broadcasts',
-        'playlist_mincount': 54,
+        'playlist_mincount': 805,
-from ..utils import parse_iso8601
+from ..utils import (
-        },
+    _TESTS = [{
-    ]
+        'url': 'http://www.meipai.com/media/585526361',
-                r'<title[^>]*>(.+)</title>', webpage, 'title')
+        title = self._og_search_title(
-        release_date = parse_iso8601(release_date)
+        formats = []
-        info = {
+        view_count = int_or_none(self._html_search_meta(
-                'video:director', webpage, 'creator', fatal=False),
+            'thumbnail': self._og_search_thumbnail(webpage),
-        return info
+from .meipai import MeipaiIE
-import re
+from .jwplatform import JWPlatformBaseIE
-class OnDemandKoreaIE(InfoExtractor):
+class OnDemandKoreaIE(JWPlatformBaseIE):
-            raise ExtractorError('Unable to access page. You may have been blocked.', expected=True)
+            raise ExtractorError(
-        
+            self.raise_geo_restricted(
-            raise ExtractorError('This video is only available to ODK PLUS members.', expected=True)
+            raise ExtractorError(
-        self._sort_formats(formats)
+        jw_config = self._parse_json(
-            'id': video_id,
+        info.update({
-        }
+            'thumbnail': self._og_search_thumbnail(webpage),
-                'duration': float_or_none(jwplayer_data.get('duration')),
+                'duration': float_or_none(jwplayer_data.get('duration') or video_data.get('duration')),
-                        })
+                    if track.get('kind') != 'captions':
-    if re.match(r'https?://', path):
+    if re.match(r'^(?:https?:)?//', path):
-    if not isinstance(base, compat_str) or not re.match(r'https?://', base):
+    if not isinstance(base, compat_str) or not re.match(r'^(?:https?:)?//', base):
-            thumbnail = 'http://www.vporn.com' + thumbnail
+        thumbnail = urljoin('http://www.vporn.com', self._html_search_regex(
-                    })
+        self._conn_id = self._download_json(
-__version__ = '2016.12.12'
+__version__ = '2016.12.15'
-    _VALID_URL = r'https?://openload\.(?:co|io)/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
+    _VALID_URL = r'https?://(?:openload\.(?:co|io)|oload\.tv)/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
-                        (?:[\w-]+\.)?facebook\.com/
+                        (?:[\w-]+\.)?(?:facebook\.com|facebookcorewwwi\.onion)/
-                    is_live=True)
+        info = self._get_common_fields(webpage)
-                    subtitles=subtitles)
+        info = self._get_common_fields(webpage)
-            transform_source=lambda s: '[' + s + ']')
+        VIDEO_PARAMS_RE = r'\bvlive\.video\.init\(([^)]+)'
-        status, long_video_id, key = video_params[2], video_params[5], video_params[6]
+        params = self._parse_json(self._search_regex(
-            video_id, data="videoSeq=%s" % video_id, headers={
+            video_id, note='Downloading live webpage',
-            init_page, 'video params')
+            init_page, 'live stream info')
-            r'"\s*,\s*"', video_params)[2:8]
+        video_params = self._parse_json(self._search_regex(
-            return self._live(video_id, webpage, live_params)
+            return self._live(video_id, webpage)
-    def _live(self, video_id, webpage, live_params):
+    def _live(self, video_id, webpage):
-from ..utils import int_or_none
+from ..utils import (
-    _VALID_URL = r'https?://vod\.melon\.com/video/detail2\.html?.*mvId=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://vod\.melon\.com/video/detail2\.html?\?.*?mvId=(?P<id>[0-9]+)'
-            'title': 'Jessica \'Wonderland\' MV Making Film',
+            'title': "Jessica 'Wonderland' MV Making Film",
-        )
+            note='Downloading player info JSON', query={'mvId': video_id})
-        formats = self._extract_m3u8_formats(m3u8_url, video_id, 'mp4', m3u8_id='hls')
+            note='Downloading streaming info JSON',
-        thumbnail = info.get('staticDomain', '') + stream_info.get('imgPath', '')
+        artist_list = play_info.get('artistList')
-        upload_date = stream_info.get('mvSvcOpenDt', '')[:8]
+        upload_date = stream_info.get('mvSvcOpenDt', '')[:8] or None
-__version__ = '2016.12.09'
+__version__ = '2016.12.12'
-                # ourselves
+                # ourselves. Also fragments' URLs are only served signed for
-                    m3u8_format['url'] = update_url_query(m3u8_format['url'], query)
+                    m3u8_format.update({
-                break
+                video_item = item[2][0]
-             r'id=["\']canal_video_player(?P<id>\d+)'],
+             r'id=["\']canal_video_player(?P<id>\d+)',
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?mixcloud\.com/([^/]+)/(?!stream|uploads|favorites|listens|playlists)([^/]+)'
+    _VALID_URL = r'https?://(?:(?:www|beta|m)\.)?mixcloud\.com/([^/]+)/(?!stream|uploads|favorites|listens|playlists)([^/]+)'
-    _VALID_URL = r'https?://(?:www\.)?ctvnews\.ca/(?:video\?(?:clip|playlist|bin)Id=|.*?)(?P<id>[0-9.]+)'
+    _VALID_URL = r'https?://(?:.+?\.)?ctvnews\.ca/(?:video\?(?:clip|playlist|bin)Id=|.*?)(?P<id>[0-9.]+)'
-                f['acodec'] = 'none'
+        audio_groups = set()
-                        formats.append({
+                        f = {
-                        })
+                        }
-                        f['acodec'] = 'none'
+from ..compat import compat_HTTPError
-
+class RteBaseIE(InfoExtractor):
-            item_id)
+        try:
-)
+from ..compat import compat_str
-    xpath_text,
+    determine_ext,
-    _VALID_URL = r'rts:(?P<rts_id>\d+)|https?://(?:www\.)?rts\.ch/(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html'
+    _VALID_URL = r'rts:(?P<rts_id>\d+)|https?://(?:.+?\.)?rts\.ch/(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html'
-            'md5': 'f254c4b26fb1d3c183793d52bc40d3e7',
+            'md5': 'ff7f8450a90cf58dacb64e29707b4a8e',
-                'view_count': int,
+                'id': '5624065',
-            }
+            'playlist_mincount': 4,
-            'md5': 'b4326fecd3eb64a458ba73c73e91299d',
+            'params': {
-            'md5': '9f713382f15322181bb366cc8c3a4ff0',
+            'md5': '1bae984fe7b1f78e94abc74e802ed99f',
-                'uploader': 'Le Journal en continu',
+                'uploader': 'L\'actu en vidÃ©o',
-            }
+        },
-            page = self._download_webpage(url, display_id)
+            entries = []
-            if not videos:
+            for item in all_info.get('items', []):
-                    r'(?s)<iframe[^>]+class="srg-player"[^>]+src="[^"]+urn:([^"]+)"',
+                    r'<article[^>]+class="content-item"[^>]*>\s*<a[^>]+data-video-urn="urn:([^"]+)"',
-                return self.playlist_result(entries, media_id, self._og_search_title(page))
+                if not videos:
-        thumbnail = unescapeHTML(info.get('preview_image_url'))
+        title = info['title']
-            if format_id == 'hds_sd' and 'hds' in info['streams']:
+        streams = info.get('streams', {})
-            if format_id == 'hls_sd' and 'hls' in info['streams']:
+            if format_id == 'hls_sd' and 'hls' in streams:
-                    format_url, media_id, 'mp4', 'm3u8_native', m3u8_id=format_id, fatal=False))
+            ext = determine_ext(format_url)
-            } for media in info['media'] if media.get('rate')])
+        for media in info.get('media', []):
-            'title': info['title'],
+            'title': title,
-            'view_count': view_count,
+            'view_count': int_or_none(info.get('plays')),
-            'thumbnail': thumbnail,
+            'timestamp': parse_iso8601(info.get('broadcast_date')),
-                        m3u8_id=format_id, fatal=False))
+                if protocol.startswith('HTTP-HDS') or protocol.startswith('HTTP-HLS'):
-        'md5': '4cd93523723beff51bb4bee974ee238d',
+        'md5': 'da6b5b3ac9fa4761a942331cef20fcb3',
-            'ext': 'm4v',
+            'ext': 'mp4',
-__version__ = '2016.12.01'
+__version__ = '2016.12.09'
-import re
+from __future__ import unicode_literals
-)
+from ..compat import compat_chr
-            webpage, 'encrypted data')
+        ol_id = self._search_regex(
-                                           webpage, 'encrypted code')
+        first_two_chars = int(float(ol_id[0:][:2]))
-        jsi = JSInterpreter(js_code)
+        while num < len(ol_id):
-        video_url = 'https://openload.co/stream/%s?mime=true' % ''.join(video_url_chars)
+        video_url = 'https://openload.co/stream/' + urlcode
-                data=urlencode_postdata(post_data), 
+            play_url = self._download_json(
-            })
+                    'Content-Type': 'application/x-www-form-urlencoded',
-    _VALID_URL = r'https?://(?:www\.)?(?:telebruxelles|bx1)\.be/(news|sport|dernier-jt)/?(?P<id>[^/#?]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:telebruxelles|bx1)\.be/(news|sport|dernier-jt|emission)/?(?P<id>[^/#?]+)'
-        'md5': '59439e568c9ee42fb77588b2096b214f',
+        'url': 'http://bx1.be/news/que-risque-lauteur-dune-fausse-alerte-a-la-bombe/',
-            'skip_download': 'requires rtmpdump'
+            'id': '158856',
-        'md5': '181d3fbdcf20b909309e5aef5c6c6047',
+        'url': 'http://bx1.be/sport/futsal-schaerbeek-sincline-5-3-a-thulin/',
-            'skip_download': 'requires rtmpdump'
+            'id': '158433',
-            'rtmp_live': True  # if rtmpdump is not called with "--live" argument, the download is blocked and can be completed
+            'formats': formats,
-            r'["\']bmmrId["\']\s*:\s*(["\'])(?P<url>.+?)\1',
+            (r'["\']bmmrId["\']\s*:\s*(["\'])(?P<url>(?:(?!\1).)+)\1',
-                'id': item.get('id') or uid,
+                'id': compat_str(item.get('id') or item['uid']),
-            r'data-video-id=(["\'])(?P<code>.+?)\1',
+            r'data-ooyala-id=(["\'])(?P<code>(?:(?!\1).)+)\1',
-class ProxyError(IOError):
+class ProxyError(socket.error):
-                raise IOError('{0} bytes missing'.format(cnt - len(data)))
+                raise EOFError('{0} bytes missing'.format(cnt - len(data)))
-from ..compat import compat_urlparse
+from ..compat import (
-            'description': 'md5:36a39c1d19618fec57d12efe212a8370',
+            'title': 'ÐÐ¾ÑÑÑ ÐÑÐ´Ð¼Ð¸Ð»Ð° Ð¡ÐµÐ½ÑÐ¸Ð½Ð°. ÐÐ°ÐµÐ´Ð¸Ð½Ðµ ÑÐ¾Â Ð²ÑÐµÐ¼Ð¸. ÐÑÐ¿ÑÑÐº Ð¾ÑÂ 12.02.2015',
-            'description': 'md5:a242eea0031fd180a4497d52640a9572',
+            'title': 'ÐÐµÑÐµÐ½Ð½ÑÑ Ð°Ð»Ð»ÐµÑÐ³Ð¸Ñ. ÐÐ¾Ð±ÑÐ¾Ðµ ÑÑÑÐ¾. Ð¤ÑÐ°Ð³Ð¼ÐµÐ½Ñ Ð²ÑÐ¿ÑÑÐºÐ° Ð¾ÑÂ 07.04.2016',
-            r'data-playlist-url="([^"]+)', webpage, 'playlist url'))
+            r'data-playlist-url=(["\'])(?P<url>(?:(?!\1).)+)\1',
-                'quality': quality(fname),
+            entries.append({
-            webpage, 'title', default=None) or item['title']
+            webpage, 'title', default=None) or self._og_search_title(
-            'ya:ovs:upload_date', webpage, 'upload date', fatal=False))
+            'description', webpage, 'description', default=None)
-        }
+        return self.playlist_result(entries, display_id, title, description)
-            msg = self.CODES.get(code) and 'unknown error'
+            msg = self.CODES.get(code) or 'unknown error'
-        'md5': '8ff93eb073449f151d6b90c0ae1ef0c7',
+        'md5': 'a97a65f7e823ae10e9244bc5433d5fe6',
-            'assetTypes': 'medium_video_s3'
+            'assetTypes': 'high_video_s3'
-        'playlist_mincount': 24,
+        'playlist_mincount': 23,
-                    'switch': 'hls'
+                    'switch': 'hls',
-                        'switch': 'hls'
+                        'switch': 'hls',
-    _VALID_URL = r'https?://(?:www\.)?thisoldhouse\.com/(?:watch|how-to)/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?thisoldhouse\.com/(?:watch|how-to|tv-episode)/(?P<id>[^/?#]+)'
-        'md5': '568acf9ca25a639f0c4ff905826b662f',
+        'md5': '946f05bbaa12a33f9ae35580d2dfcfe3',
-__version__ = '2016.11.27'
+__version__ = '2016.12.01'
-    _CLIENT_ID = '02gUJC0hH2ct1EGOcYXQIzRFU91c72Ea'
+    _CLIENT_ID = 'fDoItMDbsbZz8dY16ZzARCZmzgHBPotA'
-        (video-clips|episodes|cc-studios|video-collections|shows)
+        (video-clips|episodes|cc-studios|video-collections|shows(?=/[^/]+/(?!full-episodes)))
-        (?:full-episodes)
+        (?:full-episodes|shows(?=/[^/]+/full-episodes))
-        'url' : 'http://m.liveleak.com/view?i=763_1473349649',
+        'url': 'http://m.liveleak.com/view?i=763_1473349649',
-        }
+        },
-                    r'<iframe[^>]+src="((?:(?:http://www.prochan.com/embed\?)|(?:http://www.youtube.com/embed))[^"]+)"',
+                    r'<iframe[^>]+src="(https?://(?:www\.)?(?:prochan|youtube)\.com/embed[^"]+)"',
-                    r'<iframe[^>]+src="(http://www.prochan.com/embed\?[^"]+)"',
+                    r'<iframe[^>]+src="((?:(?:http://www.prochan.com/embed\?)|(?:http://www.youtube.com/embed))[^"]+)"',
-    def _extract_mgid(self, webpage):
+    def _extract_mgid(self, webpage, default=NO_DEFAULT):
-                r'embed/(mgid:.+?)["\'&?/]', sm4_embed, 'mgid')
+                r'embed/(mgid:.+?)["\'&?/]', sm4_embed, 'mgid', default=default)
-        (video-clips|episodes|cc-studios|video-collections|full-episodes|shows)
+        (video-clips|episodes|cc-studios|video-collections|shows)
-    _VALID_URL = r'https?://(?:www\.)?teamfourstar\.com/(?P<id>[a-z0-9\-]+)/?'
+    _VALID_URL = r'https?://(?:www\.)?teamfourstar\.com/(?P<id>[a-z0-9\-]+)'
-            'description': 'Episode 1: The Return of Raditz! â¦ Waitâ¦\nCast\nMasakoX â Goku, Roshi\nLanipator â Piccolo, Radditz, Krillin, Vegeta\nVegeta3986 â Radditz, Yamcha, Oolong, Gohan\nHbi2k â Farmer with Shotgun\nMegami33 â Bulma, Puar\nTakahata101 â Nappa\nKaiserNeko â SpacePod\nSongs\nMorgenstemning by Edvard Hagerup Grieg\nCha-La-Head-Cha-La by Kageyama Hiranobu\nWE DO NOT OWN DRAGONBALL. DragonBall is Owned by TOEI ANIMATION, Ltd. and Licensed by FUNimation Productions, Ltd.. All Rights Reserved. DragonBall, DragonBall Z, DragonBall GT and all logos, character names and distinctive likenesses thereof are trademarks of TOEI ANIMATION, Ltd.\nThis is nothing more than a Parody made for entertainment purposes only.',            
+            'description': 'md5:d60bc389588ebab2ee7ad432bda953ae',
-            r'<h1 class="entry-title">(?P<title>.+?)</h1>',
+            r'<h1[^>]+class="entry-title"[^>]*>(?P<title>.+?)</h1>',
-            r'<span class="meta-date date updated">(?P<date>.+?)</span>',
+            r'<span[^>]+class="meta-date date updated"[^>]*>(?P<date>.+?)</span>',
-            r'(?s)<div class="content-inner">.*?(?P<description><p>.+?)</div>',
+            r'(?s)<div[^>]+class="content-inner"[^>]*>.*?(?P<description><p>.+?)</div>',
-from .screenwavemedia import ScreenwaveMediaIE, TeamFourIE
+from .teamfourstar import TeamFourStarIE
-from .screenwavemedia import ScreenwaveMediaIE
+from .jwplatform import JWPlatformIE
-        'add_ie': ['ScreenwaveMedia'],
+        'add_ie': ['JWPlatform'],
-            group='url')
+        jwplatform_url = JWPlatformIE._extract_url(webpage)
-            'ie_key': ScreenwaveMediaIE.ie_key(),
+            'url': jwplatform_url,
-        }
+# coding: utf-8
-__version__ = '2016.11.22'
+__version__ = '2016.11.27'
-    _VALID_URL = r'https?://(?:www\.)?azubu\.tv/[^/]+#!/play/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?azubu\.(?:tv|uol.com.br)/[^/]+#!/play/(?P<id>\d+)'
-    _VALID_URL = r'https?://(?:www\.)?azubu\.tv/(?P<id>[^/]+)$'
+    _VALID_URL = r'https?://(?:www\.)?azubu\.(?:tv|uol.com.br)/(?P<id>[^/]+)$'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                        entry_protocol='m3u8_native', preference=-1,
+                        entry_protocol='m3u8_native',
-import hmac
+import hmac
-                        format_dict['url'], video_id, 'mp4',
+                        format_url, video_id, 'mp4',
-                        'url': format_dict['url'],
+                        'url': format_url,
-    _VALID_URL = r'https?://(?:www\.)?puls4\.com/(?P<id>(?:[^/]+/)*?videos/[^?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?puls4\.com/(?P<id>[^?#&]+)'
-        'expected_warnings': ['Unable to download SMIL file'],
+        'expected_warnings': ['Unable to download SMIL file', 'Unable to download info'],
-        'expected_warnings': ['Unable to download SMIL file'],
+        'expected_warnings': ['Unable to download SMIL file', 'Unable to download info'],
-        'expected_warnings': ['Unable to download SMIL file'],
+        'expected_warnings': ['Unable to download SMIL file', 'Unable to download info'],
-                        artist = uploader = curr_artist['name']
+                if curr_artist.get('role') == 'Featured':
-            'title': 'K Camp - Till I Die',
+            'title': 'K Camp ft. T.I. - Till I Die',
-            'genre': 'Rap/Hip-Hop',
+            'genre': 'Hip-Hop',
-                artist = uploader = artists[0]['name']
+            for curr_artist in artists:
-        gigya_sc = self._download_webpage(compat_urlparse.urljoin(r'http://www.mitele.es/', gigya_url), video_id, 'Downloading gigya script')
+        gigya_url = self._search_regex(
-        paths = self._download_json(paths_url, video_id, 'Downloading paths JSON')
+        appKey_var = self._search_regex(
-        embedCode = source['offers'][0]['embed_codes'][0]
+        source = self._download_json(
-        duration = parse_duration(source['videos'][0]['duration'])
+
-            'thumbnail': source['images'][0]['url'],
+            'thumbnail': get('images', 'url'),
-    _VALID_URL = r'https?://(?:www\.)?mitele\.es/programas-tv/(?:[^/]+/)(?P<id>[^/]+)/player'
+    _VALID_URL = r'https?://(?:www\.)?mitele\.es/(?:[^/]+/)+(?P<id>[^/]+)/player'
-from ..utils import unified_timestamp
+from ..utils import (
-    _VALID_URL = r'https?://[a-z]+\.cbslocal\.com/\d+/\d+/\d+/(?P<id>[0-9a-z-]+)'
+    _VALID_URL = r'https?://[a-z]+\.cbslocal\.com/(?:\d+/\d+/\d+|video)/(?P<id>[0-9a-z-]+)'
-        timestamp = unified_timestamp(time_str)
+            r'class="entry-date">([^<]+)<', webpage, 'released date', default=None)
-    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s'
+    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s&disable_polymer=true'
-__version__ = '2016.11.18'
+__version__ = '2016.11.22'
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?hellporno\.(?:com/videos|net/v)/(?P<id>[^/]+)'
-    }
+    }, {
-        ext = flashvars.get('postfix', '.mp4')[1:]
+        ext = determine_ext(flashvars.get('postfix'), 'mp4')
-    _VALID_URL = r'https?://(?:www\.)?(?:amc|bbcamerica|ifc|wetv)\.com/(?:movies/|shows/[^/]+/(?:full-episodes/)?season-\d+/episode-\d+(?:-(?:[^/]+/)?|/))(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:amc|bbcamerica|ifc|wetv)\.com/(?:movies/|shows/[^/]+/(?:full-episodes/)?[^/]+/episode-\d+(?:-(?:[^/]+/)?|/))(?P<id>[^/?#]+)'
-        'md5': 'c26b9ee0e1ca138c12071f59572ba9c7',
+        'md5': 'bcd81e0c4f26189ee09be362ad6e6ba9',
-
+        if source_formats:
-            m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+        formats.extend(m3u8_formats)
-        'md5': 'bcd81e0c4f26189ee09be362ad6e6ba9',
+        'md5': 'c26b9ee0e1ca138c12071f59572ba9c7',
-        bitrates = [int(bitrate) for bitrate in re.findall(r'[,/]v(\d+)[,/]', m3u8_url)]
+        bitrates = [int(bitrate) for bitrate in re.findall(r'[,/]v(\d+)(?=[,/])', m3u8_url)]
-            r'"retry_url":"(.+?)"', final_url_webpage, 'final video URL'), 'http:')
+        download_webpage = self._download_webpage(
-            'url': final_url,
+            'title': title,
-            r'(?s)(<form[^>]+id="Form-login".+?</form>)', login_webpage, 'login form')
+            r'(?s)(<form[^>]+(?:id|name)="Form-login".+?</form>)', login_webpage, 'login form')
-    _VALID_URL = r'https?://(?:www\.)?twitter\.com/i/(?:cards/tfw/v1|videos/tweet)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?twitter\.com/i/(?:cards/tfw/v1|videos(?:/tweet)?)/(?P<id>\d+)'
-__version__ = '2016.11.14.1'
+__version__ = '2016.11.18'
-    parser = optparse.OptionParser(usage='%prog VERSION BUILDPATH')
+    parser = optparse.OptionParser(usage='%prog CHANGELOG VERSION BUILDPATH')
-    if len(args) != 2:
+    if len(args) != 3:
-    version, build_path = args
+    changelog_file, version, build_path = args
-    new_release = releaser.create_release(version, name='youtube-dl %s' % version)
+    new_release = releaser.create_release(
-    _VALID_URL = r'(?P<base_url>https?://(?:\w+\.)?youtube\.com/(?:user|channel|c)/(?P<id>[^/]+))/live'
+    _VALID_URL = r'(?P<base_url>https?://(?:\w+\.)?youtube\.com/(?:(?:user|channel|c)/)?(?P<id>[^/]+))/live'
-    all_urls = batch_urls + [url.strip() for url in args]
+    all_urls = batch_urls + [url.strip() for url in args]  # batch_urls are already striped in read_batch_urls
-    all_urls = [url.strip() for url in all_urls]
+    all_urls = batch_urls + [url.strip() for url in args]
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            lang = dict_get(caption, ('language', 'locale', 'country', 'label'))
+            lang = dict_get(caption, ('locale', 'language', 'country', 'label'))
-__version__ = '2016.11.14'
+__version__ = '2016.11.14.1'
-__version__ = '2016.11.08.1'
+__version__ = '2016.11.14'
-            if message_type == 'ProgramIsGeoBlocked' and not self._faked_ip:
+            message_type = data.get('messageType', '')
-    def _download_webpage(self, *args, **kwargs):
+    def _download_webpage_handle(self, *args, **kwargs):
-        return super(NRKBaseIE, self)._download_webpage(*args, **kwargs)
+            # NB: str is intentional
-        urlh = self.ydl.urlopen(man_url)
+
-                success = ctx['dl'].download(frag_filename, {'url': url_parsed.geturl()})
+                success = ctx['dl'].download(frag_filename, {
-        manifest = self.ydl.urlopen(man_url).read()
+
-                            success = ctx['dl'].download(frag_filename, {'url': frag_url})
+                            success = ctx['dl'].download(frag_filename, {
-                    expected=True)
+            message_type = data.get('messageType')
-        \?.*?\bnTitleNo=(?P<id>\d+)'''
+    _VALID_URL = r'''(?x)
-        video_xml = self._download_xml(info_url, video_id)
+
-                                        'Bandwidth': representation_attrib.get('bandwidth'),
+                                        'Bandwidth': int_or_none(representation_attrib.get('bandwidth')),
-                                        'Bandwidth': representation_attrib.get('bandwidth'),
+                                        'Bandwidth': int_or_none(representation_attrib.get('bandwidth')),
-    parse_duration
+    float_or_none,
-        webpage = self._download_webpage('http://ebd.cda.pl/0x0/' + video_id, video_id)
+        self._set_cookie('cda.pl', 'cda.player', 'html5')
-
+        uploader = self._search_regex(r'''(?x)
-            'title': title,
+            'title': self._og_search_title(webpage),
-            if not format_url:
+            json_str = self._search_regex(
-                'url': format_url,
+                'url': video['file'],
-                    unpacked, 'duration', fatal=False, group='duration'))
+                info_dict['duration'] = parse_duration(video.get('duration'))
-                href, video_id, 'Downloading %s version information' % resolution, fatal=False)
+                self._BASE_URL + href, video_id,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?plays\.tv/(?:video|embeds)/(?P<id>[0-9a-f]{18})'
-    }
+    }, {
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-        return {
+        info.update({
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': info.get('thumbnail') or self._og_search_thumbnail(webpage),
-        }
+        })
-                        'thumbnail': e.get('thumbnailUrl'),
+                        'thumbnail': e.get('thumbnailUrl') or e.get('thumbnailURL'),
-        'url': 'http://plays.tv/video/56af17f56c95335490/when-you-outplay-the-azir-wall',
+        'url': 'https://plays.tv/video/56af17f56c95335490/when-you-outplay-the-azir-wall',
-            'title': 'When you outplay the Azir wall',
+            'title': 'Bjergsen - When you outplay the Azir wall',
-                'content'), video_id)['content']
+        content = self._search_json_ld(webpage, video_id)
-            content).groups()
+            webpage).groups()
-        magic = compat_ord(enc_data[-1])
+        enc_code = self._html_search_regex(r'<script[^>]+>(ï¾Ïï¾[^<]+)</script>',
-                j += 3
+            if idx == len(enc_data) - offset:
-            r'^(?P<func>%s)\((?P<args>[a-zA-Z0-9_$,]+)\)$' % _NAME_RE, expr)
+            r'^(?P<func>%s)\((?P<args>[a-zA-Z0-9_$,]*)\)$' % _NAME_RE, expr)
-                for v in m.group('args').split(',')])
+                for v in m.group('args').split(',')]) if len(m.group('args')) > 0 else tuple()
-from ..compat import compat_HTTPError
+from ..compat import (
-    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata'):
+    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata', *args, **kwargs):
-            'mp4', entry_protocol='m3u8_native', m3u8_id='hls')
+            m3u8_url, video_id, 'mp4', entry_protocol='m3u8_native',
-        mp4_url = self._get_video_url(
+        m3u8_formats_dict = {}
-                if not self._is_valid_url(video_url, video_id):
+            re.sub(r'm3u8|hlsvod|hls|f4m', 'mp4s', secure_m3u8),
-                formats.append(http_format)
+                height = int_or_none(format_id)
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?audioboom\.com/(?:boos|posts)/(?P<id>[0-9]+)'
-    }
+    }, {
-__version__ = '2016.11.08'
+__version__ = '2016.11.08.1'
-from .espn import ESPNIE
+from .espn import (
-            r'(?s)<div[^>]+class="[^"]*?title-zone-diffusion[^"]*?"[^>]*>.*?<a[^>]+href="([^"]+)"',
+            r'(?s)<div[^>]+class="[^"]*?title-zone-diffusion[^"]*?"[^>]*>.*?<button[^>]+data-asset-source="([^"]+)"',
-            r'(?s)<figure[^>]+itemtype="https://schema.org/ImageObject"[^>]*>.*?<img[^>]+data-pagespeed-(?:lazy|high-res)-src="([^"]+)"',
+            r'(?s)<figure[^>]+itemtype="https://schema.org/ImageObject"[^>]*>.*?<img[^>]+data-dejavu-src="([^"]+)"',
-__version__ = '2016.11.04'
+__version__ = '2016.11.08'
-        'md5': 'e482a414a38db73087450e3a6ce69d00',
+        'md5': '3316ff838ae5bb7f642537825e1e90d2',
-            'ext': 'mp4',
+            'ext': 'mov',
-            transform_source=lambda s: s.replace('\\', ''))
+        embedded_video_info = self._parse_json(self._html_search_regex(
-from ..utils import remove_end
+from ..compat import compat_str
-    _VALID_URL = r'https?://(?:espn\.go|(?:www\.)?espn)\.com/(?:[^/]+/)*(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:espn\.go|(?:www\.)?espn)\.com/video/clip(?:\?.*?\bid=|/_/id/)(?P<id>\d+)'
-            'id': 'FkYWtmazr6Ed8xmvILvKLWjd4QvYZpzG',
+            'id': '10365079',
-            'description': None,
+            'description': 'md5:39370c2e016cb4ecf498ffe75bef7f0f',
-            'id': '50NDFkeTqRHB0nXBOK-RGdSG5YQPuxHg',
+            'id': '2743663',
-        'add_ie': ['OoyalaExternal'],
+        'expected_warnings': ['Unable to download f4m manifest'],
-        'only_matching': True,
+    @classmethod
-        }
+        return self.url_result(
-import re
+import uuid
-    remove_start,
+    smuggle_url,
-class MiTeleIE(MiTeleBaseIE):
+class MiTeleIE(InfoExtractor):
-    _VALID_URL = r'https?://(?:www\.)?mitele\.es/(?:[^/]+/){3}(?P<id>[^/]+)/'
+    _VALID_URL = r'https?://(?:www\.)?mitele\.es/programas-tv/(?:[^/]+/)(?P<id>[^/]+)/player'
-        # MD5 is unstable
+        'url': 'http://www.mitele.es/programas-tv/diario-de/57b0dfb9c715da65618b4afa/player',
-            'display_id': 'programa-144',
+            'id': '57b0dfb9c715da65618b4afa',
-        'url': 'http://www.mitele.es/programas-tv/cuarto-milenio/temporada-6/programa-226/',
+        'url': 'http://www.mitele.es/programas-tv/cuarto-milenio/57b0de3dc915da14058b4876/player',
-            'display_id': 'programa-226',
+            'id': '57b0de3dc915da14058b4876',
-            'description': 'md5:50daf9fadefa4e62d9fc866d0c015701',
+            'title': 'Cuarto Milenio Temporada 6 Programa 226',
-            'duration': 7312,
+            'duration': 7313,
-        display_id = self._match_id(url)
+        video_id = self._match_id(url)
-            'display_id': display_id,
+        return {
-            'description': get_element_by_attribute('class', 'text', webpage),
+            'description': description,
-        return info
+            'duration': duration,
-    def _extract(self, content_tree_url, video_id, domain='example.org'):
+    def _extract(self, content_tree_url, video_id, domain='example.org', supportedformats=None):
-                'supportedFormats': 'mp4,rtmp,m3u8,hds',
+                'supportedFormats': supportedformats or 'mp4,rtmp,m3u8,hds',
-        return self._extract(content_tree_url, embed_code, domain)
+        return self._extract(content_tree_url, embed_code, domain, supportedformats)
-
+        # Look for embedded PornHub player
-                        (?P<id>[0-9a-z]+)
+                        (?P<id>[\da-z]+)
-            return mobj.group('url')
+    @staticmethod
-    _TEST = {
+    _VALID_URL = r'https?://(?:(?:www\.)?redtube\.com/|embed\.redtube\.com/\?.*?\bid=)(?P<id>[0-9]+)'
-    }
+    }, {
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-            (r'class="title_watch"[^>]*><p>([^<]+)<',
+            (r'class="title_watch"[^>]*><(?:p|h\d+)[^>]*>([^<]+)<',
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?drtuber\.com/(?:video|embed)/(?P<id>\d+)(?:/(?P<display_id>[\w-]+))?'
-    }
+    }, {
-        display_id = mobj.group('display_id')
+        display_id = mobj.group('display_id') or video_id
-        webpage = self._download_webpage(url, display_id)
+        webpage = self._download_webpage(
-                    r'yahoo://article/view\?.*\buuid=([^&"\']+)',
+                    r'<meta[^<>]+yahoo://article/view\?.*\buuid=([^&"\']+)',
-    _VALID_URL = r'https?://ici\.tou\.tv/(?P<id>[a-zA-Z0-9_-]+/S[0-9]+E[0-9]+)'
+    _VALID_URL = r'https?://ici\.tou\.tv/(?P<id>[a-zA-Z0-9_-]+(?:/S[0-9]+E[0-9]+)?)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-__version__ = '2016.11.02'
+__version__ = '2016.11.04'
-            if ext == 'smil':
+            if ext == 'smil' or media_format == 'smil':
-            if ext == 'm3u8':
+            if ext == 'm3u8' or media_format in ('m3u8', 'm3u8-variant'):
-            elif ext == 'mp3':
+            elif ext == 'mp3' or media_format == 'mp3':
-
+    def _get_anvato_videos(self, access_key, video_id):
-                    f['height'] = int(height_str)
+                    mobj = re.search(r'(?P<width>\d+)[xX](?P<height>\d+)', resolution)
-                'The file you were looking for could not be found, sorry for any inconvenience.<')):
+                'The file you were looking for could not be found, sorry for any inconvenience.<',
-            smaple_entry_box = box(b'mp4a', sample_entry_payload)
+            sample_entry_box = box(b'mp4a', sample_entry_payload)
-    stsd_payload += smaple_entry_box
+            sample_entry_box = box(b'avc1', sample_entry_payload)  # AVC Simple Entry
-            avcc_payload += sps[3]  # avc level indication
+            avcc_payload += sps[1:4]  # avc profile indication + profile compatibility + avc level indication
-from ..utils import ExtractorError
+from ..compat import compat_HTTPError
-class ViceIE(InfoExtractor):
+class ViceBaseIE(AdobePassIE):
-        'md5': '6fb2989a3fed069fb8eab3401fc2d3c9',
+        'md5': 'a7ecf64ee4fa19b916c16f4b56184ae2',
-                r'data-youtube-id="([^"]+)"', webpage, 'youtube id')
+        webpage, urlh = self._download_webpage_handle(url, video_id)
-            raise ExtractorError('The page doesn\'t contain a video', expected=True)
+        return self._extract_preplay_video(urlh.geturl(), webpage)
-import json
+from .vice import ViceBaseIE
-class VicelandIE(AdobePassIE):
+class VicelandIE(ViceBaseIE):
-        }
+        return self._extract_preplay_video(url, webpage)
-    parse_iso8601,
+        'md5': '43ac06be9326f41912dc64ccf7a80320',
-            'skip_download': 'HLS download',
+            'uploader_id': 'bc168bee0d18dd1cb3b86c68706ab434',
-        title = video_data['n']
+        title = video_data['title']
-            video_data['mh'], video_id, 'mp4', 'm3u8_native')
+            self._proto_relative_url(video_data['url']),
-            sub_url = sub.get('u')
+        for sub in video_data.get('subtitles', []):
-                'url': sub_url,
+            subtitles.setdefault(sub.get('lang', 'English'), []).append({
-            'uploader': video_data.get('on'),
+            'thumbnails': thumbnails,
-    _VALID_URL = r'https?://shahid\.mbc\.net/ar/episode/(?P<id>\d+)/?'
+    _NETRC_MACHINE = 'shahid'
-            }).get('data', {})
+    def _real_initialize(self):
-        video_id = self._match_id(url)
+        page_type, video_id = re.match(self._VALID_URL, url).groups()
-            video_id, 'Downloading player JSON')
+        player = self._get_api_data(self._download_json(
-            'Downloading video JSON')['episode']
+        video = self._get_api_data(self._download_json(
-            elif re.search(r'(?i)\.(?:ism|smil)/manifest', video_url):
+            elif re.search(r'(?i)\.(?:ism|smil)/manifest', video_url) and video_url != url:
-                entry_info_dict['formats'] = self._extract_ism_formats(video_url, video_id)
+            elif re.search(r'(?i)\.(?:ism|smil)/manifest', video_url):
-__version__ = '2016.10.31'
+__version__ = '2016.11.02'
-                        fragment_ctx['duration'] = (next_fragment_time - frgament_time) / fragment_repeat
+                        fragment_ctx['duration'] = (next_fragment_time - fragment_ctx['time']) / fragment_repeat
-                            'url': re.sub(r'{start[ _]time}', str(fragment_ctx['time']), track_url_pattern),
+                            'url': re.sub(r'{start[ _]time}', compat_str(fragment_ctx['time']), track_url_pattern),
-        mpd_base_url = re.match(r'https?://[^?#&]+/', urlh.geturl()).group()
+        mpd_base_url = base_url(urlh.geturl())
-        ism_base_url = re.match(r'https?://.+/', ism_url).group()
+        ism_base_url = base_url(ism_url)
-                continue
+            sources_type = sources.get('videoType')
-                continue
+                formats.extend(self._extract_ism_formats(
-                        continue
+                        formats.extend(self._extract_ism_formats(
-                                ('mp3', 'mp4', 'm4a', 'm4p', 'm4b', 'm4r', 'm4v'),
+                                ('mp3', 'mp4', 'm4a', 'm4p', 'm4b', 'm4r', 'm4v', 'ismv', 'isma'),
-    NickNightAtIE,
+    NickNightIE,
-            {'siteKey': host})
+        mrss_url = self._extract_mrss_url(webpage, host)
-    _VALID_URL = r'https?://(?:www\.)nicknight\.(?:de|at|tv)/(?:playlist|shows)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+class NickNightIE(NickDeIE):
-        return self._get_videos_info_from_url(mrss_url, video_id)
+    def _extract_mrss_url(self, webpage, *args):
-    _VALID_URL = r'https?://(?:www\.)?(?:nick\.de|nickelodeon\.(?:nl|at))/(?:playlist|shows)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<host>nick\.de|nickelodeon\.(?:nl|at))/(?:playlist|shows)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            {'siteKey': 'nick.de'})
+            {'siteKey': host})
-    _VALID_URL = r'https?://(?:www\.)?(?:nick\.de|nickelodeon\.nl)/(?:playlist|shows)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:nick\.de|nickelodeon\.(?:nl|at))/(?:playlist|shows)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-        mpd_base_url = re.match(r'https?://.+/', urlh.geturl()).group()
+        mpd_base_url = re.match(r'https?://[^?#&]+/', urlh.geturl()).group()
-        if m.group('strval') is not None:
+        actual_value = dct.get(m.group('key'))
-            comparison_value = m.group('strval')
+            comparison_value = m.group('strval') or m.group('intval')
-__version__ = '2016.10.30'
+__version__ = '2016.10.31'
-__version__ = '2016.10.26'
+__version__ = '2016.10.30'
-    _VALID_URL = r'https?://(?:www\.)?vessel\.com/(?:videos|embed)/(?P<id>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?vessel\.com/(?:videos|embed)/(?P<id>[0-9a-zA-Z-_]+)'
-            r'<iframe[^>]+src=(["\'])((?:https?:)?//(?:www\.)?vessel\.com/embed/[0-9a-zA-Z]+.*?)\1',
+            r'<iframe[^>]+src=(["\'])((?:https?:)?//(?:www\.)?vessel\.com/embed/[0-9a-zA-Z-_]+.*?)\1',
-        }
+        },
-            if video_data:
+        server_js_data = self._parse_json(self._search_regex(
-        for format_id, f in video_data.items():
+        for f in video_data:
-    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?:(?:gallery|topic/[^/]+)/)?(?P<id>[a-zA-Z0-9]{6,})(?:[/?#&]+|\.[a-z]+)?$'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?:(?:gallery|(?:topic|r)/[^/]+)/)?(?P<id>[a-zA-Z0-9]{6,})(?:[/?#&]+|\.[a-z]+)?$'
-                    'beeg version', default=None) or self._search_regex(
+                beeg_version = int_or_none(self._search_regex(
-                    r'beeg_salt\s*=\s*(["\'])(?P<beeg_salt>.+?)\1', cpl, 'beeg beeg_salt',
+                    r'beeg_salt\s*=\s*(["\'])(?P<beeg_salt>.+?)\1', cpl, 'beeg salt',
-        beeg_salt = beeg_salt or 'MIDtGaw96f0N1kMMAM1DE46EC9pmFr'
+        beeg_version = beeg_version or '2000'
-            'http://api.beeg.com/api/v6/%s/video/%s' % (beeg_version, video_id),
+            'https://api.beeg.com/api/v6/%s/video/%s' % (beeg_version, video_id),
-                j += 2
+                j += 3
-                note='Downloading result page ' + str(pagenum + 1))
+                'http://www.google.com/search',
-             'This program is only suitable for those aged 12 and older. Video %s is therefore only available between 20 pm and 6 am.'),
+             'This program is only suitable for those aged 12 and older. Video %s is therefore only available between 8 pm and 6 am.'),
-        'md5': '95e40865aedd08eff60272b704852ad7',
+        'md5': 'e20fd862d1894b67564c96f180f43924',
-            'ext': 'flv',
+            'ext': 'mp4',
-            r'flvMask:(.*?);', webpage2, 'video_url')
+        video_id = self._match_id(url)
-        return {
+        info_dict.update({
-        }
+        })
-            "object_id\s*:\s*'(\d+)'"], webpage, 'video id')
+            r"object_id\s*:\s*'(\d+)'",
-__version__ = '2016.10.25'
+__version__ = '2016.10.26'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            raise ExtractorError('Video %s is no longer available' % video_id, expected=True)
+        ERRORS = (
-            raise ExtractorError('This program is only suitable for those aged 12 and older. Video %s is therefore only available between 20 pm and 6 am.' % video_id, expected=True)
+        for pattern, message in ERRORS:
-        data = json.loads(data_json)
+        # vars does not look to be served anymore since 24.10.2016
-__version__ = '2016.10.21.1'
+__version__ = '2016.10.25'
-from .jamendo import JamendoIE, JamendoAlbumIE
+from .jamendo import (
-    _VALID_URL = r'https?://(?:www\.)?jamendo\.com/track/(?P<id>[0-9]+)/(?P<display_id>[\w-]+)'
+    _VALID_URL = r'https?://(?:www\.)?jamendo\.com/track/(?P<id>[0-9]+)/(?P<display_id>[^/?#&]+)'
-        display_id = url_data.group('display_id')
+        mobj = self._VALID_URL_RE.match(url)
-                }
+        'playlist': [{
-        ],
+        }],
-        webpage = self._download_webpage(url, url_data.group('display_id'))
+        mobj = self._VALID_URL_RE.match(url)
-            for path in track_paths
+            self.url_result(
-        }
+
-    qualities
+    qualities,
-    _TESTS = [{
+    _TEST = {
-    }]
+        'skip': 'Live stream is offline',
-        data = config['data']
+            'http://www.panda.tv/api_room?roomid=%s' % video_id, video_id)
-            raise ExtractorError(error_desc, expected=True)
+            raise ExtractorError(
-        stream_addr = video_info.get('stream_addr', {'OD': '1', 'HD': '1', 'SD': '1'})
+        stream_addr = video_info.get(
-                    })
+            if v != '1':
-    _VALID_URL = r'https?://(?:www.)?movieclips\.com/videos/.+-(?P<id>\d+)(?:\?|$)'
+    _VALID_URL = r'https?://(?:www\.)?movieclips\.com/videos/.+-(?P<id>\d+)(?:\?|$)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                webpage, 'video url')
+                webpage, 'video url', default=None)
-            'ext': 'flv',
+        if not video_url:
-        }
+        })
-        episode_title = view_data['title']
+    def _extract_playlist(self, season_list, video_id, program_info, prompt=True):
-                self._URL_TEMPLATE % (view_data['contentType'], episode['contentId']),
+                self._URL_TEMPLATE % (program_info['contentType'], episode['contentId']),
-            'var\s+vod\s*=\s*([^;]+)', webpage, 'VOD data', default='{}'),
+        program_info = self._parse_json(self._search_regex(
-        season_list = list(vod_data.get('seasonList', {}).values())
+        season_list = list(program_info.get('seasonList', {}).values())
-                    season_list[0], video_id, vod_data, view_data,
+                    season_list[0], video_id, program_info,
-            view_data = self._download_json(
+        if 'assetId' not in program_info:
-                'contentType': view_data['contentType'],
+                'assetId': program_info['assetId'],
-        episode = int_or_none(view_data.get('episode'))
+        title = program_info['title'] + program_info.get('secondaryMark', '')
-            webpage = self._download_webpage(request, video_id)
+            webpage, urlh = self._download_webpage_handle(request, video_id)
-from .shared import SharedIE
+from .shared import (
-    _VALID_URL = r'https?://(?:shared|vivo)\.sx/(?P<id>[\da-z]{10})'
+class SharedBaseIE(InfoExtractor):
-    _TESTS = [{
+    _TEST = {
-                'Video %s does not exist' % video_id, expected=True)
+    }
-            urlh.geturl(), video_id, 'Downloading video page',
+            url, video_id, 'Downloading video page',
-                'Referer': urlh.geturl(),
+                'Referer': url,
-            'url': video_url,
+        return video_url
-        }
+            'title': 'Chicken',
-            'kraken/streams/%s' % channel_id, channel_id,
+            'kraken/streams/%s?stream_type=all' % channel_id, channel_id,
-                current.get('DisplayTimeOffset')), current.get('Text')
+            start, text = (
-                subs[num + 1].get('DisplayTimeOffset'))
+                dict_get(subs[num + 1], TIME_OFFSET_KEYS))
-__version__ = '2016.10.21'
+__version__ = '2016.10.21.1'
-                        oauth_redirect_url = self._html_search_regex(r'window\.location\s*=\s*[\'"]([^\'"]+)',
+                        oauth_redirect_url = self._html_search_regex(
-                        self._download_webpage(oauth_redirect_url, video_id, 'Confirming auto login')
+                        self._download_webpage(
-                            oauth_redirect_url = self._html_search_regex(r'content="0;\s*url=([^\'"]+)',
+                            oauth_redirect_url = self._html_search_regex(
-                            provider_login_page_res = self._download_webpage_handle(oauth_redirect_url,
+                            provider_login_page_res = self._download_webpage_handle(
-                clip_url = self._download_webpage(
+                viewclip = self._download_json(
-                    'Downloading %s URL' % format_id, fatal=False,
+                    'Downloading %s viewclip JSON' % format_id, fatal=False,
-                if not clip_url:
+                if not viewclip:
-                formats.append(f)
+
-__version__ = '2016.10.19'
+__version__ = '2016.10.21'
-    _API_BASE = 'http://app.pluralsight.com'
+    _API_BASE = 'https://app.pluralsight.com'
-            '%s/training/Player/Captions' % self._API_BASE, video_id,
+            '%s/player/retrieve-captions' % self._API_BASE, video_id,
-        course = qs.get('course', [None])[0]
+        course_name = qs.get('course', [None])[0]
-        if any(not f for f in (author, name, clip_id, course,)):
+        if any(not f for f in (author, name, clip_id, course_name,)):
-        webpage = self._download_webpage(url, display_id)
+        parsed_url = compat_urlparse.urlparse(url)
-            webpage, 'modules', default=None)
+        payload_url = compat_urlparse.urlunparse(parsed_url._replace(
-                display_id)['course']['modules']
+        course = self._download_json(
-            r'courseSupportsWidescreenVideoFormats\s*:\s*true', webpage) else False
+        widescreen = course.get('supportsWideScreenVideoFormats') is True
-                    'q': '%dx%d' % (f['width'], f['height']),
+                    'author': author,
-                    '%s/training/Player/ViewClip' % self._API_BASE, display_id,
+                    '%s/video/clips/viewclip' % self._API_BASE, display_id,
-        if info['ext'] in ('mp3', 'mkv'):
+        if info['ext'] == 'mp3':
-class NationalGeographicIE(AdobePassIE):
+class NationalGeographicIE(ThePlatformIE, AdobePassIE):
-                {'force_smil_url': True}),
+            query['auth'] = self._extract_mvpd_auth(url, video_id, 'natgeo', auth_resource_id)
-        }
+        })
-                    post_form(mvpd_confirm_page_res, 'Confirming Login')
+
-__version__ = '2016.10.16'
+__version__ = '2016.10.19'
-            video_id, transform_source=js_to_json)
+        packed_codes = [mobj.group(0) for mobj in re.finditer(
-        code)
+    mobj = re.search(PACKED_CODES_RE, code)
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?ur(?:play|skola)\.se/(?:program|Produkter)/(?P<id>[0-9]+)'
-        'md5': '15ca67b63fd8fb320ac2bcd854bad7b6',
+        'md5': 'ad5f0de86f16ca4c8062cd103959a9eb',
-    }
+        },
-                    'm3u8_native', preference, '%s-hls' % quality, fatal=False))
+                formats.extend(self._extract_wowza_formats(
-            if subtitle_url or kind and kind != 'captions':
+            if not subtitle_url or (kind and kind != 'captions'):
-        formats = self._extract_wowza_formats(playlist_url, display_id)
+        formats = self._extract_wowza_formats(playlist_url, display_id, skip_protocols=['dash'])
-        'playlist_mincout': 21,
+        'playlist_mincount': 21,
-            video_id = query_dict['v'][0]
+        video_id = query_dict.get('v', [None])[0] or self._search_regex(
-    _VALID_URL = r'(?:nrk:|https?://(?:www\.)?nrk\.no/video/PS\*)(?P<id>[^/?#&]+)'
+    _VALID_URL = r'''(?x)
-    _VALID_URL = r'(?:nrk:|https?://(?:www\.)?nrk\.no/video/PS\*)(?P<id>\d+)'
+    _VALID_URL = r'(?:nrk:|https?://(?:www\.)?nrk\.no/video/PS\*)(?P<id>[^/?#&]+)'
-            r'[Ee]pisode\s+(\d+)', episode, 'epidode number', default=None))
+            r'[Ee]pisode\s+(\d+)', episode, 'episode number', default=None))
-        
+
-    series or programme:
+    series, programme or podcast:
-    determine_ext,
+    parse_iso8601,
-            'title': "The Run-Up: \u2018He Was Like an Octopus\u2019",
+            'id': '100000004709062',
-            'description': 'We go behind the story of the two women who told us that Donald Trump touched them inappropriately (which he denies) and check in on Hillary Clintonâs campaign.',
+            'description': 'md5:fb5c6b93b12efc51649b4847fe066ee4',
-            'title': "The Rise of Hitler",
+            'id': '100000004709479',
-            }
+            'description': 'md5:bce877fd9e3444990cb141875fab0028',
-        video_id = self._html_search_regex(r'data-videoid="(\d+)"', webpage, 'video id', None, False)
+        video_id = self._search_regex(
-        return self._extract_podcast_from_json(data_json, page_id, webpage)
+
-        webpage = self._download_webpage(url, video_id)
+        page_id = self._match_id(url)
-        video_id = self._html_search_regex(r'data-videoid="(\d+)"', webpage, 'video id')
+        webpage = self._download_webpage(url, page_id)
-        return self._extract_video_from_id(video_id)
+        video_id = self._html_search_regex(r'data-videoid="(\d+)"', webpage, 'video id', None, False)
-    _VALID_URL = r'https?://(?:(?:www|app)\.)?pluralsight\.com/training/player\?'
+    _VALID_URL = r'https?://(?:(?:www|app)\.)?pluralsight\.com/(?:training/)?player\?'
-__version__ = '2016.10.12'
+__version__ = '2016.10.16'
-            r'var\s*feed\s*=\s*({.*})', webpage, 'feed json str')
+            r'var\s+feed\s*=\s*({.+})', webpage, 'feed json')
-    ArteTVOperaPlatformIE,
+    TheOperaPlatformIE,
-    _VALID_URL = r'https?://pro\.beatport\.com/track/(?P<display_id>[^/]+)/(?P<id>[0-9]+)'
+class BeatportIE(InfoExtractor):
-        'url': 'https://pro.beatport.com/track/synesthesia-original-mix/5379371',
+        'url': 'https://beatport.com/track/synesthesia-original-mix/5379371',
-        'url': 'https://pro.beatport.com/track/love-and-war-original-mix/3756896',
+        'url': 'https://beatport.com/track/love-and-war-original-mix/3756896',
-        'url': 'https://pro.beatport.com/track/birds-original-mix/4991738',
+        'url': 'https://beatport.com/track/birds-original-mix/4991738',
-from .beatportpro import BeatportProIE
+from .beatport import BeatportIE
-    _VALID_URL = r'https?://(?:www\.)?ruutu\.fi/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:ruutu|supla)\.fi/(?:video|supla)/(?P<id>\d+)'
-                'description': 'md5:da2736052fef3b2bd5e0005e63c25eac',
+                'description': 'md5:bfb7336df2a12dc21d18fa696c9f8f23',
-    _VALID_URL = r'https?://www.theoperaplatform.eu/(?P<lang>fr|de|en|es)/(?P<id>[^/?#&]+)'
+
-        'md5': '80f5d3fc97957b5dbfc1ddfde93b8098',
+        'md5': '970655901fa2e82e04c00b955e9afe7b',
-                    'width': int_or_none(format_id),
+                    'height': int_or_none(format_id),
-    _VALID_URL = r'https?://(?:www\.)?lynda\.com/(?:[^/]+/[^/]+/\d+|player/embed)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?lynda\.com/(?:[^/]+/[^/]+/(?P<course_id>\d+)|player/embed)/(?P<id>\d+)'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            video_id, 'Downloading video JSON')
+            'https://www.lynda.com/ajax/player', video_id,
-            self.raise_login_required('Video %s is only available for members' % video_id)
+            self._raise_unavailable(video_id)
-        'url': 'http://www.lynda.com/Bootstrap-tutorials/Using-exercise-files/110885/114408-4.html',
+        'url': 'https://www.lynda.com/Bootstrap-tutorials/Using-exercise-files/110885/114408-4.html',
-            'http://www.lynda.com/ajax/player?videoId=%s&type=video' % video_id,
+            'https://www.lynda.com/ajax/player?videoId=%s&type=video' % video_id,
-        url = 'http://www.lynda.com/ajax/player?videoId=%s&type=transcript' % video_id
+        url = 'https://www.lynda.com/ajax/player?videoId=%s&type=transcript' % video_id
-            'http://www.lynda.com/ajax/player?courseId=%s&type=course' % course_id,
+            'https://www.lynda.com/ajax/player?courseId=%s&type=course' % course_id,
-                        'url': 'http://www.lynda.com/%s/%s-4.html' % (course_path, video_id),
+                        'url': 'https://www.lynda.com/%s/%s-4.html' % (course_path, video_id),
-from ..utils import parse_duration, parse_iso8601
+from ..utils import (
-            'description': 'Relive or catch up with Still The King by watching this recap of season 1, episode 9. New episodes Sundays 9/8c.',
+            'description': 'Relive or catch up with Still The King by watching this recap of season 1, episode 9.',
-            'uploader_id': feed['author']['uid'],
+            'duration': parse_duration(get('feed', 'duration')),
-    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/(?:library/view/[^/]+|api/v1/book)/(?P<id>[^/]+)/?(?:[#?]|$)'
+    _VALID_URL = r'''(?x)
-import json
+from ..compat import compat_str
-    ExtractorError,
+    unescapeHTML,
-    _VALID_URL = r'https?://tvthek\.orf\.at/(?:programs/.+?/episodes|topics?/.+?|program/[^/]+)/(?P<id>\d+)'
+    _VALID_URL = r'https?://tvthek\.orf\.at/(?:[^/]+/)+(?P<id>\d+)'
-            raise ExtractorError('Unable to extract segments')
+        data_jsb = self._parse_json(
-            video_id = sd['id']
+        for sd in data_jsb:
-            } for fd in sd['playlist_item_array']['sources']]
+            } for fd in sd['sources']]
-            upload_date = unified_strdate(sd['created_date'])
+            upload_date = unified_strdate(sd.get('created_date'))
-                'title': sd['header'],
+                'title': title,
-                'duration': int(sd['duration_in_seconds']),
+                'duration': int_or_none(sd.get('duration_in_seconds')),
-        'md5': '79bc922f3e8a9097b3d68a93780fd475',
+        'url': 'http://www.clipfish.de/special/ugly-americans/video/4343170/s01-e01-ugly-americans-date-in-der-hoelle/',
-            'id': '3966754',
+            'id': '4343170',
-            'duration': 82,
+            'title': 'S01 E01 - Ugly Americans - Date in der HÃ¶lle',
-            'description': video_info.get('descr'),
+            'description': descr,
-            'http://chirbit.com/rss/%s' % profile_id, profile_id)
+        webpage = self._download_webpage(url, profile_id)
-            for audio_url in rss.findall('./channel/item/link')]
+            self.url_result(self._proto_relative_url('//chirb.it/' + video_id))
-        return self.playlist_result(entries, profile_id, title)
+        return self.playlist_result(entries, profile_id)
-        'md5': '',
+        'md5': 'a49fb0ec2ad66503eeb46aac237d3c86',
-            'ext': 'mp4',
+            'id': '475222',
-            'duration': 2678.31,
+            'thumbnail': 're:^https?://.*\.jpg',
-    qualities,
+    qualities,
-            'id': '1192814',
+            'id': '1405510',
-            'upload_date': '20150105',
+            'title': 'Zapping - 02/07/2016',
-            'title': 'Le labyrinthe - Boing super ranger',
+            'display_id': 'pid1405-le-labyrinthe-boing-super-ranger',
-        'url': 'http://www.d8.tv/d8-docs-mags/pid5198-d8-en-quete-d-actualite.html?vid=1390231',
+        'url': 'http://www.c8.fr/c8-divertissement/ms-touche-pas-a-mon-poste/pid6318-videos-integrales.html',
-            'id': '1390231',
+            'id': '1420213',
-            'skip_download': True,
+            'title': 'TPMP ! MÃªme le matin - Les 35H de Baba - 14/10/2016',
-        'url': 'http://www.itele.fr/chroniques/invite-bruce-toussaint/thierry-solere-nicolas-sarkozy-officialisera-sa-candidature-a-la-primaire-quand-il-le-voudra-167224',
+        'url': 'http://www.itele.fr/chroniques/invite-michael-darmon/rachida-dati-nicolas-sarkozy-est-le-plus-en-phase-avec-les-inquietudes-des-francais-171510',
-            'id': '1398334',
+            'id': '1420176',
-            'skip_download': True,
+            'title': 'L\'invitÃ© de MichaÃ«l Darmon du 14/10/2016 - ',
-        display_id = mobj.group('display_id') or video_id
+        display_id = remove_end(dict_get(mobj.groupdict(), ('display_id', 'id', 'vid')), '.html')
-                webpage, 'video id', group='id')
+        webpage = self._download_webpage(url, display_id)
-            r"data-(?:cnet|zdnet)-video(?:-uvp)?-options='([^']+)'",
+            r"data-(?:cnet|zdnet)-video(?:-uvp(?:js)?)?-options='([^']+)'",
-    _VALID_URL = r'https?://(?:www\.)?parliamentlive\.tv/Event/Index/(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})'
+    _VALID_URL = r'(?i)https?://(?:www\.)?parliamentlive\.tv/Event/Index/(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-__version__ = '2016.10.07'
+__version__ = '2016.10.12'
-            }
+            },
-             r'buildPlayer\(({.+?})\);'],
+             r'buildPlayer\(({.+?})\);',
-            default=NO_DEFAULT if video_password_verified else None)
+        data = self._parse_json(self._search_regex(
-        self.assertEqual(r['url'], 'http://localhost:%d/vid.mp4' % self.port)
+        self.assertEqual(r['entries'][0]['url'], 'http://localhost:%d/vid.mp4' % self.port)
-        self.assertEqual(r['url'], 'https://localhost:%d/vid.mp4' % self.port)
+        self.assertEqual(r['entries'][0]['url'], 'https://localhost:%d/vid.mp4' % self.port)
-        for media_tag, media_type, media_content in re.findall(r'(?s)(<(?P<tag>video|audio)[^>]*>)(.*?)</(?P=tag)>', webpage):
+        media_tags = [(media_tag, media_type, '')
-                formats.extend(self._extract_m3u8_formats(
+                m3u8_formats = self._extract_m3u8_formats(
-                    m3u8_id=playback.get('name', 'hls'), fatal=False))
+                    m3u8_id=playback.get('name', 'hls'), fatal=False)
-from .hbo import HBOIE
+from .hbo import (
-    _VALID_URL = r'https?://footyroom\.com/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://footyroom\.com/matches/(?P<id>\d+)'
-        'url': 'http://footyroom.com/schalke-04-0-2-real-madrid-2015-02/',
+        'url': 'http://footyroom.com/matches/79922154/hull-city-vs-chelsea/review',
-            'title': 'Schalke 04 0 â 2 Real Madrid',
+            'id': '79922154',
-        'skip': 'Video for this match is not available',
+        'playlist_count': 2,
-        'url': 'http://footyroom.com/georgia-0-2-germany-2015-03/',
+        'url': 'http://footyroom.com/matches/75817984/georgia-vs-germany/review',
-            'title': 'Georgia 0 â 2 Germany',
+            'id': '75817984',
-                r'VideoSelector\.load\((\[.+?\])\);', webpage, 'video selector'),
+        playlist = self._parse_json(self._search_regex(
-            playwire_url = self._search_regex(
+            playwire_url = self._html_search_regex(
-        'md5': '979d10b2939101f0d27a06b79edad536',
+        'url': 'http://iview.abc.net.au/programs/diaries-of-a-broken-mind/ZX9735A001S00',
-            'id': 'FA1505V024S00',
+            'id': 'ZX9735A001S00',
-            'timestamp': 1471719600,
+            'title': 'Diaries Of A Broken Mind',
-        title = video_params['title']
+        title = video_params.get('title') or video_params['seriesTitle']
-            'episode': self._html_search_meta('episode_title', webpage),
+            'episode_number': int_or_none(self._html_search_meta('episodeNumber', webpage, default=None)),
-        return self._extract_from_id(video_id)
+        info_dict = self._extract_from_id(video_id)
-    }
+class HBOBaseIE(InfoExtractor):
-        video_id = self._match_id(url)
+    def _extract_from_id(self, video_id):
-            'duration': parse_duration(xpath_element(video_data, 'duration/tv14')),
+            'duration': parse_duration(xpath_text(video_data, 'duration/tv14')),
-        'only_matching': True,
+        'md5': '3566c0668c0235e2d224fd8edb389f67',
-        model_data = self._parse_json(model, display_id)
+            r'data-model="([^"]+)"', webpage, 'data model', default=None)
-        quality = qualities(['ld', 'md', 'hd'])
+            for video_url in model_data['sources'].values():
-            'title': model_data['title'],
+            'title': title,
-    xpath_element,
+    url_basename,
-    _VALID_URL = r'https?://(?:www\.)?allocine\.fr/(?P<typ>article|video|film)/(fichearticle_gen_carticle=|player_gen_cmedia=|fichefilm_gen_cfilm=|video-)(?P<id>[0-9]+)(?:\.html)?'
+    _VALID_URL = r'https?://(?:www\.)?allocine\.fr/(?:article|video|film)/(?:fichearticle_gen_carticle=|player_gen_cmedia=|fichefilm_gen_cfilm=|video-)(?P<id>[0-9]+)(?:\.html)?'
-            'description': 'md5:abcd09ce503c6560512c14ebfdb720d2',
+            'description': 'md5:4a754271d9c6f16c72629a8a993ee884',
-        'url': 'http://www.allocine.fr/film/fichefilm_gen_cfilm=181290.html',
+        'url': 'http://www.allocine.fr/video/player_gen_cmedia=19544709&cfilm=181290.html',
-            'description': 'md5:601d15393ac40f249648ef000720e7e3',
+            'description': 'md5:6cdd2d7c2687d4c6aafe80a35e17267a',
-        display_id = mobj.group('id')
+        display_id = self._match_id(url)
-        xml = self._download_xml('http://www.allocine.fr/ws/AcVisiondataV4.ashx?media=%s' % video_id, display_id)
+        model = self._html_search_regex(
-                })
+        for video_url in model_data['sources'].values():
-            'title': video['videoTitle'],
+            'display_id': display_id,
-    _VALID_URL = r'https?://(www|ent)\.appledaily\.com\.tw/(?:animation|appledaily|enews|realtimenews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
+    _VALID_URL = r'https?://(www|ent)\.appledaily\.com\.tw/(?:animation|appledaily|enews|realtimenews|actionnews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
-        'md5': '0cf531ae8006b530bd9df947a6a0df77',
+        'md5': '868309628ba00fd488cf516a113fd717',
-
+        video_id = self._match_id(url)
-from ..utils import str_or_none
+from ..utils import (
-            })
+        for thumb_key in THUMBNAILS:
-        'md5': '3da12ebca28c67c111a7f8b262d3f7a7',
+        'md5': 'c0aaf339bcee189495fdf5a8c8ba8645',
-            'thumbnail': 're:^https://gp1\.wac\.edgecastcdn\.net/.*?\.jpg$'
+            'thumbnail': 're:^https?://.*\.jpg',
-        song_id = mobj.group('id')
+        song_id = self._match_id(url)
-            'url': api_res.get('url'),
+            'title': api_res['name'],
-                api_res.get('image', api_res.get('thumbnail'))),
+            'thumbnails': thumbnails,
-    int_or_none,
+    parse_duration,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?lego\.com/(?P<locale>[^/]+)/(?:[^/]+/)*videos/(?:[^/]+/)*[^/?#]+-(?P<id>[0-9a-f]+)'
-    }
+            'description': 'Blocumentary Great Creations: Akiyuki Kawaguchi',
-        item_id = video_data['ItemId']
+        locale, video_id = re.match(self._VALID_URL, url).groups()
-        path = '/'.join([net_storage_path, base_path])
+            net_storage_path = video_data.get('NetStoragePath') or '/'.join([item_id[:2], item_id[2:4]])
-            'duration': int_or_none(video_data.get('Length')),
+            'description': self._html_search_meta('description', webpage),
-__version__ = '2016.10.02'
+__version__ = '2016.10.07'
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//player\.vimeo\.com/video/.+?)\1', webpage):
+                r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//player\.vimeo\.com/video/.+?)\1',
-                r'handleServerJS\(({.+})\);', webpage, 'server js data', default='{}'), video_id)
+                r'handleServerJS\(({.+})(?:\);|,")', webpage, 'server js data', default='{}'), video_id)
-from .commonprotocols import RtmpIE
+from .commonprotocols import (
-        title = compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0])
+        video_id = self._generic_id(url)
-            }
+            video_id = self._generic_id(url)
-            'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),
+            'title': self._generic_title(url),
-            return self.url_result(vimeo_url)
+        vimeo_urls = VimeoIE._extract_urls(url, webpage)
-    def _extract_vimeo_url(url, webpage):
+    def _extract_urls(url, webpage):
-            return mobj.group('url')
+        for mobj in re.finditer(
-        vimeo_url = VimeoIE._extract_vimeo_url(url, info_page)
+        vimeo_url = VimeoIE._extract_url(url, info_page)
-                        video_id, 'Downloading %s stream JSON' % format_id)
+                    try:
-    _PLAYLIST_TITLE_RE = r'<h1[^>]+class=["\'].*?\bmedia-platform-title\b.*?["\'][^>]*>([^<]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:tegenlicht\.)?vpro|2doc)\.nl/(?:[^/]+/)*(?P<id>[^/]+)\.html'
-    _VALID_URL = r'https?://techtalks\.tv/talks/(?:[^/]*/)?(?P<id>\d+)/'
+    _VALID_URL = r'https?://techtalks\.tv/talks/(?:[^/]+/)?(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'https?://techtalks\.tv/talks/[^/]*/(?P<id>\d+)/'
+    _VALID_URL = r'https?://techtalks\.tv/talks/(?:[^/]*/)?(?P<id>\d+)/'
-    _VALID_URL = r'(?P<base_url>https?://(?:\w+\.)?youtube\.com/(?:user|channel)/(?P<id>[^/]+))/live'
+    _VALID_URL = r'(?P<base_url>https?://(?:\w+\.)?youtube\.com/(?:user|channel|c)/(?P<id>[^/]+))/live'
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# coding=utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding:utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# encoding: utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# coding=utf-8
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-# -*- coding: utf-8 -*-
+# coding: utf-8
-    _VALID_URL = r'https?://(?:www\.)?nhl\.com/([^/]+/)*c-(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<site>nhl|wch2016)\.com/(?:[^/]+/)*c-(?P<id>\d+)'
-        tmp_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            tmp_id)
+            'https://nhl.bamcontent.com/%s/id/v1/%s/details/web-v1.json'
-from .common import InfoExtractor
+from .jwplatform import JWPlatformBaseIE
-class PornoXOIE(InfoExtractor):
+class PornoXOIE(JWPlatformBaseIE):
-            'description': 'Striptease From Sexy Secretary!',
+            'display_id': 'striptease-from-sexy-secretary',
-        video_id = mobj.group('id')
+        video_id, display_id = mobj.groups()
-            r'\'file\'\s*:\s*"([^"]+)"', webpage, 'video_url')
+        video_data = self._extract_jwplayer_data(webpage, video_id, require_title=False)
-        return {
+        video_data.update({
-            'thumbnail': thumbnail,
+            'display_id': display_id,
-        }
+        })
-__version__ = '2016.09.27'
+__version__ = '2016.10.02'
-    def _parse_jwplayer_data(self, jwplayer_data, video_id=None, require_title=True, m3u8_id=None, rtmp_params=None, base_url=None):
+    def _parse_jwplayer_data(self, jwplayer_data, video_id=None, require_title=True,
-            jwplayer_data, video_id, require_title=False, m3u8_id='hls')
+            jwplayer_data, video_id, require_title=False, m3u8_id='hls', mpd_id='dash')
-            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml')
+            return '.' in vpath and vext not in ('swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml', 'js')
-        if not found:
+        self.msg = msg
-        postprocessors.append({'key': 'XAttrMetadata'})
+    # XAttrMetadataPP should be run after post-processors that may change file
-    _VALID_URL = r'https?://(?:www\.)?byutv.org/watch/(?P<id>[0-9a-f-]+)(?:/(?P<display_id>[^/?#&]+))?'
+    _VALID_URL = r'https?://(?:www\.)?byutv\.org/watch/(?!event/)(?P<id>[0-9a-f-]+)(?:/(?P<display_id>[^/?#&]+))?'
-from .byutv import BYUtvIE
+from .byutv import (
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?byutv.org/watch/(?P<id>[0-9a-f-]+)(?:/(?P<display_id>[^/?#&]+))?'
-            'id': 'studio-c-season-5-episode-5',
+            'id': '6587b9a3-89d2-42a6-a7f7-fd2f81840a7d',
-            'description': 'md5:e07269172baff037f8e8bf9956bc9747',
+            'description': 'md5:e07269172baff037f8e8bf9956bc9747',
-    }
+    }, {
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id)
-            episode_code, video_id, transform_source=lambda s:
+            episode_code, display_id, transform_source=lambda s:
-        else:
+        if ep['providerType'] != 'Ooyala':
-    _VALID_URL = r'^https?://(?:www\.)?byutv.org/watch/[0-9a-f-]+/(?P<video_id>[^/?#]+)'
+    _VALID_URL = r'^https?://(?:www\.)?byutv.org/watch/[0-9a-f-]+/(?P<id>[^/?#]+)'
-        video_id = mobj.group('video_id')
+        video_id = self._match_id(url)
-        ep = json.loads(episode_json)
+
-        session_id = data_store['SessionToken']['broadcastHistory']['token']['session_id']
+        session_id = data_store['SessionToken']['public']['broadcastHistory']['token']['session_id']
-                    pyxattr_required_version, xattr.__version__))
+        if hasattr(xattr, 'set'):  # pyxattr
-            xattr.set(path, key, value)
+            setxattr(path, key, value)
-                        write_xattr(tmpfilename, 'user.ytdl.filesize', str(data_len))
+                        write_xattr(tmpfilename, 'user.ytdl.filesize', str(data_len).encode('utf-8'))
-# -*- coding: utf-8 -*-
+# coding: utf-8
-
+            'thumbnail': 're:^https?://.*\.jpg$',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'so.addVariable\("videoURL", "(.+?)"\)\;', webpage, 'video url')
+            r'so\.addVariable\("videoURL", "(.+?)"\)\;', webpage, 'video url')
-            r'so.addVariable\("thumbnailURL", "(.+?)"\)\;',
+            r'so\.addVariable\("thumbnailURL", "(.+?)"\)\;',
-# encoding: utf-8
+# coding: utf-8
-from ..compat import compat_str
+from ..utils import unified_strdate
-            'id': '1324',
+            'id': '95eaa4f33dad413aa17b4ee613cccc6c',
-            'title': 'Videoinstallation fÃ¼r eine Kaufhausfassade'
+            'ext': 'mp4',
-        play_path = 'mp4:{0}_dctp_0500_{1}.m4v'.format(uuid, ratio)
+        webpage = self._download_webpage(url, video_id)
-            'http://www.dctp.tv/streaming_servers/',
+            'http://www.dctp.tv/elastic_streaming_client/get_streaming_server/',
-        url = servers_json[0]['endpoint']
+        server = servers_json[0]['server']
-            'display_id': video_id
+            'formats': formats,
-            parser.error('setting filesize xattr requested but python-xattr is not available')
+    write_xattr,
-                    except(OSError, IOError, ImportError) as err:
+                        write_xattr(tmpfilename, 'user.ytdl.filesize', str(data_len))
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        config_json = self._search_regex(
+        config = self._parse_json(self._search_regex(
-        config = json.loads(config_json)
+            'configuration'), video_id)
-                if comment.get('text')]
+                } for comment in media.get(
-         uploader_id, like_count, comment_count) = [None] * 8
+         uploader_id, like_count, comment_count, height, width) = [None] * 10
-            'url': video_url,
+            'formats': formats,
-    _VALID_URL = r'https?://(?:www\.)?tvland\.com/(?:video-clips|episodes)/(?P<id>[^/?#.]+)'
+    _VALID_URL = r'https?://(?:www\.)?tvland\.com/(?:video-clips|(?:full-)?episodes)/(?P<id>[^/?#.]+)'
-                        embed?.*id=
+                        embed?.*id=|
-from .aftonbladet import AftonbladetIE
+                'view_count': int,
-            r'class=["\']mv_info_date[^>]*>([^<]+)(?:<|from)', info_page,
+            r'class=["\']mv_info_date[^>]+>([^<]+)(?:<|from)', info_page,
-            info_page, 'view count', default=None))
+        view_count = str_to_int(self._search_regex(
-    unified_strdate,
+    unified_timestamp,
-            r'class="mv_info_date[^>]*>([^<]*)<', info_page, 'upload date', default=None))
+        timestamp = unified_timestamp(self._html_search_regex(
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-    '%b %d %Y at %H:%M:%S',
+    '%b %d %Y at %H:%M',
-                r'([\d,.]+)', views, 'view count', fatal=False))
+        upload_date = unified_strdate(self._html_search_regex(
-    encodeFilename,
+    write_xattr,
-
+        except XAttrUnavailableError as e:
-            if not isinstance(v, compat_str) or not v.startswith('http'):
+        for format_id, format_url in data.items():
-            })
+            if format_id.startswith(('url', 'cache')) or format_id in ('extra_data', 'live_mp4'):
-            'id': compat_str(data['vid']),
+            'id': compat_str(data.get('vid') or video_id),
-            'title': unescapeHTML(data['md_title']),
+            'title': title,
-            }
+            },
-            if not k.startswith('url') and not k.startswith('cache') and k != 'extra_data' or not v:
+            if (not k.startswith('url') and not k.startswith('cache')
-    _VALID_URL = r'https?://(?:www\.le\.com/ptv/vplay|sports\.le\.com/video)/(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://(?:www\.le\.com/ptv/vplay|(?:sports\.le|(?:www\.)?lesports)\.com/(?:match|video))/(?P<id>\d+)\.html'
-            entry_protocol='m3u8_native', m3u8_id='hls')
+        formats = []
-                    http_url = 'http://%s/%s' % (rtmp.group('host').replace('csl.', 'cpl.'), rtmp.group('playpath')[4:])
+                    http_url = 'http://cpl.delvenetworks.com/' + rtmp.group('playpath')[4:]
-__version__ = '2016.09.24'
+__version__ = '2016.09.27'
-    _VALID_URL = r'https?://(?:www\.)?mtv\.com/(video-clips|full-episodes)/(?P<id>[^/?#.]+)'
+    _VALID_URL = r'https?://(?:www\.)?mtv\.com/(?:video-clips|full-episodes)/(?P<id>[^/?#.]+)'
-from .vimeo import VimeoIE
+from .dailymotion import DailymotionIE
-                f['protocol'] = 'm3u8_native' if state == 'ended' else 'm3u8'
+                f['protocol'] = 'm3u8_native' if state in ('ended', 'timed_out') else 'm3u8'
-            'ext': 'flv',
+            'ext': 'mp4',
-        'md5': '73856edf3e89a711e70d5cf7cb280b37',
+        'params': {
-        'md5': '375c483c5080ab8cd85c9c84cfc2d1e4',
+        'params': {
-            'md5': 'af244f4458cd667205e513d75da5b8b1',
+            'md5': 'd71379996ff5b7f217eca034c34e3461',
-            'md5': 'ef63c7a803e22315880ed182c10d1c5c',
+            'md5': 'b16a6fd3c67c06eb7c79c8a8615f4213',
-                'description': 'md5:05d8a0c0281a4240d86d76e14f2f4d51',
+                'description': 'md5:b40f2bf7320b4f9414f3780817b2af8c',
-        video_url = self._download_webpage(
+        m3u8_url = self._download_webpage(
-            % video_id, video_id)
+            % video_id, video_id, headers={'Referer': url})
-            'url': video_url,
+            'formats': formats,
-        chash = self._html_search_regex(chash_pattern, webpage, "chash")
+        chash = self._search_regex(
-        fields[k] = chash + fields[k]
+        keys = list(fields.keys())
-            req, video_id, 'Downloading video page')
+            url, video_id, 'Downloading video page',
-        url = self._html_search_regex(url_pattern, webpage, 'URL')
+        video_url = self._search_regex(
-            'url': url,
+            'url': video_url,
-        'md5': 'd1451b6302da7215485837aaea882c4c',
+        'url': 'http://www.promptfile.com/l/86D1CE8462-576CAAE416',
-            'id': 'D21B4746E9-F01462F0FF',
+            'id': '86D1CE8462-576CAAE416',
-            'title': 'Birds.mp4',
+            'title': 'oceans.mp4',
-        url = self._html_search_regex(r'url:\s*\'([^\']+)\'', webpage, 'URL')
+        url_pattern = r'<a href="(http://www\.promptfile\.com/file/[^"]+)'
-                        (?P<q2>['\"])_?(?P<partner_id>[^'\"]+)(?P=q2),.*?
+                        (?P<q2>['\"])_?(?P<partner_id>(?:(?!(?P=q2)).)+)(?P=q2),.*?
-                        (?P<q4>['\"])(?P<id>[^'\"]+)(?P=q4),
+                        (?P<q4>['\"])(?P<id>(?:(?!(?P=q4)).)+)(?P=q4),
-                        (?:https?:)?//cdnapi(?:sec)?\.kaltura\.com/.*?(?:p|partner_id)/(?P<partner_id>\d+).*?
+                        (?:https?:)?//cdnapi(?:sec)?\.kaltura\.com/(?:(?!(?P=q1)).)*(?:p|partner_id)/(?P<partner_id>\d+)(?:(?!(?P=q1)).)*
-                    (?P<q3>["\'])(?P<id>.+?)(?P=q3)
+                    (?P<q3>["\'])(?P<id>(?:(?!(?P=q3)).)+)(?P=q3)
-    WNLIE
+    WNLIE,
-            for video_id in re.findall(self._PLAYLIST_ENTRY_RE, webpage)
+            for video_id in orderedSet(re.findall(self._PLAYLIST_ENTRY_RE, webpage))
-    _PLAYLIST_TITLE_RE = r'<title>\s*([^>]+?)\s*-\s*Teledoc\s*-\s*VPRO\s*</title>'
+    _PLAYLIST_TITLE_RE = r'<h1[^>]+class=["\'].*?\bmedia-platform-title\b.*?["\'][^>]*>([^<]+)'
-                'title': 'Sergio Herman: Fucking perfect',
+                'title': 'sergio herman: fucking perfect',
-                'title': '2Doc',
+                'title': 'education education',
-class VPROIE(NPOIE):
+class NPOPlaylistBaseIE(NPOIE):
-class WNLIE(InfoExtractor):
+class WNLIE(NPOPlaylistBaseIE):
-    _TEST = {
+    _TESTS = [{
-        return self.playlist_result(entries, playlist_id, playlist_title)
+    }]
-            'url': 'http://www.youtube.com/watch?v=BaW_jenozKc&t=1s&end=9',
+            'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&t=1s&end=9',
-            'url': 'http://www.youtube.com/watch?v=UxxajLWwzqY',
+            'url': 'https://www.youtube.com/watch?v=UxxajLWwzqY',
-            'url': 'http://www.youtube.com/watch?v=BaW_jenozKc&v=UxxajLWwzqY',
+            'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&v=UxxajLWwzqY',
-            'url': 'http://www.youtube.com/watch?v=a9LDPn-MO4I',
+            'url': 'https://www.youtube.com/watch?v=a9LDPn-MO4I',
-            'url': 'http://youtube.com/watch?v=HtVdAasjOgU',
+            'url': 'https://youtube.com/watch?v=HtVdAasjOgU',
-            'url': 'http://www.youtube.com/watch?v=6kLq3WMV1nU',
+            'url': 'https://www.youtube.com/watch?v=6kLq3WMV1nU',
-            'url': 'http://vid.plus/FlRa-iH7PGw',
+            'url': 'https://vid.plus/FlRa-iH7PGw',
-            'url': 'http://zwearz.com/watch/9lWxNJF-ufM/electra-woman-dyna-girl-official-trailer-grace-helbig.html',
+            'url': 'https://zwearz.com/watch/9lWxNJF-ufM/electra-woman-dyna-girl-official-trailer-grace-helbig.html',
-        'url': 'http://www.youtube.com/embed/videoseries?list=PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',
+        'url': 'https://www.youtube.com/embed/videoseries?list=PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',
-        'url': 'http://www.youtube.com/p/YN5VISEtHet5D4NEvfTd0zcgFk84NqFZ?hl=en_US&fs=1&rel=0',
+        'url': 'https://www.youtube.com/p/YN5VISEtHet5D4NEvfTd0zcgFk84NqFZ?hl=en_US&fs=1&rel=0',
-        'url': 'http://www.youtube.com/user/TheYoungTurks/live',
+        'url': 'https://www.youtube.com/user/TheYoungTurks/live',
-        'url': 'http://www.youtube.com/channel/UC1yBKRuGpC1tSM73A0ZjYjQ/live',
+        'url': 'https://www.youtube.com/channel/UC1yBKRuGpC1tSM73A0ZjYjQ/live',
-        'url': 'http://www.youtube.com/user/ThirstForScience/playlists',
+        'url': 'https://www.youtube.com/user/ThirstForScience/playlists',
-        'url': 'http://www.youtube.com/user/igorkle1/playlists?view=1&sort=dd',
+        'url': 'https://www.youtube.com/user/igorkle1/playlists?view=1&sort=dd',
-        'url': 'http://www.youtube.com/watch?annotation_id=annotation_3951667041',
+        'url': 'https://www.youtube.com/watch?annotation_id=annotation_3951667041',
-        'url': 'http://www.youtube.com/watch?',
+        'url': 'https://www.youtube.com/watch?',
-            '"http://www.youtube.com/watch?feature=foo&v=BaW_jenozKc" '
+            '"https://www.youtube.com/watch?feature=foo&v=BaW_jenozKc" '
-                                prosieben(?:maxx)?|sixx|sat1(?:gold)?|kabeleins(?:doku)?|the-voice-of-germany|7tv
+                                prosieben(?:maxx)?|sixx|sat1(?:gold)?|kabeleins(?:doku)?|the-voice-of-germany|7tv|advopedia
-                            ran\.de|fem\.com
+                            ran\.de|fem\.com|advopedia\.de
-                                prosieben|prosiebenmaxx|sixx|sat1(?:gold)?|kabeleins|the-voice-of-germany|7tv|kabeleinsdoku
+                                prosieben(?:maxx)?|sixx|sat1(?:gold)?|kabeleins(?:doku)?|the-voice-of-germany|7tv
-    _VALID_URL = r'https?://mwave\.interest\.me/mnettv/videodetail\.m\?searchVideoDetailVO\.clip_id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://mwave\.interest\.me/(?:[^/]+/)?mnettv/videodetail\.m\?searchVideoDetailVO\.clip_id=(?P<id>[0-9]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _TEST = {
+    _VALID_URL = r'https?://mwave\.interest\.me/(?:[^/]+/)?meetgreet/view/(?P<id>\d+)'
-    }
+    }, {
-                return self.playlist_result(entries, playlist_id, title, description)
+        playlist = self._parse_json(
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|the-voice-of-germany|7tv|kabeleinsdoku)\.(?:de|at|ch)|ran\.de|fem\.com)/(?P<id>.+)'
+    _VALID_URL = r'''(?x)
-    _VALID_URL = r'https?://(?:www\.)?cbsnews\.com/live/video/(?P<id>[\da-z_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?cbsnews\.com/live/video/(?P<id>[^/?#]+)'
-            'ext': 'flv',
+            'ext': 'mp4',
-        webpage = self._download_webpage(url, video_id)
+        display_id = self._match_id(url)
-            r'data-story-obj=\'({.+?})\'', webpage, 'video JSON info'), video_id)['story']
+        video_info = self._download_json(
-        self._sort_formats(f4m_formats)
+        formats = self._extract_akamai_formats(video_info['url'], display_id)
-            'id': video_id,
+            'id': display_id,
-            'formats': f4m_formats,
+            'formats': formats,
-            video_id, f4m_id='hds', fatal=False))
+        if 'hdcore=' not in f4m_url:
-            'title': title,
+            'title': self._live_title(title) if is_live else title,
-            'duration': float_or_none(json_data.get('duration'), 1000),
+            'duration': duration,
-    def can_download(manifest):
+    def can_download(manifest, info_dict):
-        if not self.can_download(s):
+        if not self.can_download(s, info_dict):
-class SoundcloudBaseIE(SoundcloudIE):
+class SoundcloudPlaylistBaseIE(SoundcloudIE):
-class SoundcloudSetIE(SoundcloudBaseIE):
+class SoundcloudSetIE(SoundcloudPlaylistBaseIE):
-class SoundcloudUserIE(SoundcloudBaseIE):
+class SoundcloudUserIE(SoundcloudPlaylistBaseIE):
-class SoundcloudPlaylistIE(SoundcloudBaseIE):
+class SoundcloudPlaylistIE(SoundcloudPlaylistBaseIE):
-class SoundcloudSetIE(SoundcloudIE):
+class SoundcloudBaseIE(SoundcloudIE):
-        entries = [self.url_result(track['permalink_url'], 'Soundcloud') for track in info['tracks']]
+        entries = self._extract_track_entries(info['tracks'])
-class SoundcloudUserIE(SoundcloudIE):
+class SoundcloudUserIE(SoundcloudBaseIE):
-        'playlist_mincount': 111,
+        'playlist_mincount': 74,
-        'playlist_mincount': 50,
+        'playlist_mincount': 37,
-        'playlist_mincount': 3,
+        'playlist_mincount': 2,
-            'title': 'Grynpyret (Spotlight)',
+            'title': 'GRYNPYRET (Spotlight)',
-                            return permalink_url
+                            return permalink_url, entry_id
-                permalink_url = resolve_permalink_url((e, e.get('track'), e.get('playlist')))
+                permalink_url, entry_id = resolve_permalink_url((e, e.get('track'), e.get('playlist')))
-                    entries.append(self.url_result(permalink_url))
+                    entries.append(self.url_result(permalink_url, video_id=entry_id))
-class SoundcloudPlaylistIE(SoundcloudIE):
+class SoundcloudPlaylistIE(SoundcloudBaseIE):
-            for track in data['tracks'] if track.get('permalink_url')]
+        entries = self._extract_track_entries(data['tracks'])
-            'md5': 'd4724ffe6d2437886d004fa5de1043b3',
+            'md5': 'b6d9683dd3f48e340ded81c0e917ad46',
-                'description': 'Take a quick peek at what\'s new and improved in Ubuntu 11.10.\n\nOnce installed take a look at 10 Things to Do After Installing: http://www.omgubuntu.co.uk/2011/10/10...',
+                'description': 'md5:a831e97fa384863d6e26ce48d1c43376',
-            r'data-(?:player-)?config="([^"]+)"', webpage, 'data player config'),
+            r'data-(?:player-)?config="([^"]+)"', webpage,
-            'description': 'Donte The Dumbass on Twitter: "BEAT PROD: @suhmeduh  https://t.co/HBrQ4AfpvZ #Damndaniel https://t.co/byBooq2ejZ"',
+            'title': 'JG - BEAT PROD: @suhmeduh #Damndaniel',
-            'uploader': 'Donte The Dumbass',
+            'uploader': 'JG',
-                'url': '%s//twitter.com/i/videos/tweet/%s' % (self.http_scheme(), twid),
+                'url': twitter_card_url,
-    _VALID_URL = r'(?x)https?://(?:www\.)?mtv\.com/(video-clips|full-episodes)/(?P<id>[^/?#.]+)'
+    IE_NAME = 'mtv'
-        return {
+        entries = self._parse_html5_media_entries(url, webpage, video_id)
-                    if not kind or kind == 'subtitles':
+                    if not kind or kind in ('subtitles', 'captions'):
-            if media_info['formats']:
+            if media_info['formats'] or media_info['subtitles']:
-__version__ = '2016.09.19'
+__version__ = '2016.09.24'
-        entries = [self.url_result(track['permalink_url'], 'Soundcloud') for track in data['tracks']]
+        entries = [
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|the-voice-of-germany|7tv)\.(?:de|at|ch)|ran\.de|fem\.com)/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|the-voice-of-germany|7tv|kabeleinsdoku)\.(?:de|at|ch)|ran\.de|fem\.com)/(?P<id>.+)'
-    ExtractorError,
+    xpath_element,
-            except ExtractorError:
+    def _extract_video_info(self, content_id):
-        info = self._parse_theplatform_metadata(metadata)
+
-            'id': guid,
+            'id': content_id,
-            r'<span[^>]+id="hiddenurl"[^>]*>([^<]+)</span>', webpage, 'encrypted data')
+            r'<span[^>]*>([^<]+)</span>\s*<span[^>]*>[^<]+</span>\s*<span[^>]+id="streamurl"',
-                j += 3
+                j += 2
-        } for format_id, video_url in video['media_urls'].items()]
+        } for format_id, video_url in video['media_urls'].items() if video_url]
-        video_id = asset['id']
+        video_id = compat_str(asset['id'])
-                        s_url, embed_code, 'mp4', 'm3u8_native',
+                        re.sub(r'/ip(?:ad|hone)/', '/all/', s_url), embed_code, 'mp4', 'm3u8_native',
-            r'<object[^>]+data=(["\'])https?://videomore.ru/player\.swf\?.*config=(?P<url>https?://videomore\.ru/(?:[^/]+/)+\d+\.xml).*\1',
+            r'<object[^>]+data=(["\'])https?://videomore\.ru/player\.swf\?.*config=(?P<url>https?://videomore\.ru/(?:[^/]+/)+\d+\.xml).*\1',
-        'name': 'DirecTV',
+        'name': 'DIRECTV',
-        'name': 'Rogers Cable',
+        'name': 'Rogers',
-                    mso_info['password_field']: password,
+                    mso_info.get('username_field', 'username'): username,
-                if mso_id == 'DTV':
+                if mso_id != 'Rogers':
-        if thumbnail is not None:
+        thumbnail = info.get('artwork_url')
-            'upload_date': unified_strdate(info['created_at']),
+            'uploader': info.get('user', {}).get('username'),
-            'description': info['description'],
+            'description': info.get('description'),
-            'license': track_license,
+            'license': info.get('license'),
-        token = None
+                'license': 'all-rights-reserved',
-
+        track_license = info['license']
-from .common import InfoExtractor
+from .adobepass import AdobePassIE
-class FOXIE(InfoExtractor):
+class FOXIE(AdobePassIE):
-            video_id)['release_url']
+        settings = self._parse_json(self._search_regex(
-                release_url, {'switch': 'http'}), {'force_smil_url': True}),
+            'url': smuggle_url(update_url_query(release_url, query), {'force_smil_url': True}),
-        guid = xml_text(resource, 'guid')
+        guid = xml_text(resource, 'guid') if '<' in resource else resource
-)
+from ..utils import extract_attributes
-                ' is not currently supported.', expected=True)
+            }, {
-from .common import InfoExtractor
+from .adobepass import AdobePassIE
-class TurnerBaseIE(InfoExtractor):
+class TurnerBaseIE(AdobePassIE):
-    def _extract_cvp_info(self, data_src, video_id, path_data={}):
+    def _extract_cvp_info(self, data_src, video_id, path_data={}, ap_data={}):
-                        })
+                        secure_path_data['tokenizer_src'], video_id, query=query)
-__version__ = '2016.09.18'
+__version__ = '2016.09.19'
-        if '<title>Redirecting' in response:
+        if is_logged(response):
-                'TwitchProfile', channel_id)
+            raise ExtractorError('%s is offline' % channel_id, expected=True)
-        title = self._html_search_regex(r'<h1>([^<]*)</h1>', webpage, 'title')
+        title = remove_end(self._html_search_regex(
-            station_id)
+            station_id, 'Downloading channels JSON')
-        title = info['name']
+            'http://vybory.mos.ru/json/voting_stations/%s/%s.json'
-            'title': self._live_title(title),
+            'title': self._live_title(info['name'] if info else station_id),
-__version__ = '2016.09.15'
+__version__ = '2016.09.18'
-            [r'style="z-index: [0-9]+;">([^<]+)</span>',
+            (r'style="z-index: [0-9]+;">([^<]+)</span>',
-            webpage, 'title', default=None) or self._og_search_title(webpage)).strip()
+             r'<h2 class="video-page-head">([^<]+)</h2>',
-    _VALID_URL = r'https?://.+?\.globo\.com/(?:[^/]+/)*(?P<id>[^/]+)(?:\.html)?'
+    _VALID_URL = r'https?://.+?\.globo\.com/(?:[^/]+/)*(?P<id>[^/.]+)(?:\.html)?'
-        }
+            'id': 'novidade-na-fiscalizacao-de-bagagem-pela-receita-provoca-discussoes',
-        return self.url_result('globo:%s' % video_id, 'Globo')
+        video_ids = []
-                    'url': format_url(line.strip()),
+                    'url': manifest_url,
-        initialization_url = info_dict.get('initialization_url')
+        segments = info_dict['fragments'][:1] if self.params.get(
-            'total_frags': len(segment_urls) + (1 if initialization_url else 0),
+            'total_frags': len(segments),
-            target_url, segment_name = segment
+        def process_segment(segment, tmp_filename, num):
-                    success = ctx['dl'].download(target_filename, {'url': combine_url(base_url, target_url)})
+                    success = ctx['dl'].download(target_filename, {'url': segment_url})
-            if not process_segment(segment, ctx['tmpfilename'], fatal):
+        for i, segment in enumerate(segments):
-                                 (DASH, hls, hds).
+                    * url        Mandatory. The URL of the video file
-            compat_etree_fromstring(mpd.encode('utf-8')), mpd_id, mpd_base_url, formats_dict=formats_dict)
+            compat_etree_fromstring(mpd.encode('utf-8')), mpd_id, mpd_base_url,
-    def _parse_mpd_formats(self, mpd_doc, mpd_id=None, mpd_base_url='', formats_dict={}):
+    def _parse_mpd_formats(self, mpd_doc, mpd_id=None, mpd_base_url='', formats_dict={}, mpd_url=None):
-                        if 'segment_urls' in representation_ms_info:
+                        # NB: MPD manifest may contain direct URLs to unfragmented media.
-                    doc, video_id, mpd_base_url=url.rpartition('/')[0])
+                    doc, video_id,
-            player_type = vr.get('playerType')
+            player_type = vr.get('playerType') or vr.get('format')
-                            ms_info['segment_duration'] = int(segment_duration)
+                    extract_common(segment_template)
-                            ms_info['initialization_url'] = initialization.attrib['sourceURL']
+                        extract_Initialization(segment_template)
-                                representation_ms_info['total_number'] = int(math.ceil(float(period_duration) / segment_duration))
+
-                            if '%(Number' in media_template:
+                            if '%(Number' in media_template and 's' not in representation_ms_info:
-                                    )
+                                    segment_url = media_template % {
-                                        segment_time += s['d']
+                                        segment_time += segment_d
-                                    segment_time += s['d']
+                                        segment_number += 1
-                    * url        Mandatory. The URL of the video file
+                    * url        Mandatory. The URL of the video file or URL of
-from ..utils import determine_ext
+from .jwplatform import JWPlatformBaseIE
-class ThisAVIE(InfoExtractor):
+class ThisAVIE(JWPlatformBaseIE):
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r"addVariable\('file','([^']+)'\);", webpage, 'video url')
+            r"addVariable\('file','([^']+)'\);", webpage, 'video url', default=None)
-        return {
+        info_dict.update({
-        }
+        })
-            'jwplayer\((?P<quote>[\'"])[^\'" ]+(?P=quote)\)\.setup\((?P<options>[^)]+)\)',
+            r'jwplayer\((?P<quote>[\'"])[^\'" ]+(?P=quote)\)\.setup\s*\((?P<options>[^)]+)\)',
-            self._find_jwplayer_data(webpage), video_id)
+            self._find_jwplayer_data(webpage), video_id,
-        'md5': '4e3aeb58fe0e83d7b0581fa213c409d0',
+        'url': 'https://www.franceinter.fr/emissions/affaires-sensibles/affaires-sensibles-07-septembre-2016',
-            'id': 'la-tete-au-carre/la-tete-au-carre-14-septembre-2016',
+            'id': 'affaires-sensibles/affaires-sensibles-07-septembre-2016',
-            'upload_date': '20160914',
+            'title': 'Affaire Cahuzac : le contentieux du compte en Suisse',
-            r'''(?x)<iframe[^>]+src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?admin\.mangomolo.com/analytics/index\.php/customers/embed/
+            r'''(?x)<iframe[^>]+src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?admin\.mangomolo\.com/analytics/index\.php/customers/embed/
-    _VALID_URL = r'https?://admin\.mangomolo.com/analytics/index\.php/customers/embed/video\?.*?\bid=(?P<id>\d+)'
+    _VALID_URL = r'https?://admin\.mangomolo\.com/analytics/index\.php/customers/embed/video\?.*?\bid=(?P<id>\d+)'
-    _VALID_URL = r'https?://admin\.mangomolo.com/analytics/index\.php/customers/embed/index\?.*?\bchannelid=(?P<id>(?:[A-Za-z0-9+/=]|%2B|%2F|%3D)+)'
+    _VALID_URL = r'https?://admin\.mangomolo\.com/analytics/index\.php/customers/embed/index\?.*?\bchannelid=(?P<id>(?:[A-Za-z0-9+/=]|%2B|%2F|%3D)+)'
-        self.run_ffmpeg(filename, temp_filename, options)
+        if self.get_audio_codec(filename) == 'aac':
-        os.rename(encodeFilename(temp_filename), encodeFilename(filename))
+            options = ['-c', 'copy', '-f', 'mp4', '-bsf:a', 'aac_adtstoasc']
-    IENAME = 'mangomolo:video'
+    IE_NAME = 'mangomolo:video'
-    IENAME = 'mangomolo:live'
+    IE_NAME = 'mangomolo:live'
-        info['formats'] = self._extract_video_formats(webpage, video_id, 'm3u8_native')
+        embed_url = 'http://admin.mangomolo.com/analytics/index.php/customers/embed/video?' + compat_urllib_parse_urlencode({
-        info['formats'] = self._extract_video_formats(webpage, channel_id, 'm3u8')
+        embed_url = 'http://admin.mangomolo.com/analytics/index.php/customers/embed/index?' + compat_urllib_parse_urlencode({
-        formats = self._extract_m3u8_formats(playlist_url, display_id, 'mp4')
+        playlist_url = 'http://vod.streamcloud.be/%s/_definst_/mp4:%s.mp4/playlist.m3u8' % (application, filename)
-            formats.extend([rtmp_format, rtsp_format])
+        formats = self._extract_wowza_formats(
-                        http_format = rtmp_format_c.copy()
+            formats = self._extract_wowza_formats(src, video_id)
-                            'format_id': rtmp_format['format_id'].replace('rtmp', 'http'),
+                            'url': f['url'].replace('rtsp://', 'http://').replace('vod.', 'download.').replace('/_definst_/', '/').replace('mp4:', ''),
-                    '%s/manifest.f4m' % src, video_id, f4m_id='hds', fatal=False))
+                        formats.append(http_format)
-        device_types = ['ipad', 'android']
+        metadata = self._download_xml(
-                    'deviceType': device_type,
+            validation_url = 'http://api.radio-canada.ca/validationMedia/v1/Validation.ashx'
-                }, fatal=False)
+                })
-from ..utils import int_or_none
+from ..utils import (
-            'url': 'radiocanada:%s:%s' % (metadata.get('AppCode', 'toutv'), video_id),
+            'url': video_url,
-        'md5': '4764932e466e6f6c79c317d2e74f6884',
+        'url': 'https://www.franceinter.fr/emissions/la-tete-au-carre/la-tete-au-carre-14-septembre-2016',
-            'id': 'la-marche-de-l-histoire/la-marche-de-l-histoire-18-decembre-2013',
+            'id': 'la-tete-au-carre/la-tete-au-carre-14-septembre-2016',
-            'upload_date': '20131218',
+            'title': 'Et si les rÃªves pouvaient nous aider Ã  agir dans notre vie quotidienne ?',
-            upload_date_list[1] = compat_str(month_by_name(upload_date_list[1], lang='fr'))
+            upload_date_list[1] = '%02d' % (month_by_name(upload_date_list[1], lang='fr') or 0)
-            'http://www.tv4play.se/player/assets/%s.json' % video_id, video_id, 'Downloading video info JSON')
+            'http://www.tv4play.se/player/assets/%s.json' % video_id,
-        if info['is_geo_restricted']:
+        if info.get('is_geo_restricted'):
-        if info['requires_subscription']:
+        if info.get('requires_subscription'):
-        sources = sources_data['playback']
+        title = info['title']
-            })
+        # http formats are linked with unresolvable host
-            'title': info['title'],
+            'title': title,
-            'duration': info.get('duration'),
+            'duration': int_or_none(info.get('duration')),
-            'is_live': sources.get('live'),
+            'is_live': info.get('is_live') is True,
-__version__ = '2016.09.11.1'
+__version__ = '2016.09.15'
-            r'data-video=(["\'])(?P<id>.+?)\1', webpage, 'video id', group='id')
+            r'data-video=(["\'])(?P<id>(?:(?!\1).)+)\1', webpage, 'video id', group='id')
-            r'(?:<nflcs:avplayer[^>]+data-content[Ii]d\s*=\s*|content[Ii]d\s*:\s*)(["\'])(?P<id>.+?)\1',
+            r'(?:<nflcs:avplayer[^>]+data-content[Ii]d\s*=\s*|content[Ii]d\s*:\s*)(["\'])(?P<id>(?:(?!\1).)+)\1',
-            r'data-mid=(["\'])(?P<id>.+?)\1', webpage, 'video_id', group='id')
+            r'data-mid=(["\'])(?P<id>(?:(?!\1).)+)\1', webpage, 'video_id', group='id')
-            requestor_info = self._downloader.cache.load('mvpd', requestor_id) or {}
+            requestor_info = self._downloader.cache.load(self._MVPD_CACHE, requestor_id) or {}
-                    self._downloader.cache.store('mvpd', requestor_id, {})
+                    self._downloader.cache.store(self._MVPD_CACHE, requestor_id, {})
-                self._downloader.cache.store('mvpd', requestor_id, requestor_info)
+                self._downloader.cache.store(self._MVPD_CACHE, requestor_id, requestor_info)
-                    self._downloader.cache.store('mvpd', requestor_id, {})
+                    self._downloader.cache.store(self._MVPD_CACHE, requestor_id, {})
-                self._downloader.cache.store('mvpd', requestor_id, requestor_info)
+                self._downloader.cache.store(self._MVPD_CACHE, requestor_id, requestor_info)
-                self._downloader.cache.store('mvpd', requestor_id, {})
+                self._downloader.cache.store(self._MVPD_CACHE, requestor_id, {})
-                    raise netrc.NetrcParseError('No authenticators for %s' % netrc_machine)
+                    raise netrc.NetrcParseError(
-                self._downloader.report_warning('parsing .netrc: %s' % error_to_compat_str(err))
+                self._downloader.report_warning(
-        return (username, password)
+        return username, password
-        It will look in the netrc file using the _NETRC_MACHINE value
+        First look for the manually specified credentials using username_option
-        return (username, password)
+        return username, password
-    ap_password:       TV Provider password for authentication purposes.
+    ap_mso:            Adobe Pass multiple-system operator identifier.
-        help='Adobe Pass Multiple-system operator Identifier')
+        help='Adobe Pass multiple-system operator (TV provider) identifier, use --ap-list-mso for a list of available MSOs')
-        help='TV Provider Login with this account ID')
+        help='Multiple-system operator account login')
-        help='TV Provider Account password. If this option is left out, youtube-dl will ask interactively.')
+        help='Multiple-system operator account password. If this option is left out, youtube-dl will ask interactively.')
-        help='List all supported TV Providers')
+        help='List all supported multiple-system operators')
-            if not re.search(r'type=(["\'])(?:hidden|submit)\1', input):
+        for input in re.findall(r'(?i)(<input[^>]+>)', html):
-            if not name:
+            if attrs.get('type') not in ('hidden', 'submit'):
-            hidden_inputs[name.group('value')] = value.group('value')
+            name = attrs.get('name') or attrs.get('id')
-            'password': password,
+
-        self._download_webpage(login_request, None, False, 'Wrong login info')
+
-            '%s/%s' % (self._API_BASE, path), item_id, note)
+            '%s/%s' % (self._API_BASE, path), item_id, note,
-    _VALID_URL = r'https?://(?:www\.)?(?P<domain>ctv|tsn|bnn|thecomedynetwork)\.ca/.*?(?:\bvid=|-vid|~|%7E)(?P<id>[0-9.]+)'
+class BellMediaIE(InfoExtractor):
-            domain = 'comedy'
+        domain = domain.split('.')[0]
-            'url': '9c9media:%s_web:%s' % (domain, video_id),
+            'url': '9c9media:%s_web:%s' % (self._DOMAINS.get(domain, domain), video_id),
-    if opts.ap_mso_list:
+    if opts.ap_list_mso:
-        parser.error('Unsupported TV Provider, use --ap-mso-list to get a list of supported TV Providers')
+        parser.error('Unsupported TV Provider, use --ap-list-mso to get a list of supported TV Providers')
-        action='store_true', dest='ap_mso_list', default=False,
+        '--ap-list-mso',
-    ap_mso_id:         Adobe Pass Multiple-system operator Identifier.
+    ap_mso:            Adobe Pass Multiple-system operator Identifier.
-    if opts.list_ap_mso_ids:
+    if opts.ap_mso_list:
-        write_string('Supported TV Providers:\n' + render_table(['mso id', 'mso name'], table) + '\n', out=sys.stdout)
+        write_string('Supported TV Providers:\n' + render_table(['mso', 'mso name'], table) + '\n', out=sys.stdout)
-        'ap_mso_id': opts.ap_mso_id,
+        'ap_mso': opts.ap_mso,
-                'and --netrc to provide account credentials.', expected=True)
+                'Use --ap-mso to specify Adobe Pass Multiple-system operator Identifier '
-                mso_id = self._downloader.params.get('ap_mso_id')
+                mso_id = self._downloader.params.get('ap_mso')
-        dest='ap_mso_id', metavar='APMSOID',
+        '--ap-mso',
-        dest='ap_username', metavar='APUSERNAME',
+        dest='ap_username', metavar='USERNAME',
-        dest='ap_password', metavar='APPASSWORD',
+        dest='ap_password', metavar='PASSWORD',
-        action='store_true', dest='list_ap_mso_ids', default=False,
+        '--ap-mso-list',
-)
+from ..compat import compat_str
-            'timestamp': 1387324800,
+            'description': 'md5:7f2ce449894d1e585932273080fb410d',
-            r'<button class="replay-button playable" data-is-aod="1" data-url="([^"]+)"', webpage, 'video url')
+            r'(?s)<div[^>]+class=["\']page-diffusion["\'][^>]*>.*?<button[^>]+data-url=(["\'])(?P<url>(?:(?!\1).)+)\1',
-        timestamp = unified_timestamp(extractdate)
+        upload_date_str = self._search_regex(
-            'timestamp': timestamp,
+            'upload_date': upload_date,
-        self.assertEqual(month_by_name('decembre', 'fr'), 12)
+        self.assertEqual(month_by_name('dÃ©cembre', 'fr'), 12)
-        self.assertEqual(month_by_name('decembre'), None)
+        self.assertEqual(month_by_name('dÃ©cembre'), None)
-        'juillet', 'aout', 'septembre', 'octobre', 'novembre', 'decembre'],
+        'janvier', 'fÃ©vrier', 'mars', 'avril', 'mai', 'juin',
-    'juillet', 'aout', 'septembre', 'octobre', 'novembre', 'decembre']
+MONTH_NAMES = {
-        name_list = FRENCH_MONTH_NAMES
+    month_names = MONTH_NAMES.get(lang, MONTH_NAMES['en'])
-        return name_list.index(name) + 1
+        return month_names.index(name) + 1
-from ..utils import int_or_none
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?franceinter\.fr/player/reecouter\?play=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?franceinter\.fr/emissions/(?P<id>[^?#]+)'
-        'url': 'http://www.franceinter.fr/player/reecouter?play=793962',
+        'url': 'https://www.franceinter.fr/emissions/la-marche-de-l-histoire/la-marche-de-l-histoire-18-decembre-2013',
-            'id': '793962',
+            'id': 'la-marche-de-l-histoire/la-marche-de-l-histoire-18-decembre-2013',
-            'timestamp': 1387369800,
+            'title': 'LâHistoire dans les jeux vidÃ©o du 18 dÃ©cembre 2013 - France Inter',
-            r'data-date="(\d+)"', webpage, 'upload date', fatal=False))
+        video_url = self._search_regex(
-def month_by_name(name):
+def month_by_name(name, lang='en'):
-        return ENGLISH_MONTH_NAMES.index(name) + 1
+        return name_list.index(name) + 1
-        webpage = self._download_webpage(
+        webpage, urlh = self._download_webpage_handle(
-        if 'å¯¹ä¸èµ·ï¼è¯¥æ­æ²ç±äºçæé®é¢å·²è¢«ä¸çº¿ï¼å°è¿åç½ç«é¦é¡µ' in webpage:
+        if song_id not in urlh.geturl() or 'å¯¹ä¸èµ·ï¼è¯¥æ­æ²ç±äºçæé®é¢å·²è¢«ä¸çº¿ï¼å°è¿åç½ç«é¦é¡µ' in webpage:
-            'format': 'mp3-320'
+            'format': 'mp3-320',
-        'playlist_mincount': 10,
+        'playlist_mincount': 7,
-            'creator': 'PM02:00',
+            'creator': '2PM',
-                        raise ExtractorError('%s said: %s' % (self.IE_NAME, error_massege), expected=True)
+                        error_message = ', '.join([error['message'] for error in errors])
-    _VALID_URL = r'https?://(?:(?P<sub_domain>%s)\.)?go\.com/.*?vdka(?P<id>\w+)' % '|'.join(_BRANDS.keys())
+    _VALID_URL = r'https?://(?:(?P<sub_domain>%s)\.)?go\.com/(?:[^/]+/)*(?:vdka(?P<id>\w+)|season-\d+/\d+-(?P<display_id>[^/?#]+))' % '|'.join(_BRANDS.keys())
-        sub_domain, video_id = re.match(self._VALID_URL, url).groups()
+        sub_domain, video_id, display_id = re.match(self._VALID_URL, url).groups()
-            'http://api.contents.watchabc.go.com/vp2/ws/contents/3000/videos/%s/001/-1/-1/-1/%s/-1/-1.json' % (self._BRANDS[sub_domain], video_id),
+            'http://api.contents.watchabc.go.com/vp2/ws/contents/3000/videos/%s/001/-1/-1/-1/%s/-1/-1.json' % (brand, video_id),
-    _VALID_URL = r'https?://www\.abc\.net\.au/news/(?:[^/]+/){1,2}(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?abc\.net\.au/news/(?:[^/]+/){1,2}(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.aljazeera\.com/programmes/.*?/(?P<id>[^/]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?aljazeera\.com/programmes/.*?/(?P<id>[^/]+)\.html'
-    _VALID_URL = r'https?://www.azubu.tv/(?P<id>[^/]+)$'
+    _VALID_URL = r'https?://(?:www\.)?azubu\.tv/(?P<id>[^/]+)$'
-    _VALID_URL = r'https?://www.bbc.co.uk/programmes/articles/(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/programmes/articles/(?P<id>[a-zA-Z0-9]+)'
-    _VALID_URL = r'https?://www\.bpb\.de/mediathek/(?P<id>[0-9]+)/'
+    _VALID_URL = r'https?://(?:www\.)?bpb\.de/mediathek/(?P<id>[0-9]+)/'
-    _VALID_URL = r'https?://www.camdemy.com/folder/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?camdemy\.com/folder/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.cbssports\.com/video/player/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?cbssports\.com/video/player/[^/]+/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.ceskatelevize\.cz/(porady|ivysilani)/(?:[^/]+/)*(?P<id>[^/#?]+)/*(?:[#?].*)?$'
+    _VALID_URL = r'https?://(?:www\.)?ceskatelevize\.cz/(porady|ivysilani)/(?:[^/]+/)*(?P<id>[^/#?]+)/*(?:[#?].*)?$'
-    _VALID_URL = r'https?://(?:www\.)?chirbit.com/(?:rss/)?(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?chirbit\.com/(?:rss/)?(?P<id>[^/]+)'
-    _VALID_URL = r'https?://www\.cmt\.com/(?:videos|shows)/(?:[^/]+/)*(?P<videoid>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?cmt\.com/(?:videos|shows)/(?:[^/]+/)*(?P<videoid>\d+)'
-    _VALID_URL = r'https?://www\.criterion\.com/films/(?P<id>[0-9]+)-.+'
+    _VALID_URL = r'https?://(?:www\.)?criterion\.com/films/(?P<id>[0-9]+)-.+'
-    _VALID_URL = r'https?://www.dctp.tv/(#/)?filme/(?P<id>.+?)/$'
+    _VALID_URL = r'https?://(?:www\.)?dctp\.tv/(#/)?filme/(?P<id>.+?)/$'
-    _VALID_URL = r'https?://(?:www\.)?democracynow.org/(?P<id>[^\?]*)'
+    _VALID_URL = r'https?://(?:www\.)?democracynow\.org/(?P<id>[^\?]*)'
-    _VALID_URL = r'https?://www.engadget.com/video/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?engadget\.com/video/(?P<id>[^/?#]+)'
-    _VALID_URL = r'https?://www\.expotv\.com/videos/[^?#]*/(?P<id>[0-9]+)($|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?expotv\.com/videos/[^?#]*/(?P<id>[0-9]+)($|[?#])'
-    _VALID_URL = r'https://www\.freespeech\.org/video/(?P<title>.+)'
+    _VALID_URL = r'https?://(?:www\.)?freespeech\.org/video/(?P<title>.+)'
-    _VALID_URL = r'https?://www\.gamestar\.de/videos/.*,(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?gamestar\.de/videos/.*,(?P<id>[0-9]+)\.html'
-    _VALID_URL = r'https://plus\.google\.com/(?:[^/]+/)*?posts/(?P<id>\w+)'
+    _VALID_URL = r'https?://plus\.google\.com/(?:[^/]+/)*?posts/(?P<id>\w+)'
-    _VALID_URL = r'https?://www\.goshgay\.com/video(?P<id>\d+?)($|/)'
+    _VALID_URL = r'https?://(?:www\.)?goshgay\.com/video(?P<id>\d+?)($|/)'
-    _VALID_URL = r'https?://www\.hark\.com/clips/(?P<id>.+?)-.+'
+    _VALID_URL = r'https?://(?:www\.)?hark\.com/clips/(?P<id>.+?)-.+'
-    _VALID_URL = r'https?://www\.hotnewhiphop\.com/.*\.(?P<id>.*)\.html'
+    _VALID_URL = r'https?://(?:www\.)?hotnewhiphop\.com/.*\.(?P<id>.*)\.html'
-    _VALID_URL = r'https?://www\.imdb\.com/list/(?P<id>[\da-zA-Z_-]{11})'
+    _VALID_URL = r'https?://(?:www\.)?imdb\.com/list/(?P<id>[\da-zA-Z_-]{11})'
-    _VALID_URL = r'https?://www\.karaoketv\.co\.il/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?karaoketv\.co\.il/[^/]+/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.kickstarter\.com/projects/(?P<id>[^/]*)/.*'
+    _VALID_URL = r'https?://(?:www\.)?kickstarter\.com/projects/(?P<id>[^/]*)/.*'
-    _VALID_URL = r'https?://www\.kuwo\.cn/yinyue/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?kuwo\.cn/yinyue/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.kuwo\.cn/album/(?P<id>\d+?)/'
+    _VALID_URL = r'https?://(?:www\.)?kuwo\.cn/album/(?P<id>\d+?)/'
-    _VALID_URL = r'https?://www\.kuwo\.cn/mingxing/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?kuwo\.cn/mingxing/(?P<id>[^/]+)'
-    _VALID_URL = r'https?://www\.kuwo\.cn/mv/(?P<id>\d+?)/'
+    _VALID_URL = r'https?://(?:www\.)?kuwo\.cn/mv/(?P<id>\d+?)/'
-    _VALID_URL = r'https?://www\.litv\.tv/(?:vod|promo)/[^/]+/(?:content\.do)?\?.*?\b(?:content_)?id=(?P<id>[^&]+)'
+    _VALID_URL = r'https?://(?:www\.)?litv\.tv/(?:vod|promo)/[^/]+/(?:content\.do)?\?.*?\b(?:content_)?id=(?P<id>[^&]+)'
-    _VALID_URL = r'https?://www\.lynda\.com/(?:[^/]+/[^/]+/\d+|player/embed)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?lynda\.com/(?:[^/]+/[^/]+/\d+|player/embed)/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.macgamestore\.com/mediaviewer\.php\?trailer=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?macgamestore\.com/mediaviewer\.php\?trailer=(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.metacritic\.com/.+?/trailers/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?metacritic\.com/.+?/trailers/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.mgtv\.com/v/(?:[^/]+/)*(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?mgtv\.com/v/(?:[^/]+/)*(?P<id>\d+)\.html'
-    _VALID_URL = r'https?://www\.ministrygrid.com/([^/?#]*/)*(?P<id>[^/#?]+)/?(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?ministrygrid\.com/([^/?#]*/)*(?P<id>[^/#?]+)/?(?:$|[?#])'
-    _VALID_URL = r'https?://www\.mitele\.es/(?:[^/]+/){3}(?P<id>[^/]+)/'
+    _VALID_URL = r'https?://(?:www\.)?mitele\.es/(?:[^/]+/){3}(?P<id>[^/]+)/'
-    _VALID_URL = r'https?://www\.motorsport\.com/[^/?#]+/video/(?:[^/?#]+/)(?P<id>[^/]+)/?(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?motorsport\.com/[^/?#]+/video/(?:[^/?#]+/)(?P<id>[^/]+)/?(?:$|[?#])'
-    _VALID_URL = r'https?://www\.moviezine\.se/video/(?P<id>[^?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?moviezine\.se/video/(?P<id>[^?#]+)'
-    _VALID_URL = r'https?://www\.myspass\.de/.*'
+    _VALID_URL = r'https?://(?:www\.)?myspass\.de/.*'
-    _VALID_URL = r'https?://www\.nbc\.com/(?:[^/]+/)+(?P<id>n?\d+)'
+    _VALID_URL = r'https?://(?:www\.)?nbc\.com/(?:[^/]+/)+(?P<id>n?\d+)'
-    _VALID_URL = r'https?://www\.nbcsports\.com//?(?:[^/]+/)+(?P<id>[0-9a-z-]+)'
+    _VALID_URL = r'https?://(?:www\.)?nbcsports\.com//?(?:[^/]+/)+(?P<id>[0-9a-z-]+)'
-    _VALID_URL = r'https?://www\.csnne\.com/video/(?P<id>[0-9a-z-]+)'
+    _VALID_URL = r'https?://(?:www\.)?csnne\.com/video/(?P<id>[0-9a-z-]+)'
-    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)*(?P<id>[^/?#]+),[\da-z]+\.html'
+    _VALID_URL = r'https?://(?:www\.)?ndr\.de/(?:[^/]+/)*(?P<id>[^/?#]+),[\da-z]+\.html'
-    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)*(?:(?P<display_id>[^/?#]+),)?(?P<id>[\da-z]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?n-joy\.de/(?:[^/]+/)*(?:(?P<display_id>[^/?#]+),)?(?P<id>[\da-z]+)\.html'
-    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)*(?P<id>[\da-z]+)-(?:player|externalPlayer)\.html'
+    _VALID_URL = r'https?://(?:www\.)?ndr\.de/(?:[^/]+/)*(?P<id>[\da-z]+)-(?:player|externalPlayer)\.html'
-    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)*(?P<id>[\da-z]+)-(?:player|externalPlayer)_[^/]+\.html'
+    _VALID_URL = r'https?://(?:www\.)?n-joy\.de/(?:[^/]+/)*(?P<id>[\da-z]+)-(?:player|externalPlayer)_[^/]+\.html'
-    _VALID_URL = r'https?://hk.apple.nextmedia.com/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)'
+    _VALID_URL = r'https?://hk\.apple\.nextmedia\.com/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)'
-    _VALID_URL = r'https?://hk.dv.nextmedia.com/actionnews/[^/]+/(?P<date>\d+)/(?P<id>\d+)/\d+'
+    _VALID_URL = r'https?://hk\.dv\.nextmedia\.com/actionnews/[^/]+/(?P<date>\d+)/(?P<id>\d+)/\d+'
-    _VALID_URL = r'https?://(www|ent).appledaily.com.tw/(?:animation|appledaily|enews|realtimenews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
+    _VALID_URL = r'https?://(www|ent)\.appledaily\.com\.tw/(?:animation|appledaily|enews|realtimenews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
-    _VALID_URL = r'https?://www\.nicovideo\.jp/mylist/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?nicovideo\.jp/mylist/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.oktoberfest-tv\.de/[^/]+/[^/]+/video/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?oktoberfest-tv\.de/[^/]+/[^/]+/video/(?P<id>[^/?#]+)'
-    _VALID_URL = r'https://openload.(?:co|io)/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
+    _VALID_URL = r'https?://openload\.(?:co|io)/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
-    _VALID_URL = r'https?://www\.periscope\.tv/(?P<id>[^/]+)/?$'
+    _VALID_URL = r'https?://(?:www\.)?periscope\.tv/(?P<id>[^/]+)/?$'
-    _VALID_URL = r'https?://www\.playvid\.com/watch(\?v=|/)(?P<id>.+?)(?:#|$)'
+    _VALID_URL = r'https?://(?:www\.)?playvid\.com/watch(\?v=|/)(?P<id>.+?)(?:#|$)'
-    _VALID_URL = r'https?://y.qq.com/#type=song&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y\.qq\.com/#type=song&mid=(?P<id>[0-9A-Za-z]+)'
-    _VALID_URL = r'https?://y.qq.com/#type=singer&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y\.qq\.com/#type=singer&mid=(?P<id>[0-9A-Za-z]+)'
-    _VALID_URL = r'https?://y.qq.com/#type=album&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y\.qq\.com/#type=album&mid=(?P<id>[0-9A-Za-z]+)'
-    _VALID_URL = r'https?://www\.rottentomatoes\.com/m/[^/]+/trailers/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?rottentomatoes\.com/m/[^/]+/trailers/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.roxwel\.com/player/(?P<filename>.+?)(\.|\?|$)'
+    _VALID_URL = r'https?://(?:www\.)?roxwel\.com/player/(?P<filename>.+?)(\.|\?|$)'
-    _VALID_URL = r'https?://www\.rtve\.es/(m/)?(alacarta/videos|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?rtve\.es/(m/)?(alacarta/videos|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.rtve\.es/directo/(?P<id>[a-zA-Z0-9-]+)'
+    _VALID_URL = r'https?://(?:www\.)?rtve\.es/directo/(?P<id>[a-zA-Z0-9-]+)'
-    _VALID_URL = r'https?://www\.rtve\.es/television/[^/]+/[^/]+/(?P<id>\d+).shtml'
+    _VALID_URL = r'https?://(?:www\.)?rtve\.es/television/[^/]+/[^/]+/(?P<id>\d+).shtml'
-    _VALID_URL = r'https?://www.screenjunkies.com/video/(?P<display_id>[^/]+?)(?:-(?P<id>\d+))?(?:[/?#&]|$)'
+    _VALID_URL = r'https?://(?:www\.)?screenjunkies\.com/video/(?P<display_id>[^/]+?)(?:-(?P<id>\d+))?(?:[/?#&]|$)'
-    _VALID_URL = r'https?://www\.senate\.gov/isvp/?\?(?P<qs>.+)'
+    _VALID_URL = r'https?://(?:www\.)?senate\.gov/isvp/?\?(?P<qs>.+)'
-    _VALID_URL = r'https?://www\.slideshare\.net/[^/]+?/(?P<title>.+?)($|\?)'
+    _VALID_URL = r'https?://(?:www\.)?slideshare\.net/[^/]+?/(?P<title>.+?)($|\?)'
-    _VALID_URL = r'https?://www\.spiegel\.de/(?!video/)[^?#]*?-(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/(?!video/)[^?#]*?-(?P<id>[0-9]+)\.html'
-    _VALID_URL = r'https?://www\.syfy\.com/(?:[^/]+/)?videos/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?syfy\.com/(?:[^/]+/)?videos/(?P<id>[^/?#]+)'
-    _VALID_URL = r'https?://www\.teachingchannel\.org/videos/(?P<title>.+)'
+    _VALID_URL = r'https?://(?:www\.)?teachingchannel\.org/videos/(?P<title>.+)'
-    _VALID_URL = r'https?://www\.(?:telecinco\.es|cuatro\.com|mediaset\.es)/(?:[^/]+/)+(?P<id>.+?)\.html'
+    _VALID_URL = r'https?://(?:www\.)?(?:telecinco\.es|cuatro\.com|mediaset\.es)/(?:[^/]+/)+(?P<id>.+?)\.html'
-    _VALID_URL = r'https?://www\.telewebion\.com/#!/episode/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?telewebion\.com/#!/episode/(?P<id>\d+)'
-    _VALID_URL = r'https://theintercept.com/fieldofvision/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://theintercept\.com/fieldofvision/(?P<id>[^/?#]+)'
-    _VALID_URL = r'https://thescene\.com/watch/[^/]+/(?P<id>[^/#?]+)'
+    _VALID_URL = r'https?://thescene\.com/watch/[^/]+/(?P<id>[^/#?]+)'
-    _VALID_URL = r'https?://www\.tlc\.de/(?:[^/]+/)*videos/(?P<title>[^/?#]+)?(?:.*#(?P<id>\d+))?'
+    _VALID_URL = r'https?://(?:www\.)?tlc\.de/(?:[^/]+/)*videos/(?P<title>[^/?#]+)?(?:.*#(?P<id>\d+))?'
-    _VALID_URL = r'https?://www\.udemy\.com/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?udemy\.com/(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://www\.ustream\.tv/(?P<type>recorded|embed|embed/recorded)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?ustream\.tv/(?P<type>recorded|embed|embed/recorded)/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.ustream\.tv/channel/(?P<slug>.+)'
+    _VALID_URL = r'https?://(?:www\.)?ustream\.tv/channel/(?P<slug>.+)'
-        (?:https?://www\.vevo\.com/watch/(?!playlist|genre)(?:[^/]+/(?:[^/]+/)?)?|
+        (?:https?://(?:www\.)?vevo\.com/watch/(?!playlist|genre)(?:[^/]+/(?:[^/]+/)?)?|
-    _VALID_URL = r'https?://www\.vevo\.com/watch/(?P<kind>playlist|genre)/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?vevo\.com/watch/(?P<kind>playlist|genre)/(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://www\.videodetective\.com/[^/]+/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?videodetective\.com/[^/]+/[^/]+/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.weiqitv\.com/index/video_play\?videoId=(?P<id>[A-Za-z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?weiqitv\.com/index/video_play\?videoId=(?P<id>[A-Za-z0-9]+)'
-    _VALID_URL = r'https?://mymedia.yam.com/m/(?P<id>\d+)'
+    _VALID_URL = r'https?://mymedia\.yam\.com/m/(?P<id>\d+)'
-    _VALID_URL = r'https?://www\.youtube\.com/show/(?P<id>[^?#]*)'
+    _VALID_URL = r'https?://(?:www\.)?youtube\.com/show/(?P<id>[^?#]*)'
-    _VALID_URL = r'https?://www\.youtube\.com/(?:feed/watch_later|(?:playlist|watch)\?(?:.+&)?list=WL)|:ytwatchlater'
+    _VALID_URL = r'https?://(?:www\.)?youtube\.com/(?:feed/watch_later|(?:playlist|watch)\?(?:.+&)?list=WL)|:ytwatchlater'
-    _VALID_URL = r'https?://www\.youtube\.com/my_favorites|:ytfav(?:ou?rites)?'
+    _VALID_URL = r'https?://(?:www\.)?youtube\.com/my_favorites|:ytfav(?:ou?rites)?'
-    _VALID_URL = r'https?://www\.youtube\.com/feed/recommended|:ytrec(?:ommended)?'
+    _VALID_URL = r'https?://(?:www\.)?youtube\.com/feed/recommended|:ytrec(?:ommended)?'
-    _VALID_URL = r'https?://www\.youtube\.com/feed/subscriptions|:ytsubs(?:criptions)?'
+    _VALID_URL = r'https?://(?:www\.)?youtube\.com/feed/subscriptions|:ytsubs(?:criptions)?'
-    _VALID_URL = r'https?://www\.youtube\.com/feed/history|:ythistory'
+    _VALID_URL = r'https?://(?:www\.)?youtube\.com/feed/history|:ythistory'
-        'url': 'www.viafree.se/program/reality/sommaren-med-youtube-stjarnorna/sasong-1/avsnitt-2',
+        'url': 'http://www.viafree.se/program/reality/sommaren-med-youtube-stjarnorna/sasong-1/avsnitt-2',
-        while count < retries:
+        while count < 2:
-            for backup_url in durl['backup_url']:
+            for backup_url in durl.get('backup_url', []):
-    _TESTS = [{
+    _TEST = {
-    }]
+    }
-    ap_mso_id          Adobe Pass Multiple-system operator Identifier.
+    ap_mso_id:         Adobe Pass Multiple-system operator Identifier.
-                        'Content-Type': 'application/x-www-form-urlencoded',
+        retries = self._downloader.params.get('ap_retries', 3)
-                    'redirect_url': url,
+                provider_login_page_res = post_form(
-                    'resource_id': resource,
+                if mso_id == 'DTV':
-                    'userMeta': '1',
+                    'session_guid': xml_text(authn_token, 'simpleTokenAuthenticationGuid'),
-            if '<pendingLogout' in authorize:
+            if '<pendingLogout' in short_authorize:
-        return short_authorize
+                count += 1
-    def _get_login_info(self):
+    def _get_login_info(self, username_option='username', password_option='password', netrc_machine=None):
-            password = downloader_params['password']
+        if downloader_params.get(username_option) is not None:
-            username, password = self._get_netrc_login_info()
+            username, password = self._get_netrc_login_info(netrc_machine)
-        PRIVATE_OPTS = ['-p', '--password', '-u', '--username', '--video-password']
+        PRIVATE_OPTS = ['-p', '--password', '-u', '--username', '--video-password', '--ap-password', '--ap-username']
-    authentication.add_option(
+
-        help='Adobe Pass Multiple-system operator Identifier(DTV, Rogers)')
+        help='Adobe Pass Multiple-system operator Identifier')
-            raise ExtractorError('This video is only available for users of participating TV providers. '
+            raise ExtractorError(
-    _VALID_URL = r'https?://www3\.nhk\.or\.jp/nhkworld/en/vod/(?P<id>.+?)\.html'
+    _VALID_URL = r'https?://www3\.nhk\.or\.jp/nhkworld/en/vod/(?P<id>[^/]+/[^/?#&]+)'
-        'url': 'http://www3.nhk.or.jp/nhkworld/en/vod/tokyofashion/20160815.html',
+        'url': 'http://www3.nhk.or.jp/nhkworld/en/vod/tokyofashion/20160815',
-            webpage, 'series', default=None)
+        data = self._download_json(self._API_URL, video_id)
-            mso_id = 'DTV'
+            mso_id = self._downloader.params.get('ap_mso_id')
-                return ''
+                return raise_mvpd_required()
-            def post_form(form_page, note, data={}):
+            def post_form(form_page_res, note, data={}):
-                    post_url, video_id, note, data=urlencode_postdata(data or self._hidden_inputs(form_page)), headers={
+                if not re.match(r'https?://', post_url):
-            provider_redirect_page = self._download_webpage(
+            provider_redirect_page_res = self._download_webpage_handle(
-            post_form(mvpd_confirm_page, 'Confirming Login')
+            provider_login_page_res = post_form(
-            r'data-reference-id=(["\'])(?P<id>.+?)\1',
+            r'data-reference-id=(["\'])(?P<id>(?:(?!\1).)+)\1',
-            r'data-partner-id=(["\'])(?P<id>.+?)\1',
+            r'data-partner-id=(["\'])(?P<id>(?:(?!\1).)+)\1',
-            r'data-ui-id=(["\'])(?P<id>.+?)\1',
+            r'data-ui-id=(["\'])(?P<id>(?:(?!\1).)+)\1',
-                'vcodec': f.get('videoCodecId'),
+                'vcodec': vcodec,
-            return surl
+            return VimeoIE._smuggle_referrer(player_url, url)
-        return self.url_result(self._og_search_video_url(webpage), VimeoIE.ie_key())
+        return self.url_result(
-__version__ = '2016.09.11'
+__version__ = '2016.09.11.1'
-__version__ = '2016.09.08'
+__version__ = '2016.09.11'
-    js_to_json,
+import re
-    FoxNewsVideoIE,
+    FoxNewsArticleIE,
-    IE_NAME = 'foxnews:video'
+class FoxNewsIE(AMPIE):
-class FoxNewsIE(InfoExtractor):
+class FoxNewsArticleIE(InfoExtractor):
-    IE_NAME = 'foxnews'
+    IE_NAME = 'foxnews:article'
-            FoxNewsVideoIE.ie_key())
+            FoxNewsIE.ie_key())
-        'add_ie': [FoxNewsVideoIE.ie_key()],
+        'add_ie': [FoxNewsIE.ie_key()],
-            'ie_key': FoxNewsVideoIE.ie_key(),
+            'ie_key': FoxNewsIE.ie_key(),
-                j += 1
+                j += 3
-class FoxNewsIE(AMPIE):
+class FoxNewsVideoIE(AMPIE):
-        'add_ie': [FoxNewsIE.ie_key()],
+        'params': {
-            'ie_key': FoxNewsIE.ie_key(),
+            'ie_key': FoxNewsVideoIE.ie_key(),
-                thumbnail, 'video id', default=None)
+        if data:
-from .trollvids import TrollvidsIE
+# coding: utf-8
-        return info
+from .tfo import TFOIE
-    _TEST = {
+    _TESTS = [{
-            'skip_download': True,  # m3u8 download
+    }, {
-    }
+    }]
-        formats = self._extract_m3u8_formats(m3u8_url, video_id, 'mp4')
+
-        )
+
-        common_data = page_data.get('episode', {}).get('episode') or page_data.get('clip', {}).get('clip')
+        current_key = (
-from .polskieradio import PolskieRadioIE, PolskieRadioProgrammeIE
+from .polskieradio import (
-
+
-        'url': 'http://www.newgrounds.com/audio/listen/549479',
+        'url': 'https://www.newgrounds.com/audio/listen/549479',
-        'url': 'http://www.newgrounds.com/portal/view/673111',
+        'url': 'https://www.newgrounds.com/portal/view/673111',
-        webpage = self._download_webpage(url, music_id)
+        media_id = self._match_id(url)
-            webpage, 'uploader')
+            r'Author\s*<a[^>]+>([^<]+)', webpage, 'uploader', fatal=False)
-        music_url = music_url_json['url']
+        music_url = self._parse_json(self._search_regex(
-            'id': music_id,
+            'id': media_id,
-    _VALID_URL = r'https?://(?:www\.)?canvas\.be/video/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<site_id>canvas|een)\.be/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-        display_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        title = self._search_regex(
+        title = (self._search_regex(
-            webpage, 'title', default=None) or self._og_search_title(webpage)
+            webpage, 'title', default=None) or self._og_search_title(
-            'https://mediazone.vrt.be/api/v1/canvas/assets/%s' % video_id, display_id)
+            'https://mediazone.vrt.be/api/v1/%s/assets/%s'
-    _VALID_URL = r'https?://www\.parliamentlive\.tv/Main/Player\.aspx\?(?:[^&]+&)*?meetingId=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?parliamentlive\.tv/Event/Index/(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})'
-        'url': 'http://www.parliamentlive.tv/Main/Player.aspx?meetingId=15121&player=windowsmedia',
+        'url': 'http://parliamentlive.tv/Event/Index/c1e9d44d-fd6c-4263-b50f-97ed26cc998b',
-            'description': 'md5:033b3acdf83304cd43946b2d5e5798d1',
+            'id': 'c1e9d44d-fd6c-4263-b50f-97ed26cc998b',
-
+        video_id = self._match_id(url)
-            'description': description,
+            'title': event_title,
-__version__ = '2016.09.04.1'
+__version__ = '2016.09.08'
-                        'height': int_or_none(source.get('height')),
+                        'height': height,
-    _VALID_URL = r'https?://(www\.)?tvnoe\.cz/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?tvnoe\.cz/video/(?P<id>[0-9]+)'
-from .brightcove import BrightcoveNewIE
+from .brightcove import (
-            thumbnail, 'video id', default=None)
+                thumbnail, 'video id', default=None)
-    parse_iso8601,
+    xpath_element,
-        'md5': '70875fbf57a1cd004709920381587185',
+        'md5': '44455a346edc0d509ac5b5a5b531dc35',
-            'description': 'Ð Ð³Ð¾ÑÑÑÑ â Ð»ÑÑÑÐ¸Ðµ ÑÐ¾Ð¼Ð°Ð½ÑÐ¸ÑÐµÑÐºÐ¸Ðµ ÐºÐ¾Ð¼ÐµÐ´Ð¸Ð¸ Ð³Ð¾Ð´Ð°, Â«ÐÑÐ¶Ð¸Ð²ÑÐ¸Ð¹Â» ÐÐ½ÑÑÑÑÐ¸ÑÑ Ð¸ Â«Ð¡ÑÐ¸Ð² ÐÐ¶Ð¾Ð±ÑÂ» ÐÑÐ½Ð½Ð¸ ÐÐ¾Ð¹Ð»Ð°.',
+            'title': 'ÐÐ¸Ð½Ð¾ Ð² Ð´ÐµÑÐ°Ð»ÑÑ 5 ÑÐµÐ·Ð¾Ð½ Ð Ð³Ð¾ÑÑÑÑ ÐÐ»ÐµÐºÑÐµÐ¹ Ð§ÑÐ¼Ð°ÐºÐ¾Ð² Ð¸ Ð®Ð»Ð¸Ñ ÐÐ¾Ð²Ð°Ð»ÑÑÑÐº',
-            'age_limit': 16,
+            'comment_count': int,
-            'description': 'Â«ÐÐµÐ´Ð²ÐµÐ´ÐµÐ¹Â» Ð¶Ð´ÐµÑ ÑÐµÑÐ°ÑÑÐ¸Ð¹ Ð¼Ð°ÑÑ. ÐÐ°ÐºÐµÐµÐ² Ð²ÑÑÑÐ½ÑÐµÑ Ð¾ÑÐ½Ð¾ÑÐµÐ½Ð¸Ñ ÑÐ¾ Ð¡ÑÑÐµÐ»ÑÑÐ¾Ð²ÑÐ¼. ÐÐ°ÑÐ½Ð¸ ÑÐ·Ð½Ð°ÑÑ Ð¿Ð¾Ð´ÑÐ¾Ð±Ð½Ð¾ÑÑÐ¸ Ð¿ÑÐ¾ÑÐ»Ð¾Ð³Ð¾ ÐÐ°ÐºÐµÐµÐ²Ð°.',
+            'title': 'ÐÐ¾Ð»Ð¾Ð´ÐµÐ¶ÐºÐ° 2 ÑÐµÐ·Ð¾Ð½ 40 ÑÐµÑÐ¸Ñ',
-            'season_number': 2,
+            'episode': '40 ÑÐµÑÐ¸Ñ',
-            'age_limit': 16,
+            'comment_count': int,
-            'series': 'ÐÐ¾Ð»Ð¾Ð´ÐµÐ¶ÐºÐ°',
+            'title': 'ÐÑÐ¾Ð¼Ð¾ ÐÐ¾Ð¼Ð°Ð½Ð´Ð° Ð¿ÑÐ¾Ð¸Ð³ÑÐ°Ð»Ð° Ð¸Ð·-Ð·Ð° ÐÐ°ÐºÐ¸Ð½Ð°?',
-        video_url = xpath_text(video, './/video_url', 'video url', fatal=True)
+        item = xpath_element(video, './/playlist/item', fatal=True)
-        season_number = int_or_none(data.get('season_pos') or None)
+        thumbnail = xpath_text(item, './thumbnail_url')
-            'timestamp': timestamp,
+            'thumbnail': thumbnail,
-    _VALID_URL = 'https?://abcnews\.go\.com/(?:[^/]+/)+(?P<display_id>[0-9a-z-]+)/story\?id=(?P<id>\d+)'
+    _VALID_URL = r'https?://abcnews\.go\.com/(?:[^/]+/)+(?P<display_id>[0-9a-z-]+)/story\?id=(?P<id>\d+)'
-    _VALID_URL = '(?P<mainurl>https?://(www\.)?daserste\.de/[^?#]+/videos/(?P<display_id>[^/?#]+)-(?P<id>[0-9]+))\.html'
+    _VALID_URL = r'(?P<mainurl>https?://(www\.)?daserste\.de/[^?#]+/videos/(?P<display_id>[^/?#]+)-(?P<id>[0-9]+))\.html'
-    _VALID_URL = '(?:globo:|https?://.+?\.globo\.com/(?:[^/]+/)*(?:v/(?:[^/]+/)?|videos/))(?P<id>\d{7,})'
+    _VALID_URL = r'(?:globo:|https?://.+?\.globo\.com/(?:[^/]+/)*(?:v/(?:[^/]+/)?|videos/))(?P<id>\d{7,})'
-    _VALID_URL = 'https?://.+?\.globo\.com/(?:[^/]+/)*(?P<id>[^/]+)(?:\.html)?'
+    _VALID_URL = r'https?://.+?\.globo\.com/(?:[^/]+/)*(?P<id>[^/]+)(?:\.html)?'
-    _VALID_URL = 'https?://(?:www\.)?onet\.tv/[a-z]/[a-z]+/(?P<display_id>[0-9a-z-]+)/(?P<id>[0-9a-z]+)'
+    _VALID_URL = r'https?://(?:www\.)?onet\.tv/[a-z]/[a-z]+/(?P<display_id>[0-9a-z-]+)/(?P<id>[0-9a-z]+)'
-    _VALID_URL = 'https?://rutube\.ru/(?:video|play)/embed/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://rutube\.ru/(?:video|play)/embed/(?P<id>[0-9]+)'
-    _VALID_URL = 'https?://www\.spiegel\.de/(?!video/)[^?#]*?-(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'https?://www\.spiegel\.de/(?!video/)[^?#]*?-(?P<id>[0-9]+)\.html'
-    _VALID_URL = 'https?://amp\.twimg\.com/v/(?P<id>[0-9a-f\-]{36})'
+    _VALID_URL = r'https?://amp\.twimg\.com/v/(?P<id>[0-9a-f\-]{36})'
-    _VALID_URL = 'https?://www\.youtube\.com/feed/history|:ythistory'
+    _VALID_URL = r'https?://www\.youtube\.com/feed/history|:ythistory'
-    _VALID_URL = 'https?://abcnews.go.com/[^/]+/video/(?P<display_id>[0-9a-z-]+)-(?P<id>\d+)'
+    _VALID_URL = r'https?://abcnews\.go\.com/[^/]+/video/(?P<display_id>[0-9a-z-]+)-(?P<id>\d+)'
-    _VALID_URL = r'https?://www.karaoketv.co.il/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://www\.karaoketv\.co\.il/[^/]+/(?P<id>\d+)'
-    _VALID_URL = 'http://abcnews.go.com/[^/]+/video/(?P<display_id>[0-9a-z-]+)-(?P<id>\d+)'
+    _VALID_URL = 'https?://abcnews.go.com/[^/]+/video/(?P<display_id>[0-9a-z-]+)-(?P<id>\d+)'
-    _VALID_URL_PREFIX = r'http://api\.dmcloud\.net/(?:player/)?embed/'
+    _VALID_URL_PREFIX = r'https?://api\.dmcloud\.net/(?:player/)?embed/'
-    _VALID_URL = r'http://www.karaoketv.co.il/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://www.karaoketv.co.il/[^/]+/(?P<id>\d+)'
-        'md5': '80d72beab5d04e1655a56ad37afe6841',
+        'md5': '344558ccfea74d33b7adbce22e577f54',
-            'description': 'md5:5e51dc4405f1fd315f7927daed2ce5cf',
+            'title': 'Fuck Turkish-style',
-            webpage, 'description', fatal=False)
+        title = remove_end(self._html_search_regex(
-            r"t_path = '(?P<thumb>http://.*?)'", iframe, 'thumbnail', fatal=False)
+            iframe_url, video_id, headers={'User-Agent': 'curl/7.50.1'},
-            'url': video_url,
+            'formats': formats,
-            'thumbnail': thumb_url,
+            'thumbnail': video_data.get('act_vid', {}).get('thumb'),
-from ..compat import compat_parse_qs
+from ..compat import (
-            brightcove_id = compat_parse_qs(brightcove_legacy_url)['@videoPlayer'][0]
+            brightcove_id = compat_parse_qs(compat_urlparse.urlparse(brightcove_legacy_url).query)['@videoPlayer'][0]
-    _VALID_URL = r'https?://(?:www\.)?miaopai\.com/show/(?P<id>[-A-Za-z0-9~_]+).htm'
+    _VALID_URL = r'https?://(?:www\.)?miaopai\.com/show/(?P<id>[-A-Za-z0-9~_]+)'
-                       'Version/9.0 Mobile/13B143 Safari/601.1'
+    _USER_AGENT_IPAD = 'Mozilla/5.0 (iPad; CPU OS 9_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13B143 Safari/601.1'
-        webpage = self._download_webpage(request, video_id)
+        webpage = self._download_webpage(
-        thumbnail = self._html_search_regex(regex, webpage, '')
+        title = self._html_search_regex(
-                     })
+        info.update({
-    unified_strdate,
+    remove_end,
-            'thumbnail': 'http://images.gamestar.de/images/idgwpgsgp/bdb/2494525/600x.jpg',
+            'description': 'Der Teaser-Trailer zu Hobbit 3: Die Schlacht der FÃ¼nf Heere zeigt einige Szenen aus dem dritten Teil der Saga und kÃ¼ndigt den...',
-            'view_count', fatal=False))
+        # TODO: there are multiple ld+json objects in the webpage,
-            r'>Kommentieren \(([0-9]+)\)</a>', webpage, 'comment_count',
+            r'([0-9]+) Kommentare</span>', webpage, 'comment_count',
-        return {
+        info_dict.update({
-        }
+        })
-            }
+            },
-class ProSiebenSat1IE(InfoExtractor):
+class ProSiebenSat1BaseIE(InfoExtractor):
-
+        info = self._extract_video_info(url, clip_id)
-        return {
+        info.update({
-        }
+        })
-from .common import InfoExtractor
+from .prosiebensat1 import ProSiebenSat1BaseIE
-    int_or_none,
+    parse_duration,
-    _VALID_URL = r'https?://(?:www\.)?puls4\.com/video/[^/]+/play/(?P<id>[0-9]+)'
+class Puls4IE(ProSiebenSat1BaseIE):
-        'md5': '49f6a6629747eeec43cef6a46b5df81d',
+        'url': 'http://www.puls4.com/2-minuten-2-millionen/staffel-3/videos/2min2miotalk/Tobias-Homberger-von-myclubs-im-2min2miotalk-118118',
-            'upload_date': '20150224',
+            'id': '118118',
-        'skip': 'Only works from Germany',
+    _TOKEN = 'puls4'
-        return result
+        path = self._match_id(url)
-            return red_url
+            head = self._request_webpage(HEADRequest(req_url), video_id, 'Extracting %s url' % url_type, fatal=False)
-                    formats.append(f)
+            manifest_urls = self._download_json(
-from .polskieradio import PolskieRadioIE
+from .polskieradio import PolskieRadioIE, PolskieRadioProgrammeIE
-            webpage, 'video id')
+        video_id = None
-                    'media_src': 'http://apple-secure.cdn.turner.com/toon/big',
+                    'media_src': 'http://androidhls-secure.cdn.turner.com/toon/big',
-                    'media_src': 'http://apple-secure.cdn.turner.com/%s/big' % site,
+                    'media_src': 'http://androidhls-secure.cdn.turner.com/%s/big' % site,
-    compat_urlparse,
+    ExtractorError,
-                #         'videoId': video_id,
+                #         'videoId': content_id,
-                            'videoId': video_id,
+                            'videoId': content_id,
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-        video_url = self._html_search_regex(regex, webpage, '')
+        videos = self._parse_html5_media_entries(url, webpage, video_id)
-                }
+        info.update({'id': video_id,
-    _VALID_URL = r'https?://(?:www\.)?nick\.de/(?:playlist|shows)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:nick\.de|nickelodeon\.nl)/(?:playlist|shows)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-from ..utils import parse_iso8601
+from ..utils import (
-    _VALID_URL = r'https?://abc7news\.com(?:/[^/]+/(?P<display_id>[^/]+))?/(?P<id>\d+)'
+class ABCOTVSIE(InfoExtractor):
-                'title': 'East Bay museum celebrates history of synthesized music',
+                'title': 'East Bay museum celebrates vintage synthesizers',
-            'contentURL', webpage, 'm3u8 url', fatal=True)
+            'contentURL', webpage, 'm3u8 url', fatal=True).split('?')[0]
-from .abc7news import Abc7NewsIE
+from .abcotvs import (
-    _VALID_URL = r'https?://(www.|bangumi.|)bilibili\.(?:tv|com)/(video/av|anime/v/)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.|bangumi\.|)bilibili\.(?:tv|com)/(?:video/av|anime/v/)(?P<id>\d+)'
-            'description': "æäºåçå¨æ¥æ¬çæ±æ·æ¶ä»£ãé£æ¯ä¸ä¸ªå°éé¦çæå·¥å¥³ãä¸æ¥ï¼éé¦éæ¥äºä¸ç¾¤æ¶é¸ï¼è½ç¶ä»ä»¬çä¸¾å¨ä»¤é£ååä¸æ»¡ï¼ä½æ¯æ¯ç«é£åªæ¯ä¸å±å¥³æµï¼æ æ³å¯¹ä»ä»¬éåä»ä¹è¡å¨ï¼åªè½å¨å¿éååãè¿æ¶ï¼éå®¶éåè¿æ¥äºä¸ªâä¸è¯ä»½å­âæ å¹»ï¼è¯´ä»¥50ä¸ªä¸¸å­å¸®å¥¹æå®è¿ç¾¤äººï¼é£è§å¾ä»è«åå¶å¦ï¼ä¹å°±æ²¡å¤æ­çä»ãèå¨è¿æ¶ï¼é£å ä¸ºä¸ä¸ªæå¤èå°è¶æ°´æ³¼å¨äºæ¶é¸å¤´é¢ââé¾æ¬¡éèº«ä¸ãæ¤æçæ¶é¸ä»¬æ¬²å°é£çææç æï¼é£å¨æ å¥ä¸­å¤§åéï¼âä¸¸å­100ä¸ªï¼ââ¦â¦ ããå¦ä¸æ¹é¢ï¼é¾æ¬¡éçç¶äº²ä¹å°±æ¯å½å°çä»£å®ï¼ä¾ä»èªå·±æçéåçä¿éå®åï¼å¨å½å°æ¬ºåç©·äººï¼å½çå°ä¸ç©·äººæ æ³äº¤é½è¶³å¤çé±è¿æ¡¥æ¶ï¼æ¬²ä¸ä»¤å°å¶ææ­»ï¼æ­¦å£«ä»çä¸æ¯è¿ä¸å¹ï¼äºæ¯èµ°ä¸åï¼ä¸ä»£å®çä¿éäº¤æäºâ¦â¦ ããéé¦åï¼å ä¸ºé£ç­åºç»æ å¹»100ä¸ªå¢å­ï¼æ å¹»å°æ¶é¸ä»¬æè´¥äºï¼å°±å¨è¿æ¶ï¼ä»è¿æ¥äºãå¥½æçæ å¹»ç«å»åä»åäºæä¹¦ï¼æåä¸¤è´¥ä¿±ä¼¤ï¼è¢«ä»£å®æå¥ç¢æ¿ï¼é¢è®¡ç¬¬äºå¤©æ©é¦â¦â¦ ããå¾ç¥è¯¥ç¶åµçé£ï¼ä¸ºæ¥æå½ä¹æ©ï¼æ¥å°äºååºï¼å©ç¨çè±æåºäºæ å¹»åä»ãèé£åä»¥æå½æ©äººçèº«ä»½ï¼å½ä»¤äºäººåå¥¹ä¸èµ·å»å¯»æ¾å¸¦çåæ¥èµé¦å³çæ­¦å£«â¦â¦(byç¾ç§)",
+            'description': 'md5:6a9622b911565794c11f25f81d6a97d2',
-        if not _is_episode:
+        if 'anime/v' not in url:
-                r'<iframe[^>]+src="https://secure\.bilibili\.com/secure,([^"]+)"'],
+                 r'<iframe[^>]+src="https://secure\.bilibili\.com/secure,([^"]+)"'],
-                                     headers=HEADERS)
+            js = self._download_json(
-            thumbnail = self._html_search_meta('thumbnailUrl', webpage)
+        thumbnail = self._html_search_meta(['og:image', 'thumbnailUrl'], webpage)
-from ..utils import clean_html, get_element_by_class, js_to_json
+from ..utils import (
-                     'NÃ¡vrat nÃ¡boÅ¾enstvÃ­ a stÅet civilizacÃ­',
+            'title': 'prof. TomÃ¡Å¡ HalÃ­k, Th.D. - NÃ¡vrat nÃ¡boÅ¾enstvÃ­ a stÅet civilizacÃ­',
-                                        webpage, 'iframe src attribute')
+        iframe_url = self._search_regex(
-                                         video_id, transform_source=js_to_json)
+        jwplayer_data = self._parse_json(
-                                                           webpage)),
+            'title': clean_html(get_element_by_class(
-__version__ = '2016.09.04'
+__version__ = '2016.09.04.1'
-__version__ = '2016.09.03'
+__version__ = '2016.09.04'
-           (?:(?:(?:[^/]+/)+select/)?(?P<media>media/(?:guid/\d+/)?)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
+           (?:(?:(?:[^/]+/)+select/)?(?P<media>media/(?:guid/\d+/)?)?|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
-                     (?!.*?&list=)                                            # combined list/video URLs are handled by the playlist IE
+                     (?!.*?\blist=)                                            # combined list/video URLs are handled by the playlist IE
-                        |  p/
+                            youtube\.com/
-from ..utils import js_to_json
+from .internetvideoarchive import InternetVideoArchiveIE
-        self._sort_formats(formats)
+        iva_id = self._search_regex(r'publishedid=(\d+)', webpage, 'internet video archive id')
-
+        formats = [self._m3u8_meta_format(m3u8_url, ext, preference, m3u8_id)]
-                        file_url, video_id, ext='mp4', m3u8_id='hls'))
+                    m3u8_formats = self._extract_m3u8_formats(
-        def append_url_to_file(target_url, tmp_filename, segment_name):
+        def process_segment(segment, tmp_filename, fatal):
-                if skip_unavailable_fragments:
+                if not fatal:
-            if not append_url_to_file(segment_url, ctx['tmpfilename'], 'Seg%d' % i):
+        segments_to_download = [(initialization_url, 'Init')] if initialization_url else []
-    _SERVER_NUMBERS = (1, 2)
+    _VALID_URL = r'https?://(?:www\.)?pornovoisines\.com/videos/show/(?P<id>\d+)/(?P<display_id>[^/.]+)'
-        'md5': '5ac670803bc12e9e7f9f662ce64cf1d1',
+        'url': 'http://www.pornovoisines.com/videos/show/919/recherche-appartement.html',
-            'id': '1285',
+            'id': '919',
-            'description': 'md5:819ea0b785e2a04667a1a01cdc89594e',
+            'description': 'md5:fe10cb92ae2dd3ed94bb4080d11ff493',
-            'categories': ['DÃ©butantes', 'ScÃ©nario', 'Sodomie'],
+            'categories': ['DÃ©butante', 'DÃ©butantes', 'ScÃ©nario', 'Sodomie'],
-        webpage = self._download_webpage(url, video_id)
+        settings_url = self._download_json(
-        video_url = self.build_video_url(video_id)
+        webpage = self._download_webpage(url, video_id)
-            webpage, 'description', fatal=False, flags=re.DOTALL)
+        title = self._og_search_title(webpage)
-            thumbnail = 'http://www.pornovoisines.com/%s' % thumbnail
+        # The webpage has a bug - there's no space between "thumb" and src=
-            'DurÃ©e (\d+)', webpage, 'duration', fatal=False))
+            r'Le\s*<b>([\d/]+)', webpage, 'upload date', fatal=False))
-            'keywords', webpage, 'categories', fatal=False)
+        categories = self._html_search_regex(
-            'url': video_url,
+            'formats': formats,
-from .internetvideoarchive import InternetVideoArchiveIE
+from ..utils import js_to_json
-            'id': '613340',
+            'id': '11028566',
-        query = compat_urlparse.urlparse(og_video).query
+
-            'ie_key': InternetVideoArchiveIE.ie_key(),
+            'id': video_id,
-    _VALID_URL = r'https?://espn\.go\.com/(?:[^/]+/)*(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:espn\.go|(?:www\.)?espn)\.com/(?:[^/]+/)*(?P<id>[^/]+)'
-    ]
+    _VALID_URL = r'https?://(?:player\.vimple\.(?:ru|co)/iframe|vimple\.(?:ru|co))/(?P<id>[\da-f-]{32,36})'
-        video = self._check_download_just_video(url, 'WL')
+        _, video = self._check_download_just_video(url, 'WL')
-                    return
+                    return True
-            append_url_to_file(initialization_url, ctx['tmpfilename'], 'Init')
+            if not append_url_to_file(initialization_url, ctx['tmpfilename'], 'Init'):
-            append_url_to_file(segment_url, ctx['tmpfilename'], 'Seg%d' % i)
+            if not append_url_to_file(segment_url, ctx['tmpfilename'], 'Seg%d' % i):
-                except compat_urllib_error.HTTPError:
+                except compat_urllib_error.HTTPError as err:
-                        self.report_retry_fragment(segment_name, count, fragment_retries)
+                        self.report_retry_fragment(err, segment_name, count, fragment_retries)
-    def report_retry_fragment(self, fragment_name, count, retries):
+    def report_retry_fragment(self, err, fragment_name, count, retries):
-            % (fragment_name, count, self.format_retries(retries)))
+            % (error_to_compat_str(err), fragment_name, count, self.format_retries(retries)))
-                        except compat_urllib_error.HTTPError:
+                        except compat_urllib_error.HTTPError as err:
-                                self.report_retry_fragment(frag_name, count, fragment_retries)
+                                self.report_retry_fragment(err, frag_name, count, fragment_retries)
-                except (compat_urllib_error.HTTPError, ) as err:
+                except compat_urllib_error.HTTPError:
-                    # Retry fragment
+                    # To be future-proof we will retry all fragments that fail with any
-                    frag_filename = '%s-Frag%d' % (ctx['tmpfilename'], i)
+                    frag_name = 'Frag%d' % i
-                    if not success:
+                    count = 0
-                    if self.params.get('test', False):
+                    if test:
-    fragment_retries:   Number of times to retry a fragment for HTTP error (DASH only)
+    fragment_retries:   Number of times to retry a fragment for HTTP error (DASH
-            '[download] Got server HTTP error. Retrying fragment %s (attempt %d of %s)...'
+            '[download] Got server HTTP error: %s. Retrying fragment %s (attempt %d of %s)...'
-        help='Number of retries for a fragment (default is %default), or "infinite" (DASH only)')
+        help='Number of retries for a fragment (default is %default), or "infinite" (DASH and hlsnative only)')
-        'md5': '07e15fa469ba384c7693fd246905547c',
+        'md5': '78fc1901148284c69af12640e01c6310',
-            'ext': 'flv',
+            'ext': 'mp4',
-                                           webpage, 'video URL')
+        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]
-        return {
+        info_dict.update({
-        }
+        })
-from .foxnews import FoxNewsIE
+from .foxnews import (
-    _VALID_URL = r'https?://(?P<host>video\.fox(?:news|business)\.com)/v/(?:video-embed\.html\?video_id=)?(?P<id>\d+)'
+    _VALID_URL = r'https?://(?P<host>video\.(?:insider\.)?fox(?:news|business)\.com)/v/(?:video-embed\.html\?video_id=)?(?P<id>\d+)'
-from .fc2 import FC2IE
+from .fc2 import (
-#! -*- coding: utf-8 -*-
+# coding: utf-8
-    _VALID_URL = r'^https?://video\.fc2\.com/(?:[^/]+/)*content/(?P<id>[^/]+)'
+    _VALID_URL = r'^(?:https?://video\.fc2\.com/(?:[^/]+/)*content/|fc2:)(?P<id>[^/]+)'
-        thumbnail = self._og_search_thumbnail(webpage)
+        webpage = None
-                _, formats = _media_formats(src)
+                _, formats = _media_formats(src, media_type)
-__version__ = '2016.08.31'
+__version__ = '2016.09.03'
-        'md5': 'dc515a9ab50577fa14cc4e4b0265168f',
+        'url': 'https://www.dr.dk/tv/se/boern/ultra/klassen-ultra/klassen-darlig-taber-10',
-            'id': 'panisk-paske-5',
+            'id': 'klassen-darlig-taber-10',
-            'duration': 1455,
+            'title': 'Klassen - DÃ¥rlig taber (10)',
-        'md5': '2ada5074f9e79afc0d324a8e9784d850',
+        'md5': '2c37175c718155930f939ef59952474a',
-        }
+        },
-            page, 'title')
+            page, 'title', default=None)
-        return self.playlist_result(self._entries(page, playlist_id), playlist_id, playlist_title)
+        has_videos = True
-                return self.url_result(video_id, 'Youtube', video_id=video_id)
+                return video_id, self.url_result(video_id, 'Youtube', video_id=video_id)
-        video = self._check_download_just_video(url, playlist_id)
+        video_id, video = self._check_download_just_video(url, playlist_id)
-        return self._extract_playlist(playlist_id)
+        has_videos, playlist = self._extract_playlist(playlist_id)
-        return self._extract_playlist('WL')
+        _, playlist = self._extract_playlist('WL')
-        description = self._og_search_description(webpage) or data['Description']
+        title = remove_end(self._og_search_title(
-        timestamp = parse_iso8601(data['CreatedTime'])
+        timestamp = parse_iso8601(data.get('CreatedTime'))
-                    format_id = target
+            if asset.get('Kind') == 'Image':
-                            m3u8_id=format_id))
+                            uri, video_id, 'mp4', entry_protocol='m3u8_native',
-                            'tbr': bitrate,
+                            'tbr': int_or_none(bitrate),
-                        subtitles[LANGS.get(lang, lang)] = [{'url': subs['Uri'], 'ext': 'vtt'}]
+                        if not subs.get('Uri'):
-                'Unfortunately, DR is not allowed to show this program outside Denmark.', expected=True)
+            self.raise_geo_restricted(
-    res = res.lower()
+    res = res.split(';')[0].strip().lower()
-    _VALID_URL = r'https?://(?:www\.)?dr\.dk/tv/se/(?:[^/]+/)*(?P<id>[\da-z-]+)(?:[/#?]|$)'
+    _VALID_URL = r'https?://(?:www\.)?dr\.dk/(?:tv/se|nyheder)/(?:[^/]+/)*(?P<id>[\da-z-]+)(?:[/#?]|$)'
-    _TEST = {
+    _TESTS = [{
-    }
+        'skip': 'Video is no longer available',
-            r'data-(?:material-identifier|episode-slug)="([^"]+)"',
+            (r'data-(?:material-identifier|episode-slug)="([^"]+)"',
-        description = data['Description']
+        title = remove_end(self._og_search_title(webpage), ' | TV | DR') or data['Title']
-from .facebook import FacebookIE
+from .facebook import (
-                requestor_info = {}
+        if authn_token and is_expired(authn_token, 'simpleTokenExpires'):
-                    })
+        (email, password) = self._get_login_info()
-            video_id, 'Downloading video JSON')
+        # Authorization generation algorithm is reverse engineered from `signer` in
-        ]
+                return None
-                'url': 'http://www.nytimes.com/%s' % image['url'],
+        thumbnails = []
-        ]
+            })
-            'description': description,
+            'description': video_data.get('summary'),
-            'duration': duration,
+            'uploader': video_data.get('byline'),
-        'md5': '18a525a510f942ada2720db5f31644c0',
+        'md5': 'd665342765db043f7e225cff19df0f2d',
-        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)
+        brightcove_id = self._search_regex(
-            'title': 'Damon Timm\'s Glide message',
+            'title': "Damon's Glide message",
-            r'<title>(.+?)</title>', webpage, 'title')
+            r'<title>(.+?)</title>', webpage,
-        # Anonymous User uploader
+        # Unknown uploader
-            'uploader': 'Anonymous User',
+            'uploader': 'Unknown',
-                webpage, '%s tag box' % title, default=None)
+        def extract_tag_box(regex, title):
-        tags = extract_tag_box('Tags')
+        categories = extract_tag_box(
-        last_media = None
+        last_info = {}
-                stream_name = last_info.get('NAME') or last_media_name
+                stream_name = last_info.get('NAME') or last_media.get('NAME')
-                    stream_name = last_info.get('NAME')
+# coding: utf-8
-        return self.playlist_result(entries, playlist_id, list_title)
+from .movingimage import MovingImageIE
-    _VALID_URL = r'https?://ssa\.nls\.uk/film/(?P<id>\d+)'
+class MovingImageIE(InfoExtractor):
-        'url': 'http://ssa.nls.uk/film/3561',
+        'url': 'http://movingimage.nls.uk/film/3561',
-            'ext': 'flv',
+            'ext': 'mp4',
-            r"'file'\s*,\s*'([^']+)'", webpage, 'file').rpartition('.')[0]
+        formats = self._extract_m3u8_formats(
-            r"'image'\s*,\s*'([^']+)'", webpage, 'thumbnails', fatal=False)
+            r"image\s*:\s*'([^']+)'", webpage, 'thumbnail', fatal=False)
-            'ext': 'flv',
+            'formats': formats,
-            'uploader_id': 'utkualp',
+            'uploader': 'utkualp',
-        for r in ('HLS&formats=M3U', 'RTMP', 'WIFI', '3G'):
+        for r in ('OnceURL&formats=M3U', 'HLS&formats=M3U', 'RTMP', 'WIFI', '3G'):
-
+        urls = []
-            if not stream_url or stream.get('drmProtected'):
+            if not stream_url or stream.get('drmProtected') or stream_url in urls:
-                        'url': 'http://%s/%s' % (rtmp.group('host').replace('csl.', 'cpl.'), rtmp.group('playpath')[4:]),
+                        'url': http_url,
-            if not media_url or format_id == 'Widevine':
+            if not media_url or format_id in ('Widevine', 'SmoothStreaming') or media_url in urls:
-            r'class=["\']views["\'][^>]*><p>([\d,.]+)', webpage, 'view count'))
+            r'class=["\']views["\'][^>]*><p>([\d,.]+)', webpage,
-        'md5': '54706e4db4f5ad58fbad82dde1f1213f',
+        'md5': 'b2c28d528273b323abe5c6ab59f0f030',
-    compat_urllib_parse_urlencode,
+    determine_ext,
-            'md5': 'c3466d2b6d5dd6b9f41ba9ed04c24b23',
+            'md5': '251af144a19ebc4a033e8ba91ac726bb',
-            'md5': '75ffabdb87c16d4ffe8c036dc4d1c136',
+            'md5': '7993e572fac98e044588d0b5260f4352',
-            'md5': '9035d38f88b1782682a3e89f985be5bb',
+            'md5': '45c024bad51e63e9b6f6fad7a43a8c23',
-            'md5': '0b51660361f0e27c9789e7037ef76f4b',
+            'md5': '71298482f7c64cbb7fa064e4553ff1c1',
-                'ext': 'mp4',
+                'ext': 'webm',
-                'md5': 'f8e336c6b66f503282e5f719641d6565',
+                'md5': '000887d0dc609bc3a47c974151a40fb8',
-                'md5': '958bcb90b4d6df71c56312137ee1cd5a',
+                'md5': '81bc74faf10750fe36e4542f9a184c66',
-            'md5': 'b17ac378b1134fa44370fb27db09a744',
+            'md5': '2a9752f74cb898af5d1083ea9f661b58',
-            'md5': '1ddbf7c850777548438e5c4f147c7b8c',
+            'md5': '4fbafb9c9b6f07aa8f870629f6671b35',
-                entries.append(self._get_info(video_id, display_id, webpage))
+            entries.append(self.url_result(host + iframe_url, 'Yahoo'))
-                    return self._extract_info(display_id, sapi, webpage)
+                    info = self._extract_info(display_id, sapi, webpage)
-                'tbr': int_or_none(s.get('bitrate')),
+                'tbr': tbr,
-                    format_info['ext'] = 'mp4'
+                    fmt = 'hls'
-        return self._extract_info(display_id, query_result, webpage)
+            webpage, 'region', fatal=False, default='US').upper()
-__version__ = '2016.08.28'
+__version__ = '2016.08.31'
-                            (?!(?:tracks|sets(?:/[^/?#]+)?|reposts|likes|spotlight)/?(?:$|[?#]))
+                            (?!(?:tracks|sets(?:/.+?)?|reposts|likes|spotlight)/?(?:$|[?#]))
-            r'album_title\s*:\s*"(.*?)"', webpage, 'title', fatal=False)
+        title = self._html_search_regex(
-import os
+from ..compat import compat_str
-            'add_ie': ['Youtube'],
+    _VALID_URL = r'https?://(?:www\.)?pyvideo\.org/(?P<category>[^/]+)/(?P<id>[^/?#&.]+)'
-            },
+        'playlist_count': 2,
-    ]
+    }]
-        webpage = self._download_webpage(url, video_id)
+        entries = []
-            return self.url_result(m_youtube.group(1), 'Youtube')
+        data = self._download_json(
-            webpage, 'video url', flags=re.DOTALL)
+        if data:
-        }
+        return self.playlist_result(entries, video_id)
-            'id': 'nadal-1-on-1',
+            'id': 'sports/2013/06/09/nadal-1-on-1.cnn',
-            'id': 'sot-student-gives-epic-speech',
+            'id': 'us/2013/08/21/sot-student-gives-epic-speech.georgia-institute-of-technology',
-            'id': 'growing-america-nashville-salemtown-board-episode-1',
+            'id': 'living/2014/12/22/growing-america-nashville-salemtown-board-episode-1.hln',
-            'id': 'netflix-stunning-stats',
+            'id': '/video/news/2016/08/19/netflix-stunning-stats.cnnmoney',
-            'id': 'criminalizing-journalism',
+            'id': 'bestoftv/2014/02/09/criminalizing-journalism.cnn',
-            'id': 'ip-north-korea-obama',
+            'id': 'bestoftv/2014/12/21/ip-north-korea-obama.cnn',
-            'id': '0041400301-cle-atl-recap',
+            'id': 'channels/playoffs/2015/05/20/0041400301-cle-atl-recap.nba',
-        }
+        },
-            'id': '1455672027478-Doc_Feb16_720',
+            'id': 'teams/clippers/2016/02/17/1455672027478-Doc_Feb16_720.mov-297324',
-            'id': 'Wigginsmp4-3462601',
+            'id': 'teams/timberwolves/2014/12/12/Wigginsmp4-3462601',
-        video_id = video_data.attrib['id'].split('/')[-1].split('.')[0]
+        video_id = video_data.attrib['id']
-            'timestamp': timestamp,
+            'timestamp': self._extract_timestamp(video_data),
-            'id': 'bestoftv/2014/02/09/criminalizing-journalism.cnn',
+            'id': 'criminalizing-journalism',
-            'id': 'bestoftv/2014/12/21/ip-north-korea-obama.cnn',
+            'id': 'ip-north-korea-obama',
-            'description': 'md5:51ce6750450603795cad0cdfbd7d05c5',
+            'description': 'md5:0a802a40d2376f60e6b04c8d5bcebc4b',
-    _VALID_URL = r'https?://(?:www\.)?ctv\.ca/video/player\?vid=(?P<id>[0-9.]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<domain>ctv|tsn|bnn|thecomedynetwork)\.ca/.*?(?:\bvid=|-vid|~|%7E)(?P<id>[0-9.]+)'
-        video_id = self._match_id(url)
+        domain, video_id = re.match(self._VALID_URL, url).groups()
-            'url': '9c9media:ctv_web:%s' % video_id,
+            'url': '9c9media:%s_web:%s' % (domain, video_id),
-from .ninecninemedia import NineCNineMediaIE
+from .ninecninemedia import (
-    ExtractorError
+    float_or_none,
-    _VALID_URL = r'9c9media:(?P<destination_code>[^:]+):(?P<id>\d+)'
+class NineCNineMediaBaseIE(InfoExtractor):
-        stack_base_url = '%s%s/manifest.' % (stacks_base_url, stack['Id'])
+        destination_code, content_id, package_id, stack_id = re.match(self._VALID_URL, url).groups()
-            stack_base_url + 'm3u8', video_id, 'mp4',
+            stack_base_url + 'm3u8', stack_id, 'mp4',
-            stack_base_url + 'f4m', video_id,
+            stack_base_url + 'f4m', stack_id,
-        mp4_url = self._download_webpage(stack_base_url + 'pd', video_id, fatal=False)
+        mp4_url = self._download_webpage(stack_base_url + 'pd', stack_id, fatal=False)
-            'duration': parse_duration(content.get('BroadcastTime')),
+            'id': stack_id,
-        'md5': 'f926e7684294cf8cb7bdf8858e1b3988',
+        'url': 'http://www.kusi.com/story/32849881/turko-files-refused-to-help-it-aint-right',
-            'id': '12203019',
+            'id': '12689020',
-            'timestamp': 1455087571,
+            'title': "Turko Files: Refused to Help, It Ain't Right!",
-        },
+        'only_matching': True,
-                if not track_url:
+                if not isinstance(track_url, compat_str) or track_url.endswith('/big'):
-from ..utils import ExtractorError
+from ..utils import (
-                video_info = bootstrapped_data.get('heroMetadata', {}).get('trailer').get('video')
+                video_info = bootstrapped_data.get(
-        episode_duration = video_info.get('duration')
+        episode_description = video_info.get('description')
-            'duration': episode_duration
+            'duration': episode_duration,
-    _VALID_URL = r'https?://www\.bilibili\.(?:tv|com)/video/av(?P<id>\d+)'
+    _VALID_URL = r'https?://(www.|bangumi.|)bilibili\.(?:tv|com)/(video/av|anime/v/)(?P<id>\d+)'
-            webpage, 'player parameters'))['cid'][0]
+        _is_episode = 'anime/v' in url
-            'thumbnail': self._html_search_meta('thumbnailUrl', webpage),
+            'thumbnail': thumbnail,
-        for video_file in video_data.findall('files/file'):
+        rex = re.compile(
-            format_id = video_file.attrib['bitrate']
+            format_id = video_file.get('bitrate')
-                formats.extend(self._extract_smil_formats(video_url, video_id, fatal=False))
+                formats.extend(self._extract_smil_formats(
-                    video_url, video_id, 'mp4', m3u8_id=format_id, fatal=False)
+                    video_url, video_id, 'mp4', m3u8_id=format_id or 'hls',
-                    video_id, f4m_id=format_id, fatal=False))
+                    video_id, f4m_id=format_id or 'hds', fatal=False))
-                            f['tbr'] = int(mobj.group(1))
+                elif isinstance(format_id, compat_str):
-                if not source_url:
+                track_url = track.get('url')
-                    'url': source_url,
+                lang = track.get('lang') or track.get('label') or 'en'
-                    '%s does not support SOCKS proxies. Downloading may fail.' % self.get_basename())
+                    '%s does not support SOCKS proxies. Downloading is likely to fail. '
-            r'<iframe[^>]+src=[\'"]((?:https?:)?//(?:www\.)?vod-platform\.net/embed/[^/?#]+)',
+            r'<iframe[^>]+src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?vod-platform\.net/[eE]mbed/.+?)\1',
-                self._proto_relative_url(unescapeHTML(mobj.group(1))), 'VODPlatform')
+                self._proto_relative_url(unescapeHTML(mobj.group('url'))), 'VODPlatform')
-    _VALID_URL = r'https?://(?:www\.)?vod-platform\.net/embed/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?vod-platform\.net/[eE]mbed/(?P<id>[^/?#]+)'
-        }
+        extra_query = None
-                        frag_url = update_url_query(frag_url, extra_param_to_segment_url)
+                    if extra_query:
-                            decrypt_info['URI'] = update_url_query(decrypt_info['URI'], extra_param_to_segment_url)
+                        if extra_query:
-                    video_url, video_id, 'mp4', m3u8_id=format_id, fatal=False))
+                m3u8_formats = self._extract_m3u8_formats(
-                }
+                f['extra_param_to_segment_url'] = 'pbs=' + session_id
-            'http://www.cartoonnetwork.com/video-seo-svc/episodeservices/getCvpPlaylist?' + query, video_id, {
+            'http://www.cartoonnetwork.com/video-seo-svc/episodeservices/getCvpPlaylist?networkName=CN2&' + query, video_id, {
-)
+from .turner import TurnerBaseIE
-class AdultSwimIE(InfoExtractor):
+class AdultSwimIE(TurnerBaseIE):
-        }
+        },
-
+            segement_info = self._extract_cvp_info(
-            entries.append({
+            segement_info.update({
-                'description': episode_description
+                'description': episode_description,
-)
+from .turner import TurnerBaseIE
-class CNNIE(InfoExtractor):
+class CNNIE(TurnerBaseIE):
-            'id': 'sports/2013/06/09/nadal-1-on-1.cnn',
+            'id': 'nadal-1-on-1',
-            'id': 'us/2013/08/21/sot-student-gives-epic-speech.georgia-institute-of-technology',
+            'id': 'sot-student-gives-epic-speech',
-        }
+        },
-            'id': 'living/2014/12/22/growing-america-nashville-salemtown-board-episode-1.hln',
+            'id': 'growing-america-nashville-salemtown-board-episode-1',
-        }
+        },
-            'id': '/video/news/2016/08/19/netflix-stunning-stats.cnnmoney',
+            'id': 'netflix-stunning-stats',
-        }
+        },
-        }
+        return self._extract_cvp_info(
-from .common import InfoExtractor
+from .turner import TurnerBaseIE
-class NBAIE(InfoExtractor):
+class NBAIE(TurnerBaseIE):
-            'upload_date': '20160217',
+            'upload_date': '20160216',
-            'id': 'Wigginsmp4',
+            'id': 'Wigginsmp4-3462601',
-                'height': int_or_none(image.attrib.get('height')),
+        return self._extract_cvp_info(
-        }
+# coding: utf-8
-                j += 2
+                j += 1
-import datetime
+import hashlib
-)
+from ..compat import compat_parse_qs
-    xpath_text,
+    unified_timestamp,
-            'id': '1554319',
+            'id': '1074402',
-            'id': '1507019',
+            'id': '1041170',
-            'id': '7802182',
+            'id': '4808130',
-            'id': '2880301',
+            'id': '1867637',
-    _APP_KEY = '86385cdc024c0f6c'
+    _APP_KEY = '6f90a59ac58a4123'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        params = compat_parse_qs(self._search_regex(
+        cid = compat_parse_qs(self._search_regex(
-            err_msg = xpath_text(info_xml, './message')
+            webpage, 'player parameters'))['cid'][0]
-                raise ExtractorError('No videos found!')
+        video_info = self._download_json(
-            size = xpath_text(durl, ['./filesize', './size'])
+        for idx, durl in enumerate(video_info['durl']):
-                'filesize': int_or_none(size),
+                'url': durl['url'],
-            for backup_url in durl.findall('./backup_url/url'):
+            for backup_url in durl['backup_url']:
-                    'url': backup_url.text,
+                    'url': backup_url,
-                    'preference': -2 if 'hd.mp4' in backup_url.text else -3,
+                    'preference': -2 if 'hd.mp4' in backup_url else -3,
-                'duration': int_or_none(xpath_text(durl, './length'), 1000),
+                'id': '%s_part%s' % (video_id, idx),
-            timestamp = calendar.timegm(datetime.datetime.strptime(datetime_str, '%Y-%m-%dT%H:%M').timetuple())
+        timestamp = unified_timestamp(self._html_search_regex(
-            'id': compat_str(cid),
+            'id': video_id,
-            'duration': float_or_none(xpath_text(info_xml, './timelength'), scale=1000),
+            'duration': float_or_none(video_info.get('timelength'), scale=1000),
-        for c in enc_data:
+        for idx, c in enumerate(enc_data):
-            ]
+            ],
-            }
+            },
-            }
+            },
-            }
+            },
-__version__ = '2016.08.24.1'
+__version__ = '2016.08.28'
-class PeriscopeIE(InfoExtractor):
+class PeriscopeBaseIE(InfoExtractor):
-        broadcast_data = self._call_api('getBroadcastPublic', token)
+        broadcast_data = self._call_api(
-        stream = self._call_api('getAccessPublic', token)
+        stream = self._call_api(
-class PeriscopeUserIE(InfoExtractor):
+class PeriscopeUserIE(PeriscopeBaseIE):
-        user_id = self._match_id(url)
+        user_name = self._match_id(url)
-        webpage = self._download_webpage(url, user_id)
+        webpage = self._download_webpage(url, user_name)
-            user_id)
+            user_name)
-        description = user.get('description')
+        user = list(data_store['UserCache']['users'].values())[0]['user']
-                         data_store.get('BroadcastCache', {}).get('broadcastIds', []))
+        broadcast_ids = [
-                'https://www.periscope.tv/%s/%s' % (user_id, broadcast_id))
+                'https://www.periscope.tv/%s/%s' % (user_name, broadcast_id))
-from ..compat import (compat_str, compat_basestring, compat_urllib_parse_urlencode)
+from ..compat import (
-        room = room_json['data']
+        room = self._download_json(
-        error_code = flv_json.get('error', 0)
+        if room.get('show_status') == '2':
-            raise ExtractorError(error_desc, expected=True)
+            raise ExtractorError(
-        live_path = flv['rtmp_live']
+        base_url = video_info['data']['rtmp_url']
-
+    _THUMBNAIL_TEMPLATE = 'http://images-us-am.crackle.com/%stnl_1920x1080.jpg?ts=20140107233116?c=635333335057637614'
-            'thumbnails': thumbnails,
+            'thumbnail': thumbnail,
-from ..compat import (compat_str, compat_basestring)
+from ..compat import (compat_str, compat_basestring, compat_urllib_parse_urlencode)
-        config = None
+        room_url = 'http://m.douyu.com/html5/live?roomId=%s' % room_id
-            auth = hashlib.md5((prefix + '1231').encode('ascii')).hexdigest()
+            tt = int(time.time() / 60)
-                video_id)
+            payload = {'cdn': 'ws', 'rate': '0', 'tt': tt, 'did': did, 'sign': sign}
-                config = self._parse_json(config_page, video_id, fatal=False)
+                flv_json = self._parse_json(flv_content, video_id, fatal=False)
-        if config is None:
+        if flv_json is None:
-        data = config['data']
+        flv = flv_json['data']
-        error_code = config.get('error', 0)
+        error_code = flv_json.get('error', 0)
-                error_desc += ': ' + data
+            if isinstance(flv, (compat_str, compat_basestring)):
-        uploader_id = data.get('owner_uid')
+        base_url = flv['rtmp_url']
-        multi_formats['live'] = live_path
+        video_url = '%s/%s' % (base_url, live_path)
-        self._sort_formats(formats)
+        title = self._live_title(unescapeHTML(room['room_name']))
-            'formats': formats,
+    unescapeHTML,
-            cfg_url = 'https://cdn-fck.tnaflix.com/tnaflix/%s.fid?key=%s' % (inputs['vkey'], inputs['nkey'])
+            cfg_url = ('https://cdn-fck.tnaflix.com/tnaflix/%s.fid?key=%s&VID=%s&premium=1&vip=1&alpha'
-            return re.sub('speed=\d+', 'speed=', vl.text)
+            return re.sub('speed=\d+', 'speed=', unescapeHTML(vl.text))
-        'md5': '7e569419fe6d69543d01e6be22f5f7c4',
+        'md5': 'ecf3498417d09216374fc5907f9c6ec0',
-        'md5': 'fcba2636572895aba116171a899a5658',
+        'md5': '0f5d4d490dbfd117b8607054248a07c0',
-            'ext': 'flv',
+            'ext': 'mp4',
-    _TESTS = [{
+    _VALID_URL = r'https?://www3\.nhk\.or\.jp/nhkworld/en/vod/(?P<id>.+?)\.html'
-            'title': '[nhkworld]VOD;2009-251-2016;TOKYO FASHION EXPRESS;The Kimono as Global Fashion;en',
+            'title': 'TOKYO FASHION EXPRESS - The Kimono as Global Fashion',
-    }]
+        'skip': 'Videos available only for a limited period of time',
-            'ooyala embed code')
+            r'nw_vod_ooplayer\([^,]+,\s*(["\'])(?P<id>(?:(?!\1).)+)\1',
-        return self.url_result('ooyala:' + embed_code, 'Ooyala')
+        return {
-            video_id)
+from .usanetwork import USANetworkIE
-from __future__ import unicode_literals
+from __future__ import unicode_literals, division
-        'url': 'http://www.crackle.com/the-art-of-more/2496419',
+        'url': 'http://www.crackle.com/comedians-in-cars-getting-coffee/2498934',
-            'id': '2496419',
+            'id': '2498934',
-            'description': 'md5:bb56aa0708fe7b9a4861535f15c3abca',
+            'title': 'Everybody Respects A Bloody Nose',
-
+
-            'http://content.uplynk.com/ext/%s/%s.m3u8' % (self._UPLYNK_OWNER_ID, video_id),
+            'http://content.uplynk.com/ext/%s/%s.m3u8' % (config_doc.attrib['strUplynkOwnerId'], video_id),
-                        'url': '%s/%s%s_%s.xml' % (self._SUBTITLE_SERVER, path, locale, v),
+                        'url': '%s/%s%s_%s.xml' % (config_doc.attrib['strSubtitleServer'], path, locale, v),
-            'duration': int(item.attrib.get('r'), 16) if item.attrib.get('r') else None,
+            'duration': int(item.attrib.get('r'), 16) / 1000 if item.attrib.get('r') else None,
-            'thumbnail': thumbnail,
+            'thumbnails': thumbnails,
-            'description': 'dillion harper masturbates on a bed',
+            'description': 'Watch fantasy solo free HD porn video - 05 minutes - dillion harper masturbates on a bed free adult movies.',
-            webpage, 'description', default=None)
+        description = self._og_search_description(webpage)
-            r'class="user"[^>]*>([^<]+)',
+            r'class="user"[^>]*><img[^>]+>([^<]+)',
-                t.get('id') or '', t.get('url')))
+                t.get('preference') if t.get('preference') is not None else -1,
-                    expected=True)
+                if video_info.get('auth') is True:
-                expected=True)
+            if video.get('authenticated') is True:
-        stream = video['stream']
+        stream = video.get('stream')
-                t.get('id'), t.get('url')))
+                t.get('preference') or -1, t.get('width') or -1, t.get('height') or -1,
-                last_media = parse_m3u8_attributes(line)
+                media = parse_m3u8_attributes(line)
-                tbr = int_or_none(last_info.get('BANDWIDTH'), scale=1000)
+                tbr = int_or_none(last_info.get('AVERAGE-BANDWIDTH') or last_info.get('BANDWIDTH'), scale=1000)
-                stream_name = last_info.get('NAME') or last_media_name
+                    # Despite specification does not mention NAME attribute for
-                            decrypt_info['IV'] = binascii.unhexlify(decrypt_info['IV'][2:])
+                            decrypt_info['IV'] = binascii.unhexlify(decrypt_info['IV'][2:].zfill(32))
-        elif codec in ('mp4a', 'opus', 'vorbis', 'mp3', 'aac'):
+        elif codec in ('mp4a', 'opus', 'vorbis', 'mp3', 'aac', 'ac-3'):
-            'description': self._og_search_description(webpage),
+            'description': self._og_search_description(webpage, default=None),
-        return compat_urllib_parse_urlencode({
+        return {
-        })
+        }
-    compat_urllib_parse_urlencode,
+    RegexNotFoundError,
-    RegexNotFoundError,
+    @staticmethod
-        mediagen_url = re.sub(r'&[^=]*?={.*?}(?=(&|$))', '', mediagen_url)
+        mediagen_url = self._remove_template_parameter(content_el.attrib['url'])
-        return compat_urllib_parse_urlencode(data)
+        return data
-        info_url = feed_url + '?' + self._get_feed_query(uri)
+        info_url = update_url_query(feed_url, self._get_feed_query(uri))
-        return feed_url
+        config = self._download_json(
-        return compat_urllib_parse_urlencode({
+        return {
-        })
+        }
-__version__ = '2016.08.24'
+__version__ = '2016.08.24.1'
-            request, None, 'Logging in as %s' % username)
+            post_url, None, 'Logging in as %s' % username,
-                    request, display_id, 'Downloading %s URL' % format_id, fatal=False)
+                    '%s/training/Player/ViewClip' % self._API_BASE, display_id,
-import re
+import collections
-import collections
+import re
-        # { a = author, cn = clip_id, lc = end, m = name }
+        duration = int_or_none(
-            'duration': int_or_none(clip.get('duration')) or parse_duration(clip.get('formattedDuration')),
+            'title': title,
-            'formats': formats
+            'formats': formats,
-__version__ = '2016.08.22'
+__version__ = '2016.08.24'
-                                  login_page, 'Login GALX parameter')
+        login_form = self._hidden_inputs(login_page)
-            'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',
+        login_form.update({
-        }
+        })
-            data=urlencode_postdata(login_form_strs))
+            data=urlencode_postdata(login_form))
-            r'jQuery\.extend\([^,]+,\s*({.+})\);', webpage, 'drupal settings'),
+            r'jQuery\.extend\(Drupal\.settings\s*,\s*({.+?})\);', webpage, 'drupal settings'),
-            r'jQuery\.extend\([^,]+,\s*({.+})\);', webpage, 'drupal settings'),
+            r'jQuery\.extend\(Drupal\.settings\s*,\s*({.+?})\);', webpage, 'drupal settings'),
-from ..compat import compat_chr
+from ..compat import (
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage('https://openload.co/embed/%s/' % video_id, video_id)
-        if 'File not found' in webpage:
+        if 'File not found' in webpage or 'deleted by the owner' in webpage:
-        sig_str = [[0 for x in range(sig_str_length)] for y in range(10)]
+        # The following decryption algorithm is written by @yokrysty and
-                sig_str[i][j] = signums[begin:begin + 26]
+        video_url_chars = []
-            parts.append(str_.replace(',', ''))
+        for c in enc_data:
-        video_url = 'https://openload.co/stream/%s~%s~%s~%s' % (parts[3], parts[1], parts[2], parts[0])
+        video_url = 'https://openload.co/stream/%s?mime=true' % ''.join(video_url_chars)
-from ..utils import smuggle_url
+from .adobepass import AdobePassIE
-    _TEST = {
+class BravoTVIE(AdobePassIE):
-        'md5': 'd60cdf68904e854fac669bd26cccf801',
+        'md5': '9086d0b7ef0ea2aabc4781d75f4e5863',
-            'id': 'LitrBdX64qLn',
+            'id': 'zHyk1_HU_mPy',
-            'upload_date': '20151130',
+            'title': 'LCK Ep 12: Fishy Finale',
-    }
+    }, {
-            {'force_smil_url': True}), 'ThePlatform', release_pid)
+        display_id = self._match_id(url)
-class DCNIE(InfoExtractor):
+class AWAANIE(InfoExtractor):
-                'http://www.dcndigital.ae/media/%s' % video_id, 'DCNVideo')
+                'http://awaan.ae/media/%s' % video_id, 'AWAANVideo')
-                {'show_id': show_id}), 'DCNSeason')
+                'http://awaan.ae/program/season/%s' % season_id,
-                'http://www.dcndigital.ae/program/%s' % show_id, 'DCNSeason')
+                'http://awaan.ae/program/%s' % show_id, 'AWAANSeason')
-    def _extract_video_info(self, video_data, video_id, is_live):
+class AWAANBaseIE(InfoExtractor):
-            'timestamp': timestamp,
+            'description': video_data.get('description_en') or video_data.get('description_ar'),
-    IE_NAME = 'dcn:video'
+class AWAANVideoIE(AWAANBaseIE):
-        request = sanitized_Request(
+        video_data = self._download_json(
-        info = self._extract_video_info(video_data, video_id, False)
+            video_id, headers={'Origin': 'http://awaan.ae'})
-    IE_NAME = 'dcn:live'
+class AWAANLiveIE(AWAANBaseIE):
-        request = sanitized_Request(
+        channel_data = self._download_json(
-        info = self._extract_video_info(channel_data, channel_id, True)
+            channel_id, headers={'Origin': 'http://awaan.ae'})
-    IE_NAME = 'dcn:season'
+class AWAANSeasonIE(InfoExtractor):
-                request = sanitized_Request(
+                season = self._download_json(
-                season = self._download_json(request, season_id)
+                    season_id, headers={'Origin': 'http://awaan.ae'})
-        request = sanitized_Request(
+        show = self._download_json(
-                'Origin': 'http://www.dcndigital.ae',
+            show_id, data=urlencode_postdata(data), headers={
-                        'http://www.dcndigital.ae/media/%s' % video_id, 'DCNVideo', video_id))
+                        'http://awaan.ae/media/%s' % video_id, 'AWAANVideo', video_id))
-            video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+        formats = self._extract_akamai_formats(stream['hds-unmetered'], video_id)
-                formats = self._extract_formats(asset_url, video_id, fatal=False)
+                formats = self._extract_akamai_formats(asset_url, video_id)
-                formats = self._extract_formats(media_url, video_id)
+                formats = self._extract_akamai_formats(media_url, video_id)
-                      'context4/context5/config.xml'.format(site_id))
+        config_url = ('http://media.mtvnservices.com/pmt-arc/e1/players/{0}/'
-from .abc import ABCIE
+from .abc import (
-__version__ = '2016.08.19'
+__version__ = '2016.08.22'
-            r'<meta[^>]+itemprop="episode"[^>]*>\s*<meta[^>]+itemprop="episodeNumber"[^>]+content="(\d+)',
+            r'[^>]+itemprop="episode"[^>]*>\s*<meta[^>]+itemprop="episodeNumber"[^>]+content="(\d+)',
-# encoding: utf-8
+# coding: utf-8
-    sanitized_Request,
+    qualities,
-    _KNOWN_FORMATS = ['MP4-low-mobile', 'MP4-mobile', 'FLV-lo', 'MP4-lo', 'FLV-hi', 'MP4-hi', 'MP4-SHQ']
+    _KNOWN_FORMATS = (
-            request, video_id, 'Downloading video JSON')
+            'http://api.digitalaccess.ru/api/json/', video_id,
-        } for x in result['files'] if x['content_format'] in self._KNOWN_FORMATS]
+            'format_id': x.get('content_format'),
-            self._PLAYER_BASE % video_id, webpage, video_id)[0]
+            self._PLAYER_BASE % video_id, webpage, video_id,
-    def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None):
+    def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None, m3u8_entry_protocol='m3u8'):
-                    m3u8_id=m3u8_id)
+                    full_url, video_id, ext='mp4',
-        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]
+        info_dict = self._parse_html5_media_entries(
-        'only_matching': 'true',
+        'info_dict': {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        formats = entries['formats']
+        info_dict = self._parse_html5_media_entries(
-        self._remove_duplicate_formats(formats)
+        self._sort_formats(info_dict['formats'])
-        return {
+        info_dict.update({
-        }
+        })
-from ..compat import compat_xpath
+from ..compat import compat_urlparse
-    _VALID_URL = r'https?://(?:www\.)?1tv\.ru/(?:[^/]+/)+p?(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?1tv\.ru/(?:[^/]+/)+(?P<id>[^/?#]+)'
-        'md5': '82a2777648acae812d58b3f5bd42882b',
+        'url': 'http://www.1tv.ru/shows/naedine-so-vsemi/vypuski/gost-lyudmila-senchina-naedine-so-vsemi-vypusk-ot-12-02-2015',
-            'id': '35930',
+            'id': '40049',
-            'description': 'md5:357933adeede13b202c7c21f91b871b2',
+            'description': 'md5:36a39c1d19618fec57d12efe212a8370',
-        'only_matching': True,
+        'url': 'http://www.1tv.ru/shows/dobroe-utro/pro-zdorove/vesennyaya-allergiya-dobroe-utro-fragment-vypuska-ot-07042016',
-            }
+        display_id = self._match_id(url)
-                item, xpath_with_ns('./media:thumbnail', NS_MAP), 'url')
+        webpage = self._download_webpage(url, display_id)
-                'ya:ovs:upload_date', webpage, 'upload date', fatal=False))
+        title = self._html_search_regex(
-            'thumbnail': thumbnail,
+            'thumbnail': item.get('poster') or self._og_search_thumbnail(webpage),
-            headers={'Referer': redirect_url})
+        headers = {'Referer': redirect_url}
-            self.report_warning('Twitch asks you to reset your password, go to https://secure.twitch.tv/reset/submit')
+        try:
-    def _download_json(self, url, video_id, note='Downloading JSON metadata'):
+    def _call_api(self, path, item_id, note):
-            url, video_id, note, headers=headers)
+        response = self._download_json(
-            '%s/kraken/videos/%s%s' % (self._API_BASE, item, item_id), item_id,
+        return self._extract_info(self._call_api(
-            '%s/api/videos/%s%s' % (self._API_BASE, self._ITEM_SHORTCUT, item_id), item_id,
+        response = self._call_api(
-            '%s/api/vods/%s/access_token' % (self._API_BASE, item_id), item_id,
+        access_token = self._call_api(
-    _PLAYLIST_URL = '%s/kraken/channels/%%s/videos/?offset=%%d&limit=%%d' % TwitchBaseIE._API_BASE
+    _PLAYLIST_PATH = 'kraken/channels/%s/videos/?offset=%d&limit=%d'
-            '%s/kraken/channels/%s' % (self._API_BASE, channel_id),
+        info = self._call_api(
-                self._PLAYLIST_URL % (channel_id, offset, limit),
+            response = self._call_api(
-    _PLAYLIST_URL = TwitchPlaylistBaseIE._PLAYLIST_URL + '&broadcasts=true'
+    _PLAYLIST_PATH = TwitchPlaylistBaseIE._PLAYLIST_PATH + '&broadcasts=true'
-            '%s/kraken/streams/%s' % (self._API_BASE, channel_id), channel_id,
+        stream = self._call_api(
-            '%s/api/channels/%s/access_token' % (self._API_BASE, channel_id), channel_id,
+        access_token = self._call_api(
-        response = super(TwitchBaseIE, self)._download_json(request, video_id, note)
+        response = super(TwitchBaseIE, self)._download_json(
-            request, None, 'Logging in as %s' % username)
+            post_url, None, 'Logging in as %s' % username,
-                    'ext': caption.get('fileExt', 'ttml'),
+                    'ext': caption.get('fileExt') or self._CAPTION_TYPES.get(caption_format) or 'ttml',
-)
+from .zingmp3 import ZingMp3IE
-from ..utils import ExtractorError
+from ..utils import (
-        error_message = item.find('./errormessage').text
+    def _extract_item(self, item, page_type, fatal=True):
-        thumbnail = item.find('./backimage').text
+        formats = []
-            'thumbnail': thumbnail,
+            'title': (item.get('name') or item.get('title')).strip(),
-        items = player_xml.findall('./item')
+    def _extract_player_json(self, player_json_url, id, page_type, playlist_title=None):
-            data = self._extract_item(items[0])
+            data = self._extract_item(items[0], page_type)
-                entry = self._extract_item(item, fatal=False)
+                entry = self._extract_item(item, page_type, fatal=False)
-    _VALID_URL = r'https?://mp3\.zing\.vn/bai-hat/(?P<slug>[^/]+)/(?P<song_id>\w+)\.html'
+class ZingMp3IE(ZingMp3BaseInfoExtractor):
-    _TESTS = [{
+    }, {
-            'title': 'LÃ¢u ÄÃ i TÃ¬nh Ãi - Báº±ng Kiá»u ft. Minh Tuyáº¿t | Album 320 lossless',
+            'title': 'LÃ¢u ÄÃ i TÃ¬nh Ãi - Báº±ng Kiá»u,Minh Tuyáº¿t | Album 320 lossless',
-    IE_DESC = 'mp3.zing.vn albums'
+    IE_NAME = 'zingmp3'
-            playlist_title=self._og_search_title(webpage))
+        page_id = self._match_id(url)
-                    'ext': caption.get('fileExt'),
+                    'ext': caption.get('fileExt', 'ttml'),
-                    if 'ext' not in subtitle_format:
+                    if subtitle_format.get('ext') is None:
-            if 'ext' not in format:
+            if format.get('ext') is None:
-from ..utils import int_or_none
+from ..utils import (
-    _VALID_URL = r'''(?x)https?://(?:(?:edition|www)\.)?cnn\.com/video/(?:data/.+?|\?)/
+    _VALID_URL = r'''(?x)https?://(?:(?P<sub_domain>edition|www|money)\.)?cnn\.com/(?:video/(?:data/.+?|\?)/)?videos?/
-        info_url = 'http://edition.cnn.com/video/data/3.0/%s/index.xml' % path
+        sub_domain, path, page_title = re.match(self._VALID_URL, url).groups()
-            video_url = 'http://ht.cdn.turner.com/cnn/big%s' % (f.text.strip())
+            video_url = config['media_src'] + f.text.strip()
-    _VALID_URL = r'https?://(?:(?:edition|www)\.)?cnn\.com/(?!video/)'
+    _VALID_URL = r'https?://(?:(?:edition|www)\.)?cnn\.com/(?!videos?/)'
-        'expected_warnings': ['Failed to download m3u8 information'],
+        'params': {
-    TP_RELEASE_URL_TEMPLATE = 'http://link.theplatform.com/s/dJ5BDC/%s?mbr=true'
+
-        return self._extract_video_info('byGuid=%s' % content_id, content_id)
+        return self._extract_video_info(content_id)
-from .cbs import CBSBaseIE
+from .cbs import CBSIE
-class CBSNewsIE(CBSBaseIE):
+class CBSNewsIE(CBSIE):
-                'upload_date': '19700101',
+                'upload_date': '20140404',
-        return self._extract_video_info('byGuid=%s' % guid, guid)
+        return self._extract_video_info(guid)
-        'md5': '0914d4d69605090f623b7ac329fea66e',
+        'url': 'https://dotsub.com/view/9c63db2a-fa95-4838-8e6e-13deafe47f09',
-            'id': 'aed3b8b2-1889-4df5-ae63-ad85f5572f27',
+            'id': '9c63db2a-fa95-4838-8e6e-13deafe47f09',
-            'upload_date': '20101213',
+            'title': 'MOTIVATION - "It\'s Possible" Best Inspirational Video Ever',
-            'title': 'Ice Age: Continental Drift Trailer (No. 2) - IMDb',
+            'title': 'Ice Age: Continental Drift Trailer (No. 2)',
-            'title': self._og_search_title(webpage),
+            'title': remove_end(self._og_search_title(webpage), ' - IMDb'),
-            'thumbnail': format_info['slate'],
+            'thumbnail': format_info.get('slate'),
-    _VALID_URL = r'https?://www\.litv\.tv/vod/[^/]+/content\.do\?.*?\bid=(?P<id>[^&]+)'
+    _VALID_URL = r'https?://www\.litv\.tv/(?:vod|promo)/[^/]+/(?:content\.do)?\?.*?\b(?:content_)?id=(?P<id>[^&]+)'
-            'skip_download': True,  # m3u8 download
+        },
-                'watchDevices': vod_data['watchDevices'],
+                'watchDevices': view_data['watchDevices'],
-            video_data['fullpath'], video_id, ext='mp4', m3u8_id='hls')
+            video_data['fullpath'], video_id, ext='mp4',
-    str_to_int,
+    parse_filesize,
-            'ext': 'flv',
+            'ext': 'mp4',
-            'filesize_approx': 98566144,
+            'duration': 248,
-        }
+            'thumbnail': 're:^https?://.*\.jpg$',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'filesize_approx': 8912896,
+            'filesize_approx': 8500000,
-        video_url = 'http://cdn.videos.snotr.com/%s.flv' % video_id
+        info_dict = self._parse_html5_media_entries(url, webpage, video_id)[0]
-            r'<p>\n<strong>Views:</strong>\n([\d,\.]+)</p>',
+            r'<p[^>]*>\s*<strong[^>]*>Views:</strong>\s*<span[^>]*>([\d,\.]+)',
-            r'<p>\n<strong>Length:</strong>\n\s*([0-9:]+).*?</p>',
+            r'<p[^>]*>\s*<strong[^>]*>Length:</strong>\s*<span[^>]*>([\d:]+)',
-            webpage, 'filesize', fatal=False), invscale=1024 * 1024)
+        filesize_approx = parse_filesize(self._html_search_regex(
-        return {
+        info_dict.update({
-        }
+        })
-        }
+        'skip': 'Unable to load videos',
-        'md5': '',
+        'url': 'http://www.miomio.tv/watch/cc273997/',
-            'id': '273295',
+            'id': '273997',
-            'skip_download': True,
+            'title': 'ããã³ã®ç¥ããªãä¸çãåçé²åSPï¼ããã¼ã«åï¼å·åé£å2016ã 1_2 - 16 05 31',
-            entries = self._parse_html5_media_entries(player_url, player_webpage)
+            entries = self._parse_html5_media_entries(player_url, player_webpage, video_id)
-        'url': 'http://m.vuclip.com/w?cid=922692425&fid=70295&z=1010&nvar&frm=index.html',
+        'url': 'http://m.vuclip.com/w?cid=1129900602&bu=8589892792&frm=w&z=34801&op=0&oc=843169247&section=recommend',
-            'id': '922692425',
+            'id': '1129900602',
-            'duration': 177,
+            'title': 'Top 10 TV Convicts',
-            formats = self._parse_html5_media_entries(url, webpage)[0]['formats']
+            formats = self._parse_html5_media_entries(url, webpage, video_id)[0]['formats']
-    def _parse_html5_media_entries(self, base_url, webpage):
+    def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None):
-                })
+                _, formats = _media_formats(src)
-                    media_info['formats'].append(f)
+                    is_plain_url, formats = _media_formats(src, media_type)
-        'url': 'http://www.radiobremen.de/mediathek/index.html?id=114720',
+        'url': 'http://www.radiobremen.de/mediathek/?id=141876',
-            'id': '114720',
+            'id': '141876',
-            'duration': 1685,
+            'duration': 178,
-            'title': 'buten un binnen vom 22. Dezember',
+            'title': 'Druck auf Patrick ÃztÃ¼rk',
-            'description': 'Unter anderem mit diesen Themen: 45 FlÃ¼chtlinge sind in Worpswede angekommen +++ Freies Internet fÃ¼r alle: Bremer arbeiten an einem flÃ¤chendeckenden W-Lan-Netzwerk +++ Aktivisten kÃ¤mpfen fÃ¼r das Unibad +++ So war das Wetter 2014 +++',
+            'description': 'Gegen den SPD-BÃ¼rgerschaftsabgeordneten Patrick ÃztÃ¼rk wird wegen Beihilfe zum gewerbsmÃ¤Ãigen Betrug ermittelt. Am Donnerstagabend sollte er dem Vorstand des SPD-Unterbezirks Bremerhaven dazu Rede und Antwort stehen.',
-# encoding: utf-8
+# coding: utf-8
-            video_id, transform_source=js_to_json)
+            webpage, 'player data'), video_id,
-            (r'^0+[0-7]+', 8),
+            (r'^(0[xX][0-9a-fA-F]+)\s*:?$', 16),
-                i = int(im.group(0), base)
+                i = int(im.group(1), base)
-    _VALID_URL = 'https?://.+?\.globo\.com/(?:[^/]+/)*(?P<id>[^/]+)\.html'
+    _VALID_URL = 'https?://.+?\.globo\.com/(?:[^/]+/)*(?P<id>[^/]+)(?:\.html)?'
-        r'\bvideosIDs\s*:\s*["\'](\d{7,})',
+        r'\bvideosIDs\s*:\s*["\']?(\d{7,})',
-__version__ = '2016.08.17'
+__version__ = '2016.08.19'
-              'for example with -o \'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\' .'))
+        help=('Output filename template, see the "OUTPUT TEMPLATE" for all the info'))
-            r'<iframe[^>]+src=(["\'])((?:https?:)?//(?:www\.)?dbtv\.no/lazyplayer/\d+.*?)\1',
+            r'<iframe[^>]+src=(["\'])((?:https?:)?//(?:www\.)?dbtv\.no/(?:lazy)?player/\d+.*?)\1',
-    parse_duration,
+        'params': {
-            'fw_post_author', webpage)) or self._og_search_description(webpage)
+        uploader = clean_html(get_element_by_class('author', webpage))
-            })
+        audio_ids = re.findall(r'data-full-id=["\'](\d+_\d+)', webpage)
-        if cookies:
+        for header, cookies in url_handle.headers.items():
-            in mobj.groupdict() else None) or mobj.group('id')
+        display_id = (mobj.group('display_id')
-from .hgtv import HGTVIE
+from .hgtv import (
-    _VALID_URL = r'https?://(?:www\.)?discoverygo\.com/(?:[^/]+/)*(?P<id>[^/?#&]+)'
+    _VALID_URL = r'''(?x)https?://(?:www\.)?(?:
-    _VALID_URL = r'https?://(?:www\.)?extremetube\.com/(?:[^/]+/)?video/(?:(?P<display_id>[^/]+)-)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?extremetube\.com/(?:[^/]+/)?video/(?P<id>[^/#?&]+)'
-            'display_id': 'music-video-14-british-euro-brit-european-cumshots-swallow',
+            'id': 'music-video-14-british-euro-brit-european-cumshots-swallow-652431',
-        display_id = mobj.group('display_id') or video_id
+        display_id = (mobj.group('display_id') if 'display_id'
-__version__ = '2016.08.13'
+__version__ = '2016.08.17'
-import re
+from ..utils import str_to_int
-    _VALID_URL = r'https?://(?:www\.)?extremetube\.com/(?:[^/]+/)?video/(?P<id>[^/#?&]+)'
+class ExtremeTubeIE(KeezMoviesIE):
-        'md5': '344d0c6d50e2f16b06e49ca011d8ac69',
+        'md5': '1fb9228f5e3332ec8c057d6ac36f33e0',
-            'id': 'music-video-14-british-euro-brit-european-cumshots-swallow-652431',
+            'id': '652431',
-        video_id = self._match_id(url)
+        webpage, info = self._extract_info(url)
-        webpage = self._download_webpage(req, video_id)
+        if not info['title']:
-        view_count = str_to_int(self._html_search_regex(
+        view_count = str_to_int(self._search_regex(
-            'formats': formats,
+        info.update({
-        }
+        })
-from ..aes import aes_decrypt_text
+from .keezmovies import KeezMoviesIE
-class Tube8IE(InfoExtractor):
+class Tube8IE(KeezMoviesIE):
-        self._sort_formats(formats)
+        webpage, info = self._extract_info(url)
-        thumbnail = flashvars.get('image_url')
+        if not info['title']:
-            'title': title,
+        info.update({
-        }
+        })
-    compat_urllib_parse_urlparse,
+from ..utils import (
-from ..utils import sanitized_Request
+from .keezmovies import KeezMoviesIE
-        'md5': '1b2eb47ac33cc75d4a80e3026b613c5a',
+class MofosexIE(KeezMoviesIE):
-            'id': '5018',
+            'id': '318131',
-            'title': 'Japanese Teen Music Video',
+            'title': 'amateur teen playing and masturbating',
-    }
+    }, {
-        }
+        webpage, info = self._extract_info(url)
-    url_basename,
+    determine_ext,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?keezmovies\.com/video/(?:(?P<display_id>[^/]+)-)?(?P<id>\d+)'
-            'age_limit': 18,
+            'view_count': int,
-    }
+    }, {
-        video_id = self._match_id(url)
+    def _extract_info(self, url):
-        webpage = self._download_webpage(req, video_id)
+        webpage = self._download_webpage(
-            return self.url_result(embedded_url)
+        formats = []
-            r'var\s+flashvars\s*=\s*([^;]+);', webpage, 'flashvars'), video_id)
+        title = None
-        return {
+        def extract_format(format_url, height=None):
-            'title': video_title,
+            'display_id': display_id,
-            'thumbnail': flashvars.get('image_url')
+
-    _VALID_URL = r'https?://(?:www\.)?vbox7\.com/play:(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?vbox7\.com/(?:play:|emb/external\.php\?.*?\bvid=)(?P<id>[\da-fA-F]+)'
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-            r'<title>(.*)</title>', webpage, 'title').split('/')[0].strip()
+            r'<title>(.+?)</title>', webpage, 'title').split('/')[0].strip()
-            'view_count': int_or_none(video.get('views', {}).get('total')),
+            'view_count': try_get(video, lambda x: x['views']['total'], int),
-from .tvplay import TVPlayIE
+from .tvplay import (
-        '''
+    IE_NAME = 'mtg'
-            'http://playapi.mtgx.tv/v1/videos/%s' % video_id, video_id, 'Downloading video JSON')
+            'http://playapi.mtgx.tv/v3/videos/%s' % video_id, video_id, 'Downloading video JSON')
-                'http://playapi.mtgx.tv/v1/videos/stream/%s' % video_id,
+                'http://playapi.mtgx.tv/v3/videos/stream/%s' % video_id,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?(?:fxnetworks|simpsonsworld)\.com/video/(?P<id>\d+)'
-    }
+    }, {
-        player_type = self._search_regex(r'playerType\s*=\s*[\'"]([^\'"]+)', webpage, 'player type', fatal=False)
+        player_type = self._search_regex(r'playerType\s*=\s*[\'"]([^\'"]+)', webpage, 'player type', default=None)
-            'subtiles': subtitles,
+            'subtitles': subtitles,
-                subtitles[lang] = [{
+                subtitles.setdefault(lang, []).append({
-                }]
+                })
-        'md5': '4b46ae6ea5e6e9086e714d883313c0c9',
+        'md5': '14cea69fcb84db54293b1e971466c2e1',
-            'ext': 'flv',
+            'ext': 'mp4',
-            formats.append({'url': video_url})
+            formats.append({
-                        entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))
+        for kind, _, format_url in re.findall(
-            'title': 'Step 1',
+            'title': 'Maron - Season 4 - Step 1',
-        return short_authorize
+        return short_authorize
-        'playlist_mincount': 142,
+        # multipage playlist, explicit page
-        return self.playlist_result(entries, playlist_id, title, description)
+        return self.playlist_result(
-class AdobePass(InfoExtractor):
+class AdobePassIE(InfoExtractor):
-from .adobepass import AdobePass
+from .adobepass import AdobePassIE
-class FXNetworksIE(AdobePass):
+class FXNetworksIE(AdobePassIE):
-from .theplatform import ThePlatformIE
+from .adobepass import AdobePassIE
-class NationalGeographicIE(ThePlatformIE):
+class NationalGeographicIE(AdobePassIE):
-class NationalGeographicEpisodeGuideIE(ThePlatformIE):
+class NationalGeographicEpisodeGuideIE(InfoExtractor):
-from .theplatform import ThePlatformIE
+from .adobepass import AdobePassIE
-class SyfyIE(ThePlatformIE):
+class SyfyIE(AdobePassIE):
-from .adobepass import AdobePass
+from .adobepass import AdobePassIE
-class ThePlatformIE(ThePlatformBaseIE, AdobePass):
+class ThePlatformIE(ThePlatformBaseIE, AdobePassIE):
-from .adobepass import AdobePass
+from .adobepass import AdobePassIE
-class VicelandIE(AdobePass):
+class VicelandIE(AdobePassIE):
-    _TESTS = [{
+    # Live videos get deleted soon. See http://www.cbsnews.com/live/ for the latest examples
-    }]
+        'skip': 'Video gone',
-            'duration': 49,
+        'playlist_count': 9,
-            info_dict = self._extract_anvato_videos(webpage, display_id)
+            return self.url_result(
-    parse_duration,
+    float_or_none,
-    _VALID_URL = r'https?://embed\.sendtonews\.com/player/embed\.php\?(?P<query>[^#]+)'
+    _VALID_URL = r'https?://embed\.sendtonews\.com/player2/embedplayer\.php\?.*\bSC=(?P<id>[0-9A-Za-z-]+)'
-        'url': 'http://embed.sendtonews.com/player/embed.php?SK=GxfCe0Zo7D&MK=175909&PK=5588&autoplay=on&sound=yes',
+        'url': 'http://embed.sendtonews.com/player2/embedplayer.php?SC=GxfCe0Zo7D-175909-5588&type=single&autoplay=on&sound=YES',
-            'duration': 49,
+            'id': 'GxfCe0Zo7D-175909-5588'
-    _URL_TEMPLATE = '//embed.sendtonews.com/player/embed.php?SK=%s&MK=%s&PK=%s'
+    _URL_TEMPLATE = '//embed.sendtonews.com/player2/embedplayer.php?SC=%s'
-            return cls._URL_TEMPLATE % (sk, mk, pk)
+            sc = mobj.group('SC')
-        return info_dict
+        playlist_id = self._match_id(url)
-    def _parse_jwplayer_data(self, jwplayer_data, video_id, require_title=True, m3u8_id=None, rtmp_params=None, base_url=None):
+    def _parse_jwplayer_data(self, jwplayer_data, video_id=None, require_title=True, m3u8_id=None, rtmp_params=None, base_url=None):
-                        source_url, video_id, 'mp4', 'm3u8_native', m3u8_id=m3u8_id, fatal=False))
+                        source_url, this_video_id, 'mp4', 'm3u8_native', m3u8_id=m3u8_id, fatal=False))
-                        a_format['ext'] = 'flv',
+                        a_format['ext'] = 'flv'
-                'id': video_id,
+                'id': this_video_id,
-        }
+    IE_NAME = 'uplynk'
-        'add_ie': ['UplynkPreplay', 'Uplynk'],
+        'add_ie': ['UplynkPreplay'],
-            if '<pendingLogout' in short_authorize:
+            if '<pendingLogout' in session:
-        return self._download_webpage(
+        short_authorize = self._download_webpage(
-        path, external_id, video_id, session_id = re.match(self._VALID_URL, url).groups()
+    def _extract_uplynk_info(self, uplynk_content_url):
-class UplynkPreplayIE(InfoExtractor):
+class UplynkPreplayIE(UplynkIE):
-        return self.url_result(content_url, 'Uplynk')
+        return self._extract_uplynk_info(content_url)
-            resource = '<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>%s</title><item><title>%s</title><guid>%s</guid><media:rating scheme="urn:v-chip">%s</media:rating></item></channel></rss>' % (requestor_id, theplatform_metadata['title'], theplatform_metadata['AETN$PPL_pplProgramId'], theplatform_metadata['ratings'][0]['rating'])
+            resource = self._get_mvpd_resource(
-            query['auth'] = self._extract_mvpd_auth(url, display_id, 'natgeo', auth_resource_id) or ''
+            query['auth'] = self._extract_mvpd_auth(url, display_id, 'natgeo', auth_resource_id)
-            resource = '<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>syfy</title><item><title><![CDATA[%s]]></title><guid>%s</guid><media:rating scheme="urn:v-chip">%s</media:rating></item></channel></rss>' % (title, video_id, syfy_mpx.get('mpxRating', 'TV-14'))
+            resource = self._get_mvpd_resource(
-import netrc
+from .adobepass import AdobePass
-class ThePlatformIE(ThePlatformBaseIE):
+class ThePlatformIE(ThePlatformBaseIE, AdobePass):
-from ..compat import compat_urlparse
+from ..compat import (
-            r'<iframe[^>]+src=["\']((?:https?:)?//embed\.life\.ru/embed/.+?)["\']',
+            r'<iframe[^>]+src=["\']((?:https?:)?//embed\.life\.ru/(?:embed|video)/.+?)["\']',
-    _VALID_URL = r'https?://embed\.life\.ru/embed/(?P<id>[\da-f]{32})'
+    _VALID_URL = r'https?://embed\.life\.ru/(?:embed|video)/(?P<id>[\da-f]{32})'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                })
+
-        thumbnail = self._search_regex(
+        thumbnail = thumbnail or self._search_regex(
-            if token_expires and token_expires >= time.time():
+            token_expires = unified_timestamp(re.sub(r'[_ ]GMT', '', xml_text(authn_token, 'simpleTokenExpires')))
-                return None
+            username, password = self._get_netrc_login_info(mso_id)
-                'password': login_info[2],
+                'username': username,
-                self._downloader.report_warning('parsing .netrc: %s' % error_to_compat_str(err))
+        else:
-__version__ = '2016.08.12'
+__version__ = '2016.08.13'
-                # http://www.pbs.org/video/2365815229/
+                # Lower qualities (150k and 192k) are not available as HTTP formats (see [1]),
-                'description': 'md5:36f341ae62e251b8f5bd2b754b95a071',
+                'description': 'md5:31b664af3c65fd07fa460d306b837d00',
-                'description': 'md5:4d3eaa01f94e61b3e73704735f1196d9',
+                'description': 'md5:5979a4d069b157f622d02bff62fbe654',
-                'description': 'md5:95a19f568689d09a166dff9edada3301',
+                'description': 'md5:86ab9a3d04458b876147b355788b8781',
-                'description': 'md5:1b80a74e0380ed2a4fb335026de1600d',
+                'description': 'md5:67fa89a9402e2ee7d08f53b920674c18',
-            'md5': '84ced42850d78f1d4650297356e95e6f',
+            'md5': '59b0ef5009f9ac8a319cc5efebcd865e',
-                'description': 'md5:54033c6baa1f9623607c6e2ed245888b',
+                'description': 'md5:c0ff7475a4b70261c7e58f493c2792a5',
-                'description': 'md5:1a2481e86b32b2e12ec1905dd473e2c1',
+                'description': 'md5:f677e4520cfacb4a5ce1471e31b57800',
-            'md5': 'acfd4c400b48149a44861cb16dd305cf',
+            'md5': 'fdf907851eab57211dd589cf12006666',
-        {
+        description = None
-                    return tabbed_videos, presumptive_id, upload_date
+                    return tabbed_videos, presumptive_id, upload_date, description
-                return media_id, presumptive_id, upload_date
+                return media_id, presumptive_id, upload_date, description
-                return getdir['mid'], presumptive_id, upload_date
+                return getdir['mid'], presumptive_id, upload_date, description
-        return video_id, display_id, None
+        return video_id, display_id, None, description
-        video_id, display_id, upload_date = self._extract_webpage(url)
+        video_id, display_id, upload_date, description = self._extract_webpage(url)
-            'description': info.get('description') or info.get('program', {}).get('description'),
+            'description': description,
-)
+from .franceculture import FranceCultureIE
-    ExtractorError,
+    unified_strdate,
-    _VALID_URL = r'https?://(?:www\.)?franceculture\.fr/player/reecouter\?play=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?franceculture\.fr/emissions/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-        'url': 'http://www.franceculture.fr/player/reecouter?play=4795174',
+        'url': 'http://www.franceculture.fr/emissions/carnet-nomade/rendez-vous-au-pays-des-geeks',
-            'id': '4795174',
+            'id': 'rendez-vous-au-pays-des-geeks',
-            'vcodec': 'none',
+            'thumbnail': 're:^https?://.*\\.jpg$',
-            'timestamp': 1393700400,
+            'vcodec': 'none',
-        webpage = self._download_webpage(url, video_id)
+    def _real_extract(self, url):
-            webpage, 'thumbnail', fatal=False)
+        webpage = self._download_webpage(url, display_id)
-            r'<span class="path-diffusion">emission-(.*?)</span>', webpage, 'display_id')
+        video_url = self._search_regex(
-            webpage, 'description', fatal=False)
+        title = self._og_search_title(webpage)
-            'id': video_id,
+            'id': display_id,
-            'display_id': display_id,
+            'vcodec': vcodec,
-)
+from ..utils import int_or_none
-            js_config, 'originAuthenticationSpaceKey')
+        token = self._download_json(
-        token = token_answer['tokenKey']
+        video_url = self._download_json(
-        video_url = delivery_info['mediaUrl']
+        FIELDS = (
-            info_req, video_id, note='Downloading metadata')
+            'https://api.aebn.net/content/v2/clips/%s?fields=%s'
-        categories = [c['name'] for c in info.get('categories')]
+        movie_id = info.get('movieId')
-            'title': info['title'],
+            'title': title,
-            r'<a class="img-avatar" href="[^"]+/channels/([^/"]+)" title="Go to [^"]+ page">',
+            r'<a class="item-to-subscribe" href="[^"]+/channels/([^/"]+)" title="Go to [^"]+ page">',
-            r'<a class="img-avatar" href="[^"]+/channels/[^/"]+" title="Go to ([^"]+) page">',
+            r'<a class="item-to-subscribe" href="[^"]+/channels/[^/"]+" title="Go to ([^"]+) page">',
-            r'(?s)><i class="icon icon-tag"></i>\s*Categories / Tags\s*.*?<ul class="list">(.*?)</ul>',
+            r'(?s)><i class="icon icon-tag"></i>\s*Categories / Tags\s*.*?<ul class="[^"]*?list[^"]*?">(.*?)</ul>',
-            r'<meta itemprop="interactionCount" content="UserPlays:([0-9,]+)">',
+            r'<meta[^>]+itemprop="interactionCount"[^>]+content="UserPlays:([0-9,]+)">',
-            r'<meta itemprop="interactionCount" content="UserLikes:([0-9,]+)">',
+            r'<meta[^>]+itemprop="interactionCount"[^>]+content="UserLikes:([0-9,]+)">',
-            webpage, 'height', fatal=False))
+        width = int_or_none(self._og_search_property(
-)
+from ..utils import urlencode_postdata
-        self.assertTrue('secret' not in serr)
+        self.assertTrue(b'--username' in serr)
-        self.assertTrue('secret' not in serr)
+        self.assertTrue(b'-u' in serr)
-        self.assertTrue('secret' not in serr)
+        self.assertTrue(b'--username' in serr)
-        self.assertTrue('secret' not in serr)
+        self.assertTrue(b'-u' in serr)
-        'md5': '2985e6d7a392b2f7a05e0ca350fe41d0',
+        'url': 'http://www.expotv.com/videos/reviews/3/40/NYX-Butter-lipstick/667916',
-            'id': '17561',
+            'id': '667916',
-            'uploader': 'Anna T.',
+            'title': 'NYX Butter Lipstick Little Susie',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            fatal=False))
+            fatal=False), day_first=False)
-    _TEST = {
+    _TESTS = [{
-    }
+        'skip': 'georestricted',
-        (final_url, thumbnail_url) = map(lambda x: x.split('=')[1], info_response.split('&'))
+        webpage = self._download_webpage(url, video_id)
-            'url': final_url,
+            'url': self._proto_relative_url(video_url, 'http:'),
-from ..compat import compat_HTTPError
+            # has undocumented http formats(4500k and 6500k)
-                # extract only the formats that we know that they will be available as http format.
+                # lower qualities(150k and 192k) are not available as http formats
-                if not self._is_valid_url(f_url, display_id, 'http-%s video' % bitrate):
+                if not self._is_valid_url(f_url, display_id, 'http-%sk video' % bitrate):
-    _VALID_URL = r'https?://(?:www\.)?24video\.net/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?24video\.(?:net|me|xxx)/(?:video/(?:view|xml)/|player/new24_play\.swf\?id=)(?P<id>\d+)'
-            },
+    _TESTS = [{
-    ]
+    }, {
-            r'(?s)\nplaylist:\s*(\[.*?}\]),related:',
+            r'(?s)\nplaylist:\s*(\[.*?}\]),',
-            r'<div class="comments-title" id="comments-count">(\d+) ÐºÐ¾Ð¼Ð¼ÐµÐ½ÑÐ°ÑÐ¸',
+            r'<a[^>]+href="#tab-comments"[^>]*>(\d+) ÐºÐ¾Ð¼Ð¼ÐµÐ½ÑÐ°ÑÐ¸',
-    _TEST = {
+    _VALID_URL = r'https?://(?:(?:www\.)?sunporno\.com/videos|embeds\.sunporno\.com/embed)/(?P<id>\d+)'
-    }
+    }, {
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-        'md5': '6457d3c165fd6de062b99ef6c2ff4c86',
+        'md5': '507887e29033502f29dba69affeebfc9',
-            'ext': 'flv',
+            'ext': 'mp4',
-            r'itemprop="duration">\s*(\d+:\d+)\s*<',
+            (r'itemprop="duration"[^>]*>\s*(\d+:\d+)\s*<',
-            webpage, 'comment count', fatal=False))
+            webpage, 'comment count', fatal=False, default=None))
-                bitrate = self._search_regex(r'(\d+k)', m3u8_format['url'], 'bitrate', default=None)
+                bitrate = self._search_regex(r'(\d+)k', m3u8_format['url'], 'bitrate', default=None)
-                if not bitrate or bitrate not in ('400k', '800k', '1200k', '2500k'):
+                if not bitrate or int(bitrate) < 400:
-                f_url = re.sub(r'\d+k|baseline', bitrate, http_url)
+                f_url = re.sub(r'\d+k|baseline', bitrate + 'k', http_url)
-            if not video_url or not video_play_path:
+            if not video_url:
-                    path='%s/%s' % (remove_end(parsed_video_url.path, '/'), video_play_path.split(':')[-1])))
+                    path='%s/%s' % (remove_end(parsed_video_url.path, '/'), video_file.split(':')[-1])))
-                'play_path': video_play_path,
+                'play_path': video_file,
-__version__ = '2016.08.10'
+__version__ = '2016.08.12'
-from .goldenmoustache import GoldenMoustacheIE
+from .viu import ViuIE
-            [r'<p[^>]+class="title_substrate">([^<]+)</p>', r'<title>([^<]+) - \d+'],
+            (r'class="title_watch"[^>]*><p>([^<]+)<',
-from ..utils import str_to_int
+from ..utils import (
-        def extract_count(id_, name):
+        def extract_count(id_, name, default=NO_DEFAULT):
-                webpage, '%s count' % name, fatal=False))
+                webpage, '%s count' % name, default=default, fatal=False))
-        dislike_count = extract_count('rate_dislikes', 'dislike')
+        dislike_count = extract_count('rate_dislikes', 'dislike', default=None)
-        categories = [] if not cats_str else re.findall(r'<a title="([^"]+)"', cats_str)
+            r'<div[^>]+class="categories_list">(.+?)</div>',
-)
+from ..utils import parse_duration
-        'md5': '9847b0dad6ac3e074568bf2cfb197de8',
+        'url': 'http://chirb.it/be2abG',
-            'id': 'PrIPv5',
+            'id': 'be2abG',
-            'comment_count': int,
+            'title': 'md5:f542ea253f5255240be4da375c6a5d7e',
-            r'"setFile"\s*,\s*"([^"]+)"', webpage, 'audio url')
+        data_fd = self._search_regex(
-            'comment count', fatal=False))
+            r'class=["\']chirbit-title["\'][^>]*>([^<]+)', webpage, 'title')
-    _VALID_URL = r'https?://(?:www|mobile|france3-regions)\.francetvinfo\.fr/.*/(?P<title>.+)\.html'
+    _VALID_URL = r'https?://(?:www|mobile|france3-regions)\.francetvinfo\.fr/(?:[^/]+/)*(?P<title>[^/?#&.]+)'
-                        with io.open(encodeFilename(sub_filename), 'w', encoding='utf-8') as subfile:
+                        with io.open(encodeFilename(sub_filename), 'w', encoding='utf-8', newline='') as subfile:
-            rtlxl\.nl/\#!/[^/]+/|
+            rtlxl\.nl/[^\#]*\#!/[^/]+/|
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?formula1\.com/(?:content/fom-website/)?en/video/\d{4}/\d{1,2}/(?P<id>.+?)\.html'
-    }
+    }, {
-            'md5': 'fbc84e4378165278e743956d9c1bf16b',
+            'md5': '34bdfa5ca9fd3c7eb88601b635b0424c',
-            'skip': "Ce contenu n'est pas disponible pour l'instant.",
+            'expected_warnings': ["Ce contenu n'est pas disponible pour l'instant."],
-            'http://www.wat.tv/interface/contentv3/' + video_id, video_id)['media']
+        video_data = self._download_json(
-                '%s returned error: %s' % (self.IE_NAME, error_desc), expected=True)
+            self.report_warning(
-        first_chapter = chapters[0]
+        if chapters:
-            return chapter['tc_start'].split('-')[0]
+            def video_id_for_chapter(chapter):
-        # the video id for getting the video url
+            if video_id_for_chapter(first_chapter) != video_id:
-        upload_date = unified_strdate(date_diffusion) if date_diffusion else None
+        title = first_chapter['title']
-        self._sort_formats(formats)
+        try:
-            'view_count': video_info['views'],
+            'title': title,
-            'duration': video_info['files'][0]['duration'],
+            'duration': duration,
-# -*- coding: utf-8 -*-
+# coding: utf-8
-from ..utils import parse_iso8601, ExtractorError
+from ..utils import unified_timestamp
-            'description': 'md5:95e9b295c898b7ff294f09d450178d7d',
+            'description': 'ä»¥è²ååé»å·´å«©çä¸»é»¨ï¼çç¼äºå¹´æå´éè¡çªï¼éæ¹ç ²è½äº¤ç«ï¼å©åä»¥è»æ­»äº¡ï¼éæä¸åè¥¿ç­çç±çè¯ååç¶­åäºº...',
-            'description': 'md5:f183feeba3752b683827aab71adad584',
+            'description': 'è¶æå¹´ç´çäººï¼è¶å¸æçèµ·ä¾å¹´è¼ä¸é»ï¼èåéå»æä¸ä½31æ­²çç·å­ï¼çèµ·ä¾åæ¯11ã12æ­²çå°å­©ï¼èº«...',
-        'add_ie': ['Youtube'],
+        'md5': 'e4726b2ccd70ba2c319865e28f0a91d1',
-        }
+        },
-                feed_url, news_id, note='Fetching feed')
+        news_id = self._hidden_inputs(page).get('get_id')
-                raise ExtractorError('The news includes no videos!', expected=True)
+                r'src="(//www\.youtube\.com/embed/[^"]+)"', page, 'youtube url')
-            }
+            return self.url_result(youtube_url, ie='Youtube')
-        title = self._html_search_meta('title', page)
+        title = self._html_search_meta('title', page, fatal=True)
-        timestamp = parse_iso8601(datetime_str, delimiter=' ')
+            r'(\d{4}/\d{2}/\d{2} \d{2}:\d{2})', page, 'date and time', fatal=False)
-__version__ = '2016.08.07'
+__version__ = '2016.08.10'
-                ret += line.lstrip() + '\n'
+                split = re.split(r'\s{2,}', line.lstrip())
-
+from .uol import UOLIE
-            raise MetadataFromTitlePPError('Could not interpret title of video as "%s"' % self._titleformat)
+            self._downloader.to_screen('[fromtitle] Could not interpret title of video as "%s"' % self._titleformat)
-                parser.error('max sleep interval should not be less than sleep interval')
+            parser.error('sleep interval must be positive or 0')
-            sleep_interval = random.uniform(sleep_lower_bound, sleep_upper_bound)
+        min_sleep_interval = self.params.get('sleep_interval')
-                       or --sleep-interval, otherwise ignored.
+    sleep_interval:    Number of seconds to sleep before each download when
-    )
+        help=(
-    )
+        help=(
-    sleep_interval:    Number of seconds to sleep before each download.
+    sleep_interval:    Minimum number of seconds to sleep before each download.
-        if sleep_interval:
+        sleep_lower_bound = self.params.get('sleep_interval')
-        '--sleep-interval', metavar='SECONDS',
+        '--sleep-interval', '--min-sleep-interval', metavar='SECONDS',
-        help='Number of seconds to sleep before each download.')
+        help='Minimum number of seconds to sleep before each download. Sleep will be for a random interval if '
-# encoding: utf-8
+import re
-    clean_html
+    clean_html,
-    _VALID_URL = r'https?://(?:www\.)?rbmaradio\.com/shows/[^/]+/episodes/(?P<id>[^/]+)$'
+    _VALID_URL = r'https?://(?:www\.)?rbmaradio\.com/shows/(?P<show_id>[^/]+)/episodes/(?P<id>[^/?#&]+)'
-            'title': 'Ford & Lopatin - Main Stage',
+            'title': 'Main Stage - Ford & Lopatin',
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        data = self._parse_json(json_data, video_id)
+        show_title = episode.get('showTitle')
-                item = items[video_id]
+        formats = [{
-        video_url = item['audioURL'] + '?cbr=256'
+        description = clean_html(episode.get('longTeaser'))
-            'duration': item.get('duration'),
+            'id': episode_id,
-    ExtractorError,
+    clean_html
-    _VALID_URL = r'https?://(?:www\.)?rbmaradio\.com/shows/(?P<videoID>[^/]+)$'
+    _VALID_URL = r'https?://(?:www\.)?rbmaradio\.com/shows/[^/]+/episodes/(?P<id>[^/]+)$'
-        'url': 'http://www.rbmaradio.com/shows/ford-lopatin-live-at-primavera-sound-2011',
+        'url': 'https://www.rbmaradio.com/shows/main-stage/episodes/ford-lopatin-live-at-primavera-sound-2011',
-            'title': 'Live at Primavera Sound 2011',
+            'title': 'Ford & Lopatin - Main Stage',
-        video_id = m.group('videoID')
+        video_id = self._match_id(url)
-            raise ExtractorError('Invalid JSON: ' + str(e))
+        item = None
-        video_url = data['akamai_url'] + '&cbr=256'
+        video_url = item['audioURL'] + '?cbr=256'
-            'duration': data.get('duration'),
+            'title': item.get('title') + ' - ' + item.get('showTitle'),
-        'url': 'http://www.sonyliv.com/details/episodes/5024612095001/Ep.-1---Achaari-Cheese-Toast---Bachelor\'s-Delight',
+    _VALID_URL = r'https?://(?:www\.)?sonyliv\.com/details/[^/]+/(?P<id>\d+)'
-            'title': 'Ep. 1 - Achaari Cheese Toast - Bachelor\'s Delight',
+            'title': "Ep. 1 - Achaari Cheese Toast - Bachelor's Delight",
-            'description': 'Bachelor\'s Delight is a new food show from Sony LIV to satisfy the taste buds of all those bachelors looking for a quick bite.',
+            'description': 'md5:7f28509a148d5be9d0782b4d5106410d',
-    }
+    }, {
-        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % self._match_id(url), 'BrightcoveNew')
+        brightcove_id = self._match_id(url)
-        if json_ld and json_ld.get('url'):
+            webpage, video_id, default={}, expected_type='VideoObject')
-        json_ld = self._search_json_ld(webpage, video_id, default=False)
+        json_ld = self._search_json_ld(webpage, video_id, default={})
-        info = self._search_json_ld(webpage, video_id) if url_type != 'embed' else {}
+        info = self._search_json_ld(
-        json_ld_info = self._search_json_ld(webpage, playlist_id, default=None)
+        json_ld_info = self._search_json_ld(webpage, playlist_id, default={})
-            expected_type=expected_type)
+            return default if default is not NO_DEFAULT else {}
-        json_ld = self._search_json_ld(webpage, video_id, fatal=False)
+        json_ld = self._search_json_ld(webpage, video_id, default=False)
-            webpage, video_id, fatal=False, expected_type='VideoObject')
+            webpage, video_id, default=None, expected_type='VideoObject')
-        }
+        },
-        }
+        },
-        'md5': '6714e0af7e0d875c5a39c4dc4ab46ad1',
+        'md5': '131aca2e14fe7c4dcb3c4877ba300c89',
-                     video_id + '/vt/frame')
+        embed_url = 'http://www.aparat.com/video/video/embed/vt/frame/showvideo/yes/videohash/' + video_id
-        for i, video_url in enumerate(video_urls):
+        file_list = self._parse_json(self._search_regex(
-        'md5': '5f7d29e1a2872f3df0cf76b1f87d3788',
+        'md5': '9fa226fe2b8a9a4d5a69b4c6a183417e',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'duration': 308.067,
+            'duration': 308.315,
-            'id': '1041170',
+            'id': '1507019',
-            'id': '4808130',
+            'id': '7802182',
-            'ext': 'flv',
+            'ext': 'mp4',
-        }
+        },
-            video_data['videos']['variantplaylist']['uri'], video_id, 'mp4')
+        video_data = None
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        description = self._html_search_regex(r'<p title="(.+?)">', webpage, 'description', fatal=False)
+        webpage = self._download_webpage(
-        url = 'http://media.rozhlas.cz/_audio/' + audio_id + '.mp3'
+        title = self._html_search_regex(
-            'url': url,
+            'url': 'http://media.rozhlas.cz/_audio/%s.mp3' % audio_id,
-                    r'<div[^>]+class="name"><a[^>]+href="(http://www\.kuwo\.cn/yinyue/\d+)',
+                self.url_result(compat_urlparse.urljoin(url, song_url), 'Kuwo')
-__version__ = '2016.08.06'
+__version__ = '2016.08.07'
-    if s is None:
+    if type(s) == int:
-    return int(m.group('age')) if m else US_RATINGS.get(s)
+    if m:
-        json_ld = self._search_json_ld(webpage, video_id, default=False)
+        json_ld = self._search_json_ld(webpage, video_id, fatal=False)
-            webpage, video_id, default=None, expected_type='VideoObject')
+            webpage, video_id, fatal=False, expected_type='VideoObject')
-                            format_id += '-%d' %  bitrate
+                            format_id += '-%d' % bitrate
-                [self.url_result(entry, 'BBCCoUk') for entry in entries],
+                [self.url_result(entry_, 'BBCCoUk') for entry_ in entries],
-                        if bitrate:
+                        if not service and not supplier and bitrate:
-            'preference': -100,
+            'preference': preference - 100 if preference else -100,
-            self._TITLE_REGEX, webpage, 'title') if self._TITLE_REGEX else self._og_search_title(webpage)
+        title = None
-    _UPLOADER_REGEX = r'<i>\s*Verified Member\s*</i>\s*<h1>(.+?)</h1>'
+    _TITLE_REGEX = r'<title>(.+?) - (?:TNAFlix Porn Videos|TNAFlix\.com)</title>'
-from ..utils import smuggle_url
+from ..utils import (
-            video_id)['release_url'] + '&switch=http'
+            video_id)['release_url']
-            'url': smuggle_url(release_url, {'force_smil_url': True}),
+            'url': smuggle_url(update_url_query(
-from __future__ import unicode_literals
+from __future__ import unicode_literals, division
-import re
+import math
-            r'return\s+"(https?://[^"]+)"', decoded, 'video URL')
+        # The following extraction logic is proposed by @Belderak and @gdkchan
-            'ext': ext,
+            # Seems all videos have extensions in their titles
-            'title': "Tel Abyad'da IÅÄ°D bayraÄÄ± indirildi YPG bayraÄÄ± Ã§ekildi",
+            'title': "YPG: Tel Abyad'Ä±n tamamÄ± kontrolÃ¼mÃ¼zde",
-                    href = connection.get('href')
+                        if bitrate:
-                    part_of_series = e.get('partOfSeries')
+                    part_of_series = e.get('partOfSeries') or e.get('partOfTVSeries')
-            'preference': preference - 1 if preference else -1,
+            'preference': -100,
-                formats.extend(self._extract_video(media, programme_id))
+            if kind in ('video', 'audio'):
-                            for key in ('progressiveDownload', 'streaming'):
+                            entry = None
-                                        playlist_url, playlist_id, timestamp))
+                                    info = self._extract_from_playlist_sxml(
-    _VALID_URL = r'https?://(?:www\.)?pokemon\.com/[a-z]{2}(?:.*?play=(?P<id>[a-z0-9]{32})|/pokemon-episodes/(?P<display_id>[^/?#]+))'
+    _VALID_URL = r'https?://(?:www\.)?pokemon\.com/[a-z]{2}(?:.*?play=(?P<id>[a-z0-9]{32})|/[^/]+/\d+_\d+-(?P<display_id>[^/?#]+))'
-            r'loadCallback\(({.+})\)', info_page, 'video info'), video_id)['video']
+            video_id, 'Downloading video info', query=query, fatal=False)
-__version__ = '2016.08.01'
+__version__ = '2016.08.06'
-        'md5': '33e9a5d8f646523ce0868ecfb0eed77d',
+    }, {
-                    raise ExtractorError('Unable to find video info')
+            if not video_info:
-            if not clips:
+            if stream and stream.get('videoPlaybackID'):
-        return info
+        return info
-                })
+        if not isinstance(json_ld, (list, tuple, dict)):
-            'http://playapi.mtgx.tv/v1/videos/stream/%s' % video_id, video_id, 'Downloading streams JSON')
+        try:
-from ..utils import unified_strdate
+from .jwplatform import JWPlatformBaseIE
-class ArchiveOrgIE(InfoExtractor):
+class ArchiveOrgIE(JWPlatformBaseIE):
-    _VALID_URL = r'https?://(?:www\.)?archive\.org/details/(?P<id>[^?/]+)(?:[?].*)?$'
+    _VALID_URL = r'https?://(?:www\.)?archive\.org/(?:details|embed)/(?P<id>[^/?#]+)(?:[?].*)?$'
-            'ext': 'ogv',
+            'ext': 'ogg',
-            'description': 'md5:1780b464abaca9991d8968c877bb53ed',
+            'description': 'md5:da45c349df039f1cc8075268eb1b5c25',
-        'md5': '18f2a19e6d89af8425671da1cf3d4e04',
+        'md5': 'bc73c8ab3838b5a8fc6c6651fa7b58ba',
-            'ext': 'ogv',
+            'ext': 'mp4',
-            'description': 'md5:70f72ee70882f713d4578725461ffcc3',
+            'description': 'md5:b4544662605877edd99df22f9620d858',
-        upload_date = unified_strdate(get_optional(data, 'date'))
+        def get_optional(metadata, field):
-        }
+        metadata = self._download_json(
-    def _parse_jwplayer_data(self, jwplayer_data, video_id, require_title=True, m3u8_id=None, rtmp_params=None):
+    def _parse_jwplayer_data(self, jwplayer_data, video_id, require_title=True, m3u8_id=None, rtmp_params=None, base_url=None):
-                        'url': self._proto_relative_url(track['file'])
+        entries = []
-        }
+            entries.append({
-from ..compat import compat_str
+from ..compat import (
-                    m = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', video_url)
+                    m = re.search(
-    _VALID_URL = r'(?:5min:|https?://(?:[^/]*?5min\.com|delivery\.vidible\.tv/aol)/(?:(?:Scripts/PlayerSeed\.js|playerseed/?)?\?.*?playList=)?)(?P<id>\d+)'
+    _VALID_URL = r'(?:5min:|https?://(?:[^/]*?5min\.com/|delivery\.vidible\.tv/aol)(?:(?:Scripts/PlayerSeed\.js|playerseed/?)?\?.*?playList=)?)(?P<id>\d+)'
-                'id': 'nB5vIAfmyllm',
+                'id': 'vKInpacll2pC',
-                'id': '3TmMv9OvGwIR',
+                'id': 'Pok5lWCkiEFA',
-        })
+        video_data = self._download_json(
-
+from ..utils import unified_timestamp
-                time_str, '%b %d, %Y %I:%M %p').timetuple())
+        timestamp = unified_timestamp(time_str)
-    pm_delta = datetime.timedelta(hours=12 if re.search(r'(?i)PM', date_str) else 0)
+    pm_delta = 12 if re.search(r'(?i)PM', date_str) else 0
-            dt = datetime.datetime.strptime(date_str, expression) - timezone + pm_delta
+            dt = datetime.datetime.strptime(date_str, expression) - timezone + datetime.timedelta(hours=pm_delta)
-        return calendar.timegm(timetuple.timetuple())
+        return calendar.timegm(timetuple) + pm_delta * 3600
-)
+    int_or_none,
-            'inKey': key,
+        video_data = self._download_json('http://play.rmcnmv.naver.com/vod/play/v2.0/' + m_id.group(1), video_id, query={
-
+        meta = video_data['meta']
-                    'rtmp_protocol': '1',  # rtmpt
+
-            formats.append(f)
+
-            'title': info.find('Subject').text,
+            'title': title,
-            'view_count': int(info.find('PlayCount').text),
+            'thumbnail': meta.get('cover', {}).get('source') or self._og_search_thumbnail(webpage),
-    compat_urllib_parse_urlencode,
+    extract_attributes,
-                                        webpage, 'series title', flags=re.DOTALL)
+        title = self._html_search_regex(
-                              webpage, flags=re.DOTALL)
+        m_paths = re.finditer(
-                webpage, 'description', fatal=False, flags=re.DOTALL)
+        query = {}
-        } for fdata in video_info['sources'][0]]
+            params = extract_attributes(self._search_regex(
-        return {
+        info = self._search_json_ld(webpage, video_id) if url_type != 'embed' else {}
-        }
+            'title': title,
-        item_id = mobj.group('id')
+        site, url_type, item_id = re.match(self._VALID_URL, url).groups()
-            for url in re.findall('(?s)<div[^>]+class="col-inner"[^>]*?>.*?<a[^>]+href="([^"]+)"', webpage)]
+            self.url_result(self._proto_relative_url(entry_url), 'NationalGeographic')
-    _VALID_URL = r'(?:5min:|(?:https?://(?:[^/]*?5min\.com|delivery\.vidible\.tv/aol)/(?:(?:Scripts/PlayerSeed\.js|playerseed/?)?\?.*?playList=)?)(?P<id>\d+)'
+    _VALID_URL = r'(?:5min:|https?://(?:[^/]*?5min\.com|delivery\.vidible\.tv/aol)/(?:(?:Scripts/PlayerSeed\.js|playerseed/?)?\?.*?playList=)?)(?P<id>\d+)'
-    _VALID_URL = r'https?://www.engadget.com/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://www.engadget.com/video/(?P<id>[^/?#]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        return self.url_result('5min:%s' % video_id)
+        return self.url_result('aol-video:%s' % video_id)
-    _VALID_URL = r'(?:5min:(?P<id>\d+)(?::(?P<sid>\d+))?|https?://[^/]*?5min\.com/Scripts/PlayerSeed\.js\?(?P<query>.*))'
+    _VALID_URL = r'(?:5min:|(?:https?://(?:[^/]*?5min\.com|delivery\.vidible\.tv/aol)/(?:(?:Scripts/PlayerSeed\.js|playerseed/?)?\?.*?playList=)?)(?P<id>\d+)'
-            'height': 360,
+        {
-    }
+        {
-        }
+        video_id = self._match_id(url)
-                print(caption)
+    NationalGeographicVideoIE,
-    NationalGeographicChannelIE,
+    NationalGeographicEpisodeGuideIE,
-    IE_NAME = 'natgeo'
+class NationalGeographicVideoIE(InfoExtractor):
-    _VALID_URL = r'https?://channel\.nationalgeographic\.com/(?:wild/)?[^/]+/videos/(?P<id>[^/?]+)'
+class NationalGeographicIE(ThePlatformIE):
-                'ks': signature,
+            },
-                'version': '-1',
+                'ks': '{1:result:ks}',
-            info, flavor_assets = self._get_video_info(entry_id, partner_id, smuggled_data.get('service_url'))
+            _, info, flavor_assets, captions = self._get_video_info(entry_id, partner_id, smuggled_data.get('service_url'))
-                info, flavor_assets = self._get_video_info(entry_id, partner_id)
+                _, info, flavor_assets, captions = self._get_video_info(entry_id, partner_id)
-            if f['status'] != 2:
+            if f.get('status') != 2:
-        self._check_formats(formats, entry_id)
+        subtitles = {}
-            proto_preference = 0 if determine_protocol(f) in ['http', 'https'] else -0.1
+            protocol = f.get('protocol') or determine_protocol(f)
-                rtmp = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', stream_url)
+                rtmp = re.search(r'^(?P<url>rtmpe?://(?P<host>[^/]+)/(?P<app>.+))/(?P<playpath>mp4:.+)$', stream_url)
-            'ext': 'flv',
+            'ext': 'mp4',
-    _VALID_URL = r'https?://(?:www\.)?ntv\.ru/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?ntv\.ru/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-            },
+    _TESTS = [{
-            },
+    }, {
-            },
+    }, {
-            },
+    }, {
-            },
+    }, {
-    ]
+    }]
-        video_id = self._html_search_regex(self._VIDEO_ID_REGEXES, webpage, 'video id')
+        video_url = self._og_search_property(
-        escaped = self._search_regex(self._og_regexes(prop), html, name, flags=re.DOTALL, **kargs)
+            name = 'OpenGraph %s' % prop[0]
-        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:
+        PRIVATE_OPTS = ['-p', '--password', '-u', '--username', '--video-password']
-__version__ = '2016.07.30'
+__version__ = '2016.08.01'
-    _VALID_URL = r'https?://(?:www\.)?cw(?:tv|seed)\.com/(?:shows/)?(?:[^/]+/){2}\?.*\bplay=(?P<id>[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12})'
+    _VALID_URL = r'https?://(?:www\.)?cw(?:tv(?:pr)?|seed)\.com/(?:shows/)?(?:[^/]+/)+[^?]*\?.*\b(?:play|watch)=(?P<id>[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12})'
-            if not stream_url or stream.get('previewStream') or stream.get('drmProtected'):
+            if not stream_url or stream.get('drmProtected'):
-            # m3u8 download
+            # rtmp download
-    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/library/view/[^/]+/(?P<course_id>[^/]+)/(?P<part>part\d+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/library/view/[^/]+/(?P<course_id>[^/]+)/(?P<part>[^/?#&]+)\.html'
-    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/api/v1/book/(?P<course_id>[^/]+)/chapter(?:-content)?/(?P<part>part\d+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/api/v1/book/(?P<course_id>[^/]+)/chapter(?:-content)?/(?P<part>[^/?#&]+)\.html'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            if not stream_url:
+            if not stream_url or stream.get('previewStream') or stream.get('drmProtected'):
-            if '.f4m' in stream_url:
+            ext = determine_ext(stream_url)
-                    stream_url, video_id, fatal=False))
+                    stream_url, video_id, f4m_id='hds', fatal=False))
-                    'ext': determine_ext(stream_url)
+                    'ext': ext,
-            if determine_ext(media_url) == 'm3u8':
+            if not media_url or format_id == 'Widevine':
-            'ext': 'flv',
+            'ext': 'mp4',
-            # rtmp download
+            # m3u8 download
-            # rtmp download
+            # m3u8 download
-            webpage, 'id', group='url')
+            webpage, 'id', group='url', default=None)
-__version__ = '2016.07.28'
+__version__ = '2016.07.30'
-                    yield self.url_result('http://www.dailymotion.com/video/%s' % video_id, 'Dailymotion', video_id)
+                    yield self.url_result(
-                    yield self.url_result('http://www.dailymotion.com/video/%s' % video_id, 'Dailymotion')
+                    yield self.url_result('http://www.dailymotion.com/video/%s' % video_id, 'Dailymotion', video_id)
-            ).replace('.net.rtve', '.multimedia.cdn.rtve')
+            if '?' not in video_url:
-            video_url = video_url.replace('.net.rtve', '.multimedia.cdn.rtve')
+            video_url = video_url.replace(
-                        video_url, video_id, f4m_id=format_id))
+                        video_url, video_id, f4m_id=format_id, fatal=False))
-                        video_url, video_id, 'mp4', m3u8_id=format_id))
+                        video_url, video_id, 'mp4', entry_protocol='m3u8_native',
-            'title': 'Russen hetses etter pingvintyveri â innrÃ¸mmer Ã¥ ha Ã¥pnet luken pÃ¥ buret',
+            'title': 'Russen hetses etter pingvintyveri - innrÃ¸mmer Ã¥ ha Ã¥pnet luken pÃ¥ buret',
-            for video_id in re.findall(r'data-assetid="(\d+)"', webpage)]
+            self.url_result('http://www.tv2.no/v/%s' % asset_id, 'TV2')
-__version__ = '2016.07.26.2'
+__version__ = '2016.07.28'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        title = clip['channel_title']
+        title = clip.get('channel_title') or self._og_search_title(webpage)
-            'url': video_url,
+            'formats': formats,
-            return self.url_result(url)
+        soundcloud_urls = SoundcloudIE._extract_urls(webpage)
-            request, video_id, 'Downloading video page')
+            urlh.geturl(), video_id, 'Downloading video page',
-            r'data-url="([^"]+)"', video_page, 'video URL')
+            r'data-url=(["\'])(?P<url>(?:(?!\1).)+)\1',
-            r'data-poster="([^"]+)"', video_page, 'thumbnail', default=None)
+            r'data-poster=(["\'])(?P<url>(?:(?!\1).)+)\1',
-        webpage = self._download_webpage(url, video_id)
+
-            url, urlencode_postdata(download_form))
+            urlh.geturl(), urlencode_postdata(download_form))
-            % (asset_name, format_size(asset['size']), asset['download_count']))
+for page in itertools.count(1):
-__version__ = '2016.07.24'
+__version__ = '2016.07.26.2'
-            if 'playlist' in tc:
+            if tc.get('playlist', []):
-    _VALID_URL = r'https?://oe1\.orf\.at/(?:programm/|konsole.*?#\?track_id=)(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://oe1\.orf\.at/(?:programm/|konsole\?.*?\btrack_id=)(?P<id>[0-9]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                    'http://tpfeed.cbc.ca/f/ExhSPC/vms_5akSXx4Ng_Zn?byCustomValue={:mpsReleases}{%s}'% clip_id,
+                    'http://tpfeed.cbc.ca/f/ExhSPC/vms_5akSXx4Ng_Zn?byCustomValue={:mpsReleases}{%s}' % clip_id,
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                    note='Download video info for format %s' % format_id or '#%d' % idx, query=query)
+                    note='Download video info for format %s' % (format_id or '#%d' % idx),
-        # with clipId
+        # with clipId, feed available via tpfeed.cbc.ca and feed.theplatform.com
-                    clip_id)['entries'][0]['id'].split('/')[-1]
+                feed = self._download_json(
-        'md5': 'ec76aa9b1129e2e5b301a474e54fab74',
+        'md5': 'dc1b4aebb46e3a7077ecc0d9f43f61e3',
-            'description': 'md5:63b9b8ed79189c6f0418c26d9a3452ca',
+            'description': 'md5:9f0470b26a4ba8e824c823b5d95c2f6b',
-                    'format_id': '-'.join([kind, rendition.get('bitrate')]),
+                    'format_id': '-'.join(filter(None, [kind, rendition.get('bitrate')])),
-    ComedyCentralShowsIE,
+    ToshIE,
-                'title': 'ÐÐµÑÑÐ¸ Ð­ÐºÐ¾Ð½Ð¾Ð¼Ð¸ÐºÐ° â ÐÑÑÐ¼ÑÐµ ÑÑÐ°Ð½ÑÐ»ÑÑÐ¸Ð¸ Ñ Ð¤Ð¾ÑÑÐ¼Ð°-Ð²ÑÑÑÐ°Ð²ÐºÐ¸ "ÐÐ¾ÑÐ·Ð°ÐºÐ°Ð·-2013"',
+                'title': 'ÐÑÑÐ¼ÑÐµ ÑÑÐ°Ð½ÑÐ»ÑÑÐ¸Ð¸ Ñ Ð¤Ð¾ÑÑÐ¼Ð°-Ð²ÑÑÑÐ°Ð²ÐºÐ¸ "ÐÐ¾ÑÐ·Ð°ÐºÐ°Ð·-2013"',
-            'title': 'The Government Won\'t Respect My Privacy',
+            'title': 'South Park|The Government Won\'t Respect My Privacy',
-        'playlist_count': 4,
+        'info_dict': {
-        'playlist_count': 4,
+        'info_dict': {
-        'playlist_count': 4,
+        'info_dict': {
-        'playlist_count': 4,
+        'info_dict': {
-            'title': 'Auction Hunters|Can Allen Ride A Hundred Year-Old Motorcycle?',
+            'title': 'Auction Hunters|December 27, 2013|4|414|Can Allen Ride A Hundred Year-Old Motorcycle?',
-        ],
+        'info_dict': {
-            'description': 'md5:7d192f56ca8d958645c83f0de8ef0269'
+            'title': 'Younger|December 28, 2015|2|NO-EPISODE#|Younger: Hilary Duff - Little Lies',
-            'title': 'CC:Stand-Up|Greg Fitzsimmons: Life on Stage|Uncensored - Too Good of a Mother',
+            'title': 'CC:Stand-Up|August 18, 2013|1|0101|Uncensored - Too Good of a Mother',
-                     '''
+class ToshIE(MTVServicesInfoExtractor):
-        'url': 'http://thedailyshow.cc.com/extended-interviews/b6364d/sarah-chayes-extended-interview',
+        'url': 'http://tosh.cc.com/video-clips/68g93d/twitter-users-share-summer-plans',
-            'title': 'thedailyshow Sarah Chayes Extended Interview',
+            'description': 'Tosh asked fans to share their summer plans.',
-                    'title': 'thedailyshow sarah-chayes-extended-interview part 1',
+        'playlist': [{
-        'only_matching': True,
+        }]
-        'url': 'http://tosh.cc.com/video-clips/68g93d/twitter-users-share-summer-plans',
+        'url': 'http://tosh.cc.com/video-collections/x2iz7k/just-plain-foul/m5q4fp',
-        }
+    @classmethod
-    def _transform_rtmp_url(rtmp_video_url):
+    @classmethod
-            return rtmp_video_url
+            return {'rtmp': rtmp_video_url}
-        return base + m.group('finalid')
+        return {'http': base + m.group('finalid')}
-                formats.append({
+                new_urls = self._transform_rtmp_url(rtmp_video_url)
-                    'format_id': rendition.get('bitrate'),
+                    'format_id': '-'.join([kind, rendition.get('bitrate')]),
-                })
+                } for kind, new_url in new_urls.items()])
-            [self._get_video_info(item) for item in idoc.findall('.//item')])
+            [self._get_video_info(item) for item in idoc.findall('.//item')],
-            'ext': 'mp4',
+            'ext': 'flv',
-            'ext': 'mp4',
+            'ext': 'flv',
-        # single video in pagePlaylist with different id
+        'skip': 'Das Video kann zur Zeit nicht abgespielt werden.',
-            return self._get_videos_info_from_url(playlist[0]['mrss'], video_id)
+            return self._get_videos_info_from_url(_mrss_url(playlist[0]), video_id)
-                return self._get_videos_info_from_url(item['mrss'], video_id)
+                return self._get_videos_info_from_url(_mrss_url(item), video_id)
-            'title': oembed_obj['title'],
+            'title': title,
-            'duration': oembed_obj['duration'],
+            'creator': oembed_obj.get('author_name'),
-    parse_iso8601,
+    clean_html,
-            'timestamp': 1358154556,
+        # webpage returns "No permission or not login"
-            'description': 'md5:050b62f71ed62928f8a35f1a41e186c9',
+            'description': 'md5:2a9f989c2b153a2342acee579c6e7db6',
-        # External source
+        # External source (YouTube)
-        'md5': '50e1c3c3aa233d3d7b7daa2fa10b1cf7',
+            'title': 'Excel 2013 Tutorial - How to add Password Protection',
-        }
+        },
-        page = self._download_webpage(url, video_id)
+
-            'external source', default=None)
+            r"class=['\"]srcFrom['\"][^>]*>Sources?(?:\s+from)?\s*:\s*<a[^>]+(?:href|title)=(['\"])(?P<url>(?:(?!\1).)+)\1",
-            video_id, 'Filelist XML')
+            video_id, 'Downloading filelist XML')
-            page, 'view count', fatal=False))
+        # Some URLs return "No permission or not login" in a webpage despite being
-            'description': self._html_search_meta('description', page),
+            'description': description,
-            'timestamp': timestamp,
+            'upload_date': upload_date,
-    _VALID_URL = r'^https?://(?:www\.)?(?:smotri\.com/video/view/\?id=|pics\.smotri\.com/(?:player|scrubber_custom8)\.swf\?file=)(?P<id>v(?P<realvideoid>[0-9]+)[a-z0-9]{4})'
+    _VALID_URL = r'https?://(?:www\.)?(?:smotri\.com/video/view/\?id=|pics\.smotri\.com/(?:player|scrubber_custom8)\.swf\?file=)(?P<id>v(?P<realvideoid>[0-9]+)[a-z0-9]{4})'
-            'md5': '2a7b08249e6f5636557579c368040eb9',
+            'md5': '02c0dfab2102984e9c5bb585cc7cc321',
-        video = self._download_json(request, video_id, 'Downloading video JSON')
+        video = self._download_json(
-        duration = int_or_none(video['duration'])
+        thumbnail = video.get('_imgURL')
-            r'<div class="videoUnModer">(.*?)</div>', webpage,
+            r'<div[^>]+class="videoUnModer"[^>]*>(.+?)</div>', webpage,
-        if re.search('EroConfirmText">', webpage) is not None:
+        if 'EroConfirmText">' in webpage:
-                r'<a href="/video/view/\?id=%s&confirm=([^"]+)" title="[^"]+">' % video_id,
+                r'<a[^>]+href="/video/view/\?id=%s&confirm=([^"]+)"' % video_id,
-            webpage = self._download_webpage(confirm_url, video_id, 'Downloading video page (age confirmed)')
+            webpage = self._download_webpage(
-            webpage, 'view count', fatal=False, flags=re.MULTILINE | re.DOTALL)
+            r'(?s)ÐÐ±ÑÐµÐµ ÐºÐ¾Ð»Ð¸ÑÐµÑÑÐ²Ð¾ Ð¿ÑÐ¾ÑÐ¼Ð¾ÑÑÐ¾Ð².*?<span class="Number">(\d+)</span>',
-    _VALID_URL = r'^https?://(?:www\.)?smotri\.com/community/video/(?P<communityid>[0-9A-Za-z_\'-]+)'
+    _VALID_URL = r'https?://(?:www\.)?smotri\.com/community/video/(?P<id>[0-9A-Za-z_\'-]+)'
-        community_id = mobj.group('communityid')
+        community_id = self._match_id(url)
-        rss = self._download_xml(url, community_id, 'Downloading community RSS')
+        rss = self._download_xml(
-                   for video_url in rss.findall('./channel/item/link')]
+        entries = [
-        return self.playlist_result(entries, community_id, community_title)
+        return self.playlist_result(entries, community_id)
-    _VALID_URL = r'^https?://(?:www\.)?smotri\.com/user/(?P<userid>[0-9A-Za-z_\'-]+)'
+    _VALID_URL = r'https?://(?:www\.)?smotri\.com/user/(?P<id>[0-9A-Za-z_\'-]+)'
-        user_id = mobj.group('userid')
+        user_id = self._match_id(url)
-        rss = self._download_xml(url, user_id, 'Downloading user RSS')
+        rss = self._download_xml(
-            'user nickname')
+        description_text = xpath_text(rss, './channel/description') or ''
-    _VALID_URL = r'^https?://(?:www\.)?(?P<url>smotri\.com/live/(?P<broadcastid>[^/]+))/?.*'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>smotri\.com/live/(?P<id>[^/]+))/?.*'
-        broadcast_id = mobj.group('broadcastid')
+        broadcast_id = mobj.group('id')
-                self.raise_login_required('Erotic broadcasts allowed only for registered users')
+                self.raise_login_required(
-                raise ExtractorError('Unable to log in: bad username or password', expected=True)
+            if '>ÐÐµÐ²ÐµÑÐ½ÑÐ¹ Ð»Ð¾Ð³Ð¸Ð½ Ð¸Ð»Ð¸ Ð¿Ð°ÑÐ¾Ð»Ñ<' in broadcast_page:
-            broadcast_thumbnail = broadcast_json['_imgURL']
+            broadcast_thumbnail = broadcast_json.get('_imgURL')
-            broadcaster_login = broadcast_json['login']
+            broadcast_description = broadcast_json.get('description')
-__version__ = '2016.07.22'
+__version__ = '2016.07.24'
-            # <SegmentTemplate> not implemented yet
+            # TODO: <Group> found instead of <AdaptationSet> in MPD manifest.
-                        continue
+                        formats.extend(self._extract_mpd_formats(
-        #     video_id, mpd_id='dash', fatal=False))
+        formats.extend(self._extract_mpd_formats(
-                    manifest_url, video_id, ext='mp4', m3u8_id='hls'))
+                    manifest_url, video_id, ext='mp4', m3u8_id='hls', fatal=False))
-                continue
+                formats.extend(self._extract_mpd_formats(
-                    continue
+                    formats.extend(self._extract_mpd_formats(
-                                ms_info['total_number'] += 1 + int(s.get('r', '0'))
+                                r = int(s.get('r', 0))
-                    # According to page 41 of ISO/IEC 29001-1:2014, @mimeType is mandatory
+                    # According to [1, 5.3.7.2, Table 9, page 41], @mimeType is mandatory
-                            media_template = re.sub(r'\$(Number|Bandwidth)%([^$]+)\$', r'%(\1)\2', media_template)
+                            media_template = re.sub(r'\$(Number|Bandwidth|Time)\$', r'%(\1)d', media_template)
-                                    representation_ms_info['total_number'] + representation_ms_info['start_number'])]
+
-        'md5': '2f639d446394f53f3a33658b518b6615',
+        'url': 'http://www.dailymail.co.uk/video/tvshowbiz/video-1295863/The-Mountain-appears-sparkling-water-ad-Heavy-Bubbles.html',
-            'id': '1288527',
+            'id': '1295863',
-            'description': 'md5:88ddbcb504367987b2708bb38677c9d2',
+            'title': 'The Mountain appears in sparkling water ad for \'Heavy Bubbles\'',
-        title = video_data['title']
+        title = unescapeHTML(video_data['title'])
-            'description': video_data.get('descr'),
+            'description': unescapeHTML(video_data.get('descr')),
-                        (?:\w+\.)?facebook\.com/
+                        (?:[\w-]+\.)?facebook\.com/
-                        f_url, video_id, mpd_id=kind, fatal=False))
+                    # TODO: Current DASH formats are broken - $Time$ pattern in
-                    pass
+                    continue
-        return formats
+from .arkena import ArkenaIE
-    _VALID_URL = r'https?://(?:www\.)?lcp\.fr/(?:[^\/]+/)*(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?lcp\.fr/(?:[^/]+/)*(?P<id>[^/]+)'
-        'md5': 'ab96c4dae94322ece1e98d97c8dc7807',
+        'md5': 'b8bd9298542929c06c1c15788b1f277a',
-            'title': 'd56d03e9',
+            'title': 'Schwartzenberg (PRG) prÃ©conise Ã  FranÃ§ois Hollande de participer Ã  une primaire Ã  gauche',
-        }
+        },
-            'id': 'le-direct',
+            'id': 'xji3qy',
-        'playlist_mincount': 1
+    }, {
-        if not embed_url:
+        play_url = self._search_regex(
-        return self.url_result(embed_url, 'ArkenaPlay', video_id=display_id, video_title=title)
+        title = self._og_search_title(webpage, default=None) or self._html_search_meta(
-__version__ = '2016.07.17'
+__version__ = '2016.07.22'
-    _VALID_URL = r'https?://(?:www\.)?eporner\.com/hd-porn/(?P<id>\w+)/(?P<display_id>[\w-]+)'
+    _VALID_URL = r'https?://(?:www\.)?eporner\.com/hd-porn/(?P<id>\w+)(?:/(?P<display_id>[\w-]+))?'
-            'id': '95008',
+            'id': 'qlDUmNsj6VS',
-        display_id = mobj.group('display_id')
+        display_id = mobj.group('display_id') or video_id
-            r'<title>(.*?) - EPORNER', webpage, 'title')
+        hash = self._search_regex(
-            redirect_url, display_id, note='Downloading player config')
+        title = self._og_search_title(webpage, default=None) or self._html_search_regex(
-            r'(?s)sources\s*:\s*\[\s*({.+?})\s*\]', player_code, 'sources')
+        # Reverse engineered from vjs.js
-            formats.append(fmt)
+        for kind, formats_dict in sources.items():
-            r'(?s)<div[^>]+class=(["\']).*?\b(?:removed|userMessageSection)\b.*?\1[^>]*>(?P<error>.+?)</div>',
+            r'(?s)<div[^>]+class=(["\'])(?:(?!\1).)*\b(?:removed|userMessageSection)\b(?:(?!\1).)*\1[^>]*>(?P<error>.+?)</div>',
-            note='Logging in', errnote='unable to log in', fatal=False)
+            self._PASSWORD_CHALLENGE_URL, None,
-    _VALID_URL = r'(?:https?:)?//(?:www\.)?youtube\.com/shared\?ci=(?P<id>[0-9A-Za-z_-]{11})'
+    _VALID_URL = r'(?:https?:)?//(?:www\.)?youtube\.com/shared\?.*\bci=(?P<id>[0-9A-Za-z_-]{11})'
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/iplayer/episodes/(?P<id>%s)' % BBCCoUkIE._ID_REGEX
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/iplayer/(?:episodes|group)/(?P<id>%s)' % BBCCoUkIE._ID_REGEX
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _TEST = {
+    _VALID_URL = r'https?://(?:\w+\.)?youjizz\.com/videos/(?:[^/#?]+)?-(?P<id>[0-9]+)\.html(?:$|[?#])'
-    }
+    }, {
-
+
-    _VALID_URL = r'^https?://(?:www\.)?odatv\.com/(?:mob|vid)_video\.php\?id=(?P<id>[^&]*)'
+    _VALID_URL = r'https?://(?:www\.)?odatv\.com/(?:mob|vid)_video\.php\?.*\bid=(?P<id>[^&]+)'
-            'title': 'md5:69654805a16a16cf9ec9d055e079831c'
+            'title': 'ArtÄ±k DavutoÄlu ile devam edemeyiz'
-        }
+        'only_matching': True,
-        }
+        'only_matching': True,
-        if 'NO VIDEO!' in webpage:
+
-            'url': self._html_search_regex(r"(http.+?video_%s\.mp4)" % re.escape(video_id), webpage, 'url', flags=re.IGNORECASE)
+from .odatv import OdaTVIE
-from .comedycentral import ComedyCentralIE, ComedyCentralShowsIE
+from .comedycentral import (
-            'title': "YPG: Tel Abyad'Ä±n tamamÄ± kontrolÃ¼mÃ¼zde",
+            'title': "Tel Abyad'da IÅÄ°D bayraÄÄ± indirildi YPG bayraÄÄ± Ã§ekildi",
-                                playlist.get('progressiveDownloadUrl'), playlist_id, timestamp))
+                            for key in ('progressiveDownload', 'streaming'):
-__version__ = '2016.07.16'
+__version__ = '2016.07.17'
-    _TEST = {
+    _VALID_URL = r'https?://(?:[^/]+\.)?spike\.com/[^/]+/[\da-z]{6}(?:[/?#&]|$)'
-    }
+    }, {
-        'md5': 'feea2b1d7b3957f70886e6dfd8b8be84',
+        'md5': '86c0b5dbd4d83a6611a79987cc7a1989',
-        'md5': '1f54697dabc8f13f31bf06bb2e4de6db',
+        'md5': '5fa476a902e902783ac7a4d615cdbc7a',
-        'md5': '013dc282714e22acf9447cad14ff1208',
+        'md5': '1713ae35df5a521b31f6dc40730e7c9c',
-                        entry_protocol='m3u8_native',
+                        entry_protocol='m3u8_native', preference=-1,
-                        m3u8_id='m3u8-%s' % protocol, fatal=False))
+                    m3u8_formats = self._extract_m3u8_formats(
-                'ext': 'mp4',
+                'ext': 'flv',
-            'skip': 'this episode is not currently available',
+            'skip': 'Currently BBC iPlayer TV programmes are available to play in the UK only',
-            'skip': 'this episode is not currently available',
+            'skip': 'Currently BBC iPlayer TV programmes are available to play in the UK only',
-                'ext': 'mp4',
+                'ext': 'flv',
-                'ext': 'mp4',
+                'ext': 'flv',
-            'skip': 'this episode is not currently available',
+            'skip': 'geolocation',
-            'skip': 'this episode is not currently available',
+            'skip': 'geolocation',
-            'skip': 'this episode is not currently available on BBC iPlayer Radio',
+            'skip': 'Now it\'s really geo-restricted',
-                'ext': 'mp4',
+                'ext': 'flv',
-                    href, programme_id, 'mp4', 'm3u8_native',
+                    href, programme_id, ext='mp4', entry_protocol='m3u8_native',
-                    })
+                format.update({
-        description = xpath_text(itemdoc, 'description')
+        description = strip_or_none(xpath_text(itemdoc, 'description'))
-    _VALID_URL = r'^https?://(?:(?:www\.)?ardmediathek\.de|mediathek\.daserste\.de)/(?:.*/)(?P<video_id>[0-9]+|[^0-9][^/\?]+)[^/\?]*(?:\?.*)?'
+    _VALID_URL = r'^https?://(?:(?:www\.)?ardmediathek\.de|mediathek\.(?:daserste|rbb-online)\.de)/(?:.*/)(?P<video_id>[0-9]+|[^0-9][^/\?]+)[^/\?]*(?:\?.*)?'
-    float_or_none
+    float_or_none,
-    _VALID_URL = r'https?://streamable\.com/(?P<id>[\w]+)'
+    _VALID_URL = r'https?://streamable\.com/(?:e/)?(?P<id>\w+)'
-                'thumbnail': 'http://cdn.streamable.com/image/dnd1.jpg',
+                'thumbnail': 're:https?://.*\.jpg$',
-                'thumbnail': 'http://cdn.streamable.com/image/f6441ae0c84311e4af010bc47400a0a4.jpg',
+                'thumbnail': 're:https?://.*\.jpg$',
-        for key, info in video.get('files').items():
+        for key, info in video['files'].items():
-                'fps': info.get('framerate'),
+                'url': self._proto_relative_url(info['url']),
-            'duration': video.get('duration'),
+            'title': title,
-import re
+from ..utils import unescapeHTML
-    _VALID_URL = r'https?://(?:www\.)?nintendo\.com/games/detail/(?P<id>[\w-]+)'
+    _VALID_URL = r'https?://(?:www\.)?nintendo\.com/games/detail/(?P<id>[^/?#&]+)'
-        'playlist_count': 4,
+        'playlist_count': 3,
-        webpage = self._download_webpage(url, video_id)
+        page_id = self._match_id(url)
-            webpage)
+        webpage = self._download_webpage(url, page_id)
-            entries.append(OoyalaIE._build_url_result(ooyala_code[1]))
+        entries = [
-        return self.playlist_result(entries, video_id, self._og_search_title(webpage))
+        return self.playlist_result(
-
+            # twitter:player:stream should be checked before twitter:player since
-    _IE_DESC = 'cloudy.ec and videoraj.ch'
+    _IE_DESC = 'cloudy.ec'
-        https?://(?:www\.)?(?P<host>cloudy\.ec|videoraj\.(?:ch|to))/
+        https?://(?:www\.)?cloudy\.ec/
-    _API_URL = 'http://www.%s/api/player.api.php?%s'
+    _EMBED_URL = 'http://www.cloudy.ec/embed.php?id=%s'
-            }
+    _TEST = {
-    ]
+    }
-    def _extract_video(self, video_host, video_id, file_key, error_url=None, try_num=0):
+    def _extract_video(self, video_id, file_key, error_url=None, try_num=0):
-            data_url, video_id, 'Downloading player data')
+            self._API_URL, video_id, 'Downloading player data', query=form)
-                    return self._extract_video(video_host, video_id, file_key, video_url, try_num)
+                    return self._extract_video(video_id, file_key, video_url, try_num)
-        url = self._EMBED_URL % (video_host, video_id)
+        url = self._EMBED_URL % video_id
-        return self._extract_video(video_host, video_id, file_key)
+        return self._extract_video(video_id, file_key)
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-    _TEST = {
+    _TESTS = [{
-    }
+        'skip': 'Video gone, redirected to http://www.cbsnews.com/live/',
-__version__ = '2016.07.13'
+__version__ = '2016.07.16'
-        incomplete_formats = all(
+        incomplete_formats = (
-            f.get('vcodec') != 'none' and f.get('acodec') == 'none' or
+            all(f.get('vcodec') != 'none' and f.get('acodec') == 'none' for f in formats) or
-            for f in formats)
+            all(f.get('vcodec') == 'none' and f.get('acodec') != 'none' for f in formats))
-                def selector_function(formats):
+                def selector_function(ctx):
-                        for format in f(formats):
+                        for format in f(ctx):
-                def selector_function(formats):
+                def selector_function(ctx):
-                        picked_formats = list(f(formats))
+                        picked_formats = list(f(ctx))
-                    formats = list(formats)
+                def selector_function(ctx):
-                              all(f.get('vcodec') != 'none' for f in formats)):
+                        # for extractors with incomplete formats (audio only (soundcloud)
-                    for pair in itertools.product(video_selector(formats), audio_selector(formats)):
+                def selector_function(ctx):
-            def final_selector(formats):
+            def final_selector(ctx):
-                return selector_function(formats)
+                    ctx_copy['formats'] = list(filter(_filter, ctx_copy['formats']))
-        formats_to_download = list(format_selector(formats))
+
-            '-c:a', 'copy',
+            '-map', '0',
-import re
+from .theplatform import ThePlatformIE
-    _VALID_URL = r'https?://www\.syfy\.com/(?:videos/.+?vid:(?P<id>[0-9]+)|(?!videos)(?P<video_name>[^/]+)(?:$|[?#]))'
+class SyfyIE(ThePlatformIE):
-        'url': 'http://www.syfy.com/videos/Robot%20Combat%20League/Behind%20the%20Scenes/vid:2631458',
+        'url': 'http://www.syfy.com/theinternetruinedmylife/videos/the-internet-ruined-my-life-season-1-trailer',
-            'description': 'Listen to what insights George Lucas give his daughter Amanda.',
+            'id': '2968097',
-            'description': 'The Wil Wheaton Project premieres May 27th at 10/9c. Don\'t miss it.',
+        'params': {
-        return self.url_result(self._og_search_video_url(webpage))
+        display_id = self._match_id(url)
-        'expected_warnings': ['Failed to download MPD manifest'],
+        'expected_warnings': ['Failed to download MPD manifest', 'Failed to parse JSON'],
-        for item_js in re.findall(r'({.*?\b(?:src|source)\s*:\s*["\'].+?})', js):
+        for item_js in re.findall(r'({[^{]*?\b(?:src|source)\s*:\s*["\'].+?})', js):
-            'ext': 'flv',
+            'ext': 'mp4',
-                'uploader': '3sat',
+                'uploader': 'SCHWEIZWEIT',
-            'title': 'The Witcher 3: Wild Hunt [Xbox ONE]  - Now Playing',
+            'ext': 'mp4',
-        }],
+        'md5': '68f543909aea49d621dfc7703a11cfaf',
-            'is_live': False,
+            'title': 're:^d755d94b-4ab9-11e3-9162-0025907ad44f [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-        'url': 'https://www.9now.com.au/afl-footy-show/2016/episode-19',
+        'url': 'https://www.9now.com.au/andrew-marrs-history-of-the-world/season-1/episode-1',
-            source_type = source.get('type')
+            ext = mimetype2ext(source.get('type'))
-            if source_type == 'application/x-mpegURL' or container == 'M2TS':
+            if ext == 'ism':
-            elif source_type == 'application/dash+xml':
+            elif ext == 'mpd':
-                    'ext': container.lower(),
+                    'ext': ext or container.lower(),
-from .rtve import RTVEALaCartaIE, RTVELiveIE, RTVEInfantilIE
+from .rtve import RTVEALaCartaIE, RTVELiveIE, RTVEInfantilIE, RTVELiveIE, RTVETelevisionIE
-            ).replace('.net.rtve', '.multimedia.cdn.rtve')
+            video_url = video_url.replace('.net.rtve', '.multimedia.cdn.rtve')
-                formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-__version__ = '2016.07.11'
+__version__ = '2016.07.13'
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-            video_id)
+        URLS = ('http://widgets.ellentube.com/videos/%s' % video_id, url)
-            r"var\s+partnerId\s*=\s*'([^']+)", webpage, 'partner id')
+            kaltura_id = self._search_regex(
-            webpage, 'kaltura id')
+            if partner_id and kaltura_id:
-                'ext': 'flv',
+                'ext': 'mp4',
-            'skip': 'Currently BBC iPlayer TV programmes are available to play in the UK only',
+            'skip': 'this episode is not currently available',
-            'skip': 'Currently BBC iPlayer TV programmes are available to play in the UK only',
+            'skip': 'this episode is not currently available',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-            'skip': 'geolocation',
+            'skip': 'this episode is not currently available',
-            'skip': 'geolocation',
+            'skip': 'this episode is not currently available',
-            'skip': 'Now it\'s really geo-restricted',
+            'skip': 'this episode is not currently available on BBC iPlayer Radio',
-                'ext': 'flv',
+                'ext': 'mp4',
-                formats.extend(self._extract_m3u8_formats(
+                is_unified_streaming = re.search(self._USP_RE, href)
-                    m3u8_id=supplier, fatal=False))
+                    m3u8_id=supplier, fatal=False)
-                })
+                if format.get('protocol') != 'm3u8_native':
-                        vcodec, acodec = va_codecs[:2]
+                # Unified Streaming Platform
-                        'vcodec': vcodec,
+                        'vbr': vbr,
-            })
+            vbr, abr = m3u8_format.get('vbr'), m3u8_format.get('abr')
-            self._set_cookie(domain, 'remixlhk', value)
+        if cookies:
-from ..compat import compat_str
+from ..compat import (
-class VKIE(InfoExtractor):
+class VKBaseIE(InfoExtractor):
-class VKUserVideosIE(InfoExtractor):
+class VKUserVideosIE(VKBaseIE):
-from ..compat import compat_urllib_parse_urlencode
+    str_or_none,
-        error = response.get('error')
+    def _call_api(self, path, video_id, note):
-        return response
+        return data
-            % (video_id, api_vars['type']), video_id, 'Downloading player JSON')
+        player = self._call_api(
-        video = video[api_vars['playerType']]
+        video = self._call_api(
-            'timestamp': timestamp,
+            'description': video.get('description'),
-template = template.replace('@PROGRAM_SHA1SUM@', sha1sum)
+        },
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?tmz\.com/videos/(?P<id>[^/?#]+)'
-        'md5': '791204e3bf790b1426cb2db0706184c0',
+        'md5': '4d22a51ef205b6c06395d8394f72d560',
-            'thumbnail': r're:http://cdnbakmi\.kaltura\.com/.*thumbnail.*',
+            'timestamp': 1394747163,
-    }
+    }, {
-        }
+        video_id = self._match_id(url).replace('-', '_')
-            'description': json_data.get('description'),
+            'description': clean_html(json_data.get('description')),
-    _VALID_URL = r'https?://(?:www\.)?dbtv\.no/(?:(?:lazyplayer|player)/)?(?P<id>[0-9]+)(?:#(?P<display_id>.+))?'
+    _VALID_URL = r'https?://(?:www\.)?dbtv\.no/(?:[^/]+/)?(?P<id>[0-9]+)(?:#(?P<display_id>.+))?'
-        'md5': 'b89953ed25dacb6edb3ef6c6f430f8bc',
+        'md5': '2e24f67936517b143a234b4cadf792ec',
-            'id': '33100',
+            'id': '3649835190001',
-            'timestamp': 1404039863.438,
+            'thumbnail': 're:https?://.*\.jpg',
-        }
+            'uploader_id': '1027729757001',
-        self._sort_formats(formats)
+        video_id, display_id = re.match(self._VALID_URL, url).groups()
-            'id': compat_str(video['id']),
+            '_type': 'url_transparent',
-            'formats': formats,
+            'ie_key': 'BrightcoveNew',
-           tv3play\.dk/programmer|
+        (?:tvplay(?:\.skaties)?\.lv/parraides|
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                # rtmp download
+        {
-        if video['is_geo_blocked']:
+        title = video['title']
-        for format_id, video_url in streams['streams'].items():
+        for format_id, video_url in streams.get('streams', {}).items():
-            elif video_url.endswith('.f4m'):
+            ext = determine_ext(video_url)
-                continue
+                    update_url_query(video_url, {
-
+                fmt = {
-            'age_limit': video.get('age_limit', 0),
+            'title': title,
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-from ..utils import remove_end
+from ..utils import (
-    _VALID_URL = r'https?://tv\.biobiochile\.cl/notas/(?:[^/]+/)+(?P<id>[^/]+)\.shtml'
+    _VALID_URL = r'https?://(?:tv|www)\.biobiochile\.cl/(?:notas|noticias)/(?:[^/]+/)+(?P<id>[^/]+)\.shtml'
-        title = remove_end(self._og_search_title(webpage), ' - BioBioChile TV')
+        rudo_url = RudoIE._extract_url(webpage)
-        self._sort_formats(formats)
+        title = remove_end(self._og_search_title(webpage), ' - BioBioChile TV')
-            r'<a[^>]+href=["\']https?://busca\.biobiochile\.cl/author[^>]+>(.+?)</a>',
+            r'<a[^>]+href=["\']https?://(?:busca|www)\.biobiochile\.cl/(?:lista/)?(?:author|autor)[^>]+>(.+?)</a>',
-            'formats': formats,
+from .rudo import RudoIE
-__version__ = '2016.07.09.2'
+__version__ = '2016.07.11'
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?vidzi\.tv/(?:embed-)?(?P<id>[0-9a-zA-Z]+)'
-    }
+    }, {
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-        if re.search(r'(?i)<form[^>]* id="challenge"', login_results) is not None:
+        if re.search(r'(?i)<form[^>]+id="challenge"', login_results) is not None:
-            if re.search(r'(?i)<form[^>]* id="challenge"', tfa_results) is not None:
+            if re.search(r'(?i)<form[^>]+id="challenge"', tfa_results) is not None:
-            if re.search(r'(?i)<form[^>]* id="gaia_loginform"', tfa_results) is not None:
+            if re.search(r'(?i)<form[^>]+id="gaia_loginform"', tfa_results) is not None:
-        if re.search(r'(?i)<form[^>]* id="gaia_loginform"', login_results) is not None:
+        if re.search(r'(?i)<form[^>]+id="gaia_loginform"', login_results) is not None:
-    qualities,
+    remove_end,
-            'duration': 180,
+            'duration': 177,
-            r'<title>(.*?)-\s*Vuclip</title>', webpage, 'title').strip()
+        video_url = self._search_regex(
-        self._sort_formats(formats)
+        title = remove_end(self._html_search_regex(
-            r'\(([0-9:]+)\)</span>', webpage, 'duration', fatal=False))
+        duration = parse_duration(self._html_search_regex(
-        'md5': '317a5f7f6b544ce8419b784ca8edae65',
+        'params': {
-        'skip': 'This video takes time too long for retrieving the URL',
+        'skip': 'Unable to load videos',
-
+    def _extract_mioplayer(self, webpage, video_id, title, http_headers):
-            'title': 'Million Dollars, But... The Game Announcement',
+            'title': 'Million Dollars, But...: Million Dollars, But... The Game Announcement',
-            'skip_download': True,  # m3u8 downloads
+            'comment_count': int,
-            return False
+        if username is None:
-        login_page = self._download_webpage(self._LOGIN_URL, None, 'Getting login token', 'Unable to get login token')
+        login_page = self._download_webpage(
-                'Login failed (invalid username/password)', expected=True)
+            data=urlencode_postdata(login_form),
-        webpage = self._download_webpage(url, match_id)
+        display_id = self._match_id(url)
-        episode_id = self._html_search_regex(r"commentControls\('#comment-([0-9]+)'\)", webpage, 'episode id', match_id, False)
+        episode = strip_or_none(unescapeHTML(self._search_regex(
-        self.report_extraction(episode_id)
+        title = strip_or_none(self._og_search_title(
-        episode = self._html_search_regex(r'<title>([^<]+)</title>', webpage, 'episode title', fatal=False)
+        m3u8_url = self._search_regex(
-            self.raise_login_required('%s is only available for FIRST members' % title)
+        if not m3u8_url:
-            self.raise_login_required('%s is not available yet' % title)
+            if re.search(r'<div[^>]+class=["\']golive-gate', webpage):
-        formats = self._extract_m3u8_formats(self._html_search_regex(r"file: '(.+?)m3u8'", webpage, 'm3u8 url') + 'm3u8', episode_id, ext='mp4')
+            raise ExtractorError('Unable to extract m3u8 URL')
-            'id': episode_id,
+            'id': video_id,
-            'creator': creator,
+            'thumbnail': thumbnail,
-            'episode_id': episode_id,
+            'comment_count': comment_count,
-__version__ = '2016.07.09.1'
+__version__ = '2016.07.09.2'
-        def extract_entries(html, video_id, common_info, num):
+        def extract_entries(html, video_id, common_info, num=None):
-        'md5': '679734f6786145da3546585de9a356be',
+        # md5 is unstable
-                if isinstance(f, list):
+                if not isinstance(f, list):
-__version__ = '2016.07.09'
+__version__ = '2016.07.09.1'
-    _VALID_URL = r'https?://sr-mediathek\.sr-online\.de/index\.php\?.*?&id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://sr-mediathek(?:\.sr-online)?\.de/index\.php\?.*?&id=(?P<id>[0-9]+)'
-        'expected_warnings': ['Unable to download f4m manifest']
+    }, {
-                            video_id, preference=-1, f4m_id='hds', fatal=False))
+                            update_url_query(stream_url, {
-                            stream_url, video_id, 'mp4', preference=1, m3u8_id='hls', fatal=False))
+                            stream_url, video_id, 'mp4', m3u8_id='hls', fatal=False))
-        }
+        },
-        url = self._TEMPLATE_URL % channel_id
+        url = self._build_template_url(url, channel_id)
-    _TEMPLATE_URL = 'https://www.youtube.com/user/%s/videos'
+    _VALID_URL = r'(?:(?:https?://(?:\w+\.)?youtube\.com/(?:(?P<user>user|c)/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'
-        }
+        # {
-__version__ = '2016.07.07'
+__version__ = '2016.07.09'
-        def extract_info(html, video_id):
+        def extract_info(html, video_id, num=None):
-                    if not format_id_list:
+                    if not format_id_list and num is not None:
-            info = extract_info(html, video_id)
+        def extract_entries(html, video_id, common_info, num):
-            res = compat_shlex_split(optionf.read(), comments=True)
+            # FIXME: https://github.com/rg3/youtube-dl/commit/dfe5fa49aed02cf36ba9f743b11b0903554b5e56
-        # Film wording is used instead of Episode
+        # Film wording is used instead of Episode, ger/jap, Dub/OmU
-        # Episodes without titles
+        # Episodes without titles, jap, OmU
-
+        def extract_info(html, video_id):
-                    r'<input[^>]+class=["\'].*?streamstarter_html5[^>]+>', episode_html):
+                    r'<input[^>]+class=["\'].*?streamstarter_html5[^>]+>', html):
-                self._sort_formats(formats)
+            return {
-                })
+                f.update(info)
-            if not formats:
+            # Extract teaser/trailer only when full episode is not available
-                    episode_html)
+                    r'data-dialog-header=(["\'])(?P<title>.+?)\1[^>]+href=(["\'])(?P<href>.+?)\3[^>]*>(?P<kind>Teaser|Trailer)<',
-                        'id': '%s-teaser' % f['id'],
+                        'id': '%s-%s' % (f['id'], m.group('kind').lower()),
-
+from ..compat import compat_str
-    unified_strdate,
+    float_or_none,
-        'md5': '541988fb6c4c7c375215ea22a4a21841',
+    _VALID_URL = r'https?://(?:www\.)?flipagram\.com/f/(?P<id>[^/?#&]+)'
-            'description': 'Herbie\'s first bannanaðð¢ð.  #animals #pets #reptile #tortoise #sulcata #tort #justatreat #snacktime #bannanas #rescuepets  #ofmonstersandmen  @animals',
+            'id': 'nyvTSJMKId',
-    }]
+            'title': 'Flipagram by sjuria101 featuring Midnight Memories by One Direction',
-        content_data = self._search_json_ld(webpage, video_id)
+        video_data = self._parse_json(
-        video = flipagram.get('video', {})
+        video_data = flipagram.get('video', {})
-            })
+        thumbnails = [{
-            text = comment.get('comment', [])
+        for comment in video_data.get('comments', {}).get(video_id, {}).get('items', []):
-                'vcodec': 'none',
+                'text': text[0],
-            'formats': formats,
+            'title': title,
-            'description': content_data.get('description'),
+            'timestamp': unified_timestamp(flipagram.get('iso8601Created')),
-            'upload_date': unified_strdate(flipagram.get('created')),
+            'creator': user.get('name'),
-            'tags': tags,
+            'formats': formats,
-    def _search_json_ld(self, html, video_id, **kwargs):
+    def _search_json_ld(self, html, video_id, expected_type=None, **kwargs):
-        return self._json_ld(json_ld, video_id, fatal=kwargs.get('fatal', True))
+        return self._json_ld(
-    def _json_ld(self, json_ld, video_id, fatal=True):
+    def _json_ld(self, json_ld, video_id, fatal=True, expected_type=None):
-                    'url': unescapeHTML(json_ld.get('contentUrl')),
+                    'thumbnail': json_ld.get('thumbnailUrl'),
-            query={'video_id': video_id})['data']
+            query={'video_id': video_id},
-            swf_params = m.group(1).replace('\\\\', '\\').replace('\\"', '"')
+        PATTERN = re.escape(BEFORE) + '(?:\n|\\\\n)(.*?)' + re.escape(AFTER)
-            video_data = json.loads(params_raw)['video_data']
+            video_data_candidate = json.loads(params_raw)['video_data']
-
+    def _check_errors(self, play_json):
-        playurl = play_json['playurl']
+    def _real_extract(self, url):
-        dispatch = playurl['dispatch']
+        play_json_flash = self._download_json(
-                    'm3v': 1,
+        def get_h5_urls(media_url, format_id):
-                })
+                    'tss': 'no',
-                    'Download JSON metadata for format %s' % format_id)
+            return {
-                    note='Downloading m3u8 information for format %s' % format_id)
+        def get_flash_urls(media_url, format_id):
-                m3u8_data = self.decrypt_m3u8(req.read())
+            nodes_data = self._download_json(
-                }
+            req = self._request_webpage(
-                    url_info_dict['height'] = int_or_none(format_id[:-1])
+            m3u8_data = self.decrypt_m3u8(req.read())
-                urls.append(url_info_dict)
+            return {
-            'formats': urls,
+            'formats': formats,
-                'thumbnail': 're:^https?://static.prsa.pl/images/.*\.jpg$'
+                'thumbnail': 're:^https?://static\.prsa\.pl/images/.*\.jpg$'
-    _VALID_URL = r'https?://(?:www\.)?nick\.com/videos/clip/(?P<id>[^/?#.]+)'
+    _VALID_URL = r'https?://(?:www\.)?nick(?:jr)?\.com/(?:videos/clip|[^/]+/videos)/(?P<id>[^/?#.]+)'
-        'md5': 'ecfc6862da89489161fb9cd5f5a6fac1',
+        'md5': '679734f6786145da3546585de9a356be',
-            system_conf = compat_conf(_readOptions('/etc/youtube-dl.conf'))
+            system_conf = _readOptions('/etc/youtube-dl.conf')
-                user_conf = compat_conf(_readUserConf())
+                user_conf = _readUserConf()
-    assert shlex.split('ä¸­æ') == ['ä¸­æ']
+    args = shlex.split('ä¸­æ')
-except (AssertionError, UnicodeWarning, UnicodeEncodeError):
+except (AssertionError, UnicodeEncodeError):
-        'md5': '3147e4ddad366f97476a93863e4557c8',
+        'md5': 'fe73e417c093a788e0160c4025f88b15',
-            'description': 'md5:f97324cc71e86e11c853f0763820e3ba',
+            'description': 'md5:3789b21fed9c0219e9bcaacd43fab280',
-        return self.playlist_result(entries, playlist_id)
+        video_id = self._match_id(url)
-if sys.version_info >= (2, 7, 3):
+try:
-else:
+except (AssertionError, UnicodeWarning, UnicodeEncodeError):
-        return shlex.split(s, comments, posix)
+        return list(map(lambda s: s.decode('utf-8'), shlex.split(s, comments, posix)))
-        device_types = ['ipad']
+        device_types = ['ipad', 'android']
-                })
+                }, fatal=False)
-                formats.extend(self._extract_f4m_formats(v_url, video_id, f4m_id='hds', fatal=False))
+                formats.extend(self._extract_f4m_formats(
-                        'protocol': 'rtmp',
+                        'format_id': '%s-%d' % (protocol, tbr),
-            'ext': 'flv',
+            'ext': 'mp4',
-            # rtmp download
+            # m3u8 download
-        # m3u8 formats can be extracted using ipad device_type return 403 error code when ffmpeg try to download segements
+        # TODO: extract f4m formats
-        for device_type in ('flash',):
+        for device_type in device_types:
-            'ext': 'flv',
+            'ext': 'mp4',
-            # rtmp download
+            # m3u8 download
-)
+from ..utils import int_or_none
-    _VALID_URL = r'https?://www\.tou\.tv/(?P<id>[a-zA-Z0-9_-]+(?:/(?P<episode>S[0-9]+E[0-9]+)))'
+    _VALID_URL = r'https?://ici\.tou\.tv/(?P<id>[a-zA-Z0-9_-]+/S[0-9]+E[0-9]+)'
-        'url': 'http://www.tou.tv/30-vies/S04E41',
+        'url': 'http://ici.tou.tv/garfield-tout-court/S2015E17',
-            'id': '30-vies_S04E41',
+            'id': '122017',
-            'thumbnail': 'http://static.tou.tv/medias/images/2013-11-18_19_00_00_30VIES_0341_01_L.jpeg',
+            'title': 'Saison 2015 Ãpisode 17',
-            'skip_download': True,  # Requires rtmpdump
+            # m3u8 download
-        upload_date = unified_strdate(upload_date_str) if upload_date_str else None
+        path = self._match_id(url)
-            'ext': 'mp4',
+            'title': title,
-class MiTeleIE(InfoExtractor):
+class MiTeleBaseIE(InfoExtractor):
-    _VALID_URL = r'https?://www\.mitele\.es/[^/]+/[^/]+/[^/]+/(?P<id>[^/]+)/'
+    _VALID_URL = r'https?://www\.mitele\.es/(?:[^/]+/){3}(?P<id>[^/]+)/'
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-        self._sort_formats(formats)
+        info = self._get_player_info(url, webpage)
-            'id': video_id,
+        info.update({
-        }
+        })
-import json
+from .mitele import MiTeleBaseIE
-class TelecincoIE(InfoExtractor):
+class TelecincoIE(MiTeleBaseIE):
-        'md5': '5cbef3ad5ef17bf0d21570332d140729',
+        'md5': '8d7b2d5f699ee2709d992a63d5cd1712',
-            'id': 'MDSVID20141015_0058',
+            'id': 'JEA5ijCnF6p5W08A1rNKn7',
-            'title': 'Con MartÃ­n Berasategui, hacer un bacalao al ...',
+            'title': 'Bacalao con kokotxas al pil-pil',
-        'md5': '0a5b9f3cc8b074f50a0578f823a12694',
+        'md5': '284393e5387b3b947b77c613ef04749a',
-            'id': 'MDSVID20150916_0128',
+            'id': 'jn24Od1zGLG4XUZcnUnZB6',
-            'title': 'Â¿QuiÃ©n es este ex futbolista con el que hablan ...',
+            'title': 'Â¿QuiÃ©n es este ex futbolista con el que hablan Leo Messi y Luis SuÃ¡rez?',
-        'md5': 'ad1bfaaba922dd4a295724b05b68f86a',
+        'md5': '749afab6ea5a136a8806855166ae46a2',
-            'id': 'MDSVID20150513_0220',
+            'id': 'aywerkD2Sv1vGNqq9b85Q2',
-        }
+        display_id = self._match_id(url)
-__version__ = '2016.07.06'
+__version__ = '2016.07.07'
-            video_id, 'Downloading video formats info')
+            'http://videofarm.daum.net/controller/api/closed/v1_2/IntegratedMovieData.json',
-            'Downloading video info')
+            'http://tvpot.daum.net/clip/ClipInfoXml.do', video_id,
-            # playlist test
+            # playlist with 'videoList'
-        if 'videoList' not in json_data:
+        if 'videoList' in json_data:
-        videos = [self._extract_video_info(video_info) for video_info in playlist_info['mediaCollectionDTO']['videoDTOs']]
+
-                                    playlist_title=playlist_info['mediaCollectionDTO']['displayName'])
+                                    playlist_title=playlist_dto['displayName'])
-from .dailymotion import DailymotionCloudIE
+from .dailymotion import (
-            return self.url_result(dmcloud_url, 'DailymotionCloud')
+            return self.url_result(dmcloud_url, DailymotionCloudIE.ie_key())
-from .dailymotion import DailymotionCloudIE
+from .dailymotion import (
-            r'<(?:(?:embed|iframe)[^>]+?src=|input[^>]+id=[\'"]dmcloudUrlEmissionSelect[\'"][^>]+value=)(["\'])(?P<url>(?:https?:)?//(?:www\.)?dailymotion\.com/(?:embed|swf)/video/.+?)\1', webpage)
+        matches = DailymotionIE._extract_urls(webpage)
-                matches, lambda m: unescapeHTML(m[1]))
+            return _playlist_from_matches(matches)
-            ext = mimetype2ext(media.get('type')) or determne_ext(media_url)
+            ext = mimetype2ext(media.get('type')) or determine_ext(media_url)
-)
+from .onet import OnetBaseIE
-class ClipRsIE(InfoExtractor):
+class ClipRsIE(OnetBaseIE):
-        video_id = self._match_id(url)
+        display_id = self._match_id(url)
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id)
-            r'id=(["\'])mvp:(?P<id>.+?)\1', webpage, 'mvp id', group='id')
+        mvp_id = self._search_mvp_id(webpage)
-            })
+        info_dict = self._extract_from_id(mvp_id, webpage)
-        }
+        return info_dict
-from .cliprs import ClipRsIE
+from .cliprs import ClipRsIE
-def get_element_by_attribute(attribute, value, html):
+def get_element_by_class(class_name, html):
-    ''' % (re.escape(attribute), re.escape(value)), html)
+    ''' % (re.escape(attribute), value), html)
-            if media_type in ('video/f4m', 'application/f4m+xml'):
+            media = media_data.get('@attributes', {})
-                    media['url'] + '?hdcore=3.4.0&plugin=aasp-3.4.0.132.124',
+                    media_url + '?hdcore=3.4.0&plugin=aasp-3.4.0.132.124',
-            elif media_type == 'application/x-mpegURL':
+            elif ext == 'm3u8':
-                    media['url'], video_id, 'mp4', m3u8_id='hls', fatal=False))
+                    media_url, video_id, 'mp4', m3u8_id='hls', fatal=False))
-                    if type_ == 'application/x-mpegURL' or ext == 'm3u8':
+                    ext = mimetype2ext(type_) or determine_ext(media_url)
-                    elif type_ == 'application/f4m' or ext == 'f4m':
+                    elif ext == 'f4m':
-                    if mime_type == 'application/x-mpegURL' or ext == 'm3u8':
+                    ext = mimetype2ext(source.get('type')) or determine_ext(source_url)
-            if content_type == 'application/x-mpegURL' or ext == 'm3u8':
+            ext = mimetype2ext(source.get('content_type')) or determine_ext(source_url)
-            if source_type == 'application/vnd.apple.mpegURL':
+            ext = mimetype2ext(source_type) or determine_ext(source_url)
-            elif source_type == 'video/mp4':
+            elif ext == 'mp4':
-            if type_ == 'application/dash+xml' or ext == 'mpd':
+            ext = mimetype2ext(item.get('type')) or determine_ext(item_url, default_ext=None)
-            elif type_ in ('application/vnd.apple.mpegURL', 'application/x-mpegurl') or ext == 'm3u8':
+            elif ext == 'm3u8':
-                    'ext': 'mp4' if item_url.startswith('rtsp') else mimetype2ext(type_) or ext,
+                    'ext': 'mp4' if item_url.startswith('rtsp') else ext,
-    sanitized_Request,
+    get_element_by_attribute,
-    _VALID_URL = r'https?://(?:www\.)?metacafe\.com/watch/([^/]+)/([^/]+)/.*'
+    _VALID_URL = r'https?://(?:www\.)?metacafe\.com/watch/(?P<video_id>[^/]+)/(?P<display_id>[^/?#]+)'
-                'description': 'md5:38c711dd98f5bb87acf973d573442e67',
+                'uploader': 'AnyClip',
-    def _real_initialize(self):
+    def _confirm_age(self):
-        self._download_webpage(request, None, False, 'Unable to confirm age')
+        self._download_webpage(
-        video_id = mobj.group(1)
+        video_id, display_id = re.match(self._VALID_URL, url).groups()
-        req = sanitized_Request('http://www.metacafe.com/watch/%s/' % video_id)
+        # self._confirm_age()
-        webpage = self._download_webpage(req, video_id)
+        headers = {}
-        thumbnail = self._og_search_thumbnail(webpage)
+        description = self._html_search_meta(
-
+            self._html_search_meta('video:duration', webpage, default=None))
-
+
-__version__ = '2016.07.05'
+__version__ = '2016.07.06'
-                clip_id, 'Downloading urls JSON', query={
+                clip_id, 'Downloading urls JSON', fatal=False, query={
-        'md5': 'd4851405d31adfadf71cd7a487b765bb',
+        'md5': 'e49f947c105b8a78a675a0ee1bddedfe',
-            'uploader_id': 'TheAVClub',
+            'uploader_id': 'the-av-club',
-            'http://www.onionstudios.com/embed?id=%s' % video_id, video_id)
+        video_data = self._download_json(
-            if ext == 'm3u8':
+        for source in video_data.get('sources', []):
-                    src, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+                    source_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
-                    r'/(\d+)\.%s' % ext, src, 'height', default=None))
+                tbr = int_or_none(source.get('bitrate'))
-                    'height': height,
+                    'format_id': ext + ('-%d' % tbr if tbr else ''),
-            'uploader_id': uploader_id,
+            'thumbnail': video_data.get('poster_url'),
-                    channel_page, 'channel id', default=None)
+                channel_url = self._html_search_meta(
-            'title': 'TheLinuxFoundation',
+            'id': 'UUfX55Sx5hEFjoC3cNs6mCUQ',
-from ..compat import compat_urllib_parse_urlencode
+from ..compat import compat_str
-        clip_id = self._html_search_regex(self._CLIPID_REGEXES, webpage, 'clip id')
+        clip_id = self._html_search_regex(
-        video = self._download_json(videos_api_url, clip_id, 'Downloading videos JSON')[0]
+        video = self._download_json(
-        source_ids_str = ','.join(map(str, source_ids))
+        source_ids = [compat_str(source['id']) for source in video['sources']]
-        sources = self._download_json(sources_api_url, clip_id, 'Downloading sources JSON')
+        sources = self._download_json(
-                    'vbr': fix_bitrate(source['bitrate']),
+        formats = []
-
+            if urls.get('status_code') != 0:
-        'md5': '6e1d0ab079e2a00b6161442d3ceacfc1',
+        'md5': 'cdbec9f44550763c8afc96050fa747dc',
-                formats.append({'url': item['file']})
+        formats = []
-            'upload_date': '20120904',
+            'upload_date': '20120409',
-        webpage = self._download_webpage(req, video_id)
+        presentation_data = self._download_json(
-                data_json, video_id, transform_source=js_to_json)
+        title = presentation_data['Title']
-            })
+        for stream in presentation_data.get('Streams', []):
-            'description': description,
+            'description': presentation_data.get('Description'),
-            'duration': duration,
+            'timestamp': int_or_none(presentation_data.get('UnixTime'), 1000),
-        description = self._html_search_regex(
+        description = get_element_by_id('slideshow-description-paragraph', webpage) or self._html_search_regex(
-            'description': description,
+            'description': description.strip() if description else None,
-from ..compat import compat_urlparse
+from ..compat import compat_urlparse
-        description = self._html_search_meta('description', webpage, 'description')
+        video_data = extract_attributes(self._search_regex(r'(<div[^>]+id="spVideoElements"[^>]+>)', webpage, 'video element', default=''))
-            'description': description,
+            'description': description.strip() if description else None,
-                r'(?s)var\s+stitcher\s*=\s*({.+?});\n', webpage, 'episode config')),
+                r'(?s)var\s+stitcher(?:Config)?\s*=\s*({.+?});\n', webpage, 'episode config')),
-        base64_media_id = self.base64_encode_utf8(media_id)
+    def _extract_flv_config(self, encoded_media_id):
-            'http://vlog.xuite.net/flash/player?media=%s' % base64_media_id,
+            'http://vlog.xuite.net/flash/player?media=%s' % encoded_media_id,
-        flv_config = self._extract_flv_config(video_id)
+        encoded_media_id = self._search_regex(
-__version__ = '2016.07.03.1'
+__version__ = '2016.07.05'
-                '<script[^>]+src=(?:["\'])((?:https?:)?//.+?)/p/%(partner_id)s/sp/%(partner_id)s00/embedIframeJs' % embed_info,
+                r'<script[^>]+src=["\']((?:https?:)?//.+?)/p/%s/sp/%s00/embedIframeJs' % (escaped_pid, escaped_pid),
-    def _kaltura_api_call(self, video_id, actions, *args, **kwargs):
+    def _kaltura_api_call(self, video_id, actions, service_url=None, *args, **kwargs):
-            self._SERVICE_URL + self._SERVICE_BASE,
+            (service_url or self._SERVICE_URL) + self._SERVICE_BASE,
-    def _get_kaltura_signature(self, video_id, partner_id):
+    def _get_kaltura_signature(self, video_id, partner_id, service_url=None):
-            video_id, actions, note='Downloading Kaltura signature')['ks']
+            video_id, actions, service_url, note='Downloading Kaltura signature')['ks']
-        signature = self._get_kaltura_signature(video_id, partner_id)
+    def _get_video_info(self, video_id, partner_id, service_url=None):
-            video_id, actions, note='Downloading video info JSON')
+            video_id, actions, service_url, note='Downloading video info JSON')
-            info, flavor_assets = self._get_video_info(entry_id, partner_id)
+            info, flavor_assets = self._get_video_info(entry_id, partner_id, smuggled_data.get('service_url'))
-    determine_ext,
+    smuggle_url,
-        'md5': '6054674766e7988d3e02f2148ff92180',
+        'md5': '8b613ffc0c4bf9b9e377169fc19c214c',
-
+            '_type': 'url_transparent',
-            'formats': formats,
+            'ie_key': 'Kaltura',
-    compat_urllib_parse_urlencode,
+    smuggle_url,
-    _API_BASE = 'http://cdnapi.kaltura.com/api_v3/index.php?'
+    _SERVICE_URL = 'http://cdnapi.kaltura.com'
-            return 'kaltura:%(partner_id)s:%(id)s' % mobj.groupdict()
+            embed_info = mobj.groupdict()
-        data = self._download_json(url, video_id, *args, **kwargs)
+        data = self._download_json(
-            video_url = sign_url('%s/flavorId/%s' % (info['dataUrl'], f['id']))
+            video_url = sign_url(
-            m3u8_url, entry_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+        if '/playManifest/' in data_url:
-        'md5': '5b0591f55961117155430b5d544fdb01',
+        # MD5 checksum differs on my machine and Travis CI
-            r'(?s)<div[^>]+class=(["\']).*?\bremoved\b.*?\1[^>]*>(?P<error>.+?)</div>',
+            r'(?s)<div[^>]+class=(["\']).*?\b(?:removed|userMessageSection)\b.*?\1[^>]*>(?P<error>.+?)</div>',
-            return self.url_result(nbc_sports_url, 'NBCSportsVPlayer')
+            return self.url_result(nbc_sports_url, NBCSportsVPlayerIE.ie_key())
-        self.cn_proxy_thread.start()
+        self.geo_proxy = compat_http_server.HTTPServer(
-        cn_proxy = 'localhost:{0}'.format(self.cn_port)
+        geo_proxy = 'localhost:{0}'.format(self.geo_port)
-            'cn_verification_proxy': cn_proxy,
+            'geo_verification_proxy': geo_proxy,
-        req.add_header('Ytdl-request-proxy', cn_proxy)
+        req.add_header('Ytdl-request-proxy', geo_proxy)
-        self.assertEqual(response, 'cn: {0}'.format(url))
+        self.assertEqual(response, 'geo: {0}'.format(url))
-                       on Chinese sites. (Experimental)
+    geo_verification_proxy:  URL of the proxy to use for IP address verification
-            query=params, headers=headers)
+            query=params, headers=self.geo_verification_headers())
-                query=query, headers=headers,
+                query=query, headers=self.geo_verification_headers(),
-            media_id, 'Downloading playJson data')
+            'http://api.le.com/mms/out/video/playJson',
-                query={'output': 45, 'pl': platform}, headers=headers)
+                query={'output': 45, 'pl': platform},
-)
+from ..utils import ExtractorError
-                'Downloading JSON data for %s' % vid_id)
+                base_data_url + vid_id, video_id,
-    sanitized_Request,
+            headers.update(self.geo_verification_headers())
-            raw_data = self._download_json(req, video_id, note=note)
+            raw_data = self._download_json(req_url, video_id, note=note, headers=headers)
-        'The default proxy specified by --proxy (or none, if the options is not present) is used for the actual downloading. (experimental)'
+        help=optparse.SUPPRESS_HELP,
-__version__ = '2016.07.03'
+__version__ = '2016.07.03.1'
-import math
+    clean_html,
-        'md5': '470a6c160618577166db1a7aac5a3606',
+        'md5': '5b0591f55961117155430b5d544fdb01',
-        'md5': 'f09f0a6a59b2da66a26bf4eda669a4cc',
+        'md5': '667171934041350c5de3f5015f7f1152',
-            'title': 'åä¾¦æ¢æ¯å å½è¯­ç',
+            'title': 'åä¾¦æ¢æ¯å å½è¯­çï¼ç¬¬752é è¿«è¿ç°åç§å¯çé»å½± ä¸ç¯',
-        'expected_warnings': ['Needs a VIP account for full video'],
+        'skip': 'Geo-restricted to China',
-    ]
+    _FORMATS_MAP = {
-        sc = self._gen_sc(tvid, tm)
+        key = 'd5fb4bd9d50c4be6948c97edd7254b0e'
-            'src': 'd846d0c32d664d32b6b54ea48997a589',
+            'src': '76f90cbd92f94a2e925d83e8ccd22cb7',
-            '__jsT': None,
+            't': tm,
-                continue
+            for stream in data['vidl']:
-            break
+        self._sort_formats(formats)
-            'url': data['m3u'],
+            'formats': formats,
-            'manifest': 'm3u',
+            'switch': 'http',
-            r'var\s+videoURL\s*=\s*(?P<q1>[\'"])(?P<url>(https?:)?//mediapolis\.rai\.it/relinker/relinkerServlet\.htm\?cont=\d+)(?P=q1)',
+            r'(?:var\s+videoURL|mediaInfo\.mediaUri)\s*=\s*(?P<q1>[\'"])(?P<url>(https?:)?//mediapolis\.rai\.it/relinker/relinkerServlet\.htm\?cont=\d+)(?P=q1)',
-        }
+        return self._extract_from_content_id(video_id, url)
-        }
+        },
-        boot_info, bootstrap_url = self._parse_bootstrap_node(bootstrap_node, base_url)
+        # From Adobe F4M 3.0 spec:
-    _VALID_URL = r'https?://(?:.+?\.)?(?:rai\.it|rai\.tv|rainews\.it)/dl/(?:[^/]+/)+media/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html'
+class RaiBaseIE(InfoExtractor):
-
+            formats.extend(self._extract_relinker_formats(media['mediaUri'], video_id))
-class RaiIE(InfoExtractor):
+class RaiIE(RaiBaseIE):
-        return self.url_result(iframe_url)
+            webpage, 'iframe', default=None)
-)
+from ..compat import compat_urlparse
-    ExtractorError,
+    ExtractorError,
-    int_or_none,
+    update_url_query,
-            'md5': '96382709b61dd64a6b88e0f791e6df4c',
+            'md5': '8970abf8caf8aef4696e7b1f2adfc696',
-                'ext': 'flv',
+                'ext': 'mp4',
-            'md5': 'd9751b78eac9710d62c2447b224dea39',
+            # HDS download, MD5 is unstable
-            'md5': '496ab63e420574447f70d02578333437',
+            'md5': 'e57493e1cb8bc7c564663f363b171847',
-                'ext': 'flv',
+                'ext': 'mp4',
-                    'url': thumbnail_url,
+                    'url': compat_urlparse.urljoin(url, thumbnail_url),
-            has_subtitle = False
+            for platform in ('mon', 'flash', 'native'):
-                content_type = xpath_text(element, 'content-type')
+                if (platform == 'mon' and ext != 'm3u8') or (platform == 'flash' and ext != 'f4m'):
-                    bitrate = int_or_none(xpath_text(element, 'bitrate'))
+                        manifest_url, video_id, f4m_id='hds', fatal=False))
-                subtitles = self._get_subtitles(video_id, webpage)
+        subtitles = {}
-            'md5': 'e0e7a8a131e249d1aa0ebf270d1d8db7',
+            'md5': '2dd727e61114e1ee9c47f0da6914e178',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'title': 'Angry Ram destroys a punching bag',
+                'uploader': 'Angry Ram',
-                'title': 're:Munchkin the Teddy Bear gets her exercise',
+    }, {
-                class=(?P<q1>[\'"])[^\'"]*\bfb-video\b[^\'"]*(?P=q1)[^>]+
+                class=(?P<q1>[\'"])[^\'"]*\bfb-(?:video|post)\b[^\'"]*(?P=q1)[^>]+
-    _VALID_URL = r'https?://(?:www\.)?history\.com/topics/(?:[^/]+/)?(?P<topic_id>[^/]+)/videos(?:/(?P<video_display_id>[^/?#]+))?'
+    _VALID_URL = r'https?://(?:www\.)?history\.com/topics/(?:[^/]+/)?(?P<topic_id>[^/]+)(?:/[^/]+(?:/(?P<video_display_id>[^/?#]+))?)?'
-        entries = [self.url_result('hrti:%s' % category_id) for category_id in video_ids]
+        entries = [self.url_result('hrti:%s' % video_id) for video_id in video_ids]
-class NationalGeographicChannelIE(InfoExtractor):
+class NationalGeographicChannelIE(ThePlatformIE):
-                update_url_query(release_url, {'mbr': 'true', 'switch': 'http'}),
+                update_url_query(release_url, query),
-from .common import InfoExtractor
+from .theplatform import ThePlatformIE
-        }
+class AENetworksBaseIE(ThePlatformIE):
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:history|aetv|mylifetime)\.com|fyi\.tv)/(?:shows/(?P<show_path>[^/]+(?:/[^/]+){0,2})|movies/(?P<movie_display_id>[^/]+)/full-movie)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<domain>(?:history|aetv|mylifetime)\.com|fyi\.tv)/(?:shows/(?P<show_path>[^/]+(?:/[^/]+){0,2})|movies/(?P<movie_display_id>[^/]+)/full-movie)'
-        show_path, movie_display_id = re.match(self._VALID_URL, url).groups()
+        domain, show_path, movie_display_id = re.match(self._VALID_URL, url).groups()
-            }))
+        theplatform_metadata = self._download_theplatform_metadata(self._search_regex(
-        info = self.get_metadata('kYEXFC/%s' % media_guid_path, video_id)
+        info = self._extract_theplatform_metadata('kYEXFC/%s' % media_guid_path, video_id)
-    def get_metadata(self, path, video_id):
+    def _download_theplatform_metadata(self, path, video_id):
-        info = self._download_json(info_url, video_id)
+        return self._download_json(info_url, video_id)
-        ret = self.get_metadata(path, video_id)
+        ret = self._extract_theplatform_metadata(path, video_id)
-        ret = self.get_metadata('%s/%s' % (provider_id, first_video_id), video_id)
+        ret = self._extract_theplatform_metadata('%s/%s' % (provider_id, first_video_id), video_id)
-__version__ = '2016.07.02'
+__version__ = '2016.07.03'
-from ..compat import compat_urllib_parse_unquote
+    parse_duration,
-    _VALID_URL = r'(?:xtube:|https?://(?:www\.)?xtube\.com/(?:watch\.php\?.*\bv=|video-watch/(?P<display_id>[^/]+)-))(?P<id>[^/?&#]+)'
+    _VALID_URL = r'''(?x)
-            webpage, 'uploader', fatal=False)
+        sources = self._parse_json(self._search_regex(
-            'url': video_url,
+            'formats': formats,
-from .hrti import HRTiIE
+from .hrti import (
-)
+from ..compat import compat_HTTPError
-    ExtractorError
+    try_get,
-    '''
+class HRTiBaseIE(InfoExtractor):
-    }
+    _APP_LANGUAGE = 'hr'
-        req = sanitized_Request(api_url, data=app_data)
+        init_data = {
-            headers={'Content-type': 'application/json'})
+            req, None, note='Downloading session information',
-            application_id=HRTiIE.APP_PUBLICATION_ID)
+        self._search_url = modules['vod_catalog']['resources']['search']['uri'].format(
-        self.login_url += '/format/json'
+        self._login_url = (modules['user']['resources']['login']['uri'] +
-        self.logout_url = modules['user']['resources']['logout']['uri']
+        self._logout_url = modules['user']['resources']['logout']['uri']
-
+        # TODO: figure out authentication with cookies
-        auth_data = json.dumps({
+        auth_data = {
-        })
+        }
-        self.logout_url += '/format/json'
+                self._login_url, None, note='Logging in', errnote='Unable to log in',
-                            errnote='Unable to log out', fatal=False)
+
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            '/video_id/{video_id}/format/json'.format(video_id=video_id)
+        video = self._download_json(
-        description = title_info.get('summary_long')
+        title_info = video['title']
-
+        m3u8_url = movie['url'].format(TOKEN=self._token)
-        self._logout()
+        description = clean_html(title_info.get('summary_long'))
-    req_type = HEADRequest if req.get_method() == 'HEAD' else compat_urllib_request.Request
+    req_get_method = req.get_method()
-        new_req.get_method = lambda : 'PUT'
+from .hrti import HRTiIE
-    parse_duration,
+    determine_ext,
-        'md5': 'ec7d1f0224d20ba293ab56cf2259651f',
+    IE_NAME = 'la7.it'
-            'id': '50355319',
+            'id': '189080',
-            'duration': 6254,
+            'title': 'TG LA7',
-    }
+    }, {
-        } for vnode in doc.findall('.//videos/video')]
+
-            'duration': duration,
+            'title': player_data['title'],
-                data-href=(?P<q2>[\'"])(?P<url>[^\'"]+)(?P=q2)''', webpage)
+                data-href=(?P<q2>[\'"])(?P<url>(?:https?:)?//(?:www\.)?facebook.com/.+?)(?P=q2)''', webpage)
-        }
+        },
-            return self.url_result(mobj.group('url'), 'Facebook')
+        facebook_url = FacebookIE._extract_url(webpage)
-                                (?:m\.)?vk\.com/video_|
+                                (?:(?:m|new)\.)?vk\.com/video_|
-                                (?:m\.)?vk\.com/(?:.+?\?.*?z=)?video|
+                                (?:(?:m|new)\.)?vk\.com/(?:.+?\?.*?z=)?video|
-    _VALID_URL = r'https?://vk\.com/videos(?P<id>-?[0-9]+)(?!\?.*\bz=video)(?:[/?#&]|$)'
+    _VALID_URL = r'https?://(?:(?:m|new)\.)?vk\.com/videos(?P<id>-?[0-9]+)(?!\?.*\bz=video)(?:[/?#&]|$)'
-__version__ = '2016.07.01'
+__version__ = '2016.07.02'
-        
+
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?fusion\.net/video/(?P<id>\d+)'
-        'md5': '55c3dd61d2b96dc17c4ab6711d02a39e',
+        'params': {
-    }
+    }, {
-            webpage, 'ooyala code')
+        ooyala_code = self._search_regex(
-    _VALID_URL = r'https?://(?:[a-z]+\.)?pornhub\.com/(?:view_video\.php\?viewkey=|embed/)(?P<id>[0-9a-z]+)'
+    IE_DESC = 'PornHub and Thumbzilla'
-            for broadcast in data_store.get('UserBroadcastHistory', {}).get('broadcastIds', [])]
+                'https://www.periscope.tv/%s/%s' % (user_id, broadcast_id))
-            for broadcast in data_store.get('UserBroadcastHistory', {}).get('broadcasts', [])]
+                'https://www.periscope.tv/%s/%s' % (user_id, broadcast))
-                r'window\.POST_DATA\s*=\s*{\s*%s\s*:\s*({.+?})\s*};\s*</script>' % video_id,
+                r'window\.POST_DATA\s*=\s*({.+?});\s*</script>',
-    _USHER_BASE = 'http://usher.twitch.tv'
+    _USHER_BASE = 'https://usher.ttvnw.net'
-__version__ = '2016.06.30'
+__version__ = '2016.07.01'
-        preference = qualities(['lq', 'sd', 'hq', 'hd'])
+        quality_key = qualities(['lq', 'sd', 'hq', 'hd'])
-                    'preference': preference(quality),
+                    'quality': quality_key(quality),
-                res += compat_shlex_split(l, comments=True)
+            res = compat_shlex_split(optionf.read(), comments=True)
-            webpage, 'error message', default=None)
+            r'(?s)<div[^>]+class=(["\']).*?\bremoved\b.*?\1[^>]*>(?P<error>.+?)</div>',
-            r'(?s)<div class="userMessageSection[^"]*".*?>(.*?)</div>',
+            r'<div[^>]+class="removed">\s*<div[^>]*>\s*<p>\s*<span>([^<]*)</span>',
-        'url': 'http://www.ctvnews.ca/video?binId=1.810401',
+        'url': 'http://www.ctvnews.ca/video?binId=1.2876780',
-            'id': '1.810401',
+            'id': '1.2876780',
-        'playlist_mincount': 91,
+        'playlist_mincount': 100,
-                'maxItemsPerPage': 20,
+                'maxItemsPerPage': 1000000,
-            entries = [ninecninemedia_url_result(clip_id) for clip_id in set(
+            entries = [ninecninemedia_url_result(clip_id) for clip_id in orderedSet(
-
+    js_to_json,
-    _VALID_URL = r'https?://(?:www\.)?rds\.ca/vid(?:[eÃ©]|%C3%A9)os/(?:[^/]+/)*(?P<display_id>[^/]+)-(?P<id>\d+\.\d+)'
+    _VALID_URL = r'https?://(?:www\.)?rds\.ca/vid(?:[eÃ©]|%C3%A9)os/(?:[^/]+/)*(?P<id>[^/]+)-\d+\.\d+'
-            'id': '3.1132799',
+            'id': '604333',
-        display_id = mobj.group('display_id')
+        display_id = self._match_id(url)
-        title = self._og_search_title(webpage) or self._html_search_meta(
+        item = self._parse_json(self._search_regex(r'(?s)itemToPush\s*=\s*({.+?});', webpage, 'item'), display_id, js_to_json)
-        thumbnail = self._og_search_thumbnail(webpage) or self._search_regex(
+        thumbnail = item.get('urlImageBig') or self._og_search_thumbnail(webpage) or self._search_regex(
-            'url': video_url,
+            'url': '9c9media:rds_web:%s' % video_id,
-__version__ = '2016.06.27'
+__version__ = '2016.06.30'
-        return info
+        st_html5 = self._search_regex(
-            r'<iframe[^>]+src="(?P<url>(?:https?:)?//out\.pladform\.ru/player\?.+?)"', webpage)
+            r'<iframe[^>]+src=(["\'])(?P<url>(?:https?:)?//out\.pladform\.ru/player\?.+?)\1', webpage)
-            'description': self._og_search_description(webpage),
+            'description': self._og_search_description(webpage, default=None),
-            'duration': int_or_none(self._og_search_property('video:duration', webpage)),
+            'duration': int_or_none(self._og_search_property(
-    _TEST = {
+    _VALID_URL = r'https?://video\.meta\.ua/(?:iframe/)?(?P<id>[0-9]+)'
-    }
+    }, {
-        embed_url = self._twitter_search_player(webpage)
+        embed_url = self._html_search_meta('twitter:player', webpage, default=None)
-        }
+        video_id = self._match_id(url)
-from .theatlantic import TheAtlanticIE
+        # twitter:player embed
-            r'urPlayer.init\(({.+?})\);', webpage, 'urplayer data'), video_id)
+            r'urPlayer\.init\(({.+?})\);', webpage, 'urplayer data'), video_id)
-        }
+        }
-            return self.url_result(mobj.group('url'), 'EaglePlatform')
+        eagleplatform_url = EaglePlatformIE._extract_url(webpage)
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:history|aetv|mylifetime)\.com|fyi\.tv)/shows/(?P<id>[^/]+(?:/[^/]+){0,2})'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:history|aetv|mylifetime)\.com|fyi\.tv)/(?:shows/(?P<show_path>[^/]+(?:/[^/]+){0,2})|movies/(?P<movie_display_id>[^/]+)/full-movie)'
-        display_id = self._match_id(url)
+        show_path, movie_display_id = re.match(self._VALID_URL, url).groups()
-                r"media_url\s*=\s*'([^']+)'", webpage, 'video url')
+        if show_path:
-            return info
+        info = self._search_json_ld(webpage, video_id, fatal=False)
-    _VALID_URL = r'https?://(?:www\.)?history\.com/topics/(?:[^/]+/)?(?P<topic_id>[^/]+)/videos(?:/(?P<display_id>[^/?#]+))?'
+    _VALID_URL = r'https?://(?:www\.)?history\.com/topics/(?:[^/]+/)?(?P<topic_id>[^/]+)/videos(?:/(?P<video_display_id>[^/?#]+))?'
-            webpage = self._download_webpage(url, display_id)
+        topic_id, video_display_id = re.match(self._VALID_URL, url).groups()
-            return self.playlist_result(entries, topic_id)
+            return self.playlist_result(entries, topic_id, get_element_by_attribute('class', 'show-title', webpage))
-                    video_attributes['data-href'], video_attributes['data-id'], {
+                    video_attributes['data-release-url'], video_attributes['data-id'], {
-class AENetworksIE(InfoExtractor):
+class AENetworksIE(AENetworksBaseIE):
-
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:history|aetv|mylifetime)\.com|fyi\.tv)/shows/(?P<id>[^/]+(?:/[^/]+){0,2})'
-            'id': 'eg47EERs_JsZ',
+            'id': '22253814',
-        'url': 'http://www.aetv.com/shows/duck-dynasty/video/inlawful-entry',
+        'url': 'http://www.history.com/shows/ancient-aliens/season-1',
-        'url': 'http://www.fyi.tv/shows/tiny-house-nation/videos/207-sq-ft-minnesota-prairie-cottage',
+        'url': 'http://www.fyi.tv/shows/tiny-house-nation/season-1/episode-8',
-        'url': 'http://www.mylifetime.com/shows/project-runway-junior/video/season-1/episode-6/superstar-clients',
+        'url': 'http://www.mylifetime.com/shows/project-runway-junior/season-1/episode-6',
-        page_type, video_id = re.match(self._VALID_URL, url).groups()
+        display_id = self._match_id(url)
-        webpage = self._download_webpage(url, video_id)
+            info = self._search_json_ld(webpage, video_id, fatal=False)
-        return info
+class HistoryTopicIE(AENetworksBaseIE):
-from .aenetworks import AENetworksIE
+from .aenetworks import (
-            }
+            },
-            }
+            },
-            }
+            },
-            'only_matching': True,
+            'md5': 'b8b93da1df1cea6c8556255a796b7d61',
-            'only_matching': True,
+            'md5': '',
-__version__ = '2016.06.26'
+__version__ = '2016.06.27'
-                    'url': re.sub(r'\d+k|baseline', bitrate, http_url),
+                    'url': f_url,
-                {'source_url': url}), 'Kaltura')
+        kaltura_url = KalturaIE._extract_url(webpage)
-            self.assertEqual(len(ie_list), 1, 'Only 1 extractor with IE_NAME "%s" (%s)' % (ie_name, ie_list))
+            name_accu[ie.IE_NAME.lower()].append(type(ie).__name__)
-    IE_NAME = 'skynewsarabia:video'
+    IE_NAME = 'skynewsarabia:article'
-                re.search(r'(?s)(?P<q1>["\'])(?:https?:)?//cdnapi(?:sec)?\.kaltura\.com/.*?(?:p|partner_id)/(?P<partner_id>\d+).*?(?P=q1).*?entry_?[Ii]d\s*:\s*(?P<q2>["\'])(?P<id>.+?)(?P=q2)', webpage))
+                re.search(r'(?s)(?P<q1>["\'])(?:https?:)?//cdnapi(?:sec)?\.kaltura\.com/.*?(?:p|partner_id)/(?P<partner_id>\d+).*?(?P=q1).*?(?P<q2>["\'])?entry_?[Ii]d(?P=q2)\s*:\s*(?P<q3>["\'])(?P<id>.+?)(?P=q3)', webpage))
-__version__ = '2016.06.25'
+__version__ = '2016.06.26'
-from .common import InfoExtractor
+from .common import InfoExtractor
-    unescapeHTML,
+    determine_ext,
-    _VALID_URL = r'https?://(?:www\.)?msn\.com/[a-z-]{2,5}(?:/[a-z]+)+/(?P<display_id>[a-z-]+)/[a-z]{2}-(?P<id>[a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?msn\.com/(?:[^/]+/)+(?P<display_id>[^/]+)/[a-z]{2}-(?P<id>[\da-zA-Z]+)'
-            'ext': 'mp4',
+            'uploader': 'CBS Entertainment',
-        }
+        'only_matching': True,
-            webpage, 'video data'), display_id)
+        video = self._parse_json(
-            if not '.ism' in video_file.get('url', '.ism'):
+        for file_ in video.get('videoFiles', []):
-                    'url': unescapeHTML(video_file.get('url')),
+                    'url': format_url,
-                    'height': int_or_none(video_file.get('height')),
+                    'format_id': 'http',
-                    'url': unescapeHTML(f.get('url')),
+        for file_ in video.get('files', []):
-            'creator': video_data.get('creator'),
+            'display_id': display_id,
-            'duration': int_or_none(video_data.get('durationSecs')),
+            'formats': formats,
-                return tuple(f.get(field) if f.get(field) is not None else -1 for field in field_preference)
+                return tuple(
-from ..utils import url_basename
+from ..utils import (
-        'md5': 'f1a579a93282a78de7e1c53220ef0f12',
+    _VALID_URL = r'https?://(?:www\.)?vidbit\.co/(?:watch|embed)\?.*?\bv=(?P<id>[\da-zA-Z]+)'
-            'id': 'MrM7LeaMJq',
+            'id': 'jkL2yDOEq2',
-            'thumbnail': 'http://www.vidbit.co/thumbnails/MrM7LeaMJq.jpg',
+            'title': 'Intro to VidBit',
-    }
+    }, {
-        webpage = self._download_webpage(url, video_id)
+
-                webpage, 'video URL', group=2)),
+            'url': video_url,
-                webpage, 'description', None, group=2),
+            'upload_date': upload_date,
-from youtube_dl.utils import encode_data_uri, strip_jsonp, ExtractorError
+from youtube_dl.utils import encode_data_uri, strip_jsonp, ExtractorError, RegexNotFoundError
-            display_name = name
+            display_name = name[0]
-            self._meta_regex(name),
+            [self._meta_regex(n) for n in name],
-        },
+        'skip': 'Geo-restricted to China',
-    compat_urllib_parse_urlparse,
+    intlist_to_bytes,
-    url_basename,
+    urshift,
-        'md5': '2cb594dc2781e6c941a110d8f358118b',
+        'md5': '470a6c160618577166db1a7aac5a3606',
-            'ext': 'f4v',
+        'md5': 'f09f0a6a59b2da66a26bf4eda669a4cc',
-            'title': 'åä¾¦æ¢æ¯åç¬¬752é',
+            'ext': 'mp4',
-            'skip_download': True,
+            'cn_verification_proxy': 'http://proxy.uku.im:443/',
-            'aid': tvid,
+    @staticmethod
-            'k_tag': 1,
+            'cupid': 'qc_100001_100186',
-        return enc_key
+        headers = {}
-        return info
+
-            param1 = self.urshift(param1, 1) + ((param1 & 1) << 31)
+            param1 = urshift(param1, 1) + ((param1 & 1) << 31)
-            'md5': '49444254273501a64675a7e68c502681',
+            'md5': 'dcaf23ad0c67a256f4278bce6e0bae38',
-                'id': '5585de919473990de4bee11b',
+                'id': 'x2uy8t3',
-                'title': 'Le dÃ©bat',
+                'title': 'Sauvons les abeilles ! - Le dÃ©bat',
-        92: 'request rejected becasue SOCKS server cannot connect to identd on the client',
+        92: 'request rejected because SOCKS server cannot connect to identd on the client',
-    _VALID_URL = r'https?://(?:www\.)?(?:svtplay|oppetarkiv)\.se/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:svtplay|oppetarkiv)\.se/(?:video|klipp)/(?P<id>[0-9]+)'
-from ..utils import int_or_none
+import re
-from datetime import datetime
+from .common import InfoExtractor
-    _VALID_URL = r'https?://(?:www\.)?polskieradio\.pl/[0-9]+/[0-9]+/Artykul/(?P<id>[0-9]+),.+'
+    _VALID_URL = r'https?://(?:www\.)?polskieradio\.pl/\d+/\d+/Artykul/(?P<id>[0-9]+)'
-        }
+        },
-        'md5': '68a393e25b942c1a76872f56d303a31a',
+        'url': 'http://www.polskieradio.pl/265/5217/Artykul/1635803,Euro-2016-nie-ma-miejsca-na-blad-Polacy-graja-ze-Szwajcaria-o-cwiercfinal',
-        }
+            'id': '1635803',
-        metadata = self._parse_json(metadata_string, video_id)
+        playlist_id = self._match_id(url)
-            title = title.strip()
+        entries = []
-            description = description.strip()
+        media_urls = set()
-            release_date = datetime.strptime(release_date, '%d.%m.%Y').strftime('%Y%m%d')
+        for data_media in re.findall(r'<[^>]+data-media=({[^>]+})', content):
-            timestamp = None
+        title = self._og_search_title(webpage).strip()
-        }
+        return self.playlist_result(entries, playlist_id, title, description)
-                    minutes=sign * int(m.group('minutes')))
+        timezone, date_str = extract_timezone(date_str)
-        date_str = re.sub(r' ?(\+|-)[0-9]{2}:?[0-9]{2}$', '', date_str)
+    _, date_str = extract_timezone(date_str)
-    for expression in format_expressions:
+    for expression in date_formats(day_first):
-__version__ = '2016.06.23.1'
+__version__ = '2016.06.25'
-        print("Cannot import py2exe", file=sys.stderr)
+        print('Cannot import py2exe', file=sys.stderr)
-    "dll_excludes": ['w9xpopen.exe', 'crypt32.dll'],
+    'bundle_files': 1,
-    "dest_base": "youtube-dl",
+    'script': './youtube_dl/__main__.py',
-    'options': {"py2exe": py2exe_options},
+    'options': {'py2exe': py2exe_options},
-    description = "Build the extractor lazy loading module"
+    description = 'Build the extractor lazy loading module'
-    ' YouTube.com and other video sites.',
+    description=DESCRIPTION,
-        "Programming Language :: Python :: 3.5",
+        'Topic :: Multimedia :: Video',
-                'uploader': 'Olympics',
+                'uploader': 'Olympic',
-                'formats': 'mincount:33',
+                'formats': 'mincount:32',
-            }
+            },
-                    class="(?:yt-uix-redirect-link|yt-uix-sessionlink[^"]*)"[^>]*>
+                    class="[^"]*"[^>]*>
-                'format': '141',
+                'format': '141/bestaudio[ext=m4a]',
-                'format': '141',
+                'format': '141/bestaudio[ext=m4a]',
-            webpage, 'like count', fatal=False))
+            webpage, 'like count', default=None))
-            webpage, 'play count', fatal=False))
+            webpage, 'play count', default=None))
-
+    }, {
-            'https://player.vimeo.com/video/%s/config' % video_id, video_id)
+        config_url = self._get_config_url(url, video_id)
-                    'thumbnail': clip.get('screen') or clip.get('runtime'),
+                    'thumbnail': clip.get('screen') or clip.get('thumb'),
-    _VALID_URL = r'https?://(?:www\.)?dcndigital\.ae/(?:#/)?show/(?P<show_id>\d+)/[^/]+(?:/(?P<video_id>\d+)/(?P<season_id>\d+))?'
+    _VALID_URL = r'https?://(?:www\.)?(?:awaan|dcndigital)\.ae/(?:#/)?show/(?P<show_id>\d+)/[^/]+(?:/(?P<video_id>\d+)/(?P<season_id>\d+))?'
-    def _extract_video_formats(self, webpage, video_id, entry_protocol):
+    def _extract_video_formats(self, webpage, video_id, m3u8_entry_protocol):
-
+        format_url_base = 'http' + self._html_search_regex(
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?(?:awaan|dcndigital)\.ae/(?:#/)?(?:video(?:/[^/]+)?|media|catchup/[^/]+/[^/]+)/(?P<id>\d+)'
-    }
+    }, {
-    _VALID_URL = r'https?://(?:www\.)?dcndigital\.ae/(?:#/)?live/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:awaan|dcndigital)\.ae/(?:#/)?live/(?P<id>\d+)'
-    _VALID_URL = r'https?://(?:www\.)?dcndigital\.ae/(?:#/)?program/(?:(?P<show_id>\d+)|season/(?P<season_id>\d+))'
+    _VALID_URL = r'https?://(?:www\.)?(?:awaan|dcndigital)\.ae/(?:#/)?program/(?:(?P<show_id>\d+)|season/(?P<season_id>\d+))'
-            'id': 'manofsteel',
+            'id': '5111',
-        'md5': 'c3b15ed1af288131115ff17a17c19dda',
+        'md5': 'b0005b542e5b4de643a9690326ab1257',
-        if not video_url:
+            r'0:{src:([\'"])(?P<url>.*?)\1', webpage,
-                ext = 'mp4'
+        formats = []
-                'ext': ext,
+                'ext': determine_ext(video_url, 'mp4'),
-__version__ = '2016.06.23'
+__version__ = '2016.06.23.1'
-                (?:function\s+%s|[{;,]%s\s*=\s*function|var\s+%s\s*=\s*function)\s*
+                (?:function\s+%s|[{;,]\s*%s\s*=\s*function|var\s+%s\s*=\s*function)\s*
-    _VALID_URL = r'''(?x)https?://(?:www\.)?(?:nbcnews|today)\.com/
+    _VALID_URL = r'''(?x)https?://(?:www\.)?(?:nbcnews|today|msnbc)\.com/
-        ([^/]+/)*(?P<display_id>[^/?]+))
+        ([^/]+/)*(?:.*-)?(?P<mpx_id>[^/?]+))
-                'id': 'Wjf9EDR3A_60',
+                'id': '529953347624',
-                'description': 'md5:d22d1281a24f22ea0880741bb4dd6301',
+                'title': 'Volkswagen U.S. Chief:\xa0 We Have Totally Screwed Up',
-            'expected_warnings': ['http-6000 is not available']
+                'uploader': 'NBCU-NEWS',
-                    subtitles = self._merge_subtitles(subtitles, tp_subtitles)
+            video_id = mobj.group('mpx_id')
-            self._sort_formats(formats)
+                    info = bootstrap
-                'subtitles': subtitles,
+                # http://feed.theplatform.com/f/2E2eJC/nbcnews also works
-            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8}).*?\1',
+            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8})\1',
-__version__ = '2016.06.22'
+__version__ = '2016.06.23'
-    _VALID_URL = r'^https?://(?:video|www)\.xnxx\.com/video-?(?P<id>[0-9a-z]+)/(.*)'
+    _VALID_URL = r'https?://(?:video|www)\.xnxx\.com/video-?(?P<id>[0-9a-z]+)/'
-        'md5': '6a2a6aff3f10467d94e572edb7b7deb6',
+        'url': 'http://www.xnxx.com/video-55awb78/skyrim_test_video',
-            'id': '6gqggeb',
+            'id': '55awb78',
-            'title': 'HD STAR-581 sam',
+            'title': 'Skyrim Test Video',
-        'md5': '0831677e2b4761795f68d417e0b7b445',
+    _VALID_URL = r'^https?://(?:video|www)\.xnxx\.com/video-?(?P<id>[0-9a-z]+)/(.*)'
-            'id': '1135332',
+            'id': '6gqggeb',
-            'title': 'lida Â» Naked Funny Actress  (5)',
+            'title': 'HD STAR-581 sam',
-    }
+        },
-            request, None, note='Logging in as %s' % username)
+            'https://login.vk.com/?act=login', None,
-        login_page = self._download_webpage(
+        login_page, url_handle = self._download_webpage_handle(
-    _VALID_URL = r'https://vimeo\.com/album/(?P<id>\d+)/?(?:$|[?#])'
+    _VALID_URL = r'https://vimeo\.com/album/(?P<id>\d+)(?:$|[?#]|/(?!video))'
-                        (?!channels/[^/?#]+/?(?:$|[?#])|[^/]+/review/|(?:album|ondemand)/)
+                        (?!(?:channels|album)/[^/?#]+/?(?:$|[?#])|[^/]+/review/|ondemand/)
-                yield self.url_result('https://vimeo.com/%s' % video_id, 'Vimeo', video_id=video_id)
+            # Try extracting href first since not all videos are available via
-    _VALID_URL = r'https://vimeo\.com/album/(?P<id>\d+)'
+    _VALID_URL = r'https://vimeo\.com/album/(?P<id>\d+)/?(?:$|[?#])'
-                yield self.url_result('https://vimeo.com/%s' % video_id, 'Vimeo')
+                yield self.url_result('https://vimeo.com/%s' % video_id, 'Vimeo', video_id=video_id)
-            'md5': '53c688fa95a55bf4b7293d37a89c5c53',
+            'md5': '2d9f5475e0537f013d0073e812ab89e6',
-        else:
+        elif any(p in url for p in ('play_redirect_hls', 'moogaloop.swf')):
-from youtube_dl.extractor.common import InfoExtractor
+from youtube_dl.extractor.common import InfoExtractor, SearchInfoExtractor
-module_contents = [module_template + '\n' + getsource(InfoExtractor.suitable)]
+module_contents = [
-class {name}(LazyLoadExtractor):
+class {name}({bases}):
-    name = ie.ie_key() + 'IE'
+for ie in ordered_cls:
-    names.append(name)
+    if ie in _ALL_CLASSES:
-__version__ = '2016.06.20'
+__version__ = '2016.06.22'
-
+    def _extract_video(self, video_info, video_id):
-        age_limit = 18 if video_info.get('inappropriateForChildren') else 0
+        title = video_info.get('title')
-        info_dict = self._extract_video(info, article_id)
+        info_dict = self._extract_video(info['video'], article_id)
-    _TEST = {
+    _TESTS = [{
-        return info['context']['dispatcher']['stores']['VideoTitlePageStore']['data']['video']
+    }, {
-            r'root\["__svtplay"\]\s*=\s*([^;]+);', webpage, 'embedded data'), video_id)
+        data = self._parse_json(
-        return info_dict
+        if data:
-from .common import InfoExtractor
+from .once import OnceIE
-    compat_urlparse,
+    url_basename,
-class GameSpotIE(InfoExtractor):
+class GameSpotIE(OnceIE):
-        data_video = json.loads(unescapeHTML(data_video_json))
+        data_video = self._parse_json(unescapeHTML(data_video_json), page_id)
-        else:
+        if f4m_url:
-        info = self._download_json(url, video_id)
+    def _extract_video(self, info, video_id):
-        subtitle_references = video_info.get('subtitleReferences')
+        subtitle_references = dict_get(video_info, ('subtitles', 'subtitleReferences'))
-                    subtitles.setdefault('sv', []).append({'url': subtitle_url})
+                    if determine_ext(subtitle_url) == 'm3u8':
-        'md5': '9648197555fc1b49e3dc22db4af51d46',
+        'md5': '33e9a5d8f646523ce0868ecfb0eed77d',
-            'title': 'HÃ¤r trycker Jagr till Giroux (under SVT-intervjun)',
+            'ext': 'mp4',
-        return self._extract_video(
+
-    _VALID_URL = r'https?://(?:www\.)?(?P<host>svtplay|oppetarkiv)\.se/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:svtplay|oppetarkiv)\.se/video/(?P<id>[0-9]+)'
-            video_id)
+        video_id = self._match_id(url)
-            r'file:\s*"([^"]+)"', webpage, 'video URL')
+            url, video_id, data=urlencode_postdata(fields), headers={
-__version__ = '2016.06.19.1'
+__version__ = '2016.06.20'
-        check_results.append(not (re.search(r'#EXT-X-KEY:METHOD=AES-128', manifest) and not can_decrypt_frag))
+        check_results.append(can_decrypt_frag or '#EXT-X-KEY:METHOD=AES-128' not in manifest)
-                        frag_content = AES.new(decrypt_info['KEY'], AES.MODE_CBC, iv).decrypt(frag_content)
+                        iv = decrypt_info.get('IV') or compat_struct_pack('>8xq', media_sequence)
-                            decrypt_info['URI'] = compat_urlparse.urljoin(man_url, decrypt_info['URI'])
+                            decrypt_info['URI'] = compat_urlparse.urljoin(
-                    variable, self.extract_object(variable))
+                if variable not in self._objects:
-            self._functions.setdefault(fname, self.extract_function(fname))
+            if fname not in self._functions:
-    _VALID_URL = r'(?:cbs|https?://(?:www\.)?(?:cbs\.com/shows/[^/]+/video|colbertlateshow\.com/(?:video|podcasts))/)(?P<id>[\w-]+)'
+    _VALID_URL = r'(?:cbs:|https?://(?:www\.)?(?:cbs\.com/shows/[^/]+/video|colbertlateshow\.com/(?:video|podcasts))/)(?P<id>[\w-]+)'
-from .theplatform import ThePlatformIE
+from .theplatform import ThePlatformFeedIE
-class CBSBaseIE(ThePlatformIE):
+class CBSBaseIE(ThePlatformFeedIE):
-    _VALID_URL = r'(?:cbs:(?P<content_id>\w+)|https?://(?:www\.)?(?:cbs\.com/shows/[^/]+/(?:video|artist)|colbertlateshow\.com/(?:video|podcasts))/[^/]+/(?P<display_id>[^/]+))'
+    _VALID_URL = r'(?:cbs|https?://(?:www\.)?(?:cbs\.com/shows/[^/]+/video|colbertlateshow\.com/(?:video|podcasts))/)(?P<id>[\w-]+)'
-        },
+        'expected_warnings': ['Failed to download m3u8 information'],
-        return info
+        content_id = self._match_id(url)
-                'id': 'fort-hood-shooting-army-downplays-mental-illness-as-cause-of-attack',
+                'id': 'SNJBOYzXiWBOvaLsdzwH8fmtP1SCd91Y',
-        }
+        guid = item['mpxRefId']
-import re
+from .cbs import CBSBaseIE
-from .common import InfoExtractor
+class CBSSportsIE(CBSBaseIE):
-        'url': 'http://www.cbssports.com/video/player/tennis/318462531970/0/us-open-flashbacks-1990s',
+    _TESTS = [{
-            'description': 'Bill Macatee relives the best moments in US Open history from the 1990s.',
+            'id': '708337219968',
-    }
+        'params': {
-        return self.url_result('theplatform:%s' % video_info['pid'], 'ThePlatform')
+        video_id = self._match_id(url)
-    _TEST = {
+    _URL_TEMPLATE = '%s//feed.theplatform.com/f/%s/%s?form=json&%s'
-        feed_id = mobj.group('feed_id')
+    }]
-        entry = feed['entries'][0]
+    def _extract_feed_info(self, provider_id, feed_id, filter_query, video_id, custom_fields=None, asset_types_query={}):
-            smil_url = item['plfile$url'] + '&mbr=true'
+            smil_url = item['plfile$url']
-            subtitles = self._merge_subtitles(subtitles, cur_subtitles)
+            for asset_type in item['plfile$assetTypes']:
-from ..utils import(
+from ..utils import (
-from ..utils import smuggle_url
+from ..utils import (
-            'ext': 'flv',
+            'id': 'i0qKWsk3qJaM',
-            config['releaseURL'] + '&manifest=f4m', {'force_smil_url': True}))
+        return self.url_result(smuggle_url(update_url_query(
-from ..compat import compat_urlparse
+from ..compat import (
-            r'#EXT-X-KEY:METHOD=(?!NONE)',  # encrypted streams [1]
+            r'#EXT-X-KEY:METHOD=(?!NONE|AES-128)',  # encrypted streams [1]
-        return all(not re.search(feature, manifest) for feature in UNSUPPORTED_FEATURES)
+        check_results = [not re.search(feature, manifest) for feature in UNSUPPORTED_FEATURES]
-        fragment_urls = []
+        total_frags = 0
-                    break
+                total_frags += 1
-            'total_frags': len(fragment_urls),
+            'total_frags': total_frags,
-            frags_filenames.append(frag_sanitized)
+        for line in s.splitlines():
-                    last_info[m.group('key')] = v
+                last_info = parse_m3u8_attributes(line)
-                    last_media[m.group('key')] = v
+                last_media = parse_m3u8_attributes(line)
-__version__ = '2016.06.19'
+__version__ = '2016.06.19.1'
-        if '>You rented this title.<' in webpage:
+        def is_rented():
-                obj = self._objects[variable]
+                obj = self._objects.setdefault(
-                self._functions[fname] = self.extract_function(fname)
+            self._functions.setdefault(fname, self.extract_function(fname))
-__version__ = '2016.06.18.1'
+__version__ = '2016.06.19'
-from .r7 import R7IE
+from .r7 import (
-)
+from ..utils import int_or_none
-    _VALID_URL = r'''(?x)https?://
+    _VALID_URL = r'''(?x)
-                        '''
+                    '''
-            'http://player.r7.com/video/i/%s' % video_id, video_id)
+        video = self._download_json(
-        view_count = int_or_none(statistics.get('views'))
+        title = video['title']
-                })
+        media_url_hls = video.get('media_url_hls')
-            }
+    _VALID_URL = r'https?://(?:www\.)?closertotruth\.com/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-            }
+        'params': {
-            }
+    }, {
-    ]
+        'playlist_mincount': 2,
-        webpage = self._download_webpage(url, video_id)
+        display_id = self._match_id(url)
-        video_title = self._search_regex(r'<title>(.+) \|.+</title>', webpage, 'video title')
+        webpage = self._download_webpage(url, display_id)
-        entry_id = self._search_regex(r'<a[^>]+id="(?:video-%s|embed-kaltura)"[^>]+data-kaltura="([^"]+)' % video_id, webpage, "video entry_id")
+        partner_id = self._search_regex(
-        interviewee_name = self._search_regex(r'<div id="(?:node_interview_full_group_white_wrapper|node_interview_series_full_group_ajax_content)"(?:.|\n)*<h3>(.*)</h3>.+', webpage, "video interviewee_name", False)
+        title = self._search_regex(
-            video_title = video_title + ' - ' + interviewee_name
+        select = self._search_regex(
-        p_id = self._search_regex(r'<script[^>]+src=["\'].+?partner_id/(\d+)', webpage, "kaltura partner_id")
+        entry_id = self._search_regex(
-            'url': 'kaltura:%s:%s' % (p_id, entry_id),
+            'display_id': display_id,
-            'title': video_title
+            'title': title
-    _VALID_URL = r'https?://(?:(?:www|sites)\.)?arte\.tv/[^/]+/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions|embed)/)?(?P<id>[^/]+)/(?P<name>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:(?:www|sites)\.)?arte\.tv/[^/]+/(?P<lang>fr|de|en|es)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-    }. {
+    }, {
-    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions|embed)/)?(?P<id>[^/]+)/(?P<name>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:(?:www|sites)\.)?arte\.tv/[^/]+/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions|embed)/)?(?P<id>[^/]+)/(?P<name>[^/?#&]+)'
-    SportschauIE,
+from .sportschau import SportschauIE
-class WDRIE(InfoExtractor):
+class WDRBaseIE(InfoExtractor):
-            # HDS download, MD5 is unstable
+            'md5': '803138901f6368ee497b4d195bb164f2',
-                'ext': 'flv',
+                'ext': 'mp4',
-            webpage, 'media link', default=None, flags=re.MULTILINE)
+        info_dict = self._extract_wdr_video(webpage, display_id)
-        if not json_metadata:
+        if not info_dict:
-            upload_date = unified_strdate(upload_date)
+            info_dict.update({
-            'upload_date': upload_date,
+        info_dict.update({
-        }
+        })
-            }
+            },
-            }
+            },
-            }
+            },
-        uploader_id = data['user']['id']
+        description = data.get('description')
-        duration = float_or_none(stream_params['length'], 1000)
+        timestamp = float_or_none(stream_params.get('creationDate'), 1000)
-        return self.url_result(embed_url)
+        entries = [
-        'url': 'http://creative.arte.tv/de/magazin/agentur-amateur-corporate-design',
+        'url': 'http://creative.arte.tv/fr/episode/osmosis-episode-1',
-            'id': '72176',
+            'id': '057405-001-A',
-            'upload_date': '20131004',
+            'title': 'OSMOSIS - N\'AYEZ PLUS PEUR D\'AIMER (1)',
-        }
+        'playlist_count': 11,
-        'md5': '6b275511a5107c60bacbeeda368c3aa1',
+        'url': 'http://cinema.arte.tv/fr/article/les-ailes-du-desir-de-julia-reck',
-            'id': '055876-000_PWA12025-D',
+            'id': '062494-000-A',
-            'description': 'md5:7f749bbb77d800ef2be11d54529b96bc',
+            'title': 'Film laurÃ©at du concours web - "Les ailes du dÃ©sir" de Julia Reck',
-        meta_url = 'http://aftonbladet-play.drlib.aptoma.no/video/%s.json'
+        meta_url = 'http://aftonbladet-play-metadata.cdn.drvideo.aptoma.no/video/%s.json'
-        internal_meta_id = player_config['videoId']
+        internal_meta_id = player_config['aptomaVideoId']
-        video_data = self._download_json(url + '?format=json', video_id)
+        webpage = self._download_webpage(url, video_id)
-                    'url': self._transform_rtmp_url(rtmp_video_url),
+                    'ext': 'flv' if new_url.startswith('rtmp') else ext,
-)
+from .mtv import MTVServicesInfoExtractor
-class BetIE(InfoExtractor):
+class BetIE(MTVServicesInfoExtractor):
-                'id': 'news/national/2014/a-conversation-with-president-obama',
+                'id': '07e96bd3-8850-3051-b856-271b457f0ab8',
-                'description': 'md5:699d0652a350cf3e491cd15cc745b5da',
+                'description': 'President Obama urges persistence in confronting racism and bias.',
-                'uploader': 'admin',
+                'subtitles': {
-                'id': 'news/national/2014/justice-for-ferguson-a-community-reacts',
+                'id': '9f516bf1-7543-39c4-8076-dd441b459ba9',
-                'uploader': 'admin',
+                'subtitles': {
-            webpage, 'media URL'))
+    _FEED_URL = "http://feeds.mtvnservices.com/od/feed/bet-mrss-player"
-            r'/video/(.*)/_jcr_content/', media_url, 'video id')
+    def _get_feed_query(self, uri):
-        }
+    def _extract_mgid(self, webpage):
-            'uploader', fatal=False)
+    def _real_extract(self, url):
-        smil_url = media_content.get('url')
+        webpage = self._download_webpage(url, display_id)
-            xpath_with_ns('./media:thumbnail', NS_MAP)).get('url')
+        info_dict = videos_info['entries'][0]
-        self._sort_formats(formats)
+        upload_date = unified_strdate(self._html_search_meta('date', webpage))
-            'id': video_id,
+        info_dict.update({
-        }
+            'upload_date': upload_date,
-__version__ = '2016.06.18'
+__version__ = '2016.06.18.1'
-__version__ = '2016.06.16'
+__version__ = '2016.06.18'
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-import json
+    ExtractorError,
-        sources = json.loads(js_to_json(self._search_regex(
+        sources = self._parse_json(js_to_json(self._search_regex(
-            webpage, 'sources')))
+            webpage, 'sources', default='{}')), video_id)
-        for qname, video_url in sources.items():
+        for format_id, video_url in sources.items():
-                'quality': quality(qname),
+                'format_id': format_id,
-            r'<div class="description">([^<]+)</div>', webpage, 'description', fatal=False)
+            r'<(div|p)[^>]+class="description"[^>]*>(?P<value>[^<]+)</\1',
-            r'(\d+) views\s*</span>', webpage, 'view count', fatal=False))
+            r'(\d+) views\s*<', webpage, 'view count', fatal=False))
-            title_el = itemdoc.find('.//{http://search.yahoo.com/mrss/}title')
+            title_el = itemdoc.find(compat_xpath('.//{http://search.yahoo.com/mrss/}title'))
-            title_el = itemdoc.find('.//title') or itemdoc.find('./title')
+            title_el = itemdoc.find(compat_xpath('.//title'))
-from .nick import NickIE
+from .nick import (
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r'class="Destacado-text"[^>]*>\s*<strong>([^<]+)</strong>', webpage, 'title')
+            r'class="Destacado-text"[^>]*>\s*<strong>([^<]+)</strong>',
-                        (?P<id>%s)
+                        (?P<id>%s)(?!/(?:episodes|broadcasts|clips))
-        return False if BBCCoUkIE.suitable(url) or BBCCoUkArticleIE.suitable(url) else super(BBCIE, cls).suitable(url)
+        EXCLUDE_IE = (BBCCoUkIE, BBCCoUkArticleIE, BBCCoUkIPlayerPlaylistIE, BBCCoUkPlaylistIE)
-__version__ = '2016.06.14'
+__version__ = '2016.06.16'
-                r"url:\\'(.+?)\\'", unpacked, '%s url' % version, fatal=False)
+                r"(?:file|url)\s*:\s*(\\?[\"'])(?P<url>http.+?)\1", unpacked,
-                    r"duration:\\'(.+?)\\'", unpacked, 'duration', fatal=False))
+                    r"duration\s*:\s*(\\?[\"'])(?P<duration>.+?)\1",
-from .common import InfoExtractor
+from .jwplatform import JWPlatformBaseIE
-class WimpIE(InfoExtractor):
+class WimpIE(JWPlatformBaseIE):
-        'url': 'http://www.wimp.com/maruexhausted/',
+        'url': 'http://www.wimp.com/maru-is-exhausted/',
-            'id': 'maruexhausted',
+            'id': 'maru-is-exhausted',
-        'md5': '4e2986c793694b55b37cf92521d12bb4',
+        'md5': '5c31ad862a90dc5b1f023956faec13fe',
-            'id': 'clowncar',
+            'id': 'cG4CEr2aiSg',
-            'description': 'md5:0e56db1370a6e49c5c1d19124c0d2fb2',
+            'title': 'Basset hound clown car...incredible!',
-            webpage, 'video URL', group='url')
+        info_dict = self._extract_jwplayer_data(
-        return {
+        info_dict.update({
-        }
+        })
-        (?:0[xX][0-9a-fA-F]+|0+[0-7]+)(?:\s*:)?|
+        \b(?:0[xX][0-9a-fA-F]+|0+[0-7]+)(?:\s*:)?|
-    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/video/[^/]+/vi(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/(?:video/[^/]+/|title/tt\d+.*?#lb-)vi(?P<id>\d+)'
-        'md5': 'bc78077859bea7bcfe4295d7d7fc9025',
+        'url': 'http://vexling.wrzuta.pl/audio/01xBFabGXu6/james_horner_-_into_the_na_39_vi_world_bonus',
-            'description': 'md5:2d2b6340f9188c8c4cd891580e481096',
+            'id': '01xBFabGXu6',
-        webpage = self._download_webpage(url, video_id)
+        webpage, urlh = self._download_webpage_handle(url, video_id)
-        }
+        },
-            video_title = self._html_search_regex(r'<h1 [^>]+>([^<]+)', webpage, 'title')
+            title, thumbnail, duration = [None] * 3
-            'title': video_title,
+            'title': title,
-__version__ = '2016.06.12'
+__version__ = '2016.06.14'
-from .wrzuta import WrzutaPlaylistIE
+from .wrzuta import (
-
+    _VALID_URL = r'https?://(?P<uploader>[0-9a-zA-Z]+)\.wrzuta\.pl/playlista/(?P<id>[0-9a-zA-Z]+)'
-        playlist_size = int(playlist_size) if playlist_size else 0
+        playlist_size = int_or_none(self._html_search_regex(
-        playlist_title = self._og_search_title(webpage).replace('Playlista: ', '', 1)
+        playlist_title = remove_start(
-
+            entries = [
-                    ),
+                    'http://%s.wrzuta.pl/xhr/get_playlist_offset/%s' % (uploader, playlist_id),
-                entries += [self.url_result(entry['filelink']) for entry in playlist_content['files']]
+                    'Downloading playlist JSON',
-    parse_iso8601
+    int_or_none,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?rockstargames\.com/videos(?:/video/|#?/?\?.*\bvideo=)(?P<id>\d+)'
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': 're:^https?://.*\.jpg$',
-    }
+    }, {
-        formats = []
+        video = self._download_json(
-        for video in json_data['files_processed']['video/mp4']:
+        formats = []
-            
+            resolution = video.get('resolution')
-                'height': int(height) if height.isdigit() else -1,
+                'format_id': resolution,
-            'description': json_data.get('description'),
+            'title': title,
-            'timestamp': parse_iso8601(json_data.get('created'))
+from .rockstargames import RockstarGamesIE
-    _FILE_NOT_FOUND_REGEX = r'>(?:404 - )?File Not Found<'
+    _FILE_NOT_FOUND_REGEXES = (
-        if re.search(self._FILE_NOT_FOUND_REGEX, webpage) is not None:
+        if any(re.search(p, webpage) for p in self._FILE_NOT_FOUND_REGEXES):
-            'ext': 'flv',
+            'ext': 'mp4',
-            webpage, 'file url')
+
-            self.to_stderr(stderr)
+            self.to_stderr(stderr.decode('utf-8', 'replace'))
-__version__ = '2016.06.11.3'
+__version__ = '2016.06.12'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'https?://(?:www\.)?nrk\.no/skole/klippdetalj?.*\btopic=(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?nrk\.no/skole/?\?.*\bmediaId=(?P<id>\d+)'
-        'md5': '04cd85877cc1913bce73c5d28a47e00f',
+        'url': 'https://www.nrk.no/skole/?page=search&q=&mediaId=14099',
-            'ext': 'flv',
+            'ext': 'mp4',
-        'url': 'http://www.nrk.no/skole/klippdetalj?topic=urn:x-mediadb:21379',
+        'url': 'https://www.nrk.no/skole/?page=objectives&subject=naturfag&objective=K15114&mediaId=19355',
-        video_id = compat_urllib_parse_unquote(self._match_id(url))
+        video_id = self._match_id(url)
-        webpage = self._download_webpage(url, video_id)
+        nrk_id = self._parse_json(
-            'duration': 1741.52,
+            'duration': 1741,
-            'duration': 4605.08,
+            'duration': 4605,
-        }
+            'thumbnail': 're:^https?://.*\.jpg',
-            desc = lowercase_escape(desc)
+
-            'url': self._og_search_video_url(webpage, secure=False),
+            'url': video_url,
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'description': description,
-            'description': desc,
+            'uploader': uploader,
-        'md5': '71ec5fcfddacf80f495efa8b6a8d9a89',
+        'md5': '3744d24c50438cf5b6f6d59feb5055c2',
-            r'(?s)<div[^>]+class=["\']videoInfoBy(?:\s+[^"\']+)?["\'][^>]*>\s*By:\s*</div>(.+?)</(?:a|div)>',
+            r'(?s)<div[^>]+class=["\']submitByLink["\'][^>]*>(.+?)</div>',
-            r'(?s)<div[^>]+class=["\']videoInfoTime["\'][^>]*>(.+?)</div>',
+            r'(?s)<div[^>]+class=["\']videoInfo(?:Date|Time)["\'][^>]*>(.+?)</div>',
-            r'<div[^>]+class=["\']videoInfoRating["\'][^>]*>\s*<div[^>]+class=["\']videoRatingPercentage["\'][^>]*>(\d+)%</div>',
+            r'<div[^>]+class=["\']videoRatingPercentage["\'][^>]*>(\d+)%</div>',
-            webpage, 'view count', fatal=False))
+            r'(?s)<div[^>]+class=(["\']).*?\bvideoInfoViews\b.*?\1[^>]*>.*?(?P<count>[\d,.]+)<',
-)
+from ..utils import xpath_text
-    _TEST = {
+    _VALID_URL = r'https?://matchtv\.ru(?:/on-air|/?#live-player)'
-    }
+    }, {
-            'http://player.matchtv.ntvplus.tv/player/smil?%s' % compat_urllib_parse_urlencode({
+        video_url = self._download_json(
-            }),
+            },
-        video_url = self._download_json(request, video_id)['data']['videoUrl']
+            })['data']['videoUrl']
-    def dict_selection(dict_obj, preferred_key):
+    def dict_selection(dict_obj, preferred_key, allow_fallback=True):
-        title = self.dict_selection(video.get('titles', {}), 'en')
+        title = self.dict_selection(video.get('titles', {}), 'en', allow_fallback=False)
-        'md5': '86c0b5dbd4d83a6611a79987cc7a1989',
+        'md5': 'feea2b1d7b3957f70886e6dfd8b8be84',
-        'md5': '190f3ef426005ba3a080a63325955bc3',
+        'md5': '1f54697dabc8f13f31bf06bb2e4de6db',
-            'duration': 4155,
+            'description': 'md5:b89cf50038b480b88b5b3c93589a9076',
-        'md5': '1713ae35df5a521b31f6dc40730e7c9c',
+        'md5': '013dc282714e22acf9447cad14ff1208',
-        'playlist_count': 70,
+        'playlist_mincount': 71,
-        }
+        },
-                'description': 'This is "youtube-dl password protected test video" by Jaime MarquÃ­nez FerrÃ¡ndiz on Vimeo, the home for high quality videos and the people\u2026',
+                'description': 'This is "youtube-dl password protected test video" by  on Vimeo, the home for high quality videos and the people who love them.',
-        return {
+        info_dict = self._parse_config(config, video_id)
-            'uploader_id': video_uploader_id,
+            'formats': formats,
-        }
+        })
-class VimeoReviewIE(InfoExtractor):
+class VimeoReviewIE(VimeoBaseInfoExtractor):
-        return self.url_result(player_url, 'Vimeo', video_id)
+        video_id = self._match_id(url)
-        },
+from .telewebion import TelewebionIE
-    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20150101 Firefox/44.0 (Chrome)',
+    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20150101 Firefox/47.0 (Chrome)',
-            'description': 'md5:6a7235a84cc6400ec3b38a7bdaf1d60c',
+            'title': 'Made\xa0Series\xa0ãMã',
-            'title': 'Bruno Mars',
+            'title': 'Bruno\xa0Mars',
-            'creator': '2PM',
+            'creator': 'PM02:00',
-    _VALID_URL = r'https?://www\.le\.com/ptv/vplay/(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://(?:www\.le\.com/ptv/vplay|sports\.le\.com/video)/(?P<id>\d+)\.html'
-    _VALID_URL = r'https?://[a-z]+\.le\.com/[a-z]+/(?P<id>[a-z0-9_]+)'
+    _VALID_URL = r'https?://[a-z]+\.le\.com/(?!video)[a-z]+/(?P<id>[a-z0-9_]+)'
-__version__ = '2016.06.11.2'
+__version__ = '2016.06.11.3'
-__version__ = '2016.06.11.1'
+__version__ = '2016.06.11.2'
-                subtitles[lang] = [{
+                subtitles.setdefault(lang, []).append({
-                }]
+                })
-        for caption in properties.get('captions', {}):
+        for caption in properties.get('captions', []):
-    _VALID_URL = r'(?:limelight:media:|https?://link\.videoplatform\.limelight\.com/media/\?.*?\bmediaId=)(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'''(?x)
-    _TEST = {
+    _VALID_URL = r'''(?x)
-    }
+    }, {
-    _TEST = {
+    _VALID_URL = r'''(?x)
-    }
+    }, {
-    _VALID_URL = r'(?:limelight:media:|https?://link\.videoplatform\.limelight\.com/media/\??\bmediaId=)(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'(?:limelight:media:|https?://link\.videoplatform\.limelight\.com/media/\?.*?\bmediaId=)(?P<id>[a-z0-9]{32})'
-    _VALID_URL = r'(?:limelight:channel:|https?://link\.videoplatform\.limelight\.com/media/\??\bchannelId=)(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'(?:limelight:channel:|https?://link\.videoplatform\.limelight\.com/media/\?.*?\bchannelId=)(?P<id>[a-z0-9]{32})'
-            'height': self._search_regex(r'\.(\d{3,4})\.mp4$', video_url, 'height', default=None),
+            'height': int_or_none(self._search_regex(
-__version__ = '2016.06.11'
+__version__ = '2016.06.11.1'
-__version__ = '2016.06.03'
+__version__ = '2016.06.11'
-        return self.playlist_result(entries, course_id, course_title)
+        return self.playlist_result(entries, course_id, course_title, course_description)
-from ..compat import compat_str
+from ..compat import (
-    _LOGIN_URL = 'https://www.lynda.com/login/login.aspx'
+    _SIGNIN_URL = 'https://www.lynda.com/signin'
-            raise ExtractorError('Unable to log in')
+        # Step 1: download signin page
-except ImportError:
+    compat_html_entities_html5 = compat_html_entities.html5
-            'md5': '35727f82f58c76d996fc188f9755b0d5',
+            'url': 'http://www.vulture.com/2016/06/new-key-peele-sketches-released.html',
-                'id': '0306a69b-8adf-4fb5-aace-75f8e8cbfca9',
+                'id': '769f7ec0-0692-4d62-9b45-0d88074bffc1',
-                'description': 'Mario\'s life in the fast lane has never looked so good.',
+                'title': 'Key and Peele|October 10, 2012|2|203|Liam Neesons - Uncensored',
-    _VALID_URL = r'(?:(?:https?://(?:\w+\.)?youtube\.com/(?:user/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:https?://(?:\w+\.)?youtube\.com/(?:user/|c/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'
-                    'id': api_response.get('id', song_id),
+                    'id': compat_str(api_response.get('id', song_id)),
-from ..compat import compat_urlparse
+from ..compat import (
-        'md5': '0554a24d1657915aa8e8f84e15dc9353',
+        'md5': 'b9174d651323f17783000876347116e3',
-            'description': 'md5:715ba964958afa2398df615809cfecb1',
+            'description': 'Secret surveillance programs have metadata too. The people and companies that operate secret surveillance programs can be surveilled.',
-            talk_id = data.get('talk_id') or display_id
+            talk_id = compat_str(data.get('talk_id') or display_id)
-            }
+            },
-                'categories': ['Big Boobs', 'Erotic', 'Teen', 'Female'],
+                'categories': ['Big Boobs', 'Erotic', 'Teen', 'Female', '720p'],
-def _htmlentity_transform(entity):
+def _htmlentity_transform(entity_with_semicolon):
-        r'&([^;]+);', lambda m: _htmlentity_transform(m.group(1)), s)
+        r'&([^;]+;)', lambda m: _htmlentity_transform(m.group(1)), s)
-
+    'compat_html_entities_html5',
-
+        # NBC News embed
-                r'(?m)var\s+(?:bootstrapJson|playlistData)\s*=\s*({.+});?\s*$',
+                [r'(?m)(?:var\s+(?:bootstrapJson|playlistData)|NEWS\.videoObj)\s*=\s*({.+});?\s*$',
-                bootstrap = self._parse_json(bootstrap_json, display_id)
+            bootstrap = self._parse_json(
-                info = self._parse_json(player_instance_json, display_id)
+                info = bootstrap
-        }
+        },
-            'region': region,
+            'region': region.upper(),
-                    'url': 'http://ondemand-ww.wdr.de/medp/fsk0/105/1058683/1058683_12220974.xml'
+                    'url': 'http://ondemand-ww.wdr.de/medp/fsk0/105/1058683/1058683_12220974.xml',
-                'url': caption_url
+                'url': caption_url,
-    _VALID_URL = r'https?://(?:www\.)?god\.tv(?:/[^/]+)+/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?god\.tv(?:/[^/]+)*/(?P<id>[^/?#&]+)'
-# coding: utf-8
+from ..utils import js_to_json
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        ooyala_id = self._search_regex(r'"content_id"\s*:\s*"([\w-]{32})"', webpage, display_id)
+
-    _VALID_URL = r'https://openload.(?:co|io)/(?:f|embed)/(?P<id>[a-zA-Z0-9-]+)'
+    _VALID_URL = r'https://openload.(?:co|io)/(?:f|embed)/(?P<id>[a-zA-Z0-9-_]+)'
-            r'</video>\s*</div>\s*<script[^>]+>([^<]+)</script>',
+            r'</video>\s*</div>\s*<script[^>]+>[^>]+</script>\s*<script[^>]+>([^<]+)</script>',
-    _PAGE_REGEX = r'/(?:mediathek/)?(?P<media_type>[^/]+)/(?P<type>[^/]+)/(?P<display_id>.+)\.html'
+    _PAGE_REGEX = r'/(?:mediathek/)?[^/]+/(?P<type>[^/]+)/(?P<display_id>.+)\.html'
-                    m3u_fmt = self._extract_m3u8_formats(
+                    formats.extend(self._extract_m3u8_formats(
-                    formats.extend(m3u_fmt)
+                        m3u8_id='hls'))
-
+    update_url_query,
-                'ext': 'mp3',
+                'ext': 'flv',
-                formats.extend(self._extract_smil_formats(video_url, 'stream', fatal=False))
+        for kind, media_resource in metadata_media_resource.items():
-    _PAGE_REGEX = r'/mediathek/(?P<media_type>[^/]+)/(?P<type>[^/]+)/(?P<display_id>.+)\.html'
+    _PAGE_REGEX = r'/(?:mediathek/)?(?P<media_type>[^/]+)/(?P<type>[^/]+)/(?P<display_id>.+)\.html'
-            r'class=(?:"mediaLink\b[^"]*"[^>]+|"videoLink\b[^"]*"[\s]*>\n[^\n]*)data-extension="([^"]+)"',
+            r'class=(?:"(?:mediaLink|wdrrPlayerPlayBtn)\b[^"]*"[^>]+|"videoLink\b[^"]*"[\s]*>\n[^\n]*)data-extension="([^"]+)"',
-                    if determine_ext(alt_url) == 'm3u8':
+                    ext = determine_ext(alt_url)
-                        formats.append({
+                        a_format = {
-                        })
+                        }
-                    entry_protocol='m3u8_native', m3u8_id='m3u8'))
+                    entry_protocol='m3u8_native', m3u8_id='m3u8', fatal=False))
-            if f.get('name') == 'hls-index':
+            name = f.get('name')
-                    'format_id': f.get('name'),
+                    'format_id': name,
-                    location, video_id, ext='mp4', m3u8_id='m3u8'))
+                    location, video_id, ext='mp4',
-    _VALID_URL = r'https?://(?:www\.)?vessel\.com/videos/(?P<id>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?vessel\.com/(?:videos|embed)/(?P<id>[0-9a-zA-Z]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            if f['name'] == 'hls-index':
+            location = f.get('location')
-                    f['location'], video_id, ext='mp4', m3u8_id='m3u8'))
+                    location, video_id, ext='mp4', m3u8_id='m3u8'))
-                    'format_id': f['name'],
+                    'format_id': f.get('name'),
-                    'url': f['location'],
+                    'url': location,
-from .youku import YoukuIE
+from .youku import (
-                'description': 'Take a quick peek at what\'s new and improved in Ubuntu 11.10.\n\nOnce installed take a look at 10 Things to Do After Installing: http://www.omgubuntu.co.uk/2011/10/10-things-to-do-after-installing-ubuntu-11-10/',
+                'description': 'Take a quick peek at what\'s new and improved in Ubuntu 11.10.\n\nOnce installed take a look at 10 Things to Do After Installing: http://www.omgubuntu.co.uk/2011/10/10...',
-            'description': 'jay on Twitter: "BEAT PROD: @suhmeduh  https://t.co/HBrQ4AfpvZ #Damndaniel https://t.co/byBooq2ejZ"',
+            'title': 'Donte The Dumbass - BEAT PROD: @suhmeduh #Damndaniel',
-            'uploader': 'jay',
+            'uploader': 'Donte The Dumbass',
-            }
+            if determine_ext(video_url) == 'm3u8':
-            _search_dimensions_in_video_url(f, video_url)
+                _search_dimensions_in_video_url(f, video_url)
-            formats.append(f)
+                formats.append(f)
-        # md5 constantly changes
+        'params': {
-        webpage = self._download_webpage(self._TEMPLATE_URL % (user_id, twid), twid)
+        webpage, urlh = self._download_webpage_handle(
-        )/(?P<id>[A-Za-z0-9]+)/?$'''
+        )/(?:[^/]+/)?(?P<id>[A-Za-z0-9]+)/?$'''
-                    'Livestream', v['id'], v['caption']))
+                    'http://livestream.com/accounts/%s/events/%s/videos/%s' % (account_id, event_id, v_id),
-            'md5': 'e58c39c3e30077141d258bf588700a7b',
+            # HDS download, MD5 is unstable
-            'md5': 'ca365705551e4bd5217490f3b0591290',
+            # HDS download, MD5 is unstable
-            },
+    xpath_element,
-        bootstrap_info = xpath_text(
+        bootstrap_info = xpath_element(
-                'ext': 'flv' if bootstrap_info else None,
+                'ext': 'flv' if bootstrap_info is not None else None,
-        'md5': '12164a6f14ff6df8bd628e8ba9b10b78',
+        'url': 'http://www.canalplus.fr/c-emissions/pid1830-c-zapping.html?vid=1192814',
-            'id': '1263092',
+            'id': '1192814',
-            'upload_date': '20150513',
+            'title': "L'AnnÃ©e du Zapping 2014 - L'AnnÃ©e du Zapping 2014",
-        'url': 'http://www.d8.tv/d8-docs-mags/pid6589-d8-campagne-intime.html',
+        'url': 'http://www.d8.tv/d8-docs-mags/pid5198-d8-en-quete-d-actualite.html?vid=1390231',
-            'upload_date': '20131108',
+            'id': '1390231',
-        'md5': '38b8f7934def74f0d6f3ba6c036a5f82',
+        'url': 'http://www.itele.fr/chroniques/invite-bruce-toussaint/thierry-solere-nicolas-sarkozy-officialisera-sa-candidature-a-la-primaire-quand-il-le-voudra-167224',
-            'id': '1213714',
+            'id': '1398334',
-            'upload_date': '20150211',
+            'title': "L'invitÃ© de Bruce Toussaint du 07/06/2016 - ",
-    _VALID_URL = r'https?://(?:www\.(?P<site>canalplus\.fr|piwiplus\.fr|d8\.tv|itele\.fr)/.*?/(?P<path>.*)|player\.canalplus\.fr/#/(?P<id>[0-9]+))'
+    _VALID_URL = r'''(?x)
-        'itele.fr': 'itele',
+        'canalplus': 'cplus',
-        video_id = mobj.groupdict().get('id')
+        video_id = mobj.groupdict().get('id') or mobj.groupdict().get('vid')
-        site_id = self._SITE_ID_MAP[mobj.group('site') or 'canal']
+        site_id = self._SITE_ID_MAP[compat_urllib_parse_urlparse(url).netloc.rsplit('.', 2)[-2]]
-        display_id = url_basename(mobj.group('path'))
+        display_id = mobj.group('display_id') or video_id
-    releaser = GitHubReleaser(debuglevel=0)
+    releaser = GitHubReleaser()
-        version, name='youtube-dl %s' % version, draft=True, prerelease=True)
+    new_release = releaser.create_release(version, name='youtube-dl %s' % version)
-        '--load-info',
+        '--load-info-json', '--load-info',
-        compat_print(std_headers['User-Agent'])
+        write_string(std_headers['User-Agent'] + '\n', out=sys.stdout)
-            compat_print(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else ''))
+            write_string(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else '') + '\n', out=sys.stdout)
-                compat_print('  ' + mu)
+                write_string('  ' + mu + '\n', out=sys.stdout)
-            compat_print(desc)
+            write_string(desc + '\n', out=sys.stdout)
-            # be appended to the end of the playlist.
+            # Twitch vods of finished streams have EXT-X-PLAYLIST-TYPE:EVENT despite
-                                              # event media playlists [4]
+            #                                 # event media playlists [4]
-            item_id, 'mp4')
+            item_id, 'mp4', entry_protocol='m3u8_native')
-                                            # event media playlists [4]
+
-
+try:
-from .common import InfoExtractor
+from .common import InfoExtractor
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?vidio\.com/watch/(?P<id>\d+)-(?P<display_id>[^/?#&]+)'
-            'title': 'DJ_AMBRED - Booyah (Live 2015)',
+            'display_id': 'dj_ambred-booyah-live-2015',
-            'thumbnail': 'https://cdn0-a.production.vidio.static6.com/uploads/video/image/165683/dj_ambred-booyah-live-2015-bfb2ba.jpg',
+            'title': 'DJ_AMBRED - Booyah (Live 2015)',
-            'duration': 149, 
+            'thumbnail': 're:^https?://.*\.jpg$',
-    }
+    }, {
-            r'data-json-clips\s*=\s*"\[(.+)\]"', webpage, 'video data'), display_id)
+        title = self._og_search_title(webpage)
-            display_id, ext='mp4')
+        clips = self._parse_json(
-            'thumbnail': video_data.get('image'),
+            'display_id': display_id,
-            'duration': int_or_none(video_data.get('clip_duration')),
+            'thumbnail': thumbnail,
-            },
+    _VALID_URL = r'https?://(?:www\.)?channel9\.msdn\.com/(?P<contentpath>.+?)(?P<rss>/RSS)?/?(?:[?#&]|$)'
-            },
+    }, {
-    ]
+    }, {
-        rss = self._download_xml(self._RSS_URL % content_path, content_path, 'Downloading RSS')
+    def _extract_list(self, video_id, rss_url=None):
-        return self.playlist_result(entries, content_path, title_text)
+        return self.playlist_result(entries, video_id, title_text)
-        webpage = self._download_webpage(url, content_path, 'Downloading web page')
+        webpage = self._download_webpage(
-            page_type = page_type_m.group('pagetype')
+        page_type = self._search_regex(
-
+import re
-        title = derivative.get('shortName') or data.get('shortName') or self._og_search_title(webpage)
+        # embedded via <div class="media-player"
-        'only_matching': True,
+        'info_dict': {
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?loc\.gov/(?:item/|today/cyberlc/feature_wdesc\.php\?.*\brec=)(?P<id>[0-9]+)'
-    }
+    }, {
-             r'<video[^>]+data-uuid=(["\'])(?P<id>.+?)\1'),
+             r'<video[^>]+data-uuid=(["\'])(?P<id>.+?)\1',
-                video_id),
+        data = self._download_json(
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': self._og_search_thumbnail(webpage, default=None),
-__version__ = '2016.06.02'
+__version__ = '2016.06.03'
-from ..utils import determine_ext
+from ..utils import (
-    'url': 'http://loc.gov/item/90716351/',
+    _TEST = {
-            'title': 'Pa\'s trip to Mars /'
+            'title': "Pa's trip to Mars",
-    }]
+    }
-        json_id = self._search_regex('media-player-([0-9A-Z]{32})', webpage, 'json id')
+        media_id = self._search_regex(
-        data = data['mediaObject']
+        derivative = data['derivatives'][0]
-        media_url = data['derivatives'][0]['derivativeUrl']
+        # Following algorithm was extracted from setAVSource js function
-        if not determine_ext(media_url) in ('mp4', 'mp3'):
+        is_video = data.get('mediaType', 'v').lower() == 'v'
-            media_url = media_url.replace('vod/mp3:', '')
+        if 'vod/mp4:' in media_url:
-            })
+        title = derivative.get('shortName') or data.get('shortName') or self._og_search_title(webpage)
-            'title': self._og_search_title(webpage),
+            'duration': duration,
-                                        'aaaaaa', ['ae'], 'ceeeeiiiionoooooo', ['oe'], 'uuuuypy')))
+ACCENT_CHARS = dict(zip('ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÅÃÅÃÃÃÃÅ°ÃÃÃÃ Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã°Ã±Ã²Ã³Ã´ÃµÃ¶ÅÃ¸ÅÃ¹ÃºÃ»Ã¼Å±Ã½Ã¾Ã¿',
-            'AAAAAAAECEEEEIIIIDNOOOOOOOEUUUUYPssaaaaaaaeceeeeiiiionoooooooeuuuuypy')
+            'ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÅÃÅÃÃÃÃÅ°ÃÃÃÃ Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã°Ã±Ã²Ã³Ã´ÃµÃ¶ÅÃ¸ÅÃ¹ÃºÃ»Ã¼Å±Ã½Ã¾Ã¿', restricted=True),
-    if os.name == 'java':
+    if os.name == 'java' and isinstance(httpd.socket, ssl.SSLSocket):
-        self.port = sock.getsockname()[1]
+        self.port = http_server_port(self.httpd)
-        self.port = self.proxy.socket.getsockname()[1]
+        self.port = http_server_port(self.proxy)
-        self.cn_port = self.cn_proxy.socket.getsockname()[1]
+        self.cn_port = http_server_port(self.cn_proxy)
-from .revision3 import Revision3IE
+from .revision3 import (
-    _VALID_URL = r'https?://(?:www\.)?(?P<domain>(?:revision3|testtube|animalist)\.com)/(?P<id>[^/]+(?:/[^/?#]+)?)'
+    IE_NAME = 'revision'
-        'add_ie': ['Youtube'],
+        'url': 'http://revision3.com/variant',
-        'playlist_mincount': 9,
+        'url': 'http://revision3.com/vr',
-                'formats': formats,
+                '_type': 'url_transparent',
-__version__ = '2016.05.30.2'
+__version__ = '2016.06.02'
-
+class ArteTVBaseIE(InfoExtractor):
-
+class ArteTVPlus7IE(ArteTVBaseIE):
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-            f = {
+            m = re.search(r'/(?P<height>\d+)[pP]_(?P<tbr>\d+)[kK]', path)
-            formats.append(f)
+                'tbr': tbr,
-            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8})(?:.*?)?\1',
+            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8}).*?\1',
-            'url': 'http://www.udn.com/news/story/7314/822787',
+            'url': 'https://video.udn.com/news/300346',
-            }
+            },
-        }
+        },
-            r'var options\s*=\s*([^;]+);', page, 'video urls dictionary')))
+            r'var\s+options\s*=\s*([^;]+);', page, 'video urls dictionary')))
-            pass
+        formats = []
-            'url': self._download_webpage(
+            video_url = self._download_webpage(
-        } for video_type, api_url in video_urls.items() if api_url]
+                note='retrieve url for %s video' % video_type)
-            raise ExtractorError('No videos found', expected=True)
+            ext = determine_ext(video_url)
-            thumbnail = options['gallery'][0].get('original')
+        thumbnails = [{
-            'thumbnail': thumbnail
+            'thumbnails': thumbnails,
-        },
+    }, {
-        mobj = (re.search(r"(?s)kWidget\.(?:thumb)?[Ee]mbed\(\{.*?'wid'\s*:\s*'_?(?P<partner_id>[^']+)',.*?'entry_?[Ii]d'\s*:\s*'(?P<id>[^']+)',", webpage) or
+        mobj = (re.search(r"(?s)kWidget\.(?:thumb)?[Ee]mbed\(\{.*?(?P<q1>['\"])wid(?P=q1)\s*:\s*(?P<q2>['\"])_?(?P<partner_id>[^'\"]+)(?P=q2),.*?(?P<q3>['\"])entry_?[Ii]d(?P=q3)\s*:\s*(?P<q4>['\"])(?P<id>[^'\"]+)(?P=q4),", webpage) or
-        if xpath_text(video_xml, './track/flag', default='FAIL') != 'SUCCEED':
+        if xpath_element(video_xml, './track/video/file') is None:
-        dest='ratelimit', metavar='LIMIT',
+        '-r', '--limit-rate', '--rate-limit',
-                expected=True)
+            self._raise_captcha()
-__version__ = '2016.05.30.1'
+__version__ = '2016.05.30.2'
-__version__ = '2016.05.30'
+__version__ = '2016.05.30.1'
-__version__ = '2016.05.21.2'
+__version__ = '2016.05.30'
-                        action='store', default='localhost:8142',
+                        action='store', default='0.0.0.0:8142',
-                compat_winreg.HKEY_LOCAL_MACHINE, r'SOFTWARE\Python\PythonCore\%s\InstallPath' % python_version)
+        python_path = None
-        except Exception:
+                key = compat_winreg.OpenKey(
-import sys
+PREFIX = '''%YOUTUBE-DL(1)
-    print(readme)
+if __name__ == '__main__':
-from socketserver import ThreadingMixIn
+import shutil
-class BuildHTTPServer(ThreadingMixIn, HTTPServer):
+try:
-    input('Press ENTER to shut down')
+    compat_input('Press ENTER to shut down')
-        pythonVersion = kwargs.pop('python', '2.7')
+        python_version = kwargs.pop('python', '3.4')
-            key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE, r'SOFTWARE\Python\PythonCore\%s\InstallPath' % pythonVersion)
+            key = compat_winreg.OpenKey(
-                self.pythonPath, _ = _winreg.QueryValueEx(key, '')
+                self.pythonPath, _ = compat_winreg.QueryValueEx(key, '')
-                _winreg.CloseKey(key)
+                compat_winreg.CloseKey(key)
-            raise BuildError('No such Python version: %s' % pythonVersion)
+            raise BuildError('No such Python version: %s' % python_version)
-                                    cwd=self.buildPath)
+            proc = subprocess.Popen([os.path.join(self.pythonPath, 'python.exe'), 'setup.py', 'py2exe'], stdin=subprocess.PIPE, cwd=self.buildPath)
-class BuildHTTPRequestHandler(BaseHTTPRequestHandler):
+class BuildHTTPRequestHandler(compat_http_server.BaseHTTPRequestHandler):
-        paramDict = dict([(key, value[0]) for key, value in urlparse.parse_qs(path.query).items()])
+        path = compat_urlparse.urlparse(self.path)
-                    msg = unicode(e).encode('UTF-8')
+                    msg = compat_str(e).encode('UTF-8')
-
+import calendar
-from ..compat import compat_str
+from ..compat import (
-    unescapeHTML,
+    int_or_none,
-    _VALID_URL = r'https?://www\.bilibili\.(?:tv|com)/video/av(?P<id>\d+)(?:/index_(?P<page_num>\d+).html)?'
+    _VALID_URL = r'https?://www\.bilibili\.(?:tv|com)/video/av(?P<id>\d+)'
-        'md5': '2c301e4dab317596e837c3e7633e7d86',
+        'md5': '5f7d29e1a2872f3df0cf76b1f87d3788',
-            'duration': 308313,
+            'description': 'md5:ce18c2a2d2193f0df2917d270f2e5923',
-            'timestamp': 1397983878,
+            'uploader_id': '156160',
-            'timestamp': 1396501299,
+    # BiliBili blocks keys from time to time. The current key is extracted from
-            raise ExtractorError('%s said: %s' % (self.IE_NAME, view_data['error']), expected=True)
+        webpage = self._download_webpage(url, video_id)
-        title = unescapeHTML(view_data['title'])
+        info_xml_str = self._download_webpage(
-        )
+        err_msg = None
-            raise ExtractorError('%s said: %s' % (self.IE_NAME, xpath_text(doc, './message')), expected=True)
+        if info_xml is not None:
-        for durl in doc.findall('./durl'):
+        for durl in durls:
-            formats.reverse()
+            for backup_url in durl.findall('./backup_url/url'):
-                'title': title,
+        title = self._html_search_regex('<h1[^>]+title="([^"]+)">', webpage, 'title')
-            'duration': int_or_none(xpath_text(doc, './timelength')),
+            'description': description,
-            info.update({
+            return {
-            return info
+            }
-            return any(p in webpage for p in ['href="https://www.udemy.com/user/logout/', '>Logout<'])
+            return any(re.search(p, webpage) for p in (
-        info_url = url
+            tbr = int_or_none(media_el.attrib.get('bitrate'))
-                    formats.extend(self._extract_f4m_formats(
+                    f4m_formats = self._extract_f4m_formats(
-                        transform_source=transform_source, fatal=fatal))
+                        transform_source=transform_source, fatal=fatal)
-                'format_id': '-'.join(filter(None, [f4m_id, compat_str(i if tbr is None else tbr)])),
+                'format_id': format_id,
-                'height': int_or_none(media_el.attrib.get('height')),
+                'width': width,
-        if requested_bitrate is None:
+        if requested_bitrate is None or len(formats) == 1:
-            'playlist_mincount': 10,
+            'playlist_mincount': 8,
-                    r'<a href="(%s)"' % self._PAGE_REGEX,
+                    r'<a href="(%s)"[^>]+data-extension=' % self._PAGE_REGEX,
-    _CURRENT_MAUS_URL = r'https?://www.wdrmaus.de/aktuelle-sendung/(wdr|index).php5'
+    _CURRENT_MAUS_URL = r'https?://(?:www\.)wdrmaus.de/(?:[^/]+/){1,2}[^/?#]+\.php5'
-        }
+    js_to_json,
-        js_url = self._search_regex(self._JS_URL_REGEX, webpage, 'js_url', default=None)
+        # for wdr.de the data-extension is in a tag with the class "mediaLink"
-        if not js_url:
+        if not json_metadata:
-            js_url, 'metadata', transform_source=strip_jsonp)
+            jsonp_url, 'metadata', transform_source=strip_jsonp)
-                'ext': 'flv',
+                'ext': 'mp4',
-            }
+            },
-                    })
+                    alt_url = metadata_media_alt[tag_name]
-        metadata = self._parse_json(json_data, display_id)
+        metadata = self._download_json(
-    _VALID_URL = r'(?P<page_url>https?://(?:www\d\.)?wdr\d?\.de)' + _PAGE_REGEX + "|" + _CURRENT_MAUS_URL
+    _VALID_URL = r'(?P<page_url>https?://(?:www\d\.)?wdr\d?\.de)' + _PAGE_REGEX + '|' + _CURRENT_MAUS_URL
-        metadata_media_resource = metadata["mediaResource"]
+        metadata_tracker_data = metadata['trackerData']
-        metadata_media_alt = metadata_media_resource.get("alt")
+        metadata_media_alt = metadata_media_resource.get('alt')
-            for tag_name in ["videoURL", 'audioURL']:
+            for tag_name in ['videoURL', 'audioURL']:
-            video_url = metadata_media_resource["dflt"]["videoURL"]
+        if 'dflt' in metadata_media_resource and 'videoURL' in metadata_media_resource['dflt']:
-        caption_url = metadata_media_resource.get("captionURL")
+        caption_url = metadata_media_resource.get('captionURL')
-        title = metadata_tracker_data.get("trackerClipTitle")
+        title = metadata_tracker_data.get('trackerClipTitle')
-            'id': metadata_tracker_data.get("trackerClipId", display_id),
+            'id': metadata_tracker_data.get('trackerClipId', display_id),
-            'alt_title': metadata_tracker_data.get("trackerClipSubcategory"),
+            'alt_title': metadata_tracker_data.get('trackerClipSubcategory'),
-            'description': self._html_search_meta("Description", webpage),
+            'description': self._html_search_meta('Description', webpage),
-                        m3u8_id=m3u8_id, fatal=False))
+                        m3u8_id=m3u8_id, fatal=fatal))
-from .tvp import TvpIE, TvpSeriesIE
+from .tvp import (
-# -*- coding: utf-8 -*-
+# coding: utf-8
-    _VALID_URL = r'https?://(?:vod|www)\.tvp\.pl/.*/(?P<id>\d+)$'
+class TVPIE(InfoExtractor):
-        'url': 'http://vod.tvp.pl/seriale/obyczajowe/czas-honoru/sezon-1-1-13/i-seria-odc-13/194536',
+        'url': 'http://vod.tvp.pl/194536/i-seria-odc-13',
-        },
+        'only_matching': True,
-    IE_NAME = 'tvp.pl:Series'
+class TVPSeriesIE(InfoExtractor):
-            self.url_result('http://vod.tvp.pl%s' % v_path, ie=TvpIE.ie_key())
+            self.url_result('http://vod.tvp.pl%s' % v_path, ie=TVPIE.ie_key())
-                             fatal=True, assume_f4mv2=False, m3u8_id=None):
+                             fatal=True, m3u8_id=None):
-            m3u8_id=m3u8_id)
+            transform_source=transform_source, fatal=fatal, m3u8_id=m3u8_id)
-                           fatal=True, assume_f4mv2=False, m3u8_id=None):
+                           fatal=True, m3u8_id=None):
-                media_url = media_el.attrib.get('href') or media_el.attrib.get('url')
+            # If <bootstrapInfo> is present, the specified f4m is a
-        formats = self._extract_f4m_formats(src, video_id, assume_f4mv2=True, m3u8_id='hls')
+        formats = self._extract_f4m_formats(src, video_id, m3u8_id='hls')
-from ..utils import int_or_none
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?dw\.com/(?:[^/]+/)+av-(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?dw\.com/(?:[^/]+/)+(?:av|e)-(?P<id>\d+)'
-            'upload_date': hidden_inputs.get('display_date'),
+            'upload_date': upload_date,
-        r'(?s)^[a-zA-Z0-9_.]+\s*\(\s*(.*)\);?\s*?(?://[^\n]*)*$', r'\1', code)
+        r'(?s)^[a-zA-Z0-9_.$]+\s*\(\s*(.*)\);?\s*?(?://[^\n]*)*$', r'\1', code)
-        formats = self._extract_f4m_formats(src, video_id, assume_f4mv2=True)
+        formats = self._extract_f4m_formats(src, video_id, assume_f4mv2=True, m3u8_id='hls')
-                             fatal=True, assume_f4mv2=False):
+                             fatal=True, assume_f4mv2=False, m3u8_id=None):
-            transform_source=transform_source, fatal=fatal, assume_f4mv2=assume_f4mv2)
+            transform_source=transform_source, fatal=fatal, assume_f4mv2=assume_f4mv2,
-                           fatal=True, assume_f4mv2=False):
+                           fatal=True, assume_f4mv2=False, m3u8_id=None):
-                if determine_ext(manifest_url) == 'f4m':
+                ext = determine_ext(manifest_url)
-    xpath_text,
+    dict_get,
-    int_or_none,
+        # Multiple resolutions while bitrates missing
-            formats.append(f)
+        formats = self._extract_f4m_formats(src, video_id, assume_f4mv2=True)
-                             fatal=True):
+                             fatal=True, assume_f4mv2=False):
-            transform_source=transform_source, fatal=fatal)
+            transform_source=transform_source, fatal=fatal, assume_f4mv2=assume_f4mv2)
-                           fatal=True):
+                           fatal=True, assume_f4mv2=False):
-            if manifest_version == '2.0':
+            if manifest_version == '2.0' or assume_f4mv2:
-                'ext': 'flv',
+                'ext': 'flv' if bootstrap_info else None,
-    {
+    }, {
-        },
+        'only_matching': True,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?eporner\.com/hd-porn/(?P<id>\w+)/(?P<display_id>[\w-]+)'
-    }
+        },
-        }]
+        }],
-            }
+    _TESTS = [{
-            }
+        'params': {
-            }
+    }, {
-            'only_matching': True,
+        'params': {
-    ]
+    }, {
-    _VALID_URL = r'(?P<proto>https?)://(?:.+?\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.+?)\.html(?:\?.*)?'
+    _VALID_URL = r'(?P<proto>https?)://(?:.+?\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.*?)\.html(?:\?.*)?'
-            r'href="(https?://xhamster\.com/movies/%s/[^"]+\.html[^"]*)"' % video_id,
+            r'href="(https?://xhamster\.com/movies/%s/[^"]*\.html[^"]*)"' % video_id,
-        }
+        'add_ie': ['Ooyala'],
-        },
+        'add_ie': ['OoyalaExternal'],
-        },
+        'add_ie': ['OoyalaExternal'],
-        }
+        },
-        }
+            'add_ie': ['Youtube'],
-        'md5': '8b743df908c42f60cf6496586c7f12c3',
+        'md5': '7d45932269a288149483144f01b99789',
-        },
+        'add_ie': ['Ooyala'],
-                url = base64.b64decode(
+                s_url = base64.b64decode(
-                if url in urls:
+                if s_url in urls:
-                urls.append(url)
+                urls.append(s_url)
-                if delivery_type == 'hls' or '.m3u8' in url:
+                if delivery_type == 'hls' or ext == 'm3u8':
-                        url, embed_code, 'mp4', 'm3u8_native',
+                        s_url, embed_code, 'mp4', 'm3u8_native',
-                elif delivery_type == 'hds' or '.f4m' in url:
+                elif delivery_type == 'hds' or ext == 'f4m':
-                elif '.smil' in url:
+                        s_url + '?hdcore=3.7.0', embed_code, f4m_id='hds', fatal=False))
-                        url, embed_code, fatal=False))
+                        s_url, embed_code, fatal=False))
-                        'ext': stream.get('delivery_type'),
+                        'url': s_url,
-        },
+        'add_ie': ['Ooyala'],
-        }
+        },
-        }
+        },
-        }
+        },
-        }
+        },
-from __future__ import division, unicode_literals
+from __future__ import unicode_literals
-            'title': "[V] Girl's Day's Broadcast",
+            'title': "[V LIVE] Girl's Day's Broadcast",
-            r'vlive\.tv\.video\.ajax\.request\.handler\.init\((.+)\)',
+            r'\bvlive\.video\.init\(([^)]+)\)',
-            r'"\s*,\s*"', video_params)[1:4]
+        status, _, _, live_params, long_video_id, key = re.split(
-            raise ExtractorError('Coming soon! %s' % air_start, expected=True)
+            raise ExtractorError('Coming soon!', expected=True)
-    _AUTHORIZATION_URL_TEMPLATE = _PLAYER_BASE + 'sas/player_api/v1/authorization/embed_code/%s/%s?'
+    _AUTHORIZATION_URL_TEMPLATE = _PLAYER_BASE + 'sas/player_api/v2/authorization/embed_code/%s/%s?'
-                    self.IE_NAME, cur_auth_data['message']), expected=True)
+        if cur_auth_data['authorized']:
-        }
+        title = metadata['title']
-        return video_info
+        subtitles = {}
-            elif video_type in ('ts', 'hls'):
+            elif video_type in ('ts', 'hls') and ('_master.m3u8' in s_url or '_mobile.m3u8' in s_url):
-    _VALID_URL = r'https?://(?:www\.)?(?:cbs\.com/shows/[^/]+/(?:video|artist)|colbertlateshow\.com/(?:video|podcasts))/[^/]+/(?P<id>[^/]+)'
+    _VALID_URL = r'(?:cbs:(?P<content_id>\w+)|https?://(?:www\.)?(?:cbs\.com/shows/[^/]+/(?:video|artist)|colbertlateshow\.com/(?:video|podcasts))/[^/]+/(?P<display_id>[^/]+))'
-            webpage, 'content id')
+        content_id, display_id = re.match(self._VALID_URL, url).groups()
-                    }.get(s.get('type')),
+from .reuters import ReutersIE
-from .washingtonpost import WashingtonPostIE
+from .washingtonpost import (
-    _VALID_URL = r'https?://(?:www\.)?washingtonpost\.com/.*?/(?P<id>[^/]+)/(?:$|[?#])'
+    IE_NAME = 'washingtonpost'
-            })
+        entries = [self.url_result('washingtonpost:%s' % uuid, 'WashingtonPost', uuid) for uuid in uuids]
-                    video_url, video_id, 'mp4', m3u8_id='m3u8'))
+                    video_url, video_id, 'mp4',
-    _VALID_URL = r'https?://lifenews\.ru/(?:mobile/)?(?P<section>news|video)/(?P<id>\d+)'
+    IE_NAME = 'life'
-        'url': 'http://lifenews.ru/news/98736',
+        'url': 'https://life.ru/t/Ð½Ð¾Ð²Ð¾ÑÑÐ¸/98736',
-        'url': 'http://lifenews.ru/news/152125',
+        'url': 'https://life.ru/t/Ð½Ð¾Ð²Ð¾ÑÑÐ¸/152125',
-        'url': 'http://lifenews.ru/news/153461',
+        'url': 'https://life.ru/t/Ð½Ð¾Ð²Ð¾ÑÑÐ¸/153461',
-        'url': 'http://lifenews.ru/video/13035',
+        'url': 'https://life.ru/t/Ð½Ð¾Ð²Ð¾ÑÑÐ¸/213035',
-        section = mobj.group('section')
+        video_id = self._match_id(url)
-            video_id, 'Downloading page')
+        webpage = self._download_webpage(url, video_id)
-            ' - ÐÐµÑÐ²ÑÐ¹ Ð¿Ð¾ ÑÑÐ¾ÑÐ½ÑÐ¼ Ð½Ð¾Ð²Ð¾ÑÑÑÐ¼ â LIFE | NEWS')
+            ' - Life.ru')
-    ExtractorError,
+            'timestamp': 1344154740,
-            'upload_date': '20150505',
+            'timestamp': 1430825520,
-            webpage, 'comment count', fatal=False)
+            r'<div[^>]+class=(["\']).*?\bhits-count\b.*?\1[^>]*>\s*(?P<value>\d+)\s*</div>',
-            upload_date = unified_strdate(upload_date)
+        timestamp = parse_iso8601(self._search_regex(
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-                r'Volume\.createVideo\(({.+})\s*,\s*{.*}\);', volume_webpage, 'video data'), volume_uuid)
+                r'Volume\.createVideo\(({.+})\s*,\s*{.*}\s*,\s*\[.*\]\s*,\s*{.*}\);', volume_webpage, 'video data'), volume_uuid)
-            r'<iframe[^>]+src="(?P<url>https?://new\.livestream\.com/[^"]+/player[^"]+)"',
+            r'<iframe[^>]+src="(?P<url>https?://(?:new\.)?livestream\.com/[^"]+/player[^"]+)"',
-        broadcast_id = stream_info['broadcast_id']
+        broadcast_id = compat_str(stream_info['broadcast_id'])
-    compat_etree_fromstring = xml.etree.ElementTree.fromstring
+    def compat_etree_fromstring(text):
-            parser = etree.XMLParser(target=etree.TreeBuilder())
+            parser = etree.XMLParser(target=_TreeBuilder())
-        doc = _XML(text, parser=etree.XMLParser(target=etree.TreeBuilder(element_factory=_element_factory)))
+        doc = _XML(text, parser=etree.XMLParser(target=_TreeBuilder(element_factory=_element_factory)))
-    _VALID_URL = r'https?://(?:(?:videos|www|lci)\.tf1|www\.tfou)\.fr/(?:[^/]+/)*(?P<id>.+?)\.html'
+    _VALID_URL = r'https?://(?:(?:videos|www|lci)\.tf1|(?:www\.)?(?:tfou|ushuaiatv|histoire|tvbreizh))\.fr/(?:[^/]+/)*(?P<id>[^/?#.]+)'
-            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8})(?:#.*?)?\1',
+            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8})(?:.*?)?\1',
-import hashlib
+from ..compat import compat_str
-    _VALID_URL = r'(?:wat:(?P<real_id>\d{8})|https?://www\.wat\.tv/video/(?P<display_id>.*)-(?P<short_id>.*?)_.*?\.html)'
+    _VALID_URL = r'(?:wat:|https?://(?:www\.)?wat\.tv/video/.*-)(?P<id>[0-9a-z]+)'
-            'md5': 'ce70e9223945ed26a8056d413ca55dc9',
+            'md5': '83d882d9de5c9d97f0bb2c6273cde56a',
-            real_id = self._search_regex(r'xtpage = ".*-(.*?)";', webpage, 'real id')
+        video_id = self._match_id(url)
-        video_info = self.download_video_info(real_id)
+        # 'contentv4' is used in the website, but it also returns the related
-            return self.playlist_result(entries, real_id, video_info['title'])
+        def video_id_for_chapter(chapter):
-            upload_date = unified_strdate(first_chapter['date_diffusion'])
+        if video_id_for_chapter(first_chapter) != video_id:
-            if not video_url:
+        # the video id for getting the video url
-                'format_id': fmt[0],
+            abr, vbr = mobj.groups()
-            'display_id': display_id,
+            'id': video_id,
-            'duration': first_file['duration'],
+            'duration': video_info['files'][0]['duration'],
-        for video_url in found:
+        for video_url in orderedSet(found):
-        'md5': '2b68e5851514c20efdff2afc5603b8b4',
+        'md5': '73d0b3171568232574e45652f8720b5c',
-                    'id': compat_str(data['id']),
+                    'id': track_id,
-            filename += '.exe'
+    # sys.executable is set to the full pathname of the exe-file for py2exe
-        exe = os.path.abspath(filename)
+        exe = filename
-            upload_date = datetime.datetime(*timetuple[:6]).strftime('%Y%m%d')
+            try:
-                              (?:(?:guests/[^/]+|videos|video-clips|video-playlists|special-editions|news-team/[^/]+)/[^/]+/(?P<videotitle>[^/?#]+))
+                              (?:(?:guests/[^/]+|videos|video-(?:clips|playlists)|special-editions|news-team/[^/]+)/[^/]+/(?P<videotitle>[^/?#]+))
-                          (?P<showname>thedailyshow|thecolbertreport)\.(?:cc\.)?com/
+                          (?P<showname>thedailyshow|thecolbertreport|tosh)\.(?:cc\.)?com/
-                              (?:(?:guests/[^/]+|videos|video-playlists|special-editions|news-team/[^/]+)/[^/]+/(?P<videotitle>[^/?#]+))
+                              (?:(?:guests/[^/]+|videos|video-clips|video-playlists|special-editions|news-team/[^/]+)/[^/]+/(?P<videotitle>[^/?#]+))
-        uploader_id = broadcast.get('user_id') or broadcast_data.get('user', {}).get('id')
+        user = broadcast_data.get('user', {})
-from ..utils import parse_iso8601
+from ..utils import (
-            self._html_search_meta('user-broadcasts', webpage, default='{}'),
+        data_store = self._parse_json(
-            for broadcast in user_broadcasts.get('broadcasts', [])]
+            for broadcast in data_store.get('UserBroadcastHistory', {}).get('broadcasts', [])]
-        return self.playlist_result(entries, user_id, username)
+        return self.playlist_result(entries, user_id, title, description)
-__version__ = '2016.05.21.1'
+__version__ = '2016.05.21.2'
-__version__ = '2016.05.21'
+__version__ = '2016.05.21.1'
-__version__ = '2016.05.16'
+__version__ = '2016.05.21'
-    _VALID_URL = r'https?://www\.rtve\.es/(m/)?alacarta/videos/[^/]+/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://www\.rtve\.es/(m/)?(alacarta/videos|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)'
-                    rtmp_url, prefix, play_path = re.split(
+                    rtmp_url_parts = re.split(
-                    })
+                    if len(rtmp_url_parts) == 3:
-    def _parse_jwplayer_data(self, jwplayer_data, video_id, require_title=True):
+    def _parse_jwplayer_data(self, jwplayer_data, video_id, require_title=True, m3u8_id=None, rtmp_params=None):
-            if source_type in ('application/vnd.apple.mpegurl', 'hls'):
+            if source_type in ('application/vnd.apple.mpegurl', 'hls') or determine_ext(source_url) == 'm3u8':
-                    source_url, video_id, 'mp4', 'm3u8_native', fatal=False))
+                    source_url, video_id, 'mp4', 'm3u8_native', m3u8_id=m3u8_id, fatal=False))
-                formats.append({
+                a_format = {
-                })
+                }
-                last_media_name = last_media.get('NAME') if last_media and last_media.get('TYPE') != 'SUBTITLES' else None
+                last_media_name = last_media.get('NAME') if last_media and last_media.get('TYPE') not in ('SUBTITLES', 'CLOSED-CAPTIONS') else None
-        formats = [{
+    def _m3u8_meta_format(self, m3u8_url, ext=None, preference=None, m3u8_id=None):
-        }]
+        }
-                        subtitles.setdefault('no', []).append({'url': subtitle_url})
+                        subtitles.setdefault('no', []).append({
-                raise ExtractorError(json_data[0]['message'], expected=True)
+                json_data = self._parse_json(e.cause.read().decode(), video_id)[0]
-    _VALID_URL = r'https?://(?:www\.)?localnews8\.com/.+?/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?localnews8\.com/(?:[^/]+/)*(?P<display_id>[^/]+)/(?P<id>[0-9]+)'
-        'md5': '477bdb188f177788c65db27ecb56649b',
+        'md5': 'be4d48aea61aa2bde7be2ee47691ad20',
-            'timestamp': '1441844822',
+            'duration': 153,
-        }}
+        }
-        webpage = self._download_webpage(url, video_id)
+        mobj = re.match(self._VALID_URL, url)
-        kaltura_id = self._search_regex(r'var\s+videoIdString\s*=\s*"kaltura:(.+)";', webpage, video_id)
+        partner_id = self._search_regex(
-        return self.url_result('kaltura:%s:%s' % (partner_id, kaltura_id), 'Kaltura')
+        return {
-            'md5': '8788b683c777a5cf25621eaf286d0c23',
+            'url': 'http://study.com/academy/lesson/north-american-exploration-failed-colonies-of-spain-france-england.html#lesson',
-                'id': '1cfaf6b7ea',
+                'id': '6e2wtrbdaf',
-                'uploader': 'education-portal.com',
+                'title': 'paywall_north-american-exploration-failed-colonies-of-spain-france-england',
-                'title': 'Conversation about Hexagonal Rails Part 1 - ThoughtWorks',
+                'title': 'Conversation about Hexagonal Rails Part 1',
-                'upload_date': '20140603',
+                'upload_date': '20140603',
-                'upload_date': '20160518',
+                'upload_date': '20160518',
-                'url': 'http://fast.wistia.net/embed/iframe/{0:}'.format(match.group('id')),
+                'url': 'wistia:%s' % match.group('id'),
-                'id': match.group('id')
+        # Wistia standard embed (async)
-            'duration': int_or_none(data.get('duration')),
+            'duration': float_or_none(data.get('duration')),
-                'http://link.theplatform.com/s/ExhSPC/media/guid/2655402169/%s?mbr=true' % video_id, {
+                'http://link.theplatform.com/s/ExhSPC/media/guid/2655402169/%s?mbr=true&formats=MPEG4,FLV,MP3' % video_id, {
-                    'ext': a.get('ext'),
+                    'ext': 'mp4' if is_m3u8 else aext,
-            if (astatus is not None and astatus != 2) or atype == 'preview':
+            if (astatus is not None and astatus != 2) or atype in ('preview', 'storyboard'):
-                    'resolution': '%dx%d' % (a['width'], a['height']),
+                    'url': aurl,
-                    'url': a['url'],
+                    'url': aurl,
-    _API_URL = 'http://fast.wistia.com/embed/medias/{0:}.json'
+    _VALID_URL = r'(?:wistia:|https?://(?:fast\.)?wistia\.net/embed/iframe/)(?P<id>[a-z0-9]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        data_json = self._download_json(request, video_id)
+        data_json = self._download_json(
-                                 expected=True)
+            raise ExtractorError(
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            src = video.get('src')
+        media = smil.findall(self._xpath_ns('.//video', namespace)) + smil.findall(self._xpath_ns('.//audio', namespace))
-            ext = video.get('ext')
+            bitrate = float_or_none(medium.get('system-bitrate') or medium.get('systemBitrate'), 1000)
-            streamer = video.get('streamer') or base
+            streamer = medium.get('streamer') or base
-    _VALID_URL = r'https?://(?:www\.)?cbc\.ca/(?:[^/]+/)+(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?cbc\.ca/(?!player/)(?:[^/]+/)+(?P<id>[^/?#]+)'
-from ..utils import js_to_json
+from ..utils import (
-            'ext': 'flv',
+            'ext': 'mp4',
-            'timestamp': 1454475540,
+            'timestamp': 1454463000,
-            'skip_download': True,
+            'uploader': 'CBCC-NEW',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'upload_date': '19700101',
+            'upload_date': '19780210',
-            'skip_download': True,
+            'timestamp': 255977160,
-                'ext': 'flv',
+                'ext': 'mp4',
-                'upload_date': '19700101',
+                'upload_date': '20160201',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'upload_date': '19700101',
+                'upload_date': '20150315',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'timestamp': 1455067800,
+            'timestamp': 1455071400,
-            'skip_download': True,
+            'uploader': 'CBCC-NEW',
-            'ThePlatformFeed', video_id)
+        return {
-            r'<span itemprop="description">([^<]+)</span>', webpage, 'description', fatal=False)
+            r'<(p|span)[^>]+itemprop="description"[^>]*>(?P<description>[^<]+)</\1>',
-    month_by_name,
+    remove_end,
-    _VALID_URL = r'^https?://(?:www\.)?ndtv\.com/video/player/[^/]*/[^/]*/(?P<id>[a-z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?ndtv\.com/video/(?:[^/]+/)+[^/?^&]+-(?P<id>\d+)'
-        'url': 'http://www.ndtv.com/video/player/news/ndtv-exclusive-don-t-need-character-certificate-from-rahul-gandhi-says-arvind-kejriwal/300710',
+        'url': 'http://www.ndtv.com/video/news/news/ndtv-exclusive-don-t-need-character-certificate-from-rahul-gandhi-says-arvind-kejriwal-300710',
-            'thumbnail': 'http://i.ndtvimg.com/video/images/vod/medium/2013-12/big_300710_1386518307.jpg',
+            'thumbnail': 're:https?://.*\.jpg',
-                     filename)
+        video_url = 'http://bitcast-b.bitgravity.com/ndtvod/23372/ndtv/%s' % filename
-            description = description[:-len(READ_MORE)]
+        upload_date = unified_strdate(self._html_search_meta(
-            title = title[:-len(TITLE_SUFFIX)]
+        description = remove_end(self._og_search_description(webpage), ' (Read more)')
-    return s
+    return s[len(start):] if s is not None and s.startswith(start) else s
-    return s
+    return s[:-len(end)] if s is not None and s.endswith(end) else s
-    sanitized_Request,
+    clean_html,
-            'ext': 'mp4',
+            'ext': 'flv',
-            'description': 'md5:836d8aff55e087d04d9f6df554d4e038',
+            'description': 'md5:6b8e32dde3abf91e58857b174916620c',
-        request = sanitized_Request(
+        config = self._download_xml(
-        config = self._download_xml(request, video_id, 'Downloading player config XML')
+            video_id, 'Downloading player config XML',
-            return list(thumbnails.values())[0]
+        title, description, thumbnail, duration, uploader, author = [None] * 6
-                thumbnail = extract_thumbnail(media)
+                quality_key = qualities(('low', 'high'))
-                # It seems assets always go from lower to better quality, so no need to sort
+                title = xpath_text(media, 'title', fatal=True)
-                    for x in asset:
+                    quality = asset.get('quality')
-                            'play_path': x.find('url').text,
+                            'url': streamer,
-                            'format_id': '%s-%s' % (x.tag, asset.get('quality')),
+                            'ext': 'flv',
-            'thumbnail': thumbnail,
+            'thumbnails': thumbnails,
-            'uploader_id': uploader_id,
+            'subtitles': subtitles,
-                                           page, 'director name', fatal=False)
+        uploader = self._og_search_property('video:director', page, 'director name')
-            if media_type == 'video/f4m':
+            if media_type in ('video/f4m', 'application/f4m+xml'):
-                    'format_id': media_data['media-category']['@attributes']['label'],
+                    'format_id': media_data.get('media-category', {}).get('@attributes', {}).get('label'),
-        compat_urllib_parse_unquote_plus(url_components.password),
+        unquote_if_non_empty(url_components.username),
-__version__ = '2016.05.10'
+__version__ = '2016.05.16'
-    _VALID_URL = r'https?://www\.groupon\.com/deals/(?P<id>[^?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?groupon\.com/deals/(?P<id>[^/?#&]+)'
-                'title': 'Bikram Yoga Huntington Beach | Orange County',
+                'id': 'fk6OhWpXgIQ',
-                'duration': 44.961,
+                'duration': 45,
-            'skip_download': 'HDS',
+            'skip_download': True,
-            if v.get('provider') != 'OOYALA':
+            provider = v.get('provider')
-                    (playlist_id, v.get('provider')))
+                    (playlist_id, provider))
-            entries.append(self.url_result('ooyala:%s' % v['media']))
+            entries.append(self.url_result(url_pattern % video_id, ie_key))
-            'description': 'Creepy Patch. Mutable Instruments Braids Vowel + Formant Mode.',
+            'description': 'Listen to Dr. Kreep by Moofi on hearthis.at - Modular, Eurorack, Mutable Intruments Braids, Valhalla-DSP',
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            })
+            if ext in KNOWN_EXTENSIONS:
-        getheader = url_handle.info().getheader
+    getheader = url_handle.headers.get
-        }]
+        formats = []
-        android_webpage = self._download_webpage(android_req, video_id, fatal=False)
+        video_url = compat_urllib_parse_unquote(self._search_regex(
-                } for param in player_params if determine_ext(param) == 'mp4'])
+        player_args = self._search_regex(
-            'ext': 'flv',
+                # Despite specification does not mention NAME attribute for
-                    format_id.append(last_media_name if last_media_name else '%d' % (tbr if tbr else len(formats)))
+                    format_id.append(stream_name if stream_name else '%d' % (tbr if tbr else len(formats)))
-        video_title = self._html_search_regex(
+        video_title = self._og_search_title(
-            return self.url_result(self._proto_relative_url(threeqsdn_url), ThreeQSDNIE.ie_key())
+            return {
-            (r'^(0+[0-7]+)', 8),
+            (r'^0[xX][0-9a-fA-F]+', 16),
-                i = int(im.group(1), base)
+                i = int(im.group(0), base)
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?(?:ora\.tv|unsafespeech\.com)/([^/]+/)*(?P<id>[^/\?#]+)'
-    }
+    }, {
-
+        video_data = self._search_regex(
-            'id': video_data.get('id', display_id),
+            'id': self._search_regex(
-            'thumbnail': self._proto_relative_url(video_data.get('thumb')),
+            'thumbnail': self._proto_relative_url(self._search_regex(
-    _VALID_URL = r'https?://(?:www\.)?ora\.tv/([^/]+/)*(?P<id>[^/\?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?(ora\.tv|unsafespeech\.com)/([^/]+/)*(?P<id>[^/\?#]+)'
-            r'hls_stream"?\s*:\s*"([^"]+)', video_data, 'm3u8 url', None)
+        ora_meta = self._parse_json(self._search_regex(
-                r'"id"\s*:\s*(\d+)', video_data, 'video id', default=display_id),
+            'id': video_data.get('id', display_id),
-                r'"thumb"\s*:\s*"([^"]+)', video_data, 'thumbnail', None)),
+            'thumbnail': self._proto_relative_url(video_data.get('thumb')),
-                "\\'": "'",
+        elif v.startswith('/*') or v == ',':
-            }[m.group(0)], v)
+                "\\'": "'",
-        [a-zA-Z_][.a-zA-Z_0-9]*
+    return re.sub(r'''(?sx)
-                if ose.errno == 2:
+                if ose.errno == errno.ENOENT:
-        base64_fragments = re.findall(r'"([a-zA-z0-9+/=]+)"', preload_codes)
+        base64_fragments = re.findall(r'"([a-zA-Z0-9+/=]+)"', preload_codes)
-from .cinemassacre import CinemassacreIE
+            ie_result['url'] = sanitize_url(ie_result['url'])
-from ..utils import sanitized_Request
+from ..utils import (
-                            |
+    _VALID_URL = r'''(?x)https?://(?:.*?\.)?video\.sina\.com\.cn/
-                            (api/sinawebApi/outplay.php/(?P<token>.+?)\.swf)
+                            api/sinawebApi/outplay.php/(?P<token>.+?)\.swf
-            'md5': 'd65dd22ddcf44e38ce2bf58a10c3e71f',
+            'url': 'http://video.sina.com.cn/news/spj/topvideoes20160504/?opsubject_id=top1#250576622',
-                'title': 'ãä¸­å½æ°é»ã æé²è¦æ±å·´æ¿é©¬ç«å³éæ¾è¢«æ£è¹å',
+                'id': '250576622',
-        return self._extract_video(video_id)
+        video_id = mobj.group('video_id')
-import json
+    mimetype2ext,
-            f_id = format_info['ffname']
+            info = self._parse_json(json_data, video_id, fatal=False)
-                'quality': quality(f_id),
+                'format_id': format_id,
-    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/video/imdb/vi(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/video/[^/]+/vi(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r'<video[^>]+>\s*<script[^>]+>([^<]+)</script>',
+            r'</video>\s*</div>\s*<script[^>]+>([^<]+)</script>',
-            'id': compat_str(video_info['id']),
+            'id': video_id,
-                            self._extract_m3u8_formats(url, info['id'], 'mp4'))
+                            self._extract_m3u8_formats(
-                        'protocol': 'm3u8',
+                        'protocol': 'm3u8_native',
-            raise ExtractorError('Unable to extract video url for %s' % info['id'])
+            raise ExtractorError('Unable to extract video url for %s' % video_id)
-                    src, video_id, 'mp4', m3u8_id='hls', fatal=False))
+                    src, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
-        return self._extract_f4m_formats(
+        formats = []
-            video_id, f4m_id='hds', fatal=fatal)
+            video_id, f4m_id='hds', fatal=fatal))
-        # MD5 is unstable
+        'md5': '2f7f6eeb2aacdd99885f355428715cfa',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'id': 'MUHH48000314',
+            'id': 'MUHH48000314AA',
-            'title': '20 spÃ¸rsmÃ¥l',
+            'title': '20 spÃ¸rsmÃ¥l 23.05.2014',
-        },
+        'md5': '43d0be26663d380603a9cf0c24366531',
-            'id': 'mdfp15000514',
+            'id': 'MDFP15000514CA',
-            'upload_date': '20140524',
+            'title': 'GrunnlovsjubilÃ©et - Stor stÃ¥hei for ingenting 24.05.2014',
-from .ustudio import UstudioIE
+from .ustudio import (
-        display_id = mobj.group('display_id')
+        video_id, display_id = re.match(self._VALID_URL, url).groups()
-                'url': item.attrib['url'],
+                'url': unescapeHTML(item.attrib['url']),
-        'md5': '',
+        'md5': '1bdadcf760a0b90946ca68ee9a2db41a',
-            })
+            stream_url = stream.get('url')
-)
+from ..compat import compat_urllib_parse_unquote
-    float_or_none,
+    int_or_none,
-    ]
+class NRKBaseIE(InfoExtractor):
-            video_id, 'Downloading media JSON')
+            'http://%s/mediaelement/%s' % (self._API_HOST, video_id),
-        media_url = data.get('mediaUrl')
+        if not entries:
-            if data['usageRights']['isGeoBlocked']:
+        if not entries:
-        duration = parse_duration(data.get('duration'))
+        conviva = data.get('convivaStatistics') or {}
-            'formats': formats,
+        if images and isinstance(images, dict):
-
+        'skip': 'HTTP Error 404: Not Found',
-        url_components.username, url_components.password
+        compat_urllib_parse_unquote_plus(url_components.username),
-        return compat_struct_unpack('!Q', self.read(8))[0]
+        return compat_struct_unpack('!Q', self.read_bytes(8))[0]
-        return compat_struct_unpack('!I', self.read(4))[0]
+        return compat_struct_unpack('!I', self.read_bytes(4))[0]
-        return compat_struct_unpack('!B', self.read(1))[0]
+        return compat_struct_unpack('!B', self.read_bytes(1))[0]
-            char = self.read(1)
+            char = self.read_bytes(1)
-        box_type = self.read(4)
+        box_type = self.read_bytes(4)
-        return real_size, box_type, self.read(real_size - header_end)
+        return real_size, box_type, self.read_bytes(real_size - header_end)
-        self.read(3)
+        self.read_bytes(3)
-        self.read(3)
+        self.read_bytes(3)
-        self.read(3)
+        self.read_bytes(3)
-                    _, box_type, box_data = reader.read_box_info()
+                    try:
-            if response and response.get('statusCode') != 909:
+            try:
-                raise ExtractorError('Unable to extract videos')
+                raise
-            'AAAAAAAECEEEEIIIIDNOOOOOOUUUUYPssaaaaaaaeceeeeiiiionoooooouuuuypy')
+            'ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÅÃÃÃÃÃÃÃÃ Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã°Ã±Ã²Ã³Ã´ÃµÃ¶Ã¸ÅÃ¹ÃºÃ»Ã¼Ã½Ã¾Ã¿', restricted=True),
-                                        'aaaaaa', ['ae'], 'ceeeeiiiionoooooouuuuypy')))
+ACCENT_CHARS = dict(zip('ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÅÃÃÃÃÃÃÃÃ Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã°Ã±Ã²Ã³Ã´ÃµÃ¶Ã¸ÅÃ¹ÃºÃ»Ã¼Ã½Ã¾Ã¿',
-            'um': 0,
+            # In iQiyi's flash player, um is set to 1 if there's a logged user
-            if h.find(':', 1) < 0:
+            if ':' not in h:
-            key, value = h.split(':', 2)
+            key, value = h.split(':', 1)
-    from shlex import quote as shlex_quote
+    from shlex import quote as compat_shlex_quote
-    def shlex_quote(s):
+    def compat_shlex_quote(s):
-
+    'compat_shlex_quote',
-from ..compat import shlex_quote
+from ..compat import compat_shlex_quote
-        cmd = cmd.replace('{}', shlex_quote(information['filepath']))
+        cmd = cmd.replace('{}', compat_shlex_quote(information['filepath']))
-    return ' '.join(shlex_quote(a) for a in args)
+    return ' '.join(compat_shlex_quote(a) for a in args)
-__version__ = '2016.05.01'
+__version__ = '2016.05.10'
-        self.port = random.randint(49152, 65535)
+        self.port = random.randint(20000, 30000)
-        help='Use the specified HTTP/HTTPS proxy. Pass in an empty string (--proxy "") for direct connection')
+        help='Use the specified HTTP/HTTPS/SOCKS proxy. To enable experimental '
-from youtube_dl.compat import compat_urllib_request
+import random
-class TestSocks(unittest.TestCase):
+
-        self.assertEqual(struct_unpack('!B', b'\x00'), (0,))
+        self.assertEqual(compat_struct_unpack('!B', b'\x00'), (0,))
-    def struct_pack(spec, *args):
+    def compat_struct_pack(spec, *args):
-    def struct_unpack(spec, *args):
+    def compat_struct_unpack(spec, *args):
-    struct_unpack = struct.unpack
+    compat_struct_pack = struct.pack
-    struct_unpack,
+    compat_struct_pack,
-        return struct_unpack('!Q', self.read(8))[0]
+        return compat_struct_unpack('!Q', self.read(8))[0]
-        return struct_unpack('!I', self.read(4))[0]
+        return compat_struct_unpack('!I', self.read(4))[0]
-        return struct_unpack('!B', self.read(1))[0]
+        return compat_struct_unpack('!B', self.read(1))[0]
-    stream.write(struct_pack('!I', val))
+    stream.write(compat_struct_pack('!I', val))
-    stream.write(struct_pack('!I', val)[1:])
+    stream.write(compat_struct_pack('!I', val)[1:])
-    struct_unpack,
+    compat_struct_unpack,
-    length = struct_unpack('!I', text_chunk[:4])[0]
+    length = compat_struct_unpack('!I', text_chunk[:4])[0]
-    struct_unpack,
+    compat_struct_pack,
-SOCKS4_DEFAULT_DSTIP = struct_pack('!BBBB', 0, 0, 0, 0xFF)
+SOCKS4_DEFAULT_DSTIP = compat_struct_pack('!BBBB', 0, 0, 0, 0xFF)
-        return struct_unpack('!{0}B'.format(cnt), data)
+        return compat_struct_unpack('!{0}B'.format(cnt), data)
-        return struct_pack('!B', len(data)) + data
+        return compat_struct_pack('!B', len(data)) + data
-        packet = struct_pack('!BBH', SOCKS4_VERSION, Socks4Command.CMD_CONNECT, port) + ipaddr
+        packet = compat_struct_pack('!BBH', SOCKS4_VERSION, Socks4Command.CMD_CONNECT, port) + ipaddr
-        version, resp_code, dstport, dsthost = struct_unpack('!BBHI', self.recvall(8))
+        version, resp_code, dstport, dsthost = compat_struct_unpack('!BBHI', self.recvall(8))
-        packet = struct_pack('!B', SOCKS5_VERSION)
+        packet = compat_struct_pack('!B', SOCKS5_VERSION)
-        packet += struct_pack('!{0}B'.format(len(auth_methods)), *auth_methods)
+        packet += compat_struct_pack('!B', len(auth_methods))
-            packet = struct_pack('!B', SOCKS5_USER_AUTH_VERSION)
+            packet = compat_struct_pack('!B', SOCKS5_USER_AUTH_VERSION)
-        packet = struct_pack('!BBB', SOCKS5_VERSION, Socks5Command.CMD_CONNECT, reserved)
+        packet = compat_struct_pack('!BBB', SOCKS5_VERSION, Socks5Command.CMD_CONNECT, reserved)
-            packet += struct_pack('!B', Socks5AddressType.ATYP_DOMAINNAME)
+            packet += compat_struct_pack('!B', Socks5AddressType.ATYP_DOMAINNAME)
-        packet += struct_pack('!H', port)
+            packet += compat_struct_pack('!B', Socks5AddressType.ATYP_IPV4) + ipaddr
-        destport = struct_unpack('!H', self.recvall(2))[0]
+        destport = compat_struct_unpack('!H', self.recvall(2))[0]
-    struct_unpack,
+    compat_struct_unpack,
-    framesize_nbits = struct_unpack('!B', content[:1])[0] >> 3
+    framesize_nbits = compat_struct_unpack('!B', content[:1])[0] >> 3
-        header16 = struct_unpack('<H', content[pos:pos + 2])[0]
+        header16 = compat_struct_unpack('<H', content[pos:pos + 2])[0]
-            tag_len = struct_unpack('<I', content[pos:pos + 4])[0]
+            tag_len = compat_struct_unpack('<I', content[pos:pos + 4])[0]
-        b = struct_unpack('<B', buf)[0]
+        b = compat_struct_unpack('<B', buf)[0]
-    return struct_unpack('<i', bs + last_byte)[0]
+    return compat_struct_unpack('<i', bs + last_byte)[0]
-    res = struct_unpack('<B', resb)[0]
+    res = compat_struct_unpack('<B', resb)[0]
-    return struct_pack('%dB' % len(xs), *xs)
+    return compat_struct_pack('%dB' % len(xs), *xs)
-        if compat_urlparse.urlparse(proxy).scheme.lower() in ('socks', 'socks4', 'socks5'):
+        if compat_urlparse.urlparse(proxy).scheme.lower() in ('socks', 'socks4', 'socks4a', 'socks5'):
-    pass
+    ERR_SUCCESS = 0x00
-        0x5D: 'request rejected because the client program and identd report different user-ids'
+        91: 'request rejected or failed',
-        super(Socks4Error, self).__init__(code, msg)
+class Socks5Error(ProxyError):
-Proxy = collections.namedtuple('Proxy', ('type', 'host', 'port', 'username', 'password', 'remote_dns'))
+Proxy = collections.namedtuple('Proxy', (
-            self.__proxy = Proxy(proxytype, addr, port, username, password, rdns)
+    def __init__(self, *args, **kwargs):
-        destaddr, port = address
+    def _recv_bytes(self, cnt):
-            ipaddr = socket.inet_aton(destaddr)
+            return socket.inet_aton(destaddr)
-                ipaddr = struct_pack('!BBBB', 0, 0, 0, 0xFF)
+            if use_remote_dns and self._proxy.remote_dns:
-            packet += b'\x00'
+                return socket.inet_aton(socket.gethostbyname(destaddr))
-            packet += struct_pack('!{0}s'.format(len(destaddr) + 1), destaddr)
+            packet += destaddr.encode('utf-8') + b'\x00'
-        nbyte, resp_code, dstport, dsthost = struct_unpack('!BBHI', packet)
+        version, resp_code, dstport, dsthost = struct_unpack('!BBHI', self.recvall(8))
-                0, 'Invalid response from server. Expected {0:02x} got {1:02x}'.format(0, nbyte))
+        self._check_response_version(SOCKS4_REPLY_VERSION, version)
-        if resp_code != 0x5a:
+        if resp_code != Socks4Error.ERR_SUCCESS:
-        destaddr, port = address
+    def _setup_socks4a(self, address):
-                ipaddr = socket.inet_aton(socket.gethostbyname(destaddr))
+    def _socks5_auth(self):
-        packet = struct_pack('!BBB', 0x5, auth_methods, 0x00)  # no auth
+        auth_methods = [Socks5Auth.AUTH_NONE]
-            packet += struct_pack('!B', 0x02)  # user/pass auth
+            auth_methods.append(Socks5Auth.AUTH_USER_PASS)
-        version, method = struct_unpack('!BB', packet)
+        version, method = self._recv_bytes(2)
-                0, 'Invalid response from server. Expected {0:02x} got {1:02x}'.format(5, version))
+        self._check_response_version(SOCKS5_VERSION, version)
-        if method == 0xFF:
+        if method == Socks5Auth.AUTH_NO_ACCEPTABLE:
-            packet += struct_pack('!B', len(password)) + password
+        if method == Socks5Auth.AUTH_USER_PASS:
-            version, status = struct_unpack('!BB', packet)
+            version, status = self._recv_bytes(2)
-                    0, 'Invalid response from server. Expected {0:02x} got {1:02x}'.format(1, version))
+            self._check_response_version(SOCKS5_USER_AUTH_VERSION, version)
-            if status != 0x00:
+            if status != SOCKS5_USER_AUTH_SUCCESS:
-        elif method == 0x00:  # no auth
+                raise Socks5Error(Socks5Error.ERR_GENERAL_FAILURE)
-        packet = struct_pack('!BBB', 5, 1, 0)
+    def _setup_socks5(self, address):
-            packet += struct_pack('!BB', 3, len(destaddr)) + destaddr
+            destaddr = destaddr.encode('utf-8')
-            packet += struct_pack('!B', 1) + ipaddr
+            packet += struct_pack('!B', Socks5AddressType.ATYP_IPV4) + ipaddr
-        version, status, _, atype = struct_unpack('!BBBB', packet)
+        version, status, reserved, atype = self._recv_bytes(4)
-                0, 'Invalid response from server. Expected {0:02x} got {1:02x}'.format(5, version))
+        self._check_response_version(SOCKS5_VERSION, version)
-        if status != 0x00:
+        if status != Socks5Error.ERR_SUCCESS:
-        if atype == 0x01:
+        if atype == Socks5AddressType.ATYP_IPV4:
-            alen = struct_unpack('!B', self.recv(1))[0]
+        elif atype == Socks5AddressType.ATYP_DOMAINNAME:
-        elif atype == 0x04:
+        elif atype == Socks5AddressType.ATYP_IPV6:
-        else:
+        if not self._proxy:
-# s.close()
+# Public Domain SOCKS proxy protocol implementation
-__author__ = 'Timo Schmid <coding@timoschmid.de>'
+import collections
-_orig_socket = socket.socket
+from .compat import (
-    from Collections import namedtuple
+__author__ = 'Timo Schmid <coding@timoschmid.de>'
-    Enum = object
+class ProxyError(IOError):
-class ProxyError(IOError): pass
+
-    SOCKS4  = 0
+
-    sys.modules['socket'].socket = sockssocket
+    SOCKS5 = 2
-        super(sockssocket, self).__init__(*args, **kwargs)
+class sockssocket(socket.socket):
-        return _default_proxy
+        return self.__proxy
-                raise IOError("{0} bytes missing".format(cnt-len(data)))
+                raise IOError('{0} bytes missing'.format(cnt - len(data)))
-                ipaddr = struct.pack('!BBBB', 0, 0, 0, 0xFF)
+                ipaddr = struct_pack('!BBBB', 0, 0, 0, 0xFF)
-        packet = struct.pack('!BBH', 0x4, 0x1, port) + ipaddr
+        packet = struct_pack('!BBH', 0x4, 0x1, port) + ipaddr
-            packet += struct.pack('!{0}s'.format(len(username)+1), username)
+            packet += struct_pack('!{0}s'.format(len(username) + 1), username)
-            packet += struct.pack('!{0}s'.format(len(destaddr)+1), destaddr)
+            packet += struct_pack('!{0}s'.format(len(destaddr) + 1), destaddr)
-        nbyte, resp_code, dstport, dsthost = struct.unpack('!BBHI', packet)
+        nbyte, resp_code, dstport, dsthost = struct_unpack('!BBHI', packet)
-            raise ProxyError(0, "Invalid response from server. Expected {0:02x} got {1:02x}".format(0, nbyte))
+            raise ProxyError(
-        packet = struct.pack('!BBB', 0x5, auth_methods, 0x00) # no auth
+        packet = struct_pack('!BBB', 0x5, auth_methods, 0x00)  # no auth
-            packet += struct.pack('!B', 0x02) # user/pass auth
+            packet += struct_pack('!B', 0x02)  # user/pass auth
-        version, method = struct.unpack('!BB', packet)
+        version, method = struct_unpack('!BB', packet)
-            raise ProxyError(0, "Invalid response from server. Expected {0:02x} got {1:02x}".format(5, version))
+            raise ProxyError(
-            packet += struct.pack('!B', len(password)) + password
+            packet = struct_pack('!BB', 1, len(username)) + username
-            version, status = struct.unpack('!BB', packet)
+            version, status = struct_unpack('!BB', packet)
-                raise ProxyError(0, "Invalid response from server. Expected {0:02x} got {1:02x}".format(1, version))
+                raise ProxyError(
-        elif method == 0x00: # no auth
+        elif method == 0x00:  # no auth
-        packet = struct.pack('!BBB', 5, 1, 0)
+        packet = struct_pack('!BBB', 5, 1, 0)
-            packet += struct.pack('!BB', 3, len(destaddr)) + destaddr
+            packet += struct_pack('!BB', 3, len(destaddr)) + destaddr
-        packet += struct.pack('!H', port)
+            packet += struct_pack('!B', 1) + ipaddr
-        version, status, _, atype = struct.unpack('!BBBB', packet)
+        version, status, _, atype = struct_unpack('!BBBB', packet)
-            raise ProxyError(0, "Invalid response from server. Expected {0:02x} got {1:02x}".format(5, version))
+            raise ProxyError(
-            alen = struct.unpack('!B', self.recv(1))[0]
+            alen = struct_unpack('!B', self.recv(1))[0]
-        destport = struct.unpack('!H', self.recvall(2))[0]
+        destport = struct_unpack('!H', self.recvall(2))[0]
-        self._make_proxy(_orig_socket.connect, address)
+        self._make_proxy(socket.socket.connect, address)
-        return self._make_proxy(_orig_socket.connect_ex, address)
+        return self._make_proxy(socket.socket.connect_ex, address)
-            _create_http_connection, self, compat_http_client.HTTPConnection, False),
+            _create_http_connection, self, conn_class, False),
-            _create_http_connection, self, self._https_conn_class, True),
+            _create_http_connection, self, conn_class, True),
-
+import struct
-    struct_unpack,
+from ..compat import (
-from .compat import compat_str
+from .compat import (
-import struct
+    struct_pack,
-
+# This is free and unencumbered software released into the public domain.
-            #r'#EXT-X-MEDIA-SEQUENCE:(?!0$)',  # live streams [3]
+            # r'#EXT-X-MEDIA-SEQUENCE:(?!0$)',  # live streams [3]
-from youtube_dl.utils import get_filesystem_encoding
+from ..compat import compat_setenv
-        proc = subprocess.Popen(args, stdin=subprocess.PIPE)
+        proc = subprocess.Popen(args, stdin=subprocess.PIPE, env=env)
-        compat_setenv('HOME', old_home)
+        compat_setenv('HOME', old_home or '')
-            else test_str.encode(get_filesystem_encoding()))
+        compat_setenv('YOUTUBE-DL-TEST', test_str)
-            else test_str.encode(get_filesystem_encoding()))
+        compat_setenv('HOME', test_str)
-        os.environ['HOME'] = old_home
+        compat_setenv('HOME', old_home)
-            r'#EXT-X-MEDIA-SEQUENCE:(?!0$)',  # live streams [3]
+            # Live streams heuristic does not always work (e.g. geo restricted to Germany
-            'title': 're:ÄT Sport.*',
+            'title': 're:^ÄT Sport \d{4}-\d{2}-\d{2} \d{2}:\d{2}$',
-            is_live = item['type'] == 'LIVE'
+            is_live = item.get('type') == 'LIVE'
-                    final_title = playlist_title
+                    final_title = self._live_title(final_title)
-        'url': 'http://www.ceskatelevize.cz/ivysilani/10532695142-prvni-republika/bonus/14716-zpevacka-z-duparny-bobina',
+        # live stream
-            'id': '61924494876844374',
+            'id': 402,
-            'duration': 88.4,
+            'title': 're:ÄT Sport.*',
-        playlist_description = self._og_search_description(webpage)
+        playlist_title = self._og_search_title(webpage, default=None)
-                    entry_protocol='m3u8_native', fatal=False))
+                    entry_protocol='m3u8' if is_live else 'm3u8_native',
-                'title': playlist_title if playlist_len == 1 else '%s (%s)' % (playlist_title, title),
+                'title': final_title,
-    _VALID_URL = r'(?:%s:|https?://(?:mva\.microsoft|microsoftvirtualacademy)\.com/[^/]+/training-courses/[^/?#&]+-)(?P<course_id>\d+)(?::|\?l=)(?P<id>[\da-zA-Z]+_\d+)' % IE_NAME
+    _VALID_URL = r'(?:%s:|https?://(?:mva\.microsoft|(?:www\.)?microsoftvirtualacademy)\.com/[^/]+/training-courses/[^/?#&]+-)(?P<course_id>\d+)(?::|\?l=)(?P<id>[\da-zA-Z]+_\d+)' % IE_NAME
-    _VALID_URL = r'(?:%s:|https?://(?:mva\.microsoft|microsoftvirtualacademy)\.com/[^/]+/training-courses/(?P<display_id>[^/?#&]+)-)(?P<id>\d+)' % IE_NAME
+    _VALID_URL = r'(?:%s:|https?://(?:mva\.microsoft|(?:www\.)?microsoftvirtualacademy)\.com/[^/]+/training-courses/(?P<display_id>[^/?#&]+)-)(?P<id>\d+)' % IE_NAME
-            video_key = self.parse_video_key(video_file.get('key'))
+        for i, video_file in enumerate(video_xml.findall('./track/video/file')):
-        for i, video_file in enumerate(video_xml.findall('./track/video/file')):
+        for i, video_file in enumerate(video_xml.findall('./track/video/file[@key]')):
-            info['upload_date'] = entries[0]['upload_date']
+            info['upload_date'] = entries[0].get('upload_date')
-            'thumbnail': 're:^https?://videoimg.afreecatv.com/.*$',
+            'thumbnail': 're:^https?://(?:video|st)img.afreecatv.com/.*$',
-            'thumbnail': 're:^https?://videoimg.afreecatv.com/.*$',
+            'thumbnail': 're:^https?://(?:video|st)img.afreecatv.com/.*$',
-                    source_pref -= 9
+            l = re.escape(langcode)
-from .afreecatv import AfreecaTVIE
+from .afreecatv import AfreecaTVIE
-        video_key = {'upload_date': None, 'part': '0'}
+        video_key = {}
-        for video_file in video_xml.findall('./track/video/file'):
+        for i, video_file in enumerate(video_xml.findall('./track/video/file')):
-                'id': '%s_%s' % (video_id, video_key['part']),
+                'id': '%s_%s' % (video_id, video_key.get('part', i + 1)),
-                'upload_date': video_key['upload_date'],
+                'upload_date': video_key.get('upload_date'),
-                retcode = ydl.download_with_info_file(opts.load_info_filename)
+                retcode = ydl.download_with_info_file(compat_expanduser(opts.load_info_filename))
-        if protocol == 'm3u8':
+        if protocol in ('m3u8', 'm3u8_native'):
-                batchfd = io.open(opts.batchfile, 'r', encoding='utf-8', errors='ignore')
+                batchfd = io.open(
-from ..utils import remove_end
+from ..utils import (
-        'md5': '83245a9779bcc4a24454bfd53c65b6dc',
+        'params': {
-        playlist_id = self._match_id(url)
+        video_id = self._match_id(url)
-        webpage = self._download_webpage(url, playlist_id)
+        webpage = self._download_webpage(url, video_id)
-            r"iframe\.loadPlayer\('([^']+)'", webpage, 'player')
+            r'playlist\s*:\s*"([^"]+)"', player_page, 'playlist URL')
-        entries = self._extract_xspf_playlist(playlist_url, playlist_id)
+        duration = item.get('duration')
-        return self.playlist_result(entries, playlist_id, title, description)
+        return {
-                'uploader_id': owner.get('nsid'),
+                'uploader_id': uploader_id,
-
+    # https://help.yahoo.com/kb/flickr/SLN25525.html
-                'tags': [tag.get('_content') for tag in video_info.get('tags', {}).get('tag', [])]
+                'tags': [tag.get('_content') for tag in video_info.get('tags', {}).get('tag', [])],
-            'title': 'Most unlucky car accident'
+            'title': 'Most unlucky car accident',
-            'title': 'Crazy Hungarian tourist films close call waterspout in Croatia'
+            'title': 'Crazy Hungarian tourist films close call waterspout in Croatia',
-        json_url = 'http://videoplayer.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id
+        json_url = 'http://api.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id
-        json_url = 'http://api.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id
+        json_url = 'http://videoplayer.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id
-            json_url, video_id, 'Downloading video info', 'Unable to download info')
+            json_url, video_id, 'Downloading video info',
-            if response.get('statusCode') != 909:
+            if response and response.get('statusCode') != 909:
-                    (?:[a-zA-Z-]+="[^"]+"\s+)*?
+                    (?:[a-zA-Z-]+="[^"]*"\s+)*?
-                    (?:[a-zA-Z-]+="[^"]+"\s+)*?
+                    (?:[a-zA-Z-]+="[^"]*"\s+)*?
-         (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|="[^"]+"|='[^']+'))*?
+         (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?
-         (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|="[^"]+"|='[^']+'))*?
+         (?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|="[^"]*"|='[^']*'))*?
-                            (?:m\.)?vk\.com/video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|
+                            (?:
-                                (?:www\.)?biqle\.ru/watch/
+                                (?:www\.)?daxab.com/embed/
-                            (?P<videoid>[^s].*?)(?:\?(?:.*\blist=(?P<list_id>[\da-f]+))?|%2F|$)
+                            (?P<videoid>-?\d+_\d+)(?:.*\blist=(?P<list_id>[\da-f]+))?
-            }
+            },
-                'description': 'md5:bf9c26cfa4acdfb146362682edd3827a',
+                'description': 'md5:d9903938abdc74c738af77f527ca0596',
-        if not video_id:
+        info_url = url
-            r'(?s)<!><div[^>]+class="video_layer_message"[^>]*>(.+?)</div>',
+            [r'(?s)<!><div[^>]+class="video_layer_message"[^>]*>(.+?)</div>',
-            info_page, 'view count', fatal=False)
+            info_page, 'view count', default=None)
-            if not k.startswith('url') and k != 'extra_data' or not v:
+            if not k.startswith('url') and not k.startswith('cache') and k != 'extra_data' or not v:
-                r'^url(\d+)', k, 'height', default=None))
+                r'^(?:url|cache)(\d+)', k, 'height', default=None))
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                'id': video_file.get('key'),
+                'id': '%s_%s' % (video_id, video_key['part']),
-                'formats': [{'url': video_file.text}]
+                'url': video_file.text,
-            info['formats'] = entries[0]['formats']
+            info['url'] = entries[0]['url']
-from .periscope import PeriscopeIE
+from .periscope import (
-        if track.find('flag').text != 'SUCCEED':
+        if xpath_text(video_xml, './track/flag', default='FAIL') != 'SUCCEED':
-        thumbnail = track.find('titleImage').text
+        title = xpath_text(video_xml, './track/title', 'title')
-                })
+        for video_file in video_xml.findall('./track/video/file'):
-from ..utils import ExtractorError
+from ..utils import (
-        video_thumbnail = self._og_search_thumbnail(webpage)
+        title = self._html_search_regex(
-            'thumbnail': video_thumbnail,
+            'title': title,
-
+from ..compat import compat_urlparse
-    _VALID_URL = r'https?://(?:www\.)?fc-zenit\.ru/video/gl(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?fc-zenit\.ru/video/(?P<id>[0-9]+)'
-        'md5': '458bacc24549173fe5a5aa29174a5606',
+        'url': 'http://fc-zenit.ru/video/41044/',
-            'id': '6785',
+            'id': '41044',
-            'title': 'Â«ÐÐµÐ½Ð¸Ñ-Ð¢ÐÂ»: ÐºÐ°Ðº ÐÐ»ÐµÐ³ Ð¨Ð°ÑÐ¾Ð² Ð¸Ð³ÑÐ°Ð» Ð¿ÑÐ¾ÑÐ¸Ð² Â«Ð£ÑÐ°Ð»Ð°Â»',
+            'title': 'Ð¢Ð°Ðº Ð¿Ð¸ÑÐµÑÑÑ Ð¸ÑÑÐ¾ÑÐ¸Ñ: ÐºÐ°Ð·Ð°Ð½ÑÐºÐ¸Ð¹ ÑÐ°Ð·Ð³ÑÐ¾Ð¼ Ð¦Ð¡ÐÐ Ð½Ð° Â«ÐÐµÐ½Ð¸Ñ-Ð¢ÐÂ»',
-        video_title = self._html_search_regex(r'<div class=\"photoalbum__title\">([^<]+)', webpage, 'title')
+        video_title = self._html_search_regex(
-        bitrates = re.findall(r'url:.?\'(.+?)\'.*?bitrate:.?([0-9]{3}?)', bitrates_raw)
+        def merge_dicts(*dicts):
-        } for furl, tbr in bitrates]
+            'url': compat_urlparse.urljoin(url, video_url),
-        'playlist_count': 310,
+        'playlist_mincount': 300,
-            lecture_id, 'Downloading lecture JSON')
+            'https://www.udemy.com/api-2.0/users/me/subscribed-courses/%s/lectures/%s?'
-            request, None, 'Logging in as %s' % username)
+            self._LOGIN_URL, None, 'Logging in as %s' % username,
-                course_id, 'Enrolling in the course')
+                course_id, 'Enrolling in the course',
-        tracks, track_ids = playlist['tracks'], playlist['trackIds']
+        tracks, track_ids = playlist['tracks'], map(compat_str, playlist['trackIds'])
-            missing_track_ids = set(map(compat_str, track_ids)) - set(present_track_ids)
+            present_track_ids = set([
-            playlist['title'], playlist.get('description'))
+            playlist.get('title'), playlist.get('description'))
-                urlencode_postdata({
+            missing_tracks = self._download_json(
-                request, playlist_id, 'Downloading missing tracks JSON', fatal=False)
+                })
-    _VALID_URL = r'https?://music\.yandex\.(?:ru|kz|ua|by)/users/[^/]+/playlists/(?P<id>\d+)'
+    _VALID_URL = r'https?://music\.yandex\.(?P<tld>ru|kz|ua|by)/users/(?P<user>[^/]+)/playlists/(?P<id>\d+)'
-            playlist_id)
+        mobj = re.match(self._VALID_URL, url)
-        # tracks dictionary shipped with webpage is limited to 150 tracks,
+        # tracks dictionary shipped with playlist.jsx API is limited to 150 tracks,
-                    'external-domain': 'music.yandex.ru',
+                    'lang': tld,
-                '%s said: This page is currently unavailable in your region.' % self.IE_NAME, expected=True)
+            self.raise_geo_restricted(
-    _VALID_URL = r'(?:aol-video:|https?://on\.aol\.com/.*-)(?P<id>[^/?-]+)'
+    _VALID_URL = r'(?:aol-video:|https?://on\.aol\.com/(?:[^/]+/)*(?:[^/?#&]+-)?)(?P<id>[^/?#&]+)'
-    '''
+    _SITES = (
-            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com|vidto\.me|powerwatch\.pw))/
+            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com|vidto\.me|powerwatch\.pw|thevideobee\.to))/
-        }
+        },
-        }
+        },
-            'description': 'è¿äºé½æ¯å±äºå«åå¹´ä»£çåå¿ï¼',
+        if category_desc == 'ææ ':
-            return accents[char]
+        if restricted and char in ACCENT_CHARS:
-    creator:        The main artist who created the video.
+    creator:        The creator of the video.
-                                 if v is not None)
+                                 if v is not None and not isinstance(v, (list, tuple, dict)))
-                self.report_error('unable to download video data: %s' % str(err))
+                self.report_error('unable to download video data: %s' % error_to_compat_str(err))
-        genre = video_info.get('genres', [None])[0]
+
-        self.assertEqual(sanitize_filename(tests, restricted=True), 'a_b_c')
+        tests = 'aÃ¤b\u4e2d\u56fd\u7684c'
-import itertools
+import itertools
-import ssl
+import ssl
-            subtitles = []
+            subtitles = {}
-                uploader = artists[0]['name']
+                artist = uploader = artists[0]['name']
-                uploader = artists[0]['artistName']
+                artist = uploader = artists[0]['artistName']
-        title = '%s - %s' % (uploader, track) if uploader else track
+        if featured_artist:
-            entries, playlist.get('playlistId'),
+            entries, playlist.get('playlistId') or playlist_id,
-            'title': 'Somebody to Die For',
+            'title': 'Hurts - Somebody to Die For',
-            'timestamp': 1372057200,
+            'track': 'Somebody to Die For',
-            'title': 'I Wish I Could Break Your Heart',
+            'title': 'Cassadee Pope - I Wish I Could Break Your Heart',
-            'timestamp': 1392796919,
+            'track': 'I Wish I Could Break Your Heart',
-            'upload_date': '20130703',
+            'title': 'Justin Timberlake - Tunnel Vision (Explicit)',
-            'uploader': 'Justin Timberlake',
+            'upload_date': '20130703',
-            'upload_date': '20151207',
+            'title': 'K Camp - Till I Die',
-            'uploader': 'K Camp',
+            'upload_date': '20151207',
-            'upload_date': '20160428',
+            'title': 'ABC - Viva Love',
-            'uploader': 'ABC',
+            'upload_date': '20160428',
-        timestamp = None
+        timestamp = None
-        title = video_info['title']
+        track = video_info['title']
-            'title': 'Y.U. MAD',
+            'title': 'Birdman - Y.U. MAD',
-class VevoIE(InfoExtractor):
+class VevoBaseIE(InfoExtractor):
-                'Failed to download video versions info')
+                'Failed to download video versions info',
-class VevoPlaylistIE(InfoExtractor):
+class VevoPlaylistIE(VevoBaseIE):
-            playlist_id)['default']['%ss' % playlist_kind]
+        playlists = self._extract_json(webpage, playlist_id, '%ss' % playlist_kind)
-        return self._download_json(self._api_url_template % path, video_id, note, errnote)
+    def _call_api(self, path, *args, **kwargs):
-    _VALID_URL = r'https?://www\.vevo\.com/watch/(?:playlist|genre)/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://www\.vevo\.com/watch/(?P<kind>playlist|genre)/(?P<id>[^/?#&]+)'
-        playlist_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            playlist_id)['default']['playlists']
+            playlist_id)['default']['%ss' % playlist_kind]
-        playlist = list(playlists.values())[0]
+        playlist = (list(playlists.values())[0]
-from .vevo import VevoIE
+from .vevo import (
-from ..compat import compat_etree_fromstring
+from ..compat import (
-        (?:https?://www\.vevo\.com/watch/(?:[^/]+/(?:[^/]+/)?)?|
+        (?:https?://www\.vevo\.com/watch/(?!playlist|genre)(?:[^/]+/(?:[^/]+/)?)?|
-__version__ = '2016.04.24'
+__version__ = '2016.05.01'
-            metadata['album'] = info['album']
+
-                    r'(?s)<p[^>]+class="infotext"[^>]*>.*?<strong>(.+?)</strong>.*?</p>.*?%s' % DOWNLOAD_REGEX,
+                    r'(?s)<p[^>]+class="infotext"[^>]*>\s*(?:<a[^>]+>)?\s*<strong>(.+?)</strong>.*?</p>.*?%s' % DOWNLOAD_REGEX,
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/(?P<path>[^/]+/(?:[^/]+/)*?[^/#?]+?(?P<id>-?[0-9]+)?)(?:~_?[^/#?]+?)?\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/(?P<path>[^/]+/(?:[^/]+/)*?(?P<id>[^/#?]+?(?:-?[0-9]+)?))(?:~_?[^/#?]+?)?\.html'
-            'id': '102143',
+            'id': 'video-102143',
-            'id': '5727',
+            'id': 'ts-5727',
-            'id': '29417',
+            'id': 'audio-29417',
-            'id': '303',
+            'id': 'bnd-303',
-            'id': '135',
+            'id': 'afd-parteitag-135',
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/[^/]+/(?:[^/]+/)*?[^/#?]+?(?P<id>-?[0-9]+)(?:~_?[^/#?]+?)?\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/(?P<path>[^/]+/(?:[^/]+/)*?[^/#?]+?(?P<id>-?[0-9]+)?)(?:~_?[^/#?]+?)?\.html'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-from .tagesschau import TagesschauIE
+from .tagesschau import (
-            'description': 'md5:171feccd9d9b3dd54d05d501568f6359',
+            'description': '18.07.2015 20:10 Uhr',
-            'description': 'md5:695c01bfd98b7e313c501386327aea59',
+            'description': 'md5:695c01bfd98b7e313c501386327aea59',
-        'md5': 'aef45de271c4bf0a5db834aa40bf774c',
+        # audio in article
-            'id': '18407',
+            'id': '303',
-            'description': 'FlÃ¼chtlingsdebatte: Hitzig, aber wenig hilfreich',
+            'title': 'Viele Baustellen fÃ¼r neuen BND-Chef',
-    }
+    @classmethod
-                    })
+        title = self._html_search_regex(
-                    webpage, 'description', default=None)
+            formats = entries[0]['formats']
-    unified_strdate,
+    parse_iso8601,
-            'id': '30C3_-_5443_-_en_-_saal_g_-_201312281830_-_introduction_to_processor_design_-_byterazor',
+            'id': '1839',
-            'description': 'md5:80be298773966f66d56cb11260b879af',
+            'description': 'md5:df55f6d073d4ceae55aae6f2fd98a0ac',
-            'duration': 3660,
+            'timestamp': 1388188800,
-            webpage, 'duration', fatal=False, group='duration'))
+        display_id = self._match_id(url)
-                'none' if format_id in ('mp3', 'opus') else None
+        for recording in event_data.get('recordings', []):
-                'url': m.group('http_url'),
+                'url': recording_url,
-            'duration': duration,
+            'id': event_id,
-                        webpage)):
+                        webpage), 1):
-                        'title': '%s-%d' % (entry_title, num),
+                        'id': '%s-%d' % (display_id, num),
-from ..utils import parse_filesize
+from ..utils import (
-    def _extract_formats(self, download_text):
+    def _extract_formats(self, download_text, media_kind):
-                r'.*/[^/.]+\.([^/]+)\.[^/.]+', l.group('url'), 'format ID')
+                r'.*/[^/.]+\.([^/]+)\.[^/.]+$', link_url, 'format ID',
-                })
+            title = l.group('title')
-            DOWNLOAD_REGEX = r'(?s)<p>Wir bieten dieses Video in folgenden Formaten zum Download an:</p>\s*<div class="controls">(.*?)</div>\s*<p>'
+            DOWNLOAD_REGEX = r'(?s)<p>Wir bieten dieses (?P<kind>Video|Audio) in folgenden Formaten zum Download an:</p>\s*<div class="controls">(?P<links>.*?)</div>\s*<p>'
-                for num, (entry_title, download_text) in enumerate(re.findall(
+                for num, (entry_title, media_kind, download_text) in enumerate(re.findall(
-                        'formats': self._extract_formats(download_text),
+                        'formats': self._extract_formats(download_text, media_kind),
-                formats = self._extract_formats(download_text)
+                download_text = self._search_regex(
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:[^/]+/)*?[^/#?]+?(?P<id>-?[0-9]+)(?:~_?[^/#?]+?)?\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/[^/]+/(?:[^/]+/)*?[^/#?]+?(?P<id>-?[0-9]+)(?:~_?[^/#?]+?)?\.html'
-        'md5': '917a228bc7df7850783bc47979673a09',
+        'md5': 'f7c27a0eff3bfe8c7727e65f8fe1b1e6',
-                type_ = media.group('type')
+                webpage_type = media.group('type')
-                    'vcodec': 'none' if type_ == 'audio' else None,
+                    'vcodec': 'none' if webpage_type == 'audio' else None,
-                webpage, 'description', default=None)
+            DOWNLOAD_REGEX = r'(?s)<p>Wir bieten dieses Video in folgenden Formaten zum Download an:</p>\s*<div class="controls">(.*?)</div>\s*<p>'
-                    pg_formats.append(f)
+                    f = next(f for f in formats if f.get('height') == height)
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:[^/]+/)*?[^/#?]+?(?P<id>-?[0-9]+)(?:~_[^/#?]+?)?\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:[^/]+/)*?[^/#?]+?(?P<id>-?[0-9]+)(?:~_?[^/#?]+?)?\.html'
-        's': {'width': 256, 'height': 144, 'quality': 1},
+        'xs': {'quality': 0},
-        'l': {'width': 960, 'height': 544, 'quality': 3},
+        'l': {'width': 960, 'height': 540, 'quality': 3},
-)
+from ..compat import compat_str
-
+                '_type': 'url_transparent',
-                'formats': formats,
+
-from ..compat import compat_str
+from ..compat import (
-                video_info['src'], display_id, 'mp4', 'm3u8_native', m3u8_id='hls',
+            m3u8_url = video_info['src']
-    XiamiIE,
+    XiamiSongIE,
-
+# coding: utf-8
-)
+from ..utils import int_or_none
-            'duration': int_or_none(xpath_text(track, xpath_with_ns('xm:length', self._NS_MAP))),
+    _API_BASE_URL = 'http://www.xiami.com/song/playlist/cat/json/id'
-        return [self._extract_track(track) for track in tracklist]
+    def _extract_tracks(self, item_id, typ=None):
-                if len(l[j])>i:
+                if len(l[j]) > i:
-class XiamiIE(XiamiBaseIE):
+class XiamiSongIE(XiamiBaseIE):
-    ]
+    _VALID_URL = r'https?://(?:www\.)?xiami\.com/song/(?P<id>[0-9]+)'
-        return self._extract_xml(_id)[0]
+        return self._extract_tracks(self._match_id(url))[0]
-class XiamiAlbumIE(XiamiBaseIE):
+class XiamiPlaylistBaseIE(XiamiBaseIE):
-            'playlist_count': 10,
+    _VALID_URL = r'https?://(?:www\.)?xiami\.com/album/(?P<id>[0-9]+)'
-        return self.playlist_result(self._extract_xml(_id, '/type/1'), _id)
+        'playlist_count': 10,
-class XiamiArtistIE(XiamiBaseIE):
+class XiamiArtistIE(XiamiPlaylistBaseIE):
-    _VALID_URL = r'http://www\.xiami\.com/artist/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?xiami\.com/artist/(?P<id>[0-9]+)'
-class XiamiCollectionIE(XiamiBaseIE):
+class XiamiCollectionIE(XiamiPlaylistBaseIE):
-    _VALID_URL = r'http://www\.xiami\.com/collect/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?xiami\.com/collect/(?P<id>[0-9]+)'
-        'playlist_count': 26,
+        'playlist_mincount': 29,
-        return self.playlist_result(self._extract_xml(_id, '/type/3'), _id)
+from .xiami import (
-        'md5': 'fc94ac279feebbce69f21c0c6ee82810',
+        'md5': '0de43ac406aa3e4ea74b66c9c7789b13',
-            'width': 854,
+            'width': 853,
-        'md5': '226f4fb9c62380d11b7995efa4c87994',
+        'md5': 'b899ac15e345fb39534d913f7606082b',
-            'id': 'vishal-sikka-the-beauty-and-power-of-algorithms',
+            'id': 'tSVI8ta_P4w',
-        }
+            'description': 'md5:6261fdfe3e02f4f579cbbfc00aff73f4',
-        self._sort_formats(formats, ('width', 'height', 'tbr', 'format_id'))
+        self._sort_formats(formats)
-            webpage, 'config')
+            webpage, 'config', default=None)
-        'high': {'preference': 3, 'width': 854, 'height': 480},
+        'low': {'width': 320, 'height': 180},
-                        'url': resource['file'],
+                        'url': h264_url,
-                formats.extend(hls_formats)
+                formats.extend(self._extract_m3u8_formats(
-        self._sort_formats(formats)
+        self._sort_formats(formats, ('width', 'height', 'tbr', 'format_id'))
-            headers={'Referer': url})
+            headers={'Referer': url.encode('utf-8')})
-                if not bitrate or bitrate not in ('192k', '400k', '800k', '1200k', '2500k'):
+                if not bitrate or bitrate not in ('400k', '800k', '1200k', '2500k'):
-                if not bitrate:
+                # extract only the formats that we know that they will be available as http format.
-            'md5': 'ce1888486f0908d555a8093cac9a7362',
+            'md5': '173dc391afd361fa72eab5d3d918968d',
-            'md5': '143c98aa54a346738a3d78f54c925321',
+            'md5': '6f722cb3c3982186d34b0f13374499c7',
-            },
+            'md5': '115223d41bd55cda8ae5cd5ed4e11497',
-            },
+            'md5': '84ced42850d78f1d4650297356e95e6f',
-            },
+            'md5': 'acfd4c400b48149a44861cb16dd305cf',
-            },
+        http_url = None
-                    format_url, display_id, 'mp4', preference=1, m3u8_id='hls'))
+                    format_url, display_id, 'mp4', m3u8_id='hls', fatal=False))
-    _VALID_URL = r'https?://video-api\.wsj\.com/api-video/player/iframe\.html\?guid=(?P<id>[a-zA-Z0-9-]+)'
+    _VALID_URL = r'''(?x)https?://
-    _TEST = {
+    _TESTS = [{
-        'md5': '9747d7a6ebc2f4df64b981e1dde9efa9',
+        'md5': 'e230a5bb249075e40793b655a54a02e4',
-    }
+    }, {
-                video_id, ','.join('video%dkMP4Url' % br for br in bitrates))
+            'type=guid&count=1&query=%s&fields=type,hls,videoMP4List,'
-        if info.get('hls'):
+        formats = []
-                })
+                entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))
-            'upload_date': upload_date,
+            # Thumbnails are conveniently in the correct format already
-            'categories': categories,
+            'categories': info.get('keywords'),
-        'md5': 'cc16baa36a6c169391f0764fa6b16654',
+        'url': 'http://www.rtlxl.nl/#!/rtl-nieuws-132237/82b1aad1-4a14-3d7b-b554-b0aed1b2c416',
-            'id': '6e4203a6-0a5e-3596-8424-c599a59e0677',
+            'id': '82b1aad1-4a14-3d7b-b554-b0aed1b2c416',
-            'duration': 576.880,
+            'title': 'RTL Nieuws',
-            'thumbnail': 're:^https?://screenshots\.rtl\.nl/system/thumb/sz=[0-9]+x[0-9]+/uuid=84ae5571-ac25-4225-ae0c-ef8d9efb2aed$',
+            'thumbnail': 're:^https?://screenshots\.rtl\.nl/(?:[^/]+/)*sz=[0-9]+x[0-9]+/uuid=84ae5571-ac25-4225-ae0c-ef8d9efb2aed$',
-            'thumbnail': 're:^https?://screenshots\.rtl\.nl/system/thumb/sz=[0-9]+x[0-9]+/uuid=f536aac0-1dc3-4314-920e-3bd1c5b3811a$',
+            'thumbnail': 're:^https?://screenshots\.rtl\.nl/(?:[^/]+/)*sz=[0-9]+x[0-9]+/uuid=f536aac0-1dc3-4314-920e-3bd1c5b3811a$',
-        formats = self._extract_m3u8_formats(m3u8_url, uuid)
+        formats = self._extract_m3u8_formats(
-                'quality': 0,
+        PG_FORMATS = (
-        ])
+
-        formats = self._extract_m3u8_formats(m3u8_url, uuid, ext='mp4')
+        formats = self._extract_m3u8_formats(m3u8_url, uuid)
-                'format_id': 'pg-sd',
+                'url': PG_URL_TEMPLATE % ('a2t', video_urlpart),
-                'format_id': 'pg-hd',
+                'url': PG_URL_TEMPLATE % ('a3t', video_urlpart),
-        # The md5 is different each time
+        'md5': 'ac0f98a52a330f700b4b3034ad240649',
-            'ext': 'flv',
+            'ext': 'mp4',
-        display_id = mobj.group('display_id')
+        display_id, video_id = re.match(self._VALID_URL, url).groups()
-        formats = self._extract_f4m_formats(manifest_url, display_id)
+        stream_access_url = self._proto_relative_url(video_info.find('url').text.strip())
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': 'http://tv.dfb.de/images/%s_640x360.jpg' % video_id,
-            'User-Agent': 'Mozilla/5.0 (Windows NT 5.2; WOW64; rv:42.0) Gecko/20100101 Firefox/42.0',
+        user_agent = self._extract_cloudflare_session_ua(self._LOGIN_URL)
-                request, display_id, 'Downloading %s webpage' % kind)
+                request, display_id,
-                if last_media_name and not live:
+                if not live:
-            available_fmts = re.findall(r'token="showmedia\.([0-9]{3,4})p"', webpage)
+            for p in (r'token=["\']showmedia\.([0-9]{3,4})p"', r'showmedia\.([0-9]{3,4})p'):
-        for a, fmt in re.findall(r'(<a[^>]+token="showmedia\.([0-9]{3,4})p"[^>]+>.*?</a>)', webpage):
+        for a, fmt in re.findall(r'(<a[^>]+token=["\']showmedia\.([0-9]{3,4})p["\'][^>]+>)', webpage):
-    ExtractorError,
+    ExtractorError,
-        )
+                    id=video_id,
-        )
+                    id=video_id,
-                              fatal=True):
+                              fatal=True, live=False):
-                format_id.append(last_media_name if last_media_name else '%d' % (tbr if tbr else len(formats)))
+                # Bandwidth of live streams may differ over time thus making
-from __future__ import unicode_literals
+from __future__ import division, unicode_literals
-            webpage, 'long video id')
+        # UTC+x - UTC+9 (KST)
-            webpage, 'key')
+        status_params = self._download_json(
-        }
+        return dict(self._get_common_fields(webpage),
-        formats = []
+        available_fmts = []
-        for fmt in re.findall(r'token="showmedia\.([0-9]{3,4})p"', webpage):
+        formats = []
-)
+from .viewlift import (
-from .snagfilms import SnagFilmsEmbedIE
+from .viewlift import ViewLiftEmbedIE
-            return self.url_result(snagfilms_url)
+        # Look for ViewLift embeds
-    _VALID_URL = r'https?://(?:(?:www|embed)\.)?snagfilms\.com/embed/player\?.*\bfilmId=(?P<id>[\da-f-]{36})'
+class ViewLiftBaseIE(InfoExtractor):
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:embed\.)?snagfilms\.com/embed/player.+?)\1',
+            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:embed\.)?(?:%s)/embed/player.+?)\1' % ViewLiftBaseIE._DOMAINS_REGEX,
-            if all(v == 'm3u8' for v in (type_, ext)):
+            if all(v == 'm3u8' or v == 'hls' for v in (type_, ext)):
-                    'format_id': format_id,
+                    'format_id': 'http-%s%s' % (format_id, ('-%dk' % bitrate if bitrate else '')),
-        self._sort_formats(formats)
+        field_preference = None if has_bitrate else ('height', 'tbr', 'format_id')
-    _VALID_URL = r'https?://(?:www\.)?snagfilms\.com/(?:films/title|show)/(?P<id>[^?#]+)'
+class ViewLiftIE(ViewLiftBaseIE):
-        display_id = self._match_id(url)
+        domain, display_id = re.match(self._VALID_URL, url).groups()
-            'url': 'http://embed.snagfilms.com/embed/player?filmId=%s' % film_id,
+            'url': 'http://%s/embed/player?filmId=%s' % (domain, film_id),
-from .sexykarma import SexyKarmaIE
+from .watchindianporn import WatchIndianPornIE
-        'md5': 'b9798e7d1ef1765116a8f516c8091dbd',
+class WatchIndianPornIE(InfoExtractor):
-            'display_id': 'taking-a-quick-pee',
+            'id': 'RZa2avywNPa',
-            'title': 'Taking a quick pee.',
+            'title': 'Hot milf from kerala shows off her gorgeous large breasts on camera',
-            'duration': 22,
+            'uploader': 'LoveJay',
-    }]
+    }
-    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions|embed)/)?(?P<id>[^/]+)/(?P<name>[^/?#&+])'
+    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions|embed)/)?(?P<id>[^/]+)/(?P<name>[^/?#&]+)'
-                'cookies and pass cookie file to youtube-dl with --cookies',
+                'YandexMusic has considered youtube-dl requests automated and '
-        for fmt in re.findall(r'showmedia\.([0-9]{3,4})p', webpage):
+        video_encode_ids = []
-                % (stream_id, stream_format, stream_quality),
+                % (video_id, stream_format, stream_quality),
-            'thumbnail': video_thumbnail,
+            'thumbnail': xpath_text(metadata, 'episode_image_url'),
-    def _download_json(self, url, video_id, note='Downloading JSON metadata', fatal=True):
+    def _download_json(self, url, video_id, note='Downloading JSON metadata', fatal=True, query={}):
-        return super(ViewsterIE, self)._download_json(request, video_id, note, fatal=fatal)
+        return super(ViewsterIE, self)._download_json(request, video_id, note, fatal=fatal, query=query)
-                if not qualities_basename:
+        for language_set in info.get('LanguageSets', []):
-                if not qualities:
+                video_url = media.get('Uri')
-                        formats.append(f)
+                ext = determine_ext(video_url)
-        if not formats and not info.get('LanguageSets') and not info.get('VODSettings'):
+                    qualities_basename = self._search_regex(
-            raise ExtractorError('Blocked by YandexMusic', expected=True)
+            raise ExtractorError(
-            raise ExtractorError(error, expected=True)
+        if isinstance(response, dict):
-        formats = []
+        page_url = 'http://m.nuvid.com/video/%s' % video_id
-                continue
+        html5_video_re = r'(?s)<(?:video|audio)[^<]*(?:>.*?<source[^>]*)?\s+src=["\'](.*?)["\']',
-                'format_id': format_id,
+                'url': mp4_video_url,
-             r'<div class="thumb-holder video">\s*<h5[^>]*>([^<]+)</h5>'], webpage, 'title').strip()
+             r'<div class="thumb-holder video">\s*<h5[^>]*>([^<]+)</h5>',
-            r'<i class="fa fa-user"></i>\s*(\d{4}-\d{2}-\d{2})', webpage, 'upload date', fatal=False))
+            [r'<i class="fa fa-clock-o"></i>\s*(\d{2}:\d{2})',
-            'upload_date': upload_date,
+    def _download_webpage(self, *args, **kwargs):
-        }
+        },
-    _VALID_URL = r'https?://mwave\.interest\.me/meetgreet/view/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://mwave\.interest\.me/meetgreet/view/(?P<id>\d+)'
-        clip_url = 'http://mwave.interest.me/mnettv/videodetail.m?searchVideoDetailVO.clip_id={0}'.format(clip_id)
+        clip_id = self._html_search_regex(
-        https?://(?:www\.)?(?P<host>cloudy\.ec|videoraj\.ch)/
+        https?://(?:www\.)?(?P<host>cloudy\.ec|videoraj\.(?:ch|to))/
-            'url': 'http://www.videoraj.ch/v/47f399fd8bb60',
+            'url': 'http://www.videoraj.to/v/47f399fd8bb60',
-    _VALID_URL = r'https?://(?:www\.)?cw(?:tv|seed)\.com/shows/(?:[^/]+/){2}\?play=(?P<id>[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12})'
+    _VALID_URL = r'https?://(?:www\.)?cw(?:tv|seed)\.com/(?:shows/)?(?:[^/]+/){2}\?.*\bplay=(?P<id>[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12})'
-        }
+        },
-            return binascii.a2b_hex(hex)
+        def hex_to_bytes(hex):
-        clear_text = hex_to_str(flags + expiration_date + str_to_hex(relative_path))
+        clear_text = hex_to_bytes(flags + expiration_date + str_to_hex(relative_path))
-from .mwave import MwaveIE
+from .mwave import MwaveIE, MwaveMeetGreetIE
-        }
+        'skip': 'Not accessible from Travis CI server',
-class YoutubeSearchURLIE(InfoExtractor):
+class YoutubeSearchURLIE(YoutubePlaylistBaseInfoExtractor):
-        }
+        return self.playlist_result(self._process_page(webpage), playlist_title=query)
-                http_template = re.sub(QUALITIES_RE, r'%s', qualities_basename)
+                qualities = list(map(lambda q: int(q[:-1]), qualities.strip(',').split(',')))
-                    })
+                if m3u8_formats:
-from ..compat import compat_urllib_parse_unquote
+from ..compat import (
-        'url': 'http://ok.ru/video/63567059965189-0',
+        'url': 'http://ok.ru/video/63567059965189-0?fromTime=5',
-        title = movie['title']
+
-        if metadata.get('provider') == 'USER_YOUTUBE':
+        if provider == 'USER_YOUTUBE':
-            # rtmp download
+            # m3u8 download
-            r"file:\s'(?P<file>[^']+\.mp4)'", player_page, 'file')
+        screenwavemedia_url = self._html_search_regex(
-            'url': video_url,
+            'url': screenwavemedia_url,
-    _VALID_URL = r'https?://player\d?\.screenwavemedia\.com/(?:play/)?[a-zA-Z]+\.php\?.*\bid=(?P<id>[A-Za-z0-9-]+)'
+    _VALID_URL = r'(?:https?:)?//player\d?\.screenwavemedia\.com/(?:play/)?[a-zA-Z]+\.php\?.*\bid=(?P<id>[A-Za-z0-9-]+)'
-        'md5': '881ee8460e1b7735a8be938e2ffb362b',
+        # Not checking MD5 as sometimes the direct HTTP link results in 404 and HLS is used
-                    'url': mp4_url.replace(mp4_url_basename, mobj.group(1)),
+                    'url': video_url,
-    _TESTS = [{
+    _TEST = {
-        'md5': '0ff1a13aebb35d9bc14081ff633dd324',
+        # MD5 is unstable
-    }]
+    }
-            'md5': 'bccd850baebefe23b56d708a113229c2',
+            # MD5 is unstable
-            'md5': '0b1493ba1aae7d9579a5ad5531bc395a',
+            # MD5 is unstable
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': self._og_search_thumbnail(webpage, default=None),
-            r'return\s+"(https?://[^"]+)"', self.openload_decode(code), 'video URL')
+            r'return\s+"(https?://[^"]+)"', decoded, 'video URL')
-            'title': self._og_search_title(webpage),
+            'title': title,
-            'description': 'md5:f34981259a03e980a3c6404190a3ed61',
+            'description': 're:.*m7show@163\.com.*',
-        'skip': 'Romm not found',
+        'skip': 'Room not found',
-            'description': 'md5:f34981259a03e980a3c6404190a3ed61',
+            'description': 're:.*m7show@163\.com.*',
-            video_id)
+        config = None
-    parse_filesize,
+    parse_duration,
-            'title': 'ÐÐµÐ¾Ð½Ð¸Ð´ ÐÐ³ÑÑÐ¸Ð½-ÐÐµÑÐµÐ½ÐºÐ° ÑÐ¾ÑÐµÑÐ°',
+            'title': 'ÐÐµÐ¾Ð½Ð¸Ð´ ÐÐ³ÑÑÐ¸Ð½-ÐÐµÑÐµÐ½ÐºÐ° ÑÐ¾ÑÑÑÐ°',
-            r'minus_track\.artist="(.+?)"', webpage, 'artist')
+            r'<a[^>]+href="/artist/\d+">([^<]+)</a>', webpage, 'artist')
-            r'minus_track\.dur_sec=\'([0-9]*?)\'',
+            r'<span[^>]+class="minustrack-full-title(?:\s+[^"]+)?"[^>]*>([^<]+)', webpage, 'title')
-            webpage, 'bitrate', fatal=False))
+        mobj = re.search(
-            r'<div class="quality.*?âº ([0-9]+)',
+            r'<span><[^>]+class="icon-chart-bar".*?>(\d+)</span>',
-            r'(?s)<div id="song_texts">(.*?)</div><br',
+            r'(?s)<pre[^>]+id="lyrics-original"[^>]*>(.*?)</pre>',
-        video_url = 'http://x-minus.org/dwlf/%s/%s.mp3' % (video_id, token)
+        k = self._search_regex(
-__version__ = '2016.04.19'
+__version__ = '2016.04.24'
-            'description': 'md5:b2ab6295d014005bfc607525bfc1e38a',
+            'description': 'md5:5d0e947b242c35dc0eb1d2fce9fbf02c',
-            webpage, 'singer name', fatal=False)
+            r'<p[^>]+id="lrcName">([^<]+)</p>', webpage, 'song name')
-            r'<p[^>]+class="album"[^<]+<a[^>]+href="http://www\.kuwo\.cn/album/(\d+)/"',
+            r'<a[^>]+href="http://www\.kuwo\.cn/album/(\d+)/"',
-                        })
+                if not qualities_basename:
-        'playlist_count': 24,
+        'playlist_mincount': 24,
-            r'share_description\s*=\s*(["\'])(?P<description>[^\1]+?)\1',
+            r'share_description\s*=\s*(["\'])(?P<description>[^\'"]+?)\1',
-        'md5': 'c930e27b7720aaa3c9d0018dfc8ff6cc',
+        # md5 is unstable
-            'md5': '3a09cf59349cfaddae1797acc3c087fc',
+            'url': 'https://tw.news.yahoo.com/%E6%95%A2%E5%95%8F%E5%B8%82%E9%95%B7%20%E9%BB%83%E7%A7%80%E9%9C%9C%E6%89%B9%E8%B3%B4%E6%B8%85%E5%BE%B7%20%E9%9D%9E%E5%B8%B8%E9%AB%98%E5%82%B2-034024051.html',
-            }
+            },
-            }
+            },
-            }
+            },
-        webpage = self._download_webpage(url, display_id)
+        webpage, urlh = self._download_webpage_handle(url, display_id)
-            }
+                'id': '154609075',
-        if iframe_m:
+        entries = []
-                host + iframe_m.group(1), display_id, 'Downloading iframe webpage')
+                host + iframe_url, display_id,
-                return self._get_info(video_id, display_id, webpage)
+                entries.append(self._get_info(video_id, display_id, webpage))
-            'md5': 'd6e6fc6e1313c608f316ddad7b82b306',
+            'md5': 'c3466d2b6d5dd6b9f41ba9ed04c24b23',
-            'md5': '60e8ac193d8fb71997caa8fce54c6460',
+            'md5': '75ffabdb87c16d4ffe8c036dc4d1c136',
-            'md5': '989396ae73d20c6f057746fb226aa215',
+            'md5': 'b17ac378b1134fa44370fb27db09a744',
-            'md5': '4fbafb9c9b6f07aa8f870629f6671b35',
+            'md5': '1ddbf7c850777548438e5c4f147c7b8c',
-    _VALID_URL = r'(?P<url>(?P<host>https?://(?:[a-zA-Z]{2}\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?P<display_id>.+)?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html)'
+    _VALID_URL = r'(?P<url>(?P<host>https?://(?:[a-zA-Z]{2}\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?P<display_id>.+)?-(?P<id>[0-9]+)(?:-[a-z]+)?(?:\.html)?)'
-                if sapi:
+                if sapi and 'query' in sapi:
-                    '/([^/]+)(?:.csmil/manifest.f4m|.csmil/master.m3u8)',
+                    '/([^/]+)\.csmil/',
-                formats.append(f)
+                qualities_basename = self._search_regex(
-            '-c', 'copy',
+            '-map', '0:v',
-from ..utils import int_or_none
+from ..compat import compat_urlparse
-        # non geo restricted, via secure api
+        # non geo restricted, via secure api, unsigned download hls URL
-            'ext': 'flv',
+            'ext': 'mp4',
-        # geo restricted, via secure api
+        # geo restricted, via secure api, unsigned download hls URL
-            'ext': 'flv',
+            'ext': 'mp4',
-            'creator': 'Kanal 4',
+            'creator': 'Kanal 4 (Home)',
-                formats.extend(self._extract_m3u8_formats(
+                m3u8_formats = self._extract_m3u8_formats(
-                    entry_protocol='m3u8_native', m3u8_id=protocol, fatal=False))
+                    entry_protocol='m3u8_native', m3u8_id=protocol, fatal=False)
-        else:
+
-        if domain_tld in ('se', 'dk'):
+        if domain_tld in ('se', 'dk', 'no'):
-    _VALID_URL = r'(?P<page_url>https?://(?:www\d\.)?wdr\d?\.de)' + _PAGE_REGEX
+    _VALID_URL = r'(?P<page_url>https?://(?:www\d\.)?wdr\d?\.de)' + _PAGE_REGEX + "|" + _CURRENT_MAUS_URL
-        }
+        },
-    _VALID_URL = r'https?://(?:www\.)?wdrmaus\.de/(?:[^/]+/){,2}(?P<id>[^/?#]+)(?:/index\.php5|(?<!index)\.php5|/(?:$|[?#]))'
+    _VALID_URL = 'https?://(?:www\.)?wdrmaus\.de/(?:[^/]+/){,2}(?P<id>[^/?#]+)((?<!index)\.php5|/(?:$|[?#]))'
-        'md5': '3b1227ca3ed28d73ec5737c65743b2a3',
+        'url': 'http://www.wdrmaus.de/sachgeschichten/sachgeschichten/achterbahn.php5',
-            'id': '40_jahre_maus',
+            'id': 'achterbahn',
-            'title': '12.03.2011 - 40 Jahre Maus',
+            'upload_date': '20131001',
-    qualities,
+    ExtractorError,
-    _VALID_URL = r'(?P<url>https?://www\d?\.(?:wdr\d?|funkhauseuropa)\.de/)(?P<id>.+?)(?P<player>%s)?\.html' % _PLAYER_REGEX
+    _PAGE_REGEX = r'/mediathek/(?P<media_type>[^/]+)/(?P<type>[^/]+)/(?P<display_id>.+)\.html'
-            'url': 'http://www1.wdr.de/themen/av/videomargaspiegelisttot101-videoplayer.html',
+            'url': 'http://www1.wdr.de/mediathek/video/sendungen/doku-am-freitag/video-geheimnis-aachener-dom-100.html',
-                'id': 'mdb-363194',
+                'id': 'mdb-1058683',
-                'skip_download': True,
+                'display_id': 'doku-am-freitag/video-geheimnis-aachener-dom-100',
-            'md5': '83e9e8fefad36f357278759870805898',
+            'url': 'http://www1.wdr.de/mediathek/audio/wdr3/wdr3-gespraech-am-samstag/audio-schriftstellerin-juli-zeh-100.html',
-                'id': 'mdb-194332',
+                'id': 'mdb-1072000',
-                'is_live': False
+                'display_id': 'wdr3-gespraech-am-samstag/audio-schriftstellerin-juli-zeh-100',
-            'playlist_mincount': 146,
+            'url': 'http://www1.wdr.de/mediathek/video/live/index.html',
-                'id': 'mediathek/video/sendungen/quarks_und_co/filterseite-quarks-und-co100',
+                'id': 'mdb-103364',
-            'url': 'http://www1.wdr.de/mediathek/video/livestream/index.html',
+            'url': 'http://www1.wdr.de/mediathek/video/sendungen/aktuelle-stunde/aktuelle-stunde-120.html',
-                'skip_download': True,
+                'id': 'aktuelle-stunde/aktuelle-stunde-120',
-        page_id = mobj.group('id')
+        url_type = mobj.group('type')
-        webpage = self._download_webpage(url, page_id)
+        js_url = self._search_regex(self._JS_URL_REGEX, webpage, 'js_url', default=None)
-        if mobj.group('player') is None:
+        if not js_url:
-                self.url_result(page_url + href, 'WDR')
+                self.url_result(page_url + href[0], 'WDR')
-                    r'<a href="/?(.+?%s\.html)" rel="nofollow"' % self._PLAYER_REGEX,
+                    r'<a href="(%s)"' % self._PAGE_REGEX,
-                return self.playlist_result(entries, page_id)
+                return self.playlist_result(entries, playlist_id=display_id)
-            return self.playlist_result(entries, page_id)
+            raise ExtractorError('No downloadable streams found', expected=True)
-            r'<param name="flashvars" value="([^"]+)"', webpage, 'flashvars'))
+        metadata_tracker_data = metadata["trackerData"]
-        is_live = flashvars.get('isLive', ['0'])[0] == '1'
+        # check if there are flash-streams for this video
-            upload_date = flashvars['trackerClipAirTime'][0]
+            upload_date = None
-                'DC.Date', webpage, 'upload date')
+            upload_date = self._html_search_meta('DC.Date', webpage, 'upload date')
-            'formats': formats,
+            'id': metadata_tracker_data.get("trackerClipId", display_id),
-            'thumbnail': thumbnail,
+            'alt_title': metadata_tracker_data.get("trackerClipSubcategory"),
-            'is_live': is_live
+            'description': self._html_search_meta("Description", webpage),
-    NHLNewsIE,
+    NHLNewsIE,
-    compat_urllib_parse_urlparse
+    compat_urllib_parse_urlparse,
-    IE_NAME = 'nhl.com'
+class NHLVideocenterIE(NHLBaseInfoExtractor):
-    IE_NAME = 'nhl.com:videocenter'
+class NHLVideocenterCategoryIE(NHLBaseInfoExtractor):
-    _VALID_URL = r'''(?x)https?://(?:www\.)?nbcnews\.com/
+    _VALID_URL = r'''(?x)https?://(?:www\.)?(?:nbcnews|today)\.com/
-                    r'videoObj\s*:\s*({.+})', webpage, 'player instance')
+                    r'videoObj\s*:\s*({.+})', webpage, 'player instance', default=None)
-                    tbr = int_or_none(video_asset.get('bitRate'), 1000)
+                    tbr = int_or_none(video_asset.get('bitRate') or video_asset.get('bitrate'), 1000)
-                'timestamp': parse_iso8601(info.get('pubDate')),
+                'timestamp': parse_iso8601(info.get('pubDate') or info.get('pub_date')),
-        if auth_result['code'] == 'Q00506':  # End of preview time (è¯çç»æé´æå¤±è´¥)
+        code = auth_result.get('code')
-                self.report_warning('Needs a VIP account for full video')
+                self.report_warning(msg)
-        return auth_result
+        return auth_result['data']
-                        't': auth_result['data']['t'],
+                        't': auth_result['t'],
-                        'QY00001': auth_result['data']['u'],
+                        'QY00001': auth_result['u'],
-        'md5': '70f5187fb620f2c1d503b3b22fd4efe3',
+        'md5': '881ee8460e1b7735a8be938e2ffb362b',
-        'md5': '90b26344ba442c8e44aa4cf8f301164a',
+        'md5': '358597369cf8ba56675c1df15e7af624',
-        formats = self._extract_m3u8_formats(
+        m3u8_formats = self._extract_m3u8_formats(
-        formats.append({'url': mp4_url, 'format_id': 'mp4'})
+        mp4_url_basename = url_basename(mp4_url)
-from ..utils import ExtractorError
+from ..utils import (
-            'ext': 'flv',
+            'ext': 'mp4',
-                'format_note': name,
+                'format_id': 'rtmp' + ('-%s' % name if name else ''),
-    unescapeHTML,
+    ExtractorError,
-    _VALID_URL = r'https?://(?:www\.)?rtbf\.be/(?:video/[^?]+\?.*\bid=|ouftivi/(?:[^/]+/)*[^?]+\?.*\bvideoId=)(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-
+    _IMAGE_HOST = 'http://ds1.ds.static.rtbf.be'
-        ('url', 'MD'),
+        ('mobile', 'SD'),
-            'http://www.rtbf.be/video/embed?id=%s' % video_id, video_id)
+        error = data.get('error')
-            video_id)
+        data = data['data']
-            format_url = data['sources'].get(key)
+            format_url = data.get(key + 'Url')
-            'thumbnail': data.get('thumbnail'),
+            'thumbnails': thumbnails,
-import codecs
+    parse_iso8601,
-    _VALID_URL = r'https?://(?:www\.)?tubitv\.com/video\?id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?tubitv\.com/video/(?P<id>[0-9]+)'
-        'url': 'http://tubitv.com/video?id=54411&title=The_Kitchen_Musical_-_EP01',
+        'url': 'http://tubitv.com/video/283829/the_comedian_at_the_friday',
-            'id': '54411',
+            'id': '283829',
-            'duration': 2407,
+            'title': 'The Comedian at The Friday',
-        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')
+        formats = self._extract_m3u8_formats(
-            'duration': duration,
+            'subtitles': subtitles,
-            'Wrong password')
+            'Verifying the password', 'Wrong password')
-    hls_prefer_native: Use the native HLS downloader instead of ffmpeg/avconv.
+    hls_prefer_native: Use the native HLS downloader instead of ffmpeg/avconv
-    if protocol == 'm3u8' and params.get('hls_prefer_native'):
+    if protocol == 'm3u8' and params.get('hls_prefer_native') is True:
-        dest='hls_prefer_native', action='store_true',
+        dest='hls_prefer_native', action='store_true', default=None,
-        help='Use the native HLS downloader instead of ffmpeg (experimental)')
+        help='Use the native HLS downloader instead of ffmpeg')
-        }
+            if vcodec == 'hls':
-    _VALID_URL = r'https?://www\.mgtv\.com/v/(?:[^/]+/)*(?P<id>\d+).html'
+    _VALID_URL = r'https?://www\.mgtv\.com/v/(?:[^/]+/)*(?P<id>\d+)\.html'
-class DigitalSpeakingIE(InfoExtractor):
+class DigitallySpeakingIE(InfoExtractor):
-from .dispeak import DigitalSpeakingIE
+from .dispeak import DigitallySpeakingIE
-            'ie_key': 'DigitalSpeaking',
+            'ie_key': 'DigitallySpeaking',
-            'ie_key': 'DigitalSpeaking',
+            'ie_key': 'DigitallySpeaking',
-    _VALID_URL = r'http://(?:evt\.dispeak|events\.digitallyspeaking)\.com/([^/]+/)+xml/(?P<id>[^.]+).xml'
+    _VALID_URL = r'https?://(?:evt\.dispeak|events\.digitallyspeaking)\.com/(?:[^/]+/)+xml/(?P<id>[^.]+)\.xml'
-        # From http://evt.dispeak.com/ubm/gdc/sf16/xml/840376_BQRC.xml
+        # From http://gdcvault.com/play/1023460/Tenacious-Design-and-The-Interface
-            'ie': 'DigitalSpeaking',
+            'ie_key': 'DigitalSpeaking',
-            'ie': 'DigitalSpeaking',
+            'ie_key': 'DigitalSpeaking',
-            (?:
+    days, hours, mins, secs, ms = [None] * 5
-                    (?P<hours>[0-9]+)\s*(?:[:h]|hours?)\s*
+                    (?P<days>[0-9]+)\s*d(?:ays?)?\s*
-    return res
+                (?:
-    _VALID_URL = r'http://evt.dispeak.com/([^/]+/)+xml/(?P<id>[^.]+).xml'
+    _VALID_URL = r'http://(?:evt\.dispeak|events\.digitallyspeaking)\.com/([^/]+/)+xml/(?P<id>[^.]+).xml'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                })
+        audios = metadata.findall('./audios/audio')
-
+            '_type': 'url_transparent',
-            'formats': video_formats,
+            'url': '%s/xml/%s' % (xml_root, xml_name),
-        self._sort_formats(formats)
+        root_path = self._search_regex(
-            'formats': formats,
+            'url': '%sxml/%s.xml' % (root_path, xml_file_id),
-        }
+        },
-            return None
+        if mp4_video is not None:
-        video_root = mobj.group('root')
+        if not formats:
-            'http://streetvoice.com/music/api/song/%s' % song_id, song_id)
+            'https://streetvoice.com/api/v1/public/song/%s/' % song_id, song_id, data=b'')
-        author = song['musician']['name']
+        author = song['user']['nickname']
-            'uploader_id': compat_str(song['musician']['id']),
+            'uploader_id': compat_str(song['user']['id']),
-            if data or headers:
+            if data is not None or headers:
-                r'class="video-preview current_playing" id="(\d+)">',
+                (r'<div[^>]+class=["\']player["\'][^>]+id=["\'](\d+)',
-        }
+        error_msg = self._html_search_regex(
-            # m3u8 download
+from .people import PeopleIE
-__version__ = '2016.04.13'
+__version__ = '2016.04.19'
-                        (?!channels/[^/?#]+/?(?:$|[?#])|(?:album|ondemand)/)
+                        (?!channels/[^/?#]+/?(?:$|[?#])|[^/]+/review/|(?:album|ondemand)/)
-        self.assertTrue(len(entries) >= 20)
+        self.assertTrue(len(entries) >= 50)
-            url, playlist_id, 'Downloading Youtube mix')
+        ids = []
-    _VALID_URL = r'https?://(?:.+?\.)?musicplayon\.com/play(?:-touch)?\?(?:v|pl=100&play)=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:.+?\.)?musicplayon\.com/play(?:-touch)?\?(?:v|pl=\d+&play)=(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-from ..utils import int_or_none
+from ..compat import compat_urlparse
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                })
+        sources = self._parse_json(
-from ..utils import determine_ext
+from ..utils import (
-            'description': 'md5:545299bda6abf87e5ec666548c6a9448',
+            'description': 'md5:e786add7f280b7f0fe237b64cc73df76',
-            if determine_ext(src) != 'm3u8':  # m3u8 always results in 403
+            ext = determine_ext(src)
-            args.append(encodeFilename(ffpp._ffmpeg_filename_argument(tmpfilename), True))
+        args.append(encodeFilename(ffpp._ffmpeg_filename_argument(tmpfilename), True))
-        return 'file:' + fn
+        return 'file:' + fn if fn != '-' else fn
-        'playlist_count': 30,
+        'playlist_count': 24,
-            'ext': 'mp4',
+            'ext': 'flv',
-            'skip_download': True,
+    }, {
-            ooyala_url = OoyalaIE._url_for_embed_code(embed_code)
+                'ooyala embed code', default=None)
-            return self.url_result(instagram_embed_url, InstagramIE.ie_key())
+            return self.url_result(
-    _VALID_URL = r'https?://(?:www\.)?instagram\.com/p/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'(?P<url>https?://(?:www\.)?instagram\.com/p/(?P<id>[^/?#&]+))'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            'upload_date': '20141220',
+            'timestamp': 1450950000,
-            webpage, 'data url', default=None, group='url').replace('\/', '/')
+            r'(?:dataURL|playerXml(?:["\'])?)\s*:\s*(["\'])(?P<url>.+/(?:video|audio)-?[0-9]+-avCustom\.xml)\1',
-                formats.extend(self._extract_f4m_formatsa(
+                formats.extend(self._extract_f4m_formats(
-                r'501.*Not Implemented'
+                r'501.*Not Implemented',
-            return self.url_result(desktop_url, 'Ustream')
+            content_video_ids = self._parse_json(self._search_regex(
-
+            'description': 'Fast-paced football, wit, wisdom and a ready smile - why Liverpool fans should come to love new boss Jurgen Klopp.',
-            'url': 'http://www.audiomack.com/song/xclusiveszone/take-kare',
+            'url': 'http://www.audiomack.com/song/hip-hop-daily/black-mamba-freestyle',
-                'id': '172419696',
+                'id': '258901379',
-                'upload_date': '20141016',
+                'description': 'mamba day freestyle for the legend Kobe Bryant ',
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?newgrounds\.com/(?:audio/listen|portal/view)/(?P<id>[0-9]+)'
-    }
+    }, {
-            r',"name":"([^"]+)",', webpage, 'music title')
+            r'<title>([^>]+)</title>', webpage, 'title')
-            r',"artist":"([^"]+)",', webpage, 'music uploader')
+            [r',"artist":"([^"]+)",', r'[\'"]owner[\'"]\s*:\s*[\'"]([^\'"]+)[\'"],'],
-                continue
+            tp_release_url = self.TP_RELEASE_URL_TEMPLATE % pid
-
+        self._sort_formats(formats)
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-        title = self._og_search_title(webpage)
+        title = remove_start(self._html_search_regex(
-        thumbnail = self._og_search_thumbnail(webpage)
+            webpage, 'description', default=None)
-            webpage, display_id, default=display_id)
+            webpage, display_id, default=None)
-    _VALID_URL = r'(?P<url>https?://(?:www\.)?gazeta\.ru/(?:[^/]+/)?video/(?:(?:main|\d{4}/\d{2}/\d{2})/)?(?P<id>[A-Za-z0-9-_.]+)\.s?html)'
+    _VALID_URL = r'(?P<url>https?://(?:www\.)?gazeta\.ru/(?:[^/]+/)?video/(?:main/)*(?:\d{4}/\d{2}/\d{2}/)?(?P<id>[A-Za-z0-9-_.]+)\.s?html)'
-        self._handle_error(response)
+        try:
-            r'<div class="message-error">(.+?)</div>',
+            r'<div[^>]+class="message-error"[^>]*>(.+?)</div>',
-            webpage, 'hls file')
+        formats = []
-        self._sort_formats(formats)
+        def cleanup_js(code):
-            r'sportboxPlayer\.node_title\s*=\s*"([^"]+)"', webpage, 'title')
+        rtsp_url = jwplayer_data.get('rtsp_url')
-            webpage, 'thumbnail', default=None)
+        title = jwplayer_data['node_title']
-    TP_RELEASE_URL_TEMPLATE = 'http://link.theplatform.com/s/dJ5BDC/%s?manifest=m3u&mbr=true'
+    TP_RELEASE_URL_TEMPLATE = 'http://link.theplatform.com/s/dJ5BDC/%s?mbr=true'
-                    self.TP_RELEASE_URL_TEMPLATE % pid, content_id, 'Downloading %s SMIL data' % pid)
+                    tp_release_url, content_id, 'Downloading %s SMIL data' % pid)
-        if any(ie.suitable(url) for ie in other_ies):
+        other_yt_ies = iter(klass for (name, klass) in globals().items() if name.startswith('Youtube') and name.endswith('IE') and klass is not cls)
-
+        },
-            webpage, 'API play URL')
+        settings = self._parse_json(
-            'url': api_page_url,
+            'formats': formats,
-    _VALID_URL = r'https?://(?:[^.]+\.)?iqiyi\.com/.+\.html'
+    _VALID_URL = r'https?://(?:(?:[^.]+\.)?iqiyi\.com|www\.pps\.tv)/.+\.html'
-    _VALID_URL = r'https?://karaoketv\.co\.il/\?container=songs&id=(?P<id>[0-9]+)'
+    '''
-        'url': 'http://karaoketv.co.il/?container=songs&id=171568',
+        'url': 'http://www.karaoketv.co.il/%D7%A9%D7%99%D7%A8%D7%99_%D7%A7%D7%A8%D7%99%D7%95%D7%A7%D7%99/58356/%D7%90%D7%99%D7%96%D7%95%D7%9F',
-            'title': '×× ××¢××× ×©×× - ×¨××ª× ××× - ×©×¨×× ×§×¨×××§×',
+            'id': '58356',
-        url = urls_info_json['playlist'][0]['url']
+        api_page_url = self._html_search_regex(
-            'url': url,
+            'url': api_page_url,
-        }
+        },
-        for url in data['images'].values():
+        for url in filter(None, data['images'].values()):
-        } for key, url in data.get('sources', {}).get('live', {}).items()]
+        formats = []
-    MixcloudPlaylistIE
+    MixcloudPlaylistIE,
-        resp = self._download_webpage(
+    def _find_urls_in_page(self, page):
-            query={'page': (current_page + 1), 'list': 'main', '_ajax': '1'},
+            query={'page': real_page_number, 'list': 'main', '_ajax': '1'},
-                MixcloudIE.ie_key())
+    def _tracks_page_func(self, page, video_id, page_name, current_page):
-                self._fetch_tracks_page,
+                self._tracks_page_func,
-                self._fetch_tracks_page,
+                self._tracks_page_func,
-            'thumbnail': 're:https?://.*/images/',
+            'thumbnail': 're:https?://.*',
-            return False
+    # See https://www.mixcloud.com/media/js2/www_js_2.9e23256562c080482435196ca3975ab5.js
-            webpage, 'preview url', default=None if message else NO_DEFAULT)
+        encrypted_play_info = self._search_regex(
-        if message:
+        if message and 'stream_url' not in play_info:
-                raise ExtractorError('Unable to extract track url')
+        song_url = play_info['stream_url']
-    compat_urllib_request
+    compat_urlparse,
-    """
+class MixcloudPlaylistBaseIE(InfoExtractor):
-            'id': 'dholbach/uploads',
+            'id': 'dholbach_uploads',
-        'playlist_mincount': 11
+        'playlist_mincount': 11,
-            'id': 'dholbach/uploads',
+            'id': 'dholbach_uploads',
-        'playlist_mincount': 11
+        'playlist_mincount': 11,
-            'id': 'dholbach/favorites',
+            'id': 'dholbach_favorites',
-        'playlist_mincount': 244
+        'params': {
-            'id': 'dholbach/listens',
+            'id': 'dholbach_listens',
-        'playlist_mincount': 846
+        'params': {
-        list_type = mobj.group("type")
+        user_id = mobj.group('user')
-            list_type = "uploads"
+            list_type = 'uploads'
-        video_id = "%s/%s" % (user_id, list_type)
+        video_id = '%s_%s' % (user_id, list_type)
-                                         errnote="Unable to download user profile")
+        profile = self._download_webpage(
-        username = self._get_username(profile)
+        username = self._og_search_title(profile)
-        }
+        entries = OnDemandPagedList(
-    """
+class MixcloudPlaylistIE(MixcloudPlaylistBaseIE):
-            'id': 'RedBullThre3style/playlists/tokyo-finalists-2015',
+            'id': 'RedBullThre3style_tokyo-finalists-2015',
-        'playlist_mincount': 16
+        'playlist_mincount': 16,
-            'id': 'maxvibes/playlists/jazzcat-on-ness-radio',
+            'id': 'maxvibes_jazzcat-on-ness-radio',
-        video_id = "%s/playlists/%s" % (user_id, playlist_id)
+        user_id = mobj.group('user')
-                                         errnote="Unable to download playlist page")
+        profile = self._download_webpage(
-            dl_errnote="Unable to tracklist of %s" % playlist_title)
+        playlist_title = self._html_search_regex(
-        entries = self._handle_track_urls(track_urls)
+        entries = OnDemandPagedList(
-        }
+        return self.playlist_result(entries, video_id, playlist_title, description)
-        formats = []
+    BRIGHTCOVE_URL_TEMPLATE = 'http://players.brightcove.net/2034960640001/default_default/index.html?videoId=%s'
-        }
+    def _real_extract(self, url):
-        'url': 'https://xboxclips.com/video.php?uid=2533274823424419&gamertag=Iabdulelah&vid=074a69a9-5faf-46aa-b93b-9909c1720325',
+        'url': 'http://xboxclips.com/video.php?uid=2533274823424419&gamertag=Iabdulelah&vid=074a69a9-5faf-46aa-b93b-9909c1720325',
-            'uploader': 'LifeWay Christian Resources (MG)',
+        },
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        portlets = json.loads(portlets_json)
+        portlets = self._parse_json(self._search_regex(
-            r'<!--\s*p_l_id - ([0-9]+)<br>', webpage, 'p_l_id')
+            r'getPlid:function\(\){return"(\d+)"}', webpage, 'p_l_id')
-                }
+                return self.url_result(
-            if self.params.get('hls_use_mpegts', False):
+            if self.params.get('hls_use_mpegts', False) or tmpfilename == '-':
-        args.append(encodeFilename(ffpp._ffmpeg_filename_argument(tmpfilename), True))
+        if tmpfilename == '-':
-    _VALID_URL = r'https?://creative\.arte\.tv/(?P<lang>fr|de|en|es)/(?:magazine?/)?(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://creative\.arte\.tv/(?P<lang>fr|de|en|es)/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-    _VALID_URL = r'(?:aol-video:|https?://on\.aol\.com/video/.*-)(?P<id>[^/?-]+)'
+    _VALID_URL = r'(?:aol-video:|https?://on\.aol\.com/.*-)(?P<id>[^/?-]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+        'skip': 'Not providing trailers anymore',
-            'ext': 'flv',
+            'ext': 'mp4',
-        for url in set(re.findall(r'"src","([^"]+)"', webpage)):
+        for url in set(re.findall(r'var\s+playerUri\d+\s*=\s*"([^"]+)"', webpage)):
-                formats.extend(self._extract_f4m_formats(url, video_id))
+                formats.extend(self._extract_f4m_formats(url, video_id, f4m_id='hds'))
-                formats.extend(self._extract_m3u8_formats(url, video_id))
+                formats.extend(self._extract_m3u8_formats(url, video_id, ext='mp4', m3u8_id='hls'))
-            video_id, transform_source=fix_xml_ampersands)
+            video_id, transform_source=fix_xml_ampersands,
-                tbr = int_or_none(rend.get('encodingRate'), 1000),
+                tbr = int_or_none(rend.get('encodingRate'), 1000)
-__version__ = '2016.04.06'
+__version__ = '2016.04.13'
-        }
+        },
-        }
+        },
-            r'<div class="description-text">.*?<p>(?P<description>.*?)</p></div></div></div>',
+            r'<div class="description-text">.*?<p>(.*?)</p></div></div></div>',
-            default="")
+            fatal=False)
-            req = compat_urllib_request.Request(page_url, headers={"X-Requested-With": "XMLHttpRequest"}, method="GET")
+            req = compat_urllib_request.Request(page_url, headers={"X-Requested-With": "XMLHttpRequest"})
-            'ext': 'mp3',
+            'ext': 'm4a',
-            'description': 'md5:c2c51a1f1b8bb5442f2ca67c3dc4af27',
+            'description': 'md5:7bbbf0d6359a0b8cda85224be0f8f263',
-from .mixcloud import MixcloudIE
+from .mixcloud import (
-from ..compat import compat_urllib_parse_unquote
+from ..compat import (
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?mixcloud\.com/([^/]+)/([^/]+)'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?mixcloud\.com/([^/]+)/(?!stream|uploads|favorites|listens|playlists)([^/]+)'
-        if playlist_id.startswith('RD') or playlist_id.startswith('UL'):
+        if playlist_id.startswith(('RD', 'UL', 'PU')):
-                'ext': 'srt',
+                'ext': 'ttml',
-                'thumbnail': 're:^http://.*\.jpg',
+                'thumbnail': 're:^https?://.*\.jpg',
-                'thumbnail': 're:^http://.*\.jpg',
+                'thumbnail': 're:^https://.*\.jpg',
-        description = self._og_search_description(webpage)
+        description = self._og_search_description(webpage, default=None)
-                'ext': 'mp4',
+                'ext': 'flv',
-            'skip_download': 'HLS',
+            'skip_download': 'HDS',
-            r'var\s+payload\s*=\s*(.*?);\n', webpage, 'payload'), playlist_id)
+            r'(?:var\s+|window\.)payload\s*=\s*(.*?);\n', webpage, 'payload'), playlist_id)
-        'md5': '027fcc54459dff0feb0bc06a7aeda680',
+        'md5': '4b6db9a0a333142eb9f15913142b0ed1',
-            'duration': 79,
+            'duration': 80,
-            'age_limit': self._family_friendly_search(webpage),
+            'age_limit': 18,
-            r'\s(?:data-preview-url|m-preview)="([^"]+)"', webpage, 'preview url')
+            r'\s(?:data-preview-url|m-preview)="([^"]+)"',
-        }
+from .openclassroom import OpenClassRoomIE
-        /playerv2/embed\.php\?json_url=
+        /(?:playerv2/embed|arte_vp/index)\.php\?json_url=
-            r'<script [^>]*?src="(?P<url>http://www\.arte\.tv/playerv2/embed[^"]+)"',
+            r'<(?:script|iframe) [^>]*?src="(?P<url>http://www\.arte\.tv/(?:playerv2/embed|arte_vp/index)[^"]+)"',
-from ..utils import str_to_int
+from ..utils import remove_start
-    _VALID_URL = r'https?://(?:www\.)?presstv\.ir/[^/]+/(?P<y>[0-9]+)/(?P<m>[0-9]+)/(?P<d>[0-9]+)/(?P<id>[0-9]+)/'
+    _VALID_URL = r'https?://(?:www\.)?presstv\.ir/[^/]+/(?P<y>\d+)/(?P<m>\d+)/(?P<d>\d+)/(?P<id>\d+)/(?P<display_id>[^/]+)?'
-        webpage = self._download_webpage(url, video_id)
+        mobj = re.match(self._VALID_URL, url)
-                                            'Video URL')
+        video_url = self._hidden_inputs(webpage)['inpPlayback']
-            ("1080p", ".mp4")
+            (180, '_low200.mp4'),
-            })
+        formats = [{
-        title = title.partition('-')[2].strip()
+        title = remove_start(
-            str_to_int(match.group('d'))
+            int(mobj.group('y')),
-    _VALID_URL = r'https?://(?:www\.)?telebruxelles\.be/(news|sport|dernier-jt)/?(?P<id>[^/#?]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:telebruxelles|bx1)\.be/(news|sport|dernier-jt)/?(?P<id>[^/#?]+)'
-            r"<article id=\"post-(\d+)\"", webpage, 'article ID')
+            r"<article id=\"post-(\d+)\"", webpage, 'article ID', default=None)
-        description = self._og_search_description(webpage)
+        description = self._og_search_description(webpage, default=None)
-            r"file: \"(rtmp://\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5}/vod/mp4:\" \+ \"\w+\" \+ \".mp4)\"",
+            r'file\s*:\s*"(rtmp://[^/]+/vod/mp4:"\s*\+\s*"[^"]+"\s*\+\s*".mp4)"',
-        rtmp_url = rtmp_url.replace("\" + \"", "")
+        rtmp_url = re.sub(r'"\s*\+\s*"', '', rtmp_url)
-            'id': article_id,
+            'id': article_id or display_id,
-            r'<title>(.*?)</title>', webpage, 'title')
+            r'<title>(.+?)</title>', webpage, 'title')
-            else self.http_scheme() + thumbnail_url)
+            webpage, 'video URL', default=None,
-            r'<source src="(.*?)" type="video/mp4">', webpage, 'video URL')
+        video_url = self._proto_relative_url(self._search_regex(
-                subtitles[track['label']] = [{'url': self._proto_relative_url(track['file'])}]
+        subtitles = {}
-from ..utils import int_or_none
+from ..utils import (
-)
+from .jwplatform import JWPlatformBaseIE
-class ScreencastOMaticIE(InfoExtractor):
+class ScreencastOMaticIE(JWPlatformBaseIE):
-        thumbnail = data.get('image')
+        jwplayer_data = self._parse_json(
-            'id': video_id,
+        info_dict = self._parse_jwplayer_data(jwplayer_data, video_id, require_title=False)
-        }
+        })
-    _VALID_URL = r'https?://www\.ebaumsworld\.com/video/watch/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?ebaumsworld\.com/videos/[^/]+/(?P<id>\d+)'
-        'url': 'http://www.ebaumsworld.com/video/watch/83367677/',
+        'url': 'http://www.ebaumsworld.com/videos/a-giant-python-opens-the-door/83367677/',
-                            'and electricity use.')
+            'thumbnail': 're:^https?://.*\.jpg',
-            }
+        _formats = [
-        formats.reverse()
+
-        description = self._html_search_meta('og:description', webpage, 'Description', True)
+        thumbnail = self._og_search_thumbnail(webpage)
-        upload_date = '%04d%02d%02d' % (year, month, day)
+        match = re.match(PressTVIE._VALID_URL, url)
-)
+# coding: utf-8
-        # data, headers and query params will be ignored for `Request` objects
+from youtube_dl.utils import encode_data_uri, strip_jsonp, ExtractorError
-from ..utils import int_or_none
+from ..compat import compat_xpath
-    _VALID_URL = r'https?://(?:www\.)?1tv\.ru/(?:[^/]+/)+(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?1tv\.ru/(?:[^/]+/)+p?(?P<id>\d+)'
-        'md5': '777f525feeec4806130f4f764bc18a4f',
+        # single format via video_materials.json API
-            'id': '73390',
+            'id': '35930',
-            'description': 'md5:d41d8cd98f00b204e9800998ecf8427e',
+            'title': 'ÐÐ¾ÑÑÑ ÐÑÐ´Ð¼Ð¸Ð»Ð° Ð¡ÐµÐ½ÑÐ¸Ð½Ð°. ÐÐ°ÐµÐ´Ð¸Ð½Ðµ ÑÐ¾ Ð²ÑÐµÐ¼Ð¸. ÐÑÐ¿ÑÑÐº Ð¾Ñ 12.02.2015',
-            'dislike_count': int,
+            'upload_date': '20150212',
-        'md5': 'a1b6b60d530ebcf8daacf4565762bbaf',
+        # multiple formats via video_materials.json API
-            'id': '35930',
+            'id': '113641',
-            'description': 'md5:89553aed1d641416001fe8d450f06cb9',
+            'title': 'ÐÐµÑÐµÐ½Ð½ÑÑ Ð°Ð»Ð»ÐµÑÐ³Ð¸Ñ. ÐÐ¾Ð±ÑÐ¾Ðµ ÑÑÑÐ¾. Ð¤ÑÐ°Ð³Ð¼ÐµÐ½Ñ Ð²ÑÐ¿ÑÑÐºÐ° Ð¾Ñ 07.04.2016',
-            'duration': 2694,
+            'upload_date': '20160407',
-        'skip': 'Only works from Russia',
+    }, {
-        webpage = self._download_webpage(url, video_id, 'Downloading page')
+        # Videos with multiple formats only available via this API
-            webpage, 'video URL')
+        description, thumbnail, upload_date, duration = [None] * 4
-                'description', webpage, 'description')
+        if video:
-            'video duration', fatal=False)
+            item = xpath_element(video, './channel/item', fatal=True)
-            webpage, 'dislike count', default=None)
+        self._sort_formats(formats)
-            'url': video_url,
+            'upload_date': upload_date,
-            'dislike_count': int_or_none(dislike_count),
+            'formats': formats
-    _VALID_URL = r'https?://(?:www\.)?presstv\.ir/Video/(?P<y>[0-9]+)/(?P<m>[0-9]+)/(?P<d>[0-9]+)/(?P<id>[0-9]+)/'
+    _VALID_URL = r'https?://(?:www\.)?presstv\.ir/[^/]+/(?P<y>[0-9]+)/(?P<m>[0-9]+)/(?P<d>[0-9]+)/(?P<id>[0-9]+)/'
-        'md5': 'e95736ac75088b5f1e5bbb68f248f90d',
+        'url': 'http://www.presstv.ir/Detail/2016/04/09/459911/Australian-sewerage-treatment-facility-/',
-            'id': '431915',
+            'id': '459911',
-                            'to Face program, was aired on October 3, 2015.')
+            'title': 'Organic mattresses used to clean waste water',
-                                              'Description', flags=re.DOTALL)
+        title = title.partition('-')[2].strip()
-            'duration': 138,
+            'description': 'md5:c189d5b7280400630a1d3dd17eaa8d8a',
-        return self.url_result(InternetVideoArchiveIE._build_url(query), ie=InternetVideoArchiveIE.ie_key())
+        return self.url_result(InternetVideoArchiveIE._build_json_url(query), ie=InternetVideoArchiveIE.ie_key())
-from .videodetective import VideoDetectiveIE
+from .common import InfoExtractor
-class RottenTomatoesIE(VideoDetectiveIE):
+class RottenTomatoesIE(InfoExtractor):
-            'description': 'From the creators of the beloved TOY STORY films, comes a story that will reunite the gang in a whole new way.',
+            'title': 'Toy Story 3',
-
+    compat_parse_qs,
-    xpath_with_ns,
+    determine_ext,
-    _VALID_URL = r'https?://video\.internetvideoarchive\.net/flash/players/.*?\?.*?publishedid.*?'
+    _VALID_URL = r'https?://video\.internetvideoarchive\.net/(?:player|flash/players)/.*?\?.*?publishedid.*?'
-        'url': 'http://video.internetvideoarchive.net/flash/players/flashconfiguration.aspx?customerid=69249&publishedid=452693&playerid=247',
+        'url': 'http://video.internetvideoarchive.net/player/6/configuration.ashx?customerid=69249&publishedid=194487&reporttag=vdbetatitle&playerid=641&autolist=0&domain=www.videodetective.com&maxrate=high&minrate=low&socialplayer=false',
-            'id': '452693',
+            'id': '194487',
-            'duration': 152,
+            'title': 'KICK-ASS 2',
-        return 'http://video.internetvideoarchive.net/flash/players/flashconfiguration.aspx?' + query
+    def _build_json_url(query):
-        return compat_urllib_parse_urlencode(cleaned_dic)
+    def _build_xml_url(query):
-        query_dic = compat_urlparse.parse_qs(query)
+        query_dic = compat_parse_qs(query)
-        item = info.find('channel/item')
+        if '/player/' in url:
-            })
+            self._sort_formats(formats)
-        self._sort_formats(formats)
+            title = video_info['title']
-            'title': item.find('title').text,
+            'title': title,
-            'duration': int(attr['duration']),
+            'thumbnail': thumbnail,
-            webpage, 'm3u8 url', default=None, group='url')
+            r'<source[^>]+src=(["\'])(?P<url>.+?/master\.m3u8[^"\']*)\1',
-    _VALID_URL = r'(?:aol-video:|https?://on\.aol\.com/video/.*-)(?P<id>[0-9]+)(?:$|\?)'
+    _VALID_URL = r'(?:aol-video:|https?://on\.aol\.com/video/.*-)(?P<id>[^/?-]+)'
-        'add_ie': ['FiveMin'],
+        'params': {
-        return self.url_result('5min:%s' % video_id)
+
-    from setuptools import setup
+    from setuptools import setup, Command
-    from distutils.core import setup
+    from distutils.core import setup, Command
-    def __new__(cls):
+    def __new__(cls, *args, **kwargs):
-        return real_cls.__new__(real_cls)
+        instance = real_cls.__new__(real_cls)
-from .extractor import get_info_extractor, gen_extractor_classes
+from .extractor import get_info_extractor, gen_extractor_classes, _LAZY_LOADER
-        s += getsource(ie.suitable)
+        s += '\n' + getsource(ie.suitable)
-for ie in _ALL_CLASSES:
+for ie in list(sorted(_ALL_CLASSES[:-1], key=lambda cls: cls.ie_key())) + _ALL_CLASSES[-1:]:
-module_src = '\n'.join(module_contents)
+module_src = '\n'.join(module_contents) + '\n'
-        return {!r}
+        return {valid_url!r}
-        s += make_valid_template.format(ie._make_valid_url())
+        s += make_valid_template.format(valid_url=ie._make_valid_url())
-    '_ALL_CLASSES = [{}]'.format(', '.join(names)))
+    '_ALL_CLASSES = [{0}]'.format(', '.join(names)))
-_ALL_CLASSES.append(GenericIE)
+try:
-from .zippcast import ZippCastIE
+from .extractors import *
-from .extractor import get_info_extractor, gen_extractors
+from .extractor import get_info_extractor, gen_extractor_classes
-        ie.set_downloader(self)
+        if not isinstance(ie, type):
-        for ie in gen_extractors():
+        for ie in gen_extractor_classes():
-    return [klass() for klass in _ALL_CLASSES]
+    return [klass() for klass in gen_extractor_classes()]
-        categories = categories_str.split(', ') if categories_str is not None else []
+        categories = [c.strip() for c in categories_str.split(',')] if categories_str is not None else []
-    _UPLOADER_REGEX = r'(?s)<span[^>]+class="infoTitle"[^>]*>Uploaded By:</span>(.+?)<div'
+    _DESCRIPTION_REGEX = r'<meta[^>]+name="description"[^>]+content="([^"]+)"'
-        'md5': 'ecf3498417d09216374fc5907f9c6ec0',
+        'md5': '7e569419fe6d69543d01e6be22f5f7c4',
-            'categories': [],
+            'categories': ['Porn Stars'],
-        'md5': '0f5d4d490dbfd117b8607054248a07c0',
+        'md5': 'fcba2636572895aba116171a899a5658',
-            'ext': 'mp4',
+            'ext': 'flv',
-            self._CONFIG_REGEX, webpage, 'flashvars.config'), 'http:')
+            self._CONFIG_REGEX, webpage, 'flashvars.config', default=None), 'http:')
-            name = re.search(r'name=(["\'])(?P<value>.+?)\1', input)
+            name = re.search(r'(?:name|id)=(["\'])(?P<value>.+?)\1', input)
-            start_page, 'xml root', default=None)
+            PLAYER_REGEX, start_page, 'xml root', default=None)
-                    start_page, 'xml root')
+                    PLAYER_REGEX, start_page, 'xml root')
-            xml_name = self._html_search_regex(r'<iframe src=".*?\?xmlURL=xml/(?P<xml_file>.+?\.xml).*?".*?</iframe>', start_page, 'xml filename')
+            xml_name = self._html_search_regex(
-        xml_description = self._download_xml(xml_description_url, display_id)
+        xml_description = self._download_xml(
-                            media_template = re.sub(r'\$(Number|Bandwidth)%(\d+)\$', r'%(\1)\2d', media_template)
+                            media_template = re.sub(r'\$(Number|Bandwidth)%([^$]+)\$', r'%(\1)\2', media_template)
-        video_id = None
+
-        default_lang = 'en'
+        video_id = None
-        self._sort_formats(formats)
+        description = self._og_search_description(webpage, default=None)
-            'title': json_data['title'],
+            'title': title,
-        'md5': 'fbb8fe3d7a56a5e12431ce2f9b2fab0d',
+        'md5': '3757c182d3d84da68f5c8f506c18c196',
-            'description': 'A daily independent global news hour with Amy Goodman & Juan GonzÃ¡lez "What to the Slave is 4th of July?": James Earl Jones Reads Frederick Douglass\u2019 Historic Speech : "This Flag Comes Down Today": Bree Newsome Scales SC Capitol Flagpole, Takes Down Confederate Flag : "We Shall Overcome": Remembering Folk Icon, Activist Pete Seeger in His Own Words & Songs',
+            'title': 'Daily Show',
-        'md5': 'fbb8fe3d7a56a5e12431ce2f9b2fab0d',
+        'params': {
-        description = self._og_search_description(webpage)
+        description = self._og_search_description(webpage, default=None)
-    _VALID_URL_TEMPLATE = r'http://(?:(?:www\.)?%(host)s/(?:file|video|mobile/#/videos)/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<id>[a-z\d]{13})'
+    _VALID_URL_TEMPLATE = r'''(?x)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-from ..utils import int_or_none
+from ..utils import (
-        cast_data = self._download_json('https://embed.acast.com/api/acasts/%s/%s' % (channel, display_id), display_id)
+        cast_data = self._download_json(
-        entries = [self.url_result('https://www.acast.com/%s/%s' % (display_id, cast['url']), 'ACast') for cast in casts]
+    def _fetch_page(self, channel_slug, page):
-        return self.playlist_result(entries, compat_str(channel_data['id']), channel_data['name'], channel_data.get('description'))
+    def _real_extract(self, url):
-
+        cast_data = self._download_json('https://embed.acast.com/api/acasts/%s/%s' % (channel, display_id), display_id)
-        if thumbnails and 'thumbnail' not in info_dict:
+        thumbnail = info_dict.get('thumbnail')
-from ..utils import float_or_none
+from ..utils import (
-                video_id, f4m_id='hds', fatal=False))
+
-            'https://api.beeg.com/api/v6/1738/video/%s' % video_id, video_id)
+            'http://api.beeg.com/api/v6/%s/video/%s' % (beeg_version, video_id),
-            a = 'GUuyodcfS8FW8gQp4OKLMsZBcX0T7B'
+            a = beeg_salt
-            'age_limit': 18,
+            'age_limit': self._rta_search(webpage),
-            'title': 'Carlo Ambrosio - Gypsy Eyes 1',
+            'title': 'Carlo Ambrosio & Fabio Di Bari, Carlo Ambrosio - Gypsy Eyes 1',
-        return {
+
-            'title': '%s - %s' % (track['artists'][0]['name'], track['title']),
+            'track': track_title,
-__version__ = '2016.04.05'
+__version__ = '2016.04.06'
-                e = encode_list(e)
+                list_e = encode_list(e)
-        if auth_result['code'] == 'Q00506':  # requires a VIP account
+
-__version__ = '2016.04.01'
+__version__ = '2016.04.05'
-            r'naboo\.display\(\'[^\']+\',\s*(.*?)\);\n', webpage, 'data JSON')
+            (r'__DZR_APP_STATE__\s*=\s*({.+?})\s*</script>',
-        thumbnail = 'http://img.rasset.ie/' + thumbnail_id + '.jpg'
+        thumbnail = None
-    WholeCloudIE,
+    AuroraVidIE,
-    AuroraVidIE,
+    WholeCloudIE,
-    }
+    _TEST = None
-        title = self._html_search_regex(self._TITLE_REGEX, webpage, 'title', fatal=False)
+        title = self._html_search_regex(self._TITLE_REGEX, webpage, 'title')
-    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall(_x('.//ttaf1:p')) or dfxp.findall('.//p')
+    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall(_x('.//ttaf1:p')) or dfxp.findall(_x('.//ttaf1_0604:p')) or dfxp.findall('.//p')
-                            vid\.plus                                         # or vid.plus/xxxx
+                            vid\.plus|                                        # or vid.plus/xxxx
-            'uploader_id': compat_str(video_info.get('publisherId')),
+            'uploader_id': compat_str(publisher_id) if publisher_id else None,
-                'uploader_id': 1589608506001,
+                'uploader_id': '1589608506001',
-                'uploader_id': 1460825906,
+                'uploader_id': '1460825906',
-                'uploader_id': 1130468786001,
+                'uploader_id': '1130468786001',
-                'uploader_id': 710858724001,
+                'uploader_id': '710858724001',
-            'uploader_id': video_info.get('publisherId'),
+            'uploader_id': compat_str(video_info.get('publisherId')),
-            'uploader': 'Nowness',
+            'timestamp': 1446745676,
-            'uploader': 'Nowness',
+            'timestamp': 1407315371,
-        title = json_data['name']
+        title = json_data['name'].strip()
-        tags = json_data.get('tags', [])
+        subtitles = {}
-            'timestamp': timestamp,
+            'description': json_data.get('description'),
-            'tags': tags,
+            'subtitles': subtitles,
-            'url': 'http://c.brightcove.com/services/viewer/htmlFederated?%40videoPlayer=ref%3ABC2996102916001&linkBaseURL=http%3A%2F%2Fwww.redbull.com%2Fen%2Fbike%2Fvideos%2F1331655630249%2Freplay-uci-fort-william-2014-dh&playerKey=AQ%7E%7E%2CAAAApYJ7UqE%7E%2Cxqr_zXk0I-zzNndy8NlHogrCb5QdyZRf&playerID=1398061561001#__youtubedl_smuggle=%7B%22Referer%22%3A+%22http%3A%2F%2Fwww.redbull.com%2Fen%2Fbike%2Fstories%2F1331655643987%2Freplay-uci-dh-world-cup-2014-from-fort-william%22%7D',
+            'url': 'http://c.brightcove.com/services/viewer/htmlFederated?%40videoPlayer=ref%3Aevent-stream-356&linkBaseURL=http%3A%2F%2Fwww.redbull.com%2Fen%2Fbike%2Fvideos%2F1331655630249%2Freplay-uci-fort-william-2014-dh&playerKey=AQ%7E%7E%2CAAAApYJ7UqE%7E%2Cxqr_zXk0I-zzNndy8NlHogrCb5QdyZRf&playerID=1398061561001#__youtubedl_smuggle=%7B%22Referer%22%3A+%22http%3A%2F%2Fwww.redbull.com%2Fen%2Fbike%2Fstories%2F1331655643987%2Freplay-uci-dh-world-cup-2014-from-fort-william%22%7D',
-                'id': '2996102916001',
+                'id': '3750436379001',
-                'uploader': 'Red Bull TV',
+                'uploader': 'RBTV Old (do not use)',
-                size = rend.get('size')
+                tbr = int_or_none(rend.get('encodingRate'), 1000),
-                    'filesize': size if size != 0 else None,
+                    'filesize': int_or_none(rend.get('size')) or None,
-            max_id = page['items'][-1]['id']
+            max_id = page['items'][-1]['id'].split('_')[0]
-                            representation_ms_info['segment_urls'] = [media_template % {'Number': segment_number, 'Bandwidth': representation_attrib.get('bandwidth')} for segment_number in range(representation_ms_info['start_number'], representation_ms_info['total_number'] + representation_ms_info['start_number'])]
+                            representation_ms_info['segment_urls'] = [
-                            media_template = re.sub(r'\$(Number|Bandwidth)(?:%(0\d+)d)?\$', r'%(\1)\2d', media_template)
+                            media_template = re.sub(r'\$(Number|Bandwidth)\$', r'%(\1)d', media_template)
-                        'preference': 2 if src else 1,
+                        'source_preference': 0 if src else -1,
-from .cnet import CNETIE
+import re
-    _VALID_URL = r'https?://(?:www\.)?cnet\.com/videos/(?P<id>[^/]+)/'
+class CBSInteractiveIE(ThePlatformIE):
-        display_id = self._match_id(url)
+        site, display_id = re.match(self._VALID_URL, url).groups()
-            r"data-cnet-video(?:-uvp)?-options='([^']+)'",
+            r"data-(?:cnet|zdnet)-video(?:-uvp)?-options='([^']+)'",
-        formats, subtitles = self._extract_theplatform_smil(self.TP_RELEASE_URL_TEMPLATE % media_guid_path, video_id)
+        media_guid_path = 'media/guid/%d/%s' % (self.MPX_ACCOUNTS[site], vdata['mpxRefId'])
-        subtitles = {}
+        media_guid_path = 'media/guid/2288573011/%s' % vdata['mpxRefId']
-            release_url = 'http://link.theplatform.com/s/kYEXFC/%s?mbr=true' % vid
+            release_url = self.TP_RELEASE_URL_TEMPLATE % vid
-        return {
+        info = self.get_metadata('kYEXFC/%s' % media_guid_path, video_id)
-            'duration': duration,
+            'duration': int_or_none(vdata.get('duration')),
-        }
+        })
-            if ext == 'dfxp' or ext == 'ttml':
+            if ext == 'dfxp' or ext == 'ttml' or ext == 'tt':
-            ext = textstream.get('ext') or determine_ext(src) or mimetype2ext(textstream.get('type'))
+            ext = textstream.get('ext') or mimetype2ext(textstream.get('type')) or determine_ext(src)
-                video_url, query), {
+            'url': smuggle_url(
-            'only_matching': True,
+    _VALID_URL = r'https?://(?:www\.)?camwithher\.tv/view_video\.php\?.*\bviewkey=(?P<id>\w+)'
-            'only_matching': True,
+        'params': {
-    ]
+    }, {
-        flv_id = self._html_search_regex(r'<a href="/download/\?v=(\d+)', webpage, 'id')
+        flv_id = self._html_search_regex(
-        rtmp_url = 'rtmp://camwithher.tv/clipshare/%s' % (('mp4:%s.mp4' % flv_id) if int(flv_id) > 2010 else flv_id)
+        # Video URL construction algorithm is reverse-engineered from cwhplayer.swf
-            'no_resume': True,
+            'no_resume': True,
-            'url': smuggle_url(theplatform_url, {'force_smil_url': True}),
+            'url': smuggle_url(self._proto_relative_url(theplatform_url), {'force_smil_url': True}),
-                 r'<title>([^<]*)</title>'],
+                [r'<b>Title:</b> ([^<]+)</div>',
-                 r'class="tabSeperator">></span><span class="tabText">(.*?)<'],
+                 r'class="tabSeperator">></span><span class="tabText">(.*?)<',
-        'url': 'http://screencast.com/t/aAB3iowa',
+        'url': 'http://www.screencast.com/t/aAB3iowa',
-    ]
+    }, {
-    _VALID_URL = r'https?://www\.screencast\.com/t/(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?screencast\.com/t/(?P<id>[a-zA-Z0-9]+)'
-        'url': 'http://www.screencast.com/t/aAB3iowa',
+        'url': 'http://screencast.com/t/aAB3iowa',
-            'Password': password.encode('utf-8'),
+            'Username': username,
-            'password': password.encode('utf-8'),
+            'username': username,
-            'password': password.encode('utf-8'),
+            'email': username,
-        asset_type = asset.get('assetType') or asset.get('asset_type')
+        asset_type = asset.get('asset_type') or asset.get('assetType')
-        stream_url = asset.get('streamUrl') or asset.get('stream_url')
+        stream_url = asset.get('stream_url') or asset.get('streamUrl')
-        thumbnail = asset.get('thumbnailUrl') or asset.get('thumbnail_url')
+        thumbnail = asset.get('thumbnail_url') or asset.get('thumbnailUrl')
-                'fields[lecture]': 'title',
+                'fields[lecture]': 'title,asset',
-from ..utils import sanitized_Request
+from ..utils import (
-    _VALID_URL = r'https?://(?:www.)?movieclips\.com/videos/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www.)?movieclips\.com/videos/.+-(?P<id>\d+)(?:\?|$)'
-        'url': 'http://www.movieclips.com/videos/warcraft-trailer-1-561180739597?autoPlay=true&playlistId=5',
+        'url': 'http://www.movieclips.com/videos/warcraft-trailer-1-561180739597',
-            'display_id': 'warcraft-trailer-1-561180739597',
+            'timestamp': 1446843055,
-        description = self._html_search_meta('description', webpage)
+        video_id = self._match_id(url)
-            'description': description,
+            'ie_key': 'ThePlatform',
-class CBSIE(ThePlatformIE):
+class CBSBaseIE(ThePlatformIE):
-from .theplatform import ThePlatformIE
+from .cbs import CBSBaseIE
-class CBSNewsIE(ThePlatformIE):
+class CBSNewsIE(CBSBaseIE):
-
+import re
-from ..utils import smuggle_url
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:history|aetv|mylifetime)\.com|fyi\.tv)/(?:[^/]+/)+(?P<id>[^/]+?)(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:history|aetv|mylifetime)\.com|fyi\.tv)/(?P<type>[^/]+)/(?:[^/]+/)+(?P<id>[^/]+?)(?:$|[?#])'
-        video_id = self._match_id(url)
+        page_type, video_id = re.match(self._VALID_URL, url).groups()
-        video_url = self._search_regex(video_url_re, webpage, 'video url')
+        video_url = unescapeHTML(self._search_regex(video_url_re, webpage, 'video url'))
-            'url': smuggle_url(video_url, {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}}),
+            'url': smuggle_url(update_url_query(
-        relative_path = url.split('http://link.theplatform.com/s/')[1].split('?')[0]
+        relative_path = re.match(r'https?://link.theplatform.com/s/([^?]+)', url).group(1)
-__version__ = '2016.03.27'
+__version__ = '2016.04.01'
-from .common import InfoExtractor
+from .theplatform import ThePlatformIE
-    smuggle_url,
+    xpath_text,
-class CBSIE(InfoExtractor):
+class CBSIE(ThePlatformIE):
-            'id': '4JUVEwq3wUT7',
+            'id': '_u7W953k6la293J7EPTd9oHkSPs6Xn6_',
-            'ext': 'flv',
+            'ext': 'mp4',
-                {'force_smil_url': True}),
+        webpage = self._download_webpage(url, display_id)
-        }
+            'title': title,
-        },
+    }, {
-        provider_video_type = None
+        def create_entry(provider_video_id, provider_video_type, title=None, description=None):
-            r'var\s+entry\s*=\s*({.+});'
+        entries = []
-                description = video_data.get('description')
+        if entries_data:
-                        break
+        provider_video_id = self._search_regex(
-        }
+        volume_uuid = self._search_regex(
-    _VALID_URL = r'https?://www\.udemy\.com/(?P<id>[\da-z-]+)'
+    _VALID_URL = r'https?://www\.udemy\.com/(?P<id>[^/?#&]+)'
-                        'url': 'https://www.udemy.com/%s/#/lecture/%s' % (course_path, entry['id']),
+                        'url': 'https://www.udemy.com/%s/learn/v4/t/lecture/%s' % (course_path, entry['id']),
-                'ext': 'flv',
+                'ext': 'mp4',
-            formats += self._extract_m3u8_formats(m3u8_url, video_id, 'mp4')
+        if m3u8_url and determine_ext(m3u8_url) == 'm3u8':
-                'vbr': int(video['bitrate'].rstrip('k')),
+                'format_id': 'mp4-%s' % video['bitrate'],
-            'duration': clip_info.get('duration'),
+            'duration': int_or_none(clip_info.get('duration')),
-        course_url = update_url_query(
+        response = self._download_json(
-            {
+            course_id, 'Downloading course curriculum', query={
-
+    compat_urllib_request,
-    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers=None, query=None):
+    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers={}, query={}):
-        if isinstance(url_or_request, compat_str):
+        if isinstance(url_or_request, compat_urllib_request.Request):
-                url_or_request = sanitized_Request(url_or_request, data, headers or {})
+                url_or_request = sanitized_Request(url_or_request, data, headers)
-    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers=None, query=None):
+    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers={}, query={}):
-    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None, data=None, headers=None, query=None):
+    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None, data=None, headers={}, query={}):
-                      transform_source=None, fatal=True, encoding=None, data=None, headers=None, query=None):
+                      transform_source=None, fatal=True, encoding=None, data=None, headers={}, query={}):
-                       fatal=True, encoding=None, data=None, headers=None, query=None):
+                       fatal=True, encoding=None, data=None, headers={}, query={}):
-            req = new_req
+            req = update_Request(req, url=url_escaped)
-    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata'):
+    def _download_json(self, url_or_request, *args, **kwargs):
-        response = super(UdemyIE, self)._download_json(url_or_request, video_id, note)
+        response = super(UdemyIE, self)._download_json(url_or_request, *args, **kwargs)
-            webpage, 'course id')
+        course_id, _ = self._extract_course_info(webpage, lecture_id)
-        course_title = response.get('title')
+        course_id, title = self._extract_course_info(webpage, course_path)
-            course_id, 'Downloading course curriculum')
+            course_url, course_id, 'Downloading course curriculum')
-                if asset_id:
+        chapter, chapter_number = [None] * 2
-                        'url': 'https://www.udemy.com/%s/#/lecture/%s' % (course_path, asset['id']),
+                        'url': 'https://www.udemy.com/%s/#/lecture/%s' % (course_path, entry['id']),
-                chapter = asset.get('title')
+            elif clazz == 'chapter':
-        return self.playlist_result(entries, course_id, course_title)
+        return self.playlist_result(entries, course_id, title)
-            'https://api.beeg.com/api/v5/video/%s' % video_id, video_id)
+            'https://api.beeg.com/api/v6/1738/video/%s' % video_id, video_id)
-            a = '5ShMcIQlssOd7zChAIOlmeTZDaUxULbJRnywYaiB'
+            # Reverse engineered from http://static.beeg.com/cpl/1738.js
-from .nationalgeographic import NationalGeographicIE
+from .nationalgeographic import (
-                'ext': 'flv',
+                'id': '0000014b-70a1-dd8c-af7f-f7b559330001',
-                'ext': 'flv',
+                'id': 'ngc-I0IauNSWznb_UV008GxSbwY35BZvgi2e',
-            {'force_smil_url': True}))
+        return {
-                        (\d+)/([\da-f-]+)_([^/]+)/index(?:\.min)?\.js
+                        (\d+)/([^/]+)_([^/]+)/index(?:\.min)?\.js
-        }
+            'title': 'Fighting zombies is big business',
-           (?:(?P<media>(?:(?:[^/]+/)+select/)?media/)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
+           (?:(?:(?:[^/]+/)+select/)?(?P<media>media/(?:guid/\d+/)?)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
-        path = provider_id
+        path = provider_id + '/'
-        path += '/' + video_id
+            path += mobj.group('media')
-    compat_str,
+from ..utils import (
-from ..utils import ExtractorError
+                'timestamp': 1414108751,
-                'uploader': 'Jacob Soren',
+                'uploader': 'Yumi K',
-            if not streamUrl:
+            stream_url = search_data('stream-url')
-            info = {
+            return {
-                'id': compat_str(video['mediaId']),
+            video = self._parse_json(self._search_regex(
-                'uploader_id': video['artistUsername'],
+                'description': video.get('description'),
-
+            headers = {}
-                (file_format['ext'], file_format.get('br', ''), song_id),
+                'http://antiserver.kuwo.cn/anti.s',
-            self._sort_formats(formats)
+        self._sort_formats(formats)
-    _VALID_URL = r'https?://www\.kuwo\.cn/yinyue/(?P<id>\d+?)'
+    _VALID_URL = r'https?://www\.kuwo\.cn/yinyue/(?P<id>\d+)'
-    _VALID_URL = r'https?://(?P<blog_name>.*?)\.tumblr\.com/(?:post|video)/(?P<id>[0-9]+)(?:$|[/?#])'
+    _VALID_URL = r'https?://(?P<blog_name>[^/?#&]+)\.tumblr\.com/(?:post|video)/(?P<id>[0-9]+)(?:$|[/?#])'
-            'title': video_data['title'],
+            'title': title,
-        output += """ScaledBorderAndShadow: yes
+        output += """ScaledBorderAndShadow: no
-    out = issue_template_tmpl % {'version': __version__}
+    out = issue_template_tmpl % {'version': locals()['__version__']}
-    parser = optparse.OptionParser(usage='%prog FILE')
+    parser = optparse.OptionParser(usage='%prog INFILE OUTFILE')
-        parser.error('Expected an filename')
+    if len(args) != 2:
-        issue_template_text = inf.read()
+    infile, outfile = args
-         'youtube_dl/version.py', 'exec'))
+                 'youtube_dl/version.py', 'exec'))
-    )
+    out = issue_template_tmpl % {'version': __version__}
-         outf.write(issue_template_text)
+    with io.open(outfile, 'w', encoding='utf-8') as outf:
-                    subtitle_format['url'] = sanitize_url(subtitle_format['url'])
+                    if subtitle_format.get('url'):
-                r'var\s+flashv1ars_\d+\s*=\s*({.+?});', webpage, 'flashvars', default='{}'),
+                r'var\s+flashvars_\d+\s*=\s*({.+?});', webpage, 'flashvars', default='{}'),
-                # 'upload_date': '20110503',
+                'timestamp': 1304411491,
-                # 'upload_date': '20141204',
+                'timestamp': 1417662047,
-            'timestamp': parse_iso8601(item.get('pubDate'), ' '),
+            'timestamp': timestamp,
-        'url': 'http://www.pornhub.com/users/rushandlia/videos',
+        'url': 'http://www.pornhub.com/users/zoe_ph/videos/public',
-            'id': 'rushandlia',
+            'id': 'zoe_ph',
-        'playlist_mincount': 13,
+        'playlist_mincount': 171,
-        return self.playlist_result(self._extract_entries(webpage), user_id)
+        entries = []
-                r'href="/?(view_video\.php\?.*\bviewkey=[\da-z]+[^"]*)"', webpage))
+            self.url_result(
-            for video_url in set(re.findall(
+            for video_url in orderedSet(re.findall(
-            [r'data-video-player-vpid="(%s)"' % self._ID_REGEX,
+            [r'data-(?:video-player|media)-vpid="(%s)"' % self._ID_REGEX,
-__version__ = '2016.03.26'
+__version__ = '2016.03.27'
-                            media))
+        media = remove_encrypted_media(media)
-        self._sort_formats(formats)
+        self._sort_formats(formats)
-            'formats': self._extract_m3u8_formats(
+        entries = []
-        } for idx, video_info in enumerate(info['playlist'])]
+                note='Download m3u8 information for video %d' % (idx + 1))
-        formats = []
+            self._sort_formats(formats)
-                return self._parse_smil(doc, url, video_id)
+                smil = self._parse_smil(doc, url, video_id)
-            'formats': self._extract_f4m_formats(f4m_url, video_id),
+            'formats': formats,
-        for module in course_data:
+        for num, module in enumerate(course_data, 1):
-                    'Pluralsight'))
+                entries.append({
-        videos = []
+        entries = []
-                    videos.append(video['ID'])
+                video_id = video.get('ID')
-        json_url = 'http://videoplayer.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id
+        json_url = 'http://api.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id
-            r'href=(["\'])(?P<url>https?://(?:www\.)?udemy\.com/payment/checkout/.+?)\1',
+            r'href=(["\'])(?P<url>(?:https?://(?:www\.)?udemy\.com)?/payment/checkout/.+?)\1',
-                'Use this URL to confirm purchase: %s' % (course_id, checkout_url), expected=True)
+                'Use this URL to confirm purchase: %s'
-            webpage = self._download_webpage(enroll_url, course_id, 'Enrolling in the course')
+            webpage = self._download_webpage(
-        def add_output_format_meta(f, key, format_id):
+        def add_output_format_meta(f, key):
-                return f
+            return f
-                        f = add_output_format_meta(f, format_id, '%sp' % format_id)
+                        f = add_output_format_meta(f, format_id)
-                    }, res, '%dp' % height if height else None))
+                    }, res))
-
+        def add_output_format_meta(f, key, format_id):
-                            f['format_id'] = '%sp' % format_id
+                        f = add_output_format_meta(f, format_id, '%sp' % format_id)
-                    formats.append({
+                    formats.append(add_output_format_meta({
-                    })
+                    }, res, '%dp' % height if height else None))
-                'format_id': '%sp' % (src.get('label') or format_id),
+                'format_id': '%sp' % (src.get('height') or format_id),
-        self._sort_formats(formats)
+        self._sort_formats(formats, field_preference=('height', 'width', 'tbr', 'format_id'))
-                    'fields[lecture]': 'title,description,asset',
+                    'fields[lecture]': 'title,description,view_html,asset',
-                    'instructorPreviewMode': 'False',
+        view_html = lecture.get('view_html')
-        for playlist_id in orderedSet(re.findall(r'href="/?playlist\?list=([0-9A-Za-z-_]{10,})"', content)):
+        for playlist_id in orderedSet(re.findall(
-    PostProcessingError,
+    PostProcessingError,
-    age_restricted,
+    sanitize_url,
-        'http:%s' % url if url.startswith('//') else url, *args, **kwargs)
+    return compat_urllib_request.Request(sanitize_url(url), *args, **kwargs)
-    _VALID_URL = r'https?://(?:www\.)?my\.mail\.ru/(?:video/.*#video=/?(?P<idv1>(?:[^/]+/){3}\d+)|(?:(?P<idv2prefix>(?:[^/]+/){2})video/(?P<idv2suffix>[^/]+/\d+))\.html)'
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?my\.mail\.ru/(?:video/.*#video=/?(?P<idv1>(?:[^/]+/){3}\d+)|(?:(?P<idv2prefix>(?:[^/]+/){2})video/(?P<idv2suffix>[^/]+/\d+))\.html)'
-            video_url = playlist[0]['source']
+        video_url = config.get('video_url') or config.get('playlist', [{}])[0].get('source')
-        }
+        },
-        renditions = video_info.get('renditions')
+        renditions = video_info.get('renditions', []) + video_info.get('IOSRenditions', [])
-                formats.append({
+                a_format = {
-                })
+                }
-            return None
+            return data_url_params.get(name)
-__version__ = '2016.03.25'
+__version__ = '2016.03.26'
-)
+from ..compat import compat_str
-    int_or_none,
+    ExtractorError,
-            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, urlencode_postdata(login_form))
-)
+from ..compat import compat_str
-    int_or_none,
+    int_or_none,
-            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, urlencode_postdata(login_form))
-    compat_urllib_parse_urlencode,
+    urlencode_postdata,
-            data=compat_urllib_parse_urlencode(data))
+            data=urlencode_postdata(data))
-        playerdata_req.data = compat_urllib_parse_urlencode({'current_page': webpage_url})
+        playerdata_req.data = urlencode_postdata({'current_page': webpage_url})
-            compat_urllib_parse_urlencode(data),
+            urlencode_postdata(data),
-    compat_urllib_parse_urlencode,
+    urlencode_postdata
-            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, urlencode_postdata(login_form))
-    compat_urllib_parse_urlencode,
+    urlencode_postdata,
-        login_data = compat_urllib_parse_urlencode(login_form_strs).encode('utf-8')
+        login_data = urlencode_postdata(login_form_strs)
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-        request = sanitized_Request(login_url, compat_urllib_parse_urlencode(login_form))
+        request = sanitized_Request(login_url, urlencode_postdata(login_form))
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-        reqdata = compat_urllib_parse_urlencode([
+        reqdata = urlencode_postdata([
-)
+from ..compat import compat_str
-            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, urlencode_postdata(login_form))
-                    self._LOGIN_URL, compat_urllib_parse_urlencode(confirm_form).encode('utf-8'))
+                    self._LOGIN_URL, urlencode_postdata(confirm_form))
-    compat_urllib_parse_urlencode,
+    urlencode_postdata,
-        request = sanitized_Request(self._FILTER_POST, compat_urllib_parse_urlencode(disclaimer_form))
+        request = sanitized_Request(self._FILTER_POST, urlencode_postdata(disclaimer_form))
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-            data=compat_urllib_parse_urlencode(token_data))
+            data=urlencode_postdata(token_data))
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-        post = compat_urllib_parse_urlencode({'r': r_json})
+        post = urlencode_postdata({'r': r_json})
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-            post = compat_urllib_parse_urlencode(data)
+            post = urlencode_postdata(data)
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-            'http://mooshare.biz/%s' % video_id, compat_urllib_parse_urlencode(download_form))
+            'http://mooshare.biz/%s' % video_id, urlencode_postdata(download_form))
-from ..utils import sanitized_Request
+from ..utils import (
-            compat_urllib_parse_urlencode({'getConfig': 'true'}).encode('ascii'))
+            urlencode_postdata({'getConfig': 'true'}))
-        login_data = compat_urllib_parse_urlencode(login_form_strs).encode('utf-8')
+        login_data = urlencode_postdata(login_form_strs)
-    compat_urllib_parse_urlencode,
+    urlencode_postdata,
-        request = sanitized_Request(self._LOGIN_URL, compat_urllib_parse_urlencode(login_form))
+        request = sanitized_Request(self._LOGIN_URL, urlencode_postdata(login_form))
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-        post = compat_urllib_parse_urlencode(data)
+        post = urlencode_postdata(data)
-    compat_urllib_parse_urlencode,
+    urlencode_postdata,
-            post_url, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
+            post_url, urlencode_postdata(login_form))
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-            url, compat_urllib_parse_urlencode(fields), headers)
+            url, urlencode_postdata(fields), headers)
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-        post = compat_urllib_parse_urlencode(fields)
+        post = urlencode_postdata(fields)
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-            url, compat_urllib_parse_urlencode(download_form))
+            url, urlencode_postdata(download_form))
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-        post = compat_urllib_parse_urlencode(fields)
+        post = urlencode_postdata(fields)
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-            'http://smotri.com/video/view/url/bot/', compat_urllib_parse_urlencode(video_form))
+            'http://smotri.com/video/view/url/bot/', urlencode_postdata(video_form))
-                broadcast_url + '/?no_redirect=1', compat_urllib_parse_urlencode(login_form))
+                broadcast_url + '/?no_redirect=1', urlencode_postdata(login_form))
-from ..utils import sanitized_Request
+from ..utils import (
-        post = compat_urllib_parse_urlencode(fields)
+        post = urlencode_postdata(fields)
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-        payload = compat_urllib_parse_urlencode(form_data).encode('utf-8')
+        payload = urlencode_postdata(form_data)
-            post_url, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
+            post_url, urlencode_postdata(login_form))
-            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, urlencode_postdata(login_form))
-)
+from ..compat import compat_urlparse
-        data = compat_urllib_parse_urlencode({'as3': '1', 'vid': video_id})
+        data = urlencode_postdata({'as3': '1', 'vid': video_id})
-)
+from ..compat import compat_str
-            compat_urllib_parse_urlencode(login_form).encode('utf-8'))
+            urlencode_postdata(login_form))
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-            post = compat_urllib_parse_urlencode(fields)
+            post = urlencode_postdata(fields)
-from ..compat import compat_urllib_parse_urlencode
+    urlencode_postdata,
-            post = compat_urllib_parse_urlencode(fields)
+            post = urlencode_postdata(fields)
-)
+from ..compat import compat_str
-                compat_urllib_parse_urlencode({
+                urlencode_postdata({
-                }).encode('utf-8'))
+                }))
-        login_data = compat_urllib_parse_urlencode(login_form_strs).encode('ascii')
+        login_data = urlencode_postdata(login_form_strs)
-            tfa_data = compat_urllib_parse_urlencode(tfa_form_strs).encode('ascii')
+            tfa_data = urlencode_postdata(tfa_form_strs)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-                compat_urllib_parse.urlencode({
+                compat_urllib_parse_urlencode({
-            post_url, urlencode_postdata(encode_dict(login_form)))
+            post_url, urlencode_postdata(login_form))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        parsed_url[4] = compat_urllib_parse.urlencode(query)
+        parsed_url[4] = compat_urllib_parse_urlencode(query)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            data=compat_urllib_parse.urlencode(data))
+            data=compat_urllib_parse_urlencode(data))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        data_url = self._API_URL % (video_host, compat_urllib_parse.urlencode(form))
+        data_url = self._API_URL % (video_host, compat_urllib_parse_urlencode(form))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        index_url = 'http://%s.cc.com/feeds/mrss?%s' % (show_name, compat_urllib_parse.urlencode({'uri': uri}))
+        index_url = 'http://%s.cc.com/feeds/mrss?%s' % (show_name, compat_urllib_parse_urlencode({'uri': uri}))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-                f4m_url += compat_urllib_parse.urlencode(f4m_params)
+                f4m_url += compat_urllib_parse_urlencode(f4m_params)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        data = compat_urllib_parse.urlencode({'videoId': video_id,
+        data = compat_urllib_parse_urlencode({'videoId': video_id,
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            parsed_url._replace(query=compat_urllib_parse.urlencode(qs, True)))
+            parsed_url._replace(query=compat_urllib_parse_urlencode(qs, True)))
-        playerdata_req.data = compat_urllib_parse.urlencode({'current_page': webpage_url})
+        playerdata_req.data = compat_urllib_parse_urlencode({'current_page': webpage_url})
-                compat_urllib_parse.urlencode({'current_page': url}).encode('utf-8'))
+                compat_urllib_parse_urlencode({'current_page': url}).encode('utf-8'))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        query = compat_urllib_parse.urlencode({'vid': video_id})
+        query = compat_urllib_parse_urlencode({'vid': video_id})
-            format_query = compat_urllib_parse.urlencode({
+            format_query = compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            compat_urllib_parse.urlencode({
+            compat_urllib_parse_urlencode({
-            compat_urllib_parse.urlencode({
+            compat_urllib_parse_urlencode({
-            compat_urllib_parse.urlencode(data),
+            compat_urllib_parse_urlencode(data),
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        query = compat_urllib_parse.urlencode({
+        query = compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('utf-8')
+        login_data = compat_urllib_parse_urlencode(login_form_strs).encode('utf-8')
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            compat_urllib_parse.urlencode({
+            compat_urllib_parse_urlencode({
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        data = self._download_json(self._API_BASE_URL + compat_urllib_parse.urlencode(query), video_id, note)
+        data = self._download_json(self._API_BASE_URL + compat_urllib_parse_urlencode(query), video_id, note)
-        data = urlencode_postdata(encode_dict({
+        data = urlencode_postdata({
-        }))
+        })
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        request = sanitized_Request(login_url, compat_urllib_parse.urlencode(login_form))
+        request = sanitized_Request(login_url, compat_urllib_parse_urlencode(login_form))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        reqdata = compat_urllib_parse.urlencode([
+        reqdata = compat_urllib_parse_urlencode([
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        request = sanitized_Request(url + '?' + compat_urllib_parse.urlencode(data))
+        request = sanitized_Request(url + '?' + compat_urllib_parse_urlencode(data))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        return compat_urllib_parse.urlencode(cleaned_dic)
+        return compat_urllib_parse_urlencode(cleaned_dic)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            'http://kylin.iqiyi.com/validate?' + compat_urllib_parse.urlencode(validation_params), None,
+            'http://kylin.iqiyi.com/validate?' + compat_urllib_parse_urlencode(validation_params), None,
-                api_video_url += compat_urllib_parse.urlencode(param)
+                api_video_url += compat_urllib_parse_urlencode(param)
-            compat_urllib_parse.urlencode(param)
+            compat_urllib_parse_urlencode(param)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            'url': 'https://streaming.ivideon.com/flv/live?%s' % compat_urllib_parse.urlencode({
+            'url': 'https://streaming.ivideon.com/flv/live?%s' % compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        query = compat_urllib_parse.urlencode(params)
+        query = compat_urllib_parse_urlencode(params)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            % compat_urllib_parse.urlencode({
+            % compat_urllib_parse_urlencode({
-            compat_urllib_parse.urlencode({
+            compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            'http://api.le.com/mms/out/video/playJson?' + compat_urllib_parse.urlencode(params)
+            'http://api.le.com/mms/out/video/playJson?' + compat_urllib_parse_urlencode(params)
-                media_url += '&' + compat_urllib_parse.urlencode({
+                media_url += '&' + compat_urllib_parse_urlencode({
-                'http://api.letvcloud.com/gpc.php?' + compat_urllib_parse.urlencode(data),
+                'http://api.letvcloud.com/gpc.php?' + compat_urllib_parse_urlencode(data),
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
-                    self._LOGIN_URL, compat_urllib_parse.urlencode(confirm_form).encode('utf-8'))
+                    self._LOGIN_URL, compat_urllib_parse_urlencode(confirm_form).encode('utf-8'))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            'http://player.matchtv.ntvplus.tv/player/smil?%s' % compat_urllib_parse.urlencode({
+            'http://player.matchtv.ntvplus.tv/player/smil?%s' % compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        request = sanitized_Request(self._FILTER_POST, compat_urllib_parse.urlencode(disclaimer_form))
+        request = sanitized_Request(self._FILTER_POST, compat_urllib_parse_urlencode(disclaimer_form))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            data=compat_urllib_parse.urlencode(token_data))
+            data=compat_urllib_parse_urlencode(token_data))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-                '%s/?%s' % (gat, compat_urllib_parse.urlencode(encode_dict(token_data))),
+                '%s/?%s' % (gat, compat_urllib_parse_urlencode(token_data)),
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        post = compat_urllib_parse.urlencode({'r': r_json})
+        post = compat_urllib_parse_urlencode({'r': r_json})
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            post = compat_urllib_parse.urlencode(data)
+            post = compat_urllib_parse_urlencode(data)
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            'http://mooshare.biz/%s' % video_id, compat_urllib_parse.urlencode(download_form))
+            'http://mooshare.biz/%s' % video_id, compat_urllib_parse_urlencode(download_form))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        return compat_urllib_parse.urlencode(data)
+        return compat_urllib_parse_urlencode(data)
-)
+from ..compat import compat_urllib_parse_urlencode
-        info_data = compat_urllib_parse.urlencode({
+        info_data = compat_urllib_parse_urlencode({
-        data = compat_urllib_parse.urlencode({
+        data = compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        xmldata_url = '%s?%s' % (encxml, compat_urllib_parse.urlencode(params))
+        xmldata_url = '%s?%s' % (encxml, compat_urllib_parse_urlencode(params))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        query_urls = compat_urllib_parse.urlencode({
+        query = compat_urllib_parse_urlencode({'vid': vid, 'inKey': key, })
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        search_url = 'http://searchapp2.nba.com/nba-search/query.jsp?' + compat_urllib_parse.urlencode({
+        search_url = 'http://searchapp2.nba.com/nba-search/query.jsp?' + compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            'song/detail?' + compat_urllib_parse.urlencode(params),
+            'song/detail?' + compat_urllib_parse_urlencode(params),
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        return compat_urllib_parse.urlencode({
+        return compat_urllib_parse_urlencode({
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            compat_urllib_parse.urlencode({'getConfig': 'true'}).encode('ascii'))
+            compat_urllib_parse_urlencode({'getConfig': 'true'}).encode('ascii'))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            data = compat_urllib_parse.urlencode({
+            data = compat_urllib_parse_urlencode({
-        data = compat_urllib_parse.urlencode({
+        data = compat_urllib_parse_urlencode({
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        return compat_urllib_parse.urlencode({
+        return compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('utf-8')
+        login_data = compat_urllib_parse_urlencode(login_form_strs).encode('utf-8')
-            flv_info_data = compat_urllib_parse.urlencode({
+            flv_info_data = compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        request = sanitized_Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
+        request = sanitized_Request(self._LOGIN_URL, compat_urllib_parse_urlencode(login_form))
-                post_url, urlencode_postdata(encode_dict(fields)))
+                post_url, urlencode_postdata(fields))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            'http://api.npr.org/query?%s' % compat_urllib_parse.urlencode({
+            'http://api.npr.org/query?%s' % compat_urllib_parse_urlencode({
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-                compat_urllib_parse.urlencode({
+                compat_urllib_parse_urlencode({
-            compat_urllib_parse.urlencode(login_form).encode('utf-8')
+            compat_urllib_parse_urlencode(login_form).encode('utf-8')
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        post = compat_urllib_parse.urlencode(data)
+        post = compat_urllib_parse_urlencode(data)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            parsed_url._replace(query=compat_urllib_parse.urlencode(qs, True)))
+            parsed_url._replace(query=compat_urllib_parse_urlencode(qs, True)))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            post_url, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            post_url, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        url_params = compat_urllib_parse.urlencode({
+        url_params = compat_urllib_parse_urlencode({
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            url, compat_urllib_parse.urlencode(fields), headers)
+            url, compat_urllib_parse_urlencode(fields), headers)
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        post = compat_urllib_parse.urlencode(fields)
+        post = compat_urllib_parse_urlencode(fields)
-)
+from ..compat import compat_urllib_parse_urlencode
-        videos_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos?%s' % compat_urllib_parse.urlencode({
+        videos_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos?%s' % compat_urllib_parse_urlencode({
-        sources_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources?%s' % (clip_id, compat_urllib_parse.urlencode({
+        sources_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources?%s' % (clip_id, compat_urllib_parse_urlencode({
-        url_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources/url?%s' % (clip_id, compat_urllib_parse.urlencode({
+        url_api_url = 'http://vas.sim-technik.de/vas/live/v2/videos/%s/sources/url?%s' % (clip_id, compat_urllib_parse_urlencode({
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-                compat_urllib_parse.urlencode({
+                compat_urllib_parse_urlencode({
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            url, compat_urllib_parse.urlencode(download_form))
+            url, compat_urllib_parse_urlencode(download_form))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        post = compat_urllib_parse.urlencode(fields)
+        post = compat_urllib_parse_urlencode(fields)
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        data = compat_urllib_parse.urlencode({'vid': video_id})
+        data = compat_urllib_parse_urlencode({'vid': video_id})
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            'http://smotri.com/video/view/url/bot/', compat_urllib_parse.urlencode(video_form))
+            'http://smotri.com/video/view/url/bot/', compat_urllib_parse_urlencode(video_form))
-                broadcast_url + '/?no_redirect=1', compat_urllib_parse.urlencode(login_form))
+                broadcast_url + '/?no_redirect=1', compat_urllib_parse_urlencode(login_form))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-                        'http://%s/?%s' % (allot, compat_urllib_parse.urlencode(params)),
+                        'http://%s/?%s' % (allot, compat_urllib_parse_urlencode(params)),
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        next_href = base_url + '?' + compat_urllib_parse.urlencode(query)
+        next_href = base_url + '?' + compat_urllib_parse_urlencode(query)
-                parsed_next_href._replace(query=compat_urllib_parse.urlencode(qs, True)))
+                parsed_next_href._replace(query=compat_urllib_parse_urlencode(qs, True)))
-        data = compat_urllib_parse.urlencode(data_dict)
+        data = compat_urllib_parse_urlencode(data_dict)
-        data = compat_urllib_parse.urlencode(encode_dict(query))
+        data = compat_urllib_parse_urlencode(query)
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        post = compat_urllib_parse.urlencode(fields)
+        post = compat_urllib_parse_urlencode(fields)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        token_query = compat_urllib_parse.urlencode({'id': video_link})
+        token_query = compat_urllib_parse_urlencode({'id': video_link})
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-        payload = compat_urllib_parse.urlencode(form_data).encode('utf-8')
+        payload = compat_urllib_parse_urlencode(form_data).encode('utf-8')
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            post_url, compat_urllib_parse.urlencode(encode_dict(login_form)).encode('utf-8'))
+            post_url, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
-                compat_urllib_parse.urlencode({
+                compat_urllib_parse_urlencode({
-            % (self._USHER_BASE, channel_id, compat_urllib_parse.urlencode(query)),
+            % (self._USHER_BASE, channel_id, compat_urllib_parse_urlencode(query)),
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-                course_id, lecture_id, compat_urllib_parse.urlencode({
+                course_id, lecture_id, compat_urllib_parse_urlencode({
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            self._LOGIN_URL, compat_urllib_parse_urlencode(login_form).encode('utf-8'))
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        data = compat_urllib_parse.urlencode({'as3': '1', 'vid': video_id})
+        data = compat_urllib_parse_urlencode({'as3': '1', 'vid': video_id})
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            % compat_urllib_parse.urlencode(query), None, headers)
+            % compat_urllib_parse_urlencode(query), None, headers)
-        data = urlencode_postdata(encode_dict({
+        data = urlencode_postdata({
-        }))
+        })
-        data = urlencode_postdata(encode_dict({
+        data = urlencode_postdata({
-        }))
+        })
-        data = urlencode_postdata(encode_dict({'password': password}))
+        data = urlencode_postdata({'password': password})
-        post = urlencode_postdata(encode_dict(fields))
+        post = urlencode_postdata(fields)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-            compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            compat_urllib_parse_urlencode(login_form).encode('utf-8'))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            % compat_urllib_parse.urlencode({
+            % compat_urllib_parse_urlencode({
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            post = compat_urllib_parse.urlencode(fields)
+            post = compat_urllib_parse_urlencode(fields)
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_urlencode
-            post = compat_urllib_parse.urlencode(encode_dict(fields))
+            post = compat_urllib_parse_urlencode(fields)
-        data = compat_urllib_parse.urlencode({
+        data = compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-                compat_urllib_parse.urlencode({
+                compat_urllib_parse_urlencode({
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-                    compat_urllib_parse.urlencode(param)
+                    compat_urllib_parse_urlencode(param)
-    compat_urllib_parse,
+    compat_urllib_parse_urlencode,
-        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('ascii')
+        login_data = compat_urllib_parse_urlencode(login_form_strs).encode('ascii')
-            tfa_data = compat_urllib_parse.urlencode(encode_dict(tfa_form_strs)).encode('ascii')
+            tfa_data = compat_urllib_parse_urlencode(tfa_form_strs).encode('ascii')
-                params = compat_urllib_parse.urlencode({
+                params = compat_urllib_parse_urlencode({
-                list_params = compat_urllib_parse.urlencode({
+                list_params = compat_urllib_parse_urlencode({
-                        params = compat_urllib_parse.urlencode({
+                        params = compat_urllib_parse_urlencode({
-            parsed_caption_url = compat_urlparse.urlparse(caption_url)
+            parsed_caption_url = compat_urllib_parse_urlparse(caption_url)
-                        query=compat_urllib_parse.urlencode(caption_qs, True)))
+                        query=compat_urllib_parse_urlencode(caption_qs, True)))
-            parsed_playback_url._replace(query=compat_urllib_parse.urlencode(qs, True)))
+            parsed_playback_url._replace(query=compat_urllib_parse_urlencode(qs, True)))
-            data = compat_urllib_parse.urlencode({
+            data = compat_urllib_parse_urlencode({
-            result_url = 'https://www.youtube.com/results?' + compat_urllib_parse.urlencode(url_query)
+            result_url = 'https://www.youtube.com/results?' + compat_urllib_parse_urlencode(url_query)
-    sdata = compat_urllib_parse.urlencode(
+    sdata = compat_urllib_parse_urlencode(
-    return compat_urllib_parse.urlencode(*args, **kargs).encode('ascii')
+    return compat_urllib_parse_urlencode(*args, **kargs).encode('ascii')
-    return dict((encode(k), encode(v)) for k, v in d.items())
+        query=compat_urllib_parse_urlencode(qs, True)))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urlparse
-        player_url = compat_urllib_parse.urljoin(
+
-        info = self._parse_json(self._search_regex(r'(?m)var\s+video\s+=\s+({.+?});$', player, 'info json'), display_id)
+        player = self._download_webpage(player_url, display_id)
-        qualities_order = qualities(['low', 'high'])
+        qualities_order = qualities(('low', 'high'))
-    _VALID_URL = r'https?://once\.unicornmedia\.com/now/[^/]+/[^/]+/(?P<domain_id>[^/]+)/(?P<application_id>[^/]+)/(?:[^/]+/)?(?P<media_item_id>[^/]+)/content\.(?:once|m3u8|mp4)'
+    _VALID_URL = r'https?://.+?\.unicornmedia\.com/now/[^/]+/[^/]+/(?P<domain_id>[^/]+)/(?P<application_id>[^/]+)/(?:[^/]+/)?(?P<media_item_id>[^/]+)/content\.(?:once|m3u8|mp4)'
-__version__ = '2016.03.18'
+__version__ = '2016.03.25'
-        enc_key = '8ed797d224d043e7ac23d95b70227d32'
+        enc_key = '4a1caba4b4465345366f28da7c117d20'
-    _VALID_URL = r'https?://(?:www\.)?douyutv\.com/(?P<id>[A-Za-z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?douyu(?:tv)?\.com/(?P<id>[A-Za-z0-9]+)'
-            'only_matching': True,
+    _TESTS = [{
-            'only_matching': True,
+        'params': {
-    ]
+    }, {
-        info = info['data']['info']
+
-        file_url = rtmp_info['serverurl'] + rtmp_info['fileurl']
+
-        ]
+        thumbnails = [{
-            'ext': 'flv',
+            'formats': formats,
-    _VALID_URL = r'https?://www\.udemy\.com/(?:[^#]+#/lecture/|lecture/view/?\?lectureId=)(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-                'height': int_or_none(format_id),
+
-            formats.append(f)
+
-    def _enroll_course(self, webpage, course_id):
+    def _enroll_course(self, base_url, webpage, course_id):
-            r'href=(["\'])(?P<url>https?://(?:www\.)?udemy\.com/course/subscribe/.+?)\1',
+            r'href=(["\'])(?P<url>(?:https?://(?:www\.)?udemy\.com)?/course/subscribe/.+?)\1',
-                self._enroll_course(webpage, course_id)
+                self._enroll_course(url, webpage, course_id)
-        self._enroll_course(webpage, course_id)
+        self._enroll_course(url, webpage, course_id)
-        return False if YoutubePlaylistsIE.suitable(url) else super(YoutubeChannelIE, cls).suitable(url)
+        return (False if YoutubePlaylistsIE.suitable(url) or YoutubeLiveIE.suitable(url)
-        timestamp = parse_iso8601(video_data['publication_date'][:-8])
+        uploader = video_data.get('byline')
-            } for video in video_data['renditions']
+            } for video in video_data['renditions'] if video.get('url')
-            } for image in video_data['images']
+            } for image in video_data.get('images', []) if image.get('url')
-# -*- coding: utf-8 -*-
+# coding: utf-8
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        m3u8_url = self._search_regex(r"'src': '([^']+\.m3u8)'", playerpage, 'm3u8 url')
+        formats = []
-        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')
+        def extract_formats(format_url, format_key=None, lang=None):
-            description = None
+        description = xpath_text(itemdoc, 'description')
-    # In Python 2.6 (and some 2.7 versions), struct requires a bytes argument
+    # In Python 2.6 and 2.7.x < 2.7.7, struct requires a bytes argument
-            'http://ÑÐµÑÑ.ÑÑ/%D0%B0%D0%B1%D0%B2?%D0%B0%D0%B1%D0%B2=%D0%B0%D0%B1%D0%B2#%D0%B0%D0%B1%D0%B2'
+            'http://xn--e1aybc.xn--p1ai/%D0%B0%D0%B1%D0%B2?%D0%B0%D0%B1%D0%B2=%D0%B0%D0%B1%D0%B2#%D0%B0%D0%B1%D0%B2'
-            'http://ÑÐµÑÑ.ÑÑ/%D1%84%D1%80%D0%B0%D0%B3%D0%BC%D0%B5%D0%BD%D1%82'
+            'http://xn--e1aybc.xn--p1ai/%D1%84%D1%80%D0%B0%D0%B3%D0%BC%D0%B5%D0%BD%D1%82'
-import json
+import re
-            r'\((.*)\);', stream_data, 'stream info'))['Streams']
+        streams = self._download_json(
-    _VALID_URL = r'https?://(?:www\.)?laola1\.tv/(?P<lang>[a-z]+)-(?P<portal>[a-z]+)/[^/]+/(?P<slug>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?laola1\.tv/(?P<lang>[a-z]+)-(?P<portal>[a-z]+)/(?P<kind>[^/]+)/(?P<slug>[^/?#&]+)'
-        }
+        },
-        }
+        },
-                'label': 'laola1tv',
+                'target': VS_TARGETS.get(kind, '2'),
-                    stream_url, playlist_id, 'mp4', entry_protocol='m3u8_native'))
+                    stream_url, playlist_id, 'mp4',
-                entries.append(f)
+            # Extract teaser only when full episode is not available
-                        format_id_list.append('hls')
+                        format_id_list.append(compat_str(num))
-                    playlist = playlist[0]
+                    playlist = playlist[start_video]
-                            m3u8_formats = self._extract_m3u8_formats(
+                        if not file_:
-                            formats.extend(m3u8_formats)
+                                entry_protocol='m3u8_native', m3u8_id=format_id, fatal=False)
-            webpage, 'xhamster url')
+            webpage, 'xhamster url', default=None)
-            (?P<path>flash2v/container\.swf\?id=
+            (?P<path>flash\d+v/container\.swf\?id=
-            r'<meta[^>]+?property=(["\'])og:video\1[^>]+?content=(["\'])(?P<url>https?://player\.(?:rutv\.ru|vgtrk\.com)/flash2v/container\.swf\?id=.+?\2)',
+            r'<meta[^>]+?property=(["\'])og:video\1[^>]+?content=(["\'])(?P<url>https?://player\.(?:rutv\.ru|vgtrk\.com)/flash\d+v/container\.swf\?id=.+?\2)',
-        if video_path.startswith('flash2v'):
+        if re.match(r'flash\d+v', video_path):
-                        'player_url': 'http://player.rutv.ru/flash2v/osmf.swf?i=22',
+                        'player_url': 'http://player.rutv.ru/flash3v/osmf.swf?i=22',
-    _VALID_URL = r'http://www\.abc\.net\.au/news/(?:[^/]+/){1,2}(?P<id>\d+)'
+    _VALID_URL = r'https?://www\.abc\.net\.au/news/(?:[^/]+/){1,2}(?P<id>\d+)'
-    _VALID_URL = r'http://(?:\w+\.)?add-anime\.net/(?:watch_video\.php\?(?:.*?)v=|video/)(?P<id>[\w_]+)'
+    _VALID_URL = r'https?://(?:\w+\.)?add-anime\.net/(?:watch_video\.php\?(?:.*?)v=|video/)(?P<id>[\w_]+)'
-    _VALID_URL = r'http://tv\.aftonbladet\.se/abtv/articles/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://tv\.aftonbladet\.se/abtv/articles/(?P<id>[0-9]+)'
-    _VALID_URL = r'http://www\.aljazeera\.com/programmes/.*?/(?P<id>[^/]+)\.html'
+    _VALID_URL = r'https?://www\.aljazeera\.com/programmes/.*?/(?P<id>[^/]+)\.html'
-    _VALID_URL = r'(?:aol-video:|http://on\.aol\.com/video/.*-)(?P<id>[0-9]+)(?:$|\?)'
+    _VALID_URL = r'(?:aol-video:|https?://on\.aol\.com/video/.*-)(?P<id>[0-9]+)(?:$|\?)'
-    _VALID_URL = r'http://features\.aol\.com/video/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://features\.aol\.com/video/(?P<id>[^/?#]+)'
-    _VALID_URL = r'http://videos\.arte\.tv/(?P<lang>fr|de|en|es)/.*-(?P<id>.*?)\.html'
+    _VALID_URL = r'https?://videos\.arte\.tv/(?P<lang>fr|de|en|es)/.*-(?P<id>.*?)\.html'
-    _VALID_URL = r'http://www.azubu.tv/(?P<id>[^/]+)$'
+    _VALID_URL = r'https?://www.azubu.tv/(?P<id>[^/]+)$'
-    _VALID_URL = r'http://v\.baidu\.com/(?P<type>[a-z]+)/(?P<id>\d+)\.htm'
+    _VALID_URL = r'https?://v\.baidu\.com/(?P<type>[a-z]+)/(?P<id>\d+)\.htm'
-    _VALID_URL = r'http://www.bbc.co.uk/programmes/articles/(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'https?://www.bbc.co.uk/programmes/articles/(?P<id>[a-zA-Z0-9]+)'
-    _VALID_URL = r'http://(?:www\.)?behindkink\.com/(?P<year>[0-9]{4})/(?P<month>[0-9]{2})/(?P<day>[0-9]{2})/(?P<id>[^/#?_]+)'
+    _VALID_URL = r'https?://(?:www\.)?behindkink\.com/(?P<year>[0-9]{4})/(?P<month>[0-9]{2})/(?P<day>[0-9]{2})/(?P<id>[^/#?_]+)'
-    _VALID_URL = r'http://www\.bilibili\.(?:tv|com)/video/av(?P<id>\d+)(?:/index_(?P<page_num>\d+).html)?'
+    _VALID_URL = r'https?://www\.bilibili\.(?:tv|com)/video/av(?P<id>\d+)(?:/index_(?P<page_num>\d+).html)?'
-    _VALID_URL = r'http://union\.bokecc\.com/playvideo\.bo\?(?P<query>.*)'
+    _VALID_URL = r'https?://union\.bokecc\.com/playvideo\.bo\?(?P<query>.*)'
-    _VALID_URL = r'http://www\.bpb\.de/mediathek/(?P<id>[0-9]+)/'
+    _VALID_URL = r'https?://www\.bpb\.de/mediathek/(?P<id>[0-9]+)/'
-    _VALID_URL = r'http://(?:www\.)?break\.com/video/(?:[^/]+/)*.+-(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?break\.com/video/(?:[^/]+/)*.+-(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?camdemy\.com/media/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?camdemy\.com/media/(?P<id>\d+)'
-    _VALID_URL = r'http://www.camdemy.com/folder/(?P<id>\d+)'
+    _VALID_URL = r'https?://www.camdemy.com/folder/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?cbsnews\.com/(?:news|videos)/(?P<id>[\da-z_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?cbsnews\.com/(?:news|videos)/(?P<id>[\da-z_-]+)'
-    _VALID_URL = r'http://(?:www\.)?cbsnews\.com/live/video/(?P<id>[\da-z_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?cbsnews\.com/live/video/(?P<id>[\da-z_-]+)'
-    _VALID_URL = r'http://www\.cbssports\.com/video/player/(?P<section>[^/]+)/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://www\.cbssports\.com/video/player/(?P<section>[^/]+)/(?P<id>[^/]+)'
-    _VALID_URL = r'''(?x)http://(?:www\.)?cliphunter\.com/w/
+    _VALID_URL = r'''(?x)https?://(?:www\.)?cliphunter\.com/w/
-    _VALID_URL = r'http://(?:chic|www)\.clipsyndicate\.com/video/play(list/\d+)?/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:chic|www)\.clipsyndicate\.com/video/play(list/\d+)?/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?clubic\.com/video/(?:[^/]+/)*video.*-(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?clubic\.com/video/(?:[^/]+/)*video.*-(?P<id>[0-9]+)\.html'
-    _VALID_URL = r'http://(?:www\.)?comediansincarsgettingcoffee\.com/(?P<id>[a-z0-9\-]*)'
+    _VALID_URL = r'https?://(?:www\.)?comediansincarsgettingcoffee\.com/(?P<id>[a-z0-9\-]*)'
-    _VALID_URL = r'http://(?:video|www|player)\.(?P<site>%s)\.com/(?P<type>watch|series|video|embed(?:js)?)/(?P<id>[^/?#]+)' % '|'.join(_SITES.keys())
+    _VALID_URL = r'https?://(?:video|www|player)\.(?P<site>%s)\.com/(?P<type>watch|series|video|embed(?:js)?)/(?P<id>[^/?#]+)' % '|'.join(_SITES.keys())
-    _VALID_URL = r'http://(?:www\.)?c-span\.org/video/\?(?P<id>[0-9a-f]+)'
+    _VALID_URL = r'https?://(?:www\.)?c-span\.org/video/\?(?P<id>[0-9a-f]+)'
-    _VALID_URL = r'http://news\.cts\.com\.tw/[a-z]+/[a-z]+/\d+/(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://news\.cts\.com\.tw/[a-z]+/[a-z]+/\d+/(?P<id>\d+)\.html'
-    _VALID_URL = r'http://www.dctp.tv/(#/)?filme/(?P<id>.+?)/$'
+    _VALID_URL = r'https?://www.dctp.tv/(#/)?filme/(?P<id>.+?)/$'
-    _VALID_URL = r'http://.*?\.defense\.gouv\.fr/layout/set/ligthboxvideo/base-de-medias/webtv/(?P<id>[^/?#]*)'
+    _VALID_URL = r'https?://.*?\.defense\.gouv\.fr/layout/set/ligthboxvideo/base-de-medias/webtv/(?P<id>[^/?#]*)'
-    _VALID_URL = r'http://(?:www\.)?douyutv\.com/(?P<id>[A-Za-z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?douyutv\.com/(?P<id>[A-Za-z0-9]+)'
-    _VALID_URL = r'http://(?P<domain>it\.dplay\.com|www\.dplay\.(?:dk|se|no))/[^/]+/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?P<domain>it\.dplay\.com|www\.dplay\.(?:dk|se|no))/[^/]+/(?P<id>[^/?#]+)'
-    _VALID_URL = r'(?:http://)?(?:www\.)?3sat\.de/mediathek/(?:index\.php|mediathek\.php)?\?(?:(?:mode|display)=[^&]+&)*obj=(?P<id>[0-9]+)$'
+    _VALID_URL = r'(?:https?://)?(?:www\.)?3sat\.de/mediathek/(?:index\.php|mediathek\.php)?\?(?:(?:mode|display)=[^&]+&)*obj=(?P<id>[0-9]+)$'
-    _VALID_URL = r'http://video\.aktualne\.cz/(?:[^/]+/)+r~(?P<id>[0-9a-f]{32})'
+    _VALID_URL = r'https?://video\.aktualne\.cz/(?:[^/]+/)+r~(?P<id>[0-9a-f]{32})'
-    _VALID_URL = r'http://(?:www\.)?echo\.msk\.ru/sounds/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?echo\.msk\.ru/sounds/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?ex\.fm/song/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?ex\.fm/song/(?P<id>[^/]+)'
-    _VALID_URL = r'^http://video\.fc2\.com/(?:[^/]+/)*content/(?P<id>[^/]+)'
+    _VALID_URL = r'^https?://video\.fc2\.com/(?:[^/]+/)*content/(?P<id>[^/]+)'
-    _VALID_URL = r'http://(?:www\.)?firstpost\.com/[^/]+/.*-(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?firstpost\.com/[^/]+/.*-(?P<id>[0-9]+)\.html'
-    _VALID_URL = r'http://(?:www\.)?1tv\.ru/(?:[^/]+/)+(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?1tv\.ru/(?:[^/]+/)+(?P<id>.+)'
-    _VALID_URL = r'http://(?:www\.)?fernsehkritik\.tv/folge-(?P<id>[0-9]+)(?:/.*)?'
+    _VALID_URL = r'https?://(?:www\.)?fernsehkritik\.tv/folge-(?P<id>[0-9]+)(?:/.*)?'
-    _VALID_URL = r'http://footyroom\.com/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://footyroom\.com/(?P<id>[^/]+)'
-    _VALID_URL = r'http://(?:www\.)?foxgay\.com/videos/(?:\S+-)?(?P<id>\d+)\.shtml'
+    _VALID_URL = r'https?://(?:www\.)?foxgay\.com/videos/(?:\S+-)?(?P<id>\d+)\.shtml'
-    _VALID_URL = r'http://(?:www\.)?franceinter\.fr/player/reecouter\?play=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?franceinter\.fr/player/reecouter\?play=(?P<id>[0-9]+)'
-    _VALID_URL = r'^http://www.freevideo.cz/vase-videa/(?P<id>[^.]+)\.html(?:$|[?#])'
+    _VALID_URL = r'^https?://www.freevideo.cz/vase-videa/(?P<id>[^.]+)\.html(?:$|[?#])'
-    _VALID_URL = r'http://www\.gamekings\.nl/(?:videos|nieuws)/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://www\.gamekings\.nl/(?:videos|nieuws)/(?P<id>[^/]+)'
-    _VALID_URL = r'http://(?:www\.)?gamespot\.com/.*-(?P<id>\d+)/?'
+    _VALID_URL = r'https?://(?:www\.)?gamespot\.com/.*-(?P<id>\d+)/?'
-    _VALID_URL = r'http://www\.gamestar\.de/videos/.*,(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'https?://www\.gamestar\.de/videos/.*,(?P<id>[0-9]+)\.html'
-    _VALID_URL = r'http://www\.gametrailers\.com/videos/view/[^/]+/(?P<id>.+)'
+    _VALID_URL = r'https?://www\.gametrailers\.com/videos/view/[^/]+/(?P<id>.+)'
-    _VALID_URL = r'http://www\.hotnewhiphop\.com/.*\.(?P<id>.*)\.html'
+    _VALID_URL = r'https?://www\.hotnewhiphop\.com/.*\.(?P<id>.*)\.html'
-    _VALID_URL = r'http://(?:www\.)?hypem\.com/track/(?P<id>[^/]+)/'
+    _VALID_URL = r'https?://(?:www\.)?hypem\.com/track/(?P<id>[^/]+)/'
-    _VALID_URL = r'http://(?:www|m)\.imdb\.com/video/imdb/vi(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www|m)\.imdb\.com/video/imdb/vi(?P<id>\d+)'
-    _VALID_URL = r'http://www\.imdb\.com/list/(?P<id>[\da-zA-Z_-]{11})'
+    _VALID_URL = r'https?://www\.imdb\.com/list/(?P<id>[\da-zA-Z_-]{11})'
-    _VALID_URL = r'http://(?:[^.]+\.)?iqiyi\.com/.+\.html'
+    _VALID_URL = r'https?://(?:[^.]+\.)?iqiyi\.com/.+\.html'
-    _VALID_URL = r'http://(?:www\.)?jadorecettepub\.com/[0-9]{4}/[0-9]{2}/(?P<id>.*?)\.html'
+    _VALID_URL = r'https?://(?:www\.)?jadorecettepub\.com/[0-9]{4}/[0-9]{2}/(?P<id>.*?)\.html'
-    _VALID_URL = r'http://.*?\.jeuxvideo\.com/.*/(.*?)\.htm'
+    _VALID_URL = r'https?://.*?\.jeuxvideo\.com/.*/(.*?)\.htm'
-    _VALID_URL = r'http://karaoketv\.co\.il/\?container=songs&id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://karaoketv\.co\.il/\?container=songs&id=(?P<id>[0-9]+)'
-    _VALID_URL = r'http://(?:www\.)?karrierevideos\.at(?:/[^/]+)+/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?karrierevideos\.at(?:/[^/]+)+/(?P<id>[^/]+)'
-    _VALID_URL = r'http://(?:www\.)?kontrtube\.ru/videos/(?P<id>\d+)/(?P<display_id>[^/]+)/'
+    _VALID_URL = r'https?://(?:www\.)?kontrtube\.ru/videos/(?P<id>\d+)/(?P<display_id>[^/]+)/'
-    _VALID_URL = r'http://v\.ku6\.com/show/(?P<id>[a-zA-Z0-9\-\_]+)(?:\.)*html'
+    _VALID_URL = r'https?://v\.ku6\.com/show/(?P<id>[a-zA-Z0-9\-\_]+)(?:\.)*html'
-    _VALID_URL = r'http://(?:www\.)?kusi\.com/(?P<path>story/.+|video\?clipId=(?P<clipId>\d+))'
+    _VALID_URL = r'https?://(?:www\.)?kusi\.com/(?P<path>story/.+|video\?clipId=(?P<clipId>\d+))'
-    _VALID_URL = r'http://www\.kuwo\.cn/yinyue/(?P<id>\d+?)'
+    _VALID_URL = r'https?://www\.kuwo\.cn/yinyue/(?P<id>\d+?)'
-    _VALID_URL = r'http://www\.kuwo\.cn/album/(?P<id>\d+?)/'
+    _VALID_URL = r'https?://www\.kuwo\.cn/album/(?P<id>\d+?)/'
-    _VALID_URL = r'http://yinyue\.kuwo\.cn/billboard_(?P<id>[^.]+).htm'
+    _VALID_URL = r'https?://yinyue\.kuwo\.cn/billboard_(?P<id>[^.]+).htm'
-    _VALID_URL = r'http://www\.kuwo\.cn/mingxing/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://www\.kuwo\.cn/mingxing/(?P<id>[^/]+)'
-    _VALID_URL = r'http://yinyue\.kuwo\.cn/yy/cinfo_(?P<id>\d+?).htm'
+    _VALID_URL = r'https?://yinyue\.kuwo\.cn/yy/cinfo_(?P<id>\d+?).htm'
-    _VALID_URL = r'http://www\.kuwo\.cn/mv/(?P<id>\d+?)/'
+    _VALID_URL = r'https?://www\.kuwo\.cn/mv/(?P<id>\d+?)/'
-    _VALID_URL = r'http://www\.le\.com/ptv/vplay/(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://www\.le\.com/ptv/vplay/(?P<id>\d+)\.html'
-    _VALID_URL = r'http://[a-z]+\.le\.com/[a-z]+/(?P<id>[a-z0-9_]+)'
+    _VALID_URL = r'https?://[a-z]+\.le\.com/[a-z]+/(?P<id>[a-z0-9_]+)'
-    _VALID_URL = r'http://lifenews\.ru/(?:mobile/)?(?P<section>news|video)/(?P<id>\d+)'
+    _VALID_URL = r'https?://lifenews\.ru/(?:mobile/)?(?P<section>news|video)/(?P<id>\d+)'
-    _VALID_URL = r'http://embed\.life\.ru/embed/(?P<id>[\da-f]{32})'
+    _VALID_URL = r'https?://embed\.life\.ru/embed/(?P<id>[\da-f]{32})'
-    _VALID_URL = r'(?:limelight:media:|http://link\.videoplatform\.limelight\.com/media/\??\bmediaId=)(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'(?:limelight:media:|https?://link\.videoplatform\.limelight\.com/media/\??\bmediaId=)(?P<id>[a-z0-9]{32})'
-    _VALID_URL = r'(?:limelight:channel:|http://link\.videoplatform\.limelight\.com/media/\??\bchannelId=)(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'(?:limelight:channel:|https?://link\.videoplatform\.limelight\.com/media/\??\bchannelId=)(?P<id>[a-z0-9]{32})'
-    _VALID_URL = r'(?:limelight:channel_list:|http://link\.videoplatform\.limelight\.com/media/\?.*?\bchannelListId=)(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'(?:limelight:channel_list:|https?://link\.videoplatform\.limelight\.com/media/\?.*?\bchannelListId=)(?P<id>[a-z0-9]{32})'
-    _VALID_URL = r'http://(?:www\.)?m6\.fr/[^/]+/videos/(?P<id>\d+)-[^\.]+\.html'
+    _VALID_URL = r'https?://(?:www\.)?m6\.fr/[^/]+/videos/(?P<id>\d+)-[^\.]+\.html'
-    _VALID_URL = r'http://(?:www\.)?metacafe\.com/watch/([^/]+)/([^/]+)/.*'
+    _VALID_URL = r'https?://(?:www\.)?metacafe\.com/watch/([^/]+)/([^/]+)/.*'
-    _VALID_URL = r'^http://ocw\.mit\.edu/courses/(?P<topic>[a-z0-9\-]+)'
+    _VALID_URL = r'^https?://ocw\.mit\.edu/courses/(?P<topic>[a-z0-9\-]+)'
-    _VALID_URL = r'http://www\.mitele\.es/[^/]+/[^/]+/[^/]+/(?P<id>[^/]+)/'
+    _VALID_URL = r'https?://www\.mitele\.es/[^/]+/[^/]+/[^/]+/(?P<id>[^/]+)/'
-    _VALID_URL = r'http://(?:www\.)?mooshare\.biz/(?P<id>[\da-z]{12})'
+    _VALID_URL = r'https?://(?:www\.)?mooshare\.biz/(?P<id>[\da-z]{12})'
-    _VALID_URL = r'http://(?:www\.)?motherless\.com/(?:g/[a-z0-9_]+/)?(?P<id>[A-Z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?motherless\.com/(?:g/[a-z0-9_]+/)?(?P<id>[A-Z0-9]+)'
-    _VALID_URL = r'http://www\.motorsport\.com/[^/?#]+/video/(?:[^/?#]+/)(?P<id>[^/]+)/?(?:$|[?#])'
+    _VALID_URL = r'https?://www\.motorsport\.com/[^/?#]+/video/(?:[^/?#]+/)(?P<id>[^/]+)/?(?:$|[?#])'
-    _VALID_URL = r'http://www\.myspass\.de/.*'
+    _VALID_URL = r'https?://www\.myspass\.de/.*'
-    _VALID_URL = r'http://(?:www\.)?myvideo\.de/(?:[^/]+/)?watch/(?P<id>[0-9]+)/[^?/]+.*'
+    _VALID_URL = r'https?://(?:www\.)?myvideo\.de/(?:[^/]+/)?watch/(?P<id>[0-9]+)/[^?/]+.*'
-    _VALID_URL = r'http://(?:www\.)?myvidster\.com/video/(?P<id>\d+)/'
+    _VALID_URL = r'https?://(?:www\.)?myvidster\.com/video/(?P<id>\d+)/'
-    _VALID_URL = r'http://video\.nationalgeographic\.com/.*?'
+    _VALID_URL = r'https?://video\.nationalgeographic\.com/.*?'
-    _VALID_URL = r'http://www\.nbcsports\.com//?(?:[^/]+/)+(?P<id>[0-9a-z-]+)'
+    _VALID_URL = r'https?://www\.nbcsports\.com//?(?:[^/]+/)+(?P<id>[0-9a-z-]+)'
-    _VALID_URL = r'http://www\.msnbc\.com/[^/]+/watch/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://www\.msnbc\.com/[^/]+/watch/(?P<id>[^/]+)'
-    _VALID_URL = r'http://hk.apple.nextmedia.com/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)'
+    _VALID_URL = r'https?://hk.apple.nextmedia.com/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)'
-    _VALID_URL = r'http://hk.dv.nextmedia.com/actionnews/[^/]+/(?P<date>\d+)/(?P<id>\d+)/\d+'
+    _VALID_URL = r'https?://hk.dv.nextmedia.com/actionnews/[^/]+/(?P<date>\d+)/(?P<id>\d+)/\d+'
-    _VALID_URL = r'http://(www|ent).appledaily.com.tw/(?:animation|appledaily|enews|realtimenews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
+    _VALID_URL = r'https?://(www|ent).appledaily.com.tw/(?:animation|appledaily|enews|realtimenews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
-    _VALID_URL = r'http://(?:(?:www\.)?noco\.tv/emission/|player\.noco\.tv/\?idvideo=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:(?:www\.)?noco\.tv/emission/|player\.noco\.tv/\?idvideo=)(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?normalboots\.com/video/(?P<id>[0-9a-z-]*)/?$'
+    _VALID_URL = r'https?://(?:www\.)?normalboots\.com/video/(?P<id>[0-9a-z-]*)/?$'
-    _VALID_URL = r'http://(?:[^.]+\.)?(?P<site>tv(?:noviny)?|tn|novaplus|vymena|fanda|krasna|doma|prask)\.nova\.cz/(?:[^/]+/)+(?P<id>[^/]+?)(?:\.html|/|$)'
+    _VALID_URL = r'https?://(?:[^.]+\.)?(?P<site>tv(?:noviny)?|tn|novaplus|vymena|fanda|krasna|doma|prask)\.nova\.cz/(?:[^/]+/)+(?P<id>[^/]+?)(?:\.html|/|$)'
-    _VALID_URL = r'http://(?:www\.)?npr\.org/player/v2/mediaPlayer\.html\?.*\bid=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?npr\.org/player/v2/mediaPlayer\.html\?.*\bid=(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?ntv\.ru/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?ntv\.ru/(?P<id>.+)'
-    _VALID_URL = r'http://oe1\.orf\.at/(?:programm/|konsole.*?#\?track_id=)(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://oe1\.orf\.at/(?:programm/|konsole.*?#\?track_id=)(?P<id>[0-9]+)'
-    _VALID_URL = r'http://fm4\.orf\.at/(?:7tage/?#|player/)(?P<date>[0-9]+)/(?P<show>\w+)'
+    _VALID_URL = r'https?://fm4\.orf\.at/(?:7tage/?#|player/)(?P<date>[0-9]+)/(?P<show>\w+)'
-    _VALID_URL = r'http://iptv\.orf\.at/(?:#/)?stories/(?P<id>\d+)'
+    _VALID_URL = r'https?://iptv\.orf\.at/(?:#/)?stories/(?P<id>\d+)'
-    _VALID_URL = r'http://live\.philharmoniedeparis\.fr/(?:[Cc]oncert/|misc/Playlist\.ashx\?id=)(?P<id>\d+)'
+    _VALID_URL = r'https?://live\.philharmoniedeparis\.fr/(?:[Cc]oncert/|misc/Playlist\.ashx\?id=)(?P<id>\d+)'
-    _VALID_URL = r'http://(?:[a-z0-9]+\.)?photobucket\.com/.*(([\?\&]current=)|_)(?P<id>.*)\.(?P<ext>(flv)|(mp4))'
+    _VALID_URL = r'https?://(?:[a-z0-9]+\.)?photobucket\.com/.*(([\?\&]current=)|_)(?P<id>.*)\.(?P<ext>(flv)|(mp4))'
-    _VALID_URL = r'http://(?:www\.)?pornhd\.com/(?:[a-z]{2,4}/)?videos/(?P<id>\d+)(?:/(?P<display_id>.+))?'
+    _VALID_URL = r'https?://(?:www\.)?pornhd\.com/(?:[a-z]{2,4}/)?videos/(?P<id>\d+)(?:/(?P<display_id>.+))?'
-    _VALID_URL = r'http://(?:www\.)?pornovoisines\.com/showvideo/(?P<id>\d+)/(?P<display_id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?pornovoisines\.com/showvideo/(?P<id>\d+)/(?P<display_id>[^/]+)'
-    _VALID_URL = r'http://(?:www\.)?pyvideo\.org/video/(?P<id>\d+)/(.*)'
+    _VALID_URL = r'https?://(?:www\.)?pyvideo\.org/video/(?P<id>\d+)/(.*)'
-    _VALID_URL = r'http://y.qq.com/#type=song&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y.qq.com/#type=song&mid=(?P<id>[0-9A-Za-z]+)'
-    _VALID_URL = r'http://y.qq.com/#type=singer&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y.qq.com/#type=singer&mid=(?P<id>[0-9A-Za-z]+)'
-    _VALID_URL = r'http://y.qq.com/#type=album&mid=(?P<id>[0-9A-Za-z]+)'
+    _VALID_URL = r'https?://y.qq.com/#type=album&mid=(?P<id>[0-9A-Za-z]+)'
-    _VALID_URL = r'http://y\.qq\.com/#type=toplist&p=(?P<id>(top|global)_[0-9]+)'
+    _VALID_URL = r'https?://y\.qq\.com/#type=toplist&p=(?P<id>(top|global)_[0-9]+)'
-    _VALID_URL = r'http://y\.qq\.com/#type=taoge&id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://y\.qq\.com/#type=taoge&id=(?P<id>[0-9]+)'
-    _VALID_URL = r'http://(?:.+?\.)?(?:rai\.it|rai\.tv|rainews\.it)/dl/(?:[^/]+/)+media/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html'
+    _VALID_URL = r'https?://(?:.+?\.)?(?:rai\.it|rai\.tv|rainews\.it)/dl/(?:[^/]+/)+media/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html'
-    _VALID_URL = r'http://(?:.+?\.)?(?:rai\.it|rai\.tv|rainews\.it)/dl/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html'
+    _VALID_URL = r'https?://(?:.+?\.)?(?:rai\.it|rai\.tv|rainews\.it)/dl/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html'
-    _VALID_URL = r'http://(?:www\.)?redtube\.com/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?redtube\.com/(?P<id>[0-9]+)'
-    _VALID_URL = r'http://(?:www\.)?ringtv\.craveonline\.com/(?P<type>news|videos/video)/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?ringtv\.craveonline\.com/(?P<type>news|videos/video)/(?P<id>[^/?#]+)'
-    _VALID_URL = r'http://www\.rtve\.es/(m/)?alacarta/videos/[^/]+/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://www\.rtve\.es/(m/)?alacarta/videos/[^/]+/[^/]+/(?P<id>\d+)'
-    _VALID_URL = r'http://www\.rtve\.es/directo/(?P<id>[a-zA-Z0-9-]+)'
+    _VALID_URL = r'https?://www\.rtve\.es/directo/(?P<id>[a-zA-Z0-9-]+)'
-    _VALID_URL = r'http://(?:www\.)?ruhd\.ru/play\.php\?vid=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?ruhd\.ru/play\.php\?vid=(?P<id>\d+)'
-    _VALID_URL = r'http://rutube\.ru/tags/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://rutube\.ru/tags/video/(?P<id>\d+)'
-    _VALID_URL = r'http://rutube\.ru/metainfo/tv/(?P<id>\d+)'
+    _VALID_URL = r'https?://rutube\.ru/metainfo/tv/(?P<id>\d+)'
-    _VALID_URL = r'http://rutube\.ru/video/person/(?P<id>\d+)'
+    _VALID_URL = r'https?://rutube\.ru/video/person/(?P<id>\d+)'
-    _VALID_URL = r'http://www.screenjunkies.com/video/(?P<display_id>[^/]+?)(?:-(?P<id>\d+))?(?:[/?#&]|$)'
+    _VALID_URL = r'https?://www.screenjunkies.com/video/(?P<display_id>[^/]+?)(?:-(?P<id>\d+))?(?:[/?#&]|$)'
-    _VALID_URL = r'http://www\.senate\.gov/isvp/?\?(?P<qs>.+)'
+    _VALID_URL = r'https?://www\.senate\.gov/isvp/?\?(?P<qs>.+)'
-    _VALID_URL = r'http://(?:shared|vivo)\.sx/(?P<id>[\da-z]{10})'
+    _VALID_URL = r'https?://(?:shared|vivo)\.sx/(?P<id>[\da-z]{10})'
-    _VALID_URL = r'http://(?:www|vod)?\.sport5\.co\.il/.*\b(?:Vi|docID)=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www|vod)?\.sport5\.co\.il/.*\b(?:Vi|docID)=(?P<id>\d+)'
-    _VALID_URL = r'http://ssa\.nls\.uk/film/(?P<id>\d+)'
+    _VALID_URL = r'https?://ssa\.nls\.uk/film/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:(?:www\.)?sztv\.hu|www\.tvszombathely\.hu)/(?:[^/]+)/.+-(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:(?:www\.)?sztv\.hu|www\.tvszombathely\.hu)/(?:[^/]+)/.+-(?P<id>[0-9]+)'
-    _VALID_URL = r'http://teamcoco\.com/video/(?P<video_id>[0-9]+)?/?(?P<display_id>.*)'
+    _VALID_URL = r'https?://teamcoco\.com/video/(?P<video_id>[0-9]+)?/?(?P<display_id>.*)'
-    _VALID_URL = r'^http://(?:www\.)?t13\.cl/videos(?:/[^/]+)+/(?P<id>[\w-]+)'
+    _VALID_URL = r'^https?://(?:www\.)?t13\.cl/videos(?:/[^/]+)+/(?P<id>[\w-]+)'
-    _VALID_URL = r'http://(?:(?:videos|www|lci)\.tf1|www\.tfou)\.fr/(?:[^/]+/)*(?P<id>.+?)\.html'
+    _VALID_URL = r'https?://(?:(?:videos|www|lci)\.tf1|www\.tfou)\.fr/(?:[^/]+/)*(?P<id>.+?)\.html'
-    _VALID_URL = r'http://(?:www\.)?thvideo\.tv/(?:v/th|mobile\.php\?cid=)(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?thvideo\.tv/(?:v/th|mobile\.php\?cid=)(?P<id>[0-9]+)'
-    _VALID_URL = r'http://(?:.+?\.)?tinypic\.com/player\.php\?v=(?P<id>[^&]+)&s=\d+'
+    _VALID_URL = r'https?://(?:.+?\.)?tinypic\.com/player\.php\?v=(?P<id>[^&]+)&s=\d+'
-    _VALID_URL = r'http://www\.tlc\.de/(?:[^/]+/)*videos/(?P<title>[^/?#]+)?(?:.*#(?P<id>\d+))?'
+    _VALID_URL = r'https?://www\.tlc\.de/(?:[^/]+/)*videos/(?P<title>[^/?#]+)?(?:.*#(?P<id>\d+))?'
-    _VALID_URL = r'http://videos\.toypics\.net/(?P<username>[^/?]+)(?:$|[?#])'
+    _VALID_URL = r'https?://videos\.toypics\.net/(?P<username>[^/?]+)(?:$|[?#])'
-    _VALID_URL = r'(?:http://)?(?:www\.)?traileraddict\.com/(?:trailer|clip)/(?P<movie>.+?)/(?P<trailer_name>.+)'
+    _VALID_URL = r'(?:https?://)?(?:www\.)?traileraddict\.com/(?:trailer|clip)/(?P<movie>.+?)/(?P<trailer_name>.+)'
-    _VALID_URL = r'http://(?:www\.)?trollvids\.com/video/(?P<id>\d+)/(?P<display_id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?trollvids\.com/video/(?P<id>\d+)/(?P<display_id>[^/?#&]+)'
-    _VALID_URL = r'http://(?P<blog_name>.*?)\.tumblr\.com/(?:post|video)/(?P<id>[0-9]+)(?:$|[/?#])'
+    _VALID_URL = r'https?://(?P<blog_name>.*?)\.tumblr\.com/(?:post|video)/(?P<id>[0-9]+)(?:$|[/?#])'
-    _VALID_URL = r'http://(?:www\.)?tv2\.no/v/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tv2\.no/v/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?tv2\.no/(?:a|\d{4}/\d{2}/\d{2}(/[^/]+)+)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tv2\.no/(?:a|\d{4}/\d{2}/\d{2}(/[^/]+)+)/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?tvc\.ru/video/iframe/id/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tvc\.ru/video/iframe/id/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?tvc\.ru/(?!video/iframe/id/)(?P<id>[^?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?tvc\.ru/(?!video/iframe/id/)(?P<id>[^?#]+)'
-    _VALID_URL = r'''(?x)http://(?:www\.)?
+    _VALID_URL = r'''(?x)https?://(?:www\.)?
-    _VALID_URL = r'http://(?:www\.)?ubu\.com/film/(?P<id>[\da-z_-]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?ubu\.com/film/(?P<id>[\da-z_-]+)\.html'
-    _VALID_URL = r'http://utv\.unistra\.fr/(?:index|video)\.php\?id_video\=(?P<id>\d+)'
+    _VALID_URL = r'https?://utv\.unistra\.fr/(?:index|video)\.php\?id_video\=(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?vbox7\.com/play:(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?vbox7\.com/play:(?P<id>[^/]+)'
-    _VALID_URL = r'http://(?:www\.)?veoh\.com/(?:watch|iphone/#_Watch)/(?P<id>(?:v|yapi-)[\da-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?veoh\.com/(?:watch|iphone/#_Watch)/(?P<id>(?:v|yapi-)[\da-zA-Z]+)'
-    _VALID_URL = r'http://(?:.+?\.)?vesti\.ru/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:.+?\.)?vesti\.ru/(?P<id>.+)'
-    _VALID_URL = r'http://(?:www\.)?bt\.no/(?:[^/]+/)+(?P<id>[^/]+)-\d+\.html'
+    _VALID_URL = r'https?://(?:www\.)?bt\.no/(?:[^/]+/)+(?P<id>[^/]+)-\d+\.html'
-    _VALID_URL = r'http://(?:www\.)?bt\.no/spesial/vestlendingen/#!/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?bt\.no/spesial/vestlendingen/#!/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?video\.tt/(?:(?:video|embed)/|watch_video\.php\?v=)(?P<id>[\da-zA-Z]{9})'
+    _VALID_URL = r'https?://(?:www\.)?video\.tt/(?:(?:video|embed)/|watch_video\.php\?v=)(?P<id>[\da-zA-Z]{9})'
-    _VALID_URL = r'''(?x)http://(?:www\.)?(?:
+    _VALID_URL = r'''(?x)https?://(?:www\.)?(?:
-    _VALID_URL = r'http://vube\.com/(?:[^/]+/)+(?P<id>[\da-zA-Z]{10})\b'
+    _VALID_URL = r'https?://vube\.com/(?:[^/]+/)+(?P<id>[\da-zA-Z]{10})\b'
-    _VALID_URL = r'http://(?:m\.)?vuclip\.com/w\?.*?cid=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:m\.)?vuclip\.com/w\?.*?cid=(?P<id>[0-9]+)'
-    _VALID_URL = r'http://vod\.walla\.co\.il/[^/]+/(?P<id>\d+)/(?P<display_id>.+)'
+    _VALID_URL = r'https?://vod\.walla\.co\.il/[^/]+/(?P<id>\d+)/(?P<display_id>.+)'
-    _VALID_URL = r'(?:wat:(?P<real_id>\d{8})|http://www\.wat\.tv/video/(?P<display_id>.*)-(?P<short_id>.*?)_.*?\.html)'
+    _VALID_URL = r'(?:wat:(?P<real_id>\d{8})|https?://www\.wat\.tv/video/(?P<display_id>.*)-(?P<short_id>.*?)_.*?\.html)'
-    _VALID_URL = r'http://(?:www\.)?wdrmaus\.de/(?:[^/]+/){,2}(?P<id>[^/?#]+)(?:/index\.php5|(?<!index)\.php5|/(?:$|[?#]))'
+    _VALID_URL = r'https?://(?:www\.)?wdrmaus\.de/(?:[^/]+/){,2}(?P<id>[^/?#]+)(?:/index\.php5|(?<!index)\.php5|/(?:$|[?#]))'
-    _VALID_URL = r'http://www\.weiqitv\.com/index/video_play\?videoId=(?P<id>[A-Za-z0-9]+)'
+    _VALID_URL = r'https?://www\.weiqitv\.com/index/video_play\?videoId=(?P<id>[A-Za-z0-9]+)'
-    _VALID_URL = r'http://(?:www\.)?wimp\.com/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?wimp\.com/(?P<id>[^/]+)'
-    _VALID_URL = r'http://(?:www\.)?xbef\.com/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?xbef\.com/video/(?P<id>[0-9]+)'
-    _VALID_URL = r'http://mymedia.yam.com/m/(?P<id>\d+)'
+    _VALID_URL = r'https?://mymedia.yam.com/m/(?P<id>\d+)'
-    _VALID_URL = r'http://(?:.+?\.)?ynet\.co\.il/(?:.+?/)?0,7340,(?P<id>L(?:-[0-9]+)+),00\.html'
+    _VALID_URL = r'https?://(?:.+?\.)?ynet\.co\.il/(?:.+?/)?0,7340,(?P<id>L(?:-[0-9]+)+),00\.html'
-    _VALID_URL = 'http://www.bbc.co.uk/programmes/articles/(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'http://www.bbc.co.uk/programmes/articles/(?P<id>[a-zA-Z0-9]+)'
-    _VALID_URL = 'http://(?:[^.]+\.)?(?P<site>tv(?:noviny)?|tn|novaplus|vymena|fanda|krasna|doma|prask)\.nova\.cz/(?:[^/]+/)+(?P<id>[^/]+?)(?:\.html|/|$)'
+    _VALID_URL = r'http://(?:[^.]+\.)?(?P<site>tv(?:noviny)?|tn|novaplus|vymena|fanda|krasna|doma|prask)\.nova\.cz/(?:[^/]+/)+(?P<id>[^/]+?)(?:\.html|/|$)'
-    _VALID_URL = 'http://(?:www\.)?tv2\.no/v/(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www\.)?tv2\.no/v/(?P<id>\d+)'
-    _VALID_URL = 'http://(?:www\.)?tv2\.no/(?:a|\d{4}/\d{2}/\d{2}(/[^/]+)+)/(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www\.)?tv2\.no/(?:a|\d{4}/\d{2}/\d{2}(/[^/]+)+)/(?P<id>\d+)'
-    _VALID_URL = 'http://(?:www\.)?bt\.no/(?:[^/]+/)+(?P<id>[^/]+)-\d+\.html'
+    _VALID_URL = r'http://(?:www\.)?bt\.no/(?:[^/]+/)+(?P<id>[^/]+)-\d+\.html'
-    _VALID_URL = 'http://(?:www\.)?bt\.no/spesial/vestlendingen/#!/(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www\.)?bt\.no/spesial/vestlendingen/#!/(?P<id>\d+)'
-    _VALID_URL = 'http://(?:www\.)?wdrmaus\.de/(?:[^/]+/){,2}(?P<id>[^/?#]+)(?:/index\.php5|(?<!index)\.php5|/(?:$|[?#]))'
+    _VALID_URL = r'http://(?:www\.)?wdrmaus\.de/(?:[^/]+/){,2}(?P<id>[^/?#]+)(?:/index\.php5|(?<!index)\.php5|/(?:$|[?#]))'
-    _VALID_URL = r'http://(?:www\.)?my\.mail\.ru/(?:video/.*#video=/?(?P<idv1>(?:[^/]+/){3}\d+)|(?:(?P<idv2prefix>(?:[^/]+/){2})video/(?P<idv2suffix>[^/]+/\d+))\.html)'
+    _VALID_URL = r'https?://(?:www\.)?my\.mail\.ru/(?:video/.*#video=/?(?P<idv1>(?:[^/]+/){3}\d+)|(?:(?P<idv2prefix>(?:[^/]+/){2})video/(?P<idv2suffix>[^/]+/\d+))\.html)'
-            res += '[%s]' % fdict['language']
+            res += '[%s] ' % fdict['language']
-from ..compat import compat_urlparse
+from ..compat import (
-                    title = playlist['title']
+            for input_ in re.findall(
-                            formats = self._extract_m3u8_formats(
+                            m3u8_formats = self._extract_m3u8_formats(
-                                entry_protocol='m3u8_native', m3u8_id='hls')
+                                entry_protocol='m3u8_native', m3u8_id=format_id)
-import itertools
+    InAdvancePagedList,
-    _VALID_URL = r'http://www\.kuwo\.cn/yinyue/(?P<id>\d+?)/'
+    _VALID_URL = r'http://www\.kuwo\.cn/yinyue/(?P<id>\d+?)'
-                r'<a[^>]+href="(http://www\.kuwo\.cn/yinyue/\d+)/"', webpage)
+                r'<a[^>]+href="(http://www\.kuwo\.cn/yinyue/\d+)', webpage)
-        return self.playlist_result(entries, chart_id, chart_name, chart_desc)
+        return self.playlist_result(entries, chart_id)
-        'playlist_count': 10,
+        'playlist_mincount': 329,
-        )
+            r'<h1>([^<]+)</h1>', webpage, 'singer name')
-        for page_num in itertools.count(1):
+        def page_func(page_num):
-                errnote='Unable to get song list page #%d' % page_num)
+                'http://www.kuwo.cn/artist/contentMusicsAjax',
-            entries.extend([
+            return [
-                    r'<p[^>]+class="m_name"><a[^>]+href="(http://www\.kuwo\.cn/yinyue/\d+)/',
+                    r'<div[^>]+class="name"><a[^>]+href="(http://www\.kuwo\.cn/yinyue/\d+)',
-            ][:10 if first_page_only else None])
+            ]
-                break
+        entries = InAdvancePagedList(page_func, page_count, self.PAGE_SIZE)
-            r'<div[^>]+class="info_area"[^>]*>\s*<strong[^>]+class="name"[^>]*>([^<]+)</strong>',
+            r'<div[^>]+class="info_area"[^>]*>\s*<a\s+[^>]*>([^<]+)',
-from ..utils import encode_base_n
+from ..utils import (
-    _VALID_URL = r'https://openload.co/f/(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'https://openload.(?:co|io)/(?:f|embed)/(?P<id>[a-zA-Z0-9-]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        for part in parts:
+
-            part_info = {
+            return [{
-            result.append(part_info)
+            }]
-            'entries': result,
+            'entries': entries,
-                        f4m_url + '&hdcore=3.7.0&plugin=aasp-3.7.0.39.44', video_id, 1, format_id))
+                        f4m_url + '&hdcore=3.7.0&plugin=aasp-3.7.0.39.44',
-                formats.extend(self._extract_m3u8_formats(video_url, video_id, 'mp4', m3u8_id=format_id))
+                formats.extend(self._extract_m3u8_formats(
-                })
+                if self._is_valid_url(video_url, video_id, format_id):
-            'ext': 'flv',
+            'ext': 'mp4',
-            'id': '556e03339473995ee145930c',
+            'id': 'NI_173343',
-        }
+            'timestamp': 1433273139,
-            'ext': 'flv',
+            'ext': 'mp4',
-    _VALID_URL = r'https?://(?:www|mobile)\.francetvinfo\.fr/.*/(?P<title>.+)\.html'
+    _VALID_URL = r'https?://(?:www|mobile|france3-regions)\.francetvinfo\.fr/.*/(?P<title>.+)\.html'
-            r'id-video=([^@]+@[^"]+)', webpage, 'video id').split('@')
+            (r'id-video=([^@]+@[^"]+)',
-    _VALID_URL = r'''(?x)http://(?:www\.)?(?:
+    _VALID_URL = r'''(?x)https?://(?:www\.)?(?:
-        help='Embed subtitles in the video (only for mkv and mp4 videos)')
+        help='Embed subtitles in the video (only for mp4, webm and mkv videos)')
-            self._downloader.to_screen('[ffmpeg] Subtitles can only be embedded in mp4 or mkv files')
+        if information['ext'] not in ('mp4', 'webm', 'mkv'):
-        sub_filenames = [subtitles_filename(filename, lang, sub_info['ext']) for lang, sub_info in subtitles.items()]
+
-        webpage = self._download_webpage(url, video_id, 'get HTML content')
+
-            'get real video url')
+            'Downloading real video url')
-from ..compat import compat_urllib_parse
+from ..compat import (
-        video_url = self._search_regex(r'file=([^&]+)&', info_cn, 'url')
+        video_url = compat_urllib_parse_unquote(self._search_regex(
-        }
+# coding: utf-8
-            }
+    _VALID_URL = r'https?://(?:(?:www\.)?cda\.pl/video|ebd\.cda\.pl/[0-9]+x[0-9]+)/(?P<id>[0-9a-z]+)'
-    ]
+    }, {
-            }, parse_duration(duration)
+        title = self._html_search_regex(r'<title>(.+?)</title>', webpage, 'title')
-            formats.append(format_desc)
+        info_dict = {
-            webpage = self._download_webpage(version[0], video_id, 'Downloading %s version information' % version[1], fatal=False)
+        def extract_format(page, version):
-                self.report_warning('Unable to download %s version information' % version[1])
+                # Manually report warning because empty page is returned when
-                formats.append(format_desc)
+            extract_format(webpage, resolution)
-        }
+        return info_dict
-    '''
+    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/library/view/[^/]+/(?P<course_id>[^/]+)/(?P<part>part\d+)\.html'
-        ui_id = self._search_regex(r'data-ui-id="([^"]+)"', webpage, 'kaltura uiconf id')
+        video_id = '%s/%s' % (mobj.group('course_id'), mobj.group('part'))
-                course_id, 'Downloading kaltura session JSON',
+                video_id, 'Downloading kaltura session JSON',
-            self.url_result(chapter, 'Safari')
+            self.url_result(chapter, SafariApiIE.ie_key())
-        self.to_screen('[download] Got server HTTP error. Retrying (attempt %d of %.0f)...' % (count, retries))
+        self.to_screen(
-            % (fragment_name, count, retries))
+            '[download] Got server HTTP error. Retrying fragment %s (attempt %d of %s)...'
-            if not success:
+        fragment_retries = self.params.get('fragment_retries', 0)
-            append_url_to_file(initialization_url, ctx['tmpfilename'] + '-Init')
+            append_url_to_file(initialization_url, ctx['tmpfilename'], 'Init')
-            append_url_to_file(segment_url, segment_filename)
+            append_url_to_file(segment_url, ctx['tmpfilename'], 'Seg%d' % i)
-            opts_retries = float('inf')
+
-                opts_retries = int(opts.retries)
+                parsed_retries = int(retries)
-        'retries': opts_retries,
+        'retries': opts.retries,
-        r'(?P<num>[0-9]+(?:[,.][0-9]*)?)\s*(?P<unit>%s)$' % units_re, s)
+        r'(?P<num>[0-9]+(?:[,.][0-9]*)?)\s*(?P<unit>%s)\b' % units_re, s)
-        if first_bytes.startswith('#EXTM3U'):
+        if first_bytes.startswith(b'#EXTM3U'):
-        r'(?P<num>[0-9]+(?:[,.][0-9]*)?)\s*(?P<unit>%s)' % units_re, s)
+        r'(?P<num>[0-9]+(?:[,.][0-9]*)?)\s*(?P<unit>%s)$' % units_re, s)
-                \s*(?P<key>ext|acodec|vcodec|container|protocol)
+                \s*(?P<key>ext|acodec|vcodec|container|protocol|format_id)
-            })
+                info_dict['direct'] = True
-                'upload_date': upload_date,
+        # m3u8 served with Content-Type: audio/x-mpegURL; charset=utf-8
-        content_type = head_response.headers.get('Content-Type', '')
+        content_type = head_response.headers.get('Content-Type', '').lower()
-        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\.apple\.|x-)?mpegurl)))/(?P<format_id>.+)$', content_type)
+        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\.apple\.|x-)?mpegurl)))/(?P<format_id>[^;\s]+)', content_type)
-        if error_element is not None:
+        error_element = find_xpath_attr(meta, _x('.//smil:ref'), 'src')
-        adaptive_formats = self._extract_m3u8_formats(
+        formats = self._extract_m3u8_formats(
-        for adaptive_format in adaptive_formats:
+        progressive_formats = []
-                formats.append(progressive_format)
+                progressive_formats.append(progressive_format)
-__version__ = '2016.03.14'
+__version__ = '2016.03.18'
-        meta = self._download_xml(smil_url, video_id, note=note)
+        meta = self._download_xml(smil_url, video_id, note=note, query={'format': 'SMIL'})
-            'http://link.theplatform.com/s/%s/%s?format=SMIL&mbr=true&switch=progressive' % (account_pid, release_pid),
+            'http://link.theplatform.com/s/%s/%s?mbr=true&switch=progressive' % (account_pid, release_pid),
-            release_url = 'http://link.theplatform.com/s/dJ5BDC/%s?format=SMIL&mbr=true' % pid
+            release_url = 'http://link.theplatform.com/s/dJ5BDC/%s?mbr=true' % pid
-            release_url = 'http://link.theplatform.com/s/kYEXFC/%s?format=SMIL&mbr=true' % vid
+            release_url = 'http://link.theplatform.com/s/kYEXFC/%s?mbr=true' % vid
-            'http://link.theplatform.com/s/ngs/%s?format=SMIL&formats=MPEG4&manifest=f4m' % theplatform_id,
+            'http://link.theplatform.com/s/ngs/%s?formats=MPEG4&manifest=f4m' % theplatform_id,
-            smil_url += '?' if '?' not in smil_url else '&' + 'formats=m3u,mpeg4&format=SMIL'
+            smil_url += '?' if '?' not in smil_url else '&' + 'formats=m3u,mpeg4'
-            smil_url = release_url + '&format=SMIL&formats=MPEG4&manifest=f4m'
+            smil_url = release_url + '&formats=MPEG4&manifest=f4m'
-            smil_url = 'http://link.theplatform.com/s/%s/meta.smil?format=smil&mbr=true' % path
+            smil_url = 'http://link.theplatform.com/s/%s?mbr=true' % path
-            smil_url = item['plfile$url'] + '&format=SMIL&mbr=true'
+            smil_url = item['plfile$url'] + '&mbr=true'
-from ..compat import compat_urllib_parse_unquote
+from ..compat import (
-        for qnode in doc.findall('.//article/movie/file/qualities/qual'):
+        for qnode in doc.findall(compat_xpath('.//article/movie/file/qualities/qual')):
-        for f in node.findall(xpath):
+        for f in node.findall(compat_xpath(xpath)):
-        return node.find(xpath)
+        return node.find(compat_xpath(xpath))
-                r'(?s)<h3[^>]+class="episodebox-title".+?>Episodeninhalt<', webpage)):
+                r'(?s)<h3[^>]+class="episodebox-title".+?>Episodeninhalt<', webpage), 1):
-                webpage, 'episodebox title', default=None)
+                (r'class="episodebox-title"[^>]+title=(["\'])(?P<title>.+?)\1',
-                r'^(?:Episode|Film)\s*(\d+)',
+                r'(?:Episode|Film)\s*(\d+)',
-                r'(?:Episode|Film)\s*\d+\s*-\s*(?P<title>.+?)',
+                r'(?:Episode|Film)\s*\d+\s*-\s*(.+)',
-            if not m:
+        for num, episode_html in enumerate(re.findall(
-            episode_title = m.group('title')
+            episode_number = int(self._search_regex(
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                r'class="episodebox-title"[^>]+title="Episode (?P<number>\d+) - (?P<title>.+?)"', episode_html)
+                r'class="episodebox-title"[^>]+title="(?:Episode|Film)\s*(?P<number>\d+)\s*-\s*(?P<title>.+?)"', episode_html)
-    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None):
+    def _download_webpage(self, url_or_request, *args, **kwargs):
-            request, video_id, note, errnote, fatal, tries, timeout, encoding)
+        return super(CrunchyrollBaseIE, self)._download_webpage(request, *args, **kwargs)
-            if atype == 'still':
+            if (astatus is not None and astatus != 2) or atype == 'preview':
-            })
+            else:
-            'title': data['name'],
+            'title': title,
-            'duration': data.get('duration'),
+            'duration': int_or_none(data.get('duration')),
-from ..compat import compat_HTTPError
+from .theplatform import ThePlatformIE
-    ExtractorError,
+    update_url_query,
-class NBCNewsIE(InfoExtractor):
+class NBCNewsIE(ThePlatformIE):
-        (?:watch|feature|nightly-news)/[^/]+/(?P<title>.+))
+        ([^/]+/)*(?P<display_id>[^/?]+))
-            'md5': 'b2421750c9f260783721d898f4c42063',
+            'url': 'http://www.nbcnews.com/watch/nbcnews-com/how-twitter-reacted-to-the-snowden-interview-269389891880',
-                'id': 'I1wpAI_zmhsQ',
+                'id': '269389891880',
-            'add_ie': ['ThePlatform'],
+            'skip': 'This page is unavailable.',
-            'md5': 'b5dda8cddd8650baa0dcb616dd2cf60d',
+            'md5': '73135a2e0ef819107bbb55a5a9b2a802',
-                'id': 'sekXqyTVnmN3',
+                'id': '394064451844',
-            webpage = self._download_webpage(url, title)
+            display_id = mobj.group('display_id')
-            mpxid = info['mpxId']
+                r'(?m)var\s+(?:bootstrapJson|playlistData)\s*=\s*({.+});?\s*$',
-            ]
+            subtitles = {}
-                if not base_url:
+            formats = []
-                except StopIteration:
+                container = video_asset.get('format')
-                raise ExtractorError('Could not find video in playlists')
+                elif asset_type == 'OnceURL':
-                'ie_key': 'ThePlatform',
+                'id': video_id,
-from .common import InfoExtractor
+from .once import OnceIE
-class ThePlatformBaseIE(InfoExtractor):
+class ThePlatformBaseIE(OnceIE):
-        formats = self._parse_smil_formats(
+        smil_formats = self._parse_smil_formats(
-                _format['ext'] = 'mp4'
+        formats = []
-        'md5': '734f3790fb5fc4903da391beeebc4836',
+        'md5': 'fb96bb3d85118930a5b055783a3bd992',
-        'md5': '22d2b84f058d3586efcd99e57d59d314',
+        'md5': '6e32495b5073ab414471b615c5ded394',
-            video_id)
+        player_params = self._download_json(
-                           urls.get('html') or player_params['relatedItemsURL'])
+        theplatform_url = (urls.get('progressive') or urls.get('html') or
-            'url': theplatform_url,
+            'url': smuggle_url(theplatform_url, {'force_smil_url': True}),
-        self.assertEqual(extract_attributes('<e x="&lambda;">'), {'x': 'Î»'}) # HTML 4.0
+        self.assertEqual(extract_attributes('<e x="&pound;">'), {'x': 'Â£'})  # HTML 3.2
-        self.assertEqual(extract_attributes('<e CAPS=x>'), {'caps': 'x'}) # Names lowercased
+        self.assertEqual(extract_attributes('<e CAPS=x>'), {'caps': 'x'})  # Names lowercased
-        self.attrs = { }
+        self.attrs = {}
-            (r'data-course-id=["\'](\d+)', r'&quot;id&quot;: (\d+)'),
+            (r'data-course-id=["\'](\d+)', r'&quot;id&quot;\s*:\s*(\d+)'),
-            r'data-course-id=["\'](\d+)', webpage, 'course id')
+            (r'data-course-id=["\'](\d+)', r'&quot;id&quot;: (\d+)'),
-            entries.append(url)
+                r'<iframe[^>]+src=(["\'])((?:https?:)?//players\.brightcove\.net/\d+/[^/]+/index\.html.+?)\1', webpage):
-    sanitized_Request,
+    update_url_query,
-    _FEDERATED_URL_TEMPLATE = 'http://c.brightcove.com/services/viewer/htmlFederated?%s'
+    _FEDERATED_URL = 'http://c.brightcove.com/services/viewer/htmlFederated'
-        # The three fields hold the id of the video
+        # These fields hold the id of the video
-        return cls._FEDERATED_URL_TEMPLATE % data
+        return update_url_query(cls._FEDERATED_URL, params)
-                videoPlayer[0], query_str, query, referer=referer)
+                videoPlayer[0], query, referer=referer)
-        req = sanitized_Request(request_url)
+    def _get_video_info(self, video_id, query, referer=None):
-        webpage = self._download_webpage(req, video_id)
+            headers['Referer'] = referer
-            headers={'Accept': 'application/json;pk=%s' % policy_key})
+        api_url = 'https://edge.api.brightcove.com/playback/v1/accounts/%s/videos/%s' % (account_id, video_id)
-            json_data = self._download_json(req, video_id)
+            json_data = self._download_json(api_url, video_id, headers={
-                    m3u8_id='hls', fatal=False))
+                    src, video_id, 'mp4', m3u8_id='hls', fatal=False))
-        videoPlayer = find_param('@videoPlayer') or find_param('videoId') or find_param('videoID')
+        videoPlayer = find_param('@videoPlayer') or find_param('videoId') or find_param('videoID') or find_param('@videoList')
-                        data-video-id=["\']((?:ref:)?\d+)["\'][^>]*>.*?
+                        data-video-id=["\'](\d+|ref:[^"\']+)["\'][^>]*>.*?
-                qnode, './html_urls/video_url[@format="video/mp4"]')
+            http_url_ele = find_xpath_attr(
-                    qnode, './html_urls/video_url[@format="application/vnd.apple.mpegurl"]')
+                m3u8_url_ele = find_xpath_attr(
-    def _get_formats(self, song_id):
+    def _get_formats(self, song_id, tolerate_ip_deny=False):
-            if song_url == 'IPDeny':
+            if song_url == 'IPDeny' and not tolerate_ip_deny:
-        self._sort_formats(formats)
+
-            'title': 'æä»¬å®¶MV',
+            'ext': 'mp4',
-        formats = self._get_formats(song_id)
+        formats = self._get_formats(song_id, tolerate_ip_deny=True)
-            'uploader': 'Al Jazeera English',
+            'uploader_id': '665003303001',
-        'add_ie': ['BrightcoveLegacy'],
+        'add_ie': ['BrightcoveNew'],
-        }
+        return self.url_result(self.BRIGHTCOVE_URL_TEMPLATE % brightcove_id, 'BrightcoveNew', brightcove_id)
-                    m3u8_id=vr.get('playerType')))
+                    m3u8_id=player_type, fatal=False))
-                    f4m_id=vr.get('playerType')))
+                    f4m_id=player_type, fatal=False))
-                    'format_id': vr.get('playerType'),
+                    'format_id': player_type,
-                    'ext': source.get('container').lower(),
+                    'ext': container.lower(),
-                    'Twitch paging is broken on twitch side, requesting all videos at once',
+                    'Twitch pagination is broken on twitch side, requesting all videos at once',
-            })
+            http_url = xpath_text(
-            if source_type == 'application/x-mpegURL':
+            if source_type == 'application/x-mpegURL' or container == 'M2TS':
-                    'container': source.get('container'),
+                    'container': container,
-    _VALID_URL = r'https?://players\.brightcove\.net/(?P<account_id>\d+)/(?P<player_id>[^/]+)_(?P<embed>[^/]+)/index\.html\?.*videoId=(?P<video_id>(?:ref:)?\d+)'
+    _VALID_URL = r'https?://players\.brightcove\.net/(?P<account_id>\d+)/(?P<player_id>[^/]+)_(?P<embed>[^/]+)/index\.html\?.*videoId=(?P<video_id>\d+|ref:[^&]+)'
-                        (\d+)/([\da-f-]+)_([^/]+)/index\.min\.js
+                        (\d+)/([\da-f-]+)_([^/]+)/index(?:\.min)?\.js
-        json_data = self._download_json(req, video_id)
+        try:
-from ..compat import compat_urlparse
+from ..compat import compat_parse_qs
-    _VALID_URL = r'http://www\.tlc\.de/sendungen/[^/]+/videos/(?P<title>[^/?]+)'
+    _VALID_URL = r'http://www\.tlc\.de/(?:[^/]+/)*videos/(?P<title>[^/?#]+)?(?:.*#(?P<id>\d+))?'
-            'uploader': 'Discovery Networks - Germany',
+            'timestamp': 1396598084,
-        }
+        brightcove_id = mobj.group('id')
-            'ext': 'm3u8',
+            'ext': 'mp4',
-            'skip_download': True,
+            'timestamp': 1443457610,
-        }
+        brightcove_id = self._search_regex(r"getVideo\('[^']+video_id=(\d+)", webpage, 'brightcove id')
-        if info_dict.get('protocol') == 'm3u8':
+        if protocol == 'm3u8':
-__version__ = '2016.03.06'
+__version__ = '2016.03.14'
-            args += ['-t', compat_str(end_time - start_time)]
+        # start_time = info_dict.get('start_time') or 0
-    # if (info_dict.get('start_time') or info_dict.get('end_time')) and FFmpegFD.can_download(info_dict):
+    # if (info_dict.get('start_time') or info_dict.get('end_time')) and not info_dict.get('requested_formats') and FFmpegFD.can_download(info_dict):
-        return info_dict['protocol'] in ('http', 'https', 'ftp', 'ftps', 'm3u8', 'rtsp', 'rtmp', 'mms') and not info_dict.get('requested_formats')
+        return info_dict['protocol'] in ('http', 'https', 'ftp', 'ftps', 'm3u8', 'rtsp', 'rtmp', 'mms')
-        return FFmpegFD
+    # if (info_dict.get('start_time') or info_dict.get('end_time')) and FFmpegFD.can_download(info_dict):
-    'rtsp': FFmpegFD,
+    'mms': RtspFD,
-    if (info_dict.get('start_time') or info_dict.get('end_time')) and FFmpegFD.available() and FFmpegFD.supports(info_dict):
+    if (info_dict.get('start_time') or info_dict.get('end_time')) and FFmpegFD.can_download(info_dict):
-        if ed.available() and ed.supports(info_dict):
+        if ed.can_download(info_dict):
-        return check_executable(cls.get_basename(), cls.available_opt)
+        return check_executable(cls.get_basename(), [cls.AVAILABLE_OPT])
-    available_opt = ['-V']
+    AVAILABLE_OPT = '-V'
-    available_opt = ['-V']
+    AVAILABLE_OPT = '-V'
-    available_opt = ['--version']
+    AVAILABLE_OPT = '--version'
-    available_opt = ['-v']
+    AVAILABLE_OPT = '-v'
-                return
+            self.to_screen('[info] No thumbnails present for %s' % info_dict['id'])
-        return info_dict['protocol'] in ('http', 'https', 'ftp', 'ftps', 'm3u8', 'rtsp', 'rtmp', 'mms')
+        return info_dict['protocol'] in ('http', 'https', 'ftp', 'ftps', 'm3u8', 'rtsp', 'rtmp', 'mms') and not info_dict.get('requested_formats')
-from .vice import ViceIE
+from .vice import (
-    ]
+    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/(?:[^/]+/)?videos?/(?P<id>[^/?#&]+)'
-from ..postprocessor.ffmpeg import FFmpegPostProcessor
+from ..postprocessor.ffmpeg import FFmpegPostProcessor, EXT_TO_OUT_FORMATS
-            args += ['-f', info_dict['ext']]
+            args += ['-f', EXT_TO_OUT_FORMATS.get(info_dict['ext'], info_dict['ext'])]
-            r'\bbutton-favorite\b[^>]+m-ajax-toggle-count="([^"]+)"',
+        like_count = parse_count(self._search_regex(
-    if not m:
+    return lookup_unit_table(_UNIT_TABLE, s)
-    return int(float(num_str) * mult)
+    s = s.strip()
-            'title': 'What Liverpool can expect from Klopp',
+            'title': 'Jurgen Klopp: Furious football from a witty and winning coach',
-            'title': 'BBC Blogs - Adam Curtis - BUGGER',
+            'title': 'BUGGER',
-        playlist_description = json_ld_info.get('description')
+        if not playlist_title:
-    remove_end,
+        playlist_title = self._og_search_title(webpage, default=None)
-
+from .makerschannel import MakersChannelIE
-    smuggle_url,
+            elif ext == 'f4m':
-            if m.group('format_id').endswith('mpegurl'):
+            format_id = m.group('format_id')
-                'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),
+            info_dict.update({
-            }
+            })
-                'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),
+            info_dict.update({
-            }
+            })
-                }
+                info_dict['formats'] = self._parse_mpd_formats(
-                        manifest_url, video_id, preference, f4m_id, fatal=fatal))
+                        manifest_url, video_id, preference=preference, f4m_id=f4m_id,
-            SafariBaseIE.LOGGED_IN = True
+        self._login()
-    _API_BASE = 'https://www.safaribooksonline.com/api/v1/book'
+    _API_BASE = 'https://www.safaribooksonline.com/api/v1'
-            self.raise_login_required('safaribooksonline.com account is required')
+            return
-        return self.url_result(update_url_query('https://cdnapisec.kaltura.com/html5/html5lib/v2.37.1/mwEmbedFrame.php', {
+        query = {
-        }), 'Kaltura')
+        }
-            '%s/%s/?override_format=%s' % (self._API_BASE, course_id, self._API_FORMAT),
+            '%s/book/%s/?override_format=%s' % (self._API_BASE, course_id, self._API_FORMAT),
-        info, flavor_assets = None, None
+        ks = None
-                video_url += '?referrer=%s' % referrer
+            video_url = sign_url('%s/flavorId/%s' % (info['dataUrl'], f['id']))
-            m3u8_url += '?referrer=%s' % referrer
+        m3u8_url = sign_url(info['dataUrl'].replace('format/url', 'format/applehttp'))
-                    params[splitted_path[i]] = [splitted_path[i + 1]]
+                params.update(dict((zip(splitted_path[::2], [[v] for v in splitted_path[1::2]]))))
-from .dw import DWIE
+from .dw import (
-        webpage = self._download_webpage(url, video_id)
+        media_id = self._match_id(url)
-                'http://www.dw.com/smil/v-%s' % video_id, video_id,
+                'http://www.dw.com/smil/v-%s' % media_id, media_id,
-            'id': video_id,
+            'id': media_id,
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-
+        formats = []
-        smil = self._download_smil(smil_url, video_id, fatal=fatal)
+    def _extract_smil_formats(self, smil_url, video_id, fatal=True, f4m_params=None, transform_source=None):
-    def _download_smil(self, smil_url, video_id, fatal=True):
+    def _download_smil(self, smil_url, video_id, fatal=True, transform_source=None):
-            'Unable to download SMIL file', fatal=fatal)
+            'Unable to download SMIL file', fatal=fatal, transform_source=transform_source)
-    _TEST = {
+    _VALID_URL = r'https?://(?:(?:docs|drive)\.google\.com/(?:uc\?.*?id=|file/d/)|video\.google\.com/get_player\?.*?docid=)(?P<id>[a-zA-Z0-9_-]{28,})'
-    }
+    }, {
-            r'<iframe[^>]+src="https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28})',
+            r'<iframe[^>]+src="https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28,})',
-    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):
+    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers=None, query=None):
-    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None):
+    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers=None, query=None):
-        urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal)
+        urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal, data=data, headers=headers, query=query)
-    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None):
+    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None, data=None, headers=None, query=None):
-                res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal, encoding=encoding)
+                res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal, encoding=encoding, data=data, headers=headers, query=query)
-                      transform_source=None, fatal=True, encoding=None):
+                      transform_source=None, fatal=True, encoding=None, data=None, headers=None, query=None):
-            url_or_request, video_id, note, errnote, fatal=fatal, encoding=encoding)
+            url_or_request, video_id, note, errnote, fatal=fatal, encoding=encoding, data=data, headers=headers, query=query)
-                       fatal=True, encoding=None):
+                       fatal=True, encoding=None, data=None, headers=None, query=None):
-            encoding=encoding)
+            encoding=encoding, data=data, headers=headers, query=query)
-        'md5': '5b0c4cc1b3c1ba15dda7344085aa5592',
+        'md5': 'dcc5a425e79f2564148652616af1f2a3',
-            'id': '2842601850001',
+            'id': '0_qbqx90ic',
-            'title': 'Introduction',
+            'title': 'Introduction to Hadoop Fundamentals LiveLessons',
-            raise ExtractorError('Could not extract Brightcove URL from %s' % url, expected=True)
+        webpage = self._download_webpage(url, '%s/%s' % (course_id, part))
-        return self.url_result(smuggle_url(bc_url, {'Referer': url}), 'BrightcoveLegacy')
+        return self.url_result(update_url_query('https://cdnapisec.kaltura.com/html5/html5lib/v2.37.1/mwEmbedFrame.php', {
-                    kaltura:(?P<partner_id_s>\d+):(?P<id_s>[0-9a-z_]+)|
+                    kaltura:(?P<partner_id>\d+):(?P<id>[0-9a-z_]+)|
-                                (?:[^/]+/)*?entry_id/(?P<id>[0-9a-z_]+)|
+                                index\.php/kwidget|
-                                .*\?.*\bwid=_(?P<partner_id_html5>\d+)
+                                html5/html5lib/[^/]+/mwEmbedFrame\.php
-                        )
+                        )(?:/(?P<path>[^?]+))?(?:\?(?P<query>.*))?
-        info, flavor_assets = self._get_video_info(entry_id, partner_id)
+        partner_id, entry_id = mobj.group('partner_id', 'id')
-                    content_type = mime_type.split('/')[0] if mime_type else representation_attrib.get('contentType')
+                    # According to page 41 of ISO/IEC 29001-1:2014, @mimeType is mandatory
-                            'ext': codec2ext(representation_attrib.get('codecs')),
+                            'ext': mimetype2ext(mime_type),
-            'duration': 2245.72
+            'duration': 2245.72,
-        title = self._og_search_title(webpage)
+        clip = None
-        download_url = self._og_search_property('audio', webpage, 'url')
+        duration = float_or_none(from_clip('duration') or self._html_search_meta(
-            'weibo:audio:duration', webpage, fatal=False))
+        uploader = from_clip('author') or self._og_search_property(
-            'description': self._og_search_description(webpage),
+            'description': description,
-                            [^/]+/posts/
+                            [^/]+/posts/|
-                for video_id in self._parse_json(
+                self.url_result('facebook:%s' % vid, FacebookIE.ie_key())
-        enc_key = '6ab6d0280511493ba85594779759d4ed'
+        enc_key = '8ed797d224d043e7ac23d95b70227d32'
-        BEFORE = '{swf.addParam(param[0], param[1]);});\n'
+        BEFORE = '{swf.addParam(param[0], param[1]);});'
-        m = re.search(re.escape(BEFORE) + '(.*?)' + re.escape(AFTER), webpage)
+        m = re.search(re.escape(BEFORE) + '(?:\n|\\\\n)(.*?)' + re.escape(AFTER), webpage)
-            data = dict(json.loads(m.group(1)))
+            swf_params = m.group(1).replace('\\\\', '\\').replace('\\"', '"')
-                r'handleServerJS\(({.+})\);', webpage, 'server js data'), video_id)
+                r'handleServerJS\(({.+})\);', webpage, 'server js data', default='{}'), video_id)
-)
+from .facebook import FacebookIE
-                            [^/]+/videos/(?:[^/]+/)?
+                            [^/]+/videos/(?:[^/]+/)?|
-        req = sanitized_Request('https://www.facebook.com/video/video.php?v=%s' % video_id)
+    def _extract_from_url(self, url, video_id, fatal_if_no_video=True):
-        return {
+        info_dict = {
-    }
+        return webpage, info_dict
-        post_id = self._match_id(url)
+        video_id = self._match_id(url)
-        webpage = self._download_webpage(url, post_id)
+        if info_dict:
-                post_id)]
+        if '/posts/' in url:
-        return self.playlist_result(entries, post_id)
+            return self.playlist_result(entries, video_id)
-
+        assertRegexpMatches(self, ydl._format_note({
-            res += ', %sfps' % fdict['fps']
+            if res:
-        /?(?:[?&].*)?(?:[#].*)?$'''
+                    https?://
-                '%s%s?v=3.0.3&fp=WIN%%2014,0,0,145' % (base, vn.attrib['src']))
+                update_url_query(compat_urlparse.urljoin(base, vn.attrib['src']), {
-            return self._extract_from_json_url(json_url, video_id, lang)
+            title = self._search_regex(
-    def _extract_from_json_url(self, json_url, video_id, lang):
+    def _extract_from_json_url(self, json_url, video_id, lang, title=None):
-        title = player_info['VTI'].strip()
+        title = (player_info.get('VTI') or title or player_info['VID']).strip()
-        # Differend kind of embed URL (e.g.
+        # Different kind of embed URL (e.g.
-            r'"sources":\s*\[([^\]]+)\]', webpage, 'format string')
+        jwvideo = self._parse_json(
-        } for fmt in re.findall(r'"file":"([^"]+)","label":"([^"]+)"', quality_arr)]
+            'url': source['file'].replace('\\', ''),
-            webpage, 'thumbnail', fatal=False)
+        thumbnail = jwvideo.get('image')
-            'description': 'md5:c5ed8625eb386855d5a7967bd7b77a54',
+            'description': 'md5:2b75327061310a3afb3fbd7d09e2e403',
-            r'sources:\s*\[([^\]]+)\]', webpage, 'forrmat string')
+            r'"sources":\s*\[([^\]]+)\]', webpage, 'format string')
-            r'image:\s*"([^"]+)"',
+            r'"image":\s*"([^"]+)"',
-                                 "m3u8", or "m3u8_native".
+                                 "m3u8", "m3u8_native" or "http_dash_segments".
-        headers = std_headers
+        headers = std_headers.copy()
-            self._LOGIN_URL, None,
+            login_page_request, None,
-__version__ = '2016.03.01'
+__version__ = '2016.03.06'
-        headers = std_headers
+        headers = std_headers.copy()
-        request = sanitized_Request(url, None, headers)
+        request = sanitized_Request(url, headers=headers)
-                state['speed'] = s.get('speed')
+                state['speed'] = s.get('speed') or ctx.get('speed')
-                                    info_dict['id'], stretched_ratio))
+                                '%s: Non-uniform pixel ratio (%s). %s'
-                if info_dict.get('requested_formats') is None and info_dict.get('container') == 'm4a_dash':
+                if (info_dict.get('requested_formats') is None and
-                            info_dict['id']))
+                        self.report_warning(
-                                    info_dict['id']))
+                                '%s: writing DASH m4a. '
-                if info_dict.get('protocol') == 'm3u8_native' or info_dict.get('protocol') == 'm3u8' and self.params.get('hls_prefer_native', False):
+                if (info_dict.get('protocol') == 'm3u8_native' or
-                                    info_dict['id']))
+                                '%s: malformated aac bitstream. %s'
-                if info_dict.get('protocol') == 'm3u8_native' or info_dict.get('protocol') == 'm3u8' and self._downloader.params.get('hls_prefer_native', False):
+                if info_dict.get('protocol') == 'm3u8_native' or info_dict.get('protocol') == 'm3u8' and self.params.get('hls_prefer_native', False):
-            'ext': 'mp4',
+            'ext': 'webm',
-        'md5': '7021db7f2d47d4fff89b13177cb1e8f4',
+        'md5': '7b391cce85e758fb94f763ddc1bbb979',
-            'ext': 'mp4',
+            'ext': 'webm',
-                'ext': 'mp4',
+                'ext': 'webm',
-            'md5': 'de317418c8bc76b1fd8633e4f32acbc6',
+            'md5': '520915673e53a5c5d487c36e0c4d85b5',
-                'ext': 'mp4',
+                'ext': 'webm',
-                'uploader': 'NextDayVideo',
+                'uploader': 'Next Day Video',
-            'ext': 'mp4',
+            'ext': 'webm',
-        'md5': '216d1afdc0c64d1febc1e9f2bd4b864b',
+        'md5': '63f8600c1da6f01b7640eee7eca4f1da',
-            'ext': 'mp4',
+            'ext': 'webm',
-            'duration': 607,
+            'duration': 606,
-                'ext': 'mp4',
+                'ext': 'webm',
-                'duration': 179,
+                'duration': 178,
-            'ext': 'mp4',
+            'ext': 'webm',
-            'md5': 'df4cf8a1dcedaec79a73d96d83b99023',
+            'md5': 'ec9838a5520ef5409b3e4e42fcb0a3b9',
-                'ext': 'mp4',
+                'ext': 'webm',
-            'md5': '6eb30961fa795fedc750eac4881ad2e1',
+            'md5': '7393c4e0f54602ad110c793eb7a6513a',
-                'ext': 'mp4',
+                'ext': 'webm',
-                'uploader': 'Cinemassacre Extras',
+                'uploader': 'Cinemassacre Extra',
-            }
+            },
-        metadata = self.get_metadata('%s/%s' % (mpx_account, list(vdata['files'].values())[0]), video_id)
+        metadata = self.get_metadata('kYEXFC/%s' % list(vdata['files'].values())[0], video_id)
-            release_url = 'http://link.theplatform.com/s/%s/%s?format=SMIL&mbr=true' % (mpx_account, vid)
+            release_url = 'http://link.theplatform.com/s/kYEXFC/%s?format=SMIL&mbr=true' % vid
-                    /
+                    /?
-                'ext': 'mov',
+                'ext': 'mp4',
-            }
+            },
-            r'data-src="(/contenu/medias/video.php.*?)"',
+            r'data-src(?:set-video)?="(/contenu/medias/video.php.*?)"',
-            'id': '73034',
+            'id': '71089',
-            'id': '60163',
+            'id': '58227',
-            'id': '73573',
+            'id': '71618',
-                'id': video_id,
+                'id': page_id,
-                    'http://%s%s' % (domain, episode['path'])) for episode in episodes_data])
+                entries.extend([{
-                    template_dict['resolution'] = '?x%d' % template_dict['width']
+                    template_dict['resolution'] = '%dx?' % template_dict['width']
-        if page_type == 'episode' or page_type == 'embed':
+        if page_type in ('episode', 'embed'):
-            show_data = page_info['show']['data']
+            list_data = page_info[page_type]['data']
-                    'http://%s/%s/%s' % (domain, display_id, episode['slug'])) for episode in episodes_data])
+                    'http://%s%s' % (domain, episode['path'])) for episode in episodes_data])
-                show_data.get('name'), show_data.get('summary'))
+                entries, compat_str(list_data['id']),
-            video_id = compat_str(episode_data['video']['data']['id'])
+        page_data = page_info['data']
-                'display_id': display_id,
+            info.update({
-            }
+            })
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r'var url_cache = "([^"]+)";', webpage, 'URL prefix')
+            r'var\s+url_cache\s*=\s*"([^"]+)";', webpage, 'URL prefix')
-            r"URLMediaFile = url_cache \+ '([^']+)'", webpage, 'video URL')
+            r"(?:URLMediaFile|urlVideo_\d+)\s*=\s*url_cache\s*\+\s*'([^']+)'", webpage, 'video URL')
-            fatal=False)
+            r"(?:URLMediaStill|urlFotogramaFijo_\d+)\s*=\s*url_cache\s*\+\s*'([^']+)'",
-            '<h2 class="entry-header entry-title.*?>(.*?)</h2>',
+            (r"tituloVideo\s*=\s*'([^']+)'", webpage, 'title',
-        date_str = self._search_regex(
+        upload_date = unified_strdate(self._search_regex(
-        upload_date = (None if date_str is None else unified_strdate(date_str))
+            webpage, 'upload date', default=None) or self._html_search_meta(
-                })
+            _search_dimensions_in_video_url(f, video_url)
-            r'sources\s*:\s*({.+?})', webpage, 'sources', default=None)
+            r'(?s)sources\s*:\s*({.+?})', webpage, 'sources', default=None)
-            mobj = re.search(r'/(?P<height>\d{3,4})[pP]_(?P<bitrate>\d+)[kK]_\d+/', video_url)
+            mobj = re.search(r'(?P<height>\d{3,4})[pP]_(?P<bitrate>\d+)[kK]_\d+/', video_url)
-        'md5': 'af5f90dc9c7ba1c19d0a3eac806bbf50',
+        'md5': '6a5cd403418c7b01719248ca97fb0692',
-            'ext': 'mp4',
+            'ext': 'webm',
-            'ext': 'flv',
+            'ext': 'mp4',
-    _VALID_URL = r'https?://(?:www\.)?audimedia\.tv/(?:en|de)/vid/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?audi-mediacenter\.com/(?:en|de)/audimediatv/(?P<id>[^/?#]+)'
-        'url': 'https://audimedia.tv/en/vid/60-seconds-of-audi-sport-104-2015-wec-bahrain-rookie-test',
+        'url': 'https://www.audi-mediacenter.com/en/audimediatv/60-seconds-of-audi-sport-104-2015-wec-bahrain-rookie-test-1467',
-        raw_payload = self._search_regex(r'<script[^>]+class="amtv-embed"[^>]+id="([^"]+)"', webpage, 'raw payload')
+        raw_payload = self._search_regex([
-                formats.append({
+                f = {
-                })
+                }
-            'duration': 231,
+            'duration': 231.0,
-            xpath_text(doc, 'rfc822creationdate', fatal=False))
+        video_title = xpath_text(doc, 'HEADLINE', fatal=True)
-                'vbr': float_or_none(quality.attrib.get('bitratebits'), scale=1024),
+                'vbr': float_or_none(quality.attrib.get('bitratebits'), scale=1000),
-class YandexMusicTrackIE(InfoExtractor):
+class YandexMusicBaseIE(InfoExtractor):
-class YandexMusicPlaylistBaseIE(InfoExtractor):
+class YandexMusicPlaylistBaseIE(YandexMusicBaseIE):
-from ..utils import int_or_none
+from ..utils import (
-            'duration': 231000,
+            'duration': 231,
-            'duration': 231000,
+            'duration': 231.0,
-                                               'clipId')
+        webpage = self._download_webpage(url, video_id)
-                                 errnote='Failed to download video info')
+        if clip_id is None:
-        description = doc.find('ABSTRACT')
+        affiliate_id = self._search_regex(
-                })
+            formats.append({
-from .aol import AolIE
+from .aol import (
-    '''
+    _VALID_URL = r'(?:aol-video:|http://on\.aol\.com/video/.*-)(?P<id>[0-9]+)(?:$|\?)'
-            return self.url_result('5min:%s' % video_id)
+        video_id = self._match_id(url)
-            playlist_html)]
+class AolFeaturesIE(InfoExtractor):
-        }
+    _TESTS = [{
-        '''
+    _VALID_URL = r'https?://www.engadget.com/video/(?P<id>\d+)'
-        'url': 'http://www.engadget.com/video/5min/518153925/',
+        'url': 'http://www.engadget.com/video/518153925/',
-            }
+        return self.url_result('5min:%s' % video_id)
-        '''
+    _VALID_URL = r'(?:5min:(?P<id>\d+)(?::(?P<sid>\d+))?|https?://[^/]*?5min\.com/Scripts/PlayerSeed\.js\?(?P<query>.*))'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        })
+        if not sid:
-            'https://syn.5min.com/handlers/SenseHandler.ashx?' + query,
+            'https://syn.5min.com/handlers/SenseHandler.ashx?' +
-            elif rendition['RenditionType'] == 'aac':
+            if rendition['RenditionType'] == 'aac' or rendition['RenditionType'] == 'm3u8':
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-        'playlist_mincount': 7
+        # This series is moved to http://www.le.com/tv/10005297.html
-                'format_id': int_or_none(play_url.get('vtype')),
+                'format_id': str_or_none(play_url.get('vtype')),
-            'description': 'md5:c93d6692dde6fe33809a46edcbecca44',
+            'description': 'md5:f34981259a03e980a3c6404190a3ed61',
-        }
+        },
-        }
+        },
-        base = base_ele.get('content') if base_ele else 'http://livestreamvod-f.akamaihd.net/'
+        base = base_ele.get('content') if base_ele is not None else 'http://livestreamvod-f.akamaihd.net/'
-        tags = [tag['title'] for tag in video.get('tags', [])]
+        tags = [tag['title'] for tag in video.get('tags') or []]
-
+def update_url_query(url, query):
-                offset = 0
+                offset = total
-    _PAGE_LIMIT = 10
+    _PAGE_LIMIT = 100
-            [self.url_result(entry) for entry in set(entries)],
+            [self.url_result(entry) for entry in orderedSet(entries)],
-    _PAGE_LIMIT = 100
+    _PAGE_LIMIT = 10
-                channel_id, 'Downloading %s videos JSON page %d' % (self._PLAYLIST_TYPE, counter))
+                channel_id,
-        self.port = self.httpd.socket.getsockname()[1]
+        if os.name == 'java':
-from youtube_dl.utils import (
+from youtube_dl.compat import (
-    if sys.stderr.isatty() and os.name != 'nt':
+    if sys.stderr.isatty() and compat_os_name != 'nt':
-
+    compat_os_name,
-        if os.name == 'nt' and ctypes.windll.kernel32.GetConsoleWindow():
+        if compat_os_name == 'nt' and ctypes.windll.kernel32.GetConsoleWindow():
-            if not self.params.get('no_color') and self._err_file.isatty() and os.name != 'nt':
+            if not self.params.get('no_color') and self._err_file.isatty() and compat_os_name != 'nt':
-        if not self.params.get('no_color') and self._err_file.isatty() and os.name != 'nt':
+        if not self.params.get('no_color') and self._err_file.isatty() and compat_os_name != 'nt':
-    if os.name == 'posix':
+    if compat_os_name == 'posix':
-    elif os.name == 'nt' or os.name == 'ce':
+    elif compat_os_name == 'nt' or compat_os_name == 'ce':
-            if os.name == 'nt':
+            if compat_os_name == 'nt':
-            if os.name == 'nt':
+            if compat_os_name == 'nt':
-        if not self._downloader.params.get('no_color') and os.name != 'nt' and sys.stderr.isatty():
+        if not self._downloader.params.get('no_color') and compat_os_name != 'nt' and sys.stderr.isatty():
-            if os.name == 'nt':
+            if compat_os_name == 'nt':
-                if os.name == 'nt':
+                if compat_os_name == 'nt':
-        qs = compat_urlparse.parse_qs(parsed_url.query)
+        qs = compat_parse_qs(parsed_url.query)
-        media_info = config.get('status', {}).get('entities', [{}])[0].get('mediaInfo', {})
+        media_info = None
-                    'url': self._get_vmap_video_url(vmap_url, video_id),
+        webpage = self._download_webpage(url, video_id)
-                break   # same video regardless of UA
+            formats.append(f)
-            video_url = config['playlist'][0]['source']
+            playlist = config.get('playlist')
-            }
+                f = {
-                    'height': int(m.group('height')),
+            vmap_url = config.get('vmapUrl') or config.get('vmap_url')
-            formats.append(f)
+                break   # same video regardless of UA
-        duration = float_or_none(config.get('duration'))
+        duration = float_or_none(config.get('duration')) or duration
-        # MD5 checksums are different in different places
+        'params': {
-    _VALID_URL = r'https?://(?:www\.)?twitter\.com/i/cards/tfw/v1/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?twitter\.com/i/(?:cards/tfw/v1|videos/tweet)/(?P<id>\d+)'
-                'title': 'TwitterCard',
+                'title': 'Twitter Card',
-                'title': 'TwitterCard',
+                'title': 'Twitter Card',
-        }
+        }, {
-                r'data-player-config="([^"]+)"', webpage, 'data player config'),
+                r'data-(?:player-)?config="([^"]+)"', webpage, 'data player config'),
-                if 'vmapUrl' in config:
+                vmap_url = config.get('vmapUrl') or config.get('vmap_url')
-                        'url': self._get_vmap_video_url(config['vmapUrl'], video_id),
+                        'url': self._get_vmap_video_url(vmap_url, video_id),
-        thumbnail = config.get('posterImageUrl')
+        title = self._search_regex(r'<title>([^<]+)</title>', webpage, 'title')
-            'title': 'TwitterCard',
+            'title': title,
-            raise ExtractorError(error_msg, expected=True)
+        error_element = find_xpath_attr(
-    LetvPlaylistIE,
+from .leeco import (
-class LetvIE(InfoExtractor):
+class LeIE(InfoExtractor):
-class LetvPlaylistIE(InfoExtractor):
+class LePlaylistIE(InfoExtractor):
-        return False if LetvIE.suitable(url) else super(LetvPlaylistIE, cls).suitable(url)
+        return False if LeIE.suitable(url) else super(LePlaylistIE, cls).suitable(url)
-        entries = [self.url_result(LetvIE._URL_TEMPLATE % media_id, ie='Letv')
+        entries = [self.url_result(LeIE._URL_TEMPLATE % media_id, ie='Le')
-    _VALID_URL = r'http://www\.le\.com/tv/(?P<id>\d+)\.html'
+class LetvPlaylistIE(InfoExtractor):
-    _TESTS = [{
+    }, {
-    _VALID_URL = r'http://www\.le\.com/ptv/vplay/(?P<id>\d+).html'
+    _VALID_URL = r'http://www\.le\.com/ptv/vplay/(?P<id>\d+)\.html'
-    _URL_TEMPLATE = r'http://www.le.com/ptv/vplay/%s.html'
+    _URL_TEMPLATE = 'http://www.le.com/ptv/vplay/%s.html'
-    _VALID_URL = r'http://www.le.com/tv/(?P<id>\d+).html'
+    _VALID_URL = r'http://www\.le\.com/tv/(?P<id>\d+)\.html'
-            r'http://www.letv.com/ptv/vplay/(\d+).html', page))
+            r'http://www\.letv\.com/ptv/vplay/(\d+)\.html', page))
-    _VALID_URL = r'http://tv.le.com/[a-z]+/(?P<id>[a-z]+)/index.s?html'
+    _VALID_URL = r'http://tv\.le\.com/[a-z]+/(?P<id>[a-z]+)/index\.s?html'
-    compat_urllib_parse,
+    compat_urllib_parse,
-    orderedSet,
+    orderedSet,
-            r'http://www.letv.com/ptv/vplay/(\d+).html', page)))
+        media_ids = orderedSet(re.findall(
-    _VALID_URL = r'http://www\.letv\.com/ptv/vplay/(?P<id>\d+).html'
+    _VALID_URL = r'http://www\.le\.com/ptv/vplay/(?P<id>\d+).html'
-        'url': 'http://www.letv.com/ptv/vplay/22005890.html',
+        'url': 'http://www.le.com/ptv/vplay/22005890.html',
-        'url': 'http://www.letv.com/ptv/vplay/1415246.html',
+        'url': 'http://www.le.com/ptv/vplay/1415246.html',
-        'url': 'http://www.letv.com/ptv/vplay/1118082.html',
+        'url': 'http://www.le.com/ptv/vplay/1118082.html',
-            'domain': 'www.letv.com'
+            'domain': 'www.le.com'
-            'http://api.letv.com/mms/out/video/playJson?' + compat_urllib_parse.urlencode(params)
+            'http://api.le.com/mms/out/video/playJson?' + compat_urllib_parse.urlencode(params)
-    _VALID_URL = r'http://www.letv.com/tv/(?P<id>\d+).html'
+    _VALID_URL = r'http://www.le.com/tv/(?P<id>\d+).html'
-        'url': 'http://www.letv.com/tv/46177.html',
+        'url': 'http://www.le.com/tv/46177.html',
-                   for media_url in media_urls]
+        # Currently old domain names are still used in playlists
-    _VALID_URL = r'http://tv.letv.com/[a-z]+/(?P<id>[a-z]+)/index.s?html'
+    _VALID_URL = r'http://tv.le.com/[a-z]+/(?P<id>[a-z]+)/index.s?html'
-        'url': 'http://tv.letv.com/izt/wuzetian/index.html',
+        'url': 'http://tv.le.com/izt/wuzetian/index.html',
-        'url': 'http://tv.letv.com/pzt/lswjzzjc/index.shtml',
+        'url': 'http://tv.le.com/pzt/lswjzzjc/index.shtml',
-        video_uploader_id = config['video']['owner']['url'].split('/')[-1] if config['video']['owner']['url'] else None
+        # Extract uploader, uploader_url and uploader_id
-        mobj = re.search(r'<link itemprop="url" href="http://www.youtube.com/(?:user|channel)/([^"]+)">', video_webpage)
+        video_uploader_url = None
-            video_uploader_id = mobj.group(1)
+            video_uploader_id = mobj.group('uploader_id')
-                'description': 'md5:782e8651347686cba06e58f71ab51773',
+                'description': 'md5:f3ceb5ef83a08d95b9d146f973157cc8',
-                    })
+                    if len(spec) > 1:
-        '35': {'ext': 'flv', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'tbr': 1280},
+        '5': {'ext': 'flv', 'width': 400, 'height': 240, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},
-        '45': {'ext': 'webm', 'width': 1280, 'height': 720, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'tbr': 3192},
+        '36': {'ext': '3gp', 'width': 320, 'acodec': 'aac', 'vcodec': 'mp4v'},
-        '78': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'tbr': 1280},
+        '59': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
-        '85': {'ext': 'mp4', 'height': 1080, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20, 'tbr': 6000},
+        '82': {'ext': 'mp4', 'height': 360, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},
-        '96': {'ext': 'mp4', 'height': 1080, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10, 'tbr': 6349.21875},
+        '92': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},
-        '160': {'ext': 'mp4', 'height': 144, 'format_note': 'DASH video', 'vcodec': 'h264', 'preference': -40, 'tbr': 91.796875},
+        '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'h264', 'preference': -40},
-        '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 256, 'preference': -50, 'container': 'm4a_dash', 'tbr': 320},
+        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 48, 'preference': -50, 'container': 'm4a_dash'},
-            if success:
+            if success and filename != '-':
-        '35': {'ext': 'flv', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
+        '5': {'ext': 'flv', 'width': 400, 'height': 240, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263', 'tbr': 320},
-        '45': {'ext': 'webm', 'width': 1280, 'height': 720, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},
+        '36': {'ext': '3gp', 'width': 320, 'acodec': 'aac', 'vcodec': 'mp4v', 'tbr': 256},
-        '78': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
+        '59': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'tbr': 1280},
-        '85': {'ext': 'mp4', 'height': 1080, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},
+        '82': {'ext': 'mp4', 'height': 360, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20, 'tbr': 800},
-        '96': {'ext': 'mp4', 'height': 1080, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},
+        '92': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10, 'tbr': 186.625},
-        '160': {'ext': 'mp4', 'height': 144, 'format_note': 'DASH video', 'vcodec': 'h264', 'preference': -40},
+        '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'h264', 'preference': -40, 'tbr': 261.71875},
-        '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 256, 'preference': -50, 'container': 'm4a_dash'},
+        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 48, 'preference': -50, 'container': 'm4a_dash', 'tbr': 32},
-from ..compat import compat_urlparse
+from ..compat import (
-    _VALID_URL = r'https?://(?:www\.)?nrk\.no/skole/klippdetalj?.*\btopic=nrk(?::|%3[Aa])klipp(?:/|%2[Ff])(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?nrk\.no/skole/klippdetalj?.*\btopic=(?P<id>[^/?#&]+)'
-        video_id = self._match_id(url)
+        video_id = compat_urllib_parse_unquote(self._match_id(url))
-    _VALID_URL = r'https?://(?:www\.)?nrk\.no/(?!video)(?:[^/]+/)+(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?nrk\.no/(?!video|skole)(?:[^/]+/)+(?P<id>[^/]+)'
-
+class FFmpegFixupM3u8PP(FFmpegPostProcessor):
-        for atype, a in data['assets'].items():
+        for a in data['assets']:
-        'md5': 'e1b50a5c5fb98a6a544250f2e0db570a',
+        # single video embedded via video/source
-            'id': '126342',
+            'id': '98736',
-            'upload_date': '20140130',
+            'title': 'ÐÑÐ¶ÑÐ¸Ð½Ð° Ð½Ð°ÑÐµÐ» Ð´Ð¾Ð¼Ð° Ð°ÑÑÐ¸Ð² Ð¾Ð±Ð¾ÑÐ¾Ð½Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð²Ð¾Ð´Ð°',
-        # video in <iframe>
+        # single video embedded via iframe
-        }
+        },
-        if not videos and not iframe_link:
+        video_urls = re.findall(
-        def make_entry(video_id, media, video_number=None):
+        def make_entry(video_id, video_url, index=None):
-                'title': title if video_number is None else '%s-video%s' % (title, video_number),
+                'id': video_id if not index else '%s-video%s' % (video_id, index),
-            })
+        def make_video_entry(video_id, video_url, index=None):
-            return [make_entry(video_id, media, video_number + 1) for video_number, media in enumerate(videos)]
+        if len(video_urls) == 1 and not iframe_links:
-    def get_enc_key(self, swf_url, video_id):
+    def get_enc_key(self, video_id):
-        enc_key = self.get_enc_key(swf_url, video_id)
+        enc_key = self.get_enc_key(video_id)
-__version__ = '2016.02.27'
+__version__ = '2016.03.01'
-    _VALID_URL = r'http://www\.rtve\.es/(?:deportes/directo|noticias|television)/(?P<id>[a-zA-Z0-9-]+)'
+    _VALID_URL = r'http://www\.rtve\.es/directo/(?P<id>[a-zA-Z0-9-]+)'
-        'url': 'http://www.rtve.es/noticias/directo-la-1/',
+        'url': 'http://www.rtve.es/directo/la-1/',
-            'title': 're:^La 1 de TVE [0-9]{4}-[0-9]{2}-[0-9]{2}Z[0-9]{6}$',
+            'id': 'la-1',
-        title = remove_end(self._og_search_title(webpage), ' en directo')
+        title = remove_end(self._og_search_title(webpage), ' en directo en RTVE.es')
-        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/default/videos/%s.png' % vidplayer_id
+            r'playerId=player([0-9]+)', webpage, 'internal video ID')
-        video_url = _decrypt_url(png)
+        m3u8_url = _decrypt_url(png)
-            'rtmp_live': True,
+            'formats': formats,
-    _VALID_URL = r'https?://(?:www\.)?(?:mdr|kika)\.de/(?:.*)/[a-z]+(?P<id>\d+)(?:_.+?)?\.html'
+    _VALID_URL = r'https?://(?:www\.)?(?:mdr|kika)\.de/(?:.*)/[a-z]+-?(?P<id>\d+)(?:_.+?)?\.html'
-            webpage, 'data url', group='url')
+            r'(?:dataURL|playerXml(?:["\'])?)\s*:\s*(["\'])(?P<url>\\?/.+/(?:video|audio)-?[0-9]+-avCustom\.xml)\1',
-            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8})\1',
+            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8})(?:#.*?)?\1',
-                format_label = source.get('label')
+                if not self._is_valid_url(file_, video_id, format_id or 'video'):
-        self._sort_formats(formats)
+        self._sort_formats(formats, field_preference=('height', 'width', 'tbr', 'format_id'))
-                formats.extend(self._extract_m3u8_formats(source['file'], video_id, ext='mp4'))
+            file_ = source.get('file')
-                    'url': source['file'],
+                    'url': file_,
-            }
+    _TESTS = [{
-            }
+        'params': {
-    ]
+    }]
-        title = self._og_search_title(webpage)
+        # Sometimes og:title meta is malformed
-__version__ = '2016.02.22'
+__version__ = '2016.02.27'
-    _VALID_URL = r'http://(?P<domain>it\.dplay\.com|www\.dplay\.(?:dk|se))/[^/]+/(?P<id>[^/?#]+)'
+    _VALID_URL = r'http://(?P<domain>it\.dplay\.com|www\.dplay\.(?:dk|se|no))/[^/]+/(?P<id>[^/?#]+)'
-# encoding: utf-8
+# coding: utf-8
-from ..compat import compat_urlparse
+
-    _VALID_URL = r'(?P<domain>http://(?:it|www)\.dplay\.(?:com|dk|se))/[^/]+/(?P<id>[^/?#]+)'
+    _VALID_URL = r'http://(?P<domain>it\.dplay\.com|www\.dplay\.(?:dk|se))/[^/]+/(?P<id>[^/?#]+)'
-            },
+    _TESTS = [{
-            },
+        'expected_warnings': ['Unable to download f4m manifest'],
-    ]
+    }, {
-        display_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        video_url = compat_urlparse.urljoin(domain, 'api/v2/ajax/videos?video_id=')
+        video_id = self._search_regex(
-        info = self._download_json(video_url + video_id,
+        info = self._download_json(
-                '{"countryCode":"%s","expiry":%d}' % (domain_tld.upper(), ((time.time() + 20 * 60) * 1000)))
+        title = info['title']
-            manifest_url = info['hls']
+        PROTOCOLS = ('hls', 'hds')
-            manifest_url, video_id, ext='mp4', entry_protocol='m3u8_native')
+        def extract_formats(protocol, manifest_url):
-            'duration': int_or_none(info.get('video_metadata_length'), scale=1000),
+            'title': title,
-
+from ..compat import compat_urlparse
-            'duration': 2650,
+    _VALID_URL = r'(?P<domain>http://(?:it|www)\.dplay\.(?:com|dk|se))/[^/]+/(?P<id>[^/?#]+)'
-    }
+        {
-            'http://www.dplay.se/api/v2/ajax/videos?video_id=' + video_id,
+        video_url = compat_urlparse.urljoin(domain, 'api/v2/ajax/videos?video_id=')
-            video_id, 'Getting manifest url for hls stream')['hls']
+        # get url's TLD to determine which cookie and url to use
-        age_limit = self._rta_search(webpage)
+        age_limit = self._rta_search(webpage) or 18
-        display_id = mobj.group('display_id')
+        display_id = mobj.group('display_id') if 'display_id' in mobj.groupdict() else video_id
-        quality = qualities(['SD', '480p', '720p'])
+        quality = qualities(('SD', '480p', '720p', '1080p'))
-        if '#EXT-X-TARGETDURATION' in m3u8_doc:
+
-                        f['acodec'] = va_codecs[1]
+                codecs = last_info.get('CODECS')
-
+def encode_base_n(num, n, table=None):
-    assert n <= len(FULL_TABLE)
+    if n > len(table):
-        base_n_count = base_n(count, base)
+        base_n_count = encode_base_n(count, base)
-)
+from ..compat import compat_urllib_parse_unquote
-class InfoQIE(InfoExtractor):
+class InfoQIE(BokeCCBaseIE):
-            formats = self._extract_bokecc_videos(webpage, video_id)
+            formats = self._extract_bokecc_formats(webpage, video_id)
-            encrypted_data = encrypted_data[1:]
+        _loc4_ = bytearray(2 * len(encrypted_data))
-            _loc4_ = _loc4_[2:]
+        _loc7_ = bytearray(len(encrypted_data))
-            caption_kind = original_lang_node.attrib.get('kind', '')
+            caption_url = args.get('ttsurl')
-                sub_lang = lang_node.attrib['lang_code']
+            for lang in caption_translation_languages.split(','):
-                        'kind': caption_kind,
+                    caption_qs.update({
-                        'url': caption_url + '&' + params,
+                        'url': sub_url,
-    base_n,
+    decode_packed_codes,
-        code = code.replace('\\\'', '\'')
+        code = decode_packed_codes(webpage).replace('\\\'', '\'')
-        r"'([^']+)',(\d+),(\d+),'([^']+)'\.split\('\|'\),[^,]+,{}",
+        r"}\('(.+)',(\d+),(\d+),'([^']+)'\.split\('\|'\)",
-from ..utils import sanitized_Request
+from ..utils import (
-    _WORKING = False
+
-            r'<source[^>]+?src="([^"]+)"', webpage, 'video URL')
+            r'"src"\s*,\s*"([^"]+)"', real_codes, 'video URL')
-    base_n,
+    decode_packed_codes,
-        self.decode_eval_codes()
+        self.sdk_code = decode_packed_codes(self.sdk_code)
-    base62,
+    base_n,
-            b62count = base62(count)
+            b62count = base_n(count, 62)
-    base36,
+    base_n,
-                code = re.sub(r'\b%s\b' % base36(count), symbols[count], code)
+                code = re.sub(r'\b%s\b' % base_n(count, 36), symbols[count], code)
-def base_n(num, n, table):
+def base_n(num, n, table=None):
-    def _parse_jwplayer_data(self, jwplayer_data, video_id):
+    def _parse_jwplayer_data(self, jwplayer_data, video_id, require_title=True):
-            if source_type == 'application/vnd.apple.mpegurl':
+            if source_type in ('application/vnd.apple.mpegurl', 'hls'):
-            'title': video_data['title'],
+            'title': video_data['title'] if require_title else video_data.get('title'),
-from ..utils import smuggle_url
+import re
-class VidziIE(InfoExtractor):
+
-        }
+        mobj = re.search(r"}\('(.+)',36,(\d+),'([^']+)'\.split\('\|'\)", webpage)
-        video_data = json_data['playlist'][0]
+class JWPlatformBaseIE(InfoExtractor):
-            b62count = self.base62(count)
+            b62count = base62(count)
-# coding: utf-8
+import re
-from ..utils import int_or_none
+from ..utils import (
-    ]
+    _VALID_URL = r'https?://(?:(?:www|v1)\.)?ustudio\.com/video/(?P<id>[^/]+)/(?P<display_id>[^/?#&]+)'
-        ]
+        mobj = re.match(self._VALID_URL, url)
-            'formats': formats,
+            'display_id': display_id,
-                fatal=False),
+            'thumbnails': extract('image'),
-            }
+    _TESTS = [{
-            'only_matching': True,
+        'skip': '404',
-    ]
+    }, {
-        '%b %dth %Y %I:%M%p',
+        '%b %dst %Y %I:%M',
-        categories = self._html_search_meta('keywords', webpage)
+        categories = self._html_search_meta('keywords', webpage, default=None)
-                            'preference': -10 if format_id == 'progressive' else 0,
+                            'preference': preference,
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            if k.startswith('url')]
+        formats = []
-                            )\?(?:.*?)(?:v|video_id)=|
+                                video/embed|
-    def __init__(self, pagefunc, pagesize):
+    def __init__(self, pagefunc, pagesize, use_cache=False):
-            page_results = list(self._pagefunc(pagenum))
+            page_results = None
-    parse_duration,
+    parse_duration,
-    _VALID_URL = r'https?://(?:watch\.|www\.)?nba\.com/(?P<path>(?:[^/]+/)?video/(?P<id>[^?]*?))/?(?:/index\.html)?(?:\?.*)?$'
+    _VALID_URL = r'https?://(?:watch\.|www\.)?nba\.com/(?P<path>(?:[^/]+/)+(?P<id>[^?]*?))/?(?:/index\.html)?(?:\?.*)?$'
-        video_id = xpath_text(video_info, 'slug')
+        video_id = os.path.splitext(xpath_text(video_info, 'slug'))[0]
-            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com|vidto\.me))/
+            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com|vidto\.me|powerwatch\.pw))/
-__version__ = '2016.02.13'
+__version__ = '2016.02.22'
-        return self.url_result(wat_info['media']['url'], 'Wat')
+        return self.url_result('wat:%s' % wat_id, 'Wat')
-    _VALID_URL = r'http://www\.wat\.tv/video/(?P<display_id>.*)-(?P<short_id>.*?)_.*?\.html'
+    _VALID_URL = r'(?:wat:(?P<real_id>\d{8})|http://www\.wat\.tv/video/(?P<display_id>.*)-(?P<short_id>.*?)_.*?\.html)'
-        real_id = self._search_regex(r'xtpage = ".*-(.*?)";', webpage, 'real id')
+        real_id = mobj.group('real_id')
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': self._og_search_thumbnail(webpage, default=None),
-                    embed_html = self._parse_json(program,video_id)
+                    embed_html = self._parse_json(program, video_id)
-
+            # Serves hd only via wigget/partnerplayer page
-            info = self._download_json(
+            video_info = self._download_json(
-            # videoInfo API may not work for some videos, fallback to portalplayer API
+
-                display_id, transform_source=js_to_json, fatal=False)
+                'http://player.pbs.org/%s/%s' % (page, video_id),
-                continue
+        for num, redirect in enumerate(redirects):
-                'Downloading %s video url info' % encoding_name)
+                '%s?format=json' % redirect['url'], display_id,
-                    'format_id': redirect.get('eeid'),
+                    'format_id': redirect_id,
-                (?:poster="(?P<poster>[^"]+)")?[^>]*>\s*
+            <video[^>]+class="animated-gif"(?P<more_info>[^>]+)>\s*
-                'thumbnail': mobj.group('poster'),
+                'height': height,
-        raise ExtractorError('There\'s not video in this tweet.')
+        raise ExtractorError('There\'s no video in this tweet.')
-            'url': video_url,
+            'formats': formats,
-            'md5': '4fa26a35f9d1bf4b646590ba8e84be19',
+            # MD5 checksums are different in different places
-            'md5': 'b6f35e8b08a0bec6c8af77a2f4b3a814',
+            'md5': 'd4724ffe6d2437886d004fa5de1043b3',
-                'title': 'Vine by @ArsenalTerje',
+                'uploader': 'ArsenalTerje',
-        'md5': 'db6612ec5d03355953c3ca9250c97e5e',
+        # MD5 checksums are different in different places
-from .twitter import TwitterCardIE, TwitterIE
+from .twitter import (
-class TwitterCardIE(InfoExtractor):
+class TwitterBaseIE(InfoExtractor):
-                        'url': video_url,
+                        'url': self._get_vmap_video_url(config['vmapUrl'], video_id),
-        'md5': '66a093339c1278bb3719157ef07107b2',
+        'md5': '2a9369bcccf847d1c741e51416299f25',
-        return self._extract_from_json_url(json_url, video_id, lang)
+                program = self._search_regex(
-    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions)/)?(?P<id>[^/]+)/(?P<name>[^/?#&+])'
+    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions|embed)/)?(?P<id>[^/]+)/(?P<name>[^/?#&+])'
-                    ext = SUBTITLES_TYPES[type_]
+            ext = textstream.get('ext') or determine_ext(src) or mimetype2ext(textstream.get('type'))
-                    'ext': 'srt' if mime == 'text/srt' else 'ttml',
+                    'ext': mimetype2ext(mime),
-        if info['ext'] == 'mp3':
+        if info['ext'] in ('mp3', 'mkv'):
-    import fcntl
+    # Some platforms, such as Jython, is missing fcntl
-        fcntl.flock(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)
+        def _lock_file(f, exclusive):
-        fcntl.flock(f, fcntl.LOCK_UN)
+        def _unlock_file(f):
-            if encoding:
+            if encoding is not None:
-        return hashlib.md5(text.encode('utf-8')).hexdigest()
+    def _rsa_fun(data):
-            return self.md5_text(t + mg + x)
+            return md5_text(t + mg + x)
-            'src': self.md5_text('youtube-dl'),
+            'src': md5_text('youtube-dl'),
-            'enc': self.md5_text(enc_key + tail),
+            'enc': md5_text(enc_key + tail),
-            'authkey': self.md5_text(self.md5_text('') + tail),
+            'authkey': md5_text(md5_text('') + tail),
-    _VALID_URL = r'https?://(?:www\.)?trailers\.apple\.com/(?:trailers|ca)/(?P<company>[^/]+)/(?P<movie>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.|movie)?trailers\.apple\.com/(?:trailers|ca)/(?P<company>[^/]+)/(?P<movie>[^/]+)'
-        start_time = info_dict.get('start_time', 0)
+        start_time = info_dict.get('start_time') or 0
-    if (info_dict.get('start_time') or info_dict.get('end_time')) and FFmpegFD.supports(info_dict):
+    if (info_dict.get('start_time') or info_dict.get('end_time')) and FFmpegFD.available() and FFmpegFD.supports(info_dict):
-        if ed.supports(info_dict):
+        if ed.available() and ed.supports(info_dict):
-            '38', '37', '46', '22', '45', '35', '44', '18', '34', '43', '6', '5', '36', '17', '13',
+            '38', '37', '46', '22', '45', '35', '44', '18', '34', '43', '6', '5', '17', '36', '13',
-        mediagen_url = itemdoc.find('%s/%s' % (_media_xml_tag('group'), _media_xml_tag('content'))).attrib['url']
+        content_el = itemdoc.find('%s/%s' % (_media_xml_tag('group'), _media_xml_tag('content')))
-            'duration': duration,
+            'duration': float_or_none(content_el.attrib.get('duration')),
-from .rtsp import RtspFD
+from .external import (
-    'rtsp': RtspFD,
+    'm3u8_native': HlsFD,
-        return NativeHlsFD
+        return HlsFD
-import os
+import os.path
-    """ A more limited implementation that does not require ffmpeg """
+class HlsFD(FragmentFD):
-            return False
+    int_or_none,
-        'md5': '882f488fa1f0026f023f33576004a2ed',
+        'md5': '1e19b41231a02eba417839222ac9d58e',
-            'age_limit': 18
+            'uploader': 'Babes',
-        video_title = self._html_search_regex(r'<h1 [^>]+>([^<]+)', webpage, 'title')
+        flashvars = self._parse_json(
-            thumbnail = compat_urllib_parse_unquote(thumbnail)
+            'duration': duration,
-            self.url_result('http://www.pornhub.com/%s' % video_url, 'PornHub')
+            self.url_result('http://www.pornhub.com/%s' % video_url, PornHubIE.ie_key())
-    }]
+class PornHubPlaylistBaseIE(InfoExtractor):
-        ]
+        entries = self._extract_entries(webpage)
-            r'href="http://videos?\.francetv\.fr/video/([^@]+@[^"]+)"',
+            r'(?:href=|player\.setVideo\(\s*)"http://videos?\.francetv\.fr/video/([^@]+@[^"]+)"',
-
+    def _check_download_just_video(self, url, playlist_id):
-    _VALID_URL = r'https?://www\.youtube\.com/(?:feed/watch_later|playlist\?list=WL)|:ytwatchlater'
+    _VALID_URL = r'https?://www\.youtube\.com/(?:feed/watch_later|(?:playlist|watch)\?(?:.+&)?list=WL)|:ytwatchlater'
-    _TESTS = []  # override PlaylistIE tests
+    _TESTS = [{
-    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
+    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions)/)?(?P<id>[^/]+)/(?P<name>[^/?#&+])'
-    _VALID_URL = r'https?://creative\.arte\.tv/(?P<lang>fr|de|en|es)/(?:magazine?/)?(?P<id>[^?#]+)'
+    _VALID_URL = r'https?://creative\.arte\.tv/(?P<lang>fr|de|en|es)/(?:magazine?/)?(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://future\.arte\.tv/(?P<lang>fr|de|en|es)/(?P<id>.+)'
+    _VALID_URL = r'https?://future\.arte\.tv/(?P<lang>fr|de|en|es)/(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://ddc\.arte\.tv/(?P<lang>emission|folge)/(?P<id>.+)'
+    _VALID_URL = r'https?://ddc\.arte\.tv/(?P<lang>emission|folge)/(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://concert\.arte\.tv/(?P<lang>fr|de|en|es)/(?P<id>.+)'
+    _VALID_URL = r'https?://concert\.arte\.tv/(?P<lang>fr|de|en|es)/(?P<id>[^/?#&]+)'
-    _VALID_URL = r'https?://(?:www\.)?arte\.tv/magazine/(?P<name>.*?)/(?P<lang>fr|de)/(?P<id>.*?)'
+    _VALID_URL = r'https?://(?:www\.)?arte\.tv/magazine/[^/]+/(?P<lang>fr|de|en|es)/(?P<id>[^/?#&]+)'
-        },
+        'only_matching': True,
-from ..utils import parse_duration
+from ..utils import (
-        closed_caption_e = smil.find(self._xpath_ns('.//param[@name=\'ClosedCaptionURL\']', namespace))
+        closed_caption_e = find_xpath_attr(smil, self._xpath_ns('.//param', namespace), 'name', 'ClosedCaptionURL')
-            webpage, 'view count', fatal=False))
+        view_count_str = self._search_regex(
-                video_id, 'mp4', m3u8_id='hls'))
+                video_id, 'mp4', m3u8_id='hls', fatal=False))
-                '%s/manifest.f4m' % mobj.group('src'), video_id, f4m_id='hds'))
+                '%s/manifest.f4m' % mobj.group('src'),
-            upload_date_str = player_info.get('VDA', '').split(' ')[0]
+            upload_date_str = (player_info.get('VRA') or player_info.get('VDA') or '').split(' ')[0]
-                iframe_url= find_iframe_url(embed_html)
+                iframe_url = find_iframe_url(embed_html)
-                    else -10))
+            langcode = LANGS.get(lang, lang)
-                if re.match(r'VO-ST(F|A)', versionCode):
+                if re.match(r'VO-ST(F|A|E)', versionCode):
-                elif re.match(r'VO?(F|A)-STM\1', versionCode):
+                elif re.match(r'VO?(F|A|E)-STM\1', versionCode):
-    _VALID_URL = r'http://videos\.arte\.tv/(?P<lang>fr|de)/.*-(?P<id>.*?)\.html'
+    _VALID_URL = r'http://videos\.arte\.tv/(?P<lang>fr|de|en|es)/.*-(?P<id>.*?)\.html'
-    _VALID_URL = r'https?://creative\.arte\.tv/(?P<lang>fr|de)/(?:magazine?/)?(?P<id>[^?#]+)'
+    _VALID_URL = r'https?://creative\.arte\.tv/(?P<lang>fr|de|en|es)/(?:magazine?/)?(?P<id>[^?#]+)'
-    _VALID_URL = r'https?://future\.arte\.tv/(?P<lang>fr|de)/(?P<id>.+)'
+    _VALID_URL = r'https?://future\.arte\.tv/(?P<lang>fr|de|en|es)/(?P<id>.+)'
-    _VALID_URL = r'https?://concert\.arte\.tv/(?P<lang>de|fr)/(?P<id>.+)'
+    _VALID_URL = r'https?://concert\.arte\.tv/(?P<lang>fr|de|en|es)/(?P<id>.+)'
-    _VALID_URL = r'https?://cinema\.arte\.tv/(?P<lang>de|fr)/(?P<id>.+)'
+    _VALID_URL = r'https?://cinema\.arte\.tv/(?P<lang>fr|de|en|es)/(?P<id>.+)'
-                iframe_url = find_iframe_url(player['html'])
+                    r'arte_vp_url_oembed=\'([^\']+?)\'', webpage, 'embed url', default=None)
-    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
+    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de|en|es)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
-            for _, video_id in re.findall(r'data-plid=(["\'])(.+?)\1', html):
+            for video_id in orderedSet([video_id for _, video_id in re.findall(
-    _TEST = {
+    _VALID_URL = r'(?:xtube:|https?://(?:www\.)?xtube\.com/(?:watch\.php\?.*\bv=|video-watch/(?P<display_id>[^/]+)-))(?P<id>[^/?&#]+)'
-    }
+    }, {
-             r'By:\s*<a href="/community/profile\.php\?user=([^"]+)'],
+        mobj = re.match(self._VALID_URL, url)
-            r'<span class="bold">Views:</span> ([\d,\.]+)</p>',
+        description = self._search_regex(
-            r'<div id="commentBar">([\d,\.]+) Comments</div>',
+            r'>Comments? \(([\d,\.]+)\)<',
-            'description': video_description,
+            'display_id': display_id,
-            for item in server_js_data['instances']:
+            for item in server_js_data.get('instances', []):
-            # available. We can grabbing them assuming bitrates to be default.
+            # media list will be empty. However, hds and hls uris are still
-    _VALID_URL = r'https?://(?:www\.)?youtube\.com/results\?(.*?&)?search_query=(?P<query>[^&]+)(?:[&]|$)'
+    _VALID_URL = r'https?://(?:www\.)?youtube\.com/results\?(.*?&)?(?:search_query|q)=(?P<query>[^&]+)(?:[&]|$)'
-)
+from .common import InfoExtractor
-    _VALID_URL = r'http://www.screenjunkies.com/video/(.+-(?P<id>\d+)|.+)'
+class ScreenJunkiesIE(InfoExtractor):
-            'title': "Honest Trailers - 'The Dark Knight'",
+            'title': "Honest Trailers: 'The Dark Knight'",
-        'only_matching': True,
+        'info_dict': {
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            video_id = self._html_search_regex(r'src="/embed/(\d+)"', webpage, 'video id')
+        if not video_id:
-        video_vars = self._parse_json(video_vars_str, video_id)
+        webpage = self._download_webpage(
-            raise ExtractorError('This video requires ScreenJunkiesPlus', expected=True)
+        title = embed_vars['contentName']
-            if not f['mediaPurpose'] == 'play':
+        bitrates = []
-
+            bitrate = int_or_none(f.get('bitRate'))
-                'tbr': int_or_none(f.get('bitRate')),
+                'tbr': bitrate,
-            'title': video_vars['contentName'],
+            'display_id': display_id,
-
+from .screenjunkies import ScreenJunkiesIE
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        
+
-                }]
+        subtitle_urls = data.get('subtitleUrls')
-from ..utils import ExtractorError
+from ..compat import (
-    def construct_video_urls(self, data, video_id, _uuid):
+    def _authenticate_vip_video(self, api_video_url, video_id, tvid, _uuid, do_report_warning):
-                    vl.split('/')[-1].split('.')[0], format_id, segment_index)
+                is_vip_video = '/vip/' in vl
-                base_url.insert(-1, key)
+                if not is_vip_video:
-                    compat_urllib_parse.urlencode(param)
+                api_video_url = base_url + vl
-            data, video_id, _uuid)
+            data, video_id, _uuid, tvid)
-# -*- coding: utf-8 -*-
+# coding: utf-8
-from ..utils import (
+from ..compat import (
-    xpath_text,
+    xpath_element,
-    _VALID_URL = r'https?://(?:www\.)?laola1\.tv/(?P<lang>[a-z]+)-(?P<portal>[a-z]+)/.*?/(?P<slug>[\w-]+)'
+    _VALID_URL = r'https?://(?:www\.)?laola1\.tv/(?P<lang>[a-z]+)-(?P<portal>[a-z]+)/[^/]+/(?P<slug>[^/?#&]+)'
-            'is_live': False,
+            'display_id': 'straubing-tigers-koelner-haie',
-            'is_live': False,
+            'display_id': 'straubing-tigers-koelner-haie',
-        webpage = self._download_webpage(url, mobj.group('slug'))
+        webpage = self._download_webpage(url, display_id)
-            webpage, 'iframe URL')
+            webpage, 'iframe url')
-            r'videoid=(\d+)', iframe_url, 'video ID')
+            r'videoid=(\d+)', iframe_url, 'video id')
-            url, iframe_url), video_id, note='Downloading iframe')
+            url, iframe_url), display_id, 'Downloading iframe')
-        hd_doc = self._download_xml(xml_url, video_id)
+            r'partnerid\s*:\s*(["\'])(?P<partner_id>.+?)\1',
-            categories = categories.split(',')
+        req = sanitized_Request(
-            token_url, video_id, note='Downloading token')
+        token_url = self._download_json(req, display_id)['data']['stream-access'][0]
-        if token_auth in ('blocked', 'restricted'):
+        if token_auth in ('blocked', 'restricted', 'error'):
-        video_url = '%s?hdnea=%s&hdcore=3.2.0' % (token_attrib['url'], token_auth)
+        formats = self._extract_f4m_formats(
-            'is_live': _v('islive') == 'true',
+            'display_id': display_id,
-            'upload_date': upload_date,
+            'upload_date': unified_strdate(_v('time_date')),
-import random
+    compat_urlparse,
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?laola1\.tv/(?P<lang>[a-z]+)-(?P<portal>[a-z]+)/.*?/(?P<slug>[\w-]+)'
-            'ext': 'mp4',
+            'is_live': False,
-    }
+    }]
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, mobj.group('slug'))
-            r'<iframe[^>]*?class="main_tv_player"[^>]*?src="([^"]+)"',
+            r'<iframe[^>]*?id="videoplayer"[^>]*?src="([^"]+)"',
-        flashvars = dict((m[0], m[1]) for m in flashvars_m)
+        video_id = self._search_regex(
-            r'partnerid\s*:\s*"([^"]+)"', iframe, 'partner id')
+            r'partnerid\s*:\s*"([^"]+)"', iframe, 'partner ID')
-        is_live = xpath_text(hd_doc, './/video/islive') == 'true'
+        _v = lambda x, **k: xpath_text(hd_doc, './/video/' + x, **k)
-        categories = xpath_text(hd_doc, './/video/meta_sports')
+        categories = _v('meta_sports')
-            flash_url, ident, flashvars['timestamp'], flashvars['auth'])
+        time_date = _v('time_date')
-        if token_attrib.get('auth') in ('blocked', 'restricted'):
+
-                'Token error: %s' % token_attrib.get('comment'), expected=True)
+                'Token error: %s' % token_attrib['comment'], expected=True)
-            token_attrib['url'], token_attrib['auth'])
+        video_url = '%s?hdnea=%s&hdcore=3.2.0' % (token_attrib['url'], token_auth)
-            'is_live': is_live,
+            'is_live': _v('islive') == 'true',
-            'ext': 'mp4',
+            'upload_date': upload_date,
-                    "[%s] playlist %s: Collected %d video ids (downloading %d of them)" %
+                    '[%s] playlist %s: Collected %d video ids (downloading %d of them)' %
-                    "[%s] playlist %s: Downloading %d videos" %
+                    '[%s] playlist %s: Downloading %d videos' %
-                    "[%s] playlist %s: Downloading %d videos" %
+                    '[%s] playlist %s: Downloading %d videos' %
-if __package__ is None and not hasattr(sys, "frozen"):
+if __package__ is None and not hasattr(sys, 'frozen'):
-            mediatype, data = data.split(",", 1)
+            scheme, data = url.split(':', 1)
-            if mediatype.endswith(";base64"):
+            if mediatype.endswith(';base64'):
-                mediatype = "text/plain;charset=US-ASCII"
+                mediatype = 'text/plain;charset=US-ASCII'
-                "Content-type: %s\nContent-length: %d\n" % (mediatype, len(data)))
+                'Content-type: %s\nContent-length: %d\n' % (mediatype, len(data)))
-                    raise ValueError("bad query field: %r" % (name_value,))
+                    raise ValueError('bad query field: %r' % (name_value,))
-            raise socket.error("getaddrinfo returns an empty list")
+            raise socket.error('getaddrinfo returns an empty list')
-            max_data_len = self.params.get("max_filesize")
+            min_data_len = self.params.get('min_filesize')
-            'title': "Winter Is Coming",
+            'title': 'Winter Is Coming',
-                'description': "Emma Willis and Marvin Humes present the fifth set of blind auditions in the singing competition, as the coaches continue to build their teams based on voice alone.",
+                'description': 'Emma Willis and Marvin Humes present the fifth set of blind auditions in the singing competition, as the coaches continue to build their teams based on voice alone.',
-            r"(?s)<h3>About</h3>(.+?)<h3>",
+            r'(?s)<h3>About</h3>(.+?)<h3>',
-            return "{3:02}:{2:02}:{1:02},{0:03}".format(*components)
+            return '{3:02}:{2:02}:{1:02},{0:03}'.format(*components)
-                m = re.match(r"^\s*([0-9]+);\s*([0-9]+)\s+([0-9]+)\s*$", line)
+                m = re.match(r'^\s*([0-9]+);\s*([0-9]+)\s+([0-9]+)\s*$', line)
-                    yield "{0} --> {1}".format(start, stop)
+                    yield '{0} --> {1}'.format(start, stop)
-        return "\r\n".join(_fix_subtitle(subtitles))
+        return '\r\n'.join(_fix_subtitle(subtitles))
-        "info_dict": {
+        'url': 'http://edition.cnn.com/video/?/video/us/2013/08/21/sot-student-gives-epic-speech.georgia-institute-of-technology&utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+rss%2Fcnn_topstories+%28RSS%3A+Top+Stories%29',
-            "upload_date": "20130821",
+            'title': "Student's epic speech stuns new freshmen",
-                "QueryString": "",
+            'getPlayerOptionsRequest': {
-                mMovieParams = [("http://media.mtvnservices.com/" + altMovieParams[0], altMovieParams[0])]
+                mMovieParams = [('http://media.mtvnservices.com/' + altMovieParams[0], altMovieParams[0])]
-        now_str = now.strftime("%Y-%m-%d %H:%M")
+        now_str = now.strftime('%Y-%m-%d %H:%M')
-        raise NotImplementedError("This method must be implemented by subclasses")
+        raise NotImplementedError('This method must be implemented by subclasses')
-        raise NotImplementedError("This method must be implemented by subclasses")
+        raise NotImplementedError('This method must be implemented by subclasses')
-        raise NotImplementedError("This method must be implemented by subclasses")
+        raise NotImplementedError('This method must be implemented by subclasses')
-        output += 'Title: %s\n' % sub_root.attrib["title"]
+        output += 'Title: %s\n' % sub_root.attrib['title']
-        output += 'PlayResY: %s\n' % sub_root.attrib["play_res_y"]
+        output += 'WrapStyle: %s\n' % sub_root.attrib['wrap_style']
-            output += ',' + style.attrib["encoding"]
+            output += 'Style: ' + style.attrib['name']
-            output += ',' + event.attrib["text"]
+            output += ',' + event.attrib['start']
-    IE_NAME = "crunchyroll:playlist"
+    IE_NAME = 'crunchyroll:playlist'
-            if info['Type'] == "Video":
+            if info['Type'] == 'Video':
-                elif file['Type'] == "Thumb":
+                elif file['Type'] == 'Thumb':
-                if file['Type'] == "Audio":
+            elif info['Type'] == 'Audio':
-                elif file['Type'] == "Thumb":
+                elif file['Type'] == 'Thumb':
-        "info_dict": {
+        'name': 'EightTracks',
-            "title": "youtube-dl test tracks \"'/\\Ã¤â­<>",
+            'description': "test chars:  \"'/\\Ã¤â­",
-        "playlist": [
+        'playlist': [
-                    "uploader_id": "ytdl"
+                'md5': '96ce57f24389fc8734ce47f4c1abcc55',
-                    "uploader_id": "ytdl"
+                'md5': '4ab26f05c1f7291ea460a3920be8021f',
-                    "uploader_id": "ytdl"
+                'md5': 'd30b5b5f74217410f4689605c35d1fd7',
-                    "uploader_id": "ytdl"
+                'md5': '4eb0a669317cd725f6bbd336a29f923a',
-                    "uploader_id": "ytdl"
+                'md5': '1893e872e263a2705558d1d319ad19e8',
-                    "uploader_id": "ytdl"
+                'md5': 'b673c46f47a216ab1741ae8836af5899',
-                    "uploader_id": "ytdl"
+                'md5': '1d74534e95df54986da7f5abf7d842b7',
-                    "uploader_id": "ytdl"
+                'md5': 'f081f47af8f6ae782ed131d38b9cd1c0',
-            return json.loads("[{" + json_string + "}]")
+            return json.loads('[{' + json_string + '}]')
-        "info_dict": {
+        'info_dict': {
-            "upload_date": "20081015"
+            'title': "Passion Pit - \"Sleepyhead\" (Official Music Video)",
-        info_url = "http://ex.fm/api/v3/song/%s" % song_id
+        info_url = 'http://ex.fm/api/v3/song/%s' % song_id
-            "http://video.fc2.com/ginfo.php?mimi={1:s}&href={2:s}&v={0:s}&fversion=WIN%2011%2C6%2C602%2C180&from=2&otag=0&upid={0:s}&tk=null&".
+            'http://video.fc2.com/ginfo.php?mimi={1:s}&href={2:s}&v={0:s}&fversion=WIN%2011%2C6%2C602%2C180&from=2&otag=0&upid={0:s}&tk=null&'.
-        "info_dict": {
+        'info_dict': {
-            "age_limit": 18,
+            'title': 'vysukany-zadecek-22033',
-            "age_limit": 18,
+            'title': 'Inyouchuu Etsu Bonus',
-        gcids = re.findall(r"http://.+?/.+?/(.+?)/", surls)
+        gcids = re.findall(r'http://.+?/.+?/(.+?)/', surls)
-            'description': "Happened on 27.7.2014. \r\nAt 0:53 you can see people still swimming at near beach.",
+            'description': 'Happened on 27.7.2014. \r\nAt 0:53 you can see people still swimming at near beach.',
-        format = "-".join(format)
+        format = '-'.join(format)
-            "title": "Absolute Mehrheit vom 17.02.2013 - Die Highlights, Teil 2",
+            'description': 'Wer kann in die Fu\u00dfstapfen von Wolfgang Kubicki treten und die Mehrheit der Zuschauer hinter sich versammeln? Wird vielleicht sogar die Absolute Mehrheit geknackt und der Jackpot von 200.000 Euro mit nach Hause genommen?',
-        feed = self._download_json(url, url, "Downloading NerdCubed JSON feed")
+        feed = self._download_json(url, url, 'Downloading NerdCubed JSON feed')
-            'url': "http://www.youtube.com/watch?v=" + feed_entry['youtube_id'],
+            'url': 'http://www.youtube.com/watch?v=' + feed_entry['youtube_id'],
-            "age_limit": 18
+            'uploader': 'Babes',
-            format = "-".join(format)
+            format = '-'.join(format)
-            webpage, "description", fatal=False, flags=re.DOTALL)
+            webpage, 'description', fatal=False, flags=re.DOTALL)
-        meta_url = "http://www.radiobremen.de/apps/php/mediathek/metadaten.php?id=%s" % video_id
+        meta_url = 'http://www.radiobremen.de/apps/php/mediathek/metadaten.php?id=%s' % video_id
-            r"<h1.*>(?P<title>.+)</h1>", meta_doc, "title")
+            r'<h1.*>(?P<title>.+)</h1>', meta_doc, 'title')
-            r"<p>(?P<description>.*)</p>", meta_doc, "description", fatal=False)
+            r'<p>(?P<description>.*)</p>', meta_doc, 'description', fatal=False)
-            meta_doc, "duration", fatal=False))
+            r'L&auml;nge:</td>\s+<td>(?P<duration>[0-9]+:[0-9]+)</td>',
-            'width': int(mobj.group("width")),
+            'width': int(mobj.group('width')),
-            "uploader": "Thomas HercouÃ«t",
+            'title': 'One to one',
-            "title": "Live at Primavera Sound 2011",
+            'uploader_id': 'ford-lopatin',
-            "thumbnail": "re:^https://gp1\.wac\.edgecastcdn\.net/.*?\.jpg$"
+            'id': '16965047',
-        "info_dict": {
+        'url': 'http://ringtv.craveonline.com/news/310833-luis-collazo-says-victor-ortiz-better-not-quit-on-jan-30',
-            "description": 'Luis Collazo is excited about his Jan. 30 showdown with fellow former welterweight titleholder Victor Ortiz at Barclays Center in his hometown of Brooklyn. The SuperBowl week fight headlines a Golden Boy Live! card on Fox Sports 1.',
+            'title': 'Video: Luis Collazo says Victor Ortiz "better not quit on Jan. 30" - Ring TV',
-        thumbnail_url = "http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/snapshots/%s.jpg" % video_id
+        final_url = 'http://ringtv.craveonline.springboardplatform.com/storage/ringtv.craveonline.com/conversion/%s.mp4' % video_id
-        feeds_url = self._html_search_meta("feeds-prefix", webpage, 'feeds url') + video_id
+        feeds_url = self._html_search_meta('feeds-prefix', webpage, 'feeds url') + video_id
-        rtmp_conn = ["S:connect", "O:1", "NS:pageUrl:" + url, "NB:fpad:0", "NN:videoFunction:1", "O:0"]
+        rtmp_conn = ['S:connect', 'O:1', 'NS:pageUrl:' + url, 'NB:fpad:0', 'NN:videoFunction:1', 'O:0']
-                        r"sources\s*:\s*(\[[^\]]+?\])", playerconfig,
+                        r'sources\s*:\s*(\[[^\]]+?\])', playerconfig,
-        ["arch", "", "http://ussenate-f.akamaihd.net/"]
+        ['ag', '76440', 'http://ag-f.akamaihd.net'],
-            "age_limit": 18,
+            'title': 'virginie baisee en cam',
-        video_url = "http://cdn.videos.snotr.com/%s.flv" % video_id
+        video_url = 'http://cdn.videos.snotr.com/%s.flv' % video_id
-                info_json_url += "&secret_token=" + token
+                info_json_url += '&secret_token=' + token
-        "playlist": [
+        'url': 'http://store.steampowered.com/video/105600/',
-                "info_dict": {
+                'md5': 'f870007cee7065d7c76b88f0a45ecc07',
-                    "title": "Terraria 1.1 Trailer",
+                    'title': 'Terraria 1.1 Trailer',
-                "info_dict": {
+                'md5': '61aaf31a5c5c3041afb58fb83cbb5751',
-                    "title": "Terraria Trailer",
+                    'title': 'Terraria Trailer',
-        "playsTrailingWeek", "renditions", "captioning", "startDate", "endDate"]
+        'id', 'name', 'shortDescription', 'longDescription', 'creationDate',
-        "c": "9"
+        'x': 'a',
-            fvar = "fvarhd"
+            fvar = 'fvarhd'
-            fvar = "fvar"
+            fvar = 'fvar'
-        info_webpage = self._download_webpage(info_url, video_id, "Downloading the info webpage")
+        info_url = 'http://www.traileraddict.com/%s.php?tid=%s' % (fvar, str(video_id))
-        xml_data = self._download_xml(info_url, video_id, "Opening the info XML page")
+        xml_data = self._download_xml(info_url, video_id, 'Opening the info XML page')
-        info_url = "http://vbox7.com/play/magare.do"
+        info_url = 'http://vbox7.com/play/magare.do'
-        if re.match(r"^<html><head><script[^>]*>window.location\s*=", webpage):
+        if re.match(r'^<html><head><script[^>]*>window.location\s*=', webpage):
-            'player_url': "http://videopremium.tv/uplayer/uppod.swf",
+            'url': 'rtmp://e%d.md.iplay.md/play' % random.randint(1, 16),
-        video_title = config["video"]["title"]
+        video_title = config['video']['title']
-        video_uploader_id = config["video"]["owner"]["url"].split('/')[-1] if config["video"]["owner"]["url"] else None
+        video_uploader = config['video']['owner']['name']
-        video_thumbnail = config["video"].get("thumbnail")
+        video_thumbnail = config['video'].get('thumbnail')
-            video_thumbs = config["video"].get("thumbs")
+            video_thumbs = config['video'].get('thumbs')
-        video_duration = int_or_none(config["video"].get("duration"))
+        video_duration = int_or_none(config['video'].get('duration'))
-        "info_dict": {
+        'info_dict': {
-            "title": 'Videos urza likes',
+            'description': 'See all the videos urza likes',
-    _VINE_BASE_URL = "https://vine.co/"
+    _VINE_BASE_URL = 'https://vine.co/'
-        profile_url = "%sapi/users/profiles/%s%s" % (
+        profile_url = '%sapi/users/profiles/%s%s' % (
-            timeline_url = "%sapi/timelines/users/%s?page=%s&size=100" % (
+            timeline_url = '%sapi/timelines/users/%s?page=%s&size=100' % (
-            "title": "KO Of The Week: MMA Fighter Gets Knocked Out By Swift Head Kick!"
+        'url': 'http://www.worldstarhiphop.com/videos/video.php?v=wshh6a7q1ny0G34ZwuIO',
-            "title": "KO Of The Week: MMA Fighter Gets Knocked Out By Swift Head Kick!"
+            'title': 'KO Of The Week: MMA Fighter Gets Knocked Out By Swift Head Kick!'
-            "age_limit": 18,
+            'title': 'Zeichentrick 1',
-        basic_data_url = "http://play.youku.com/play/get.json?vid=%s&ct=12" % video_id
+        basic_data_url = 'http://play.youku.com/play/get.json?vid=%s&ct=12' % video_id
-        return "".join(opts)
+        return ''.join(opts)
-        self._downloader.to_screen("[exec] Executing command: %s" % cmd)
+        self._downloader.to_screen('[exec] Executing command: %s' % cmd)
-        regex = ""
+        regex = ''
-                    ads_fn = path + ":" + key
+                    ads_fn = path + ':' + key
-                        with open(ads_fn, "wb") as f:
+                        with open(ads_fn, 'wb') as f:
-                user_has_xattr = check_executable("xattr", ['-h'])
+                user_has_setfattr = check_executable('setfattr', ['--version'])
-                    if infoname == "upload_date":
+                    if infoname == 'upload_date':
-    UPDATE_URL = "https://rg3.github.io/youtube-dl/update/"
+    UPDATE_URL = 'https://rg3.github.io/youtube-dl/update/'
-    if not isinstance(globals().get('__loader__'), zipimporter) and not hasattr(sys, "frozen"):
+    if not isinstance(globals().get('__loader__'), zipimporter) and not hasattr(sys, 'frozen'):
-    if hasattr(sys, "frozen") and not os.path.isfile(filename):
+    if hasattr(sys, 'frozen') and not os.path.isfile(filename):
-    if hasattr(sys, "frozen"):
+    if hasattr(sys, 'frozen'):
-    return get_element_by_attribute("id", id, html)
+    return get_element_by_attribute('id', id, html)
-    return datetime.datetime.strptime(date_str, "%Y%m%d").date()
+    return datetime.datetime.strptime(date_str, '%Y%m%d').date()
-        (b"GetStdHandle", ctypes.windll.kernel32))
+        (b'GetStdHandle', ctypes.windll.kernel32))
-        ctypes.wintypes.LPVOID)((b"WriteConsoleW", ctypes.windll.kernel32))
+        ctypes.wintypes.LPVOID)((b'WriteConsoleW', ctypes.windll.kernel32))
-    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)((b"GetFileType", ctypes.windll.kernel32))
+    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)((b'GetFileType', ctypes.windll.kernel32))
-        (b"GetConsoleMode", ctypes.windll.kernel32))
+        (b'GetConsoleMode', ctypes.windll.kernel32))
-        libc = ctypes.cdll.LoadLibrary("libc.so.6")
+        libc = ctypes.cdll.LoadLibrary('libc.so.6')
-        return "HEAD"
+        return 'HEAD'
-        date = info_dict.get('upload_date', None)
+        date = info_dict.get('upload_date')
-        view_count = info_dict.get('view_count', None)
+        view_count = info_dict.get('view_count')
-            playlist = ie_result.get('title', None) or ie_result.get('id', None)
+            playlist = ie_result.get('title') or ie_result.get('id')
-            playlistend = self.params.get('playlistend', None)
+            playlistend = self.params.get('playlistend')
-            playlistitems_str = self.params.get('playlist_items', None)
+            playlistitems_str = self.params.get('playlist_items')
-        rate_limit = self.params.get('ratelimit', None)
+        rate_limit = self.params.get('ratelimit')
-                'ratelimit': self.params.get('ratelimit', None),
+                'ratelimit': self.params.get('ratelimit'),
-            max_data_len = self.params.get("max_filesize", None)
+            min_data_len = self.params.get("min_filesize")
-        flash_version = info_dict.get('flash_version', None)
+        player_url = info_dict.get('player_url')
-        protocol = info_dict.get('rtmp_protocol', None)
+        conn = info_dict.get('rtmp_conn')
-        if downloader_params.get('username', None) is not None:
+        if downloader_params.get('username') is not None:
-        if downloader_params.get('twofactor', None) is not None:
+        if downloader_params.get('twofactor') is not None:
-        return RATING_TABLE.get(rating.lower(), None)
+        return RATING_TABLE.get(rating.lower())
-        return RATING_TABLE.get(family_friendly.lower(), None)
+        return RATING_TABLE.get(family_friendly.lower())
-        video_password = self._downloader.params.get('videopassword', None)
+        video_password = self._downloader.params.get('videopassword')
-        broadcast_password = self._downloader.params.get('videopassword', None)
+        broadcast_password = self._downloader.params.get('videopassword')
-        password = self._downloader.params.get('videopassword', None)
+        password = self._downloader.params.get('videopassword')
-        password = self._downloader.params.get('videopassword', None)
+        password = self._downloader.params.get('videopassword')
-        password = self._downloader.params.get('videopassword', None)
+        password = self._downloader.params.get('videopassword')
-        video_password = self._downloader.params.get('videopassword', None)
+        video_password = self._downloader.params.get('videopassword')
-    return int(m.group('age')) if m else US_RATINGS.get(s, None)
+    return int(m.group('age')) if m else US_RATINGS.get(s)
-    class MD5:
+    class MD5(object):
-    class Counter:
+    class Counter(object):
-        mobj = re.search(r'<iframe[^>]+src=[\'"](%s)[\'"]' % self._VALID_EMBED_URL, webpage)
+    def _extract_dmcloud_url(cls, webpage):
-            r'<input[^>]+id=[\'"]dmcloudUrlEmissionSelect[\'"][^>]+value=[\'"](%s)[\'"]' % self._VALID_EMBED_URL,
+            r'<input[^>]+id=[\'"]dmcloudUrlEmissionSelect[\'"][^>]+value=[\'"](%s)[\'"]' % cls._VALID_EMBED_URL,
-        (video-clips|episodes|cc-studios|video-collections|full-episodes)
+        (video-clips|episodes|cc-studios|video-collections|full-episodes|shows)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-__version__ = '2016.02.10'
+__version__ = '2016.02.13'
-            'skip': 'Expired'
+            'only_matching': True,
-                multifeed_metadata_list = compat_urllib_parse_unquote_plus(video_info['multifeed_metadata_list'][0])
+                multifeed_metadata_list = video_info['multifeed_metadata_list'][0]
-                    feed_data = compat_parse_qs(feed)
+                    # Unquote should take place before split on comma (,) since textual
-                    'formats': self._parse_mpd_formats(doc, video_id),
+                    'formats': self._parse_mpd_formats(
-                        if not re.match(r'^https?://', base_url):
+                        if mpd_base_url and not re.match(r'^https?://', base_url):
-            'url': smuggle_url(video_url + '?mbr=true&format=SMIL&assetTypes=medium_video_s3', {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}, 'force_smil_url': True}),
+            'url': smuggle_url(video_url, {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}}),
-            'url': smuggle_url(video_url, {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}}),
+            'url': smuggle_url(video_url + '?mbr=true&format=SMIL&assetTypes=medium_video_s3', {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}, 'force_smil_url': True}),
-            r'<(?:embed|iframe)[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?dailymotion\.com/(?:embed|swf)/video/.+?)\1', webpage)
+            r'<(?:(?:embed|iframe)[^>]+?src=|input[^>]+id=[\'"]dmcloudUrlEmissionSelect[\'"][^>]+value=)(["\'])(?P<url>(?:https?:)?//(?:www\.)?dailymotion\.com/(?:embed|swf)/video/.+?)\1', webpage)
-            r'xsrft\s*[=:]\s*(?P<q>["\'])(?P<xsrft>.+?)(?P=q)',
+            r'(?:(?P<q1>["\'])xsrft(?P=q1)\s*:|xsrft\s*[=:])\s*(?P<q>["\'])(?P<xsrft>.+?)(?P=q)',
-            smil_url = item['plfile$url'] + '&format=SMIL&Tracking=true&Embedded=true&formats=MPEG4,F4M'
+            smil_url = item['plfile$url'] + '&format=SMIL&mbr=true'
-            cur_video_id = url_basename(smil_url)
+            cur_video_id = ThePlatformIE._match_id(smil_url)
-    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20150101 Firefox/20.0 (Chrome)',
+    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20150101 Firefox/44.0 (Chrome)',
-        src_urls = []
+        srcs = []
-            if not src:
+            if not src or src in srcs:
-            res = '?x%d' % format['width']
+            res = '%dx?' % format['width']
-            'url': 'http://www.youtube.com/watch?v=BaW_jenozKcj&t=1s&end=9',
+            'url': 'http://www.youtube.com/watch?v=BaW_jenozKc&t=1s&end=9',
-            'url': 'http://www.youtube.com/watch?v=BaW_jenozKcj&v=UxxajLWwzqY',
+            'url': 'http://www.youtube.com/watch?v=BaW_jenozKc&v=UxxajLWwzqY',
-            'content'), video_id)['content']
+            self._search_regex(
-                return tabbed_videos, presumptive_id, upload_date
+            MULTI_PART_REGEXES = (
-                'description': 'md5:ba0c207295339c8d6eced00b7c363c6a',
+                'description': 'md5:36f341ae62e251b8f5bd2b754b95a071',
-                'description': 'md5:f5bfbefadf421e8bb8647602011caf8e',
+                'description': 'md5:4d3eaa01f94e61b3e73704735f1196d9',
-                'description': 'md5:5871c15cba347c1b3d28ac47a73c7c28',
+                'description': 'md5:95a19f568689d09a166dff9edada3301',
-                'description': 'md5:68d87ef760660eb564455eb30ca464fe',
+                'description': 'md5:657897370e09e2bc6bf0f8d2cd313c6b',
-                'description': 'American Experience, TVâs most-watched history series, brings to life the compelling stories from our past that inform our understanding of the world today.',
+                'description': 'md5:1b80a74e0380ed2a4fb335026de1600d',
-            'url': 'http://video.pbs.org/video/2365367186/',
+            'url': 'http://www.pbs.org/video/2365245528/',
-                'display_id': '2365367186',
+                'id': '2365245528',
-                'duration': 3342,
+                'title': 'FRONTLINE - United States of Secrets (Part One)',
-                'description': 'md5:61db2ddf27c9912f09c241014b118ed1',
+                'description': 'md5:54033c6baa1f9623607c6e2ed245888b',
-                'description': 'md5:f5bfbefadf421e8bb8647602011caf8e',
+                'description': 'md5:1a2481e86b32b2e12ec1905dd473e2c1',
-            'description': info['program'].get('description'),
+            'description': info.get('description') or info.get('program', {}).get('description'),
-        if not info:
+        try:
-                            'format_id': mpd_id or representation_id,
+                            'format_id': '%s-%s' % (mpd_id, representation_id) if mpd_id else representation_id,
-            video_id, 'mp4', fatal=None)
+            video_id, 'mp4', m3u8_id='hls', fatal=None)
-                    'format_id': mfs_path.split('.')[0],
+                    'format_id': 'http-' + mfs_path.split('.')[0],
-            'http://legacyweb-us.crackle.com/app/revamp/vidwallcache.aspx?flags=-1&fm=%s' % video_id, video_id).find('i')
+            'http://legacyweb-us.crackle.com/app/revamp/vidwallcache.aspx?flags=-1&fm=%s' % video_id,
-        formats = self._extract_m3u8_formats('http://content.uplynk.com/ext/%s/%s.m3u8' % (self._UPLYNK_OWNER_ID, video_id), video_id, 'mp4', fatal=None)
+        formats = self._extract_m3u8_formats(
-        self._sort_formats(formats, ('width', 'height', 'tbr'))
+        self._sort_formats(formats, ('width', 'height', 'tbr', 'format_id'))
-            'id': 'miranda-sings-happy-thanksgiving-miranda',
+            'id': '2494164',
-        video_data = full_data.get('videos', {}).get(video_id) or full_data['singleshots'][video_id]
+        display_id = full_data['activeVideo']['video']
-            video_data['mediaUrl'], video_id, ext='mp4')
+            '_type': 'url_transparent',
-            'formats': formats,
+            'season_number': int_or_none(video_data.get('season')),
-__version__ = '2016.02.09.1'
+__version__ = '2016.02.10'
-            display_id)
+        player = self._download_webpage(
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?hotstar\.com/(?:.+?[/-])?(?P<id>\d{10})'
-    }
+    }, {
-__version__ = '2016.02.09'
+__version__ = '2016.02.09.1'
-        'md5': 'ae43ad7cb59431ce043f0ff7fa13cbf4',
+        'md5': '9eee21161d2c7f5b39690c3e325fab2f',
-            'ext': 'mp4',
+            'ext': 'mov',
-        'md5': 'faa71fbf70c0bee7ab93076fd007f4b0',
+        'md5': 'f12c5a7fa839c47a79363bfdf69404fb',
-            'ext': 'mp4',
+            'ext': 'ts',
-        'md5': '0defa2bd0ea613d14a6e9bd1db6be326',
+        'md5': '740511f61d3d1bb71dc14a0fe01a1c10',
-            'ext': 'mp4',
+            'ext': 'mov',
-            video_id)
+        query = {
-        request = sanitized_Request(json_url, None, headers)
+        request = sanitized_Request(
-        },
+import os
-from ..utils import sanitized_Request
+from .fragment import FragmentFD
-class DashSegmentsFD(FileDownloader):
+class DashSegmentsFD(FragmentFD):
-                req.add_header('Range', 'bytes=0-%d' % (remaining_bytes - 1))
+    FD_NAME = 'dashsegments'
-            data = self.ydl.urlopen(req).read()
+    def real_download(self, filename, info_dict):
-                data = data[:remaining_bytes]
+        ctx = {
-            return len(data)
+        self._prepare_and_start_frag_download(ctx)
-        })
+        segments_filenames = []
-            if not src:
+            if not src or src in urls:
-            video_id)['release_url'] + '&manifest=m3u'
+            video_id)['release_url'] + '&switch=http'
-                'uploader': 'hitech',
+                'timestamp': 1397039888,
-        view_count = video_data.get('views_count')
+        formats = []
-        self._sort_formats(formats)
+        title = remove_end(meta_data['title'], '.mp4')
-            'http://api.video.mail.ru/videos/%s.json?new=1' % video_id, video_id, 'Downloading video JSON')
+        webpage = self._download_webpage(url, video_id)
-__version__ = '2016.02.05.1'
+__version__ = '2016.02.09'
-            r'\ssrc="((?:https?:)?//rutube\.ru\\?/video\\?/embed(?:.*?))\\?"', info_page)
+            r'\ssrc="((?:https?:)?//rutube\.ru\\?/(?:video|play)\\?/embed(?:.*?))\\?"', info_page)
-        '36': {'ext': '3gp', 'width': 320, 'height': 240, 'acodec': 'aac', 'abr': 32, 'vcodec': 'mp4v'},
+        # itag 36 videos are either 320x180 (BaW_jenozKc) or 320x240 (__2ABJjxzNo), abr varies as well
-
+        connection_url = (player_config.get('rtmp', {}).get(
-    _VALID_URL = r'https?://(?:www\.)?konserthusetplay\.se/\?m=(?P<id>[^&]+)'
+    _VALID_URL = r'https?://(?:www\.)?konserthusetplay\.se/\?.*\bm=(?P<id>[^&]+)'
-    _TESTS = [{
+    _VALID_URL = r'https?://(?:www\.)?konserthusetplay\.se/\?m=(?P<id>[^&]+)'
-            'ext': 'mp4',
+            'ext': 'flv',
-    }]
+            'thumbnail': 're:^https?://.*$',
-        thumbnail = self._og_search_thumbnail(webpage)
+
-            'thumbnail': thumbnail
+            'thumbnail': thumbnail,
-        r'(?s)^[a-zA-Z0-9_]+\s*\(\s*(.*)\);?\s*?(?://[^\n]*)*$', r'\1', code)
+        r'(?s)^[a-zA-Z0-9_.]+\s*\(\s*(.*)\);?\s*?(?://[^\n]*)*$', r'\1', code)
-            'a': 42,
+        FALSE_VALUES = {
-def dict_get(d, key_or_keys, default=None):
+def dict_get(d, key_or_keys, default=None, skip_false_values=True):
-                return d[key]
+            if key not in d or d[key] is None or skip_false_values and not d[key]:
-    int_or_none
+    dict_get,
-    _VALID_URL = r'https?://(?:(www|m)\.)?vlive\.tv/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?vlive\.tv/video/(?P<id>[0-9]+)'
-            'creator': 'Girl\'s Day',
+            'title': "[V] Girl's Day's Broadcast",
-            video_id, note='Download video page')
+            'http://www.vlive.tv/video/%s' % video_id, video_id)
-            r'vlive\.tv\.video\.ajax\.request\.handler\.init\("[0-9]+",\s?"[^"]*",\s?"([^"]+)",\s?"[^"]+",\s?"[^"]*",\s?"[^"]*"\)', webpage, 'long_video_id')
+            r'vlive\.tv\.video\.ajax\.request\.handler\.init\(\s*"[0-9]+"\s*,\s*"[^"]*"\s*,\s*"([^"]+)"',
-            r'vlive\.tv\.video\.ajax\.request\.handler\.init\("[0-9]+",\s?"[^"]*",\s?"[^"]+",\s?"([^"]+)",\s?"[^"]*",\s?"[^"]*"\)', webpage, 'key')
+            r'vlive\.tv\.video\.ajax\.request\.handler\.init\(\s*"[0-9]+"\s*,\s*"[^"]*"\s*,\s*"[^"]+"\s*,\s*"([^"]+)"',
-        playinfo = self._download_json(url, video_id, 'Downloading video json')
+        playinfo = self._download_json(
-            })
+        formats = [{
-                 'url': caption['source']}]
+            lang = dict_get(caption, ('language', 'locale', 'country', 'label'))
-    determine_ext
+    determine_ext,
-    # www.vlive.tv/video/ links redirect to m.vlive.tv/video/ for mobile devices
+    # vlive.tv/video/ links redirect to www.vlive.tv/video/ 
-        'url': 'http://m.vlive.tv/video/1326',
+        'url': 'http://www.vlive.tv/video/1326',
-            'http://m.vlive.tv/video/%s' % video_id,
+            'http://www.vlive.tv/video/%s' % video_id,
-            r'<span[^>]+class="name">([^<>]+)</span>', webpage, 'creator')
+            r'<div class="info_area">\s*<strong[^>]+class="name">([^<>]+)</strong>', webpage, 'creator',fatal=False)
-        url += '&' + compat_urllib_parse.urlencode({'msgpad': msgpad, 'md': md})
+        # doct = document type (xml or json), cpt = caption type (vtt or ttml)
-        for vid in playinfo['result'].get('videos', {}).get('list', []):
+        for vid in playinfo.get('videos', {}).get('list', []):
-                'width': vid.get('width'),
+                'format_id': vid.get('encodingOption', {}).get('name'),
-        for caption in playinfo['result'].get('captions', {}).get('list', []):
+        for caption in playinfo.get('captions', {}).get('list', []):
-            '&_ts=%s&productId=%s' % (round(time.time()), 'p22201'))
+            '&_ts=%s&productId=%s' % (round(time.time()), video_id))
-        req = sanitized_Request('http://play.iprima.cz/prehravac/init?_infuse=1'
+        req = sanitized_Request(
-from math import floor
+import time
-    _VALID_URL = r'https?://play\.iprima\.cz/(?:[^/]+/)*(?P<id>[^?#]+)'
+    _VALID_URL = r'https?://play\.iprima\.cz/(?:.+/)?(?P<id>[^?#]+)'
-        'url': 'http://play.iprima.cz/particka/particka-92',
+        'url': 'http://play.iprima.cz/gondici-s-r-o-33',
-            'thumbnail': 'http://play.iprima.cz/sites/default/files/image_crops/image_620x349/3/491483_particka-92_image_620x349.jpg',
+            'id': 'p136534',
-            'skip_download': True,  # requires rtmpdump
+            'skip_download': True,  # m3u8 download
-        'url': 'http://play.iprima.cz/zpravy-ftv-prima-2752015',
+        'url': 'http://play.iprima.cz/particka/particka-92',
-                '%s said: You do not have permission to access this page' % self.IE_NAME, expected=True)
+        video_id = self._search_regex(r'data-product="([^"]+)">', webpage, 'real id')
-        req = sanitized_Request(player_url)
+        req = sanitized_Request('http://play.iprima.cz/prehravac/init?_infuse=1'
-                filename, 'real video id')
+        playerpage = self._download_webpage(req, video_id, note='Downloading player')
-                filename = 'hq/' + filename
+        m3u8_url = self._search_regex(r"'src': '([^']+\.m3u8)'", playerpage, 'm3u8 url')
-            })
+        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')
-            'title': remove_end(self._og_search_title(webpage), ' | Prima PLAY'),
+            'id': video_id,
-                webpage, 'description', default=None),
+            'description': self._og_search_description(webpage),
-    # Radioplayer URLs have the specifier #!rii=<channel_id>:<id>:<playable_item_id>:<date>:
+    # Radioplayer URLs have two distinct specifier formats,
-    _VALID_URL = r'https?://(?:www\.)?rte\.ie/radio/utils/radioplayer/rteradioweb\.html#!rii=(?:[0-9]*)(?:%3A|:)(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?rte\.ie/radio/utils/radioplayer/rteradioweb\.html#!rii=(?:b?[0-9]*)(?:%3A|:|%5F|_)(?P<id>[0-9]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            formats.append({'url': mg['url']})
+        if mg.get('url'):
-                ext = 'srt'
+                else:
-                    'ext': ext,
+                    'ext': new_ext,
-            proc.communicate(b'q')
+            # streams). Note that Windows is not affected and produces playable
-            video_id, 'Downloadinng video JSON')
+            video_id, 'Downloading video JSON')
-        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|dash\+xml|(?:vnd\.apple\.|x-)?mpegurl)))/(?P<format_id>.+)$', content_type)
+        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\.apple\.|x-)?mpegurl)))/(?P<format_id>.+)$', content_type)
-                formats = self._extract_mpd_formats(url, video_id)
+            elif ext == 'mpd':
-        # Is it an RSS feed, a SMIL file or a XSPF playlist?
+        # Is it an RSS feed, a SMIL file, an XSPF playlist or a MPD manifest?
-from __future__ import unicode_literals, division
+from __future__ import unicode_literals
-                                representation_ms_info['total_number'] = int(math.ceil(period_duration / segment_duration))
+                                segment_duration = float(representation_ms_info['segment_duration']) / float(representation_ms_info['timescale'])
-            # XXX: In real cases InfoExtractor._parse_mpd() fills up 'acodec'
+            # XXX: In real cases InfoExtractor._parse_mpd_formats() fills up 'acodec'
-        return self._parse_mpd(
+        return self._parse_mpd_formats(
-    def _parse_mpd(self, mpd_doc, mpd_id=None, mpd_base_url='', formats_dict={}):
+    def _parse_mpd_formats(self, mpd_doc, mpd_id=None, mpd_base_url='', formats_dict={}):
-        namespace = self._search_regex(r'(?i)^{([^}]+)?}MPD$', mpd_doc.tag, 'namespace')
+        namespace = self._search_regex(r'(?i)^{([^}]+)?}MPD$', mpd_doc.tag, 'namespace', default=None)
-                formats.extend(self._parse_mpd(
+                formats.extend(self._parse_mpd_formats(
-        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\.apple\.|x-)?mpegurl)))/(?P<format_id>.+)$', content_type)
+        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|dash\+xml|(?:vnd\.apple\.|x-)?mpegurl)))/(?P<format_id>.+)$', content_type)
-            for ext in ['ttml', 'vtt']:
+            for ext in self._SUBTITLE_FORMATS:
-                for ext in ['sbv', 'vtt', 'srt']:
+                for ext in self._SUBTITLE_FORMATS:
-
+class VidmeListBaseIE(InfoExtractor):
-                'Downloading user page %d' % page_num)
+                'https://api.vid.me/videos/%s?user=%s&limit=%d&offset=%d'
-        return self.playlist_result(self._entries(user_id, user_name), user_id, user_name)
+        return self.playlist_result(
-from .vidme import VidmeIE
+from .vidme import (
-    _VALID_URL = r'https?://vid\.me/(?:e/)?(?P<id>[\da-zA-Z]+)'
+    _VALID_URL = r'https?://vid\.me/(?:e/)?(?P<id>[\da-zA-Z]{,5})(?:[^\da-zA-Z]|$)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        } for height in re.findall(r'<(?:span|li)[^>]+q_(\d+)p', webpage)]
+        } for height in re.findall(r'<(?:span|li|p)[^>]+[qb]_(\d+)p', webpage)]
-        if info.get('protocol') == 'm3u8_native' or self._downloader.params.get('hls_prefer_native', False):
+        if info.get('protocol') == 'm3u8_native' or info.get('protocol') == 'm3u8' and self._downloader.params.get('hls_prefer_native', False):
-__version__ = '2016.02.05'
+__version__ = '2016.02.05.1'
-        if info['protocol'] == 'm3u8_native' or self._downloader.params.get('hls_prefer_native', False):
+        if info.get('protocol') == 'm3u8_native' or self._downloader.params.get('hls_prefer_native', False):
-__version__ = '2016.02.04'
+__version__ = '2016.02.05'
-                webpage, 'iframe url', group='url')
+            def find_iframe_url(webpage, default=NO_DEFAULT):
-__version__ = '2016.02.01'
+__version__ = '2016.02.04'
-        for lang in ['it', 'fr', 'de']:
+        self.assertEqual(md5(subtitles['en']), '3cb210999d3e021bd6c7f0ea751eab06')
-    def test_youtube_subtitles_sbv_format(self):
+    def test_youtube_subtitles_ttml_format(self):
-        self.DL.params['subtitlesformat'] = 'sbv'
+        self.DL.params['subtitlesformat'] = 'ttml'
-        self.assertEqual(md5(subtitles['en']), '13aeaa0c245a8bed9a451cb643e3ad8b')
+        self.assertEqual(md5(subtitles['en']), 'e306f8c42842f723447d9f63ad65df54')
-            for ext in ['vtt', 'ttml']:
+            for ext in ['ttml', 'vtt']:
-            for ext in ['sbv', 'vtt', 'srt']:
+            for ext in ['vtt', 'ttml']:
-        m = re.match(r'^(?P<type>audio|video|application(?=/ogg$))/(?P<format_id>.+)$', content_type)
+        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\.apple\.|x-)?mpegurl)))/(?P<format_id>.+)$', content_type)
-                }],
+                'formats': formats,
-from __future__ import unicode_literals
+from __future__ import unicode_literals, division
-                            media_template = re.sub(r'\$(Number)(?:%(0\d+)d)?\$', r'%(\1)\2d', media_template)
+                            media_template = re.sub(r'\$(Number|Bandwidth)(?:%(0\d+)d)?\$', r'%(\1)\2d', media_template)
-                            representation_ms_info['segment_urls'] = [media_template % {'Number': segment_number} for segment_number in range(representation_ms_info['start_number'], representation_ms_info['total_number'] + representation_ms_info['start_number'])]
+                            representation_ms_info['segment_urls'] = [media_template % {'Number': segment_number, 'Bandwidth': representation_attrib.get('bandwidth')} for segment_number in range(representation_ms_info['start_number'], representation_ms_info['total_number'] + representation_ms_info['start_number'])]
-                            'language': representation_attrib.get('lang'),
+                            'language': lang if lang not in ('mul', 'und', 'zxx', 'mis') else None,
-                        'ext': ext,
+                        'ext': 'flv' if protocol == 'RTMP' else None,
-from .cbsnews import CBSNewsIE
+from .cbsnews import (
-
+from .common import InfoExtractor
-    _VALID_URL = r'http://(?:www\.)?cbsnews\.com/(?:[^/]+/)+(?P<id>[\da-z_-]+)'
+    _VALID_URL = r'http://(?:www\.)?cbsnews\.com/(?:news|videos)/(?P<id>[\da-z_-]+)'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        video_info = json.loads(self._html_search_regex(
+        video_info = self._parse_json(self._html_search_regex(
-            webpage, 'video JSON info'))
+            webpage, 'video JSON info'), video_id)
-    class TTMLPElementParser:
+    class TTMLPElementParser(object):
-        if info['protocol'] == 'm3u8_native':
+        if info['protocol'] == 'm3u8_native' or self._downloader.params.get('hls_prefer_native', False):
-            segment_list = element.find(self._xpath_ns('SegmentList', namespace))
+            segment_list = element.find(_add_ns('SegmentList'))
-                segment_urls_e = segment_list.findall(self._xpath_ns('SegmentURL', namespace))
+                segment_urls_e = segment_list.findall(_add_ns('SegmentURL'))
-                initialization = segment_list.find(self._xpath_ns('Initialization', namespace))
+                initialization = segment_list.find(_add_ns('Initialization'))
-                segment_template = element.find(self._xpath_ns('SegmentTemplate', namespace))
+                segment_template = element.find(_add_ns('SegmentTemplate'))
-                    segment_timeline = segment_template.find(self._xpath_ns('SegmentTimeline', namespace))
+                    segment_timeline = segment_template.find(_add_ns('SegmentTimeline'))
-                        s_e = segment_timeline.findall(self._xpath_ns('S', namespace))
+                        s_e = segment_timeline.findall(_add_ns('S'))
-                        initialization = segment_template.find(self._xpath_ns('Initialization', namespace))
+                        initialization = segment_template.find(_add_ns('Initialization'))
-        for period in mpd_doc.findall(self._xpath_ns('Period', namespace)):
+        for period in mpd_doc.findall(_add_ns('Period')):
-            for adaptation_set in period.findall(self._xpath_ns('AdaptationSet', namespace)):
+            for adaptation_set in period.findall(_add_ns('AdaptationSet')):
-                for representation in adaptation_set.findall(self._xpath_ns('Representation', namespace)):
+                for representation in adaptation_set.findall(_add_ns('Representation')):
-                            base_url_e = element.find(self._xpath_ns('BaseURL', namespace))
+                            base_url_e = element.find(_add_ns('BaseURL'))
-                            media_template = re.sub(r'\$(Bandwidth)(?:%(0\d+d))?\$', r'%(\1)\2', media_template)
+                            media_template = re.sub(r'\$(Bandwidth)(?:%(0\d+)d)?\$', r'%(\1)\2d', media_template)
-                            media_template = re.sub(r'\$(Number)(?:%(0\d+d))?\$', r'%(\1)\2', media_template)
+                            media_template = re.sub(r'\$(Number)(?:%(0\d+)d)?\$', r'%(\1)\2d', media_template)
-                if '.mpd' in version_url or '.ism' in version_url:
+                if '.ism' in version_url:
-                'initialization segment')
+            if info_dict.get('initialization_url'):
-                    namespace='urn:mpeg:dash:schema:mpd:2011'))
+                formats.extend(self._parse_mpd(
-            for dash_manifest_url in dash_mpds:
+            for mpd_url in dash_mpds:
-                    dash_manifest_url = re.sub(r'/s/([a-fA-F0-9\.]+)', decrypt_sig, dash_manifest_url)
+                    mpd_url = re.sub(r'/s/([a-fA-F0-9\.]+)', decrypt_sig, mpd_url)
-                            namespace='urn:mpeg:DASH:schema:MPD:2011', formats_dict=self._formats):
+                    for df in self._extract_mpd_formats(
-            errnote='Could not download DASH manifest',
+    def _extract_mpd_formats(self, mpd_url, video_id, mpd_id=None, note=None, errnote=None, fatal=True, formats_dict={}):
-        if dash_doc is False:
+        if res is False:
-            dash_doc, namespace=namespace, formats_dict=formats_dict)
+    def _parse_mpd(self, mpd_doc, mpd_id=None, mpd_base_url='', formats_dict={}):
-            return self._xpath_ns(path, namespace)
+        def extract_multisegment_info(element, ms_parent_info):
-                                'acodec': acodec,
+        for period in mpd_doc.findall(self._xpath_ns('Period', namespace)):
-                        formats.append(full_info)
+                            if 'initialization_url' in representation_ms_info:
-                    self.report_warning('Unknown MIME type %s in DASH manifest' % mime_type)
+                        self.report_warning('Unknown MIME type %s in DASH manifest' % mime_type)
-    _VALID_URL = r'https?://vk\.com/videos(?P<id>-?[0-9]+)$'
+    _VALID_URL = r'https?://vk\.com/videos(?P<id>-?[0-9]+)(?!\?.*\bz=video)(?:[/?#&]|$)'
-__version__ = '2016.01.31'
+__version__ = '2016.02.01'
-    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/mypot/(?:View|Top)\.do\?.*?ownerid=(?P<id>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/mypot/(?:View|Top)\.(?:do|tv)\?.*?ownerid=(?P<id>[0-9a-zA-Z]+)'
-            'title': 'md5:a100d65d09cec246d8aa9bde7de45aed',
+            'title': '1297í, \'ìë¹  ìë¤ë¡ íì´ëê¸¸ ì íì´\' ë¯¼ì, ê°ëì ëë¬¼[ìë¹  ì´ëê°] 20150118',
-            return self.url_result(url, 'DaumClip')
+    @classmethod
-        self.to_screen('Downloading playlist %s - add --no-playlist to just download video' % list_id)
+
-            return self.url_result(url, 'DaumClip')
+        list_id = self._match_id(url)
-            return self.url_result(url, 'DaumPlaylist')
+        clip_result = self._check_clip(url, list_id)
-            
+                    pagenum, list_id_type, list_id), list_id, 'Downloading list info - %s' % pagenum)
-        'url': 'https://www.kickstarter.com/projects/1404461844/intersection-the-story-of-josh-grant?ref=home_location',
+        'url': 'https://www.kickstarter.com/projects/1404461844/intersection-the-story-of-josh-grant/description',
-            r'<title>\s*(.*?)(?:\s*&mdash; Kickstarter)?\s*</title>',
+            r'<title>\s*(.*?)(?:\s*&mdash;\s*Kickstarter)?\s*</title>',
-        }
+        },
-                'url': url,
+                'url': smuggle_url(url, {'to_generic': True}),
-            for f in ('_type', 'url'):
+            for f in ('_type', 'url', 'ie_key'):
-        video_url = 'http://' + video_host + '/' + video_hash + '/v.' + ext
+        # Vidzi now uses jwplayer, which can be handled by GenericIE
-            'url': video_url,
+            'url': smuggle_url(url, {'to_generic': True}),
-        video = xml.find('./AcVisionVideo').attrib
+        video = xpath_element(xml, './/AcVisionVideo').attrib
-        'md5': '0792086e8e2bfbac9cdf27835d5f2093',
+        # md5 fails in Python 2.6 due to buggy server response and wrong handling of urllib2
-            webpage, 'video URL')
+        video_info_dicts = re.findall(
-            'url': video_url,
+            'formats': formats,
-        video = xml.find('.//AcVisionVideo').attrib
+        video = xml.find('./AcVisionVideo').attrib
-            'description': 'md5:eeaffe7c2d634525e21159b93acf3b1e',
+            'description': 'Regardez la bande annonce du film Planes 2 (Planes 2 Bande-annonce VF). Planes 2, un film de Roberts Gannaway',
-            'description': 'md5:71742e3a74b0d692c7fce0dd2017a4ac',
+            'description': 'md5:601d15393ac40f249648ef000720e7e3',
-            video_id = compat_str(player_data['refMedia'])
+            player = self._search_regex(r'data-player=\'([^\']+)\'>', webpage, 'data player', default=None)
-class ACastIE(ACastBaseIE):
+class ACastIE(InfoExtractor):
-class ACastChannelIE(ACastBaseIE):
+class ACastChannelIE(InfoExtractor):
-            'description': 'md5:0c5d8201dfea2b93218ea986c91eee6e',
+            'description': 'md5:a0b4ef3634e63866b542e5b1199a1a0e',
-        cast_data = self._download_json(self._API_BASE_URL + 'channels/%s/acasts/%s/playback' % (channel, display_id), display_id)
+
-            r'gogoVideo\(.*,\s*"([^"]+)', webpage, 'playlist id')
+            r'gogoVideo\([^,]+,\s*"([^"]+)', webpage, 'playlist id')
-        if playlist_id.find('youtube') != -1:
+        if YoutubeIE.suitable(playlist_id):
-        # 'md5': '2f32b1f7b80fdc5cb616efb4f387f8a3',
+        'md5': '5208d3a17adeaef829a7861887cb9029',
-        for playlist_id in set(re.findall(r'href="/?playlist\?list=([0-9A-Za-z-_]{10,})"', content)):
+        for playlist_id in orderedSet(re.findall(r'href="/?playlist\?list=([0-9A-Za-z-_]{10,})"', content)):
-                dfxp_file = subtitles_filename(filename, lang, ext)
+                dfxp_file = old_file
-                new_file, ['-f', new_format])
+            self.run_ffmpeg(old_file, new_file, ['-f', new_format])
-        return [], info
+        return sub_filenames, info
-        'md5': 'c45737fc8ac5dc8ac2f92ecbcecf505e',
+        'url': 'http://vlog.xuite.net/play/WUxxR2xCLTI1OTI1MDk5LmZsdg==',
-            'id': '3441629',
+            'id': '25925099',
-            'title': 'å­«çå§¿ - ç¼æ·æè©©',
+            'title': 'BigBuckBunny_320x180',
-            'categories': ['å½±è¦å¨æ¨'],
+            'duration': 596.458,
-            webpage, 'description', default=None)
+        description = self._og_search_description(webpage, default=None)
-            r'(?s)<div[^>]+class=["\']videoInfoBy["\'][^>]*>\s*By:\s*</div>(.+?)</(?:a|div)>',
+            r'(?s)<div[^>]+class=["\']videoInfoBy(?:\s+[^"\']+)?["\'][^>]*>\s*By:\s*</div>(.+?)</(?:a|div)>',
-    RaiIE,
+    RaiTVIE,
-    IE = RaiIE
+    IE = RaiTVIE
-        entries = result['entries']
+        entries = list(result['entries'])
-__version__ = '2016.01.29'
+__version__ = '2016.01.31'
-        for playlist_id in re.findall(r'href="/?playlist\?list=(.+?)"', content):
+        for playlist_id in set(re.findall(r'href="/?playlist\?list=([0-9A-Za-z-_]{10,})"', content)):
-class YoutubeEntryListBaseInfoExtractor(InfoExtractor):
+class YoutubeEntryListBaseInfoExtractor(YoutubeBaseInfoExtractor):
-class YoutubePlaylistIE(YoutubeBaseInfoExtractor, YoutubePlaylistBaseInfoExtractor):
+class YoutubePlaylistIE(YoutubePlaylistBaseInfoExtractor):
-            'id': 'phoenix-wright-ace-attorney-dual-destinies-review',
+            'id': 'HkSQKetlGOU',
-            'description': 'md5:36fd701e57e8c15ac8682a2374c99731',
+            'title': 'Phoenix Wright: Ace Attorney - Dual Destinies Review',
-            r'gogoVideo\(\s*\d+\s*,\s*"([^"]+)', webpage, 'playlist id')
+            r'gogoVideo\(.*,\s*"([^"]+)', webpage, 'playlist id')
-        play_json = self._download_json(play_json_req, media_id, 'Downloading playJson data')
+    @staticmethod
-    _VALID_URL = r'http://www\.gamekings\.tv/(?:videos|nieuws)/(?P<id>[^/]+)'
+    _VALID_URL = r'http://www\.gamekings\.nl/(?:videos|nieuws)/(?P<id>[^/]+)'
-        'url': 'http://www.gamekings.tv/videos/phoenix-wright-ace-attorney-dual-destinies-review/',
+        'url': 'http://www.gamekings.nl/videos/phoenix-wright-ace-attorney-dual-destinies-review/',
-        'url': 'http://www.gamekings.tv/videos/the-legend-of-zelda-majoras-mask/',
+        'url': 'http://www.gamekings.nl/videos/the-legend-of-zelda-majoras-mask/',
-        'url': 'http://www.gamekings.tv/nieuws/gamekings-extra-shelly-en-david-bereiden-zich-voor-op-de-livestream/',
+        'url': 'http://www.gamekings.nl/nieuws/gamekings-extra-shelly-en-david-bereiden-zich-voor-op-de-livestream/',
-        video_id = self._search_regex(r'data-mid="([^"]+)"', webpage, 'video_id')
+        video_id = self._search_regex(
-            'ext': 'flv',
+            'ext': 'mp4',
-                formats.extend(self._extract_m3u8_formats(video_url, video_id, m3u8_id='hls', fatal=False))
+                formats.extend(self._extract_m3u8_formats(video_url, video_id, ext='mp4', m3u8_id='hls', fatal=False))
-                'ext': 'flv',
+                'id': '112966',
-                'id': 'XwU9KZkp98TH',
+                'id': '176',
-            'skip': 'Only works from US',
+            'skip': '404 Not Found',
-                'ext': 'flv',
+                'id': '2832821',
-        return self.url_result(smuggle_url(theplatform_url, {'source_url': url}))
+        return {
-                'ext': 'flv',
+                'ext': 'mp4',
-                'title': 'Kunnskapskanalen: GrunnlovsjubilÃ©et - Stor stÃ¥hei for ingenting',
+                'ext': 'mp4',
-                'duration': 4605.0,
+                'duration': 4605.08,
-            'ext': 'flv',
+            'ext': 'mp4',
-        }
+        },
-            'ext': 'flv',
+            'ext': 'mp4',
-        }
+        },
-            'title': 'Se Gryttens hyllest av Steven Gerrard',
+            'ext': 'mp4',
-        }
+        },
-                formats.extend(self._extract_m3u8_formats(source['file'], video_id))
+                formats.extend(self._extract_m3u8_formats(source['file'], video_id, ext='mp4'))
-        }
+        },
-                'ext': 'flv',
+                'ext': 'mp4',
-                    formats.extend(self._extract_m3u8_formats(video_url, video_id))
+                    formats.extend(self._extract_m3u8_formats(video_url, video_id, 'mp4'))
-                formats.extend(self._extract_f4m_formats(stream_url, video_id))
+                formats.extend(self._extract_f4m_formats(
-                    preference=-1, m3u8_id=format_id))
+                    media_url, video_id, 'mp4', 'm3u8_native',
-                            dash_doc, namespace='urn:mpeg:DASH:schema:MPD:2011', formats_dict=self._formats):
+
-    def _parse_dash_manifest(self, video_id, dash_doc, namespace=None, formats_dict={}, fatal=True):
+    def _parse_dash_manifest(self, dash_doc, namespace=None, formats_dict={}):
-                    video_id, compat_etree_fromstring(compat_urllib_parse_unquote_plus(dash_manifest)),
+                    compat_etree_fromstring(compat_urllib_parse_unquote_plus(dash_manifest)),
-                            video_id, dash_doc, namespace='urn:mpeg:DASH:schema:MPD:2011', formats_dict=self._formats, fatal=dash_mpd_fatal):
+                            dash_doc, namespace='urn:mpeg:DASH:schema:MPD:2011', formats_dict=self._formats):
-            return '{%s}%s' % (default_ns, tag)
+    def _parse_dash_manifest(self, video_id, dash_doc, namespace=None, formats_dict={}, fatal=True):
-                    default_ns='urn:mpeg:dash:schema:mpd:2011'))
+                    namespace='urn:mpeg:dash:schema:mpd:2011'))
-                            video_id, dash_doc, formats_dict=self._formats, fatal=dash_mpd_fatal):
+                            video_id, dash_doc, namespace='urn:mpeg:DASH:schema:MPD:2011', formats_dict=self._formats, fatal=dash_mpd_fatal):
-        '266': {'ext': 'mp4', 'height': 2160, 'format_note': 'DASH video', 'acodec': 'none', 'vcodec': 'h264', 'preference': -40},
+        '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'h264', 'preference': -40},
-        '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'vcodec': 'none', 'abr': 256, 'preference': -50, 'container': 'm4a_dash'},
+        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 48, 'preference': -50, 'container': 'm4a_dash'},
-        '271': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'acodec': 'none', 'vcodec': 'vp9', 'preference': -40},
+        '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8', 'preference': -40},
-        '315': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'acodec': 'none', 'vcodec': 'vp9', 'fps': 60, 'preference': -40},
+        '272': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9', 'preference': -40},
-        '172': {'ext': 'webm', 'acodec': 'vorbis', 'vcodec': 'none', 'format_note': 'DASH audio', 'abr': 256, 'preference': -50},
+        '171': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 128, 'preference': -50},
-        '251': {'ext': 'webm', 'vcodec': 'none', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 160, 'preference': -50},
+        '249': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 50, 'preference': -50},
-        if self.params.get('test', False):
+        test = self.params.get('test', False)
-            if not fragments_list and live and bootstrap_url:
+            if not fragments_list and not test and live and bootstrap_url:
-                                full_info['acodec'] = codecs
+                            if mime_type.startswith('video/'):
-                    filesize = int_or_none(url_el.attrib.get('{http://youtube.com/yt/2012/10/10}contentLength') if url_el else None)
+                    video_url = url_el.text if url_el is not None else None
-                    for df in self._parse_dash_manifest(video_id, dash_doc, dash_mpd_fatal):
+                    for df in self._parse_dash_manifest(
-        webpage = self._download_webpage(url, video_id)
+        req = sanitized_Request('https://www.facebook.com/video/video.php?v=%s' % video_id)
-
+            state['elapsed'] = time_now - start
-    def _parse_dash_manifest(self, video_id, dash_doc, fatal=True):
+    def _parse_dash_manifest(self, video_id, dash_doc, default_ns='urn:mpeg:DASH:schema:MPD:2011', formats_dict={}, fatal=True):
-        for a in dash_doc.findall('.//{urn:mpeg:DASH:schema:MPD:2011}AdaptationSet'):
+        for a in dash_doc.findall('.//' + _add_ns('AdaptationSet')):
-                    continue
+            for r in a.findall(_add_ns('Representation')):
-                    segment_list = r.find('{urn:mpeg:DASH:schema:MPD:2011}SegmentList')
+                    segment_list = r.find(_add_ns('SegmentList'))
-                    filesize = int_or_none(url_el.attrib.get('{http://youtube.com/yt/2012/10/10}contentLength'))
+                    video_url = url_el.text if url_el else None
-                            'segment_urls': [segment.attrib.get('media') for segment in segment_list.findall('{urn:mpeg:DASH:schema:MPD:2011}SegmentURL')],
+                            'initialization_url': initialization_url,
-                        full_info = self._formats.get(format_id, {}).copy()
+                        full_info = formats_dict.get(format_id, {}).copy()
-        self.to_screen('[%s] Total fragments: %d' % (self.FD_NAME, ctx['total_frags']))
+        if 'live' not in ctx:
-            state['total_bytes_estimate'] = estimated_size
+            if not ctx['live']:
-                    state['downloaded_bytes'])
+                if not ctx['live']:
-             'video while downloading (some players may not be able to play it')
+             'video while downloading (some players may not be able to play it)')
-        if node.text is None:
+        # Sometimes non empty inline bootstrap info can be specified along
-                base_url, node.attrib['url'])
+                base_url, bootstrap_url)
-        return (boot_info, bootstrap_url)
+        return boot_info, bootstrap_url
-            'title': clip_info['title'],
+            'title': unescapeHTML(clip_info['title']),
-
+    def _parse_dash_manifest(self, video_id, dash_doc, fatal=True):
-                            video_id, dash_manifest_url, player_url, age_gate, dash_mpd_fatal):
+                    def decrypt_sig(mobj):
-        if not m:
+        if m:
-        for format_id, f in params['video_data'].items():
+        for format_id, f in video_data.items():
-    xattr_set_filesize, external_downloader_args.
+    xattr_set_filesize, external_downloader_args, hls_use_mpegts.
-        args += ['-i', url, '-f', 'mp4', '-c', 'copy', '-bsf:a', 'aac_adtstoasc']
+        args += ['-i', url, '-c', 'copy']
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': 're:^https?://.*\.(?:jpg|png)',
-from ..compat import compat_urllib_parse
+from ..compat import (
-    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/v/(?P<id>[^?#&]+)'
+    _VALID_URL = r'https?://(?:(?:m\.)?tvpot\.daum\.net/v/|videofarm\.daum\.net/controller/player/VodPlayer\.swf\?vid=)(?P<id>[^?#&]+)'
-        video_id = self._match_id(url)
+        video_id = compat_urllib_parse_unquote(self._match_id(url))
-            'Downloading video info')
+        info = self._download_xml(
-            'duration': 154
+            'duration': 154,
-        },    }, {
+        },
-            webpage, 'video id')
+            r'class=(["\']).*?video-play-button.*?\1[^>]+data-id=["\'](?P<id>\d+)',
-            if 'tbr' not in f and 'abr' in f and 'vbr' in f:
+            if 'tbr' not in f and f.get('abr') is not None and f.get('vbr') is not None:
-                path = get_text_attr(f, 'path')
+                path = unescapeHTML(get_text_attr(f, 'path'))
-from .azubu import AzubuIE
+from .azubu import AzubuIE, AzubuLiveIE
-from ..utils import float_or_none
+from ..utils import (
-__version__ = '2016.01.27'
+__version__ = '2016.01.29'
-        self.assertMatch('www.youtube.com/NASAgovVideo/videos', ['youtube:user'])
+        self.assertMatch('http://www.youtube.com/NASAgovVideo/videos', ['youtube:user'])
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:https?://(?:\w+\.)?youtube\.com/(?:user/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'
-                r'<p class="[^"]*medium-description[^"]*">([^<]+)</p>',
+                (r'<p class="[^"]*medium-description[^"]*">([^<]+)</p>',
-                r'<h2[^>]+id="parent-title"[^>]*>(.+?)</h2>', webpage, 'title')
+                (r'<h2[^>]+id="parent-title"[^>]*>(.+?)</h2>',
-    _VALID_URL = r'https?://(?:www\.)?(?:odnoklassniki|ok)\.ru/(?:video(?:embed)?|web-api/video/moviePlayer)/(?P<id>[\d-]+)'
+    _VALID_URL = r'https?://(?:(?:www|m|mobile)\.)?(?:odnoklassniki|ok)\.ru/(?:video(?:embed)?|web-api/video/moviePlayer)/(?P<id>[\d-]+)'
-                    src, video_id, m3u8_id='hls', entry_protocol='m3u8_native'))
+                    src, video_id, 'mp4', m3u8_id='hls', entry_protocol='m3u8_native'))
-        str_or_empty = functools.partial(str_or_none, default='')
+    class TTMLPElementParser:
-        out = str_or_empty(node.text)
+        def start(self, tag, attrib):
-                out += str_or_empty(xml.etree.ElementTree.tostring(child))
+        def end(self, tag):
-        return out
+        def data(self, data):
-                \s*(?P<value>[a-zA-Z0-9_-]+)
+                \s*(?P<value>[a-zA-Z0-9._-]+)
-from .common import InfoExtractor
+from .theplatform import ThePlatformIE
-class CBSNewsIE(InfoExtractor):
+class CBSNewsIE(ThePlatformIE):
-                'ext': 'flv',
+                'ext': 'mp4',
-                # rtmp download
+                # m3u8 download
-
+        formats = []
-                    src_url, video_id, ext or 'mp4', m3u8_id='hls', fatal=False))
+                m3u8_formats = self._extract_m3u8_formats(
-            r'(?s)<h1>(.+?)</h1>', webpage, 'title')
+            r'(?s)<h1[^>]*>(.+?)</h1>', webpage, 'title')
-        } for height in re.findall(r'<span[^>]+q_(\d+)p', webpage)]
+        } for height in re.findall(r'<(?:span|li)[^>]+q_(\d+)p', webpage)]
-__version__ = '2016.01.23'
+__version__ = '2016.01.27'
-    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/(?:clip/ClipView.do|mypot/View.do)\?.*?clipid=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/(?:clip/ClipView.(?:do|tv)|mypot/View.do)\?.*?clipid=(?P<id>\d+)'
-                                  fatal=False)
+        desc = self._search_regex(
-        'md5': '2dbc7e9fd4f1c60436c9aa73a5406193',
+        'md5': '95ee28ee45e70130e3ab02b0f579ae23',
-            'id': 'Pt1kc_FniKM',
+            'id': 'GB1101300280',
-            'uploader': 'HurtsVEVO',
+            'title': 'Somebody to Die For',
-            'duration': 230,
+            'uploader': 'Hurts',
-        'md5': '13d5204f520af905eeffa675040b8e76',
+        'md5': 'f6ab09b034f8c22969020b042e5ac7fc',
-            'id': 'ByGmQn1uxJw',
+            'id': 'USUV71302923',
-            'uploader': 'CassadeeVEVO',
+            'title': 'I Wish I Could Break Your Heart',
-            'age_limit': 0,
+            'uploader': 'Cassadee Pope',
-            'id': '07FYdnEawAQ',
+            'id': 'USRV81300282',
-            'uploader': 'justintimberlakeVEVO',
+            'title': 'Tunnel Vision (Explicit)',
-            'skip_download': 'true',
+            'age_limit': 18,
-        'md5': 'a8b84d1d1957cd01046441b701b270fb',
+        'md5': '8b83cc492d72fc9cf74a02acee7dc1b0',
-            'id': 'Lad2jHtJCqY',
+            'id': 'USUV71503000',
-            'uploader': 'KCampVEVO',
+            'title': 'Till I Die',
-            'duration': 193,
+            'age_limit': 18,
-    def _initialize_api(self, video_url, video_id):
+    def _initialize_api(self, video_id):
-            raise ExtractorError('%s said: This page is currently unavailable in your region.' % self.IE_NAME, expected=True)
+            raise ExtractorError(
-        response = self._download_json(json_url, video_id, 'Downloading video info', 'Unable to download info')
+        response = self._download_json(
-
+                ytid = response.get('errorInfo', {}).get('ytid')
-            self._initialize_api(url, video_id)
+            self._initialize_api(video_id)
-                        continue
+                    continue
-                        video_version['id'], 'Youtube', video_version['id'])
+                    continue
-                    elif source_type == 'smil' and not smil_parsed:
+                    elif source_type == 'smil' and version == 'level3' and not smil_parsed:
-                return self.url_result(surl, 'SenateISVP', video_id, title)
+            m = re.search(r'data-(?P<type>clip|prog)id=["\'](?P<id>\d+)', webpage)
-        'md5': '8b83cc492d72fc9cf74a02acee7dc1b0',
+        'md5': 'a8b84d1d1957cd01046441b701b270fb',
-            'id': 'USUV71503000',
+            'id': 'Lad2jHtJCqY',
-            'title': 'Till I Die - K Camp ft. T.I.',
+            'title': 'K Camp - Till I Die ft. T.I.',
-        0: 'youtube',
+        0: 'youtube',  # only in AuthenticateVideo videoVersions
-        video_info = response['video'] or {}
+        response = self._download_json(json_url, video_id, 'Downloading video info', 'Unable to download info')
-        title = video_info.get('title') or self._og_search_title(webpage)
+            self._initialize_api(url, video_id)
-            if version == 'youtube':
+            ytid = video_info.get('youTubeId')
-                elif source_type == 'hls':
+                    ytid, 'Youtube', ytid)
-                    smil_parsed = True
+                        version_url, video_id, 'mp4', 'm3u8_native',
-            self._html_search_meta('video:duration', webpage))
+        duration = video_info.get('duration')
-            'thumbnail': video_info.get('imageUrl'),
+            'thumbnail': video_info.get('imageUrl') or video_info.get('thumbnailUrl'),
-            'uploader': video_info['mainArtists'][0]['artistName'] if video_info else None,
+            'uploader': uploader,
-)
+from ..compat import compat_etree_fromstring
-    """
+    '''
-    """
+    '''
-        "md5": "95ee28ee45e70130e3ab02b0f579ae23",
+        'md5': '2dbc7e9fd4f1c60436c9aa73a5406193',
-            'id': 'GB1101300280',
+            'id': 'Pt1kc_FniKM',
-        }
+            'title': 'Hurts - Somebody to Die For',
-        'md5': 'f6ab09b034f8c22969020b042e5ac7fc',
+        'md5': '13d5204f520af905eeffa675040b8e76',
-            'id': 'USUV71302923',
+            'id': 'ByGmQn1uxJw',
-            'duration': 226.101,
+            'duration': 226,
-        }
+        },
-            'id': 'USRV81300282',
+            'id': '07FYdnEawAQ',
-            'timestamp': int,
+            'title': 'Justin Timberlake - Tunnel Vision (Explicit)',
-        }
+        },
-    def _formats_from_smil(self, smil_doc):
+    _SMIL_BASE_URL = 'http://smil.lvl3.vevo.com'
-        els = smil_doc.findall('.//{http://www.w3.org/2001/SMIL20/Language}video')
+        els = smil.findall('.//{http://www.w3.org/2001/SMIL20/Language}video')
-                    _(?P<cbr>[0-9]+)k
+                    _(?P<tbr>[0-9]+)k
-                'format_id': 'SMIL_' + m.group('cbr'),
+                'format_id': 'smil_' + m.group('tbr'),
-
+            ytid = response.get('errorInfo', {}).get('ytid')
-                raise ExtractorError('Please specify full Vevo URL for downloading', expected=True)
+                raise ExtractorError(
-        formats = self._formats_from_json(video_info)
+        smil_parsed = False
-from .facebook import FacebookIE
+from .facebook import (
-        (?:.*)'''
+                (?:
-                        f['vcodec'] = va_codecs[0].partition('.')[0]
+                        f['vcodec'] = va_codecs[0]
-                        f['acodec'] = va_codecs[1].partition('.')[0]
+                        f['acodec'] = va_codecs[1]
-                            if full_info.get('acodec') == 'none' and 'vcodec' not in full_info:
+                            if full_info.get('acodec') == 'none':
-                            elif full_info.get('vcodec') == 'none' and 'acodec' not in full_info:
+                            elif full_info.get('vcodec') == 'none':
-                    'player_url': player_url,
+
-                        dct['ext'] = ext
+                        kind, _ = kind_ext
-        'ttml+xml': 'ttml',
+        'ttml+xml': 'ttml',
-__version__ = '2016.01.15'
+__version__ = '2016.01.23'
-                        'Danish': 'dk',
+                        'Danish': 'da',
-        return {'se': [{'ext': 'srt', 'data': self._fix_subtitles(subs)}]} if subs else {}
+        return {'sv': [{'ext': 'srt', 'data': self._fix_subtitles(subs)}]} if subs else {}
-        help='Languages of the subtitles to download (optional) separated by commas, use IETF language tags like \'en,pt\'')
+        help='Languages of the subtitles to download (optional) separated by commas, use --list-subs for available language tags')
-                subtitles.setdefault('sv', []).append({'url': sr['url']})
+        subtitle_references = video_info.get('subtitleReferences')
-        'md5': 'c3101a17ce9634f4c1f9800f0746c187',
+    _TEST = {
-            'duration': 2566,
+            'id': '5996901',
-    }]
+    }
-from .ruleporn import RulepornIE
+from .ruleporn import RulePornIE
-from .common import InfoExtractor
+from .nuevo import NuevoBaseIE
-    _VALID_URL = r'https?://(?:www\.)?ruleporn\.com/(?:[a-z]+(?:-[a-z]+)+)'
+class RulePornIE(NuevoBaseIE):
-        webpage = self._download_webpage(url, None)
+        display_id = self._match_id(url)
-        url = info_xml.find('file').text
+        webpage = self._download_webpage(url, display_id)
-            'id': video_id,
+        video_id = self._search_regex(
-        }
+            'description': description,
-        thumbnail = xpath_text(config, './image')
+        thumbnail = xpath_text(config, ['./image', './thumb'])
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        return self._extract_nuevo(config_url, video_id)
+        return self._extract_nuevo(
-        tree = self._download_xml(config_url, video_id, transform_source=lambda s: s.strip())
+        config = self._download_xml(
-        duration = float_or_none(xpath_text(tree, './duration'))
+        title = xpath_text(config, './title', 'title', fatal=True).strip()
-            })
+            video_url = xpath_text(config, element_name)
-
+from .nuevo import NuevoBaseIE
-    _VALID_URL = r'http://(?:www\.)?trollvids\.com/+video/+(?P<id>[0-9]+)/+(?P<title>[^?&]+)'
+    _VALID_URL = r'http://(?:www\.)?trollvids\.com/video/(?P<id>\d+)/(?P<display_id>[^/?#&]+)'
-        info = self._extract_nuevo(config_url, video_id)
+        mobj = re.match(self._VALID_URL, url)
-            'webpage_url': url,
+            'display_id': display_id,
-    _VALID_URL = r'https?://(?:www\.)?trutube\.tv/(?:video/|nuevo/player/embed\.php\?v=)(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?trutube\.tv/(?:video/|nuevo/player/embed\.php\?v=)(?P<id>\d+)'
-        return info
+        return self._extract_nuevo(
-from .common import InfoExtractor
+from .nuevo import NuevoBaseIE
-class AnitubeIE(InfoExtractor):
+class AnitubeIE(NuevoBaseIE):
-        }
+        config_url = 'http://www.anitube.se/nuevo/econfig.php?key=%s' % key
-from ..utils import xpath_text
+from .nuevo import NuevoBaseIE
-class TruTubeIE(InfoExtractor):
+class TruTubeIE(NuevoBaseIE):
-            video_id, transform_source=lambda s: s.strip())
+        info = self._extract_nuevo(config_url, video_id)
-        thumbnail = xpath_text(config, './image', ' thumbnail')
+        # filehd always 404s
-        }
+        return info
-            },
+    _TESTS = [{
-    ]
+    }, {
-            'upload_date': '20131101',
+    _VALID_URL = r'https?://future\.arte\.tv/(?P<lang>fr|de)/(?P<id>.+)'
-        return self._extract_from_webpage(row, anchor_id, lang)
+        {
-                'duration': 787,
+                'subtitles': {
-            subtitles = {}
+            subtitles['en'] = [{
-        self.to_screen('[download] Got server HTTP error. Retrying (attempt %d of %d)...' % (count, retries))
+        self.to_screen('[download] Got server HTTP error. Retrying (attempt %d of %.0f)...' % (count, retries))
-    if signature != sha256(message).digest():
+    byte_size = (len(bin(key[0])) - 2 + 8 - 1) // 8
-    return True
+    expected = b'0001' + (byte_size - len(asn1) // 2 - 3) * b'ff' + b'00' + asn1
-        enc_key = '8b6b683780897eb8d9a48a02ccc4817d'[::-1]
+        # last update at 2016-01-22 for Zombie::bite
-                self._downloader.report_warning("No automatic captions")
+            if not caption_url:
-                    r'yahoo:\/\/article\/view\?uuid=([^&]+)&',
+                    r'<article[^>]data-uuid=["\']([^"\']+)',
-                        ext = source_file.get('extension', determine_ext(download_url)).lower(),
+                        ext = source_file.get('extension', determine_ext(download_url)).lower()
-    },{
+    }, {
-            r'"current"\s*:\s*({[^}]+?})', webpage, 'current video')
+            r'"(?:video|current)"\s*:\s*({[^}]+?})', webpage, 'current video')
-            r'"hls_stream"\s*:\s*"([^"]+)', video_data, 'm3u8 url', None)
+            r'hls_stream"?\s*:\s*"([^"]+)', video_data, 'm3u8 url', None)
-                r'"video_id"\s*:\s*(\d+)', video_data, 'video id'),
+                r'"id"\s*:\s*(\d+)', video_data, 'video id', default=display_id),
-    ]
+    _TESTS = [{
-        like_count = int_or_none(self._html_search_regex(
+        like_count = int_or_none(self._search_regex(
-        dislike_count = int_or_none(self._html_search_regex(
+        dislike_count = int_or_none(self._search_regex(
-            comment_count = str_to_int(comment_count)
+        view_count = str_to_int(self._search_regex(
-from ..compat import compat_urllib_parse_urlparse
+from ..compat import compat_str
-            r'flashvars\s*=\s*({.+?});\r?\n', webpage, 'flashvars'))
+        flashvars = self._parse_json(
-        format_id = '-'.join(path.split('/')[4].split('_')[:2])
+        formats = []
-            'format_id': format_id,
+            'formats': formats,
-        retval = subprocess.call(args, stdin=subprocess.PIPE)
+        proc = subprocess.Popen(args, stdin=subprocess.PIPE)
-from ..utils import sanitized_Request
+from ..utils import (
-                        'abr': details.get('bitrate', 0) / 1000,
+                        'abr': float_or_none(details.get('bitrate'), scale=1000),
-            "ie_key": 'LetvCloud',
+            'ie_key': 'LetvCloud',
-from .weiqitv import WeiqitvIE
+from .weiqitv import WeiqiTVIE
-class WeiqitvIE(InfoExtractor):
+class WeiqiTVIE(InfoExtractor):
-            page, 'info_json_str')
+            'var\s+video\s*=\s*(.+});', page, 'info json str')
-            page, 'letvcloud_url')
+            'var\s+letvurl\s*=\s*"([^"]+)', page, 'letvcloud url')
-                'ext': 'mp4',
+                'url': url,
-            'title': 'p7jnfw5hw9_467623dedf',
+            'title': 'Video p7jnfw5hw9_467623dedf',
-            'title': 'p7jnfw5hw9_ec93197892',
+            'title': 'Video p7jnfw5hw9_ec93197892',
-            'title': 'p7jnfw5hw9_187060b6fd',
+            'title': 'Video p7jnfw5hw9_187060b6fd',
-            'title': media_id,
+            'title': 'Video %s' % media_id,
-    _VALID_URL = r'http://yuntv\.letv\.com/bcloud.html\?.*$'
+    _VALID_URL = r'https?://yuntv\.letv\.com/bcloud.html\?.+'
-        vu = re.search('vu=([\w]+)', url).group(1)
+        uu_mobj = re.search('uu=([\w]+)', url)
-            "uu=" + uu + "&vu=" + vu)
+            'uu=' + uu + '&vu=' + vu)
-                'url': base64.b64decode(play_url['main_url'].encode('utf-8')).decode("utf-8"),
+                'url': base64.b64decode(play_url['main_url'].encode('utf-8')).decode('utf-8'),
-        } for media in play_json['data']['video_info']['media'].values()]
+        formats = []
-        synopsis = info.get('Synopsis', {})
+        synopsis = info.get('Synopsis') or {}
-        description = synopsis.get('Detailed') or info.get('Synopsis', {}).get('Short')
+        description = synopsis.get('Detailed') or (info.get('Synopsis') or {}).get('Short')
-from .ultimedia import UltimediaIE
+from .digiteka import DigitekaIE
-class UltimediaIE(InfoExtractor):
+class DigitekaIE(InfoExtractor):
-from .ultimedia import UltimediaIE
+from .digiteka import DigitekaIE
-            return self.url_result(self._proto_relative_url(ultimedia_url), 'Ultimedia')
+        # Look for Digiteka embeds
-        https?://(?:www\.)?ultimedia\.com/
+        https?://(?:www\.)?(?:digiteka\.net|ultimedia\.com)/
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?dailymotion\.com/embed/video/.+?)\1', webpage)
+            r'<(?:embed|iframe)[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?dailymotion\.com/(?:embed|swf)/video/.+?)\1', webpage)
-    _VALID_URL = r'(?i)(?:https?://)?(?:(www|touch)\.)?dailymotion\.[a-z]{2,3}/(?:(embed|#)/)?video/(?P<id>[^/?_]+)'
+    _VALID_URL = r'(?i)(?:https?://)?(?:(www|touch)\.)?dailymotion\.[a-z]{2,3}/(?:(?:embed|swf|#)/)?video/(?P<id>[^/?_]+)'
-    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?!(?:embed|#|video|playlist)/)(?:(?:old/)?user/)?(?P<user>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?!(?:embed|swf|#|video|playlist)/)(?:(?:old/)?user/)?(?P<user>[^/]+)'
-            }
+            },
-                    class="(?:yt-uix-redirect-link|yt-uix-sessionlink[^"]*)".*?>
+                    class="(?:yt-uix-redirect-link|yt-uix-sessionlink[^"]*)"[^>]*>
-        # some sites use this embed format (see: http://github.com/rg3/youtube-dl/issues/2990)
+        # some sites use this embed format (see: https://github.com/rg3/youtube-dl/issues/2990)
-    def extract_formats(cls, info):
+    def extract_formats(self, info):
-        for song_format in cls._FORMATS:
+        for song_format in self._FORMATS:
-            })
+            song_file_path = '/%s/%s.%s' % (
-from .ae import AEIE
+from .aenetworks import AENetworksIE
-class AEIE(InfoExtractor):
+class AENetworksIE(InfoExtractor):
-# Old 2.6 and 2.7 releases require kwargs to be bytes
+# Python < 2.6.5 require kwargs to be bytes
-            'description': 'md5:a40e370925074260b1c8a633c632c63a',
+            'description': 'md5:641f424b7a19d8e24f26dea22cf59d74',
-            playlist_description = ld.get('articleBody')
+        json_ld_info = self._search_json_ld(webpage, playlist_id, default=None)
-    def _search_json_ld(self, html, video_id, fatal=True):
+    def _search_json_ld(self, html, video_id, **kwargs):
-            html, 'JSON-LD', fatal=fatal, group='json_ld')
+            html, 'JSON-LD', group='json_ld', **kwargs)
-        return self._json_ld(json_ld, video_id, fatal=fatal)
+        return self._json_ld(json_ld, video_id, fatal=kwargs.get('fatal', True))
-                'url': 'http://m5.music.126.net/%s/%s.%s' %
+                'url': 'http://203.130.59.9/m1.music.126.net/%s/%s.%s' %
-# coding: utf-8
+import re
-    _VALID_URL = r'https?://(?:www\.)?zippcast\.com/video/(?P<id>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?zippcast\.com/(?:video/|videoview\.php\?.*\bvplay=)(?P<id>[0-9a-zA-Z]+)'
-        'md5': 'f2aea8659962d9155031aaeac53f7c54',
+        'md5': '5ea0263b5606866c4d6cda0fc5e8c6b6',
-            'categories': ['Entertainment'],
+            'categories': ['Entertainment'],
-        },
+        'only_matching': True,
-        view_count = self._html_search_regex(r'<td align="right"><h3>(.+?) views!', webpage, 'view_count')
+        webpage = self._download_webpage(
-            'view_count': int(view_count.replace(',', '')),
+            'uploader': uploader,
-__version__ = '2016.01.14'
+__version__ = '2016.01.15'
-        return self.url_result(smuggle_url(video_url, {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}}))
+        info = self._search_json_ld(webpage, video_id, fatal=False)
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:history|aetv|mylifetime)\.com|fyi.tv)/(?:[^/]+/)+(?P<id>[^/]+?)(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:history|aetv|mylifetime)\.com|fyi\.tv)/(?:[^/]+/)+(?P<id>[^/]+?)(?:$|[?#])'
-from .history import HistoryIE
+import itertools
-    _VALID_URL = r'https?://(?:www\.)?xtube\.com/community/profile\.php\?(.*?)user=(?P<username>[^&#]+)(?:$|[&#])'
+    _VALID_URL = r'https?://(?:www\.)?xtube\.com/profile/(?P<id>[^/]+-\d+)'
-        'url': 'http://www.xtube.com/community/profile.php?user=greenshowers',
+        'url': 'http://www.xtube.com/profile/greenshowers-4056496',
-            'id': 'greenshowers',
+            'id': 'greenshowers-4056496',
-        }
+        user_id = self._match_id(url)
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>xtube\.com/watch\.php\?v=(?P<id>[^/?&#]+))'
+    _VALID_URL = r'(?:xtube:|https?://(?:www\.)?xtube\.com/watch\.php\?.*\bv=)(?P<id>[^/?&#]+)'
-        req = sanitized_Request(url)
+        req = sanitized_Request('http://www.xtube.com/watch.php?v=%s' % video_id)
-    _VALID_URL = r'https?://(?:www\.)?history\.com/(?:[^/]+/)+(?P<id>[^/]+?)(?:$|[?#])'
+class AEIE(InfoExtractor):
-            'id': 'bLx5Dv5Aka1G',
+            'id': 'g12m5Gyt3fdR',
-        video_url = self._search_regex(
+        video_url_re = [
-            webpage, 'video url')
+            r"media_url\s*=\s*'([^']+)'"
-           (?:(?P<media>(?:[^/]+/)+select/media/)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
+           (?:(?P<media>(?:(?:[^/]+/)+select/)?media/)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
-            compat_urllib_parse.urlencode({'url': media_url}), video_id)
+        video_url = self._search_regex(
-            media_url + '?mbr=true&format=smil&sig=' + pdk_signature, {'force_smil_url': True}))
+        return self.url_result(smuggle_url(video_url, {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}}))
-           (?:(?P<media>(?:(?:[^/]+/)+select/)?media/)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
+           (?:(?P<media>(?:[^/]+/)+select/media/)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
-            webpage, 'video url')
+        media_url = self._search_regex(self._VIDEO_URL_RE, webpage, 'video url')
-        return self.url_result(smuggle_url(video_url, {'sig': {'key': 'crazyjava', 'secret': 's3cr3t'}}))
+        return self.url_result(smuggle_url(
-           (?:(?P<media>(?:[^/]+/)+select/media/)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
+           (?:(?P<media>(?:(?:[^/]+/)+select/)?media/)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
-from youtube_dl import utils
+from ..utils import float_or_none
-    _VALID_URL = r'(?:https?://)?(?:www\.)?canvas\.be/video/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?canvas\.be/video/(?:[^/]+/)*(?P<id>[^/?#&]+)'
-            'title': 'De afspraak veilt voor de Warmste Week',
+            'id': 'mz-ast-5e5f90b6-2d72-4c40-82c2-e134f884e93e',
-            'duration': 49,
+            'title': 'De afspraak veilt voor de Warmste Week',
-        video_id = self._match_id(url)
+        display_id = self._match_id(url)
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id)
-        data = self._download_json(json_url, video_id)
+            r'<h1[^>]+class="video__body__header__title"[^>]*>(.+?)</h1>',
-
+            format_url, format_type = target.get('url'), target.get('type')
-        duration = utils.int_or_none(data.get('duration')) / 1000
+
-            'duration': duration,
+            'duration': float_or_none(data.get('duration'), 1000),
-                'ext': 'mp4',
+                'ext': 'flv',
-                'ext': 'mp4',
+                'ext': 'flv',
-                'ext': 'mp4',
+                'ext': 'flv',
-                'description': 'Romantischer Kurztrip zum Valentinstag? Wir verraten, was sich hier wirklich lohnt.',
+                'description': 'Romantischer Kurztrip zum Valentinstag? Nina Heinemann verrÃ¤t, was sich hier wirklich lohnt.',
-                # rtmp download
+        r'clip[iI]d\s*=\s*["\'](\d+)',
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|the-voice-of-germany)\.(?:de|at|ch)|ran\.de|fem\.com)/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|the-voice-of-germany|7tv)\.(?:de|at|ch)|ran\.de|fem\.com)/(?P<id>.+)'
-            r'(?s)ntv.pageInfo.article =\s(\{.*?\});', webpage, 'info'),
+            r'(?s)ntv\.pageInfo\.article\s*=\s*(\{.*?\});', webpage, 'info'),
-    _VALID_URL = r'http://fm4\.orf\.at/7tage/?#(?P<date>[0-9]+)/(?P<show>\w+)'
+    _VALID_URL = r'http://fm4\.orf\.at/(?:7tage/?#|player/)(?P<date>[0-9]+)/(?P<show>\w+)'
-            entry_protocol='m3u8_native', preference=0))
+
-        files = set(re.findall(r'file\s*:\s*"([^"]+)"', webpage))
+        files = set(re.findall(r'file\s*:\s*"(/[^"]+)"', webpage))
-    _VALID_URL = r'https?://(?:www\.)?vodlocker\.com/(?:embed-)?(?P<id>[0-9a-zA-Z]+)(?:\..*?)?'
+    _VALID_URL = r'https?://(?:www\.)?vodlocker\.(?:com|city)/(?:embed-)?(?P<id>[0-9a-zA-Z]+)(?:\..*?)?'
-            r'file:\s*"(http[^\"]+)",', webpage, 'file url')
+            r'image:\s*"(http[^\"]+)",', thumbnail_webpage, 'thumbnail', fatal=False)
-            'url': url,
+            'url': video_url,
-            raise compat_urllib_error.URLError('file:/// protocol is explicitly disabled in youtube-dl for security reasons')
+            raise compat_urllib_error.URLError('file:// scheme is explicitly disabled in youtube-dl for security reasons')
-__version__ = '2016.01.09'
+__version__ = '2016.01.14'
-            'http://beeg.com/api/v5/video/%s' % video_id, video_id)
+            'https://api.beeg.com/api/v5/video/%s' % video_id, video_id)
-                encrypted_url.replace('{DATA_MARKERS}', ''), 'http:')
+                encrypted_url.replace('{DATA_MARKERS}', ''), 'https:')
-            raise compat_urllib_error.URLError('file protocol is disabled')
+            raise compat_urllib_error.URLError('file:/// protocol is explicitly disabled in youtube-dl for security reasons')
-        # which can be used for malicious purposes (see
+
-            opener.add_handler(handler)
+        file_handler = compat_urllib_request.FileHandler()
-from youtube_dl.compat import compat_str
+from youtube_dl.compat import compat_str, compat_urllib_error
-            proxy_handler, https_handler, cookie_processor, ydlh, data_handler)
+        unknown_handler = compat_urllib_request.UnknownHandler()
-from .tudou import TudouIE
+from .tudou import (
-    _VALID_URL = r'https?://(?:www\.)?tudou\.com/(?:listplay|programs(?:/view)?|albumplay)/([^/]+/)*(?P<id>[^/?#]+?)(?:\.html)?/?(?:$|[?#])'
+    IE_NAME = 'tudou'
-        webpage = self._download_webpage(url, video_id)
+        item_data = self._download_json(
-            r'vcode\s*:\s*[\'"]([^\'"]*)[\'"]', webpage, 'youku vcode', default=None)
+        youku_vcode = item_data.get('vcode')
-            webpage, 'player URL', default=self._PLAYER_URL)
+        title = unescapeHTML(item_data['kw'])
-            r'segs: \'([^\']+)\'', webpage, 'segments'), video_id)
+        segments = self._parse_json(item_data['itemSegs'], video_id)
-                    'Referer': player_url,
+                    'Referer': self._PLAYER_URL,
-                                    acodec, vcodec = codecs[0], codecs[1]
+                                    acodec, vcodec = codecs[1], codecs[0]
-            'id': clip['clipName'],
+            'id': clip.get('clipName') or clip['name'],
-            '_complete_frags_downloaded_bytes': 0,
+            'complete_frags_downloaded_bytes': 0,
-        ctx['started'] = start
+            'prev_frag_downloaded_bytes': 0,
-                (state['_complete_frags_downloaded_bytes'] + frag_total_bytes) /
+                (ctx['complete_frags_downloaded_bytes'] + frag_total_bytes) /
-                state['_prev_frag_downloaded_bytes'] = 0
+                state['downloaded_bytes'] += frag_total_bytes - ctx['prev_frag_downloaded_bytes']
-                state['downloaded_bytes'] += frag_downloaded_bytes - state['_prev_frag_downloaded_bytes']
+                state['downloaded_bytes'] += frag_downloaded_bytes - ctx['prev_frag_downloaded_bytes']
-                state['_prev_frag_downloaded_bytes'] = frag_downloaded_bytes
+                ctx['prev_frag_downloaded_bytes'] = frag_downloaded_bytes
-                            media_url, video_id, 'mp4', m3u8_id='hls', fatal=False))
+                            media_url, video_id, 'mp4', preference=-1,
-                            'format_id': quality,
+                            'format_id': 'http-%s' % quality,
-                (state['downloaded_bytes'] + frag_total_bytes) /
+                (state['_complete_frags_downloaded_bytes'] + frag_total_bytes) /
-            if s['status'] != 'finished':
+            if s['status'] == 'finished':
-                    state['downloaded_bytes'] + s['downloaded_bytes'])
+                    state['downloaded_bytes'])
-
+            if s['status'] != 'finished':
-                    start, time_now, estimated_size, state['downloaded_bytes'] + frag_downloaded_bytes)
+                    start, time_now, estimated_size,
-    call_home:         Boolean, true if we are allowed to contact the
+    call_home:         Boolean, true iff we are allowed to contact the
-        """ Returns None if the file should be downloaded """
+        """ Returns None iff the file should be downloaded """
-    """ Returns True if the content should be blocked """
+    """ Returns True iff the content should be blocked """
-    call_home:         Boolean, true iff we are allowed to contact the
+    call_home:         Boolean, true if we are allowed to contact the
-        """ Returns None iff the file should be downloaded """
+        """ Returns None if the file should be downloaded """
-    """ Returns True iff the content should be blocked """
+    """ Returns True if the content should be blocked """
-import io  # For Python 2 compatibilty
+import io  # For Python 2 compatibility
-                # remove the first occurance, there could be more than one annotation with the same text
+                # remove the first occurrence, there could be more than one annotation with the same text
-            # wich can't be exported to json
+            # which can't be exported to json
-            raise ExtractorError('A network error has occured.', cause=e, expected=True)
+            raise ExtractorError('A network error has occurred.', cause=e, expected=True)
-            raise ExtractorError('An extractor error has occured.', cause=e)
+            raise ExtractorError('An extractor error has occurred.', cause=e)
-                self._downloader.report_warning('unable to log in: bad username/password, or exceded login rate limit (~3/min). Check credentials or wait.')
+                self._downloader.report_warning('unable to log in: bad username/password, or exceeded login rate limit (~3/min). Check credentials or wait.')
-                self._downloader.report_warning('Unable to confirm login, you have to login in your brower and authorize the login.')
+                self._downloader.report_warning('Unable to confirm login, you have to login in your browser and authorize the login.')
-        # Embeded Ustream video
+        # Embedded Ustream video
-        # Look for embeded soundcloud player
+        # Look for embedded soundcloud player
-        # Serial's serie
+        # Serial's series
-        # MDR regularily deletes its videos
+        # MDR regularly deletes its videos
-    # Does not include https becuase its certificate is invalid
+    # Does not include https because its certificate is invalid
-            self._downloader.report_warning('Got an empty reponse, trying '
+            self._downloader.report_warning('Got an empty response, trying '
-            # simular to GameSpotIE
+            # similar to GameSpotIE
-    """ Allows adressing of the test cases as test:yout.*be_1 """
+    """ Allows addressing of the test cases as test:yout.*be_1 """
-        # If is_geo_restricted is true, it doesn't neceserally mean we can't download it
+        # If is_geo_restricted is true, it doesn't necessarily mean we can't download it
-        # season single serie with og:video:iframe
+        # season single series with og:video:iframe
-                        # Assume unitialized
+                        # Assume uninitialized
-        # A bad aproximation?
+        # A bad approximation?
-    # The lower-case forms are of course incorrect and inofficial,
+    # The lower-case forms are of course incorrect and unofficial,
-            frag_total_bytes = s.get('total_bytes', 0)
+            frag_total_bytes = s.get('total_bytes') or 0
-            r'ContentURL_(\d{3,4})[pP][^=]+=([^&]+)', webpage):
+                r'ContentURL_(\d{3,4})[pP][^=]+=([^&]+)', webpage):
-from ..compat import compat_urllib_parse
+from ..compat import (
-                        'http://www.dcndigital.ae/media/%s' % video['id'], 'DCNVideo'))
+                        'http://www.dcndigital.ae/media/%s' % video_id, 'DCNVideo', video_id))
-        # multiple formats
+        # 2 formats
-                quoted_b64_url)).encode('ascii').decode('utf-8')
+                quoted_b64_url).encode('ascii')).decode('utf-8')
-            r'ContentURL_(\d{3,4})[pP][^=]+=([^&]+)', webpage)]
+        file_url = self._search_regex(
-            })
+        self._sort_formats(formats)
-from base64 import b64decode
+import base64
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?bigflix\.com/.+/(?P<id>[0-9]+)'
-    }
+    }, {
-            r'file=([^&]+)', webpage, 'video url')).encode('ascii')).decode('utf-8')
+        def decode_url(quoted_b64_url):
-            'url': video_url,
+            'formats': formats
-    _VALID_URL = r'https?://(?:www\.)?canalc2\.tv/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:(?:www\.)?canalc2\.tv/video/|archives-canalc2\.u-strasbg\.fr/video\.asp\?.*\bidVideo=)(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            })
+
-__version__ = '2016.01.01'
+__version__ = '2016.01.09'
-                })
+            if isinstance(source_file, dict):
-                'duration': 893,
+                'duration': 893.52,
-                'duration': 200,
+                'duration': 200.48,
-            r"<a href='[^']+xhamster\.com/user/[^>]+>(?P<uploader>[^<]+)",
+            r'<span[^>]+itemprop=["\']author[^>]+><a[^>]+href=["\'].+?xhamster\.com/user/[^>]+>(?P<uploader>.+?)</a>',
-             r'<meta[^>]+itemprop=".*?caption.*?"[^>]+content="(.+?)"'], webpage, 'title')
+            [r'<h1[^>]*>([^<]+)</h1>',
-            view_count = str_to_int(view_count)
+        view_count = int_or_none(self._search_regex(
-    str_to_int,
+    float_or_none,
-    parse_duration,
+    str_to_int,
-                                                          webpage, 'duration', fatal=False))
+        duration = float_or_none(self._search_regex(
-            upload_date = unified_strdate(upload_date)
+        upload_date = unified_strdate(self._search_regex(
-             r'<h1(?: itemprop="name")?>([^<]+)</h1>'], webpage, 'title')
+            [r'<title[^>]*>(.+?)(?:,\s*[^,]*?\s*Porn\s*[^,]*?:\s*xHamster[^<]*| - xHamster\.com)</title>',
-             r'<h1>([^<]+)</h1>'], webpage, 'title')
+             r'<h1(?: itemprop="name")?>([^<]+)</h1>'], webpage, 'title')
-            surl = smuggle_url(player_url, {'Referer': url})
+            surl = smuggle_url(player_url, {'http_headers': {'Referer': url}})
-        url, data = unsmuggle_url(url)
+        url, data = unsmuggle_url(url, {})
-        if data is not None:
+        if 'http_headers' in data:
-            headers.update(data)
+            headers.update(data['http_headers'])
-                if data and '_video_password_verified' in data:
+                if '_video_password_verified' in data:
-from ..compat import compat_urllib_parse
+from ..compat import (
-    _VALID_URL = r'https?://(?:www\.)?ivideon\.com/tv/camera/(?P<id>\d+-[\da-f]+)/(?P<camera_id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?ivideon\.com/tv/(?:[^/]+/)*camera/(?P<id>\d+-[\da-f]+)/(?P<camera_id>\d+)'
-        webpage = self._download_webpage(url, server_id, fatal=False)
+        webpage = self._download_webpage(camera_url, server_id, fatal=False)
-                        media_url, segment_title, 'mp4', preference=0, m3u8_id='hls'))
+                        media_url, segment_title, 'mp4', preference=0,
-        next_href = None
+        COMMON_QUERY = {
-                next_href = None
+            next_href = response.get('next_href')
-                    title="([^"]+)"\s+
+                    (?:title|href)="([^"]+)"\s+
-                [^<]+
+                    class="(?:yt-uix-redirect-link|yt-uix-sessionlink[^"]*)".*?>
-            video_play_path = stream_info.find('./file').text
+            video_url = xpath_text(stream_info, './host')
-from ..utils import url_basename
+from ..compat import compat_urllib_parse
-}
+class NprIE(InfoExtractor):
-        config = self._download_json(json_url, video_id)
+        playlist_id = self._match_id(url)
-        content = config["list"]["story"]
+        config = self._download_json(
-        print album_title['$text']
+        story = config['list']['story'][0]
-                        song_id = x["id"]
+        KNOWN_FORMATS = ('threegp', 'mp4', 'mp3')
-                        formats = []
+        entries = []
-                    'entries': entries  }
+        playlist_title = story.get('title', {}).get('$text')
-                'Course %s is not free. You have to pay for it before you can download.'
+                'Course %s is not free. You have to pay for it before you can download. '
-        enroll_url = self._search_regex(
+        checkout_url = unescapeHTML(self._search_regex(
-            self.to_screen('%s: Already enrolled in' % course_id)
+            webpage, 'enroll url', group='url', default=None))
-                video_id, 'mp4'))
+                video_id, 'mp4', m3u8_id='hls'))
-                '%s/manifest.f4m' % mobj.group('src'), video_id))
+                '%s/manifest.f4m' % mobj.group('src'), video_id, f4m_id='hds'))
-    _VALID_URL = r'https?://(?:deredactie|sporza|cobra)\.be/cm/(?:[^/]+/)+(?P<id>[^/]+)/*'
+    _VALID_URL = r'https?://(?:deredactie|sporza|cobra(?:\.canvas)?)\.be/cm/(?:[^/]+/)+(?P<id>[^/]+)/*'
-    _TEST = {
+    _TESTS = [{
-            'ext': 'flv',
+            'ext': 'mp4',
-    }
+    }, {
-                        info['episode'] = v.get('title', episode_fallback)
+                        info['episode'] = v.get('title') or episode_fallback
-                        info['episode_number'] = int_or_none(v.get('number'))
+                        episode_number = int_or_none(v.get('number'))
-                    })
+            if isinstance(value, list):
-        retval = subprocess.call(args)
+        retval = subprocess.call(args, stdin=subprocess.PIPE)
-            'ext': 'flv',
+            'ext': 'mp4',
-            'description': 'Tim Thurston guides you through a millennium of sacred music featuring Gregorian chant, pure solo voices and choral masterpieces, framed around the glorious music of J.S. Bach.',
+            'description': 'md5:9ce124a7fb41559ec68f06387cabddf0',
-        json_string = self._download_json(feeds_url, item_id)
+
-            'formats': formats,
+            'timestamp': timestamp,
-            formats.append({'url': mg.get('url')})
+            formats.append({'url': mg['url']})
-            formats.extend(hls_formats)
+            formats.extend(self._extract_m3u8_formats(
-            formats.extend(f4m_formats)
+            formats.extend(self._extract_f4m_formats(
-            hls_url = mg['hls_server'] +  mg['hls_url']
+            hls_url = mg['hls_server'] + mg['hls_url']
-                    hls_url, item_id, 'mp4', m3u8_id='hls', fatal=False)
+                hls_url, item_id, 'mp4', m3u8_id='hls', fatal=False)
-                    f4m_url, item_id, f4m_id='hds', fatal=False)
+                f4m_url, item_id, f4m_id='hds', fatal=False)
-from .rte import RteIE
+from .rte import RteIE, RteRadioIE
-            'ext': 'mp4',
+            'ext': 'flv',
-        } for f in f4m_formats]
+
-                for serie in re.findall(r'<strong><a href="/watch/%s/(\d+)">(?:[^<]+)</a></strong>' % compilation_id, html)]
+        return [
-            season_page = self._download_webpage(url, compilation_id, 'Downloading season %s web page' % season_id)
+            season_page = self._download_webpage(
-            if len(seasons) == 0:  # No seasons in this compilation
+            seasons = re.findall(
-                'thumbnail': 'http://thumbs.ivi.ru/f20.vcp.digitalaccess.ru/contents/d/1/c3c885163a082c29bceeb7b5a267a6.jpg',
+                'thumbnail': 're:^https?://.*\.jpg$',
-                'title': 'ÐÐ²Ð¾Ðµ Ð¸Ð· Ð»Ð°ÑÑÐ° - Ð¡ÐµÑÐ¸Ñ 1',
+                'title': 'ÐÐ²Ð¾Ðµ Ð¸Ð· Ð»Ð°ÑÑÐ° - ÐÐµÐ»Ð¾ ÐÐ¾Ð»ÑÐ´Ð±ÐµÑÐ³Ð° (1 ÑÐ°ÑÑÑ)',
-                'thumbnail': 'http://thumbs.ivi.ru/f15.vcp.digitalaccess.ru/contents/8/4/0068dc0677041f3336b7c2baad8fc0.jpg',
+                'thumbnail': 're:^https?://.*\.jpg$',
-        return int(m.group('commentcount')) if m is not None else 0
+    _KNOWN_FORMATS = ['MP4-low-mobile', 'MP4-mobile', 'FLV-lo', 'MP4-lo', 'FLV-hi', 'MP4-hi', 'MP4-SHQ']
-        video_json_page = self._download_webpage(
+        request = sanitized_Request(
-        } for x in result['files'] if x['content_format'] in self._known_formats]
+            'preference': self._KNOWN_FORMATS.index(x['content_format']),
-        compilation = result['compilation']
+        duration = int_or_none(result.get('duration'))
-        thumbnail = previews[-1]['url'] if len(previews) > 0 else None
+        thumbnails = [{
-        comment_count = self._extract_comment_count(video_page)
+        description = self._og_search_description(webpage, default=None) or self._html_search_meta(
-            'thumbnail': thumbnail,
+            'series': compilation,
-            'url': 'http://www.bbc.co.uk/music/clips/p02frcc3',
+            'url': 'http://www.bbc.co.uk/music/clips/p022h44b',
-                'id': 'p02frcch',
+                'id': 'p022h44j',
-                'duration': 3507,
+                'title': 'BBC Proms Music Guides, Rachmaninov: Symphonic Dances',
-            'url': 'http://www.bbc.co.uk/programmes/b06bp7lf',
+            'url': 'http://www.bbc.co.uk/programmes/b06rkn85',
-                'id': 'b06bp7kf',
+                'id': 'b06rkms3',
-                'duration': 10800,
+                'title': "Best of the Mini-Mixes 2015: Part 3, Annie Mac's Friday Night - BBC Radio 1",
-from .min20 import Min20IE
+from .twentymin import TwentyMinutenIE
-        }
+# coding: utf-8
-    _TEST = {
+    _VALID_URL = r'http://www\.20min\.ch/(videotv/\?vid=(?P<video_id>[0-9]+)|.+?-(?P<page_id>[0-9]+)$)'
-    }
+    }, {
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        title = self._html_search_regex(r'<h1><span>(.+?)</span></h1>', webpage, 'title')
+        title = self._html_search_regex(r'<h1>.*<span>(.+?)</span></h1>', webpage, 'title')
-            'f4f', 'f4m', 'm3u8', 'smil'):
+    # Try extract ext from URLs like http://example.com/foo/bar.mp4/?download
-        '102': {'ext': 'webm', 'height': 720, 'format_note': '3D', 'preference': -20},
+        '5': {'ext': 'flv', 'width': 400, 'height': 240, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},
-        '151': {'ext': 'mp4', 'height': 72, 'format_note': 'HLS', 'preference': -10},
+        '92': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},
-        '266': {'ext': 'mp4', 'height': 2160, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40, 'vcodec': 'h264'},
+        '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'acodec': 'none', 'vcodec': 'h264', 'preference': -40},
-        '271': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40},
+        '278': {'ext': 'webm', 'height': 144, 'format_note': 'DASH video', 'acodec': 'none', 'container': 'webm', 'vcodec': 'vp9', 'preference': -40},
-        '315': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40, 'fps': 60, 'vcodec': 'vp9'},
+        '272': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'acodec': 'none', 'vcodec': 'vp9', 'preference': -40},
-        '172': {'ext': 'webm', 'vcodec': 'none', 'format_note': 'DASH audio', 'abr': 256, 'preference': -50},
+        '171': {'ext': 'webm', 'acodec': 'vorbis', 'vcodec': 'none', 'format_note': 'DASH audio', 'abr': 128, 'preference': -50},
-)
+from .zdf import ZDFIE
-class DreiSatIE(InfoExtractor):
+class DreiSatIE(ZDFIE):
-        }
+        return self.extract_from_xml_url(video_id, details_url)
-                    'protocol': proto,
+        status_code = doc.find('./status/statuscode')
-                    video_url, video_id, 'mp4', m3u8_id='hls', fatal=False))
+                    video_url, video_id, 'mp4', m3u8_id=format_id, fatal=False))
-                    video_url, video_id, f4m_id='hds', fatal=False))
+                    video_url, video_id, f4m_id=format_id, fatal=False))
-            'description': 'md5:2a222d89ba4455a3af19940c0481bb78',
+            'description': 'md5:870ec08f7d8547c29c93010899103751',
-            'title': 'QQé³ä¹å·å³°æ¦Â·æ¬§ç¾',
+            'title': 'å·å³°æ¦Â·æ¬§ç¾',
-    _TEST = {
+    _TESTS = [{
-    }
+        'skip': 'playlist gone',
-
+            transform_source=strip_jsonp)
-            ) for song in list_json['songlist']
+            ) for song in cdlist['songlist']
-        list_description = clean_html(unescapeHTML(list_json.get('desc')))
+        list_name = cdlist.get('dissname')
-                episode['url'], video_title=episode['title']))
+        entries = [self.url_result(
-        return self._download_json('http://app.video.baidu.com/%s/?worktype=adnative%s&id=%s' % (path, category, playlist_id), playlist_id)
+    def _call_api(self, path, category, playlist_id, note):
-        playlist_detail = self._call_api('xqinfo', category, playlist_id)
+        playlist_detail = self._call_api(
-        episodes_detail = self._call_api('xqsingle', category, playlist_id)
+        episodes_detail = self._call_api(
-            title = self._og_search_title(webpage)
+            title = self._og_search_title(webpage, default=None) or self._html_search_regex(
-            'description': 'md5:40a9c1b1c7f4e05d642e7bb1c84eeda0',
+            'description': 'md5:51be07afe461cf99fa61231421b5397c',
-        playlist_description = playlist_detail.get('intro')
+        playlist_description = unescapeHTML(playlist_detail.get('intro'))
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:(?:programmes/(?!articles/)|iplayer(?:/[^/]+)?/(?:episode/|playlist/))|music/clips[/#])(?P<id>%s)' % _ID_REGEX
+    _VALID_URL = r'''(?x)
-                            'format_id': '%s-%s' % (proto, label if label else tbr),
+                            'format_id': format_id,
-from .testtube import TestTubeIE
+    qualities,
-            for media_type, media in video_data['media'].items():
+            for vcodec, media in video_data['media'].items():
-                            'format_id': '%s-%s' % (media_type, quality_id),
+                            'format_id': '%s-%s' % (vcodec, quality_id),
-                    url + '/%s' % episode['slug']) for episode in episodes_data])
+                    'http://%s/%s/%s' % (domain, display_id, episode['slug'])) for episode in episodes_data])
-        }
+from .revision3 import Revision3IE
-        chapter, chapter_id = None, None
+        chapter, chapter_number = None, None
-                        entry['chapter_id'] = chapter_id
+                    if chapter_number:
-                chapter_id = asset.get('index') or asset.get('object_index')
+                chapter_number = asset.get('index') or asset.get('object_index')
-            'episode_id': None,
+            'episode_number': None,
-            'season_id': 5,
+            'season_number': 5,
-            'episode_id': 40,
+            'episode_number': 40,
-            'season_id': 2,
+            'season_number': 2,
-            'episode_id': None,
+            'episode_number': None,
-            'season_id': 99,
+            'season_number': 99,
-        episode_id = data.get('episode_of_season') or None
+        episode_number = int_or_none(data.get('episode_of_season') or None)
-        season_id = data.get('season_pos') or None
+        season_number = int_or_none(data.get('season_pos') or None)
-            'episode_id': episode_id,
+            'episode_number': episode_number,
-            'season_id': season_id,
+            'season_number': season_number,
-                    or unicode string.
+    chapter_number: Number of the chapter the video belongs to, as an integer.
-                    integer or unicode string.
+    season_number:  Number of the season the video episode belongs to, as an integer.
-                    or unicode string.
+    episode_number: Number of the video episode within a season, as an integer.
-        }
+        }, {
-            video_id = self._search_regex(CONTENT_ID_REGEXES, webpage, 'content ID')
+            alias = self._search_regex(
-            <(?:span|div)\s+class='label\s+filetype'>(?P<format>.*?)</(?:span|div)>\s*
+            <(?:span|div)\s+class='label\s+filetype'>(?P<format>[^<]*)</(?:span|div)>\s*
-                <a\s+href='(?P<torrent_url>[^']+\.torrent)'
+                <a\s+(?:download\s+)?href='(?P<torrent_url>[^']+\.torrent)'
-                                 language?
+                    * language   Language code, e.g. "de" or "en-US".
-__version__ = '2015.12.31'
+__version__ = '2016.01.01'
-            'description': 'md5:5ddbf8c734800267f2cee4eab187bc1b',
+            'description': 'md5:80be298773966f66d56cb11260b879af',
-            'upload_date': '20131229',
+            'upload_date': '20131228',
-            r"(?s)<p class='description'>(.*?)</p>",
+            r"(?s)<h3>About</h3>(.+?)<h3>",
-            r"(?s)<span class='[^']*fa-calendar-o'></span>(.*?)</li>",
+            r"(?s)<span[^>]+class='[^']*fa-calendar-o'[^>]*>(.+?)</span>",
-    _VALID_URL = r'https?://(?:www\.)?media\.ccc\.de/[^?#]+/[^?#/]*?_(?P<id>[0-9]{8,})._[^?#/]*\.html'
+    _VALID_URL = r'https?://(?:www\.)?media\.ccc\.de/v/(?P<id>[^/?#&]+)'
-        'url': 'http://media.ccc.de/browse/congress/2013/30C3_-_5443_-_en_-_saal_g_-_201312281830_-_introduction_to_processor_design_-_byterazor.html#video',
+    _TESTS = [{
-            'id': '20131228183',
+            'id': '30C3_-_5443_-_en_-_saal_g_-_201312281830_-_introduction_to_processor_design_-_byterazor',
-    }
+    }, {
-            'mgid': uri
+            'mgid': uri,
-        info_url += data
+        info_url = feed_url + '?' + self._get_feed_query(uri)
-        webpage = self._download_webpage(url, title)
+    def _extract_mgid(self, webpage):
-
+from ..compat import compat_urlparse
-        webpage = self._download_webpage(url, video_id)
+        video_id = self._match_id(url)
-            r'<h1><a class="movie-title".*?>(.*?)</a></h1>', webpage, 'title')
+        title = self._html_search_regex(
-            r'data-movieid="(.*?)"', webpage, 'movieid')
+        video_id = self._search_regex(
-        video_url = self._download_webpage(geturl, video_id)
+        video_url = self._download_webpage(
-            thumbnail = thumbnail.replace('..', 'http://www.einthusan.com')
+            thumbnail = compat_urlparse.urljoin(url, remove_start(thumbnail, '..'))
-            'title': video_title,
+            'title': title,
-            webpage, 'video url')
+        movieid = self._html_search_regex(
-
+from ..compat import compat_urlparse
-        webpage = self._download_webpage(url, video_id)
+        video_id = self._match_id(url)
-            r'<h1><a class="movie-title".*?>(.*?)</a></h1>', webpage, 'title')
+        title = self._html_search_regex(
-            r'data-movieid="(.*?)"', webpage, 'movieid')
+        video_id = self._search_regex(
-        video_url = self._download_webpage(geturl, video_id)
+        video_url = self._download_webpage(
-            thumbnail = thumbnail.replace('..', 'http://www.einthusan.com')
+            thumbnail = compat_urlparse.urljoin(url, remove_start(thumbnail, '..'))
-            'title': video_title,
+            'title': title,
-            webpage, 'video url')
+        movieid = self._html_search_regex(
-from .mtv import MTVIE
+from .mtv import MTVServicesInfoExtractor
-class TVLandIE(MTVIE):
+class TVLandIE(MTVServicesInfoExtractor):
-    _FEED_URL = 'http://www.tvland.com/feeds/mrss/?uri='
+    _FEED_URL = 'http://www.tvland.com/feeds/mrss/'
-        return self._get_videos_info_from_url(self._FEED_URL + mgid, video_id)
+from .tvland import TVLandIE
-            'title': 'dm_140128_30for30Shorts___JudgingJewellv2',
+            'title': '30 for 30 Shorts: Judging Jewell',
-            'title': 'int_151206_Must_See_Moments_Best_of_MLS_2015_season',
+            'title': 'Must-See Moments: Best of the MLS season',
-            'OoyalaExternal')
+        title = remove_end(
-            'https://espn.go.com/video/iframe/twitter/?id=%s' % video_id, video_id)
+            player_url, video_id)
-            'ooyalaexternal:espn:%s:%s' % (video_id, pcode),
+            'ooyalaexternal:%s:%s:%s' % (cms, video_id, pcode),
-            'description': '',
+            'description': None,
-
+    compat_str,
-    _TESTS = [{
+    _VALID_URL = r'https?://(?:.+?\.)?channel\.pandora\.tv/channel/video\.ptv\?'
-            'title': '\u982d\u3092\u64ab\u3067\u3066\u304f\u308c\u308b\uff1f',
+            'ext': 'flv',
-
+    }
-        data = self._download_json(data_url, video_id)
+        data = self._download_json(
-        for format_id in sorted([k for k in info if k.startswith('v') and k.endswith('Url') and info[k]]):
+        for format_id, format_url in info.items():
-                'height': int(format_id[1:-3]),
+                'format_id': '%sp' % height,
-            'view_count': info['hit'],
+            'description': info.get('body'),
-from .tlc import TlcIE, TlcDeIE
+from .tlc import TlcDeIE
-        )\.com/([^/]+/)*(?P<id>[^\./\?#]+)'''
+        )\.com/(?:[^/]+/)*(?P<id>[^./?#]+)'''
-    _VALID_URL = r'https?://www\.discovery\.com\/[a-zA-Z0-9\-]*/[a-zA-Z0-9\-]*/videos/(?P<id>[a-zA-Z0-9_\-]*)(?:\.htm)?'
+    _VALID_URL = r'''(?x)http://(?:www\.)?(?:
-            'upload_date': '20110418',
+            'timestamp': 1302032462,
-        'playlist_count': 9,
+        'playlist_mincount': 10,
-        info = self._download_json(url + '?flat=1', video_id)
+        display_id = self._match_id(url)
-                video_info['src'], video_id, ext='mp4',
+                video_info['src'], display_id, 'mp4', 'm3u8_native', m3u8_id='hls',
-            'webpage_url': video_info.get('href'),
+            'webpage_url': video_info.get('href') or video_info.get('url'),
-        return self.playlist_result(entries, video_id, video_title)
+        return self.playlist_result(entries, display_id, video_title)
-# -*- coding: utf-8 -*-
+# coding: utf-8
-
+    xpath_text,
-    ]
+    _VALID_URL = r'https?://(?:www\.)?regio-tv\.de/video/(?P<id>[0-9]+)'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            webpage, 'title')
+        key = self._search_regex(
-        video_data = self._download_xml(request, video_id, 'video data')
+        request = sanitized_Request(
-        description = self._html_search_meta('description', webpage)
+        video_url = xpath_text(
-            'thumbnail': thumbnail,
+            'thumbnail': thumbnail,
-__version__ = '2015.12.29'
+__version__ = '2015.12.31'
-    _VIDEO_INFO_TEMPLATE = 'http://service.canal-plus.com/video/rest/getVideosLiees/%s/%s'
+    _VIDEO_INFO_TEMPLATE = 'http://service.canal-plus.com/video/rest/getVideosLiees/%s/%s?format=json'
-        'md5': 'b3481d7ca972f61e37420798d0a9d934',
+        'md5': '12164a6f14ff6df8bd628e8ba9b10b78',
-            'ext': 'flv',
+            'ext': 'mp4',
-        'md5': 'f3a46edcdf28006598ffaf5b30e6a2d4',
+        'md5': '38b8f7934def74f0d6f3ba6c036a5f82',
-            'ext': 'flv',
+            'ext': 'mp4',
-        doc = self._download_xml(info_url, video_id, 'Downloading video XML')
+        video_data = self._download_json(info_url, video_id, 'Downloading video JSON')
-        infos = video_info.find('INFOS')
+        if isinstance(video_data, list):
-        preference = qualities(['MOBILE', 'BAS_DEBIT', 'HAUT_DEBIT', 'HD', 'HLS', 'HDS'])
+        preference = qualities(['MOBILE', 'BAS_DEBIT', 'HAUT_DEBIT', 'HD'])
-        fmt_url = next(iter(media.find('VIDEOS'))).text
+        fmt_url = next(iter(media.get('VIDEOS')))
-            format_url = fmt.text
+        for format_id, format_url in media['VIDEOS'].items():
-                    format_url, video_id, 'mp4', preference=preference(format_id)))
+                    format_url, video_id, 'mp4', 'm3u8_native', m3u8_id=format_id, fatal=False))
-                    format_url + '?hdcore=2.11.3', video_id, preference=preference(format_id)))
+                    format_url + '?hdcore=2.11.3', video_id, f4m_id=format_id, fatal=False))
-                    'url': format_url,
+                    # the secret extracted ya function in http://player.canalplus.fr/common/js/canalPlayer.js
-            'comment_count': int(infos.find('NB_COMMENTS').text),
+            'title': '%s - %s' % (titrage['TITRE'],
-    _VALID_URL = r'http://www\.discovery\.com\/[a-zA-Z0-9\-]*/[a-zA-Z0-9\-]*/videos/(?P<id>[a-zA-Z0-9_\-]*)(?:\.htm)?'
+    _VALID_URL = r'https?://www\.discovery\.com\/[a-zA-Z0-9\-]*/[a-zA-Z0-9\-]*/videos/(?P<id>[a-zA-Z0-9_\-]*)(?:\.htm)?'
-    _WORKING = False
+from ..utils import remove_start
-        ]
+        entries = []
-                lecture_id = self._download_lecture(course_id, lecture_id)
+                lecture = self._download_lecture(course_id, lecture_id)
-        '--convert-subtitles', '--convert-subs',
+        '--convert-subs', '--convert-subtitles',
-                    info['subtitiles'].setdefault('English', []).append({
+                    info.setdefault('subtitles', {}).setdefault('English', []).append({
-                if '.f4m' in asset_url:
+            for asset in source['url']:
-                elif '.m3u8' in asset_url:
+                        f4m_id=format_id, fatal=False))
-                    asset_url = asset['text']
+                        m3u8_id=format_id, fatal=False))
-                    if asset_url.startswith('rtmp'):
+                    if protocol == 'RTMP':
-                        'format_id': asset['@quality'],
+                        'format_id': format_id,
-                        'preference': preference(asset['@quality']),
+                        'preference': preference(quality),
-                for href in re.findall(r'<a href="/?(.+?%s\.html)" rel="nofollow"' % self._PLAYER_REGEX, webpage)
+                for href in re.findall(
-            self._html_search_regex(r'<param name="flashvars" value="([^"]+)"', webpage, 'flashvars'))
+        flashvars = compat_parse_qs(self._html_search_regex(
-            upload_date = self._html_search_meta('DC.Date', webpage, 'upload date')
+            upload_date = self._html_search_meta(
-            formats.extend(self._extract_f4m_formats(video_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18', page_id, f4m_id='hds', fatal=False))
+            formats.extend(self._extract_f4m_formats(
-            }))
+            formats.extend(self._extract_smil_formats(
-        m3u8_url = self._search_regex(r'rel="adaptiv"[^>]+href="([^"]+)"', webpage, 'm3u8 url', default=None)
+        m3u8_url = self._search_regex(
-            formats.extend(self._extract_m3u8_formats(m3u8_url, page_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+            formats.extend(self._extract_m3u8_formats(
-        direct_urls = re.findall(r'rel="web(S|M|L|XL)"[^>]+href="([^"]+)"', webpage)
+        direct_urls = re.findall(
-                'http://player.ooyala.com/sas/player_api/v1/authorization/embed_code/%s/%s?' % (pcode, embed_code) + compat_urllib_parse.urlencode({'domain': domain, 'supportedFormats': supported_format}),
+                self._AUTHORIZATION_URL_TEMPLATE % (pcode, embed_code) +
-                    url = base64.b64decode(stream['url']['data'].encode('ascii')).decode('utf-8')
+                    url = base64.b64decode(
-                        formats.extend(self._extract_m3u8_formats(url, embed_code, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+                        formats.extend(self._extract_m3u8_formats(
-                        formats.extend(self._extract_f4m_formats(url, embed_code, f4m_id='hds', fatal=False))
+                        formats.extend(self._extract_f4m_formats(
-                        formats.extend(self._extract_smil_formats(url, embed_code, fatal=False))
+                        formats.extend(self._extract_smil_formats(
-                raise ExtractorError('%s said: %s' % (self.IE_NAME, cur_auth_data['message']), expected=True)
+                raise ExtractorError('%s said: %s' % (
-        content_tree_url = 'http://player.ooyala.com/player_api/v1/content_tree/embed_code/%s/%s' % (embed_code, embed_code)
+        content_tree_url = self._CONTENT_TREE_BASE + 'embed_code/%s/%s' % (embed_code, embed_code)
-            'duration': 1302000,
+            'duration': 1302.0,
-        content_tree_url = 'http://player.ooyala.com/player_api/v1/content_tree/external_id/%s/%s:%s' % (pcode, partner_id, video_id)
+        content_tree_url = self._CONTENT_TREE_BASE + 'external_id/%s/%s:%s' % (pcode, partner_id, video_id)
-                media['mediaUri'] + '&output=43', video_id, transform_source=fix_xml)
+                media['mediaUri'] + '&output=43',
-                        fatal=False))
+                        media_url, video_id, 'mp4', 'm3u8_native',
-        sources = self._parse_json(self._search_regex(r'sources\s*:\s*(\[[^\]]+\])', setup_js, 'sources'), display_id, js_to_json)
+        setup_js = self._search_regex(
-                    formats.extend(self._extract_m3u8_formats(format_url, display_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+                    formats.extend(self._extract_m3u8_formats(
-            'thumbnail': self._search_regex(r'image\s*:\s*"([^"]+)"', setup_js, 'thumbnail', default=None),
+            'title': self._search_regex(
-                    format_url, media_id, 'mp4', m3u8_id=format_id, fatal=False))
+                    format_url, media_id, 'mp4', 'm3u8_native', m3u8_id=format_id, fatal=False))
-            raise ExtractorError('%s said: %s' % (self.IE_NAME, self._ERRORS[media_data['block']]), expected=True)
+            raise ExtractorError('%s said: %s' % (
-                    formats.extend(self._extract_f4m_formats(asset_url + '?hdcore=3.4.0', media_id, f4m_id='hds', fatal=False))
+                    formats.extend(self._extract_f4m_formats(
-                    formats.extend(self._extract_m3u8_formats(asset_url, media_id, m3u8_id='hls', fatal=False))
+                    formats.extend(self._extract_m3u8_formats(
-            return self.url_result(self._search_regex(self._EMBED_RE, webpage, 'embed url'))
+            return self.url_result(self._search_regex(
-        api_data = self._download_json(self._API_URL_TEMPLATE % video_id, video_id)
+        api_data = self._download_json(
-            formats.extend(self._extract_m3u8_formats(m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
+            formats.extend(self._extract_m3u8_formats(
-            formats.extend(self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False))
+            formats.extend(self._extract_f4m_formats(
-                formats.extend(self._extract_m3u8_formats(stream_url_hls, video_id, 'mp4', entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))
+                formats.extend(self._extract_m3u8_formats(
-                formats.extend(self._extract_f4m_formats(json_data.get('stream_url_hds') + '?hdcore=3.4.0', video_id, -1, f4m_id='hds', fatal=False))
+                formats.extend(self._extract_f4m_formats(
-    IE_NAME = 'daum.net'
+    IE_NAME = 'daum.net:clip'
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'ext': 'flv',
+                'ext': 'mp4',
-                f4m_formats = self._extract_f4m_formats(
+                formats.extend(self._extract_f4m_formats(
-                    formats.extend(f4m_formats)
+                    media_id, f4m_id=format_id, fatal=False))
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-                })
+        thumbnails = [{
-            assets = {}
+        for source in media_data.get('Playlists', {}).get('Playlist', []) + media_data.get('Downloads', {}).get('Download', []):
-                        formats.extend(f4m_formats)
+                    formats.extend(self._extract_f4m_formats(asset_url + '?hdcore=3.4.0', media_id, f4m_id='hds', fatal=False))
-                        formats.extend(m3u8_formats)
+                    formats.extend(self._extract_m3u8_formats(asset_url, media_id, m3u8_id='hls', fatal=False))
-            'ext': 'flv',
+            'ext': 'mp4',
-__version__ = '2015.12.23'
+__version__ = '2015.12.29'
-from .franceculture import FranceCultureIE
+from .franceculture import (
-        video_id = self._match_id(url)
+    def _extract_from_player(self, url, video_id):
-            'description': 'startswith:Avec :Jean-Baptiste PÃ©retiÃ© pour son documentaire sur Arte "La revanche des Â« geeks Â», une enquÃªte menÃ©e aux Etats',
+            'thumbnail': r're:^http://static\.franceculture\.fr/.*/images/player/Carnet-nomade\.jpg$',
-                f4m_formats = self._extract_f4m_formats(
+                formats.extend(self._extract_f4m_formats(
-                    formats.extend(f4m_formats)
+                    video_id, f4m_id='hds', fatal=False))
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-                        f4m_formats = self._extract_f4m_formats(
+                        formats.extend(self._extract_f4m_formats(
-                            formats.extend(f4m_formats)
+                            video_id, preference=-1, f4m_id='hds', fatal=False))
-                            formats.extend(m3u8_formats)
+                        formats.extend(self._extract_m3u8_formats(
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(
-                formats.extend(f4m_formats)
+            formats.extend(self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False))
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(stream_url_hls, video_id, 'mp4', entry_protocol='m3u8_native', m3u8_id='hls', fatal=False))
-                    formats.extend(f4m_formats)
+                formats.extend(self._extract_f4m_formats(json_data.get('stream_url_hds') + '?hdcore=3.4.0', video_id, -1, f4m_id='hds', fatal=False))
-                m3u8_formats = self._extract_m3u8_formats(
+                formats.extend(self._extract_m3u8_formats(
-                    formats.extend(m3u8_formats)
+                    m3u8_id=supplier, fatal=False))
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-                    formats.extend(f4m_formats)
+                formats.extend(self._extract_f4m_formats(
-                    formats.extend(f4m_formats)
+                formats.extend(self._extract_f4m_formats(
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-                m3u8_formats = self._extract_m3u8_formats(
+                formats.extend(self._extract_m3u8_formats(
-                    formats.extend(m3u8_formats)
+                    m3u8_id='hls', fatal=False))
-                        formats.extend(f4m_formats)
+                    formats.extend(self._extract_f4m_formats(
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-                    formats.extend(f4m_formats)
+                formats.extend(self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False))
-                            formats.extend(m3u8_formats)
+                        formats.extend(self._extract_m3u8_formats(
-                            formats.extend(f4m_formats)
+                        formats.extend(self._extract_f4m_formats(
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(
-                        formats.extend(m3u8_formats)
+                    formats.extend(self._extract_m3u8_formats(
-            f4m_formats = self._extract_f4m_formats(
+            formats.extend(self._extract_f4m_formats(
-                formats.extend(f4m_formats)
+                video_id, f4m_id='hds', fatal=False))
-                        m3u8_formats = self._extract_m3u8_formats(
+                        formats.extend(self._extract_m3u8_formats(
-                            formats.extend(m3u8_formats)
+                            preference=preference, m3u8_id='%s-hls' % funimation_id, fatal=False))
-            formats.extend(m3u8_formats)
+        formats.extend(self._extract_m3u8_formats(
-                m3u8_formats = self._extract_m3u8_formats(
+                formats.extend(self._extract_m3u8_formats(
-                    formats.extend(m3u8_formats)
+                    m3u8_id='hls', fatal=False))
-                        formats.extend(m3u8_formats)
+                    formats.extend(self._extract_m3u8_formats(format_url, video_id, 'mp4', m3u8_id='hls', fatal=False))
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
-                formats.extend(f4m_formats)
+            formats.extend(self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False))
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-            formats.extend(m3u8_formats)
+        formats.extend(self._extract_m3u8_formats(
-                formats.extend(smil_formats)
+            formats.extend(self._extract_smil_formats(smil_url, video_id))
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(
-                formats.extend(f4m_formats)
+            formats.extend(self._extract_f4m_formats(
-                formats.extend(smil_formats)
+            formats.extend(self._extract_smil_formats(smil_url, broadcast_id))
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(video_url, video_id, m3u8_id='hls', fatal=False))
-                    formats.extend(f4m_formats)
+                formats.extend(self._extract_f4m_formats(video_url + '?hdcore=3.4.1.1', video_id, f4m_id='hds', fatal=False))
-                            formats.extend(m3u8_formats)
+                        formats.extend(self._extract_m3u8_formats(url, embed_code, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
-                            formats.extend(f4m_formats)
+                        formats.extend(self._extract_f4m_formats(url, embed_code, f4m_id='hds', fatal=False))
-                            formats.extend(smil_formats)
+                        formats.extend(self._extract_smil_formats(url, embed_code, fatal=False))
-                    m3u8_formats = self._extract_m3u8_formats(
+                    formats.extend(self._extract_m3u8_formats(
-                        formats.extend(m3u8_formats)
+                        fatal=False))
-                    f4m_formats = self._extract_f4m_formats(
+                    formats.extend(self._extract_f4m_formats(
-                        formats.extend(f4m_formats)
+                        video_id, f4m_id='hds', fatal=False))
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-                    formats.extend(f4m_formats)
+                formats.extend(self._extract_f4m_formats(
-                            formats.extend(m3u8_formats)
+                        formats.extend(self._extract_m3u8_formats(
-                            formats.extend(f4m_formats)
+                        formats.extend(self._extract_f4m_formats(
-                        formats.extend(m3u8_formats)
+                    formats.extend(self._extract_m3u8_formats(format_url, display_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
-                m3u8_formats = self._extract_m3u8_formats(
+                formats.extend(self._extract_m3u8_formats(
-                    formats.extend(m3u8_formats)
+                    fatal=False))
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(
-                    m3u8_formats = self._extract_m3u8_formats(
+                    formats.extend(self._extract_m3u8_formats(
-                        formats.extend(m3u8_formats)
+                        m3u8_id='m3u8-%s' % protocol, fatal=False))
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(
-                formats.extend(f4m_formats)
+            formats.extend(self._extract_f4m_formats(video_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18', page_id, f4m_id='hds', fatal=False))
-            smil_formats = self._extract_smil_formats(video_url, page_id, False, {
+            formats.extend(self._extract_smil_formats(video_url, page_id, False, {
-                formats.extend(smil_formats)
+            }))
-                formats.extend(m3u8_formats)
+            formats.extend(self._extract_m3u8_formats(m3u8_url, page_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
-                    formats.extend(smil_formats)
+                formats.extend(self._extract_smil_formats(
-                    formats.extend(m3u8_formats)
+                formats.extend(self._extract_m3u8_formats(
-                    formats.extend(f4m_formats)
+                formats.extend(self._extract_f4m_formats(
-    compat_urllib_parse_urlparse,
+    determine_protocol,
-                preference = 0 if proto in ['http', 'https'] else -0.1
+                preference = 0
-from .zdf import extract_from_xml_url
+from .zdf import ZDFIE
-class PhoenixIE(InfoExtractor):
+class PhoenixIE(ZDFIE):
-        return extract_from_xml_url(self, video_id, api_url)
+        api_url = 'http://www.phoenix.de/php/mediaplayer/data/beitrags_details.php?ak=web&id=%s' % internal_id
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-        return extract_from_xml_url(self, video_id, xml_url)
+        return self.extract_from_xml_url(video_id, xml_url)
-        login_page_req.add_header('Cookie', 'locale=en_US')
+        self._set_cookie('facebook.com', 'locale', 'en_US')
-                    r'name="h"\s+(?:\w+="[^"]+"\s+)*?value="([^"]+)"', login_results, 'h'),
+                'fb_dtsg': fb_dtsg,
-        if matches:
+        # We first look for clipid, because clipprog always appears before
-                video_type = 'program'
+            video_type = 'clip' if video_type == 'id' else 'program'
-            m3u8_url, video_id, 'mp4', entry_protocol, m3u8_id='hls')
+            r'file\s*:\s*"([^"]+)', webpage, 'm3u8 url', fatal=False)
-from .tunein import TuneInIE
+from .tunein import (
-import re
+from ..compat import compat_urlparse
-    ]
+class TuneInBaseIE(InfoExtractor):
-        streams_url = station_info.get('StreamUrl')
+        content_id = self._match_id(url)
-                                 expected=True)
+            raise ExtractorError('No downloadable streams found', expected=True)
-            streams_url, station_id, note='Downloading stream data')
+            streams_url, content_id, note='Downloading stream data')
-            'id': station_id,
+            'id': content_id,
-                'ext': 'mp4',
+                'ext': 'flv',
-        if hds_url and stream_type != 'wasLive':
+        if hds_url:
-                hds_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18', video_id, f4m_id='hds', fatal=False)
+                hds_url + '?%s' % hdcore_sign, video_id, f4m_id='hds', fatal=False)
-                formats.extend(f4m_formats)
+                for entry in f4m_formats:
-        'url': 'http://www.livestream.com/znsbahamas',
+        'url': 'http://original.livestream.com/znsbahamas',
-    _VALID_URL = r'http://(?:www\.)iqiyi.com/._.+?\.html'
+    _VALID_URL = r'http://(?:[^.]+\.)?iqiyi\.com/.+\.html'
-    _VALID_URL = r'http://(?:www\.)iqiyi.com/v_.+?\.html'
+    _VALID_URL = r'http://(?:www\.)iqiyi.com/._.+?\.html'
-                m3u8_formats = self._extract_m3u8_formats(source_url, video_id, 'mp4', 'm3u8_native', fatal=False)
+                m3u8_formats = self._extract_m3u8_formats(
-                        m3u8_id='m3u8-%s' % protocol, fatal=None)
+                        m3u8_id='m3u8-%s' % protocol, fatal=False)
-                        fatal=None)
+                        fatal=False)
-                        video_id, f4m_id='hds', fatal=None)
+                        video_id, f4m_id='hds', fatal=False)
-                m3u8_formats = self._extract_m3u8_formats(source_url, video_id, 'mp4', 'm3u8_native', fatal=None)
+                m3u8_formats = self._extract_m3u8_formats(source_url, video_id, 'mp4', 'm3u8_native', fatal=False)
-            'last-modified', webpage, 'upload date', fatal=None))
+            'last-modified', webpage, 'upload date', fatal=False))
-            return manifest
+            return []
-            return res
+            return []
-            base_url = smil_doc.find('./head/meta').attrib['base']
+            base_url_el = smil_doc.find('./head/meta')
-                'url': base_url,
+                'url': base_url if base_url_el else n.attrib['src'],
-        base_ele = find_xpath_attr(smil, self._xpath_ns('.//meta', namespace), 'name', 'httpBase')
+        base_ele = find_xpath_attr(
-                bitrate = int_or_none(self._search_regex(r'(\d+)\.%s' % ext, video_url, 'bitrate', default=None))
+                bitrate = int_or_none(self._search_regex(
-            f4m_formats = self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False)
+            f4m_formats = self._extract_f4m_formats(
-                m3u8_url, broadcast_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)
+                m3u8_url, broadcast_id, 'mp4', entry_protocol, m3u8_id='hls', fatal=False)
-            videos_info = self._download_json(info_url, event_id, 'Downloading page {0}'.format(i))['data']
+            videos_info = self._download_json(
-            video_data = self._download_json(api_url + '/videos/%s' % video_id, video_id)
+            video_data = self._download_json(
-        (?:\?.*?Id=|/)(?P<id>.*?)(&|$)
+        (?P<user>[^/\?#]+)(?:/(?P<type>video|folder)
-
+    def _extract_video_info(self, user, video_id):
-        is_live = stream_info.get('isLive')
+
-        duration = float_or_none(xpath_attr(item, xpath_with_ns('media:content', media_ns), 'duration'))
+        thumbnail_url = xpath_attr(
-        view_count = int_or_none(xpath_text(item, xpath_with_ns('ls:viewsCount', ls_ns)))
+        view_count = int_or_none(xpath_text(
-        }]
+        return {
-        m3u8_url = stream_info.get('httpUrl')
+        m3u8_url = video_data.get('httpUrl')
-                m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)
+                m3u8_url, video_id, 'mp4', entry_protocol, m3u8_id='hls', fatal=False)
-        rtsp_url = stream_info.get('rtspUrl')
+        rtsp_url = video_data.get('rtspUrl')
-        }
+        self._sort_formats(formats)
-        id = mobj.group('id')
+        content_id = mobj.group('id')
-            return self._extract_folder(url, id)
+            return self._extract_folder(url, content_id)
-            return self._extract_video(user, id)
+            # this url is used on mobile devices
-
+        m3u8_url = info['dataUrl'].replace('format/url', 'format/applehttp')
-            entry_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)
+            m3u8_url, entry_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)
-    DCNGeneralIE,
+    DCNIE,
-class DCNGeneralIE(InfoExtractor):
+class DCNIE(InfoExtractor):
-            return self.url_result('http://www.dcndigital.ae/#/media/%s' % video_id, 'DCNVideo')
+            return self.url_result(
-            return self.url_result(url, 'DCNSeason')
+            return self.url_result(
-class DCNVideoIE(InfoExtractor):
+class DCNBaseIE(InfoExtractor):
-        timestamp = parse_iso8601(video.get('create_time') or video.get('update_time'), ' ')
+        video_data = self._download_json(request, video_id)
-                'signature': video['signature'],
+            'http://admin.mangomolo.com/analytics/index.php/customers/embed/video?' +
-class DCNLiveIE(InfoExtractor):
+class DCNLiveIE(DCNBaseIE):
-        timestamp = parse_iso8601(channel.get('create_time') or channel.get('update_time'), ' ')
+        channel_data = self._download_json(request, channel_id)
-                'signature': channel['signature'],
+                'id': base64.b64encode(channel_data['user_id'].encode()).decode(),
-        }
+        info['formats'] = self._extract_video_formats(webpage, channel_id, 'm3u8')
-                    entries.append(self.url_result('http://www.dcndigital.ae/#/media/%s' % video['id'], 'DCNVideo'))
+                    entries.append(self.url_result(
-        formats = self._extract_m3u8_formats(link, video_id, "mp4")
+            r'var\s+record_len\s*=\s*(["\'])(?P<duration>[0-9]+:[0-9]+:[0-9]+)\1',
-            'skip_download': True,  # HLS download
+            'skip_download': True,  # m3u8 download
-                    self._extract_m3u8_formats(data['file'], video_id, 'mp4'))
+        link = self._search_regex(r'file: "(.*)" \+ location\.hash\.substring\(1\)', webpage, 'link to m3u8')
-            'duration', fatal=False, default=None))
+            r"var record_len = '([0-9]+:[0-9]+:[0-9]+)';", webpage, 'record_len', fatal=False, default=None))
-                 webpage)
+                webpage)
-    },{
+    }, {
-                        formats.extend(self._extract_f4m_formats(
+                        f4m_formats = self._extract_f4m_formats(
-                            video_id, preference=-1, f4m_id='hds'))
+                            video_id, preference=-1, f4m_id='hds', fatal=False)
-                            stream_url, video_id, 'mp4', preference=1, m3u8_id='hls'))
+                        m3u8_formats = self._extract_m3u8_formats(
-import json
+from .ard import ARDMediathekIE
-class SRMediathekIE(InfoExtractor):
+class SRMediathekIE(ARDMediathekIE):
-    _TEST = {
+    _TESTS = [{
-    }
+        'skip': 'no longer available',
-            r'var mediaTitles\s*=\s*(.*?);\n', webpage, 'title')))[0]
+        if '>Der gew&uuml;nschte Beitrag ist leider nicht mehr verf&uuml;gbar.<' in webpage:
-        return {
+        media_collection_url = self._search_regex(
-            'formats': formats,
+            'title': get_element_by_attribute('class', 'ardplayer-title', webpage),
-        }
+        })
-            'http://player.rutv.ru/iframe/%splay/id/%s' % ('live-' if is_live else '', video_id),
+            'http://player.rutv.ru/iframe/data%s/id/%s' % ('live' if is_live else 'video', video_id),
-from .rai import RaiIE
+from .rai import (
-    _VALID_URL = r'(?P<url>(?P<host>http://(?:.+?\.)?(?:rai\.it|rai\.tv|rainews\.it))/dl/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html)'
+class RaiTVIE(InfoExtractor):
-            'md5': 'c064c0b2d09c278fb293116ef5d0a32d',
+            'md5': '96382709b61dd64a6b88e0f791e6df4c',
-                'ext': 'mp4',
+                'ext': 'flv',
-            'md5': '8bb9c151924ce241b74dd52ef29ceafa',
+            'md5': 'd9751b78eac9710d62c2447b224dea39',
-                'ext': 'mp4',
+                'ext': 'flv',
-            }
+            },
-            'md5': '02b64456f7cc09f96ff14e7dd489017e',
+            'md5': '496ab63e420574447f70d02578333437',
-                'uploader': 'RaiTre',
+                'description': 'md5:364b604f7db50594678f483353164fb8',
-        host = mobj.group('host')
+        video_id = self._match_id(url)
-        webpage = self._download_webpage(url, video_id)
+        thumbnails = []
-            }]
+        subtitles = []
-            upload_date = unified_strdate(media.get('date'))
+            has_subtitle = False
-        subtitles = self.extract_subtitles(video_id, webpage)
+            raise ExtractorError('not a media file')
-            'duration': duration,
+            'title': media['name'],
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'(?:zdf:topic:|https?://www\.zdf\.de/ZDFmediathek(?:#)?/.*kanaluebersicht/(?:(?:aktuellste|meist-gesehen)/)?)(?P<id>[0-9]+)'
+    _VALID_URL = r'(?:zdf:topic:|https?://www\.zdf\.de/ZDFmediathek(?:#)?/.*kanaluebersicht/(?:[^/]+/)?)(?P<id>[0-9]+)'
-    _VALID_URL = r'(?:zdf:topic:|https?://www\.zdf\.de/ZDFmediathek(?:#)?/.*kanaluebersicht/)(?P<id>[0-9]+)'
+    _VALID_URL = r'(?:zdf:topic:|https?://www\.zdf\.de/ZDFmediathek(?:#)?/.*kanaluebersicht/(?:(?:aktuellste|meist-gesehen)/)?)(?P<id>[0-9]+)'
-            raise ExtractorError(error, expected=True)
+                [r'<span[^>]+class=(["\'])desc_span\1[^>]*>(?P<error>[^<]+)</span>',
-
+from ..compat import compat_str
-    _VALID_URL = r'https://theintercept.com/fieldofvision/(?P<id>.+?)/'
+    _VALID_URL = r'https://theintercept.com/fieldofvision/(?P<id>[^/?#]+)'
-            'id': 'thisisacoup-episode-four-surrender-or-die',
+            'id': '46214',
-            'upload_date': '20151218',
+            'timestamp': 1450429239,
-        json_data = self._parse_json(mobj.group('json_data'), display_id)
+        json_data = self._parse_json(self._search_regex(
-        }
+                return {
-        (r'(?:video|www)\.pbs\.org', 'PBS: Public Broadcasting Service'),  # http://www.pbs.org/
+        (r'(?:video|www|player)\.pbs\.org', 'PBS: Public Broadcasting Service'),  # http://www.pbs.org/
-        video_id = mobj.group('id')
+        query = compat_parse_qs(compat_urllib_parse_urlparse(url).query)
-            webpage, 'json vp url', default=None)
+            patterns, webpage, 'json vp url', default=None)
-    _VALID_URL = r'https://instagram\.com/(?P<username>[^/]{2,})/?(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?instagram\.com/(?P<username>[^/]{2,})/?(?:$|[?#])'
-            'md5': 'd041af8b5b4246ea466226a0d6693345',
+            'md5': 'e09fc0901d9eaeedac872f154931deeb',
-        video = self._download_xml(
+        video_xml = self._download_xml(
-            video_id, 'Downloading video XML').find('.//video')
+            video_id, 'Downloading video XML')
-            'url': video.attrib['url'],
+            'url': xpath_attr(video, '', 'url', 'video URL', fatal=True),
-        formats = []
+        # Sets some cookies
-        pc_video = self._download_xml(
+        video = self._download_xml(
-            video_id, 'Downloading PC video URL').find('.//video')
+            video_id, 'Downloading video XML').find('.//video')
-        })
+        formats = [{
-        self._sort_formats(formats)
+        like_count = int_or_none(video.get('ratingPlus'))
-            s = re.sub(r'<img ([^<]*?)>', r'<img \1/>', s)
+            s = re.sub(r'<img ([^<]*?)/?>', r'<img \1/>', s)
-__version__ = '2015.12.21'
+__version__ = '2015.12.23'
-from .appletrailers import AppleTrailersIE
+from .appletrailers import (
-            webpage, 'full id')
+            r'tvpot\.daum\.net/v/([^/]+)', og_url, 'full id')
-            'https://api.periscope.tv/api/v2/%s?%s=%s' % (method, attribute, value), value)
+            'https://api.periscope.tv/api/v2/%s?broadcast_id=%s' % (method, value), value)
-from ..utils import parse_iso8601
+from ..utils import (
-            'timestamp': parse_iso8601(video_data.get('pubDate')),
+            'timestamp': timestamp,
-            webpage, 'full data json'))['videoData']
+        full_data = self._parse_json(
-    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(gallery/)?(?P<id>[a-zA-Z0-9]{6,})'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?:(?:gallery|topic/[^/]+)/)?(?P<id>[a-zA-Z0-9]{6,})(?:[/?#&]+|\.[a-z]+)?$'
-    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(gallery/)?(?P<id>[a-zA-Z0-9]{5})(?![a-zA-Z0-9])'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?:(?:a|gallery|topic/[^/]+)/)?(?P<id>[a-zA-Z0-9]{5})(?:[/?#&]+)?$'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        return self.playlist_result(entries, album_id)
+        album_images = self._download_json(
-    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?!gallery)(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(gallery/)?(?P<id>[a-zA-Z0-9]{6,})'
-            'description': 're:The origin of the Internet\'s most viral images$|The Internet\'s visual storytelling community\. Explore, share, and discuss the best visual stories the Internet has to offer\.$',
+            'description': 'Imgur: The most awesome images on the Internet.',
-            'description': 're:The origin of the Internet\'s most viral images$|The Internet\'s visual storytelling community\. Explore, share, and discuss the best visual stories the Internet has to offer\.$',
+            'description': 'Imgur: The most awesome images on the Internet.',
-    _VALID_URL = r'https?://(?:i\.)?imgur\.com/gallery/(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(gallery/)?(?P<id>[a-zA-Z0-9]{5})(?![a-zA-Z0-9])'
-            album_id)['data']['images']
+        album_img_data = self._download_json(
-            for image in album_images if image.get('hash')]
+        if len(album_img_data) == 0:
-            'md5': '7fbc265a3ca4933a423c7a66aa879a67',
+            'md5': 'fd828cd29774a729bf4d4425fe192972',
-                'ext': 'mp4',
+                'ext': 'mov',
-                vbr = int(mobj.group(3))
+                tbr = int(mobj.group(3))
-                    'format_id': 'mp4-%s' % vbr,
+                    'tbr': tbr,
-        'md5': 'd055e8ee918ef2844745fcfd1a4175fb',
+        'md5': '2acbe8ad129b3469d5ae51b1158878df',
-            r'SVP\.Player\.load\(\s*(\d+)', webpage, 'video id')
+            r'<video[^>]+data-id="(\d+)"', webpage, 'video id')
-    _TEST = {
+    _TESTS = [{
-    }
+        'skip': '404 Error',
-                'preference': 2,
+                'preference': 1,
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'<span class="title">(.+?)</span>', webpage, 'title')
+            r'<span class="title-diffusion">(.+?)</span>', webpage, 'title')
-        'md5': 'f0ca220af012d4df857b54f792c586bb',
+        'md5': '8c2c12e3af7805152675446c905d159b',
-                        format_dict['url'], video_id, 'mp4', m3u8_id='m3u8-%s' % protocol)
+                    m3u8_formats = self._extract_m3u8_formats(
-            webpage, 'full data json'))
+            r'\nwindow.app = (?P<json>.+?);\n',
-    LetvPlaylistIE
+    LetvPlaylistIE,
-            'id': '1564',
+            'id': '1565',
-        api_key = self._download_json('https://www.flickr.com/hermes_error_beacon.gne', video_id, 'Downloading api key',)['site_key']
+        api_key = self._download_json(
-        video_info = self._call_api('photos.getInfo', video_id, api_key, 'Downloading video info')['photo']
+        video_info = self._call_api(
-            streams = self._call_api('video.getStreamInfo', video_id, api_key, 'Downloading streams info', video_info['secret'])['streams']
+            streams = self._call_api(
-            preference = qualities(['iphone_wifi', '700', 'appletv', 'orig'])
+            preference = qualities(
-    _BASE_URL = 'http://www.br.de'
+    _VALID_URL = r'(?P<base_url>https?://(?:www\.)?br(?:-klassik)?\.de)/(?:[a-z0-9\-_]+/)+(?P<id>[a-z0-9\-_]+)\.html'
-                'description': 'Betriebliche Altersvorsorge: Die bÃ¶se Ãberraschung',
+                'description': 'md5:ce9ac81b466ce775b8018f6801b48ac9',
-            'md5': 'a44396d73ab6a68a69a568fae10705bb',
+            'md5': 'af3a3a4aa43ff0ce6a89504c67f427ef',
-                'ext': 'mp4',
+                'ext': 'flv',
-                'description': 'Abendschau kompakt: Manfred Schreiber ist tot',
+                'description': 'md5:b454d867f2a9fc524ebe88c3f5092d97',
-            'url': 'http://www.br.de/radio/br-klassik/sendungen/allegro/premiere-urauffuehrung-the-land-2015-dance-festival-muenchen-100.html',
+            'url': 'https://www.br-klassik.de/audio/peeping-tom-premierenkritik-dance-festival-muenchen-100.html',
-                'description': '"The Land" von Peeping Tom: Kurzweilig und sehr bewegend',
+                'description': 'md5:0351996e3283d64adeb38ede91fac54e',
-                'description': 'Uwe Erdelt: Umweltbewusster HÃ¤uslebauer',
+                'description': 'md5:d52dae9792d00226348c1dbb13c9bae2',
-                'description': 'Kant fÃ¼r AnfÃ¤nger: Folge 1 - Metaphysik',
+                'description': 'md5:bb659990e9e59905c3d41e369db1fbe3',
-        display_id = self._match_id(url)
+        base_url, display_id = re.search(self._VALID_URL, url).groups()
-        xml = self._download_xml(self._BASE_URL + xml_url, None)
+        xml = self._download_xml(base_url + xml_url, display_id)
-                'webpage_url': xml_media.find('permalink').text
+                'id': media_id,
-                media['upload_date'] = ''.join(reversed(xml_media.find('broadcastDate').text.split('.')))
+            broadcast_date = xpath_text(xml_media, 'broadcastDate')
-
+    def _extract_formats(self, assets, media_id):
-    def _extract_thumbnails(self, variants):
+    def _extract_thumbnails(self, variants, base_url):
-        } for variant in variants.findall('variant')]
+            'url': base_url + xpath_text(variant, 'url'),
-            raise ExtractorError('Invalid url %s', url)
+            raise ExtractorError('Invalid url %s' % url)
-                    'ext': 'flv',
+                    'ext': 'mp4',
-
+import hashlib
-            (episode_id + timestamp_shifted).encode('utf-8')
+            (episode_id + timestamp_shifted).encode('utf-8'), hashlib.md5
-        self._sort_formats(formats)
+        request = sanitized_Request(
-            episode_id)
+        fmt_json = self._download_json(
-            video_id, 'Downloading episode XML')
+            self._EPISODE_URL_TEMPLATE % path_data, video_id,
-__version__ = '2015.12.18'
+__version__ = '2015.12.21'
-            )['channel']['item']
+            url, None, 'Downloading Akamai AMP feed',
-        
+
-        media_thumbnail = self._get_media_node(item, 'thumbnail')
+        media_thumbnail = get_media_node('thumbnail')
-        media_subtitle = self._get_media_node(item, 'subTitle')
+        media_subtitle = get_media_node('subTitle')
-        media_content = self._get_media_node(item, 'content')
+        media_content = get_media_node('content')
-                f4m_formats = self._extract_f4m_formats(media['url'] + '?hdcore=3.4.0&plugin=aasp-3.4.0.132.124', video_id, f4m_id='hds', fatal=False)
+                f4m_formats = self._extract_f4m_formats(
-                m3u8_formats = self._extract_m3u8_formats(media['url'], video_id, m3u8_id='hls', fatal=False)
+                m3u8_formats = self._extract_m3u8_formats(
-                    'vbr': int_or_none(media.get('bitrate')),
+                    'tbr': int_or_none(media.get('bitrate')),
-            'description': self._get_media_node(item, 'description'),
+            'title': get_media_node('title'),
-    },{
+    }, {
-            'description': 'md5:e95afafa43619816552723878b3b0a84',
+            'description': 'md5:825e94e0f3521df52fa83b2ed198fa20',
-            info = self._extract_feed_info('http://www.dramafever.com/amp/episode/feed.json?guid=%s' % video_id)
+            info = self._extract_feed_info(
-                #'upload_date': '20110503',
+                # 'timestamp': 1304411491,
-                #'upload_date': '20141204',
+                # 'timestamp': 1417662047,
-        host = mobj.group('host')
+        host, video_id = re.match(self._VALID_URL, url).groups()
-        info = self._extract_feed_info('http://%s/v/feed/video/%s.js?template=fox' % (host, video_id))
+        info = self._extract_feed_info(
-            r'<script[^>]+?src=["\'](?P<url>(?:https?:)?//content.jwplatform.com/players/[a-zA-Z0-9]{8}',
+            r'<script[^>]+?src=["\'](?P<url>(?:https?:)?//content.jwplatform.com/players/[a-zA-Z0-9]{8})',
-                formats.extend(self._extract_m3u8_formats(source_url, video_id, 'mp4', 'm3u8_native', fatal=None))
+                m3u8_formats = self._extract_m3u8_formats(source_url, video_id, 'mp4', 'm3u8_native', fatal=None)
-            'id': video_data['mediaid'],
+            'id': video_id,
-    _VALID_URL = r'https?://(?:(?:www\.)?maker\.tv/(?:[^/]+/)?video|http://makerplayer.com/embed/maker)/(?P<id>[a-zA-Z0-9]{12})'
+    _VALID_URL = r'https?://(?:(?:www\.)?maker\.tv/(?:[^/]+/)*video|makerplayer.com/embed/maker)/(?P<id>[a-zA-Z0-9]{12})'
-            'id': 'brOEcGut',
+            'id': 'Fh3QgymL9gsc',
-        jwplatform_id = self._search_regex([r'jwid="([^"]+)"', r'Maker.jw_id\s*=\s*"([^"]+)";'], webpage, 'jwplatform id')
+        jwplatform_id = self._search_regex(r'jw_?id="([^"]+)"', webpage, 'jwplatform id')
-        return self.url_result('jwplatform:%s' % jwplatform_id, 'JWPlatform')
+        return {
-)
+from .googledrive import GoogleDriveIE
-from .googledrive import GoogleDriveEmbedIE
+from .googledrive import GoogleDriveIE
-        google_drive_url = GoogleDriveEmbedIE._extract_url(webpage)
+        google_drive_url = GoogleDriveIE._extract_url(webpage)
-    RegexNotFoundError,
+    int_or_none,
-    _VALID_URL = r'https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28})'
+
-        'url': 'https://docs.google.com/file/d/0B8KB9DRosYGKMXNoeWxqa3JYclE/preview',
+        'url': 'https://drive.google.com/file/d/0ByeS4oOUV-49Zzh4R1J6R09zazQ/edit?pli=1',
-            'id': '0B8KB9DRosYGKMXNoeWxqa3JYclE',
+            'id': '0ByeS4oOUV-49Zzh4R1J6R09zazQ',
-            'title': 'Jimmy Fallon Sings Since You\'ve Been Gone.wmv',
+            'title': 'Big Buck Bunny.mp4',
-            r'<iframe src="https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28})',
+            r'<iframe[^>]+src="https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28})',
-        }
+        webpage = self._download_webpage(
-    }
+        reason = self._search_regex(r'"reason"\s*,\s*"([^"]+)', webpage, 'reason', default=None)
-                return
+        title = self._search_regex(r'"title"\s*,\s*"([^"]+)', webpage, 'title')
-            resolution = fmt_list[i].split('/')[1]
+        for fmt, fmt_stream in zip(fmt_list, fmt_stream_map):
-                'ext': self._formats[fmt_id]['ext']
+                'width': int_or_none(width),
-            'formats': formats
+            'thumbnail': self._og_search_thumbnail(webpage),
-            r'(?:var\s+)?videoXMLURL\s*=\s*"([^"]+)', webpage, 'config xml url')
+            r'videoXMLURL\s*=\s*"([^"]+)', webpage, 'config xml url')
-        encodings = config.find('ENCODINGS')
+        encodings = xpath_element(config, 'ENCODINGS', 'encodings', True)
-            })
+            encoding = xpath_element(encodings, code)
-            'thumbnail': config.find('STILL/STILL_BIG').text,
+            'description': description.strip() if description else None,
-from ..utils import js_to_json
+from .youtube import YoutubeIE
-            'md5': '65d1ae54812c96f4b345dd21d3bb1adc',
+            'md5': '867adf6a3b3fef932c68a71d70b70946',
-                'description': 'md5:a1cd2e74f6ee6851552c9cf5851d6b06',
+                'description': 'md5:7292ff2a34b2f673da77da222ae77e1e',
-            'description', webpage, 'description')
+        setup_js = self._search_regex(r"(?s)jwplayer\('player-vivo'\).setup\((\{.*?\})\)", webpage, 'setup code')
-        for f in setup_js['playlist'][0]['sources']:
+        urls = []
-                    formats.extend(self._extract_m3u8_formats(format_url, display_id))
+            if format_url and format_url not in urls:
-                        formats.append({'url': format_url, 'format_id': f.get('label')})
+                    formats.append({
-            'thumbnail': thumbnail,
+            'title': self._search_regex(r'title\s*:\s*"([^"]+)"', setup_js, 'title'),
-from .common import InfoExtractor
+from ..utils import int_or_none
-class CNETIE(InfoExtractor):
+class CNETIE(ThePlatformIE):
-            'ext': 'mp4',
+            'ext': 'flv',
-            'ext': 'mp4',
+            'ext': 'flv',
-            'title': 'Whiny potholes tweet at local government when hit by cars (Tomorrow Daily 187)',
+            'duration': 1482,
-            r"<div class=\"videoPlayer\"\s+.*?data-cnet-video-uvp-options='([^']+)'",
+            r"data-cnet-video(?:-uvp)?-options='([^']+)'",
-        vdata = data['videos'][0]
+        data = self._parse_json(data_json, display_id)
-        tp = ThePlatformIE(self._downloader)
+
-
+            release_url = 'http://link.theplatform.com/s/%s/%s?format=SMIL&mbr=true' % (mpx_account, vid)
-    YoutubeUserPlaylistsIE,
+    YoutubePlaylistsIE,
-    IE_NAME = 'youtube:user:playlists'
+class YoutubePlaylistsIE(YoutubePlaylistsBaseInfoExtractor):
-    error_to_str,
+    error_to_compat_str,
-                    self.report_error(error_to_str(e), tb=encode_compat_str(traceback.format_exc()))
+                    self.report_error(error_to_compat_str(e), tb=encode_compat_str(traceback.format_exc()))
-            self.report_error('unable to create directory ' + error_to_str(err))
+            self.report_error('unable to create directory ' + error_to_compat_str(err))
-                                            (sub_lang, error_to_str(err.cause)))
+                                            (sub_lang, error_to_compat_str(err.cause)))
-                                        (t['url'], error_to_str(err)))
+                                        (t['url'], error_to_compat_str(err)))
-    error_to_str,
+    error_to_compat_str,
-            self.report_error('unable to rename file: %s' % error_to_str(err))
+            self.report_error('unable to rename file: %s' % error_to_compat_str(err))
-    error_to_str,
+    error_to_compat_str,
-            errmsg = '%s: %s' % (errnote, error_to_str(err))
+            errmsg = '%s: %s' % (errnote, error_to_compat_str(err))
-                self._downloader.report_warning('parsing .netrc: %s' % error_to_str(err))
+                self._downloader.report_warning('parsing .netrc: %s' % error_to_compat_str(err))
-    error_to_str,
+    error_to_compat_str,
-            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_str(err))
+            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_compat_str(err))
-    error_to_str,
+    error_to_compat_str,
-            self._downloader.report_warning('unable to log in: %s' % error_to_str(err))
+            self._downloader.report_warning('unable to log in: %s' % error_to_compat_str(err))
-    error_to_str,
+    error_to_compat_str,
-            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_str(err))
+            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_compat_str(err))
-def error_to_str(err):
+def error_to_compat_str(err):
-)
+from ..compat import compat_HTTPError
-                'description': compat_str(info.find('caption').text),
+                'description': info.find('caption').text,
-                self.report_error(error_to_str(e), e.format_traceback())
+                self.report_error(compat_str(e), e.format_traceback())
-                    tb += compat_str(traceback.format_exc())
+                    tb += encode_compat_str(traceback.format_exc())
-                    self.report_error(error_to_str(e), tb=compat_str(traceback.format_exc()))
+                    self.report_error(error_to_str(e), tb=encode_compat_str(traceback.format_exc()))
-from .compat import compat_str
+from .utils import encode_compat_str
-            to_screen(compat_str(traceback.format_exc()))
+            to_screen(encode_compat_str(traceback.format_exc()))
-            to_screen(compat_str(traceback.format_exc()))
+            to_screen(encode_compat_str(traceback.format_exc()))
-                to_screen(compat_str(traceback.format_exc()))
+                to_screen(encode_compat_str(traceback.format_exc()))
-                to_screen(compat_str(traceback.format_exc()))
+                to_screen(encode_compat_str(traceback.format_exc()))
-                to_screen(compat_str(traceback.format_exc()))
+                to_screen(encode_compat_str(traceback.format_exc()))
-                to_screen(compat_str(traceback.format_exc()))
+                to_screen(encode_compat_str(traceback.format_exc()))
-                to_screen(compat_str(traceback.format_exc()))
+                to_screen(encode_compat_str(traceback.format_exc()))
-                                            (sub_lang, compat_str(err.cause)))
+                                            (sub_lang, error_to_str(err.cause)))
-                self.report_error(compat_str(de), de.format_traceback())
+            except ExtractorError as e:  # An error we somewhat expected
-                    self.report_error(compat_str(e), tb=compat_str(traceback.format_exc()))
+                    self.report_error(error_to_str(e), tb=compat_str(traceback.format_exc()))
-            self.report_error('unable to create directory ' + compat_str(err))
+            self.report_error('unable to create directory ' + error_to_str(err))
-                                        (t['url'], compat_str(err)))
+                                        (t['url'], error_to_str(err)))
-from ..compat import compat_str
+    error_to_str,
-            self.report_error('unable to rename file: %s' % compat_str(err))
+            self.report_error('unable to rename file: %s' % error_to_str(err))
-            errmsg = '%s: %s' % (errnote, err_str)
+
-                self._downloader.report_warning('parsing .netrc: %s' % compat_str(err))
+                self._downloader.report_warning('parsing .netrc: %s' % error_to_str(err))
-    ExtractorError,
+    error_to_str,
-            self._downloader.report_warning('unable to download video subtitles: %s' % compat_str(err))
+            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_str(err))
-    compat_str,
+    error_to_str,
-            self._downloader.report_warning('unable to log in: %s' % compat_str(err))
+            self._downloader.report_warning('unable to log in: %s' % error_to_str(err))
-            self._downloader.report_warning('unable to download video subtitles: %s' % compat_str(err))
+            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_str(err))
-        http_host = xpath_text(metadata, 'httpHost')
+        http_host = xpath_text(metadata, 'httpHost', 'http host', True)
-                    'format_id': 'http-%d' % bitrate,
+                    'tbr': int_or_none(xpath_text(mbr_video, 'bitrate')),
-            errmsg = '%s: %s' % (errnote, compat_str(err))
+            err_str = str(err)
-            r'writeFLV\(\'(.+?)\',', webpage, 'config xml url')
+            r'(?:var\s+)?videoXMLURL\s*=\s*"([^"]+)', webpage, 'config xml url')
-    ExtractorError,
+    js_to_json,
-        } for furl in urls]
+        thumbnail = self._search_regex(r'POSTER\s*=\s*"([^"]+)', webpage, 'thumbnail', fatal=False)
-            'thumbnail': poster,
+            'thumbnail': thumbnail,
-    IE_NAME = 'togglesg'
+    IE_NAME = 'toggle'
-from .togglesg import ToggleSgIE
+from .toggle import ToggleIE
-class ToggleSgIE(InfoExtractor):
+class ToggleIE(InfoExtractor):
-    _VALID_URL = r'https?://video\.toggle\.sg/(?:en|zh)/(?:series|clips|movies)/.+?/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://video\.toggle\.sg/(?:en|zh)/(?:series|clips|movies)/(?:[^/]+/)+(?P<id>[0-9]+)'
-        'url': 'http://video.toggle.sg/en/series/28th-sea-games-5-show/ep11/332861',
+        'url': 'http://video.toggle.sg/en/series/28th-sea-games-5-show/28th-sea-games-5-show-ep11/332861',
-            vid_format = video_file['Format'].replace(' ', '')
+            video_url, vid_format = video_file.get('URL'), video_file.get('Format')
-                    video_file['URL'], video_id, ext='mp4', m3u8_id=vid_format,
+                    video_url, video_id, ext='mp4', m3u8_id=vid_format,
-                    'url': video_file['URL'],
+                    'url': video_url,
-        formats = []
+        formats = []
-
+        duration = int_or_none(info.get('Duration'))
-            'thumbnail': thumbnail,
+            'thumbnails': thumbnails,
-        webpage = self._download_webpage(url, video_id, note='Downloading video page')
+        webpage = self._download_webpage(
-            r'apiUser:\s*"([^"]+)"', webpage, 'apiUser', default=self._API_USER)
+            r'apiUser\s*:\s*(["\'])(?P<user>.+?)\1', webpage, 'apiUser',
-            r'apiPass:\s*"([^"]+)"', webpage, 'apiPass', default=self._API_PASS)
+            r'apiPass\s*:\s*(["\'])(?P<pass>.+?)\1', webpage, 'apiPass',
-                )
+                    fatal=False)
-            if ext in ['mp4', 'wvm']:
+            elif ext in ('mp4', 'wvm'):
-                    'LocaleDevice': '', 'LocaleUserState': 0
+                    'LocaleLanguage': '',
-                'ApiUser': api_user, 'ApiPass': api_pass
+                'Platform': 0,
-import itertools
+    determine_ext,
-    remove_end
+    remove_end,
-        req = compat_urllib_request.Request(
+        req = sanitized_Request(
-    _VALID_URL = r'https?://video\.toggle\.sg/(?:(en|zh))/(?:(series|clips|movies))/.+?/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://video\.toggle\.sg/(?:en|zh)/(?:series|clips|movies)/.+?/(?P<id>[0-9]+)'
-            r'apiUser:\s*"([^"]+)"', webpage, 'apiUser', default=self._API_USER, fatal=False)
+            r'apiUser:\s*"([^"]+)"', webpage, 'apiUser', default=self._API_USER)
-            r'apiPass:\s*"([^"]+)"', webpage, 'apiPass', default=self._API_PASS, fatal=False)
+            r'apiPass:\s*"([^"]+)"', webpage, 'apiPass', default=self._API_PASS)
-    mobj = re.match(r'^(\d+):(\d\d):(\d\d(?:\.\d+)?)$', time_expr)
+    mobj = re.match(r'^(\d+):(\d\d):(\d\d(?:(?:\.|:)\d+)?)$', time_expr)
-        return 3600 * int(mobj.group(1)) + 60 * int(mobj.group(2)) + float(mobj.group(3))
+        return 3600 * int(mobj.group(1)) + 60 * int(mobj.group(2)) + float(mobj.group(3).replace(':', '.'))
-        self.assertEqual(parse_dfxp_time_expr(''), 0.0)
+        self.assertEqual(parse_dfxp_time_expr(None), None)
-        return 0.0
+        return
-        begin_time = parse_dfxp_time_expr(para.attrib['begin'])
+        begin_time = parse_dfxp_time_expr(para.attrib.get('begin'))
-            end_time = begin_time + parse_dfxp_time_expr(para.attrib['dur'])
+            if not dur:
-        # 2. http://docs.brightcove.com/en/video-cloud/brightcove-player/guides/publish-video.html#setvideousingjavascript)
+        # 2. http://docs.brightcove.com/en/video-cloud/brightcove-player/guides/publish-video.html#setvideousingjavascript
-    _VALID_URL = r'https?://players\.brightcove\.net/(?P<account_id>\d+)/(?P<player_id>[^/]+)_(?P<embed>[^/]+)/index\.html\?.*videoId=(?P<video_id>\d+)'
+    _VALID_URL = r'https?://players\.brightcove\.net/(?P<account_id>\d+)/(?P<player_id>[^/]+)_(?P<embed>[^/]+)/index\.html\?.*videoId=(?P<video_id>(?:ref:)?\d+)'
-                        data-video-id=["\'](\d+)["\'][^>]*>.*?
+                        data-video-id=["\']((?:ref:)?\d+)["\'][^>]*>.*?
-from .brightcove import BrightcoveLegacyIE
+from .brightcove import (
-                        return self.url_result(bc_url, 'BrightcoveLegacy')
+                        if bc_url:
-            webpage, 'description', fatal=False)
+            webpage, 'description', default=None) or self._og_search_description(webpage)
-                r'<span itemprop="datePublished" content="([^"]+)">',
+                r'<span[^>]+itemprop="(?:datePublished|uploadDate)"[^>]+content="([^"]+)"',
-__version__ = '2015.12.13'
+__version__ = '2015.12.18'
-                (?:function\s+%s|[{;]%s\s*=\s*function|var\s+%s\s*=\s*function)\s*
+                (?:function\s+%s|[{;,]%s\s*=\s*function|var\s+%s\s*=\s*function)\s*
-        enc_key = '3719f6a1da83ee0aee3488d8802d7696'[::-1]
+        # last update at 2015-12-18 for Zombie::bite
-    orderedSet,
+    xpath_attr,
-    _VALID_URL = r'https?://(?:new\.)?livestream\.com/.*?/(?P<event_name>.*?)(/videos/(?P<id>[0-9]+)(?:/player)?)?/?(?:$|[?#])'
+    _VALID_URL = r'https?://(?:new\.)?livestream\.com/(?:accounts/(?P<account_id>\d+)|(?P<account_name>[^/]+))/(?:events/(?P<event_id>\d+)|(?P<event_name>[^/]+))(?:/videos/(?P<id>\d+))?'
-            '{http://www.w3.org/2001/SMIL20/Language}video')
+        video_nodes = smil.findall(self._xpath_ns('.//video', namespace))
-            tbr = int_or_none(vn.attrib.get('system-bitrate'))
+            tbr = int_or_none(vn.attrib.get('system-bitrate'), 1000)
-                (vn.attrib['src']))
+                '%s%s?v=3.0.3&fp=WIN%%2014,0,0,145' % (base, vn.attrib['src']))
-            if video_data.get(key)]
+
-            formats.extend(self._parse_smil(video_id, smil_url))
+            smil_formats = self._extract_smil_formats(smil_url, video_id)
-            'upload_date': video_data['updated_at'].replace('-', '')[:8],
+            'duration': float_or_none(video_data.get('duration'), 1000),
-        return self.playlist_result(_extract_videos(), event_id, info['full_name'])
+    def _extract_event(self, event_data):
-            return self._extract_event(info)
+        event = mobj.group('event_id') or mobj.group('event_name')
-            return videos[0]
+            event_data = self._download_json(api_url, video_id)
-        thumbnail_url = item.find(xpath_with_ns('media:thumbnail', ns)).attrib['url']
+        media_ns = {'media': 'http://search.yahoo.com/mrss'}
-            'url': stream_info['progressiveUrl'],
+            'title': self._live_title(xpath_text(item, 'title')) if is_live else xpath_text(item, 'title'),
-        }
+        entries = [{
-                        'vbr': int_or_none(fmt.get('videobitrate')),
+                        'abr': int_or_none(fmt.get('audiobitrate'), 1000),
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        ts = compat_str(int(time.time() * 1000))
+        ts = compat_str(self._ts() + self._ts_offset)
-        resp = self._download_json(url, video_id, note)
+        request = sanitized_Request(url)
-        ('video.kbtc.org', 'KBTC Public Television (KBTC)'),  # http://kbtc.org
+        (r'(?:video|www)\.pbs\.org', 'PBS: Public Broadcasting Service'),  # http://www.pbs.org/
-    ''' % '|'.join(re.escape(p) for p in list(zip(*_STATIONS))[0])
+    ''' % '|'.join(list(zip(*_STATIONS))[0])
-                if error is not None:
+                if error_note is not None:
-                m3u8_url, video_id, 'mp4', 'm3u8_native', 0, 'hls', fatal=False)
+                m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)
-        self._sort_formats(formats, field_preference=('height', 'width', 'fps', 'format_id'))
+        self._sort_formats(formats, field_preference=('preference', 'height', 'width', 'fps', 'format_id'))
-    _VALID_URL = r'https?://rutube\.ru/video/(?P<id>[\da-z]{32})'
+    _VALID_URL = r'https?://rutube\.ru/(?:video|play/embed)/(?P<id>[\da-z]{32})'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'id': '12043945',
+            'id': 'le-grand-mysterioso-chuggington-7085291-739',
-    _VALID_URL = r'http://(?:(?:videos|www|lci)\.tf1|www\.tfou)\.fr/.*?-(?P<id>\d+)(?:-\d+)?\.html'
+    _VALID_URL = r'http://(?:(?:videos|www|lci)\.tf1|www\.tfou)\.fr/(?:[^/]+/)*(?P<id>.+?)\.html'
-            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d+)\1',
+            r'(["\'])(?:https?:)?//www\.wat\.tv/embedframe/.*?(?P<id>\d{8})\1',
-        wat_id = self._search_regex(r'UVID=(.*?)&', embed_page, 'wat id')
+        wat_id = self._html_search_regex(
-                    r'var\s*%s\s*=\s*"([^"]+)"' % re.escape(filekey), webpage, 'filekey', default=default)
+                    r'var\s+%s\s*=\s*"([^"]+)"' % re.escape(filekey), webpage, 'filekey', default=default)
-                    r'var\s*%s\s*=\s*"([^"]+)"', webpage, 'filekey', default=default)
+                    r'var\s*%s\s*=\s*"([^"]+)"' % re.escape(filekey), webpage, 'filekey', default=default)
-        'md5': 'f8fbbc8add72bd95b7850c6a02fc8817',
+        'url': 'http://www.nowvideo.sx/video/f1d6fce9a968b',
-            'id': '0mw0yow7b6dxa',
+            'id': 'f1d6fce9a968b',
-            'title': 'youtubedl test video _BaW_jenozKc.mp4',
+            'title': 'youtubedl test video BaWjenozKc',
-        'skip': 'Video 0mw0yow7b6dxa does not exist',
+        'skip': 'Video for this match is not available',
-    _VALID_URL_TEMPLATE = r'http://(?:(?:www\.)?%(host)s/(?:file|video)/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<id>[a-z\d]{13})'
+    _VALID_URL_TEMPLATE = r'http://(?:(?:www\.)?%(host)s/(?:file|video|mobile/#/videos)/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<id>[a-z\d]{13})'
-from ..compat import compat_urllib_parse_unquote
+from ..compat import (
-            'id': '12-jan-pythonthings',
+            'id': 'A-Few-of-My-Favorite-Python-Things',
-        webpage = self._download_webpage(url, video_id)
+    def _extract_bokecc_videos(self, webpage, video_id):
-        video_description = self._html_search_meta('description', webpage, 'description')
+        player_params = compat_parse_qs(player_params_str)
-            r"jsclassref\s*=\s*'([^']*)'", webpage, 'encoded id')
+            r"jsclassref\s*=\s*'([^']*)'", webpage, 'encoded id', default=None)
-        video_id, extension = video_filename.split('.')
+        return [{
-        }, {
+        return [{
-__version__ = '2015.12.10'
+__version__ = '2015.12.13'
-)
+from ..compat import compat_urllib_parse_unquote
-            'HTTP base URL')
+        http_video_url = self._search_regex(r'P\.s\s*=\s*\'([^\']+)\'', webpage, 'video URL')
-            'url': compat_urlparse.urljoin(url, http_base) + real_id,
+            'url': http_video_url,
-        }
+        },
-            raise ExtractorError('Video %s does not exist' % video_id, expected=True)
+        self._check_existence(webpage, video_id)
-    _FILEKEY_REGEX = r'flashvars\.filekey="(?P<filekey>[^"]+)";'
+    _FILEKEY_REGEX = r'flashvars\.filekey=(?P<filekey>"?[^"]+"?);'
-        url = 'http://%s/video/%s' % (self._HOST, video_id)
+        url = self._URL_TEMPLATE % (self._HOST, video_id)
-            return self._search_regex(
+            filekey = self._search_regex(
-    _FILEKEY_REGEX = r'var fkzd="([^"]+)";'
+    _URL_TEMPLATE = 'http://%s/file/%s'
-
+    _NETRC_MACHINE = 'funimation'
-        login = self._download_webpage(
+        login_page = self._download_webpage(
-            raise ExtractorError('Unable to login, wrong username or password.', expected=True)
+        if any(p in login_page for p in ('funimation.com/logout', '>Log Out<')):
-            'hd3': '3',
+            'flv': '0',
-            'mp4hd2': '1'
+            'mp4hd2': '1',
-            'flvhd': 'h4',
+            'flvhd': 'h4',
-            'hd3': 'h1',
+            'mp4hd2': 'h4',
-            'mp4hd2': 'h4'
+            'hd2': 'h2',
-            'Downloading JSON metadata 1')
+        data = retrieve_data(basic_data_url, 'Downloading JSON metadata')
-        'skip': 'Available in China only',
+        # MD5 is unstable
-                    '_00'+ \
+                    '_00' + \
-            req = sanitized_Request(req_url,headers=headers)
+                'Referer': req_url,
-        #get video title
+        # get video title
-from ..compat import compat_urllib_parse
+    urlencode_postdata,
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form), headers=headers)
+            self._LOGIN_URL, urlencode_postdata(login_form), headers=headers)
-    def construct_video_urls(self, data1, data2):
+    def construct_video_urls(self, data):
-            b'becaf9be', base64.b64decode(data2['security']['encrypt_string'].encode('ascii'))
+            b'becaf9be', base64.b64decode(data['security']['encrypt_string'].encode('ascii'))
-        oip = data1['security']['ip']
+        oip = data['security']['ip']
-        for stream in data1['stream']:
+        for stream in data['stream']:
-        for stream in data1['stream']:
+        for stream in data['stream']:
-        data1 = retrieve_data(
+        data = retrieve_data(
-        error = data1.get('error')
+        error = data.get('error')
-        title = data1['video']['title']
+        title = data['video']['title']
-        video_urls_dict = self.construct_video_urls(data1, data2)
+        video_urls_dict = self.construct_video_urls(data)
-        for stream in data1['stream']:
+        } for i in range(max(len(v.get('segs')) for v in data['stream']))]
-            basic_data_url += '?password=%s' % video_password
+            basic_data_url += '&pwd=%s' % video_password
-            "http://play.youku.com/play/get.json?vid=%s&ct=12" % video_id,
+            basic_data_url,
-            if error is not None and 'å çæåå æ æ³è§çæ­¤è§é¢' in error:
+        error = data1.get('error')
-                msg = 'Youku server reported error %i' % error_code
+                msg = 'Youku server reported error %i' % error.get('code')
-                    msg += ': ' + error
+                    msg += ': ' + error_note
-            'flvhd': '0'
+            'flvhd': '0',
-            'mp4hd2': 'mp4',
+            'mp4hd2': 'flv',
-            'hd3': 'h1'
+            'hd3': 'h1',
-        #title = data1['title']
+        #get video title
-        'md5': '8e3c576bf2e9bfff4d76565f56f94c9c',
+        'md5': '4294cf98bc165f218aaa0b89e0fd8042',
-            'ext': 'mp4',
+            'ext': 'mov',
-            'description': 'md5:587e79fbbd0d73b148bc596d99ce48e6',
+            'description': 'md5:3539013ddcbfa64b2a6d1b38d910868a',
-                'title': 'Track 4',
+                'title': 'Straight from the Heart',
-                'contextDataParams:streamerType': 'http',
+                'action': 'getbyentryid',
-                'service': 'baseentry',
+                'service': 'flavorAsset',
-        info, source_data = self._get_video_info(entry_id, partner_id)
+        info, flavor_assets = self._get_video_info(entry_id, partner_id)
-        for f in source_data['flavorAssets']:
+        for f in flavor_assets:
-            'http://beeg.com/api/v4/video/%s' % video_id, video_id)
+            'http://beeg.com/api/v5/video/%s' % video_id, video_id)
-            a = '8RPUUCS35ZWp3ADnKcSmpH71ZusrROo'
+            # Reverse engineered from http://static.beeg.com/cpl/1105.js
-                compat_chr(compat_ord(e[n]) - compat_ord(a[n % len(a)]) % 25)
+            o = ''.join([
-                for quality in ('sd', 'hd', 'hd1080'):
+                for quality, height in (('sd', 480), ('hd', 720), ('hd1080', 1080)):
-                            preference=preference, m3u8_id=funimation_id or 'hls', fatal=False)
+                            preference=preference, m3u8_id='%s-hls' % funimation_id, fatal=False)
-                        f = {
+                        tbr = int_or_none(self._search_regex(
-                            'format_id': funimation_id,
+                            'format_id': '%s-http-%dp' % (funimation_id, height),
-                        formats.append(f)
+                        })
-        'only_matching': True,
+        'info_dict': {
-            items = self._parse_json(
+            playlist = self._parse_json(
-                display_id)[0]['playlist'][0]['items']
+                display_id)[0]['playlist']
-    _VALID_URL = r'https?://(?:www\.)?funimation\.com/shows/[^/]+/videos/official/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?funimation\.com/shows/[^/]+/videos/(?:official|promotional)/(?P<id>[^/?#&]+)'
-    _TEST = {
+    _TESTS = [{
-        return response
+    }, {
-        item = next(item for item in items if item.get('itemAK') == display_id)
+        errors = []
-                if not format_url:
+        USER_AGENTS = (
-                    })
+                funimation_id = video.get('FUNImationID') or video.get('videoId')
-    _VALID_URL = r'https?://(?:www\.)?funimation\.com/shows/[^/]+/videos/official/(?P<id>[^?]+)'
+    _VALID_URL = r'https?://(?:www\.)?funimation\.com/shows/[^/]+/videos/official/(?P<id>[^/?#&]+)'
-            'title': 'Air - 1 - Breeze ',
+            'id': '658',
-        }
+            'title': 'Air - 1 - Breeze',
-from ..compat import compat_HTTPError
+from ..compat import compat_urllib_request
-    _VALID_URL = r'https?://(?:www\.)?funimation\.com/shows/.+[^ ]/videos/official/(?P<id>[^?]+)'
+    _VALID_URL = r'https?://(?:www\.)?funimation\.com/shows/[^/]+/videos/official/(?P<id>[^?]+)'
-            'User-Agent': 'Mozilla/5.0 (Windows NT 5.2; WOW64; rv:42.0) Gecko/20100101 Firefox/42.0',
+        login_request = sanitized_Request('http://www.funimation.com/login', data, headers={
-            raise
+        login = self._download_webpage(
-        video_id = self._search_regex(r'"FUNImationID":"(.+?)"', webpage, 'video_id')
+        display_id = self._match_id(url)
-            'title': video_show + ' - ' + video_title + ' ',
+            'display_id': display_id,
-        login_request.add_header('Content-Type', 'application/x-www-form-urlencoded')
+        login_request = sanitized_Request(login_url, data, headers={
-            login = self._download_webpage(login_request, login_url)
+            login = self._download_webpage(
-                raise ExtractorError('Unable to login, wrong username or password.', expected=True)
+            raise ExtractorError('Unable to login, wrong username or password.', expected=True)
-    determine_ext,
+    qualities,
-                'title': 're:^WDR Fernsehen [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
+                'title': 're:^WDR Fernsehen Live [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-                'upload_date': '20150212',
+                'upload_date': '20150101',
-            ext = 'flv'
+            f4m_formats = self._extract_f4m_formats(video_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18', page_id, f4m_id='hds', fatal=False)
-            ext = fmt['ext']
+            smil_formats = self._extract_smil_formats(video_url, page_id, False, {
-            ext = determine_ext(video_url)
+            formats.append({
-            'ext': ext,
+            'formats': formats,
-        manifest = fix_xml_ampersands(urlh.read()).strip()
+        manifest = fix_xml_ampersands(urlh.read().decode('utf-8', 'ignore')).strip()
-            fileid = fileid_dict[format]
+            #fileid = fileid_dict[format]
-                    'ts': dt['total_milliseconds_video'],
+                    #'ts': dt['total_milliseconds_video'],
-                    '_' + str(int(n) + 1).zfill(2) + \
+                    '_00'+ \
-        oip = data2['security']['ip']
+        oip = data1['security']['ip']
-                n = str(int(dt['size']))
+                #n = str(int(dt['size']))
-        } for i in range(max(len(v) for v in data1['stream']))]
+        } for i in range(max(len(v.get('segs')) for v in data1['stream']))]
-        'expected_warnings': ['HTTP Error 404'],
+        'expected_warnings': ['Unable to download SMIL file'],
-    def _formats_from_smil(self, smil_xml):
+    def _formats_from_smil(self, smil_doc):
-                formats.extend(self._formats_from_smil(smil_xml))
+            smil_doc = self._download_smil(smil_url, video_id, fatal=False)
-from ..compat import compat_etree_fromstring
+from ..compat import (
-    def _download_api_formats(self, video_id):
+    def _download_api_formats(self, video_id, video_url):
-            video_id, self._oauth_token)
+        api_url = compat_urlparse.urljoin(video_url, '//apiv2.vevo.com/video/%s/streams/hls?token=%s' % (
-        formats.extend(self._download_api_formats(video_id))
+        formats.extend(self._download_api_formats(video_id, url))
-        video_info = response['video']
+        video_info = response['video'] or {}
-        if not video_info:
+        if not video_info and response.get('statusCode') != 909:
-            f for f in video_info['videoVersions']
+            f for f in video_info.get('videoVersions', [])
-        timestamp_ms = int_or_none(self._search_regex(
+        timestamp = int_or_none(self._search_regex(
-            video_info['launchDate'], 'launch date', fatal=False))
+            video_info['launchDate'], 'launch date', fatal=False),
-            'title': video_info['title'],
+            'title': title,
-            'duration': video_info['duration'],
+            'thumbnail': video_info.get('imageUrl'),
-            b'becaf9be', base64.b64decode(data2['ep'].encode('ascii'))
+            b'becaf9be', base64.b64decode(data2['security']['encrypt_string'].encode('ascii'))
-        oip = data2['ip']
+        oip = data2['security']['ip']
-        seed = data1['seed']
+        seed = data1.get('seed')
-            fileid_dict[format] = fileid[:8] + '%s' + fileid[10:]
+        for stream in data1['stream']:
-            fileid = fileid_dict[format] % hex(int(n))[2:].upper().zfill(2)
+            #fileid = fileid_dict[format] % hex(int(n))[2:].upper().zfill(2)
-        for format in data1['streamtypes']:
+        for stream in data1['stream']:
-                n = str(int(dt['no']))
+            for dt in stream['segs']:
-                    'K': dt['k'],
+                    'K': dt['key'],
-                    'ts': dt['seconds'],
+                    'ts': dt['total_milliseconds_video'],
-            '3gphd': '1'
+            '3gphd': '1',
-            '3gphd': 'mp4'
+            '3gphd': 'mp4',
-            return raw_data['data']['security']
+            return raw_data['data']
-        title = data1['title']
+        #title = data1['title']
-        for fm in data1['streamtypes']:
+        } for i in range(max(len(v) for v in data1['stream']))]
-            for video_url, seg, entry in zip(video_urls, data1['segs'][fm], entries):
+            for video_url, seg, entry in zip(video_urls, stream['segs'], entries):
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                webpage)
+                r'<param name="flashvars"[^>]*value="[^"]*?url=(https?://www\.ign\.com/videos/.*?)["&]',
-            formats.extend(self._extract_m3u8_formats(m3u8_url, video_id))
+            m3u8_formats = self._extract_m3u8_formats(m3u8_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False)
-            formats.extend(self._extract_f4m_formats(f4m_url, video_id))
+            f4m_formats = self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False)
-            thumbnails.append({'url': thumbnail['url']})
+        thumbnails = [{
-    _VALID_URL = r'https?://(?:www\.)?ultimedia\.com/deliver/(?P<type>generic|musique)(?:/[^/]+)*/(?:src|article)/(?P<id>[\d+a-z]+)'
+    _VALID_URL = r'''(?x)
-        'url': 'https://www.ultimedia.com/deliver/generic/iframe/mdtk/01601930/zone/1/src/s8uk0r/autoplay/yes/ad/no/width/714/height/435',
+        'url': 'https://www.ultimedia.com/default/index/videogeneric/id/s8uk0r',
-        'url': 'https://www.ultimedia.com/deliver/musique/iframe/mdtk/01601930/zone/1/article/xvpfp8/autoplay/yes/ad/no/width/714/height/435',
+        'url': 'https://www.ultimedia.com/default/index/videomusic/id/xvpfp8',
-        video_type, video_id = re.match(self._VALID_URL, url).groups()
+        mobj = re.match(self._VALID_URL, url)
-class VGTVIE(InfoExtractor):
+class VGTVIE(XstreamIE):
-        self._sort_formats(formats)
+        info['formats'].extend(formats)
-        return {
+        self._sort_formats(info['formats'])
-        }
+        })
-
+    def _extract_video_info(self, partner_id, video_id):
-                        formats.extend(self._extract_f4m_formats(url, embed_code, -1, 'hds', fatal=False))
+                    if delivery_type == 'hls' or '.m3u8' in url:
-                            'format_id': '%s-%s-%sp' % (stream.get('profile'), delivery_type, stream.get('height')),
+                            'format_id': delivery_type,
-        manifest = urlh.read()
+        # Some manifests may be malformed, e.g. prosiebensat1 generated manifests
-__version__ = '2015.12.09'
+__version__ = '2015.12.10'
-        #('azpm.org', 'KUAT 6 (KUAT)'),  # http://www.azpm.org/
+        # ('kuac.org', 'KUAC (KUAC)'),  # http://kuac.org/kuac-tv/
-        #('kvcr.org', 'KVCR TV/DT/FM :: Vision for the Future (KVCR)'),  # http://kvcr.org
+        # ('klcs.org', 'KLCS/Channel 58 (KLCS)'),  # http://www.klcs.org
-        #('ripbs.org', 'Rhode Island PBS (WSBE)'),  # http://www.ripbs.org/home/
+        # ('ripbs.org', 'Rhode Island PBS (WSBE)'),  # http://www.ripbs.org/home/
-        #('wjct.org', 'WJCT Public Broadcasting (WJCT)'),  # http://www.wjct.org
+        # ('wjct.org', 'WJCT Public Broadcasting (WJCT)'),  # http://www.wjct.org
-        #('pbsguam.org', 'PBS Guam (KGTF)'),  # http://www.pbsguam.org/
+        # ('pbsguam.org', 'PBS Guam (KGTF)'),  # http://www.pbsguam.org/
-        #('wtvp.org', 'WTVP & WTVP.org, Public Media for Central Illinois (WTVP)'),  # http://www.wtvp.org/
+        # ('wtvp.org', 'WTVP & WTVP.org, Public Media for Central Illinois (WTVP)'),  # http://www.wtvp.org/
-        #('lakeshorepublicmedia.org', 'Lakeshore Public Television (WYIN)'),  # http://lakeshorepublicmedia.org/
+        # ('lakeshorepublicmedia.org', 'Lakeshore Public Television (WYIN)'),  # http://lakeshorepublicmedia.org/
-        #('blueridgepbs.org', 'Blue Ridge PBS (WBRA)'),  # http://www.blueridgepbs.org/
+        # ('shptv.org', 'Smoky Hills Public Television (KOOD)'),  # http://www.shptv.org
-        #('wyes.org', 'WYES-TV/New Orleans (WYES)'),  # http://www.wyes.org
+        # ('wyes.org', 'WYES-TV/New Orleans (WYES)'),  # http://www.wyes.org
-        #('prairiepublic.org', 'PRAIRIE PUBLIC (KFME)'),  # http://www.prairiepublic.org/
+        # ('prairiepublic.org', 'PRAIRIE PUBLIC (KFME)'),  # http://www.prairiepublic.org/
-        #('wqln.org', 'WQLN/Channel 54 (WQLN)'),  # http://www.wqln.org
+        # ('wqln.org', 'WQLN/Channel 54 (WQLN)'),  # http://www.wqln.org
-        #('whro.org', 'WHRO (WHRO)'),  # http://whro.org
+        # ('whro.org', 'WHRO (WHRO)'),  # http://whro.org
-        #('kedt.org', 'KEDT/Channel 16 (KEDT)'),  # http://www.kedt.org
+        # ('tamu.edu', 'KAMU - TV (KAMU)'),  # http://KAMU.tamu.edu
-        #('ktxt.org', 'KTTZ-TV (KTXT)'),  # http://www.ktxt.org
+        # ('kmbh.org', 'KMBH-TV (KMBH)'),  # http://www.kmbh.org
-                } for subtitle_url in subtitle.get('urls', [])]
+            subtitles_data = metadata.get('subtitles', {}).get('data', {})
-            [r'buildPlayer\(({.+?})\);', r'playerV5\s*=\s*dmp\.create\([^,]+?,\s*({.+?})\);'],
+            [r'buildPlayer\(({.+?})\);\n',  # See https://github.com/rg3/youtube-dl/issues/7826
-        ('kbtc.org', 'KBTC Public Television (KBTC)'),  # http://kbtc.org
+        ('video.pbs.org', 'PBS: Public Broadcasting Service'),  # http://www.pbs.org/
-           (?:videos?|watch)\.(?:%s)/(?:viralplayer|video)/(?P<id>[0-9]+)/? |
+           (?:%s)/(?:viralplayer|video)/(?P<id>[0-9]+)/? |
-    ''' % '|'.join(list(zip(*_STATIONS))[0])
+    ''' % '|'.join(re.escape(p) for p in list(zip(*_STATIONS))[0])
-            req = sanitized_Request(req_url)
+            
-            return raw_data['data'][0]
+
-        basic_data_url = 'http://v.youku.com/player/getPlayList/VideoIDS/%s' % video_id
+        #basic_data_url = 'http://v.youku.com/player/getPlayList/VideoIDS/%s' % video_id
-            'http://v.youku.com/player/getPlayList/VideoIDS/%s/Pf/4/ctype/12/ev/1' % video_id,
+            #'http://v.youku.com/player/getPlayList/VideoIDS/%s/Pf/4/ctype/12/ev/1' % video_id,
-        prefer_ffmpeg = self._downloader.params.get('prefer_ffmpeg', False)
+        prefer_ffmpeg = False
-        ('WesternReservePublicMedia.org', 'Western Reserve PBS (WNEO)'),  # http://www.WesternReservePublicMedia.org/
+        ('westernreservepublicmedia.org', 'Western Reserve PBS (WNEO)'),  # http://www.WesternReservePublicMedia.org/
-        ('kbyutv.org', 'KBYU-TV (KBYU)'),  # WY, http://www.kbyutv.org/
+        ('aptv.org', 'APT - Alabama Public Television (WBIQ)'),  # http://aptv.org/
-__version__ = '2015.12.06'
+__version__ = '2015.12.09'
-                    https?://(?:www\.)?
+                    (?:https?://(?:www\.)?
-                        aftenposten.no/webtv
+                        %s
-                    )
+                    )|
-                    '''
+                    ''' % ('|'.join(_HOST_TO_APPNAME.keys()), '|'.join(_APP_NAME_TO_VENDOR.keys()))
-    }
+        appname = self._HOST_TO_APPNAME[host] if host else mobj.group('appname')
-            % (self._HOST_WEBSITES[host]['vendor'], video_id, self._HOST_WEBSITES[host]['appname']),
+            % (vendor, video_id, appname),
-            m3u8_formats = self._extract_m3u8_formats(hls_url, video_id, 'mp4', m3u8_id='hls', fatal=False)
+            m3u8_formats = self._extract_m3u8_formats(
-            f4m_formats = self._extract_f4m_formats(hds_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18', video_id, f4m_id='hds', fatal=False)
+            f4m_formats = self._extract_f4m_formats(
-        return self.url_result('http://bt.no/tv/embed?id=%s' % video_id, 'VGTV')
+        return self.url_result('bttv:%s' % video_id, 'VGTV')
-        return self.url_result('http://bt.no/tv/embed?id=%s' % self._match_id(url), 'VGTV')
+        return self.url_result('bttv:%s' % self._match_id(url), 'VGTV')
-        self.assertMatch('http://video.pbs.org/widget/partnerplayer/980042464/', ['PBS'])
+        self.assertMatch('http://video.pbs.org/viralplayer/2365173446/', ['pbs'])
-           (?:video\.pbs|watch\.knpb)\.org/(?:viralplayer|video)/(?P<id>[0-9]+)/? |
+           (?:videos?|watch)\.(?:%s)/(?:viralplayer|video)/(?P<id>[0-9]+)/? |
-    '''
+    ''' % '|'.join(list(zip(*_STATIONS))[0])
-           video\.pbs\.org/(?:viralplayer|video)/(?P<id>[0-9]+)/? |
+           (?:video\.pbs|watch\.knpb)\.org/(?:viralplayer|video)/(?P<id>[0-9]+)/? |
-from ..utils import determine_ext
+from ..utils import int_or_none
-            r'var player_btns\s*=\s*(.*?);\n', webpage, 'quality info'), video_id)
+        gexo_files = self._parse_json(
-
+        for format_id, f in gexo_files.items():
-        return self.url_result(theplatform_url)
+        return self.url_result(smuggle_url(theplatform_url, {'source_url': url}))
-    unsmuggle_url,
+    float_or_none,
-    float_or_none,
+    xpath_with_ns,
-            webpage = self._download_webpage(url, video_id)
+            headers = {}
-            r'<video[^>]+>\s*<source src=(["\'])(?P<url>.+?)\1',
+            r'<video[^>]+>\s*<source[^>]+src=(["\'])(?P<url>.+?)\1',
-    _VALID_URL = r'http://(?:www\.)?wimp\.com/(?P<id>[^/]+)/'
+    _VALID_URL = r'http://(?:www\.)?wimp\.com/(?P<id>[^/]+)'
-            self.to_screen('Found YouTube video')
+
-                'url': video_url,
+                'url': youtube_id,
-            self.to_screen('rutube video detected')
+from .pladform import PladformIE
-            return self.url_result(mobj.group('url'), 'Pladform')
+        pladform_url = PladformIE._extract_url(webpage)
-__version__ = '2015.12.05'
+__version__ = '2015.12.06'
-            'http://beeg.com/api/v3/video/%s' % video_id, video_id)
+            'http://beeg.com/api/v4/video/%s' % video_id, video_id)
-    _VALID_URL = r'https?://(?:www\.)?nowtv\.(?:de|at|ch)/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<show_id>[^/]+)/(?:list/[^/]+/)?(?P<id>[^/]+)/(?:player|preview)'
+    _VALID_URL = r'https?://(?:www\.)?nowtv\.(?:de|at|ch)/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<show_id>[^/]+)/(?:(?:list/[^/]+|jahr/\d{4}/\d{1,2})/)?(?P<id>[^/]+)/(?:player|preview)'
-        enc_key = '2c76de15dcb44bd28ff0927d50d31620'
+        # last update at 2015-12-06 for Zombie::bite
-                    http://(?:www\.)?
+                    https?://(?:www\.)?
-                    (?P<id>[0-9]+)
+                    (?P<id>\d+)
-        },{
+        },
-                hls_url, video_id, 'mp4', m3u8_id='hls'))
+            m3u8_formats = self._extract_m3u8_formats(hls_url, video_id, 'mp4', m3u8_id='hls', fatal=False)
-                video_id, f4m_id='hds'))
+            f4m_formats = self._extract_f4m_formats(hds_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18', video_id, f4m_id='hds', fatal=False)
-                    'height': height,
+            mp4_urls.append(mp4_url)
-                    'preference': 1,
+                    'format_id': 'mp4-%s' % vbr,
-        return self.url_result('xstream:btno:%s' % self._match_id(url), 'Xstream')
+        return self.url_result('http://bt.no/tv/embed?id=%s' % self._match_id(url), 'VGTV')
-        'url': 'http://www.nowvideo.ch/video/0mw0yow7b6dxa',
+        'url': 'http://www.nowvideo.to/video/0mw0yow7b6dxa',
-    MovShareIE,
+    WholeCloudIE,
-    IE_DESC = 'MovShare'
+class WholeCloudIE(NovaMovIE):
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'movshare\.(?:net|sx|ag)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': '(?:wholecloud\.net|movshare\.(?:net|sx|ag))'}
-    _HOST = 'www.movshare.net'
+    _HOST = 'www.wholecloud.net'
-        'url': 'http://www.movshare.net/video/559e28be54d96',
+        'url': 'http://www.wholecloud.net/video/559e28be54d96',
-from .novamov import NovaMovIE
+from .novamov import (
-    }
+
-                        'tbr': int(mobj.group(3)),
+                        'tbr': int_or_none(mobj.group(3)),
-                        'tbr': int_or_none(mobj.group(3)),
+                        'width': int(mobj.group(1)),
-                req_format_split = req_format.split('-')
+                req_format_split = req_format.split('-', 1)
-            AllowedQuality('mp4', ('low', 'medium', 'high',)),
+            AllowedQuality('webm', ['high', ]),
-                return (AllowedQuality(req_ext, ('high', )), )
+                return (AllowedQuality(req_ext, (best_quality, )), )
-            for quality in qualities:
+        for ext, qualities_ in allowed_qualities:
-                formats.append({
+                format_info = {
-                })
+                }
-            if re.search(r'"contentRating":"restricted"', webpage)
+            if re.search(r'(?:"contentRating":|"rating",)"restricted"', webpage)
-        mobj = re.search(r'(?m)&mediaURL=([^&]+)', webpage)
+        mobj = re.search(r'(?m)&(?:media|video)URL=([^&]+)', webpage)
-            video_ext = mediaURL[-3:]
+            video_ext = determine_ext(mediaURL)
-__version__ = '2015.11.27.1'
+__version__ = '2015.12.05'
-from .common import InfoExtractor
+from .srgssr import SRGSSRIE
-class RTSIE(InfoExtractor):
+class RTSIE(SRGSSRIE):
-                    )'''
+    _VALID_URL = r'rts:(?P<rts_id>\d+)|https?://(?:www\.)?rts\.ch/(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html'
-            'md5': '753b877968ad8afaeddccc374d4256a5',
+            'md5': 'f254c4b26fb1d3c183793d52bc40d3e7',
-                'ext': 'mp4',
+                'ext': 'flv',
-            'md5': 'c148457a27bdc9e5b1ffe081a7a8337b',
+            'md5': 'f1077ac5af686c76528dc8d7c5df29ba',
-                'ext': 'mp4',
+                'id': '5742494',
-            'md5': '9bb06503773c07ce83d3cbd793cebb91',
+            'md5': '9f713382f15322181bb366cc8c3a4ff0',
-                'ext': 'mp4',
+                'ext': 'flv',
-        display_id = m.group('display_id') or m.group('display_id_new')
+        media_id = m.group('rts_id') or m.group('id')
-        all_info = download_json(video_id)
+        all_info = download_json(media_id)
-        # video_id extracted out of URL is not always a real id
+        # media_id extracted out of URL is not always a real id
-                r'<article[^>]+class="content-item"[^>]*>\s*<a[^>]+data-video-urn="urn:rts:video:(\d+)"',
+                r'<article[^>]+class="content-item"[^>]*>\s*<a[^>]+data-video-urn="urn:([^"]+)"',
-                return self.playlist_result(entries, video_id, self._og_search_title(page))
+                entries = [self.url_result('srgssr:%s' % video_urn, 'SRGSSR') for video_urn in videos]
-                    video_id, 'Downloading %s token' % format_id)
+                    media_id, 'Downloading %s token' % format_id)
-                formats.extend(self._extract_f4m_formats(
+                f4m_formats = self._extract_f4m_formats(
-                    video_id, f4m_id=format_id))
+                    media_id, f4m_id=format_id, fatal=False)
-                    format_url, video_id, 'mp4', m3u8_id=format_id))
+                m3u8_formats = self._extract_m3u8_formats(
-        self._check_formats(formats, video_id)
+        self._check_formats(formats, media_id)
-            'id': video_id,
+            'id': media_id,
-#        'ENDDATE': 'For legal reasons, this video was only available for a specified period of time.',
+        # 'ENDDATE': 'For legal reasons, this video was only available for a specified period of time.',
-
+    def get_media_data(self, bu, media_type, media_id):
-                    expected=True)
+            raise ExtractorError('%s said: %s' % (self.IE_NAME, self._ERRORS[media_data['block']]), expected=True)
-                    formats.extend(self._extract_f4m_formats(asset_url + '?hdcore=3.4.0', media_id, f4m_id='hds'))
+                    f4m_formats = formats.extend(self._extract_f4m_formats(asset_url + '?hdcore=3.4.0', media_id, f4m_id='hds', fatal=False))
-                    formats.extend(self._extract_m3u8_formats(asset_url, media_id, m3u8_id='hls'))
+                    m3u8_formats = formats.extend(self._extract_m3u8_formats(asset_url, media_id, m3u8_id='hls', fatal=False))
-    },{
+    }, {
-        request = sanitized_Request(complete_url)
+        request = sanitized_Request(url + '?' + compat_urllib_parse.urlencode(data))
-            r'(?ms)<script type="application/json" id="displayList-data">\s*(.*?)\s*</script>',
+            r'(?ms)<script type="application/json" id="displayList-data">(.+?)</script>',
-            serve_url, '', {'Content-Type': 'application/json'})
+            'http://hypem.com/serve/source/%s/%s' % (track_id, key),
-        final_url = song_data["url"]
+        final_url = song_data['url']
-        }
+        },
-from ..utils import sanitized_Request
+from ..utils import (
-        'md5': '6e297b7e789329923fcf83abb67c9289',
+        'md5': '1c1e75d22ffa53320f45eeb07bc4cdc0',
-        format = "-".join(format)
+        flashvars = self._parse_json(self._search_regex(
-            'format_id': format,
+            'formats': formats,
-        'md5': '9e9cd59c3a8a7d8d5407605f51093050',
+        'url': 'https://www.acast.com/condenasttraveler/-where-are-you-taipei-101-taiwan',
-            'id': '43da2262-ade7-420c-8564-f6367da7c010',
+            'id': '57de3baa-4bb0-487e-9418-2692c1277a34',
-            'duration': 2520,
+            'title': '"Where Are You?": Taipei 101, Taiwan',
-        'url': 'https://www.acast.com/gardenersquestiontime',
+        'url': 'https://www.acast.com/condenasttraveler',
-            'description': 'md5:c7ef18049da6a52b63d371b3edccce90',
+            'id': '50544219-29bb-499e-a083-6087f4cb7797',
-        'playlist_mincount': 5,
+        'playlist_mincount': 20,
-            }
+            },
-                'title': 'Kaleidoscope, Leonard Cohen',
+                'title': 'Leonard Cohen, Kaleidoscope - BBC Radio 4',
-                'duration': 1740,
+        duration = None
-                webpage, 'description', fatal=False)
+                webpage, 'description', default=None)
-    _VALID_URL = r'https?://(?:www\.srf\.ch/play(?:er)?/tv/[^/]+/video/(?P<display_id>[^?]+)\?id=|tp\.srgssr\.ch/p/flash\?urn=urn:srf:ais:video:)(?P<id>[0-9a-f\-]{36})'
+    _VALID_URL = r'https?://(?:www\.srf\.ch/play(?:er)?/(?:tv|radio)/[^/]+/(?P<media_type>video|audio)/(?P<display_id>[^?]+)\?id=|tp\.srgssr\.ch/p/flash\?urn=urn:srf:ais:video:)(?P<id>[0-9a-f\-]{36})'
-        display_id = re.match(self._VALID_URL, url).group('display_id') or video_id
+        mobj = re.match(self._VALID_URL, url)
-            'http://il.srgssr.ch/integrationlayer/1.0/ue/srf/video/play/%s.xml' % video_id,
+            'http://il.srgssr.ch/integrationlayer/1.0/ue/srf/%s/play/%s.xml' % (media_type, video_id),
-                original_ext = determine_ext(full_url)
+                original_ext = determine_ext(full_url).lower()
-        video_info = self._download_json('http://www.clipfish.de/devapi/id/%s?format=json&apikey=hbbtv' % video_id, video_id)['items'][0]
+        video_info = self._download_json(
-        }]
+        formats = []
-class SkyNewArabiaBaseIE(InfoExtractor):
+class SkyNewsArabiaBaseIE(InfoExtractor):
-class SkyNewsArabiaIE(SkyNewArabiaBaseIE):
+class SkyNewsArabiaIE(SkyNewsArabiaBaseIE):
-class SkyNewsArabiaArticleIE(SkyNewArabiaBaseIE):
+class SkyNewsArabiaArticleIE(SkyNewsArabiaBaseIE):
-            'duration': 1486486,
+            'duration': 1486.486,
-                'duration': 238231,
+                'duration': 238.231,
-                'duration': 135427,
+                'duration': 135.427,
-                'duration': 191933,
+                'duration': 191.933,
-                'duration': 44961,
+                'duration': 44.961,
-            'duration': 56823,
+            'duration': 56.823,
-            'duration': int_or_none(metadata.get('duration')),
+            'duration': float_or_none(metadata.get('duration'), 1000),
-                'duration': 853386,
+                'duration': 853.386,
-                'duration': 194948,
+                'duration': 194.948,
-                'duration': 204405,
+                'duration': 204.405,
-            'duration': 422255,
+            'duration': 422.255,
-                'duration': 725983,
+                'duration': 725.983,
-        for video_file in video_info.find('files').iter('file'):
+        for video_file in video_info.findall('.//file'):
-                formats.extend(self._extract_m3u8_formats(video_url, video_id, m3u8_id='hls'))
+                m3u8_formats = self._extract_m3u8_formats(video_url, video_id, m3u8_id='hls', fatal=False)
-                formats.extend(self._extract_f4m_formats(video_url + '?hdcore=3.4.1.1', video_id, f4m_id='hds'))
+                f4m_formats = self._extract_f4m_formats(video_url + '?hdcore=3.4.1.1', video_id, f4m_id='hds', fatal=False)
-                width, height, bitrate = re.search(r'(\d+)x(\d+)(?:_(\d+))?', key).groups()
+                mobj = re.search(r'(\d+)x(\d+)(?:_(\d+))?', key)
-                    'tbr': int_or_none(bitrate),
+                    'width': int_or_none(mobj.group(1)),
-        },{
+        }, {
-        song_url = preview_url.replace('/previews/', '/c/originals/')
+        song_url = re.sub(r'audiocdn(\d+)', r'stream\1', preview_url)
-            'id': str(video_data['id']),
+            'id': compat_str(video_data['id']),
-            str(show_data['id']),
+            compat_str(show_data['id']),
-class AdobeTVIE(InfoExtractor):
+class AdobeTVBaseIE(InfoExtractor):
-            'http://tv.adobe.com/api/v4/episode/get/?language=%s&show_urlname=%s&urlname=%s&disclosure=standard' % (language, show_urlname, urlname),
+            self._API_BASE_URL + 'episode/get/?language=%s&show_urlname=%s&urlname=%s&disclosure=standard' % (language, show_urlname, urlname),
-class AdobeTVPlaylistBaseIE(InfoExtractor):
+class AdobeTVPlaylistBaseIE(AdobeTVBaseIE):
-            'http://tv.adobe.com/api/v4/show/get/?%s' % query, show_urlname)['data'][0]
+        show_data = self._download_json(self._API_BASE_URL + 'show/get/?%s' % query, show_urlname)['data'][0]
-            self._extract_playlist_entries('http://tv.adobe.com/api/v4/episode/?%s' % query, show_urlname),
+            self._extract_playlist_entries(self._API_BASE_URL + 'episode/?%s' % query, show_urlname),
-            self._extract_playlist_entries('http://tv.adobe.com/api/v4/show/?%s' % query, channel_urlname),
+            self._extract_playlist_entries(self._API_BASE_URL + 'show/?%s' % query, channel_urlname),
-        json_data = self._download_json(bc_api_url + '&video_fields=id,name,shortDescription,publishedDate,videoStillURL,length,IOSRenditions', display_id)
+        json_data = self._download_json(
-    },{
+    }, {
-        timestamp = int_or_none(video_info.find('dateCreated').attrib.get('uts'))
+        video_id = xpath_text(video_info, 'slug')
-                'url': media_info['href'],
+        # TODO: get correct ext for audio files
-
+            })
-from ..utils import ExtractorError
+from ..utils import (
-        'md5': 'c1450a00da251e2769b74b9005601cac',
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?trilulilu\.ro/(?:[^/]+/)?(?P<id>[^/#\?]+)'
-    }
+    }, {
-            raise ExtractorError('This video is private.', expected=True)
+        media_info = self._download_json('http://m.trilulilu.ro/%s?format=json' % display_id, display_id)
-            r'block_flash_vars\s*=\s*(\{[^\}]+\})', webpage, 'flashvars', fatal=False, default=None)
+        thumbnail = media_info.get('cover_url')
-            flashvars = self._parse_json(flashvars_str, display_id)
+        media_class = media_info.get('class')
-            }
+            raise ExtractorError('not a video or an audio')
-        ]
+        if media_class == 'audio':
-            'id': video_id,
+            'id': media_info['identifier'].split('|')[1],
-            'description': description,
+            'title': media_info['title'],
-)
+from ..compat import compat_str
-            'view_count': view_data.get('play'),
+            'view_count': int_or_none(view_data.get('play')),
-        raw_payload = self._search_regex(r'<script[^>]+class="amtv-embed"[^>]+id="([^"]+)"', webpage, 'raw payload');
+
-        page = self._download_webpage(
+        doc = self._download_xml(
-        doc = compat_etree_fromstring(page)
+        if xpath_text(doc, './result') == 'error':
-            size = durl.find('./filesize|./size')
+            size = xpath_text(durl, ['./filesize', './size'])
-                'filesize': int_or_none(size.text) if size else None,
+                'filesize': int_or_none(size),
-                'id': '%s_part%s' % (cid, durl.find('./order').text),
+                'id': '%s_part%s' % (cid, xpath_text(durl, './order')),
-                'duration': int_or_none(durl.find('./length').text) // 1000,
+                'duration': int_or_none(xpath_text(durl, './length'), 1000),
-            'id': str(cid),
+            'id': compat_str(cid),
-            'duration': int_or_none(doc.find('./timelength').text),
+            'duration': int_or_none(xpath_text(doc, './timelength')),
-                'url': self._proto_relative_url(video_url.replace('{DATA_MARKERS}', ''), 'http:'),
+                'url': decrypt_url(video_url),
-            'http://beeg.com/api/v1/video/%s' % video_id, video_id)
+            'http://beeg.com/api/v3/video/%s' % video_id, video_id)
-    duration:       Length of the video in seconds, as an integer.
+    duration:       Length of the video in seconds, as an integer or float.
-    _VALID_URL = r'https?://(?:(?:www\.)?bbc\.co\.uk/(?:(?:programmes/(?!articles/)|iplayer(?:/[^/]+)?/(?:episode/|playlist/))|music/clips[/#])|)(?P<id>%s)' % _ID_REGEX
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:(?:programmes/(?!articles/)|iplayer(?:/[^/]+)?/(?:episode/|playlist/))|music/clips[/#])(?P<id>%s)' % _ID_REGEX
-from .mtv import MTVServicesInfoExtractor
+from .common import InfoExtractor
-    _VALID_URL = r'http://www\.gametrailers\.com/(?P<type>videos|reviews|full-episodes)/(?P<id>.*?)/(?P<title>.*)'
+class GametrailersIE(InfoExtractor):
-        'md5': '4c8e67681a0ea7ec241e8c09b3ea8cf7',
+        'url': 'http://www.gametrailers.com/videos/view/gametrailers-com/116437-Just-Cause-3-Review',
-            'id': '70e9a5d7-cf25-4a10-9104-6f3e7342ae0d',
+            'id': '2983958',
-            'description': 'Faith is back!  Check out the World Premiere trailer for Mirror\'s Edge 2 straight from the EA Press Conference at E3 2013!',
+            'display_id': '116437-Just-Cause-3-Review',
-    _FEED_URL = 'http://www.gametrailers.com/feeds/mrss'
+    def _real_extract(self, url):
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:(?:programmes/(?!articles/)|iplayer(?:/[^/]+)?/(?:episode/|playlist/))|music/clips[/#])(?P<id>[\da-z]{8})'
+    _ID_REGEX = r'[pb][\da-z]{7}'
-                r'"vpid"\s*:\s*"([\da-z]{8})"', webpage, 'vpid', fatal=False, default=None)
+                r'"vpid"\s*:\s*"(%s)"' % self._ID_REGEX, webpage, 'vpid', fatal=False, default=None)
-             r'<param[^>]+name="externalIdentifier"[^>]+value="([\da-z]{8})"'],
+            [r'data-video-player-vpid="(%s)"' % self._ID_REGEX,
-        EMBED_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:[^/]+/)+[\da-z]{8}(?:\b[^"]+)?'
+        EMBED_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:[^/]+/)+%s(?:\b[^"]+)?' % self._ID_REGEX
-            lecture_id, 'Downloading lecture JSON', fatal=False)
+            lecture_id, 'Downloading lecture JSON')
-    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata', *args, **kwargs):
+    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata'):
-        response = super(UdemyIE, self)._download_json(url_or_request, video_id, note, *args, **kwargs)
+        response = super(UdemyIE, self)._download_json(url_or_request, video_id, note)
-
+    compat_HTTPError,
-    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata'):
+    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata', *args, **kwargs):
-        response = super(UdemyIE, self)._download_json(url_or_request, video_id, note)
+        response = super(UdemyIE, self)._download_json(url_or_request, video_id, note, *args, **kwargs)
-            lecture_id, 'Downloading lecture JSON')
+        webpage = self._download_webpage(url, lecture_id)
-        asset_type = lecture.get('assetType') or lecture.get('asset_type')
+        try:
-            return self.url_result(mobj.group(1), 'Youtube')
+        if stream_url:
-                        'filesize': int_or_none(f.get('file_size_in_bytes')),
+        duration = float_or_none(asset.get('data', {}).get('duration'))
-    _ALREADY_ENROLLED = '>You are already taking this course.<'
+    _VALID_URL = r'https?://www\.udemy\.com/(?P<id>[\da-z-]+)'
-        course_path = mobj.group('coursepath')
+        course_path = self._match_id(url)
-        course_title = response['title']
+        course_id = response['id']
-            self.to_screen('%s: Already enrolled in' % course_id)
+        self._enroll_course(webpage, course_id)
-            self.raise_login_required('Udemy account is required')
+            return
-        duration = asset['data']['duration']
+        duration = int_or_none(asset.get('data', {}).get('duration'))
-        ]
+        formats = [{
-        description = lecture['description']
+        description = lecture.get('description')
-                expected=True)
+        media_url = data.get('mediaUrl')
-        video_url = data['mediaUrl'] + '?hdcore=3.5.0&plugin=aasp-3.5.0.151.81'
+        if not media_url:
-            'ext': 'flv',
+            'formats': formats,
-                webpage, 'alternative title', fatal=False)
+                webpage, 'alternative title', default=None)
-from ..utils import sanitized_Request
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?vodlocker\.com/(?P<id>[0-9a-zA-Z]+)(?:\..*?)?'
+    _VALID_URL = r'https?://(?:www\.)?vodlocker\.com/(?:embed-)?(?P<id>[0-9a-zA-Z]+)(?:\..*?)?'
-            for video_url in set(re.findall('href="/?(view_video\.php\?viewkey=\d+[^"]*)"', webpage))
+            for video_url in set(re.findall(
-                           \? (?:.*?&)*? (?:p|a|list)=
+                           \? (?:.*?[&;])*? (?:p|a|list)=
-                                 (?:.*?&)??                                   # any other preceding param (like /?s=tuff&v=xxxx)
+                                 (?:.*?[&;])??                                # any other preceding param (like /?s=tuff&v=xxxx or ?s=tuff&amp;v=V36LpHqtcDY)
-                a_format['http_headers']['Youtubedl-no-compression'] = True
+                a_format.setdefault('http_headers', {})['Youtubedl-no-compression'] = 'True'
-            r'var\s+server\s*=\s*"([^"]+)\"', webpage, 'server URL')
+            [r'server\s*:\s*(["\'])(?P<url>.+?)\1', r'var\s+server\s*=\s*"(?P<url>[^"]+)\"'],
-        filtered_headers = dict((k, v) for k, v in headers.items() if k.lower() != 'accept-encoding')
+    filtered_headers = headers
-    return headers
+    return filtered_headers
-    to include the HTTP header "Youtubedl-No-Compression", which will be
+    to include the HTTP header "Youtubedl-no-compression", which will be
-                ''.join('%s: %s\r\n' % (key, val) for key, val in info_dict['http_headers'].items() if key.lower() != 'accept-encoding')]
+                ''.join('%s: %s\r\n' % (key, val) for key, val in headers.items())]
-            del req.headers['Youtubedl-no-compression']
+
-
+        def get_text_attr(d, attr):
-            raise ExtractorError('%s said: %s' % (self.IE_NAME, self.get_text_attr(data, 'error')), expected=True)
+            raise ExtractorError('%s said: %s' % (self.IE_NAME, get_text_attr(data, 'error')), expected=True)
-        capfile = self.get_text_attr(data, 'capfile')
+        capfile = get_text_attr(data, 'capfile')
-                    'tbr': int_or_none(self.get_text_attr(quality, 'bitrate')),
+                    'format_id': '%s-%sp' % (get_text_attr(quality, 'bitrate'), get_text_attr(quality, 'height')),
-                'duration': int_or_none(self.get_text_attr(f, 'length')),
+                'duration': int_or_none(get_text_attr(f, 'length')),
-            'categories': [video_data.get('topicTitle')],
+            'tags': video_data.get('tags', []),
-                'categories': [article_data.get('topicTitle')],
+                'tags': article_data.get('tags', []),
-                formats.extend(self._extract_m3u8_formats(stream['url'], video_id))
+                m3u8_formats = self._extract_m3u8_formats(
-                formats.extend(self._extract_f4m_formats(stream['url'], video_id))
+                f4m_formats = self._extract_f4m_formats(
-        video_id = self._search_regex(r'"bmmrId":"(.+?)"', webpage, 'id')
+        video_id = self._search_regex(
-            if stream["muxing_format"] == "TS":
+            if stream['muxing_format'] == 'TS':
-    _VALID_URL = r'https?://www\.bloomberg\.com/news/[^/]+/[^/]+/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?bloomberg\.com/(?:[^/]+/)*(?P<id>[^/?#]+)'
-    _IE_NAME = 'skynewsarabia:video'
+    IE_NAME = 'skynewsarabia:video'
-    _IE_NAME = 'skynewsarabia:video'
+    IE_NAME = 'skynewsarabia:video'
-                ratio = float(stretched_m.group('w')) / float(stretched_m.group('h'))
+                ratio = w / h
-        help='List all available formats of specified videos')
+        help='List all available formats of requested videos')
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?dbtv\.no/(?:(?:lazyplayer|player)/)?(?P<id>[0-9]+)(?:#(?P<display_id>.+))?'
-    }
+    }, {
-        display_id = mobj.group('display_id')
+        display_id = mobj.group('display_id') or video_id
-                    f['stretched_ratio'] = ratio
+            w = float(stretched_m.group('w'))
-__version__ = '2015.11.27'
+__version__ = '2015.11.27.1'
-__version__ = '2015.11.24'
+__version__ = '2015.11.27'
-                ''.join('%s: %s\r\n' % (key, val) for key, val in info_dict['http_headers'].items())]
+                ''.join('%s: %s\r\n' % (key, val) for key, val in info_dict['http_headers'].items() if key.lower() != 'accept-encoding')]
-        help='List all available formats')
+        help='List all available formats of specified videos')
-__version__ = '2015.11.23'
+__version__ = '2015.11.24'
-            r'\s*(?P<fields>([a-zA-Z$0-9]+\s*:\s*function\(.*?\)\s*\{.*?\})*)' +
+            r'\s*(?P<fields>([a-zA-Z$0-9]+\s*:\s*function\(.*?\)\s*\{.*?\}(?:,\s*)?)*)' +
-__version__ = '2015.11.21'
+__version__ = '2015.11.23'
-        pr = compat_urllib_request.Request(info_dict['url'])
+        pr = sanitized_Request(info_dict['url'])
-from ..compat import compat_urllib_request
+from ..utils import sanitized_Request
-            req = compat_urllib_request.Request(target_url)
+            req = sanitized_Request(target_url)
-)
+from ..compat import compat_urllib_error
-        request = compat_urllib_request.Request(url, None, headers)
+        basic_request = sanitized_Request(url, None, headers)
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-            request = compat_urllib_request.Request(
+            request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-            req = compat_urllib_request.Request(req_url)
+            req = sanitized_Request(req_url)
-)
+from ..compat import compat_urlparse
-            req = compat_urllib_request.Request(url)
+            req = sanitized_Request(url)
-    compat_urllib_request,
+    sanitized_Request,
-        req = compat_urllib_request.Request(request_url)
+        req = sanitized_Request(request_url)
-        req = compat_urllib_request.Request(
+        req = sanitized_Request(
-from ..utils import smuggle_url
+from ..utils import (
-        request = compat_urllib_request.Request(url)
+        request = sanitized_Request(url)
-    compat_urllib_request,
+    sanitized_Request,
-        req = compat_urllib_request.Request(
+        req = sanitized_Request(
-        req = compat_urllib_request.Request(compat_urllib_parse_unquote(playlist_url))
+        req = sanitized_Request(compat_urllib_parse_unquote(playlist_url))
-from ..compat import compat_urllib_request
+    sanitized_Request,
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-        login_request = compat_urllib_request.Request(login_url, data)
+        login_request = sanitized_Request(login_url, data)
-                   else compat_urllib_request.Request(url_or_request))
+                   else sanitized_Request(url_or_request))
-        playerdata_req = compat_urllib_request.Request(playerdata_url)
+        playerdata_req = sanitized_Request(playerdata_url)
-            streamdata_req = compat_urllib_request.Request(
+            streamdata_req = sanitized_Request(
-)
+from ..compat import compat_str
-        request = compat_urllib_request.Request(url)
+        request = sanitized_Request(url)
-)
+from ..compat import compat_urllib_parse
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-from ..utils import qualities
+from ..utils import (
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-from ..compat import compat_urllib_request
+    sanitized_Request,
-            request = compat_urllib_request.Request(
+            request = sanitized_Request(
-
+    sanitized_Request,
-        config_req = compat_urllib_request.Request(
+        config_req = sanitized_Request(
-)
+    sanitized_Request,
-        pllist_req = compat_urllib_request.Request(pllist_url)
+        pllist_req = sanitized_Request(pllist_url)
-        pl_req = compat_urllib_request.Request(pl_url)
+        pl_req = sanitized_Request(pl_url)
-from ..compat import compat_urllib_request
+    sanitized_Request,
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-    compat_urllib_request,
+    sanitized_Request,
-        login_page_req = compat_urllib_request.Request(self._LOGIN_URL)
+        login_page_req = sanitized_Request(self._LOGIN_URL)
-        request = compat_urllib_request.Request(self._LOGIN_URL, urlencode_postdata(login_form))
+        request = sanitized_Request(self._LOGIN_URL, urlencode_postdata(login_form))
-            check_req = compat_urllib_request.Request(self._CHECKPOINT_URL, urlencode_postdata(check_form))
+            check_req = sanitized_Request(self._CHECKPOINT_URL, urlencode_postdata(check_form))
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-        login_redir = compat_urllib_request.Request('http://id.fc2.com/?mode=redirect&login=done')
+        login_redir = sanitized_Request('http://id.fc2.com/?mode=redirect&login=done')
-from ..compat import compat_urllib_request
+    sanitized_Request,
-        req = compat_urllib_request.Request(webpage_url)
+        req = sanitized_Request(webpage_url)
-)
+    sanitized_Request,
-        token_req = compat_urllib_request.Request(token_url, b'{}', headers)
+        token_req = sanitized_Request(token_url, b'{}', headers)
-)
+from ..compat import compat_urllib_parse
-        request = compat_urllib_request.Request(login_url, compat_urllib_parse.urlencode(login_form))
+        request = sanitized_Request(login_url, compat_urllib_parse.urlencode(login_form))
-    compat_urllib_request,
+    sanitized_Request,
-            request = compat_urllib_request.Request(url)
+            request = sanitized_Request(url)
-            request = compat_urllib_request.Request(url)
+            request = sanitized_Request(url)
-)
+from ..compat import compat_urlparse
-        req = compat_urllib_request.Request(self._PLAYLIST_URL, payload)
+        req = sanitized_Request(self._PLAYLIST_URL, payload)
-)
+from ..compat import compat_urllib_parse
-        r = compat_urllib_request.Request(
+        r = sanitized_Request(
-)
+from ..compat import compat_urllib_parse
-        request = compat_urllib_request.Request(complete_url)
+        request = sanitized_Request(complete_url)
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-)
+    sanitized_Request,
-        req = compat_urllib_request.Request(player_url)
+        req = sanitized_Request(player_url)
-)
+    sanitized_Request,
-        request = compat_urllib_request.Request(api_url, json.dumps(data))
+        request = sanitized_Request(api_url, json.dumps(data))
-)
+from ..compat import compat_urllib_parse_urlparse
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-    compat_urllib_request,
+    sanitized_Request,
-        play_json_req = compat_urllib_request.Request(
+        play_json_req = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-                request = compat_urllib_request.Request(
+                request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(self._FILTER_POST, compat_urllib_parse.urlencode(disclaimer_form))
+        request = sanitized_Request(self._FILTER_POST, compat_urllib_parse.urlencode(disclaimer_form))
-        req = compat_urllib_request.Request('http://www.metacafe.com/watch/%s/' % video_id)
+        req = sanitized_Request('http://www.metacafe.com/watch/%s/' % video_id)
-)
+from ..compat import compat_urllib_parse
-        req = compat_urllib_request.Request(
+        req = sanitized_Request(
-from ..compat import compat_urllib_request
+    sanitized_Request,
-        vid_config_request = compat_urllib_request.Request(
+        vid_config_request = sanitized_Request(
-)
+from ..compat import compat_urllib_parse
-        req = compat_urllib_request.Request(self._API_URL, post)
+        req = sanitized_Request(self._API_URL, post)
-    compat_urllib_request,
+from ..utils import sanitized_Request
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-)
+from ..compat import compat_urllib_parse
-            req = compat_urllib_request.Request(builtin_url)
+            req = sanitized_Request(builtin_url)
-            req = compat_urllib_request.Request(url, post, headers)
+            req = sanitized_Request(url, post, headers)
-)
+from ..compat import compat_urllib_parse
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-)
+from ..utils import sanitized_Request
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-    compat_urllib_request,
+    sanitized_Request,
-        req = compat_urllib_request.Request(webpage_url)
+        req = sanitized_Request(webpage_url)
-    compat_urllib_request,
+    sanitized_Request,
-            request = compat_urllib_request.Request('http://www.myvideo.de/service/data/video/%s/config' % video_id, '')
+            request = sanitized_Request('http://www.myvideo.de/service/data/video/%s/config' % video_id, '')
-    compat_urllib_request,
+from ..utils import sanitized_Request
-        req = compat_urllib_request.Request('%s%s' % (self._API_BASE, endpoint))
+        req = sanitized_Request('%s%s' % (self._API_BASE, endpoint))
-)
+from ..compat import compat_urllib_parse
-                                                compat_urllib_parse.urlencode({'getConfig': 'true'}).encode('ascii'))
+        request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-            flv_info_request = compat_urllib_request.Request(
+            flv_info_request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
+        request = sanitized_Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
-)
+    sanitized_Request,
-        req = compat_urllib_request.Request(url, urlencode_postdata(fields))
+        req = sanitized_Request(url, urlencode_postdata(fields))
-)
+from ..compat import compat_urlparse
-            request = compat_urllib_request.Request(
+            request = sanitized_Request(
-    compat_urllib_request,
+from ..compat import compat_str
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-)
+    sanitized_Request,
-            request = compat_urllib_request.Request(
+            request = sanitized_Request(
-)
+from ..utils import js_to_json
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-)
+from ..compat import compat_urllib_parse
-        req = compat_urllib_request.Request(url, post, headers)
+        req = sanitized_Request(url, post, headers)
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-                request = compat_urllib_request.Request(
+                request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        req = compat_urllib_request.Request(
+        req = sanitized_Request(
-)
+    sanitized_Request,
-        token_req = compat_urllib_request.Request(
+        token_req = sanitized_Request(
-        delivery_req = compat_urllib_request.Request(
+        delivery_req = sanitized_Request(
-        info_req = compat_urllib_request.Request(
+        info_req = sanitized_Request(
-    compat_urllib_request,
+from ..compat import compat_urllib_parse
-        req = compat_urllib_request.Request(
+        req = sanitized_Request(
-)
+from ..compat import compat_urllib_parse
-        req = compat_urllib_request.Request(url, post)
+        req = sanitized_Request(url, post)
-            req = compat_urllib_request.Request(
+            req = sanitized_Request(
-from ..compat import compat_urllib_request
+    sanitized_Request,
-        png_request = compat_urllib_request.Request(png_url)
+        png_request = sanitized_Request(png_url)
-)
+from ..compat import compat_urllib_parse
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-)
+from ..compat import compat_urlparse
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-)
+from ..compat import compat_urllib_parse
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-)
+from ..compat import compat_urllib_parse
-        req = compat_urllib_request.Request(url, post)
+        req = sanitized_Request(url, post)
-)
+from ..compat import compat_urllib_parse
-            request = compat_urllib_request.Request(url)
+            request = sanitized_Request(url)
-)
+from ..compat import compat_urllib_parse
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-            request = compat_urllib_request.Request(
+            request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-            req = compat_urllib_request.Request(base_data_url + vid_id)
+            req = sanitized_Request(base_data_url + vid_id)
-    compat_urllib_request,
+    sanitized_Request,
-        req = compat_urllib_request.Request('http://www.' + mobj.group('url'))
+        req = sanitized_Request('http://www.' + mobj.group('url'))
-)
+    sanitized_Request,
-        req = compat_urllib_request.Request(api_url, headers={
+        req = sanitized_Request(api_url, headers={
-)
+from ..compat import compat_urllib_parse
-        req = compat_urllib_request.Request(url, post, headers)
+        req = sanitized_Request(url, post, headers)
-)
+    sanitized_Request,
-        req = compat_urllib_request.Request(self._API_URL + api_path)
+        req = sanitized_Request(self._API_URL + api_path)
-)
+    sanitized_Request,
-        request = compat_urllib_request.Request(playlist_url)
+        request = sanitized_Request(playlist_url)
-)
+from ..compat import compat_urllib_parse_urlparse
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-)
+from ..compat import compat_urllib_parse
-        request = compat_urllib_request.Request(self._LOGIN_URL, payload)
+        request = sanitized_Request(self._LOGIN_URL, payload)
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(url, headers=headers)
+        request = sanitized_Request(url, headers=headers)
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-from ..compat import compat_urllib_request
+    sanitized_Request,
-            request = compat_urllib_request.Request(url)
+            request = sanitized_Request(url)
-            url_or_request = compat_urllib_request.Request(url_or_request, headers=headers)
+            url_or_request = sanitized_Request(url_or_request, headers=headers)
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        info_request = compat_urllib_request.Request(info_url, data)
+        info_request = sanitized_Request(info_url, data)
-)
+    sanitized_Request,
-            request = compat_urllib_request.Request(url)
+            request = sanitized_Request(url)
-from ..compat import compat_urllib_request
+    sanitized_Request,
-        req = compat_urllib_request.Request(url, payload)
+        req = sanitized_Request(url, payload)
-)
+from ..compat import compat_etree_fromstring
-        req = compat_urllib_request.Request(
+        req = sanitized_Request(
-    compat_urllib_request
+    sanitized_Request,
-        request = compat_urllib_request.Request(json_url, None, headers)
+        request = sanitized_Request(json_url, None, headers)
-from ..compat import compat_urllib_request
+from ..utils import sanitized_Request
-        req = compat_urllib_request.Request(iframe_url)
+        req = sanitized_Request(iframe_url)
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(url)
+        request = sanitized_Request(url)
-        return compat_urllib_request.Request(
+        return sanitized_Request(
-    compat_urllib_request,
+    sanitized_Request,
-        request = compat_urllib_request.Request(
+        request = sanitized_Request(
-)
+from ..compat import compat_urllib_parse
-            req = compat_urllib_request.Request(url, post)
+            req = sanitized_Request(url, post)
-)
+from ..compat import compat_urlparse
-        req = compat_urllib_request.Request(
+        req = sanitized_Request(
-from ..utils import ExtractorError
+from ..utils import (
-        request = compat_urllib_request.Request(self._API_URL.format(video_id))
+        request = sanitized_Request(self._API_URL.format(video_id))
-)
+from ..compat import compat_urllib_parse
-            req = compat_urllib_request.Request(url, post)
+            req = sanitized_Request(url, post)
-)
+from ..compat import compat_urllib_parse_unquote
-        req = compat_urllib_request.Request(url)
+        req = sanitized_Request(url)
-)
+from ..compat import compat_urllib_parse_unquote
-        android_req = compat_urllib_request.Request(url)
+        android_req = sanitized_Request(url)
-    compat_urllib_request,
+    sanitized_Request,
-            request = compat_urllib_request.Request(
+            request = sanitized_Request(
-    compat_urllib_request,
+)
-            req = compat_urllib_request.Request(req_url)
+            req = sanitized_Request(req_url)
-from ..compat import compat_urllib_request
+    sanitized_Request,
-        request = compat_urllib_request.Request(url)
+        request = sanitized_Request(url)
-    compat_urllib_request,
+    sanitized_Request,
-        req = compat_urllib_request.Request(self._LOGIN_URL, login_data)
+        req = sanitized_Request(self._LOGIN_URL, login_data)
-            tfa_req = compat_urllib_request.Request(self._TWOFACTOR_URL, tfa_data)
+            tfa_req = sanitized_Request(self._TWOFACTOR_URL, tfa_data)
-    compat_urllib_request_Request,
+    sanitized_Request,
-            req = compat_urllib_request_Request(req)
+            req = sanitized_Request(req)
-    compat_urllib_request_Request,
+    sanitized_Request,
-        login_request = compat_urllib_request_Request(self._LOGIN_URL, data)
+        login_request = sanitized_Request(self._LOGIN_URL, data)
-        password_request = compat_urllib_request_Request(url + '/password', data)
+        password_request = sanitized_Request(url + '/password', data)
-        password_request = compat_urllib_request_Request(pass_url, data)
+        password_request = sanitized_Request(pass_url, data)
-        request = compat_urllib_request_Request(url, None, headers)
+        request = sanitized_Request(url, None, headers)
-        password_request = compat_urllib_request_Request(password_url, post)
+        password_request = sanitized_Request(password_url, post)
-        request = compat_urllib_request_Request(url)
+        request = sanitized_Request(url)
-    compat_urllib_request,
+    compat_urllib_request_Request,
-        login_request = compat_urllib_request.Request(self._LOGIN_URL, data)
+        login_request = compat_urllib_request_Request(self._LOGIN_URL, data)
-        password_request = compat_urllib_request.Request(url + '/password', data)
+        password_request = compat_urllib_request_Request(url + '/password', data)
-        password_request = compat_urllib_request.Request(pass_url, data)
+        password_request = compat_urllib_request_Request(pass_url, data)
-        request = compat_urllib_request.Request(url, None, headers)
+        request = compat_urllib_request_Request(url, None, headers)
-        password_request = compat_urllib_request.Request(password_url, post)
+        password_request = compat_urllib_request_Request(password_url, post)
-        request = compat_urllib_request.Request(url)
+        request = compat_urllib_request_Request(url)
-                'upload_date': '20120724',
+                'upload_date': '20150827',
-                'uploader_id': 'setindia'
+                'uploader_id': 'setindia',
-            # Title with JS-like syntax "};"
+            # Title with JS-like syntax "};" (see https://github.com/rg3/youtube-dl/issues/7468)
-            return json.loads(uppercase_escape(config))
+    def _get_ytplayer_config(self, video_id, webpage):
-        player_config = self._get_ytplayer_config(webpage)
+        player_config = self._get_ytplayer_config(video_id, webpage)
-        if player_config is None:
+        if not player_config:
-            if ytplayer_config is not None:
+            ytplayer_config = self._get_ytplayer_config(video_id, video_webpage)
-            display_id)
+        modules = self._search_regex(
-            if module_.get('moduleName') == name:
+            if name in (module_.get('moduleName'), module_.get('name')):
-                return json.loads(uppercase_escape(config))
+        config = self._search_regex(patterns, webpage, 'ytconfig.player', default=None)
-        }
+        },
-        mobj = re.search(r';ytplayer.config = ({.*?});', webpage)
+        player_config = self._get_ytplayer_config(webpage)
-        if mobj is None:
+        if player_config is None:
-                ytplayer_config = json.loads(json_code)
+            ytplayer_config = self._get_ytplayer_config(video_webpage)
-            mobj = re.search(r';ytplayer\.config\s*=\s*({.*?});', video_webpage)
+            mobj = re.search(r';ytplayer\.config\s*=\s*({.*?});ytplayer', video_webpage)
-            r'<title>(.+) porn HD.+?</title>', webpage, 'title')
+            [r'<span[^>]+class=["\']video-name["\'][^>]*>([^<]+)',
-    guess = url.partition('?')[0].rpartition('.')[2].rstrip('/')
+    guess = url.partition('?')[0].rpartition('.')[2]
-    guess = url.partition('?')[0].rpartition('.')[2]
+    guess = url.partition('?')[0].rpartition('.')[2].rstrip('/')
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    # Extract the video ids from the playlist pages
+class YoutubeEntryListBaseInfoExtractor(InfoExtractor):
-                    video_title=video_title)
+            for entry in self._process_page(content_html):
-class YoutubePlaylistsBaseInfoExtractor(InfoExtractor):
+class YoutubePlaylistsBaseInfoExtractor(YoutubeEntryListBaseInfoExtractor):
-        return self.playlist_result(entries, playlist_id, title)
+        return self.playlist_result(self._entries(webpage, playlist_id), playlist_id, title)
-__version__ = '2015.11.19'
+__version__ = '2015.11.21'
-class YoutubeShowIE(InfoExtractor):
+class YoutubeShowIE(YoutubePlaylistsBaseInfoExtractor):
-        }
+        playlist_id = self._match_id(url)
-        # only single format until explicit listformats was requested.
+        # only single format until formats listing was explicitly requested.
-        limit = results_per_page = min(
+        limit = min(
-            ('mp4', ('low', 'medium', 'high',)),
+            AllowedQuality('webm', ('high',)),
-        for ext, qualities in ALLOWED_QUALITIES:
+        for ext, qualities in allowed_qualities:
-                self._sleep(3, display_id)
+
-class PluralsightIE(InfoExtractor):
+class PluralsightBaseIE(InfoExtractor):
-    _API_BASE = 'http://app.pluralsight.com'
+
-class PluralsightCourseIE(InfoExtractor):
+class PluralsightCourseIE(PluralsightBaseIE):
-                    'http://app.pluralsight.com/training/Player/ViewClip',
+                    '%s/training/Player/ViewClip' % self._API_BASE,
-            'http://www.pluralsight.com/data/course/%s' % course_id,
+            '%s/data/course/%s' % (self._API_BASE, course_id),
-            'http://www.pluralsight.com/data/course/content/%s' % course_id,
+            '%s/data/course/content/%s' % (self._API_BASE, course_id),
-                    'http://www.pluralsight.com/training/player?%s' % player_parameters,
+                    '%s/training/player?%s' % (self._API_BASE, player_parameters),
-    _LOGIN_URL = 'https://www.pluralsight.com/id/'
+    _LOGIN_URL = 'https://app.pluralsight.com/id/'
-        query['limit'] = results_per_page = min(
+        limit = results_per_page = min(
-
+        for i in itertools.count(1):
-                next_url, collection_id, 'Downloading page {0}'.format(i + 1),
+                next_url, collection_id, 'Downloading page {0}'.format(i),
-                'total_results', total_results))
+            collection = response.get('collection', [])
-            collection = response['collection']
+            collection = list(filter(bool, collection))
-                yield item
+            for item in collection:
-            if (total_results is not None and collected_results >= total_results) or not collection:
+            if not collection or collected_results >= limit:
-        return self.playlist_result(results, playlist_title=query)
+        tracks = self._get_collection('/search/tracks', query, limit=n, q=query)
-
+    encode_dict,
-                data = compat_urllib_parse.urlencode(query)
+                data = compat_urllib_parse.urlencode(encode_dict(query))
-    return dict((k.encode(encoding), v.encode(encoding)) for k, v in d.items())
+    def encode(v):
-                    errnote='Unable to download API page')
+            response = self._download_json(
-                collected_results >= total_results) or not collection:
+            if (total_results is not None and collected_results >= total_results) or not collection:
-            next_url = response.get('next_href', None)
+            next_url = response.get('next_href')
-            limit=n, q=query)
+        tracks = self._get_collection(
-            for track in itertools.islice(tracks, n)]
+        results = [self.url_result(track['uri']) for track in itertools.islice(tracks, n)]
-        return self.playlist_result(results, playlist_title=query)
+        return self.playlist_result(results, playlist_title=query)
-    _MAX_RESULTS = 200
+    _MAX_RESULTS = float('inf')
-    _RESULTS_PER_PAGE = 50
+    _MAX_RESULTS_PER_PAGE = 200
-        query['limit'] = self._RESULTS_PER_PAGE
+        query['limit'] = results_per_page = min(
-        total_results = self._MAX_RESULTS
+        total_results = None
-                query['offset'] = i * self._RESULTS_PER_PAGE
+                query['offset'] = i * results_per_page
-                next_url = '{0}{1}?{2}'.format(self._API_V2_BASE, endpoint, data)
+                next_url = '{0}{1}?{2}'.format(
-            if collected_results >= total_results or not collection:
+            if (total_results is not None and
-            q=query.encode('utf-8'))
+            limit=n, q=query)
-                '[soundcloud] No track results', expected=True)
+                'Soundcloud said: No track results', expected=True)
-        return self.playlist_result(results[:n], playlist_title=query)
+        return self.playlist_result(results, playlist_title=query)
-            results.append(self.url_result(url=uri))
+        results = [self.url_result(url=track['uri'])
-                break
+        for track in itertools.islice(tracks, n):
-                next_url = '{0}{1}?{2}'.format(api_base_url, endpoint, data)
+                next_url = '{0}{1}?{2}'.format(self._API_V2_BASE, endpoint, data)
-                u'total_results', total_results))
+                'total_results', total_results))
-            next_url = response.get(u'next_href', None)
+            next_url = response.get('next_href', None)
-            collection_id='Query "{}"'.format(query),
+            collection_id='Query "{0}"'.format(query),
-                video_title='{0} - {1}'.format(username, title)))
+            uri = track['uri']
-    SoundcloudPlaylistIE
+    SoundcloudPlaylistIE,
-from .common import InfoExtractor
+from .common import (
-    ExtractorError,
+    determine_ext,
-        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')
+        formats = []
-                    else ('/'.join(manifest_url.split('/')[:-1]) + '/' + media_url))
+                    else ((base_url or '/'.join(manifest_url.split('/')[:-1])) + '/' + media_url))
-    _VALID_URL = 'https?://rutube\.ru/video/embed/(?P<id>[0-9]+)'
+    _VALID_URL = 'https?://rutube\.ru/(?:video|play)/embed/(?P<id>[0-9]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                })
+                entry_info_dict['formats'] = self._extract_smil_formats(video_url, video_id)
-                })
+                entry_info_dict['url'] = video_url
-    _VALID_URL = r'https?://(?:www\.)?pluralsight\.com/courses/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:(?:www|app)\.)?pluralsight\.com/(?:library/)?courses/(?P<id>[^/]+)'
-            self.raise_login_required('Pluralsight account is required')
+            return
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                    'http://www.pluralsight.com/training/Player/ViewClip',
+                    'http://app.pluralsight.com/training/Player/ViewClip',
-    _VALID_URL = r'https?://(?:www\.)?pluralsight\.com/training/player\?author=(?P<author>[^&]+)&name=(?P<name>[^&]+)(?:&mode=live)?&clip=(?P<clip>\d+)&course=(?P<course>[^&]+)'
+    _VALID_URL = r'https?://(?:(?:www|app)\.)?pluralsight\.com/training/player\?'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        course = mobj.group('course')
+        qs = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)
-            'description': info.get('description'),
+            'description': clean_html(info.get('description')),
-                'fps': f.get('frameRate'),
+                'ext': f.get('fileExt'),
-                'width': f.get('width'),
+                'height': int_or_none(f.get('height')),
-            return self.url_result('kaltura:%(partner_id)s:%(id)s' % mobj.groupdict(), 'Kaltura')
+            return self.url_result(smuggle_url(
-from ..compat import compat_urllib_parse
+from ..compat import (
-        } for f in source_data['flavorAssets']]
+        source_url = smuggled_data.get('source_url')
-            # Remove operators that we don't use and join them with the sourrounding strings
+            # Remove operators that we don't use and join them with the surrounding strings
-                        (experimenatal)
+                        (experimental)
-        # the connection was interrumpted and resuming appears to be
+        # the connection was interrupted and resuming appears to be
-    _VALID_URL = r'https://instagram\.com/p/(?P<id>[^/?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?instagram\.com/p/(?P<id>[^/?#&]+)'
-                feed_id = self._search_regex(r'defaultFeedId\s*:\s*"([^"]+)"', feed_script, 'default feed id', default=None)
+                    self._proto_relative_url(script, 'http:'),
-                feed_script = self._download_webpage(script, video_id, 'Downloading feed script')
+                feed_script = self._download_webpage(
-    _VALID_URL = r'https?://www\.bloomberg\.com/news/videos/[^/]+/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://www\.bloomberg\.com/news/[^/]+/[^/]+/(?P<id>[^/?#]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'https://vimeo\.com/groups/(?P<name>[^/]+)'
+    _VALID_URL = r'https://vimeo\.com/groups/(?P<name>[^/]+)(?:/(?!videos?/\d+)|$)'
-        video_ids = []
+    def _title_and_entries(self, list_id, base_url):
-                }
+    def _extract_videos(self, list_id, base_url):
-__version__ = '2015.11.18'
+__version__ = '2015.11.19'
-            r'<iframe[^>]+src="(?P<url>%s)"' % UDNEmbedIE._VALID_URL, webpage)
+            r'<iframe[^>]+src="(?P<url>%s)"' % UDNEmbedIE._PROTOCOL_RELATIVE_VALID_URL, webpage)
-    _VALID_URL = r'https?://video\.udn\.com/(?:embed|play)/news/(?P<id>\d+)'
+    _PROTOCOL_RELATIVE_VALID_URL = r'//video\.udn\.com/(?:embed|play)/news/(?P<id>\d+)'
-            'http://video.pbs.org/videoInfo/%s?format=json&type=partner' % video_id,
+            'http://player.pbs.org/videoInfo/%s?format=json&type=partner' % video_id,
-__version__ = '2015.11.15'
+__version__ = '2015.11.18'
-            r'(?s)<h1 class="pl-header-title[^"]*">\s*(.*?)\s*</h1>',
+            r'(?s)<h1 class="pl-header-title[^"]*"[^>]*>\s*(.*?)\s*</h1>',
-           video\.pbs\.org/(?:widget/)?partnerplayer/(?P<player_id>[^/]+)/
+           (?:video|player)\.pbs\.org/(?:widget/)?partnerplayer/(?P<player_id>[^/]+)/
-from ..compat import compat_urllib_request, compat_urlparse
+from ..compat import compat_urllib_request
-            auth_url = video_url.replace(
+            video_url = video_url.replace(
-    return ('&%s;' % entity)
+    return '&%s;' % entity
-            unescapeHTML('&eacute;'), 'Ã©')
+        self.assertEqual(unescapeHTML('&eacute;'), 'Ã©')
-        return compat_chr(int(numstr, base))
+        # See https://github.com/rg3/youtube-dl/issues/7518
-    writeautomaticsub: Write the automatic subtitles to a file
+    writeautomaticsub: Write the automatically generated subtitles to a file
-        help='Write automatic subtitle file (YouTube only)')
+        help='Write automatically generated subtitle file (YouTube only)')
-                'url': 'http://m1.music.126.net/%s/%s.%s' %
+                'url': 'http://m5.music.126.net/%s/%s.%s' %
-__version__ = '2015.11.13'
+__version__ = '2015.11.15'
-)
+from .compat import compat_str
-from .nowtv import NowTVIE
+from .nowtv import (
-    _VALID_URL = r'https?://(?:www\.)?nowtv\.(?:de|at|ch)/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/(?:player|preview)'
+class NowTVBaseIE(InfoExtractor):
-            'title': 'Die neuen Bauern und eine Hochzeit',
+            'title': 'Inka Bause stellt die neuen Bauern vor',
-            display_id = '/'.join((display_id_split[0], display_id_split[-1]))
+        mobj = re.match(self._VALID_URL, url)
-            display_id)
+            'https://api.nowtv.de/v3/movies/%s?fields=%s'
-        video_id = compat_str(info['id'])
+        return self._extract_video(info, display_id)
-        self._sort_formats(formats)
+class NowTVListIE(NowTVBaseIE):
-        duration = parse_duration(info.get('duration'))
+    _SHOW_FIELDS = ('title', )
-        thumbnail = f.get('defaultImage169Format') or f.get('defaultImage169Logo')
+    _TESTS = [{
-        }
+    def _real_extract(self, url):
-    _VALID_URL = r'https?://(?:www\.)?dumpert\.nl/(?:mediabase|embed)/(?P<id>[0-9]+/[0-9a-zA-Z]+)'
+    _VALID_URL = r'(?P<protocol>https?)://(?:www\.)?dumpert\.nl/(?:mediabase|embed)/(?P<id>[0-9]+/[0-9a-zA-Z]+)'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        url = 'http://www.dumpert.nl/mediabase/' + video_id
+        url = '%s://www.dumpert.nl/mediabase/%s' % (protocol, video_id)
-        url = 'https://www.dumpert.nl/mediabase/' + video_id
+        url = 'http://www.dumpert.nl/mediabase/' + video_id
-    _VALID_URL = r'https?://(?:www\.)?periscope\.tv/w/(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?periscope\.tv/[^/]+/(?P<id>[^/?#]+)'
-        # http://www.bbc.co.uk/programmes/b06bp7lf)
+        # http://www.bbc.co.uk/programmes/b06bp7lf). Also may fail with selectionunavailable.
-                if e.id in ('notukerror', 'geolocation'):
+                if e.id in ('notukerror', 'geolocation', 'selectionunavailable'):
-            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 403:
+            if isinstance(ee.cause, compat_HTTPError) and ee.cause.code in (403, 404):
-)
+from .periscope import PeriscopeIE
-        (username, password) = self._get_login_info()
+        username, password = self._get_login_info()
-            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com|vidto.\me))/
+            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com|vidto\.me))/
-                return self.url_result(youtube_url, 'Youtube')
+            iframe_url = self._html_search_regex(
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'https://instagram\.com/p/(?P<id>[\da-zA-Z]+)'
+    _VALID_URL = r'https://instagram\.com/p/(?P<id>[^/?#&]+)'
-        # and what to do when it is
+                # According to examples from [3] it's unclear whether video id
-    _TEST = {
+    _TESTS = [{
-            'duration': 165.768,
+            'formats': 'mincount:22',
-    }
+    }]
-            'duration': 165768,
+            'duration': 165.768,
-    js_to_json,
+    js_to_json,
-        'add_ie': ['Brightcove'],
+        'add_ie': ['BrightcoveLegacy'],
-            'ie_key': 'Brightcove',
+            'ie_key': 'BrightcoveLegacy',
-            'add_ie': ['Brightcove'],
+            'add_ie': ['BrightcoveLegacy'],
-            'add_ie': ['Brightcove'],
+            'add_ie': ['BrightcoveLegacy'],
-            'add_ie': ['Brightcove'],
+            'add_ie': ['BrightcoveLegacy'],
-                'ie_key': 'Brightcove'
+                'ie_key': 'BrightcoveLegacy'
-                        return self.url_result(bc_url, 'Brightcove')
+                        return self.url_result(bc_url, 'BrightcoveLegacy')
-        return self.url_result(smuggle_url(bc_url, {'Referer': url}), 'Brightcove')
+        return self.url_result(smuggle_url(bc_url, {'Referer': url}), 'BrightcoveLegacy')
-        'add_ie': ['Brightcove'],
+        'add_ie': ['BrightcoveLegacy'],
-        # Look for BrightCove:
+        # Look for Brightcove Legacy Studio embeds
-            return self.url_result(brightcove_in_page_embed_url, 'BrightcoveInPageEmbed')
+        # Look for Brightcove New Studio embeds
-    def _extract_urls(self, webpage):
+    @staticmethod
-            entries.append(self.url_result(self._proto_relative_url(url)))
+            entries.append(url)
-            entries.append(self.url_result(
+            entries.append(
-                % (account_id, player_id, embed, video_id)))
+                % (account_id, player_id, embed, video_id))
-    BrightcoveInPageEmbedIE,
+    BrightcoveNewIE,
-class BrightcoveInPageEmbedIE(InfoExtractor):
+class BrightcoveNewIE(InfoExtractor):
-    BrightcoveInPageEmbedIE,
+    BrightcoveNewIE,
-        brightcove_in_page_embed_url = BrightcoveInPageEmbedIE._extract_url(webpage)
+        brightcove_in_page_embed_url = BrightcoveNewIE._extract_url(webpage)
-    BrightcoveIE,
+    BrightcoveLegacyIE,
-class BrightcoveIE(InfoExtractor):
+class BrightcoveLegacyIE(InfoExtractor):
-    BrightcoveIE,
+    BrightcoveLegacyIE,
-        bc_urls = BrightcoveIE._extract_brightcove_urls(webpage)
+        bc_urls = BrightcoveLegacyIE._extract_brightcove_urls(webpage)
-from .brightcove import BrightcoveIE
+from .brightcove import BrightcoveLegacyIE
-                        bc_url = BrightcoveIE._extract_brightcove_url(player_code)
+                        bc_url = BrightcoveLegacyIE._extract_brightcove_url(player_code)
-from .brightcove import BrightcoveIE
+from .brightcove import BrightcoveLegacyIE
-        bc_url = BrightcoveIE._extract_brightcove_url(webpage)
+        bc_url = BrightcoveLegacyIE._extract_brightcove_url(webpage)
-from .brightcove import BrightcoveIE
+from .brightcove import BrightcoveLegacyIE
-            brightcove_url = BrightcoveIE._extract_brightcove_url(webpage)
+            brightcove_url = BrightcoveLegacyIE._extract_brightcove_url(webpage)
-        return self.url_result(brightcove_url, BrightcoveIE.ie_key())
+        return self.url_result(brightcove_url, BrightcoveLegacyIE.ie_key())
-from .brightcove import BrightcoveIE
+from .brightcove import BrightcoveLegacyIE
-            'ie': BrightcoveIE.ie_key(),
+            'url': BrightcoveLegacyIE._extract_brightcove_url(iframe),
-    _VALID_URL = r'https?://players\.brightcove\.net/(?P<account_id>\d+)/(?P<player_id>[\da-f-]+)_(?P<embed>[a-z]+)/index\.html\?.*videoId=(?P<video_id>\d+)'
+    _VALID_URL = r'https?://players\.brightcove\.net/(?P<account_id>\d+)/(?P<player_id>[^/]+)_(?P<embed>[^/]+)/index\.html\?.*videoId=(?P<video_id>\d+)'
-        return None
+    def _extract_urls(self, webpage):
-    _VALID_URL = r'https?://players\.brightcove\.net/(?P<account_id>\d+)/([a-z0-9-]+)_([a-z]+)/index.html?.*videoId=(?P<video_id>\d+)'
+    _VALID_URL = r'https?://players\.brightcove\.net/(?P<account_id>\d+)/(?P<player_id>[\da-f-]+)_(?P<embed>[a-z]+)/index\.html\?.*videoId=(?P<video_id>\d+)'
-        webpage = self._download_webpage('http://players.brightcove.net/%s/%s_%s/index.min.js' % (account_id, player_id, embed), video_id)
+        webpage = self._download_webpage(
-        policy_key = catalog['policyKey']
+        policy_key = None
-            'https://edge.api.brightcove.com/playback/v1/accounts/%s/videos/%s' % (account_id, video_id),
+            'https://edge.api.brightcove.com/playback/v1/accounts/%s/videos/%s'
-        for source in json_data.get('sources'):
+        for source in json_data.get('sources', []):
-                formats.extend(self._extract_m3u8_formats(source.get('src'), video_id))
+                if not src:
-                    })
+                streaming_src = source.get('streaming_src')
-            'formats': formats,
+            'timestamp': timestamp,
-        webpage = self._download_webpage(url, display_id)
+        request = compat_urllib_request.Request(url)
-            'url': 'theplatform:%s' % real_id,
+            'url': smuggle_url(
-        title = self._og_search_description(webpage).strip('').replace('\n', ' ')
+        title = description = self._og_search_description(webpage).strip('').replace('\n', ' ').strip('ââ')
-        title, short_url = mobj.groups()
+        title = re.sub(r'\s+(https?://[^ ]+)', '', title)
-            'description': '%s on Twitter: "%s %s"' % (username, title, short_url),
+            'description': '%s on Twitter: "%s"' % (username, description),
-            'md5': '7d2f6b4d2eb841a7ccc893d479bfceb4',
+            'md5': '4fa26a35f9d1bf4b646590ba8e84be19',
-        'md5': '31cd83a116fc41f99ae3d909d4caf6a0',
+        'md5': 'db6612ec5d03355953c3ca9250c97e5e',
-__version__ = '2015.11.10'
+__version__ = '2015.11.13'
-                            video_url, video_id, 'mp4', m3u8_id='hls'))
+                        m3u8_formats = self._extract_m3u8_formats(
-                            video_url, video_id, f4m_id='hds'))
+                        f4m_formats = self._extract_f4m_formats(
-                    if not video_url or video_url in processed_urls or 'NOT_USED' in video_url:
+                    if (not video_url or video_url in processed_urls or
-                    'play_path': 'mp4:' + uri.split('<break>')[-1],
+                    'play_path': 'mp4:' + play_path,
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'ie_key': 'TwitterCard',
+        info = {
-            'url': card_url,
+
-        m3u8_url = config_files.get('hls', {}).get('all')
+        config_files = config['video'].get('files') or config['request'].get('files', {})
-        self._sort_formats(formats)
+        # Bitrates are completely broken. Single m3u8 may contain entries in kbps and bps
-from .gorillavid import GorillaVidIE
+from .xfileshare import XFileShareIE
-# -*- coding: utf-8 -*-
+# coding: utf-8
-    IE_DESC = 'GorillaVid.in, daclips.in, movpod.in, fastvideo.in, realvid.net, filehoot.com and vidto.me'
+class XFileShareIE(InfoExtractor):
-        title = self._search_regex(
+        title = (self._search_regex(
-            webpage, 'title', default=None) or self._og_search_title(webpage)
+            webpage, 'title', default=None) or self._og_search_title(webpage)).strip()
-    IE_DESC = 'GorillaVid.in, daclips.in, movpod.in, fastvideo.in, realvid.net and filehoot.com'
+    IE_DESC = 'GorillaVid.in, daclips.in, movpod.in, fastvideo.in, realvid.net, filehoot.com and vidto.me'
-            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com))/
+            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com|vidto.\me))/
-            [r'style="z-index: [0-9]+;">([^<]+)</span>', r'<td nowrap>([^<]+)</td>', r'>Watch (.+) '],
+            [r'style="z-index: [0-9]+;">([^<]+)</span>',
-            r'file\s*:\s*["\'](http[^"\']+)["\'],', webpage, 'file url')
+            [r'file\s*:\s*["\'](http[^"\']+)["\'],',
-            r'image\s*:\s*["\'](http[^"\']+)["\'],', webpage, 'thumbnail', fatal=False)
+            r'image\s*:\s*["\'](http[^"\']+)["\'],', webpage, 'thumbnail', default=None)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        self._set_cookie('vimeo.com', 'vuid', vuid)
+        self._set_vimeo_cookie('vuid', vuid)
-        self._set_cookie('vimeo.com', 'vuid', vuid)
+        self._set_vimeo_cookie('vuid', vuid)
-        self._set_cookie('vimeo.com', 'xsrft', token)
+        self._set_vimeo_cookie('vuid', vuid)
-        login_request.add_header('Cookie', 'vuid=%s' % vuid)
+        self._set_cookie('vimeo.com', 'vuid', vuid)
-        password_request.add_header('Cookie', 'clip_test_v2=0; vuid=%s' % vuid)
+        self._set_cookie('vimeo.com', 'vuid', vuid)
-        password_request.add_header('Cookie', 'vuid=%s' % vuid)
+        self._set_cookie('vimeo.com', 'vuid', vuid)
-        password_request.add_header('Cookie', 'clip_test2=1; vuid=%s' % vuid)
+        password_request.add_header('Cookie', 'clip_test_v2=0; vuid=%s' % vuid)
-    compat_urllib_parse
+from ..utils import (
-            'title': 'test.mp4'
+            'title': 'test'
-        cookies = self._get_cookies('http://%s/%s.html' % (self._HOST, video_id))
+            'http://vidto.me/%s.html' % video_id, video_id, 'Downloading video page')
-            cookie_string += "%s=%s;" % (key, cookies[key].value)
+        title = remove_end(self._html_search_regex(
-        req.add_header('Cookie', '%s' % cookie_string)
+        hidden_fields = self._hidden_inputs(page)
-        self.to_screen("Waiting for countdown...")
+        self.to_screen('Waiting for countdown...')
-        file_link = self._search_regex(file_link_regex, post_result, 'file_link')
+        file_link = self._search_regex(
-            'http://%s/video/%s' % (self._HOST, video_id), video_id, 'Downloading video page')
+        url = 'http://%s/video/%s' % (self._HOST, video_id)
-            raise ExtractorError('Video %s does not exist' % video_id, expected=True)
+        webpage = self._download_webpage(
-        filekey = self._search_regex(self._FILEKEY_REGEX, page, 'filekey')
+        if re.search(self._FILE_DELETED_REGEX, webpage) is not None:
-        description = self._html_search_regex(self._DESCRIPTION_REGEX, page, 'description', default='', fatal=False)
+        def extract_filekey(default=NO_DEFAULT):
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:ch|ec|sx|eu|at|ag|co|li)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:to|ch|ec|sx|eu|at|ag|co|li)'}
-    _HOST = 'www.nowvideo.ch'
+    _HOST = 'www.nowvideo.to'
-from .common import InfoExtractor
+from .common import InfoExtractor
-            note='Proceed to video...', errnote='unable to proceed', fatal=True)
+            note='Proceed to video...', errnote='unable to proceed')
-        file_link = self._search_regex(file_link_regex, post_result, 'file_link', fatal=True)
+        file_link = self._search_regex(file_link_regex, post_result, 'file_link')
-import sys
+import re
-)
+from ..utils import encode_dict
-    compat_str,
+    compat_urllib_parse
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            req.add_header('Cookie', '%s=%s' % (morsel.key, morsel.value))
+        cookie_string = ""
-        print("Waiting for countdown...")
+        self.to_screen("Waiting for countdown...")
-            req, None,
+            req, video_id,
-        file_link_regex = r'file_link ?= ?\'(https?:\/\/[0-9a-zA-z.\/\-_]+)'
+        file_link_regex = r'file_link\s*=\s*\'(https?:\/\/[0-9a-zA-z.\/\-_]+)'
-        bitrates.sort()
+        m3u8_url = self._search_regex(
-            update_self(ydl.to_screen, opts.verbose, ydl.get_opener())
+            update_self(ydl.to_screen, opts.verbose, ydl._opener)
-            update_self(ydl.to_screen, opts.verbose)
+            update_self(ydl.to_screen, opts.verbose, ydl.get_opener())
-from .utils import make_HTTPS_handler
+
-def update_self(to_screen, verbose):
+def update_self(to_screen, verbose, opener):
-__version__ = '2015.11.02'
+__version__ = '2015.11.10'
-            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?)?\.(?P<ext>[a-z]+)$',
+            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?|/base)?\.(?P<ext>[a-z]+)$',
-                                    r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\.js',
+                                    [r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\.js', r'(?:www|player)-([^/]+)/base\.js'],
-                (?:function\s+%s|[{;]%s\s*=\s*function)\s*
+                (?:function\s+%s|[{;]%s\s*=\s*function|var\s+%s\s*=\s*function)\s*
-                re.escape(funcname), re.escape(funcname)),
+                re.escape(funcname), re.escape(funcname), re.escape(funcname)),
-                        (:?(?:www|cdnapisec)\.)?kaltura\.com/
+                        (:?(?:www|cdnapi(?:sec)?)\.)?kaltura\.com/
-        mobj = (re.search(r"(?s)kWidget\.(?:thumb)?[Ee]mbed\(\{.*?'wid'\s*:\s*'_?(?P<partner_id>[^']+)',.*?'entry_id'\s*:\s*'(?P<id>[^']+)',", webpage) or
+        mobj = (re.search(r"(?s)kWidget\.(?:thumb)?[Ee]mbed\(\{.*?'wid'\s*:\s*'_?(?P<partner_id>[^']+)',.*?'entry_?[Ii]d'\s*:\s*'(?P<id>[^']+)',", webpage) or
-                re.search(r'(?s)(["\'])(?:https?:)?//cdnapisec\.kaltura\.com/.*?(?:p|partner_id)/(?P<partner_id>\d+).*?\1.*?entry_id\s*:\s*(["\'])(?P<id>[^\2]+?)\2', webpage))
+                re.search(r'(?s)(?P<q1>["\'])(?:https?:)?//cdnapi(?:sec)?\.kaltura\.com/.*?(?:p|partner_id)/(?P<partner_id>\d+).*?(?P=q1).*?entry_?[Ii]d\s*:\s*(?P<q2>["\'])(?P<id>.+?)(?P=q2)', webpage))
-    _VALID_URL = r'https?://www\.cmt\.com/videos/.+?/(?P<videoid>[^/]+)\.jhtml'
+    _VALID_URL = r'https?://www\.cmt\.com/(?:videos|shows)/(?:[^/]+/)*(?P<videoid>\d+)'
-        return self.url_result(embed_url, ie='TechTVMIT')
+        return self.url_result(embed_url)
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>extremetube\.com/.*?video/.+?(?P<id>[0-9]+))(?:[/?&]|$)'
+    _VALID_URL = r'https?://(?:www\.)?extremetube\.com/(?:[^/]+/)?video/(?P<id>[^/#?&]+)'
-            'id': '652431',
+            'id': 'music-video-14-british-euro-brit-european-cumshots-swallow-652431',
-        url = 'http://www.' + mobj.group('url')
+        video_id = self._match_id(url)
-)
+from ..compat import compat_urllib_request
-    qualities,
+    int_or_none,
-            r'<param[^>]+?name="flashvars"[^>]+?value="([^"]+)"', webpage, 'flash vars'))
+        flash_vars = self._parse_json(
-                    'url': vals[0],
+        for quality_key, video_url in flash_vars.items():
-
+            else:
-    _VALID_URL = r'https?://www\.rtbf\.be/(?:video/[^?]+\?.*\bid=|ouftivi/(?:[^/]+/)*[^?]+\?.*\bvideoId=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?rtbf\.be/(?:video/[^?]+\?.*\bid=|ouftivi/(?:[^/]+/)*[^?]+\?.*\bvideoId=)(?P<id>\d+)'
-    ]
+    _VALID_URL = r'https?://www\.rtbf\.be/(?:video/[^?]+\?.*\bid=|ouftivi/(?:[^/]+/)*[^?]+\?.*\bvideoId=)(?P<id>\d+)'
-    }
+    _VALID_URL = r'''(?x)
-    clean_html,
+    compat_urllib_request,
-    _VALID_URL = r'https?://movieclips\.com/(?P<id>[\da-zA-Z]+)(?:-(?P<display_id>[\da-z-]+))?'
+    _VALID_URL = r'https?://(?:www.)?movieclips\.com/videos/(?P<id>[^/?#]+)'
-        'url': 'http://movieclips.com/Wy7ZU-my-week-with-marilyn-movie-do-you-love-me/',
+        'url': 'http://www.movieclips.com/videos/warcraft-trailer-1-561180739597?autoPlay=true&playlistId=5',
-            'display_id': 'my-week-with-marilyn-movie-do-you-love-me',
+            'id': 'pKIGmG83AqD9',
-            'description': 'md5:e86795bd332fe3cff461e7c8dc542acb',
+            'title': 'Warcraft Trailer 1',
-        }
+        'add_ie': ['ThePlatform'],
-        smil_file = properties.attrib['smil_file']
+        display_id = self._match_id(url)
-        categories = properties.attrib['clip_categories'].split(',')
+        req = compat_urllib_request.Request(url)
-            'display_id': display_id,
+            '_type': 'url_transparent',
-            'id': '20171_part1',
+            'id': '20171',
-            'id': '14891_part1',
+            'id': '14891',
-            'duration': 5352,
+            'timestamp': 1284375600,
-                'title': 'Introduction To Bayesian Inference',
+                'title': 'Introduction To Bayesian Inference (Part 1)',
-                'title': 'Introduction To Bayesian Inference',
+                'title': 'Introduction To Bayesian Inference (Part 2)',
-        lecture_slug, part = re.match(self._VALID_URL, url).groups()
+        lecture_slug, explicit_part_id = re.match(self._VALID_URL, url).groups()
-        cfg = self._parse_json(self._search_regex([r'cfg\s*:\s*({.+?}),[\da-zA-Z_]:\(?function', r'cfg\s*:\s*({[^}]+})'], webpage, 'cfg'), lecture_slug, js_to_json)
+        cfg = self._parse_json(self._search_regex(
-        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (base_url, lecture_id), lecture_id)['lecture'][0]
+        lecture_data = self._download_json(
-        parts = cfg.get('videos')
+        playlist_entries = []
-                smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part)
+            multipart = len(parts) > 1
-                info['id'] = '%s_part%s' % (lecture_id, part)
+                info['id'] = lecture_id if not multipart else '%s_part%s' % (lecture_id, part_id)
-                return info
+                item_info = lecture_info.copy()
-            playlist_webpage = self._download_webpage('%s/site/ajax/drilldown/?id=%s' % (base_url, lecture_id), lecture_id)
+                result = {
-            lecture_info['_type'] = 'playlist'
+                for _, video_url in re.findall(
-        return lecture_info
+        playlist = self.playlist_result(playlist_entries, lecture_id)
-    compat_HTTPError,
+    compat_str,
-        cfg = self._parse_json(self._search_regex(r'cfg\s*:\s*({[^}]+})', webpage, 'cfg'), lecture_slug, js_to_json)
+        cfg = self._parse_json(self._search_regex([r'cfg\s*:\s*({.+?}),[\da-zA-Z_]:\(?function', r'cfg\s*:\s*({[^}]+})'], webpage, 'cfg'), lecture_slug, js_to_json)
-        lecture_id = str(cfg['obj_id'])
+        lecture_id = compat_str(cfg['obj_id'])
-                part = str(parts[0])
+                part = compat_str(parts[0])
-        else:
+        if not parts or lecture_data.get('type') == 'evt':
-        )(?:/lecture)?/(?P<id>[^/]+)(?:/video/(?P<part>\d+))?'''
+        )(?:/lecture)?/(?P<id>[^/]+)(?:/video/(?P<part>\d+))?/*(?:[#?].*)?$'''
-                    entries.append(self.url_result('%s/video/%s' % (base_url, lecture_id, part), 'Viidea'))
+                    entries.append(self.url_result('%s/%s/video/%s' % (base_url, lecture_slug, part), 'Viidea'))
-from .videolecturesnet import VideoLecturesNetIE
+from .viidea import ViideaIE
-    IE_NAME = 'videolectures.net'
+class ViideaIE(InfoExtractor):
-        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (self._proto_relative_url(cfg['livepipe'], 'http:'), lecture_id), lecture_id)['lecture'][0]
+        base_url = self._proto_relative_url(cfg['livepipe'], 'http:')
-                smil_url = 'http://videolectures.net/%s/video/%s/smil.xml' % (lecture_slug, part)
+                smil_url = '%s/%s/video/%s/smil.xml' % (base_url, lecture_slug, part)
-                    entries.append(self.url_result('http://videolectures.net/%s/video/%s' % (lecture_slug, part), 'VideoLecturesNet'))
+                    entries.append(self.url_result('%s/video/%s' % (base_url, lecture_id, part), 'Viidea'))
-                for _, video_url in re.findall(r'<a[^>]+href=(["\'])(.+?)\1[^>]+id=["\']lec=\d+', webpage)]
+                self.url_result(compat_urlparse.urljoin(url, video_url), 'Viidea')
-    _VALID_URL = r'http://(?:www\.)?videolectures\.net/(?P<id>[^/#?]+)/*(?:[#?].*)?$'
+    _VALID_URL = r'http://(?:www\.)?videolectures\.net/(?P<id>[^/]+)(?:/video/(?P<part>\d+))?'
-            'id': 'promogram_igor_mekjavic_eng',
+            'id': '20171_part1',
-            'id': 'russir2010_filippova_nlp',
+            'id': '14891_part1',
-            'id': 'deeplearning2015_montreal',
+            'id': '23181',
-            'description': 'md5:90121a40cc6926df1bf04dcd8563ed3b',
+            'description': 'md5:0533a85e4bd918df52a01f0e1ebe87b7',
-        video_id = self._match_id(url)
+        lecture_slug, part = re.match(self._VALID_URL, url).groups()
-        smil_url = 'http://videolectures.net/%s/video/1/smil.xml' % video_id
+        cfg = self._parse_json(self._search_regex(r'cfg\s*:\s*({[^}]+})', webpage, 'cfg'), lecture_slug, js_to_json)
-                return self.playlist_result(entries, video_id, playlist_title, playlist_description)
+        lecture_id = str(cfg['obj_id'])
-        info = self._parse_smil(smil, smil_url, video_id)
+        lecture_data = self._download_json('%s/site/api/lecture/%s?format=json' % (self._proto_relative_url(cfg['livepipe'], 'http:'), lecture_id), lecture_id)['lecture'][0]
-        info['id'] = video_id
+        lecture_info = {
-            info['duration'] = parse_duration(switch.attrib.get('dur'))
+        entries = []
-        return info
+        lecture_info['entries'] = entries
-            r'\d+,(\d+),(\d+),"(https?://redirector\.googlevideo\.com.*?)"', webpage)]
+            r'\d+,(\d+),(\d+),"(https?://[^.]+\.googleusercontent.com.*?)"', webpage)]
-from .common import InfoExtractor
+from .amp import AMPIE
-class DramaFeverBaseIE(InfoExtractor):
+class DramaFeverBaseIE(AMPIE):
-        }
+        },
-                video_id, 'Downloading episode JSON')['channel']['item']
+            info = self._extract_feed_info('http://www.dramafever.com/amp/episode/feed.json?guid=%s' % video_id)
-                    subtitles.setdefault('English', []).append({
+                    info['subtitiles'].setdefault('English', []).append({
-        }
+        return info
-from .common import InfoExtractor
+from .amp import AMPIE
-class FoxNewsIE(InfoExtractor):
+class FoxNewsIE(AMPIE):
-                'description': 'Doctors baffled by 16-year-old girl that is the size of a toddler',
+                'description': '16-year-old girl is size of toddler',
-                'upload_date': '20110503',
+                #'timestamp': 1304411491,
-                'description': "Congressman discusses the president's executive action",
+                'description': "Congressman discusses president's plan",
-                'upload_date': '20141204',
+                #'timestamp': 1417662047,
-        }
+        info = self._extract_feed_info('http://%s/v/feed/video/%s.js?template=fox' % (host, video_id))
-            'description': 'md5:fe2743efedb49d279552926d0bd0cd9e',
+            'description': 'md5:2fbc01f90b87e8e9137296f37b461c12',
-            r'"description":"([^"]+)', webpage, 'video_description', default=None)
+            r'<script[^>]*>\s*.+?\[media_id=%s\].+?"description"\s*:\s*"([^"]+)' % video_id,
-            video_description = None
+        video_description = self._html_search_regex(
-        video_title = self._html_search_regex(r'<h1[^>]*>(.+?)</h1>', webpage, 'video_title', flags=re.DOTALL)
+        video_title = self._html_search_regex(
-            r'{\s*file\s*:\s*"([^"]+)"\s*}', webpage, 'video url')
+        video_host = self._html_search_regex(
-                r'videoid\s*:\s*"([\d+a-z]{7,})"', webpage, 'videoid')
+                r'videoid\s*:\s*"([\d+a-z]{7,})"', webpage, 'videoid', default=None)
-                webpage, 'player URL')
+            for iframe in re.findall(r'(?s)<iframe(.+?)></iframe>', webpage):
-        http_headers = {'Referer': 'http://www.miomio.tv%s' % mioplayer_path,}
+        http_headers = {'Referer': 'http://www.miomio.tv%s' % mioplayer_path}
-                    videos.append(video_id)
+                if video.get('ID'):
-        page = self._download_webpage(
+        video = self._download_json(
-        if 'Status' in video_json:
+        if 'Status' in video:
-                'lynda returned error: %s' % video_json['Message'], expected=True)
+                'lynda returned error: %s' % video['Message'], expected=True)
-        if video_json['HasAccess'] is False:
+        if video.get('HasAccess') is False:
-        title = video_json['Title']
+        video_id = compat_str(video.get('ID') or video_id)
-        fmts = video_json.get('Formats')
+        fmts = video.get('Formats')
-        prioritized_streams = video_json.get('PrioritizedStreams')
+            formats.extend([{
-                ])
+                formats.extend([{
-        subtitles = self.extract_subtitles(video_id, page)
+        subtitles = self.extract_subtitles(video_id)
-    def _get_subtitles(self, video_id, webpage):
+    def _get_subtitles(self, video_id):
-        page = self._download_webpage(
+        course = self._download_json(
-        if 'Status' in course_json and course_json['Status'] == 'NotFound':
+        if course.get('Status') == 'NotFound':
-                if video['HasAccess'] is False:
+        for chapter in course['Chapters']:
-                videos.append(video['ID'])
+                video_id = video.get('ID')
-        course_title = course_json['Title']
+        course_title = course.get('Title')
-            self._downloader.to_screen('[' + self.basename + '] Destination: ' + new_path)
+            self._downloader.to_screen('[ffmpeg] Destination: ' + new_path)
-    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)+(?P<id>[\da-z]+)-(?:player|externalPlayer)_[^/]+\.html'
+    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)*(?P<id>[\da-z]+)-(?:player|externalPlayer)_[^/]+\.html'
-    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)+(?P<id>[\da-z]+)-(?:player|externalPlayer)\.html'
+    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)*(?P<id>[\da-z]+)-(?:player|externalPlayer)\.html'
-    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)+(?:(?P<display_id>[^/?#]+),)?(?P<id>[\da-z]+)\.html'
+    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)*(?:(?P<display_id>[^/?#]+),)?(?P<id>[\da-z]+)\.html'
-    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)+(?P<id>[^/?#]+),[\da-z]+\.html'
+    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)*(?P<id>[^/?#]+),[\da-z]+\.html'
-        for vid in vdata['files'].values():
+        for (fkey, vid) in vdata['files'].items():
-            headers={'Referer': 'http://www.miomio.tv/mioplayer/mioplayer-v3.0.swf'})
+            headers=http_headers)
-
+from ..compat import compat_urllib_request
-        vid_config = self._download_xml(
+        vid_config_request = compat_urllib_request.Request(
-            video_id)
+            headers={'Referer': 'http://www.miomio.tv/mioplayer/mioplayer-v3.0.swf'})
-            outtmpl = sanitize_path(self.params.get('outtmpl', DEFAULT_OUTTMPL))
+            outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)
-            return filename
+            return sanitize_path(filename)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    def _call_api(self, method, token):
+    def _call_api(self, method, value):
-            'https://api.periscope.tv/api/v2/%s?token=%s' % (method, token), token)
+            'https://api.periscope.tv/api/v2/%s?%s=%s' % (method, attribute, value), value)
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|the-voice-of-germany)\.(?:de|at)|ran\.de|fem\.com)/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|the-voice-of-germany)\.(?:de|at|ch)|ran\.de|fem\.com)/(?P<id>.+)'
-            info_page, 'view count', fatal=False))
+        view_count = None
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'uploader_id': 196,
+            'uploader_id': '196',
-            'uploader_id': 265,
+            'uploader_id': '265',
-            'uploader_id': 196,
+            'uploader_id': '196',
-        uploader_id = video.get('channel_id')
+        uploader_id = str_or_none(video.get('channel_id'))
-        }
+        },
-        'md5': 'c1defca721ce25b2354e927d3e4b3dec',
+        'url': 'http://globoplay.globo.com/v/4581987/',
-            'id': '3928201',
+            'id': '4581987',
-        }
+            'title': 'Acidentes de trÃ¢nsito estÃ£o entre as maiores causas de queda de energia em SP',
-                    'height': resource.get('height'),
+                    'format_id': 'http-%s' % resource_id,
-                    signed_url, resource_id, 'mp4', m3u8_id='hls', fatal=False)
+                    signed_url, resource_id, 'mp4', entry_protocol='m3u8_native',
-            if not resource_id:
+            if not resource_id or resource_id.endswith('manifest'):
-                formats.extend(self._extract_m3u8_formats(signed_url, resource_id, 'mp4'))
+                m3u8_formats = self._extract_m3u8_formats(
-from .globo import GloboIE
+from .globo import (
-    _VALID_URL = 'https?://.+?\.globo\.com/(?P<id>.+)'
+    _VALID_URL = '(?:globo:|https?://.+?\.globo\.com/(?:[^/]+/)*(?:v/(?:[^/]+/)?|videos/))(?P<id>\d{7,})'
-    ]
+    _TESTS = [{
-    class MD5():
+    class MD5:
-
+
-            'title': json_data.get('title'),
+            'id': video_id or display_id,
-        js = self._parse_json(self._search_regex(
+        json_data = self._parse_json(self._search_regex(
-        if 'caption_file' in js:
+        if 'caption_file' in json_data:
-                'url': compat_urlparse.urljoin(url, js['caption_file']),
+                'url': compat_urlparse.urljoin(url, json_data['caption_file']),
-        for subtitle_item in js.get('captions', []):
+        for subtitle_item in json_data.get('captions', []):
-            media_url = js.get(key, '')
+            media_url = json_data.get(key, '')
-            'title': js.get('title'),
+            'title': json_data.get('title'),
-        post = urlencode_postdata(fields)
+        post = urlencode_postdata(encode_dict(fields))
-        data = urlencode_postdata({
+        data = urlencode_postdata(encode_dict({
-        })
+        }))
-        data = compat_urllib_parse.urlencode({'password': password})
+        data = urlencode_postdata(encode_dict({'password': password}))
-        data = urlencode_postdata({
+        data = urlencode_postdata(encode_dict({
-        })
+        }))
-    _VALID_URL = r'https?://(?:www\.)?democracynow.org/?(?P<id>[^\?]*)'
+    _VALID_URL = r'https?://(?:www\.)?democracynow.org/(?P<id>[^\?]*)'
-            'upload_date': None,
+            'description': 'A daily independent global news hour with Amy Goodman & Juan GonzÃ¡lez "What to the Slave is 4th of July?": James Earl Jones Reads Frederick Douglass\u2019 Historic Speech : "This Flag Comes Down Today": Bree Newsome Scales SC Capitol Flagpole, Takes Down Confederate Flag : "We Shall Overcome": Remembering Folk Icon, Activist Pete Seeger in His Own Words & Songs',
-        js = self._parse_json(jstr, display_id)
+        js = self._parse_json(self._search_regex(
-            }]
+
-            if url == '' or url is None:
+            media_url = js.get(key, '')
-                url = url + 'start=' + str(js.get('start'))
+            media_url = re.sub(r'\?.*', '', compat_urlparse.urljoin(url, media_url))
-                'url': url,
+                'url': media_url,
-        ret = {
+
-__version__ = '2015.11.01'
+__version__ = '2015.11.02'
-    return compat_str(upload_date)
+    if upload_date is not None:
-    find_xpath_attr,
+    parse_iso8601,
-            'description': None,
+            'description': '',
-            r'([0-9]+)', video.find('views').text, 'view count', fatal=False))
+
-            'view_count': view_count,
+            'title': video['title'],
-from ..compat import compat_urllib_parse
+from ..compat import (
-        'md5': '757b0b66cbd7e0a97226d7d3156cb3e9',
+        'md5': '0ff1a13aebb35d9bc14081ff633dd324',
-        path_part if path_part in ['.', '..'] else re.sub('(?:[/<>:"\\|\\\\?\\*]|\.$)', '#', path_part)
+        path_part if path_part in ['.', '..'] else re.sub('(?:[/<>:"\\|\\\\?\\*]|[\s.]$)', '#', path_part)
-__version__ = '2015.10.24'
+__version__ = '2015.11.01'
-        return self._download_json(self._API_BASE_URL + compat_urllib_parse.urlencode(query), video_id, note)
+        data = self._download_json(self._API_BASE_URL + compat_urllib_parse.urlencode(query), video_id, note)
-    def _call_api(self, method, video_id, secret=None):
+    def _call_api(self, method, video_id, api_key, note, secret=None):
-            'api_key': self._API_KEY,
+            'api_key': api_key,
-        return self._download_json(self._API_BASE_URL + compat_urllib_parse.urlencode(query), video_id)
+        return self._download_json(self._API_BASE_URL + compat_urllib_parse.urlencode(query), video_id, note)
-        video_info = self._call_api('photos.getInfo', video_id)['photo']
+        api_key = self._download_json('https://www.flickr.com/hermes_error_beacon.gne', video_id, 'Downloading api key',)['site_key']
-            streams = self._call_api('video.getStreamInfo', video_id, video_info['secret'])['streams']
+            streams = self._call_api('video.getStreamInfo', video_id, api_key, 'Downloading streams info', video_info['secret'])['streams']
-        hds_url = media.get('HDS_SURL').replace('euskalsvod', 'euskalvod')
+        hds_url = media.get('HDS_SURL')
-                '%s?hdcore=3.7.0' % hds_url, video_id, f4m_id='hds', fatal=False)
+                '%s?hdcore=3.7.0' % hds_url.replace('euskalsvod', 'euskalvod'),
-from ..compat import compat_urllib_request
+from ..compat import compat_urllib_parse
-    find_xpath_attr,
+    int_or_none,
-    _VALID_URL = r'https?://(?:www\.|secure\.)?flickr\.com/photos/(?P<uploader_id>[\w\-_@]+)/(?P<id>\d+).*'
+    _VALID_URL = r'https?://(?:www\.|secure\.)?flickr\.com/photos/[\w\-_@]+/(?P<id>\d+)'
-        'md5': '6fdc01adbc89d72fc9c4f15b4a4ba87b',
+        'md5': '164fe3fa6c22e18d448d4d5af2330f31',
-            "title": "Dark Hollow Waterfalls"
+            'ext': 'mpg',
-        webpage = self._download_webpage(req, video_id)
+    _API_BASE_URL = 'https://api.flickr.com/services/rest?'
-        secret = self._search_regex(r'secret"\s*:\s*"(\w+)"', webpage, 'secret')
+    def _call_api(self, method, video_id, secret=None):
-        first_xml = self._download_xml(first_url, video_id, 'Downloading first data webpage')
+    def _real_extract(self, url):
-            'id').text
+        video_info = self._call_api('photos.getInfo', video_id)['photo']
-        second_xml = self._download_xml(second_url, video_id, 'Downloading second data webpage')
+            preference = qualities(['iphone_wifi', '700', 'appletv', 'orig'])
-        self.report_extraction(video_id)
+            formats = []
-        video_url = stream.attrib['APP'] + stream.attrib['FULLPATH']
+            owner = video_info.get('owner', {})
-        }
+            return {
-    unified_strdate,
+    parse_iso8601,
-    _VALID_URL = r'https?://www\.eitb\.tv/(eu/bideoa|es/video)/[^/]+/\d+/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?eitb\.tv/(?:eu/bideoa|es/video)/[^/]+/\d+/(?P<id>\d+)'
-            'duration': 3996760,
+            'description': 'Programa de reportajes de actualidad.',
-        video_data = self._download_json('http://mam.eitb.eus/mam/REST/ServiceMultiweb/Video/MULTIWEBTV/%s/' % video_id, video_id)['web_media'][0]
+
-        for rendition in video_data['RENDITIONS']:
+        for rendition in media['RENDITIONS']:
-                'tbr': int_or_none(rendition.get('ENCODING_RATE')),
+                'tbr': tbr,
-                formats.extend(m3u8_formats)
+        hls_url = media.get('HLS_SURL')
-            'upload_date': unified_strdate(video_data.get('BROADCST_DATE')),
+            'title': media.get('NAME_ES') or media.get('name') or media['NAME_EU'],
-from ..utils import ExtractorError
+from ..compat import compat_urllib_request
-    _VALID_URL = r'https?://www\.eitb\.tv/(eu/bideoa|es/video)/[^/]+/(?P<playlist_id>\d+)/(?P<chapter_id>\d+)'
+    _VALID_URL = r'https?://www\.eitb\.tv/(eu/bideoa|es/video)/[^/]+/\d+/(?P<id>\d+)'
-        'url': 'http://www.eitb.tv/es/video/60-minutos-60-minutos-2013-2014/2677100210001/2743577154001/lasa-y-zabala-30-anos/',
+        'url': 'http://www.eitb.tv/es/video/60-minutos-60-minutos-2013-2014/4104995148001/4090227752001/lasa-y-zabala-30-anos/',
-            'id': '2743577154001',
+            'id': '4090227752001',
-            'uploader': 'Euskal Telebista',
+            'description': '',
-        return self.url_result(bc_url, BrightcoveIE.ie_key())
+        video_id = self._match_id(url)
-        account_id, player_id, embed, video_id = mobj.groups()
+        account_id, player_id, embed, video_id = re.match(self._VALID_URL, url).groups()
-        attributes_dict = {attribute_name: attribute_value for (attribute_name, attribute_value) in attributes}
+        for (attribute_name, attribute_value) in attributes:
-        m3u8_doc, urlh = self._download_webpage_handle(
+        res = self._download_webpage_handle(
-            return m3u8_doc
+        if res is False:
-                    url_formats.append(f)
+                    url_formats = [f]
-                    formats.extend(url_formats)
+                formats.extend(url_formats)
-        return cls.__name__[:-2]
+        return compat_str(cls.__name__[:-2])
-        return type(self).__name__[:-2]
+        return compat_str(type(self).__name__[:-2])
-    return upload_date
+    return compat_str(upload_date)
-    },  {
+    }, {
-                 xpath_text(doc, './broadcast/broadcastName', 'title'))
+        title = xpath_text(doc, ['./title', './broadcast/broadcastName'], 'title', fatal=True)
-            xpath_text(doc, './broadcast/broadcastStartDate', 'timestamp', default=None))
+            xpath_text(
-        xpath = xpath.encode('ascii')
+    def _find_xpath(xpath):
-    n = node.find(xpath)
+    },  {
-        }
+# coding: utf-8
-
+from ..compat import compat_urlparse
-    _VALID_URL = r'^(?P<domain>https?://(?:www\.)?mdr\.de)/(?:.*)/(?P<type>video|audio)(?P<video_id>[^/_]+)(?:_|\.html)'
+    IE_DESC = 'MDR.DE and KiKA'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        domain = m.group('domain')
+        video_id = self._match_id(url)
-        html = self._download_webpage(url, video_id)
+        data_url = self._search_regex(
-            r'dataURL:\'(/(?:.+)/(?:video|audio)[0-9]+-avCustom.xml)', html, 'XML URL')
+        doc = self._download_xml(
-            formats.append(format)
+        processed_urls = []
-            }
+                'description': None,
-            }
+                'description': 'md5:b69d32d7b2c55cbe86945ab309d39bbd',
-            }
+                'description': None,
-        }
+                'description': 'md5:b69d32d7b2c55cbe86945ab309d39bbd',
-        formats_list.sort(key=lambda x: x['width'] * x['height'])
+        formats = [{
-            'formats': formats_list,
+            'formats': formats,
-            'webpage_url': webpage_url
+            'webpage_url': webpage_url,
-    _VALID_URL = r'https?://(?:www\.)?kika\.de/(?:[a-z-]+/)*(?:video|sendung)(?P<id>\d+).*'
+    _VALID_URL = r'https?://(?:www\.)?kika\.de/(?:[a-z-]+/)*(?:video|(?:einzel)?sendung)(?P<id>\d+).*'
-            'md5': '94fc748cf5d64916571d275a07ffe2d5',
+            'url': 'http://www.kika.de/baumhaus/videos/video19636.html',
-                'id': '9572',
+                'id': '19636',
-                'title': 'Baumhaus vom 29. Oktober 2014',
+                'title': 'Baumhaus vom 30. Oktober 2015',
-            'md5': '94fc748cf5d64916571d275a07ffe2d5',
+            'url': 'http://www.kika.de/baumhaus/sendungen/video19636_zc-fea7f8a0_zs-4bf89c60.html',
-                'id': '9572',
+                'id': '19636',
-                'title': 'Baumhaus vom 29. Oktober 2014',
+                'title': 'Baumhaus vom 30. Oktober 2015',
-            'url': 'http://www.kika.de/sendungen/einzelsendungen/weihnachtsprogramm/videos/sendung81244_zc-81d703f8_zs-f82d5e31.html',
+            'url': 'http://www.kika.de/sendungen/einzelsendungen/weihnachtsprogramm/einzelsendung2534.html',
-        return self.playlist_result(entries, season_id, title)
+        if not season_id:
-        description = re_desc.group(2) if re_desc else ''
+        description = self._og_search_description(webpage)
-        jstr = self._search_regex(r'({.+?"related_video_xml".+?})', webpage, 'json', default=None)
+        jstr = self._search_regex(r'<script[^>]+type="text/json"[^>]*>\s*({[^>]+})', webpage, 'json')
-        for key in ('file', 'audio'):
+        for key in ('file', 'audio', 'video'):
-            format_dict['resolution'] = '%dx%d' % (width, height)
+            format_dict['width'] = int(elem.find('frameWidth').text)
-            formats_list.append((width * height, format_dict))
+            formats_list.append(format_dict)
-        out_list = [x[1] for x in formats_list]
+        formats_list.sort(key=lambda x: x['width'] * x['height'])
-            'formats': out_list,
+            'formats': formats_list,
-from .daum import DaumIE
+from .daum import (
-)
+from ..compat import compat_urllib_parse
-    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/(?:v/|.*?clipid=)(?P<id>[^?#&]+)'
+    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/v/(?P<id>[^?#&]+)'
-        'url': 'http://tvpot.daum.net/clip/ClipView.do?clipid=52554690',
+        'url': 'http://tvpot.daum.net/v/vab4dyeDBysyBssyukBUjBz',
-            'id': '52554690',
+            'id': 'vab4dyeDBysyBssyukBUjBz',
-            'duration': 3868,
+            'title': 'ë§í¬ íí¸ vs ìí ëì¤ ì¤ë°',
-        query = compat_urllib_parse.urlencode({'vid': full_id})
+        video_id = self._match_id(url)
-            'http://videofarm.daum.net/controller/api/open/v1_2/MovieData.apixml?' + query,
+        movie_data = self._download_json(
-            profile = format_el.attrib['profile']
+        for format_el in movie_data['output_list']['output_list']:
-                'vid': full_id,
+                'vid': video_id,
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': info.find('THUMB_URL').text,
-            'duration': int(info.find('DURATION').text),
+            'duration': int_or_none(info.find('DURATION').text),
-    remove_end,
+    unified_strdate,
-            'timestamp': 1370938118,
+            'description': 'Video zu FIFA 14: E3 2013 Trailer',
-        webpage = self._download_webpage(url, video_id)
+        video_info = self._download_json('http://www.clipfish.de/devapi/id/%s?format=json&apikey=hbbtv' % video_id, video_id)['items'][0]
-        timestamp = parse_iso8601(self._html_search_meta('uploadDate', webpage, 'upload date'))
+        formats = [{
-            'title': title,
+            'title': video_info['title'],
-            'timestamp': timestamp,
+            'thumbnail': video_info.get('media_content_thumbnail_large') or video_info.get('media_thumbnail'),
-            r'http://www\.anitube\.se/embed/([A-Za-z0-9_-]*)', webpage, 'key')
+        key = self._search_regex(
-            'description': 'md5:395a419e41215e531c857bb037bbaf80',
+            'title': 'ä¸­åå°å½å®¶ TVçå½è¯­',
-        'playlist_mincount': 3,
+        'playlist_mincount': 12,
-        category = category2 = mobj.group('type')
+        category, playlist_id = re.match(self._VALID_URL, url).groups()
-            category2 = 'tvshow'
+            category = 'tvshow'
-        webpage = self._download_webpage(url, playlist_id)
+        playlist_detail = self._call_api('xqinfo', category, playlist_id)
-            playlist_id, 'playlist description')
+        playlist_title = playlist_detail['title']
-            playlist_id, 'Get playlist links')
+        episodes_detail = self._call_api('xqsingle', category, playlist_id)
-        for episode in api_result[0]['episodes']:
+        for episode in episodes_detail['videos']:
-                real_url, video_title=episode['single_title']))
+                episode['url'], video_title=episode['title']))
-    IE_DESC = 'VGTV, BTTV, FTV, Aftenposten, Aftonbladet'
+    IE_DESC = 'VGTV, BTTV, FTV, Aftenposten and Aftonbladet'
-                        http://(?:www\.)?
+                    http://(?:www\.)?
-                    (?P<host>vgtv.no|(?:bt.no|aftenbladet.no)/tv|fvn.no/fvntv|aftenposten.no/webtv)
+                    /
-                        /embed?id=
+                        \#!/(?:video|live)/|
-        return self.url_result('vgtv:bt:%s' % video_id, 'VGTV')
+        return self.url_result('http://bt.no/tv/embed?id=%s' % video_id, 'VGTV')
-    IE_DESC = 'VGTV and BTTV'
+    IE_DESC = 'VGTV, BTTV, FTV, Aftenposten, Aftonbladet'
-                    (?P<host>vgtv|bt)
+                    (?P<host>vgtv.no|(?:bt.no|aftenbladet.no)/tv|fvn.no/fvntv|aftenposten.no/webtv)
-                        \.no/(?:tv/)?\#!/(?:video|live)/
+                        /\#!/(?:video|live)/|
-            # streamType: live
+            # streamType: wasLive
-                'title': 're:^DIREKTE: V75 fra Solvalla [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
+                'ext': 'mp4',
-                'duration': 0,
+                'duration': 25966,
-            % (host, video_id, HOST_WEBSITES[host]),
+            % (self._HOST_WEBSITES[host]['vendor'], video_id, self._HOST_WEBSITES[host]['appname']),
-            'title': self._live_title(data['title']),
+            'title': self._live_title(data['title']) if stream_type == 'live' else data['title'],
-            video_id)
+        video_data = self._download_json(url + '?format=json', video_id)
-        } for source in player_params['sources']]
+            'width': int_or_none(source.get('width')),
-            for source in player_params['sources']]))
+            for source in video_data['sources']]))
-        for translation in player_params.get('translations', []):
+        for translation in video_data.get('translations', []):
-            'description': self._og_search_description(webpage),
+            'title': video_data['title'],
-    _VALID_URL = r'https?://tv\.adobe\.com/watch/[^/]+/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://tv\.adobe\.com/(?:(?P<language>fr|de|es|jp)/)?watch/(?P<show_urlname>[^/]+)/(?P<id>[^/]+)'
-            'id': 'quick-tip-how-to-draw-a-circle-around-an-object-in-photoshop',
+            'id': '10981',
-        thumbnail = self._og_search_thumbnail(webpage)
+        language, show_urlname, urlname = re.match(self._VALID_URL, url).groups()
-            webpage, 'view count'))
+        video_data = self._download_json(
-        } for source in player['sources']]
+            'url': source['url'],
-            'view_count': view_count,
+            'id': str(video_data['id']),
-    _VALID_URL = r'https?://(?:www\.)?(?:allmyvideos|vidspot)\.net/(?P<id>[a-zA-Z0-9_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:allmyvideos|vidspot)\.net/(?:(?:2|v)/v-)?(?P<id>[a-zA-Z0-9_-]+)'
-        data = dict(fields)
+        builtin_url = self._search_regex(
-            req, video_id, note='Downloading video page ...')
+        if builtin_url:
-        title = os.path.splitext(data['fname'])[0]
+            title = os.path.splitext(data['fname'])[0]
-    # objects
+    # python 2.x tries to encode unicode strings with ascii (see the
-
+from ..utils import (
-    _TESTS = [{
+    _TEST = {
-    }]
+    }
-        title = metadata['Title']
+        metadata = self._download_json(
-            }]
+        title = metadata['Title']
-            'duration': duration
+            'duration': duration,
-            r'(\.[0-9]+)?(?:Z$| ?(?P<sign>\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$)',
+            r'(?:Z$| ?(?P<sign>\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$)',
-    return calendar.timegm(dt.timetuple())
+    try:
-        } for subtitle in info.get('subtitles', []) if subtitle.get('url')]
+            'url': subformat['url'],
-            r'data-diffusion=["\'](\d+)', webpage, 'video id')
+                r'data-diffusion=["\'](\d+)', webpage, 'video id')
-    _VALID_URL = r'https?://(?:m\.)?pluzz\.francetv\.fr/videos/(.*?)\.html'
+    _VALID_URL = r'https?://(?:m\.)?pluzz\.francetv\.fr/videos/(?P<id>.+?)\.html'
-            r'data-diffusion="(\d+)"', webpage, 'ID')
+        display_id = self._match_id(url)
-    _VALID_URL = r'https?://pluzz\.francetv\.fr/videos/(.*?)\.html'
+    _VALID_URL = r'https?://(?:m\.)?pluzz\.francetv\.fr/videos/(.*?)\.html'
-        xml = '<el foo="bar" spam="ä¸­æ"></el>'
+        xml = '''
-    # on python 2.x the the attributes of a node aren't always unicode objects
+    # on python 2.x the attributes and text of a node aren't always unicode
-        return _XML(text, parser=etree.XMLParser(target=etree.TreeBuilder(element_factory=_element_factory)))
+        doc = _XML(text, parser=etree.XMLParser(target=etree.TreeBuilder(element_factory=_element_factory)))
-    parse_xml,
+from ..compat import compat_etree_fromstring
-            doc = parse_xml(webpage)
+            doc = compat_etree_fromstring(webpage.encode('utf-8'))
-            doc = parse_xml(webpage)
+            doc = compat_etree_fromstring(webpage.encode('utf-8'))
-
+            'subtitles': {
-                })
+        subtitles_list = [{
-        xml = '<el foo="bar"></el>'
+        xml = '<el foo="bar" spam="ä¸­æ"></el>'
-    # unicode
+    # on python 2.x the the attributes of a node aren't always unicode objects
-            el.set(k, v.decode('utf-8'))
+            if isinstance(v, bytes):
-        doc = xml.etree.ElementTree.fromstring(testxml)
+        doc = compat_etree_fromstring(testxml)
-        doc = xml.etree.ElementTree.fromstring(testxml)
+        doc = compat_etree_fromstring(testxml)
-        doc = xml.etree.ElementTree.fromstring(testxml)
+        doc = compat_etree_fromstring(testxml)
-        doc = xml.etree.ElementTree.fromstring(testxml)
+        doc = compat_etree_fromstring(testxml)
-import xml.etree.ElementTree as etree
+    compat_etree_fromstring,
-        doc = etree.fromstring(manifest)
+        doc = compat_etree_fromstring(manifest)
-from ..compat import compat_HTTPError
+from ..compat import (
-                media_selection = xml.etree.ElementTree.fromstring(ee.cause.read().decode('utf-8'))
+                media_selection = compat_etree_fromstring(ee.cause.read().decode('utf-8'))
-import xml.etree.ElementTree as ET
+from ..compat import (
-        lq_doc = ET.fromstring(lq_page)
+        lq_doc = compat_etree_fromstring(lq_page)
-import xml.etree.ElementTree
+    compat_etree_fromstring,
-            object_doc = xml.etree.ElementTree.fromstring(object_str.encode('utf-8'))
+            object_doc = compat_etree_fromstring(object_str.encode('utf-8'))
-import xml.etree.ElementTree
+    compat_etree_fromstring,
-        return xml.etree.ElementTree.fromstring(xml_string.encode('utf-8'))
+        return compat_etree_fromstring(xml_string.encode('utf-8'))
-import xml.etree.ElementTree
+    compat_etree_fromstring,
-        sub_root = xml.etree.ElementTree.fromstring(subtitle)
+        sub_root = compat_etree_fromstring(subtitle)
-import xml.etree.ElementTree
+    compat_etree_fromstring,
-        renditions = xml.etree.ElementTree.fromstring(last_version['data'])
+        renditions = compat_etree_fromstring(last_version['data'])
-        smil_doc = xml.etree.ElementTree.fromstring(smil_xml.encode('utf-8'))
+        smil_doc = compat_etree_fromstring(smil_xml.encode('utf-8'))
-    dfxp = xml.etree.ElementTree.fromstring(dfxp_data.encode('utf-8'))
+    dfxp = compat_etree_fromstring(dfxp_data.encode('utf-8'))
-        } for episode_key in ('origEpisodeURL', 'episodeURL') if episode.get(episode_key)]
+        } for episode_key in ('episodeURL',) if episode.get(episode_key)]
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-            r'<div[^>]+class=["\']videoInfoBy["\'][^>]*>\s*By:\s*</div>\s*<a[^>]+href="[^"]*">([^<]+)</a>',
+        uploader = self._html_search_regex(
-            webpage, 'description', fatal=False)
+            webpage, 'description', default=None)
-)
+from ..compat import compat_urllib_request
-    ExtractorError,
+    int_or_none,
-)
+from ..aes import aes_decrypt_text
-    _VALID_URL = r'^(?P<proto>https?://)(?:www\.)?(?P<url>youporn\.com/watch/(?P<videoid>[0-9]+)/(?P<title>[^/]+))'
+    _VALID_URL = r'https?://(?:www\.)?youporn\.com/watch/(?P<id>\d+)/(?P<display_id>[^/?#&]+)'
-            'description': 'Watch Sex Ed: Is It Safe To Masturbate Daily? at YouPorn.com - YouPorn is the biggest free porn tube site on the net!',
+            'description': 'Love & Sex Answers: http://bit.ly/DanAndJenn -- Is It Unhealthy To Masturbate Daily?',
-            'date': '20101221',
+            'upload_date': '20101221',
-        url = mobj.group('proto') + 'www.' + mobj.group('url')
+        video_id = mobj.group('id')
-        age_limit = self._rta_search(webpage)
+        request = compat_urllib_request.Request(url)
-            if link not in links:
+        links = []
-            formats.append({
+        for video_url in set(unescapeHTML(link) for link in links):
-
+            }
-            raise ExtractorError('ERROR: no known formats available for video')
+        description = self._html_search_regex(
-            'date': video_date,
+            'display_id': display_id,
-            'uploader': 'Ask Dan And Jennifer',
+            'description': 'Watch Sex Ed: Is It Safe To Masturbate Daily? at YouPorn.com - YouPorn is the biggest free porn tube site on the net!',
-            raise ExtractorError('Missing JSON parameter: ' + sys.exc_info()[1])
+        video_title = self._html_search_regex(r'page_params.video_title = \'(.+?)\';', webpage, 'video URL', fatal=False)
-        LINK_RE = r'<a href="([^"]+)">'
+        DOWNLOAD_LIST_RE = r'(?s)sources: {\n(?P<download_list>.*?)}'
-        encrypted_links = re.findall(r'var encryptedQuality[0-9]{3}URL = \'([a-zA-Z0-9+/]+={0,2})\';', webpage)
+        encrypted_links = re.findall(r'page_params.encryptedQuality[0-9]{3,4}URL\s=\s\'([a-zA-Z0-9+/]+={0,2})\';', webpage)
-            links.append(link)
+            # it's unclear if encryted links still differ from normal ones, so only include in links array if it's unique
-            # http://cdn1.download.youporn.phncdn.com/201210/31/8004515/480p_370k_8004515/YouPorn%20-%20Nubile%20Films%20The%20Pillow%20Fight.mp4?nvb=20121113051249&nva=20121114051249&ir=1200&sr=1200&hash=014b882080310e95fb6a0
+            # http://cdn2b.public.youporn.phncdn.com/201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=200&ri=2500&s=1445599900&e=1445773500&h=5345d19ce9944ec52eb167abf24af248
-            # /201210/31/8004515/480p_370k_8004515/YouPorn%20-%20Nubile%20Films%20The%20Pillow%20Fight.mp4
+            # 201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4
-            'thumbnail': thumbnail,
+            'thumbnail': video_thumbnail,
-        display_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)+(?P<id>[^/?#]+),[\da-z]+\.html'
+    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)+(?:(?P<display_id>[^/?#]+),)?(?P<id>[\da-z]+)\.html'
-                            media_url, video_id, 'mp4', m3u8_id='hls'))
+                    ext = determine_ext(media_url)
-            hdcore_sign = '?hdcore=3.1.0'
+            hdcore_sign = 'hdcore=3.1.0'
-            f4m_url = '%s/z/%s_1@%s/manifest.f4m' % url_params + hdcore_sign
+            f4m_url = '%s/z/%s_1@%s/manifest.f4m?' % url_params + hdcore_sign
-            url_parsed = base_url_parsed._replace(path=base_url_parsed.path + name)
+            query = []
-                url_parsed = url_parsed._replace(query=url_parsed.query + akamai_pv.strip(';'))
+                query.append(akamai_pv.strip(';'))
-                url_parsed = url_parsed._replace(query=url_parsed.query + info_dict.get('extra_param_to_segment_url'))
+                query.append(info_dict['extra_param_to_segment_url'])
-        manifest = self.ydl.urlopen(man_url).read()
+        urlh = self.ydl.urlopen(man_url)
-            url = base_url + name
+            url_parsed = base_url_parsed._replace(path=base_url_parsed.path + name)
-                url += '?' + akamai_pv.strip(';')
+                url_parsed = url_parsed._replace(query=url_parsed.query + akamai_pv.strip(';'))
-                url += info_dict.get('extra_param_to_segment_url')
+                url_parsed = url_parsed._replace(query=url_parsed.query + info_dict.get('extra_param_to_segment_url'))
-                success = ctx['dl'].download(frag_filename, {'url': url})
+                success = ctx['dl'].download(frag_filename, {'url': url_parsed.geturl()})
-        m3u8_doc = self._download_webpage(
+        m3u8_doc, urlh = self._download_webpage_handle(
-        'md5': '627c7c124ac2a9b5ab6addb94e0e65f7',
+        'md5': '0cd9e28ad270488911b0d2a72323395d',
-            'ext': 'flv',
+            'ext': 'mp4',
-    _VALID_URL = r'http://www\.abc\.net\.au/news/[^/]+/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'http://www\.abc\.net\.au/news/(?:[^/]+/){1,2}(?P<id>\d+)'
-            r'inline(?P<type>Video|YouTube)Data\.push\((?P<json_data>[^)]+)\);',
+            r'inline(?P<type>Video|Audio|YouTube)Data\.push\((?P<json_data>[^)]+)\);',
-                        'Accept-Encoding': 'deflate', # gzip causes trouble on the server side
+                        'Accept-Encoding': 'deflate',  # gzip causes trouble on the server side
-    compat_HTTPError,
+        self._check_formats(formats, video_id)
-            if isinstance(e.cause, compat_HTTPError):
+            if isinstance(e.cause, compat_urllib_error.URLError):
-                    formats.extend(m3u8_formats)
+                formats.append({
-        'md5': 'ace7635b2a0b286aaa37d3ff192d2a8a',
+        'md5': '757b0b66cbd7e0a97226d7d3156cb3e9',
-                '%s/?%s' % (gat, compat_urllib_parse.urlencode(encode_dict(token_data)).encode('utf-8')),
+                '%s/?%s' % (gat, compat_urllib_parse.urlencode(encode_dict(token_data))),
-__version__ = '2015.10.23'
+__version__ = '2015.10.24'
-    "dll_excludes": ['w9xpopen.exe'],
+    "dll_excludes": ['w9xpopen.exe', 'crypt32.dll'],
-                    r'data-channel-external-id="([^"]+)"',
+                    r'data-(?:channel-external-|yt)id="([^"]+)"',
-            'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
+            'id': 'UUKfVa3S1e4PHvxWcwyMMg8w',
-            params.setdefault('extract_flat', True)
+            params.setdefault('extract_flat', 'in_playlist')
-__version__ = '2015.10.18'
+__version__ = '2015.10.23'
-        for sub_id, sub_name in re.findall(r'\?ssid=([0-9]+)" title="([^"]+)', webpage):
+        for sub_id, sub_name in re.findall(r'\bssid=([0-9]+)"[^>]+?\btitle="([^"]+)', webpage):
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:(?:(?:programmes|iplayer(?:/[^/]+)?/(?:episode|playlist))/)|music/clips[/#])(?P<id>[\da-z]{8})'
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:(?:programmes/(?!articles/)|iplayer(?:/[^/]+)?/(?:episode/|playlist/))|music/clips[/#])(?P<id>[\da-z]{8})'
-        return False if BBCCoUkIE.suitable(url) else super(BBCIE, cls).suitable(url)
+        return False if BBCCoUkIE.suitable(url) or BBCCoUkArticleIE.suitable(url) else super(BBCIE, cls).suitable(url)
-        enc_key = '97596c0abee04ab49ba25564161ad225'
+        # last update at 2015-10-22 for Zombie::bite
-                        media_url, segment_title, 'mp4', 'm3u8_native', preference=0, m3u8_id='hls'))
+                        media_url, segment_title, 'mp4', preference=0, m3u8_id='hls'))
-                })
+        for format_id, f in params['video_data'].items():
-                r'window\.POST_DATA = { %s: ({.+?}) };\s*</script>' % video_id,
+            self._search_regex(
-                formats.append({'url': backup_url.find('./url').text})
+        for durl in doc.findall('./durl'):
-            formats.append({
+            formats = [{
-            })
+            }]
-# coding: utf-8
+
-from ..utils import int_or_none
+from ..utils import (
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?stitcher\.com/podcast/(?:[^/]+/)+e/(?:(?P<display_id>[^/#?&]+?)-)?(?P<id>\d+)(?:[/#?&]|$)'
-    }
+            'title': 'Machine Learning Mastery and Cancer Clusters',
-        audio_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        webpage = self._download_webpage(url, audio_id)
+        webpage = self._download_webpage(url, display_id)
-        duration = int_or_none(self._search_regex(r'duration: (\d+?),', webpage, 'duration', fatal=False))
+        episode = self._parse_json(
-            'url': url,
+            'display_id': display_id,
-            'vcodec': 'none',
+            'thumbnail': thumbnail,
-        if v.startswith("'"):
+            v = re.sub(r"\\'", "'", v[1:-1])
-                'description': 'This is "youtube-dl password protected test video" by Jaime MarquÃ­nez FerrÃ¡ndiz on Vimeo, the home for high quality videos and the people who love them.',
+                'description': 'This is "youtube-dl password protected test video" by Jaime MarquÃ­nez FerrÃ¡ndiz on Vimeo, the home for high quality videos and the people\u2026',
-        'md5': 'c62f1156138dc3323902188c5b5a8bd6',
+        'md5': 'f42d05e7149aeaec5c037b17e5d3dc82',
-            'title': 'e5g',
+            'title': 'Video upload (e5g)',
-            'title': title or video_id,
+            'title': title or 'Video upload (%s)' % video_id,
-            r'vimeo\.config\s*=\s*({.+?});', webpage,
+            r'vimeo\.config\s*=\s*(?:({.+?})|_extend\([^,]+,\s+({.+?})\));', webpage,
-                    '%s returned error: %s' % (self.IE_NAME, seed_status['title']),
+                    '%s said: %s' % (self.IE_NAME, seed_status['title']),
-
+    def get_text_attr(self, d, attr):
-            raise ExtractorError('%s said: %s' % (self.IE_NAME, get_text_attr(data, 'error')), expected=True)
+            raise ExtractorError('%s said: %s' % (self.IE_NAME, self.get_text_attr(data, 'error')), expected=True)
-        capfile = get_text_attr(data, 'capfile')
+        capfile = self.get_text_attr(data, 'capfile')
-                    'tbr': int_or_none(get_text_attr(quality, 'bitrate')),
+                    'format_id': '%s-%sp' % (self.get_text_attr(quality, 'bitrate'), self.get_text_attr(quality, 'height')),
-                'duration': int_or_none(get_text_attr(f, 'length')),
+                'duration': int_or_none(self.get_text_attr(f, 'length')),
-        if video.get('state') == 'user-disabled':
+        if video.get('state') in ('user-disabled', 'suspended'):
-            'title': title,
+            'title': title or video_id,
-    upload_date = unified_strdate(doc.find('.//details/airtime').text)
+    description = xpath_text(doc, './/information/detail', 'description')
-        vbr = None if vbr_node is None else int(vbr_node.text) // 1000
+        quality = xpath_text(fnode, './quality', 'quality')
-        height = None if height_node is None else int_or_none(height_node.text)
+        width = int_or_none(xpath_text(fnode, './width', 'width'))
-            'filesize': int_or_none(fnode.find('./filesize').text),
+            'filesize': filesize,
-        thumbnails = list()
+        thumbnails = []
-            thumbnail = {'url': node.text}
+            thumbnail_url = node.text
-    thumbnails = xml_to_thumbnails(thumbnail_nodes)
+    thumbnails = xml_to_thumbnails(doc.findall('.//teaserimages/teaserimage'))
-                    thumbnail['height'] = int_or_none(node.attrib['key'].split('x')[1])
+                m = re.match('^([0-9]+)x([0-9]+)$', node.attrib['key'])
-                thumbnail['height'] = int_or_none(width_x_height.split('x')[1])
+                if re.match("^[0-9]+x[0-9]+$", node.attrib['key']):
-            }
+            thumbnail = {'url': node.text}
-    _VALID_URL = r'https?://(?:www\.)?(?:odnoklassniki|ok)\.ru/(?:video|web-api/video/moviePlayer)/(?P<id>[\d-]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:odnoklassniki|ok)\.ru/(?:video(?:embed)?|web-api/video/moviePlayer)/(?P<id>[\d-]+)'
-__version__ = '2015.10.16'
+__version__ = '2015.10.18'
-            'mp4', entry_protocol='m3u8_native')
+            'mp4', entry_protocol='m3u8_native', m3u8_id='hls')
-                formats.extend(self._extract_m3u8_formats(
+                m3u8_formats = self._extract_m3u8_formats(
-                ))
+                    fatal=False)  # m3u8 sometimes fail
-            'title': 'Terrasses du NumÃ©rique'
+            'ext': 'flv',
-            'formats': formats,
+            'duration': duration,
-    _VALID_URL = r'https?://(www\.)?canalc2\.tv/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?canalc2\.tv/video/(?P<id>\d+)'
-            webpage, 'video_url')
+            r'jwplayer\((["\'])Player\1\)\.setup\({[^}]*file\s*:\s*(["\'])(?P<file>.+?)\2',
-            rtmp = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<play_path>mp4:.+)$', video_url)
+            rtmp = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+/))(?P<play_path>mp4:.+)$', video_url)
-    _VALID_URL = r'http://.*?\.canalc2\.tv/video\.asp\?.*?idVideo=(?P<id>\d+)'
+    _VALID_URL = r'https?://(www\.)?canalc2\.tv/video/(?P<id>\d+)'
-        'url': 'http://www.canalc2.tv/video.asp?idVideo=12163&voir=oui',
+        'url': 'http://www.canalc2.tv/video/12163',
-        url = 'http://www.canalc2.tv/video.asp?idVideo=%s&voir=oui' % video_id
+        video_id = self._match_id(url)
-        video_url = 'http://vod-flash.u-strasbg.fr:8080/' + file_name
+        video_url = self._search_regex(
-            r'class="evenement8">(.*?)</a>', webpage, 'title')
+            r'(?s)class="[^"]*col_description[^"]*">.*?<h3>(.*?)</h3>', webpage, 'title')
-            'url': video_url,
+            'formats': formats,
-    compat_urlparse,
+from ..utils import (
-            flags=re.MULTILINE)
+        player_url = 'http://www.imdb.com/video/imdb/vi%s/imdb/single' % video_id
-                'Downloading info for %s format' % f_id)
+        for format_page in format_pages:
-                    'url': encode_data_uri(m3u8_data, 'application/x-mpegURL'),
+                    'url': encode_data_uri(m3u8_data, 'application/vnd.apple.mpegurl'),
-        mobj = re.match(r'â(.*)\s+(http://[^ ]+)â', title)
+        mobj = re.match(r'â(.*)\s+(https?://[^ ]+)â', title)
-                    r'data-player-config="([^"]+)"', webpage, 'data player config')),
+            config = self._parse_json(self._html_search_regex(
-    _VALID_URL = r'https?://(?:www|m|mobile)?\.?twitter\.com/(?P<id>[^/]+/status/\d+)'
+    _VALID_URL = r'https?://(?:www\.|m\.|mobile\.)?twitter\.com/(?P<user_id>[^/]+)/status/(?P<id>\d+)'
-            'title': 'freethenipple - FTN supporters on Hollywood Blvd today!',
+            'title': 'FREE THE NIPPLE - FTN supporters on Hollywood Blvd today!',
-        card_id = self._search_regex(r'["\']/i/cards/tfw/v1/(\d+)', webpage, '/i/card/...')
+        mobj = re.match(self._VALID_URL, url)
-            'uploader': name,
+            'uploader_id': user_id,
-            'description': description,
+            'description': '%s on Twitter: "%s %s"' % (username, title, short_url),
-        description = unescapeHTML(self._search_regex('<title>\s*(.+?)\s*</title>', webpage, 'title'))
+        description = self._html_search_regex('<title>\s*(.+?)\s*</title>', webpage, 'title')
-class TwitterIE(TwitterCardIE):
+class TwitterIE(InfoExtractor):
-    _TESTS = [{
+    _TEST = {
-    }]
+    }
-                    f = {
+                    formats.append({
-                    formats.append(f)
+                    })
-                        r'<MediaFile>\s*<!\[CDATA\[(https?://.+?)\]\]>', webpage, 'data player config (xml)')
+                    vmap_data = self._download_xml(config['vmapUrl'], video_id)
-            'md5': 'a74f50b310c83170319ba16de6955192',
+            'md5': '7d2f6b4d2eb841a7ccc893d479bfceb4',
-        'md5': '8bbccb487bd7a31349b775915fcd412f',
+        'url': 'https://twitter.com/freethenipple/status/643211948184596480',
-            'id': '614301758345490432',
+            'id': '643211948184596480',
-            'title': 'thereaIbanksy - This time lapse is so pretty \U0001f60d\U0001f60d',
+            'title': 'freethenipple - FTN supporters on Hollywood Blvd today!',
-            'uploader_id': 'thereaIbanksy',
+            'duration': 12.922,
-            proxy_handler, https_handler, cookie_processor, ydlh)
+            proxy_handler, https_handler, cookie_processor, ydlh, data_handler)
-        if info_dict['http_headers']:
+        if info_dict['http_headers'] and re.match(r'^https?://', url):
-    compat_urlparse,
+    compat_ord,
-        'md5': 'cab23bd68d5a8db9be31c9a222c1e8df',
+        'md5': 'edadcfe5406976f42f9f266057ee5e40',
-        }
+        },
-        'md5': 'f80936fbe20fb2f58648e81386ff7927',
+        'md5': '2424c74948a62e5f31988438979c5ad1',
-                    'retry': 1
+                media_url += '&' + compat_urllib_parse.urlencode({
-                media_url = compat_urlparse.urlunparse(url_parts)
+
-                    'url': media_url,
+                    'url': encode_data_uri(m3u8_data, 'application/x-mpegURL'),
-from ..utils import unified_strdate
+from ..utils import (
-            'title': u'\u0e22\u0e34\u0e49\u0e21~ \u0e40\u0e02\u0e34\u0e19~ \u0e2d\u0e32\u0e22~ \u0e19\u0e48\u0e32\u0e23\u0e49\u0e32\u0e01\u0e2d\u0e49\u0e30 >//< @n_whitewo @orlameena #lovesicktheseries  #lovesickseason2',
+            'title': 'à¸¢à¸´à¹à¸¡~ à¹à¸à¸´à¸~ à¸­à¸²à¸¢~ à¸à¹à¸²à¸£à¹à¸²à¸à¸­à¹à¸° >//< @n_whitewo @orlameena #lovesicktheseries  #lovesickseason2',
-            'quality': f['rate'],
+            'vcodec': f.get('format'),
-        } for f in data['videoUrls']]
+        } for f in data['videoUrls'] if f.get('videoUrl')]
-            'repost_count': data['reposts']['count'],
+            'title': data.get('description') or self._og_search_title(webpage),
-            'alt_title': 'Vine by Luna',
+            'alt_title': 'Vine by Mars Ruiz',
-            'uploader': 'Luna',
+            'uploader': 'Mars Ruiz',
-            'alt_title': self._og_search_description(webpage, default=None),
+            'title': data['description'],
-        content_re = r'content=(?:"([^>]+?)"|\'([^>]+?)\'|\s*([^\s"\'=<>`]+?))'
+        content_re = r'content=(?:"([^"]+?)"|\'([^\']+?)\'|\s*([^\s"\'=<>`]+?))'
-        webpage = self._download_webpage(webpage_url, video_id, 'Downloading webpage')
+        webpage = self._download_webpage(self._add_skip_wall(webpage_url), video_id, 'Downloading webpage')
-    _VALID_URL = r'https?://(?:(?P<prefix>www|m)\.)?(?P<url>crunchyroll\.com/(?!(?:news|anime-news|library|forum|launchcalendar|lineup|store|comics|freetrial|login))(?P<id>[\w\-]+))/?$'
+    _VALID_URL = r'https?://(?:(?P<prefix>www|m)\.)?(?P<url>crunchyroll\.com/(?!(?:news|anime-news|library|forum|launchcalendar|lineup|store|comics|freetrial|login))(?P<id>[\w\-]+))/?(?:\?|$)'
-        webpage = self._download_webpage(url, show_id)
+        webpage = self._download_webpage(self._add_skip_wall(url), show_id)
-    _VALID_URL = r'http://www\.bilibili\.(?:tv|com)/video/av(?P<id>[0-9]+)/'
+    _VALID_URL = r'http://www\.bilibili\.(?:tv|com)/video/av(?P<id>\d+)(?:/index_(?P<page_num>\d+).html)?'
-        'playlist_count': 12,
+        'playlist_count': 9,
-        title = view_data['title']
+    def _real_extract(self, url):
-            'Downloading page %d/%d' % (page_num, num_pages)
+            'Downloading page %s/%s' % (page_num, view_data['pages'])
-            'id': cid,
+            'id': str(cid),
-            return self._extract_video_info(str(view_data['cid']), view_data)
+    ExtractorError,
-        'md5': '067803f994e049b455a58b16e5aab442',
+        'md5': '94b29a4f131ff03d23471dd6f60b6a1d',
-        'md5': '4eafd1e91a75d2b1e6a3cbd0995816a2',
+        'md5': '8e5fbfabe6ad0f89f3012a7943c1287b',
-        'md5': '446562a736c6bf97118e389433ed88d4',
+        'md5': '2ae5051559169baadba13fc35345ae74',
-            video_id)
+            'http://www.c-span.org/assets/player/ajax-player.php?os=android&html5=%s&id=%s' % (video_type, video_id),
-            capfile = None
+        files = data['files']
-        } for partnum, f in enumerate(files)]
+        entries = []
-            ])
+            for prioritized_stream_id, prioritized_stream in prioritized_streams.items():
-            raise ExtractorError(msg, expected=True)
+            raise ExtractorError(
-class YoutubePlaylistIE(YoutubeBaseInfoExtractor):
+class YoutubePlaylistIE(YoutubeBaseInfoExtractor, YoutubePlaylistBaseInfoExtractor):
-    _VIDEO_RE = r'href="\s*/watch\?v=(?P<id>[0-9A-Za-z_-]{11})&amp;[^"]*?index=(?P<index>\d+)'
+    _VIDEO_RE = r'href="\s*/watch\?v=(?P<id>[0-9A-Za-z_-]{11})&amp;[^"]*?index=(?P<index>\d+)(?:[^>]+>(?P<title>[^<]+))?'
-        return self.playlist_result(_entries(), playlist_id, playlist_title)
+        return self.playlist_result(self._entries(page, playlist_id), playlist_id, playlist_title)
-class YoutubeChannelIE(InfoExtractor):
+class YoutubeChannelIE(YoutubePlaylistBaseInfoExtractor):
-        return self.playlist_result(_entries(), channel_id)
+        return self.playlist_result(self._entries(channel_page, channel_id), channel_id)
-                'ext': 'flv',
+                'formats': formats,
-            raise ExtractorError(msg, expected=True)
+        self._check_error(info)
-                    # New react-based page
+                    # Sometimes new react-based page is served instead of old one that require
-                    config_url = self._parse_json(vimeo_clip_page_config, video_id)['player']['config_url']
+                    config_url = self._parse_json(
-                    r' data-config-url="(.+?)"', webpage, 'config URL')
+                    r' data-config-url="(.+?)"', webpage,
-            'id': '1074402_part1',
+            'id': '1554319',
-            'duration': 308,
+            'duration': 308313,
-        'playlist_count': 9,
+        'playlist_count': 12,
-        entries = []
+    def _extract_video_info(self, cid, view_data, page_num=1, num_pages=1):
-            note='Downloading LQ video info'
+        page = self._download_webpage(
-            err_info = json.loads(lq_page)
+            err_info = json.loads(page)
-        lq_durls = lq_doc.findall('./durl')
+        doc = ET.fromstring(page)
-            self._sort_formats(formats)
+        entries = []
-                'id': '%s_part%d' % (video_id, i),
+                'id': '%s_part%s' % (cid, durl.find('./order').text),
-                'thumbnail': thumbnail,
+                'url': durl.find('./url').text,
-            'title': title
+        info = {
-           'Downloading %s access token' % self._ITEM_TYPE)
+            '%s/api/vods/%s/access_token' % (self._API_BASE, item_id), item_id,
-               compat_urllib_parse.urlencode({
+            '%s/vod/%s?%s' % (
-           item_id, 'mp4')
+            item_id, 'mp4')
-            'Downloading %s access token' % self._ITEM_TYPE)
+           '%s/api/vods/%s/access_token' % (self._API_BASE, item_id), item_id,
-            item_id, 'mp4')
+           '%s/vod/%s?%s' % (
-    _LOGIN_POST_URL = 'https://passport.twitch.tv/authentications/new'
+    _LOGIN_URL = 'http://www.twitch.tv/login'
-        login_page = self._download_webpage(
+        login_page, handle = self._download_webpage_handle(
-            'password': password.encode('utf-8'),
+            'username': username,
-            'post url', default=self._LOGIN_POST_URL, group='url')
+            'post url', default=redirect_url, group='url')
-            post_url = compat_urlparse.urljoin(self._LOGIN_URL, post_url)
+            post_url = compat_urlparse.urljoin(redirect_url, post_url)
-        request.add_header('Referer', self._LOGIN_URL)
+            post_url, compat_urllib_parse.urlencode(encode_dict(login_form)).encode('utf-8'))
-    _VALID_URL = r'http?://(?:www\.)?rte\.ie/player/[^/]{2,3}/show/[^/]+/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?rte\.ie/player/[^/]{2,3}/show/[^/]+/(?P<id>[0-9]+)'
-        'url': 'http://www.rte.ie/player/de/show/10363114/',
+        'url': 'http://www.rte.ie/player/ie/show/iwitness-862/10478715/',
-            'id': '10363114',
+            'id': '10478715',
-            'title': 'One News',
+            'title': 'Watch iWitness  online',
-            'duration': 436.844,
+            'description': 'iWitness : The spirit of Ireland, one voice and one minute at a time.',
-__version__ = '2015.10.13'
+__version__ = '2015.10.16'
-    _VALID_URL = r'http?://(?:www\.)?rte\.ie/player/[^/]{2,3}/show/(?P<id>[0-9]+)/'
+    _VALID_URL = r'http?://(?:www\.)?rte\.ie/player/[^/]{2,3}/show/[^/]+/(?P<id>[0-9]+)'
-                        'abr': int(abr_str),
+                        'abr': int_or_none(abr_str),
-                    'duration': float(data['duration']),
+                    'duration': float_or_none(data.get('duration')),
-                        'url': format_url,
+                        'url': self._proto_relative_url(format_url, 'http:'),
-            description = description_el.text if description_el else None
+            description = description_el.text if description_el is not None else None
-            'description': 'md5:5438d33774b6bdc662f9485a340401cc',
+            'description': 'md5:e07269172baff037f8e8bf9956bc9747',
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': 're:^https?://.*\.jpg$',
-                'description': 'VIDEO: Index/Match versus VLOOKUP.',
+                'description': 'VIDEO: INDEX/MATCH versus VLOOKUP.',
-            return OoyalaIE._build_url_result(mobj.group('ec'))
+            return OoyalaIE._build_url_result(smuggle_url(mobj.group('ec'), {'domain': url}))
-                    embeds, getter=lambda v: OoyalaIE._url_for_embed_code(v['provider_video_id']), ie='Ooyala')
+                    embeds, getter=lambda v: OoyalaIE._url_for_embed_code(smuggle_url(v['provider_video_id'], {'domain': url})), ie='Ooyala')
-        content_tree = self._download_json(player_url, video_id)['content_tree']
+    def _extract(self, content_tree_url, video_id, domain='example.org'):
-                'http://player.ooyala.com/sas/player_api/v1/authorization/embed_code/%s/%s?domain=www.example.org&supportedFormats=%s' % (pcode, embed_code, supported_format),
+                'http://player.ooyala.com/sas/player_api/v1/authorization/embed_code/%s/%s?' % (pcode, embed_code) + compat_urllib_parse.urlencode({'domain': domain, 'supportedFormats': supported_format}),
-                    })
+            if cur_auth_data['authorized']:
-        return self._extract(content_tree_url, embed_code)
+        return self._extract(content_tree_url, embed_code, domain)
-                    formats.extend(self._extract_m3u8_formats(url, embed_code, 'mp4', 'm3u8_native', 0, m3u8_id='hls', fatal=False))
+                    formats.extend(self._extract_m3u8_formats(url, embed_code, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
-                    formats.extend(self._extract_f4m_formats(url, embed_code, f4m_id='hds', fatal=False))
+                    formats.extend(self._extract_f4m_formats(url, embed_code, -1, 'hds', fatal=False))
-                        'format_id': stream.get('profile'),
+                        'format_id': '%s-%s-%sp' % (stream.get('profile'), delivery_type, stream.get('height')),
-        title = self._html_search_meta('name', webpage)
+        title = self._html_search_meta('name', webpage) or self._og_search_title(webpage)
-from .bliptv import BlipTVIE, BlipTVUserIE
+from .jwplatform import JWPlatformIE
-            # blip.tv embedded video
+            # Youtube embedded video
-            'md5': 'ca9b3c8dd5a66f9375daeb5135f5a3de',
+            'md5': 'df4cf8a1dcedaec79a73d96d83b99023',
-                'ext': 'flv',
+                'id': 'OEVzPCY2T-g',
-                'description': 'md5:0a108c78d130676b207d0f6d029ecffd',
+                'uploader': 'Cinemassacre',
-
+# coding: utf-8
-    determine_ext,
+    float_or_none,
-            'thumbnail': more_info['promo'],
+    def _extract(self, player_url, video_id):
-            formats = []
+        formats = []
-                video_id)
+                'http://player.ooyala.com/sas/player_api/v1/authorization/embed_code/%s/%s?domain=www.example.org&supportedFormats=%s' % (pcode, embed_code, supported_format),
-            cur_auth_data = auth_data['authorization_data'][video_id]
+            cur_auth_data = auth_data['authorization_data'][embed_code]
-            return self._extract_result(videos_info[0], videos_more_info)
+                url = base64.b64decode(stream['url']['data'].encode('ascii')).decode('utf-8')
-                'description': '',
+                'duration': 194948,
-                'title': 'Ooyala video',
+                'title': 'Divide Tool Path.mp4',
-        return self._extract(player_url, embed_code)
+        content_tree_url = 'http://player.ooyala.com/player_api/v1/content_tree/embed_code/%s/%s' % (embed_code, embed_code)
-                    (&|$)
+                    (?:&|$)
-            'description': '',
+            'duration': 1302000,
-        return self._extract(player_url, video_id)
+        partner_id, video_id, pcode = re.match(self._VALID_URL, url).groups()
-                'thumbnail': 'http://video.ch9.ms/ch9/9d51/03902f2d-fc97-4d3c-b195-0bfe15a19d51/KOS002_220.jpg',
+                'thumbnail': 're:http://.*\.jpg',
-                'thumbnail': 'http://video.ch9.ms/ch9/87e1/0300391f-a455-4c72-bec3-4422f19287e1/selfservicenuk_512.jpg',
+                'thumbnail': 're:http://.*\.jpg',
-from ..utils import ExtractorError
+from ..utils import (
-        # Extract known formats
+        quality = qualities((
-            'preference': self._known_formats.index(x.group('quality')),
+            'filesize_approx': parse_filesize(x.group('filesize')),
-        } for x in list(re.finditer(FORMAT_REGEX, html)) if x.group('quality') in self._known_formats]
+        } for x in list(re.finditer(FORMAT_REGEX, html))]
-        pass
+        return default
-    return default if v is None else (float(v) * invscale / scale)
+    if v is None:
-    return default if v is None else (int(v) * invscale // scale)
+    if v is None:
-
+        thumbnail = None
-            'thumbnail': a_thumb,
+            'thumbnail': thumbnail,
-        property_re = r'(?:name|property)=[\'"]?og:%s[\'"]?' % re.escape(prop)
+        property_re = (r'(?:name|property)=(?:\'og:%(prop)s\'|"og:%(prop)s"|\s*og:%(prop)s\b)'
-            webpage, 'video description')
+        description = self._html_search_meta('description', webpage)
-        password_request.add_header('Cookie', 'clip_v=1; vuid=%s' % vuid)
+        password_request.add_header('Cookie', 'clip_test2=1; vuid=%s' % vuid)
-    compat_str,
+    compat_parse_qs,
-            raise ExtractorError(msg, expected=True, video_id=video_id)
+            raise ExtractorError(
-            if any(r['ID'] == quality for r in info['Renditions']):
+        parsed_video_url = compat_urllib_parse_urlparse(compat_parse_qs(
-                    'height': height,
+                    'format_id': '%s-%d' % (rendition['RenditionType'], rendition['ID']),
-    _VALID_URL = r'(?:https?://tp\.srgssr\.ch/p(?:/[^/]+)+\?urn=)?urn:(?P<bu>srf|rts|rsi|rtr|swi):(?:[^:]+:)?(?P<type>video|audio):(?P<id>[0-9a-f\-]{36}|\d+)'
+    _VALID_URL = r'(?:https?://tp\.srgssr\.ch/p(?:/[^/]+)+\?urn=urn|srgssr):(?P<bu>srf|rts|rsi|rtr|swi):(?:[^:]+:)?(?P<type>video|audio):(?P<id>[0-9a-f\-]{36}|\d+)'
-            })
+        if 'Image' in media_data:
-            for source in downloads['Download']:
+        if 'Downloads' in media_data:
-        return self.url_result('urn:%s:%s:%s' % (bu[:3], media_type, media_id), 'SRGSSR')
+        return self.url_result('srgssr:%s:%s:%s' % (bu[:3], media_type, media_id), 'SRGSSR')
-        return m.group('day') if m is not None else None
+        return m.group('day').strip() if m is not None else None
-        authors = self._extract_authors(html)
+        if len(contents) > 1:
-        return contents
+        return result
-
+from ..utils import (
-        'md5': '1bff67111adb785c51d1b42959ec10e5',
+        'md5': '46c384def73b33dbc581262e5ee67cef',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'description': 'md5:d22219c09da287c14bed3d6c37ce4bc2',
-            r'(?s)var\s+qualityArr\s*=\s*{\s*(.+?)\s*}', webpage, 'quality formats')
+        video_id = self._match_id(url)
-        } for fmt in re.findall(r"'([^']+)'\s*:\s*'([^']+)'", quality_arr)]
+        video = self._download_json(
-            r'<title>([^<]+)\s*-\s*beeg\.?</title>', webpage, 'title')
+        title = video['title']
-            webpage, 'thumbnail', fatal=False)
+        timestamp = parse_iso8601(video.get('date'), ' ')
-            else categories_str.split(','))
+        tags = [tag.strip() for tag in video['tags'].split(',')] if video.get('tags') else None
-            'categories': categories,
+            'timestamp': timestamp,
-__version__ = '2015.10.12'
+__version__ = '2015.10.13'
-                formats.append(m3u8_formats)
+                formats.extend(m3u8_formats)
-__version__ = '2015.10.09'
+__version__ = '2015.10.12'
-                r'data-video="([^"]+)"', webpage, 'data video')),
+                r'data-media="([^"]+)"', webpage, 'data video')),
-        if filename != '-' and nooverwrites_and_exists or continuedl_and_exists:
+        if filename != '-' and (nooverwrites_and_exists or continuedl_and_exists):
-        continue_dl = info_dict.get('continuedl', True)
+        continue_dl = self.params.get('continuedl', True)
-# encoding: utf-8
+from __future__ import unicode_literals
-    _VALID_URL = r'https?://(?:www\.)?chaturbate\.com/(?P<id>[^/]+)/?$'
+    _VALID_URL = r'https?://(?:[^/]+\.)?chaturbate\.com/(?P<id>[^/?#]+)'
-        m3u8_url = self._search_regex(r"'(https?://.*?\.m3u8)'", webpage, 'playlist')
+        m3u8_url = self._search_regex(
-            'description': self._html_search_meta('description', webpage, 'description'),
+            'thumbnail': 'https://cdn-s.highwebmedia.com/uHK3McUtGCG3SMFcd4ZJsRv8/roomimage/%s.jpg' % video_id,
-            'thumbnail': 'https://cdn-s.highwebmedia.com/uHK3McUtGCG3SMFcd4ZJsRv8/roomimage/%s.jpg' % (video_id,),
+from .chaturbate import ChaturbateIE
-            formats = self._extract_m3u8_formats(m3u8_url, video_id, 'mp4', 'm3u8_native', 0, 'hls', fatal=False)
+            m3u8_formats = self._extract_m3u8_formats(
-                note='Downloading video configuration')
+            'http://client.expotv.com/video/config/%s/%s' % (video_id, player_key),
-                formats.extend(self._extract_m3u8_formats(fcfg['file'], video_id))
+            media_url = fcfg.get('file')
-                    'url': fcfg['file'],
+                    'url': media_url,
-                        'file extension', default=None),
+                        r'filename=.*\.([a-z0-9_A-Z]+)&', media_url,
-            note='Downloading video configuration')
+                'http://client.expotv.com/video/config/%s/%s' % (video_id, player_key),
-        } for fcfg in config['sources']]
+        formats = []
-            'title': 'Das kÃ¶nnen die  neuen iPads ',
+            'title': 'Das kÃ¶nnen die  neuen iPads',
-        video_data = self._download_json(url.split(".bild.html")[0] + ",view=json.bild.html", video_id)
+        video_data = self._download_json(
-            'title': unescapeHTML(video_data['title']),
+            'title': unescapeHTML(video_data['title']).strip(),
-    fix_xml_ampersands,
+    unescapeHTML,
-            'title': 'BILD hat sie getestet',
+            'title': 'Das kÃ¶nnen die  neuen iPads ',
-        duration = int_or_none(doc.attrib.get('duration'), scale=1000)
+        video_data = self._download_json(url.split(".bild.html")[0] + ",view=json.bild.html", video_id)
-            'duration': duration,
+            'title': unescapeHTML(video_data['title']),
-            webpage, 'vuid', group='vuid')
+        token, vuid = self._extract_xsrft_and_vuid(webpage)
-        return self._search_regex(
+    def _extract_xsrft_and_vuid(self, webpage):
-        token = self._extract_xsrft(webpage)
+        token, vuid = self._extract_xsrft_and_vuid(webpage)
-        token = self._extract_xsrft(webpage)
+        token, vuid = self._extract_xsrft_and_vuid(webpage)
-                "duration": 10,
+                'title': "youtube-dl test video - \u2605 \" ' \u5e78 / \\ \u00e4 \u21ad \U0001d550",
-                'description': 'md5:380943ec71b89736ff4bf27183233d09',
+                'description': 'md5:fd69a7b8d8c34a4e1d2ec2e4afd6ec30',
-                    'tbr': file_info.get('bitrate'),
+                    'width': int_or_none(file_info.get('width')),
-            formats = self._extract_m3u8_formats(hls['all'], video_id, 'mp4', 'm3u8_native', 0, 'hls', fatal=False)
+        m3u8_url = config_files.get('hls', {}).get('all')
-            formats = self._extract_m3u8_formats(hls['all'], video_id, m3u8_id='hls')
+            formats = self._extract_m3u8_formats(hls['all'], video_id, 'mp4', 'm3u8_native', 0, 'hls', fatal=False)
-                    raise ExtractorError('Unable to find clips')
+                raise ExtractorError(
-                    return video
+                return video
-                        return collection, video
+                    return collection, video
-            clips = [stream] if stream else video_info['clips']
+            clips = [stream] if stream else video_info.get('clips')
-        }
+        },
-                return video
+                if video.get('auth'):
-                    return collection, video
+                    if video.get('auth'):
-                 r'"datePublished":\s*"([^"]+)',],
+                 r'"datePublished":\s*"([^"]+)'],
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'mp4',
+            'ext': 'flv',
-            'ext': 'mp4',
+            'ext': 'flv',
-            'ext': 'mp4',
+            'ext': 'flv',
-            'upload_date': '20130513',
+            'timestamp': 1415867444,
-            'ext': 'mp4',
+            'ext': 'flv',
-            webpage, 'date', default=None))
+        timestamp = None
-            playlist_description = self._og_search_description(webpage, default=None)
+            playlist_title = playlist_title or remove_end(self._og_search_title(webpage), ' - BBC News')
-        # playlist.sxml, externalId and no direct video links
+        # article with multiple videos embedded with data-playable containing vpids
-        # article with multiple videos embedded with data-media-meta (more videos)
+        # article with multiple videos embedded with data-playable (more videos)
-        # single video embedded with mediaAssetPage.init()
+        # single video embedded with data-playable containing vpid
-        # media items as f4m and m3u8 - currently unsupported)
+        # article with single video embedded with data-playable containing XML playlist
-        # single video embedded with mediaAssetPage.init() (regional section)
+        # single video embedded with data-playable containing XML playlists (regional section)
-        # single video with playlist.sxml URL
+        # single video with playlist.sxml URL in playlist param
-        # article with multiple videos embedded with playlist.sxml
+        # article with multiple videos embedded with playlist.sxml in playlist param
-                'duration': duration,
+        entries = []
-                # http://www.bbc.com/news/world-us-canada-34473351)
+        # news article with multiple videos embedded with data-playable
-                            playlist.get('progressiveDownloadUrl'), playlist_id, timestamp)
+                            formats, subtitles = self._download_media_selector(programme_id)
-                    r'data-playable="({.+?})"', webpage, 'data playable', default='{}')),
+                    r'data-playable=(["\'])(?P<json>{.+?})\1', webpage,
-                    'format_id': supplier,
+                    'format_id': supplier or kind or protocol,
-        return playlist.findall('./{http://bbc.co.uk/2008/emp/playlist}item')
+        return playlist.findall('./{%s}item' % self._EMP_PLAYLIST_NS)
-        error = media_selection.find('./{http://bbc.co.uk/2008/mp/mediaselection}error')
+        error = media_selection.find('./{%s}error' % self._MEDIASELECTION_NS)
-        return media_selection.findall('./{http://bbc.co.uk/2008/mp/mediaselection}media')
+        return self._findall_ns(media_selection, './{%s}media')
-        return media.findall('./{http://bbc.co.uk/2008/mp/mediaselection}connection')
+        return self._findall_ns(media, './{%s}connection')
-                    'format_id': '%s_%s' % (service, format['format_id']),
+                if service:
-        no_items = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}noItems')
+        no_items = playlist.find('./{%s}noItems' % self._EMP_PLAYLIST_NS)
-            description_el = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}summary')
+            title = playlist.find('./{%s}title' % self._EMP_PLAYLIST_NS).text
-                mediator = item.find('./{http://bbc.co.uk/2008/emp/playlist}mediator')
+                mediator = item.find('./{%s}mediator' % self._EMP_PLAYLIST_NS)
-            formats, subtitles = self._download_media_selector(programme_id)
+
-                entry = self._extract_item(item)
+                entry = self._extract_item(item, fatal=False)
-    def _extract_item(self, item):
+    def _extract_item(self, item, fatal=True):
-            'playlist_count': 10,
+    _TESTS = [{
-    ]
+        'playlist_count': 10,
-            'title': 'LÃ¢u ÄÃ i TÃ¬nh Ãi - Báº±ng Kiá»u ft. Minh Tuyáº¿t | Album 320 lossless',
+    _VALID_URL = r'https?://mp3\.zing\.vn/(?:album|playlist)/(?P<slug>[^/]+)/(?P<album_id>\w+)\.html'
-    }]
+        {
-            description = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}summary').text
+            description_el = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}summary')
-                })
+            entries = [
-                    programme_id = items[0].get('vpid')
+                # data-playable has video vpid in settings.playlistObject.items (e.g.
-            playlist_description = self._og_search_description(webpage)
+            playlist_description = self._og_search_description(webpage, default=None)
-            }
+        # article with multiple videos embedded with playlist.sxml (e.g.
-            'enc': self.md5_text((enc_key + tail)[1:64:2] + tail),
+            'enc': self.md5_text(enc_key + tail),
-        enc_key = 'eac64f22daf001da6ba9aa8da4d501508bbe90a4d4091fea3b0582a85b38c2cc'  # last update at 2015-09-23-23 for Zombie::bite
+        # last update at 2015-10-10 for Zombie::bite
-        content_re = r'content=(?:"([^>]+?)"|\'([^>]+?)\')'
+        content_re = r'content=(?:"([^>]+?)"|\'([^>]+?)\'|\s*([^\s"\'=<>`]+?))'
-    _VALID_URL = r'https?://(?:(?:www|play)\.)?(?P<bu>srf|rts|rsi|rtr|swi)\.ch/play/(?:tv|radio)/[^/]+/(?P<type>video|audio)/[^?]+\?id=(?P<id>[0-9a-f\-]{36}|\d+)'
+    _VALID_URL = r'https?://(?:(?:www|play)\.)?(?P<bu>srf|rts|rsi|rtr|swissinfo)\.ch/play/(?:tv|radio)/[^/]+/(?P<type>video|audio)/[^?]+\?id=(?P<id>[0-9a-f\-]{36}|\d+)'
-        return self.url_result('urn:%s:%s:%s' % (bu, media_type, media_id), 'SRGSSR')
+        return self.url_result('urn:%s:%s:%s' % (bu[:3], media_type, media_id), 'SRGSSR')
-from .srf import SrfIE
+from .srgssr import (
-        }
+# coding: utf-8
-__version__ = '2015.10.06.2'
+__version__ = '2015.10.09'
-        property_re = r'(?:name|property)=[\'"]og:%s[\'"]' % re.escape(prop)
+        property_re = r'(?:name|property)=[\'"]?og:%s[\'"]?' % re.escape(prop)
-            r'playerV5\s*=\s*dmp\.create\([^,]+?,\s*({.+?})\);',
+            [r'buildPlayer\(({.+?})\);', r'playerV5\s*=\s*dmp\.create\([^,]+?,\s*({.+?})\);'],
-                raise ExtractorError('PBS said: %s' % self._ERRORS.get(redirect_info['http_code'], redirect_info['message']), expected=True)
+                raise ExtractorError(
-            'skip': 'Expired',
+    _ERRORS = {
-                raise ExtractorError('PBS said: %s' % message, expected=True)
+                raise ExtractorError('PBS said: %s' % self._ERRORS.get(redirect_info['http_code'], redirect_info['message']), expected=True)
-                'id': '2280706814',
+                'id': '2276541483',
-                'title': 'American Experience - Death and the Civil War',
+                'title': 'American Experience - Death and the Civil War, Chapter 1',
-                'duration': 6705,
+                'duration': 682,
-                        'right restrictions')
+                http_code = redirect_info['http_code']
-                raise ExtractorError(message, expected=True)
+                raise ExtractorError('PBS said: %s' % message, expected=True)
-        sources = ['%s' % p for p in params[2]]
+        media_id = self._search_regex(
-            r'<a class="img-avatar" href="[^"]+/users/([^/"]+)" title="Go to [^"]+ page">', webpage, 'uploader id')
+            r'<a class="img-avatar" href="[^"]+/channels/([^/"]+)" title="Go to [^"]+ page">',
-            r'<a class="img-avatar" href="[^"]+/users/[^/"]+" title="Go to ([^"]+) page">', webpage, 'uploader')
+            r'<a class="img-avatar" href="[^"]+/channels/[^/"]+" title="Go to ([^"]+) page">',
-        player_js = self._download_webpage(player_url,video_id,'Downloading player Javascript')
+        player_js = self._download_webpage(
-            webpage, 'uploader id')
+            r'<a class="img-avatar" href="[^"]+/users/([^/"]+)" title="Go to [^"]+ page">', webpage, 'uploader id')
-            webpage, 'uploader')
+            r'<a class="img-avatar" href="[^"]+/users/[^/"]+" title="Go to ([^"]+) page">', webpage, 'uploader')
-            webpage, 'initialization parameters'
+            player_js, 'initialization parameters'
-                'player_url': 'http://rtl-now.rtl.de/includes/nc_player.swf',
+                'page_url': 'http://rtlnow.rtl.de',
-    _VALID_URL = r'https?://(?:watch\.|www\.)?nba\.com/(?:nba/)?video/(?P<id>[^?]*?)/?(?:/index\.html)?(?:\?.*)?$'
+    _VALID_URL = r'https?://(?:watch\.|www\.)?nba\.com/(?P<path>(?:[^/]+/)?video/(?P<id>[^?]*?))/?(?:/index\.html)?(?:\?.*)?$'
-        'md5': '9d902940d2a127af3f7f9d2f3dc79c96',
+        'md5': '9e7729d3010a9c71506fd1248f74e4f4',
-            'ext': 'mp4',
+            'ext': 'flv',
-        'url': 'http://watch.nba.com/nba/video/channels/playoffs/2015/05/20/0041400301-cle-atl-recap.nba',
+        'url': 'http://watch.nba.com/video/channels/playoffs/2015/05/20/0041400301-cle-atl-recap.nba',
-        video_info = self._download_xml('http://www.nba.com/video/%s.xml' % video_id, video_id)
+        path, video_id = re.match(self._VALID_URL, url).groups()
-                formats.extend(self._extract_m3u8_formats(video_url, video_id))
+                formats.extend(self._extract_m3u8_formats(video_url, video_id, m3u8_id='hls'))
-                formats.extend(self._extract_f4m_formats(video_url + '?hdcore=3.4.1.1', video_id))
+                formats.extend(self._extract_f4m_formats(video_url + '?hdcore=3.4.1.1', video_id, f4m_id='hds'))
-                quality = self._QUALITIES[key]
+                width, height, bitrate = re.search(r'(\d+)x(\d+)(?:_(\d+))?', key).groups()
-                    'preference': quality['preference'],
+                    'width': int_or_none(width),
-            'preference': 4,
+            'preference': 3,
-            'preference': 5,
+            'preference': 4,
-            'preference': 6,
+            'preference': 5,
-            'preference': 7,
+            'preference': 6,
-            'preference': 8,
+            'preference': 7,
-            'preference': 9,
+            'preference': 8,
-            'preference': 10,
+            'preference': 9,
-            'preference': 11,
+            'preference': 10,
-            'preference': 12,
+            'preference': 11,
-                    video_url = self._BASE_PATHS['turner'] + video_url
+            if video_url.startswith('/'):
-__version__ = '2015.10.06.1'
+__version__ = '2015.10.06.2'
-                 webpage, 'video id', group='id')
+                webpage, 'video id', group='id')
-                r'<canal:player[^>]+?videoId="(\d+)"', webpage, 'video id')
+                [r'<canal:player[^>]+?videoId=(["\'])(?P<id>\d+)', r'id=["\']canal_video_player(?P<id>\d+)'],
-            r'"retry_url":"(.*?)"', final_url_webpage, 'final video URL')
+        final_url = self._proto_relative_url(self._search_regex(
-                _columns, _lines = map(int, out.split())
+                _lines, _columns = map(int, out.split())
-__version__ = '2015.10.06'
+__version__ = '2015.10.06.1'
-        columns = compat_getenv('COLUMNS', None)
+        columns = compat_getenv('COLUMNS')
-        lines = compat_getenv('LINES', None)
+        lines = compat_getenv('LINES')
-        if columns <= 0 or lines <= 0:
+        if columns is None or lines is None or columns <= 0 or lines <= 0:
-            if columns <= 0:
+            if columns is None or columns <= 0:
-            if lines <= 0:
+            if lines is None or lines <= 0:
-__version__ = '2015.09.28'
+__version__ = '2015.10.06'
-            'uploader': 'Young Americans for Liberty',
+            'description': 'Young Americans for Liberty February 7, 2012 2:28 AM',
-        }
+        },
-            'id': format_id,
+            'id': video_id,
-    _VALID_URL = r'https?://www\.ustream\.tv/(?P<type>recorded|embed|embed/recorded)/(?P<videoID>\d+)'
+    _VALID_URL = r'https?://www\.ustream\.tv/(?P<type>recorded|embed|embed/recorded)/(?P<id>\d+)'
-        video_id = m.group('videoID')
+        video_id = m.group('id')
-            video_id = m.group('videoID')
+            video_id = m.group('id')
-            video_id = m.group('videoID')
+            video_id = m.group('id')
-        params = self._download_json('https://api.ustream.tv/videos/' + video_id + '.json', video_id)
+        params = self._download_json(
-from ..utils import ExtractorError
+from ..utils import (
-        self.report_extraction(video_id)
+        error = params.get('error')
-                                              webpage, 'title', default=None)
+        video = params['video']
-            video_title = 'Ustream video ' + video_id
+        formats = [{
-                                           webpage, 'uploader', fatal=False, flags=re.DOTALL, default=None)
+        title = video['title']
-                uploader = None
+        uploader = video.get('owner', {}).get('username')
-                                            webpage, 'thumbnail', fatal=False)
+        thumbnails = [{
-            'title': video_title,
+            'title': title,
-            'thumbnail': thumbnail,
+            'uploader_id': uploader_id,
-            }), video_id)
+        params = self._download_json('https://api.ustream.tv/videos/' + video_id + '.json', video_id)
-        video_url = params['flv']
+        video_url = params['video']['media_urls']['flv']
-        'url': 'http://hdvideotest.tumblr.com/post/130323439814/test-description-for-my-hd-video',
+from ..utils import int_or_none
-                                        'Downloading iframe page')
+        iframe = self._download_webpage(iframe_url, video_id, 'Downloading iframe page')
-        video_urls.append({
+        formats = [{
-        })
+            'format_id': format_id,
-            })
+        self._sort_formats(formats)
-            'formats': video_urls,
+            'duration': duration,
-                                       iframe, 'video url')
+
-            'url': video_url,
+            'formats': video_urls,
-        "url": "http://trailers.apple.com/trailers/wb/manofsteel/",
+        'url': 'http://trailers.apple.com/trailers/wb/manofsteel/',
-        "playlist": [
+        'playlist': [
-                    "uploader_id": "wb",
+                'md5': 'd97a8e575432dbcb81b7c3acb741f8a8',
-                    "uploader_id": "wb",
+                'md5': 'b8017b7131b721fb4e8d6f49e1df908c',
-                    "uploader_id": "wb",
+                'md5': 'd0f1e1150989b9924679b441f3404d48',
-                    "uploader_id": "wb",
+                'md5': '5fe08795b943eb2e757fa95cb6def1cb',
-                r'(?s)<iframe[^>]+?(?:[a-z-]+?=["\'].+?["\'][^>]+?)*?\bsrc=["\']([^\'"]+partnerplayer[^\'"]+)["\']',
+                r'(?s)<iframe[^>]+?(?:[a-z-]+?=["\'].*?["\'][^>]+?)*?\bsrc=["\']([^\'"]+partnerplayer[^\'"]+)["\']',
-                r'<iframe\s+[^>]*\s+src=["\']([^\'"]+partnerplayer[^\'"]+)["\']',
+                r'(?s)<iframe[^>]+?(?:[a-z-]+?=["\'].+?["\'][^>]+?)*?\bsrc=["\']([^\'"]+partnerplayer[^\'"]+)["\']',
-    _TEST = {
+    _TESTS = [{
-            'description': 'As Harry Potter begins his 6th year at Hogwarts School of Witchcraft and Wizardry, he discovers an old book marked mysteriously "This book is the property of the Half-Blood Prince" and begins to learn more about Lord Voldemort\'s dark past.',
+            'description': 'md5:8005b944181778e313d95c1237ddb640',
-    }
+    }, {
-    LimeLightChannelListIE,
+    LimelightMediaIE,
-    int_or_none,
+    float_or_none,
-class LimeLightBaseIE(InfoExtractor):
+class LimelightBaseIE(InfoExtractor):
-        return self._download_json(self.PLAYLIST_SERVICE_URL % (id, method), id)
+    def _call_playlist_service(self, item_id, method, fatal=True):
-        return self._download_json(self.API_URL % (orgId, id, method), id)
+    def _call_api(self, organization_id, item_id, method):
-    def process_data(self, mobileUrls, streams, properties):
+    def _extract(self, item_id, pc_method, mobile_method, meta_method):
-                formats.extend(self._extract_f4m_formats(stream['url'], video_id))
+            stream_url = stream.get('url')
-                    'ext': determine_ext(stream.get('url'))
+                    'url': stream_url,
-                rtmp = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', stream['url'])
+                rtmp = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>.+))/(?P<playpath>mp4:.+)$', stream_url)
-        filesize = properties.get('total_storage_in_bytes')
+        timestamp = int_or_none(properties.get('publish_date') or properties.get('create_date'))
-            'url': thumbnail.get('url'),
+            'url': thumbnail['url'],
-        subtitles = {caption.get('language_code'): [{'url': caption.get('url')}] for caption in properties.get('captions')}
+        } for thumbnail in properties.get('thumbnails', []) if thumbnail.get('url')]
-class LimeLightMediaIE(LimeLightBaseIE):
+class LimelightMediaIE(LimelightBaseIE):
-    _VALID_URL = r'http://link\.videoplatform\.limelight\.com/media/?.*mediaId=(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'(?:limelight:media:|http://link\.videoplatform\.limelight\.com/media/\??\bmediaId=)(?P<id>[a-z0-9]{32})'
-            'ext': 'mp4',
+            'ext': 'flv',
-            'duration': 144230,
+            'duration': 144.23,
-        }
+            'upload_date': '20090604',
-    API_URL = 'http://api.video.limelight.com/rest/organizations/%s/media/%s/%s.json'
+    _PLAYLIST_SERVICE_PATH = 'media'
-        properties = self.get_api(pc_json_data['orgId'], video_id, 'properties')
+        pc, mobile, metadata = self._extract(
-        return self.process_data(mobile_json_data['mediaList'][0]['mobileUrls'], pc_json_data['playlistItems'][0]['streams'], properties)
+        return self._extract_info(
-class LimeLightChannelIE(LimeLightBaseIE):
+class LimelightChannelIE(LimelightBaseIE):
-    _VALID_URL = r'http://link\.videoplatform\.limelight\.com/media/?.*channelId=(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'(?:limelight:channel:|http://link\.videoplatform\.limelight\.com/media/\??\bchannelId=)(?P<id>[a-z0-9]{32})'
-    API_URL = 'http://api.video.limelight.com/rest/organizations/%s/channels/%s/%s.json'
+    _PLAYLIST_SERVICE_PATH = 'channel'
-        medias = self.get_api(pc_json_data['orgId'], channel_id, 'media')
+        pc, mobile, medias = self._extract(
-            entries.append(self.process_data(mobile_json_data['mediaList'][i]['mobileUrls'], pc_json_data['playlistItems'][i]['streams'], medias['media_list'][i]))
+        entries = [
-        }
+        return self.playlist_result(entries, channel_id, pc['title'])
-class LimeLightChannelListIE(LimeLightBaseIE):
+class LimelightChannelListIE(LimelightBaseIE):
-    _VALID_URL = r'http://link\.videoplatform\.limelight\.com/media/?.*channelListId=(?P<id>[a-z0-9]{32})'
+    _VALID_URL = r'(?:limelight:channel_list:|http://link\.videoplatform\.limelight\.com/media/\?.*?\bchannelListId=)(?P<id>[a-z0-9]{32})'
-    PLAYLIST_SERVICE_URL = 'http://production-ps.lvp.llnw.net/r/PlaylistService/channel_list/%s/%s'
+    _PLAYLIST_SERVICE_PATH = 'channel_list'
-        json_data = self.get_playlist_service(channel_list_id, 'getMobileChannelListById')
+        channel_list = self._call_playlist_service(channel_list_id, 'getMobileChannelListById')
-            })
+        entries = [
-        }
+        return self.playlist_result(entries, channel_list_id, channel_list['title'])
-            self.list_subtitles(info_dict['id'], info_dict.get('subtitles'), 'subtitles')
+            self.list_subtitles(info_dict['id'], subtitles, 'subtitles')
-            info_dict['id'], info_dict.get('subtitles'),
+            info_dict['id'], subtitles,
-        'md5': '8e44ce11f0f725527daccc453f553eb0',
+        'md5': '067803f994e049b455a58b16e5aab442',
-            'description': 'Attorney General Eric Holder spoke to reporters following the Supreme Court decision in Shelby County v. Holder in which the court ruled that the preclearance provisions of the Voting Rights Act could not be enforced until Congress established new guidelines for review.',
+            'description': 'Attorney General Eric Holder speaks to reporters following the Supreme Court decision in [Shelby County v. Holder], in which the court ruled that the preclearance provisions of the Voting Rights Act could not be enforced.',
-        # two different ones
+        'md5': '4eafd1e91a75d2b1e6a3cbd0995816a2',
-            'id': '340723',
+            'id': 'c4486943',
-            'title': 'International Health Care Models',
+            'title': 'CSPAN - International Health Care Models',
-            'description': 'md5:70c7c3b8fa63fa60d42772440596034c'
+            'description': 'md5:118081aedd24bf1d3b68b3803344e7f3'
-            webpage, 'description', flags=re.DOTALL, default=None)
+        video_id = self._match_id(url)
-        data = self._download_json(info_url, video_id)
+        data = self._download_json(
-            'http://www.c-span.org/common/services/flashXml.php?programid=' + video_id,
+            'http://www.c-span.org/common/services/flashXml.php?%sid=%s' % (video_type, video_id),
-            entry['id'] = video_id
+            entry['id'] = 'c' + video_id if video_type == 'clip' else video_id
-                'id': video_id,
+                'id': 'c' + video_id if video_type == 'clip' else video_id,
-    _VALID_URL = r'https?://(?:www\.)?tape\.ly/(?P<id>[A-Za-z0-9\-_]+)(?:/(?P<songnr>\d+))?'
+    _VALID_URL = r'https?://(?:www\.)?(?:tape\.ly|tapely\.com)/(?P<id>[A-Za-z0-9\-_]+)(?:/(?P<songnr>\d+))?'
-        (?:video/5min/(?P<id>\d+)|
+        (?:video(?:/5min)?/(?P<id>\d+)|
-)
+from .nba import NBAIE
-    _VALID_URL = r'https?://(?:www\.)?nba\.com/(?:nba/)?video(?P<id>/[^?]*?)/?(?:/index\.html)?(?:\?.*)?$'
+class NBAIE(InfoExtractor):
-            'id': '0021200253-okc-bkn-recap.nba',
+            'id': '0021200253-okc-bkn-recap',
-            'upload_date': '20121205',
+            'timestamp': 1354638466,
-    _TESTS = [{
+    },{
-            'id': '0041400301-cle-atl-recap.nba',
+            'id': '0041400301-cle-atl-recap',
-            'timestamp': 1432094400,
+            'timestamp': 1432134543,
-            'http://smbsolr.cdnak.neulion.com/solr_nbav6/nba/nba/mlt/?wt=json&fl=name,description,image,runtime,releaseDate&q=sequence%3A' + program_id, video_id)['match']['docs'][0]
+    _BASE_PATHS = {
-            'timestamp': parse_iso8601(metadata.get('releaseDate'))
+            'id': video_id,
-        return [{
+        formats.extend([{
-        }]
+            'preference': 7,
-    def compat_get_terminal_size():
+    def compat_get_terminal_size(fallback=(80, 24)):
-            pass
+        if columns <= 0 or lines <= 0:
-            'also have a description, use  --match-filter '
+            'also have a description, use --match-filter '
-        help='[deprecated; use  -o "%(autonumber)s-%(title)s.%(ext)s" ] Number downloaded files starting from 00000')
+        help='[deprecated; use -o "%(autonumber)s-%(title)s.%(ext)s" ] Number downloaded files starting from 00000')
-from .ign import IGNIE, OneUPIE
+from .ign import (
-    _VALID_URL = r'https?://.+?\.ign\.com/(?P<type>videos|show_videos|articles|(?:[^/]*/feature))(/.+)?/(?P<name_or_id>.+)'
+    _VALID_URL = r'https?://.+?\.ign\.com/(?:[^/]+/)?(?P<type>videos|show_videos|articles|feature|(?:[^/]+/\d+/video))(/.+)?/(?P<name_or_id>.+)'
-    ]
+    _API_URL_TEMPLATE = 'http://apis.ign.com/video/v3/videos/%s'
-            'md5': 'eac8bdc1890980122c3b66f14bdd02e9',
+            'md5': 'febda82c4bafecd2d44b6e1a18a595f8',
-                ),
+                'description': 'Brian and Jared explore Michel Ancel\'s captivating new preview.',
-        return self._search_regex(res_id, webpage, 'video id')
+        return self._search_regex(res_id, webpage, 'video id', default=None)
-        return result
+        if not video_id:
-        media = config['playlist']['media']
+        api_data = self._download_json(self._API_URL_TEMPLATE % video_id, video_id)
-            'thumbnail': media['poster'][0]['url'].replace('{size}', 'grande'),
+            'id': api_data.get('videoId') or video_id,
-        'md5': '68a54ce4ebc772e4b71e3123d413163d',
+        'md5': 'c9cc69e07acb675c31a16719f909e347',
-            'description': 'md5:5d289b722f5a6d940ca3136e9dae89cf',
+            'description': 'md5:bf0516c5ee32a3217aa703e9b1bc7826',
-        view_count = int_or_none(xpath_text(playlist,'./info/views', 'views'))
+        view_count = int_or_none(xpath_text(playlist, './info/views', 'views'))
-    _VALID_URL = r'https?://ec\.europa\.eu/avservices/video/player\.cfm\?.*?\bref=(?P<id>[A-Za-z0-9]+)'
+    _VALID_URL = r'https?://ec\.europa\.eu/avservices/(?:video/player|audio/audioDetails)\.cfm\?.*?\bref=(?P<id>[A-Za-z0-9-]+)'
-    compat_urlparse,
+    int_or_none,
-    _TEST = {
+    _VALID_URL = r'https?://ec\.europa\.eu/avservices/video/player\.cfm\?.*?\bref=(?P<id>[A-Za-z0-9]+)'
-        'md5': '728cca2fd41d5aa7350cec1141fbe620',
+        'md5': '574f080699ddd1e19a675b0ddf010371',
-            'thumbnail': 're:^http://defiris\.ec\.streamcloud\.be/findmedia/18/107758/THUMB_[0-9A-Z]+\.jpg$'
+            'thumbnail': 're:^https?://.*\.jpg$',
-    }
+    }, {
-        formats = []
+        playlist = self._download_xml(
-            videos[xpath_text(item, 'lg')] = {'title': xpath_text(item, 'label').strip()}
+        def get_item(type_, preference):
-            videos[xpath_text(item, 'lg')]['description'] = xpath_text(item, 'label').strip()
+        query = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)
-            vid['url'] = xpath_text(item, 'url')
+        preferred_langs = orderedSet((preferred_lang, 'en', 'int'))
-                vid['language_preference'] = 10
+        title = get_item('title', preferred_langs) or video_id
-            formats.append(vid)
+        language_preference = qualities(preferred_langs[::-1])
-        def_video = videos.get(lang, videos['int'])
+        formats = []
-            'thumbnail': xpath_text(playlist, 'info/thumburl', 'thumburl'),
+            'title': title,
-from .nba import NBAIE
+from .nba import (
-    remove_end,
+    parse_iso8601,
-    _VALID_URL = r'https?://(?:watch\.|www\.)?nba\.com/(?:nba/)?video(?P<id>/[^?]*?)/?(?:/index\.html)?(?:\?.*)?$'
+class NBABaseIE(InfoExtractor):
-        'md5': 'c0edcfc37607344e2ff8f13c378c88a4',
+        'md5': '9d902940d2a127af3f7f9d2f3dc79c96',
-    }, {
+    }]
-            'title': 'NBA GAME TIME | Video: Hawks vs. Cavaliers Game 1',
+            'title': 'Hawks vs. Cavaliers Game 1',
-            'skip_download': True,
+            'timestamp': 1432094400,
-
+    def _extract_metadata(self, webpage, video_id):
-            'duration': duration,
+            'title': metadata['name'],
-                        width, height = [int_or_none(x) for x in child.get('resolution', 'x').split('x')]
+                        width, height = [int_or_none(x) for x in child.get('resolution', 'x').split('x')[:2]]
-                        width, height = [int_or_none(x) for x in child.get('resolution', '').split('x')]
+                        width, height = [int_or_none(x) for x in child.get('resolution', 'x').split('x')]
-                index, field, type_expected, type_got))
+                    index, field, type_expected, type_got))
-    clean_html,
+        # video with invalid direct format links (HTTP 403)
-                formats.extend(self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds'))
+                f4m_formats = self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False)
-                             transform_source=lambda s: fix_xml_ampersands(s).strip()):
+                             transform_source=lambda s: fix_xml_ampersands(s).strip(),
-            transform_source=transform_source)
+            transform_source=transform_source,
-                    formats.extend(self._extract_f4m_formats(manifest_url, video_id, preference, f4m_id))
+                    f4m_formats = self._extract_f4m_formats(
-                    src_url, video_id, ext or 'mp4', m3u8_id='hls'))
+                m3u8_formats = self._extract_m3u8_formats(
-            if src_url.startswith('http'):
+            if src_url.startswith('http') and self._is_valid_url(src, video_id):
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-from ..utils import parse_duration
+from ..compat import (
-            return self.playlist_result(entries, video_id, playlist_title, playlist_description)
+
-)
+from ..compat import compat_urlparse
-        smil = self._download_smil(smil_url, video_id)
+        smil = self._download_smil(smil_url, video_id, fatal=False)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        smil = self._download_xml(smil_url, video_id)
+        smil = self._download_smil(smil_url, video_id)
-            find_xpath_attr(smil, './/meta', 'name', 'date').attrib['content'])
+        info = self._parse_smil(smil, smil_url, video_id)
-            None if thumbnail_el is None else thumbnail_el.attrib.get('src'))
+        info['id'] = video_id
-        self._sort_formats(formats)
+        switch = smil.find('.//switch')
-        }
+        return info
-            bitrate = int_or_none(video.get('system-bitrate') or video.get('systemBitrate'), 1000)
+            bitrate = float_or_none(video.get('system-bitrate') or video.get('systemBitrate'), 1000)
-        baseurl = mobj.group('baseurl')
+        base_url = mobj.group('baseurl')
-        subtitles = None
+            r'data-subtitlesurl\s*=\s*(["\'])(?P<url>.+?)\1',
-            subtitles = self.extract_subtitles(subtitles_url, video_id, baseurl)
+            subtitles['no'] = [{
-                'NRK har ikke rettig-heter til Ã¥ vise dette programmet utenfor Norge',
+                'NRK har ikke rettigheter til Ã¥ vise dette programmet utenfor Norge',
-                raise ExtractorError(clean_html(m_error.group('msg')), expected=True)
+            error = self._html_search_regex(
-            'Expect a list of length %d, but got a list of length %d' % (len(expected), len(got)))
+            'Expect a list of length %d, but got a list of length %d for field %s' % (
-                'Type doesn\'t match at element %d of the list in field %s, expect %s, got %s' % (
+                'Type mismatch for list item at index %d for field %s, expected %r, got %r' % (
-            'invalid value for field %s, expected %r, got %r' % (field, expected, got))
+            'Invalid value for field %s, expected %r, got %r' % (field, expected, got))
-                        'Expected type %r for field %s, but got value %r of type %r' % (expected, field, got, type(got)))
+        self.assertTrue(
-                         len(expected), len(got)))
+        self.assertEqual(
-                             index, field, type_expected, type_got))
+            self.assertEqual(
-            )
+                'Expected %d items in field %s, but only got %d' % (expected_num, field, len(got)))
-                         'invalid value for field %s, expected %r, got %r' % (field, expected, got))
+        self.assertEqual(
-            self.assertEqual(_type_j, _type_i,
+        for index, (item_got, item_expected) in enumerate(zip(got, expected)):
-            _id += 1
+                             index, field, type_expected, type_got))
-                    compat_str.__name__, type(got).__name__, info_field))
+def expect_value(self, got, expected, field):
-                    )
+                isinstance(got, (list, dict)),
-                             'invalid value for field %s, expected %r, got %r' % (info_field, expected, got))
+            )
-def expect_info_dict(self, got_dict, expected_dict):
+def expect_dict(self, got_dict, expected_dict):
-            r'(?:<nflcs:avplayer[^>]+data-contentId\s*=\s*|contentId\s*:\s*)(["\'])(?P<id>.+?)\1',
+            r'(?:<nflcs:avplayer[^>]+data-content[Ii]d\s*=\s*|content[Ii]d\s*:\s*)(["\'])(?P<id>.+?)\1',
-            assert mobj is not None
+            return self.url_result('http://www.cc.com/shows/the-daily-show-with-trevor-noah/full-episodes')
-    TEST = {
+    _TEST = {
-            'ext': 'flv',
+            'ext': 'mp4',
-            'description': 'md5:a950cc4285c43e44d763d036710cd9cd',
+            'description': 'md5:eac376a4fe366edc70279bfb681aea16',
-        thumbnail = json_data.get('name')
+        thumbnail = json_data.get('thumbnail')
-                        'abr': source.get('avg_bitrate'),
+                        'tbr': source.get('avg_bitrate'),
-                        'vcodec': source.get('container'),
+                        'vcodec': source.get('codec'),
-            segment_ids = [clip['videoPlaybackID'] for clip in video_info['clips']]
+            stream = video_info.get('stream')
-            segment_url = 'http://www.adultswim.com/videos/api/v0/assets?id=%s&platform=mobile' % segment_id
+            segment_url = 'http://www.adultswim.com/videos/api/v0/assets?id=%s&platform=desktop' % segment_id
-                })
+                media_url = file_el.text
-__version__ = '2015.09.22'
+__version__ = '2015.09.28'
-            'title': self._og_search_description(webpage),
+            'title': self._og_search_description(webpage).strip(),
-            'uploader_id': self._search_regex(r'data-user-id="([^"]+)"', webpage, 'uploader id', fatal=False),
+            'uploader': self._search_regex(
-            'description': 'md5:35d42050a3ece241d5ddd7fdcc6fd896',
+            'title': 'md5:35d42050a3ece241d5ddd7fdcc6fd896',
-            'description': self._og_search_description(webpage),
+            'title': self._og_search_description(webpage),
-            'uploader_id': self._search_regex(r'data-user-id="([^"]+)"', webpage, 'uploader id', None),
+            'uploader': self._search_regex(r'data-username="([^"]+)"', webpage, 'uploader', fatal=False),
-            'uploader_id': uploader_id,
+            'uploader': self._search_regex(r'data-username="([^"]+)"', webpage, 'uploader', None),
-            'title': 'test chars: "\'/\\\xe4<>This is a test video for youtube-dl.For more information, contact phihag@phihag.de . - Video - Videos on Keek',
+            'title': 'test chars: "\'/\\Ã¤<>This is a test video for youtube-dl.For more information, contact phihag@phihag.de . - Video - Videos on Keek',
-            'description': 'test chars: "\'/\\Ã¤<>This is a test video for youtube-dl.For more information, contact phihag@phihag.de .',
+            'title': 'test chars: "\'/\\\xe4<>This is a test video for youtube-dl.For more information, contact phihag@phihag.de . - Video - Videos on Keek',
-    _VALID_URL = r'https?://(?:www\.)?keek\.com/(?:!|\w+/keeks/)(?P<id>\w+)'
+    _VALID_URL = r'https?://(?:www\.)?keek\.com/keek/(?P<id>\w+)'
-        'md5': '09c5c109067536c1cec8bac8c21fea05',
+        'url': 'https://www.keek.com/keek/NODfbab',
-            'title': 'test chars: "\'/\\\u00e4<>This is a test video for youtube-dl.For more information, contact phihag@phihag.de .',
+            'title': 'test chars: "\'/\\Ã¤<>This is a test video for youtube-dl.For more information, contact phihag@phihag.de . - Video - Videos on Keek',
-            'url': video_url,
+            'url': self._og_search_video_url(webpage),
-            'uploader_id': uploader_id,
+            'thumbnail': self._og_search_thumbnail(webpage),
-            r'<iframe[^>]+?src=(["\'])(?P<url>%s)\1' % CondeNastIE.EMBED_URL,
+            r'<(?:iframe|script)[^>]+?src=(["\'])(?P<url>%s)\1' % CondeNastIE.EMBED_URL,
-    _VALID_URL = r'http://(?:video|www|player)\.(?P<site>%s)\.com/(?P<type>watch|series|video|embed)/(?P<id>[^/?#]+)' % '|'.join(_SITES.keys())
+    _VALID_URL = r'http://(?:video|www|player)\.(?P<site>%s)\.com/(?P<type>watch|series|video|embed(?:js)?)/(?P<id>[^/?#]+)' % '|'.join(_SITES.keys())
-    EMBED_URL = r'(?:https?:)?//player\.(?P<site>%s)\.com/(?P<type>embed)/.+?' % '|'.join(_SITES.keys())
+    EMBED_URL = r'(?:https?:)?//player\.(?P<site>%s)\.com/(?P<type>embed(?:js)?)/.+?' % '|'.join(_SITES.keys())
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-sys.path.append(dirn(dirn((os.path.abspath(__file__)))))
+sys.path.insert(0, dirn(dirn((os.path.abspath(__file__)))))
-sys.path.append(dirn(dirn((os.path.abspath(__file__)))))
+sys.path.insert(0, dirn(dirn((os.path.abspath(__file__)))))
-sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
-sys.path.append(ROOT_DIR)
+sys.path.insert(0, ROOT_DIR)
-sys.path.append(dirn(dirn((os.path.abspath(__file__)))))
+sys.path.insert(0, dirn(dirn((os.path.abspath(__file__)))))
-    sys.path.append(os.path.dirname(os.path.dirname(path)))
+    sys.path.insert(0, os.path.dirname(os.path.dirname(path)))
-        thumbnail = self._proto_relative_url(media.get('snapshot'))
+        thumbnail = self._proto_relative_url(media.get('snapshot'), 'http:')
-    def _handle_error(self, response):
+    @staticmethod
-            secure_m3u8.replace("m3u8", "mp4").replace("hlsvod", "mp4").replace("hls", "mp4"),
+            # Secure mp4 URL is constructed according to Player.prototype.mp4 from
-        secure_m3u8 = self._proto_relative_url(media['sources']['secure_m3u8']['auto'])
+        secure_m3u8 = self._proto_relative_url(media['sources']['secure_m3u8']['auto'], 'http:')
-        response = self._download_json(url_or_request, video_id, note)
+    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata'):
-        return response['data'][0]
+        return response
-        'md5': '0b7994faa2bd5c0f69a3db6db28d078d',
+        'md5': '70f5187fb620f2c1d503b3b22fd4efe3',
-        'md5': '6c2ebeab03b739597ce8d86339d5a905',
+        'md5': '90b26344ba442c8e44aa4cf8f301164a',
-        response = super(EaglePlatformIE, self)._download_json(url_or_request, video_id, note)
+    def _get_video_url(self, url_or_request, video_id, note='Downloading JSON metadata'):
-        return response
+        return response['data'][0]
-        thumbnail = media.get('snapshot')
+        thumbnail = self._proto_relative_url(media.get('snapshot'))
-            video_id, 'Downloading m3u8 JSON')
+        secure_m3u8 = self._proto_relative_url(media['sources']['secure_m3u8']['auto'])
-            m3u8_data['data'][0], video_id,
+            m3u8_url, video_id,
-                r'(?m)^(\[[0-9]{2}:[0-9]{2}\.[0-9]{2,}\][^\n]*|\[[^\]]*\])', lrc_content))
+                r'(?m)^(\[[0-9]{2}:[0-9]{2}(?:\.[0-9]{2,})?\][^\n]*|\[[^\]]*\])', lrc_content))
-            'upload_date': '20141227',
+            'release_date': '20141227',
-            'upload_date': '20050626',
+            'release_date': '20050626',
-            'upload_date': '19970225',
+            'release_date': '19970225',
-            'upload_date': publish_time,
+            'release_date': publish_time,
-                r'(\[[0-9]{2}:[0-9]{2}\.[0-9]{2,}\][^\n]*|\[[^\]]*\])', lrc_content))
+                r'(?m)^(\[[0-9]{2}:[0-9]{2}\.[0-9]{2,}\][^\n]*|\[[^\]]*\])', lrc_content))
-        actual_lrc_lyrics = self._filter_lrc(lrc_content)
+        actual_lrc_lyrics = ''.join(
-        return {
+        actual_lrc_lyrics = self._filter_lrc(lrc_content)
-            'thumbnail': thumbnail_url,
+            'thumbnail': thumbnail_url
-                if e.id == 'notukerror':
+                if e.id in ('notukerror', 'geolocation'):
-            return self.url_result(url, ie='MTVServicesEmbedded')
+        mtvservices_url = MTVServicesEmbeddedIE._extract_url(webpage)
-                webpage, 'mgid')
+                webpage, 'mgid', default=None)
-            raise ExtractorError('this song has been offline because of copyright issues')
+            raise ExtractorError('this song has been offline because of copyright issues', expected=True)
-            r'(?s)class="(?:[^" ]+ +)*title(?: +[^" ]+)*".*?<h1[^>]+title="([^"]+)"', webpage, 'song name')
+            r'(?s)class="(?:[^"\s]+\s+)*title(?:\s+[^"\s]+)*".*?<h1[^>]+title="([^"]+)"', webpage, 'song name')
-            'format_id': determine_ext(url),
+            'format_id': determine_ext(furl),
-            'url': url,
+            'url': furl,
-        } for url in urls]
+        } for furl in urls]
-            r'(?s)class="[^"]*title[^"]*".*?<h1[^>]+title="([^"]+)"', webpage, 'song name')
+            r'(?s)class="(?:[^" ]+ +)*title(?: +[^" ]+)*".*?<h1[^>]+title="([^"]+)"', webpage, 'song name')
-            r'<h1[^>]+title="([^"]+)">', webpage, 'song name')
+            r'(?s)class="[^"]*title[^"]*".*?<h1[^>]+title="([^"]+)"', webpage, 'song name')
-            r'(?s)<video[^>]+(?:poster="([^"]+)")?[^>]*>(.*)</video>', webpage)
+            r'(?s)<video(?:(?!poster)[^>])+(?:poster="([^"]+)")?[^>]*>(.*)</video>',
-        matches = re.search(r'(?s)<video[^>]+(?:poster="([^"]+)")?[^>]*>(.*)</video>', webpage)
+        webpage = self._download_webpage(
-        formats = [{'url': url, 'format_id': determine_ext(url)} for url in urls]
+        formats = [{
-        matches = re.search(r'(?s)<video[^>]+poster="([^"]+)"[^>]*>(.*)</video>', webpage)
+        matches = re.search(r'(?s)<video[^>]+(?:poster="([^"]+)")?[^>]*>(.*)</video>', webpage)
-from .jukebox import JukeboxIE
+from .ultimedia import UltimediaIE
-)
+from ..utils import int_or_none
-    _VALID_URL = r'https?://(?:www\.)?ultimedia\.com/default/index/video[^/]+/id/(?P<id>[\d+a-z]+)'
+    _VALID_URL = r'https?://(?:www\.)?ultimedia\.com/deliver/(?P<type>generic|musique)(?:/[^/]+)*/(?:src|article)/(?P<id>[\d+a-z]+)'
-        'url': 'https://www.ultimedia.com/default/index/videogeneric/id/s8uk0r',
+        'url': 'https://www.ultimedia.com/deliver/generic/iframe/mdtk/01601930/zone/1/src/s8uk0r/autoplay/yes/ad/no/width/714/height/435',
-            'description': 'md5:3e5c8fd65791487333dda5db8aed32af',
+            'duration': 74,
-        'url': 'https://www.ultimedia.com/default/index/videomusic/id/xvpfp8',
+        'url': 'https://www.ultimedia.com/deliver/musique/iframe/mdtk/01601930/zone/1/article/xvpfp8/autoplay/yes/ad/no/width/714/height/435',
-            'description': 'Two',
+            'title': 'Two - C\'est La Vie (clip)',
-        webpage = self._download_webpage(url, video_id)
+    @staticmethod
-            webpage, 'deliver URL'), compat_urllib_parse_urlparse(url).scheme + ':')
+    def _real_extract(self, url):
-            deliver_url, video_id, 'Downloading iframe page')
+        deliver_info = self._download_json(
-                'Video %s is currently not available' % video_id, expected=True)
+        yt_id = deliver_info.get('yt_id')
-            video_id)
+        jwconf = deliver_info['jwconf']
-                return self.url_result(video_url, 'Youtube')
+        for source in jwconf['playlist'][0]['sources']:
-                'quality': quality(mode.get('type')),
+                'url': source['file'],
-            'description', fatal=False))
+        self._sort_formats(formats)
-            'upload date', fatal=False))
+        title = deliver_info['title']
-            'upload_date': upload_date,
+            'duration': duration,
-        matches = re.search(r'(?s)<video[^>]*poster="([^"]+)"[^>]*>(.*?)</video>', webpage)
+        title = clean_html(self._html_search_regex('<h3>([^<]+)</h3>', webpage, 'title'))
-        urls = re.findall(r'(?s)<source[^>]*src="([^"]+)"[^>]*>', sources)
+        urls = re.findall(r'<source[^>]+src="([^"]+)"', sources)
-                }
+        if matches is None:
-            poster, sources = matchs.groups()
+        matches = re.search(r'(?s)<video[^>]*poster="([^"]+)"[^>]*>(.*?)</video>', webpage)
-        }
+        },
-        ]
+        ],
-        'only_matching': True,
+        'md5': 'eaa20e6b9df418c912d7f5dec2ba734d',
-    _VALID_URL = r'http://(video|www|player)\.(?P<site>%s)\.com/(?P<type>watch|series|video|embed)/(?P<id>[^/?#]+)' % '|'.join(_SITES.keys())
+    _VALID_URL = r'http://(?:video|www|player)\.(?P<site>%s)\.com/(?P<type>watch|series|video|embed)/(?P<id>[^/?#]+)' % '|'.join(_SITES.keys())
-        'bonappetit': 'Bon Appetit',
+        'bonappetit': 'Bon AppÃ©tit',
-        video_info = self._search_regex(r'var\s*video\s*=\s*({.+?});', info_page, 'video info')
+        video_info = self._search_regex(r'var\s+video\s*=\s*({.+?});', info_page, 'video info')
-        'wired': 'WIRED',
+        'allure': 'Allure',
-        'glamour': 'Glamour',
+        'wired': 'WIRED',
-        video_info = json.loads(video_info)
+        video_info = self._search_regex(r'var\s*video\s*=\s*({.+?});', info_page, 'video info')
-            'title': 'A little over a year ago, I posted my first #dailycortado, a drink introduced to...',
+            'title': 'Instagram photo by @aguynamedpatrick (Patrick Janelle)',
-            webpage, 'title')
+        title = remove_end(self._og_search_title(webpage), ' - via Iconosquare')
-from ..utils import int_or_none
+from ..utils import (
-            'title': 'Instagram media by @aguynamedpatrick (Patrick Janelle)',
+            'title': 'A little over a year ago, I posted my first #dailycortado, a drink introduced to...',
-                r'window\.media\s*=\s*({.+?});\n', webpage, 'media'),
+            get_element_by_id('mediaJson', webpage),
-            r'<title>(.+?)(?: *\(Videos?\))? \| (?:Iconosquare|Statigram)</title>',
+            r'<title>(.+?)</title>',
-            [r'<title>(?P<title>.+?)(?:, Free Porn: xHamster| - xHamster\.com)</title>',
+            [r'<title>(?P<title>.+?)(?:, (?:[^,]+? )?Porn: xHamster| - xHamster\.com)</title>',
-    _VALID_URL = r'https?://(?:www\.)?nhl\.com/ice/news\.html?(?:\?(?:.*?[?&])?)id=(?P<id>[-0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:.+?\.)?nhl\.com/(?:ice|club)/news\.html?(?:\?(?:.*?[?&])?)id=(?P<id>[-0-9a-zA-Z]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            [r'pVid(\d+)', r"nlid\s*:\s*'(\d+)'"],
+            [r'pVid(\d+)', r"nlid\s*:\s*'(\d+)'",
-    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/(?:console)?(?:\?(?:.*?[?&])?)(?:id|hlg)=(?P<id>[-0-9a-zA-Z,]+)'
+    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/(?:console|embed)?(?:\?(?:.*?[?&])?)(?:id|hlg|playlist)=(?P<id>[-0-9a-zA-Z,]+)'
-        title = self._html_search_regex(r'<title>(?P<title>.+?) - xHamster\.com</title>', webpage, 'title')
+        title = self._html_search_regex(
-            return hashlib.md5((t + mg + x).encode('utf8')).hexdigest()
+            return self.md5_text(t + mg + x)
-            'src': hashlib.md5(b'youtube-dl').hexdigest(),
+            'src': self.md5_text('youtube-dl'),
-                (enc_key + tm + tvid).encode('utf8')).hexdigest(),
+            'enc': self.md5_text((enc_key + tail)[1:64:2] + tail),
-                (tm + tvid).encode('utf8')).hexdigest()
+            'authkey': self.md5_text(self.md5_text('') + tail),
-        enc_key = '3601ba290e4f4662848c710e2122007e'  # last update at 2015-08-10 for Zombie
+        # TODO: automatic key extraction
-    _CLIENT_ID = 'b45b1aa10f1ac2941910a7f0d10f8e28'
+    _CLIENT_ID = '02gUJC0hH2ct1EGOcYXQIzRFU91c72Ea'
-                src = source.get('src')
+                src = source.get('src') or source.get('streaming_src')
-)
+from .theplatform import ThePlatformIE
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-            r"<div class=\"cnetVideoPlayer\"\s+.*?data-cnet-video-options='([^']+)'",
+            r"<div class=\"videoPlayer\"\s+.*?data-cnet-video-uvp-options='([^']+)'",
-        tp_link = 'http://link.theplatform.com/s/%s/%s' % (mpx_account, vid)
+        vdata = data['videos'][0]
-        thumbnail = vdata.get('image', {}).get('path')
+        title = vdata['title']
-            'url': tp_link,
+            'description': description,
-            'thumbnail': thumbnail,
+            'subtitles': subtitles,
-            for opt in (ffpp.executable, '-y', '-i', url, '-f', 'mp4', '-c', 'copy', '-bsf:a', 'aac_adtstoasc')]
+        args = [ffpp.executable, '-y']
-__version__ = '2015.09.09'
+__version__ = '2015.09.22'
-    _VALID_URL = r'https?://(?:www\.)?9gag(?:\.com/tv|\.tv)/p/(?P<id>[a-zA-Z0-9]+)(?:/(?P<display_id>[^?#/]+))?'
+    _VALID_URL = r'https?://(?:www\.)?9gag(?:\.com/tv|\.tv)/(?:p|embed)/(?P<id>[a-zA-Z0-9]+)(?:/(?P<display_id>[^?#/]+))?'
-            "title": "\"People Are Awesome 2013\" Is Absolutely Awesome",
+        'url': 'http://9gag.com/tv/p/Kk2X5/people-are-awesome-2013-is-absolutely-awesome',
-            "view_count": int,
+            'view_count': int,
-        'add_ie': ['Youtube']
+        'add_ie': ['Youtube'],
-            webpage, 'post view'))
+        post_view = self._parse_json(
-        view_count = str_to_int(post_view['externalView'])
+        description = post_view.get('description')
-            r'var postView = new app\.PostView\({\s*post:\s*({.+?}),\s*posts:\s*prefetchedCurrentPost', webpage, 'post view'))
+            r'var\s+postView\s*=\s*new\s+app\.PostView\({\s*post:\s*({.+?})\s*,\s*posts:\s*prefetchedCurrentPost',
-    _VALID_URL = r'https?://(?:www\.)?9gag\.com/tv/p/(?P<id>[a-zA-Z0-9]+)(?:/(?P<display_id>[^?#/]+))?'
+    _VALID_URL = r'https?://(?:www\.)?9gag(?:\.com/tv|\.tv)/p/(?P<id>[a-zA-Z0-9]+)(?:/(?P<display_id>[^?#/]+))?'
-        'add_ie': ['Youtube']
+        'url': 'http://9gag.com/tv/p/KklwM',
-    _VALID_URL = r'https?://(?:www\.)?9gag\.com/tv/p/(?P<id>[a-zA-Z0-9]+)/(?P<display_id>[^?#/]+)'
+    _VALID_URL = r'https?://(?:www\.)?9gag\.com/tv/p/(?P<id>[a-zA-Z0-9]+)(?:/(?P<display_id>[^?#/]+))?'
-        display_id = mobj.group('display_id')
+        display_id = mobj.group('display_id') or video_id
-        if not source_url or source_url == '':
+        if not source_url:
-        external_video_provider = post_view['videoExternalProvider']
+        ie_key = None
-            'ie_key': self._EXTERNAL_VIDEO_PROVIDER[external_video_provider]['ie_key'],
+            'url': source_url,
-    '''
+    _VALID_URL = r'https?://(?:www\.)?9gag\.com/tv/p/(?P<id>[a-zA-Z0-9]+)/(?P<display_id>[^?#/]+)'
-        "url": "http://9gag.tv/v/1912",
+        "url": "http://9gag.com/tv/p/Kk2X5/people-are-awesome-2013-is-absolutely-awesome",
-            "id": "1912",
+            "id": "Kk2X5",
-        'url': 'http://9gag.tv/p/KklwM/alternate-banned-opening-scene-of-gravity?ref=fsidebar',
+        'url': 'http://9gag.com/tv/p/KklwM/alternate-banned-opening-scene-of-gravity?ref=fsidebar',
-        display_id = mobj.group('display_id') or video_id
+        video_id = mobj.group('id')
-        youtube_id = post_view['videoExternalId']
+        external_video_id = post_view['videoExternalId']
-            'ie_key': 'Youtube',
+            'url': self._EXTERNAL_VIDEO_PROVIDER[external_video_provider]['url'] % external_video_id,
-        if info.get('Type') in ['Serie', None]:
+        if info.get('Type') in ('Serie', None):
-                video_id, 'Downloading series JSON')
+            try:
-        'md5': '14d3cfffe66d57b41ae2d9c873416f01',
+        'md5': 'e642d1b27fcf3a4ffa79f194f5adde36',
-            'ext': 'flv',
+            'ext': 'mp4',
-        'md5': 'd5434c80fcfdb61651cc2199a88d6ba3',
+        'md5': '9243079a8531809efe1b089db102c069',
-            'ext': 'flv',
+            'ext': 'mp4',
-                formats.append({
+                format_id = media.get('Bitrate')
-                })
+                    'preference': 1,
-    _VALID_URL = r'http://(?:www\.)?viewster\.com/(?:serie|movie)/(?P<id>\d+-\d+-\d+)'
+    _VALID_URL = r'https?://(?:www\.)?viewster\.com/(?:serie|movie)/(?P<id>\d+-\d+-\d+)'
-        cookies = self._get_cookies(url)
+        self._request_webpage(HEADRequest('http://www.viewster.com/'), video_id)
-        for media_type in ('application/f4m+xml', 'application/x-mpegURL'):
+        for media_type in ('application/f4m+xml', 'application/x-mpegURL', 'video/mp4'):
-        # self.assertMatch(':ythistory', ['youtube:history'])
+        self.assertMatch(':ythistory', ['youtube:history'])
-    #YoutubeHistoryIE,
+    YoutubeHistoryIE,
-    YoutubeHistoryIE,
+    #YoutubeHistoryIE,
-    #YoutubeHistoryIE,
+    # remember to uncomment test in test/test_all_urls when it's fixed
-                        (?P<id>(?:[a-z0-9]{16}|\w{8}\-(?:\w{4}\-){3}\w{12}))
+                        (?P<id>[^/#?&]+)
-            default='static/content/static/config/video/config.json'))
+            r'(?:(?:config|configURL)\s*:\s*|<nflcs:avplayer[^>]+data-config\s*=\s*)(["\'])(?P<config>.+?)\1',
-                                     note='Downloading player config')
+            r'(?:<nflcs:avplayer[^>]+data-contentId\s*=\s*|contentId\s*:\s*)(["\'])(?P<id>.+?)\1',
-            'only_matching': True,
+    _VALID_URL = r'''(?x)
-    ]
+    }, {
-        kwargs['strict'] = True
+        kwargs[b'strict'] = True
-        self.assertMatch(':ythistory', ['youtube:history'])
+        # self.assertMatch(':ythistory', ['youtube:history'])
-                webpage, 'iframe url', group='iframe url')
+                webpage, 'iframe url', group='url')
-            webpage, 'json vp url')
+            webpage, 'json vp url', default=None)
-    YoutubeHistoryIE,
+    #YoutubeHistoryIE,
-            'ext': 'm3u8',
+            'ext': 'mp4',
-                }).encode('utf-8')),
+                })),
-            'thumbnail': 're:^http://.*\.png$',
+            'thumbnail': 're:^https?://.*\.png$',
-        args.append(encodeFilename(tmpfilename, True))
+        args.append(encodeFilename(ffpp._ffmpeg_filename_argument(tmpfilename), True))
-            files_cmd.extend([encodeArgument('-i'), encodeFilename(path, True)])
+            files_cmd.extend([
-        return fn
+        # Always use 'file:' because the filename may contain ':' (ffmpeg
-    IE_DESC = 'telecinco.es, cuatro.es and mediaset.es'
+    IE_DESC = 'telecinco.es, cuatro.com and mediaset.es'
-    _VALID_URL = r'https?://www\.(?:telecinco\.es|cuatro\.com)/(?:[^/]+/)+(?P<id>.+?)\.html'
+    IE_DESC = 'telecinco.es, cuatro.es and mediaset.es'
-    IE_NAME = 'mitele.es'
+    IE_DESC = 'mitele.es'
-    IE_NAME = 'telecinco.es'
+    IE_DESC = 'telecinco.es and cuatro.es'
-    _VALID_URL = r'https?://www\.telecinco\.es/(?:[^/]+/)+(?P<id>.+?)\.html'
+    _VALID_URL = r'https?://www\.(?:telecinco\.es|cuatro\.com)/(?:[^/]+/)+(?P<id>.+?)\.html'
-            token_info['tokenizedUrl'], episode, ext='mp4')
+            token_info['tokenizedUrl'], episode, ext='mp4', entry_protocol='m3u8_native')
-)
+from ..compat import compat_urllib_parse
-    strip_jsonp,
+    int_or_none,
-            'description': 'md5:3b6fce7eaa41b2d97358726378d9369f',
+            'id': '0NF1jJnxS1Wu3pHrmvFyw2',
-        embed_data = json.loads(embed_data_json)
+        display_id = self._match_id(url)
-        info_el = self._download_xml(info_url, episode).find('./video/info')
+        config_url = self._search_regex(
-            token_info['tokenizedUrl'], episode, ext='mp4')
+        config = self._download_json(
-            'formats': formats,
+            'id': video_id,
-            'duration': parse_duration(info_el.find('duration').text),
+            'thumbnail': thumbnail,
-from .mitele import MiTeleIE
+import json
-class TelecincoIE(MiTeleIE):
+
-                r'<iframe[^>]+src="/?(dl/[^"]+\?iframe\b[^"]*)"',
+            iframe_url = self._search_regex(
-                '%s/%s' % (host, iframe_path), video_id)
+                iframe_url, video_id)
-    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/(?:view_video\.php\?viewkey=|embed/)(?P<id>[0-9a-z]+)'
+    _VALID_URL = r'https?://(?:[a-z]+\.)?pornhub\.com/(?:view_video\.php\?viewkey=|embed/)(?P<id>[0-9a-z]+)'
-                channel_page, 'channel id', default=None)
+        if channel_page is False:
-        if isinstance(string, unicode):
+        if isinstance(string, compat_str):
-        if isinstance(s, unicode):
+        if isinstance(s, compat_str):
-    _VALID_URL = r'http://(?:www\.)?clubic\.com/video/[^/]+/video.*-(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'http://(?:www\.)?clubic\.com/video/(?:[^/]+/)*video.*-(?P<id>[0-9]+)\.html'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        }
+        },
-        }
+        },
-    NownessSerieIE,
+    NownessSeriesIE,
-from ..compat import compat_urllib_request
+from ..compat import (
-    def extract_url_result(self, post):
+    def _extract_url_result(self, post):
-                            errnote='Player download failed')
+                            errnote='Unable to download player JavaScript')
-    def api_request(self, url, request_path):
+    def _api_request(self, url, request_path):
-        return display_id, json_data
+        request = compat_urllib_request.Request(
-    ]
+    _TESTS = [{
-        return self.extract_url_result(post)
+        _, post = self._api_request(url, 'post/getBySlug/%s')
-        {
+        'info_dict': {
-        entries = [self.extract_url_result(item) for item in playlist['items']]
+        playlist_id, playlist = self._api_request(url, 'post?PlaylistId=%s')
-    IE_NAME = 'nowness:serie'
+class NownessSeriesIE(NownessBaseIE):
-        {
+        'info_dict': {
-        return self.playlist_result(entries, serie_id)
+        display_id, series = self._api_request(url, 'series/getBySlug/%s')
-# encoding: utf-8
+# coding: utf-8
-    ExtractorError,
+    determine_ext,
-        return self.extract_video_info(json_data['playlist'], video_id)
+        display_id = self._match_id(url)
-            }
+    IE_DESC = 'NDR.de - Norddeutscher Rundfunk'
-    _TEST = {
+    IE_NAME = 'njoy'
-class NDREmbedBaseIE(NDRBaseIE):
+class NDREmbedBaseIE(InfoExtractor):
-        return self.extract_video_info(json_data['playlist'], video_id)
+        mobj = re.match(self._VALID_URL, url)
-    _TEST = {
+    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)+(?P<id>[\da-z]+)-(?:player|externalPlayer)\.html'
-        'md5': 'cb63be60cd6f9dd75218803146d8dc67',
+        'md5': '8b9306142fe65bbdefb5ce24edb6b0a9',
-    }
+        },
-        'md5': 'cb63be60cd6f9dd75218803146d8dc67',
+    IE_NAME = 'njoy:embed'
-            'id': 'portraet374',
+            'id': 'doku948',
-    }
+            'title': 'Zehn Jahre Reeperbahn Festival - die Doku',
-        info_url = "http://v2.tudou.com/f?id=" + str(video_id)
+        info_url = 'http://v2.tudou.com/f?id=' + compat_str(video_id)
-            r'vcode:\s*[\'"](.+?)[\'"]', webpage, 'youku vcode', default=None)
+            r'vcode\s*:\s*[\'"]([^\'"]*)[\'"]', webpage, 'youku vcode', default=None)
-            r",kw:\s*['\"](.+?)[\"']", webpage, 'title')
+            r',kw\s*:\s*[\'"]([^\'"]+)[\'"]', webpage, 'title')
-            r",pic:\s*[\"'](.+?)[\"']", webpage, 'thumbnail URL', fatal=False)
+            r',pic\s*:\s*[\'"]([^\'"]+)[\'"]', webpage, 'thumbnail URL', fatal=False)
-            r"playerUrl\s*:\s*['\"](.+?\.swf)[\"']",
+            r'playerUrl\s*:\s*[\'"]([^\'"]+\.swf)[\'"]',
-            r'segs: \'(.*)\'', webpage, 'segments'), video_id)
+            r'segs: \'([^\']+)\'', webpage, 'segments'), video_id)
-        final_url = self._html_search_regex('>(.+?)</f>', webpage, 'video url')
+        xml_data = self._download_xml(info_url, video_id, "Opening the info XML page")
-        info_url = "http://v2.tudou.com/f?id=" + str(id)
+    def _url_for_id(self, video_id, quality=None):
-        webpage = self._download_webpage(info_url, id, "Opening the info webpage")
+        webpage = self._download_webpage(info_url, video_id, "Opening the info webpage")
-            }
+        youku_vcode = self._search_regex(
-        segments = json.loads(segs_json)
+        segments = self._parse_json(self._search_regex(
-    _VALID_URL = r'https?://(?:www\.)?tudou\.com/(?:listplay|programs(?:/view)?|albumplay)/?.*/(?P<id>[^/?#]+?)(?:\.html)?/?(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?tudou\.com/(?:listplay|programs(?:/view)?|albumplay)/([^/]+/)*(?P<id>[^/?#]+?)(?:\.html)?/?(?:$|[?#])'
-        }
+        html = re.sub(r'<!--(?:(?!<!--).)*-->', '', html)
-        for input in re.findall(r'<input([^>]+)>', html):
+        for input in re.findall(r'(?i)<input([^>]+)>', html):
-            r'(?s)<form[^>]+?id=(["\'])%s\1[^>]*>(?P<form>.+?)</form>' % form_id,
+            r'(?is)<form[^>]+?id=(["\'])%s\1[^>]*>(?P<form>.+?)</form>' % form_id,
-from .brightcove import BrightcoveIE
+from .brightcove import (
-from .brightcove import BrightcoveIE
+from .brightcove import (
-            },
+        }, {
-        info = query_result['query']['results']['mediaObj'][0]
+    def _extract_info(self, display_id, query, webpage):
-__version__ = '2015.09.03'
+__version__ = '2015.09.09'
-        for current_page_id in range(start_page, last_page):
+        for current_page_id in itertools.count(start_page):
-                'Downloading page %d' % (current_page_id + 1)) if current_page_id != page_id else webpage
+                'Downloading page %d' % (current_page_id + 1))
-from .common import InfoExtractor, ExtractorError
+from .common import InfoExtractor
-            'duration': 119.92,
+            'thumbnail': 're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'age_limit': 0,
-            'duration': 223.72,
+            'thumbnail': 're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'uploader': 'SunshineM',
-            'duration': 97.859999999999999,
+            'thumbnail': 're:^https?://.*\.jpg',
-            'thumbnail': 're:^https?://.*\.jpg',
+            'uploader_id': '109747',
-        # From http://naked-yogi.tumblr.com/post/118312946248/naked-smoking-stretching
+        # nsfw test from http://naked-yogi.tumblr.com/post/118312946248/naked-smoking-stretching
-        'only_matching': True,
+        'info_dict': {
-            raise ExtractorError('Could not extract the vid.me video data')
+        try:
-        comment_count = int_or_none(video_data.get('comment_count'))
+        error = response.get('error')
-            uploader = user_data.get('username')
+        video = response['video']
-        } for format in video_data.get('formats', [])]
+            'format_id': f.get('type'),
-from .common import InfoExtractor
+from .common import InfoExtractor, ExtractorError
-    str_to_int,
+    parse_iso8601,
-        'md5': 'f42d05e7149aeaec5c037b17e5d3dc82',
+        'md5': 'c62f1156138dc3323902188c5b5a8bd6',
-        webpage = self._download_webpage(url, video_id)
+        api_url = 'https://api.vid.me/videoByUrl/' + video_id
-            r'<source src="([^"]+)"', webpage, 'video URL')
+        uploader = None
-            webpage, 'uploader', default=None)
+        formats = [{
-            'height': height,
+            'comment_count': comment_count,
-)
+from .fktv import FKTVIE
-    get_element_by_id,
+    determine_ext,
-            'ext': 'flv',
+            'id': '1',
-        }
+        episode = self._match_id(url)
-            'md5': '79132cc09ec5309fa590ae46e4cc31bc',
+            'md5': 'b9be794ceb56c7267d410a13f99d801a',
-                'duration': 1287,
+                'duration': 1290,
-            'md5': 'e1d5734c06865cc504ad99dc2de0d443',
+            'md5': '1fff6a689d8770966df78c8cb6c8c17c',
-                'duration': 2217,
+                'duration': 2220,
-        'md5': '63a42c705772aa53fd4c1a0027f86adf',
+        'md5': 'e79284c87b371424885448d11f6398c8',
-preferences = {'xl': 4, 'l': 3, 'm': 2, 's': 1, 'xs': 0,}
+preference = qualities(['xs', 's', 'm','l', 'xl'])
-                            'preference': preferences.get(quality),
+                            'preference': preference(quality),
-            'preference': preferences.get(thumbnail.get('quality'))
+            'preference': preference(thumbnail.get('quality'))
-    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)+(?P<id>\w+)'
+    _VALID_URL = r'https?://www\.ndr\.de/(?:[^/]+/)+(?P<id>[a-z0-9]+)-(?:player|externalPlayer)\.html'
-    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)(?P<id>\w+)'
+    _VALID_URL = r'https?://www\.n-joy\.de/(?:[^/]+/)+(?P<id>[a-z0-9]+)-(?:player|externalPlayer)\.html'
-        video_upload_date = self._html_search_regex(r'<div>Availability for free users:(.+?)</div>', webpage, 'video_upload_date', fatal=False, flags=re.DOTALL)
+        video_upload_date = self._html_search_regex(
-        video_uploader = self._html_search_regex(r'<div>\s*Publisher:(.+?)</div>', webpage, 'video_uploader', fatal=False, flags=re.DOTALL)
+        video_uploader = self._html_search_regex(
-class CrunchyrollIE(InfoExtractor):
+class CrunchyrollBaseIE(InfoExtractor):
-class CrunchyrollShowPlaylistIE(InfoExtractor):
+class CrunchyrollShowPlaylistIE(CrunchyrollBaseIE):
-            }
+                'title': 'El cÃ­rculo de hierro de Michelle Bachelet en su regreso a La Moneda',
-        json_data = self._download_json('http://www.ndr.de/%s-ppjson.json' % video_id, video_id, 'Downloading page')
+    def extract_video_info(self, playlist, video_id):
-            for key, f in json_data.get('playlist').items():
+        streamType = playlist.get('config').get('streamType')
-                        formats.extend(self._extract_m3u8_formats(src, video_id))
+                        formats.extend(self._extract_m3u8_formats(src, video_id, fatal=False))
-            for key, f in json_data.get('playlist').items():
+        elif streamType == 'httpAudio':
-                        
+                        'vcodec': 'none',
-        config = json_data.get('playlist').get('config')
+        config = playlist.get('config')
-            'id': '2480',
+            'id': 'comedycontest2480',
-from .canal13cl import Canal13clIE
+from .tele13 import Tele13IE
-        }
+# coding: utf-8
-    _VALID_URL = r'http://(?:www\.)?wimp\.com/([^/]+)/'
+    _VALID_URL = r'http://(?:www\.)?wimp\.com/(?P<id>[^/]+)/'
-        'md5': 'f1acced123ecb28d9bb79f2479f2b6a1',
+        'md5': 'ee21217ffd66d058e8b16be340b74883',
-            'ext': 'flv',
+            'ext': 'mp4',
-        # youtube video
+        'md5': '4e2986c793694b55b37cf92521d12bb4',
-            'id': 'cG4CEr2aiSg',
+            'id': 'clowncar',
-            'upload_date': '20140303',
+            'title': 'It\'s like a clown car.',
-        video_id = mobj.group(1)
+        video_id = self._match_id(url)
-        'url': 'http://www.youtube.com/show/airdisasters',
+        'url': 'https://www.youtube.com/show/airdisasters',
-            'http://www.youtube.com/show/%s/playlists' % playlist_id, playlist_id, 'Downloading show webpage')
+            'https://www.youtube.com/show/%s/playlists' % playlist_id, playlist_id, 'Downloading show webpage')
-        'playlist_mincount': 3,
+        'playlist_mincount': 5,
-            url, playlist_id, 'Downloading show webpage')
+            'http://www.youtube.com/show/%s/playlists' % playlist_id, playlist_id, 'Downloading show webpage')
-    parse_duration,
+preferences = {'xl': 4, 'l': 3, 'm': 2, 's': 1, 'xs': 0,}
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        page = self._download_webpage(url, video_id, 'Downloading page')
+        json_data = self._download_json('http://www.ndr.de/%s-ppjson.json' % video_id, video_id, 'Downloading page')
-            description = description.strip()
+        formats = []
-                page, 'duration', default=None))
+        self._sort_formats(formats)
-        formats = []
+        config = json_data.get('playlist').get('config')
-            raise ExtractorError('No media links available for %s' % video_id)
+        title = config['title']
-            'thumbnail': thumbnail,
+            'thumbnails': thumbnails,
-    _VALID_URL = r'https?://www\.ndr\.de/.+?(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://www\.ndr\.de/.+?,(?P<id>\w+)\.html'
-                'id': '25866',
+                'id': 'nordmagazin25866',
-                'id': '988',
+                'id': 'hafengeburtstag988',
-            'url': 'http://www.ndr.de/info/audio51535.html',
+            'url': 'http://www.ndr.de/info/La-Valette-entgeht-der-Hinrichtung,audio51535.html',
-                'id': '51535',
+                'id': 'audio51535',
-    _VALID_URL = r'https?://www\.n-joy\.de/.+?(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://www\.n-joy\.de/.+?,(?P<id>\w+)\.html'
-ANNOTATIONS_FILE = TEST_ID + '.flv.annotations.xml'
+ANNOTATIONS_FILE = TEST_ID + '.annotations.xml'
-            'md5': '67010fdf3a08d290e060a4dd96baa07b',
+            'md5': '88e209b417f173d86186bef6e4d1f160',
-            'url': 'http://www.ceskatelevize.cz/ivysilani/ivysilani/10441294653-hyde-park-civilizace/214411058091220',
+    _VALID_URL = r'https?://www\.ceskatelevize\.cz/(porady|ivysilani)/(?:[^/]+/)*(?P<id>[^/#?]+)/*(?:[#?].*)?$'
-                'id': '214411058091220',
+                'id': '61924494876844842',
-                'skip_download': True,
+                'title': 'Queer: Bogotart (VarovÃ¡nÃ­ 18+)',
-            'url': 'http://www.ceskatelevize.cz/ivysilani/10532695142-prvni-republika/bonus/14716-zpevacka-z-duparny-bobina',
+        }, {
-                'id': '14716',
+                'id': '61924494877068022',
-                'description': 'SÃ¡ga mapujÃ­cÃ­ atmosfÃ©ru prvnÃ­ republiky od r. 1918 do r. 1945.',
+                'title': 'Queer: Bogotart (Queer)',
-                'skip_download': True,
+                'duration': 1558.3,
-    ]
+    }]
-        video_id = mobj.group('id')
+        playlist_id = mobj.group('id')
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, playlist_id)
-        episode_id = self._html_search_regex(r'getPlaylistUrl\(\[\{"type":".+?","id":"(.+?)"\}\],', webpage, 'episode_id')
+        typ = self._html_search_regex(
-        playlistpage = self._download_json(req, video_id)
+        playlistpage = self._download_json(req, playlist_id)
-        }
+        playlist_title = self._og_search_title(webpage)
-        'md5': '1f8cb3e170d41fd74add04d3c9330e5f',
+        'md5': '00a3a27ee20d44bcaa0933ccec4a2cf7',
-            'description': 'md5:82313335e8a8a3f243351ba55bc1b474',
+            'title': 'MIT DNA and Protein Sets',
-            r'ipadUrl: \'(.+?cloudfront.net/)', raw_page, 'base url')
+        base_url = self._proto_relative_url(self._search_regex(
-            media['sources']['secure_m3u8']['auto'],
+            self._proto_relative_url(media['sources']['secure_m3u8']['auto'], 'http:'),
-        'playlist_count': 4,
+        'playlist_count': 3,
-            'thumbnail': 're:https://\w+\.cloudfront\.net/6x4q2w/poster\.jpg\?t=\d+',
+            'thumbnail': 're:https?://vid\.ly/(?P<id>[0-9a-z-]+)/poster',
-            'categories': ['Main'],
+            'categories': ['Main', 'Privacy'],
-                        response.headers[set_cookie_header] = set_cookie_escaped
+        # if sys.version_info < (3, 0) and response.headers:
-                        for cookie_attr in set_cookie.decode('iso-8859-1').split(';')]).encode('iso-8859-1')
+                    set_cookie_escaped = compat_urllib_parse.quote(set_cookie, b"%/;:@&=+$,!~*'()?#[] ")
-        login_data = compat_urllib_parse.urlencode(login_form).encode('utf-8')
+        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('utf-8')
-        login_data = compat_urllib_parse.urlencode(login_form).encode('utf-8')
+        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('utf-8')
-        login_data = compat_urllib_parse.urlencode(login_form).encode('ascii')
+        login_data = compat_urllib_parse.urlencode(encode_dict(login_form_strs)).encode('ascii')
-            tfa_data = compat_urllib_parse.urlencode(tfa_form).encode('ascii')
+            tfa_data = compat_urllib_parse.urlencode(encode_dict(tfa_form_strs)).encode('ascii')
-            [r'style="z-index: [0-9]+;">([^<]+)</span>', r'>Watch (.+) '],
+            [r'style="z-index: [0-9]+;">([^<]+)</span>', r'<td nowrap>([^<]+)</td>', r'>Watch (.+) '],
-            post = compat_urllib_parse.urlencode(fields)
+            post = compat_urllib_parse.urlencode(encode_dict(fields))
-    IE_DESC = 'GorillaVid.in, daclips.in, movpod.in, fastvideo.in and realvid.net'
+    IE_DESC = 'GorillaVid.in, daclips.in, movpod.in, fastvideo.in, realvid.net and filehoot.com'
-            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net))/
+            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net|filehoot\.com))/
-        webpage = self._download_webpage('http://%s/%s' % (mobj.group('host'), video_id), video_id)
+        url = 'http://%s/%s' % (mobj.group('host'), video_id)
-            if not re.search(r'type=(["\'])hidden\1', input):
+            if not re.search(r'type=(["\'])(?:hidden|submit)\1', input):
-        # Percent-encode redirect URL of Location HTTP header to satisfy RFC 3986
+        # Percent-encode redirect URL of Location HTTP header to satisfy RFC 3986 (see
-            self.cookiejar)
+        cookie_processor = YoutubeDLCookieProcessor(self.cookiejar)
-            file_els = idoc.findall('.//files/file')
+            file_els = idoc.findall('.//files/file') or idoc.findall('./files/file')
-                        return self.url_result('http://cinematique.com/embed/%s' % video_id, 'Cinematique')
+                        # youtube-dl currently doesn't support cinematique
-    def api_request(self, url, request_url):
+    def api_request(self, url, request_path):
-        request = compat_urllib_request.Request(request_url % display_id, headers={
+        request = compat_urllib_request.Request('http://api.nowness.com/api/' + request_path % display_id, headers={
-        display_id, post = self.api_request(url, 'http://api.nowness.com/api/post/getBySlug/%s')
+        display_id, post = self.api_request(url, 'post/getBySlug/%s')
-        playlist_id, playlist = self.api_request(url, 'http://api.nowness.com/api/post?PlaylistId=%s')
+        playlist_id, playlist = self.api_request(url, 'post?PlaylistId=%s')
-        display_id, serie = self.api_request(url, 'http://api.nowness.com/api/series/getBySlug/%s')
+        display_id, serie = self.api_request(url, 'series/getBySlug/%s')
-        id = self._match_id(url)
+        display_id = self._match_id(url)
-        request = compat_urllib_request.Request(request_url % id, headers={
+        request = compat_urllib_request.Request(request_url % display_id, headers={
-        return id, json_data
+        json_data = self._download_json(request, display_id)
-    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/(story|series/[^/]+)/(?P<id>[0-9a-z-]+)'
+    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/(?:story|(?:series|category)/[^/]+)/(?P<id>[^/]+?)(?:$|[?#])'
-        post = self._download_json(request, display_id)
+        display_id, post = self.api_request(url, 'http://api.nowness.com/api/post/getBySlug/%s')
-    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/playlist/(?P<id>\d+)/[0-9a-z-]+'
+    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/playlist/(?P<id>\d+)'
-        playlist = self._download_json(request, playlist_id)
+        playlist_id, playlist = self.api_request(url, 'http://api.nowness.com/api/post?PlaylistId=%s')
-    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/series/(?P<id>[0-9a-z-]+)'
+    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/series/(?P<id>[^/]+?)(?:$|[?#])'
-        serie = self._download_json(request, display_id)
+        display_id, serie = self.api_request(url, 'http://api.nowness.com/api/series/getBySlug/%s')
-if sys.version_info > (2, 7, 2):
+if sys.version_info >= (2, 7, 3):
-    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/(story|series/[^/])/(?P<id>[0-9a-z-]+)'
+    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/(story|series/[^/]+)/(?P<id>[0-9a-z-]+)'
-        request = compat_urllib_request.Request('https://api.nowness.com/api/series/getBySlug/%s' % display_id, headers={
+        request = compat_urllib_request.Request('http://api.nowness.com/api/series/getBySlug/%s' % display_id, headers={
-            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source[^>]*)?\s+src=["\'](.*?)["\']', webpage)
+            found = re.findall(r'(?s)<(?:video|audio)[^<]*(?:>.*?<source[^>]*)?\s+src=["\'](.*?)["\']', webpage)
-    def test_compat_shlex(self):
+    def test_compat_shlex_split(self):
-import shlex
+    compat_shlex_split,
-                res += shlex.split(l, comments=True)
+                res += compat_shlex_split(l, comments=True)
-import shlex
+    compat_shlex_split,
-        external_downloader_args = shlex.split(opts.external_downloader_args)
+        external_downloader_args = compat_shlex_split(opts.external_downloader_args)
-        postprocessor_args = shlex.split(opts.postprocessor_args)
+        postprocessor_args = compat_shlex_split(opts.postprocessor_args)
-from .nowness import NownessIE
+from .nowness import (
-
+from ..compat import compat_urllib_request
-    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/[^?#]*?/(?P<id>[0-9]+)/(?P<slug>[^/]+?)(?:$|[?#])'
+class NownessIE(NownessBaseIE):
-            'url': 'http://www.nowness.com/day/2013/6/27/3131/candor--the-art-of-gesticulation',
+            'url': 'https://www.nowness.com/story/candor-the-art-of-gesticulation',
-            'url': 'http://cn.nowness.com/day/2014/8/7/4069/kasper-bj-rke-ft-jaakko-eino-kalevi--tnr',
+            'url': 'https://cn.nowness.com/story/kasper-bjorke-ft-jaakko-eino-kalevi-tnr',
-        video_id = mobj.group('slug')
+        display_id = self._match_id(url)
-            r'\sdata-videoId="([0-9]+)"', webpage, 'internal video ID')
+        lang = 'zh-cn' if 'cn.nowness.com' in url else 'en-us'
-        }
+class NownessSerieIE(NownessBaseIE):
-        self.params = params
+        self.params = {
-            ie_key = 'DCNVideo'
+            return self.url_result('http://www.dcndigital.ae/#/media/%s' % video_id, 'DCNVideo')
-        }
+            return self.url_result(url, 'DCNSeason')
-            'title': 'Dubai Al Oula',
+            'title': 're:^Dubai Al Oula [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-            + compat_urllib_parse.urlencode({
+            'http://admin.mangomolo.com/analytics/index.php/customers/embed/index?' +
-            'title': title,
+            'title': self._live_title(title),
-            'description': '',
+
-        description = show['cat'].get('description_en') or show['cat'].get('description_ar')
+        season = {}
-        }
+            entries.append(self.url_result('http://www.dcndigital.ae/#/media/%s' % video['id'], 'DCNVideo'))
-        return cli_configuration_args(self.params, 'postprocessor_args', default)
+        return cli_configuration_args(self._downloader.params, 'postprocessor_args', default)
-            + compat_urllib_parse.urlencode({
+            'http://admin.mangomolo.com/analytics/index.php/customers/embed/video?' +
-        
+
-        return pp_args
+        return cli_configuration_args(self.params, 'postprocessor_args', default)
-        return [command_option, param]
+        return cli_option(self.params, command_option, param)
-        return [command_option, true_value if param else false_value]
+        return cli_bool_option(self.params, command_option, param, true_value, false_value, separator)
-        return [command_option] if param == expected_value else []
+        return cli_valueless_option(self.params, command_option, param, expected_value)
-        return ex_args
+        return cli_configuration_args(self.params, 'external_downloader_args', default)
-        if param is None or param is False:
+        if param is None:
-    def _argless_option(self, command_option, param, expected_value=True):
+    def _valueless_option(self, command_option, param, expected_value=True):
-        cmd += self._argless_option('--insecure', 'nocheckcertificate')
+        cmd += self._valueless_option('--insecure', 'nocheckcertificate')
-        cmd += self._argless_option('--no-check-certificate', 'nocheckcertificate')
+        cmd += self._valueless_option('--no-check-certificate', 'nocheckcertificate')
-            return [command_option]
+    def _argless_option(self, command_option, param, expected_value=True):
-        cmd += self._option('--insecure', 'nocheckcertificate')
+        cmd += self._argless_option('--insecure', 'nocheckcertificate')
-        cmd += self._option('--no-check-certificate', 'nocheckcertificate')
+        cmd += self._argless_option('--no-check-certificate', 'nocheckcertificate')
-            'url': 'http://www.ruutu.fi/ohjelmat/superpesis/superpesis-katso-koko-kausi-ruudussa',
+            'url': 'http://www.ruutu.fi/video/2057306',
-        cmd += self._option('--check-certificate=false', 'nocheckcertificate')
+        cmd += self._bool_option('--check-certificate', 'nocheckcertificate', 'false', 'true', '=')
-    if n is None or n.text is None:
+    if n is None:
-    return xpath_element(node, xpath, name, fatal=fatal, default=default).text
+    n = xpath_element(node, xpath, name, fatal=fatal, default=default)
-    _VALID_URL = r'http://(?:www\.)?ruutu\.fi/ohjelmat/(?:[^/?#]+/)*(?P<id>[^/?#]+)'
+    _VALID_URL = r'https?://(?:www\.)?ruutu\.fi/video/(?P<id>\d+)'
-            'url': 'http://www.ruutu.fi/ohjelmat/oletko-aina-halunnut-tietaa-mita-tapahtuu-vain-hetki-ennen-lahetysta-nyt-se-selvisi',
+            'url': 'http://www.ruutu.fi/video/2058907',
-                'description': 'md5:44c44a99fdbe5b380ab74ebd75f0af77',
+                'description': 'md5:da2736052fef3b2bd5e0005e63c25eac',
-        display_id = self._match_id(url)
+        video_id = self._match_id(url)
-        video_xml = self._download_xml(video_xml_url, video_id)
+        video_xml = self._download_xml(
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'title': xpath_attr(video_xml, './/Behavior/Program', 'program_name', 'title', fatal=True),
-        assert re.match(r'^[a-zA-Z-]+$', key)
+        assert re.match(r'^[a-zA-Z_-]+$', key)
-def xpath_text(node, xpath, name=None, fatal=False, default=NO_DEFAULT):
+def xpath_element(node, xpath, name=None, fatal=False, default=NO_DEFAULT):
-    return n.text
+    return n
-    _VALID_URL = r'https?://(?:www\.)?dcndigital\.ae/(?:#/)?(?:video/[^/]+|media)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?dcndigital\.ae/(?:#/)?(?:video/[^/]+|media|catchup/[^/]+/[^/]+)/(?P<id>\d+)'
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:ch|sx|eu|at|ag|co|li)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:ch|ec|sx|eu|at|ag|co|li)'}
-        if param is None:
+        if param is None or param is False:
-    DCNShowIE,
+    DCNSeasonIE,
-            ie_key = 'DCNShow'
+            ie_key = 'DCNSeason'
-                url = 'http://www.dcndigital.ae/#/program/season/%s' % season_id
+                url = smuggle_url('http://www.dcndigital.ae/#/program/season/%s' % season_id, {'show_id': show_id})
-class DCNShowIE(InfoExtractor):
+class DCNSeasonIE(InfoExtractor):
-            'id': '205024',
+            'id': '7910',
-            show_id = season['id']
+            show_id = smuggled_data.get('show_id')
-            'id': show_id,
+            'id': season_id,
-                    formats.append({
+                    format_info.update({
-                        'format_id': video_format,
+                    formats.append(format_info)
-            formats.append({
+            format_info.update({
-                'format_id': video_format,
+            formats.append(format_info)
-__version__ = '2015.08.28'
+__version__ = '2015.09.03'
-from .dcn import DCNIE
+from .dcn import (
-    _VALID_URL = r'https?://(?:www\.)?dcndigital\.ae/(?:#/)?(?:video/.+|show/\d+/.+?)/(?P<id>\d+)'
+class DCNGeneralIE(InfoExtractor):
-        'url': 'http://www.dcndigital.ae/#/show/199074/%D8%B1%D8%AD%D9%84%D8%A9-%D8%A7%D9%84%D8%B9%D9%85%D8%B1-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-1/17375/6887',
+        'url': 'http://www.dcndigital.ae/#/video/%D8%B1%D8%AD%D9%84%D8%A9-%D8%A7%D9%84%D8%B9%D9%85%D8%B1-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-1/17375',
-        return {
+        info = {
-            'formats': formats,
+
-                r'data-options="([^"]+%s[^"]+)"' % video_id, webpage, 'player')),
+                r'data-options=(?P<quote>["\'])(?P<player>{.+?%s.+?})(?P=quote)' % video_id,
-                r'data-options="([^"]+)"', webpage, 'player')),
+                r'data-options="([^"]+%s[^"]+)"' % video_id, webpage, 'player')),
-from ..compat import compat_urlparse
+from ..compat import compat_urllib_request, compat_urlparse
-        png = self._download_webpage(png_url, video_id, 'Downloading url information')
+        png_request = compat_urllib_request.Request(png_url)
-            'md5': '78f0f4064f9074438e660785bbf2c5d9',
+            'url': 'http://www.france5.fr/emissions/c-a-dire/videos/quels_sont_les_enjeux_de_cette_rentree_politique__31-08-2015_908948?onglet=tous&page=1',
-                'id': '108961659',
+                'id': '123327454',
-                'timestamp': 1410795000,
+                'description': 'md5:4a0d5cb5dce89d353522a84462bae5a4',
-                'title': 'C Ã  dire ?!',
+                'title': 'C Ã  dire ?! - Quels sont les enjeux de cette rentrÃ©e politique ?',
-            'title': info['titre'],
+            'title': title,
-        help='Video password (vimeo, smotri)')
+        help='Video password (vimeo, smotri, youku)')
-            'ext': 'flv',
+        'playlist_count': 19,
-            'title': u'é¢ç¾©ç°å¤æ¦è®²åº§ä¹æ³è±¡ä¸­çè¡äººâä»âå·¦è¡½å­å­âè¯´èµ·',
+            'title': 'é¢ç¾©ç°å¤æ¦è®²åº§ä¹æ³è±¡ä¸­çè¡äººâä»âå·¦è¡½å­å­âè¯´èµ·',
-            basic_data_url = '%s?password=%s' % (basic_data_url, video_password)
+            basic_data_url += '?password=%s' % video_password
-                'Downloading JSON metadata 1')
+            basic_data_url = '%s?password=%s' % (basic_data_url, video_password)
-            'Downloading JSON metadata 1')
+        if video_password:
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?dumpert\.nl/(?:mediabase|embed)/(?P<id>[0-9]+/[0-9a-zA-Z]+)'
-    }
+    }, {
-
+        duration = float_or_none(video.get('duration'), 1000)
-    _VALID_URL = r'https?://(?:odnoklassniki|ok)\.ru/(?:video|web-api/video/moviePlayer)/(?P<id>[\d-]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:odnoklassniki|ok)\.ru/(?:video|web-api/video/moviePlayer)/(?P<id>[\d-]+)'
-                r'data-attributes="([^"]+)"', webpage, 'player')),
+                r'data-options="([^"]+)"', webpage, 'player')),
-        refer = url.replace('/content/', '/a/content/')
+        refer = url.replace('/content/', '/a/content/') if '/a/content/' not in url else url
-    _VALID_URL = r'^http://video\.fc2\.com/(?:[^/]+/)?content/(?P<id>[^/]+)'
+    _VALID_URL = r'^http://video\.fc2\.com/(?:[^/]+/)*content/(?P<id>[^/]+)'
-            r'<span class="name">([^<>]+)</span>', webpage, 'creator')
+            r'<span[^>]+class="name">([^<>]+)</span>', webpage, 'creator')
-            raise ExtractorError(playinfo['message'])
+            raise ExtractorError(playinfo.get('message', 'JSON request unsuccessful'))
-            frags_filenames.append(frag_filename)
+            down, frag_sanitized = sanitize_open(frag_filename, 'rb')
-            os.remove(frag_file)
+            os.remove(encodeFilename(frag_file))
-                    with open(thumb_filename, 'wb') as thumbf:
+                    with open(encodeFilename(thumb_filename), 'wb') as thumbf:
-from .imgur import ImgurIE
+from .imgur import (
-    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?P<id>[a-zA-Z0-9]+)'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?!gallery)(?P<id>[a-zA-Z0-9]+)'
-                format_url = {
+                # Some itags are not included in DASH manifest thus corresponding formats will
-                    'tbr': float_or_none(url_data.get('bitrate', [None])[0], scale=1024),
+                    'tbr': float_or_none(url_data.get('bitrate', [None])[0], 1000),
-
+                type_ = url_data.get('type', [None])[0]
-            url_map = {}
+            formats = []
-            formats = _map_to_format_list(url_map)
+
-            'filesize': int(url_info['filesize']),
+            'width': int_or_none(url_info.get('width')),
-import json
+from ..utils import (
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        urls_info = json.loads(urls_info_json.replace('\'', '"'))
+        mobj = re.search(
-                        (?:www|cdnapisec)\.)?kaltura\.com/
+                        (:?(?:www|cdnapisec)\.)?kaltura\.com/
-                                # html player
+                                # html5 player
-    (?:\?wid=_(?P<partner_id_html5>\d+))?'''
+                (?:
-        partner_id, entry_id = mobj.group('partner_id') or mobj.group('partner_id_html5'), mobj.group('id')
+        partner_id = mobj.group('partner_id_s') or mobj.group('partner_id') or mobj.group('partner_id_html5')
-            'id': video_id,
+            'id': entry_id,
-    )(?P<id>[0-9a-z_]+)'''
+        https?://(:?(?:www|cdnapisec)\.)?kaltura\.com/(?:
-        partner_id, entry_id = mobj.group('partner_id'), mobj.group('id')
+        partner_id, entry_id = mobj.group('partner_id') or mobj.group('partner_id_html5'), mobj.group('id')
-            webpage)
+        mobj = re.search(ScreenwaveMediaIE.EMBED_PATTERN, webpage)
-                'ScreenwaveMedia')
+            return self.url_result(unescapeHTML(mobj.group('url')), 'ScreenwaveMedia')
-                r'<iframe[^>]+src="((?:https?:)?//(?:[^.]+\.)?youtube\.com/.+?)"',
+                ScreenwaveMediaIE.EMBED_PATTERN,
-            webpage, 'player data URL', default=None)
+            webpage, 'player data URL', default=None, group='url')
-    _VALID_URL = r'http://player\d?\.screenwavemedia\.com/(?:play/)?[a-zA-Z]+\.php\?[^"]*\bid=(?P<id>.+)'
+    _VALID_URL = r'https?://player\d?\.screenwavemedia\.com/(?:play/)?[a-zA-Z]+\.php\?.*\bid=(?P<id>[A-Za-z0-9-]+)'
-
+    EMBED_PATTERN = r'src=(["\'])(?P<url>(?:https?:)?//player\d?\.screenwavemedia\.com/(?:play/)?[a-zA-Z]+\.php\?.*\bid=.+?)\1'
-        videoserver = self._search_regex(r"\[ipaddress\]\s*=>\s*([\d\.]+)", playerdata, 'videoserver')
+        videoserver = self._search_regex(r'SWMServer\s*=\s*"([\d\.]+)"', playerdata, 'videoserver')
-            title_el = itemdoc.find('.//title')
+            title_el = itemdoc.find('.//title') or itemdoc.find('./title')
-        if re.match(r'.*/(error_country_block\.swf|geoblock\.mp4)$', mdoc.find('.//src').text) is not None:
+        if re.match(r'.*/(error_country_block\.swf|geoblock\.mp4|copyright_error\.flv(?:\?geo\b.+?)?)$', mdoc.find('.//src').text) is not None:
-    _VALID_URL = r'https?://(?:www\.)?mtv\.de/(?:artists|shows)/(?:[^/]+/)+(?P<id>\d+)-[^/#?]+/*(?:[#?].*)?$'
+    _VALID_URL = r'https?://(?:www\.)?mtv\.de/(?:artists|shows|news)/(?:[^/]+/)*(?P<id>\d+)-[^/#?]+/*(?:[#?].*)?$'
-            mediagen_url += '&acceptMethods=fms'
+            mediagen_url += '&' if '?' in mediagen_url else '?'
-            info_url, video_id,
+            url, video_id,
-            },
+    _VALID_URL = r'https?://(?:www\.)?mtv\.de/(?:artists|shows)/(?:[^/]+/)+(?P<id>\d+)-[^/#?]+/*(?:[#?].*)?$'
-    ]
+        'params': {
-        return self._get_videos_info(url, mobj.group('video_path'))
+        video_id = self._match_id(url)
-            [self._get_video_info(item) for item in idoc.findall('.//item')])
+            item_id = item.get('id')
-__version__ = '2015.08.23'
+__version__ = '2015.08.28'
-    _VALID_URL = r'https?://video\.fox(?:news|business)\.com/v/(?:video-embed\.html\?video_id=)?(?P<id>\d+)'
+    _VALID_URL = r'https?://(?P<host>video\.fox(?:news|business)\.com)/v/(?:video-embed\.html\?video_id=)?(?P<id>\d+)'
-        m = re.match(r'^https?://video\.fox(news|business)', url)
+        mobj = re.match(self._VALID_URL, url)
-            'http://video.fox' + m.group(1) + '.com/v/feed/video/%s.js?template=fox' % video_id, video_id)
+            'http://%s/v/feed/video/%s.js?template=fox' % (host, video_id), video_id)
-    _VALID_URL = r'https?://video\.foxnews\.com/v/(?:video-embed\.html\?video_id=)?(?P<id>\d+)'
+    _VALID_URL = r'https?://video\.fox(?:news|business)\.com/v/(?:video-embed\.html\?video_id=)?(?P<id>\d+)'
-            'http://video.foxnews.com/v/feed/video/%s.js?template=fox' % video_id, video_id)
+            'http://video.fox' + m.group(1) + '.com/v/feed/video/%s.js?template=fox' % video_id, video_id)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'http://shared\.sx/(?P<id>[\da-z]{10})'
+    _VALID_URL = r'http://(?:shared|vivo)\.sx/(?P<id>[\da-z]{10})'
-            self.raise_login_required(video_id)
+            self.raise_login_required()
-                expected=True)
+            self.raise_login_required('Udemy account is required')
-                'options to provide account credentials.', expected=True)
+            self.raise_login_required('This video requires login')
-                    expected=True)
+                self.raise_login_required('Erotic broadcasts allowed only for registered users')
-                expected=True)
+            self.raise_login_required('safaribooksonline.com account is required')
-                expected=True)
+            self.raise_login_required('Pluralsight account is required')
-                % video_id + self._ACCOUNT_CREDENTIALS_HINT, expected=True)
+            self.raise_login_required('Video %s is only available for members' % video_id)
-                'This video requires login. Please specify a username and password and try again.', expected=True)
+            self.raise_login_required('This video requires login')
-                expected=True)
+            self.raise_login_required(video_id)
-        note_m = self._html_search_regex(r'<div class="showmedia-trailer-notice">(.+?)</div>', webpage, 'trailer-notice', default='')
+        note_m = self._html_search_regex(
-            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player)?\.(?P<ext>[a-z]+)$',
+            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?)?\.(?P<ext>[a-z]+)$',
-                                    r'html5player-([^/]+?)(?:/html5player)?\.js',
+                                    r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\.js',
-from ..compat import compat_str
+from ..compat import (
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        playlist = self._parse_json(
+        mu = self._parse_json(
-            playlist_id)['pageData']['playlist']
+            playlist_id)
-            self._build_playlist(playlist['tracks']),
+            self._build_playlist(tracks),
-            for track in tracks]
+            for track in tracks if track.get('albums') and isinstance(track.get('albums'), list)]
-
+        
-
+        msgpad = '%.0f' % (time() * 1000)
-__version__ = '2015.08.16.1'
+__version__ = '2015.08.23'
-class YandexMusicBaseIE(InfoExtractor):
+class YandexMusicTrackIE(InfoExtractor):
-# coding=utf-8
+# coding: utf-8
-class YandexMusicAlbumIE(YandexMusicBaseIE):
+class YandexMusicPlaylistBaseIE(InfoExtractor):
-        entries = [self._get_track_info(track) for track in album['volumes'][0]]
+        entries = self._build_playlist(album['volumes'][0])
-class YandexMusicPlaylistIE(YandexMusicBaseIE):
+class YandexMusicPlaylistIE(YandexMusicPlaylistBaseIE):
-            entries, compat_str(playlist_id),
+            self._build_playlist(playlist['tracks']),
-            r'by:\s*<a href="/user/viewProfile\?.*?UserId=(\d+).*?"',
+            r'by:\s*<a href="/(?:user/viewProfile|Profile\.aspx)\?.*?UserId=(\d+).*?"',
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>spankwire\.com/[^/]*/video(?P<videoid>[0-9]+)/?)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>spankwire\.com/[^/]*/video(?P<id>[0-9]+)/?)'
-        url = 'http://www.' + mobj.group('url')
+        video_id = mobj.group('id')
-        req = compat_urllib_request.Request(url)
+        req = compat_urllib_request.Request('http://www.' + mobj.group('url'))
-              }]
+        # download URL pattern: */<height>P_<tbr>K_<video_id>.mp4
-            re.findall(r'playerData\.cdnPath[0-9]{3,}\s*=\s*(?:encodeURIComponent\()?["\']([^"\']+)["\']', webpage)))
+        videos = re.findall(
-        for video_url in video_urls:
+        for height, video_url in zip(heights, video_urls):
-                    'format_id': format,
+            _, quality = path.split('/')[4].split('_')[:2]
-                })
+                f['format_id'] = quality
-    }
+    _TESTS = [{
-            })
+            if format[0] == 'mp4':
-            r'by:\s*<a href="/Profile\.aspx\?.*?UserId=(\d+).*?"',
+            r'by:\s*<a href="/user/viewProfile\?.*?UserId=(\d+).*?"',
-from ..utils import int_or_none
+from ..utils import (
-        video_url = self._html_search_regex(
+        video_url = self._search_regex(
-            r"preview_url\s*:\s*'(.+?)/?',", webpage, 'video thumbnail', fatal=False)
+        thumbnail = self._search_regex(
-            r'<title>(.+?)</title>', webpage, 'video title')
+            r'(?s)<h2>(.+?)</h2>', webpage, 'title')
-            'description', webpage, 'video description')
+            'description', webpage, 'description')
-        duration = int(mobj.group('minutes')) * 60 + int(mobj.group('seconds')) if mobj else None
+        duration = self._search_regex(
-            r'<div class="col_2">ÐÑÐ¾ÑÐ¼Ð¾ÑÑÐ¾Ð²: <span>(\d+)</span></div>',
+        view_count = self._search_regex(
-                comment_count = mobj.group('total')
+        comment_count = int_or_none(self._search_regex(
-    _ACCOUNT_CREDENTIALS_HINT = 'Use --username and --password options to provide lynda.com account credentials.'
+from .pluralsight import (
-        'playlist_mincount': 112,
+        'playlist_mincount': 111,
-        'playlist_mincount': 9,
+        'playlist_mincount': 7,
-        'playlist_mincount': 333,
+        'playlist_mincount': 321,
-    def _merge_subtitles(kls, subtitle_dict1, subtitle_dict2):
+    def _merge_subtitles(cls, subtitle_dict1, subtitle_dict2):
-            ret[lang] = kls._merge_subtitle_items(subtitle_dict1.get(lang, []), subtitle_dict2[lang])
+            ret[lang] = cls._merge_subtitle_items(subtitle_dict1.get(lang, []), subtitle_dict2[lang])
-        'md5': 'ffcd517d2805b57ce11a58a2980c2b02',
+import re
-            r'vivi_id\s*:\s*([0-9]+)', webpage, 'vivi_id')
+        mobj = re.search(
-        webpage = self._download_webpage(info_url, '')
+        'params': {
-        print(ret)
+    ThePlatformFeedIE,
-    def _extract_theplatform_smil_formats(self, smil_url, video_id, note='Downloading SMIL data'):
+    def _extract_theplatform_smil(self, smil_url, video_id, note='Downloading SMIL data'):
-        return formats
+        subtitles = self._parse_smil_subtitles(meta, default_ns)
-        formats = self._extract_theplatform_smil_formats(smil_url, video_id)
+        formats, subtitles = self._extract_theplatform_smil(smil_url, video_id)
-            formats.extend(self._extract_theplatform_smil_formats(smil_url, video_id, 'Downloading SMIL data for %s' % cur_video_id))
+            cur_formats, cur_subtitles = self._extract_theplatform_smil(smil_url, video_id, 'Downloading SMIL data for %s' % cur_video_id)
-            lang = textstream.get('systemLanguage') or textstream.get('systemLanguageName') or subtitles_lang
+            lang = textstream.get('systemLanguage') or textstream.get('systemLanguageName') or textstream.get('lang') or subtitles_lang
-        info = json.loads(info_json)
+        info = self._download_json(info_url, video_id)
-                    ext = 'srt'
+                SUBTITLES_TYPES = {
-    def _parse_smil_subtitles(self, smil, namespace=None):
+    def _parse_smil_subtitles(self, smil, namespace=None, subtitles_lang='en'):
-            lang = textstream.get('systemLanguage') or textstream.get('systemLanguageName')
+            lang = textstream.get('systemLanguage') or textstream.get('systemLanguageName') or subtitles_lang
-from .theplatform import ThePlatformIE
+from .theplatform import (
-class ThePlatformIE(InfoExtractor):
+class ThePlatformBaseIE(InfoExtractor):
-            raise ExtractorError(error_msg, expected=True)
+        formats = self._extract_theplatform_smil_formats(smil_url, video_id)
-        info = json.loads(info_json)
+        ret = self.get_metadata(path, video_id)
-                }]
+        return ret
-                _format['ext'] = 'mp4'
+class ThePlatformFeedIE(ThePlatformBaseIE):
-        return {
+        thumbnails = [{
-        }
+            'thumbnails': thumbnails,
-    _TESTS = [{
+    _TEST = {
-            'creator': 'M COUNTDOWN',
+            'thumbnail': 're:^https?://.*\.jpg$',
-    }]
+    }
-        stream_info = self._download_json(
+        vod_info = self._download_json(
-            'Download stream info')
+            video_id, 'Download vod JSON')
-            f4m_stream = self._download_json(info['url'], video_id, 'Download f4m stream')
+        for num, cdn_info in enumerate(vod_info['cdn']):
-                self._extract_f4m_formats(f4m_stream['fileurl'] + '&g=PCROWKHLYUDY&hdcore=3.0.3', video_id))
+                self._extract_f4m_formats(f4m_url + '&hdcore=3.0.3', video_id, f4m_id=stream_name))
-            'creator': stream_info.get('program_title'),
+            'title': vod_info['title'],
-    def _parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None):
+    def _parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None):
-_x = lambda p: xpath_with_ns(p, {'smil': 'http://www.w3.org/2005/SMIL21/Language'})
+default_ns = 'http://www.w3.org/2005/SMIL21/Language'
-                f4m_url += '?'
+        formats = self._parse_smil_formats(
-            self._sort_formats(formats)
+            f4m_params={'g': 'UXWGVKRWHFSP', 'hdcore': '3.0.3'},
-        }
+    compat_urlparse,
-            parsed_url._replace(query = compat_urllib_parse.urlencode(qs, True)))
+            parsed_url._replace(query=compat_urllib_parse.urlencode(qs, True)))
-    _LOGIN_POST_URL = 'https://passport.twitch.tv/authorize'
+    _LOGIN_POST_URL = 'https://passport.twitch.tv/authentications/new'
-            self._LOGIN_POST_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            post_url, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
-    _VALID_URL = r'https?://www\.telecinco\.es/[^/]+/[^/]+/(?:[^/]+/)?(?P<id>.*?)\.html'
+    _VALID_URL = r'https?://www\.telecinco\.es/(?:[^/]+/)+(?P<id>.+?)\.html'
-    _VALID_URL = r'https?://html5-player\.libsyn\.com/embed/episode/id/(?P<id>[0-9]+)'
+    _VALID_URL = r'(?P<mainurl>https?://html5-player\.libsyn\.com/embed/episode/id/(?P<id>[0-9]+))'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-
+        m = re.match(self._VALID_URL, url)
-            r'<h2>([^<]+)</h2>', webpage, 'title')
+            r'<h2>([^<]+)</h2>', webpage, 'podcast title', default=None)
-            r'<h3>([^<]+)</h3>', webpage, 'title', default=None)
+            r'(?:<div class="episode-title">|<h3>)([^<]+)</', webpage, 'episode title')
-
+            'description', default=None)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'view_count': info['views'],
+            'description': info.get('description'),
-            'title': info['title'],
+            'title': info.get('title') or 'Untitled Broadcast',
-__version__ = '2015.08.16'
+__version__ = '2015.08.16.1'
-        api_url = 'http://splink.tv/api/permalinks/%s/%s' % (
+        api_url = 'http://proxy.vidibusdynamic.net/sportdeutschland.tv/api/permalinks/%s/%s?access_token=true' % (
-        assets_info = self._download_json(asset['url'], video_id)
+        categories = [data['section']['title']]
-        smil_url = assets_info['video']
+        smil_url = asset['video']
-                         |youtu\.be/                                          # just youtu.be/xxxx
+                         |(?:
-            r'(?s)<h3 class="yt-lockup-title">(.*?)</h3>', result_code)
+            r'(?s)<h3[^>]+class="[^"]*yt-lockup-title[^"]*"[^>]*>(.*?)</h3>', result_code)
-            video_id
+            video_id, fatal=False
-        quality = qualities(['low', 'middle', 'high'])
+        quality = qualities(('low', 'middle', 'high'))
-            if format_ in ['mp4', 'webm']:
+            if format_ in ('mp4', 'webm'):
-                    video_id
+                re.sub(
-            'description': self._og_search_description(webpage),
+            'description': description,
-__version__ = '2015.08.09'
+__version__ = '2015.08.16'
-        r'(?s)^VideoPlayer.data\("", ({.*})\);?\s*?(?://[^\n]*)*$', r'\1', code)
+from ..utils import (
-    _VALID_URL = r'https?://.*?(playtvak|idnes|lidovky|metro)\.cz/.*\?c=(?P<id>[A-Z][0-9]{6}_[0-9]{6}_.*)'
+    IE_DESC = 'Playtvak.cz, iDNES.cz and Lidovky.cz'
-            'description': 'MÃ¡lo co kazÃ­ atmosfÃ©ru venkovnÃ­ho posezenÃ­ tak jako neustÃ¡lÃ© bzuÄenÃ­ kolem hlavy.  VyzkouÅ¡ejte nÃ¡Å¡ lapaÄ a odpuzovaÄ vos a srÅ¡ÅÅ¯.',
+            'description': 'md5:f93d398691044d303bc4a3de62f3e976',
-            'thumbnail': 'http://data.idnes.cz/soubory/servisni-play-porady/89A150630_ACEK_026_VIDEOPLAYER-STREA.PNG',
+            'thumbnail': 're:(?i)^https?://.*\.(?:jpg|png)$',
-            'description': 'Na sociÃ¡lnÃ­ch sÃ­tÃ­ch se objevila vÃ½zva, aby lidÃ©, kteÅÃ­ v horkÃ½ch letnÃ­ch dnech uvidÃ­ v zaparkovanÃ©m autÄ zavÅenÃ©ho psa, nevÃ¡hali rozbÃ­t okÃ©nko. ZastÃ¡nci tohoto postoje argumentujÃ­ zdravÃ­m zvÃ­Åete, kterÃ© v dusnu mÅ¯Å¾e zkolabovat. Policie doporuÄuje nejprve volat tÃ­sÅovou linku.',
+            'description': 'md5:01e73f02329e2e5760bd5eed4d42e3c2',
-            'description': 'DesÃ­tky lidÃ­ se seÅ¡ly v Praze na protest proti imigrantÅ¯m. SouÄasnÄ probÃ­hala i demonstrace na jejich podporu. Na StaromÄstskÃ©m nÃ¡mÄstÃ­ vystoupil i pÅedseda dÄlnickÃ© strany TomÃ¡Å¡ Vandas a kontroverznÃ­ slovenskÃ½ politik Marian Kotleba. DalÅ¡Ã­ho slovenskÃ©ho nacionalistu MariÃ¡na MagÃ¡ta odvedla policie.',
+            'description': 'md5:97c81d589a9491fbfa323c9fa3cca72c',
-        jsoninfo = self._download_json(infourl, video_id, transform_source=_extract_json)
+
-            if i['type'] == 'video' or i['type'] == 'stream':
+        for i in json_info['items']:
-        if item is None:
+        if not item:
-            title = self._live_title(title)
+
-                format_entry['protocol'] = 'm3u8'
+            video_url = fmt.get('file')
-                format_entry['ext'] = 'flv'
+                preference = -1
-
+            formats.append({
-            'thumbnail': thumbnail,
+            'thumbnail': item.get('image'),
-            tfa_code = self._get_tfa_info()
+            tfa_code = self._get_tfa_info('2-step verification code')
-                self._downloader.report_warning('(Note that only TOTP (Google Authenticator App) codes work at this time.)')
+            if not tfa_code:
-                'gxf': gxf,
+            tfa_code = remove_start(tfa_code, 'G-')
-            }
+            })
-                self._downloader.report_warning('Two-factor code expired. Please try again, or use a one-use backup code instead.')
+                self._downloader.report_warning('Two-factor code expired or invalid. Please try again, or use a one-use backup code instead.')
-    def _get_tfa_info(self):
+    def _get_tfa_info(self, note='two-factor verification code'):
-        return None
+        return compat_getpass('Type %s and press [Return]: ' % note)
-        ])
+        hidden_inputs = {}
-    _TWOFACTOR_URL = 'https://accounts.google.com/SecondFactor'
+    _TWOFACTOR_URL = 'https://accounts.google.com/signin/challenge'
-        if re.search(r'(?i)<form[^>]* id="gaia_secondfactorform"', login_results) is not None:
+        if re.search(r'(?i)<form[^>]* id="challenge"', login_results) is not None:
-            # Unlike the first login form, secTok and timeStmp are both required for the TFA form
+            def find_value(element_id):
-            timeStmp = match.group(1)
+            challengeId = find_value('challengeId')
-                'timeStmp': timeStmp,
+                'checkedDomains': 'youtube',
-            if re.search(r'(?i)<form[^>]* id="gaia_secondfactorform"', tfa_results) is not None:
+            if re.search(r'(?i)<form[^>]* id="challenge"', tfa_results) is not None:
-    int_or_none
+    int_or_none,
-            }
+    _TESTS = [{
-            'only_matching': True
+        'params': {
-    ]
+    }, {
-    }
+    def _handle_error(self, response):
-                        self._api_vars[key] = player_info[key]
+        api_vars = {
-        formats = self._extract_m3u8_formats(m3u8_url, video_id)
+        formats = self._extract_m3u8_formats(player['url'], video_id, 'mp4')
-        duration = int_or_none(video_info.get('duration'))
+        video = self._download_json(
-            'categories': categories,
+            'thumbnail': thumbnail,
-from .videoesri import VideoEsriIE
+from .esri import EsriVideoIE
-class VideoEsriIE(InfoExtractor):
+class EsriVideoIE(InfoExtractor):
-
+from ..compat import compat_urlparse
-    unified_strdate
+    int_or_none,
-        'md5': '170b4d513c2466ed483c150a48384133',
+        'url': 'https://video.esri.com/watch/1124/arcgis-online-_dash_-developing-applications',
-            'id': '4228',
+            'id': '1124',
-            'title': 'AppStudio for ArcGIS',
+            'title': 'ArcGIS Online - Developing Applications',
-            'upload_date': '20150310',
+            'duration': 185,
-        video_paths = re.findall(r'mp4:(.*)\'', settings_info)
+        webpage = self._download_webpage(url, video_id)
-            r'netstreambasepath\':\s\'(h.*)\'', settings_info)[0]
+        formats = []
-            }
+        duration = int_or_none(self._search_regex(
-                formats.append(videos_by_res[height])
+        upload_date = unified_strdate(self._html_search_meta(
-        result = {
+        return {
-            'formats': formats,
+            'formats': formats
-                    (?=[^>]+(?:itemprop|name|property|id)=(["\']?)%s\1)
+                    (?=[^>]+(?:itemprop|name|property|id|http-equiv)=(["\']?)%s\1)
-from ..utils import ExtractorError
+from ..utils import (
-        video_id = self._match_id(url)
+        orig_video_id = self._match_id(url)
-            'id': video_id,
+            'id': video.get('id') or video_id,
-    _TEST = {
+    _VALID_URL = r'https?://(?:.+?\.)?indavideo\.hu/video/(?P<id>[^/#?]+)'
-    }
+    }, {
-from .indavideo import IndavideoIE
+from .indavideo import (
-            },
+class IndavideoEmbedIE(InfoExtractor):
-    ]
+    }, {
-        webpage = self._download_webpage(url, video_disp_id)
+        video_id = self._match_id(url)
-        video_hash = embed_url.split('/')[-1]
+        video_urls = video.get('video_files', [])
-        video_info = payload['data']
+        video_prefix = video_urls[0].rsplit('/', 1)[0]
-            thumbnails = [{'url': self._proto_relative_url(x)} for x in thumbnails]
+        for flv_file in video.get('flv_files', []):
-            tags = [x['title'] for x in tags]
+        formats = [{
-            'display_id': video_disp_id,
+            'id': video_id,
-            'age_limit': utils.int_or_none(video_info.get('age_limit')),
+            'uploader': video.get('user_name'),
-            smil_url = config['releaseUrl'] + '&format=SMIL&formats=MPEG4&manifest=f4m'
+            if 'releaseUrl' in config:
-)
+from ..utils import parse_duration
-        enc_key = '3601ba290e4f4662848c710e2122007e'	# last update at 2015-08-10 for Zombie
+        enc_key = '3601ba290e4f4662848c710e2122007e'  # last update at 2015-08-10 for Zombie
-)
+from ..utils import ExtractorError
-        
+
-            'http://www.rtvnh.nl/video/smil?m=' + video_id, video_id)
+            'http://www.rtvnh.nl/video/smil?m=' + video_id, video_id, fatal=False)
-            'thumbnail': meta['image'],
+            'thumbnail': meta.get('image'),
-        formats = self._extract_smil_formats('http://www.rtvnh.nl/video/smil?m=' + video_id, video_id)
+
-                formats.extend(self._extract_m3u8_formats(item['file'], video_id, ext='mp4', entry_protocol='m3u8_native'))
+                formats.extend(self._extract_m3u8_formats(
-                formats.extend(self._extract_m3u8_formats(item['file'], video_id, ext='mp4'))
+                formats.extend(self._extract_m3u8_formats(item['file'], video_id, ext='mp4', entry_protocol='m3u8_native'))
-from .rtvnhnl import RtvnhNlIE
+from .rtvnh import RTVNHIE
-class RtvnhNlIE(InfoExtractor):
+class RTVNHIE(InfoExtractor):
-            'thumbnail': 're:^http:.*\.jpg$'
+            'thumbnail': 're:^https?:.*\.jpg$'
-            'thumbnail': 're:^https?://rtvnh-webfiles\.[^.]+\.amazonaws\.com/data/cache/[0-9]+/basedata/pf_image/[0-9.]+/[0-9\-a-f]+\.jpg$'
+            'thumbnail': 're:^http:.*\.jpg$'
-                'description': 'md5:2acfda1b285bdd478ccec22f9918199d',
+                'description': 'md5:95f66187cd7c8b2c13eb78e1223b63c3',
-                'upload_date': '20120731',
+                'upload_date': '20120724',
-                'ext': 'mp4',
+                'ext': 'webm',
-                    'url': '%s%d.%s' % (link[0], bitrate, link[1]),
+                    'url': self._proto_relative_url('%s%d.%s' % (link[0], bitrate, link[1])),
-        enc_key = '8e29ab5666d041c3a1ea76e06dabdffb'
+        enc_key = '3601ba290e4f4662848c710e2122007e'	# last update at 2015-08-10 for Zombie
-        cmd += self._source_address('--interface')
+        cmd += self._option('--interface', 'source_address')
-        cmd += self._source_address('--bind-address')
+        cmd += self._option('--bind-address', 'source_address')
-        cmd += self._no_check_certificate('--no-check-certificate')
+        cmd += self._option('--no-check-certificate', 'nocheckcertificate')
-        cmd += self._source_address('--interface')
+        cmd += self._option('--interface', 'source_address')
-            }
+            },
-    _VALID_URL = r'https://vimeo\.com/(?![0-9]+(?:$|[?#/]))(?P<name>[^/]+)(?:/videos|[#?]|$)'
+    _VALID_URL = r'https://vimeo\.com/(?!(?:[0-9]+|watchlater)(?:$|[?#/]))(?P<name>[^/]+)(?:/videos|[#?]|$)'
-                                 (?:.*?&)?                                    # any other preceding param (like /?s=tuff&v=xxxx)
+                                 (?:.*?&)??                                   # any other preceding param (like /?s=tuff&v=xxxx)
-        return self._html_search_regex(self._TITLE_RE, webpage, 'list title')
+        return self._TITLE or self._html_search_regex(self._TITLE_RE, webpage, 'list title')
-    _VALID_URL = r'https://vimeo\.com/home/watchlater|:vimeowatchlater'
+    _VALID_URL = r'https://vimeo\.com/(?:home/)?watchlater|:vimeowatchlater'
-        'url': 'https://vimeo.com/home/watchlater',
+        'url': 'https://vimeo.com/watchlater',
-        return self._extract_videos('watchlater', 'https://vimeo.com/home/watchlater')
+        return self._extract_videos('watchlater', 'https://vimeo.com/watchlater')
-        token = self._search_regex(r'xsrft":"(.*?)"', webpage, 'login token')
+        webpage = self._download_webpage(self._LOGIN_URL, None, False)
-        login_request = compat_urllib_request.Request(login_url, data)
+        login_request = compat_urllib_request.Request(self._LOGIN_URL, data)
-        login_request.add_header('Cookie', 'xsrft=%s' % token)
+        login_request.add_header('Referer', self._LOGIN_URL)
-        token = self._search_regex(r'xsrft[\s=:"\']+([^"\']+)', webpage, 'login token')
+        token = self._extract_xsrft(webpage)
-class VimeoChannelIE(InfoExtractor):
+class VimeoChannelIE(VimeoBaseInfoExtractor):
-        token = self._search_regex(r'xsrft[\s=:"\']+([^"\']+)', webpage, 'login token')
+        token = self._extract_xsrft(webpage)
-class VimeoWatchLaterIE(VimeoBaseInfoExtractor, VimeoChannelIE):
+class VimeoWatchLaterIE(VimeoChannelIE):
-            format(video_id, mimi, compat_urllib_request.quote(refer, safe='').replace('.', '%2E')))
+            format(video_id, mimi, compat_urllib_request.quote(refer, safe=b'').replace('.', '%2E')))
-__version__ = '2015.08.06.1'
+__version__ = '2015.08.09'
-        # Is it an RSS feed or a SMIL file?
+        # Is it an RSS feed, a SMIL file or a XSPF playlist?
-            if determine_ext(video_url) == 'smil':
+            ext = determine_ext(video_url)
-        playlist = self._download_xml(
+    def _extract_xspf_playlist(self, playlist_url, playlist_id, fatal=True):
-            'Unable to download xspf manifest')
+            'Unable to download xspf manifest', fatal=fatal)
-        video_id = self._match_id(url)
+        playlist_id = self._match_id(url)
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, playlist_id)
-            'thumbnail')
+        entries = self._extract_xspf_playlist(playlist_url, playlist_id)
-            'url': video_url,
+        entries[0].update({
-        }
+        })
-                track, xpath_with_ns('./xspf:title', NS_MAP), 'title')
+                track, xpath_with_ns('./xspf:title', NS_MAP), 'title', default=playlist_id)
-        'md5': '1b5afa817403bb5baa08359dca31e6df',
+        'md5': '3147e4ddad366f97476a93863e4557c8',
-        }
+        playlist_id = self._match_id(url)
-    semantics as videos (see above).
+    Additionally, playlists can have "title", "description" and "id" attributes
-        password_request.add_header('Cookie', 'xsrft=%s' % token)
+        password_request.add_header('Referer', url)
-    _VALID_URL = r'http://(?:www\.)?videolectures\.net/(?P<id>[^/#?]+)(?:/?[#?].*)?$'
+    _VALID_URL = r'http://(?:www\.)?videolectures\.net/(?P<id>[^/#?]+)/*(?:[#?].*)?$'
-        'md5': '8e24ad2da6f387948e7a7d44eb8668fe',
+        'md5': '6ba728d85d60aa2e6dd37c9e70fdc6bc',
-            'uploader': 'ÐÐ½Ð´ÑÐµÐ¹ ÐÐµÑÐ°Ð½Ð¸Ð½Ð¾Ð²',
+            'uploader': 'â­ ÐÐ½Ð´ÑÐµÐ¹ ÐÐµÑÐ°Ð½Ð¸Ð½Ð¾Ð² â­',
-                          if value and key in ('id', 'title', 'description', 'uploader', 'upload_date', 'timestamp', 'uploader_id', 'location'))
+                          if value and key in ('id', 'title', 'description', 'uploader', 'upload_date', 'timestamp', 'uploader_id', 'location', 'age_limit'))
-        player_type = player_info['playerType']
+        flash_vars = self._search_regex('var flashvars = ({[^}]+})', webpage, 'flashvars', None)
-            'https://shahid.mbc.net/arContent/getPlayerContent-param-.id-' + video_id + '.type-' + player_info['type'] + '.html',
+            'https://shahid.mbc.net/arContent/getPlayerContent-param-.id-' + video_id + '.type-' + self._api_vars['type'] + '.html',
-            player_info['url'] + '/' + player_type + '/' + video_id + '?apiKey=sh%40hid0nlin3&hash=b2wMCTHpSmyxGqQjJFOycRmLSex%2BBpTK%2Fooxy6vHaqs%3D',
+            self._api_vars['url'] + '/' + self._api_vars['playerType'] + '/' + video_id + '?apiKey=sh%40hid0nlin3&hash=b2wMCTHpSmyxGqQjJFOycRmLSex%2BBpTK%2Fooxy6vHaqs%3D',
-        video_info = video_info[player_type]
+        video_info = video_info[self._api_vars['playerType']]
-    IE_DESC = 'Quisck Scope'
+    IE_DESC = 'Quick Scope'
-from .periscope import PeriscopeIE
+from .periscope import (
-    unescapeHTML,
+from ..compat import (
-
+        state = broadcast.get('state').lower()
-            'protocol': 'm3u8_native',
+            'formats': formats,
-        video_id = self._match_id(url)
+    def _call_api(self, method, token):
-            'https://api.periscope.tv/api/v2/getAccessPublic?token=%s' % video_id, video_id)
+    def _real_extract(self, url):
-
+        broadcast_data = self._call_api('getBroadcastPublic', token)
-            'id': broadcast.get('id') or video_id,
+            'id': broadcast.get('id') or token,
-                    (?=[^>]+(?:itemprop|name|property)=(["\']?)%s\1)
+                    (?=[^>]+(?:itemprop|name|property|id)=(["\']?)%s\1)
-            'url': 'https://shahid.mbc.net/ar/episode/108084/%D8%AE%D9%88%D8%A7%D8%B7%D8%B1-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%85-11-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-1.html',
+            'url': 'https://shahid.mbc.net/ar/episode/90574/%D8%A7%D9%84%D9%85%D9%84%D9%83-%D8%B9%D8%A8%D8%AF%D8%A7%D9%84%D9%84%D9%87-%D8%A7%D9%84%D8%A5%D9%86%D8%B3%D8%A7%D9%86-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%85-1-%D9%83%D9%84%D9%8A%D8%A8-3.html',
-                'id': '108084',
+                'id': '90574',
-                'duration': 1166,
+                'title': 'Ø§ÙÙÙÙ Ø¹Ø¨Ø¯Ø§ÙÙÙ Ø§ÙØ¥ÙØ³Ø§Ù Ø§ÙÙÙØ³Ù 1 ÙÙÙØ¨ 3',
-            'url': 'https://shahid.mbc.net/ar/series/90497/%D9%85%D8%B1%D8%A7%D9%8A%D8%A7-2011.html',
+            'url': 'https://shahid.mbc.net/ar/episode/90511/%D9%85%D8%B1%D8%A7%D9%8A%D8%A7-2011-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%85-1-%D8%A7%D9%84%D8%AD%D9%84%D9%82%D8%A9-1.html',
-        mobj = (re.search(r'player\.ooyala\.com/[^"?]+\?[^"]*?(?:embedCode|ec)=(?P<ec>[^"&]+)', webpage) or
+        mobj = (re.search(r'player\.ooyala\.com/[^"?]+[?#][^"]*?(?:embedCode|ec)=(?P<ec>[^"&]+)', webpage) or
-    ExtractorError,
+    determine_ext,
-    determine_ext,
+    parse_iso8601,
-    _VALID_URL = r'^https?://(?:www\.)?clipfish\.de/.*?/video/(?P<id>[0-9]+)/'
+    _VALID_URL = r'https?://(?:www\.)?clipfish\.de/(?:[^/]+/)+video/(?P<id>[0-9]+)'
-        formats = [{'url': video_info['videourl']},{'url': video_url}]
+            js_to_json(self._html_search_regex(
-    _VALID_URL = r'https?://(?:www\.)?dcndigital\.ae/(?:#/)?(?:video/.+|show/\d+/.+?)/(?P<id>\d+)/?'
+    _VALID_URL = r'https?://(?:www\.)?dcndigital\.ae/(?:#/)?(?:video/.+|show/\d+/.+?)/(?P<id>\d+)'
-from .dcn import DcnIE
+from .dcn import DCNIE
-from ..utils import int_or_none
+from ..compat import (
-class DcnIE(InfoExtractor):
+class DCNIE(InfoExtractor):
-            'ext': 'm3u8',
+            'ext': 'mp4',
-            'duration': 2041
+            'description': 'md5:0156e935d870acb8ef0a66d24070c6d6',
-        description = json_data.get('description_ar')
+            'http://admin.mangomolo.com/analytics/index.php/plus/video?id=%s' % video_id,
-        formats = self._extract_m3u8_formats(m3u8_url, video_id)
+            'http://admin.mangomolo.com/analytics/index.php/customers/embed/video?'
-            'description': description,
+            'timestamp': timestamp,
-    _VALID_URL = r'https?://(?:www\.)?nowtv\.(?:de|at)/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/(?:player|preview)'
+    _VALID_URL = r'https?://(?:www\.)?nowtv\.(?:de|at|ch)/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/(?:player|preview)'
-    _VALID_URL = r'https?://(?:www\.)?nowtv\.de/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/(?:player|preview)'
+    _VALID_URL = r'https?://(?:www\.)?nowtv\.(?:de|at)/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/(?:player|preview)'
-            'duration': '2041'
+            'duration': 2041
-        description = json_data['description_ar']
+        thumbnail = 'http://admin.mangomolo.com/analytics/' + json_data.get('img')
-__version__ = '2015.08.06'
+__version__ = '2015.08.06.1'
-__version__ = '2015.07.28'
+__version__ = '2015.08.06'
-        'skip': 'Broken python 3',
+        # Percent-encode redirect URL of Location HTTP header to satisfy RFC 3986
-            #shahid plus subscriber only
+            # shahid plus subscriber only
-        for line in self._search_regex( 'var flashvars = ({[^}]+})', webpage, 'flashvars').splitlines():
+        for line in self._search_regex('var flashvars = ({[^}]+})', webpage, 'flashvars').splitlines():
-                '?apiKey=sh%40hid0nlin3&hash=b2wMCTHpSmyxGqQjJFOycRmLSex%2BBpTK%2Fooxy6vHaqs%3D',
+            player_info['url'] + '/' + player_type + '/' + video_id + '?apiKey=sh%40hid0nlin3&hash=b2wMCTHpSmyxGqQjJFOycRmLSex%2BBpTK%2Fooxy6vHaqs%3D',
-        if video_info['error']:
+        if video_info.get('error'):
-        formats = self._extract_m3u8_formats(m3u8_url, video_id)
+# coding: utf-8
-            'description': '"ÙÙ ÙØ°Ù Ø§ÙØ­ÙÙØ© ÙÙ Ø¨Ø±ÙØ§ÙØ¬ Ø±Ø­ÙØ© Ø§ÙØ¹ÙØ± ÙÙØ¯ÙÙ Ø§ÙØ¯ÙØªÙØ± Ø¹ÙØ± Ø¹Ø¨Ø¯ Ø§ÙÙØ§ÙÙ ØªØ¨Ø³ÙØ·Ø§Ù ÙÙÙØ§Ø³Ù Ø§ÙØ­Ø¬ ÙØ§ÙØ¹ÙØ±Ø© ÙÙØ¬ÙØ¨ ÙØ¨Ø§Ø´Ø±Ø© Ø¹ÙÙ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø­Ø¬Ø§Ø¬ Ø¨ÙØª Ø§ÙÙÙ Ø§ÙØ­Ø±Ø§Ù Ø¨Ø®ØµÙØµ ÙÙØ§Ø³Ù Ø§ÙØ­Ø¬ ÙØ§ÙØ¹ÙØ±Ø©1"',
+            'description': 'ÙÙ ÙØ°Ù Ø§ÙØ­ÙÙØ© ÙÙ Ø¨Ø±ÙØ§ÙØ¬ Ø±Ø­ÙØ© Ø§ÙØ¹ÙØ± ÙÙØ¯ÙÙ Ø§ÙØ¯ÙØªÙØ± Ø¹ÙØ± Ø¹Ø¨Ø¯ Ø§ÙÙØ§ÙÙ ØªØ¨Ø³ÙØ·Ø§Ù ÙÙÙØ§Ø³Ù Ø§ÙØ­Ø¬ ÙØ§ÙØ¹ÙØ±Ø© ÙÙØ¬ÙØ¨ ÙØ¨Ø§Ø´Ø±Ø© Ø¹ÙÙ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø­Ø¬Ø§Ø¬ Ø¨ÙØª Ø§ÙÙÙ Ø§ÙØ­Ø±Ø§Ù Ø¨Ø®ØµÙØµ ÙÙØ§Ø³Ù Ø§ÙØ­Ø¬ ÙØ§ÙØ¹ÙØ±Ø©\n1',
-        }
+        },
-            video_id
+        request = compat_urllib_request.Request(
-        description = json_data['description_ar'];
+        json_data = self._download_json(request, video_id)
-            'http://admin.mangomolo.com/analytics/index.php/customers/embed/video?id='+json_data['id']+'&user_id='+json_data['user_id']+'&countries=Q0M=&w=100%&h=100%&filter=DENY&signature='+json_data['signature'],
+            'http://admin.mangomolo.com/analytics/index.php/customers/embed/video?id=' + json_data['id'] + '&user_id=' + json_data['user_id'] + '&countries=Q0M=&w=100%&h=100%&filter=DENY&signature=' + json_data['signature'],
-    HEADRequest,
+        'skip': 'Broken python 3',
-
+        # According to RFC 3986, URLs can not contain non-ASCII characters, however this is not
-             webpage, 'thumbnail', fatal=False, group='thumbnail')
+            webpage, 'thumbnail', fatal=False, group='thumbnail')
-	
+
-                    'Referer': self._PLAYER_URL,
+                    'Referer': player_url,
-                r'[^A-Za-z0-9]?file["\']?:\s*["\'](http(?![^\'"]+\.[0-9]+[\'"])[^\'"]+)["\']', webpage))
+                r'[^A-Za-z0-9]?(?:file|video_url)["\']?:\s*["\'](http(?![^\'"]+\.[0-9]+[\'"])[^\'"]+)["\']', webpage))
-                'uploader_id': 'Ruseful2011',
+                'uploader': 'Ruseful2011',
-                'uploader_id': 'jojo747400',
+                'uploader': 'jojo747400',
-                                              webpage, 'uploader id', default='anonymous')
+        uploader = self._html_search_regex(
-            'uploader_id': uploader_id,
+            'uploader': uploader,
-        thumbnail = self._html_search_regex(r'<video\s+.*?poster="([^"]+)".*?>', webpage, 'thumbnail', fatal=False)
+        thumbnail = self._search_regex(
-                return mp4.group(1)
+        def extract_video_url(webpage, name):
-        video_url = extract_video_url(webpage)
+        format_id = 'hd' if hd else 'sd'
-                video_url = extract_video_url(webpage)
+                video_url = extract_video_url(webpage, 'hd')
-            mp4 = re.search(r'<video\s+.*?file="([^"]+)".*?>', webpage)
+            mp4 = re.search(r'file:\s+\'([^\']+)\'', webpage)
-        m = re.search(r'loginResultJson = \'(?P<json>[^\']+)\';', login_page)
+        m = re.search(r'loginResultJson\s*=\s*\'(?P<json>[^\']+)\';', login_page)
-        if re.search(self._SUCCESSFUL_LOGIN_REGEX, login_page) is None:
+        if all(not re.search(p, login_page) for p in ('isLoggedIn\s*:\s*true', r'logout\.aspx', r'>Log out<')):
-    _SUCCESSFUL_LOGIN_REGEX = r'isLoggedIn: true'
+    _SUCCESSFUL_LOGIN_REGEX = r'isLoggedIn\s*:\s*true'
-            tokens = list(compat_tokenize_tokenize(stream.readline))
+            tokens = list(_remove_unused_ops(compat_tokenize_tokenize(stream.readline)))
-            media_asset_page = self._parse_json(
+            media_asset = self._search_regex(
-                    r'mediaAssetPage\.init\(\s*({.+?}), "/', webpage, 'media asset'),
+                    r'<script[^>]+class="vxp-playlist-data"[^>]+type="application/json"[^>]*>([^<]+)</script>',
-                medias.extend(video.values())
+            playlist_medias = []
-        'url': 'http://www.twitch.tv/riotgames/v/6528877',
+        'url': 'http://www.twitch.tv/riotgames/v/6528877?t=5m10s',
-            m = re.match(r'^(?P<height>[0-9]+)P-(?P<tbr>[0-9]+)K$', format)
+            m = re.match(r'^(?P<height>[0-9]+)[pP]-(?P<tbr>[0-9]+)[kK]$', format)
-            url_el = a.find('.//progressiveDownloadUrl')
+            url_el = a.find('./progressiveDownloadUrl')
-        video_urls = list(map(compat_urllib_parse_unquote, re.findall(r"var player_quality_[0-9]{3}p = '([^']+)'", webpage)))
+        video_urls = list(map(compat_urllib_parse_unquote, re.findall(r"player_quality_[0-9]{3}p\s*=\s*'([^']+)'", webpage)))
-        video_urls = list(map(compat_urllib_parse_unquote, re.findall(r'"quality_[0-9]{3}p":"([^"]+)', webpage)))
+        video_urls = list(map(compat_urllib_parse_unquote, re.findall(r"var player_quality_[0-9]{3}p = '([^']+)'", webpage)))
-                    # Content-Range is invalid - wipe the file and do entire redownload
+                        # Content-Range is present and matches requested Range, resume is possible
-
+                        # Content-Range is correct - go on
-
+import re
-        video_ids = []
+        video_ids = set()
-            video_ids.extend(re.findall(r'data-xid="(.+?)"', webpage))
+            for video_id in re.findall(r'data-xid="(.+?)"', webpage):
-    _VALID_URL = r'http://(?:www\.)?videolectures\.net/(?P<id>[^/#?]+)/'
+    _VALID_URL = r'http://(?:www\.)?videolectures\.net/(?P<id>[^/#?]+)(?:/?[#?].*)?$'
-    _VALID_URL = r'https?://(?:www\.)?nowtv\.de/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/player'
+    _VALID_URL = r'https?://(?:www\.)?nowtv\.de/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/(?:player|preview)'
-    _VALID_URL = r'https?://(?:www\.)?nowtv\.de/(?P<station>rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/player'
+    _VALID_URL = r'https?://(?:www\.)?nowtv\.de/(?:rtl|rtl2|rtlnitro|superrtl|ntv|vox)/(?P<id>.+?)/player'
-            'ext': 'mp4',
+            'ext': 'flv',
-            # m3u8 download
+            # rtmp download
-            'ext': 'mp4',
+            'ext': 'flv',
-            # m3u8 download
+            # rtmp download
-            'ext': 'mp4',
+            'ext': 'flv',
-            # m3u8 download
+            # rtmp download
-            'ext': 'mp4',
+            'ext': 'flv',
-            # m3u8 download
+            # rtmp download
-            'ext': 'mp4',
+            'ext': 'flv',
-            # m3u8 download
+            # rtmp download
-            'ext': 'mp4',
+            'ext': 'flv',
-            # m3u8 download
+            # rtmp download
-        station = mobj.group('station')
+        display_id = self._match_id(url)
-            m3u8_url = m3u8_url.replace('now/', 'now/videos/')
+            if determine_ext(item['path']) != 'f4v':
-                'tbr': tbr,
+                'url': 'rtmpe://fms.rtl.de',
-        videoserver = self._search_regex(r"'videoserver'\s*:\s*'([^']+)", playerconfig, 'videoserver')
+        videoserver = self._search_regex(r"\[ipaddress\]\s*=>\s*([\d\.]+)", playerdata, 'videoserver')
-
+    js_to_json,
-            'http://player.screenwavemedia.com/play/player.php?id=%s' % video_id,
+            'http://player.screenwavemedia.com/player.php?id=%s' % video_id,
-            }]
+
-            r'{([^}]+)?}smil', smil.tag, 'namespace', default=None)
+        namespace = self._parse_smil_namespace(smil)
-            r'{([^}]+)?}smil', smil.tag, 'namespace', default=None)
+        namespace = self._parse_smil_namespace(smil)
-                f4m_url += compat_urllib_parse.urlencode(f4m_params).encode('utf-8')
+                f4m_url += compat_urllib_parse.urlencode(f4m_params)
-                    'Expected field %s to be a list, but it is of type %s' % (
+                    isinstance(got, (list, dict)),
-                    res_dict = ydl.extract_info(test_case['url'])
+                    res_dict = ydl.extract_info(
-        # Is it an RSS feed?
+        # Is it an RSS feed or a SMIL file?
-            'Unable to download SMIL file', fatal=fatal)
+    @staticmethod
-        base = smil.find('./head/meta').get('base')
+        namespace = self._search_regex(
-                formats.extend(fmts)
+        http_count = 0
-            }], rtmp_count)
+    def _parse_smil_subtitles(self, smil, namespace=None):
-        (?:feature|nightly-news)/[^/]+/(?P<title>.+))
+        (?:watch|feature|nightly-news)/[^/]+/(?P<title>.+))
-    def find_xpath_attr(node, xpath, key, val):
+    def find_xpath_attr(node, xpath, key, val=None):
-        expr = xpath + "[@%s='%s']" % (key, val)
+        if val:
-    def find_xpath_attr(node, xpath, key, val):
+    def find_xpath_attr(node, xpath, key, val=None):
-            if f.attrib.get(key) == val:
+            if key not in f.attrib:
-        xml_description = self._download_xml(xml_decription_url, display_id)
+        xml_description_url = xml_root + 'xml/' + xml_name
-from ..utils import remove_end
+from ..utils import (
-        video_formats = []
+        formats = []
-        video_formats.append({
+        formats.append({
-        video_formats.append({
+        formats.append({
-        return video_formats
+        return formats
-            video_url = 'http://www.gdcvault.com/' + direct_url
+            video_url = 'http://www.gdcvault.com' + direct_url
-                'ext': 'flv',
+    HEADRequest,
-        self._request_webpage(url, video_id)
+        self._request_webpage(HEADRequest(url), video_id)
-        height = int_or_none(self._og_search_property('video:height', webpage, fatal=False))
+        timestamp = int_or_none(self._og_search_property(
-            r'<(?:li|span) class="video_views">\s*([\d,\.]+)\s*plays?', webpage, 'view count', fatal=False))
+            r'<(?:li|span) class="video_views">\s*([\d,\.]+)\s*plays?',
-        uploader = self._html_search_regex('class="video_author_username">([^<]+)', webpage, 'uploader', fatal=False)
+        uploader = self._html_search_regex(
-                            (?!(?:tracks|sets|reposts|likes|spotlight)/?(?:$|[?#]))
+                            (?!(?:tracks|sets(?:/[^/?#]+)?|reposts|likes|spotlight)/?(?:$|[?#]))
-    _VALID_URL = r'https?://(?:(?:www|m)\.)?soundcloud\.com/(?P<user>[^/]+)/?((?P<rsrc>tracks|sets|reposts|likes|spotlight)/?)?(\?.*)?$'
+    _VALID_URL = r'''(?x)
-                            (?!sets/|(?:likes|tracks)/?(?:$|[?#]))
+                            (?!(?:tracks|sets|reposts|likes|spotlight)/?(?:$|[?#]))
-    _VALID_URL = r'https?://(?:(?:www|m)\.)?soundcloud\.com/(?P<user>[^/]+)/?((?P<rsrc>tracks|likes)/?)?(\?.*)?$'
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?soundcloud\.com/(?P<user>[^/]+)/?((?P<rsrc>tracks|sets|reposts|likes|spotlight)/?)?(\?.*)?$'
-        'url': 'https://soundcloud.com/the-concept-band',
+        'url': 'https://soundcloud.com/the-akashic-chronicler',
-            'title': 'The Royal Concept',
+            'id': '114582580',
-        'playlist_mincount': 12
+        'playlist_mincount': 112,
-        'url': 'https://soundcloud.com/the-concept-band/likes',
+        'url': 'https://soundcloud.com/the-akashic-chronicler/tracks',
-            'title': 'The Royal Concept',
+            'id': '114582580',
-        'playlist_mincount': 1,
+        'playlist_mincount': 50,
-        'only_matching': True,
+        'url': 'https://soundcloud.com/the-akashic-chronicler/sets',
-        base_url = 'http://api.soundcloud.com/users/%s/%s.json?' % (uploader, resource)
+
-            if len(new_entries) == 0:
+            if not next_href:
-            entries.extend(self.url_result(e['permalink_url'], 'Soundcloud') for e in new_entries)
+
-            'title': user['username'],
+            'title': '%s (%s)' % (user['username'], self._TITLE_MAP[resource]),
-        self._AUTH_TOKEN = compat_urllib_parse.unquote(cookies['api_token'].value)
+        self._AUTH_TOKEN = compat_urllib_parse_unquote(cookies['api_token'].value)
-    _AUTH_TOKEN = '/YqhSYsx8EaU9Bsta3ojlA=='
+        # Get 'api_token' cookie
-    _MEDIASELECTOR_URL = 'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/%s'
+    _MEDIASELECTOR_URLS = [
-                '%s returned error: %s' % (self.IE_NAME, error.get('id')), expected=True)
+            raise BBCCoUkIE.MediaSelectionError(error.get('id'))
-                 raise
+        last_exception = None
-    _MEDIASELECTOR_ALT_URL = 'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/journalism-pc/vpid/%s'
+    _MEDIASELECTOR_URLS = [
-            return self.playlist_result(entries, video_id, video_title, video_description)
+        if 'multifeed_metadata_list' in video_info and not smuggled_data.get('force_singlefeed', False):
-                'description': 'md5:fea86fda2d5a5784273df5c7cc994d9f',
+                'description': 'md5:782e8651347686cba06e58f71ab51773',
-        , video_webpage, re.DOTALL | re.IGNORECASE);
+        video_tags = [
-            'tags' : video_tags,
+            'tags': video_tags,
-    tags:           A list of keywords attached to the video.
+    @staticmethod
-                    [^>]+?content=(["\'])(?P<content>.*?)\2''' % re.escape(name),
+            self._meta_regex(name),
-)
+from .fragment import FragmentFD
-class NativeHlsFD(FileDownloader):
+class NativeHlsFD(FragmentFD):
-        tmpfilename = self.temp_name(filename)
+        man_url = info_dict['url']
-        segment_urls = []
+        s = manifest.decode('utf-8', 'ignore')
-                if remaining_bytes is not None and remaining_bytes <= 0:
+                    else compat_urlparse.urljoin(man_url, line))
-            'total_bytes': byte_counter,
+        ctx = {
-        self.try_rename(tmpfilename, filename)
+            'total_frags': len(fragment_urls),
-from .http import HttpFD
+from .fragment import FragmentFD
-class F4mFD(FileDownloader):
+class F4mFD(FragmentFD):
-        self.to_screen('[download] Downloading f4m manifest')
+        self.to_screen('[%s] Downloading f4m manifest' % self.FD_NAME)
-        (dest_stream, tmpfilename) = sanitize_open(tmpfilename, 'wb')
+        ctx = {
-        http_dl.add_progress_hook(frag_progress_hook)
+        self._start_frag_download(ctx)
-            frag_filename = '%s-%s' % (tmpfilename, name)
+            frag_filename = '%s-%s' % (ctx['tmpfilename'], name)
-                success = http_dl.download(frag_filename, {'url': url})
+                success = ctx['dl'].download(frag_filename, {'url': url})
-        dest_stream.close()
+        self._finish_frag_download(ctx)
-
+from __future__ import division, unicode_literals
-        m = re.findall(r'''<meta(?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|="[^"]+"|='[^']+'))*?\s+property=['"]?og:video:tag['"]?(?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|="[^"]+"|='[^']+'))*?\s+content=['"]?([^>'"]+?)['"]?\s*>'''
+        video_tags = re.findall(r'''<meta(?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|="[^"]+"|='[^']+'))*?\s+property=['"]?og:video:tag['"]?(?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|="[^"]+"|='[^']+'))*?\s+content=['"]?([^>'"]+?)['"]?\s*>'''
-        video_tags = ", ".join(m)
+        m = re.findall(r'''<meta(?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|="[^"]+"|='[^']+'))*?\s+property=['"]?og:video:tag['"]?(?:\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]+|="[^"]+"|='[^']+'))*?\s+content=['"]?([^>'"]+?)['"]?\s*>'''
-__version__ = '2015.07.21'
+__version__ = '2015.07.28'
-        EMBED_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:[^/]+/)+[\da-z]{8}(?:\b[^"]*)?'
+        EMBED_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:[^/]+/)+[\da-z]{8}(?:\b[^"]+)?'
-        playlist_description = self._og_search_description(webpage)
+        playlist_description = self._og_search_description(webpage, default=None)
-            re.findall(r"data-media-meta='({[^']+})'", webpage))))
+        medias = extract_all(r"data-media-meta='({[^']+})'")
-            self._MEDIASELECTOR_URL % programme_id, programme_id)
+        try:
-    _MEDIASELECTOR_URL = 'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/journalism-pc/vpid/%s'
+    # fails with notukerror for some videos ( non news sites such as bbc.com/travel )
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'flv',
+            'ext': 'mp4',
-    expected = None
+        # Both in bytes
-        '278': {'ext': 'webm', 'height': 144, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40, 'container': 'webm', 'vcodec': 'VP9'},
+        '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'acodec': 'none', 'container': 'webm', 'vcodec': 'vp8', 'preference': -40},
-        '315': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40, 'fps': 60, 'vcodec': 'VP9'},
+        '302': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40, 'fps': 60, 'vcodec': 'vp9'},
-    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<id>[0-9]+)(?:-embed)?(?:\.html)?(?:#.*)?$'
+    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<id>[0-9]+)(?:-embed|-iframe)?(?:\.html)?(?:#.*)?$'
-        video_data = full_data['videos'][video_id]
+        video_data = full_data.get('videos', {}).get(video_id) or full_data['singleshots'][video_id]
-            for error in json_data['error'].values():
+            for error in player_json_data['error'].values():
-    get_element_by_id,
+    js_to_json,
-                'description': 'Ø¨Ø³Ù Ø§ÙÙÙ'
+                'title': 'Ø®ÙØ§Ø·Ø± Ø§ÙÙÙØ³Ù 11 Ø§ÙØ­ÙÙØ© 1',
-            get_element_by_id('jsonld', webpage),
+        player_info = ''
-        description = json_data.get('description')
+        )['data']
-            'https://shahid.mbc.net/arContent/getPlayerContent-param-.id-'+video_id+'.type-player.html',
+            'https://shahid.mbc.net/arContent/getPlayerContent-param-.id-' + video_id + '.type-' + player_info['type'] + '.html',
-    #_MEDIASELECTOR_URL = 'http://open.live.bbc.co.uk/mediaselector/4/mtis/stream/%s'
+    # _MEDIASELECTOR_URL = 'http://open.live.bbc.co.uk/mediaselector/4/mtis/stream/%s'
-        if not smuggled_data.get('force_singlefeed', False) and 'multifeed_metadata_list' in video_info:
+        if (not self._downloader.params.get('noplaylist') and
-from .bbc import BBCCoUkIE, BBCNewsIE
+from .bbc import (
-    parse_duration,
+    float_or_none,
-    mediaselector_url = 'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/%s'
+    _MEDIASELECTOR_URL = 'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/%s'
-                programme_id, 'Downloading media selection XML')
+                url, programme_id, 'Downloading media selection XML')
-            playlist_id, 'Downloading legacy playlist XML')
+        return self._process_legacy_playlist(playlist_id)
-            programme_id = item.get('identifier')
+
-    _VALID_URL = r'https?://(?:www\.)?bbc\.com/.+?/(?P<id>[^/]+)$'
+class BBCIE(BBCCoUkIE):
-    mediaselector_url = 'http://open.live.bbc.co.uk/mediaselector/4/mtis/stream/%s'
+    # fails with notukerror for some videos
-            'ext': 'mp4',
+            'ext': 'flv',
-            'description': 'Germanwings plane crash site in aerial video - Aerial footage showed the site of the crash in the Alps - courtesy BFM TV',
+            'timestamp': 1427219242,
-            'uploader': 'BBC News',
+            # rtmp download
-            'id': 'NA',
+            'id': '150615_telabyad_kentin_cogu',
-            'description': 'YPG: Tel Abyad\'\u0131n tamam\u0131 kontrol\xfcm\xfczde',
+            'title': "YPG: Tel Abyad'Ä±n tamamÄ± kontrolÃ¼mÃ¼zde",
-            'uploader': 'BBC News',
+        # single video embedded with mediaAssetPage.init() (regional section)
-            'id': '39275083',
+            'id': '150619_video_honduras_militares_hospitales_corrupcion_aw',
-            'description': 'Honduras militariza sus hospitales por nuevo esc\xe1ndalo de corrupci\xf3n',
+            'title': 'Honduras militariza sus hospitales por nuevo escÃ¡ndalo de corrupciÃ³n',
-            'uploader': 'BBC News',
+    }, {
-                formats, subtitles = self._download_media_selector(programme_id)
+        playlist_id = self._match_id(url)
-                raise ExtractorError('unsupported json media entry.\n    ' + str(jent) + '\n')
+        # single video story (e.g. http://www.bbc.com/travel/story/20150625-sri-lankas-spicy-secret)
-                id = 'NA'
+            video_id = media_meta.get('externalId')
-                'upload_date': pubdate,
+            images = []
-                'thumbnail': thumbnail,
+                'thumbnails': thumbnails,
-        raise ExtractorError('No video found', expected=True)
+        return self.playlist_result(entries, playlist_id, playlist_title, playlist_description)
-        thumbnail = self._search_regex(r'poster="([^"]+)"', webpage, 'thumbnail url')
+        thumbnail = self._search_regex(r'poster="([^"]+)"', webpage, 'thumbnail url', fatal=False)
-            'thumbnail' : thumbnail,
+            'video_url': video_url,
-            r'<title>\n90tv.ir :: (.*?)</title>', webpage, 'title')
+        title = remove_start(self._html_search_regex(
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            for t in data['tracks']]
+        entries = [self.url_result(track['permalink_url'], 'Soundcloud') for track in data['tracks']]
-            'entries': [self._extract_info_dict(track, secret_token=token) for track in info['tracks']],
+            'entries': entries,
-                    if regions_allowed is not None:
+                    if regions_allowed:
-                    url_info_dict['height'] = format_id[:-1]
+                    url_info_dict['height'] = int_or_none(format_id[:-1])
-                id, 'Downloading page %s' % pagenum)
+            page_url = self._PAGE_TEMPLATE % (id, pagenum)
-    parse_duration,
+    int_or_none,
-        'md5': '2521cd644e862936cf2e698206e47385',
+        'md5': '79bc922f3e8a9097b3d68a93780fd475',
-        'skip': 'Blocked in the US'
+        }
-        video_id = mobj.group(1)
+        video_id = self._match_id(url)
-        duration = parse_duration(doc.find('duration').text)
+        duration = int_or_none(video_info['length'])
-            'url': video_url,
+            'formats': formats,
-    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?:(?:old/)?user/)?(?P<user>[^/]+)$'
+    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?!(?:embed|#|video|playlist)/)(?:(?:old/)?user/)?(?P<user>[^/]+)'
-        vbr = int(media.get('bitrate'))
+        vbr = int_or_none(media.get('bitrate'))
-        file_size = int(media.get('media_file_size'))
+        width = int_or_none(media.get('width'))
-        abr = int(media.get('bitrate'))
+        abr = int_or_none(media.get('bitrate'))
-                    duration = int(item.get('duration'))
+                    duration = int_or_none(item.get('duration'))
-            duration = int(item.get('duration'))
+            duration = int_or_none(item.get('duration'))
-                formats.extend(hls_formats)
+                formats.extend(self._extract_m3u8_formats(
-                formats.extend(hds_formats)
+                formats.extend(self._extract_f4m_formats(
-                hls_formats = self._extract_m3u8_formats(format_url, video_id, 'flv')
+                hls_formats = self._extract_m3u8_formats(format_url, video_id, 'mp4')
-                    * ext        Will be calculated from url if missing
+                    * ext        Will be calculated from URL if missing
-                        * "url": A url pointing to the subtitles file
+                        * "url": A URL pointing to the subtitles file
-    webpage_url:    The url to the video webpage, if given to youtube-dl it
+    webpage_url:    The URL to the video webpage, if given to youtube-dl it
-                    specified in the url.
+                    specified in the URL.
-                    specified in the url.
+                    specified in the URL.
-        """Returns a url that points to a page that should be processed"""
+        """Returns a URL that points to a page that should be processed"""
-        return self._og_search_property('image', html, 'thumbnail url', fatal=False, **kargs)
+        return self._og_search_property('image', html, 'thumbnail URL', fatal=False, **kargs)
-    They accept urls in the format _SEARCH_KEY(|all|[0-9]):{query}
+    They accept URLs in the format _SEARCH_KEY(|all|[0-9]):{query}
-        # allows bypassing georestriction therefore is retained for now.
+        # m3u8 streams are encrypted and may not be handled properly by older ffmpeg/avconv.
-        videopath = material['videopath'].replace('/adaptive/', '/flash/')
+        videopath = material['videopath']
-        video_urlpart = videopath.split('/flash/')[1][:-5]
+        video_urlpart = videopath.split('/adaptive/')[1][:-5]
-    _VALID_URL = r'https?://(?:www\.)?rts\.ch/(?:(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html|play/tv/[^/]+/video/(?P<display_id_new>.+?)\?id=(?P<id_new>[0-9]+))'
+    _VALID_URL = r'''(?x)
-        video_id = m.group('id') or m.group('id_new')
+        video_id = m.group('rts_id') or m.group('id') or m.group('id_new')
-    """Information Extractor for Dailymotion"""
+class DailymotionIE(DailymotionBaseInfoExtractor):
-                'upload_date': '20150306',
+                'description': 'Several come bundled with the Steam Controller.',
-        webpage = self._download_webpage(request, video_id)
+        webpage = self._download_webpage_no_ff(
-        self.report_extraction(video_id)
+        view_count = str_to_int(self._search_regex(
-        m_vevo = re.search(
+        # vevo embed
-            return self.url_result('vevo:%s' % vevo_id, ie='Vevo')
+            webpage, 'vevo embed', default=None)
-        age_limit = self._rta_search(webpage)
+        # fallback old player
-            raise ExtractorError('Unable to extract video URL')
+        self._sort_formats(formats)
-            'upload_date': video_upload_date,
+            'timestamp': timestamp,
-                                             id, 'Downloading page %s' % pagenum)
+            webpage = self._download_webpage_no_ff(
-        webpage = self._download_webpage(request, video_id)
+        webpage = self._download_webpage_no_ff(url, video_id)
-            'url': 'http://www.youtube.com/watch?v=BaW_jenozKcj&t=1s',
+            'url': 'http://www.youtube.com/watch?v=BaW_jenozKcj&t=1s&end=9',
-            if 't' in query:
+            if start_time is None and 't' in query:
-                break
+            if end_time is None and 'end' in query:
-from ..utils import RegexNotFoundError
+from ..utils import (
-                self.report_warning(reason)
+                raise ExtractorError(reason)
-                self.report_warning('not a video')
+                raise ExtractorError('not a video')
-            'ie-key': 'GoogleDrive',
+            'ie_key': 'GoogleDrive',
-                r'"title"\s+,\s+"[^"]+',
+                r'"title"\s*,\s*"([^"]+)',
-                r'"fmt_stream_map"\s+,\s+"[^"]+',
+                r'"fmt_stream_map"\s*,\s*"([^"]+)',
-                r'"fmt_list"\s+,\s+"[^"]+',
+                r'"fmt_list"\s*,\s*"([^"]+)',
-#				r'"timestamp"\s+,\s+"[^"]+',
+#				r'"timestamp"\s*,\s*"([^"]+)',
-                r'"length_seconds"\s+,\s+"[^"]+',
+                r'"length_seconds"\s*,\s*"([^"]+)',
-                    r'"reason","[^"]+',
+                    r'"reason","([^"]+)',
-            'http://docs.google.com/file/d/'+video_id, video_id, encoding='unicode_escape'
+            'http://docs.google.com/file/d/' + video_id, video_id, encoding='unicode_escape'
-                r'"title","(?P<title>.*?)"',
+                r'"title"\s+,\s+"[^"]+',
-                group='title'
+                'title'
-                r'"fmt_stream_map","(?P<fmt_stream_map>.*?)"',
+                r'"fmt_stream_map"\s+,\s+"[^"]+',
-                group='fmt_stream_map'
+                'fmt_stream_map'
-                r'"fmt_list","(?P<fmt_list>.*?)"',
+                r'"fmt_list"\s+,\s+"[^"]+',
-                group='fmt_list'
+                'fmt_list'
-#				r'"timestamp","(?P<timestamp>.*?)"',
+#				r'"timestamp"\s+,\s+"[^"]+',
-#				group='timestamp'
+#				'timestamp'
-                r'"length_seconds","(?P<length_seconds>.*?)"',
+                r'"length_seconds"\s+,\s+"[^"]+',
-                group='length_seconds'
+                'length_seconds'
-                    r'"reason","(?P<reason>.*?)"',
+                    r'"reason","[^"]+',
-                    group='reason'
+                    'reason'
-    _VALID_URL = r'https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9-]{28})(?:/preview)'
+    _VALID_URL = r'https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28})'
-            r'<iframe src="https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9-]{28})(?:/preview)',
+            r'<iframe src="https?://(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28})',
-    _VALID_URL = r'https?://(?:docs|drive)\.google\.com/(?:uc\?.*?id=|file/d/)(?P<id>[a-zA-Z0-9-]{28})'
+    _VALID_URL = r'https?://(?:docs|drive)\.google\.com/(?:uc\?.*?id=|file/d/)(?P<id>[a-zA-Z0-9_-]{28})'
-from .googledrive import GoogleDriveIE
+from .googledrive import (
-    _VALID_URL = r'(?:https?://)?(?:video\.google\.com/get_player\?.*?docid=|(?:docs|drive)\.google\.com/(?:uc\?.*?id=|file/d/))(?P<id>.+?)(?:&|/|$)'
+    _VALID_URL = r'https?://(?:docs|drive)\.google\.com/(?:uc\?.*?id=|file/d/)(?P<id>[a-zA-Z0-9-]{28})'
-        'url': 'https://drive.google.com/file/d/0BzpExh0WzJF0NlR5WUlxdEVsY0U/edit?pli=1',
+        'url': 'https://drive.google.com/file/d/0ByeS4oOUV-49Zzh4R1J6R09zazQ/edit?pli=1',
-            'id': '0BzpExh0WzJF0NlR5WUlxdEVsY0U',
+            'id': '0ByeS4oOUV-49Zzh4R1J6R09zazQ',
-            'title': '[AHSH] Fairy Tail S2 - 01 [720p].mp4',
+            'title': 'Big Buck Bunny.mp4',
-            'description': 'md5:16f25aeffdeba55aaa8ec37e093ad8b3',
+    _VALID_URL = r'http://video\.nationalgeographic\.com/.*?'
-    }
+        {
-            # For some reason, the normal links don't work and we must force the use of f4m
+            # For some reason, the normal links don't work and we must force
-            return '%s/%s' % (base_url, target_url)
+            return '%s%s%s' % (base_url, '' if base_url.endswith('/') else '/', target_url)
-            title = titles.get('en') or titles[titles.keys()[0]]
+        title = self.dict_selection(video.get('titles', {}), 'en')
-                description = filtered_descriptions[0]
+            container_titles = video.get('container', {}).get('titles', {})
-        title = titles.get('en') or titles[titles.keys()[0]]
+        title = self.dict_selection(channel['titles'], 'en')
-        description = descriptions.get('en') or descriptions[descriptions.keys()[0]]
+        description = self.dict_selection(channel['descriptions'], 'en')
-        description = descriptions.get('en') or descriptions[titles.keys()[0]] if descriptions else None
+        descriptions = video.get('descriptions', {})
-                new_url = compat_urlparse.urljoin(url, found.group(1))
+                new_url = compat_urlparse.urljoin(url, unescapeHTML(found.group(1)))
-                    add_dash_mpd(get_video_info)
+                    if get_video_info.get('use_cipher_signature') != ['True']:
-from ..utils import parse_filesize, ExtractorError
+from ..utils import parse_filesize
-        duration = float(video['duration'])
+        duration = float_or_none(video.get('duration'))
-        videos = self._download_json(videos_api_url, clip_id, 'Downloading videos JSON')
+        video = self._download_json(videos_api_url, clip_id, 'Downloading videos JSON')[0]
-        source_ids = [source['id'] for source in videos[0]['sources']]
+        if video.get('is_protected') is True:
-                r'^(\d+)[pP]$', format_id, 'height', default=None)
+            height = int_or_none(self._search_regex(
-            'thumbnail': 're:^http:.*\.jpg$',
+            'thumbnail': 're:^https?:.*\.jpg$',
-            'thumbnail': 're:^http:.*\.jpg$',
+            'thumbnail': 're:^https?:.*\.jpg$',
-            for url, ext, res in medias:
+            for media in re.finditer(
-                    'format_id': res + '_' + ext,
+                    'format_id': '%s_%s' % (res, ext) if res else ext,
-            thumbnail_fn = re.findall(r'"(/multimedia/.+?\.jpg)"', playerpage)[-1]
+            thumbnail = self._og_search_thumbnail(playerpage)
-                webpage, 'thumbnail', fatal=False)
+            thumbnail = self._og_search_thumbnail(webpage)
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:sendung/(ts|tsg|tt|nm|bab/bab)|video/video|tsvorzwanzig)(?P<id>-?[0-9]+)(?:~[-_a-zA-Z0-9]*)?\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:[^/]+/)*?[^/#?]+?(?P<id>-?[0-9]+)(?:~_[^/#?]+?)?\.html'
-        }
+        },
-        }
+        'only_matching': True,
-        }
+        'only_matching': True,
-        }
+        'only_matching': True,
-        }
+        'only_matching': True,
-        }
+        'only_matching': True,
-                webpage, 'description', fatal=False, default=None)
+                webpage, 'description', default=None)
-            info['title'] = alt_title + ' - ' + re.sub(r'^' + alt_title + '[\s\-\:]+', '', info['title'])
+            info['title'] = alt_title + ' - ' + re.sub(r'^' + alt_title + '[\s\-:]+', '', info['title'])
-        # 'Full Episode', 'Episode 5', etc. prepend program->title
+        # info['title'] is often incomplete (e.g. 'Full Episode', 'Episode 5', etc)
-        if login_popup == '<div class="run-command close-popup redirect" data-url="https://www.udemy.com/"></div>':
+        def is_logged(webpage):
-               for logout_pattern in ['href="https://www.udemy.com/user/logout/', '>Logout<']):
+        if not is_logged(response):
-        creator = self._html_search_regex(r'<div[^>]+id="description">([^<]+)</div>', webpage, 'creator')
+        creator = self._html_search_regex(
-from ..utils import determine_ext
+from ..utils import (
-            'creator': creator
+            'creator': creator,
-            (?P<only_mins>[0-9.]+)\s*(?:mins?|minutes?)\s*|
+            (?P<only_mins>[0-9.]+)\s*(?:mins?\.?|minutes?)\s*|
-            \s*(?P<hours_reversed>[0-9]+)\s*(?:[:h]|hours?)\s*(?P<mins_reversed>[0-9]+)\s*(?:[:m]|mins?|minutes?)\s*|
+            \s*(?P<hours_reversed>[0-9]+)\s*(?:[:h]|hours?)\s*(?P<mins_reversed>[0-9]+)\s*(?:[:m]|mins?\.?|minutes?)\s*|
-        'md5': 'a9e76f83b3ef58019c4b7dbc35f406c1',
+        'md5': 'ac02b570883020d208d405d5a3fd2f7f',
-            'title': '2 - Endliche Automaten und regulÃ¤re Sprachen'
+            'ext': 'flv',
-        video_url = self._search_regex(r'b.isFirefox..a.useHTML5\).b.setOption.a,"src","(.*.mp4)"\).else', webpage, 'video_url')
+
-            'url': video_url,
+            'formats': formats,
-    _VALID_URL = r'https?://lecture2go.uni-hamburg.de/veranstaltungen/-/v/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://lecture2go\.uni-hamburg\.de/veranstaltungen/-/v/(?P<id>\d+)'
-        title = self._html_search_regex(r'<em class="title">(.*?)</em>', webpage, 'title')
+        title = self._html_search_regex(r'<em[^>]+class="title">(.+)</em>', webpage, 'title')
-        creator = self._html_search_regex(r'<div id="description">(.*)</div>', webpage, 'creator')
+        creator = self._html_search_regex(r'<div[^>]+id="description">([^<]+)</div>', webpage, 'creator')
-from .twitter import TwitterCardIE
+from .twitter import TwitterCardIE, TwitterIE
-            'duration': 30.033,
+    _TESTS = [
-    }
+        {
-            title = info.get('Title') or info['Synopsis']['Title']
+            title = (info.get('Title') or info['Synopsis']['Title']).strip()
-        title = info.get('Title') or synopsis['Title'].strip()
+        title = (info.get('Title') or synopsis['Title']).strip()
-from ..compat import compat_urllib_request
+from ..compat import (
-    _VALID_URL = r'http://(?:www\.)?viewster\.com/movie/(?P<id>\d+-\d+-\d+)'
+    _VALID_URL = r'http://(?:www\.)?viewster\.com/(?:serie|movie)/(?P<id>\d+-\d+-\d+)'
-        # movielink, paymethod=adv
+        # movie, Type=Movie
-        }],
+        'md5': '14d3cfffe66d57b41ae2d9c873416f01',
-        }
+            'ext': 'flv',
-        }],
+        # series episode, Type=Episode
-        }
+            'id': '1284-19427-001',
-            'http://api.live.viewster.com/api/v1/movie/%s' % video_id)
+    def _download_json(self, url, video_id, note='Downloading JSON metadata', fatal=True):
-                request.add_header('Accept', self._ACCEPT_HEADER)
+    def _real_extract(self, url):
-                    request, video_id, 'Downloading movie link JSON', fatal=False)
+        info = self._download_json(
-                    }
+        entry_id = info.get('Id') or info['id']
-                }
+        # unfinished serie has no Type
-                    'title': '%s - %s' % (title, clip['title']),
+        formats = []
-                entries.append(entry)
+        self._sort_formats(formats)
-        return playlist
+        synopsis = info.get('Synopsis', {})
-            if all(_ == 'm3u8' for _ in (type_, ext)):
+            if all(v == 'm3u8' for v in (type_, ext)):
-            if any(_ == 'm3u8' for _ in (type_, ext)):
+            format_id = source.get('label') or ext
-                    r'(\d+)kbps', file_, 'bitrate', default=None))
+                    [r'(\d+)kbps', r'_\d{1,2}x\d{1,2}_(\d{3,})\.%s' % ext],
-__version__ = '2015.07.18'
+__version__ = '2015.07.21'
-        help='Playlist video items to download. Specify indices of the videos in the playlist seperated by commas like: "--playlist-items 1,2,5,8" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: "--playlist-items 1-3,7,10-13", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')
+        help='Playlist video items to download. Specify indices of the videos in the playlist separated by commas like: "--playlist-items 1,2,5,8" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: "--playlist-items 1-3,7,10-13", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')
-            'url': 'http://www.youtube.com/watch?v=BaW_jenozKc',
+            'url': 'http://www.youtube.com/watch?v=BaW_jenozKcj&t=1s',
-                    info_dict['extractor'] in ['youtube', 'ted']):
+                    info_dict['extractor'] in ['youtube', 'ted'] and
-                'upload_date': '20150510',
+                'upload_date': '20150501',  # According to '<meta itemprop="datePublished"', but in other places it's 20150510
-        iframe = self._download_webpage(iframe_url, video_id)
+        iframe = self._download_webpage(iframe_url, video_id,
-            return self.url_result(vimeo_url, 'Vimeo')
+        webpage, urlh = self._download_webpage_handle(url, video_id)
-            webpage, 'iframe url')
+            webpage, 'iframe url', default=None)
-    _VALID_URL = r'%s/(?P<id>[^/]+)/?(?:\#.*)?$' % TwitchBaseIE._VALID_URL_BASE
+    _VALID_URL = r'%s/(?P<id>[^/#?]+)/?(?:\#.*)?$' % TwitchBaseIE._VALID_URL_BASE
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                                    emissions/[^/]+/(?:videos|diffusions)?|
+                                    emissions/[^/]+/(?:videos|diffusions)|
-        if alt_title != '':
+        alt_title = info.get('program', {}).get('title')
-    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/.*?/(?P<name>.+)'
+    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/(?:[^/]+/)+(?P<id>.+)'
-        webpage = self._download_webpage(url, name)
+        video_id = self._match_id(url)
-            },
+            'only_matching': True,
-    _VALID_URL = r'https?://(.+?\.)?vice\.com/.*?/(?P<name>.+)'
+    _VALID_URL = r'https?://(?:.+?\.)?vice\.com/.*?/(?P<name>.+)'
-        'url': 'http://www.ardmediathek.de/tv/Tatort/Das-Wunder-von-Wolbeck-Video-tgl-ab-20/Das-Erste/Video?documentId=22490580&bcastId=602916',
+        'url': 'http://www.ardmediathek.de/tv/Dokumentation-und-Reportage/Ich-liebe-das-Leben-trotzdem/rbb-Fernsehen/Video?documentId=29582122&bcastId=3822114',
-            'id': '22490580',
+            'id': '29582122',
-            'description': 'Auf einem restaurierten Hof bei Wolbeck wird der Heilpraktiker Raffael Lembeck eines morgens von seiner Frau Stella tot aufgefunden. Das Opfer war offensichtlich in seiner Praxis zu Fall gekommen und ist dann verblutet, erklÃ¤rt Prof. Boerne am Tatort.',
+            'title': 'Ich liebe das Leben trotzdem',
-        'skip': 'Blocked outside of Germany',
+    }, {
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-from .ard import ARDIE, ARDMediathekIE
+from .ard import (
-from .sportschau import SportschauIE
+    get_element_by_attribute,
-        }
+    def _extract_media_info(self, media_info_url, webpage, video_id):
-                    determine_ext(format['url']), format['quality'])
+            info = self._extract_media_info(
-        return {
+        info.update({
-        }
+        })
-                'title': 'A More Perfect Union',
+                'title': 'Constitution USA with Peter Sagal - A More Perfect Union',
-                'title': 'Losing Iraq',
+                'title': 'FRONTLINE - Losing Iraq',
-                'title': 'Cyber Schools Gain Popularity, but Quality Questions Persist',
+                'title': 'PBS NewsHour - Cyber Schools Gain Popularity, but Quality Questions Persist',
-                'title': 'Dudamel Conducts Verdi Requiem at the Hollywood Bowl - Full',
+                'title': 'Great Performances - Dudamel Conducts Verdi Requiem at the Hollywood Bowl - Full',
-                'title': 'Killer Typhoon',
+                'title': 'NOVA - Killer Typhoon',
-                'title': 'Death and the Civil War',
+                'title': 'American Experience - Death and the Civil War',
-    _VALID_URL = r'http://www\.vice\.com/.*?/(?P<name>.+)'
+    _VALID_URL = r'https?://(.+?\.)?vice\.com/.*?/(?P<name>.+)'
-    }
+    _TESTS = [
-)
+from ..compat import compat_urlparse
-                'description': 'md5:',
+                'description': 'md5:61f08036dcc8f47e9cfc33aed08ffaff',
-            'md5': '52f0bfe202848b15915a2f39aaa8981b',
+            'url': 'http://www.franceo.fr/jt/info-soir/18-07-2015',
-                'id': '108634970',
+                'id': '125377621',
-                'timestamp': 1410822000,
+                'title': 'InfÃ´ soir',
-                    formats.extend(self._extract_f4m_formats(f4m_url, video_id, 1, format_id))
+                    formats.extend(self._extract_f4m_formats(
-                                    videos
+                                    videos|
-                    'http://hdfauth.francetv.fr/esi/TA?url=%s' % video_url_parsed.path,
+                    'http://hdfauth.francetv.fr/esi/TA?url=%s' % video_url,
-            'title': 'Seppelt: "Kokain hat nichts mit klassischem Doping zu tun" - Tour de France - sportschau.de',
+            'title': 'Seppelt: "Kokain hat nichts mit klassischem Doping zu tun"',
-        title = self._html_search_regex(r'<title>(.*?)</title>', webpage, 'title')
+        title = get_element_by_attribute('class', 'headline', webpage)
-        }
+        },
-    float_or_none,
+        'params': {
-            'description': '',
+            'description': None,
-            'description': '',
+            'description': None,
-            'description': '',
+            'description': None,
-                pass
+            description = self._html_search_regex(
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:sendung/(ts|tsg|tt|nm)|video/video|tsvorzwanzig)(?P<id>-?[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:sendung/(ts|tsg|tt|nm|bab/bab)|video/video|tsvorzwanzig)(?P<id>-?[0-9]+)(?:~[-_a-zA-Z0-9]*)?\.html'
-        'md5': 'bcdeac2194fb296d599ce7929dfa4009',
+        'url': 'http://www.tagesschau.de/multimedia/video/video-102143.html',
-            'id': '1399128',
+            'id': '102143',
-            'description': 'md5:69da3c61275b426426d711bde96463ab',
+            'title': 'Regierungsumbildung in Athen: Neue Minister in Griechenland vereidigt',
-from ..utils import parse_filesize
+from ..utils import parse_filesize, ExtractorError
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:sendung/ts|video/video)(?P<id>-?[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:sendung/(ts|tsg|tt|nm)|video/video|tsvorzwanzig)(?P<id>-?[0-9]+)\.html'
-                webpage, 'description', fatal=False)
+            # there are some videos without description
-        description = json_data['description']
+        thumbnail = json_data.get('image')
-}
+)
-from ..utils import get_element_by_id
+from ..utils import (
-                self.report_warning(error)
+                raise ExtractorError(error)
-            r'file: "(?P<m3u8_url>.*?)"',
+            r'file:\s*"([^"]+)',
-            group='m3u8_url'
+            'm3u8_url'
-)
+from ..utils import ExtractorError
-        description = material.get('synopsis') or info['episodes'][0]['synopsis']
+        title = info['abstracts'][0]['name']
-            'title': '%s - %s' % (progname, subtitle),
+            'title': title,
-            'duration': float_or_none(info.get('real_duration'), 1000) or parse_duration(info['duree']),
+            'duration': int_or_none(info.get('real_duration')) or parse_duration(info['duree']),
-        )'''
+    _VALID_URL = r'''(?x)
-        webpage = self._download_webpage(url, mobj.group('key') or mobj.group('id'))
+        video_id = self._match_id(url)
-            r'href="http://videos\.francetv\.fr/video/([^@]+@[^"]+)"',
+            r'href="http://videos?\.francetv\.fr/video/([^@]+@[^"]+)"',
-    _VALID_URL = r'https?://(?:www\.)?tudou\.com/(?:listplay|programs(?:/view)?|albumplay)/.*?/(?P<id>[^/?#]+?)(?:\.html)?/?(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?tudou\.com/(?:listplay|programs(?:/view)?|albumplay)/?.*/(?P<id>[^/?#]+?)(?:\.html)?/?(?:$|[?#])'
-    _asciire = re.compile('([\x00-\x7f]+)') if sys.version_info < (2, 7) else compat_urllib_parse._asciire
+    _asciire = (compat_urllib_parse._asciire if hasattr(compat_urllib_parse, '_asciire')
-            for video_id in set(re.findall(r'href="/video(-?[0-9_]+)"', webpage))]
+            for video_id in orderedSet(re.findall(r'href="/video(-?[0-9_]+)"', webpage))]
-            raise ExtractorError('The video does not exist or was deleted', expected=True)
+        if '(æ­¤è§é¢ä¸å­å¨æè¢«å é¤)' in webpage:
-    IE_NAME = 'vk.com'
+    IE_NAME = 'vk'
-    IE_DESC = 'vk.com:All of a user\'s videos'
+    IE_NAME = 'vk:uservideos'
-    _VALID_URL = r'https?://vk\.com/videos(?P<id>[0-9]+)(?:m\?.*)?'
+    _VALID_URL = r'https?://vk\.com/videos(?P<id>-?[0-9]+)$'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        url_entries = [
+
-        return self.playlist_result(url_entries, page_id)
+            for video_id in set(re.findall(r'href="/video(-?[0-9_]+)"', webpage))]
-            return ([], rtmp_count)
+            return [], rtmp_count
-            return (self._extract_m3u8_formats(src, video_id, ext), rtmp_count)
+            return self._extract_m3u8_formats(src, video_id, ext), rtmp_count
-__version__ = '2015.07.07'
+__version__ = '2015.07.18'
-
+        enc_key = '8e29ab5666d041c3a1ea76e06dabdffb'
-        guid = self._search_regex(r'data-video-guid="([^"]+)"', webpage, 'guid')
+        feed_url = self._search_regex(
-    _VALID_URL = r'https?://(?:www\.)?videomega\.tv/(?:(?:view|iframe|cdn)\.php)?\?ref=(?P<id>[A-Za-z0-9]+)'
+    _VALID_URL = r'(?:videomega:|https?://(?:www\.)?videomega\.tv/(?:(?:view|iframe|cdn)\.php)?\?ref=)(?P<id>[A-Za-z0-9]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        'url': 'http://videomega.tv/cdn.php?ref=AOSQBJYKIDDIKYJBQSOA&width=1070&height=600',
+        'url': 'http://videomega.tv/cdn.php?ref=AOSQBJYKIDDIKYJBQSOA',
-        req = compat_urllib_request.Request(url)
+        iframe_url = 'http://videomega.tv/cdn.php?ref=%s' % video_id
-                'Referer': url,
+                'Referer': iframe_url,
-        '''
+    _VALID_URL = r'https?://(?:www\.)?videomega\.tv/(?:(?:view|iframe|cdn)\.php)?\?ref=(?P<id>[A-Za-z0-9]+)'
-        'md5': 'bf5c2f95c4c917536e80936af7bc51e1',
+        'url': 'http://videomega.tv/cdn.php?ref=AOSQBJYKIDDIKYJBQSOA&width=1070&height=600',
-            'id': '4GNA688SU99US886ANG4',
+            'id': 'AOSQBJYKIDDIKYJBQSOA',
-            'title': 'BigBuckBunny_320x180',
+            'title': '1254207',
-        req = compat_urllib_request.Request(iframe_url)
+        req = compat_urllib_request.Request(url)
-            r'<title>(.*?)</title>', webpage, 'title')
+            r'<title>(.+?)</title>', webpage, 'title')
-            r'(?:^[Vv]ideo[Mm]ega\.tv\s-\s?|\s?-\svideomega\.tv$)', '', title)
+            r'(?:^[Vv]ideo[Mm]ega\.tv\s-\s*|\s*-\svideomega\.tv$)', '', title)
-                'Referer': iframe_url,
+                'Referer': url,
-    _VALID_URL = r'https?://(?:www\.)?sbs\.com\.au/ondemand/video/(?:single/)?(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?sbs\.com\.au/(?:ondemand|news)/video/(?:single/)?(?P<id>[0-9]+)'
-            'description': 'Dingoes are on the brink of extinction; most of the animals we think are dingoes are in fact crossbred with wild dogs. This family run a dingo conservation park to prevent their extinction',
+            'title': 'Dingo Conservation (The Feed)',
-        'add_ies': ['generic'],
+    }, {
-        player_params_json = self._parse_json(player_params_js, video_id)
+        webpage = self._download_webpage(
-        theplatform_url = player_params_json.get('releaseUrls')['progressive'] or player_params_json.get('releaseUrls')['standard']
+        player_params = self._parse_json(
-        thumbnail = self._og_search_thumbnail(webpage)
+        urls = player_params['releaseUrls']
-            'thumbnail': thumbnail,
+        {
-            'md5': 'c6934ad0b6acf2bd920720ec888eb812',
+            'md5': '80baf1ec5c3d2019037c1c707d676b9f',
-                'ext': 'mov',
+                'ext': 'm4v',
-            return '{http://www.itunes.com/dtds/podcast-1.0.dtd}%s' % s
+        def _x(p):
-        categories = [category.text for category in item.findall('category')]
+        video_id = xpath_text(item, _x('blip:item_id'), 'video id') or lookup_id
-        for media_content in media_group.findall(media('content')):
+        media_group = item.find(_x('media:group'))
-            role = media_content.get(blip('role'))
+            role = media_content.get(_x('blip:role'))
-                    'acodec': media_content.get(blip('acodec')),
+                    'vcodec': media_content.get(_x('blip:vcodec')) or 'none',
-        bits = compat_urllib_parse._asciire.split(string)
+        bits = _asciire.split(string)
-            video_url = compat_urlparse.unquote(config['clip']['url'])
+            video_url = compat_urllib_parse_unquote(config['clip']['url'])
-)
+from ..compat import compat_urllib_parse_unquote
-            url = proto + '://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')
+            url = proto + '://www.youtube.com/' + compat_urllib_parse_unquote(mobj.group(1)).lstrip('/')
-        video_uploader = compat_urllib_parse.unquote_plus(video_info['author'][0])
+        video_uploader = compat_urllib_parse_unquote_plus(video_info['author'][0])
-            video_thumbnail = compat_urllib_parse.unquote_plus(video_info['thumbnail_url'][0])
+            video_thumbnail = compat_urllib_parse_unquote_plus(video_info['thumbnail_url'][0])
-            video_duration = int(compat_urllib_parse.unquote_plus(video_info['length_seconds'][0]))
+            video_duration = int(compat_urllib_parse_unquote_plus(video_info['length_seconds'][0]))
-        query = compat_urllib_parse.unquote_plus(mobj.group('query'))
+        query = compat_urllib_parse_unquote_plus(mobj.group('query'))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_unquote_plus
-        content = compat_urllib_parse.unquote_plus(self._og_search_video_url(webpage))
+        content = compat_urllib_parse_unquote_plus(self._og_search_video_url(webpage))
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-        video_url = compat_urllib_parse.unquote(
+        video_url = compat_urllib_parse_unquote(
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-                'url': compat_urllib_parse.unquote(video_url),
+                'url': compat_urllib_parse_unquote(video_url),
-            video_url = compat_urllib_parse.unquote(self._search_regex(
+            video_url = compat_urllib_parse_unquote(self._search_regex(
-)
+from ..compat import compat_urllib_parse_unquote
-        video_url = compat_urllib_parse.unquote(video_url)
+        video_url = compat_urllib_parse_unquote(video_url)
-)
+from ..compat import compat_urllib_parse_unquote
-        config_url = compat_urllib_parse.unquote(config_url_enc)
+        config_url = compat_urllib_parse_unquote(config_url_enc)
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-            compat_urllib_parse.unquote,
+            compat_urllib_parse_unquote,
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-            thumbnail = compat_urllib_parse.unquote(thumbnail)
+            thumbnail = compat_urllib_parse_unquote(thumbnail)
-        video_urls = list(map(compat_urllib_parse.unquote, re.findall(r'"quality_[0-9]{3}p":"([^"]+)', webpage)))
+        video_urls = list(map(compat_urllib_parse_unquote, re.findall(r'"quality_[0-9]{3}p":"([^"]+)', webpage)))
-            password = compat_urllib_parse.unquote_plus(
+            password = compat_urllib_parse_unquote_plus(
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-        infos = compat_urllib_parse.unquote(flashvars).split(r'&')
+        infos = compat_urllib_parse_unquote(flashvars).split(r'&')
-                    video_title = compat_urllib_parse.unquote_plus(val)
+                    video_title = compat_urllib_parse_unquote_plus(val)
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_unquote
-        url = compat_urllib_parse.unquote(self._html_search_regex(r'file=(.+\.mp4)', info['linkcodes']['html'], 'url'))
+        url = compat_urllib_parse_unquote(self._html_search_regex(r'file=(.+\.mp4)', info['linkcodes']['html'], 'url'))
-    compat_urllib_parse,
+    compat_urllib_parse_unquote_plus,
-        player = compat_urllib_parse.unquote_plus(
+        player = compat_urllib_parse_unquote_plus(
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_unquote
-                compat_urllib_parse.unquote(flashvars['metadataUrl']),
+                compat_urllib_parse_unquote(flashvars['metadataUrl']),
-                encxml = compat_urllib_parse.unquote(b)
+                encxml = compat_urllib_parse_unquote(b)
-            video_url = compat_urllib_parse.unquote(mobj.group(1))
+            video_url = compat_urllib_parse_unquote(mobj.group(1))
-            video_url = compat_urllib_parse.unquote(mobj.group(1)) + compat_urllib_parse.unquote(mobj.group(2))
+            video_url = compat_urllib_parse_unquote(mobj.group(1)) + compat_urllib_parse_unquote(mobj.group(2))
-        video_file = compat_urllib_parse.unquote(video_file)
+        video_file = compat_urllib_parse_unquote(video_file)
-        video_swfobj = compat_urllib_parse.unquote(video_swfobj)
+        video_swfobj = compat_urllib_parse_unquote(video_swfobj)
-        video_url = compat_urllib_parse.unquote(self._html_search_regex(r'flashvars.video_url = \'([^\']+)', webpage, 'video_url'))
+        video_url = compat_urllib_parse_unquote(self._html_search_regex(r'flashvars.video_url = \'([^\']+)', webpage, 'video_url'))
-)
+from ..compat import compat_urllib_parse_unquote
-        track_id = compat_urllib_parse.unquote('-'.join((uploader, cloudcast_name)))
+        track_id = compat_urllib_parse_unquote('-'.join((uploader, cloudcast_name)))
-            compat_urllib_parse.unquote(embed_data['flashvars']['host'])
+            compat_urllib_parse_unquote(embed_data['flashvars']['host'])
-            mediaURL = compat_urllib_parse.unquote(mobj.group(1))
+            mediaURL = compat_urllib_parse_unquote(mobj.group(1))
-)
+from ..compat import compat_urllib_parse_unquote
-        video_url = compat_urllib_parse.unquote(self._search_regex(
+        video_url = compat_urllib_parse_unquote(self._search_regex(
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_unquote_plus
-        config_json = compat_urllib_parse.unquote_plus(self._search_regex(
+        config_json = compat_urllib_parse_unquote_plus(self._search_regex(
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-        real_id = compat_urllib_parse.unquote(base64.b64decode(encoded_id.encode('ascii')).decode('utf-8'))
+        real_id = compat_urllib_parse_unquote(base64.b64decode(encoded_id.encode('ascii')).decode('utf-8'))
-            return self.url_result(compat_urllib_parse.unquote(mobj.group('url')))
+            return self.url_result(compat_urllib_parse_unquote(mobj.group('url')))
-            video_id = compat_urllib_parse.unquote(os.path.basename(video_url))
+            video_id = compat_urllib_parse_unquote(os.path.basename(video_url))
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-            'title': compat_urllib_parse.unquote(data_video['title']),
+            'title': compat_urllib_parse_unquote(data_video['title']),
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-        params_raw = compat_urllib_parse.unquote(data['params'])
+        params_raw = compat_urllib_parse_unquote(data['params'])
-    compat_urllib_parse,
+    compat_urllib_parse_unquote,
-        final_url = compat_urllib_parse.unquote(video_url)
+        final_url = compat_urllib_parse_unquote(video_url)
-        playerdata_url = compat_urllib_parse.unquote(self._html_search_regex(r'"config_url":"([^"]+)', webpage, 'playerdata_url'))
+        playerdata_url = compat_urllib_parse_unquote(self._html_search_regex(r'"config_url":"([^"]+)', webpage, 'playerdata_url'))
-        req = compat_urllib_request.Request(compat_urllib_parse.unquote(playlist_url))
+        req = compat_urllib_request.Request(compat_urllib_parse_unquote(playlist_url))
-from ..compat import compat_urllib_parse
+from ..compat import compat_urllib_parse_unquote
-        media_url = compat_urllib_parse.unquote(self._search_regex(
+        media_url = compat_urllib_parse_unquote(self._search_regex(
-    # HACK: The following are the correct unquote_to_bytes and unquote
+    # HACK: The following are the correct unquote_to_bytes, unquote and unquote_plus
-            self.assertEqual(strutf, compat_urllib_parse_unquote(strurlenc))
+        self.assertEqual(compat_urllib_parse_unquote(''), '')
-except ImportError:
+except ImportError:  # Python 2
-        if isinstance(string, str):
+        if isinstance(string, unicode):
-
+        bits = string.split(b'%')
-                append(item[:2].decode('hex'))
+                append(compat_urllib_parse._hextochr[item[:2]])
-            except:
+            except KeyError:
-        bits = compat_urllib_parse_asciire.split(string)
+        bits = compat_urllib_parse._asciire.split(string)
-                append(bar)
+            append(compat_urllib_parse_unquote_to_bytes(bits[i]).decode(encoding, errors))
-            },
+            'only_matching': True,
-    _VALID_URL = r'https?://[\da-z-]+\.howstuffworks\.com/(?:[^/]+/)*(\d+-)*(?P<id>.+?)-video\.htm'
+    _VALID_URL = r'https?://[\da-z-]+\.howstuffworks\.com/(?:[^/]+/)*(?:\d+-)?(?P<id>.+?)-video\.htm'
-    _VALID_URL = r'https?://[\da-z-]+\.howstuffworks\.com/(?:[^/]+/)*\d+-(?P<id>.+?)-video\.htm'
+    _VALID_URL = r'https?://[\da-z-]+\.howstuffworks\.com/(?:[^/]+/)*(\d+-)*(?P<id>.+?)-video\.htm'
-     },{
+    }, {
-        re_desc = re.search(r'<meta property=.og:description. content=(["\'])(.+?)\1',webpage,re.DOTALL)
+        re_desc = re.search(r'<meta property=.og:description. content=(["\'])(.+?)\1', webpage, re.DOTALL)
-        for key in ('caption_file','.......'):
+        for key in ('caption_file', '.......'):
-            if url == '' or url == None:
+            url = js.get(key, '')
-            if not re.match(r'^https?://',url):
+            if not re.match(r'^https?://', url):
-            ext = re.search(r'\.([^\.]+)$',url).group(1)
+            ext = re.search(r'\.([^\.]+)$', url).group(1)
-            if url == '' or url == None:
+            url = js.get(key, '')
-            if not re.match(r'^https?://',url):
+            if not re.match(r'^https?://', url):
-            if video_id == None:
+            purl = re.search(r'/(?P<dir>[^/]+)/(?:dn)?(?P<fn>[^/]+?)\.(?P<ext>[^\.\?]+)(?P<hasparams>\?|$)', url)
-            if js.get('start') != None:
+            if js.get('start') is not None:
-                url = url + 'start='+str(js.get('start'))
+                url = url + 'start=' + str(js.get('start'))
-    },{
+    }, {
-    },{
+    }, {
-    },{
+    }, {
-    },{
+    }, {
-           pubdate = pubdate.replace('-','')
+            pubdate = pubdate.replace('-', '')
-           re.findall(r"data-media-meta='({[^']+})'", webpage)
+            lambda m: self._parse_json(m, list_id),
-                      jsent.append(sval)
+            # http://www.bbc.com/news/video_and_audio/international
-           )          
+            # stubbornly generic extractor for {json with "image":{allvideoshavethis},etc}
-           raise ExtractorError('No video found', expected=True)
+            raise ExtractorError('No video found', expected=True)
-            title = jent.get('caption','')
+            title = jent.get('caption', '')
-               title = list_title
+                title = list_title
-               description += ' - ' + jent.get('caption')
+                description += ' - ' + jent.get('caption')
-               thumbnail=jent['image'].get('href')
+            if jent.get('image') is not None:
-                  } )
+                formats, subtitles = self._download_media_selector(programme_id)
-               formats, subtitles = self._download_media_selector(programme_id)
+                # Cheap fallback
-               
+                raise ExtractorError('unsupported json media entry.\n    ' + str(jent) + '\n')
-               id = 'NA'
+            id = jent.get('id') if programme_id is None else programme_id
-            ret.append( {
+            ret.append({
-            } )
+            })
-           return self.playlist_result(ret, list_id, list_title)
+            return self.playlist_result(ret, list_id, list_title)
-            title = jent.get('caption',list_title)
+            title = jent.get('caption','')
-            if jent.get('caption'):
+            if jent.get('caption', '') != '':
-    def new_compat_urllib_parse_unquote(string, encoding='utf-8', errors='replace'):
+    def compat_urllib_parse_unquote(string, encoding='utf-8', errors='replace'):
-
+from pprint import (pprint, pformat)
-    def compat_urllib_parse_unquote(string, encoding='utf-8', errors='replace'):
+    def compat_urllib_parse_unquote_to_bytes(string):
-    def _extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None):
+    def _extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None,
-            transform_source=lambda s: fix_xml_ampersands(s).strip())
+            transform_source=transform_source)
-                'title': 'De Mega Mike & Mega Thomas show',
+                'title': 'De Mega Mike & Mega Thomas show: The best of.',
-                'title': 'Tegenlicht',
+                'title': 'Tegenlicht: De toekomst komt uit Afrika',
-            'title': metadata.get('aflevering_titel') or metadata['titel'],
+            'title': title,
-    url_basename,
+        },
-            self.url_result('npo:%s' % video_id, 'NPO')
+            self.url_result('npo:%s' % video_id if not video_id.startswith('http') else video_id)
-            'description': metadata['info'],
+            'description': metadata.get('info'),
-            'title': metadata['titel'],
+            # prefer aflevering_titel if any since titel may be too generic, e.g.
-                'title': 'Tegenlicht',
+                'title': 'De toekomst komt uit Afrika',
-    TegenlichtVproIE,
+    VPROIE,
-    _VALID_URL = r'https?://tegenlicht\.vpro\.nl/afleveringen/.*?'
+class VPROIE(NPOIE):
-                'description': 'md5:d6476bceb17a8c103c76c3b708f05dd1',
+                'description': 'md5:52cf4eefbc96fffcbdc06d024147abea',
-        return self._get_info(info_page['mid'])
+        playlist_id = self._match_id(url)
-                            omroepwnl\.nl/video/fragment/[^/]+__
+                    (?:
-                'description': 'md5:d6476bceb17a8c103c76c3b708f05dd1',
+                'description': 'md5:52cf4eefbc96fffcbdc06d024147abea',
-    _VALID_URL = r'https?://(?:www\.)?(?:npo|ntr)\.nl/(?!live|radio)(?:[^/]+/){2,}(?P<id>[^/?#]+)'
+    _VALID_URL = r'''(?x)
-    _VALID_URL = r'https?://(?:www\.)?npo\.nl/(?!live|radio)[^/]+/[^/]+/(?P<id>[^/?]+)'
+    IE_NAME = 'npo'
-        webpage = compat_urllib_parse.unquote(webpage)
+        webpage = compat_urllib_parse_unquote(webpage)
-                media_url = media_el.attrib.get('href') or media_el.attrib['url']
+                media_url = media_el.attrib.get('href') or media_el.attrib.get('url')
-    fix_xml_ampersands,
+    determine_ext,
-                            manifest_url, clip_id, f4m_id='hds'))
+            elif 'f4mgenerator' in source_url or determine_ext(source_url) == 'f4m':
-                                (media_el.attrib.get('href') or media_el.attrib.get('url')))
+                media_url = media_el.attrib.get('href') or media_el.attrib['url']
-            'Unable to download f4m manifest')
+            'Unable to download f4m manifest',
-    unified_strdate,
+    fix_xml_ampersands,
-        client_name = 'kolibri-1.12.6'
+        client_name = 'kolibri-2.0.19-splec4'
-                mobj = re.search(r'^(?P<url>rtmpe?://[^/]+)/(?P<path>.+)$', source['url'])
+                mobj = re.search(r'^(?P<url>rtmpe?://[^/]+)/(?P<path>.+)$', source_url)
-                    'url': source['url'],
+                    'url': source_url,
-            'ext': 'flv',
+            'formats': formats,
-    _VALID_URL = r'https?://tv\.dfb\.de/video/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'https?://tv\.dfb\.de/video/(?P<display_id>[^/]+)/(?P<id>\d+)'
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id)
-            video_id)
+            display_id)
-        f4m_info = self._download_xml(self._proto_relative_url(video_info.find('url').text.strip()), video_id)
+        f4m_info = self._download_xml(
-            'upload_date': ''.join(video_info.find('time_date').text.split('.')[::-1]),
+            'upload_date': unified_strdate(video_info.find('time_date').text),
-        'url': 'http://tv.dfb.de/video/highlights-des-empfangs-in-berlin/9070/',
+        'url': 'http://tv.dfb.de/video/u-19-em-stimmen-zum-spiel-gegen-russland/11633/',
-            'id': '9070',
+            'id': '11633',
-            'upload_date': '20140716',
+            'title': 'U 19-EM: Stimmen zum Spiel gegen Russland',
-    _VALID_URL = r'http://.*?\.jeuxvideo\.com/.*/(.*?)-\d+\.htm'
+    _VALID_URL = r'http://.*?\.jeuxvideo\.com/.*/(.*?)\.htm'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _LOGIN_URL = 'https://www.udemy.com/join/login-submit/'
+    _LOGIN_URL = 'https://www.udemy.com/join/login-popup/?displayType=ajax&showSkipButton=1'
-            'Downloading login popup')
+            self._LOGIN_URL, None, 'Downloading login popup')
-            login_popup, 'csrf token')
+        login_form = self._form_hidden_inputs('login-form', login_popup)
-            'csrf': csrf,
+        login_form.update({
-        }
+            'email': username.encode('utf-8'),
-        response = self._download_json(
+        request.add_header('Referer', self._ORIGIN_URL)
-        if 'returnUrl' not in response:
+        if all(logout_pattern not in response
-            html))
+    def _hidden_inputs(html):
-        fields = self._form_hidden_inputs(webpage)
+        fields = self._hidden_inputs(webpage)
-        fields = self._form_hidden_inputs(webpage)
+        fields = self._hidden_inputs(webpage)
-        data = self._form_hidden_inputs(orig_webpage)
+        data = self._hidden_inputs(orig_webpage)
-        fields = self._form_hidden_inputs(webpage)
+        fields = self._hidden_inputs(webpage)
-        fields = self._form_hidden_inputs(webpage)
+        fields = self._hidden_inputs(webpage)
-        download_form = self._form_hidden_inputs(webpage)
+        download_form = self._hidden_inputs(webpage)
-        login_form = self._form_hidden_inputs(login_page)
+        login_form = self._hidden_inputs(login_page)
-        fields = self._form_hidden_inputs(login_form)
+        fields = self._hidden_inputs(login_form)
-        login_form = self._form_hidden_inputs(login_page)
+        login_form = self._hidden_inputs(login_page)
-        fields = self._form_hidden_inputs(webpage)
+        fields = self._hidden_inputs(webpage)
-            self._downloader.to_screen('[youtube] Post-process file %s exists, skipping' % new_path)
+            self._downloader.to_screen('[ffmpeg] Post-process file %s exists, skipping' % new_path)
-            % (consumer_secret, series_id),
+            % (self._consumer_secret, series_id),
-                % (consumer_secret, series_id, self._PAGE_SIZE, page_num),
+                % (self._consumer_secret, series_id, self._PAGE_SIZE, page_num),
-        metadata = self._download_xml(metadata_url, video_id)
+        metadata = self._download_xml(
-            'https://api.nowtv.de/v3/movies/%s?fields=*,format,files' % display_id,
+            'https://api.nowtv.de/v3/movies/%s?fields=id,title,free,geoblocked,articleLong,articleShort,broadcastStartDate,seoUrl,duration,format,files' % display_id,
-)
+from ..utils import remove_end
-        webpage = self._download_webpage(url, video_id)
+        # the video is in the following iframe
-        player = re.sub(r"'\s*\+\s*[\da-zA-Z_]+\s*\+\s*'", '', player)
+        player_params = self._search_regex(
-        release_urls = self._parse_json(js_to_json(player), video_id)
+        player_params_json = self._parse_json(player_params_js, video_id)
-        theplatform_url = release_urls.get('progressive') or release_urls['standard']
+        theplatform_url = player_params_json.get('releaseUrls')['progressive'] or player_params_json.get('releaseUrls')['standard']
-        title = remove_end(self._og_search_title(webpage), ' (The Feed)')
+        title = remove_end(self._og_search_title(webpage, default=video_id, fatal=False), ' (The Feed)')
-    _VALID_URL = r'https?://(?:www\.)?rds\.ca/videos/(?:[^/]+/)+(?P<display_id>[^/]+)-(?P<id>\d+\.\d+)'
+    _VALID_URL = r'https?://(?:www\.)?rds\.ca/vid(?:[eÃ©]|%C3%A9)os/(?:[^/]+/)*(?P<display_id>[^/]+)-(?P<id>\d+\.\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-from .rdsca import RDScaIE
+from .rds import RDSIE
-        return self._extract_f4m_formats(manifest_url + '?hdcore=3.1.1&plugin=aasp-3.1.1.69.124', video_id)
+        return self._extract_f4m_formats(
-            formats.extend(self._extract_m3u8_formats(m3u8_url.group(1), video_id, 'mp4'))
+            formats.extend(self._extract_m3u8_formats(m3u8_url.group(1), video_id, 'mp4', m3u8_id='hls'))
-    _VALID_URL = r'(?P<baseurl>https?://tv\.nrk(?:super)?\.no/)(?:serie/[^/]+|program)/(?P<id>[a-zA-Z]{4}\d{8})(?:/\d{2}-\d{2}-\d{4})?(?:#del=(?P<part_id>\d+))?'
+    IE_DESC = 'NRK TV and NRK Radio'
-            r'share_title\s*=\s*"([^"]+)"', webpage, 'title')
+            r'share_title\s*=\s*(["\'])(?P<title>[^\1]+?)\1',
-            'description', default=None)
+            r'share_description\s*=\s*(["\'])(?P<description>[^\1]+?)\1',
-            r'poster="([^"]+)"', webpage, 'thumbnail', default=False)
+            r'poster\s*=\s*(["\'])(?P<thumbnail>[^\1]+?)\1',
-            webpage, 'uploader id', fatal=False)
+            r'twitter_handle\s*=\s*(["\'])(?P<uploader_id>[^\1]+?)\1',
-            webpage, 'uploader', default=False)
+            r'window\.channelName\s*=\s*(["\'])Embedded:(?P<uploader>[^\1]+?)\1',
-        'postprocessor_args': shlex.split(opts.postprocessor_args or ''),
+        'postprocessor_args': postprocessor_args,
-            options.extend(['-c:v', 'libxvid', '-vtag', 'XVID'])
+        options = []
-    --postprocessor-args.
+    to InfoExtractor objects.
-        self._extra_cmd_args = downloader.params.get('postprocessor_args')
+    def _configuration_args(self, default=[]):
-    postprocessor_args: Extra parameters for external apps, like avconv.
+    postprocessor_args: A list of additional command-line arguments for the
-        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg', 'mkv', 'xvid']:
+        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg', 'mkv', 'avi']:
-        help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|xvid)')
+        help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|avi)')
-        help='Extra parameters for video post-processor.')
+        dest='postprocessor_args', metavar='ARGS',
-        ext = self._preferedformat
+        outpath = prefix + sep + self._preferedformat
-            ext = 'avi'
+        if self._preferedformat == 'avi':
-        information['ext'] = ext
+        information['ext'] = self._preferedformat
-                            (?P<videoid>[^s].*?)(?:\?|%2F|$)
+                            (?P<videoid>[^s].*?)(?:\?(?:.*\blist=(?P<list_id>[\da-f]+))?|%2F|$)
-    _TESTS = []
+    _TEST = {
-        return self.playlist_result(entries, playlist_id, title, description)
+        title = self._search_regex(
-
+    IE_DESC = 'QQé³ä¹ - æ­æ'
-            webpage, 'singer name', default=None)
+            webpage, 'singer name', fatal=False)
-            webpage, 'album id', default=None, fatal=False)
+            webpage, 'album id', fatal=False)
-                'publish time', default=None)
+                'publish time', fatal=False)
-            ''', webpage))
+        fields = self._form_hidden_inputs(webpage)
-            ''', webpage))
+        fields = self._form_hidden_inputs(webpage)
-        data = dict(fields)
+        data = self._form_hidden_inputs(orig_webpage)
-    _VALID_URL = r'http://www\.kuwo\.cn/yinyue/(?P<id>[0-9]+?)/'
+    _VALID_URL = r'http://www\.kuwo\.cn/yinyue/(?P<id>\d+?)/'
-    _VALID_URL = r'http://www\.kuwo\.cn/album/(?P<id>[0-9]+?)/'
+    _VALID_URL = r'http://www\.kuwo\.cn/album/(?P<id>\d+?)/'
-            'description': 're:[0-9]{4}ç¬¬[0-9]{2}æ',
+            'description': 're:\d{4}ç¬¬\d{2}æ',
-        first_page_only = False if re.search(r'/music(?:_[0-9]+)?\.htm', url) else True
+        first_page_only = False if re.search(r'/music(?:_\d+)?\.htm', url) else True
-    _VALID_URL = r'http://yinyue\.kuwo\.cn/yy/cinfo_(?P<id>[0-9]+?).htm'
+    _VALID_URL = r'http://yinyue\.kuwo\.cn/yy/cinfo_(?P<id>\d+?).htm'
-    _VALID_URL = r'http://www\.kuwo\.cn/mv/(?P<id>[0-9]+?)/'
+    _VALID_URL = r'http://www\.kuwo\.cn/mv/(?P<id>\d+?)/'
-            ''', webpage))
+        fields = self._form_hidden_inputs(webpage)
-            ''', webpage))
+        fields = self._form_hidden_inputs(webpage)
-            r'<input type="hidden" name="([^"]+)" value="([^"]*)"', webpage))
+        download_form = self._form_hidden_inputs(webpage)
-            ''', login_form))
+        fields = self._form_hidden_inputs(login_form)
-                r'<p[^>]+class="listen"><a[^>]+href="http://www\.kuwo\.cn/yinyue/(\d+)/"',
+            self.url_result(song_url, 'Kuwo') for song_url in re.findall(
-                r'<a[^>]+href="http://www\.kuwo\.cn/yinyue/(\d+)/"', webpage)
+            self.url_result(song_url, 'Kuwo') for song_url in re.findall(
-                    r'<p[^>]+class="m_name"><a[^>]+href="http://www\.kuwo\.cn/yinyue/([0-9]+)/',
+                self.url_result(song_url, 'Kuwo') for song_url in re.findall(
-                'Kuwo', song['musicrid'])
+            self.url_result('http://www.kuwo.cn/yinyue/%s/' % song['musicrid'], 'Kuwo')
-            ''', webpage))
+        fields = self._form_hidden_inputs(webpage)
-            login_page))
+        login_form = self._form_hidden_inputs(login_page)
-            login_page))
+        login_form = self._form_hidden_inputs(login_page)
-                "http://antiserver.kuwo.cn/anti.s?format=%s&br=%s&rid=MUSIC_%s&type=convert_url&response=url" %
+                'http://antiserver.kuwo.cn/anti.s?format=%s&br=%s&rid=MUSIC_%s&type=convert_url&response=url' %
-                song_id, note="Download %s url info" % file_format["format"],
+                song_id, note='Download %s url info' % file_format['format'],
-        lrc_content = clean_html(get_element_by_id("lrcContent", webpage))
+        lrc_content = clean_html(get_element_by_id('lrcContent', webpage))
-                "http://www.kuwo.cn/album/%s/" % album_id, song_id,
+                'http://www.kuwo.cn/album/%s/' % album_id, song_id,
-            clean_html(get_element_by_id("intro", webpage)),
+            clean_html(get_element_by_id('intro', webpage)),
-            self.url_result("http://www.kuwo.cn/yinyue/%s/" % song_id, 'Kuwo', song_id)
+            self.url_result('http://www.kuwo.cn/yinyue/%s/' % song_id, 'Kuwo', song_id)
-            self.url_result("http://www.kuwo.cn/yinyue/%s/" % song_id, 'Kuwo', song_id)
+            self.url_result('http://www.kuwo.cn/yinyue/%s/' % song_id, 'Kuwo', song_id)
-                self.url_result("http://www.kuwo.cn/yinyue/%s/" % song_id, 'Kuwo', song_id)
+                self.url_result('http://www.kuwo.cn/yinyue/%s/' % song_id, 'Kuwo', song_id)
-            get_element_by_id("intro", webpage).strip(),
+            get_element_by_id('intro', webpage).strip(),
-                "http://www.kuwo.cn/yinyue/%s/" % song['musicrid'],
+                'http://www.kuwo.cn/yinyue/%s/' % song['musicrid'],
-            raise ExtractorError("Unable to find song or singer names")
+            raise ExtractorError('Unable to find song or singer names')
-    }]
+class KuwoBaseIE(InfoExtractor):
-class KuwoMvIE(KuwoIE):
+class KuwoMvIE(KuwoBaseIE):
-    _TESTS = [{
+    _TEST = {
-    _FORMATS = KuwoIE._FORMATS + [
+    }
-            'password': password,
+            'login': username.encode('utf-8'),
-            r'<h1 title="(.+?)">', webpage, 'song name')
+            r'<h1[^>]+title="([^"]+)">', webpage, 'song name')
-            flags=re.DOTALL, default=None)
+            r'<div[^>]+class="s_img">\s*<a[^>]+title="([^>]+)"',
-            r'<p class="album" title=".+?">.+?<a href="http://www\.kuwo\.cn/album/([0-9]+)/" ',
+            r'<p[^>]+class="album"[^<]+<a[^>]+href="http://www\.kuwo\.cn/album/(\d+)/"',
-            re.sub(r'^.+ç®ä»ï¼', '', get_element_by_id("intro", webpage).strip()))
+            r'<div[^>]+class="comm"[^<]+<h1[^>]+title="([^"]+)"', webpage,
-                r'<p class="listen"><a href="http://www\.kuwo\.cn/yinyue/([0-9]+)/" target="_blank" title="è¯å¬.*?"></a></p>',
+                r'<p[^>]+class="listen"><a[^>]+href="http://www\.kuwo\.cn/yinyue/(\d+)/"',
-    _VALID_URL = r'http://yinyue\.kuwo\.cn/billboard_(?P<id>.+?).htm'
+    _VALID_URL = r'http://yinyue\.kuwo\.cn/billboard_(?P<id>[^.]+).htm'
-            r'<h1 class="unDis">(.+?)</h1>', webpage, 'chart name')
+            r'<h1[^>]+class="unDis">([^<]+)</h1>', webpage, 'chart name')
-            r'<p class="tabDef">([0-9]{4}ç¬¬[0-9]{2}æ)</p>', webpage, 'chart desc')
+            r'<p[^>]+class="tabDef">(\d{4}ç¬¬\d{2}æ)</p>', webpage, 'chart desc')
-                r'<a href="http://www\.kuwo\.cn/yinyue/([0-9]+)/" .+?>.+?</a>', webpage)
+                r'<a[^>]+href="http://www\.kuwo\.cn/yinyue/(\d+)/"', webpage)
-            r'<div class="title clearfix">[\n\s\t]*?<h1>(.+?)<span', webpage, 'singer name'
+            r'<div class="title clearfix">\s*<h1>([^<]+)<span', webpage, 'singer name'
-        first_page_only = False if re.match(r'.+/music(?:_[0-9]+)?\.htm', url) else True
+        first_page_only = False if re.search(r'/music(?:_[0-9]+)?\.htm', url) else True
-                    r'<p class="m_name"><a href="http://www\.kuwo\.cn/yinyue/([0-9]+)/',
+                    r'<p[^>]+class="m_name"><a[^>]+href="http://www\.kuwo\.cn/yinyue/([0-9]+)/',
-            if first_page_only or not re.search(r'<a href="[^"]+">ä¸ä¸é¡µ</a>', webpage):
+            if first_page_only or not re.search(r'<a[^>]+href="[^"]+">ä¸ä¸é¡µ</a>', webpage):
-            r'<h1 title="([^<>]+?)">[^<>]+?</h1>', webpage, 'category name')
+            r'<h1[^>]+title="([^<>]+?)">[^<>]+?</h1>', webpage, 'category name')
-            r'^.+ç®ä»ï¼', '', get_element_by_id("intro", webpage).strip())
+        category_desc = remove_start(
-            r'var jsonm = (\{.+?\});', webpage, 'category songs'), category_id)
+            r'var\s+jsonm\s*=\s*([^;]+);', webpage, 'category songs'), category_id)
-            r'<h1 title="(?P<song>.+?)">[^<>]+<span .+?title="(?P<singer>.+?)".+?>[^<>]+</span></h1>',
+            r'<h1[^>]+title="(?P<song>[^"]+)">[^<]+<span[^>]+title="(?P<singer>[^"]+)"',
-            name = '%s - %s' % (name, ";".join(info['artist']['alias']))
+            name = '%s - %s' % (name, ';'.join(info['artist']['alias']))
-        if m:
+        error_message = self._search_regex(
-                'Unable to login: %s' % m.group('msg').strip(), expected=True)
+                'Unable to login. Twitch said: %s' % error_message, expected=True)
-    _LOGIN_POST_URL = 'https://secure-login.twitch.tv/login'
+    _LOGIN_URL = 'https://secure.twitch.tv/login'
-            'follow': '',
+        login_form = dict(re.findall(
-        }
+        })
-        
+
-        
+
-import itertools
+    compat_itertools_count,
-        for offset in itertools.count(start=0, step=self._PAGE_SIZE):
+        for offset in compat_itertools_count(start=0, step=self._PAGE_SIZE):
-        string_bytes = bytearray(str(dfsid))
+        salt_bytes = bytearray(cls._NETEASE_SALT.encode('utf-8'))
-        result = b64encode(m.digest())
+        m.update(bytes(string_bytes))
-        return int(round(ms/1000.0))
+        return int(round(ms / 1000.0))
-            'song/lyric?id=%s&lv=-1&tv=-1' % song_id, 
+            'song/lyric?id=%s&lv=-1&tv=-1' % song_id,
-            'album/%s?id=%s' % (album_id, album_id), 
+            'album/%s?id=%s' % (album_id, album_id),
-            'artist/%s?id=%s' % (singer_id, singer_id), 
+            'artist/%s?id=%s' % (singer_id, singer_id),
-            'playlist/detail?id=%s&lv=-1&tv=-1' % list_id, 
+            'playlist/detail?id=%s&lv=-1&tv=-1' % list_id,
-            
+
-                'dj/program/byradio?asc=false&limit=%d&radioId=%s&offset=%d' 
+                'dj/program/byradio?asc=false&limit=%d&radioId=%s&offset=%d'
-    _TEST = {
+    _VALID_URL = r'http://www\.kuwo\.cn/mingxing/(?P<id>[^/]+)'
-    _TEST = {
+    }, {
-            'title': 'Aliçç­é¨æ­æ²',
+            'title': 'Ali',
-    }
+    }]
-        list_name = None
+        first_page_only = False if re.match(r'.+/music(?:_[0-9]+)?\.htm', url) else True
-            if not re.search(r'<a href="[^"]+">ä¸ä¸é¡µ</a>', webpage):
+            ][:10 if first_page_only else None])
-        return self.playlist_result(entries, singer_id, list_name)
+        return self.playlist_result(entries, singer_id, singer_name)
-    KuwoSingerMusicIE,
+from base64 import b64encode
-        salt_bytes = bytearray(str(cls._NETEASE_SALT))
+        salt_bytes = bytearray(cls._NETEASE_SALT, 'utf-8')
-        for i in xrange(len(string_bytes)):
+        for i in range(len(string_bytes)):
-        result = m.digest().encode('base64')[:-1]
+        result = b64encode(m.digest())
-                'preference': details['bitrate'],
+                'ext': details.get('extension'),
-                'asr': details['sr']
+                'filesize': details.get('size'),
-
+        translation_ts_dict = dict(
-            alt_title = '/'.join(info.get('alias'))
+        if info.get('transNames'):
-            {'url': mv_url, 'ext': 'mp4', 'format_id': '%sp' % brs, 'preference': int(brs)}
+            {'url': mv_url, 'ext': 'mp4', 'format_id': '%sp' % brs, 'height': int(brs)}
-from .myvi import MyviEmbedIE
+from .myvi import MyviIE
-        myvi_url = MyviEmbedIE._extract_url(webpage)
+        myvi_url = MyviIE._extract_url(webpage)
-class MyviEmbedIE(SprutoBaseIE):
+class MyviIE(SprutoBaseIE):
-                            (?P<id>[\da-zA-Z_]+)
+                            (?P<id>[\da-zA-Z_-]+)
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//myvi\.(?:ru/player|tv)/embed/html/[^"]+)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//myvi\.(?:ru/player|tv)/(?:embed/html|flash)/[^"]+)\1', webpage)
-                        myvi\.ru/player/
+                        myvi\.(?:ru/player|tv)/
-class VimpleIE(InfoExtractor):
+class SprutoBaseIE(InfoExtractor):
-        playlist = self._parse_json(
+        spruto = self._parse_json(
-        self._sort_formats(formats)
+            video_id)
-        }
+        return self._extract_spruto(spruto, video_id)
-            self, video_id, dash_manifest_url, player_url, age_gate):
+            self, video_id, dash_manifest_url, player_url, age_gate, fatal=True):
-            errnote='Could not download DASH manifest')
+            errnote='Could not download DASH manifest',
-                            video_id, dash_manifest_url, player_url, age_gate):
+                            video_id, dash_manifest_url, player_url, age_gate, dash_mpd_fatal):
-    _VALID_URL = r'https?://v\.yinyuetai\.com/video(/h5)?/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://v\.yinyuetai\.com/video(?:/h5)?/(?P<id>[0-9]+)'
-            'filesize': format_info['fileSize'],
+            'format': format_info.get('qualityLevelName'),
-            'preference': format_info['bitrate'],
+            'tbr': format_info.get('bitrate'),
-            'duration': info['duration'],
+            'thumbnail': info.get('bigHeadImage'),
-        ]
+        formats = [{
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            return self.url_result(youtube_url, 'Youtube', video_id)
+            return self.url_result(youtube_url, 'Youtube')
-            return self.url_result(m_yt.group(1), 'Youtube')
+        youtube_url = self._search_regex(
-    _VALID_URL = r'https?://(?:m\.)?vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|(?:.+?\?.*?z=)?video(?P<videoid>[^s].*?)(?:\?|%2F|$))'
+    _VALID_URL = r'''(?x)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-    _VALID_URL = r'http://www\.clipsyndicate\.com/video/play(list/\d+)?/(?P<id>\d+)'
+    _VALID_URL = r'http://(?:chic|www)\.clipsyndicate\.com/video/play(list/\d+)?/(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-__version__ = '2015.07.04'
+__version__ = '2015.07.07'
-            video_id, 'Downloading video info')['gfyItem']
+            video_id, 'Downloading video info')
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?gfycat\.com/(?:ifr/)?(?P<id>[^/?#]+)'
-    }
+    }, {
-        info_url = 'http://vk.com/al_video.php?act=show&al=1&module=video&video=%s' % video_id
+        info_url = 'https://vk.com/al_video.php?act=show&al=1&module=video&video=%s' % video_id
-            'thumbnail': 'http://i.gtimg.cn/music/photo/mid_album_500/7/p/001IV22P1RDX7p.jpg',
+            'thumbnail': 're:^https?://.*\.jpg$',
-            'thumbnail': 'http://i.gtimg.cn/music/photo/mid_album_500/r/Q/0042owYj46IxrQ.jpg',
+            'thumbnail': 're:^https?://.*\.jpg$',
-        album_name = album['name']
+        album_name = album.get('name')
-            'description': 'md5:712f0cdbfc7e776820d08150e6df593d',
+            'description': 'md5:179c5dce203a5931970d306aa9607ea6',
-            'description': 'md5:b1d133b8c9bac8fed4e1a97df759f4cf',
+            'description': 'md5:a48823755615508a95080e81b51ba729',
-        list_name = list_json['dissname']
+        list_name = list_json.get('dissname')
-                formats.extend(self._extract_m3u8_formats(
+                m3u8_formats = self._extract_m3u8_formats(
-                    m3u8_id='hls'))
+                    m3u8_id='hls', fatal=False)
-                              m3u8_id=None, note=None, errnote=None):
+                              m3u8_id=None, note=None, errnote=None,
-            errnote=errnote or 'Failed to download m3u8 information')
+            errnote=errnote or 'Failed to download m3u8 information',
-        # encrypted m3u8 streams
+        # encrypted m3u8 streams, georestricted
-        m3u8_url = info['meta']['videohost'] + videopath
+        videopath = material['videopath'].replace('/adaptive/', '/flash/')
-        meta = info.get('meta', {})
+
-    _VALID_URL = r'https?://(?:(?P<prefix>www|m)\.)?(?P<url>crunchyroll\.(?:com|fr)/(?:[^/]*/[^/?&]*?|media/\?id=)(?P<video_id>[0-9]+))(?:[/?&]|$)'
+    _VALID_URL = r'https?://(?:(?P<prefix>www|m)\.)?(?P<url>crunchyroll\.(?:com|fr)/(?:media(?:-|/\?id=)|[^/]*/[^/?&]*?)(?P<video_id>[0-9]+))(?:[/?&]|$)'
-            streamdata_req.data = 'req=RpcApiVideoEncode%5FGetStreamInfo&video%5Fencode%5Fquality=' + stream_quality + '&media%5Fid=' + stream_id + '&video%5Fformat=' + stream_format
+            streamdata_req = compat_urllib_request.Request(
-            video_play_path = streamdata.find('./file').text
+            stream_info = streamdata.find('./{default}preload/stream_info')
-from youtube_dl.utils import match_filter_func
+from youtube_dl.utils import ExtractorError, match_filter_func
-                        selectors.append(FormatSelector(PICKFIRST, (first_choice, second_choice), []))
+                        current_selector = FormatSelector(PICKFIRST, (first_choice, second_choice), [])
-__version__ = '2015.06.25'
+__version__ = '2015.07.04'
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?thisamericanlife\.org/(?:radio-archives/episode/|play_full\.php\?play=)(?P<id>\d+)'
-        'md5': '5cda28076c9f9d1fd0b0f5cff5959948',
+        'md5': '8f7d2da8926298fdfca2ee37764c11ce',
-            'skip_download': True,
+            'description': 'md5:ee40bdf3fb96174a9027f76dbecea655',
-    }
+    }, {
-        webpage = self._download_webpage(url, video_id)
+
-            'description': self._html_search_regex(r'<meta name="description" content="(.*?)"', webpage, 'description'),
+            'url': 'http://stream.thisamericanlife.org/{0}/stream/{0}_64k.m3u8'.format(video_id),
-
+
-        }
+            'thumbnail': 'http://www.thisamericanlife.org/sites/default/files/imagecache/large_square/episodes/487_lg_2.jpg',
-        media_url = 'http://stream.thisamericanlife.org/' + video_id + '/stream/' + video_id + '_64k.m3u8'
+        # TODO check to see if there's a free mp3. if so, download that, otherwise get the m3u8 stream.
-            'url': media_url,
+            'title': self._html_search_regex(r'<meta property="twitter:title" content="(.*?)"', webpage, 'title'),
-    _VALID_URL = r'http://api\.dmcloud\.net/embed/[^/]+/(?P<id>[^/?]+)'
+    _VALID_URL_PREFIX = r'http://api\.dmcloud\.net/(?:player/)?embed/'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        mobj = re.search(r'<iframe[^>]+src=[\'"](http://api\.dmcloud\.net/embed/[^/]+/[^\'"]+)[\'"]', webpage)
+        mobj = re.search(r'<iframe[^>]+src=[\'"](%s)[\'"]' % self._VALID_EMBED_URL, webpage)
-        mobj = re.search(r'<input[^>]+id=[\'"]dmcloudUrlEmissionSelect[\'"][^>]+value=[\'"](http://api\.dmcloud\.net/embed/[^/]+/[^\'"]+)[\'"]', webpage)
+        mobj = re.search(
-
+from ..utils import parse_iso8601
-        }
+            'description': 'md5:dbe792e5f6f1489027027bf2eba188a3',
-        mobj = re.match(self._VALID_URL, url)
+        video_id = self._match_id(url)
-                                                    webpage, 'description', fatal=False)
+        embed_code = self._search_regex(
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'timestamp': parse_iso8601(self._html_search_meta(
-            r'EXPRESSINSTALL_SWF\s*=\s*"(https?://[^/"]+/)', webpage,
+            r'EXPRESSINSTALL_SWF\s*=\s*[^"]*"((?:https?:)?//[^/"]+/)', webpage,
-            'url': http_base + real_id,
+            'url': compat_urlparse.urljoin(url, http_base) + real_id,
-            r"(?s)kWidget\.(?:thumb)?[Ee]mbed\(\{.*?'wid'\s*:\s*'_?(?P<partner_id>[^']+)',.*?'entry_id'\s*:\s*'(?P<id>[^']+)',", webpage)
+        mobj = (re.search(r"(?s)kWidget\.(?:thumb)?[Ee]mbed\(\{.*?'wid'\s*:\s*'_?(?P<partner_id>[^']+)',.*?'entry_id'\s*:\s*'(?P<id>[^']+)',", webpage) or
-        return self._search_regex(
+        token = self._search_regex(
-            'http://e.omroep.nl/metadata/aflevering/%s' % video_id,
+            'http://e.omroep.nl/metadata/%s' % video_id,
-            }
+            },
-            }
+            },
-            }
+            },
-                r'<iframe\s+(?:class|id)=["\']partnerPlayer["\'].*?\s+src=["\'](.*?)["\']>',
+                r'<iframe\s+[^>]*\s+src=["\']([^\'"]+partnerplayer[^\'"]+)["\']',
-            'extra_cmd_args': opts.postprocessor_args,
+        'postprocessor_args': shlex.split(opts.postprocessor_args or ''),
-        self._extra_cmd_args = shlex.split(extra_cmd_args or '')
+    def __init__(self, downloader=None):
-        PostProcessor.__init__(self, downloader, extra_cmd_args)
+    def __init__(self, downloader=None):
-        super(FFmpegVideoConvertorPP, self).__init__(downloader, extra_cmd_args)
+    def __init__(self, downloader=None, preferedformat=None):
-            [r'class="hd_title" style="[^"]+">([^<]+)</h1>', r'<title>([^<]+) - \d+'],
+            [r'<p[^>]+class="title_substrate">([^<]+)</p>', r'<title>([^<]+) - \d+'],
-            webpage, 'comment count', fatal=False))
+        def extract_count(id_, name):
-            r'<span>Categories:</span><div>(.+?)</div>', webpage, 'categories', fatal=False)
+            r'<div[^>]+class="categories_list">(.+?)</div>', webpage, 'categories', fatal=False)
-    pp_params:         Extra parameters for external apps, like avconv.
+    postprocessor_args: Extra parameters for external apps, like avconv.
-            'extra_params': opts.pp_params
+            'extra_cmd_args': opts.postprocessor_args,
-        dest='pp_params', default=None, metavar='ARGS',
+        '--postprocessor-args',
-    --pp-params.
+    --postprocessor-args.
-    def __init__(self, downloader=None):
+    def __init__(self, downloader=None, extra_cmd_args=None):
-        PostProcessor.__init__(self, downloader)
+    def __init__(self, downloader=None, extra_cmd_args=None):
-        super(FFmpegVideoConvertorPP, self).__init__(downloader)
+    def __init__(self, downloader=None, preferedformat=None, extra_cmd_args=None):
-        options = self._extra_params
+        options = self._extra_cmd_args
-        def _parse_format_selection(tokens, endwith=[]):
+        def _parse_format_selection(tokens, inside_merge=False, inside_choice=False, inside_group=False):
-                    if string in endwith:
+                    if string == ')':
-                        # ')' will be handled by the parentheses group
+                    elif inside_merge and string in ['/', ',']:
-                    if string == ',':
+                    elif inside_choice and string == ',':
-                        second_choice = _parse_format_selection(tokens, [','])
+                        second_choice = _parse_format_selection(tokens, inside_choice=True)
-                        current_selector = FormatSelector(GROUP, _parse_format_selection(tokens, [')']), [])
+                        group = _parse_format_selection(tokens, inside_group=True)
-                        selectors.append(FormatSelector(MERGE, (video_selector, audio_selector), []))
+                        audio_selector = _parse_format_selection(tokens, inside_merge=True)
-            upload_date = unified_strdate(upload_date)
+        upload_date = self._html_search_meta(
-    _VALID_URL = r'http://(?:www\.)?ina\.fr/video/(?P<id>I?[A-Z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?ina\.fr/video/(?P<id>I?[A-Z0-9]+)'
-                r'(?s)id="watch-uploader-info".*?>.*?(?:Published|Uploaded|Streamed live) on (.*?)</strong>',
+                r'id="watch-uploader-info".*?>.*?(?:Published|Uploaded|Streamed live|Started) on (.*?)</strong>',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'<h2 class="posttitle"><a[^>]*>([^<]+)</a>',
+            r'<h2[^>]+class="posttitle"[^>]*><a[^>]*>([^<]+)</a>',
-            r'<iframe src="([^"]+mp4)"', webpage, 'wrapper url')
+            r'<iframe[^>]+src="([^"]+mp4)"', webpage, 'wrapper url')
-            r'file:"([^"]+)"', wrap_webpage, 'video url')
+            r'file\s*:\s*"([^"]+)"', wrap_webpage, 'video url')
-        parsed_selector = _parse_format_selection(tokens)
+        try:
-            r'clip:\s*{\s*url: "([^"]*)"', wrap_webpage, 'video url')
+            r'file:"([^"]+)"', wrap_webpage, 'video url')
-            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/fmt=flash/' % uuid,
+            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/fmt=adaptive/' % uuid,
-        m3u8_url = 'http://manifest.us.rtl.nl' + videopath
+        videopath = material['videopath'].replace('adaptive', 'flash')
-    _VALID_URL = r'(?:nrk:|http://(?:www\.)?nrk\.no/video/PS\*)(?P<id>\d+)'
+    _VALID_URL = r'(?:nrk:|https?://(?:www\.)?nrk\.no/video/PS\*)(?P<id>\d+)'
-    _VALID_URL = r'http://(?:www\.)?nrk\.no/(?!video)(?:[^/]+/)+(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?nrk\.no/(?!video)(?:[^/]+/)+(?P<id>[^/]+)'
-    _VALID_URL = r'(?P<baseurl>http://tv\.nrk(?:super)?\.no/)(?:serie/[^/]+|program)/(?P<id>[a-zA-Z]{4}\d{8})(?:/\d{2}-\d{2}-\d{4})?(?:#del=(?P<part_id>\d+))?'
+    _VALID_URL = r'(?P<baseurl>https?://tv\.nrk(?:super)?\.no/)(?:serie/[^/]+|program)/(?P<id>[a-zA-Z]{4}\d{8})(?:/\d{2}-\d{2}-\d{4})?(?:#del=(?P<part_id>\d+))?'
-            'url': 'http://tv.nrk.no/serie/20-spoersmaal-tv/MUHH48000314/23-05-2014',
+            'url': 'https://tv.nrk.no/serie/20-spoersmaal-tv/MUHH48000314/23-05-2014',
-            'url': 'http://tv.nrk.no/program/mdfp15000514',
+            'url': 'https://tv.nrk.no/program/mdfp15000514',
-            'url': 'http://tv.nrk.no/serie/tour-de-ski/MSPO40010515/06-01-2015#del=2',
+            'url': 'https://tv.nrk.no/serie/tour-de-ski/MSPO40010515/06-01-2015#del=2',
-            'url': 'http://tv.nrk.no/serie/tour-de-ski/MSPO40010515/06-01-2015',
+            'url': 'https://tv.nrk.no/serie/tour-de-ski/MSPO40010515/06-01-2015',
-                    if format_spec in ['best', 'worst', None]:
+                    if format_spec == 'all':
-            formats_to_download = list(format_selector(formats))
+        format_selector = self.build_format_selector(req_format)
-            f2['url'] = 'url:' + f2id
+        def format_info(f_id):
-            self.assertEqual(downloaded['format_id'], f1id)
+            self.assertEqual(downloaded['format_id'], f1['format_id'])
-            self.assertEqual(downloaded['format_id'], f1id)
+            self.assertEqual(downloaded['format_id'], f1['format_id'])
-        " Returns a tuple of the remaining format_spec and filtered formats "
+    def _build_format_filter(self, filter_spec):
-        operator_rex = re.compile(r'''(?x)\s*\[
+        operator_rex = re.compile(r'''(?x)\s*
-            \]$
+            $
-        m = operator_rex.search(format_spec)
+        m = operator_rex.search(filter_spec)
-                            m.group('value'), format_spec))
+                            m.group('value'), filter_spec))
-            str_operator_rex = re.compile(r'''(?x)\s*\[
+            str_operator_rex = re.compile(r'''(?x)
-                \s*\]$
+                \s*$
-            m = str_operator_rex.search(format_spec)
+            m = str_operator_rex.search(filter_spec)
-            raise ValueError('Invalid format specification %r' % format_spec)
+            raise ValueError('Invalid filter specification %r' % filter_spec)
-        new_formats = [f for f in available_formats if _filter(f)]
+        return _filter
-            new_format_spec = 'best'
+                def selector_function(formats):
-        return (new_format_spec, new_formats)
+            filters = [self._build_format_filter(f) for f in selector.filters]
-            return None
+            def final_selector(formats):
-        return None
+        stream = io.BytesIO(format_spec.encode('utf-8'))
-                        break
+            format_selector = self.build_format_selector(req_format)
-
+    str_to_int,
-            return None
+            return str_to_int(self._search_regex(
-from .tnaflix import TNAFlixIE
+from .tnaflix import (
-        }
+from ..compat import compat_str
-    parse_duration,
+    float_or_none,
-        }
+class TNAFlixNetworkBaseIE(InfoExtractor):
-            cfg_url, display_id, note='Downloading metadata',
+            cfg_url, display_id, 'Downloading metadata',
-
+
-                'url': self._proto_relative_url(video_url, 'http:'),
+            video_link = item.find('./videoLink')
-            formats.append(fmt)
+                'height': height,
-_NO_DEFAULT = object()
+
-    def _search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0, group=None):
+    def _search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None):
-        elif default is not _NO_DEFAULT:
+        elif default is not NO_DEFAULT:
-    def _html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0, group=None):
+    def _html_search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None):
-def xpath_text(node, xpath, name=None, fatal=False):
+def xpath_text(node, xpath, name=None, fatal=False, default=NO_DEFAULT):
-        if fatal:
+        if default is not NO_DEFAULT:
-                if 'width' in t and 'height' in t:
+                if t.get('width') and t.get('height'):
-        'url': 'http://www.twitch.tv/ksptv/v/3622000',
+        'url': 'http://www.twitch.tv/riotgames/v/6528877',
-            'id': 'v3622000',
+            'id': 'v6528877',
-            'title': '''KSPTV: Squadcast: "Everyone's on vacation so here's Dahud" Edition!''',
+            'title': 'LCK Summer Split - Week 6 Day 1',
-            'uploader_id': 'ksptv',
+            'duration': 17208,
-            '%s/vod/%s?nauth=%s&nauthsig=%s'
+            '%s/vod/%s?nauth=%s&nauthsig=%s&allow_source=true'
-                r'flashvars\.config = escape\("(.+?)"', webpage, 'player parameters')
+        info_url = self._html_search_regex(
-                    r'<div id="view_title"><h1>(.*?)</h1>', webpage, 'title'),
+            'title': self._html_search_regex(
-                    r'<span id="comCount">([0-9]+)</span>', webpage, 'comment_count', fatal=False)),
+            'description': self._html_search_regex(
-                    r'</div>\s*(.*?)\s*<br>', webpage, 'categories', fatal=False).split(', ')
+            'webpage_url': self._html_search_regex(
-        info = {
+        # find the video container
-        info_url = self._html_search_regex(r'flashvars\.config = escape\("(.+?)"', webpage, 'player parameters')
+        info_url = self._html_search_regex( \
-            'title': self._html_search_regex(r'<div id="view_title"><h1>(.*?)</h1>', webpage, 'title'),
+            'title': self._html_search_regex( \
-            'comment_count': str_to_int(self._html_search_regex(r'<span id="comCount">([0-9]+)</span>', webpage, 'comment_count', fatal=False)),
+            'description': self._html_search_regex( \
-            'categories': self._html_search_regex(r'</div>\s*(.*?)\s*<br>', webpage, 'categories', fatal=False).split(', ')
+            'webpage_url': self._html_search_regex( \
-            # N.B. formats are already in ascending order of quality
+                resolution = xpath_text(item, 'res', 'resolution', True)  # 480p etc.
-                    'resolution': xpath_text(item, 'res', 'resolution', True)  # 480p etc.
+                    'resolution': resolution,
-                'url': pattern.replace('#', str(i)),
+                'url': pattern.replace('#', compat_str(i)),
-from ..utils import str_to_int
+from ..utils import (
-            'thumbnail': xml.find('startThumb').text,
+            'thumbnail': xpath_text(xml, 'startThumb', 'thumbnail'),
-            info['url'] = xml.find('videoLink').text
+            info['url'] = xpath_text(xml, 'videoLink', 'url', True)
-                    'resolution': item.find('res').text  # 480p etc.
+                    'url': xpath_text(item, 'videoLink', 'url', True),
-        # find the URL of the XML document detailing video download URLs
+        # find and retrieve the XML document detailing video download URLs
-            'comment_count': str_to_int(self._html_search_regex(r'<span id="comCount">([0-9]+)</span>', webpage, 'comment_count')),
+            'description': self._html_search_regex(r'name="description" value="(.*?)"', webpage, 'description', fatal=False),
-            'categories': self._html_search_regex(r'</div>\s*(.*?)\s*<br>', webpage, 'categories').split(', ')
+            'webpage_url': self._html_search_regex(r'name="link" value="(.*?)"', webpage, 'webpage_url', fatal=False),
-    }, {
+        # normal, multi-format video
-            'display_id': 'jeune-couple-russe'
+            'display_id': 'jeune-couple-russe',
-            'display_id': 'experienced-milf-amazing-handjob'
+            'display_id': 'experienced-milf-amazing-handjob',
-        'md5': 'bedef72cb23d27a20755fc430a6d7a0e',
+        'url': 'http://www.moviefap.com/videos/be9867c9416c19f54a4a/experienced-milf-amazing-handjob.html',
-            'id': '3080837f6712355015c2',
+            'id': 'be9867c9416c19f54a4a',
-            'display_id': 'busty-british-blonde-takes-backdoor-in-fake-taxi'
+            'title': 'Experienced MILF Amazing Handjob',
-                 for attr in ['imageWidth', 'imageHeight', 'imageFirst', 'imageLast']}
+        width = str_to_int(timeline.find('imageWidth').text)
-        for i in range(attrs['imageFirst'], attrs['imageLast'] + 1):
+        for i in range(first, last + 1):
-                'height': attrs['imageHeight']
+                'width': width,
-    bn = os.path.basename(external_downloader)
+    # Drop .exe extension on Windows
-        # video-password
+        # video-password, not approved by moderator
-        # age limit + video-password
+        # video-password
-        },
+        video_password = self._downloader.params.get('videopassword', None)
-            if video.get('_moderate_no') or not video.get('moderated'):
+            if video.get('_moderate_no'):
-                'This film is not playable in your area.', expected=True)
+                'Film %s is not playable in your area.' % video_id, expected=True)
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:embed\.)?snagfilms\.com/embed/player.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:embed\.)?snagfilms\.com/embed/player.+?)\1',
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?snagfilms\.com/(?:films/title|show)/(?P<id>[^?#]+)'
-    }
+    }, {
-from .snagfilms import SnagFilmsIE
+from .snagfilms import (
-from re import match,DOTALL
+from __future__ import unicode_literals
-from ..utils import js_to_json
+from ..utils import (
-    _VALID_URL = r'(?:https?://)?(?:www.|embed.)?snagfilms\.com/(?:films/title/(?P<display_id>.+?)|embed/player\?.*filmId=(?P<id>.+?))(?:&|/|$)'
+
-        {
+        'url': 'http://embed.snagfilms.com/embed/player?filmId=74849a00-85a9-11e1-9660-123139220831&w=500',
-            'categories': ['Documentary','Politics']
+    }, {
-        )), video_id)
+        video_id = self._match_id(url)
-                formats.extend(self._extract_m3u8_formats(source['file'], video_id))
+        for source in self._parse_json(js_to_json(self._search_regex(
-                formats.append({'url': source['file'],'ext': source['type'], 'resolution': source['label']})
+                bitrate = int_or_none(self._search_regex(
-            'formats': formats,
+            'duration': duration,
-                r'<meta property="og:video:url" content="https?://(?:www\.)?newstube\.ru/freshplayer\.swf\?guid=(?P<guid>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})',
+            r'<meta property="og:video:url" content="https?://(?:www\.)?newstube\.ru/freshplayer\.swf\?guid=(?P<guid>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})',
-            r'<meta property="og:video" content="https?://(?:www\.)?newstube\.ru/freshplayer\.swf\?guid=(?P<guid>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})',
+                r'<meta property="og:video:url" content="https?://(?:www\.)?newstube\.ru/freshplayer\.swf\?guid=(?P<guid>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})',
-
+        if video_id is None:
-
+        # Extraction from multiple DASH manifests (https://github.com/rg3/youtube-dl/pull/6097)
-        help='Do not download the DASH manifest on YouTube videos')
+        help='Do not download the DASH manifests and related data on YouTube videos')
-                    break
+            if not video_info or self._downloader.params.get('youtube_include_dash_manifest', True):
-            'If a merge is required (e.g. bestvideo+bestaudio), output to given container format. One of mkv, mp4, ogg, webm, flv.'
+            'If a merge is required (e.g. bestvideo+bestaudio), '
-            'expire': '1',
+        login_page = self._download_webpage(
-        }
+        })
-        login_page = self._download_webpage(request, None, note='Logging in as %s' % username)
+        request = compat_urllib_request.Request(
-            raise ExtractorError('Unable to login, incorrect username and/or password', expected=True)
+            raise ExtractorError(
-    _TEST = {
+    _VALID_URL = r'(?:https?://)?(?:www.|embed.)?snagfilms\.com/(?:films/title/(?P<display_id>.+?)|embed/player\?.*filmId=(?P<id>.+?))(?:&|/|$)'
-    }
+    },{
-        webpage = self._download_webpage(url, display_id)
+        display_id, video_id = match(self._VALID_URL,url).groups()
-            'data',
+            'data'
-        video_id = json_data['id']
+        thumbnail = json_data['image']
-        embed_webpage = self._download_webpage('http://www.snagfilms.com/embed/player?filmId=' + video_id, video_id)
+            'thumbnail': thumbnail,
-	}
+    _VALID_URL = r'(?:https?://)?(?:www.)?snagfilms\.com/films/title/(?P<display_id>.+?)(?:/|$)'
-		webpage = self._download_webpage(url, display_id)
+    def _real_extract(self, url):
-		categories = [category['title'] for category in json_data['categories']]
+        json_data = self._parse_json(self._html_search_regex(
-		)), video_id)
+        embed_webpage = self._download_webpage('http://www.snagfilms.com/embed/player?filmId=' + video_id, video_id)
-		self._sort_formats(formats)
+        formats = []
-		}
+        return {
-                    formats = [f for f in formats if f['format_id'] not in dash_keys]
+                    formats = [f for f in formats if f['format_id'] not in dash_formats.keys()]
-                    raise ValueError('Could not find ytplayer.config')  # caught below
+            # Try looking directly into the video webpage
-                        break
+                if args.get('url_encoded_fmt_stream_map'):
-                dash_manifest_url = dash_mpd[0]
+            for dash_manifest_url in dash_mpds:
-                        video_id, dash_manifest_url, player_url, age_gate)
+                    for df in self._parse_dash_manifest(
-                else:
+                if dash_formats:
-                    dash_keys = set(df['format_id'] for df in dash_formats)
+                    dash_keys = set(df['format_id'] for df in dash_formats.values())
-                    formats.extend(dash_formats)
+                    formats.extend(dash_formats.values())
-from .webofstories import WebOfStoriesIE
+from .webofstories import (
-            'password': password,
+            'username': username.encode('utf-8'),
-                    self._LOGIN_URL, compat_urllib_parse.urlencode(confirm_form))
+                    self._LOGIN_URL, compat_urllib_parse.urlencode(confirm_form).encode('utf-8'))
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
+            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
-    _VALID_URL = r'https?://(?:www\.)?infoq\.com/[^/]+/(?P<id>[^/]+)$'
+    _VALID_URL = r'https?://(?:www\.)?infoq\.com/(?:[^/]+/)+(?P<id>[^/]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        }
+        },
-        song_id = mobj.group('id')
+        song_id = self._match_id(url)
-            r'"%s":\s(\{.*?\})' % song_id, webpage, 'song_data'))
+        song_data = self._parse_json(self._search_regex(
-    _SONG_FILE_URL_TEMPLATE = 'http://{audio_server:}.thesixtyone.com/thesixtyone_production/audio/{0:}_stream'
+    _SONG_FILE_URL_TEMPLATE = 'http://{audio_server:}/thesixtyone_production/audio/{0:}_stream'
-__version__ = '2015.06.15'
+__version__ = '2015.06.25'
-            'title': 'YPG - Tel Abyad..n tamam. kontrol.m.zde',
+            'title': 'YPG: Tel Abyad\'\u0131n tamam\u0131 kontrol\xfcm\xfczde',
-            'title': 'Honduras militariza sus hospitales por nuevo esc.ndalo de corrupci.n',
+            'title': 'Honduras militariza sus hospitales por nuevo esc\xe1ndalo de corrupci\xf3n',
-            description = list_title + ' - ' + jent.get('caption','')
+            description = list_title
-                'id': jent.get('id') if programme_id == None else programme_id,
+                'id': id,
-                            (?!sets/|likes/?(?:$|[?#]))
+                            (?!sets/|(?:likes|tracks)/?(?:$|[?#]))
-            title += ' - ' + episode
+            title += ' - ' + compat_str(episode)
-        'md5': 'fe330252ddea607635cf2eb2c99a0af3',
+        'params': {
-            self._downloader.report_warning('Falling back on generic information extractor.')
+        if not self._downloader.params.get('test', False) and not is_intentional:
-        except xml.etree.ElementTree.ParseError:
+        except compat_xml_parse_error:
-                'id': jent.get('programme_id',jent.get('id')),
+                'id': jent.get('id') if programme_id == None else programme_id,
-    _VALID_URL = r'https?://www\.faz\.net/multimedia/videos/.*?-(?P<id>\d+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?faz\.net/(?:[^/]+/)*.*?-(?P<id>\d+)\.html'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        return self.url_result(video_url, 'XHamster');
+        return self.url_result(video_url, 'XHamster')
-from .xhamster import XHamsterIE
+from .xhamster import (
-    """Information Extractor for xHamster"""
+
-    compat_urllib_request
+    compat_urllib_request,
-                    % (format_id, i + 1, part_count))
+                video_url = 'newflv.sohu.ccgslb.net'
-                part_info = part_str.split('|')
+                while 'newflv.sohu.ccgslb.net' in video_url:
-                    '%s%s?key=%s' % (part_info[0], su[i], part_info[3]))
+                    if cdnId is not None:
-from ..utils import ExtractorError
+from ..utils import (
-        'md5': 'ac9a5d322b4bf9ae184d53e4711e4f1a',
+        'md5': '699060e75cf58858dd47fb9c03c42cfb',
-        'md5': '49308ff6dafde5ece51137d04aec311e',
+        'md5': '9bf34be48f2f4dadcb226c74127e203c',
-            'md5': '492923eac023ba2f13ff69617c32754a',
+            'md5': 'bdbfb8f39924725e6589c146bc1883ad',
-            'md5': 'de604848c0e8e9c4a4dde7e1347c0637',
+            'md5': '3e1f46aaeb95354fd10e7fca9fc1804e',
-            'md5': '93584716ee0657c0b205b8aa3d27aa13',
+            'md5': '8407e634175fdac706766481b9443450',
-                    video_url = cdn_info['url']
+                video_url = sanitize_url_path_consecutive_slashes(
-    _x = functools.partial(xpath_with_ns, ns_map={'ttml': 'http://www.w3.org/ns/ttml'})
+    _x = functools.partial(xpath_with_ns, ns_map={
-            if child.tag in (_x('ttml:br'), 'br'):
+            if child.tag in (_x('ttml:br'), _x('ttaf1:br'), 'br'):
-            elif child.tag in (_x('ttml:span'), 'span'):
+            elif child.tag in (_x('ttml:span'), _x('ttaf1:span'), 'span'):
-    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall('.//p')
+    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall(_x('.//ttaf1:p')) or dfxp.findall('.//p')
-from .adobetv import AdobeTVIE
+from .adobetv import (
-            lang_code = self._conver_lang_code(lang)
+            lang_code = ISO639Utils.short2long(lang)
-            return self.url_result(mobj.group(1))
+        vimeo_url = VimeoIE._extract_vimeo_url(url, webpage)
-            r'data-quality=((?:\\)?["\'])(.+?)\1[^>]+src=\1(.+?)\1', webpage):
+                r'data-quality=((?:\\)?["\'])(.+?)\1[^>]+src=\1(.+?)\1', webpage):
-            'timestamp': int(info.get('album', {}).get('publishTime')/1000),
+            'timestamp': self.convert_milliseconds(info.get('album', {}).get('publishTime')),
-            'duration': int(info.get('duration', 0)/1000),
+            'duration': self.convert_milliseconds(info.get('duration', 0)),
-            datestamp = datetime.fromtimestamp(info['updateTime']/1000).strftime('%Y-%m-%d')
+            datestamp = datetime.fromtimestamp(
-            'duration': int(info.get('duration', 0)/1000),
+            'duration': self.convert_milliseconds(info.get('duration', 0)),
-            'timestamp': 1434179341,
+            'timestamp': 1434179342,
-            'timestamp': 1434450840,
+            'timestamp': 1434450841,
-                'timestamp': int(info['createTime']/1000),
+                'timestamp': self.convert_milliseconds(info['createTime']),
-                'duration': int(info.get('duration', 0)/1000),
+                'duration': self.convert_milliseconds(info.get('duration', 0)),
-                'url': format_info['url'],
+                'url': format_info['videoInfoList'][0]['videoUrl'],
-            'url': video_url,
+            'formats': formats,
-            xml_url = jent.get('hxref')
+            xml_url = jent.get('href')
-from .bbccouk import BBCCoUkIE, BBCNewsIE
+from .bbc import BBCCoUkIE, BBCNewsIE
-    _VALID_URL = r'https?://(?:www\.)?(?:bbc\.co\.uk|bbc\.com)/news/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?bbc\.com/.+?/(?P<id>[^/]+)$'
-        list_title = self._html_search_regex(r'<title>(.*?)(?:\s*-\s*BBC News)?</title>', webpage, 'list title')
+        list_title = self._html_search_regex(r'<title>(.*?)(?:\s*-\s*BBC [^ ]+)?</title>', webpage, 'list title')
-        if not matches:
+        jsent = map(
-           raise ExtractorError('No video found', expected=True)
+           # prone to breaking if entries have sourceFiles list
-            jent = self._parse_json(ent,list_id)
+        if len(jsent) == 0:
-            xml_url = jent.get('href')
+            xml_url = jent.get('hxref')
-            title = jent['caption']
+            formats = []
-               raise ExtractorError('data-media-meta entry has no externalId or href value.')
+
-                'id': programme_id,
+                'id': jent.get('programme_id',jent.get('id')),
-            duration = parse_duration(jent.get('duration')
+            duration = parse_duration(jent.get('duration'))
-            xml_url = jent.get('href', None)
+            programme_id = jent.get('externalId')
-            duration = parse_duration(jent.get('duration',None))
+            duration = parse_duration(jent.get('duration')
-               thumbnail=jent['image'].get('href',None)
+               thumbnail=jent['image'].get('href')
-from .bbcnews import BBCNewsIE
+from .bbccouk import BBCCoUkIE, BBCNewsIE
-        raise ExtractorError('No video found', expected=True)
+    _token = None
-        self._call_api(
+        login = self._call_api(
-    remove_start
+    remove_start,
-    _VALID_URL = r'https?://(?:www\.)?pinkbike\.com/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:(?:www\.)?pinkbike\.com/video/|es\.pinkbike\.org/i/kvid/kvid-y5\.swf\?id=)(?P<id>[0-9]+)'
-            'uploader_id': 'revelco',
+            'duration': 100,
-            'duration': 100
+            'uploader': 'revelco',
-        }
+        'url': 'http://es.pinkbike.org/i/kvid/kvid-y5.swf?id=406629',
-        title = remove_end(title, ' Video - Pinkbike')
+        webpage = self._download_webpage(
-        description = remove_start(description, title + '. ')
+        formats = []
-        upload_date = upload_date.replace('-', '')
+        uploader = self._search_regex(
-            webpage, 'location')
+            r'(?s)<dt>Location</dt>\s*<dd>(.+?)<',
-            webpage)
+        def extract_count(webpage, label):
-        formats = [{'url': fmt[1], 'height': int_or_none(fmt[0])} for fmt in formats]
+        view_count = extract_count(webpage, 'Views')
-            'uploader_id': uploader_id,
+            'uploader': uploader,
-                    compat_urlparse.urljoin(url, episode['episode_url']),
+                    compat_urlparse.urljoin(url, episode_url),
-class DramaFeverIE(InfoExtractor):
+class DramaFeverBaseIE(InfoExtractor):
-class DramaFeverSeriesIE(InfoExtractor):
+class DramaFeverSeriesIE(DramaFeverBaseIE):
-            duration = self._duration_str2int(jent.get('duration',None))
+            duration = parse_duration(jent.get('duration',None))
-                'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/%s' % programme_id,
+                self.mediaselector_url % programme_id,
-
+from .bbcnews import BBCNewsIE
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/(?:view_video\.php\?viewkey=|embed/)(?P<id>[0-9a-z]+)'
-    }
+    }, {
-    def _prepare_call(self, path, timestamp=None):
+    _NETRC_MACHINE = 'viki'
-        return self._API_URL_TEMPLATE % (query, sig)
+        url = self._API_URL_TEMPLATE % (query, sig)
-    def _call_api(self, path, video_id, note, timestamp=None):
+    def _call_api(self, path, video_id, note, timestamp=None, post_data=None):
-            self._prepare_call(path, timestamp), video_id, note)
+            self._prepare_call(path, timestamp, post_data), video_id, note)
-                    self._prepare_call(path, int(resp['current_timestamp'])),
+                    self._prepare_call(path, int(resp['current_timestamp']), post_data),
-    compat_HTTPError,
+from ..compat import compat_urllib_request
-                    })
+            formats.append({
-                r'<p class="medium-description">([^<]+)</p>',
+                r'<p class="[^"]*medium-description[^"]*">([^<]+)</p>',
-                media_selection = xml.etree.ElementTree.fromstring(ee.cause.read().encode('utf-8'))
+                media_selection = xml.etree.ElementTree.fromstring(ee.cause.read().decode('utf-8'))
-            [r'albummid:\'([0-9a-zA-Z]+)\'', r'"albummid":"([0-9a-zA-Z]+)"'], detail_info_page, 'album mid', default=None)
+            [r'albummid:\'([0-9a-zA-Z]+)\'', r'"albummid":"([0-9a-zA-Z]+)"'],
-from ..compat import compat_urllib_request
+            'thumbnail': 'http://i.gtimg.cn/music/photo/mid_album_500/7/p/001IV22P1RDX7p.jpg',
-            })
+            video_url = 'http://cc.stream.qqmusic.qq.com/%s%s.%s?vkey=%s&guid=%s&fromtag=0' \
-        'url': 'http://y.qq.com/#type=album&mid=000gXCTb2AhRR1&play=0',
+    _TESTS = [{
-            'description': 'md5:d216c55a2d4b3537fe4415b8767d74d6',
+            'description': 'md5:712f0cdbfc7e776820d08150e6df593d',
-    }
+    }, {
-            self.qq_static_url('album', mid), mid, 'Download album page')
+        album = self._download_json(
-            album_page, 'album details', default=None)
+        entries = [
-            'uploader': 'embed.life.ru',
+    remove_end,
-            title = title[:-len(TITLE_SUFFIX)]
+        title = remove_end(
-            r'<div class=\'comments\'>\s*<span class=\'counter\'>\s*(\d+)\s*</span>', webpage, 'comment count', fatal=False)
+            r'=\'commentCount\'[^>]*>\s*(\d+)\s*<',
-            r'<time datetime=\'([^\']+)\'>', webpage, 'upload date', fatal=False)
+            r'<time[^>]*datetime=\'([^\']+)\'', webpage, 'upload date', fatal=False)
-        opts.pp_params = opts.pp_params.split()
+    if opts.pp_params is None:
-        help='Extra parameters for video post-processor. The params will be splited on spaces.')
+        dest='pp_params', default=None, metavar='ARGS',
-    to InfoExtractor objects.
+    to InfoExtractor objects. And it can receive parameters from CLI trough
-            'upload_date': '20070508',
+            'upload_date': '20070507',
-            r'<div\s+id="descriptionContent">([^<]+)<',
+            r'(?s)<div\s+id="descriptionContent">(.+?)</div>',
-            r'Comments<span[^>]+>\s*\(([\d,\.]+)\)</span>',
+            r'<span\s+id="spCommentCount"[^>]*>([\d,\.]+)</span>',
-            re.findall(r'playerData\.cdnPath[0-9]{3,}\s*=\s*["\']([^"\']+)["\']', webpage)))
+            re.findall(r'playerData\.cdnPath[0-9]{3,}\s*=\s*(?:encodeURIComponent\()?["\']([^"\']+)["\']', webpage)))
-        entries = []
+        entries = [{
-                    'url': video_urls[i],
+            for video_url, seg, entry in zip(video_urls, data1['segs'][fm], entries):
-                    'filesize': int(data1['segs'][fm][i]['size'])
+                    'filesize': int(seg['size']),
-                )
+                entries[i]['formats'].append({
-            )
+            entries[i].update({
-        data2_url = 'http://v.youku.com/player/getPlayList/VideoIDS/%s/Pf/4/ctype/12/ev/1' % video_id
+        def retrieve_data(req_url, note):
-        data2 = raw_data2['data'][0]
+            cn_verification_proxy = self._downloader.params.get('cn_verification_proxy')
-                expected=True)
+            if error is not None and 'å çæåå æ æ³è§çæ­¤è§é¢' in error:
-            'id': 'XMTc1ODE5Njcy',
+            'id': 'XMTc1ODE5Njcy_part1',
-                    'id': '_part%d' % (i + 1),
+                    'id': '%s_part%d' % (video_id, i + 1),
-        return info
+        return {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                    'http://hdfauth.francetv.fr/esi/urltokengen2.html?url=%s' % video_url_parsed.path,
+                    'http://hdfauth.francetv.fr/esi/TA?url=%s' % video_url_parsed.path,
-bytes_is_str = (bytes == str)  # for compatible
+from ..compat import (
-                t = (t + ls[i] + ord(s1[i % len(s1)])) % 256
+                t = (t + ls[i] + compat_ord(s1[i % len(s1)])) % 256
-            s = '' if not bytes_is_str else b''
+            s = bytearray()
-            return s
+                s.append(compat_ord(s2[i]) ^ ls[(ls[x] + ls[y]) % 256])
-        ).split('_')
+            b'becaf9be', base64.b64decode(data2['ep'].encode('ascii'))
-                else ('%s_%s_%s' % (sid, fileid, token))
+                b'bf7e5f01',
-            ).decode()
+            ep = base64.b64encode(ep_t).decode('ascii')
-                'search_query': query,
+                'search_query': query.encode('utf-8'),
-                'upload_date': '20130721'
+                'upload_date': '20130721',
-                'upload_date': '20121218'
+                'upload_date': '20121218',
-        mobj = re.search(r'id="mv_date_wrap".*?Added ([a-zA-Z]+ [0-9]+), ([0-9]+) at', info_page)
+        mobj = re.search(r'id="mv_date(?:_views)?_wrap"[^>]*>([a-zA-Z]+ [0-9]+), ([0-9]+) at', info_page)
-        m_opts = re.search(r'(?s)var\s+opts\s*=\s*({.*?});', info_page)
+        m_opts = re.search(r'(?s)var\s+opts\s*=\s*({.+?});', info_page)
-            m_opts_url = re.search(r"url\s*:\s*'([^']+)", m_opts.group(1))
+            m_opts_url = re.search(r"url\s*:\s*'((?!/\b)[^']+)", m_opts.group(1))
-        data_json = self._search_regex(r'var vars = ({.*?});', info_page, 'vars')
+        data_json = self._search_regex(r'var\s+vars\s*=\s*({.+?});', info_page, 'vars')
-            }
+        'url': 'http://v.youku.com/v_show/id_XMTc1ODE5Njcy.html',
-                t = (t + ls[i] + ord(s1[i%len(s1)])) % 256
+                t = (t + ls[i] + ord(s1[i % len(s1)])) % 256
-                    s += chr(s2[i] ^ ls[(ls[x]+ls[y]) % 256])
+                    s += chr(s2[i] ^ ls[(ls[x] + ls[y]) % 256])
-                    s += chr(ord(s2[i]) ^ ls[(ls[x]+ls[y]) % 256])
+                    s += chr(ord(s2[i]) ^ ls[(ls[x] + ls[y]) % 256])
-                else base64.b64decode(data2['ep'])
+            base64.b64decode(bytes(data2['ep'], 'ascii'))
-                if not bytes_is_str \
+                bytes('%s_%s_%s' % (sid, fileid, token), 'ascii')
-                if not bytes_is_str \
+                bytes(ep_t, 'latin')
-                    '_' + str(int(n)+1).zfill(2) + \
+                    '_' + str(int(n) + 1).zfill(2) + \
-                    '/fileid/' + get_fileid(format, n)  + '?' + \
+                    '/fileid/' + get_fileid(format, n) + '?' + \
-            '3gphd' : '1'
+            'flv': '0',
-            '3gphd' : 'mp4'
+            'flv': 'flv',
-            'hd3'   : 'h1'
+            '3gp': 'h6',
-                if len(entries) < i+1:
+                if len(entries) < i + 1:
-                    'id': '_part%d' % (i+1),
+                    'id': '_part%d' % (i + 1),
-        webpage = self._download_webpage(redirect_url, video_id,
+        # need to get the page 3 times for the correct jsSecretToken cookie
-__version__ = '2015.06.04.1'
+__version__ = '2015.06.15'
-                                (?P<course_id>\d+)/
+                                (?P<course_id>[^/]+)/
-    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/(?:library/view/[^/]+|api/v1/book)/(?P<id>\d+)/?(?:[#?]|$)'
+    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/(?:library/view/[^/]+|api/v1/book)/(?P<id>[^/]+)/?(?:[#?]|$)'
-            'format_note' : format_note,
+            'format_id': 'economy' if video_real_url.endswith('low') else 'normal',
-             'detect_or_warn(the default; fix file if we can, warn otherwise)')
+             'detect_or_warn (the default; fix file if we can, warn otherwise)')
-            orig_url = re.sub(r'.h264_.+\.mp4', '', s['file'])
+            orig_url = re.sub(r'\.h264_.+?\.mp4', '', s['file'])
-            orig_url = s['file'].replace('.h264_base.mp4', '')
+            orig_url = re.sub(r'.h264_.+\.mp4', '', s['file'])
-    videopassword:     Password for acces a video.
+    videopassword:     Password for accessing a video.
-    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+/[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+/[0-9]+)(?:/|$)'
-    _PAGE_SIZE = 5  # max is 60 (see http://api.drama9.com/#get--api-4-episode-series-)
+    _PAGE_SIZE = 60  # max is 60 (see http://api.drama9.com/#get--api-4-episode-series-)
-    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+)(?:/(?:(?!\d).+)?)?$'
+    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+)(?:/(?:(?!\d+(?:/|$)).+)?)?$'
-import re
+import itertools
-    _TESTS = [{
+    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+/[0-9]+)'
-            'description': 'Served at all special occasions and featured in the hit drama Heirs, Shin cooks Red Bean Rice.',
+            'duration': 343,
-    }]
+    }
-        consumer_secret = self._get_consumer_secret(video_id)
+        video_id = self._match_id(url).replace('/', '.')
-            errnote="Video may not be available for your location")["channel"]["item"]
+        try:
-        upload_date = mobj.group(1) + mobj.group(2) + mobj.group(3) if mobj is not None else None
+        media_group = feed.get('media-group', {})
-
+        for media_content in media_group['media-content']:
-        video_subtitles = self.extract_subtitles(video_id, consumer_secret)
+
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-            'subtitles': video_subtitles,
+            'subtitles': subtitles,
-class DramaFeverSeriesIE(DramaFeverIE):
+
-    _VALID_URL = r'^https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+)/\d*[a-zA-Z_][a-zA-Z0-9_]*/'
+    _VALID_URL = r'https?://(?:www\.)?dramafever\.com/drama/(?P<id>[0-9]+)(?:/(?:(?!\d).+)?)?$'
-            'description': 'Professional chef and cooking instructor Shin Kim takes some of the delicious dishes featured in your favorite dramas and shows you how to make them right at home.',
+            'description': 'md5:84a3f26e3cdc3fb7f500211b3593b5c1',
-            'description': 'Lee Byung Hun and Kim Tae Hee star in this powerhouse drama and ratings megahit of action, intrigue and romance.',
+            'description': 'md5:b3a30e587cf20c59bd1c01ec0ee1b862',
-            series_id, note='Downloading series metadata')["series"][series_id]
+        series = self._download_json(
-        description = series_json["description_short"]
+        title = clean_html(series['name'])
-                'http://www.dramafever.com%s' % ep['episode_url'], 'DramaFever', ep['guid']))
+        for page_num in itertools.count(1):
-            return urls
+        return list(filter(None, [
-        return list(filter(None, [cls._build_brighcove_url(m) for m in matches]))
+        if matches:
-    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/view_video\.php\?viewkey=(?P<id>[0-9a-f]+)'
+    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/(?:view_video\.php\?viewkey=|embed/)(?P<id>[0-9a-f]+)'
-        req = compat_urllib_request.Request(url)
+        req = compat_urllib_request.Request(
-            'pass': password,
+            'email': username.encode('cp1251'),
-                    return self.process_ie_result(ie_result, download, extra_info, force_generic_extractor=False)
+                    return self.process_ie_result(ie_result, download, extra_info)
-    def process_ie_result(self, ie_result, download=True, extra_info={}, force_generic_extractor=False):
+    def process_ie_result(self, ie_result, download=True, extra_info={}):
-                                     force_generic_extractor=force_generic_extractor)
+                                     extra_info=extra_info)
-                     process=True):
+                     process=True, force_generic_extractor=False):
-            self._force_generic_extractor_required = False
+        if not ie_key and force_generic_extractor:
-                    return self.process_ie_result(ie_result, download, extra_info)
+                    return self.process_ie_result(ie_result, download, extra_info, force_generic_extractor=False)
-    def process_ie_result(self, ie_result, download=True, extra_info={}):
+    def process_ie_result(self, ie_result, download=True, extra_info={}, force_generic_extractor=False):
-                                     extra_info=extra_info)
+                                     extra_info=extra_info,
-                res = self.extract_info(url)
+                res = self.extract_info(
-        self._force_generic_extractor_required = params.get('force_generic_extractor', False)
+                self._force_generic_extractor_required = self.params.get('force_generic_extractor', False)
-        client_name = 'kolibri-1.2.5'
+        access_token = 'prosieben'
-                mobj = re.search(r'^(?P<url>rtmpe?://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', source['url'])
+                mobj = re.search(r'^(?P<url>rtmpe?://[^/]+)/(?P<path>.+)$', source['url'])
-                    'play_path': mobj.group('playpath'),
+                    'url': '%s/%s' % (mobj.group('url'), app),
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:http://)?(?:www\.)?tvc\.ru/video/iframe/id/[^"]+)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>(?:http:)?//(?:www\.)?tvc\.ru/video/iframe/id/[^"]+)\1', webpage)
-        if not self._downloader.params.get('test', False) and not is_intentional:
+        if (not self._downloader.params.get('test', False) and
-            return self.url_result(rutv_url, 'TVC')
+        tvc_url = TVCIE._extract_url(webpage)
-)
+from ..utils import int_or_none
-            },
+    _VALID_URL = r'''(?x)
-            },
+    }, {
-    ]
+    }, {
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            r'(<a.*?class="videoplayer">)', webpage, 'video link')
+        video_url = self._search_regex(
-            r'height:(\d+)px', video_link, 'height', default=None, fatal=False))
+        title = self._og_search_title(webpage, default=None) or self._search_regex(
-            'video:duration', webpage, 'duration'))
+            'video:duration', webpage, 'duration', default=None))
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'url': video_url,
-            return self.url_result(rutv_url, 'TVCEmbed')
+            return self.url_result(rutv_url, 'TVC')
-            'ie_key': 'TVCEmbed',
+            'ie_key': 'TVC',
-    TVCEmbedIE,
+    TVCArticleIE,
-from .tvc import TVCEmbedIE
+from .tvc import TVCIE
-        rutv_url = TVCEmbedIE._extract_url(webpage)
+        rutv_url = TVCIE._extract_url(webpage)
-class TVCEmbedIE(InfoExtractor):
+class TVCIE(InfoExtractor):
-class TVCIE(InfoExtractor):
+class TVCArticleIE(InfoExtractor):
-from .tvc import TVCIE
+from .tvc import (
-            },
+class TVCEmbedIE(InfoExtractor):
-    ]
+    }
-            r'video/iframe/id/(\d+)/', video_url, 'video id')
+        video_id = self._match_id(url)
-        video_json = self._download_json(video_json_url, video_id)
+        video = self._download_json(
-        for info in video_json.get('path', {}).get('quality', []):
+        for info in video.get('path', {}).get('quality', []):
-                fatal=False)
+                r'cdnvideo/([^/]+?)(?:-[^/]+?)?/', video_url,
-                'url': info.get('url'),
+                'url': video_url,
-            'duration': int_or_none(video_json.get('duration')),
+            'title': video['title'],
-            r'flashvars\s*=\s*({.+?})', webpage, 'flashvars'))
+            r'flashvars\s*=\s*({.+?});\r?\n', webpage, 'flashvars'))
-            r'<iframe\s+(?:[a-zA-Z-]+="[^"]+"\s+)*?src="((?:https?:)?//(?:www\.)?rtl\.nl/system/videoplayer/[^"]+video_embed[^"]+)"',
+            r'<iframe[^>]+?src="((?:https?:)?//(?:www\.)?rtl\.nl/system/videoplayer/[^"]+(?:video_)?embed[^"]+)"',
-        https?://(www\.)?
+        https?://(?:www\.)?
-            rtl\.nl/system/videoplayer/[^?#]+?/video_embed\.html\#uuid=
+            rtl\.nl/system/videoplayer/(?:[^/]+/)+(?:video_)?embed\.html\b.+?\buuid=
-            if hq_durl:
+            if hq_durl is not None:
-
+            video_url = data.get('downloadUrl') or data.get('url')
-            'url': video_url,
+            'formats': formats,
-        def append_url_to_file(outf, target_url, target_name):
+        def append_url_to_file(outf, target_url, target_name, remaining_bytes=None):
-                    'segment %d / %d' % (i + 1, len(segment_urls)))
+                    'segment %d / %d' % (i + 1, len(segment_urls)),
-        (?P<id>(?:\d[a-z]{2}\d{13}|\w{8}\-(?:\w{4}\-){3}\w{12}))'''
+        (?P<id>(?:[a-z0-9]{16}|\w{8}\-(?:\w{4}\-){3}\w{12}))'''
-        self.byte_counter = 0
+        byte_counter = 0
-            self.byte_counter += len(data)
+            return len(data)
-                append_url_to_file(
+                segment_len = append_url_to_file(
-            'total_bytes': self.byte_counter,
+            'downloaded_bytes': byte_counter,
-                    if len(segment_list):
+                    if segment_list is not None:
-        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg', 'mkv']:
+        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg', 'mkv', 'xvid']:
-        help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv)')
+        help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|xvid)')
-    def __init__(self, downloader=None, preferedformat=None):
+    def __init__(self, downloader=None, preferedformat=None, extra_params=[]):
-        outpath = prefix + sep + self._preferedformat
+        ext = self._preferedformat
-        self.run_ffmpeg(path, outpath, [])
+        self.run_ffmpeg(path, outpath, options)
-        information['ext'] = self._preferedformat
+        information['ext'] = ext
-                break
+        def _entries():
-            more_widget_html = more['load_more_widget_html']
+                more = self._download_json(
-        return self.playlist_result(url_results, playlist_id, playlist_title)
+        return self.playlist_result(_entries(), playlist_id, playlist_title)
-           (?:(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/)|(?P<media>(?:[^/]+/)+select/media/))?
+           (?:(?P<media>(?:[^/]+/)+select/media/)|(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
-           (?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/)?
+           (?:(?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/)|(?P<media>(?:[^/]+/)+select/media/))?
-                        'format=smil&mbr=true'.format(provider_id, video_id))
+            smil_url = 'http://link.theplatform.com/s/%s/meta.smil?format=smil&mbr=true' % path
-        info_url = 'http://link.theplatform.com/s/{0}/{1}?format=preview'.format(provider_id, video_id)
+        info_url = 'http://link.theplatform.com/s/%s?format=preview' % path
-    _VALID_URL = r'https?://(?:(?:www\.)?cbs\.com/shows/[^/]+/(?:video|artist)|colbertlateshow\.com/(?:video|podcasts))/(?P<id>[^/]+)/.*'
+    _VALID_URL = r'https?://(?:www\.)?(?:cbs\.com/shows/[^/]+/(?:video|artist)|colbertlateshow\.com/(?:video|podcasts))/[^/]+/(?P<id>[^/]+)'
-        'url': 'http://colbertlateshow.com/podcasts/dYSwjqPs_X1tvbV_P2FcPWRa_qT6akTC/in-the-bad-room-with-stephen/',
+        'url': 'http://www.colbertlateshow.com/podcasts/dYSwjqPs_X1tvbV_P2FcPWRa_qT6akTC/in-the-bad-room-with-stephen/',
-        webpage = self._download_webpage(url, video_id)
+        display_id = self._match_id(url)
-        return self.url_result('theplatform:%s' % real_id)
+        return {
-    _VALID_URL = r'https?://(?:www\.)?cbs\.com/shows/[^/]+/(?:video|artist)/(?P<id>[^/]+)/.*'
+    _VALID_URL = r'https?://(?:(?:www\.)?cbs\.com/shows/[^/]+/(?:video|artist)|colbertlateshow\.com/(?:video|podcasts))/(?P<id>[^/]+)/.*'
-            r"video\.settings\.pid\s*=\s*'([^']+)';",
+            [r"video\.settings\.pid\s*=\s*'([^']+)';", r"cbsplayer\.pid\s*=\s*'([^']+)';"],
-from ..utils import float_or_none
+from ..compat import compat_urllib_parse_urlparse
-            # rtmp download
+            # m3u8 download
-        server = server_json['streamingserver'][0]['endpoint']
+
-            'rtmp_live': True,
+            'formats': formats,
-        dash_manifest_url = re.sub(r'/s/([\w\.]+)', decrypt_sig, dash_manifest_url)
+        dash_manifest_url = re.sub(r'/s/([a-fA-F0-9\.]+)', decrypt_sig, dash_manifest_url)
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': thumbnail,
-            info_dict['upload_date'] = upload_date.strftime('%Y%m%d')
+            # Working around out-of-range timestamp values (e.g. negative ones on Windows,
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        vid = vdata['files']['rtmp']
+        vid = vdata['files'].get('rtmp', vdata['files']['hds'])
-from ..utils import int_or_none
+from ..utils import (
-                    'title': title,
+                    'title': limit_length(title, 80),
-                title = it.get('caption', {}).get('text', it['id'])
+                # In some cases caption is null, which corresponds to None
-    _TEST = {
+    # DiscoveryIE has _TESTS
-            'id': '853232',
+            'id': '104493',
-            'title': 'Cake Boss: Too Big to Fly',
+            'title': 'Too Big to Fly',
-    }
+        'params': {
-    int_or_none,
+from ..compat import compat_str
-    _TEST = {
+    _TESTS = [{
-            'ext': 'flv',
+            'id': '20769',
-    }
+        'params': {
-        webpage = self._download_webpage(url, video_id)
+        info = self._download_json(url + '?flat=1', video_id)
-            webpage, 'video info'), video_id)
+        video_title = info.get('playlist_title') or info.get('video_title')
-        }
+        entries = [{
-                              m3u8_id=None):
+                              m3u8_id=None, note=None, errnote=None):
-            errnote='Failed to download m3u8 information')
+            note=note or 'Downloading m3u8 information',
-            r'<meta\s+property="og:video"\s+content="(https?://(?:secure|c)\.brightcove.com/[^"]+)"',
+            r'<meta\s+property=[\'"]og:video[\'"]\s+content=[\'"](https?://(?:secure|c)\.brightcove.com/[^\'"]+)[\'"]',
-        help='List all supported extractors and the URLs they would handle')
+        help='List all supported extractors')
-import re
+from ..utils import (
-    _VALID_URL = r'http://(www\.)?ruutu\.fi/ohjelmat/(?:[^/]+/)?(?P<id>.*)$'
+    _VALID_URL = r'http://(?:www\.)?ruutu\.fi/ohjelmat/(?:[^/?#]+/)*(?P<id>[^/?#]+)'
-                'id': 'oletko-aina-halunnut-tietaa-mita-tapahtuu-vain-hetki-ennen-lahetysta-nyt-se-selvisi',
+                'id': '2058907',
-                'description': 'Toinen toistaan huikeampia ohjelmaideoita ja tÃ¤ysin pÃ¤Ã¤tÃ¶ntÃ¤ sekoilua? No sitÃ¤ juuri nimenomaan. Metro Helsingin IltapÃ¤ivÃ¤n vieraaksi saapui Tuomas Kauhanen ja he Petra Kalliomaan kanssa keskustelivat hieman ennen lÃ¤hetyksen alkua, mutta kamerat olivatkin jo pÃ¤Ã¤llÃ¤.',
+                'description': 'md5:cfc6ccf0e57a814360df464a91ff67d6',
-                'id': 'superpesis-katso-koko-kausi-ruudussa',
+                'id': '2057306',
-                'description': 'HuippujÃ¤nnittÃ¤vÃ¤n Superpesiksen suoria ottelulÃ¤hetyksiÃ¤ seurataan Ruudussa kauden alusta viimeiseen finaaliin asti. Katso lisÃ¤tiedot osoitteesta ruutu.fi/superpesis.',
+                'description': 'md5:44c44a99fdbe5b380ab74ebd75f0af77',
-        mobj = re.match(self._VALID_URL, url)
+        display_id = self._match_id(url)
-        media_xml = self._download_xml(xml_url, media_id)
+        webpage = self._download_webpage(url, display_id)
-                continue
+        processed_urls = []
-                })
+        extract_formats(video_xml.find('./Clip'))
-            'age_limit': int(media_xml.find('.//AgeLimit').text),
+            'duration': int_or_none(xpath_text(video_xml, './/Runtime', 'duration')),
-    UPDATE_URL = "http://rg3.github.io/youtube-dl/update/"
+    UPDATE_URL = "https://rg3.github.io/youtube-dl/update/"
-from ..utils import ExtractorError
+from ..utils import (
-            r'(http://.+?MainPlayer.+?\.swf)', webpage, 'swf player URL')
+            r'(http://[^\'"]+MainPlayer[^.]+\.swf)', webpage, 'swf player URL')
-        return _dict.get(str(bid), None)
+        matched_format_ids = [_format_id for _bid, _format_id in self._FORMATS_MAP if _bid == str(bid)]
-        return _dict.get(format_id, None)
+        matched_bids = [_bid for _bid, _format_id in self._FORMATS_MAP if _format_id == format_id]
-    _VALID_URL = r'http://(?:www\.)iqiyi.com/.+?\.html'
+    _VALID_URL = r'http://(?:www\.)iqiyi.com/v_.+?\.html'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                    'id': '_part%d' % (i + 1),
+                    'id': '%s_part%d' % (video_id, i + 1),
-        def get_path_key(x):
+        def get_path_key(x, format_id, segment_index):
-                'http://data.video.qiyi.com/t?tn=' + str(random.random()), video_id)['t']
+                'http://data.video.qiyi.com/t?tn=' + str(random.random()), video_id,
-                format_id = self.get_format(i['bid'])
+        for format_item in data['vp']['tkl'][0]['vs']:
-                t = get_encode_code(i['fs'][0]['l'])
+            video_urls_info = format_item['fs']
-                    video_urls_info = i['flvs']
+                    video_urls_info = format_item['flvs']
-                vl = ii['l']
+            for segment_index, segment in enumerate(video_urls_info):
-                filesize = ii['b']
+                    vl.split('/')[-1].split('.')[0], format_id, segment_index)
-                js = self._download_json(api_video_url, video_id)
+                js = self._download_json(
-
+import hashlib
-import hashlib
+
-        assert raw_data['code'] == 'A000000'
+
-            r'tvId ?= ?(\'|\")(?P<tvid>\d+)', webpage, 'tvid', flags=re.I, group='tvid')
+            r'data-player-tvid\s*=\s*[\'"](\d+)', webpage, 'tvid')
-            webpage, 'video_id', flags=re.I, group='video_id')
+            r'data-player-videoid\s*=\s*[\'"]([a-f\d]+)', webpage, 'video_id')
-            r'(?P<swf>http://.+?MainPlayer.+?\.swf)', webpage, 'swf')
+            r'(http://.+?MainPlayer.+?\.swf)', webpage, 'swf player URL')
-    def construct_video_urls(self, data, video_id, _uuid, bid):
+    def construct_video_urls(self, data, video_id, _uuid):
-            data, video_id, _uuid, bid)
+            data, video_id, _uuid)
-            }
+        'url': 'http://www.iqiyi.com/v_19rrojlavg.html',
-                a = do_xor(int(b[c-i-1], 16), i)
+                a = do_xor(int(b[c - i - 1], 16), i)
-                 (t+mg+x).encode('utf8')).hexdigest()
+            t = str(int(math.floor(int(tm) / (600.0))))
-                   if 0 < int(i['bid']) <= 10]
+            bids = [int(i['bid']) for i in data['vp']['tkl'][0]['vs']
-            '10' : 'h1'
+            '1': 'h6',
-            'best' : 'best'
+            'h6': '1',
-                if len(entries) < i+1:
+                if len(entries) < i + 1:
-                    'id': '_part%d' % (i+1),
+                    'id': '_part%d' % (i + 1),
-                    if segment_list:
+                    if len(segment_list):
-            r'class="views">\s*(\d+)\s*<',
+            r'class="views">(?:<noscript>)?\s*(\d+)\s*<',
-            'description': 'Retrouvez dans cette rubrique toutes les vidÃ©os de l\'Turbo du 07/09/2014 : Renault Twingo 3, Bentley Continental GT Speed, CES, Guide Achat Dacia... ',
+            'description': 'Turbo du 07/09/2014 : Renault Twingo 3, Bentley Continental GT Speed, CES, Guide Achat Dacia...',
-        description = self._og_search_description(webpage)
+        description = self._html_search_meta('description', webpage)
-            channel_page, 'channel id', default=None)
+        channel_playlist_id = self._html_search_meta(
-            'categories': ['DÃ©butante', 'ScÃ©nario', 'Sodomie'],
+            'categories': ['DÃ©butantes', 'ScÃ©nario', 'Sodomie'],
-            r'Note : (\d+,\d+)', webpage, 'average rating', fatal=False)
+            r'Note\s*:\s*(\d+(?:,\d+)?)', webpage, 'average rating', fatal=False)
-                'timestamp': 1404302298,
+                'timestamp': int,
-                'timestamp': 1163322193,
+                'timestamp': int,
-            webpage, 'uploader', fatal=False, default='')
+            webpage, 'uploader', fatal=False)
-            'uploadDate', webpage, 'upload date', fatal=False))
+            'uploadDate', webpage, 'upload date'))
-            webpage, 'streams', fatal=False, default='')
+            r'"qualitylevel"\s*:\s*"([^"]+)"', webpage, 'streams', default='')
-                    'url': url,
+                    'url': compat_urllib_parse_unquote(url),
-                r'"streamurl"\s?:\s?"([^"]+)"', webpage, 'stream URL')
+                r'"streamurl"\s*:\s*"([^"]+)"', webpage, 'stream URL')
-                'url': stream_url,
+                'url': compat_urllib_parse_unquote(stream_url),
-        for k, f in self._FORMATS.items():
+        for format_id, details in self._FORMATS.items():
-                'abr': f.get('abr')
+                       % (details['prefix'], mid, details['ext'], vkey, guid),
-                'format': k, 'format_id': k, 'preference': f['preference'],
+                'format': k,
-                    filed['url'], video_id, ext='mp4'))
+                # compat_urllib_parse.urljoin does not work here
-        'mp3-128': {'prefix': 'M500', 'ext': 'mp3', 'preference': 30},
+        'mp3-320': {'prefix': 'M800', 'ext': 'mp3', 'preference': 40, 'abr': 320},
-        for k, sf in self._FORMATS.items():
+        for k, f in self._FORMATS.items():
-                'format': k, 'format_id': k, 'preference': sf['preference']
+                       % (f['prefix'], mid, f['ext'], vkey, guid),
-__version__ = '2015.06.04'
+__version__ = '2015.06.04.1'
-__version__ = '2015.05.29'
+__version__ = '2015.06.04'
-        list_description = toplist_json['topinfo']['info']
+        topinfo = toplist_json.get('topinfo', {})
-        thumbnail = cfg_xml.find('./startThumb').text
+        thumbnail = self._proto_relative_url(
-                'url': video_url,
+                'url': self._proto_relative_url(video_url, 'http:'),
-            'matching_only': True,
+            'only_matching': True,
-            duration = parse_duration(duration[1:])
+        duration = parse_duration(self._html_search_meta(
-            'matching_only': True,
+            'only_matching': True,
-    'dash_segments': DashSegmentsFD,
+    'http_dash_segments': DashSegmentsFD,
-                            'protocol': 'dash_segments',
+                            'protocol': 'http_dash_segments',
-from ..compat import compat_urllib_request
+from .common import FileDownloader
-                            'segment_urls': [segment.attrib.get('media') for segment in segment_list.findall('{urn:mpeg:DASH:schema:MPD:2011}SegmentURL')]
+                            'segment_urls': [segment.attrib.get('media') for segment in segment_list.findall('{urn:mpeg:DASH:schema:MPD:2011}SegmentURL')],
-        'md5': 'bed90b6db2a7a7a7e11bc585f471f63a',
+        'md5': '9ce1c1c8445f561506d2e3cfb0255705',
-            'ext': 'm4a',
+            'ext': 'mp3',
-        song_url = 'http://cc.stream.qqmusic.qq.com/C200%s.m4a?vkey=%s&guid=%s&fromtag=0' % (mid, vkey, guid)
+
-            'url': song_url,
+            'formats': formats,
-        'url': 'http://y.qq.com/#type=toplist&p=global_12',
+        'url': 'http://y.qq.com/#type=toplist&p=global_123',
-            'title': 'itunesæ¦',
+            'id': 'global_123',
-        'url': 'http://y.qq.com/#type=toplist&p=top_6',
+        'url': 'http://y.qq.com/#type=toplist&p=top_3',
-            'id': 'top_6',
+            'id': 'top_3',
-        'url': 'http://y.qq.com/#type=toplist&p=global_5',
+        'url': 'http://y.qq.com/#type=toplist&p=global_106',
-            'title': 'é©å½mnetæè¡æ¦',
+            'id': 'global_106',
-                song_mid))
+            'http://i.y.qq.com/v8/fcg-bin/fcg_v8_toplist_cp.fcg?type=%s&topid=%s&format=json'
-            default=None)
+        entries = [
-        return self.playlist_result(entries, list_id, list_name)
+        list_name = toplist_json['topinfo']['ListName']
-        )
+        ).decode('utf-8')
-        )
+        ).decode('utf-8')
-            'ext': 'mp4',
+            'ext': 'flv',
-            'ext': 'mp4',
+            'ext': 'flv',
-        video_url = video_url.replace('&%s:' % ext, '')
+
-            'ext': ext,
+            'formats': formats,
-            'md5': '48dd7646775690a80447a8dca6a2df76',
+            'md5': 'd041af8b5b4246ea466226a0d6693345',
-            r'ÐÐ°Ð³ÑÑÐ·Ð¸Ð»\s*<a href="/jsecUser/movies/[^"]+" class="link">([^<]+)</a>',
+            r'class="video-uploaded"[^>]*>\s*<a href="/jsecUser/movies/[^"]+"[^>]*>([^<]+)</a>',
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'description': 'md5:dc24e50be5908df83348e50d1431295e',
+            'description': 'md5:dc24e50be5908df83348e50d1431295e',  # Make sure this description is clean of html tags
-        video_url = video_url.replace('&{}:'.format(ext), '')
+        video_url = video_url.replace('&%s:' % ext, '')
-    _VALID_URL = 'http://(?:[^.]+\.)?(?P<site>tv(?:noviny)?|tn|novaplus|vymena|fanda|krasna|doma|prask)\.nova\.cz/(?:[^/]+/)+(?P<id>[^/]+?)(?:\.html|/?)$'
+    _VALID_URL = 'http://(?:[^.]+\.)?(?P<site>tv(?:noviny)?|tn|novaplus|vymena|fanda|krasna|doma|prask)\.nova\.cz/(?:[^/]+/)+(?P<id>[^/]+?)(?:\.html|/|$)'
-        'url': 'http://tvnoviny.nova.cz/clanek/novinky/co-na-sebe-sportaci-praskli-vime-jestli-pujde-hrdlicka-na-materskou.html',
+        'url': 'http://tvnoviny.nova.cz/clanek/novinky/co-na-sebe-sportaci-praskli-vime-jestli-pujde-hrdlicka-na-materskou.html?utm_source=tvnoviny&utm_medium=cpfooter&utm_campaign=novaplus',
-        'url': 'http://tn.nova.cz/clanek/tajemstvi-ukryte-v-podzemi-specialni-nemocnice-v-prazske-krci.html',
+        'url': 'http://tn.nova.cz/clanek/tajemstvi-ukryte-v-podzemi-specialni-nemocnice-v-prazske-krci.html#player_13260',
-        'url': 'http://novaplus.nova.cz/porad/policie-modrava/video/5591-policie-modrava-15-dil-blondynka-na-hrbitove/',
+        'url': 'http://novaplus.nova.cz/porad/policie-modrava/video/5591-policie-modrava-15-dil-blondynka-na-hrbitove',
-from ..utils import clean_html, determine_ext
+from ..utils import (
-            upload_date = '{}{:02d}{:02d}'.format(mobj.group('year'), int(mobj.group('month')), int(mobj.group('day')))
+            upload_date = unified_strdate(self._search_regex(
-            'description': 'md5:db00b9bc10ffd26fb148fa6a3a67c40b',
+            'description': 'md5:74e9617e51bca67c3ecfb2c6f9766f45',
-            'description': self._og_search_description(webpage),
+            'description': self._search_regex(
-    _VALID_URL = r'https?://play\.iprima\.cz/([^/]+/)*(?P<id>[^?#]+)'
+    _VALID_URL = r'https?://play\.iprima\.cz/(?:[^/]+/)*(?P<id>[^?#]+)'
-            'title': self._og_search_title(webpage).replace(' | Prima PLAY', ''),
+            'title': remove_end(self._og_search_title(webpage), ' | Prima PLAY'),
-    _VALID_URL = r'https?://play\.iprima\.cz/[^?#]+/(?P<id>[^?#]+)'
+    _VALID_URL = r'https?://play\.iprima\.cz/([^/]+/)*(?P<id>[^?#]+)'
-            'description': 'md5:3740fda51464da35a2d4d0670b8e4fd6',
+            'description': 'md5:db00b9bc10ffd26fb148fa6a3a67c40b',
-            'description': 'md5:589f8f59f414220621ff8882eb3ce7be',
+            'description': 'md5:db00b9bc10ffd26fb148fa6a3a67c40b',
-            'title': self._og_search_title(webpage),
+            'title': self._og_search_title(webpage).replace(' | Prima PLAY', ''),
-            transform_source=lambda s: re.sub(r'var\s+[\da-zA-Z_]+\s*=\s*({.+?});', r'\1', s))
+            transform_source=lambda s: s[s.index('{'):s.rindex('}') + 1])
-from ..utils import determine_ext
+from ..utils import clean_html, determine_ext
-            'description': 'md5:d804ba6b30bc7da2705b1fea961bddfe',
+            'description': 'md5:dc24e50be5908df83348e50d1431295e',
-        description = self._og_search_description(webpage)
+        description = clean_html(self._og_search_description(webpage, default=None))
-            'ext': 'flv',
+            'ext': 'mp4',
-        self._sort_formats(formats)
+        ext = determine_ext(video_url)
-            'formats': formats,
+            'url': video_url,
-    _VALID_URL = 'http://(?:[^.]+\.)?(?P<site>tv(?:noviny)?|tn|novaplus|vymena|fanda|krasna|doma|prask)\.nova\.cz/(?:[^/]+/)+(?P<id>[^/]+)(?:\.html|/?)'
+    _VALID_URL = 'http://(?:[^.]+\.)?(?P<site>tv(?:noviny)?|tn|novaplus|vymena|fanda|krasna|doma|prask)\.nova\.cz/(?:[^/]+/)+(?P<id>[^/]+?)(?:\.html|/?)$'
-    _VALID_URL = r'http://tv\.aftonbladet\.se/webbtv.+?(?P<id>article[0-9]+)\.ab(?:$|[?#])'
+    _VALID_URL = r'http://tv\.aftonbladet\.se/abtv/articles/(?P<id>[0-9]+)'
-        'url': 'http://tv.aftonbladet.se/webbtv/nyheter/vetenskap/rymden/article36015.ab',
+        'url': 'http://tv.aftonbladet.se/abtv/articles/36015',
-            'id': 'article36015',
+            'id': '36015',
-            r'data-aptomaId="([\w\d]+)"', webpage, 'internal_meta_id')
+        player_config = self._parse_json(self._html_search_regex(
-            r'<div id="watchCreation">\s*<iframe class="embedly-embed" src="([^"]+)"',
+            r'<div[^>]+id="watchCreation"[^>]*>\s*<iframe[^>]+src="([^"]+)"',
-    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?P<id>[a-zA-Z0-9]+)(?:\.mp4|\.gifv)?'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?P<id>[a-zA-Z0-9]+)'
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-            elif all(f.get('acodec') != 'none' for f in available_formats):
+            # for audio only (soundcloud) or video only (imgur) urls, select the best/worst audio format
-        thumbnail = item['thumbnail']
+        description = item.get('description')
-                    'filesize': item['video_files_size'][vcodec][format_id],
+                    'filesize': int_or_none(item.get('video_files_size', {}).get(vcodec, {}).get(format_id)),
-                'description': 'md5:a05bd01be310074d5833efc6743be95e',
+                'description': 'md5:d6b92ffb7217b4b8ebad2e7665253c17',
-                'age_limit': 0,
+                'age_limit': 12,
-            'md5': 'd9012d7c7c598fe7a11d7fb46dc1f574',
+            'md5': 'e7efe5350dd5011d0de6550b53c3ba7b',
-                'ext': 'mp4',
+                'ext': 'flv',
-                r'<li class="video-preview current_playing" id="(\d+)">',
+                r'class="video-preview current_playing" id="(\d+)">',
-            for quality, video_url in fmts.items():
+            for format_id, video_url in fmts.items():
-                    'format_id': '%s-%s' % (vcodec, quality),
+                    'format_id': '%s-%s' % (vcodec, format_id),
-                    'filesize': item['video_files_size'][vcodec][quality],
+                    'height': int_or_none(height),
-                    compat_urlparse.urljoin(url, '/%s' % channel_playlist), 'YoutubePlaylist')
+            return self.url_result(
-        # Direct link to a media delivered compressed (requires Accept-Encoding == *)
+        # Direct link to media delivered compressed (until Accept-Encoding is *)
-        },
+        # Direct link to a media delivered compressed (requires Accept-Encoding == *)
-            video_id = os.path.splitext(compat_urllib_parse.unquote(url.rstrip('/').split('/')[-1]))[0]
+            video_id = compat_urllib_parse_unquote(os.path.splitext(url.rstrip('/').split('/')[-1])[0])
-                'title': os.path.splitext(compat_urllib_parse.unquote(url_basename(url)))[0],
+                'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),
-                'title': os.path.splitext(compat_urllib_parse.unquote(url_basename(url)))[0],
+                'title': compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0]),
-            full_response = self._request_webpage(url, video_id)
+            request = compat_urllib_request.Request(url)
-            full_response = self._request_webpage(url, video_id)
+            request = compat_urllib_request.Request(url)
-            video_id = os.path.splitext(url.rstrip('/').split('/')[-1])[0]
+            video_id = os.path.splitext(compat_urllib_parse.unquote(url.rstrip('/').split('/')[-1]))[0]
-                'title': os.path.splitext(url_basename(url))[0],
+                'title': os.path.splitext(compat_urllib_parse.unquote(url_basename(url)))[0],
-                'title': os.path.splitext(url_basename(url))[0],
+                'title': os.path.splitext(compat_urllib_parse.unquote(url_basename(url)))[0],
-                req = compat_urllib_request.Request(
+                req_type = HEADRequest if req.get_method() == 'HEAD' else compat_urllib_request.Request
-        webpage = self._download_webpage(url, video_id, "get HTML content")
+        webpage = self._download_webpage(url, video_id, 'get HTML content')
-            "get real video url")
+            'get real video url')
-            'ext': 'mp4'
+            'ext': 'mp4',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            webpage, 'title', flags=re.DOTALL)
+            r'<div id="viewvideo-title">([^<]+)</div>', webpage, 'title')
-            r'so.addVariable\(\'max_vid\',\'(?P<n3>\d+)\'', webpage, 'n3')
+        file_id = self._search_regex(
-            'VID': n1,
+            'VID': file_id,
-            'max_vid': n3,
+            'seccode': sec_code,
-        video_url = self._search_regex(r'file=(?P<url>http.+?)&', info_cn, 'url')
+        info_cn = self._download_webpage(
-        info = {
+        return {
-            }
+        'url': 'http://91porn.com/view_video.php?viewkey=7e42283b4f5ab36da134',
-    _VALID_URL = r'http://(?:videos\.tf1|www\.tfou|www\.tf1)\.fr/.*?-(?P<id>\d+)(?:-\d+)?\.html'
+    _VALID_URL = r'http://(?:(?:videos|www|lci)\.tf1|www\.tfou)\.fr/.*?-(?P<id>\d+)(?:-\d+)?\.html'
-            'url': 'http://www.vgtv.no/#!/live/100015/direkte-her-kan-du-se-laksen-live-fra-suldalslaagen',
+            'url': 'http://www.vgtv.no/#!/live/113063/direkte-v75-fra-solvalla',
-                'id': '100015',
+                'id': '113063',
-                'description': 'md5:9a60cc23fa349f761628924e56eeec2d',
+                'title': 're:^DIREKTE: V75 fra Solvalla [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-                'upload_date': '20140807',
+                'timestamp': 1432975582,
-        if hds_url and data.get('streamType') != 'wasLive':
+        if hds_url and stream_type != 'wasLive':
-            'title': data['title'],
+            'title': self._live_title(data['title']),
-from ..utils import float_or_none
+from ..utils import (
-        if hds_url:
+        # wasLive hds are always 404
-        iv = bytes_to_intlist(base64.b64decode(iv))
+        data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))
-# Soompi uses the same subtitle encryption as crunchyroll
+from .common import InfoExtractor
-class SoompiIE(CrunchyrollIE):
+
-    _VALID_URL = r'^https?://tv\.soompi\.com/en/watch/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://tv\.soompi\.com/(?:en/)?watch/(?P<id>[0-9]+)'
-        subtitle_nodes = show_format_xml.findall('./{default}preload/subtitle')
+    def _get_episode(self, webpage, video_id):
-            sub_langs[i.attrib["id"]] = i.attrib["title"]
+        for subtitle in config.findall('./{default}preload/subtitles/subtitle'):
-            if lang_code is None:
+        subtitles = {}
-            }]
+            subtitles[lang_code] = self._extract_subtitles(subtitle)
-        slug = show_meta["slug"]
+        try:
-            formats.extend(avail_formats)
+        config = None
-        subtitles = self.extract_subtitles(video_id, show_format_xml)
+        episode = self._get_episode(webpage, video_id)
-class SoompiShowIE(SoompiIE):
+class SoompiShowIE(SoompiBaseIE):
-    _VALID_URL = r'^https?://tv\.soompi\.com/en/shows/(?P<id>[0-9a-zA-Z\-_]+)'
+    _VALID_URL = r'https?://tv\.soompi\.com/en/shows/(?P<id>[0-9a-zA-Z\-_]+)'
-        title = self._og_search_title(webpage).replace("SoompiTV | ", "")
+        webpage = self._download_webpage(
-                'http://tv.soompi.com/en/watch/%s' % ep['id'], 'Soompi', ep['id']))
+        entries = [
-        iv = bytes_to_intlist(iv)
+        data = bytes_to_intlist(base64.b64decode(data))
-            ]
+            subtitles[lang_code] = self._extract_subtitles(subtitle)
-            r'var flashvars\s*=\s*({.+?})', webpage, 'flashvars'))
+            r'flashvars\s*=\s*({.+?})', webpage, 'flashvars'))
-            r'videotitle\s*=\s*"([^"]+)', webpage, 'title')
+            r'videoTitle\s*=\s*"([^"]+)', webpage, 'title')
-            r'>Description:</strong>(.+?)<', webpage, 'description', fatal=False)
+            r'>Description:</strong>\s*(.+?)\s*<', webpage, 'description', fatal=False)
-            r'<strong class="video-username">(?:<a href="[^"]+">)?([^<]+)(?:</a>)?</strong>',
+            r'<span class="username">\s*(.+?)\s*<',
-            r"rupVar\s*=\s*'(\d+)'", webpage, 'like count', fatal=False))
+            r'rupVar\s*=\s*"(\d+)"', webpage, 'like count', fatal=False))
-            r"rdownVar\s*=\s*'(\d+)'", webpage, 'dislike count', fatal=False))
+            r'rdownVar\s*=\s*"(\d+)"', webpage, 'dislike count', fatal=False))
-            r'<strong>Views: </strong>([\d,\.]+)</li>', webpage, 'view count', fatal=False)
+            r'<strong>Views: </strong>([\d,\.]+)\s*</li>', webpage, 'view count', fatal=False)
-        server = server_json[0]['endpoint']
+            'http://spiegeltv-prod-static.s3.amazonaws.com/projectConfigs/projectConfig.json',
-            'thumbnails': thumbnails
+            'thumbnails': thumbnails,
-)
+from ..compat import compat_urllib_parse
-            'md5': '260f0f59686e65e886995d0ba791ab83',
+            'md5': '2cb594dc2781e6c941a110d8f358118b',
-                'ext': 'f4v'
+                'ext': 'f4v',
-    def construct_video_urls(self, data, video_id, _uuid):
+    def construct_video_urls(self, data, video_id, _uuid, bid):
-            video_urls = []
+            if int(i['bid']) != int(bid):  # ignore missing match format
-            '10': '4k'
+        _dict = {
-        return bid_dict[str(bid)]
+        return _dict.get(format_id, None)
-        video_urls_dict = self.construct_video_urls(data, video_id, _uuid)
+        video_urls_dict = self.construct_video_urls(
-            '3gphd': '1'
+            'flv'   : '0',
-            '3gphd': 'mp4',
+            'flv'   : 'flv',
-                        'format_id': fm,
+                        'format_id': self.get_format_name(fm),
-        elif info['ext'] == 'm4a':
+        elif info['ext'] in ['m4a', 'mp4']:
-            raise EmbedThumbnailPPError('Only mp3 and m4a are supported for thumbnail embedding for now.')
+            raise EmbedThumbnailPPError('Only mp3 and m4a/mp4 are supported for thumbnail embedding for now.')
-__version__ = '2015.05.20'
+__version__ = '2015.05.29'
-    _VALID_URL = r'http://www\.senate\.gov/isvp/\?(?P<qs>.+)'
+    _VALID_URL = r'http://www\.senate\.gov/isvp/?\?(?P<qs>.+)'
-            r"<iframe[^>]+src=['\"](?P<url>http://www\.senate\.gov/isvp/\?[^'\"]+)['\"]",
+            r"<iframe[^>]+src=['\"](?P<url>http://www\.senate\.gov/isvp/?\?[^'\"]+)['\"]",
-pyvs = sys.version_info[0]
+from ..compat import compat_urllib_parse
-            s = '' if pyvs == 3 else b''
+            s = '' if not bytes_is_str else b''
-                if pyvs == 3 \
+                if not bytes_is_str \
-                if pyvs == 3 \
+                if not bytes_is_str \
-                if pyvs == 3 \
+                if not bytes_is_str \
-            ep = ep.replace('=', '%2D')
+                param = {
-                    '&ep=' + generate_ep(format, n)
+                    compat_urllib_parse.urlencode(param)
-            raise ExtractorError("You are Blocked by Server.")
+import sys
-            s, x, y = '', 0, 0
+            s = '' if pyvs == 3 else b''
-                s += chr((s2[i] ^ ls[(ls[x]+ls[y]) % 256]))
+                if isinstance(s2[i], int):
-            'becaf9be', base64.b64decode(bytes(data2['ep'], 'ascii'))
+            'becaf9be',
-            ep = base64.b64encode(bytes(ep_t, 'latin')).decode()
+                bytes('%s_%s_%s' % (sid, fileid, token), 'ascii') \
-import time
+import base64
-
+from ..utils import ExtractorError
-        }
+            'url': 'http://v.youku.com/v_show/id_XMTc1ODE5Njcy.html',
-        return ''.join(realId)
+    def construct_video_urls(self, data1, data2):
-        info_url = 'http://v.youku.com/player/getPlayList/VideoIDS/' + video_id
+        # request basic data
-        config = self._download_json(info_url, video_id)
+        raw_data1 = self._download_json(data1_url, video_id)
-        error_code = config['data'][0].get('error_code')
+        error_code = data1.get('error_code')
-
+            # Chinese and English, separated by newline.
-                'ext': ext,
+                '_type': 'multi_video',
-            files_info.append(info)
+        else:
-        return files_info
+        return info
-            'https://api.nowtv.de/v3/movies/%s?fields=*,format,files,breakpoints,paymentPaytypes,trailers,pictures' % display_id,
+            'https://api.nowtv.de/v3/movies/%s?fields=*,format,files' % display_id,
-                expected=True)
+        files = info['files']
-        for item in info['files']['items']:
+        for item in files['items']:
-            re.DOTALL)
+        title = self._search_regex(
-        title = title.group(1).replace('\n', '')
+        title = title.replace('\n', '')
-        n3 = re.search(r'so.addVariable\(\'max_vid\',\'(\d+)\'', webpage)
+        n1 = self._search_regex(
-            'VID': n1.group(1),
+            'VID': n1,
-            'max_vid': n3.group(1),
+            'seccode': n2,
-        video_url = re.search(r'file=(http.+?)&', info_cn).group(1)
+        video_url = self._search_regex(r'file=(?P<url>http.+?)&', info_cn, 'url')
-from .nowtv import NowTvIE
+from .nowtv import NowTVIE
-# encoding: utf-8
+# coding: utf-8
-    unified_strdate,
+    parse_iso8601,
-            'skip': 'Only works from Germany',
+class NowTVIE(InfoExtractor):
-    ]
+        'params': {
-        info = self._download_json(info_url, None)
+        display_id = mobj.group('id')
-        thumbnail = info['format']['defaultImage169Logo']
+        info = self._download_json(
-            base_url = 'http://hls.fra.superrtlnow.de/hls-vod-enc/'
+        if info.get('geoblocked'):
-                'tbr': int_or_none(item['bitrate']),
+            item_path = remove_start(item['path'], '/')
-            formats.append(fmt)
+                'tbr': tbr,
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-            r'<h2 class="uiHeaderTitle">([^<]*)</h2>', webpage, 'title',
+            r'<h2\s+[^>]*class="uiHeaderTitle"[^>]*>([^<]*)</h2>', webpage, 'title',
-        self.assertEqual(md5(subtitles['no']), '1d221e6458c95c5494dcd38e6a1f129a')
+        self.assertEqual(md5(subtitles['no']), '544fa917d3197fcbee64634559221cc2')
-            if filed['type'] == 'hls':
+            if determine_ext(filed['url']) == 'm3u8':
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                'url': domain + format_el.find('uri').text,
+                'url': compat_urlparse.urljoin(domain, uri),
-                r'(?s)<div class="nation_error">\s*(?:<!--.*?-->)?\s*<p class="[^"]+">(?P<msg>.+?)</p>\s*</div>',
+                r'(?s)<div class="(?:nation_error|nation_box)">\s*(?:<!--.*?-->)?\s*<p class="[^"]+">(?P<msg>.+?)</p>\s*</div>',
-        lq_doc = self._download_xml(
+        lq_page = self._download_webpage(
-        assert len(lq_durls) == len(hq_durls)
+        if hq_doc is not False:
-            password = self._html_search_regex(
+            password = self._search_regex(
-            password = compat_urllib_parse.unquote_plus(self._html_search_regex(r'"video_title":"([^"]+)', webpage, 'password'))
+            password = compat_urllib_parse.unquote_plus(
-    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?:(?:old/)?user/)?(?P<user>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?:(?:old/)?user/)?(?P<user>[^/]+)$'
-    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?:old/)?user/(?P<user>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?:(?:old/)?user/)?(?P<user>[^/]+)'
-        webpage = self._download_webpage(url, user)
+        webpage = self._download_webpage(
-        }
+        },
-                r'src="(http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?[^"]*\bid=.+?)"',
+                r'src="(http://(?:player2\.screenwavemedia\.com|player\.screenwavemedia\.com/play)/[a-zA-Z]+\.php\?[^"]*\bid=.+?)"',
-        }
+        },
-            fatal=False)
+            default=None)
-                webpage, 'alternative title', default=None)
+                webpage, 'alternative title', fatal=False)
-    _TESTS = {
+    _VALID_URL = r'http://(?:videos\.tf1|www\.tfou|www\.tf1)\.fr/.*?-(?P<id>\d+)(?:-\d+)?\.html'
-    }
+    }, {
-from .rtlnow import RTLnowIE
+# encoding: utf-8
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-    _VALID_URL = r'https?://(?:odnoklassniki|ok)\.ru/(?:video|web-api/video/moviePlayer)/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:odnoklassniki|ok)\.ru/(?:video|web-api/video/moviePlayer)/(?P<id>[\d-]+)'
-            'age_limit': 0,
+        },
-        metadata = self._parse_json(player['flashvars']['metadata'], video_id)
+        flashvars = player['flashvars']
-            'ya:ovs:upload_date', webpage, 'upload date'))
+            'ya:ovs:upload_date', webpage, 'upload date', default=None))
-            'ya:ovs:adult', webpage, 'age limit')
+            'ya:ovs:adult', webpage, 'age limit', default=None)
-        title = title[:-len(' Video - Pinkbike')]
+        title = remove_end(title, ' Video - Pinkbike')
-        description = description[len(title + '. '):]
+        description = remove_start(description, title + '. ')
-        formats = [{'url': fmt[1], 'height': fmt[0]} for fmt in formats]
+        formats = [{'url': fmt[1], 'height': int_or_none(fmt[0])} for fmt in formats]
-            'duration': int(self._html_search_meta('video:duration', webpage, 'duration')),
+            'duration': duration,
-            'duration': '100'
+            'duration': 100
-            'duration': '180'
+            'duration': 180
-            'duration': self._html_search_meta('video:duration', webpage, 'duration'),
+            'duration': int(self._html_search_meta('video:duration', webpage, 'duration')),
-                'filesize': rendition['size'],
+                'format_id': '_'.join(
-            'view_count': json['playsTotal']
+            'duration': float_or_none(json.get('length'), 1000),
-                    # Hide the formats we found through non-DASH
+                    # Remove the formats we found through non-DASH, they
-                            f['preference'] = f.get('preference', 0) - 10000
+                    formats = [f for f in formats if f['format_id'] not in dash_keys]
-        row = get_element_by_id(anchor_id, webpage)
+        row = self._search_regex(
-
+from ..utils import (
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        page = self._download_webpage('https://www.rtbf.be/video/embed?id=%s' % video_id, video_id)
+        webpage = self._download_webpage(
-            r'<div class="js-player-embed(?: player-embed)?" data-video="([^"]+)"', page, 'data video'))['data']
+        data = self._parse_json(
-        if data['provider'].lower() == 'youtube':
+        if data.get('provider').lower() == 'youtube':
-            'thumbnail': data['thumbnail']['large'],
+            'thumbnail': data.get('thumbnail'),
-            'view_count': data['viewCount'],
+            'timestamp': int_or_none(data.get('created')),
-    _TEST = {
+    _VALID_URL = r'http://(?:www\.)?karrierevideos\.at(?:/[^/]+)+/(?P<id>[^/]+)'
-            'ext': 'mp4',
+            'id': '32c91',
-            'description': 'md5:dbadd1259fde2159a9b28667cb664ae2'
+            'description': 'md5:dbadd1259fde2159a9b28667cb664ae2',
-            'skip_download': 'requires rtmpdump'
+            # rtmp download
-    }
+    }, {
-            webpage, 'description')
+        title = (self._html_search_meta('title', webpage, default=None) or
-        playlist = self._html_search_regex(r'/config/video/(.*?)\.xml', webpage, 'playlist')
+        video_id = self._search_regex(
-            video_id)
+            'http://www.karrierevideos.at/player-playlist.xml.php?p=%s' % video_id,
-        namespace = 'http://developer.longtailvideo.com/trac/wiki/FlashFormats'
+        NS_MAP = {
-        streamer = item.find('{%s}streamer' % namespace).text
+        thumbnail = self._html_search_meta(
-            'title': self._html_search_meta('title', webpage),
+            'url': streamer.replace('rtmpt', 'rtmp'),
-            'ext': 'mp4'
+            'thumbnail': thumbnail,
-    _VALID_URL = r'^https?://www\.empflix\.com/videos/(?P<display_id>[0-9a-zA-Z-]+)-(?P<id>[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?empflix\.com/videos/(?P<display_id>.+?)-(?P<id>[0-9]+)\.html'
-    _VALID_URL = r'https?://(?:www\.)?tnaflix\.com/(?P<cat_id>[^/]+)/(?P<display_id>[^/]+)/video(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tnaflix\.com/[^/]+/(?P<display_id>[^/]+)/video(?P<id>\d+)'
-from ..utils import parse_iso8601
+from .common import InfoExtractor
-                    target = link['Target']
+                    target = link['Target']
-                    preference = -1 if target == 'HDS' else -2
+                    preference = None
-                        preference -= 2
+                        preference = -1
-                    })
+                    if target == 'HDS':
-    _VALID_URL = r'http://(www|ent).appledaily.com.tw/(animation|realtimenews|enews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
+    _VALID_URL = r'http://(www|ent).appledaily.com.tw/(?:animation|appledaily|enews|realtimenews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
-    AppleDailyAnimationNewsIE
+    AppleDailyIE,
-    _VALID_URL = r'http://(www|ent).appledaily.com.tw/(realtimenews|enews)/[^/]+/[^/]+/(?P<date>\d+)/(?P<id>\d+)(/.*)?'
+class AppleDailyIE(NextMediaIE):
-            'description': 'md5:b23787119933404ce515c6356a8c355c',
+            'description': 'md5:2acd430e59956dc47cd7f67cb3c003f4',
-            'description': 'md5:2648aaf6fc4f401f6de35a91d111aa1d',
+            'description': 'md5:175b4260c1d7c085993474217e4ab1b4',
-    _TESTS = [{
+    }, {
-        return self._html_search_meta('description', page, 'news title')
+        return (self._html_search_regex(r'<h1 id="h1">([^<>]+)</h1>', page, 'news title', default=None) or
-        (?P<path>.+?/(?P<title>[^/]+?)(?:\.(?:[a-z]{3,5})(?:-ap)?|(?=&)))'''
+        (?P<path>.+?/(?P<title>[^/]+?)(?:\.(?:[a-z\-]+)|(?=&)))'''
-    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|ran|the-voice-of-germany)\.de|fem\.com)/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:(?:prosieben|prosiebenmaxx|sixx|sat1|kabeleins|the-voice-of-germany)\.(?:de|at)|ran\.de|fem\.com)/(?P<id>.+)'
-            r'<iframe[^>]+?src=(["\'])(?P<url>https?://player\.rutv\.ru/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>https?://player\.(?:rutv\.ru|vgtrk\.com)/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\1', webpage)
-        help='Print downloaded pages to debug problems (very verbose)')
+        help='Print downloaded pages encoded using base64 to debug problems (very verbose)')
-            'age_limit': 18,
+    _TESTS = [
-    }
+    ]
-            'age_limit': 18,
+    _TESTS = [
-    }
+    ]
-            self._html_search_meta('duration', webpage, 'duration'))
+        duration_str = self._html_search_meta(
-    parse_iso8601,
+    unified_strdate,
-            'description': 'md5:81715fa9c4ea3d9e7915dc8180c778ed',
+            'description': 'md5:3d72dc4a006ab6805d82f037fdc637ad',
-            webpage, 'description', fatal=False)
+            [r'"nodetitle"\s*:\s*"([^"]+)"', r'class="node-header_{1,2}title">([^<]+)'],
-            webpage, 'duration', fatal=False))
+        upload_date = unified_strdate(self._html_search_meta(
-            'duration': duration,
+            'upload_date': upload_date,
-        video_url = base64.b64decode(compat_parse_qs(data_content)['kpt'][0]).decode('utf-8')
+        video_url = base64.b64decode(compat_parse_qs(data_content)['kpt'][0].encode('utf-8')).decode('utf-8')
-            'full:title', webpage, 'title')).decode('utf-8')
+            'full:title', webpage, 'title').encode('utf-8')).decode('utf-8')
-    encrypted_data = base64.b64decode(png)
+    encrypted_data = base64.b64decode(png.encode('utf-8'))
-    data = bytes_to_intlist(base64.b64decode(data))
+    data = bytes_to_intlist(base64.b64decode(data.encode('utf-8')))
-        decoded_video_info = base64.b64decode(base64_video_info).decode("utf-8")
+        decoded_video_info = base64.b64decode(base64_video_info.encode('utf-8')).decode('utf-8')
-                'url': base64.b64decode(res['u']).decode('utf-8'),
+                'url': base64.b64decode(res['u'].encode('utf-8')).decode('utf-8'),
-    _VALID_URL = r'https?://(?:www\.)?viki\.com/(?:videos|player)/(?P<id>[0-9]+v)'
+    _VALID_URL = r'%s(?:videos|player)/(?P<id>[0-9]+v)' % VikiBaseIE._VALID_URL_BASE
-    _VALID_URL = r'https?://(?:www\.)?viki\.com/(?:tv|news|movies|artists)/(?P<id>[0-9]+c)'
+    _VALID_URL = r'%s(?:tv|news|movies|artists)/(?P<id>[0-9]+c)' % VikiBaseIE._VALID_URL_BASE
-             'Additional templates: %(album), %(artist). '
+             'Additional templates: %(album)s, %(artist)s. '
-        'md5': '6a75fe9d0d3275bead0cb683c616fddb',
+        'params': {
-            'url': token_info['tokenizedUrl'],
+            'formats': formats,
-    _VALID_URL = r'https?://(?:www\.)?tnaflix\.com/(?P<cat_id>[\w-]+)/(?P<display_id>[\w-]+)/video(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tnaflix\.com/(?P<cat_id>[^/]+)/(?P<display_id>[^/]+)/video(?P<id>\d+)'
-        'md5': 'ecf3498417d09216374fc5907f9c6ec0',
+        'url': 'https://www.tnaflix.com/amateur-porn/bunzHD-Ms.Donk/video358632',
-            'display_id': 'Carmella-Decesare-striptease',
+            'id': '358632',
-            'description': '',
+            'title': 'bunzHD Ms.Donk',
-            'duration': 91,
+            'duration': 394,
-                container_title = container_titles.get('en') or container_titles[titles.keys()[0]]
+                container_title = container_titles.get('en') or container_titles[container_titles.keys()[0]]
-    _VALID_URL = r'https?://(?:www\.)?viki\.com/tv/(?P<id>[0-9]+c)'
+    _VALID_URL = r'https?://(?:www\.)?viki\.com/(?:tv|news|movies|artists)/(?P<id>[0-9]+c)'
-        for video_type in ('episodes', 'clips'):
+        for video_type in ('episodes', 'clips', 'movies'):
-class VikiChannelIE(InfoExtractor):
+class VikiChannelIE(VikiBaseIE):
-    _APP = '100000a'
+
-            channel_id, 'Downloading channel JSON')
+        channel = self._call_api(
-                    % (video_type, re.search(r'[?&]page=([0-9]+)', page_url).group(1)))
+            for page_num in itertools.count(1):
-                page_url = page['pagination']['next']
+                        'http://www.viki.com/videos/%s' % video_id, 'Viki'))
-        return {
+        result = {
-            'formats': formats,
+        streams = self._call_api(
-    mimetype2ext,
+    int_or_none,
-class VikiIE(InfoExtractor):
+class VikiBaseIE(InfoExtractor):
-    _VALID_URL = r'https?://(?:www\.)?viki\.com/videos/(?P<id>[0-9]+v)'
+    _VALID_URL = r'https?://(?:www\.)?viki\.com/(?:videos|player)/(?P<id>[0-9]+v)'
-        'md5': 'ca6493e6f0a6ec07da9aa8d6304b4b2c',
+        'md5': '86c0b5dbd4d83a6611a79987cc7a1989',
-            'title': '\'The Avengers: Age of Ultron\' Press Conference',
+            'uploader': 'Arirang TV',
-            'description': 'md5:54ff56d51bdfc7a30441ec967394e91c',
+            'duration': 6512,
-            # requires ffmpeg
+            # m3u8 download
-        video_subtitles = self.extract_subtitles(video_id, info_webpage)
+        streams = self._call_api(
-            'age_limit': age_limit,
+            'duration': duration,
-            'upload_date': upload_date,
+            'like_count': like_count,
-    _VALID_URL = r'^https?://(?:www\.)?viki\.com/videos/(?P<id>[0-9]+v)'
+    _VALID_URL = r'https?://(?:www\.)?viki\.com/videos/(?P<id>[0-9]+v)'
-    _VALID_URL = r'^https?://(?:www\.)?viki\.com/tv/(?P<id>[0-9]+c)'
+    _VALID_URL = r'https?://(?:www\.)?viki\.com/tv/(?P<id>[0-9]+c)'
-        show_page = self._download_webpage(url, show_id, 'Download show page')
+        channel_id = self._match_id(url)
-        description = self._og_search_description(show_page)
+        channel = self._download_json(
-                for video in show_json['response']:
+        for video_type in ('episodes', 'clips'):
-                json_url = show_json['pagination']['next']
+                page_url = page['pagination']['next']
-        return self.playlist_result(entries, show_id, title, description)
+        return self.playlist_result(entries, channel_id, title, description)
-        'url': 'http://tv.soompi.com/en/watch/23363',
+        'url': 'http://tv.soompi.com/en/watch/29235',
-            'id': '23363',
+            'id': '29235',
-            'description': '15sec'
+            'title': 'Episode 1096',
-__version__ = '2015.05.15'
+__version__ = '2015.05.20'
-            video_id.split(".")[0], consumer_secret, episode_filter=match_episode)
+            video_id.split(".")[0], consumer_secret,
-        },
+        'skip': 'Only available in China',
-        }
+        'skip': 'On available in China',
-            webpage, 'deliver URL')
+        deliver_url = self._proto_relative_url(self._search_regex(
-                r"jwplayer\('player(?:_temp)?'\)\.setup\(({.+?})\)\.on", deliver_page, 'player'),
+                r"jwplayer\('player(?:_temp)?'\)\.setup\(({.+?})\)\.on",
-            'description': 'md5:4348ff1dd24036906baa7b6f973f8d30',
+            'description': 'md5:d327722d0361576fde558f1ac68a7065',
-            if child.tag == _x('ttml:br'):
+            if child.tag in (_x('ttml:br'), 'br'):
-            elif child.tag == _x('ttml:span'):
+            elif child.tag in (_x('ttml:span'), 'span'):
-    paras = dfxp.findall(_x('.//ttml:p'))
+    paras = dfxp.findall(_x('.//ttml:p')) or dfxp.findall('.//p')
-            r'"nid"\s*:\s*"(\d+)"', webpage, 'video id')
+            [r'data-nid="(\d+)"', r'"nid"\s*:\s*"(\d+)"'],
-            r'"application"\s*:\s*"([^"]+)"', webpage, 'application', default='vier_vod')
+            [r'data-application="([^"]+)"', r'"application"\s*:\s*"([^"]+)"'],
-            r'"filename"\s*:\s*"([^"]+)"', webpage, 'filename')
+            [r'data-filename="([^"]+)"', r'"filename"\s*:\s*"([^"]+)"'],
-                    <img\s+src="/im/play.gif".*?>|
+                    <img\s+src="[^"]*/play.gif".*?>|
-            r'(?sm)new MagnifyEmbeddablePlayer\({.*?contentItem:\s*(\{.*?\})\n,\n',
+            r'(?sm)new MagnifyEmbeddablePlayer\({.*?contentItem:\s*(\{.*?\})\n?,\n',
-            r"[\"']file[\"']\s*[:,]\s*[\"'](.+?)[\"']", webpage, 'video URL')
+            [r"[\"']file[\"']\s*[:,]\s*[\"'](.+?)[\"']", r"videoId\s*:\s*[\"']([^\"']+)[\"']"],
-            r'<div class="filesize[^"]*"></div>\s*([0-9.]+\s*[a-zA-Z][bB])',
+            r'<div id="finfo"[^>]*>\s*â\s*([0-9.]+\s*[a-zA-Z][bB])',
-            r'minus_track\.tkn="(.+?)"', webpage, 'enc_token')
+            r'minus_track\.s?tkn="(.+?)"', webpage, 'enc_token')
-    _VALID_URL = r'https?://instagram\.com/p/(?P<id>[\da-zA-Z]+)'
+    _VALID_URL = r'https://instagram\.com/p/(?P<id>[\da-zA-Z]+)'
-        'url': 'http://instagram.com/p/aye83DjauH/?foo=bar#abc',
+        'url': 'https://instagram.com/p/aye83DjauH/?foo=bar#abc',
-    _VALID_URL = r'http://instagram\.com/(?P<username>[^/]{2,})/?(?:$|[?#])'
+    _VALID_URL = r'https://instagram\.com/(?P<username>[^/]{2,})/?(?:$|[?#])'
-        'url': 'http://instagram.com/porsche',
+        'url': 'https://instagram.com/porsche',
-                                            ' The formats won\'t be merged')
+                                            ' The formats won\'t be merged.')
-                                            'The formats will be merged into mkv')
+                        self.report_warning(
-            'http://www.karrierevideos.at/player-playlist.xml.php?p=%s' % playlist,
+            'http://www.karrierevideos.at/player-playlist.xml.php?p=' + playlist,
-        }
+        namespace = 'http://developer.longtailvideo.com/trac/wiki/FlashFormats'
-        streamer = item.find('jwplayer:streamer', namespace).text
+        streamer = item.find('{%s}streamer' % namespace).text
-            'play_path': 'mp4:' + item.find('jwplayer:file', namespace).text,
+            'play_path': 'mp4:' + item.find('{%s}file' % namespace).text,
-    VikiShowIE,
+    VikiChannelIE,
-    IE_NAME = 'viki:show'
+class VikiChannelIE(InfoExtractor):
-            json_url = 'http://api.viki.io/v4/containers/%s/%s.json?app=100000a&per_page=25&sort=number&direction=asc&with_paging=true&page=1' % (show_id, video_type)
+            json_url = 'http://api.viki.io/v4/containers/%s/%s.json?app=100000a&per_page=%d&sort=number&direction=asc&with_paging=true&page=1' % (show_id, video_type, self._PER_PAGE)
-                    json_url, show_id, note='Retrieve show json', errnote='Unable to get show json')
+                    json_url, show_id,
-from .tv2 import TV2IE
+from .tv2 import (
-                    '%s URL is invalid, skipping' % item, video_id)
+                self.to_screen(
-                raise ExtractorError('Viki said: ' + err_msg)
+                raise ExtractorError('Viki said: %s %s' % (err_msg, url))
-        'playlist_count': 25,
+        'playlist_count': 70,
-                'http://www.viki.com/videos/%s' % video_id, 'Viki', video_id))
+        for video_type in ['episodes', 'clips']:
-import json
+from .espn import ESPNIE
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        release_urls_json = js_to_json(self._search_regex(
+        player = self._search_regex(
-            release_urls.get('progressive') or release_urls.get('standard'))
+            webpage, 'player')
-                'http://player.ooyala.com/sas/player_api/v1/authorization/embed_code/%s/%s?domain=www.example.org&supportedFormats=mp4,webm' % (embedCode, embedCode),
+                'http://player.ooyala.com/sas/player_api/v1/authorization/embed_code/%s/%s?domain=www.example.org&supportedFormats=mp4,webm' % (video_id, video_id),
-from .ooyala import OoyalaIE
+from .ooyala import (
-                              ie=cls.ie_key())
+class OoyalaBaseIE(InfoExtractor):
-        player = self._download_webpage(player_url, embedCode)
+    def _extract(self, player_url, video_id):
-                '%s&device=%s' % (mobile_url, device), embedCode,
+                '%s&device=%s' % (mobile_url, device), video_id,
-                embedCode)
+                video_id)
-            cur_auth_data = auth_data['authorization_data'][embedCode]
+            cur_auth_data = auth_data['authorization_data'][video_id]
-                    'id': embedCode,
+                    'id': video_id,
-                'id': embedCode,
+                'id': video_id,
-        )
+            show_id, note='Retrieve show json', errnote='Unable to get show json')
-from .viki import VikiIE
+from .viki import (
-            return self.url_result(surl, 'SenateISVP')
+            return self.url_result(senate_isvp_url, 'SenateISVP')
-            webpage, 'thumbnail', fatal=False)
+            webpage, 'thumbnail', default=None)
-                'thumbnail': 'http://cbsnews2.cbsistatic.com/hub/i/r/2014/04/04/0c9fbc66-576b-41ca-8069-02d122060dd2/thumbnail/140x90/6dad7a502f88875ceac38202984b6d58/en-0404-werner-replace-640x360.jpg',
+                'thumbnail': 're:^https?://.*\.jpg$',
-from .sportbox import SportBoxIE
+from .sportbox import (
-            'only_matching': True,
+    _TESTS = [{
-    ]
+        'params': {
-        formats = self._extract_m3u8_formats(hls, display_id, 'mp4')
+        player = self._search_regex(
-            r'(?s)<div itemprop="description">(.+?)</div>', webpage, 'description', fatal=False)
+            r'(?s)<div itemprop="description">(.+?)</div>',
-            r'<span itemprop="uploadDate">([^<]+)</span>', webpage, 'timestamp', fatal=False))
+            r'<span itemprop="uploadDate">([^<]+)</span>',
-            r'<meta itemprop="duration" content="PT([^"]+)">', webpage, 'duration', fatal=False))
+            r'<meta itemprop="duration" content="PT([^"]+)">',
-            'id': video_id,
+            '_type': 'url_transparent',
-    _VALID_URL = r'(?:http://)?(?:www\.)?gamespot\.com/.*-(?P<id>\d+)/?'
+    _VALID_URL = r'http://(?:www\.)?gamespot\.com/.*-(?P<id>\d+)/?'
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-            })
+        f4m_url = streams.get('f4m_stream')
-        }, {
+        }, 
-        }
+        },
-            new_ids = orderedSet(matches)
+
-    http://www.youtube.com/feed_ajax
+    Base class for feed extractors
-        page = self._download_webpage('https://www.youtube.com/feed/history', title)
+        page = self._download_webpage(
-                'https://youtube.com/%s' % mobj.group('more'), title,
+                'https://youtube.com/%s' % mobj.group('more'), self._PLAYLIST_TITLE,
-        }
+        return self.playlist_result(
-        more_widget_html = content_html = page
+class YoutubeRecommendedIE(YoutubeFeedsInfoExtractor):
-                break
+class YoutubeSubscriptionsIE(YoutubeFeedsInfoExtractor):
-        }
+class YoutubeHistoryIE(YoutubeFeedsInfoExtractor):
-            'url': 'http://news.sportbox.ru/Vidy_sporta/Avtosport/Rossijskij/spbvideo_NI483529_Gonka-2-zaezd-Obyedinenniy-2000-klassi-Turing-i-S',
+            'url': 'http://news.sportbox.ru/Vidy_sporta/Avtosport/Rossijskij/spbvideo_NI483529_Gonka-2-zaezd-Obyedinenniy-2000-klassi-Turing-i-S',            
-            r'src="/vdl/player/media/(\d+)"', webpage, 'video id')
+        sobj = re.search(r'src="/vdl/player/(?P<media_type>\w+)/(?P<video_id>\d+)"', webpage)
-            'http://news.sportbox.ru/vdl/player/media/%s' % video_id,
+            'http://news.sportbox.ru/vdl/player/%s/%s' % (media_type, video_id),
-    _VALID_URL = r'https?://news\.sportbox\.ru/Vidy_sporta/(?:[^/]+/)+spbvideo_NI\d+_(?P<display_id>.+)'
+    _VALID_URL = r'https?://news\.sportbox\.ru/(?:[^/]+/)+spbvideo_NI\d+_(?P<display_id>.+)'
-            r"var\s+original_hls_file\s*=\s*'([^']+)'", player, 'hls file')
+            r"sportboxPlayer\.jwplayer_common_params\.file\s*=\s*['\"]+([^\"]+)['\"]+", player, 'hls file')
-        'md5': '205a365d0d57c0b1e43a12c9ffe8f9be',
+        'md5': '3a1eda8f3a29515d27f5adb967d7e740',
-            <a\s+href='(?P<http_url>[^']+)'>\s*
+            <a\s+download\s+href='(?P<http_url>[^']+)'>\s*
-                    entries = [ie_entries[i - 1] for i in playlistitems]
+                    entries = [
-__version__ = '2015.05.10'
+__version__ = '2015.05.15'
-class YoutubeHistoryIE(YoutubeFeedsInfoExtractor):
+class YoutubeHistoryIE(YoutubePlaylistIE):
-    _PLAYLIST_TITLE = 'Youtube Watch History'
+    _TESTS = []
-        webpage = self._download_webpage(url, display_id)
+        webpage, urlh = self._download_webpage_handle(url, display_id)
-                cur_sequence = (''.join(base64_fragments[i:] + base64_fragments[:i])).encode('ascii')
+        data = None
-                except (TypeError, binascii.Error):
+                    if compat_ord(raw_data[0]) == compat_ord('{'):
-                'Preload information could not be extracted', expected=True)
+        def _check_data():
-                base64.b64decode(preload.encode('ascii')).decode('utf-8'), video_id)
+            raise ExtractorError(
-            entries.extend(self._extract_info_dict(e, quiet=True) for e in new_entries)
+            entries.extend(self.url_result(e['permalink_url'], 'Soundcloud') for e in new_entries)
-        num_id = list_id.split("_")[1]
+        list_type, num_id = list_id.split("_")
-        list = self._download_json(
+        toplist_json = self._download_json(
-        for song in list['l']:
+        for song in toplist_json['l']:
-        return self.playlist_result(entries, list_id, list_name, list_desc)
+        return self.playlist_result(entries, list_id, list_name)
-    
+
-    
+
-            "http://y.qq.com/y/static/toplist/index/%s.html" % list_id, 
+            "http://y.qq.com/y/static/toplist/index/%s.html" % list_id,
-        list = self._download_json(jsonp_url, list_id, note='Retrieve toplist json', 
+
-            
+
-    _VALID_URL = r'http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?[^"]*\bid=(?P<id>.+)'
+    _VALID_URL = r'http://player\d?\.screenwavemedia\.com/(?:play/)?[a-zA-Z]+\.php\?[^"]*\bid=(?P<id>.+)'
-        playerdata = self._download_webpage(url, video_id, 'Downloading player webpage')
+
-            r'src="(http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?[^"]*\bid=.+?)"',
+            r'src="(http://player\d?\.screenwavemedia\.com/(?:play/)?[a-zA-Z]+\.php\?[^"]*\bid=.+?)"',
-    _TEST = {
+    _VALID_URL = r'https?://(?:www|m)\.worldstar(?:candy|hiphop)\.com/(?:videos|android)/video\.php\?v=(?P<id>.*)'
-    }
+    }, {
-            r'so\.addVariable\("file","(.*?)"\)', webpage, 'video URL')
+            [r'so\.addVariable\("file","(.*?)"\)',
-            r'(?s)<div class="content-heading">\s*<h1>(.*?)</h1>',
+            [r'(?s)<div class="content-heading">\s*<h1>(.*?)</h1>',
-            fatal=False)
+            default=None)
-            thumb_filename = os.path.splitext(filename)[0] + suffix + '.' + thumb_ext
+            t['filename'] = thumb_filename = os.path.splitext(filename)[0] + suffix + '.' + thumb_ext
-                    '(You may have to enable them in your /etc/fstab)')
+                msg = 'This filesystem doesn\'t support extended attributes. '
-        'md5': '3db39fb48b9685438ecf33a1078023e4',
+        'url': 'http://www.canalplus.fr/c-emissions/pid1830-c-zapping.html?vid=1263092',
-            'id': '922470',
+            'id': '1263092',
-            'upload_date': '20130826',
+            'title': 'Le Zapping - 13/05/15',
-        'md5': '65aa83ad62fe107ce29e564bb8712580',
+        elif self.code == errno.E2BIG or 'Argument list too long' in self.msg:
-                            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)
+                        try:
-)
+    PostProcessingError,
-                return xattr.setxattr(path, key, value)
+                try:
-                        f.write(value)
+                    try:
-                            cmd = ['setfattr', '-n', key, '-v', value, path]
+                            executable = 'setfattr'
-                            cmd = ['xattr', '-w', key, value, path]
+                            executable = 'xattr'
-                        subprocess_check_output(cmd)
+                        cmd = ([encodeFilename(executable, True)] +
-            self._downloader.report_error("This filesystem doesn't support extended attributes. (You may have to enable them in your /etc/fstab)")
+        except XAttrMetadataError as e:
-            cmd = ['AtomicParsley', filename, '--artwork', thumbnail_filename, '-o', temp_filename]
+            cmd = [encodeFilename('AtomicParsley', True),
-                '-i', thumbnail_filename, '-c', 'copy', '-map', '0', '-map', '1',
+                '-c', 'copy', '-map', '0', '-map', '1',
-            self.run_ffmpeg(filename, temp_filename, options)
+            self.run_ffmpeg_multiple_files([filename, thumbnail_filename], temp_filename, options)
-            thumb_filename = os.path.splitext(filename)[0] + suffix + '.' + thumb_ext
+            t['filename'] = thumb_filename = os.path.splitext(filename)[0] + suffix + '.' + thumb_ext
-        postprocessors.append({'key': 'EmbedThumbnail'})
+        already_have_thumbnail = opts.writethumbnail or opts.write_all_thumbnails
-    determine_ext,
+    def __init__(self, downloader=None, already_have_thumbnail=False):
-        if not info.get('thumbnail'):
+        if not info.get('thumbnails'):
-        compat_urlretrieve(info['thumbnail'], temp_thumbnail)
+        thumbnail_filename = info['thumbnails'][-1]['filename']
-                '-i', temp_thumbnail, '-c', 'copy', '-map', '0', '-map', '1',
+                '-i', thumbnail_filename, '-c', 'copy', '-map', '0', '-map', '1',
-            os.remove(encodeFilename(temp_thumbnail))
+            if not self._already_have_thumbnail:
-            cmd = ['AtomicParsley', filename, '--artwork', temp_thumbnail, '-o', temp_filename]
+            cmd = ['AtomicParsley', filename, '--artwork', thumbnail_filename, '-o', temp_filename]
-            os.remove(encodeFilename(temp_thumbnail))
+            if not self._already_have_thumbnail:
-                r"OKVideo\.start\(({.+?})\s*,\s*'VideoAutoplay_player'", webpage, 'player'),
+            unescapeHTML(self._search_regex(
-                    and FFmpegMergerPP(self).available):
+            if (self.params.get('outtmpl', DEFAULT_OUTTMPL) != '-' and
-            'thumbnail': 're:^https?://.*promo.*'
+            'thumbnail': 're:^https?://.*\.jpg$'
-        elif list_type == 'global':
+        else:
-
+            jsonp_url = "http://y.qq.com/y/static/toplist/json/top/%s/1.js" % num_id
-            entries = self.get_entries_from_page(list_page)
+            jsonp_url = "http://y.qq.com/y/static/toplist/json/global/%s/1_1.js" % num_id
-        list_page = self._download_webpage("http://y.qq.com/y/static/toplist/index/%s.html" % list_id, list_id, 'Download toplist page')
+        list_page = self._download_webpage(
-                list_id, note='Retrieve toplist json', errnote='Unable to get toplist json', transform_source=self.strip_qq_jsonp)
+                list_id, note='Retrieve toplist json', errnote='Unable to get toplist json', 
-        return self.playlist_result(entries, list_id, list_name, list_desc)
+        return self.playlist_result(entries, list_id, list_name, list_desc)
-
+    srt_subtitles_timecode,
-                self._subtitles_timecode(item['endMillis'] / 1000.0),
+                srt_subtitles_timecode(item['startMillis'] / 1000.0),
-    return '%02d:%02d:%02d,%03d' % (hours, mins, secs, millisecs)
+def srt_subtitles_timecode(seconds):
-            format_srt_time(end_time),
+            srt_subtitles_timecode(begin_time),
-            transform_source=lambda s: s.replace(r'<br />', '\r\n'))
+            url, video_id, 'Downloading subtitles')
-                    <p begin="2" end="3"><span>Third<br/>Line</span></p>
+                    <p begin="2" dur="1"><span>Third<br/>Line</span></p>
-            format_srt_time(parse_dfxp_time_expr(para.attrib.get('end'))),
+            format_srt_time(begin_time),
-    _VALID_URL = r'https?://(?:www)?\.nytimes\.com/(.(?<!video))*?/(?:[^/]+/)*(?P<id>[^.]+)(?:\.html)?'
+    _VALID_URL = r'https?://(?:www\.)?nytimes\.com/(.(?<!video))*?/(?:[^/]+/)*(?P<id>[^.]+)(?:\.html)?'
-            'alt_title': self._og_search_description(webpage),
+            'alt_title': self._og_search_description(webpage, default=None),
-    IE_NAME = 'southpark.dk'
+    IE_NAME = 'southparkstudios.dk'
-    SouthParkEsIE,
+    SouthParkEsIE,
-    def _extract_item(item):
+    def _extract_item(self, item):
-        req.add_header('Cookie', 'nsfw=1')
+        req.add_header('Cookie', 'nsfw=1; cpc=10')
-from .tmz import TMZIE
+from .tmz import (
-                if merger.available and not merger.check_outdated():
+                if merger.available and merger.can_merge():
-        return False
+    def can_merge(self):
-                req_format_list.append('bestvideo+bestaudio')
+                    and info_dict['extractor'] in ['youtube', 'ted']):
-    def __init__(self, downloader=None, exec_cmd=None):
+    def __init__(self, downloader, exec_cmd):
-        self.verboseOutput = verboseOutput
+    def __init__(self, downloader=None, exec_cmd=None):
-
+        config = self._search_regex(
-            } for format_id, talk_url in re.findall(r"data-([^=]+)='([^']+)'", webpage)]
+            } for format_id, talk_url in re.findall(r"data-([^=]+)='([^']+)'", player)]
-from ..utils import ExtractorError
+from ..compat import (
-        'url': 'https://voicerepublic.com/talks/watching-the-watchers-building-a-sousveillance-state',
+    _VALID_URL = r'https?://voicerepublic\.com/(?:talks|embed)/(?P<id>[0-9a-z-]+)'
-            'thumbnail': 'https://voicerepublic.com/system/flyer/2296.png',
+            'thumbnail': 're:^https?://.*\.(?:png|jpg)$',
-    }
+    }, {
-        req = compat_urllib_request.Request(url)
+
-            raise ExtractorError('Audio is still queued for processing')
+        if '>Queued for processing, please stand by...<' in webpage:
-        } for ext, path in re.findall(r"data-([^=]+)='(/[^']+\.\1)'", webpage)]
+        data = self._parse_json(
-            'url': self._og_search_url(webpage),
+            'id': talk_id,
-            'description': self._og_search_description(webpage),
+            'duration': duration,
-            }
+            },
-from .ndr import NDRIE
+from .ndr import (
-
+class NDRBaseIE(InfoExtractor):
-        duration = int_or_none(self._html_search_regex(r'duration: (\d+),\n', page, 'duration', fatal=False))
+        duration = int_or_none(self._html_search_regex(r'duration: (\d+),\n', page, 'duration', default=None))
-        mobj = re.search(r'<div class="[^"]*uploaded_cont[^"]*" title="[^"]*">([0-9]{2})-([0-9]{2})-([0-9]{4})</div>', webpage)
+        mobj = re.search(r'<meta property="video:release_date" content="([0-9]{4})-([0-9]{2})-([0-9]{2}).+?"/>', webpage)
-            video_upload_date = mobj.group(3) + mobj.group(2) + mobj.group(1)
+            video_upload_date = mobj.group(1) + mobj.group(2) + mobj.group(3)
-            'url': 'https://voicerepublic.com/vrmedia/{}-clean.{}'.format(video_id, ext),
+            'url': 'https://voicerepublic.com' + path,
-        } for ext in exts]
+        } for ext, path in re.findall(r"data-([^=]+)='(/[^']+\.\1)'", webpage)]
-        } for ext in ['m4a', 'mp3', 'ogg']]
+        } for ext in exts]
-)
+from ..compat import compat_urllib_request
-            formats = []
+        if '<a>Queued for processing, please stand by...</a>' in webpage:
-            'creator': self._search_regex(r'<meta content=\'([^\']*?)\' name=\'author\'>', webpage, 'author', fatal=False),
+            'creator': self._html_search_meta('author', webpage),
-                        m(?:lb)?\.(?:[\da-z_-]+\.)?mlb\.com/
+                        (?:[\da-z_-]+\.)*mlb\.com/
-                                    [^/]+/video/play\.jsp
+                                    (?:[^/]+/)+(?:play|index)\.jsp|
-                r'data-video-?id="(\d+)"', webpage, 'video id')
+                [r'data-video-?id="(\d+)"', r'content_id=(\d+)'], webpage, 'video id')
-__version__ = '2015.05.04'
+__version__ = '2015.05.10'
-from .lifenews import LifeNewsIE
+from .lifenews import (
-    _VALID_URL = r'http://lifenews\.ru/(?:mobile/)?news/(?P<id>\d+)'
+    _VALID_URL = r'http://lifenews\.ru/(?:mobile/)?(?P<section>news|video)/(?P<id>\d+)'
-        webpage = self._download_webpage('http://lifenews.ru/news/%s' % video_id, video_id, 'Downloading page')
+        webpage = self._download_webpage(
-            '<iframe[^>]+src="([^"]+)', webpage, 'iframe link', default=None)
+            '<iframe[^>]+src=["\']([^"\']+)["\']', webpage, 'iframe link', default=None)
-            formats.extend(self._extract_m3u8_formats(hls_url, video_id, 'mp4'))
+            formats.extend(self._extract_m3u8_formats(
-            formats.extend(self._extract_f4m_formats(hds_url + '?hdcore=3.2.0&plugin=aasp-3.2.0.77.18', video_id))
+            formats.extend(self._extract_f4m_formats(
-from ..utils import ExtractorError
+from ..utils import (
-            r'<source src="([^"]+)', webpage, 'video url')
+        video_url = unescapeHTML(self._search_regex(
-            'md5': '93556dd2bcb2948d9259f8670c516d59',
+            'url': 'http://www.br.de/mediathek/video/sendungen/abendschau/betriebliche-altersvorsorge-104.html',
-                'id': '25e279aa-1ffd-40fd-9955-5325bd48a53a',
+                'id': '48f656ef-287e-486f-be86-459122db22cc',
-                'upload_date': '20140802',
+                'title': 'Die bÃ¶se Ãberraschung',
-            'md5': '3db0df1a9a9cd9fa0c70e6ea8aa8e820',
+            'url': 'http://www.br.de/nachrichten/oberbayern/inhalt/muenchner-polizeipraesident-schreiber-gestorben-100.html',
-                'duration': 64,
+                'id': 'a4b83e34-123d-4b81-9f4e-c0d3121a4e05',
-        },
+            'url': 'http://m.mlb.com/news/article/118550098/blue-jays-kevin-pillar-goes-spidey-up-the-wall-to-rob-tim-beckham-of-a-homer',
-                r'data-videoid="(\d+)"', webpage, 'video id')
+                r'data-video-?id="(\d+)"', webpage, 'video id')
-                        \.no/(?:tv/)?#!/(?:video|live)/
+                        \.no/(?:tv/)?\#!/(?:video|live)/
-
+    get_element_by_attribute,
-        mobj = re.search(r'<!-- ç¼è¡¨æ¼ -->(?P<mon>[A-Z][a-z]{2})  ' +
+            r'<!-- ç¼è¡¨ä½è -->ï¼[\n ]+<a href="/([a-z0-9]+)"',
-            'title': self._html_search_meta('description', page),
+            'title': title,
-)
+from ..utils import ExtractorError
-        'md5': '699060e75cf58858dd47fb9c03c42cfb',
+        'md5': 'ac9a5d322b4bf9ae184d53e4711e4f1a',
-        'md5': '9bf34be48f2f4dadcb226c74127e203c',
+        'md5': '49308ff6dafde5ece51137d04aec311e',
-            'md5': 'bdbfb8f39924725e6589c146bc1883ad',
+            'md5': '492923eac023ba2f13ff69617c32754a',
-            'md5': '3e1f46aaeb95354fd10e7fca9fc1804e',
+            'md5': 'de604848c0e8e9c4a4dde7e1347c0637',
-            'md5': '8407e634175fdac706766481b9443450',
+            'md5': '93584716ee0657c0b205b8aa3d27aa13',
-                    '%s%s?key=%s' % (part_info[0], su[i], part_info[3]))
+                # URLs starts with http://newflv.sohu.ccgslb.net/ is not usable
-from ..utils import sanitize_url_path_consecutive_slashes
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?foxsports\.com/video\?vid=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?foxsports\.com/(?:[^/]+/)*(?P<id>[^/]+)'
-from .svtplay import (
+from .svt import (
-from .svtplay import SVTPlayIE
+from .svtplay import (
-            'http://www.%s.se/video/%s?output=json' % (host, video_id), video_id)
+class SVTBaseIE(InfoExtractor):
-from .xvideos import XVideosIE
+from .xvideos import XVideosIE
-    IE_DESC = 'Bergens Tidende'
+    IE_NAME = 'bt:article'
-        }
+        return self.url_result('xstream:ap:%s' % self._match_id(url), 'Xstream')
-from .vgtv import VGTVIE
+from .vgtv import (
-    _VALID_URL = r'http://(?:www\.)?(?P<host>vgtv|bt)\.no/(?:(?:tv/)?#!/(?:video|live)/(?P<id>[0-9]+)|(?:[^/]+/)*(?P<path>[^/]+))'
+    _VALID_URL = r'''(?x)
-    _VALID_URL = r'http://(?:www\.)?vgtv\.no/#!/[^/]+/(?P<id>[0-9]+)'
+    IE_DESC = 'VGTV and BTTV'
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            'http://svp.vg.no/svp/api/v1/vgtv/assets/%s?appName=vgtv-website' % video_id,
+            'http://svp.vg.no/svp/api/v1/%s/assets/%s?appName=%s-website'
-                            (?P<path>.+?)
+                            (?:[^/]+/)*(?P<path>[^/]+)
-    _VALID_URL = r'https?://m(?:lb)?\.(?:[\da-z_-]+\.)?mlb\.com/(?:(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|(?:shared/video/embed/(?:embed|m-internal-embed)\.html|[^/]+/video/play\.jsp)\?.*?\bcontent_id=)(?P<id>n?\d+)'
+    _VALID_URL = r'''(?x)
-            r'window\.avoCore\s*=.*?urlTemplate:\s*(\{.*?"\})',
+            r'var urlTemplate=(\{.*?"\})',
-                'id': '740ab250-bb94-4a8a-8787-fe0de7c74471',
+                'id': 'news/national/2014/a-conversation-with-president-obama',
-                'description': 'md5:5a88d8ae912c1b33e090290af7ec33c6',
+                'title': 'A Conversation With President Obama',
-                'id': 'bcd1b1df-673a-42cf-8d01-b282db608f2d',
+                'id': 'news/national/2014/justice-for-ferguson-a-community-reacts',
-            [exe] + args,
+            [encodeArgument(exe)] + args,
-        }
+        }
-        return {
+        ret = {
-            basic_args += ['--tcUrl', url]
+            basic_args += ['--tcUrl', tc_url]
-    def find_assets(data, asset_type):
+    def find_assets(data, asset_type, asset_id=None):
-            if asset.get('type') == asset_type:
+            if not asset.get('type') == asset_type:
-            video_asset = next(VesselIE.find_assets(data, 'video'))
+            video_asset = next(
-    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/(?:console)?(?:\?(?:.*?[?&])?)id=(?P<id>[-0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/(?:console)?(?:\?(?:.*?[?&])?)(?:id|hlg)=(?P<id>[-0-9a-zA-Z,]+)'
-            if len(formats):
+            if formats:
-                new_url = found.group(1)
+                new_url = compat_urlparse.urljoin(url, found.group(1))
-            if info_dict['extractor'] in ['youtube', 'ted'] and FFmpegMergerPP(self).available:
+            if (self.params.get('outtmpl', DEFAULT_OUTTMPL) != '-'
-            'thumbnail': 'http://bilder.bild.de/fotos/bild-hat-sie-getestet-das-koennen-apples-neue-ipads-38184138/Bild/1.bild.jpg',
+            'thumbnail': 're:^https?://.*\.jpg$',
-  fix_xml_ampersands,
+    int_or_none,
-from ..utils import int_or_none
+from ..utils import (
-            'thumbnail': 'http://bilder.bild.de/fotos/stand-das-koennen-die-neuen-ipads-38184138/Bild/1.bild.jpg',
+            'thumbnail': 'http://bilder.bild.de/fotos/bild-hat-sie-getestet-das-koennen-apples-neue-ipads-38184138/Bild/1.bild.jpg',
-        doc = self._download_xml(xml_url, video_id)
+        doc = self._download_xml(xml_url, video_id, transform_source=fix_xml_ampersands)
-            'ext': 'mp4',
+            'id': embedCode,
-            'url': info.get('ipad_url') or info['url'],
+            'formats': formats,
-                last_media_name = last_media.get('NAME') if last_media else None
+                last_media_name = last_media.get('NAME') if last_media and last_media.get('TYPE') != 'SUBTITLES' else None
-            print(ooyala_url)
+import binascii
-        preload = None
+        data = preload = None
-            base64.b64decode(preload.encode('ascii')).decode('utf-8'), video_id)
+        if not data:
-            r'class="tapeId">([^<]+)<', webpage, 'tape id')
+            [r'class="tapeId"[^>]*>([^<]+)<', r'tapeId\s*:\s*"([^"]+)"'],
-        },
+        'only_matching': True,
-            r'<span class="views"><strong>([\d.]+)</strong>', webpage, 'view count', fatal=False))
+            r'<span class="views"><strong>([\d.,]+)</strong>',
-                f.get('format_id'),
+                f.get('format_id') if f.get('format_id') is not None else '',
-        json_url = url + ('?' if '?' in url else '&') + 'output=json'
+        json_url = url + ('&' if '?' in url else '?') + 'output=json'
-                iframe_link = 'http:' + iframe_link
+            iframe_link = self._proto_relative_url(iframe_link, 'http:')
-        },
+        'playlist_count': 4,
-    SouthparkDeIE,
+    SouthParkDeIE,
-class SouthparkDeIE(SouthParkIE):
+class SouthParkDeIE(SouthParkIE):
-                'description': '',
+                'timestamp': 1403863200,
-                        'quality': qualities[format_id]['priority'],
+                        'width': int_or_none(fmt.get('res_width')),
-        duration = show['duration_ms'] / 1000.0
+        timestamp = parse_iso8601(show.get('online_date_start_utc'), ' ')
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-            audio_lang = show['original_lang']
+        options = self._call_api(
-            audio_lang = 'fr'
+            audio_lang_pref = list(medias.keys())[0]
-                })
+        for audio_lang, audio_lang_dict in medias.items():
-            'duration': 2851.2,
+    _TESTS = [
-    }
+        {
-        for lang, lang_dict in medias['fr']['video_list'].items():
+        for lang, lang_dict in medias[audio_lang]['video_list'].items():
-                    'shows/%s/video/%s/fr' % (video_id, format_id.lower()),
+                    'shows/%s/video/%s/%s' % (video_id, format_id.lower(), audio_lang),
-
+        is_live = video_type == 'live'
-            'http://player.rutv.ru/iframe/%splay/id/%s' % ('live-' if video_type == 'live' else '', video_id),
+            'http://player.rutv.ru/iframe/%splay/id/%s' % ('live-' if is_live else '', video_id),
-                    formats.extend(self._extract_m3u8_formats(url, video_id, 'mp4'))
+                    formats.extend(self._extract_m3u8_formats(
-            'url': 'http://live.russia.tv/index/index/channel_id/3',
+            'url': 'http://player.rutv.ru/iframe/live/id/21/showZoomBtn/false/isPlay/true/',
-from .nytimes import NYTimesIE
+from .nytimes import (
-    _TEST = {
+    _VALID_URL = r'https?://(?:www)?\.nytimes\.com/(.(?<!video))*?/(?:[^/]+/)*(?P<id>[^.]+)(?:\.html)?'
-    }
+    }, {
-
+class NYTimesBaseIE(InfoExtractor):
-    _VALID_URL = r'''(?x)https?://www\.livestream\.com/
+    _VALID_URL = r'''(?x)https?://original\.livestream\.com/
-        'url': 'http://www.livestream.com/dealbook/video?clipId=pla_8aa4a3f1-ba15-46a4-893b-902210e138fb',
+        'url': 'http://original.livestream.com/dealbook/video?clipId=pla_8aa4a3f1-ba15-46a4-893b-902210e138fb',
-        'url': 'https://www.livestream.com/newplay/folder?dirId=a07bf706-d0e4-4e75-a747-b021d84f2fd3',
+        'url': 'https://original.livestream.com/newplay/folder?dirId=a07bf706-d0e4-4e75-a747-b021d84f2fd3',
-            'ext': 'flv',
+            'ext': 'mp4',
-        },
+        # this url is used on mobile devices
-            'ext': 'flv',
+            'url': stream_info['progressiveUrl'],
-        theplatform_url = self._search_regex(
+        theplatform_url = unescapeHTML(lowercase_escape(self._html_search_regex(
-            webpage, 'theplatform url').replace('_no_endcard', '')
+            webpage, 'theplatform url').replace('_no_endcard', '').replace('\\/', '/')))
-__version__ = '2015.05.03'
+__version__ = '2015.05.04'
-        imsVideo = self._parse_json(
+        ims_video = self._parse_json(
-        key = imsVideo['hash']
+        video_id = ims_video['videoID']
-        duration = data['videoData']['duration'] / 1000
+        video_data = data['videoData']
-    _VALID_URL = r'https?://?(www\.)?escapistmagazine\.com/videos/view/[^/?#]+/(?P<id>[0-9]+)-[^/?#]*(?:$|[?#])'
+    _VALID_URL = r'https?://?(?:www\.)?escapistmagazine\.com/videos/view/[^/?#]+/(?P<id>[0-9]+)-[^/?#]*(?:$|[?#])'
-        'md5': 'c6793dbda81388f4264c1ba18684a74d',
+        'md5': 'ab3a706c681efca53f0a35f1415cf0d1',
-        'md5': 'cf8842a8a46444d241f9a9980d7874f2',
+        'md5': '9e8c437b0dbb0387d3bd3255ca77f6bf',
-    qualities,
+    int_or_none,
-        quality = qualities(['lq', 'hq', 'hd'])
+        config_req = compat_urllib_request.Request(
-            config = self._download_webpage(config_req, video_id, 'Downloading video config ' + q.upper())
+        data = json.loads(_decrypt_config(key, config))
-            data = json.loads(_decrypt_config(key, config))
+        title = clean_html(data['videoData']['title'])
-                })
+        formats = [{
-            '(?:class="video-player video-player-full" data-mpx-url|class="player" src)="(.*?)"',
+            [
-__version__ = '2015.04.28'
+__version__ = '2015.05.03'
-    _VALID_URL = r'https?://m(?:lb)?\.(?:[\da-z_-]+\.)?mlb\.com/(?:(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|(?:shared/video/embed/embed\.html|[^/]+/video/play\.jsp)\?.*?\bcontent_id=)(?P<id>n?\d+)'
+    _VALID_URL = r'https?://m(?:lb)?\.(?:[\da-z_-]+\.)?mlb\.com/(?:(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|(?:shared/video/embed/(?:embed|m-internal-embed)\.html|[^/]+/video/play\.jsp)\?.*?\bcontent_id=)(?P<id>n?\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        if not videos:
+        iframe_link = self._html_search_regex(
-            return {
+            cur_info = dict(common_info)
-            }
+            })
-            r'<div class=\'views\'>(\d+)</div>', webpage, 'view count', fatal=False)
+            r'<div class=\'views\'>\s*(\d+)\s*</div>', webpage, 'view count', fatal=False)
-            r'<div class=\'comments\'>\s*<span class=\'counter\'>(\d+)</span>', webpage, 'comment count', fatal=False)
+            r'<div class=\'comments\'>\s*<span class=\'counter\'>\s*(\d+)\s*</span>', webpage, 'comment count', fatal=False)
-        url = 'http://www.dailymotion.com/video/%s' % video_id
+        url = 'https://www.dailymotion.com/video/%s' % video_id
-        embed_url = 'http://www.dailymotion.com/embed/video/%s' % video_id
+        embed_url = 'https://www.dailymotion.com/embed/video/%s' % video_id
-                            break
+                (down, frag_sanitized) = sanitize_open(frag_filename, 'rb')
-                    os.remove(frag_filename)
+                    os.remove(encodeFilename(frag_sanitized))
-                    frags_filenames.append(frag_filename)
+                    frags_filenames.append(frag_sanitized)
-            os.remove(frag_file)
+            os.remove(encodeFilename(frag_file))
-                # rtmp download
+                # m3u8 download
-            'skip': 'Translation has finished',
+        is_live = video_type == 'live'
-            'title': title,
+            'title': self._live_title(title) if is_live else title,
-    _VALID_URL = r'http://v\.baidu\.com/(?P<type>[a-z]+)/(?P<id>\d+).htm'
+    _VALID_URL = r'http://v\.baidu\.com/(?P<type>[a-z]+)/(?P<id>\d+)\.htm'
-    _VALID_URL = r'http://(?:www\.)?vgtv\.no/#!/(?:.*)/(?P<id>[0-9]+)'
+    _VALID_URL = r'http://(?:www\.)?vgtv\.no/#!/[^/]+/(?P<id>[0-9]+)'
-        help='Write video annotations to a .annotation file')
+        help='Write video annotations to a .annotations.xml file')
-            descfn = filename + '.description'
+            descfn = replace_extension(filename, 'description', info_dict.get('ext'))
-            annofn = filename + '.annotations.xml'
+            annofn = replace_extension(filename, 'annotations.xml', info_dict.get('ext'))
-            infofn = os.path.splitext(filename)[0] + '.info.json'
+            infofn = replace_extension(filename, 'info.json', info_dict.get('ext'))
-                            fname = prepend_extension(fname, 'f%s' % f['format_id'])
+                            fname = prepend_extension(fname, 'f%s' % f['format_id'], new_info['ext'])
-def prepend_extension(filename, ext):
+def prepend_extension(filename, ext, expected_real_ext=None):
-    return '{0}.{1}{2}'.format(name, ext, real_ext)
+    return (
-                        filename = os.path.splitext(filename)[0] + '.mkv'
+                        info_dict['ext'] = 'mkv'
-            request.get_method = lambda: http_method
+        basic_request = compat_urllib_request.Request(url, None, headers)
-        }
+from ..utils import int_or_none
-    _VALID_URL = r'https?://(www\.)?(?:iconosquare\.com|statigr\.am)/p/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:iconosquare\.com|statigr\.am)/p/(?P<id>[^/]+)'
-            'title': 'Instagram photo by @aguynamedpatrick (Patrick Janelle)',
+            'title': 'Instagram media by @aguynamedpatrick (Patrick Janelle)',
-            r'@([^ ]+)', title, 'uploader name', fatal=False)
+
-            'uploader_id': uploader_id
+            'description': description,
-            err_msg = clean_html(err_msg)
+    determine_ext,
-            r'<source[^>]+src="([^"]+)"', info_webpage, 'video URL')
+        mobj = re.search(
-            'url': video_url,
+            'formats': formats,
-                expected=True)
+        err_msg = self._html_search_regex(r'<div[^>]+class="video-error[^>]+>(.+)</div>', info_webpage, 'error message', default=None)
-from ..compat import compat_urlparse
+from ..compat import (
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        info_url = 'http://www.viki.com/player5_fragment/%s?action=show&controller=videos' % video_id
+        req = compat_urllib_request.Request(
-            info_url, video_id, note='Downloading info page')
+            req, video_id, note='Downloading info page')
-                    'right restrictions')
+        info = self._download_json(
-            raise ExtractorError(message, expected=True)
+                formats.append({
-            'duration': info.get('duration'),
+            'duration': int_or_none(info.get('duration')),
-        help='Embed subtitles in the video (only for mp4 videos)')
+        help='Embed subtitles in the video (only for mkv and mp4 videos)')
-            self._downloader.to_screen('[ffmpeg] Subtitles can only be embedded in mp4 files')
+        if information['ext'] not in ['mp4', 'mkv']:
-            '-c:s', 'mov_text',
+        if information['ext'] == 'mp4':
-    _VALID_URL = r'(?P<url>(?P<host>https?://(?:[a-zA-Z]{2}\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?P<display_id>.+?)-(?P<id>[0-9]+)(?:-[a-z]+)?\.html)'
+    _VALID_URL = r'(?P<url>(?P<host>https?://(?:[a-zA-Z]{2}\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?P<display_id>.+)?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html)'
-        display_id = mobj.group('display_id')
+        display_id = mobj.group('display_id') or self._match_id(url)
-            'thumbnail': thumbnail,
+            'thumbnail': self._og_search_thumbnail(webpage, default=None),
-from ..utils import ExtractorError
+from ..utils import (
-            r'"vpid"\s*:\s*"([\da-z]{8})"', webpage, 'vpid', fatal=False, default=None)
+        thumbnail = self._og_search_thumbnail(webpage)
-            duration = player['duration']
+            title = self._og_search_title(webpage)
-        f4m_node = body.find(_x('smil:seq//smil:video')) or body.find(_x('smil:seq/smil:video'))
+        f4m_node = body.find(_x('smil:seq//smil:video'))
-                switch = body.find(_x('smil:par//smil:switch')) or body.find(_x('smil:par/smil:switch'))
+                switch = body.find(_x('smil:par//smil:switch'))
-                switch = body.find(_x('smil:seq//smil:switch')) or body.find(_x('smil:seq/smil:switch'))
+                switch = body.find(_x('smil:seq//smil:switch'))
-                    write_json_file(filtered_info_dict, infofn)
+                    write_json_file(self.filter_requested_info(info_dict), infofn)
-            info = json.loads('\n'.join(f))
+            info = self.filter_requested_info(json.loads('\n'.join(f)))
-    }
+    _VALID_URL = r'(?:http://)?(?:www\.)?3sat\.de/mediathek/(?:index\.php|mediathek\.php)?\?(?:(?:mode|display)=[^&]+&)*obj=(?P<id>[0-9]+)$'
-                    if not k in ['requested_formats', 'requested_subtitles'])
+                    if k not in ['requested_formats', 'requested_subtitles'])
-                    write_json_file(info_dict, infofn)
+                    write_json_file(filtered_info_dict, infofn)
-            r'(?s)Uploaded by:.*?<a href="/user/[^"]+">([^<]+)</a>',
+            r'(?s)Uploaded by:.*?<a href="/user/[^"]+"[^>]*>(.+?)</a>',
-        categories = re.findall(r'<a href="/cat/[^"]+">([^<]+)</a>', webpage)
+        categories = re.findall(r'<a href="/cat/[^"]+"[^>]*>([^<]+)</a>', webpage)
-        'url': 'http://veehd.com/video/4665804_Tell-No-One-Ne-le-dis-a-personne-2006-French-EngSoftSubs-Re-Up',
+        'url': 'http://veehd.com/video/2046729_2012-2009-DivX-Trailer',
-            'id': '4665804',
+            'id': '2046729',
-            'uploader_id': 'belial2549',
+            'title': '2012 (2009) DivX Trailer',
-            r'<div class="description_txt">(.*?)</div>', webpage, 'description', fatal=False)
+            r'class="(?:descr|description_txt)">(.*?)</div>',
-            r'(?s)UPLOADED BY.*?<a href="/user/[^"]+">([^<]+)</a>',
+            r'(?s)Uploaded by:.*?<a href="/user/[^"]+">([^<]+)</a>',
-            r'duration (\d+ min \d+ sec)', webpage, 'duration', fatal=False))
+            r'Runtime:\s*</span>\s*(\d+ min \d+ sec)',
-            r'<span id="dislike" class="n">([\d,\.]+)</span>', webpage, 'dislike count', fatal=False))
+        view_count = str_to_int(self._search_regex(
-            r'<h4>Comments \(<b>([\d,\.]+)</b>\)</h4>', webpage, 'comment count', fatal=False))
+            r"'Comments \(([\d,\.]+)\)'",
-        if format_spec == 'best' or format_spec is None:
+        if format_spec in ['best', 'worst', None]:
-            # for audio only urls, 'best' selects the best audio format
+                return audiovideo_formats[format_idx]
-            return available_formats[0]
+                return available_formats[format_idx]
-    _TEST = {
+    # Seems VeeHD videos have multiple copies on several servers, all of
-    }
+        'skip': 'Video deleted',
-        else:
+
-            'ext': 'mp4',
+import itertools
-    _TEST = {
+    _TESTS = [{
-            'id': '1074402',
+            'id': '1074402_part1',
-    }
+    }, {
-        }]
+        lq_durls = lq_doc.findall('./durl')
-                'url': hq_durl.find('./url').text,
+        hq_durls = hq_doc.findall('./durl') if hq_doc is not False else itertools.repeat(None)
-                    hq_durl.find('./size'), get_attr='text'),
+                    lq_durl.find('./size'), get_attr='text'),
-        self._sort_formats(formats)
+            i += 1
-            'thumbnail': thumbnail,
+            'title': title
-        webpage = self._download_webpage('http://www.nicovideo.jp/watch/' + video_id, video_id)
+        webpage, handle = self._download_webpage_handle(
-            ydl = YDL()
+            ydl = YDL({'format': 'best/bestvideo'})
-            ydl = YDL()
+            ydl = YDL({'format': 'best/bestvideo'})
-            return available_formats[-1]
+            audiovideo_formats = [
-            config_req = compat_urllib_request.Request('http://www.escapistmagazine.com/videos/'
+            config_req = compat_urllib_request.Request(
-
+                })
-        'md5': '38e53c9aad548f3ecf01ca7680b59b08',
+            'upload_date': '20071224',
-        thumbnail = xpath_text(video_info, './/thumbnail_url')
+
-        webpage_url = xpath_text(video_info, './/watch_url')
+        if not comment_count:
-        ret = {
+        return {
-        },
+        # File downloaded with and without credentials are different, so omit
-        }
+            title = self._og_search_title(webpage, default=None)
-    unified_strdate,
+    parse_iso8601,
-            'description': 'md5:',
+            'description': 'md5:689f066d74610b3b22e0f1739add0f58',
-        self._download_webpage('http://www.nicovideo.jp/watch/' + video_id, video_id)
+        # Get video webpage. We are not actually interested in it for normal
-        video_real_url = compat_urlparse.parse_qs(flv_info_webpage)['url'][0]
+        flv_info = compat_urlparse.parse_qs(flv_info_webpage)
-        extension = video_info.find('.//movie_type').text
+        title = xpath_text(video_info, './/title')
-        webpage_url = video_info.find('.//watch_url').text
+        thumbnail = xpath_text(video_info, './/thumbnail_url')
-        return {
+        ret = {
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-            [r'var\s+videoJa?son\s*=\s*({.+?});',
+            [r'videoJa?son\s*=\s*({.+})',
-    The type field determines the the type of the result.
+    The type field determines the type of the result.
-        Get the the login info as (username, password)
+        Get the login info as (username, password)
-                        self.report_warning('You have requested formats uncompatible for merge. '
+                        self.report_warning('You have requested formats incompatible for merge. '
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        }]
+        thumbnail = self._og_search_thumbnail(webpage, default=None)
-            'formats': formats,
+            'url': video_url,
-            'md5': 'bf5c2f95c4c917536e80936af7bc51e1',
+            'md5': '5e2c63385454c557f97c4c4131a393cd',
-        webpage = self._download_webpage(url, video_id)
+        embed_url = 'http://embed.yucache.net/{0:}'.format(video_id)
-        url = self._og_search_video_url(webpage)
+        video_url = self._og_search_video_url(webpage)
-            'url': url,
+            'url': video_url,
-            'ext': 'mp4',
+            'ext': 'webm',
-                expected=True)
+        for match in re.findall(r'<div class="yt-alert-message">([^<]+)</div>', page):
-        token = self._search_regex(r'xsrft":"(.*?)"', webpage, 'login token')
+        token = self._search_regex(r'xsrft[\s=:"\']+([^"\']+)', webpage, 'login token')
-        token = self._search_regex(r'xsrft":"(.*?)"', webpage, 'login token')
+        token = self._search_regex(r'xsrft[\s=:"\']+([^"\']+)', webpage, 'login token')
-__version__ = '2015.04.26'
+__version__ = '2015.04.28'
-        imsVideo = json.loads(self._search_regex(r'imsVideo\.play\(([^\)]+)\);', webpage, 'imsVideo'))
+        imsVideo = self._parse_json(
-)
+from ..compat import compat_urllib_request
-    parse_duration,
+    determine_ext,
-    _TEST = {
+    _TESTS = [{
-        'md5': 'ab3a706c681efca53f0a35f1415cf0d1',
+        'md5': 'c6793dbda81388f4264c1ba18684a74d',
-    }
+    }, {
-            webpage, 'config URL'))
+        webpage = self._download_webpage(url, video_id)
-        res = {
+        for q in ['lq', 'hq', 'hd']:
-            'description': description,
+            'description': self._og_search_description(webpage),
-        return res
+    compat_kwargs,
-    tf = tempfile.NamedTemporaryFile(**args)
+    tf = tempfile.NamedTemporaryFile(**compat_kwargs(args))
-    determine_ext,
+    float_or_none,
-    unified_strdate,
+    xpath_text,
-    _VALID_URL = r'http://live\.philharmoniedeparis\.fr/concert/(?P<id>\d+)(?:/|\.html)'
+    IE_DESC = 'Philharmonie de Paris'
-            'title': "Week-end Bach. Passion selon saint Jean. Akademie fÃ¼r alte Musik Berlin, Rias Kammerchor, RenÃ© Jacobs",
+            'ext': 'flv',
-        concert = playlist.find('.//concert')
+        concert = self._download_xml(
-            'title': concert.find('./titre').text,
+            'title': xpath_text(concert, './titre', 'title', fatal=True),
-
+        stream = fichiers.attrib['serveurstream']
-            })
+            info_dict['duration'] = float_or_none(fichier.get('timecodefin'))
-            })
+        date, hour = concert.get('date'), concert.get('heure')
-__version__ = '2015.04.17'
+__version__ = '2015.04.26'
-import sys
+    encodeArgument,
-        self._debug_cmd(cmd, subprocess_encoding)
+        cmd = [encodeArgument(a) for a in self._make_cmd(tmpfilename, info_dict)]
-import sys
+    encodeArgument,
-            '-o', encodeFilename(tmpfilename, True)]
+            '-o', tmpfilename]
-            subprocess_encoding = None
+        args = [encodeArgument(a) for a in args]
-        self._debug_cmd(args, subprocess_encoding, exe='rtmpdump')
+        self._debug_cmd(args, exe='rtmpdump')
-            retval = run_rtmpdump(basic_args + ['-e'] + [[], ['-k', '1']][retval == RD_FAILED])
+            args = basic_args + ['--resume']
-    def _debug_cmd(self, args, subprocess_encoding, exe=None):
+    def _debug_cmd(self, args, exe=None):
-            exe = os.path.basename(args[0])
+            exe = os.path.basename(str_args[0])
-            str_args = args
+def get_subprocess_encoding():
-    return s.encode(encoding, 'ignore')
+    # Pass '' directly to use Unicode APIs on Windows 2000 and up
-    IE_NAME = 'southpark.cc.com:espanol'
+    IE_NAME = 'southpark.cc.com:espaÃ±ol'
-        temp_thumbnail = prepend_extension(filename, 'thumb')
+        temp_thumbnail = filename + '.' + determine_ext(info['thumbnail'])
-from .mplayer import MplayerFD
+from .rtsp import RtspFD
-    'rtsp': MplayerFD,
+    'mms': RtspFD,
-class MplayerFD(FileDownloader):
+class RtspFD(FileDownloader):
-            self.report_error('mplayer exited with code %d' % retval)
+            self.report_error('%s exited with code %d' % (args[0], retval))
-            self.report_error('MMS or RTSP download detected but neither "mplayer" nor "mpv" could be run')
+            self.report_error('MMS or RTSP download detected but neither "mplayer" nor "mpv" could be run. Please install any.')
-)
+from ..utils import int_or_none
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-    _VALID_URL = r'http://instagram\.com/p/(?P<id>.*?)/'
+    _VALID_URL = r'https?://instagram\.com/p/(?P<id>[\da-zA-Z]+)'
-        'md5': '26ffa4bab6dbce1eee78bbc7021016cd',
+        'url': 'http://iptv.orf.at/stories/2275236/',
-            'id': '339775',
+            'id': '350612',
-            'duration': 84.729,
+            'title': 'Weitere Evakuierungen um Vulkan Calbuco',
-            'upload_date': '20150306',
+            'upload_date': '20150425',
-    _VALID_URL = r'https?://(www\.)?(?P<url>southpark\.cc\.com/(clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.cc\.com/(?:clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
-    _VALID_URL = r'https?://(www\.)?(?P<url>southpark\.de/(clips|alle-episoden)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>southpark\.de/(?:clips|alle-episoden)/(?P<id>.+?)(\?|#|$))'
-            feed_url + '?' + data, video_id,
+            info_url, video_id,
-            options = ['-i', temp_thumbnail, '-c', 'copy', '-map', '0', '-map', '1',
+            options = [
-            '-dumpstream', '-dumpfile', tmpfilename, url]
+        args = []
-            self.report_error('MMS or RTSP download detected but "%s" could not be run' % args[0])
+        if check_executable('mplayer', ['-h']):
-        'playlist_mincount': 9,
+        'playlist_mincount': 7,
-        return [self.url_result(item['url'], 'EllenTV') for item in playlist]
+        return [
-    _TESTS = [{
+    _TEST = {
-            'id': '0-ipq1gsai',
+            'id': '0_ipq1gsai',
-            'timestamp': 1428033600,
+            'description': 'md5:587e79fbbd0d73b148bc596d99ce48e6',
-    }]
+    }
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-            webpage, 'timestamp', fatal=False))
+        partner_id = self._search_regex(
-        }
+        kaltura_id = self._search_regex(
-                r'"file"\s*:\s*\'([^\']+)', webpage, 'video url')
+                [r'<source[^>]+src="([^"]+)"', r'"file"\s*:\s*\'([^\']+)'],
-    def _login(self, webpage_url, video_id):
+    def _login(self, webpage_url, display_id):
-        self._download_webpage(logout_url, video_id, 'Logging out')
+        self._download_webpage(request, display_id, 'Logging in')
-        start_page = self._download_webpage(webpage_url, video_id)
+        start_page = self._download_webpage(webpage_url, display_id)
-            login_res = self._login(webpage_url, video_id)
+            login_res = self._login(webpage_url, display_id)
-        xml_description = self._download_xml(xml_decription_url, video_id)
+        xml_description = self._download_xml(xml_decription_url, display_id)
-    _VALID_URL = r'https?://(?:www\.)?gdcvault\.com/play/(?P<id>\d+)/(?P<name>(\w|-)+)'
+    _VALID_URL = r'https?://(?:www\.)?gdcvault\.com/play/(?P<id>\d+)/(?P<name>(\w|-)+)?'
-from .common import PostProcessor
+from .ffmpeg import FFmpegPostProcessor
-class EmbedThumbnailPP(PostProcessor):
+class EmbedThumbnailPP(FFmpegPostProcessor):
-            cmd = ['ffmpeg', '-i', filename, '-i', temp_thumbnail, '-c', 'copy', '-map', '0', '-map', '1', '-metadata:s:v', 'title="Album cover"', '-metadata:s:v', 'comment="Cover (Front)"', temp_filename]
+            options = ['-i', temp_thumbnail, '-c', 'copy', '-map', '0', '-map', '1',
-                raise EmbedThumbnailPPError(msg)
+            self.run_ffmpeg(filename, temp_filename, options)
-        postprocessors.append({'key': 'AtomicParsley'})
+        postprocessors.append({'key': 'EmbedThumbnail'})
-from .atomicparsley import AtomicParsleyPP
+from .embedthumbnail import EmbedThumbnailPP
-    'AtomicParsleyPP',
+    'EmbedThumbnailPP',
-        return [], info
+# -*- coding: utf-8 -*-
-            video_play_path = streamdata.find('.//file').text
+            video_url = streamdata.find('./host').text
-                    'yourube-dl requires %s or above while your version is %s. '
+                    'youtube-dl requires %s or above while your version is %s. '
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-    _TEST = {
+    _TESTS = [{
-        'md5': '4b29a5eeec292cd5eca6388c7558db9e',
+        'md5': 'ccd52866b50bde63a6ef3b35016ba8c7',
-            'id': '19006',
+            'id': 'EjI00A3rZD0',
-            'upload_date': '20140718',
+            'title': "4 Plot Holes You Didn't Notice in Your Favorite Movies - The Spit Take",
-    }
+    }]
-            return self.url_result(youtube_url)
+            return self.url_result(youtube_url, 'Youtube')
-            [r'var\s+CK_vidSrc\s*=\s*"([^"]+)"', r'<video\s+src="([^"]+)"'], webpage, 'video URL')
+            [r'var\s+CK_vidSrc\s*=\s*"([^"]+)"', r'<video\s+src="([^"]+)"'],
-        description = self._og_search_description(webpage)
+        title = self._search_regex(
-        timestamp = self._html_search_regex(r'<time datetime="([^"]+)"', webpage, 'upload date', fatal=False)
+        description = self._search_regex(
-            r'<span class="views" id="viewCounts">([\d,\.]+) Views</span>', webpage, 'view count', fatal=False))
+            r'<span\s+class="?views"? id="?viewCounts"?>([\d,\.]+) Views</span>',
-            r'<span id="commentCounts">([\d,\.]+)</span>', webpage, 'comment count', fatal=False))
+            r'<span\s+id="?commentCounts"?>([\d,\.]+)</span>',
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                                           webpage, 'uploader', fatal=False, flags=re.DOTALL)
+                                           webpage, 'uploader', fatal=False, flags=re.DOTALL, default=None)
-                                              webpage, 'title')
+                                              webpage, 'title', default=None)
-        video_url = 'http://tcdn.ustream.tv/video/%s' % video_id
+        params = self._download_json(
-    IE_DESC = 'GorillaVid.in, daclips.in, movpod.in and fastvideo.in'
+    IE_DESC = 'GorillaVid.in, daclips.in, movpod.in, fastvideo.in and realvid.net'
-            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in))/
+            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in|realvid\.net))/
-            r'style="z-index: [0-9]+;">([^<]+)</span>',
+            [r'style="z-index: [0-9]+;">([^<]+)</span>', r'>Watch (.+) '],
-        token = self._search_regex(r'xsrft = \'(.*?)\'', webpage, 'login token')
+        token = self._search_regex(r'xsrft":"(.*?)"', webpage, 'login token')
-        token = self._search_regex(r'xsrft = \'(.*?)\'', webpage, 'login token')
+        token = self._search_regex(r'xsrft":"(.*?)"', webpage, 'login token')
-        token = self._search_regex(r'xsrft = \'(.*?)\'', webpage, 'login token')
+        token = self._search_regex(r'xsrft":"(.*?)"', webpage, 'login token')
-    unescapeHTML,
+    find_xpath_attr,
-        first_xml = self._download_webpage(first_url, video_id, 'Downloading first data webpage')
+        first_xml = self._download_xml(first_url, video_id, 'Downloading first data webpage')
-                                          first_xml, 'node_id')
+        node_id = find_xpath_attr(
-        second_xml = self._download_webpage(second_url, video_id, 'Downloading second data webpage')
+        second_xml = self._download_xml(second_url, video_id, 'Downloading second data webpage')
-        if mobj is None:
+        stream = second_xml.find('.//STREAM')
-        video_url = mobj.group(1) + unescapeHTML(mobj.group(2))
+        video_url = stream.attrib['APP'] + stream.attrib['FULLPATH']
-        webpage = self._download_webpage(webpage_url, video_id)
+        req = compat_urllib_request.Request(webpage_url)
-        secret = self._search_regex(r"photo_secret: '(\w+)'", webpage, 'secret')
+        secret = self._search_regex(r'secret"\s*:\s*"(\w+)"', webpage, 'secret')
-            '%s/%s' % (url, video_id), video_id)
+            '%s/%s' % (url, video_id), video_id,
-            video_id)
+            video_id, 'Downloading video JSON')
-
+
-
+        metadata = self._extract_metadata(
-        res = clip.get('bitrates', [])[0].get('label')
+        formats = []
-        metadata['protocol'] = 'm3u8'
+        metadata['formats'] = formats
-class YoutubeSearchIE(SearchInfoExtractor):
+class YoutubeSearchIE(SearchInfoExtractor, YoutubePlaylistIE):
-    _MAX_RESULTS = 1000
+    # there doesn't appear to be a real limit, for example if you search for
-        pagenum = 0
+        videos = []
-            data_json = self._download_webpage(
+        for pagenum in itertools.count(1):
-                note='Downloading page %s' % (pagenum + 1),
+                note='Downloading page %s' % pagenum,
-            api_response = data['data']
+            html_content = data[1]['body']['content']
-            if 'items' not in api_response:
+            if 'class="search-message' in html_content:
-            pagenum += 1
+            new_videos = self._ids_to_results(orderedSet(re.findall(
-                  for video_id in video_ids]
+        if len(videos) > n:
-    _API_URL = 'https://gdata.youtube.com/feeds/api/videos?q=%s&start-index=%i&max-results=50&v=2&alt=jsonc&orderby=published'
+    _EXTRA_QUERY_ARGS = {'search_sort': 'video_date_uploaded'}
-    def extract_videos_from_page(self, page):
+    @staticmethod
-        channel_page = self._download_webpage(url, channel_id)
+        channel_page = self._download_webpage(url, channel_id, 'Downloading page #1')
-        url = 'https://www.youtube.com/channel/%s/videos' % channel_id
+        url = self._TEMPLATE_URL % channel_id
-class YoutubeUserIE(InfoExtractor):
+class YoutubeUserIE(YoutubeChannelIE):
-    _GDATA_URL = 'https://gdata.youtube.com/feeds/api/users/%s/uploads?max-results=%d&start-index=%d&alt=json'
+    _TEMPLATE_URL = 'https://www.youtube.com/user/%s/videos'
-                (PAGE_SIZE * pagenum) + 1)
+                max((PAGE_SIZE * pagenum) + 1), 2)
-        info_dict = {
+        return {
-        return info_dict
+            # blip.tv embedded video
-            r'src="(http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?[^"]*\bid=.+?)"',
+            [
-from .screenwavemedia import CinemassacreIE, ScreenwaveMediaIE, TeamFourIE
+from .screenwavemedia import ScreenwaveMediaIE, TeamFourIE
-
+    @staticmethod
-            return self.url_result(mobj.group(1), 'BlipTV')
+        bliptv_url = BlipTVIE._extract_url(webpage)
-            webpage, 'player data URL')
+            webpage, 'player data URL', default=None)
-            thumbnail = poster[0]
+        thumbnail = poster[0] if poster else None
-        }
+        if len(entries) == 1:
-            webpage, 'description', flags=re.DOTALL)
+            webpage, 'description', flags=re.DOTALL, default=None)
-from ..utils import ExtractorError
+from ..utils import (
-        title = self._html_search_regex(r'<title>([^<]+)</title>', webpage, video_id)
+        if smuggled_data.get('force_title'):
-from ..utils import ExtractorError
+from ..compat import (
-            'uploader_id': result['owner']['uid'],
+            'duration': int_or_none(result.get('length')),
-)
+from ..compat import compat_urllib_request
-            % (self._API_KEY, video_id), video_id)['result']
+            % (self._API_KEY, video_id), video_id)
-            'uploader_id': info['owner']['uid'],
+            'title': result['title'],
-        info = json.loads(info_json)['result']
+        video_id = self._match_id(url)
-                    f['acodec'] = 'none'
+                    if not f.get('height'):
-                                ('mp4', 'm4a', 'm4p', 'm4b', 'm4r', 'm4v'),
+                                ('mp3', 'mp4', 'm4a', 'm4p', 'm4b', 'm4r', 'm4v'),
-            if info_dict['extractor'] == 'youtube' and FFmpegMergerPP(self).available:
+            if info_dict['extractor'] in ['youtube', 'ted'] and FFmpegMergerPP(self).available:
-                    resources.get('stream'), video_name, 'mp4', m3u8_id=format_id))
+                hls_formats = self._extract_m3u8_formats(
-    def _sort_formats(self, formats):
+    def _sort_formats(self, formats, field_preference=None):
-            r'(?ms)var TralbumData = {.*?id: (?P<id>\d+),?$',
+            r'(?ms)var TralbumData = .*?[{,]\s*id: (?P<id>\d+),?$',
-            ' avconv), for example -f bestvideo+bestaudio.'))
+        help='Video format code, see the "FORMAT SELECTION" for all the info')
-                    if not compatible_formats(requested_formats):
+                    if self.params.get('merge_output_format') is None and not compatible_formats(requested_formats):
-                        for f in info_dict['requested_formats']:
+                        for f in requested_formats:
-            req_format = 'best'
+            req_format_list = []
-                    info_dict['__files_to_merge'] = downloaded
+                    if os.path.exists(encodeFilename(filename)):
-        self.run_ffmpeg_multiple_files(info['__files_to_merge'], filename, args)
+        self.run_ffmpeg_multiple_files(info['__files_to_merge'], temp_filename, args)
-        title = self._og_search_title(webpage)
+        title = re.sub(r' - æçè§é¢$', '', self._og_search_title(webpage))
-                '_type': 'playlist',
+                '_type': 'multi_video',
-    if got_dict.get('_type') != 'playlist':
+    if got_dict.get('_type') not in ('playlist', 'multi_video'):
-                self.assertEqual(res_dict['_type'], 'playlist')
+                self.assertTrue(res_dict['_type'] in ['playlist', 'multi_video'])
-        if '>Video Not Found<' in webpage:
+        if any(p in webpage for p in ('>Video Not Found<', '>404 Error<')):
-from .megavideozeu import MegavideozeuIE
+from .megavideoz import MegaVideozIE
-class MegavideozeuIE(InfoExtractor):
+class MegaVideozIE(InfoExtractor):
-    unified_strdate,
+    float_or_none,
-            }
+    _VALID_URL = r'https?://(?:www\.)?megavideoz\.eu/video/(?P<id>[^/]+)(?:/(?P<display_id>[^/]+))?'
-
+    }
-        webpage = self._download_webpage(url, tmp_video_id)
+        mobj = re.match(self._VALID_URL, url)
-            r'var cnf = \'([^\']+)\'', webpage, 'config.php url')
+        webpage = self._download_webpage(url, display_id)
-	configpage = self._download_webpage(config_php, tmp_video_id)
+        config = self._download_xml(
-            r'<duration>([0-9\.]+)', configpage, 'duration', fatal=False))
+        video_url = xpath_text(config, './file', 'video url', fatal=True)
-            r'<duration>([0-9]+)', configpage, 'duration', fatal=False))
+            r'<duration>([0-9\.]+)', configpage, 'duration', fatal=False))
-                'Downloding %s video URL' % fmt[0],
+                'Downloading %s video URL' % fmt[0],
-            'md5': '4e9a0bda1e5eebd31ddcf86ec0b9b3c7',
+            'md5': '618fedb9c901fd086f6f093564ef8558',
-                    merger = FFmpegMergerPP(self, not self.params.get('keepvideo'))
+                    merger = FFmpegMergerPP(self)
-    def __init__(self, downloader=None, deletetempfiles=False):
+    def __init__(self, downloader=None):
-        return [], info
+        return info['__files_to_merge'], info
-        input_files = [filename] + [subtitles_filename(filename, lang, sub_info['ext']) for lang, sub_info in subtitles.items()]
+        sub_filenames = [subtitles_filename(filename, lang, sub_info['ext']) for lang, sub_info in subtitles.items()]
-        return [], information
+        return sub_filenames, information
-                return False, info
+                return [info['filepath']], info
-        def run_pp(params):
+        def run_pp(params, PP):
-            ydl.add_post_processor(SimplePP())
+            ydl.add_post_processor(PP())
-        run_pp({'keepvideo': True})
+        run_pp({'keepvideo': True}, SimplePP)
-        run_pp({'keepvideo': False})
+        run_pp({'keepvideo': False}, SimplePP)
-                keep_video, info = pp.run(info)
+                files_to_delete, info = pp.run(info)
-                try:
+            if files_to_delete and not self.params.get('keepvideo', False):
-                    self.report_warning('Unable to remove downloaded video file')
+                    try:
-        return True, info
+        return [], info
-        no preference), and the second of which is the updated information.
+        This method returns a tuple, the first element is a list of the files
-        return None, information  # by default, keep file and do nothing
+        return [], information  # by default, keep file and do nothing
-        return None, information  # by default, keep file and do nothing
+        return [], information
-            return True, information
+            return [], information
-        return False, information
+        return [path], information
-            return True, information
+            return [], information
-        return False, information
+        return [path], information
-            return True, information
+            return [], information
-            return True, information
+            return [], information
-        return True, information
+        return [], information
-            return True, info
+            return [], info
-        return True, info
+        return [], info
-        return True, info
+        return [], info
-        return True, info
+        return [], info
-            return True, info
+            return [], info
-        return True, info
+        return [], info
-            return True, info
+            return [], info
-        return True, info
+        return [], info
-            return True, info
+            return [], info
-        return True, info
+        return [], info
-        return True, info
+        return [], info
-            return True, info
+            return [], info
-            return False, info
+            return [], info
-            [^/]+/videos/
+            [^/]+/videos/(?:[^/]+/)?
-        (?:v|video_id)=(?P<id>[0-9]+)
+        (?:
-
+from ..utils import (
-    ]
+    _TEST = {
-        
+
-        
+
-            'view_count':  json['views']
+            'id': video_id,
-                        keep_video = keep_video_wish
+                keep_video, info = pp.run(info)
-            self._nopostoverwrites = True
+        if (new_path == path or
-                self.run_ffmpeg(path, new_path, acodec, more_opts)
+            self._downloader.to_screen('[' + self.basename + '] Destination: ' + new_path)
-        return self._nopostoverwrites, information
+        return False, information
-        uri = re.sub(r'(episode:[^.]+)(\.cc)?\.com', r'\1.cc.com', uri)
+        uri = re.sub(r'(episode:[^.]+)(\.cc)?\.com', r'\1.com', uri)
-            return
+            msgs = (compat_str(err['error_message']) for err in info['errors'])
-        return None
+    def _check_url(self, url, track_id, ext):
-            raise ExtractorError('Unable to extract track url')
+        if not self._check_url(song_url, track_id, 'mp3'):
-            'url': final_song_url,
+            'url': song_url,
-    _VALID_URL = r'https?://(player.vimple.ru/iframe|vimple.ru)/(?P<id>[a-f0-9]{10,})'
+    IE_DESC = 'Vimple - one-click video hosting'
-                'id': 'c0f6b1687dcd4000a97ebe70068039cf',
+                'id': 'c0f6b168-7dcd-4000-a97e-be70068039cf',
-        },
+        }, {
-            r'"(http://player.vimple.ru/flash/.+?)"', iframe, 'player url')
+        video_id = self._match_id(url)
-            player_url, video_id, note='Downloading swf player').read()
+        webpage = self._download_webpage(
-        player = zlib.decompress(player[8:])
+        playlist = self._parse_json(
-        xml_pieces = [piece[1:-1] for piece in xml_pieces]
+        title = playlist['title']
-        ]
+        formats = [{
-            'title': video.find('Title').text,
+            'title': title,
-            'webpage_url': video.find('Share').get('videoPageUrl'),
+    bug_reports_message,
-                                            'please report this issue on http://yt-dl.org/bug' % _name)
+            self._downloader.report_warning('unable to extract %s' % _name + bug_reports_message())
-            msg += ' Be sure to call youtube-dl with the --verbose flag and include its complete output.'
+            msg += bug_reports_message()
-__version__ = '2015.04.09'
+__version__ = '2015.04.17'
-            return self.url_result(query['url'][0])
+            real_url = query['url'][0]
-            'preference': '-1'
+            'preference': 2
-            'preference': 0
+            'preference': 1
-            'preference': 1
+            'preference': 0
-    }]
+    _TESTS = [
-    if unc_or_drive:
+    drive_or_unc, _ = os.path.splitdrive(s)
-        sanitized_path.insert(0, unc_or_drive + os.path.sep)
+    if drive_or_unc:
-            video_id)
+            display_id)
-                        full_url + '?hdcore=3.4.0', video_id, f4m_id=format_id))
+                        full_url + '?hdcore=3.4.0', display_id, f4m_id=format_id))
-                        full_url, video_id, 'mp4', m3u8_id=format_id))
+                        full_url, display_id, 'mp4', m3u8_id=format_id))
-    _VALID_URL = r'http://www\.srf\.ch/play(?:er)?/tv/[^/]+/video/(?P<display_id>[^?]+)\?id=(?P<id>[0-9a-f\-]{36})'
+    _VALID_URL = r'https?://(?:www\.srf\.ch/play(?:er)?/tv/[^/]+/video/(?P<display_id>[^?]+)\?id=|tp\.srgssr\.ch/p/flash\?urn=urn:srf:ais:video:)(?P<id>[0-9a-f\-]{36})'
-                'title': 'Ð¢Ð°Ð¹Ð½Ñ Ð¿ÐµÑÐµÐ²Ð°Ð»Ð° ÐÑÑÐ»Ð¾Ð²Ð° â¢ Ð¢Ð°Ð¸ÌÐ½Ð° Ð¿ÐµÑÐµÐ²Ð°Ð»Ð° ÐÑÑÐ»Ð¾Ð²Ð° 1 ÑÐµÑÐ¸Ñ 2 ÑÐ°ÑÑÑ',
+                'title': 'Ð¢Ð°Ð¹Ð½Ñ Ð¿ÐµÑÐµÐ²Ð°Ð»Ð° ÐÑÑÐ»Ð¾Ð²Ð° â¢ 1 ÑÐµÑÐ¸Ñ 2 ÑÐ°ÑÑÑ',
-            'title': 'Ð¢Ð°Ð¹Ð½Ñ Ð¿ÐµÑÐµÐ²Ð°Ð»Ð° ÐÑÑÐ»Ð¾Ð²Ð° â¢ Ð¢Ð°Ð¸ÌÐ½Ð° Ð¿ÐµÑÐµÐ²Ð°Ð»Ð° ÐÑÑÐ»Ð¾Ð²Ð° 1 ÑÐµÑÐ¸Ñ 2 ÑÐ°ÑÑÑ',
+            'title': 'Ð¢Ð°Ð¹Ð½Ñ Ð¿ÐµÑÐµÐ²Ð°Ð»Ð° ÐÑÑÐ»Ð¾Ð²Ð° â¢ 1 ÑÐµÑÐ¸Ñ 2 ÑÐ°ÑÑÑ',
-            'ext': 'mp4',
+            'ext': 'flv',
-                        'ext': 'mp4' if original_ext == 'm3u8' else original_ext,
+                        'ext': original_ext,
-            })
+            for url_node in item.findall('url'):
-    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True):
+    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None):
-        content = self._webpage_read_content(urlh, url_or_request, video_id, note, errnote, fatal)
+        content = self._webpage_read_content(urlh, url_or_request, video_id, note, errnote, fatal, encoding=encoding)
-            webpage_bytes = prefix + webpage_bytes
+    @staticmethod
-    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5):
+    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5, encoding=None):
-                res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal)
+                res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal, encoding=encoding)
-                      transform_source=None, fatal=True):
+                      transform_source=None, fatal=True, encoding=None):
-            url_or_request, video_id, note, errnote, fatal=fatal)
+            url_or_request, video_id, note, errnote, fatal=fatal, encoding=encoding)
-                       fatal=True):
+                       fatal=True, encoding=None):
-            url_or_request, video_id, note, errnote, fatal=fatal)
+            url_or_request, video_id, note, errnote, fatal=fatal,
-            'description': 'md5:242c97c2847e0495583b7b13764f7106',
+            'description': 'md5:4348ff1dd24036906baa7b6f973f8d30',
-            errnote='Unable to get song detail info')
+            errnote='Unable to get song detail info', encoding='gbk')
-            'publish time').replace('-', '')
+            'publish time', default=None)
-            r"singer:\s*'([^']+)", detail_info_page, 'singer')
+            r"singer:\s*'([^']+)", detail_info_page, 'singer', default=None)
-                cls.qq_song_url(song_mid), 'QQMusic', song_mid))
+                'http://y.qq.com/#type=song&mid=' + song_mid, 'QQMusic',
-    QQMusicSingerIE
+    QQMusicSingerIE,
-from ..utils import strip_jsonp
+from ..utils import (
-class QQMusicSingerIE(InfoExtractor):
+class QQPlaylistBaseIE(InfoExtractor):
-        entries = []
+            self.qq_static_url('singer', mid), mid, 'Download singer page')
-                'http://y.qq.com/#type=song&mid=' + song_mid, 'QQMusic', song_mid))
+        entries = self.get_entries_from_page(singer_page)
-                req, 'Donwload singer description XML')
+                req, mid, 'Donwload singer description XML')
-from .qqmusic import QQMusicIE
+from .qqmusic import (
-            mid, note='Download sont detail info',
+            mid, note='Download song detail info',
-
+    # Reference: m_r_GetRUin() in top_player.js
-            })
+            if determine_ext(video_url) == 'smil':
-from ..utils import js_to_json
+from ..utils import (
-    _VALID_URL = r'(?:https?:)?//video\.udn\.com/embed/news/(?P<id>\d+)'
+    _VALID_URL = r'https?://video\.udn\.com/(?:embed|play)/news/(?P<id>\d+)'
-        'url': '//video.udn.com/embed/news/300040',
+        'url': 'https://video.udn.com/embed/news/300040',
-        } for video_type, api_url in video_urls.items()]
+        } for video_type, api_url in video_urls.items() if api_url]
-        return filter(None, [cls._build_brighcove_url(m) for m in matches])
+        return list(filter(None, [cls._build_brighcove_url(m) for m in matches]))
-        (?:www\.spike\.com/(?:video-clips|(?:full-)?episodes)/.+|
+        (?:www\.spike\.com/(?:video-(?:clips|playlists)|(?:full-)?episodes)/.+|
-        preload = max([(len(p), p) for p in preloads])[1]
+        if preloads:
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'description': self._og_search_description(webpage, default=None),
-        object_doc = xml.etree.ElementTree.fromstring(object_str.encode('utf-8'))
+        try:
-        return [cls._build_brighcove_url(m) for m in matches]
+        return filter(None, [cls._build_brighcove_url(m) for m in matches])
-            ).+?</object>''',
+            ).+?>\s*</object>''',
-        'md5': '48de02137d0739c15b440a224ad364b9',
+        # "type=video" in flashvars
-            'id': '179734',
+            'id': '88912',
-            'duration': 354,
+            'title': 'ãSKYãå­å¹ é æ­¦æ­åVSå¹³æ åé¢éªå£«å¤§æFEATæé é­æå­å¹ç» å­å¹',
-            r'flashvars="type=sina&amp;(.+?)&amp;',
+            r'flashvars="type=(?:sina|video)&amp;(.+?)&amp;',
-            'md5': 'de06b4c90b042c128395a88f0384817e',
+            'md5': 'fd2060e988c326991037b9aff9df21a6',
-                'id': '300040',
+                'id': '300346',
-                'title': 'çç©èå¸«ç·è®å¥³ å¨æ ¡æº"åèªå·±"',
+                'title': 'ä¸­ä¸ä¸­ç·å¸«è®æ§ å¨æ ¡å¸«çåæº',
-                re.search(r'SBN\.VideoLinkset\.ooyala\([\'"](?P<ec>.{32})[\'"]\)', webpage))
+                re.search(r'SBN\.VideoLinkset\.ooyala\([\'"](?P<ec>.{32})[\'"]\)', webpage) or
-        os.rename(encodeFilename(temp_filename), encodeFilename(filename))
+        # for formats that don't support thumbnails (like 3gp) AtomicParsley
-                for video_id, video_title in videos]
+                for video_id, video_title in self.extract_videos_from_page(channel_page)]
-                for video_id, video_title in ids_in_page:
+                for video_id, video_title in self.extract_videos_from_page(content_html):
-        return ids_in_page
+        titles_in_page = []
-            video_ids = self.extract_videos_from_page(channel_page)
+            videos = self.extract_videos_from_page(channel_page)
-                for video_id in video_ids]
+                self.url_result(
-                for video_id in ids_in_page:
+                for video_id, video_title in ids_in_page:
-                        video_id, 'Youtube', video_id=video_id)
+                        video_id, 'Youtube', video_id=video_id,
-    def url_result(url, ie=None, video_id=None):
+    def url_result(url, ie=None, video_id=None, video_title=None):
-    {
+    }, {
-    ]
+    }]
-                entries.append(self.url_result(playwire_url, 'Playwire'))
+                entries.append(self.url_result(self._proto_relative_url(
-    _TEST = {
+    _TESTS = [{
-    }
+    },
-                a.decode(preferredencoding(), 'replace') for a in command_line_conf]
+        def compat_conf(conf):
-            system_conf = _readOptions('/etc/youtube-dl.conf')
+            system_conf = compat_conf(_readOptions('/etc/youtube-dl.conf'))
-                user_conf = _readUserConf()
+                user_conf = compat_conf(_readUserConf())
-            'title': "Fox & Friends Says Protecting Atheists From Discrimination Is Anti-Christian!",
+            'title': 'Fox & Friends Says Protecting Atheists From Discrimination Is Anti-Christian!',
-from .crooksandliars import CrooksAndLiarsIE, CrooksAndLiarsArticleIE
+from .crooksandliars import CrooksAndLiarsIE
-    mimetype2ext,
+    int_or_none,
-
+    _VALID_URL = r'https?://embed\.crooksandliars\.com/(?:embed|v)/(?P<id>[A-Za-z0-9]+)'
-            'id': 'https://embed.crooksandliars.com/embed/8RUoRhRi',
+            'id': '8RUoRhRi',
-            'description': "Fox News, Fox & Friends Weekend, April 4, 2015. Read more... http://crooksandliars.com/2015/04/fox-friends-says-protecting-atheists",
+            'description': 'md5:e1a46ad1650e3a5ec7196d432799127f',
-            'uploader': "Heather",
+            'upload_date': '20150405',
-        manifest = json.loads(self._html_search_regex(r'var manifest = ({.*?})\n', webpage, 'manifest JSON'))
+        webpage = self._download_webpage(
-            })
+        quality = qualities(('webm_low', 'mp4_low', 'webm_high', 'mp4_high'))
-            'timestamp': int(manifest['created']),
+            'description': manifest.get('description'),
-        }
+    determine_ext,
-                    if label != 'Auto':
+                    if label == 'Auto':
-                            'url': '%s/%s' % (base_url, stream.get('url')),
+                            'url': stream_url,
-                            'resolution': label,
+                            'tbr': bitrate,
-)
+from ..compat import compat_str
-            } for f in talk_info['resources']['rtmp']]
+
-            iframe_page = self._download_webpage(
+            webpage = self._download_webpage(
-            relinker_url = self._extract_relinker_url(iframe_page)
+            relinker_url = self._extract_relinker_url(webpage)
-                webpage, 'title', default=None) or self._og_search_title(webpage)
+            title = (self._search_regex(
-                'item-date', webpage, 'upload date'))
+                'item-date', webpage, 'upload date', default=None))
-    _VALID_URL = r'(?P<url>http://(?:.+?\.)?(?:rai\.it|rai\.tv|rainews\.it)/dl/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html)'
+    _VALID_URL = r'(?P<url>(?P<host>http://(?:.+?\.)?(?:rai\.it|rai\.tv|rainews\.it))/dl/.+?-(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})(?:-.+?)?\.html)'
-        media = self._download_json('%s?json' % mobj.group('url'), video_id, 'Downloading video JSON')
+        relinker_url = self._extract_relinker_url(webpage)
-        upload_date = unified_strdate(media.get('date'))
+        if not relinker_url:
-        formats = []
+        relinker = self._download_json(
-            formats.append({
+        media_url = relinker['video'][0]
-            })
+                'format_id': ct,
-        subtitles = self.extract_subtitles(video_id, url)
+        subtitles = self.extract_subtitles(video_id, webpage)
-        webpage = self._download_webpage(url, video_id)
+    def _get_subtitles(self, video_id, webpage):
-                format_id = m_format.group(1)
+            if filed['type'] == 'hls':
-                else None)
+                m_format = re.search(r'(\d+(k|p))\.mp4', filed['url'])
-            })
+                formats.append({
-from ..utils import qualities
+from ..utils import (
-            r'Y\.Ginger\.Module\.Player(?:;var\s*player\s*=\s*new\s*m)?\((\{.*?\})\);', embed, 'player data'), video_id)
+        preloads = re.findall(r'"preload":\s*"([^"]+)"', webpage)
-            base64.b64decode(player_data['preload'].encode('ascii')).decode('utf-8'), video_id)
+            base64.b64decode(preload.encode('ascii')).decode('utf-8'), video_id)
-            webpage, 'vine data'))
+        data = self._parse_json(
-    _VALID_URL = r'https?://(?:www\.)?vine\.co/v/(?P<id>\w+)'
+    _VALID_URL = r'https?://(?:www\.)?vine\.co/(?:v|oembed)/(?P<id>\w+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r'window\.POST_DATA = { %s: ({.+?}) }' % video_id, webpage, 'vine data'))
+            r'window\.POST_DATA = { %s: ({.+?}) };\s*</script>' % video_id,
-        } for f in data['videoUrls'] if f.get('rate')]
+        } for f in data['videoUrls']]
-        webpage = self._download_webpage(url, video_id)
+
-__version__ = '2015.04.03'
+__version__ = '2015.04.09'
-    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/user/(?P<user>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/(?:old/)?user/(?P<user>[^/]+)'
-                    vbr = int(attr['system-bitrate']) // 1000
+                    width = int_or_none(attr.get('width'))
-                    vbr = int(attr['system-bitrate']) // 1000
+                    vbr = int_or_none(attr.get('system-bitrate'), 1000)
-            'duration': info['duration'] // 1000,
+            'duration': int_or_none(info.get('duration'), 1000),
-        # from http://www.cnet.com/videos/tesla-model-s-a-second-step-towards-a-cleaner-motoring-future/
+        # from http://www.cnet.com/videos/tesla-model-s-a-second-step-towards-a-cleaner-motoring-future/
-        f4m_node = body.find(_x('smil:seq//smil:video'))
+        f4m_node = body.find(_x('smil:seq//smil:video')) or body.find(_x('smil:seq/smil:video'))
-                switch = body.find(_x('smil:par//smil:switch'))
+                switch = body.find(_x('smil:par//smil:switch')) or body.find(_x('smil:par/smil:switch'))
-                switch = body.find(_x('smil:seq//smil:switch'))
+                switch = body.find(_x('smil:seq//smil:switch')) or body.find(_x('smil:seq/smil:switch'))
-from ..utils import PostProcessingError
+import os
-            self._downloader.report_warning('Cannot update utime of file')
+        self.try_utime(out_path, oldest_mtime, oldest_mtime)
-                self._downloader.report_warning('Cannot update utime of audio file')
+            self.try_utime(
-                url_infer_protocol(url, mobj.group('url')), 'UDNEmbed')
+                compat_urlparse.urljoin(url, mobj.group('url')), 'UDNEmbed')
-)
+from ..utils import js_to_json
-                url_infer_protocol(url, api_url), video_id,
+                compat_urlparse.urljoin(url, api_url), video_id,
-            switch = body.find(_x('.//smil:switch'))
+            switch = body.find(_x('smil:switch'))
-    _TEST = {
+    _TESTS = [{
-    }
+        # from http://www.cnet.com/videos/tesla-model-s-a-second-step-towards-a-cleaner-motoring-future/
-            switch = body.find(_x('smil:switch'))
+            switch = body.find(_x('.//smil:switch'))
-    _VALID_URL = r'https?://new\.livestream\.com/.*?/(?P<event_name>.*?)(/videos/(?P<id>[0-9]+)(?:/player)?)?/?(?:$|[?#])'
+    _VALID_URL = r'https?://(?:new\.)?livestream\.com/.*?/(?P<event_name>.*?)(/videos/(?P<id>[0-9]+)(?:/player)?)?/?(?:$|[?#])'
-        os.utime(encodeFilename(out_path), (oldest_mtime, oldest_mtime))
+        try:
-                existing_format.update(f)
+        for a in dash_doc.findall('.//{urn:mpeg:DASH:schema:MPD:2011}AdaptationSet'):
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'^http://(?:\w+\.)?add-anime\.net/watch_video\.php\?(?:.*?)v=(?P<id>[\w_]+)(?:.*)'
+    _VALID_URL = r'http://(?:\w+\.)?add-anime\.net/(?:watch_video\.php\?(?:.*?)v=|video/)(?P<id>[\w_]+)'
-        for format_id in ('normal', 'hq'):
+        for format_id in FORMATS:
-        (?P<path>.+?/(?P<title>[^/]+?)(?:\.(?:cnn|hln|ktvk)(?:-ap)?|(?=&)))'''
+        (?P<path>.+?/(?P<title>[^/]+?)(?:\.(?:[a-z]{3,5})(?:-ap)?|(?=&)))'''
-from .common import InfoExtractor
+from .common import InfoExtractor
-    
+    _VALID_URL = r'https?://(?:(?:www|[a-z]{2})\.)?spankbang\.com/(?P<id>[\da-z]+)/video'
-            "url": "http://spankbang.com/_3vvn/IjE0MjgyNjY5MTcuMzUi.IaGrcF-vDrvktMhjd-1fWixiCzU/title/720p__mp4"
+        'url': 'http://spankbang.com/3vvn/video/fantasy+solo',
-            })
+        stream_key = self._html_search_regex(
-            "formats": formats
+            'id': video_id,
-            'thumbnail': '//crooksandliars.com/files/mediaposters/2015/04/31235.jpg?ts=1428207050',
+            'thumbnail': 'https://crooksandliars.com/files/mediaposters/2015/04/31235.jpg?ts=1428207050',
-            'thumbnail': manifest['poster'],
+            'thumbnail': self._proto_relative_url(manifest['poster']),
-            "url": "re:http://spankbang.com/_3vvn/IjE0MjgyNjY5MTcuMzUi.IaGrcF-vDrvktMhjd-1fWixiCzU/title/720p__mp4"
+            "url": "http://spankbang.com/_3vvn/IjE0MjgyNjY5MTcuMzUi.IaGrcF-vDrvktMhjd-1fWixiCzU/title/720p__mp4"
-                "url": "http://spankbang.com/_{}/{}/title/{}__mp4".format(video_id, stream_key, q)
+                "url": "http://spankbang.com/_{0}/{1}/title/{2}__mp4".format(video_id, stream_key, q)
-                        args['url_encoded_fmt_stream_map'] == ''):
+                if not args.get('url_encoded_fmt_stream_map'):
-        }
+        },
-                if 'url_encoded_fmt_stream_map' not in args:
+                if ('url_encoded_fmt_stream_map' not in args or
-        'md5': 'e4af06f3bf0d5f471921a18db5764642',
+        'url': 'http://www.ellentv.com/videos/0-ipq1gsai/',
-            'id': '0-7jqrsr18',
+            'id': '0-ipq1gsai',
-            'upload_date': '20140801',
+            'title': 'Fast Fingers of Fate',
-        video_url = self._html_search_meta('VideoURL', webpage, 'url')
+
-            webpage, 'timestamp'))
+            webpage, 'timestamp', fatal=False))
-        title = self._search_regex(r'<b>([^"]+)</b>', webpage, 'title')
+        title = self._og_search_title(webpage)
-            'thumbnail': thumb,
+            'thumbnail': thumbnail,
-        'md5': '9dcfe344732808dbfcc901537973c922',
+        'url': 'http://www.3sat.de/mediathek/index.php?mode=play&obj=45918',
-            'id': '36983',
+            'id': '45918',
-            'description': 'md5:cc4424b18b75ae9948b13929a0814033',
+            'title': 'Waidmannsheil',
-            'upload_date': '20130622'
+            'upload_date': '20140913'
-from ..utils import unified_strdate
+from ..utils import (
-        'md5': '4a7e1dd65cdb2643500a3f753c942f25',
+        'url': 'https://www.dr.dk/tv/se/boern/ultra/panisk-paske/panisk-paske-5',
-            'id': 'partiets-mand-7-8',
+            'id': 'panisk-paske-5',
-            'duration': 1299.040,
+            'title': 'Panisk PÃ¥ske (5)',
-            'ext': 'mp4',
+            'ext': 'flv',
-                'format_id': '-'.join(filter(None, [f4m_id, 'f4m-%d' % (i if tbr is None else tbr)])),
+                'format_id': '-'.join(filter(None, [f4m_id, compat_str(i if tbr is None else tbr)])),
-            if video_url.endswith('.f4m'):
+            ext = determine_ext(video_url)
-                formats.extend(self._extract_m3u8_formats(video_url, video_id, 'mp4'))
+                    formats.extend(self._extract_f4m_formats(f4m_url, video_id, 1, format_id))
-            'duration': parse_duration(info['duree']),
+            'duration': float_or_none(info.get('real_duration'), 1000) or parse_duration(info['duree']),
-        'md5': '5ad6dec1ffb2a3fbcb20cc4b744be8d6',
+        'url': 'http://culturebox.francetvinfo.fr/live/musique/musique-classique/le-livre-vermeil-de-montserrat-a-la-cathedrale-delne-214511',
-            'timestamp': 1409317200,
+            'id': 'EV_50111',
-                'tbr': fmt['bitrate'],
+                'width': int_or_none(fmt.get('width')),
-            'view_count': internal_meta_json['views'],
+            'thumbnail': internal_meta_json.get('imageUrl'),
-    _VALID_URL = r'^http://tv\.aftonbladet\.se/webbtv.+?(?P<video_id>article[0-9]+)\.ab(?:$|[?#])'
+    _VALID_URL = r'http://tv\.aftonbladet\.se/webbtv.+?(?P<id>article[0-9]+)\.ab(?:$|[?#])'
-        help='Specify JSON file containing the video information (created with the "--write-json" option)')
+        help='JSON file containing the video information (created with the "--write-info-json" option)')
-        help='[deprecated; use  -o "%(autonumber)s-%(title)s.%(ext)s" ] Number of downloaded files starting from 00000')
+        help='[deprecated; use  -o "%(autonumber)s-%(title)s.%(ext)s" ] Number downloaded files starting from 00000')
-              '%(extractor)s for the provider (YouTube, metacafe, etc), '
+              '%(extractor)s for the provider (youtube, metacafe, etc), '
-        help='Specify highest quality format to download')
+        help='Highest quality format to download')
-        help='Specify subtitle format preference, for example: "srt" or "ass/srt/best"')
+        help='Subtitle format, accepts formats preference, for example: "srt" or "ass/srt/best"')
-            'height': height,
+            'height': int(height),
-            [sys.executable, 'youtube_dl/__main__.py', 'Ã¤', '--version'],
+            [sys.executable, 'youtube_dl/__main__.py', encodeArgument('Ã¤'), '--version'],
-from ..compat import compat_urllib_parse
+from ..utils import (
-    _VALID_URL = r'^((?:http://)?(?:www\.)?pornovoisines.com)/showvideo/(\d+)/([^/]+)'
+    _VALID_URL = r'http://(?:www\.)?pornovoisines\.com/showvideo/(?P<id>\d+)/(?P<display_id>[^/]+)'
-    VIDEO_URL_TEMPLATE = 'http://stream%d.pornovoisines.com' \
+    _VIDEO_URL_TEMPLATE = 'http://stream%d.pornovoisines.com' \
-    SERVER_NUMBERS = (1, 2)
+    _SERVER_NUMBERS = (1, 2)
-            'title': "Recherche appartement",
+            'title': 'Recherche appartement',
-            'uploader': "JMTV",
+            'view_count': int,
-            'comment_count': int,
+            'categories': ['DÃ©butante', 'ScÃ©nario', 'Sodomie'],
-        return map(lambda s: s.strip(), str.split(','))
+    def build_video_url(cls, num):
-            flags=re.DOTALL))
+        video_id = mobj.group('id')
-            "comment count"))
+            r'<article id="descriptif">(.+?)</article>',
-            'id': id,
+            'id': video_id,
-            'url': url,
+            'url': video_url,
-            'uploader': uploader,
+            'upload_date': upload_date,
-            'comment_count': comment_count,
+            'categories': categories,
-    date_str = re.sub(r' ?(\+|-)[0-9]{2}:?[0-9]{2}$', '', date_str)
+    if not re.match(r'^[0-9]{1,2}-[0-9]{1,2}-[0-9]{4}$', date_str):
-# coding: utf-8
+
-import time
+from ..utils import (
-    _TESTS = [{
+    _VALID_URL = r'https?://(?:www\.)?gamersyde\.com/hqstream_(?P<display_id>[\da-z_]+)-(?P<id>\d+)_[a-z]{2}\.html'
-        return json
+        mobj = re.match(self._VALID_URL, url)
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id)
-        playlist = data[0]
+        playlist = self._parse_json(
-                'format_id': playlistEntry['label']
+        for source in playlist['sources']:
-            formats.append(format)
+        title = remove_start(playlist['title'], '%s - ' % video_id)
-            'formats': formats,
+            'thumbnail': thumbnail,
-            }
+            'formats': formats,
-    res = re.sub(r',(\s*\])', lambda m: m.group(1), res)
+    res = re.sub(r',(\s*[\]}])', lambda m: m.group(1), res)
-        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/default/videos/%s.png' % video_id
+        png_url = 'http://www.rtve.es/ztnr/movil/thumbnail/%s/videos/%s.png' % (self._manager, video_id)
-# coding: utf-8
+import re
-    str_to_int
+    unified_strdate,
-            'description': 'Chaartaar - Ashoobam',
+            'upload_date': '20150215',
-        prefix = 'https://media.rdjavan.com/media/music_video/'
+        video_id = self._match_id(url)
-            r'RJ\.video1080p = \'([^\']+)\'', webpage, '1080 video url', fatal= False)
+        webpage = self._download_webpage(url, video_id)
-            urls.append({'url': prefix + video_url_1080, 'format': '1080p'})
+        formats = [{
-        dislikes = dislikes.replace(',', '')
+        upload_date = unified_strdate(self._search_regex(
-        plays = plays.replace(',', '')
+        view_count = str_to_int(self._search_regex(
-            'id': display_id,
+            'id': video_id,
-        }
+            'upload_date': upload_date,
-import json
+
-    {
+    }, {
-        duration = time.strptime(durationString, "%M minutes %S seconds")
+        if (durationString.find("minutes") > -1):
-
+        json = json.replace('file: "', '"file": "')
-        data = json.loads(filesJson)
+        data = self._parse_json(filesJson,video_id, transform_source=self._fixJsonSyntax)
-    _TEST = {
+    },
-            opts.outtmpl = opts.outtmpl.decode(preferredencoding())
+    preferredencoding,
-                a.decode('utf-8', 'replace') for a in command_line_conf]
+                a.decode(preferredencoding(), 'replace') for a in command_line_conf]
-                'title': 'Staffel 2, Episode 18 - JahresrÃ¼ckblick',
+                'title': 'Episode 18 - Staffel 2',
-            r'\bbutton-favorite\b.+m-ajax-toggle-count="([^"]+)"',
+            r'\bbutton-favorite\b[^>]+m-ajax-toggle-count="([^"]+)"',
-    _VALID_URL = r'https?://www\.bloomberg\.com/video/(?P<id>.+?)\.html'
+    _VALID_URL = r'https?://www\.bloomberg\.com/news/videos/[^/]+/(?P<id>[^/?#]+)'
-        'url': 'http://www.bloomberg.com/video/shah-s-presentation-on-foreign-exchange-strategies-qurhIVlJSB6hzkVi229d8g.html',
+        'url': 'http://www.bloomberg.com/news/videos/b/aaeae121-5949-481e-a1ce-4562db6f5df2',
-            'description': 'md5:0681e0d30dcdfc6abf34594961d8ea88',
+            'description': 'md5:a8ba0302912d03d246979735c17d2761',
-            'f4m url')
+        video_id = self._search_regex(r'"bmmrId":"(.+?)"', webpage, 'id')
-            'id': name.split('-')[-1],
+            'id': video_id,
-            'formats': self._extract_f4m_formats(f4m_url, name),
+            'formats': formats,
-        if not self.probe_executable:
+        if not self.probe_available:
-        
+
-__version__ = '2015.03.28'
+__version__ = '2015.04.03'
-            if len(https_handler._context.get_ca_certs()) == 0:
+            ctx = https_handler._context
-from .miomio import MioMioIE
+from .miomio import MioMioIE
-from .miomio_tv import MiomioTvIE
+from .miomio import MioMioIE
-class MiomioTvIE(InfoExtractor):
+class MioMioIE(InfoExtractor):
-    _TEST = {
+    _TESTS = [{
-    }
+            'ext': 'flv',
-        xml_config = self._search_regex(r'flashvars="type=sina&amp;(.*?)&amp;cid=', webpage, 'xml config')
+        title = self._html_search_meta(
-        self._request_webpage("http://www.miomio.tv/mioplayer/mioplayerconfigfiles/xml.php?id={0}&r=cc{1}".format(id, 945), video_id)
+        self._request_webpage(
-        vidconfig = self._download_xml(xml_url, video_id)
+        vid_config = self._download_xml(
-        file_els = vidconfig.findall('.//durl')
+        http_headers = {
-
+        for f in vid_config.findall('./durl'):
-                'url': segment_url
+                'duration': int_or_none(xpath_text(f, 'length', 'duration'), 1000),
-            }
+            segment = entries[0]
-            'http_headers': http_headers
+            'title': title,
-)
+from ..compat import compat_str
-    str_to_int,
+    parse_iso8601,
-    _VALID_URL = r'https?://(?:www\.)?play\.fm/[^?#]*(?P<upload_date>[0-9]{8})(?P<id>[0-9]{6})(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?play\.fm/(?P<slug>(?:[^/]+/)+(?P<id>[^/]+))/?(?:$|[?#])'
-        'url': 'http://www.play.fm/recording/leipzigelectronicmusicbatofarparis_fr20140712137220',
+        'url': 'https://www.play.fm/dan-drastic/sven-tasnadi-leipzig-electronic-music-batofar-paris-fr-2014-07-12',
-            'id': '137220',
+            'id': '71276',
-            'upload_date': '20140712',
+            'title': 'Sven Tasnadi - LEIPZIG ELECTRONIC MUSIC @ Batofar (Paris,FR) - 2014-07-12',
-        rec_doc = self._download_xml(req, video_id)
+        slug = mobj.group('slug')
-                error_node.text, rec_doc.find('./status').text))
+        recordings = self._download_json(
-        thumbnail = recording.find('./image').text
+        error = recordings.get('error')
-        )
+        audio_url = recordings['audio']
-            'filesize': int_or_none(recording.find('./size').text),
+            'url': audio_url,
-            'comment_count': comment_count,
+            'description': description,
-            'thumbnail': thumbnail,
+            'timestamp': timestamp,
-    _TEST ={
+    _VALID_URL = r'https?://(?:www\.)?video\.varzesh3\.com/(?:[^/]+/)+(?P<id>[^/]+)/?'
-            'thumbnail': 'http://video.varzesh3.com/wp-content/uploads/230315_saves_week26.jpg',
+            'thumbnail': 're:^https?://.*\.jpg$',
-        webpage = self._download_webpage(url, video_id)
+        display_id = self._match_id(url)
-            raise ExtractorError('URL has no videos or there is a problem.')
+        title = self._og_search_title(webpage)
-        thumbnail = self._html_search_regex(r'link[^>]+rel="image_src"[^>]+href="([^"]+)"', webpage, 'thumbnail')
+        video_id = self._search_regex(
-            'id': vid_id,
+            'url': video_url,
-        request.add_header('Cookie', 'ff=off')
+        request.add_header('Cookie', 'family_filter=off; ff=off')
-                                            'Downloading embed page')
+        embed_request = self._build_request(embed_url)
-        # NBC Sports vplayer embeds
+        # NBC Sports vplayer embed
-            'url': 'http://bbs.clutchfans.net/showthread.php?t=244180',
+            'url': 'http://www.riderfans.com/forum/showthread.php?121827-Freeman&s=e98fa1ea6dc08e886b1678d35212494a',
-                'ext': 'flv'
+                'id': 'ln7x1qSThw4k',
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'https?://vplayer\.nbcsports\.com/(?:[^/]+/)+(?P<id>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://vplayer\.nbcsports\.com/(?:[^/]+/)+(?P<id>[0-9a-zA-Z_]+)'
-                if n.attrib.get('title') == 'Geographic Restriction')
+                if n.attrib.get('title') == 'Geographic Restriction' or n.attrib.get('title') == 'Expired')
-    NBCSportsIE,
+    NBCSportsIE,
-class NBCSportsIE(InfoExtractor):
+class NBCSportsVPlayerIE(InfoExtractor):
-            return self.url_result(iframe_m.group('url'), 'NBCSports')
+        nbc_sports_url = NBCSportsVPlayerIE._extract_url(webpage)
-    }
+    _VALID_URL = r'''(?x)https?://(?:www\.)?phoenix\.de/content/
-    _VALID_URL = r'https?://(?:www\.)?soundcloud\.com/(?P<uploader>[\w\d-]+)/sets/(?P<slug_title>[\w\d-]+)(?:/(?P<token>[^?/]+))?'
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?soundcloud\.com/(?P<uploader>[\w\d-]+)/sets/(?P<slug_title>[\w\d-]+)(?:/(?P<token>[^?/]+))?'
-    _VALID_URL = r'https?://(www\.)?soundcloud\.com/(?P<user>[^/]+)/?((?P<rsrc>tracks|likes)/?)?(\?.*)?$'
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?soundcloud\.com/(?P<user>[^/]+)/?((?P<rsrc>tracks|likes)/?)?(\?.*)?$'
-                  r'(?P<id>[0-9]+/[0-9a-zA-Z]+)/?.*')
+    _VALID_URL = r'https?://(?:www\.)?dumpert\.nl/mediabase/(?P<id>[0-9]+/[0-9a-zA-Z]+)'
-            'description': 'Niet schrikken hoor'
+            'description': 'Niet schrikken hoor',
-        description = self._html_search_meta('description', webpage)
+        files_base64 = self._search_regex(
-        files = self._parse_json(files_json, video_id)
+        files = self._parse_json(
-                   if name in files]
+        quality = qualities(['flv', 'mobile', 'tablet', '720p'])
-        return count
+        return str_to_int(self._search_regex(
-        dislike_count = self._extract_count(r'<span class="votesDown">([\d,\.]+)</span>', webpage, 'dislike')
+        view_count = self._extract_count(
-            r'All comments \(<var class="videoCommentCount">([\d,\.]+)</var>', webpage, 'comment')
+            r'All Comments\s*<span>\(([\d,.]+)\)', webpage, 'comment')
-        base64_media_id = base64.b64encode(media_id.encode('utf-8')).decode('utf-8')
+        base64_media_id = self.base64_encode_utf8(media_id)
-            prop_id = base64.b64decode(prop.attrib['id']).decode('utf-8')
+            prop_id = self.base64_decode_utf8(prop.attrib['id'])
-            encoded_content = base64.b64decode(prop.text).decode('utf-8')
+            encoded_content = self.base64_decode_utf8(prop.text)
-            if isinstance(data, compat_str) or isinstance(data, compat_basestring):
+            if isinstance(data, (compat_str, compat_basestring)):
-from ..utils import ExtractorError
+from ..utils import (ExtractorError, unescapeHTML)
-    _TEST = {
+    _TESTS = [{
-            'id': 'iseven',
+            'id': '17732',
-            'description': 'md5:9e525642c25a0a24302869937cf69d17',
+            'description': 'md5:c93d6692dde6fe33809a46edcbecca44',
-    }
+    }, {
-            'http://www.douyutv.com/api/client/room/%s' % video_id, video_id)
+            'http://www.douyutv.com/api/v1/%s&auth=%s' % (prefix, auth),
-                'Server reported error %i' % error_code, expected=True)
+            error_desc = 'Server reported error %i' % error_code
-        title = self._live_title(data['room_name'])
+        title = self._live_title(unescapeHTML(data['room_name']))
-            'id': video_id,
+            'id': room_id,
-        (?P<path>.+?/(?P<title>[^/]+?)(?:\.(?:cnn|hln)(?:-ap)?|(?=&)))'''
+        (?P<path>.+?/(?P<title>[^/]+?)(?:\.(?:cnn|hln|ktvk)(?:-ap)?|(?=&)))'''
-            or self._search_regex(
+                webpage, 'title', default=None) or
-    _VALID_URL = r'http://www\.dhm\.de/filmarchiv/die-filme/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?dhm\.de/filmarchiv/(?:[^/]+/)+(?P<id>[^/]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+        },
-            webpage, 'description', fatal=False)
+            webpage, 'description', default=None)
-            webpage, 'duration', fatal=False))
+            webpage, 'duration', default=None))
-import re
+from ..utils import (
-    _VALID_URL = r'http://www\.dhm\.de/filmarchiv/(?P<id>.*?)'
+    IE_DESC = 'Filmarchiv - Deutsches Historisches Museum'
-            'id': 'marshallwg',
+            'id': 'the-marshallplan-at-work-in-west-germany',
-            'thumbnail': 'http://www.dhm.de/filmarchiv/video/mpworkwg.jpg',
+            'description': 'md5:1fabd480c153f97b07add61c44407c82',
-        video_id = ''
+        video_id = self._match_id(url)
-            r'dc:title=\"(.*?)\"', webpage, 'title')
+        playlist_url = self._search_regex(
-            r'file: \'(.*?)\'', webpage, 'playlist URL')
+        playlist = self._download_xml(playlist_url, video_id)
-        xml_file.close()
+        track = playlist.find(
-        thumbnail = root[0][0][2].text
+        video_url = xpath_text(
-            video_id = m.group(1)
+        title = self._search_regex(
-            'title': title,
+            'title': title,
-    _VALID_URL = r'http://www\.nbc\.com/(?:[^/]+/)+(?P<id>n?\d+)'
+    _VALID_URL = r'https?://www\.nbc\.com/(?:[^/]+/)+(?P<id>n?\d+)'
-__version__ = '2015.03.24'
+__version__ = '2015.03.28'
-            self.params.get('continuedl', False) and
+            self.params.get('continuedl', True) and
-            if self.params.get('continuedl', False):
+            if self.params.get('continuedl', True):
-        continue_dl = info_dict.get('continuedl', False)
+        continue_dl = info_dict.get('continuedl', True)
-        except:
+        except Exception:
-        except:
+        except Exception:
-            except:
+            except Exception:
-        except:
+        except Exception:
-        except:
+        except Exception:
-        except:
+        except ValueError:
-            raise PostProcessingError(msg)
+        except AudioConversionError as e:
-            except:
+            except Exception:
-    except:
+    except Exception:
-    except:
+    except Exception:
-    except:
+    except Exception:
-    except:
+    except Exception:
-    _TEST = {
+    _LOGIN_URL = 'http://www.eroprofile.com/auth/auth.php?'
-    }
+    }, {
-            'description': u'ÙØµÙ Û²Û°Û±Ûµ-Û²Û°Û±Û´',
+            'description': 'ÙØµÙ Û²Û°Û±Ûµ-Û²Û°Û±Û´',
-        self.assertMatch('https://www.youtube.com/feed/watch_later', ['youtube:watch_later'])
+        self.assertMatch('https://www.youtube.com/feed/watch_later', ['youtube:watchlater'])
-    _PERSONAL_FEED = True
+
-        if access_info.get('allow_access') == False:
+        if not access_info.get('allow_access', True):
-    _NETRC_MACHINE = 'safaribooksonline'
+    _SUCCESSFUL_LOGIN_REGEX = r'<a href="/accounts/logout/"[^>]*>Sign Out</a>'
-        if not SafariBaseIE.LOGGED_IN:
+        if not self.LOGGED_IN:
-            r"<input +type='hidden' +name='csrfmiddlewaretoken' +value='([^']+)' +/>",
+            r"name='csrfmiddlewaretoken'\s+value='([^']+)'",
-                                 'try again.', expected=True)
+            raise ExtractorError(
-                'hadoop-fundamentals-livelessons/9780133392838/part00.html'),
+    _VALID_URL = r'''(?x)https?://
-            'id': '9780133392838',
+            'id': '2842601850001',
-    }
+        },
-        webpage = self._download_webpage(url, part)
+        webpage = self._download_webpage(
-        }
+        return self.url_result(smuggle_url(bc_url, {'Referer': url}), 'Brightcove')
-                  '(?P<course_path>[^/]+)/(?P<id>\d+)/?$')
+    _VALID_URL = r'https?://(?:www\.)?safaribooksonline\.com/(?:library/view/[^/]+|api/v1/book)/(?P<id>\d+)/?(?:[#?]|$)'
-    _API_FORMAT = 'json'
+    _TESTS = [{
-        course_id = mobj.group('id')
+        course_id = self._match_id(url)
-        webpage = self._download_webpage(
+        course_json = self._download_json(
-        course_json = json.loads(webpage)
+            course_id, 'Downloading course JSON')
-        parts = ['%02d' % part for part in range(num_parts)]
+            raise ExtractorError(
-            for part_id in parts]
+            self.url_result(chapter, 'Safari')
-            r'var\s+slideshare_object\s*=\s*({.*?});\s*var\s+user_info\s*=',
+            r'\$\.extend\(slideshare_object,\s*(\{.*?\})\);',
-
+    def _extract_playlist(self, playlist_id):
-class YoutubeWatchLaterIE(YoutubeFeedsInfoExtractor):
+class YoutubeWatchLaterIE(YoutubePlaylistIE):
-    _VALID_URL = r'https?://www\.youtube\.com/feed/watch_later|:ytwatchlater'
+    _VALID_URL = r'https?://www\.youtube\.com/(?:feed/watch_later|playlist\?list=WL)|:ytwatchlater'
-            'title': u'Ûµ ÙØ§Ú©ÙØ´ Ø¨Ø±ØªØ± Ø¯Ø±ÙØ§Ø²ÙâØ¨Ø§ÙØ§ÙØÙÙØªÙ Û²Û¶ Ø¨ÙÙØ¯Ø³ÙÛÚ¯Ø§',
+            'title': 'Ûµ ÙØ§Ú©ÙØ´ Ø¨Ø±ØªØ± Ø¯Ø±ÙØ§Ø²ÙâØ¨Ø§ÙØ§ÙØÙÙØªÙ Û²Û¶ Ø¨ÙÙØ¯Ø³ÙÛÚ¯Ø§',
-    {
+    _TEST ={
-    ]
+    }
-    mobj = re.match(r'#(x?[0-9]+)', entity)
+    mobj = re.match(r'#(x[0-9a-fA-F]+|[0-9]+)', entity)
-            r'Y\.Ginger\.Module\.Player\((\{.*?\})\);', embed, 'player data'), video_id)
+            r'Y\.Ginger\.Module\.Player(?:;var\s*player\s*=\s*new\s*m)?\((\{.*?\})\);', embed, 'player data'), video_id)
-    IE_NAME = 'TwentyTwoTracks:Tracks'
+    _VALID_URL = r'https?://22tracks\.com/(?P<city>[a-z]+)/(?P<genre>[\da-z]+)/(?P<id>\d+)'
-        self._base_url = "http://22tracks.com/api/"
+    _API_BASE = 'http://22tracks.com/api'
-            itemid = track
+    def _extract_info(self, city, genre_name, track_id=None):
-        city_id = [x['id'] for x in cities if x['slug'] == city]
+            '%s/cities' % self._API_BASE, item_id,
-        genre_id = [x['id'] for x in genres if x['slug'] == genre]
+            '%s/genres/%s' % (self._API_BASE, city_id), item_id,
-            itemid, 'Downloading track info', 'Cannot download track info')
+            '%s/tracks/%s' % (self._API_BASE, genre_id), item_id,
-            return [x for x in tracks if x['id'] == itemid][0]
+        return [x for x in tracks if x['id'] == item_id][0] if track_id else [genre['title'], tracks]
-    def _get_token(self, filename, track_id):
+    def _get_track_url(self, filename, track_id):
-            track_info['artist'].strip(), track_info['title'].strip())
+            'http://22tracks.com/token.php?desktop=true&u=/128/%s' % filename,
-            'duration': track_info['duration']
+            'duration': int_or_none(track_info.get('duration')),
-    IE_NAME = 'TwentyTwoTracks:Genre'
+    _VALID_URL = r'https?://22tracks\.com/(?P<city>[a-z]+)/(?P<genre>[\da-z]+)/?$'
-        genre_id = mobj.group(2)
+        city = mobj.group('city')
-        self.to_screen(':: Track ID not found! - Downloading entire genre')
+        genre_title, tracks = self._extract_info(city, genre)
-        playlist_info = self._extract_info(city_id, genre_id)
+        entries = [
-        }
+        return self.playlist_result(entries, genre, genre_title)
-            "age_limit": 18,
+            'title': 'Sucked on a toilet',
-        help='print this help text and exit')
+        help='Print this help text and exit')
-        help='print program version and exit')
+        help='Print program version and exit')
-        help='update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')
+        help='Update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')
-        help='continue on download errors, for example to skip unavailable videos in a playlist')
+        help='Continue on download errors, for example to skip unavailable videos in a playlist')
-        help='display the current browser identification')
+        help='Display the current browser identification')
-        help='Use this prefix for unqualified URLs. For example "gvsearch2:" downloads two videos from google videos for  youtube-dl "large apple". Use the value "auto" to let youtube-dl guess ("auto_warning" to emit a warning when guessing). "error" just throws an error. The default value "fixup_error" repairs broken URLs, but emits an error if this is not possible instead of searching.')
+        help='Use this prefix for unqualified URLs. For example "gvsearch2:" downloads two videos from google videos for youtube-dl "large apple". Use the value "auto" to let youtube-dl guess ("auto_warning" to emit a warning when guessing). "error" just throws an error. The default value "fixup_error" repairs broken URLs, but emits an error if this is not possible instead of searching.')
-        help='Do not emit color codes in output.')
+        help='Do not emit color codes in output')
-        help='playlist video to start at (default is %default)')
+        help='Playlist video to start at (default is %default)')
-        help='playlist video to end at (default is last)')
+        help='Playlist video to end at (default is last)')
-        help='playlist video items to download. Specify indices of the videos in the playlist seperated by commas like: "--playlist-items 1,2,5,8" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: "--playlist-items 1-3,7,10-13", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')
+        help='Playlist video items to download. Specify indices of the videos in the playlist seperated by commas like: "--playlist-items 1,2,5,8" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: "--playlist-items 1-3,7,10-13", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')
-        help='download only matching titles (regex or caseless sub-string)')
+        help='Download only matching titles (regex or caseless sub-string)')
-        help='skip download for matching titles (regex or caseless sub-string)')
+        help='Skip download for matching titles (regex or caseless sub-string)')
-        help='download only videos uploaded in this date')
+        help='Download only videos uploaded in this date')
-        help='download only videos uploaded on or before this date (i.e. inclusive)')
+        help='Download only videos uploaded on or before this date (i.e. inclusive)')
-        help='download only videos uploaded on or after this date (i.e. inclusive)')
+        help='Download only videos uploaded on or after this date (i.e. inclusive)')
-        help='Do not download any videos with less than COUNT views',)
+        help='Do not download any videos with less than COUNT views')
-            '(Experimental) Generic video filter. '
+            'Generic video filter (experimental). '
-        help='If the URL refers to a video and a playlist, download only the video.')
+        help='Download only the video, if the URL refers to a video and a playlist.')
-        help='If the URL refers to a video and a playlist, download the playlist.')
+        help='Download the playlist, if the URL refers to a video and a playlist.')
-        help='download only videos suitable for the given age')
+        help='Download only videos suitable for the given age')
-        help='login with this account ID')
+        help='Login with this account ID')
-        help='account password. If this option is left out, youtube-dl will ask interactively.')
+        help='Account password. If this option is left out, youtube-dl will ask interactively.')
-        help='two-factor auth code')
+        help='Two-factor auth code')
-        help='use .netrc authentication data')
+        help='Use .netrc authentication data')
-        help='video password (vimeo, smotri)')
+        help='Video password (vimeo, smotri)')
-            'video format code, specify the order of preference using'
+            'Video format code, specify the order of preference using'
-        help='download all available video formats')
+        help='Download all available video formats')
-        help='prefer free video formats unless a specific one is requested')
+        help='Prefer free video formats unless a specific one is requested')
-        help='highest quality format to download')
+        help='Specify highest quality format to download')
-        help='list all available formats')
+        help='List all available formats')
-        help='write subtitle file')
+        help='Write subtitle file')
-        help='write automatic subtitle file (youtube only)')
+        help='Write automatic subtitle file (YouTube only)')
-        help='downloads all the available subtitles of the video')
+        help='Download all the available subtitles of the video')
-        help='lists all available subtitles for the video')
+        help='List all available subtitles for the video')
-        help='subtitle format, accepts formats preference, for example: "ass/srt/best"')
+        help='Specify subtitle format preference, for example: "srt" or "ass/srt/best"')
-        help='languages of the subtitles to download (optional) separated by commas, use IETF language tags like \'en,pt\'')
+        help='Languages of the subtitles to download (optional) separated by commas, use IETF language tags like \'en,pt\'')
-        help='maximum download rate in bytes per second (e.g. 50K or 4.2M)')
+        help='Maximum download rate in bytes per second (e.g. 50K or 4.2M)')
-        help='number of retries (default is %default), or "infinite".')
+        help='Number of retries (default is %default), or "infinite".')
-        help='size of download buffer (e.g. 1024 or 16K) (default is %default)')
+        help='Size of download buffer (e.g. 1024 or 16K) (default is %default)')
-        help='do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')
+        help='Do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')
-        help='(experimental) set file xattribute ytdl.filesize with expected filesize')
+        help='Set file xattribute ytdl.filesize with expected filesize (experimental)')
-        help='(experimental) Use the native HLS downloader instead of ffmpeg.')
+        help='Use the native HLS downloader instead of ffmpeg (experimental)')
-        help='Give these arguments to the external downloader.')
+        help='Give these arguments to the external downloader')
-        help='Suppress HTTPS certificate validation.')
+        help='Suppress HTTPS certificate validation')
-        help='specify a custom user agent')
+        help='Specify a custom user agent')
-        help='specify a custom referer, use if the video access is restricted to one domain',
+        help='Specify a custom referer, use if the video access is restricted to one domain',
-        help='specify a custom HTTP header and its value, separated by a colon \':\'. You can use this option multiple times',
+        help='Specify a custom HTTP header and its value, separated by a colon \':\'. You can use this option multiple times',
-        help='activates quiet mode')
+        help='Activate quiet mode')
-        help='do not download the video and do not write anything to disk',)
+        help='Do not download the video and do not write anything to disk')
-        help='do not download the video',)
+        help='Do not download the video')
-        help='simulate, quiet but print URL')
+        help='Simulate, quiet but print URL')
-        help='simulate, quiet but print title')
+        help='Simulate, quiet but print title')
-        help='simulate, quiet but print id')
+        help='Simulate, quiet but print id')
-        help='simulate, quiet but print thumbnail URL')
+        help='Simulate, quiet but print thumbnail URL')
-        help='simulate, quiet but print video description')
+        help='Simulate, quiet but print video description')
-        help='simulate, quiet but print video length')
+        help='Simulate, quiet but print video length')
-        help='simulate, quiet but print output filename')
+        help='Simulate, quiet but print output filename')
-        help='simulate, quiet but print output format')
+        help='Simulate, quiet but print output format')
-        help='simulate, quiet but print JSON information. See --output for a description of available keys.')
+        help='Simulate, quiet but print JSON information. See --output for a description of available keys.')
-        help='simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')
+        help='Simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')
-        help='output progress bar as new lines')
+        help='Output progress bar as new lines')
-        help='do not print progress bar')
+        help='Do not print progress bar')
-        help='display progress in console titlebar')
+        help='Display progress in console titlebar')
-        help='print various debugging information')
+        help='Print various debugging information')
-        help='print downloaded pages to debug problems (very verbose)')
+        help='Print downloaded pages to debug problems (very verbose)')
-        help='Contact the youtube-dl server for debugging.')
+        help='Contact the youtube-dl server for debugging')
-        help='Do NOT contact the youtube-dl server for debugging.')
+        help='Do NOT contact the youtube-dl server for debugging')
-        help='file containing URLs to download (\'-\' for stdin)')
+        help='File containing URLs to download (\'-\' for stdin)')
-        action='store_true', dest='useid', help='use only video ID in file name')
+        action='store_true', dest='useid', help='Use only video ID in file name')
-        help=('output filename template. Use %(title)s to get the title, '
+        help=('Output filename template. Use %(title)s to get the title, '
-              '%(format_id)s for the unique id of the format (like Youtube\'s itags: "137"), '
+              '%(format_id)s for the unique id of the format (like YouTube\'s itags: "137"), '
-              '%(extractor)s for the provider (youtube, metacafe, etc), '
+              '%(extractor)s for the provider (YouTube, metacafe, etc), '
-        help='Specifies the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given')
+        help='Specify the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given')
-        help='[deprecated; use  -o "%(autonumber)s-%(title)s.%(ext)s" ] number downloaded files starting from 00000')
+        help='[deprecated; use  -o "%(autonumber)s-%(title)s.%(ext)s" ] Number of downloaded files starting from 00000')
-        help='[deprecated] use title in file name (default)')
+        help='[deprecated] Use title in file name (default)')
-        help='[deprecated] alias of --title')
+        help='[deprecated] Alias of --title')
-        help='do not overwrite files')
+        help='Do not overwrite files')
-        help='force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')
+        help='Force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')
-        help='do not resume partially downloaded files (restart from beginning)')
+        help='Do not resume partially downloaded files (restart from beginning)')
-        help='do not use .part files - write directly into output file')
+        help='Do not use .part files - write directly into output file')
-        help='do not use the Last-modified header to set the file modification time')
+        help='Do not use the Last-modified header to set the file modification time')
-        help='write video description to a .description file')
+        help='Write video description to a .description file')
-        help='write video metadata to a .info.json file')
+        help='Write video metadata to a .info.json file')
-        help='write video annotations to a .annotation file')
+        help='Write video annotations to a .annotation file')
-        help='json file containing the video information (created with the "--write-json" option)')
+        help='Specify JSON file containing the video information (created with the "--write-json" option)')
-        help='file to read cookies from and dump cookie jar in')
+        help='File to read cookies from and dump cookie jar in')
-        help='write thumbnail image to disk')
+        help='Write thumbnail image to disk')
-        help='write all thumbnail image formats to disk')
+        help='Write all thumbnail image formats to disk')
-        help='convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')
+        help='Convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')
-        help='"best", "aac", "vorbis", "mp3", "m4a", "opus", or "wav"; "%default" by default')
+        help='Specify audio format: "best", "aac", "vorbis", "mp3", "m4a", "opus", or "wav"; "%default" by default')
-        help='ffmpeg/avconv audio quality specification, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')
+        help='Specify ffmpeg/avconv audio quality, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')
-        help='keeps the video file on disk after the post-processing; the video is erased by default')
+        help='Keep the video file on disk after the post-processing; the video is erased by default')
-        help='do not overwrite post-processed files; the post-processed files are overwritten by default')
+        help='Do not overwrite post-processed files; the post-processed files are overwritten by default')
-        help='embed subtitles in the video (only for mp4 videos)')
+        help='Embed subtitles in the video (only for mp4 videos)')
-        help='embed thumbnail in the audio as cover art')
+        help='Embed thumbnail in the audio as cover art')
-        help='write metadata to the video file')
+        help='Write metadata to the video file')
-        help='parse additional metadata like song title / artist from the video title. '
+        help='Parse additional metadata like song title / artist from the video title. '
-        help='write metadata to the video file\'s xattrs (using dublin core and xdg standards)')
+        help='Write metadata to the video file\'s xattrs (using dublin core and xdg standards)')
-__version__ = '2015.03.18'
+__version__ = '2015.03.24'
-        referer = 'http://www.miomio.tv{}'.format(ref_path)
+        referer = 'http://www.miomio.tv{0}'.format(ref_path)
-        xml_url = 'http://www.miomio.tv/mioplayer/mioplayerconfigfiles/sina.php?{}'.format(xml_config)
+        
-                    transform_source=strip_jsonp)
+                    'Unable to download %s URL' % stream_type,
-    _VALID_URL = r'https?://m(?:lb)?\.mlb\.com/(?:(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|(?:shared/video/embed/embed\.html|[^/]+/video/play\.jsp)\?.*?\bcontent_id=)(?P<id>n?\d+)'
+    _VALID_URL = r'https?://m(?:lb)?\.(?:[\da-z_-]+\.)?mlb\.com/(?:(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|(?:shared/video/embed/embed\.html|[^/]+/video/play\.jsp)\?.*?\bcontent_id=)(?P<id>n?\d+)'
-    _VALID_URL = r'%s/[^/]+/b/(?P<id>[^/]+)' % TwitchBaseIE._VALID_URL_BASE
+    _VALID_URL = r'%s/[^/]+/b/(?P<id>\d+)' % TwitchBaseIE._VALID_URL_BASE
-    _VALID_URL = r'%s/[^/]+/c/(?P<id>[^/]+)' % TwitchBaseIE._VALID_URL_BASE
+    _VALID_URL = r'%s/[^/]+/c/(?P<id>\d+)' % TwitchBaseIE._VALID_URL_BASE
-    _VALID_URL = r'%s/[^/]+/v/(?P<id>[^/]+)' % TwitchBaseIE._VALID_URL_BASE
+    _VALID_URL = r'%s/[^/]+/v/(?P<id>\d+)' % TwitchBaseIE._VALID_URL_BASE
-print('aes_decrypt_text')
+print('aes_decrypt_text 16')
-        title = '%s - %s' %(podcast_title, episode_title) if podcast_title else episode_title
+        title = '%s - %s' % (podcast_title, episode_title) if podcast_title else episode_title
-from .comedycentral import ComedyCentralIE, ComedyCentralShowsIE, TheDailyShowPodcastIE
+from .comedycentral import ComedyCentralIE, ComedyCentralShowsIE
-        }
+        # Libsyn embed
-from .lifenews import LifeNewsIE
+from .lifenews import LifeNewsIE
-# encoding: utf-8
+# coding: utf-8
-)
+from ..utils import unified_strdate
-        'url': "http://html5-player.libsyn.com/embed/episode/id/3377616/",
+    _VALID_URL = r'https?://html5-player\.libsyn\.com/embed/episode/id/(?P<id>[0-9]+)'
-            'description': "<p>Bassem Youssef joins executive producer Steve Bodow and senior producer Sara Taksler for a conversation about how&nbsp;<em style=\"font-family: Tahoma, Geneva, sans-serif; font-size: 12.8000001907349px;\">The Daily Show</em>&nbsp;inspired Bassem to create&nbsp;<em style=\"font-family: Tahoma, Geneva, sans-serif; font-size: 12.8000001907349px;\">Al-Bernameg</em>, his massively popular (and now banned) Egyptian news satire program. Sara discusses her soon-to-be-released documentary,&nbsp;<em style=\"font-family: Tahoma, Geneva, sans-serif; font-size: 12.8000001907349px;\">Tickling Giants</em>, which chronicles how Bassem and his staff risked their safety every day to tell jokes.</p>",
+            'id': '3377616',
-    }]
+    }
-            }]
+        video_id = self._match_id(url)
-            'upload_date': podcast_date,
+            'id': video_id,
-    _VALID_URL = r'http://(?:www\.)?nrk\.no/(?!video)[^/]+/(?P<id>[^/]+)'
+    _VALID_URL = r'http://(?:www\.)?nrk\.no/(?!video)(?:[^/]+/)+(?P<id>[^/]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+        'playlist_count': 2,
-                r'class="[^"]*\brich\b[^"]*"[^>]+data-video-id="(\d+)"', webpage)
+                r'class="[^"]*\brich\b[^"]*"[^>]+data-video-id="([^"]+)"',
-    _VALID_URL = r'http://(?:www\.)?nrk\.no/(?:[^/]+/)*(?P<id>[^/]+)'
+    _VALID_URL = r'http://(?:www\.)?nrk\.no/(?!video)[^/]+/(?P<id>[^/]+)'
-    _VALID_URL = r'http://(?:www\.)?nrk\.no/(?:video|lyd)/[^/]+/(?P<id>[\dA-F]{16})'
+    _VALID_URL = r'(?:nrk:|http://(?:www\.)?nrk\.no/video/PS\*)(?P<id>\d+)'
-            'md5': 'a6eac35052f3b242bb6bb7f43aed5886',
+            'url': 'http://www.nrk.no/video/PS*150533',
-                'description': 'md5:d9261ba34c43b61c812cb6b0269a5c8f'
+                'description': 'md5:d9261ba34c43b61c812cb6b0269a5c8f',
-            'md5': '3471f2a51718195164e88f46bf427668',
+            'url': 'http://www.nrk.no/video/PS*154915',
-        video_id = self._html_search_regex(r'<div class="nrk-video" data-nrk-id="(\d+)">', page, 'video id')
+        video_id = self._match_id(url)
-            'http://v7.psapi.nrk.no/mediaelement/%s' % video_id, video_id, 'Downloading media JSON')
+            'http://v8.psapi.nrk.no/mediaelement/%s' % video_id,
-            raise ExtractorError('NRK har ikke rettig-heter til Ã¥ vise dette programmet utenfor Norge', expected=True)
+            raise ExtractorError(
-        video_url = data['mediaUrl'] + '?hdcore=3.1.1&plugin=aasp-3.1.1.69.124'
+        video_url = data['mediaUrl'] + '?hdcore=3.5.0&plugin=aasp-3.5.0.151.81'
-                return temp
+from __future__ import unicode_literals
-            'mp_source_action': '',
+            'mp_source_action': 'login-button',
-            'user[password]': password,
+            'login': username,
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+            self._LOGIN_POST_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-from youtube_dl.compat import compat_http_server
+from youtube_dl.compat import compat_http_server, compat_urllib_request
-        }]
+            'format_id': '%(format)s-%(rate)s' % f,
-    _VALID_URL = r'https?://(?:(?:www\.)?nytimes\.com/video/(?:[^/]+/)+|graphics8\.nytimes\.com/bcvideo/\d+(?:\.\d+)?/iframe/embed\.html\?videoId=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:(?:www\.)?nytimes\.com/video/(?:[^/]+/)+?|graphics8\.nytimes\.com/bcvideo/\d+(?:\.\d+)?/iframe/embed\.html\?videoId=)(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-)
+from ..compat import compat_urllib_request
-        (?:iframe\.php)?\?ref=(?P<id>[A-Za-z0-9]+)
+        (?:iframe\.php|cdn\.php)?\?ref=(?P<id>[A-Za-z0-9]+)
-        'url': 'http://videomega.tv/?ref=QR0HCUHI1661IHUCH0RQ',
+        'url': 'http://videomega.tv/?ref=4GNA688SU99US886ANG4',
-            'id': 'QR0HCUHI1661IHUCH0RQ',
+            'id': '4GNA688SU99US886ANG4',
-            'title': 'Big Buck Bunny',
+            'title': 'BigBuckBunny_320x180',
-        iframe_url = 'http://videomega.tv/iframe.php?ref={0:}'.format(video_id)
+        iframe_url = 'http://videomega.tv/cdn.php?ref=%s' % video_id
-
+        title = self._html_search_regex(
-        self._sort_formats(formats)
+            r'<video[^>]+?poster="([^"]+)"', webpage, 'thumbnail', fatal=False)
-            'formats': formats,
+            'url': video_url,
-from ..utils import parse_iso8601
+from ..utils import (
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            'http://www.nytimes.com/svc/video/api/v2/video/%s' % video_id, video_id, 'Downloading video JSON')
+            'http://www.nytimes.com/svc/video/api/v2/video/%s' % video_id,
-        duration = video_data['duration'] / 1000.0
+        description = video_data.get('summary')
-                'filesize': get_file_size(video['fileSize']),
+                'format_id': video.get('type'),
-                'resolution': '%dx%d' % (image['width'], image['height']),
+                'width': int_or_none(image.get('width')),
-    _VALID_URL = r'https?://(?:www\.)?nytimes\.com/video/(?:[^/]+/)+(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:(?:www\.)?nytimes\.com/video/(?:[^/]+/)+|graphics8\.nytimes\.com/bcvideo/\d+(?:\.\d+)?/iframe/embed\.html\?videoId=)(?P<id>\d+)'
-__version__ = '2015.03.15'
+__version__ = '2015.03.18'
-        } for mode in player['modes']]
+        formats = []
-from .ultimedia import UltimediaIE
+from .ultimedia import UltimediaIE
-            url = template_url % i
+    def _get_url(self, track_id, template_url, server_number):
-                    'Checking URL %d/%d ...' % (i + 1, server_count + 1))
+                    'Checking URL %d/%d ...' % (nr, boundaries[-1]))
-
+        server_number = int(self._search_regex(r'stream(\d+)', song_url, 'server number'))
-        final_song_url = self._get_url(track_id, template_url)
+        final_song_url = self._get_url(track_id, template_url, server_number)
-            final_song_url = self._get_url(track_id, template_url)
+            final_song_url = self._get_url(track_id, template_url, server_number)
-            'title': 'Electric Relaxation vol. 3',
+            'ext': 'mp3',
-            'uploader': 'Daniel Drumz',
+            'uploader': 'Gilles Peterson Worldwide',
-            'thumbnail': 're:https?://.*\.jpg',
+            'thumbnail': 're:https?://.*/images/',
-            r'<span class="play-button[^"]*?"'
+            r'm-play-on-spacebar[^>]+'
-             r'/favorites/?">([0-9]+)<'],
+            r'\bbutton-favorite\b.+m-ajax-toggle-count="([^"]+)"',
-        height = int_or_none(self._og_search_property('video:height', webpage, 'video height'))
+        width = int_or_none(self._og_search_property(
-                'http://flapi.nicovideo.jp/api/getflv?v=' + video_id,
+                'http://flapi.nicovideo.jp/api/getflv/' + video_id + '?as3=1',
-
+            REDIRECT_REGEX = r'[0-9]{,2};\s*(?:URL|url)=\'?([^\'"]+)'
-                r'(?:[a-z-]+="[^"]+"\s+)*?content="[0-9]{,2};\s*(?:URL|url)=\'?([^\'"]+)',
+                r'(?:[a-z-]+="[^"]+"\s+)*?content="%s' % REDIRECT_REGEX,
-                        r'[0-9]{,2};\s*(?:URL|url)=(.+)', refresh_header)
+                    found = re.search(REDIRECT_REGEX, refresh_header)
-                r'(?:[a-z-]+="[^"]+"\s+)*?content="[0-9]{,2};url=\'?([^\'"]+)',
+                r'(?:[a-z-]+="[^"]+"\s+)*?content="[0-9]{,2};\s*(?:URL|url)=\'?([^\'"]+)',
-            return (webpage, [x for x in o if x['attrs']['id'] == 'jsPlayerEmbed'])
+            return webpage, [x for x in o if x['attrs']['id'] == 'jsPlayerEmbed']
-        return (webpage, None)
+        return webpage, None
-            if player_objs is not None:
+            if player_objs:
-from .douyutv import DouyutvIE
+from .douyutv import DouyuTVIE
-class DouyutvIE(InfoExtractor):
+class DouyuTVIE(InfoExtractor):
-            'title': 'æ¸æ¨éèï¼T-araæ ¹æ¬åä¸ä¸æ¥ï¼',
+            'title': 're:^æ¸æ¨éèï¼T-araæ ¹æ¬åä¸ä¸æ¥ï¼ [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',
-        config = self._download_json(info_url, video_id)
+        config = self._download_json(
-        show_status = config['data'].get('show_status')
+        data = config['data']
-                                 expected=True)
+            raise ExtractorError(
-                                 expected=True)
+            raise ExtractorError(
-        thumbnail = config['data'].get('room_src') 
+        title = self._live_title(data['room_name'])
-        url = rtmp_url+'/'+rtmp_live
+        uploader = data.get('nickname')
-            'url': url,
+            'description': description,
-        }
+        }
-from ..utils import url_sanitize_consecutive_slashes
+from ..utils import sanitize_url_path_consecutive_slashes
-        'info': 'Video with title containing dash',
+        'note': 'Video with title containing dash',
-                                       'Downloading JSON data for %s' % vid_id)
+            return self._download_json(
-                video_url = url_sanitize_consecutive_slashes(
+                video_url = sanitize_url_path_consecutive_slashes(
-    url_sanitize_consecutive_slashes,
+    def test_sanitize_url_path_consecutive_slashes(self):
-
+def sanitize_url_path_consecutive_slashes(url):
-from .primesharetv import PrimesharetvIE
+from .primesharetv import PrimeShareTVIE
-)
+    compat_urllib_parse,
-    ]
+class PrimeShareTVIE(InfoExtractor):
-        })
+
-            r'url: \'(http://[a-z0-9]+\.primeshare\.tv:443/file/get/[^\']+)\',', video_page, 'video url')
+
-            r'<h1>Watch&nbsp;[^\(]+\(([^/)]+)\)&nbsp;', video_page, 'title')
+            r'<h1>Watch\s*(?:&nbsp;)?\s*\((.+?)(?:\s*\[\.\.\.\])?\)\s*(?:&nbsp;)?\s*<strong>',
-
+import re
-
+    
-            r'url: \'(http://l\.primeshare\.tv[^\']+)\',', video_page, 'video url')
+            r'url: \'(http://[a-z0-9]+\.primeshare\.tv:443/file/get/[^\']+)\',', video_page, 'video url')
-            media_id, 'playJson data')
+            media_id, 'Downloading playJson data')
-from .comedycentral import ComedyCentralIE, ComedyCentralShowsIE
+from .comedycentral import ComedyCentralIE, ComedyCentralShowsIE, TheDailyShowPodcastIE
-    _VALID_URL = r'https?://(?:www\.)?rtve\.es/infantil/serie/(?P<show>[^/]*)/video/(?P<short_tittle>[^/]*)/(?P<id>[0-9]+)/'
+    IE_NAME = 'rtve.es:infantil'
-    },]
+    }]
-        short_tittle = mobj.group('short_tittle')
+        video_id = self._match_id(url)
-from .rtve import RTVEALaCartaIE, RTVELiveIE
+from .rtve import RTVEALaCartaIE, RTVELiveIE, RTVEInfantilIE
-__version__ = '2015.03.09'
+__version__ = '2015.03.15'
-            r'filekey\s*=\s*"([^"]+)"', webpage, 'file_key')
+            [r'key\s*:\s*"([^"]+)"', r'filekey\s*=\s*"([^"]+)"'],
-         '''
+        '''
-    _VALID_URL = r'https?://(?:www\.)?aftenposten\.no/webtv/([^/]+/)*(?P<id>[^/]+)-\d+\.html'
+    _VALID_URL = r'https?://(?:www\.)?aftenposten\.no/webtv/(?:#!/)?video/(?P<id>\d+)'
-        'url': 'http://www.aftenposten.no/webtv/serier-og-programmer/sweatshopenglish/TRAILER-SWEATSHOP---I-cant-take-any-more-7800835.html?paging=&section=webtv_serierogprogrammer_sweatshop_sweatshopenglish',
+        'url': 'http://www.aftenposten.no/webtv/#!/video/21039/trailer-sweatshop-i-can-t-take-any-more',
-            r'data-xs-id="(\d+)"', webpage, 'video id')
+        video_id = self._match_id(url)
-            {'ext': 'mp4', 'height': 460, 'url': 'y'},
+            {'ext': 'webm', 'height': 460, 'url': TEST_URL},
-            {'ext': 'mp4', 'height': 1080, 'url': 'b'},
+            {'ext': 'webm', 'height': 720, 'url': TEST_URL},
-            {'ext': 'flv', 'height': 720, 'url': '_'},
+            {'ext': 'webm', 'height': 720, 'url': TEST_URL},
-            {'ext': 'webm', 'height': 720, 'url': '_'},
+            {'ext': 'flv', 'height': 720, 'url': TEST_URL},
-            {'format_id': '2', 'ext': 'flv', 'preference': 4, 'url': '_'},
+            {'format_id': '35', 'ext': 'mp4', 'preference': 1, 'url': TEST_URL},
-            {'format_id': 'vid', 'ext': 'mp4', 'preference': 4, 'url': '_'},
+            {'format_id': 'audio-low', 'ext': 'webm', 'preference': 1, 'vcodec': 'none', 'url': TEST_URL},
-            {'format_id': 'vid-high', 'ext': 'mp4', 'preference': 2, 'url': '_'},
+            {'format_id': 'vid-low', 'ext': 'mp4', 'preference': 1, 'url': TEST_URL},
-            {'format_id': 'vid', 'ext': 'mp4', 'preference': 3, 'url': '_'},
+            {'format_id': 'dash-video-low', 'ext': 'mp4', 'preference': 1, 'acodec': 'none', 'url': TEST_URL},
-        for dirpath, _, filenames in os.walk(rootDir):
+        for dirpath, dirnames, filenames in os.walk(rootDir):
-        help='parse additional metadata like song title / artist from the video title. \n'
+        help='parse additional metadata like song title / artist from the video title. '
-             'Additional templates: %(songtitle), %(album), %(artist). \n'
+             'the parsed parameters replace existing values. '
-        elif info.get('title') is not None:
+        if info.get('title') is not None:
-# -*- coding: utf-8 -*-
+from __future__ import unicode_literals
-        self._titleregex = self.fmtToRegex(titleformat)
+        self._titleregex = self.format_to_regex(titleformat)
-    def fmtToRegex(self, fmt):
+    def format_to_regex(self, fmt):
-        groups = []
+    if opts.metafromtitle:
-        if info.get('title') is not None:
+        if info.get('songtitle') is not None:
-        if info.get('uploader') is not None:
+        if info.get('artist') is not None:
-        title = raw_title.partition('-')[0].strip()
+
-                videos, '%s' % info['id'], info['full_name'])
+            return self._extract_event(info)
-        playlist_id = mobj.group('id')
+        playlist_id = self._match_id(url)
-        data = json.loads(json_like)
+        data = self._parse_json(
-    _VALID_URL = r'https?://music\.yandex\.ru/album/(?P<album_id>\d+)/track/(?P<id>\d+)'
+    _VALID_URL = r'https?://music\.yandex\.(?:ru|kz|ua|by)/album/(?P<album_id>\d+)/track/(?P<id>\d+)'
-    _VALID_URL = r'https?://music\.yandex\.ru/album/(?P<id>\d+)/?(\?|$)'
+    _VALID_URL = r'https?://music\.yandex\.(?:ru|kz|ua|by)/album/(?P<id>\d+)/?(\?|$)'
-    _VALID_URL = r'https?://music\.yandex\.ru/users/[^/]+/playlists/(?P<id>\d+)'
+    _VALID_URL = r'https?://music\.yandex\.(?:ru|kz|ua|by)/users/[^/]+/playlists/(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-        'md5': '8f9d94b282d80c42b378dffdbb11caf3',
+        'playlist': [{
-    }
+        }
-        }
+        entries = []
-            'id': '2609989',
+            'id': '3270012277',
-            'description': 'md5:',
+            'description': 'md5:6023a95832a06059832ae93bc3c7efb7',
-            'display-id': 'synesthesia-original-mix',
+            'id': '5379371',
-            'display-id': 'love-and-war-original-mix',
+            'id': '3756896',
-            'display-id': 'birds-original-mix',
+            'id': '4991738',
-import json
+from ..compat import compat_str
-        playables = json.loads(playables)
+        playables = self._parse_json(
-            if info['url'] is None:
+            if not info['url']:
-            img = {
+            image = {
-            images.append(img)
+            images.append(image)
-            'id': track['id'],
+            'id': compat_str(track.get('id')) or track_id,
-    _VALID_URL = r'https?://pro\.beatport\.com/track/.+/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://pro\.beatport\.com/track/(?P<display_id>[^/]+)/(?P<id>[0-9]+)'
-        webpage = self._download_webpage(url, track_id)
+        mobj = re.match(self._VALID_URL, url)
-            'display-id': track['slug'],
+            'display_id': track.get('slug') or display_id,
-
+from .common import InfoExtractor
-    _VALID_URL = r'https?://pro\.beatport\.com/track/.*/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://pro\.beatport\.com/track/.+/(?P<id>[0-9]+)'
-                                       'playables info', flags=re.DOTALL)
+        playables = self._search_regex(
-            formats += [fmt]
+            formats.append(fmt)
-        imgs = []
+        images = []
-            if name == 'dynamic' or info['url'] is None:
+            image_url = info.get('url')
-                'width': info['width'],
+                'url': image_url,
-            imgs += [img]
+            images.append(img)
-            'thumbnails': imgs,
+            'thumbnails': images,
-        formats.sort(key=lambda f: f['preference'])
+        self._sort_formats(formats)
-            endtime = self._seconds2str(begin + duration)
+            starttime = self._subtitles_timecode(begin)
-            'id': '5182',
+            'id': '114765',
-            'description': 'Lorsque les dÃ©veloppeurs de LittleBigPlanet proposent un nouveau titre, on ne peut que s\'attendre Ã  un rÃ©sultat original et fort attrayant.\n',
+            'title': 'Tearaway : GC 2013 : Tearaway nous prÃ©sente ses papiers d\'identitÃ©',
-            r'<param name="flashvars" value="config=(.*?)" />',
+        title = self._html_search_meta('name', webpage)
-            xml_link, 'video ID')
+            r'id=(\d+)',
-        info = json.loads(info_json)['versions'][0]
+        config = self._download_json(
-        video_url = 'http://video720.jeuxvideo.com/' + info['file']
+        formats = [{
-            'url': video_url,
+            'title': title,
-            'thumbnail': config.find('image').text,
+            'thumbnail': config.get('image'),
-        track = next(filter(lambda t: t['id'] == int(track_id), playables['tracks']))
+        track = next(t for t in playables['tracks'] if t['id'] == int(track_id))
-        self.assertMatch('http://vimeo.com/user7108434/videos', ['vimeo:user'])
+        self.assertMatch('https://vimeo.com/channels/tributes', ['vimeo:channel'])
-                    'url': 'http://vimeo.com' + tt['url'],
+                    'url': 'https://vimeo.com' + tt['url'],
-    _VALID_URL = r'https?://vimeo\.com/channels/(?P<id>[^/?#]+)/?(?:$|[?#])'
+    _VALID_URL = r'https://vimeo\.com/channels/(?P<id>[^/?#]+)/?(?:$|[?#])'
-        'url': 'http://vimeo.com/channels/tributes',
+        'url': 'https://vimeo.com/channels/tributes',
-        entries = [self.url_result('http://vimeo.com/%s' % video_id, 'Vimeo')
+        entries = [self.url_result('https://vimeo.com/%s' % video_id, 'Vimeo')
-        return self._extract_videos(channel_id, 'http://vimeo.com/channels/%s' % channel_id)
+        return self._extract_videos(channel_id, 'https://vimeo.com/channels/%s' % channel_id)
-    _VALID_URL = r'https?://vimeo\.com/(?![0-9]+(?:$|[?#/]))(?P<name>[^/]+)(?:/videos|[#?]|$)'
+    _VALID_URL = r'https://vimeo\.com/(?![0-9]+(?:$|[?#/]))(?P<name>[^/]+)(?:/videos|[#?]|$)'
-        'url': 'http://vimeo.com/nkistudio/videos',
+        'url': 'https://vimeo.com/nkistudio/videos',
-        return self._extract_videos(name, 'http://vimeo.com/%s' % name)
+        return self._extract_videos(name, 'https://vimeo.com/%s' % name)
-    _VALID_URL = r'(?:https?://)?vimeo\.com/groups/(?P<name>[^/]+)'
+    _VALID_URL = r'https://vimeo\.com/groups/(?P<name>[^/]+)'
-        'url': 'http://vimeo.com/groups/rolexawards',
+        'url': 'https://vimeo.com/groups/rolexawards',
-        return self._extract_videos(name, 'http://vimeo.com/groups/%s' % name)
+        return self._extract_videos(name, 'https://vimeo.com/groups/%s' % name)
-    _VALID_URL = r'https?://vimeo\.com/[^/]+/review/(?P<id>[^/]+)'
+    _VALID_URL = r'https://vimeo\.com/[^/]+/review/(?P<id>[^/]+)'
-        'url': 'http://vimeo.com/user22258446/review/91613211/13f927e053',
+        'url': 'https://vimeo.com/user22258446/review/91613211/13f927e053',
-    _VALID_URL = r'https?://vimeo\.com/home/watchlater|:vimeowatchlater'
+    _VALID_URL = r'https://vimeo\.com/home/watchlater|:vimeowatchlater'
-        'url': 'http://vimeo.com/home/watchlater',
+        'url': 'https://vimeo.com/home/watchlater',
-    _VALID_URL = r'https?://(?:www\.)?vimeo\.com/user(?P<id>[0-9]+)/likes/?(?:$|[?#]|sort:)'
+    _VALID_URL = r'https://(?:www\.)?vimeo\.com/user(?P<id>[0-9]+)/likes/?(?:$|[?#]|sort:)'
-                self.http_scheme(), user_id, idx + 1)
+            page_url = 'https://vimeo.com/user%s/likes/page:%d/sort:date' % (
-        token = self._search_regex(r'xsrft: \'(.*?)\'', webpage, 'login token')
+        token = self._search_regex(r'xsrft = \'(.*?)\'', webpage, 'login token')
-    _SECURITY_URL_TEMPLATE = 'http://security.video.globo.com/videos/%s/hash?player=flash&version=2.9.9.50&resource_id=%s'
+    _SECURITY_URL_TEMPLATE = 'http://security.video.globo.com/videos/%s/hash?player=flash&version=17.0.0.132&resource_id=%s'
-        }
+        },
-        if req_format in ('-1', 'all'):
+        if req_format == 'all':
-          subtitles[sublang].append({'url': 'http://www.funnyordie.com'+suburl,'ext': subext})
+        subtitles = {}
-                if stream_type == 'ss':
+                # smooth streaming is not supported
-          subtitles[sublang].append({'url': suburl,'ext': subext})
+          subtitles[sublang].append({'url': 'http://www.funnyordie.com'+suburl,'ext': subext})
-
+        subtitles={}
-        re.sub('(?:[/<>:"\\|\\\\?\\*]|\.$)', '#', path_part)
+        path_part if path_part in ['.', '..'] else re.sub('(?:[/<>:"\\|\\\\?\\*]|\.$)', '#', path_part)
-    _VALID_URL = r'https?://music\.yandex\.ru/album/(?P<id>\d+)'
+    _VALID_URL = r'https?://music\.yandex\.ru/album/(?P<id>\d+)/?(\?|$)'
-    _VALID_URL = r'https?://(?:www\.|secure\.)?nicovideo\.jp/watch/((?:[a-z]{2})?[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.|secure\.)?nicovideo\.jp/watch/(?P<id>(?:[a-z]{2})?[0-9]+)'
-        video_id = mobj.group(1)
+        video_id = self._match_id(url)
-from .yamusic import (
+from .yandexmusic import (
-import time
+from ..compat import compat_str
-    _VALID_URL = r'http://music.yandex.ru/album/(?P<id>\d+)'
+class YandexMusicBaseIE(InfoExtractor):
-        data = self._download_json('http://music.yandex.ru/api/v1.5/handlers/api-jsonp.jsx?requestId=2&nc=%d&action=getTrackSrc&p=download-info/%s/2.mp3' % (time.time(), storage_dir), track_id)
+        data = self._download_json(
-        hash = hsh.hexdigest()
+        key = hashlib.md5(('XGRlBW9FXlekgbPrRHuSiA' + data['path'][1:] + data['s']).encode('utf-8')).hexdigest()
-        return 'http://%s/get-mp3/%s/%s?track-id=%s&from=service-10-track&similarities-experiment=default' % (data['host'], hash, data['ts'] + data['path'], storage[1])
+        return ('http://%s/get-mp3/%s/%s?track-id=%s&from=service-10-track&similarities-experiment=default'
-        id = matched.group('id')
+    def _get_track_info(self, track):
-        return id, data['pageData']
+
-        id, data = self._get_album_id_and_data(url)
+        track = self._download_json(
-        entries = []
+        return self._get_track_info(track)
-        }
+class YandexMusicAlbumIE(YandexMusicBaseIE):
-    _VALID_URL = r'http://music.yandex.ru/users/(?P<user_name>[^/]+)/playlists/(?P<id>\d+)'
+    _TEST = {
-        data = data['playlist']
+        album_id = self._match_id(url)
-        entries = []
+        album = self._download_json(
-            })
+        entries = [self._get_track_info(track) for track in album['volumes'][0]]
-    _VALID_URL = r'http://music.yandex.ru/album/(?P<album_id>\d+)/track/(?P<id>\d+)'
+class YandexMusicPlaylistIE(YandexMusicBaseIE):
-        'url': 'http://music.yandex.ru/album/540508/track/4878838',
+        'url': 'http://music.yandex.ru/users/music.partners/playlists/1245',
-        }
+            'id': '1245',
-        id, data = self._get_album_id_and_data(url)
+        webpage = self._download_webpage(url, playlist_id)
-                break
+        playlist = self._parse_json(
-        }
+from .yamusic import (
-__version__ = '2015.03.03.1'
+__version__ = '2015.03.09'
-        } for media in info['media']]
+        } for media in info['media'] if media.get('mediaPurpose') == 'play']
-    xpath_text,
+    xpath_text,
-            raise ExtractorError(errmsg, cause=ve)
+        bootstrapped_data = self._parse_json(self._search_regex(
-            collections = bootstrappedData['playlists']['collections']
+            collections = bootstrapped_data['playlists']['collections']
-            collections = bootstrappedData['show']['collections']
+            collections = bootstrapped_data['show']['collections']
-            show = bootstrappedData['show']
+            # Video wasn't found in the collections, let's try `slugged_video`.
-        '--dump-intermediate-pages',
+        '--dump-pages', '--dump-intermediate-pages',
-            bootstrap = base64.b64decode(node.text)
+            bootstrap = base64.b64decode(node.text.encode('ascii'))
-            metadata = base64.b64decode(metadata_node.text)
+            metadata = base64.b64decode(metadata_node.text.encode('ascii'))
-            dn = os.path.dirname(encodeFilename(filename))
+            dn = os.path.dirname(sanitize_path(encodeFilename(filename)))
-        re.sub('[/<>:"\\|\\\\?\\*]', '#', path_part)
+        re.sub('(?:[/<>:"\\|\\\\?\\*]|\.$)', '#', path_part)
-                restricted=restrict_filenames,
+                restricted=self.params.get('restrictfilenames'),
-                restricted=restrict_filenames)
+            outtmpl = sanitize_path(self.params.get('outtmpl', DEFAULT_OUTTMPL))
-        )
+        alt_filename = sanitize_path(filename)
-            stream = open(encodeFilename(filename), open_mode)
+            stream = open(encodeFilename(alt_filename), open_mode)
-    _TEST = {
+    _VALID_URL = r'(?P<url>https?://(?:www\.)?gazeta\.ru/(?:[^/]+/)?video/(?:(?:main|\d{4}/\d{2}/\d{2})/)?(?P<id>[A-Za-z0-9-_.]+)\.s?html)'
-    }
+    }, {
-            r'"preload"\s*:\s*"([^"]+)"', embed, 'encoded data')
+        player_data = self._parse_json(self._search_regex(
-            base64.b64decode(encoded_data.encode('ascii')).decode('utf-8'), video_id)
+            base64.b64decode(player_data['preload'].encode('ascii')).decode('utf-8'), video_id)
-            r'<span class="video_views">\s*([\d,\.]+)\s*plays?', webpage, 'view count', fatal=False))
+            r'<(?:li|span) class="video_views">\s*([\d,\.]+)\s*plays?', webpage, 'view count', fatal=False))
-            'comment_count': comment_count,
+    qualities,
-            'token': access_token['token'],
+            'sig': access_token['sig'].encode('utf-8'),
-            % (self._USHER_BASE, channel_id, compat_urllib_parse.urlencode(query).encode('utf-8')),
+            % (self._USHER_BASE, channel_id, compat_urllib_parse.urlencode(query)),
-                restricted=restrict_filenames,
+                restricted=self.params.get('restrictfilenames'),
-                restricted=restrict_filenames)
+            outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)
-                restricted=self.params.get('restrictfilenames'),
+                restricted=restrict_filenames,
-            outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)
+            outtmpl = sanitize_filename(
-        print(response['status'])
+        # ClipYou (Eagle.Platform) embed (custom URL)
-            r'(?s)<ol class="item-section"(.*?)</ol>', webpage, 'result HTML')
+            r'(?s)<ol[^>]+class="item-section"(.*?)</ol>', webpage, 'result HTML')
-            'md5': '392c4b85a60a90dc4792da41ce3144eb',
+            'url': 'https://www.dailymotion.com/video/x2iuewm_steam-machine-models-pricing-listed-on-steam-store-ign-news_videogames',
-                'id': 'x33vw9',
+                'id': 'x2iuewm',
-                'title': 'Tutoriel de Youtubeur"DL DES VIDEO DE YOUTUBE"',
+                'uploader': 'IGN',
-            url = 'http://player.vimeo.com/video/' + video_id
+            url = 'https://player.vimeo.com/video/' + video_id
-        token = self._search_regex(r'xsrft: \'(.*?)\'', webpage, 'login token')
+        token = self._search_regex(r'xsrft = \'(.*?)\'', webpage, 'login token')
-        post = compat_urllib_parse.urlencode(fields)
+        post = urlencode_postdata(fields)
-    _VALID_URL = r'https?://vimeo\.com/album/(?P<id>\d+)'
+    _VALID_URL = r'https://vimeo\.com/album/(?P<id>\d+)'
-        'url': 'http://vimeo.com/album/2632481',
+        'url': 'https://vimeo.com/album/2632481',
-        return self._extract_videos(album_id, 'http://vimeo.com/album/%s' % album_id)
+        return self._extract_videos(album_id, 'https://vimeo.com/album/%s' % album_id)
-        data = compat_urllib_parse.urlencode({
+        token = self._search_regex(r'xsrft = \'(.*?)\'', webpage, 'login token')
-        password_request = compat_urllib_request.Request(pass_url + '/password', data)
+        if url.startswith('http://'):
-
+    unified_strdate,
-        mobj = re.search(r'<meta itemprop="dateCreated" content="(\d{4})-(\d{2})-(\d{2})T', webpage)
+        mobj = re.search(r'<time[^>]+datetime="([^"]+)"', webpage)
-            video_upload_date = mobj.group(1) + mobj.group(2) + mobj.group(3)
+            video_upload_date = unified_strdate(mobj.group(1))
-            'format_id': '-'.join(filter(None, [m3u8_id, 'm3u8-meta'])),
+            'format_id': '-'.join(filter(None, [m3u8_id, 'meta'])),
-        'md5': '0238ceec479c654e8c2f1223755bf3e9',
+        'url': 'http://mymedia.yam.com/m/3599430',
-            'id': 'pJ2Deys283c',
+            'id': 'CNpEoQlrIgA',
-            'upload_date': '20150202',
+            'upload_date': '20150306',
-            'description': 'md5:f5cc72f0baf259a70fb731654b0d2eff',
+            'description': 'md5:11e2e405311633ace874f2e6226c8b17',
-            'title': 'å¤å©çæ¾æ¹ç£KTV-æ½å®é¦',
+            'title': '20090412é½æå±±äºå­åª-1',
-                        m3u8_id, 'm3u8-%d' % (tbr if tbr else len(formats))]))
+                format_id = []
-                    'format_id': format_id,
+                    'format_id': '-'.join(format_id),
-        formats = sorted(formats, key=_sort_source)
+        self._prefer_source(formats)
-                    'format_id': '-'.join(filter(None, [m3u8_id, 'm3u8-%d' % (tbr if tbr else len(formats))])),
+                    'format_id': format_id,
-                video_url = '%s%s?key=%s' % (part_info[0], su[i], part_info[3])
+                video_url = url_sanitize_consecutive_slashes(
-
+        video_id = self._match_id(url)
-        video_url = self._html_search_regex(r'<source src="([^"]+)"', webpage, 'video URL')
+        video_url = self._html_search_regex(
-from ..compat import compat_urllib_request
+from ..compat import (
-from .common import compat_str
+from ..utils import compat_str
-    _TEST = {
+    _TESTS = [{
-        'md5': 'bde8d9a6ffd82c63a1eefaef4eeefec7',
+        'md5': '29175c8cadd8b5cc4055001e85d6b372',
-    }
+        'params': {
-                'Downloading JSON data for %s' % vid_id)
+            req = compat_urllib_request.Request(base_data_url + vid_id)
-    compat_urllib_parse_urlparse,
+    compat_parse_qs,
-    compat_urllib_parse,
+    qualities,
-        'md5': '1fb9228f5e3332ec8c057d6ac36f33e0',
+        'md5': '344d0c6d50e2f16b06e49ca011d8ac69',
-        format = "-".join(format)
+        flash_vars = compat_parse_qs(self._search_regex(
-            'format_id': format,
+from .playwire import PlaywireIE
-        })
+                    'rtmp_real_time': True,
-            'url': 'http://www.tv3play.lt/programos/moterys-meluoja-geriau/409229?autostart=true',
+            'url': 'http://play.tv3.lt/programos/moterys-meluoja-geriau/409229?autostart=true',
-            r'var videoJason = (.*)[,;]',
+            [r'var\s+videoJa?son\s*=\s*({.+?});',
-            self._downloader.params.get('cn_verification_proxy'))
+        cn_verification_proxy = self._downloader.params.get('cn_verification_proxy')
-            r'var currentVideo = new Video\((.*)\)[,;]',
+            r'var videoJason = (.*)[,;]',
-__version__ = '2015.03.03'
+__version__ = '2015.03.03.1'
-            https_handler, proxy_handler, cookie_processor, ydlh)
+            proxy_handler, https_handler, cookie_processor, ydlh)
-            'cn_verification_proxy': 'proxy.uku.im:8888'
+            'cn_verification_proxy': 'http://proxy.uku.im:8888'
-            'Ytdl-Request-Proxy',
+            'Ytdl-request-proxy',
-        req_proxy = req.headers.get('Ytdl-Request-Proxy')
+        req_proxy = req.headers.get('Ytdl-request-proxy')
-            del req.headers['Ytdl-Request-Proxy']
+            del req.headers['Ytdl-request-proxy']
-__version__ = '2015.02.28'
+__version__ = '2015.03.03'
-        proxy_handler = compat_urllib_request.ProxyHandler(proxies)
+        proxy_handler = PerRequestProxyHandler(proxies)
-    compat_urlparse,
+    compat_urllib_request,
-    # This video is available only in Mainland China
+        play_json_req = compat_urllib_request.Request(
-            'http://api.letv.com/mms/out/video/playJson?' + compat_urllib_parse.urlencode(params),
+            play_json_req,
-                    'ext': determine_ext(dispatch[format_id][1])
+                    'ext': determine_ext(dispatch[format_id][1]),
-            r'åå¸æ¶é´&nbsp;([^<>]+) ', page, 'publish time', fatal=False),
+            r'åå¸æ¶é´&nbsp;([^<>]+) ', page, 'publish time', default=None),
-        } for e in doc.findall('./channel/item')]
+        entries = []
-    the FileDownloader:
+    the downloader (see youtube_dl/downloader/common.py):
-    xattr_set_filesize.
+    xattr_set_filesize, external_downloader_args.
-            '--min-split-size', '1M', '--max-connection-per-server', '4']
+        cmd = [self.exe, '-c']
-        help='(experimental) Use the specified external downloader. '
+        help='Use the specified external downloader. '
-                    'ext': ext,
+                    'ext': 'flv',
-            result['formats'] = formats
+        self._check_formats(formats, track_id)
-class LyndaIE(InfoExtractor):
+class LyndaBaseIE(InfoExtractor):
-    _LOGIN_URL = 'https://www.lynda.com/login/login.aspx'
+    _VALID_URL = r'https?://www\.lynda\.com/(?:[^/]+/[^/]+/\d+|player/embed)/(?P<id>\d+)'
-        video_id = mobj.group(1)
+        video_id = self._match_id(url)
-                                      'Downloading video JSON')
+        page = self._download_webpage(
-            raise ExtractorError('lynda returned error: %s' % video_json['Message'], expected=True)
+            raise ExtractorError(
-                'Video %s is only available for members. ' % video_id + self.ACCOUNT_CREDENTIALS_HINT, expected=True)
+                'Video %s is only available for members. '
-class LyndaCourseIE(InfoExtractor):
+class LyndaCourseIE(LyndaBaseIE):
-                                      course_id, 'Downloading course JSON')
+        page = self._download_webpage(
-            raise ExtractorError('Course %s does not exist' % course_id, expected=True)
+            raise ExtractorError(
-                if username is None and video['HasAccess'] is False:
+                if video['HasAccess'] is False:
-                                            % unaccessible_videos + LyndaIE.ACCOUNT_CREDENTIALS_HINT)
+            self._downloader.report_warning(
-                            'Lynda')
+            self.url_result(
-            srt += '%s\r\n%s --> %s\r\n%s' % (str(pos), appear_time, disappear_time, text)
+            text = seq_current['Caption'].strip()
-                'uploader': 're:Noize MC.*',
+                'uploader': 're:(?:Noize MC|Alexander Ilyashenko).*',
-        info_url = 'http://vk.com/al_video.php?act=show&al=1&video=%s' % video_id
+        info_url = 'http://vk.com/al_video.php?act=show&al=1&module=video&video=%s' % video_id
-            'Video %s does not exist.'
+            'Video %s does not exist.',
-            info = json.load(f)
+        with contextlib.closing(fileinput.FileInput(
-                width = get_term_width()
+                width = compat_get_terminal_size().columns
-    columns = get_term_width()
+    columns = compat_get_terminal_size().columns
-__version__ = '2015.02.26.2'
+__version__ = '2015.02.28'
-        }
+    parse_duration,
-        response = super(TwitchBaseIE, self)._download_json(url, video_id, note)
+        headers = {
-import re
+from ..utils import (
-    _VALID_URL = r'https?://www.puls4.com/video/.+?/play/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?puls4\.com/video/[^/]+/play/(?P<id>[0-9]+)'
-        {
+            'title': 'Pro und Contra vom 23.02.2015',
-    ]
+            'title': 'Lucky Fritz',
-                                           webpage, 'fsk_button', default=None)
+        error_message = self._html_search_regex(
-        }
+        player = self._search_regex(
-        }
+import re
-    _TEST = {
+    IE_DESC = 'SVT Play and Ãppet arkiv'
-        'md5': 'f4a184968bc9c802a9b41316657aaa80',
+        'md5': 'ade3def0643fa1c40587a422f98edfd9',
-            'ext': 'mp4',
+            'ext': 'flv',
-    }
+    }, {
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            'http://www.svtplay.se/video/%s?output=json' % video_id, video_id)
+            'http://www.%s.se/video/%s?output=json' % (host, video_id), video_id)
-            if determine_ext(vurl) == 'm3u8':
+            ext = determine_ext(vurl)
-    _VALID_URL = r'https?://(?:www\.)?oppetarkiv.se/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?oppetarkiv\.se/video/(?P<id>[0-9]+)'
-        'md5': '7b95ca9bedeead63012b2d7c3992c28f',
+        'md5': '5c1eb616e59f733d4af77edc5177d2fe',
-            'ext': 'mp4',
+            'ext': 'flv',
-            if determine_ext(vurl) == 'm3u8':
+            ext = determine_ext(vurl)
-                    except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
+                        sub_data = ie._download_webpage(
-                                            (sub_lang, compat_str(err)))
+                                            (sub_lang, compat_str(err.cause)))
-       https?://(:?www\.)?kaltura\.com/index\.php/kwidget/(?:[^/]+/)*?wid/_
+       https?://(:?(?:www|cdnapisec)\.)?kaltura\.com/index\.php/kwidget/(?:[^/]+/)*?wid/_
-            text = seq_current['Caption'].strip()
+            text = seq_current['Caption'].lstrip()
-    _VALID_URL = r'https?://www\.lynda\.com/[^/]+/[^/]+/\d+/(\d+)-\d\.html'
+    _VALID_URL = r'https?://www\.lynda\.com/(?:[^/]+/[^/]+/\d+|player/embed)/(\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    struct_unpack,
+    float_or_none,
-            text = seq_current['Caption']
+            text = seq_current['Caption'].strip()
-        'md5': '2cdbb3ae75f7fb3519821507d2fb3c15',
+        'md5': '3adcbdb3dcc02d647539e53f284ba171',
-            'upload_date': '19811216',
+            'upload_date': '20131219',
-        }
+        wid = self._search_regex(r'/wid/_([0-9]+)/', webpage, 'wid')
-            'ext': 'mp4',
+            '_type': 'url_transparent',
-            'duration': duration,
+from .kaltura import KalturaIE
-    _VALID_URL = r'https?://(www\.)?mpora\.(?:com|de)/videos/(?P<id>[^?#/]+)'
+    _VALID_URL = r'https?://(?:www\.)?mpora\.(?:com|de)/videos/(?P<id>[^?#/]+)'
-            r"new FM\.Player\('[^']+',\s*(\{.*?)\).player;", webpage, 'json')
+            [r"new FM\.Player\('[^']+',\s*(\{.*?)\).player;",
-        title = og_title.replace(' - Video bei GameStar.de', '').strip()
+        title = re.sub(r'\s*- Video (bei|-) GameStar\.de$', '', og_title)
-                'Live streams are not supported by the f4m downloader.')
+            subtitles = self._extract_subtitles(cdoc, guid)
-__version__ = '2015.02.26.1'
+__version__ = '2015.02.26.2'
-        webpage = self._download_webpage(url, video_id)
+        webpage_req = compat_urllib_request.Request(url)
-        def _add_format(name, cfgurl, quality):
+        def _add_format(name, cfg_url, quality):
-                cfgurl, video_id,
+                cfg_req, video_id,
-__version__ = '2015.02.26'
+__version__ = '2015.02.26.1'
-        basic_args = ['rtmpdump', '--verbose', '-r', url, '-o', tmpfilename]
+        basic_args = [
-            fmts, rtmp_count = self._parse_smil_video(video, base, rtmp_count)
+            fmts, rtmp_count = self._parse_smil_video(video, video_id, base, rtmp_count)
-                fmts, rtmp_count = self._parse_smil_video(video, base, rtmp_count)
+                fmts, rtmp_count = self._parse_smil_video(video, video_id, base, rtmp_count)
-    def _parse_smil_video(self, video, base, rtmp_count):
+    def _parse_smil_video(self, video, video_id, base, rtmp_count):
-import os.path
+import datetime
-from ..utils import (ExtractorError, parse_iso8601)
+from ..compat import (
-    # ror() and calcTimeKey() are reversed from a embedded swf file in KLetvPlayer.swf
+    # ror() and calc_time_key() are reversed from a embedded swf file in KLetvPlayer.swf
-    def calcTimeKey(self, param1):
+    def calc_time_key(self, param1):
-            'tkey': self.calcTimeKey(int(time.time())),
+            'tkey': self.calc_time_key(int(time.time())),
-                    'ext': os.path.splitext(dispatch[format_id][1])[1][1:]
+                    'ext': determine_ext(dispatch[format_id][1])
-from ..utils import parse_iso8601
+from ..utils import (
-            formats.append(fmt)
+        formats = [{
-        duration_match = re.search(r'Duration:(?: (?P<H>\d+) hours?)?(?: (?P<M>\d+) minutes?)?', webpage)
+        view_count = int_or_none(self._html_search_regex(
-            'thumbnail': metadata['playlist'][0]['image'],
+            'thumbnail': metadata['playlist'][0].get('image'),
-            'timestamp': parse_iso8601(self._html_search_regex(r'<time datetime="(.*?)"', webpage, 'timestamp')),
+            'timestamp': timestamp,
-            'view_count': int(self._html_search_regex(r'Views since archived: ([0-9]+)', webpage, 'view count')),
+            'duration': duration,
-            })
+            for p in playlist:
-        return {
+        res = {
-__version__ = '2015.02.24.2'
+__version__ = '2015.02.26'
-    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0 (Chrome)',
+    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20150101 Firefox/20.0 (Chrome)',
-                <param\s+name="flashvars"\s+value="config=|
+                <param\s+name="flashvars".*?\s+value="config=|
-            ([^"&]+)
+            (https?://[^"&]+)
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-    _VALID_URL = r'https?://www\.telecinco\.es/[^/]+/[^/]+/[^/]+/(?P<id>.*?)\.html'
+    _VALID_URL = r'https?://www\.telecinco\.es/[^/]+/[^/]+/(?:[^/]+/)?(?P<id>.*?)\.html'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                        'url': 'rtmpe://fmspay-fra2.rtl.de/' + mobj.group('hoster'),
+                        'url': 'rtmpe://fms.rtl.de/' + mobj.group('hoster'),
-                e['title'] = '%s (%d)' % (e['title'], num)
+                # 'url' results don't have a title
-            frags_filenames.append(frag_filename)
+            try:
-                self.to_screen('Updated available fragments: %d' % len(fragments_list))
+                total_frags += len(fragments_list)
-        self.read(1)
+        flags = self.read_unsigned_char()
-            bootstrap = base64.b64decode(bootstrap_node.text)
+        boot_info, bootstrap_url = self._parse_bootstrap_node(bootstrap_node, base_url)
-        write_metadata_tag(dest_stream, metadata)
+        if not live:
-        for (seg_i, frag_i) in fragments_list:
+        while fragments_list:
-                })
+        if smil.findall('./body/seq/video'):
-        redirect_url = 'http://www.eporner.com/config5/%s/%s' % (video_id, display_id)
+        redirect_url = 'http://www.eporner.com/config5/%s' % video_id
-            'age_limit': self._rta_search(webpage),
+            'age_limit': 18,
-        'url': 'http://www.letv.com/ptv/vplay/1118082.html',
+        'url': 'http://www.letv.com/ptv/vplay/1415246.html',
-            'id': '1118082',
+            'id': '1415246',
-        }
+            'title': 'ç¾äººå¤©ä¸01',
-        title = self._html_search_meta('keywords', page, fatal=False).split('ï¼')[0]
+        title = self._html_search_meta('keywords', page,
-        'playlist_count': 96
+        # This playlist contains some extra videos other than the drama itself
-            # the playlist title
+            # The title should be "å²èéæ¥", but I can't find a simple way to
-        redirect_url = 'http://www.eporner.com/config5/%s/%s' % (video_id, redirect_code)
+        redirect_url = 'http://www.eporner.com/config5/%s/%s' % (video_id, display_id)
-from .letv import LetvIE
+from .letv import (
-    _VALID_URL = r'http://www.letv.com/ptv/vplay/(?P<id>\d+).html'
+    _VALID_URL = r'http://www\.letv\.com/ptv/vplay/(?P<id>\d+).html'
-        captions = self._download_xml(url, video_id, 'Downloading subtitles')
+        captions = self._download_xml(
-            srt += '%s\r\n%s --> %s\r\n%s\r\n\r\n' % (str(pos), starttime, endtime, text)
+            srt += '%s\r\n%s --> %s\r\n%s\r\n\r\n' % (compat_str(pos), starttime, endtime, p.text)
-__version__ = '2015.02.24.1'
+__version__ = '2015.02.24.2'
-            r'<param\s+name="flashvars"\s+value="config=([^"&]+)', webpage, 'config URL'))
+            r'''(?x)
-__version__ = '2015.02.24'
+__version__ = '2015.02.24.1'
-        return dict((s['lang'], [{'ext': 'vtt', 'url': s['src']}])
+        return dict(
-__version__ = '2015.02.23.1'
+__version__ = '2015.02.24'
-    _VALID_URL = r'https?://www\.bloomberg\.com/video/(?P<name>.+?)\.html'
+    _VALID_URL = r'https?://www\.bloomberg\.com/video/(?P<id>.+?)\.html'
-        name = mobj.group('name')
+        name = self._match_id(url)
-                            (?:PL|LL|EC|UU|FL|RD)?[0-9A-Za-z-_]{10,}
+                            (?:PL|LL|EC|UU|FL|RD|UL)?[0-9A-Za-z-_]{10,}
-                        ((?:PL|LL|EC|UU|FL|RD)[0-9A-Za-z-_]{10,})
+                        ((?:PL|LL|EC|UU|FL|RD|UL)[0-9A-Za-z-_]{10,})
-        # The mixes are generated from a a single video
+        # The mixes are generated from a single video
-        if playlist_id.startswith('RD'):
+        if playlist_id.startswith('RD') or playlist_id.startswith('UL'):
-            'partnerid\s*:\s*"([^"]+)"', iframe, 'partner id')
+            r'partnerid\s*:\s*"([^"]+)"', iframe, 'partner id')
-from ..utils import ExtractorError
+from ..utils import (
-        'url': 'http://www.laola1.tv/de-de/live/bwf-bitburger-open-grand-prix-gold-court-1/250019.html',
+        'url': 'http://www.laola1.tv/de-de/video/straubing-tigers-koelner-haie/227883.html',
-            'id': '250019',
+            'id': '227883',
-            'is_live': True,
+            'title': 'Straubing Tigers - KÃ¶lner Haie',
-                       video_id, portal, lang))
+                   'play=%s&partner=%s&portal=%s&v5ident=&lang=%s' % (
-        uploader = hd_doc.find('.//video/meta_organistation').text
+        title = xpath_text(hd_doc, './/video/title', fatal=True)
-            raise ExtractorError('Token error: ' % token_attrib.get('comment'))
+        if token_attrib.get('auth') in ('blocked', 'restricted'):
-            'is_live': True,
+            'is_live': is_live,
-            raise ExtractorError('Cannot find video URL')
+
-            'url': video_url,
+            'formats': formats,
-__version__ = '2015.02.23'
+__version__ = '2015.02.23.1'
-            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % 'fms.digitallyspeaking.com/cfx/st',
+            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % akamai_url,
-            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % 'fms.digitallyspeaking.com/cfx/st',
+            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % akamai_url,
-__version__ = '2015.02.21'
+__version__ = '2015.02.23'
-    _VALID_URL = r'https?://(?:www\.)?soundgasm\.net/u/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?soundgasm\.net/u/(?P<id>[^/]+)/?(?:\#.*)?$'
-    _VALID_URL = r'https?://(?:www\.)?soundgasm\.net/u/(?P<id>[0-9a-zA-Z_\-]+)/?$'
+    _VALID_URL = r'https?://(?:www\.)?soundgasm\.net/u/(?P<id>[^/]+)'
-        }
+        },
-            })
+        webpage = self._download_webpage(url, profile_id)
-        }
+        entries = [
-        return info_dict;
+        return self.playlist_result(entries, profile_id)
-from .chirbit import ChirbitIE, ChirbitProfileIE
+from .chirbit import (
-from ..utils import clean_html
+from ..utils import (
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?chirb\.it/(?:(?:wp|pl)/|fb_chirbit_player\.swf\?key=)?(?P<id>[\da-zA-Z]+)'
-            'url': 'http://audio.chirbit.com/kukushtv_1423231243.mp3'
+            'duration': 52,
-    }
+    }, {
-        webpage = self._download_webpage(url, audio_linkid)
+        audio_id = self._match_id(url)
-        audio_url = 'http://audio.chirbit.com/' + audio_id + '.mp3';
+        title = self._search_regex(
-            'url': audio_url
+            'id': audio_id,
-    _VALID_URL = r'https?://(?:www\.)?chirbit.com/(?P<id>[^/]+)/?$'
+    _VALID_URL = r'https?://(?:www\.)?chirbit.com/(?:rss/)?(?P<id>[^/]+)'
-        }
+            'id': 'ScarletBeauty',
-        oldestentry = clean_html(oldest_page_entries[-1]);
+        rss = self._download_xml(
-            n += 1
+        entries = [
-        }
+        title = rss.find('./channel/title').text
-        return info_dict;
+        return self.playlist_result(entries, profile_id, title)
-from .soundgasm import SoundgasmIE
+from .soundgasm import (
-    _VALID_URL = r'https?://(?:www\.)?chirbit.com/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?chirbit.com/(?P<id>[^/]+)/?$'
-            'preference': -1,
+            'preference': preference - 1 if preference else -1,
-            r"<h1 class='headline'><a href='/videos/view/(.*?)'",
+            r"<h1\s+class='headline'>\s*<a\s+href='/videos/view/(.*?)'",
-            r"<h1 class='headline'>(.*?)</a>",
+            r"<h1\s+class='headline'>(.*?)</a>",
-            r'<param name="flashvars" value="config=([^"&]+)', webpage, 'config URL'))
+            r'<param\s+name="flashvars"\s+value="config=([^"&]+)', webpage, 'config URL'))
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'https?://(?:www\.)?trailers\.apple\.com/trailers/(?P<company>[^/]+)/(?P<movie>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?trailers\.apple\.com/(?:trailers|ca)/(?P<company>[^/]+)/(?P<movie>[^/]+)'
-        self.assertEqual(md5(subtitles['en']), 'b0b781eeb45efd3f6398a925b259150b')
+        self.assertEqual(md5(subtitles['en']), '53cb083a5914b2d84ef1ab67b880d18a')
-
+        self.assertEqual(md5(subtitles['en']), '4cd9278a35ba2305f47354ee13472260')
-
+        self.assertEqual(md5(subtitles['en']), '976553874490cba125086bbfea3ff76f')
-        for lang in langs:
+        self.assertEqual(md5(subtitles['en']), '4262c1665ff928a2dada178f62cb8d14')
-
+        self.assertEqual(md5(subtitles['en']), '8062383cf4dec168fc40a088aa6d5888')
-
+        result = get_info({'writeautomaticsub': True, 'subtitleslangs': ['es', 'pt']})
-    def process_subtitles(self, video_id, available_subs, available_autocaps):
+    def process_subtitles(self, video_id, normal_subtitles, automatic_captions):
-            for lang, cap_info in available_autocaps.items():
+        available_subs = {}
-            'subtitles': video_subtitles,
+            'subtitles': self._get_subtitles(video_id, talk_info),
-        self.assertEqual(len(subtitles), 0)
+        self.assertFalse(subtitles)
-        self.assertEqual(len(subtitles), 0)
+        self.assertFalse(subtitles)
-        self.assertEqual(len(subtitles), 0)
+        self.assertFalse(subtitles)
-        self.assertEqual(len(subtitles), 0)
+        self.assertFalse(subtitles)
-        self.assertEqual(len(subtitles), 0)
+        self.assertFalse(subtitles)
-            return available_subs
+        if (not self.params.get('writesubtitles') and not
-__version__ = '2015.02.20'
+__version__ = '2015.02.21'
-                "title": "Louis C.K. Interview Pt. 1 11/3/11",
+                'description': 'Louis C.K. got starstruck by George W. Bush, so what? Part one.',
-        video_id = mobj.group("video_id")
+        video_id = mobj.group('video_id')
-            data_url, display_id, 'Downloading data webpage')
+        embed_url = 'http://teamcoco.com/embed/v/%s' % video_id
-            m_format = re.search(r'(\d+(k|p))\.mp4', file_url)
+        get_quality = qualities(['500k', '480p', '1000k', '720p', '1080p'])
-                format_id = filed.attrib['bitrate']
+                format_id = filed['bitrate']
-                if filed.attrib['bitrate'].isdigit()
+                int(filed['bitrate'])
-                'url': file_url,
+                'url': filed['url'],
-                'quality': quality,
+                'quality': get_quality(format_id),
-            'description': self._og_search_description(webpage),
+            'title': data['title'],
-            'url': 'rtmp://' + akami_url + '/' + slide_video_path,
+            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % 'fms.digitallyspeaking.com/cfx/st',
-            'url': 'rtmp://' + akami_url + '/' + speaker_video_path,
+            'url': 'rtmp://%s/ondemand?ovpfv=1.1' % 'fms.digitallyspeaking.com/cfx/st',
-    _VALID_URL = r'https?://(?:www\.)?zapiks\.fr/(?:(?P<display_id>.+?)\.html|index\.php\?.*\bmedia_id=(?P<id>\d+))'
+    _VALID_URL = r'https?://(?:www\.)?zapiks\.(?:fr|com)/(?:(?:[a-z]{2}/)?(?P<display_id>.+?)\.html|index\.php\?.*\bmedia_id=(?P<id>\d+))'
-        }
+        },
-            # Use mvod.akcdn instead of flash.akamaihd.multimedia.cdn to get
+            # Use mvod1.akcdn instead of flash.akamaihd.multimedia.cdn to get
-            )
+            video_url = compat_urlparse.urljoin(
-                   or test['info_dict']['age_limit'] != 18):
+    if RESULT and ('info_dict' not in test or 'age_limit' not in test['info_dict'] or
-                         and test['info_dict']['age_limit'] == 18):
+    elif not RESULT and ('info_dict' in test and 'age_limit' in test['info_dict'] and
-                or os.path.getmtime(swf_file) < os.path.getmtime(as_file)):
+        if ((not os.path.exists(swf_file)) or
-                and not params.get('restrictfilenames', False)):
+                sys.getfilesystemencoding() in ['ascii', 'ANSI_X3.4-1968'] and
-                and self.params.get('max_downloads') != 1):
+                '%' not in outtmpl and
-               or DEFAULT_OUTTMPL)
+    outtmpl = ((opts.outtmpl is not None and opts.outtmpl) or
-            and os.path.exists(encodeFilename(filename))
+            self.params.get('nooverwrites', False) and
-            and not self.params.get('nopart', False)
+            self.params.get('continuedl', False) and
-                / (state['frag_index'] + 1) * total_frags)
+                (state['downloaded_bytes'] + frag_total_bytes) /
-            or self._search_regex(r'Runtime:\s*(\d{2}:\d{2}:\d{2})', webpage, 'duration'))
+            self._html_search_meta('duration', webpage, 'duration') or
-                                + (media_el.attrib.get('href') or media_el.attrib.get('url')))
+                manifest_url = ('/'.join(manifest_url.split('/')[:-1]) + '/' +
-                    + video_id)
+        json_url = (
-                or GetConsoleMode(handle, ctypes.byref(ctypes.wintypes.DWORD())) == 0)
+        return ((GetFileType(handle) & ~FILE_TYPE_REMOTE) != FILE_TYPE_CHAR or
-            headers['Cookie'] = '%s_password=%s' % (video_id, hashlib.md5(password).hexdigest())
+            headers['Cookie'] = '%s_password=%s' % (
-__version__ = '2015.02.19.3'
+__version__ = '2015.02.20'
-            r'config=(.*)$', player_url, 'config URL'))
+        config_url = compat_urllib_parse.unquote(self._html_search_regex(
-            'player_url': player_url,
+    }, {
-                ext_url = talk_info['external']['uri']
+        external = talk_info.get('external')
-                'url': ext_url,
+                'url': ext_url or external['uri'],
-                'url': talk_info['external']['uri'],
+                'url': ext_url,
-from .chirbit import ChirbitIE
+from .chirbit import ChirbitIE, ChirbitProfileIE
-            'description': 'The Internet\'s visual storytelling community. Explore, share, and discuss the best visual stories the Internet has to offer.',
+            'title': 're:Imgur GIF$|MRW gifv is up and running without any bugs$',
-            'description': 'The Internet\'s visual storytelling community. Explore, share, and discuss the best visual stories the Internet has to offer.',
+            'title': 're:Imgur GIF$|MRW gifv is up and running without any bugs$',
-from ..utils import remove_start
+from ..utils import (
-    _VALID_URL = r'^(?:https?://(?:www\.)blinkx\.com/#?ce/|blinkx:)(?P<id>[^?]+)'
+    _VALID_URL = r'(?:https?://(?:www\.)blinkx\.com/#?ce/|blinkx:)(?P<id>[^?]+)'
-        'md5': '2e9a07364af40163a908edbf10bb2492',
+        'url': 'http://www.blinkx.com/ce/Da0Gw3xc5ucpNduzLuDDlv4WC9PuI4fDi1-t6Y3LyfdY2SZS5Urbvn-UPJvrvbo8LTKTc67Wu2rPKSQDJyZeeORCR8bYkhs8lI7eqddznH2ofh5WEEdjYXnoRtj7ByQwt7atMErmXIeYKPsSDuMAAqJDlQZ-3Ff4HJVeH_s3Gh8oQ',
-            'id': '8aQUy7GV',
+            'id': 'Da0Gw3xc',
-            }],
+            'title': 'No Daily Show for John Oliver; HBO Show Renewed - IGN News',
-        video_id = m.group('id')
+    def _real_extract(self, url):
-                tbr = (int(m['vbr']) + int(m['abr'])) // 1000
+                vbr = int_or_none(m.get('vbr') or m.get('vbitrate'), 1000)
-                    'vbr': int(m['vbr']) // 1000,
+                    'abr': abr,
-                    'height': int(m['h']),
+                    'width': int_or_none(m.get('w')),
-__version__ = '2015.02.19.2'
+__version__ = '2015.02.19.3'
-        if mobj.group('config'):
+        if smuggled_data.get('force_smil_url', False):
-            r'(?s)From:&nbsp;.+?<(?:a href="/users/|a href="/channels/|<span class="username)[^>]+>(.+?)<',
+            r'(?s)From:&nbsp;.+?<(?:a href="/users/|a href="/channels/|span class="username)[^>]+>(.+?)<',
-from .pornhub import PornHubIE
+from .pornhub import (
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class BBCCoUkIE(SubtitlesInfoExtractor):
+class BBCCoUkIE(InfoExtractor):
-    def _extract_captions(self, media, programme_id):
+    def _get_subtitles(self, media, programme_id):
-            subtitles[lang] = srt
+                srt += '%s\r\n%s --> %s\r\n%s\r\n\r\n' % (str(pos), p.get('begin'), p.get('end'), _extract_text(p))
-                subtitles = self._extract_captions(media, programme_id)
+                subtitles = self.extract_subtitles(media, programme_id)
-            'url': 'http://www.nbc.com/chicago-fire/video/i-am-a-firefighter/2734188',
+            'url': 'http://www.nbc.com/the-tonight-show/segments/112966',
-                'id': 'bTmnLCvIbaaH',
+                'id': 'c9xnCo0YPOPH',
-                'description': 'An emergency puts Dawson\'sf irefighter skills to the ultimate test in this four-part digital series.',
+                'title': 'Jimmy Fallon Surprises Fans at Ben & Jerry\'s',
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class ThePlatformIE(SubtitlesInfoExtractor):
+class ThePlatformIE(InfoExtractor):
-        subtitles = self.extract_subtitles(video_id, subtitles)
+                lang, src, mime = caption.get('lang', 'en'), caption.get('src'), caption.get('type')
-    str_or_none,
+
-        video_elements = str_or_none(self._search_regex(
+        video_elements = self._search_regex(
-            webpage, 'video elements', fatal=False))
+            webpage, 'video elements', default=None)
-                'No sources found for video %s' % video_id, expected=True)
+                'No sources found for video %s. Maybe an image?' % video_id,
-        video_elements = self._search_regex(
+        video_elements = str_or_none(self._search_regex(
-            webpage, 'video elements')
+            webpage, 'video elements', fatal=False))
-    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?P<id>[a-zA-Z0-9]+)(?:\.)?(?:mp4|gifv)?'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?P<id>[a-zA-Z0-9]+)(?:\.mp4|\.gifv)?'
-    _VALID_URL = r'(?x)https?://(?:www\.)?theonion\.com/video/[^,]+,(?P<article_id>[0-9]+)/?'
+    _VALID_URL = r'https?://(?:www\.)?theonion\.com/video/[^,]+,(?P<id>[0-9]+)/?'
-        webpage = self._download_webpage(url, article_id)
+        display_id = self._match_id(url)
-                    self._extract_m3u8_formats(src, video_id, preference=-1))
+                    self._extract_m3u8_formats(src, display_id, preference=-1))
-
+            'display_id': display_id,
-    _VALID_URL = r'https?://i\.imgur\.com/(?P<id>[a-zA-Z0-9]+)\.(?:mp4|gifv)'
+    _VALID_URL = r'https?://(?:i\.)?imgur\.com/(?P<id>[a-zA-Z0-9]+)(?:\.)?(?:mp4|gifv)?'
-            r'isGreatLifeStory\s*=\s*(true|false)', webpage, 'great life story')
+        embed_params = [s.strip(" \r\n\t'") for s in self._search_regex(
-            r'\.duration\((\d+)\)', webpage, 'duration', fatal=False))
+        duration = int_or_none(story_duration)
-            "hash": confirm_hash,
+            "hash": confirm_hash.encode('utf-8'),
-            webpage, 'thumbnail')
+            webpage, 'thumbnail', default=None)
-                'upload_date': '20150204',
+                'upload_date': '20150212',
-__version__ = '2015.02.19.1'
+__version__ = '2015.02.19.2'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-__version__ = '2015.02.19'
+__version__ = '2015.02.19.1'
-
+        {
-    _VALID_URL = r'https?://(?:www\.)?patreon\.com/creation\?hid=(.+)'
+    _VALID_URL = r'https?://(?:www\.)?patreon\.com/creation\?hid=(?P<id>[^&#]+)'
-
+        video_id = self._match_id(url)
-            playlist_js = self._search_regex(
+            playlist = self._parse_json(self._search_regex(
-            playlist = json.loads(playlist_json)
+                webpage, 'playlist JSON'),
-__version__ = '2015.02.18.1'
+__version__ = '2015.02.19'
-    return getheader('Content-Type').split("/")[1]
+    return mimetype2ext(getheader('Content-Type'))
-            line(f, idlen) for f in formats
+        table = [
-            formats_s[-1] += (' ' if self._format_note(formats[-1]) else '') + '(best)'
+            table[-1][-1] += (' ' if table[-1][-1] else '') + '(best)'
-            'resolution': 'resolution', 'format_note': 'note'}, idlen=idlen)
+        header_line = ['format code', 'extension', 'resolution', 'note']
-            (info_dict['id'], header_line, '\n'.join(formats_s)))
+            '[info] Available formats for %s:\n%s' %
-        '(?:[^'\\]*(?:\\\\|\\')?)*'|
+        "(?:[^"\\]*(?:\\\\|\\['"nu]))*[^"\\]*"|
-            raise ExtractorError('This video is protected by a password, use the --video-password option')
+            raise ExtractorError('This video is protected by a password, use the --video-password option', expected=True)
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class VikiIE(SubtitlesInfoExtractor):
+class VikiIE(InfoExtractor):
-    def _get_available_subtitles(self, video_id, info_webpage):
+    def _get_subtitles(self, video_id, info_webpage):
-        for sturl_html in re.findall(r'<track src="([^"]+)"/>', info_webpage):
+        for sturl_html in re.findall(r'<track src="([^"]+)"', info_webpage):
-            res[m.group('lang')] = sturl
+            res[m.group('lang')] = [{
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class RaiIE(SubtitlesInfoExtractor):
+class RaiIE(InfoExtractor):
-            subtitles = self.extract_subtitles(video_id, page)
+        subtitles = self.extract_subtitles(video_id, url)
-    def _get_available_subtitles(self, video_id, webpage):
+    def _get_subtitles(self, video_id, url):
-            subtitles['it'] = 'http://www.rai.tv%s' % compat_urllib_parse.quote(captions)
+            subtitles['it'] = [{
-            'md5': '4962b075c08be8690a922ee026d05e69',
+        elif isinstance(expected, compat_str) and expected.startswith('contains:'):
-            'description': 'http://www.xtube.com an ET kind of thing',
+            'description': 'contains:an ET kind of thing',
-            'creator': 'bbright',
+            'uploader_id': 'jdesai',
-        return self.playlist_result(videos, playlist_id=playlist_info['id'],
+        return self.playlist_result(videos, playlist_id='%s' % playlist_info['id'],
-class NRKTVIE(SubtitlesInfoExtractor):
+class NRKTVIE(InfoExtractor):
-    def _extract_captions(self, subtitlesurl, video_id, baseurl):
+    def _get_subtitles(self, subtitlesurl, video_id, baseurl):
-        return {lang: srt}
+        return {lang: [
-            return
+            subtitles = self.extract_subtitles(subtitles_url, video_id, baseurl)
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class MTVServicesInfoExtractor(SubtitlesInfoExtractor):
+class MTVServicesInfoExtractor(InfoExtractor):
-        return self.extract_subtitles(mtvn_id, subtitles)
+            subtitles[lang] = [{
-            return
+    NPOIE,
-class NPOBaseIE(SubtitlesInfoExtractor):
+class NPOBaseIE(InfoExtractor):
-        subtitles = self.extract_subtitles(video_id, subtitles)
+            subtitles['nl'] = [{
-class LyndaIE(SubtitlesInfoExtractor):
+class LyndaIE(InfoExtractor):
-        subtitles = self._fix_subtitles(self.extract_subtitles(video_id, page))
+        subtitles = self.extract_subtitles(video_id, page)
-            if len(subs) == 0:
+    def _fix_subtitles(self, subs):
-    def _get_available_subtitles(self, video_id, webpage):
+            seq_next = subs[pos + 1]
-        return {'en': url} if len(sub_json) > 0 else {}
+        subs = self._download_json(url, None, False)
-from .common import ExtractorError
+from .common import InfoExtractor, ExtractorError
-class DRTVIE(SubtitlesInfoExtractor):
+class DRTVIE(InfoExtractor):
-                        subtitles[LANGS.get(lang, lang)] = subs['Uri']
+                        subtitles[LANGS.get(lang, lang)] = [{'url': subs['Uri'], 'ext': 'vtt'}]
-            'subtitles': self.extract_subtitles(video_id, subtitles),
+            'subtitles': subtitles,
-__version__ = '2015.02.18'
+__version__ = '2015.02.18.1'
-        self.code = self._remove_comments(code)
+        self.code = code
-            cache_spec = [ord(c) for c in cache_res]
+        test_string = ''.join(map(compat_chr, range(len(example_sig))))
-                note='Downloading %s player %s' % (player_type, player_id),
+                note=download_note,
-                note='Downloading %s player %s' % (player_type, player_id),
+                note=download_note,
-__version__ = '2015.02.17.2'
+__version__ = '2015.02.18'
-    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<title>[^?#]+)|/?(?:$|[?#]))'
+    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<album_id>[^?#]+)|/?(?:$|[?#]))'
-        'skip': 'Bandcamp imposes download limits. See test_playlists:test_bandcamp_album for the playlist test'
+        'skip': 'Bandcamp imposes download limits.'
-        webpage = self._download_webpage(url, display_id)
+        uploader_id = mobj.group('subdomain')
-            'display_id': display_id,
+            'id': 'look-at-this-cute-dog-omg',
-                'uploader': 'Munchkin the Shih Tzu',
+                'description': 're:Â© 2014 Munchkin the',
-            '\n\'info_dict\': {\n' + info_dict_str + '}\n', out=sys.stderr)
+            '\n\'info_dict\': {\n' + info_dict_str + '},\n', out=sys.stderr)
-            info_dict_str += '\n'
+
-            return self.playlist_result(videos, info['id'], info['full_name'])
+            return self.playlist_result(
-                return self._real_extract(url)
+                return self._real_extract(
-            (name, video_id, header_line, '\n'.join(sub_lines)))
+            'Available %s for %s:' % (name, video_id))
-        return subtitles
+        if (self._downloader.params.get('writesubtitles', False) or
-        return automatic_captions
+        if (self._downloader.params.get('writeautomaticsub', False) or
-class BlipTVIE(SubtitlesInfoExtractor):
+class BlipTVIE(InfoExtractor):
-        subtitles = {}
+        subtitles_urls = {}
-                subtitles[langcode] = url
+                subtitles_urls[langcode] = url
-            return
+        subtitles = self.extract_subtitles(video_id, subtitles_urls)
-            'subtitles': video_subtitles,
+            'subtitles': subtitles,
-        return self._download_webpage(req, None, note=False)
+    def _get_subtitles(self, video_id, subtitles_urls):
-        last_media= None
+        last_media = None
-            if not proto in ['http', 'rtmp']:
+            if proto not in ['http', 'rtmp']:
-                eta = percent = None
+                eta = None
-    format_bytes,
+import errno
-            except SocketError as e:
+            except socket.error as e:
-                       * status: One of "downloading" and "finished".
+                       * status: One of "downloading", "error", or "finished".
-                       If status is one of "downloading" or "finished", the
+                       If status is one of "downloading", or "finished", the
-                       * tmpfilename: The filename we're currently writing to
+                       * total_bytes_estimate: Guess of the eventual file size,
-from __future__ import unicode_literals
+from __future__ import division, unicode_literals
-        if self.params.get('noprogress', False):
+    def report_progress(self, s):
-            percent_str = self.format_percent(percent)
+
-        speed_str = self.format_speed(speed)
+            s['_eta_str'] = 'Unknown ETA'
-        self._report_progress_status(msg)
+        if s.get('total_bytes') and s.get('downloaded_bytes') is not None:
-            self.to_screen('[download] Download completed')
+        if s.get('speed') is not None:
-                is_last_line=True)
+            if s.get('downloaded_bytes') is not None:
-from __future__ import unicode_literals
+from __future__ import division, unicode_literals
-        )
+        self.report_destination(filename)
-            'frag_counter': 0,
+            'frag_index': 0,
-            if status['status'] == 'finished':
+        def frag_progress_hook(s):
-                progress = self.calc_percent(state['frag_counter'], total_frags)
+                state['frag_index'] += 1
-                frag_downloaded_bytes = status['downloaded_bytes']
+                frag_downloaded_bytes = s['downloaded_bytes']
-                progress = self.calc_percent(state['frag_counter'], total_frags)
+                progress = self.calc_percent(state['frag_index'], total_frags)
-                                 status.get('speed'), eta)
+                state['eta'] = self.calc_eta(
-        self.report_finish(format_bytes(state['downloaded_bytes']), time.time() - start)
+        elapsed = time.time() - start
-            self.report_progress(percent, data_len_str, speed, eta)
+                'status': 'downloading',
-                'status': 'downloading',
+                'elapsed': now - start,
-        self.report_finish(data_len_str, (time.time() - start))
+
-                    speed = self.calc_speed(start, time.time(), downloaded_data_len - resume_downloaded_data_len)
+                    time_now = time.time()
-                    cursor_in_new_line = False
+                        'status': 'downloading',
-                        'total_bytes': data_len,
+                        'total_bytes_estimate': data_len,
-                        'status': 'downloading',
+                        'elapsed': time_now - start,
-                        cursor_in_new_line = False
+                            'elapsed': time_now - start,
-        'md5': '3b4cdd011bc59174596b6145cda474a4',
+            'is_live': True,
-
+        jscode = self._search_regex(
-
+        broadcast = self._parse_json(jscode, radio_id)
-        thumbnail = broadcast.get('picture4Url') or broadcast.get('picture4TransUrl')
+        thumbnail = broadcast.get('picture4Url') or broadcast.get('picture4TransUrl') or broadcast.get('logo100x100')
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class WallaIE(SubtitlesInfoExtractor):
+class WallaIE(InfoExtractor):
-        subtitles = self.extract_subtitles(video_id, subtitles)
+            subtitles[self._SUBTITLE_LANGS.get(lang, lang)] = [{
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class CeskaTelevizeIE(SubtitlesInfoExtractor):
+class CeskaTelevizeIE(InfoExtractor):
-        subtitles = self._fix_subtitles(self.extract_subtitles(video_id, subtitles))
+            subtitles = self.extract_subtitles(episode_id, subs)
-        return fixed_subtitles
+        return "\r\n".join(_fix_subtitle(subtitles))
-__version__ = '2015.02.17.1'
+__version__ = '2015.02.17.2'
-            if v.attrib.get('proto') == 'http']
+        formats = []
-                'Checking %s URL' % item)
+            self._request_webpage(url, video_id, 'Checking %s URL' % item)
-__version__ = '2015.02.17'
+__version__ = '2015.02.17.1'
-        if not ffpp.available():
+        if not ffpp.available:
-__version__ = '2015.02.16.1'
+__version__ = '2015.02.17'
-        required_version = '10-0' if self._uses_avconv() else '1.0'
+        required_version = '10-0' if self.basename == 'avconv' else '1.0'
-                    if not merger.available():
+                    if not merger.available:
-        if not self.available():
+        if not self.available:
-        if not ffpp.available:
+        if not ffpp.available():
-        pr = _PseudoRequest(info_dict['url'])
+        pr = compat_urllib_request.Request(info_dict['url'])
-        return pr.headers.get('Cookie')
+        return pr.get_header('Cookie')
-        cmd = [self.exe, '-o', tmpfilename]
+        cmd = [self.exe, '--location', '-o', tmpfilename]
-    external_downloader:  Executable of the external downloader to call.
+    The following options determine which downloader is picked:
-            self.list_subtitles(info_dict['id'], info_dict.get('subtitles'))
+            if 'automatic_captions' in info_dict:
-        info_dict['requested_subtitles'] = self.process_subtitles(info_dict['id'], info_dict.get('subtitles'))
+        info_dict['requested_subtitles'] = self.process_subtitles(
-    def process_subtitles(self, video_id, available_subs):
+    def process_subtitles(self, video_id, available_subs, available_autocaps):
-    def list_subtitles(self, video_id, subtitles):
+    def list_subtitles(self, video_id, subtitles, name='subtitles'):
-            self.to_screen('%s has no subtitles' % video_id)
+            self.to_screen('%s has no %s' % (video_id, name))
-            (video_id, header_line, '\n'.join(sub_lines)))
+            'Available %s for %s:\n%s\n%s' %
-class YoutubeIE(YoutubeBaseInfoExtractor, SubtitlesInfoExtractor):
+class YoutubeIE(YoutubeBaseInfoExtractor):
-    def _get_available_subtitles(self, video_id, webpage):
+    def _get_subtitles(self, video_id, webpage):
-            sub_lang_list[lang] = url
+            sub_formats = []
-    def _get_available_automatic_caption(self, video_id, webpage):
+    def _get_automatic_captions(self, video_id, webpage):
-                sub_lang_list[sub_lang] = caption_url + '&' + params
+                sub_formats = []
-            return
+        automatic_captions = self.extract_automatic_captions(video_id, video_webpage)
-class DailymotionIE(DailymotionBaseInfoExtractor, SubtitlesInfoExtractor):
+class DailymotionIE(DailymotionBaseInfoExtractor):
-    def _get_available_subtitles(self, video_id, webpage):
+    def _get_subtitles(self, video_id, webpage):
-            sub_lang_list = dict((l['language'], l['url']) for l in info['list'])
+            sub_lang_list = dict((l['language'], [{'url': l['url'], 'ext': 'srt'}]) for l in info['list'])
-        subtitles = info_dict['subtitles']
+        subtitles = info_dict['requested_subtitles']
-        info_dict['subtitles'] = self.process_subtitles(info_dict['id'], info_dict.get('subtitles'))
+        info_dict['requested_subtitles'] = self.process_subtitles(info_dict['id'], info_dict.get('subtitles'))
-        if subtitles_are_requested and 'subtitles' in info_dict and info_dict['subtitles']:
+        if subtitles_are_requested and info_dict.get('requested_subtitles'):
-            subtitles = info_dict['subtitles']
+            subtitles = info_dict['requested_subtitles']
-        if not information.get('subtitles'):
+        subtitles = information.get('requested_subtitles')
-        sub_langs = [key for key in information['subtitles']]
+        sub_langs = list(subtitles.keys())
-        input_files = [filename] + [subtitles_filename(filename, lang, sub_info['ext']) for lang, sub_info in information['subtitles'].items()]
+        input_files = [filename] + [subtitles_filename(filename, lang, sub_info['ext']) for lang, sub_info in subtitles.items()]
-class VimeoIE(VimeoBaseInfoExtractor, SubtitlesInfoExtractor):
+class VimeoIE(VimeoBaseInfoExtractor):
-            return
+                subtitles[tt['lang']] = [{
-            'subtitles': video_subtitles,
+            'subtitles': subtitles,
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class AtresPlayerIE(SubtitlesInfoExtractor):
+class AtresPlayerIE(InfoExtractor):
-            return
+        subtitle_url = xpath_text(episode, './media/asset/files/subtitle', 'subtitle')
-            'subtitles': self.extract_subtitles(video_id, subtitles),
+            'subtitles': subtitles,
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class CrunchyrollIE(SubtitlesInfoExtractor):
+class CrunchyrollIE(InfoExtractor):
-            return
+        subtitles = self.extract_subtitles(video_id, webpage)
-        self.ie = self.IE(self.DL)
+        self.ie = self.IE()
-        info_dict = self.ie.extract(self.url)
+        info_dict = self.DL.extract_info(self.url, download=False)
-        return info_dict['subtitles']
+        subtitles = info_dict['subtitles']
-        self.assertEqual(subtitles, None)
+        self.assertFalse(subtitles)
-    subtitlesformat:   Subtitle format [srt/sbv/vtt] (default=srt)
+    subtitlesformat:   The format code for subtitles
-                    continue
+            for sub_lang, sub_info in subtitles.items():
-                            subfile.write(sub)
+                            subfile.write(sub_data)
-                    {language: subtitles}.
+    subtitles:      The available subtitles as a dictionary in the format
-from .subtitles import SubtitlesInfoExtractor
+from .common import InfoExtractor
-class TEDIE(SubtitlesInfoExtractor):
+class TEDIE(InfoExtractor):
-    def _get_available_subtitles(self, video_id, talk_info):
+    def _get_subtitles(self, video_id, talk_info):
-                sub_lang_list[l] = url
+                sub_lang_list[l] = [
-        help='subtitle format (default=srt) ([sbv/vtt] youtube only)')
+        action='store', dest='subtitlesformat', metavar='FORMAT', default='best',
-        input_files = [filename] + [subtitles_filename(filename, lang, self._subformat) for lang in sub_langs]
+        input_files = [filename] + [subtitles_filename(filename, lang, sub_info['ext']) for lang, sub_info in information['subtitles'].items()]
-__version__ = '2015.02.16'
+__version__ = '2015.02.16.1'
-from .rtlnl import RtlXlIE
+from .rtlnl import RtlNlIE
-
+# coding: utf-8
-from ..utils import parse_duration
+from ..utils import (
-    _VALID_URL = r'https?://(www\.)?rtlxl\.nl/#!/[^/]+/(?P<uuid>[^/?]+)'
+class RtlNlIE(InfoExtractor):
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-
+        uuid = self._match_id(url)
-
+        description = material.get('synopsis') or info['episodes'][0]['synopsis']
-
+        thumbnails = []
-            'description': episode_info['synopsis'],
+            'description': description,
-__version__ = '2015.02.11'
+__version__ = '2015.02.16'
-import re
+from ..utils import (
-        page = self._download_webpage(url, media_id)
+        video_id = self._match_id(url)
-            'http://mymedia.yam.com/api/a/?pID=' + media_id, media_id)
+            'http://mymedia.yam.com/api/a/?pID=' + video_id, video_id,
-            r'<!-- ç¼è¡¨ä½è -->ï¼[\n ]+<a href="/([a-z]+)"', page, 'author')
+        uploader_id = self._html_search_regex(
-                                      int(mobj.group('day')))
+        if mobj:
-            'id': media_id,
+            'id': video_id,
-            'uploader_id': author,
+            'duration': duration,
-                    if not merger._executable:
+                    if not merger.available():
-        exe_versions = FFmpegPostProcessor.get_versions()
+        exe_versions = FFmpegPostProcessor.get_versions(self)
-        if program is None:
+        if not ffpp.available:
-            for opt in (program, '-y', '-i', url, '-f', 'mp4', '-c', 'copy', '-bsf:a', 'aac_adtstoasc')]
+            for opt in (ffpp.executable, '-y', '-i', url, '-f', 'mp4', '-c', 'copy', '-bsf:a', 'aac_adtstoasc')]
-            self.report_error('%s exited with code %d' % (program, retval))
+            self.report_error('%s exited with code %d' % (ffpp.basename, retval))
-        self._versions = self.get_versions()
+        self._determine_executables()
-        if not self._executable:
+        if not self.available():
-                self._versions[self._executable], required_version):
+                self._versions[self.basename], required_version):
-                self._executable, self._executable, required_version)
+                self.basename, self.basename, required_version)
-        return self._executable is not None
+    def get_versions(downloader=None):
-        if self._downloader.params.get('prefer_ffmpeg', False):
+    def _determine_executables(self):
-        return None
+                self.basename = p
-        if self._downloader.params.get('prefer_ffmpeg', False):
+        if prefer_ffmpeg:
-        return None
+                self.probe_basename = p
-        return self._executable == 'avconv'
+        return self.basename == 'avconv'
-        cmd = ([encodeFilename(self._executable, True), encodeArgument('-y')] +
+        cmd = ([encodeFilename(self.executable, True), encodeArgument('-y')] +
-        if not self._probe_executable:
+        if not self.probe_executable:
-                encodeFilename(self._probe_executable, True),
+                encodeFilename(self.probe_executable, True),
-                self._downloader.to_screen('[' + self._executable + '] Destination: ' + new_path)
+                self._downloader.to_screen('[' + self.basename + '] Destination: ' + new_path)
-                msg = 'error running ' + self._executable
+                msg = 'error running ' + self.basename
-        self.assertEqual(len(subtitles.keys()), 5)
+        self.assertTrue(len(subtitles.keys()) >= 6)
-        self.assertEqual(md5(subtitles['cs']), 'cc3957b2c6dff1db71e5f2e83d467480')
+        self.assertTrue(len(subtitles['cs']) > 20000)
-            if not isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 404:
+            if not (isinstance(ee.cause, compat_HTTPError) and ee.cause.code == 404):
-        (?:https?://(?:link|player)\.theplatform\.com/[sp]/[^/]+/
+        (?:https?://(?:link|player)\.theplatform\.com/[sp]/(?P<provider_id>[^/]+)/
-                        'format=smil&mbr=true'.format(video_id))
+            smil_url = ('http://link.theplatform.com/s/{0}/{1}/meta.smil?'
-        info_url = 'http://link.theplatform.com/s/dJ5BDC/{0}?format=preview'.format(video_id)
+        info_url = 'http://link.theplatform.com/s/{0}/{1}?format=preview'.format(provider_id, video_id)
-        # See http://schema.org/VideoObj
+        # See http://schema.org/VideoObject
-import json
+import hashlib
-            'http://www.stream.cz/API/episode/%s' % video_id, video_id)
+        api_path = '/episode/%s' % video_id
-            'title': 'Hot Perky Blonde Naked Golf',
+            'title': 'hot perky blonde naked golf',
-            r'<title>([^<]+) - \d+', webpage, 'title')
+            [r'class="hd_title" style="[^"]+">([^<]+)</h1>', r'<title>([^<]+) - \d+'],
-        'md5': '634526ae978711f6b748fe0dd6c11f57',
+        'md5': '1bff67111adb785c51d1b42959ec10e5',
-            r'<title>([^<]+)\s*-\s*Free', webpage, 'title')
+            r'<title>([^<]+) - \d+', webpage, 'title')
-        for video_url in re.findall(r'<video src="([^"]+)"', webpage):
+        for video_url in re.findall(r'<(?:source|video) src="([^"]+)"', webpage):
-        for video_url in re.findall(r'<source src="([^"]+)"', webpage):
+        for video_url in re.findall(r'<video src="([^"]+)"', webpage):
-        ((?P<program>feature|nightly-news)/[^/]+/(?P<title>.+)))
+    _VALID_URL = r'''(?x)https?://(?:www\.)?nbcnews\.com/
-            bootstrap = json.loads(bootstrap_json)
+            bootstrap_json = self._search_regex(
-        (feature/[^/]+/(?P<title>.+)))
+        ((?P<program>feature|nightly-news)/[^/]+/(?P<title>.+)))
-            # "feature" pages use theplatform.com
+            # "feature" and "nightly-news" pages use theplatform.com
-                flags=re.MULTILINE)
+            program = mobj.group('program')
-        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)
-            handle = subprocess.Popen(cmd, stderr=compat_subprocess_get_DEVNULL(), stdout=subprocess.PIPE)
+            handle = subprocess.Popen(cmd, stderr=compat_subprocess_get_DEVNULL(), stdout=subprocess.PIPE, stdin=subprocess.PIPE)
-    _VALID_URL = r'http://(?:www\.)?1tv\.ru/videoarchive/(?P<id>\d+)'
+    IE_NAME = '1tv'
-    _TEST = {
+    _TESTS = [{
-        'md5': '3de6390cf0cca4a5eae1d1d83895e5ad',
+        'md5': '777f525feeec4806130f4f764bc18a4f',
-            'thumbnail': 'http://img1.1tv.ru/imgsize640x360/PR20140210114657.JPG',
+            'description': 'md5:d41d8cd98f00b204e9800998ecf8427e',
-    }
+    }, {
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'''(?s)jwplayer\('flashvideoportal_1'\)\.setup\({.*?'file': '([^']+)'.*?}\);''', webpage, 'video URL')
+            r'''(?s)(?:jwplayer\('flashvideoportal_1'\)\.setup\({|var\s+playlistObj\s*=).*?'file'\s*:\s*'([^']+)'.*?}\);''',
-            r'<div class="tv_translation">\s*<h1><a href="[^"]+">([^<]*)</a>', webpage, 'title')
+            [r'<div class="tv_translation">\s*<h1><a href="[^"]+">([^<]*)</a>',
-            r'<div class="descr">\s*<div>&nbsp;</div>\s*<p>([^<]*)</p></div>', webpage, 'description', fatal=False)
+            r'<div class="descr">\s*<div>&nbsp;</div>\s*<p>([^<]*)</p></div>',
-        duration = self._og_search_property('video:duration', webpage, 'video duration', fatal=False)
+        duration = self._og_search_property(
-                                                webpage, 'dislike count', fatal=False)
+        like_count = self._html_search_regex(
-    _VALID_URL = r'http://www.camdemy.com/media/(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www\.)?camdemy\.com/media/(?P<id>\d+)'
-        self.assertEqual(md5(subtitles['en']), '26399116d23ae3cf2c087cea94bc43b4')
+        self.assertEqual(md5(subtitles['en']), '8062383cf4dec168fc40a088aa6d5888')
-        self.assertEqual(md5(subtitles['cs']), '9bf52d9549533c32c427e264bf0847d4')
+        self.assertEqual(md5(subtitles['cs']), 'cc3957b2c6dff1db71e5f2e83d467480')
-            'uploader_id': info['uid'],
+            'uploader_id': info['owner']['uid'],
-        return ENGLISH_NAMES.index(name) + 1
+        return ENGLISH_MONTH_NAMES.index(name) + 1
-from .nporadio import NPORadioIE
+from .common import InfoExtractor
-    _VALID_URL = r'https?://www\.npo\.nl/[^/]+/[^/]+/(?P<id>[^/?]+)'
+    _VALID_URL = r'https?://(?:www\.)?npo\.nl/(?!live|radio)[^/]+/[^/]+/(?P<id>[^/?]+)'
-    _VALID_URL = r'https?://www\.npo\.nl/live/(?P<id>.+)'
+    _VALID_URL = r'https?://(?:www\.)?npo\.nl/live/(?P<id>.+)'
-       
+            self._html_get_attribute_regex('data-channel'), webpage, 'title')
-        
+            self._html_search_regex(
-
+from .nporadio import NPORadioIE
-from ..utils import parse_iso8601
+from ..compat import (
-        srcFrom = self._html_search_regex(
+        src_from = self._html_search_regex(
-            return self.url_result(srcFrom)
+        if src_from:
-        fileListXML = self._download_xml(
+        file_list_doc = self._download_xml(
-        creation_timestamp = parse_iso8601(creation_time, delimiter=' ')
+        file_name = file_list_doc.find('./video/item/fileName').text
-        views = int(view_count_str.replace(',', ''))
+        timestamp = parse_iso8601(self._html_search_regex(
-            'url': compat_urlparse.urljoin(video_folder, fileName),
+            'url': video_url,
-            'view_count': views,
+            'timestamp': timestamp,
-def parse_iso8601(date_str, delimiter='T'):
+def parse_iso8601(date_str, delimiter='T', timezone=None):
-        if not m.group('sign'):
+    if timezone is None:
-                minutes=sign * int(m.group('minutes')))
+            date_str = date_str[:-len(m.group(0))]
-from ..compat import compat_urllib_parse
+from ..compat import (compat_urllib_parse, compat_urlparse)
-        video_folder = compat_urllib_parse.urljoin(thumb_url, 'video/')
+        video_folder = compat_urlparse.urljoin(thumb_url, 'video/')
-            compat_urllib_parse.urljoin(video_folder, 'fileList.xml'),
+            compat_urlparse.urljoin(video_folder, 'fileList.xml'),
-            'url': compat_urllib_parse.urljoin(video_folder, fileName),
+            'url': compat_urlparse.urljoin(video_folder, fileName),
-        query = dict(compat_urllib_parse.parse_qsl(parsed_url[4]))
+        parsed_url = list(compat_urlparse.urlparse(url))
-        final_url = compat_urllib_parse.urlunparse(parsed_url)
+        final_url = compat_urlparse.urlunparse(parsed_url)
-from .camdemy import CamdemyIE
+from .camdemy import (
-from ..compat import compat_urlparse
+from ..compat import compat_urllib_parse
-    _VALID_URL = r'http://www.camdemy.com/media/(?P<id>\d+).*'
+    _VALID_URL = r'http://www.camdemy.com/media/(?P<id>\d+)'
-        video_folder = compat_urlparse.urljoin(thumb_url, 'video/')
+        video_folder = compat_urllib_parse.urljoin(thumb_url, 'video/')
-            compat_urlparse.urljoin(video_folder, 'fileList.xml'),
+            compat_urllib_parse.urljoin(video_folder, 'fileList.xml'),
-            page, 'creation time', flags=re.MULTILINE | re.DOTALL) + '+08:00'
+            r"<div class='title'>Posted :</div>[\r\n ]*<div class='value'>([^<>]+)<",
-            page, 'view count', flags=re.MULTILINE | re.DOTALL)
+            r"<div class='title'>Views :</div>[\r\n ]*<div class='value'>([^<>]+)<",
-            'url': compat_urlparse.urljoin(video_folder, fileName),
+            'url': compat_urllib_parse.urljoin(video_folder, fileName),
-__version__ = '2015.02.10.5'
+__version__ = '2015.02.11'
-
+
-
+from ..utils import (
-    _VALID_URL = r'http://(?:www\.)?dotsub\.com/view/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?dotsub\.com/view/(?P<id>[^/]+)'
-            'thumbnail': 'http://dotsub.com/media/aed3b8b2-1889-4df5-ae63-ad85f5572f27/p',
+            'timestamp': 1292248482.625,
-        date = time.gmtime(info['dateCreated'] / 1000)  # The timestamp is in miliseconds
+        video_id = self._match_id(url)
-            'url': info['mediaURI'],
+            'url': video_url,
-            'upload_date': '%04i%02i%02i' % (date.tm_year, date.tm_mon, date.tm_mday),
+            'description': info.get('description'),
-    _VALID_URL = r'https?://(?:www\.(?P<site>canalplus\.fr|piwiplus\.fr|d8\.tv)/.*?/(?P<path>.*)|player\.canalplus\.fr/#/(?P<id>[0-9]+))'
+    _VALID_URL = r'https?://(?:www\.(?P<site>canalplus\.fr|piwiplus\.fr|d8\.tv|itele\.fr)/.*?/(?P<path>.*)|player\.canalplus\.fr/#/(?P<id>[0-9]+))'
-                webpage, 'video id')
+                self._VIDEO_ID_REGEXES, webpage, 'video id')
-    unescapeHTML
+    clean_html,
-                'ext': 'flv',
+                'ext': 'mp4',
-            },
+            'md5': 'adecff79691b4d71e25220a191477124',
-                'ext': 'flv',
+                'ext': 'mp4',
-            },
+            'md5': '82dbd49b38e3af1d00df16acbeab260c',
-                'description': 'Â«Ð¡ÐµÐ³Ð¾Ð´Ð½ÑÂ». 21Â Ð¼Ð°ÑÑÐ° 2014Â Ð³Ð¾Ð´Ð°. 16:00 ',
+                'ext': 'mp4',
-            },
+            'md5': 'f825770930937aa7e5aca0dc0d29319a',
-                'ext': 'flv',
+                'id': '1007609',
-            },
+            'md5': '9320cd0e23f3ea59c330dc744e06ff3b',
-                'ext': 'flv',
+                'ext': 'mp4',
-        video_id = self._html_search_regex(self._VIDEO_ID_REGEXES, page, 'video id')
+        webpage = self._download_webpage(url, video_id)
-        description = unescapeHTML(player.find('./data/description').text)
+        video_id = self._html_search_regex(self._VIDEO_ID_REGEXES, webpage, 'video id')
-        puid22 = video.find('./puid22').text
+        player = self._download_xml(
-        }
+        video = player.find('./data/video')
-        app = apps.get(puid22, apps['4'])
+        token = self._download_webpage(
-            if file is None:
+            file_ = video.find('./%sfile' % format_id)
-                'filesize': int(size.text),
+                'url': 'http://media2.ntv.ru/vod/%s&tok=%s' % (file_.text, token),
-__version__ = '2015.02.10.4'
+__version__ = '2015.02.10.5'
-        except (KeyError,) as e:
+        except (KeyError, StopIteration) as e:
-                'url': playlist[1]['url'],
+                'url': video_url,
-
+    js_to_json,
-    _VALID_URL = r'^https?://?(www\.)?escapistmagazine\.com/videos/view/(?P<showname>[^/]+)/(?P<id>[0-9]+)-'
+    _VALID_URL = r'https?://?(www\.)?escapistmagazine\.com/videos/view/[^/?#]+/(?P<id>[0-9]+)-[^/?#]*(?:$|[?#])'
-            'uploader': 'the-escapist-presents',
+            'uploader_id': 'the-escapist-presents',
-        self.report_extraction(video_id)
+        video_id = self._match_id(url)
-        playerUrl = self._og_search_video_url(webpage, name='player URL')
+        uploader_id = self._html_search_regex(
-            webpage, 'title').split(' : ')[-1]
+        raw_title = self._html_search_meta('title', webpage, fatal=True)
-        configUrl = compat_urllib_parse.unquote(configUrl)
+        player_url = self._og_search_video_url(webpage, name='player URL')
-                transform_source=lambda s: s.replace("'", '"'))
+                transform_source=js_to_json)
-                  ('&hq=1' if '?' in configUrl else configUrl + '?hq=1'))
+        _add_format('normal', config_url, quality=0)
-            'uploader': showName,
+            'uploader': uploader,
-            'player_url': playerUrl,
+            'description': description,
-__version__ = '2015.02.10.3'
+__version__ = '2015.02.10.4'
-    def _match_entry(self, info_dict):
+    def _match_entry(self, info_dict, incomplete):
-                return ret
+        if not incomplete:
-                reason = self._match_entry(entry)
+                reason = self._match_entry(entry, incomplete=True)
-        reason = self._match_entry(info_dict)
+        reason = self._match_entry(info_dict, incomplete=False)
-__version__ = '2015.02.10.2'
+__version__ = '2015.02.10.3'
-
+from test.helper import FakeYDL
-        ie = YoutubeIE()
+        ydl = FakeYDL()
-
+        video_id = self._match_id(url)
-        title = self._html_search_meta('twitter:title', page, 'title')
+
-                               'Wrong password')
+        return self._download_webpage(
-            if re.search('<form[^>]+?id="pw_form"', webpage) is not None:
+            if re.search(r'<form[^>]+?id="pw_form"', webpage) is not None:
-                self._page_url(base_url, pagenum), list_id,
+                page_url, list_id,
-        album_id = mobj.group('id')
+        album_id = self._match_id(url)
-        '--print-traffic',
+        '--print-traffic', '--dump-headers',
-            if self._err_file.isatty() and os.name != 'nt':
+            if not self.params.get('no_color') and self._err_file.isatty() and os.name != 'nt':
-        if self._err_file.isatty() and os.name != 'nt':
+        if not self.params.get('no_color') and self._err_file.isatty() and os.name != 'nt':
-        if os.name != 'nt' and sys.stderr.isatty():
+        if not self._downloader.params.get('no_color') and os.name != 'nt' and sys.stderr.isatty():
-            r"(?s)'sources'\s*:\s*(\{.+?\})\s*\}\);", webpage, 'sources')))
+            r"(?s)'sources'\s*:\s*(\{.+?\})\s*\}[;,)]",
-                })
+        for qname, video_url in sources.items():
-__version__ = '2015.02.10.1'
+__version__ = '2015.02.10.2'
-            return 'Skipping "%s" because it is age restricted' % title
+            return 'Skipping "%s" because it is age restricted' % video_title
-    DEFAULT_OUTTMPL,
+    DEFAULT_OUTTMPL,
-__version__ = '2015.02.10'
+__version__ = '2015.02.10.1'
-from .commonmistakes import CommonMistakesIE
+from .commonmistakes import CommonMistakesIE, UnicodeBOMIE
-        info = All_info[0]
+        info = all_info[0]
-            userConf = []
+        command_line_conf = sys.argv[1:]
-                userConf = []
+            system_conf = _readOptions('/etc/youtube-dl.conf')
-        argv = systemConf + userConf + commandLineConf
+                user_conf = _readUserConf()
-            write_string('[debug] Command-line args: ' + repr(_hide_login_info(commandLineConf)) + '\n')
+            write_string('[debug] System config: ' + repr(_hide_login_info(system_conf)) + '\n')
-        if self._downloader.params.get('verbose'):
+        if not self._downloader.params.get('verbose'):
-__version__ = '2015.02.09.3'
+__version__ = '2015.02.10'
-        return self._real_extract(url)
+        try:
-            webpage, 'video id', flags=re.MULTILINE | re.DOTALL)
+            r'(?ms)var TralbumData = {.*?id: (?P<id>\d+),?$',
-        info = json.loads(info)[0]
+        all_info = self._parse_json(self._search_regex(
-        m_url = re.match(re_url, initial_url)
+        m_url = re.match(
-        final_url = re.search(r'"retry_url":"(.*?)"', final_url_webpage).group(1)
+        final_url = self._search_regex(
-        'md5': '2521cd644e862936cf2e698206e47385',
+        'md5': 'f4a184968bc9c802a9b41316657aaa80',
-            'id': '3966754',
+            'id': '2609989',
-            'title': 'FIFA 14 - E3 2013 Trailer',
+            'title': 'SM veckan vinter, Ãrebro - Rally, final',
-            'thumbnail': 're:^https?://.*\.jpg$',
+            'thumbnail': 're:^https?://.*[\.-]jpg$',
-__version__ = '2015.02.09.2'
+__version__ = '2015.02.09.3'
-import json
+import re
-    _VALID_URL = r'https?://(?:www\.)?trilulilu\.ro/video-[^/]+/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?trilulilu\.ro/(?:video-[^/]+/)?(?P<id>[^/#\?]+)'
-            'id': 'big-buck-bunny-1',
+            'id': 'ae2899e124140b',
-        webpage = self._download_webpage(url, video_id)
+        display_id = self._match_id(url)
-        log = json.loads(log_str)
+        description = self._og_search_description(webpage, default=None)
-                      'video-formats2' % log)
+                      'video-formats2' % flashvars)
-            log)
+            flashvars)
-                'format': fnode.text,
+                'format_id': fnode.text.partition('-')[2],
-            '_type': 'video',
+            'display_id': display_id,
-            formats_s[0] += (' ' if self._format_note(formats[0]) else '') + '(worst)'
+from .svtplay import SVTPlayIE
-                formats.append(f)
+                full_info = self._formats.get(format_id, {}).copy()
-__version__ = '2015.02.09.1'
+__version__ = '2015.02.09.2'
-            r'<iframe[^>]+?src=(["\'])(?P<url>https?://(?:www\.)sbs\.com\.au/ondemand/video/single/.+?)\1',
+            r'''(?x)
-__version__ = '2015.02.09'
+__version__ = '2015.02.09.1'
-                .*?file\s*:\s*["\'](.*?)["\']''', webpage))
+                .*?
-__version__ = '2015.02.08'
+__version__ = '2015.02.09'
-                }
+                mobj = re.search(r'.*/(?P<hoster>[^/]+)/videos/(?P<play_path>.+)\.f4m', filename.text)
-            ' This works for filesize, height, width, tbr, abr, vbr, and fps'
+            ' This works for filesize, height, width, tbr, abr, vbr, asr, and fps'
-            ' and for ext, acodec, vcodec, container and protocol'
+            ' and for ext, acodec, vcodec, container, and protocol'
-__version__ = '2015.02.06'
+__version__ = '2015.02.08'
-            ' and the comparisons <, <=, >, >=, =, != .'
+            ' and the comparisons <, <=, >, >=, =, !='
-            (?P<key>width|height|tbr|abr|vbr|filesize|fps)
+            (?P<key>width|height|tbr|abr|vbr|asr|filesize|fps)
-            raise ValueError('Invalid format specification %r' % format_spec)
+            STR_OPERATORS = {
-        op = OPERATORS[m.group('op')]
+        if not m:
-    _VALID_URL = r'http://www\.gamekings\.tv/videos/(?P<id>[^/]+)'
+    _VALID_URL = r'http://www\.gamekings\.tv/(?:videos|nieuws)/(?P<id>[^/]+)'
- )
+    xpath_with_ns,
-        {
+    _VALID_URL = r'http://www\.gamekings\.tv/videos/(?P<id>[^/]+)'
-            'id': '20130811',
+            'id': 'phoenix-wright-ace-attorney-dual-destinies-review',
-            }
+            'thumbnail': 're:^https?://.*\.jpg$',
-        {
+    }, {
-            'id': '118933752',
+            'id': 'the-legend-of-zelda-majoras-mask',
-    ]
+            'description': 'md5:9917825fe0e9f4057601fe1e38860de3',
-        webpage = self._download_webpage(url, name)
+        playlist_id = self._search_regex(
-        
+        playlist = self._download_xml(
-         }
+        }
-        # Todo: Add medium format
+        thumbnail = xpath_text(item, xpath_with_ns('./jwplayer:image', NS_MAP), 'thumbnail')
-            'thumbnail': image
+            'thumbnail': thumbnail,
-            'age_limit': 0 if family_friendly == 'true' else 18,
+            'age_limit': self._family_friendly_search(webpage),
-            'age_limit': 18 if family_friendly == 'False' else 0,
+            'age_limit': self._family_friendly_search(webpage),
-                'description': 'Mary Kay is perhaps the most trusted name in female beauty, so of course Conan is a natural choice to sell their products.'
+                'description': 'Mary Kay is perhaps the most trusted name in female beauty, so of course Conan is a natural choice to sell their products.',
-                "title": "Louis C.K. Interview Pt. 1 11/3/11"
+                "title": "Louis C.K. Interview Pt. 1 11/3/11",
-from ..utils import xpath_text
+from ..utils import (
-            'rss': 'http://rss.jwpcdn.com/'
+        NS_MAP = {
-        # Todo: Implement Xpath for searching the video link
+        item = playlist_rss.find('./channel/item')
-
+        image = xpath_text(item, xpath_with_ns('./jwplayer:image', NS_MAP), 'image')
-            video_url = video_url.replace('http://stream.gamekings.tv/', '')
+        
-
+from ..utils import xpath_text
-            'title': 'The Legend of Zelda: Majoraâs Mask'
+            'title': 'The Legend of Zelda: Majoraâs Mask',
-        if not (self._is_valid_url(video_url, video_id)):
+        if "vimeo" in video_url:
-    _TEST = {
+    _TESTS = [
-    }
+    ]
-            video_url = video_url.replace(video_id + 'large/', video_id)
+            video_url = video_url.replace('large/' + video_id, video_id)
-            video_url = video_url.replace(video_id + '/large', video_id)
+            video_url = video_url.replace(video_id + 'large/', video_id)
-        video_urls = re.findall(r'fileList\[[0-9]+\]\s*=\s*"([^"]+)"', webpage)
+        video_urls = [video_url.replace('\\/', '/') for video_url in re.findall(
-            r'\s+image:\s*"([^"]+)"', webpage, 'thumbnail', fatal=False)
+            r'image:\s*"([^"]+)"', webpage, 'thumbnail', fatal=False)
-                print(audiofile)
+from youtube_dl.postprocessor.common import PostProcessor
-                more_opts = ['-bsf:a' if uses_avconv else '-absf', 'aac_adtstoasc']
+                more_opts = ['-bsf:a', 'aac_adtstoasc']
-                        more_opts += ['-q:a' if uses_avconv else '-aq', self._preferredquality]
+                        more_opts += ['-q:a', self._preferredquality]
-                        more_opts += ['-b:a' if uses_avconv else '-ab', self._preferredquality + 'k']
+                        more_opts += ['-b:a', self._preferredquality + 'k']
-                    more_opts += ['-q:a' if uses_avconv else '-aq', self._preferredquality]
+                    more_opts += ['-q:a', self._preferredquality]
-                    more_opts += ['-b:a' if uses_avconv else '-ab', self._preferredquality + 'k']
+                    more_opts += ['-b:a', self._preferredquality + 'k']
-                more_opts += ['-bsf:a' if uses_avconv else '-absf', 'aac_adtstoasc']
+                more_opts += ['-bsf:a', 'aac_adtstoasc']
-import json
+import re
-from ..utils import js_to_json
+        'md5': 'e736ce0c665e459ddb818546220b4ef8',
-        config = json.loads(js_to_json(player_config))
+        config = self._parse_json(player_config, video_id)
-            'vcodec': config.get('type') == 'audio' and 'none' or None,
+        # Construct regular HTTP download URLs
-    _VALID_URL = r'http://(?:www\.)?tvigle\.ru/(?:[^/]+/)+(?P<id>[^/]+)/$'
+    _VALID_URL = r'https?://(?:www\.)?(?:tvigle\.ru/(?:[^/]+/)+(?P<display_id>[^/]+)/$|cloud\.tvigle\.ru/video/(?P<id>\d+))'
-        },
+        }, {
-        webpage = self._download_webpage(url, display_id)
+        mobj = re.match(self._VALID_URL, url)
-            r'<li class="video-preview current_playing" id="(\d+)">', webpage, 'video id')
+        if not video_id:
-                ext_preference,
+                ext_preference,
-__version__ = '2015.02.04'
+__version__ = '2015.02.06'
-                manifest_url = '/'.join(manifest_url.split('/')[:-1]) + '/' + media_el.attrib.get('href')
+                manifest_url = ('/'.join(manifest_url.split('/')[:-1]) + '/'
-
+from ..utils import (
-    _VALID_URL = r'https?://tweakers\.net/video/(?P<id>[0-9]+).*'
+    _VALID_URL = r'https?://tweakers\.net/video/(?P<id>\d+)'
-        'md5': 'f7f7f3027166a7f32f024b4ae6571ced',
+        'md5': '1b5afa817403bb5baa08359dca31e6df',
-            'title': 'New-Nintendo-3Ds-Xl-Op-Alle-Fronten-Beter',
+            'title': 'New Nintendo 3DS XL - Op alle fronten beter',
-        player_page = self._download_webpage(player_url, video_id)
+
-            'url': re.findall('http.*mp4', player_page)[0],
+            'description': description,
-        video_id = splitted_url[4]
+        video_id = self._match_id(url)
-        del splitted_url[-1] # To remove extra '/' at the end
+        del splitted_url[-1]  # To remove extra '/' at the end
-        splitted_url[3] = splitted_url[3] + '/player' # Add /player to get the player page
+        title = splitted_url[5].title()  # Retrieve title for URL and capitalize
-            'url':  re.findall('http.*mp4', player_page)[0],
+            'url': re.findall('http.*mp4', player_page)[0],
-                                'format': rf,
+                                'format': '%s+%s' % (formats_info[0].get('format'),
-        } for fid, furl in info['streams'].items()]
+        formats = []
-    def _extract_f4m_formats(self, manifest_url, video_id):
+    def _extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None):
-                'format_id': format_id,
+                'format_id': '-'.join(filter(None, [f4m_id, 'f4m-%d' % (i if tbr is None else tbr)])),
-                              entry_protocol='m3u8', preference=None):
+                              entry_protocol='m3u8', preference=None,
-            'format_id': 'm3u8-meta',
+            'format_id': '-'.join(filter(None, [m3u8_id, 'm3u8-meta'])),
-                    'format_id': 'm3u8-%d' % (tbr if tbr else len(formats)),
+                    'format_id': '-'.join(filter(None, [m3u8_id, 'm3u8-%d' % (tbr if tbr else len(formats))])),
-        subtitles = {}
+        self._sort_formats(formats)
-        if self._have_to_download_any_subtitles and tt888 == 'ja':
+        subtitles = {}
-        self._sort_formats(formats)
+        if self._downloader.params.get('listsubtitles', False):
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class NPOBaseIE(InfoExtractor):
+class NPOBaseIE(SubtitlesInfoExtractor):
-__version__ = '2015.02.03.1'
+__version__ = '2015.02.04'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r'\s(?:data-preview-url|m-preview)="(.+?)"', webpage, 'preview url')
+            r'\s(?:data-preview-url|m-preview)="([^"]+)"', webpage, 'preview url')
-                re.search(r'OO\.Player\.create\([\'"].*?[\'"],\s*[\'"](?P<ec>.{32})[\'"]', webpage))
+                re.search(r'OO\.Player\.create\([\'"].*?[\'"],\s*[\'"](?P<ec>.{32})[\'"]', webpage) or
-__version__ = '2015.02.03'
+__version__ = '2015.02.03.1'
-    date_str = re.sub(r'(?i)\s*(?:AM|PM)\s+[A-Z]+', '', date_str)
+    date_str = re.sub(r'(?i)\s*(?:AM|PM)(?:\s+[A-Z]+)?', '', date_str)
-                ext_preference,
+                ext_preference,
-            for t in thumbnails:
+            for i, t in enumerate(thumbnails):
-        video_id = mobj.group('video_id')
+        video_id = self._match_id(url)
-    compat_parse_qs,
+from ..utils import (
-    _VALID_URL = r'(?P<baseurl>http://(?:www\.)?franceculture\.fr/)player/reecouter\?play=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?franceculture\.fr/player/reecouter\?play=(?P<id>[0-9]+)'
-            'description': 'Avec :Jean-Baptiste PÃ©retiÃ© pour son documentaire sur Arte "La revanche des Â« geeks Â», une enquÃªte menÃ©e aux Etats-Unis dans la S ...',
+            'description': 'startswith:Avec :Jean-Baptiste PÃ©retiÃ© pour son documentaire sur Arte "La revanche des Â« geeks Â», une enquÃªte menÃ©e aux Etats',
-
+        video_id = self._match_id(url)
-        video_url = compat_urlparse.urljoin(baseurl, params['urlAOD'][0])
+
-            thumbnail = compat_urlparse.urljoin(baseurl, thumbnail_part)
+            r'<span class="title-diffusion">(.*?)</span>', webpage, 'title')
-            r'(?s)<p class="desc">(.*?)</p>', webpage, 'description')
+            r'<span class="description">(.*?)</span>',
-            else None)
+        uploader = self._html_search_regex(
-            'duration': duration,
+            'vcodec': vcodec,
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-__version__ = '2015.02.02.5'
+__version__ = '2015.02.03'
-            metadata['comment'] = info['webpage_url']
+            metadata['purl'] = info['webpage_url']
-__version__ = '2015.02.02.4'
+__version__ = '2015.02.02.5'
-        object_str = re.sub(r'(<param name="[^"]+" value="[^"]+")>',
+        object_str = re.sub(r'(<param(?:\s+[a-zA-Z0-9_]+="[^"]*")*)>',
-__version__ = '2015.02.02.3'
+__version__ = '2015.02.02.4'
-
+from .nerdist import NerdistIE
-    def _extract_smil_formats(self, smil_url, video_id):
+    def _extract_smil_formats(self, smil_url, video_id, fatal=True):
-            'Unable to download SMIL file')
+            'Unable to download SMIL file', fatal=fatal)
-        }
+        },
-            r'(?:config|configURL)\s*:\s*"([^"]+)"', webpage, 'config URL'))
+            r'(?:config|configURL)\s*:\s*"([^"]+)"', webpage, 'config URL',
-    _VALID_URL = r'http://(?:www\.)?normalboots\.com/video/(?P<videoid>[0-9a-z-]*)/?$'
+    _VALID_URL = r'http://(?:www\.)?normalboots\.com/video/(?P<id>[0-9a-z-]*)/?$'
-
+        video_id = self._match_id(url)
-        player_url = self._html_search_regex(r'<iframe\swidth="[0-9]+"\sheight="[0-9]+"\ssrc="(?P<url>[\S]+)"', webpage, 'url')
+        video_uploader = self._html_search_regex(
-        video_url = self._html_search_regex(r"file:\s'(?P<file>[^']+\.mp4)'", player_page, 'file')
+        video_url = self._html_search_regex(
-__version__ = '2015.02.02.2'
+__version__ = '2015.02.02.3'
-            r'/Date\((\d+)\)/', video_info['launchDate'], 'launch date'))
+        timestamp_ms = int_or_none(self._search_regex(
-__version__ = '2015.02.02.1'
+__version__ = '2015.02.02.2'
-        'md5': 'd37b7df1eea32265c51a062499ca488f',
+        'md5': '6ef2514d4b1e8e03ca24b49e2f167153',
-            'format_id': 'mp4',
+            'format_id': 'mobile',
-        formats.extend(self._extract_m3u8_formats(m3u8_url, video_id))
+        formats.extend(self._extract_m3u8_formats(
-                (?:(?P<hours>[0-9]+)\s*(?:[:h]|hours?)\s*)?
+                (?:
-        [a-zA-Z_][a-zA-Z_0-9]*
+        [a-zA-Z_][.a-zA-Z_0-9]*
-from .ntv import NTVIE
+from .ntvru import NTVRuIE
-class NTVIE(InfoExtractor):
+class NTVRuIE(InfoExtractor):
-
+        video_id = self._match_id(url)
-__version__ = '2015.02.02'
+__version__ = '2015.02.02.1'
-        return command_part
+        if source_address is None:
-        if source_address:
+        if source_address is None:
-        help='(experimental) Automatically correct known faults of the file. '
+        help='Automatically correct known faults of the file. '
-             'otherwise')
+             'detect_or_warn(the default; fix file if we can, warn otherwise)')
-        source_address = self.ydl.params.get('source_address')
+        source_address = self.params.get('source_address')
-            command_part = [command_option, self.ydl.params['source_address']]
+        source_address = self.ydl.params.get('source_address')
-            'http://www.dr.dk/mu/programcard/expanded/%s' % video_id, video_id, 'Downloading video JSON')
+        webpage = self._download_webpage(url, video_id)
-                pass
+                    # Connection reset is no problem, just retry
-__version__ = '2015.02.01'
+__version__ = '2015.02.02'
-    ('/', operator.div),
+    ('/', operator.truediv),
-__version__ = '2015.01.30.2'
+__version__ = '2015.02.01'
-        self.code = code
+    def __init__(self, code, objects=None):
-        self._objects = {}
+        self._objects = objects
-    def interpret_statement(self, stmt, local_vars, allow_recursion=20):
+    def interpret_statement(self, stmt, local_vars, allow_recursion=100):
-            expr = stmt[len('return '):]
+        should_abort = False
-            assign = lambda v: v
+            return_m = re.match(r'return(?:\s+|$)', stmt)
-        return assign(v)
+        return v, should_abort
-            return local_vars[expr]
+        var_m = re.match(
-            r'^(?P<var>[$a-zA-Z0-9_]+)\.(?P<member>[^(]+)(?:\(+(?P<args>[^()]*)\))?$',
+            r'(?P<var>%s)\.(?P<member>[^(]+)(?:\(+(?P<args>[^()]*)\))?$' % _NAME_RE,
-            r'^(?P<in>[a-z]+)\[(?P<idx>.+)\]$', expr)
+            r'(?P<in>%s)\[(?P<idx>.+)\]$' % _NAME_RE, expr)
-            return a % b
+        for op, opfunc in _OPERATORS:
-            r'^(?P<func>[a-zA-Z$]+)\((?P<args>[a-z0-9,]+)\)$', expr)
+            r'^(?P<func>%s)\((?P<args>[a-zA-Z0-9_$,]+)\)$' % _NAME_RE, expr)
-            r'\((?P<args>[a-z,]+)\){(?P<code>[^}]+)}',
+            r'''(?x)
-                res = self.interpret_statement(stmt, local_vars)
+                res, abort = self.interpret_statement(stmt, local_vars)
-        args = [encodeArgument(opt) for opt in ('-y', '-i', url, '-f', 'mp4', '-c', 'copy', '-bsf:a', 'aac_adtstoasc')]
+        args = [
-        retval = subprocess.call(cmd)
+        retval = subprocess.call(args)
-            self.to_screen('\r[%s] %s bytes' % (cmd[0], fsize))
+            self.to_screen('\r[%s] %s bytes' % (args[0], fsize))
-        cmd = [program] + args
+
-                    }
+                    formats.extend(self._extract_m3u8_formats(url, video_id, 'mp4'))
-                'title': 'Uploads from Interstellar Movie',
+            'title': 'Uploads from Interstellar Movie',
-
+            'id': '2284613',
-            'id': info['id'],
+            'id': '%s' % info['id'],
-            if not tc.get('file') and not (info_dict.get('id') and info_dict.get('ext')):
+            if not (info_dict.get('id') and info_dict.get('ext')):
-            return tc.get('file') or ydl.prepare_filename(tc.get('info_dict', {}))
+            return ydl.prepare_filename(tc.get('info_dict', {}))
-    _VALID_URL = r'(?:http://)?(?:www\.)?ringtv\.craveonline\.com/(?P<type>news|videos/video)/(?P<id>[^/?#]+)'
+    _VALID_URL = r'http://(?:www\.)?ringtv\.craveonline\.com/(?P<type>news|videos/video)/(?P<id>[^/?#]+)'
-        "file": "857645.mp4",
+            'id': '857645',
-
+        'info_dict': {
-            'file': '29955898.flv',
+                'id': '29955898',
-            'file': '29907998.flv',
+                'id': '29907998',
-        'skip': 'Blocked in the US [sic]',
+        '_skip': 'Blocked in the US [sic]',
-
+        pl_id = self._match_id(url)
-    _VALID_URL = r'''https?://(.*?\.)?video\.sina\.com\.cn/
+    _VALID_URL = r'''(?x)https?://(.*?\.)?video\.sina\.com\.cn/
-            'file': '110028898.flv',
+                'id': '110028898',
-        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)
+        mobj = re.match(self._VALID_URL, url)
-        'file': '1214711.mp4',
+            'id': '1214711',
-            video_url = aes_decrypt_text(video_url, password, 32).decode('utf-8')
+        video_title = self._html_search_regex(
-        'file': '2450.m4v',
+            'id': '2450',
-        webpage = self._download_webpage(url, video_id, 'Downloading trailer page')
+        video_id = self._match_id(url)
-            raise ExtractorError('Trailer %s does not exist' % video_id, expected=True)
+        if '>Missing Media<' in webpage:
-    _VALID_URL = r'https?://generation-quoi\.france2\.fr/portrait/(?P<name>.*)(\?|$)'
+    _VALID_URL = r'https?://generation-quoi\.france2\.fr/portrait/(?P<id>[^/?#]+)'
-        'file': 'k7FJX8VBcvvLmX4wA5Q.mp4',
+            'id': 'k7FJX8VBcvvLmX4wA5Q',
-        info_json = self._download_webpage(info_url, name)
+        display_id = self._match_id(url)
-        'file': '48863.flv',
+            'id': '48863',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        'file': '50355319.mp4',
+            'id': '50355319',
-
+        video_id = self._match_id(url)
-        'file': '30-vies_S04E41.mp4',
+            'id': '30-vies_S04E41',
-            'file': '80187.mp4',
+                'id': '80187',
-            'file': '19705.mp4',
+                'id': '19705',
-                r'data-node-id="(\d+?)"',
+                r'<div\s+class="player".*?data-id="(\d+?)"',
-        'file': '75524534.mp4',
+            'id': '75524534',
-        'file': '613340.mp4',
+            'id': '613340',
-                  r'ligthboxvideo/base-de-medias/webtv/(.*)')
+    _VALID_URL = r'http://.*?\.defense\.gouv\.fr/layout/set/ligthboxvideo/base-de-medias/webtv/(?P<id>[^/?#]*)'
-            "title": "attaque-chimique-syrienne-du-21-aout-2013-1"
+        'info_dict': {
-        title = re.match(self._VALID_URL, url).group(1)
+        title = self._match_id(url)
-                }
+        info = self._download_json(json_url, title, 'Downloading JSON config')
-                                })
+                if rtmp_video_url.endswith('siteunavail.png'):
-            'file': '853555.mp4',
+                'id': '853555',
-                               webpage, re.DOTALL)
+            m_vevo = re.search(
-        'skip': 'Blocked outside of Germany',
+        'only_matching': True,
-    _VALID_URL = r'^https?://(www\.)?mpora\.(?:com|de)/videos/(?P<id>[^?#/]+)'
+    _VALID_URL = r'https?://(www\.)?mpora\.(?:com|de)/videos/(?P<id>[^?#/]+)'
-        'file': 'AAdo8okx4wiz.mp4',
+            'id': 'AAdo8okx4wiz',
-
+        video_id = self._match_id(url)
-        data = json.loads(data_json)
+        data = self._parse_json(data_json, video_id)
-    compat_basestr = basestring  # Python 2
+    compat_basestring = basestring  # Python 2
-    compat_basestr = str
+    compat_basestring = str
-        req_is_string = isinstance(req, basestring if sys.version_info < (3, 0) else compat_str)
+        req_is_string = isinstance(req, compat_basestring)
-        qs, _coerce_result = qs, unicode
+        qs, _coerce_result = qs, compat_str
-try:
+    compat_basestring,
-        if isinstance(xpath, unicode):
+        if isinstance(xpath, compat_str):
-    if not isinstance(s, basestring if sys.version_info < (3, 0) else compat_str):
+    if not isinstance(s, compat_basestring):
-    if sys.version_info < (3, 0) and isinstance(s, unicode):
+    if sys.version_info < (3, 0) and isinstance(s, compat_str):
-            if not (resource_id or resource_height):
+            if not resource_id:
-            })
+            resource_url = resource['url']
-            if not resource_id:
+            resource_height = resource.get('height')
-                'height': resource['height']
+                'height': resource_height
-        media=doc.findall(_add_ns('media'))
+        media = doc.findall(_add_ns('media'))
-        }],
+        'playlist': [
-    _VALID_URL = r'http://www\.rtve\.es/alacarta/videos/[^/]+/[^/]+/(?P<id>\d+)'
+    _VALID_URL = r'http://www\.rtve\.es/(m/)?alacarta/videos/[^/]+/[^/]+/(?P<id>\d+)'
-        }
+        },
-                                'format_id': rf,
+                                'format_id': '%s+%s' % (formats_info[0].get('format_id'),
-                              extended-interviews/(?P<interID>[0-9a-z]+)/(?:playlist_tds_extended_)?(?P<interview_title>.*?)(/.*?)?)))
+                              extended-interviews/(?P<interID>[0-9a-z]+)/
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:(?:(?:programmes|iplayer/(?:episode|playlist))/)|music/clips[/#])(?P<id>[\da-z]{8})'
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:(?:(?:programmes|iplayer(?:/[^/]+)?/(?:episode|playlist))/)|music/clips[/#])(?P<id>[\da-z]{8})'
-    int_or_none,
+    str_to_int,
-            r'<meta itemprop="interactionCount" content="UserLikes:([0-9]+)"',
+        like_count = str_to_int(self._search_regex(
-            r'<meta itemprop="interactionCount" content="UserPlays:([0-9]+)"',
+        view_count = str_to_int(self._search_regex(
-            webpage, 'upload date'))
+            webpage, 'upload date', default=None))
-from .nhl import NHLIE, NHLVideocenterIE
+from .nhl import (
-        return self._extract_video(data[0])
+        video_id = self._match_id(url)
-    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console(?:\?(?:.*?[?&])?)id=(?P<id>[-0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/(?:console)?(?:\?(?:.*?[?&])?)id=(?P<id>[-0-9a-zA-Z]+)'
-    _VALID_URL = r'https?://(?:www\.)?dr\.dk/tv/se/(?:[^/]+/)+(?P<id>[\da-z-]+)(?:[/#?]|$)'
+    _VALID_URL = r'https?://(?:www\.)?dr\.dk/tv/se/(?:[^/]+/)*(?P<id>[\da-z-]+)(?:[/#?]|$)'
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class MTVServicesInfoExtractor(InfoExtractor):
+class MTVServicesInfoExtractor(SubtitlesInfoExtractor):
-        return self._get_videos_info(mgid)
+
-         m\.spike\.com/videos/video.rbml\?id=(?P<mobile_id>[^&]+))
+        (?:www\.spike\.com/(?:video-clips|(?:full-)?episodes)/.+|
-        if mobile_id is not None:
+        mobile_id = self._match_id(url)
-                self.report_error('Media is DRM protected')
+            if 'id' not in e.attrib:
-            self.report_error('Media is DRM protected')
+            self.report_error('Unsupported DRM')
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-        uuids = re.findall(r'data-video-uuid="([^"]+)"', webpage)
+
-                }.get(s.get('type'))
+                }.get(s.get('type')),
-                                 "http", "https", "rtsp", "rtmp", "m3u8" or so.
+                                 "http", "https", "rtsp", "rtmp", "rtmpe",
-            for k, v in test_info_dict.items())
+        info_dict_str = ''
-        formats = [{'format_id': 'main', 'url': item.find('./{http://search.yahoo.com/mrss/}content').attrib['url']}]
+        formats = [{
-            'md5': '4d47034979d9390d14acdf59c4935bc2',
+            'md5': '31099eeb4bc906712c5f40092045108d',
-        })
+        formats = [{'format_id': 'main', 'url': item.find('./{http://search.yahoo.com/mrss/}content').attrib['url']}]
-                    \s*{[^}]+? ["']?clip["']?\s*:\s*\{\s*
+                    \s*\{[^}]+? ["']?clip["']?\s*:\s*\{\s*
-        return re.split('(?m)^\s*try\s*{', js)[0] \
+        return re.split('(?m)^\s*try\s*\{', js)[0] \
-__version__ = '2015.01.30.1'
+__version__ = '2015.01.30.2'
-                        embed_webpage if age_gate else video_webpage, 'JS player URL')
+                        ASSETS_RE,
-__version__ = '2015.01.30'
+__version__ = '2015.01.30.1'
-__version__ = '2015.01.25'
+__version__ = '2015.01.30'
-            'title': 'Videoinstallation fÃ¼r eine Kaufhausfassade'}
+            'title': 'Videoinstallation fÃ¼r eine Kaufhausfassade'
-
+from ..compat import compat_str
-    _VALID_URL = r'^http://www.dctp.tv/(#/)?filme/(?P<id>.+?)/$'
+    _VALID_URL = r'http://www.dctp.tv/(#/)?filme/(?P<id>.+?)/$'
-        version_json = self._download_json(base_url + 'version.json', video_id)
+        version_json = self._download_json(
-        object_id = str(info_json['object_id'])
+            '{0}{1}/restapi/slugs/{2}.json'.format(base_url, version, video_id),
-            '{0}{1}/restapi/media/{2}.json'.format(base_url, version, object_id), video_id)
+            '{0}{1}/restapi/media/{2}.json'.format(base_url, version, object_id),
-        servers_json = self._download_json('http://www.dctp.tv/streaming_servers/', video_id)
+        servers_json = self._download_json(
-            video_url = self._download_webpage(feed_url, news_id)
+            video_url = self._download_webpage(
-            'view_count': news_count,
+
-   compat_urllib_request
+    compat_urllib_request
-            parser.error('you must provide at least one URL')
+            parser.error(
-            'real_time': True,
+            'rtmp_real_time': True,
-            'id': 'videoinstallation-fuer-eine-kaufhausfassade',
+            'id': '1324',
-        object_id = info_json['object_id']
+        object_id = str(info_json['object_id'])
-            'id': video_id,
+            'id': object_id,
-            'ext': 'flv'
+            'ext': 'flv',
-            '{}{}/restapi/slugs/{}.json'.format(base_url, version, video_id), video_id)
+            '{0}{1}/restapi/slugs/{2}.json'.format(base_url, version, video_id), video_id)
-            '{}{}/restapi/media/{}.json'.format(base_url, version, object_id), video_id)
+            '{0}{1}/restapi/media/{2}.json'.format(base_url, version, object_id), video_id)
-        play_path = 'mp4:{}_dctp_0500_{}.m4v'.format(uuid, ratio)
+        play_path = 'mp4:{0}_dctp_0500_{1}.m4v'.format(uuid, ratio)
-# coding: utf-8
+# -*- coding: utf-8 -*-
-            raise ExtractorError('The news includes no videos!')
+        if self._search_regex(r'(CTSPlayer2)', page, 'CTSPlayer2 identifier', default=None):
-        feed_page = self._download_webpage(feed_url, news_id)
+            return {
-        timestamp = parse_iso8601(time, delimiter=' ')
+        datetime_str = self._html_search_regex(
-            'timestamp': timestamp
+            'timestamp': timestamp,
-                thumbnails = [{'url': thumbnail}]
+                info_dict['thumbnails'] = thumbnails = [{'url': thumbnail}]
-    _VALID_URL = r'http://vlog.xuite.net/(?:play|embed)/(?P<id>%s)' % _REGEX_BASE64
+    _VALID_URL = r'https?://vlog\.xuite\.net/(?:play|embed)/(?P<id>%s)' % _REGEX_BASE64
-)
+from ..compat import compat_urllib_parse_unquote
-    parse_duration
+    parse_duration,
-    _VALID_URL = r'http://vlog.xuite.net/play/(?P<id>%s)(/.*)?' % REGEX_BASE64
+    _REGEX_BASE64 = r'(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?'
-            'id': 'RGkzc1ZULTM4NjA5MTQuZmx2',
+            'id': '3860914',
-            'timestamp': 1314932940,
+            'duration': 247.246,
-        }
+        },
-            'id': 'TkRZNjhULTM0NDE2MjkuZmx2',
+            'id': '3441629',
-            'timestamp': 1299383640,
+            'duration': 217.399,
-        }
+        },
-            'id': 'bWo1N1pLLTIxMzAxMTcwLmZsdg==',
+            'id': '21301170',
-            'timestamp': 1421481240,
+            'description': 'å­å¹:ãæ¥µå½±å­å¹ç¤¾ã',
-        }
+        },
-    def _flv_config(self, media_id):
+    def _extract_flv_config(self, media_id):
-
+        flv_config = self._download_xml(
-
+            # CDATA may be empty in flv config
-
+                continue
-        flv_config = self._flv_config(media_id)
+        webpage = self._download_webpage(url, video_id)
-        timestamp_gmt = timestamp_local - CST_ZONE * 3600
+        video_id = self._html_search_regex(
-        ret_attrs = {
+        FORMATS = {
-            'categories': [flv_config['category']]
+            'description': flv_config.get('description'),
-        return ret_attrs
+        kwargs = {}
-            req)
+            req, **kwargs)
-    IE_DESC = 'SÃ¼ddeutscher Rundfunk'
+    IE_DESC = 'SaarlÃ¤ndischer Rundfunk'
-    _VALID_URL = r'https?://(?:www\.)?ivi\.ru/(?:watch/(?:[^/]+/)?|video/player\?.*?videoId=)(?P<videoid>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?ivi\.ru/(?:watch/(?:[^/]+/)?|video/player\?.*?videoId=)(?P<id>\d+)'
-        video_id = mobj.group('videoid')
+        video_id = self._match_id(url)
-                           ]
+        data = {
-        video_json_page = self._download_webpage(request, video_id, 'Downloading video JSON')
+        video_json_page = self._download_webpage(
-            raise ExtractorError('Unable to download video %s: %s' % (video_id, error['message']), expected=True)
+            raise ExtractorError(
-                'format_id': filed['profile_id'] or filed['profile_name'],
+                'format_id': format_id,
-                f['format_id'] = (filed['profile_id'] or filed['profile_name']) + '-cdn'
+                f['format_id'] = format_id + '-cdn'
-                f['format_id'] = (filed['profile_id'] or filed['profile_name']) + '-html5'
+                f['format_id'] = format_id + '-html5'
-
+        mobj = re.search(
-                re.search(r'OO.Player.create\([\'"].*?[\'"],\s*[\'"](?P<ec>.{32})[\'"]', webpage))
+        mobj = (re.search(r'player\.ooyala\.com/[^"?]+\?[^"]*?(?:embedCode|ec)=(?P<ec>[^"&]+)', webpage) or
-        "url": "http://www.viddler.com/v/43903784",
+        'url': 'http://www.viddler.com/v/43903784',
-            "uploader": "viddler",
+            'title': 'Video Made Easy',
-            "duration": 100.89,
+            'duration': 100.89,
-        "info_dict": {
+        'url': 'http://www.viddler.com/v/4d03aad9/',
-        "info_dict": {
+        'url': 'http://www.viddler.com/player/221ebbbd/0/',
-                'format_id': filed['profile_id'],
+                'format_id': filed['profile_id'] or filed['profile_name'],
-                f['format_id'] = filed['profile_id'] + '-cdn'
+                f['format_id'] = (filed['profile_id'] or filed['profile_name']) + '-cdn'
-                f['format_id'] = filed['profile_id'] + '-html5'
+                f['url'] = self._proto_relative_url(filed['html5_video_source'])
-            '_type': 'video',
+
-
+        real_time = info_dict.get('real_time', False)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        data = self._download_json(json_url, video_id)['video']
+        headers = {'Referer': 'http://static.cdn-ec.viddler.com/js/arpeggio/v2/embed.html'}
-                f['url'] = self._proto_relative_url(filed['cdn_url'])
+                f['url'] = self._proto_relative_url(filed['cdn_url'], 'http:')
-            'title': 'å­¤å®ååç-æ­å¾·é½'
+            'title': 'å­¤å®ååç-æ­å¾·é½',
-            }]
+            urls = [flv_config['src'], flv_config['hq_src']]
-    _VALID_URL = r'https?://(?:www\.)?lnkgo\.alfa\.lt/visi\-video/(?P<show>[^/]+)/ziurek\-(?P<display_id>[A-Za-z0-9\-]+)'
+    _VALID_URL = r'https?://(?:www\.)?lnkgo\.alfa\.lt/visi-video/(?P<show>[^/]+)/ziurek-(?P<id>[A-Za-z0-9-]+)'
-        display_id = mobj.group('display_id')
+        display_id = self._match_id(url)
-            r'VideoDuration = "([^"]+)"', webpage, 'duration', fatal=False))
+        config = self._parse_json(self._search_regex(
-        age_limit = self._AGE_LIMITS.get(pg_rating.upper(), 0)
+        if config.get('pGeo'):
-            sources_js, video_id, transform_source=js_to_json)
+        formats = [{
-                })
+        m = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<play_path>.+)$', config['EpisodeVideoLink'])
-            'duration': duration,
+            'duration': int_or_none(config.get('VideoTime')),
-            'age_limit': age_limit,
+            'age_limit': self._AGE_LIMITS.get(config.get('PGRating'), 0),
-        formats = [(int(f.attrib.get('bitrate', -1)), f) for f in doc.findall(_add_ns('media'))]
+        formats = [(int(f.attrib.get('bitrate', -1)), f)
-            (?P<key>width|height|tbr|abr|vbr|filesize)
+            (?P<key>width|height|tbr|abr|vbr|filesize|fps)
-            ' This works for filesize, height, width, tbr, abr, and vbr'
+            ' This works for filesize, height, width, tbr, abr, vbr, and fps'
-        filename = self.prepare_filename(info_dict)
+        info_dict['_filename'] = filename = self.prepare_filename(info_dict)
-__version__ = '2015.01.23.4'
+__version__ = '2015.01.25'
-)
+from ..compat import compat_urlparse
-                        continue
+        self._check_formats(formats, video_id)
-                        'format_id': target,
+                        'format_id': format_id,
-                        'preference': -1 if target == 'HDS' else -2,
+                        'preference': preference,
-                'description': 're:'
+                'description': 're:.*groundbreaking video review series.*'
-        
+        continue_dl = info_dict.get('continuedl', False)
-        args = basic_args + [[], ['--skip', '1']][not live and self.params.get('continuedl', False)]
+
-                                       width : height ratio as float.
+                                 video's pixels are not square.
-    _VALID_URL = r'http?://(?P<url>(?P<domain>(www\.)?rtl2\.de)/.*/(?P<video_id>.*))/'
+    _VALID_URL = r'http?://(?:www\.)?rtl2\.de/[^?#]*?/(?P<id>[^?#/]*?)(?:$|/(?:$|[?#]))'
-            },
+        'url': 'http://www.rtl2.de/sendung/grip-das-motormagazin/folge/folge-203-0',
-            },
+    }, {
-    ]
+    }]
-        if not url.endswith("/"):
+        # Some rtl2 urls have no slash at the end, so append it.
-        video_id = mobj.group('video_id')
+        video_id = self._match_id(url)
-
+        vico_id = self._html_search_regex(
-        thumbnail = video_info["video"]["image"]
+        info = self._download_json(info_url, video_id)
-        download_url = download_url.replace("\\", "")
+        download_url = video_info['streamurl']
-            }]
+            'url': download_url,
-            'description' : description,
+            'thumbnail': thumbnail,
-    _VALID_URL = r'http?://(?P<url>(?P<domain>(www\.)?rtl2\.de)/.*/(?P<video_id>.*))'
+    """Information Extractor for RTL2"""
-                'title': 'GRIP sucht den Sommerk\xf6nig',
+                'title': 'GRIP sucht den SommerkÃ¶nig',
-                #'skip_download': True,
+                'skip_download': True,
-                'description' : 'Matthias, Det und Helge treten gegeneinander an.'
+                'ext': 'mp4',
-                #'skip_download': True,
+                'skip_download': True,
-        vivi_id = self._html_search_regex(r'vivi_id\s*:\s*([0-9]+)', webpage, '%s');
+        webpage = self._download_webpage(url, video_id)
-        video_info = json.loads(webpage)
+        video_info = self._download_json(info_url, video_id)
-        #ext = self._html_search_regex(r'streamurl\":\".*?(\..{2,4})\"', webpage, '%s');
+        download_url = video_info["video"]["streamurl"]
-            'url' : download_url,
+        #Debug output
-        formats.append(fmt)
+                'no_resume' : True,
-                       The dict may also have some of the following entries:
+                       * status: One of "downloading" and "finished".
-from ..utils import int_or_none
+from ..utils import (
-        'md5': '8edd46ee8aa6b265fb5ed6cf05c36bc9',
+        'md5': '138d5652618bf0f03878978db9bef1ee',
-            'ext': 'mp4',
+            'ext': 'm4v',
-
+        video_id = self._match_id(url)
-            duration *= 60
+            r'Duration: (\d+) minutes', webpage, 'duration', fatal=False),
-            ['hq', r'href="(http://ubumexico\.centro\.org\.mx/video/[^"]+)"']
+            ('sq', r"'flashvars'\s*,\s*'file=([^']+)'"),
-
+        preference = qualities([fid for fid, _ in FORMAT_REGEXES])
-                          if value and key in ('title', 'description', 'uploader', 'upload_date', 'timestamp', 'uploader_id', 'location'))
+                          if value and key in ('id', 'title', 'description', 'uploader', 'upload_date', 'timestamp', 'uploader_id', 'location'))
-                    'id': '9.-heaven-or-hell-chimaca-ft-zuse-prod-by-dj-fu',
+                    'title': 'PPP (Pistol P Project) - 9. Heaven or Hell (CHIMACA) ft Zuse (prod by DJ FU)',
-                'playlistend': 8,
+                'playliststart': 9,
-    noresizebuffer, retries, continuedl, noprogress, consoletitle
+    noresizebuffer, retries, continuedl, noprogress, consoletitle,
-    max_filesize:      Skip files larger than this size
+    verbose:            Print additional info to stdout.
-            parser.error('invalid retry count specified')
+        if opts.retries in ('inf', 'infinite'):
-        'retries': opts.retries,
+        'retries': opts_retries,
-        help='number of retries (default is %default)')
+        help='number of retries (default is %default), or "infinite".')
-                entries = ie_entries[playliststart:playlistend]
+                if playlistitems:
-                    playliststart, playlistend)
+                if playlistitems:
-                    ie_entries, playliststart, playlistend))
+                if playlistitems:
-                                            (info_dict['thumbnail'], compat_str(err)))
+        self._write_thumbnails(info_dict, filename)
-                t.get('width'), t.get('height'), t.get('url')))
+                t.get('preference'), t.get('width'), t.get('height'),
-        if self.params.get('listformats', None):
+        if self.params.get('listformats'):
-                       (info_dict['id'], header_line, '\n'.join(formats_s)))
+        self.to_screen(
-from ..utils import int_or_none
+from ..utils import (
-            'thumbnail': info.get('images', {}).get('large'),
+            'thumbnails': thumbnails,
-    filesystem.add_option(
+    thumbnail = optparse.OptionGroup(parser, 'Thumbnail images')
-    unescapeHTML,
+    js_to_json,
-    _VALID_URL = r'https?://krasview\.ru/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://krasview\.ru/(?:video|embed)/(?P<id>\d+)'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'flashvars\s*:\s*({.+?})\s*}\);', webpage, 'flashvars'))
+        flashvars = json.loads(js_to_json(self._search_regex(
-        filesize = int(flashvars['size'])
+        title = self._og_search_title(webpage)
-
+        no_resume = info_dict.get('no_resume', False)
-        args = basic_args + [[], ['--resume', '--skip', '1']][not live and self.params.get('continuedl', False)]
+        if not no_resume:
-        for key, val in self._calc_headers(info_dict).items():
+        for key, val in info_dict['http_headers'].items():
-        for key, val in self._calc_headers(info_dict).items():
+        for key, val in info_dict['http_headers'].items():
-        for key, val in self._calc_headers(info_dict).items():
+        for key, val in info_dict['http_headers'].items():
-            res['User-Agent'] = ua
+        add_headers = info_dict.get('http_headers')
-                'user_agent': 'QuickTime compatible (youtube-dl)',
+                'http_headers': {
-            'http_referer': iframe_url,
+            'http_headers': {
-            'user_agent': 'mobile',
+            'http_headers': {
-            headers['Youtubedl-user-agent'] = info_dict['user_agent']
+            headers['User-agent'] = info_dict['user_agent']
-            request.add_header('Youtubedl-user-agent', self._USER_AGENT)
+            request.add_header('User-Agent', self._USER_AGENT)
-        req.add_header('Youtubedl-user-agent', 'youtube-dl')
+        req.add_header('User-Agent', 'youtube-dl')
-        req.add_header('Youtubedl-user-agent', 'curl/7')
+        req.add_header('User-Agent', 'curl/7')
-        stdout, stderr = p.communicate()
+            cmd, stderr=subprocess.PIPE)
-        (?:https?://)?[^/]+/watch\?(?:
+        (?:https?://)?
-        (?:https?://)?(?:www\.)?youtube\.com/attribution_link\?a=[^&]+$
+            annotation_id=annotation_[^&]+|
-    _VALID_URL = r'https?://(?:www\.)youtube\.com/watch\?v=(?P<id>[0-9A-Za-z_-]{1,10})$'
+    _VALID_URL = r'https?://(?:www\.)?youtube\.com/watch\?v=(?P<id>[0-9A-Za-z_-]{1,10})$'
-    _VALID_URL = r'http://(?:www\.)?video\.tt/(?:video\/|embed\/|watch_video\.php\?v=)(?P<id>[\da-zA-Z]{9})'
+    _VALID_URL = r'http://(?:www\.)?video\.tt/(?:(?:video|embed)/|watch_video\.php\?v=)(?P<id>[\da-zA-Z]{9})'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'http://(?:www\.)?video\.tt/(?:video/|watch_video\.php\?v=)(?P<id>[\da-zA-Z]{9})'
+    _VALID_URL = r'http://(?:www\.)?video\.tt/(?:video\/|embed\/|watch_video\.php\?v=)(?P<id>[\da-zA-Z]{9})'
-from .f4m import F4mFD
+    external_downloader = params.get('external_downloader')
-            self.to_screen('[debug] rtmpdump command line: ' + shell_quote(str_args))
+        self._debug_cmd(args, subprocess_encoding, exe='rtmpdump')
-                    fd = get_suitable_downloader(info)(self, self.params)
+                    fd = get_suitable_downloader(info, self.params)(self, self.params)
-    determine_ext,
+    determine_protocol,
-def get_suitable_downloader(info_dict):
+
-        return HttpFD
+    protocol = determine_protocol(info_dict)
-        }
+        }
-
+from ..utils import determine_ext
-        'md5': 'a2ba71eebf523859fe527a61018f723e',
+        'md5': 'b7c9bbd4eb3a226ab91093714dcaa480',
-            'ext': 'mp4',
+            'ext': 'flv',
-            video_url = _decode(crypted_url)
+        fmts = {}
-                'quality': i,
+                'url': url,
-                    f['tbr'] = int(m.group('tbr'))
+            if fname in qualities:
-__version__ = '2015.01.23.3'
+__version__ = '2015.01.23.4'
-                                           about it, warn otherwise
+                                           about it, warn otherwise (default)
-                        assert fixup_policy == 'ignore'
+                        assert fixup_policy in ('ignore', 'never')
-        '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'vcodec': 'none', 'abr': 256, 'preference': -50},
+        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'vcodec': 'none', 'abr': 48, 'preference': -50, 'container': 'm4a_dash'},
-            return
+            return True, info
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class AtresPlayerIE(InfoExtractor):
+class AtresPlayerIE(SubtitlesInfoExtractor):
-        'md5': '0813c2430bea7a46bf13acf3406992f4',
+        'md5': '50f79e05ba149149c1b4ea961223d5b3',
-            'ext': 'mp4',
+            'ext': 'flv',
-        'md5': 'd3f1367d14cc3c15bf24fbfbe04b9abf',
+        'md5': 'b13a29626183c9d33944e6a04f41aafc',
-        } for s in sources]
+        } for i, s in enumerate(sources)]
-            for _, video_url in fmt_json['resultObject'].items():
+            for format_id, video_url in fmt_json['resultObject'].items():
-                        'format_id': 'android',
+                        'format_id': 'android-%s' % format_id,
-    _VALID_URL = r'^(?:http://)?(?:\w+\.)?liveleak\.com/view\?(?:.*?)i=(?P<video_id>[\w_]+)(?:.*)'
+    _VALID_URL = r'https?://(?:\w+\.)?liveleak\.com/view\?(?:.*?)i=(?P<id>[\w_]+)(?:.*)'
-        video_id = mobj.group('video_id')
+        video_id = self._match_id(url)
-            if not videos:
+            page_entries = self._extract_playlist_page(response)
-            entries.extend([self.url_result(video['url']) for video in videos])
+            entries.extend(page_entries)
-        return self.playlist_result(entries, channel_id, channel_name)
+        return self.playlist_result(
-        }
+        }
-                    formats.extend(self._extract_f4m_formats(video_url[:-9] + '/manifest.f4m', video_id))
+                    if 'geodeswowsmpra3player' in video_url:
-        res.append((1, frag_number))
+    fragments_counter = itertools.count(first_frag_number)
-__version__ = '2015.01.23.2'
+__version__ = '2015.01.23.3'
-        dest='sleep_interval',
+        dest='sleep_interval', type=float,
-__version__ = '2015.01.23.1'
+__version__ = '2015.01.23.2'
-        return YoutubeDLHTTPSHandler(params, https_conn_class=HTTPSConnectionV3, **kwargs)
+        return YoutubeDLHTTPSHandler(params, **kwargs)
-        context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
+        context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)
-                    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file)
+                    self.sock = ssl.wrap_socket(
-
+        video_id = self._match_id(url)
-        if not re.match(r'^\s*<', first_bytes.decode('utf-8', 'replace')):
+        if not is_html(first_bytes):
-__version__ = '2015.01.23'
+__version__ = '2015.01.23.1'
-__version__ = '2015.01.22'
+__version__ = '2015.01.23'
-        }
+        }
-            'p': '9386337',
+            'p': random.randint(1000000, 10000000),
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    # urls can be abbreviations like :thedailyshow or :colbert
+    # urls can be abbreviations like :thedailyshow
-    _VALID_URL = r'''(?x)^(:(?P<shortname>tds|thedailyshow|cr|colbert|colbertnation|colbertreport)
+    _VALID_URL = r'''(?x)^(:(?P<shortname>tds|thedailyshow)
-            webpage, 'title', fatal=False)
+            webpage, 'mp3 URL', fatal=False)
-    _VALID_URL_BASE = r'http://(?:www\.)?twitch\.tv'
+    _VALID_URL_BASE = r'https?://(?:www\.)?twitch\.tv'
-            % (item_id, access_token['token'], access_token['sig']),
+            '%s/vod/%s?nauth=%s&nauthsig=%s'
-            r'unescape\("([^"]+)"\)', webpage, 'escaped data')
+        try:
-__version__ = '2015.01.16'
+__version__ = '2015.01.22'
-from ..compat import compat_urllib_request
+from ..compat import (
-        'md5': 'd594c573227a89f4256f0b03e68c80cc',
+        'md5': 'ab6ec33c8fed6556029337c7885eb4e0',
-            'ext': 'mp3',
+            'ext': 'wav',
-        }]
+        formats = []
-            'display-id': display_id,
+            'display_id': display_id,
-    IE_NAME = 'twitch:profile'
+    IE_NAME = 'twitch:past_broadcasts'
-            }
+    _VALID_URL = r'https?://(?:.+?\.)?streetvoice\.com/[^/]+/songs/(?P<id>[0-9]+)'
-    ]
+    }, {
-        info_dict = self._download_json(api_url, song_id)
+        song = self._download_json(
-            'ext': 'mp3',
+            'url': song['file'],
-            'description': '%s - %s' % (title, author)
+            'description': '%s - %s' % (author, title),
-from .twitch import TwitchIE
+from .twitch import (
-    _PAGE_LIMIT = 100
+class TwitchBaseIE(InfoExtractor):
-        response = super(TwitchIE, self)._download_json(url, video_id, note)
+        response = super(TwitchBaseIE, self)._download_json(url, video_id, note)
-            'c': 'chapter',
+    def _real_initialize(self):
-        info = self._extract_info(self._download_json(
+
-            return info
+            'Downloading %s info JSON' % self._ITEM_TYPE))
-            'Downloading %s playlist JSON' % ITEMS[item])
+            '%s/api/videos/%s%s' % (self._API_BASE, self._ITEM_SHORTCUT, item_id), item_id,
-        self._login()
+    def _real_extract(self, url):
-            self._LOGIN_URL, None, 'Downloading login page')
+class TwitchVideoIE(TwitchItemBaseIE):
-            login_page, 'authenticity token')
+    _TEST = {
-            request, None, 'Logging in as %s' % username)
+class TwitchChapterIE(TwitchItemBaseIE):
-                'Unable to login: %s' % m.group('msg').strip(), expected=True)
+    _TEST = {
-            return self.playlist_result(entries, channel_id, channel_name)
+        item_id = self._match_id(url)
-                if not all_videos or not 'videos' in all_videos:
+                if not all_videos or 'videos' not in all_videos:
-        info_url = 'http://cnn.com/video/data/3.0/%s/index.xml' % path
+        info_url = 'http://edition.cnn.com/video/data/3.0/%s/index.xml' % path
-        'md5': '275b326f85d80dff7592a9820f5dc887',
+        'md5': '689034c2a3d9c6dc4aa72d65a81efd01',
-            'id': 'bestoftv/2014/12/21/sotu-crowley-president-obama-north-korea-not-going-to-be-intimidated.cnn',
+            'id': 'bestoftv/2014/12/21/ip-north-korea-obama.cnn',
-            'upload_date': '20141220',
+            'title': 'Obama: Cyberattack not an act of war',
-            'title': 'shadow phenomenon weird',
+    _VALID_URL = r'http://(?:.+?\.)?tinypic\.com/player\.php\?v=(?P<id>[^&]+)&s=\d+'
-    }
+    ]
-                    info = next(v for v in all_videos if v['mpxId'] == mpxid)
+                    all_videos = self._download_json(playlist_url, title)
-            'description': 'Bohun dowiaduje siÄ o zÅamaniu przez kniahiniÄ danego mu sÅowa i wyrusza do RozÅogÃ³w. Helenie w ostatniej chwili udaje siÄ uciec dziÄki pomocy ZagÅoby.',
+        'md5': '8aa518c15e5cc32dfe8db400dc921fbb',
-            #  'description': 'WÅADEK\nCzesÅaw prosi MariÄ o dostarczenie WÅadkowi zarazki tyfusu. JeÅli zachoruje zostanie przewieziony do szpitala skÄd Åatwiej bÄdzie go odbiÄ. Czy matka zdecyduje siÄ zaraziÄ syna? Karol odwiedza WandÄ przyznaje siÄ, Å¼e jÄ oszukiwaÅ, ale ostrzega teÅ¼, Å¼e grozi jej aresztowanie i nalega, Å¼eby wyjechaÅa z Warszawy. Czy dziewczyna zdecyduje siÄ znÃ³w oddaliÄ od ukochanego? Rozpoczyna siÄ akcja odbicia WÅadka.',
+        'md5': 'c3b15ed1af288131115ff17a17c19dda',
-        },
+        'md5': 'c3b15ed1af288131115ff17a17c19dda',
-            'skip_download': 'true',
+
-            r'{name:\s*([\'"])SeriesTitle\1,\s*value:\s*\1(?P<series>.*?)\1},',
+        title = self._search_regex(
-        description = self._og_search_description(webpage, default=None)
+        if series_title:
-        if video_url is None:
+        if not video_url:
-            'description': description,
+            'thumbnail': thumbnail,
-
+        video_id = self._match_id(url)
-        help='account password')
+        help='account password. If this option is left out, youtube-dl will ask interactively.')
-__version__ = '2015.01.15.1'
+__version__ = '2015.01.16'
-        title = self._search_regex(r'album_title : "(.*?)"', webpage, 'title')
+        title = self._search_regex(
-    clean_html,
+    parse_iso8601,
-    unified_strdate,
+            'timestamp': 1383263892,
-        webpage = self._download_webpage(webpage_url, video_id)
+        webpage = self._download_webpage(url, video_id)
-        self.report_extraction(video_id)
+        title = self._html_search_meta('name', webpage)
-        thumbnail_url = self._search_regex(r'image:\s*"([^"]*)', playlist_json, 'Thumbnail', fatal=False)
+        categories_html = self._search_regex(
-        (uploader, uploader_id) = (mobj.group('name'), mobj.group('id')) if mobj else (clean_html(uploader_str), None)
+        view_count = str_to_int(self._search_regex(
-            duration = parse_duration(self._search_regex(r'Length: (\d+m\d+s)', description, 'duration', fatal=False))
+        params_js = self._search_regex(
-        token_url = "http://tkn.4tube.com/{0}/desktop/{1}".format(media_id, "+".join(sources))
+        token_url = 'http://tkn.4tube.com/{0}/desktop/{1}'.format(
-            'thumbnail': thumbnail_url,
+            'categories': categories,
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-        r'''(?ix)T?
+        r'''(?ix)(?:P?T)?
-
+            '-c:s', 'mov_text',
-            opts.extend(['-map', '%d:0' % (i + 1), '-c:s:%d' % i, 'mov_text'])
+            opts.extend(['-map', '%d:0' % (i + 1)])
-        temp_filename = filename + '.temp'
+        temp_filename = prepend_extension(filename, 'temp')
-        opts = ['-map', '0:0', '-map', '0:1', '-c:v', 'copy', '-c:a', 'copy']
+        opts = [
-__version__ = '2015.01.15'
+__version__ = '2015.01.15.1'
-            r'\.sig\|\|([a-zA-Z0-9\$]+)\(', jscode,
+            r'\.sig\|\|([a-zA-Z0-9$]+)\(', jscode,
-            r'\.sig\|\|([a-zA-Z0-9]+)\(', jscode,
+            r'\.sig\|\|([a-zA-Z0-9\$]+)\(', jscode,
-        'md5': '240fb5bcf9199961f48eb17839b084d6',
+        'url': 'http://videomega.tv/?ref=QR0HCUHI1661IHUCH0RQ',
-            'id': 'GKeGPVedBe',
+            'id': 'QR0HCUHI1661IHUCH0RQ',
-            'title': 'XXL - All Sports United',
+            'title': 'Big Buck Bunny',
-        webpage = self._download_webpage(url, video_id)
+
-        url = self._search_regex(r'file:\s*"([^"]+)"', playlist, 'URL')
+        video_url = self._search_regex(r'file:\s*"([^"]+)"', playlist, 'URL')
-            'url': url,
+            'url': video_url,
-from ..utils import (
+from ..compat import (
-__version__ = '2015.01.11'
+__version__ = '2015.01.15'
-        context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)
+        context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)
-            raise ExtractorError('Video %s has not been approved by moderator' % video_id, expected=True)
+        video_url = video.get('_vidURL') or video.get('_vidURL_mp4')
-            raise ExtractorError('Video %s does not exist' % video_id, expected=True)
+            if video.get('error'):
-from ..compat import compat_urlparse
+from ..compat import (
-        ]
+        formats = []
-        }]
+        thumbnail = {
-        age_limit = self._AGE_LIMITS.get(pg_rating, 0)
+        age_limit = self._AGE_LIMITS.get(pg_rating.upper(), 0)
-            'thumbnails': thumbnails,
+            'thumbnails': [thumbnail],
-class NPOIE(InfoExtractor):
+class NPOBaseIE(InfoExtractor):
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        token = self._search_regex(r'npoplayer\.token = "(.+?)"', token_page, 'token')
+
-            if h not in req.headers:
+            # Capitalize is needed because of Python bug 2275: http://bugs.python.org/issue2275
-    if s is None:
+    if not isinstance(s, basestring if sys.version_info < (3, 0) else compat_str):
-    unified_strdate,
+    fix_xml_ampersands,
-                if not '.asf' in stream_url:
+                if '.asf' not in stream_url:
-from ..utils import parse_iso8601
+from .common import InfoExtractor
-            'duration': 3664000,
+            'duration': 3664,
-    },{
+    }, {
-            'duration': 7369000,
+            'duration': 7369,
-        
+        webpage = self._download_webpage(url, url_id)
-            info = json.loads(self._html_search_regex(r'({.*?' + url_id + '.*})', webpage, 'json'))
+            info = json.loads(self._html_search_regex(r'({.*?%s.*})' % url_id, webpage, 'json'))
-        
+
-        
+        duration = int_or_none(info.get('Duration'), scale=1000)
-                return {'width': int(match.group(1)), 'height': int(match.group(2)), 'bitrate': int(match.group(3)), 'ext': match.group(4)}
+                return {
-        
+                return {
-        
+
-                    formats.append({
+                    format = parse_filename_info(file['Location'])
-                        'ext': fileinfo['ext'],
+                    formats.append(format)
-                    formats.append({
+                    format = parse_filename_info(file['Location'])
-                        'ext': fileinfo['ext'],
+                    formats.append(format)
-        description = "{}\n{}\n{}\n".format(info['Description'], info['Actors'], info['Colophon'])
+
-        
+
-        
+
-                if determine_ext(stream_url).lower() != 'asf':
+                if not '.asf' in stream_url:
-__version__ = '2015.01.10.2'
+__version__ = '2015.01.11'
-    _VALID_URL = r'http://(?:www\.)?dr\.dk/tv/se/(?:[^/]+/)+(?P<id>[\da-z-]+)(?:[/#?]|$)'
+    _VALID_URL = r'https?://(?:www\.)?dr\.dk/tv/se/(?:[^/]+/)+(?P<id>[\da-z-]+)(?:[/#?]|$)'
-                        info_dict['__files_to_merge'] = downloaded
+            try:
-                    return
+                        postprocessors = [merger]
-        if filename != '-' and self.params.get('continuedl', False) and os.path.isfile(encodeFilename(filename)) and not self.params.get('nopart', False):
+        if filename != '-' and nooverwrites_and_exists or continuedl_and_exists:
-        keep_video = None
+            keep_video = None
-                keep_video_wish, new_info = pp.run(info)
+                keep_video_wish, info = pp.run(info)
-                self.report_warning('Unable to remove downloaded video file')
+            if keep_video is False and not self.params.get('keepvideo', False):
-        'url': 'http://veehd.com/video/4686958',
+        'url': 'http://veehd.com/video/4639434_Solar-Sinter',
-            'id': '4686958',
+            'id': '4639434',
-            'description': 'md5:f0094c4cf3a72e22bc4e4239ef767ad7',
+            'title': 'Solar Sinter',
-        config = json.loads(config_json)
+            r'value=\'config=({.+?})\'', player_page, 'config json', default=None)
-                                              webpage, 'description', flags=re.DOTALL)
+        uploader_id = self._html_search_regex(
-            raise error("getaddrinfo returns an empty list")
+            raise socket.error("getaddrinfo returns an empty list")
-            r'>(?:Link|Download): <a href="([^"]+)">', webpage, 'video URL')
+            r'>(?:Link|Download): <a[^>]+href="([^"]+)"', webpage, 'video URL')
-    'compat_str',
+    'compat_str',
-                       contact the youtube-dl servers for debugging.
+    call_home:         Boolean, true iff we are allowed to contact the
-        help='Contact the youtube-dl server for debugging. (Experimental)')
+        help='Contact the youtube-dl server for debugging.')
-__version__ = '2015.01.10.1'
+__version__ = '2015.01.10.2'
-__version__ = '2015.01.10'
+__version__ = '2015.01.10.1'
-def _create_http_connection(ydl_handler, http_class, is_https=False, *args, **kwargs):
+def _create_http_connection(ydl_handler, http_class, is_https, *args, **kwargs):
-            _create_http_connection, self, compat_http_client.HTTPConnection),
+            _create_http_connection, self, compat_http_client.HTTPConnection, False),
-        ydlh = YoutubeDLHandler(debuglevel=debuglevel)
+        https_handler = make_HTTPS_handler(self.params, debuglevel=debuglevel)
-    general.add_option(
+    network = optparse.OptionGroup(parser, 'Network Options')
-    https_handler = make_HTTPS_handler(False)
+    https_handler = make_HTTPS_handler({})
-def make_HTTPS_handler(opts_no_check_certificate, **kwargs):
+def make_HTTPS_handler(params, **kwargs):
-            return compat_urllib_request.HTTPSHandler(context=context, **kwargs)
+            return YoutubeDLHTTPSHandler(params, context=context, **kwargs)
-        return HTTPSHandlerV3(**kwargs)
+        return YoutubeDLHTTPSHandler(params, https_conn_class=HTTPSConnectionV3, **kwargs)
-        return compat_urllib_request.HTTPSHandler(context=context, **kwargs)
+        return YoutubeDLHTTPSHandler(params, context=context, **kwargs)
-from ..utils import compat_urllib_parse, ExtractorError
+from ..compat import compat_urllib_parse
-
+        video_id = self._match_id(url)
-        urls_info_webpage = self._download_webpage(settings_json, 'Downloading settings json')
+        page_video_url = self._og_search_video_url(webpage, video_id)
-        urls_info_json = json.loads(urls_info_webpage.replace('\'', '"'))
+        urls_info_json = self._download_json(
-        }
+        }
-    
+
-    _VALID_URL = r'http?://(?:www\.)?rte\.ie/player/in/show/(?P<id>[0-9]+)/'
+    _VALID_URL = r'http?://(?:www\.)?rte\.ie/player/[^/]{2,3}/show/(?P<id>[0-9]+)/'
-        'url': 'http://www.rte.ie/player/in/show/10336191/',
+        'url': 'http://www.rte.ie/player/de/show/10363114/',
-            'id': '10336191',
+            'id': '10363114',
-            'title': 'Nine News',
+            'title': 'One News',
-            'duration': 1622.963,
+            'duration': 436.844,
-
+
-        
+        description = self._html_search_meta('description', webpage, 'description')
-        
+
-        
+        } for f in f4m_formats]
-        }
+        }
-    _VALID_URL = r'http://tv\.nrk(?:super)?\.no/(?:serie/[^/]+|program)/(?P<id>[a-zA-Z]{4}\d{8})(?:/\d{2}-\d{2}-\d{4})?(?:#del=(?P<part_id>\d+))?'
+class NRKTVIE(SubtitlesInfoExtractor):
-
+        subtitles_url = self._html_search_regex(
-        '%d/%m/%y',
+            '%d.%m.%Y',
-    _VALID_URL = r'http://oe1\.orf\.at/programm/(?P<id>[0-9]+)'
+    _VALID_URL = r'http://oe1\.orf\.at/(?:programm/|konsole.*?#\?track_id=)(?P<id>[0-9]+)'
-    IE_DESC = 'orf:fm4'
+    IE_NAME = 'orf:fm4'
-        oldest_mtime = min(os.stat(path).st_mtime for path in input_paths)
+        oldest_mtime = min(
-        os.utime(out_path, (oldest_mtime, oldest_mtime))
+        os.utime(encodeFilename(out_path), (oldest_mtime, oldest_mtime))
-__version__ = '2015.01.09.2'
+__version__ = '2015.01.10'
-import time
+)
-        avg_song_duration = duration / track_count
+        avg_song_duration = float(duration) / track_count
-                        time.sleep(avg_song_duration)
+                        self._sleep(avg_song_duration, playlist_id)
-            },
+    _VALID_URL = r'https?://(?:vod|www)\.tvp\.pl/.*/(?P<id>\d+)$'
-    ]
+    }, {
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        }
+        description = self._og_search_description(webpage, default=None)
-                'ext': ext,
+            formats = [{
-            })
+                'ext': ext,
-        return info_dict
+
-    ]
+    _TESTS = [{
-            'edId=0&sort=&page=0&pageSize=10000' % playlist_id, display_id, tries=5)
+            'edId=0&sort=&page=0&pageSize=10000' % playlist_id, display_id, tries=5,
-import time
+from ..utils import (
-                'artist': 'Roosh Williams',
+                'uploader': 'Roosh Williams',
-        return self.create_song_dictionary(api_response, album_url_tag)
+        return {
-            'playlist_count': 10
+            'playlist': [{
-        while True:
+        for track_no in itertools.count():
-                                               % (album_url_tag, track_no, time.time()), album_url_tag)
+            api_response = self._download_json(
-            track_no += 1
+                song_id = url_basename(api_response['url']).rpartition('.')[0]
-        
+
-        action='store', dest='merge_output_format', metavar='FORMAT' ,default=None,
+        '--merge-output-format',
-            'If a merge is required (e.g. bestvideo+bestaudio), output to given container format (e.g. mkv, mp4, ogg, webm, flv) '
+            'If a merge is required (e.g. bestvideo+bestaudio), output to given container format. One of mkv, mp4, ogg, webm, flv.'
-                                'ext': formats_info[0]['ext'],
+                                'ext': self.params['merge_output_format'] if self.params['merge_output_format'] is not None else formats_info[0]['ext'],
-__version__ = '2015.01.09.1'
+__version__ = '2015.01.09.2'
-
+        video_id = self._match_id(url)
-__version__ = '2015.01.09'
+__version__ = '2015.01.09.1'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-# TODO test _1
+                                'width': formats_info[0].get('width'),
-        '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'vcodec': 'none', 'abr': 256, 'preference': -50},
+        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'vcodec': 'none', 'abr': 48, 'preference': -50},
-__version__ = '2015.01.08'
+__version__ = '2015.01.09'
-        newversion = compat_urllib_request.urlopen(VERSION_URL).read().decode('utf-8').strip()
+        newversion = opener.open(VERSION_URL).read().decode('utf-8').strip()
-        versions_info = compat_urllib_request.urlopen(JSON_URL).read().decode('utf-8')
+        versions_info = opener.open(JSON_URL).read().decode('utf-8')
-            urlh = compat_urllib_request.urlopen(version['exe'][0])
+            urlh = opener.open(version['exe'][0])
-            urlh = compat_urllib_request.urlopen(version['bin'][0])
+            urlh = opener.open(version['bin'][0])
-        cmd = ([self._executable, '-y'] + files_cmd
+            files_cmd.extend([encodeArgument('-i'), encodeFilename(path, True)])
-                '-show_streams',
+                encodeFilename(self._probe_executable, True),
-    _VALID_URL = r'https?://(?:www\.)?audiomack\.com/(song)/(?P<id>[\w/-]+)'
+    _VALID_URL = r'https?://(?:www\.)?audiomack\.com/song/(?P<id>[\w/-]+)'
-        # audiomack
+        # hosted on audiomack
-                "artist": "Roosh Williams",
+                'ext': 'mp3',
-        # audiomack through soundcloud
+        # audiomack wrapper around soundcloud song
-        entry = {key: api_response[key] for key in ["title", "artist", "id", "url"] if key in api_response}
+        entry = {key: api_response[key] for key in ['title', 'artist', 'id', 'url'] if key in api_response}
-            entry["title"] = album_url_tag
+        if 'id' not in entry:
-            "http://www.audiomack.com/api/music/url/song/%s?extended=1&_=%d" % (
+            'http://www.audiomack.com/api/music/url/song/%s?extended=1&_=%d' % (
-            raise ExtractorError("Invalid url %s", url)
+        if 'url' not in api_response or not api_response['url'] or 'error' in api_response:
-            return {'_type': 'url', 'url': api_response["url"], 'ie_key': 'Soundcloud'}
+        if SoundcloudIE.suitable(api_response['url']):
-            "playlist_count": 15,
+            'playlist_count': 15,
-                'title': "Tha Tour: Part 2 (Official Mixtape)"
+                'id': '812251',
-            "playlist_count": 10
+            'url': 'http://www.audiomack.com/album/fakeshoredrive/ppp-pistol-p-project',
-        result = {"_type": "playlist", "entries": []}
+        result = {'_type': 'playlist', 'entries': []}
-            api_response = self._download_json("http://www.audiomack.com/api/music/url/album/%s/%d?extended=1&_=%d"
+            api_response = self._download_json('http://www.audiomack.com/api/music/url/album/%s/%d?extended=1&_=%d'
-                raise ExtractorError("Invalid url for track %d of album url %s" % (track_no, url))
+            if 'url' not in api_response or 'error' in api_response:
-            elif not api_response["url"]:
+            elif not api_response['url']:
-                for resultkey, apikey in [("id", "album_id"), ("title", "album_title")]:
+                for resultkey, apikey in [('id', 'album_id'), ('title', 'album_title')]:
-                result["entries"].append(AudiomackIE.create_song_dictionary(api_response, album_url_tag, track_no))
+                result['entries'].append(AudiomackIE.create_song_dictionary(api_response, album_url_tag, track_no))
-    any_printing = opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.getduration or opts.dumpjson or opts.dump_single_json
+    any_getting = opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.getduration or opts.dumpjson or opts.dump_single_json
-        'quiet': (opts.quiet or any_printing),
+        'quiet': (opts.quiet or any_getting or any_printing),
-        'forcejson': opts.dumpjson,
+        'forcejson': opts.dumpjson or opts.print_json,
-        'simulate': opts.simulate or any_printing,
+        'simulate': opts.simulate or any_getting,
-    _VALID_URL = r'(?:http://)?(?:www\.)?tudou\.com/(?:listplay|programs|albumplay)/(?:view|(.+?))/(?:([^/]+)|([^/]+))(?:\.html)?'
+    _VALID_URL = r'https?://(?:www\.)?tudou\.com/(?:listplay|programs(?:/view)?|albumplay)/.*?/(?P<id>[^/?#]+?)(?:\.html)?/?(?:$|[?#])'
-        video_id = mobj.group(2)
+        video_id = self._match_id(url)
-        return result
+        return {
-
+from ..utils import (
-    _VALID_URL = r'http://www\.discovery\.com\/[a-zA-Z0-9\-]*/[a-zA-Z0-9\-]*/videos/(?P<id>[a-zA-Z0-9\-]*)(.htm)?'
+    _VALID_URL = r'http://www\.discovery\.com\/[a-zA-Z0-9\-]*/[a-zA-Z0-9\-]*/videos/(?P<id>[a-zA-Z0-9_\-]*)(?:\.htm)?'
-        'md5': 'e12614f9ee303a6ccef415cb0793eba2',
+        'md5': '3c69d77d9b0d82bfd5e5932a60f26504',
-            'title': 'MythBusters: Mission Impossible Outtakes',
+            'id': 'mission-impossible-outtakes',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                {'url': f['src'], 'ext': 'mp4', 'tbr': int(f['bitrate'][:-1])})
+        info = self._parse_json(self._search_regex(
-            'duration': info['duration'],
+            'id': video_id,
-            }
+            },
-            'description': 'Munchkin the Teddy Bear is back !',
+            'description': 're:Munchkin the Teddy Bear is back ?!',
-                'description': 'Â© 2014 Munchkin the Shih Tzu\nAll rights reserved\nFacebook: http://facebook.com/MunchkintheShihTzu',
+                'description': 're:Â© 2014 Munchkin the Shih Tzu',
-                'title': 'Munchkin the Teddy Bear gets her exercise',
+                'title': 're:Munchkin the Teddy Bear gets her exercise',
-                'id': '406429c6-1b8a-463e-83fc-814adb81a9db',
+                'id': '740ab250-bb94-4a8a-8787-fe0de7c74471',
-                'id': '4160e53b-ad41-43b1-980f-8d85f63121f4',
+                'id': 'bcd1b1df-673a-42cf-8d01-b282db608f2d',
-__version__ = '2015.01.07.2'
+__version__ = '2015.01.08'
-            extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a']
+            extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a', 'mp3', 'ogg', 'aac', 'wav']
-            ' "worstaudio". By default, youtube-dl will pick the best quality.'
+            ' slashes, as in -f 22/17/18 . '
-    _VALID_URL = r'http://(?:www\.)?fernsehkritik\.tv/folge-(?P<ep>[0-9]+)(?:/.*)?'
+    _VALID_URL = r'http://(?:www\.)?fernsehkritik\.tv/folge-(?P<id>[0-9]+)(?:/.*)?'
-        episode = int(mobj.group('ep'))
+        episode = int(self._match_id(url))
-        start_webpage = self._download_webpage('http://fernsehkritik.tv/folge-%d/Start' % episode,
+        video_thumbnail = 'http://fernsehkritik.tv/images/magazin/folge%s.jpg' % episode
-        # TODO: return a single multipart video
+
-            video_url = 'http://dl%d.fernsehkritik.tv/fernsehkritik%d%s.flv' % (server, episode, '' if i == 1 else '-%d' % i)
+            video_url = 'http://fernsehkritik.tv/js/directme.php?file=%s%s.flv' % (episode, '' if i == 1 else '-%d' % i)
-        return videos
+        return {
-        'playlist_count': 4,
+        'playlist_count': 3,
-                'description': 'md5:eca57043abae25130f58f655ad9a7771',
+                'description': 're:(?s).{100,}About the Game\n.*?The Witcher 3: Wild Hunt.{100,}',
-        'ext': 'AAC',
+        'ext': 'aac',
-                'ext': stream.get('MediaType'),
+                'ext': stream.get('MediaType').lower(),
-                'preference': stream.get('Reliability'),
+                'source_preference': reliability,
-            'upload_date': '20141007',
+            'upload_date': '20141008',
-                    [^>]+content=(["\'])(?P<content>.*?)\1''' % re.escape(name),
+                    [^>]+?content=(["\'])(?P<content>.*?)\2''' % re.escape(name),
-
+        video_id = self._match_id(url)
-    _VALID_URL = r'^https?://(?:www\.)?washingtonpost\.com/.*?/(?P<id>[^/]+)/(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?washingtonpost\.com/.*?/(?P<id>[^/]+)/(?:$|[?#])'
-            'md5': 'c3f4b4922ffa259243f68e928db2db8c',
+            'md5': '79132cc09ec5309fa590ae46e4cc31bc',
-            'md5': 'f645a07652c2950cd9134bb852c5f5eb',
+            'md5': 'e1d5734c06865cc504ad99dc2de0d443',
-
+        page_id = self._match_id(url)
-        upload_date = unified_strdate(data['schedule']['starts_at'])
+        duration = parse_duration(data.get('running_time'))
-            })
+        } for key, url in data.get('sources', {}).get('live', {}).items()]
-            webpage, 'player params'))
+        cid = self._search_regex(r'cid=(\d+)', webpage, 'cid')
-            cid = player_params['cid'][0]
+        lq_doc = self._download_xml(
-                'url': lq_durl.find('./url').text,
+        hq_doc = self._download_xml(
-            raise ExtractorError('Unsupported player parameters: %r' % (player_params,))
+                    hq_durl.find('./size'), get_attr='text'),
-            ie_md = '**{}**'.format(ie.IE_NAME)
+            ie_md = '**{0}**'.format(ie.IE_NAME)
-                ie_md += ': {}'.format(ie.IE_DESC)
+                ie_md += ': {0}'.format(ie.IE_DESC)
-__version__ = '2015.01.07.1'
+__version__ = '2015.01.07.2'
-    for ie in sorted(youtube_dl.gen_extractors(), key=lambda i: i.IE_NAME.lower()):
+    for ie in youtube_dl.list_extractors(age_limit=None):
-from .extractor import list_extractors
+from .extractor import gen_extractors, list_extractors
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-__version__ = '2015.01.07'
+__version__ = '2015.01.07.1'
-__version__ = '2015.01.05.1'
+__version__ = '2015.01.07'
-        video_id = mobj.group(1)
+        video_id = self._match_id(url)
-            yield t
+        for tc in ie.get_testcases(include_onlymatching):
-                return 'Skipping "' + title + '" because it is age restricted'
+        if age_restricted(info_dict.get('age_limit'), self.params.get('age_limit')):
-from .extractor import gen_extractors
+from .extractor import list_extractors
-        for ie in sorted(extractors, key=lambda ie: ie.IE_NAME.lower()):
+        for ie in list_extractors(opts.age_limit):
-        for ie in sorted(extractors, key=lambda ie: ie.IE_NAME.lower()):
+        for ie in list_extractors(opts.age_limit):
-    _VALID_URL = r'http://tv\.nrk(?:super)?\.no/(?:serie/[^/]+|program)/(?P<id>[a-zA-Z]{4}\d{8})'
+    _VALID_URL = r'http://tv\.nrk(?:super)?\.no/(?:serie/[^/]+|program)/(?P<id>[a-zA-Z]{4}\d{8})(?:/\d{2}-\d{2}-\d{4})?(?:#del=(?P<part_id>\d+))?'
-            }
+            },
-            }
+            },
-            self._html_search_regex(r'data-duration="([^"]+)"', page, 'duration', fatal=False))
+        part_id = mobj.group('part_id')
-        f4m_url = re.search(r'data-media="([^"]+)"', page)
+        f4m_url = re.search(r'data-media="([^"]+)"', webpage)
-            })
+            formats.extend(self._extract_f4m(f4m_url.group(1), video_id))
-        m3u8_url = re.search(r'data-hls-media="([^"]+)"', page)
+        m3u8_url = re.search(r'data-hls-media="([^"]+)"', webpage)
-            })
+            formats.extend(self._extract_m3u8_formats(m3u8_url.group(1), video_id, 'mp4'))
-                    yield "{} --> {}".format(start, stop)
+                    yield "{0} --> {1}".format(start, stop)
-        subtitles = self.extract_subtitles(video_id, webpage)
+        subtitles = {}
-            self._list_available_subtitles(video_id, webpage)
+            self._list_available_subtitles(video_id, subtitles)
-        subtitles = self._fix_subtitles(self.extract_subtitles(video_id, webpage))
+        subtitles = self._fix_subtitles(self.extract_subtitles(video_id, subtitles))
-        """ Convert milisecond-based subtitles to SRT """
+    @staticmethod
-            """ Helper utility to convert miliseconds to timecode """
+            """ Helper utility to convert milliseconds to timecode """
-                m = re.match(r"^ *([0-9]+); *([0-9]+) +([0-9]+) *$", line)
+                m = re.match(r"^\s*([0-9]+);\s*([0-9]+)\s+([0-9]+)\s*$", line)
-        return {'cs': url} if sub else {}
+        '308': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40, 'fps': 60, 'vcodec': 'VP9'},
-__version__ = '2015.01.05'
+__version__ = '2015.01.05.1'
-                            f['preference'] -= 10000
+                            f['preference'] = f.get('preference', 0) - 10000
-        stream.write(struct_pack('!L', len(metadata))[1:])
+        stream.write(SCRIPT_TAG)
-        stream.write(b'\x00\x00\x01\x73')
+        write_unsigned_int(stream, FLV_TAG_HEADER_LEN + len(metadata))
-    """Writes the FLV header and the metadata to stream"""
+def write_flv_header(stream):
-    stream.write(b'\x00\x00\x01\x73')
+
-        metadata = base64.b64decode(media.find(_add_ns('metadata')).text)
+        metadata_node = media.find(_add_ns('metadata'))
-        write_flv_header(dest_stream, metadata)
+        write_flv_header(dest_stream)
-    int_or_none,
+    compat_urlparse,
-    _VALID_URL = r'http://www\.motorsport\.com/[^/?#]+/video/(?:[^/?#]+/)(?P<id>[^/]+)/(?:$|[?#])'
+    _VALID_URL = r'http://www\.motorsport\.com/[^/?#]+/video/(?:[^/?#]+/)(?P<id>[^/]+)/?(?:$|[?#])'
-            'id': '7063',
+            'id': '2-T3WuR-KMM',
-            'duration': 207,
+            'duration': 208,
-        }
+            'uploader': 'mcomstaff',
-            'uploader', fatal=False)
+        iframe_path = self._html_search_regex(
-            'id': params['video_id'],
+            '_type': 'url_transparent',
-            'uploader': uploader,
+            'url': 'https://youtube.com/watch?v=%s' % youtube_id,
-__version__ = '2015.01.04'
+__version__ = '2015.01.05'
-        if video_url == "" and thumbnail =="":
+        title = self._html_search_regex(
-            title = title[:-len(ext)]
+        title = remove_end(title, ext)
-        mobj = re.search(pattern, page_doc)
+        meta_doc = self._download_webpage(
-                r'<iframe[^>]+?src=(["\'])(?P<url>https?://embed(?:-ssl)?\.ted\.com/.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>https?://embed(?:-ssl)?\.ted\.com/.+?)\1', webpage)
-    _VALID_URL = r'http?://(?:www\.)?radiobremen\.de/mediathek/(index\.html)?\?id=(?P<video_id>[0-9]+)'
+    _VALID_URL = r'http?://(?:www\.)?radiobremen\.de/mediathek/(?:index\.html)?\?id=(?P<id>[0-9]+)'
-        video_id = mobj.group('video_id')
+        video_id = self._match_id(url)
-        duration = self._html_search_regex("L&auml;nge:</td>\s+<td>(?P<duration>[0-9]+:[0-9]+)</td>", meta_doc, "duration")
+        duration = parse_duration(
-        video_url = "http://dl-ondemand.radiobremen.de/mediabase/{:}/{:}_{:}_{:}.mp4".format(video_id, video_id, secret, width)
+        video_url = (
-            'thumbnail': thumbnail,
+            'formats': formats,
-        if not video_url:
+        video_url = re.findall(r'http://\w+.auengine.com/vod/.*[^\W]', webpage)
-        }
+        },
-            r'<iframe[^>]+?src=(["\'])(?P<url>http://embed\.ted\.com/.+?)\1', webpage)
+                r'<iframe[^>]+?src=(["\'])(?P<url>https?://embed(?:-ssl)?\.ted\.com/.+?)\1', webpage)
-        (?P<type>www|embed)(?P<urlmain>\.ted\.com/
+        (?P<type>www|embed(?:-ssl)?)(?P<urlmain>\.ted\.com/
-        if m.group('type') == 'embed':
+        if m.group('type').startswith('embed'):
-            'md5': '5644c6ca5d5782c1d0d350dad9bd840c',
+            'md5': '166dd577b433b4d4ebfee10b0824d8ff',
-                'description': 'Chris Ziegler takes a look at the Alcatel OneTouch Fire and the ZTE Open; two of the first Firefox OS handsets to be officially announced.',
+                'description': 're:^Chris Ziegler takes a look at the\.*',
-        }
+        },
-            'url': 'http://player.vimple.ru/iframe/b132bdfd71b546d3972f9ab9a25f201c',
+            'url': 'http://vimple.ru/c0f6b1687dcd4000a97ebe70068039cf',
-                'title': 'great-escape-minecraft.flv',
+                'id': 'c0f6b1687dcd4000a97ebe70068039cf',
-                'webpage_url': 'http://vimple.ru/b132bdfd71b546d3972f9ab9a25f201c',
+                'title': 'Sunset',
-    _VALID_URL = r'https?://www\.rtlxl\.nl/#!/[^/]+/(?P<uuid>[^/?]+)'
+    _VALID_URL = r'https?://(www\.)?rtlxl\.nl/#!/[^/]+/(?P<uuid>[^/?]+)'
-            data = json.loads(js_to_json(js))
+            data = self._parse_json(js, video_id, transform_source=js_to_json)
-        args = ['-c', 'copy', '-map', '0:v:0', '-map', '1:a:0', '-shortest']
+        args = ['-c', 'copy', '-map', '0:v:0', '-map', '1:a:0']
-        else:
+        ffpp = FFmpegPostProcessor(downloader=self)
-        ffpp = FFmpegPostProcessor(downloader=self)
+        cmd = [program] + args
-__version__ = '2015.01.03'
+__version__ = '2015.01.04'
-        ext = vid.info().gettype().split("/")[1]
+        ext_req = HEADRequest(video_url)
-            '138', '137', '248', '136', '247', '135', '246',
+            '137', '248', '136', '247', '135', '246',
-from ..compat import compat_subprocess_get_DEVNULL
+from .gogoanime import (
-            r'["\'](http(?:s)?://www.wat.tv/embedframe/.*?)["\']', webpage, 'embed url')
+            r'["\'](https?://www.wat.tv/embedframe/.*?)["\']', webpage, 'embed url')
-            'id': '7085291',
+            'id': '12043945',
-            'description': 'Emery rÃªve qu\'un article lui soit consacrÃ© dans le journal.',
+            'description': 'Le grand MystÃ©rioso - Emery rÃªve qu\'un article lui soit consacrÃ© dans le journal.',
-    _TEST = {
+    _VALID_URL = r'http://(?:videos\.tf1|www\.tfou)\.fr/.*?-(?P<id>\d+)(?:-\d+)?\.html'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'"(https://www.wat.tv/embedframe/.*?)"', webpage, 'embed url')
+            r'["\'](http(?:s)?://www.wat.tv/embedframe/.*?)["\']', webpage, 'embed url')
-__version__ = '2015.01.02'
+__version__ = '2015.01.03'
-        formats_s = [line(f, idlen) for f in formats]
+        formats_s = [
-        '138': {'ext': 'mp4', 'height': 2160, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40},
+        '138': {'ext': 'mp4', 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40},  # Height can vary (https://github.com/rg3/youtube-dl/issues/4559)
-                f.update(self._formats.get(format_id, {}))
+                f.update(self._formats.get(format_id, {}).items())
-            'url': self._html_search_meta('VideoURL', webpage, 'url'),
+            'url': video_url,
-    _VALID_URL = r'https?://(?:www\.)?(ellentv|ellentube)\.com/videos/(?P<id>[a-z0-9_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:ellentv|ellentube)\.com/videos/(?P<id>[a-z0-9_-]+)'
-    {
+    }, {
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        playlist_id = mobj.group('id')
+        playlist_id = self._match_id(url)
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?(ellentv|ellentube)\.com/videos/(?P<id>[a-z0-9_-]+)'
-    }
+    },
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:programmes|iplayer/(?:episode|playlist))/(?P<id>[\da-z]{8})'
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:(?:(?:programmes|iplayer/(?:episode|playlist))/)|music/clips[/#])(?P<id>[\da-z]{8})'
-        except (OSError, IOError):
+        if not check_executable('mplayer', ['-h']):
-        for fmt in re.findall(r'\?p([0-9]{3,4})=1', webpage):
+        for fmt in re.findall(r'showmedia\.([0-9]{3,4})p', webpage):
-    _VALID_URL = r'http://(?:www\.)?kontrtube\.ru/videos/(?P<id>\d+)/.+'
+    _VALID_URL = r'http://(?:www\.)?kontrtube\.ru/videos/(?P<id>\d+)/(?P<display_id>[^/]+)/'
-        webpage = self._download_webpage(url, video_id, 'Downloading page')
+        webpage = self._download_webpage(
-        thumbnail = self._html_search_regex(r"preview_url: '(.+?)/?',", webpage, 'video thumbnail', fatal=False)
+        video_url = self._html_search_regex(
-        description = self._html_search_meta('description', webpage, 'video description')
+        description = self._html_search_meta(
-            r'<div class="col_2">ÐÐ»Ð¸ÑÐµÐ»ÑÐ½Ð¾ÑÑÑ: <span>(?P<minutes>\d+)Ð¼:(?P<seconds>\d+)Ñ</span></div>', webpage)
+            r'<div class="col_2">ÐÐ»Ð¸ÑÐµÐ»ÑÐ½Ð¾ÑÑÑ: <span>(?P<minutes>\d+)Ð¼:(?P<seconds>\d+)Ñ</span></div>',
-            r'<div class="col_2">ÐÑÐ¾ÑÐ¼Ð¾ÑÑÐ¾Ð²: <span>(\d+)</span></div>', webpage, 'view count', fatal=False)
+            r'<div class="col_2">ÐÑÐ¾ÑÐ¼Ð¾ÑÑÐ¾Ð²: <span>(\d+)</span></div>',
-                'id': '417cd61c-c793-4e8e-b006-e445ecc45add',
+                'id': '406429c6-1b8a-463e-83fc-814adb81a9db',
-                'description': 'md5:db4755d7a665ae72343779f7dacb402c',
+                'title': 'Kaleidoscope, Leonard Cohen',
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class CeskaTelevizeIE(InfoExtractor):
+class CeskaTelevizeIE(SubtitlesInfoExtractor):
-    _VALID_URL = r'https?://(?:www\.)?vier\.be/(?P<program>[^/]+)/videos(?:\?.*\bpage=(?P<page>\d+))?'
+    _VALID_URL = r'https?://(?:www\.)?vier\.be/(?P<program>[^/]+)/videos(?:\?.*\bpage=(?P<page>\d+)|$)'
-             r'By:\s*<a href="/community/profile\.php?user=([^"]+)'],
+             r'By:\s*<a href="/community/profile\.php\?user=([^"]+)'],
-            }
+            'only_matching': True,
-        }
+        # BBC iPlayer embeds
-__version__ = '2015.01.01'
+__version__ = '2015.01.02'
-            return self.playlist_result([self.url_result(video_url, ie='BBCCoUk') for video_url in matches])
+            return _playlist_from_matches(matches, ie='BBCCoUk')
-        def _playlist_from_matches(matches, getter, ie=None):
+        def _playlist_from_matches(matches, getter=None, ie=None):
-                self.url_result(self._proto_relative_url(getter(m)), ie)
+                self.url_result(self._proto_relative_url(getter(m) if getter else m), ie)
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:programmes|iplayer/episode)/(?P<id>[\da-z]{8})'
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:programmes|iplayer/(?:episode|playlist))/(?P<id>[\da-z]{8})'
-    _VALID_URL = r'https?://(?:www\.)?vier\.be/(?P<program>[^/]+)/videos(?:\?page=(?P<page>\d+))?$'
+    _VALID_URL = r'https?://(?:www\.)?vier\.be/(?P<program>[^/]+)/videos(?:\?.*\bpage=(?P<page>\d+))?'
-from ..utils import escape_url
+# coding: utf-8
-          } for eurl in re.findall (r'<h3><a href="(.+?)">(.+?)</a></h3>', videos_page)]
+from .common import InfoExtractor
-    _VALID_URL = r'http://(?:.+?\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.+?)\.html(?:\?.*)?'
+    _VALID_URL = r'(?P<proto>https?)://(?:.+?\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.+?)\.html(?:\?.*)?'
-        mrss_url = 'http://xhamster.com/movies/%s/%s.html' % (video_id, seo)
+        proto = mobj.group('proto')
-from .audiomack import AudiomackIE
+from .audiomack import AudiomackIE, AudiomackAlbumIE
-    _VALID_URL = r'https?://(?:www\.)?audiomack\.com/song/(?P<id>[\w/-]+)'
+    _VALID_URL = r'https?://(?:www\.)?audiomack\.com/(song)/(?P<id>[\w/-]+)'
-        # hosted on audiomack
+        # audiomack
-                'title': 'Roosh Williams - Extraordinary'
+                'id': '310086',
-        # hosted on soundcloud via audiomack
+        # audiomack through soundcloud
-        video_id = self._match_id(url)
+        # URLs end with [uploader name]/[uploader title]
-            video_id)
+            "http://www.audiomack.com/api/music/url/song/%s?extended=1&_=%d" % (
-        realurl = api_response["url"]
+        # API is inconsistent with errors
-            return {'_type': 'url', 'url': realurl, 'ie_key': 'Soundcloud'}
+        # if so, pass the work off to the soundcloud extractor
-        title = artist + " - " + songtitle
+        return self.create_song_dictionary(api_response, album_url_tag)
-            'url': realurl,
+
-                _SEARCHES = ('cute kittens', 'slithering pythons', 'falling cat', 'angry poodle', 'purple fish', 'running tortoise', 'sleeping bunny')
+                _SEARCHES = ('cute kittens', 'slithering pythons', 'falling cat', 'angry poodle', 'purple fish', 'running tortoise', 'sleeping bunny', 'burping cow')
-                playlist_id, 'Downloading legacy playlist XML')
+            'http://www.bbc.co.uk/iplayer/playlist/%s' % playlist_id,
-        'usage': '%prog [options] url [url...]',
+        'usage': '%prog [OPTIONS] URL [URL...]',
-__version__ = '2014.12.17.2'
+__version__ = '2015.01.01'
-            'url': 'http://www.ceskatelevize.cz/ivysilani/10532695142-prvni-republika/213512120230004-spanelska-chripka',
+            'url': 'http://www.ceskatelevize.cz/ivysilani/ivysilani/10441294653-hyde-park-civilizace/214411058091220',
-                'duration': 3107.4,
+                'id': '214411058091220',
-                'skip_download': True,  # requires rtmpdump
+                # m3u8 download
-                'ext': 'flv',
+                'ext': 'mp4',
-                'duration': 90,
+                'description': 'SÃ¡ga mapujÃ­cÃ­ atmosfÃ©ru prvnÃ­ republiky od r. 1918 do r. 1945.',
-                'skip_download': True,  # requires rtmpdump
+                # m3u8 download
-                                            data=compat_urllib_parse.urlencode(data))
+        req = compat_urllib_request.Request(
-        req = compat_urllib_request.Request(compat_urllib_parse.unquote(playlistpage['url']))
+        playlist_url = playlistpage['url']
-        playlist = self._download_xml(req, video_id)
+        playlist = self._download_json(req, video_id)
-
+        for format_id, stream_url in item['streamUrls'].items():
-            'duration': float(duration),
+            'title': title,
-            }
+            },
-            'md5': '7b96112fbae1faf09a6f9ae1aff6cb84',
+            'md5': 'adf2c5454fa2bf032f47a9f8fb351342',
-            'md5': 'af01795a31f1cf7265c8657534d8077b',
+            'md5': '383650ece2b25ecec996ad7b5bb2a384',
-            r'''(?ix)<meta
+            r'''(?isx)<meta
-            r'var slideshare_object =  ({.*?}); var user_info =',
+            r'var\s+slideshare_object\s*=\s*({.*?});\s*var\s+user_info\s*=',
-            r'<p\s+(?:style="[^"]*"\s+)?class=".*?description.*?"[^>]*>(.*?)</p>', webpage,
+            r'(?s)<p[^>]+itemprop="description"[^>]*>(.+?)</p>', webpage,
-            self._CONFIG_REGEX, webpage, 'flashvars.config')
+        cfg_url = self._proto_relative_url(self._html_search_regex(
-    _TITLE_REGEX = None
+    _TITLE_REGEX = r'<title>(.+?) - TNAFlix Porn Videos</title>'
-    float_or_none,
+    parse_filesize,
-    _VALID_URL = r'https?://(?:www\.)?xboxclips\.com/video\.php\?.*vid=(?P<id>[\w-]{36})'
+    _VALID_URL = r'https?://(?:www\.)?xboxclips\.com/(?:video\.php\?.*vid=|[^/]+/)(?P<id>[\w-]{36})'
-            'timestamp': 1407388500,
+            'title': 'Iabdulelah playing Titanfall',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'>Link: <a href="([^"]+)">', webpage, 'video URL')
+            r'>(?:Link|Download): <a href="([^"]+)">', webpage, 'video URL')
-        timestamp = parse_iso8601(self._html_search_regex(
+        upload_date = unified_strdate(self._html_search_regex(
-            r'>Size: ([\d\.]+)MB<', webpage, 'file size', fatal=False), invscale=1024 * 1024)
+        filesize = parse_filesize(self._html_search_regex(
-            'timestamp': timestamp,
+            'upload_date': upload_date,
-            'url': info['alternate_encoding']['url'],
+            'url': redirect_info['url'],
-            sub_list = self._download_webpage(
+            subs_doc = self._download_xml(
-            lang = l[1]
+        for track in subs_doc.findall('track'):
-                'name': unescapeHTML(l[0]).encode('utf-8'),
+                'name': track.attrib['name'].encode('utf-8'),
-            if original_lang_node is None or original_lang_node.attrib.get('kind') != 'asr':
+            if original_lang_node is None:
-                    'kind': 'asr',
+                    'kind': caption_kind,
-            raise ExtractorError('Unsupported URL: %s' % url)
+            raise UnsupportedError(url)
-        token = hmac.new(self._MAGIC.encode('utf-8'), episode_id + timestamp_shifted).hexdigest()
+        token = hmac.new(
-            r'src=["\']http://videofarm.daum.net/controller/video/viewer/Video.html\?.*?vid=(.+?)[&"\']',
+            r'src=["\']http://videofarm\.daum\.net/controller/video/viewer/Video\.html\?.*?vid=(.+?)[&"\']',
-            r'<iframe src="http://videofarm.daum.net/controller/video/viewer/Video.html\?.*?vid=(.+?)[&"]',
+            r'src=["\']http://videofarm.daum.net/controller/video/viewer/Video.html\?.*?vid=(.+?)[&"\']',
-                    r'"sts"\s*:\s*(\d+)', video_webpage, 'sts', default=''),
+                    r'"sts"\s*:\s*(\d+)', embed_webpage, 'sts', default=''),
-                        player_url = json.loads(jsplayer_url_json)
+                    jsplayer_url_json = self._search_regex(
-    unified_strdate,
+    clean_html,
-            'description': '\n',
+            'description': '',
-            'duration': 215,
+            'duration': 215.1666,
-            'uploader_id': 'hitboxlive',
+            'uploader': 'hitboxlive',
-        )
+            '%s/%s' % (url, video_id), video_id)
-        duration = int(float(video_meta.get('media_duration')))
+        description = clean_html(
-        upload_date = unified_strdate(video_meta.get(date))
+        views = int_or_none(video_meta.get('media_views'))
-            'uploader_id': uploader,
+            'uploader': uploader,
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-        )
+            video_id)
-        )
+            'https://www.hitbox.tv/api/player/config/video/%s' % video_id,
-            'uploader_id': 'Dimak',
+            'description': 'md5:c9f80fa4410bc588d7faa40003fc7d0e',
-        )
+            video_id)
-        )
+            'https://www.hitbox.tv/api/player/config/live/%s' % video_id,
-from .hitbox import HitboxIE
+from .hitbox import HitboxIE, HitboxLiveIE
-    }, {
+    _TEST = {
-            'description': '',
+            'description': '\n',
-        video_id = self._match_id(url)
+    }
-            'https://www.hitbox.tv/api/media/video/%s' % (video_id), video_id
+            '%s/%s' % (url, video_id), video_id
-        video_meta = metadata.get('video', [])[0]
+        date = 'media_live_since'
-        description = video_meta.get('media_description')
+        description = video_meta.get('media_description_md')
-        upload_date = unified_strdate(video_meta.get('media_date_added'))
+        upload_date = unified_strdate(video_meta.get(date))
-            'protocol': 'm3u8',
+
-        (?P<path>.+?/(?P<title>[^/]+?)(?:\.cnn(?:-ap)?|(?=&)))'''
+        (?P<path>.+?/(?P<title>[^/]+?)(?:\.(?:cnn|hln)(?:-ap)?|(?=&)))'''
-            r'video_id:\s*\'([^\']+)\'', webpage, 'id')
+        webpage = self._download_webpage(url, display_id)
-            r'postfix:\s*\'([^\']+)\'', webpage, 'ext')[1:]
+        title = remove_end(self._html_search_regex(
-            r'video_url:\s*\'([^\']+)\'', webpage, 'video_url')
+        flashvars = self._parse_json(self._search_regex(
-            r'<title>([^<]+)\s*-\s*Hell Porno</title>', webpage, 'title')
+        video_id = flashvars.get('video_id')
-            webpage, 'thumbnail', fatal=False)
+        formats = []
-            'ext': ext,
+            'formats': formats,
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id)
-        video_url = self._html_search_regex(
+        video_url = self._search_regex(
-            r'<title>(.*?)\s*-\s*XXXYMovies.com</title>', webpage, 'title')
+            [r'<div class="block_header">\s*<h1>([^<]+)</h1>',
-            r'preview_url\s*:\s*\'(.*?)\'', webpage, 'thumbnail', fatal=False)
+        thumbnail = self._search_regex(
-            r'<span>Duration:</span>\s*(\d+:\d+)', webpage, 'duration', fatal=False))
+            r'<span>Duration:</span>\s*(\d+:\d+)',
-            r'<div class="video_views">\s*(\d+)', webpage, 'view count', fatal=False))
+            r'<div class="video_views">\s*(\d+)',
-            'age_limit': 18,
+            'like_count': like_count,
-        (?P<path>.+?/(?P<title>[^/]+?)(?:\.cnn(-ap)?|(?=&)))'''
+    _VALID_URL = r'''(?x)https?://(?:(?:edition|www)\.)?cnn\.com/video/(?:data/.+?|\?)/
-            'id': 'sports_2013_06_09_nadal-1-on-1.cnn',
+            'id': 'sports/2013/06/09/nadal-1-on-1.cnn',
-    _VALID_URL = r'https?://((edition|www)\.)?cnn\.com/(?!video/)'
+    _VALID_URL = r'https?://(?:(?:edition|www)\.)?cnn\.com/(?!video/)'
-            'url': r'http://cnn.com/video/?/video/' + cnn_url,
+            'url': 'http://cnn.com/video/?/video/' + cnn_url,
-
+
-    _VALID_URL = r'https?://(?:www\.)?hellporno\.com/videos/(?P<display_id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?hellporno\.com/videos/(?P<id>[^/]+)'
-        webpage = self._download_webpage(url, 'main')
+        display_id = self._match_id(url)
-        video_id = self._html_search_regex(r'video_id:\s*\'([^\']+)\'', webpage, 'id')
+        video_id = self._html_search_regex(
-        video_url = self._html_search_regex(r'video_url:\s*\'([^\']+)\'', webpage, 'video_url')
+        ext = self._html_search_regex(
-        ext = self._html_search_regex(r'postfix:\s*\'([^\']+)\'', webpage, 'ext')[1:]
+        video_url = self._html_search_regex(
-            else categories_str.split(','))
+        categories = self._html_search_meta(
-        },
+        }, {
-                formats, subtitles = self._download_media_selector(programme_id)
+            programme_id, title, description, duration, formats, subtitles = self._download_playlist(group_id)
-)
+from ..utils import unified_strdate
-        'file': 'XD300-23_68HighlightsAResearchCntAugHumanIntellect.ogv',
+    _VALID_URL = r'https?://(?:www\.)?archive\.org/details/(?P<id>[^?/]+)(?:[?].*)?$'
-            "uploader": "SRI International"
+            'id': 'XD300-23_68HighlightsAResearchCntAugHumanIntellect',
-            return None
+    }, {
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        data = json.loads(json_data)
+        data = self._download_json(json_url, video_id)
-            upload_date = unified_strdate(upload_date)
+        title = get_optional(data, 'title')
-        upload_date = unified_strdate(data['metadata']['date'][0])
+        title = self.get_optional_metadata(data, 'title')
-            'forma_id': q.attrib['quality'],
+            'format_id': q.attrib['quality'],
-                'quality': qfunc(f['quality']),
+                'quality': qfunc(f.get('quality')),
-
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.)?alphaporno\.com/videos/(?P<display_id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?alphaporno\.com/videos/(?P<id>[^/]+)'
-            'categories': list,  # NSFW
+            'title': 'Sensual striptease porn with Samantha Alexandra',
-        video_url = self._html_search_regex(r'video_url:\s*\'([^\']+)\'', webpage, 'video_url')
+        display_id = self._match_id(url)
-        ext = self._html_search_meta('encodingFormat', webpage, 'ext')[1:]
+        webpage = self._download_webpage(url, display_id)
-            r'<title>([^<]+)</title>', webpage, 'title')
+        video_id = self._search_regex(
-        description = self._html_search_meta('description', webpage, 'description', fatal=False)
+        video_url = self._search_regex(
-        thumbnail = self._html_search_meta('thumbnail', webpage, 'thumbnail', fatal=False)
+        title = self._search_regex(
-            else categories_str.split(','))
+        age_limit = self._rta_search(webpage)
-            'description': description,
+            'title': title,
-            'age_limit': 18,
+            'age_limit': age_limit,
-
+
-    _VALID_URL = r'https?://(?:www\.)?eroprofile\.com/m/videos/view/(?P<display_id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?eroprofile\.com/m/videos/view/(?P<id>[^/]+)'
-            'categories': list,  # NSFW
+            'title': 'sexy babe softcore',
-        webpage = self._download_webpage(url, 'main')
+        display_id = self._match_id(url)
-        video_id = self._html_search_regex(r'glbUpdViews\s*\(\'\d*\',\'(\d+)\'', webpage, 'id')
+        webpage = self._download_webpage(url, display_id)
-        video_url = self._html_search_regex(r'<source src="([^"]+)', webpage, 'video_url')
+        video_id = self._search_regex(
-            else categories_str.split(','))
+            r'Title:</th><td>([^<]+)</td>', webpage, 'title')
-def expect_info_dict(self, expected_dict, got_dict):
+def expect_info_dict(self, got_dict, expected_dict):
-                expect_info_dict(self, test_case.get('info_dict', {}), res_dict)
+                expect_info_dict(self, res_dict, test_case.get('info_dict', {}))
-                expect_info_dict(self, tc.get('info_dict', {}), info_dict)
+                expect_info_dict(self, info_dict, tc.get('info_dict', {}))
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        description = self._html_search_meta('description', webpage, 'description')
+        title = self._html_search_regex(
-            r'Duration:[^\d]+(\d+:\d+)\s*<', webpage, 'duration', fatal=False))
+            r'itemprop="duration">\s*(\d+:\d+)\s*<',
-            r'class="views">\s*(\d+)\s*<', webpage, 'view count', fatal=False))
+            r'class="views">\s*(\d+)\s*<',
-            r'(\d+)</b> Comments?', webpage, 'comment count', fatal=False))
+            r'(\d+)</b> Comments?',
-            r'Duration:\s*(\d+:\d+)\s*<', webpage, 'duration', fatal=False))
+            r'Duration:[^\d]+(\d+:\d+)\s*<', webpage, 'duration', fatal=False))
-# coding: utf-8
+
-import datetime
+from ..utils import unified_strdate
-    _VALID_URL = r'http?://(?:www\.)?tele-task\.de/archive/video/html5/(?P<id>[0-9]+)/'
+    _VALID_URL = r'https?://(?:www\.)?tele-task\.de/archive/video/html5/(?P<id>[0-9]+)'
-            {
+        }, {
-                'ext': 'mp4',
+
-        date = datetime.datetime.strptime(date, '%d.%m.%Y').strftime('%Y%m%d')
+            r'itemprop="name">([^<]+)</a>', webpage, 'title')
-            'url': url_slides}]
+            'upload_date': upload_date,
-        }
+        return self.playlist_result(entries, lecture_id, title)
-from ..utils import ExtractorError
+from .common import compat_str
-            return json.loads(data_json)
+
-                                            webpage, 'video title')
+        raw_title = self._html_search_regex(
-            raise ExtractorError('No formats available for this video')
+        vid = self._html_search_regex(
-        vid_id = vid_ids[-1]
+        formats_json = {}
-        su = format_data['data']['su']
+        part_count = vid_data['data']['totalBlocks']
-                'id': '%s_part%02d' % (video_id, i + 1),
+            formats = []
-            playlist.append(video_info)
+                'duration': vid_data['data']['clipsDuration'][i],
-    parse_iso8601
+    parse_iso8601,
-                'duration': 896,
+                'duration': 896.62,
-        duration = int(rendition_items[0].get('duration').split('.')[0])
+        duration = float_or_none(rendition_items[0].get('duration'))
-                'tbr': int(r.get('bitrate')),
+                'width': int_or_none(r.get('width')),
-            'timestamp': 1399980122,
+    _TESTS = [
-    }
+
-        duration = int(rendition_items[0].get('duration'))
+        duration = int(rendition_items[0].get('duration').split('.')[0])
-            self.url_result('http://www.gameone.de/tv/%d' % video_id, 'GameOne')
+            self.url_result('http://www.gameone.de/tv/%d' %
-            }
+            },
-        smil_url = asset['video']
+        smil_url = assets_info['video']
-    _TEST = {
+    _VALID_URL = r'https?://(?:(?P<prefix>www|m)\.)?(?P<url>crunchyroll\.(?:com|fr)/(?:[^/]*/[^/?&]*?|media/\?id=)(?P<video_id>[0-9]+))(?:[/?&]|$)'
-    }
+    }, {
-    passed to the FileDownloader. The FileDownloader processes this
+    passed to the YoutubeDL. The YoutubeDL processes this
-            'id': video['id'],
+            'id': compat_str(video['id']),
-    _VALID_URL = r'https?://www\.telecinco\.es/[^/]+/[^/]+/[^/]+/(?P<episode>.*?)\.html'
+    _VALID_URL = r'https?://www\.telecinco\.es/[^/]+/[^/]+/[^/]+/(?P<id>.*?)\.html'
-            'duration': 149,
+            'duration': 152,
-            'id': '174042',
+            'id': 'e174042',
-            'thumbnail': 'http://cdnbakmi.kaltura.com/p/591531/sp/59153100/thumbnail/entry_id/0_okj015ty/version/100002/acv/182/width/640',
+            'thumbnail': r're:http://cdnbakmi\.kaltura\.com/.*thumbnail.*',
-        
+
-            'format': 'json',
+            'protocol': 'http',
-            display_id, 'Downloading video info')
+            query_url, display_id, 'Downloading video info')
-            'md5': '92a7fdd8a08783c68a174d7aa067dde8',
+            'url': 'https://tw.screen.yahoo.com/election-2014-askmayor/æ¢åå¸é·-é»ç§éæ¹è³´æ¸å¾·-éå¸¸é«å²-033009720.html',
-                'id': '7a23b569-7bea-36cb-85b9-bd5301a0a1fb',
+                'id': 'cac903b3-fcf4-3c14-b632-643ab541712f',
-                'duration': 429,
+                'title': 'æ¢åå¸é·ï¼é»ç§éæ¹è³´æ¸å¾·ãéå¸¸é«å²ã',
-            'md5': '3e401e4eed6325aa29d9b96125fd5b4f',
+            'url': 'https://ca.finance.yahoo.com/news/hackers-sony-more-trouble-well-154609075.html',
-                'id': 'c1b4c09c-8ed8-3b65-8b05-169c55358a83',
+                'id': 'e624c4bc-3389-34de-9dfc-025f74943409',
-                'duration': 21,
+                'title': '\'The Interview\' TV Spot: War',
-            'title': meta['title'],
+            'title': unescapeHTML(meta['title']),
-import re 
+import re
-        'md5': '290ef69fb2792e481169c3958dbfbd57',
+        'url': 'http://www.tele-task.de/archive/video/html5/26168/',
-        }
+        },
-        
+        lecture_id = self._match_id(url)
-        
+        url_speaker = self._html_search_regex(
-        
+        entries = [{
-            'id': video_id,
+            '_type': "playlist",
-        }
+            'entries': entries,
-        'md5': 'TODO: md5 sum of the first 10241 bytes of the video file (use --test)',
+        'md5': '290ef69fb2792e481169c3958dbfbd57',
-            # * Any Python type (for example int or float)
+            'upload_date': '20141218',
-            'description': description,
+from .teletask import TeleTaskIE
-            'thumbnail': self._proto_relative_url(metadata['image']),
+            'thumbnail': self._proto_relative_url(metadata['image'], 'http:'),
-    ExtractorError
+    ExtractorError,
-    _VALID_URL = r'http://video\.aktualne\.cz/.*/r~(?P<id>[0-9a-f]{32})/'
+    _VALID_URL = r'http://video\.aktualne\.cz/(?:[^/]+/)+r~(?P<id>[0-9a-f]{32})'
-            'title': 'Vondra o ÄeskÃ©m stoletÃ­: PÅi pohledu na Havla mi bylo trapnÄ'
+            'title': 'Vondra o ÄeskÃ©m stoletÃ­: PÅi pohledu na Havla mi bylo trapnÄ',
-            'title': 'StropnickÃ½: Policie VrbÄtice preventivnÄ nekontrolovala'
+            'title': 'StropnickÃ½: Policie VrbÄtice preventivnÄ nekontrolovala',
-            'id': '973eb3bc854e11e498be002590604f2e'
+            'id': '973eb3bc854e11e498be002590604f2e',
-        }]
+        }],
-            'thumbnail': 'http:%s' % metadata['image'],
+            'thumbnail': self._proto_relative_url(metadata['image']),
-            webpage)
+        # single video
-            return self._parse_video_metadata(items[0], video_id)
+        if item:
-            r'(?s)BBX\.context\.assets\[\'[0-9a-f]{32}\'\]\.push\((\{.+?\})\);',
+            r"(?s)BBX\.context\.assets\['[0-9a-f]{32}'\]\.push\(({.+?})\);",
-        raise ExtractorError('Could not find neither video nor playlist for requested ID')
+        raise ExtractorError('Could not find neither video nor playlist')
-    unescapeHTML
+    unescapeHTML,
-    IE_DESC = 'http://video.aktualne.cz/dvtv/'
+    IE_DESC = 'http://video.aktualne.cz/'
-    _VALID_URL = r'http://video\.aktualne\.cz/dvtv/(?P<id>[a-z0-9-]+/r~[0-9a-f]{32})/?'
+    _VALID_URL = r'http://video\.aktualne\.cz/.*/r~(?P<id>[0-9a-f]{32})/'
-        'md5': '75800f964fa0f82939a2914563301f72',
+        'md5': '67cb83e4a955d36e1b5d31993134a0c2',
-            'ext': 'webm',
+            'id': 'dc0768de855511e49e4b0025900fea04',
-            'id': '82ed4322849211e4a10c0025900fea04',
+            'id': '72c02230849211e49f60002590604f2e',
-        webpage = self._download_webpage(url, video_id)
+    def _parse_video_metadata(self, js, video_id):
-            ext = source['type'][6:]
+        for video in metadata['sources']:
-                'url': source['file'],
+                'url': video['file'],
-                'height': int(source['label'].rstrip('p')),
+                'format': '%s %s' % (ext, video['label']),
-            'thumbnail': 'http:%s' % payload['image'],
+            'id': metadata['mediaid'],
-        }
+        },
-            else:
+
-                    'quality': quality(format_id),
+                    'ext': stream.get('formaat', 'asf'),
-import json
+    compat_urllib_parse,
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>xtube\.com/watch\.php\?v=(?P<id>[^/?&]+))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>xtube\.com/watch\.php\?v=(?P<id>[^/?&#]+))'
-        url = 'http://www.' + mobj.group('url')
+        video_id = self._match_id(url)
-        video_title = self._html_search_regex(r'<p class="title">([^<]+)', webpage, 'title')
+        video_title = self._html_search_regex(
-            r'so_s\.addVariable\("owner_u", "([^"]+)', webpage, 'uploader', fatal=False)
+            [r"var\s+contentOwnerId\s*=\s*'([^']+)",
-            r'<p class="fieldsDesc">([^<]+)', webpage, 'description', fatal=False)
+            r'<p class="fieldsDesc">([^<]+)',
-                'url': furl,
+            r'<span class="bold">Runtime:</span> ([^<]+)</p>',
-        ]
+            }
-	unescapeHTML
+    js_to_json,
-		}
+    IE_NAME = 'dvtv'
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class ThePlatformIE(InfoExtractor):
+class ThePlatformIE(SubtitlesInfoExtractor):
-                    self.record_download_archive(info_dict)
+                self.record_download_archive(info_dict)
-__version__ = '2014.12.17.1'
+__version__ = '2014.12.17.2'
-        if self.params.get('continuedl', False) and os.path.isfile(encodeFilename(filename)) and not self.params.get('nopart', False):
+        if filename != '-' and self.params.get('continuedl', False) and os.path.isfile(encodeFilename(filename)) and not self.params.get('nopart', False):
-__version__ = '2014.12.17'
+__version__ = '2014.12.17.1'
-                     (?:[?#].*|$)'''
+                     '''
-__version__ = '2014.12.16.2'
+__version__ = '2014.12.17'
-    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console(?:\?(?:.*?[?&])?)id=(?P<id>[0-9a-z-]+)'
+    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console(?:\?(?:.*?[?&])?)id=(?P<id>[-0-9a-zA-Z]+)'
-    #(https://github.com/K-S-V/Scripts)
+    # (https://github.com/K-S-V/Scripts)
-             # Some rtmp streams seem abort after ~ 99.8%. Don't complain for those
+            # Some rtmp streams seem abort after ~ 99.8%. Don't complain for those
-                                    # set as soon as step is set
+            # Quelch pyflakes warnings - start will be set when step is set
-        #assert False, 'Internal error: %r should be of type %r, is %r' % (s, compat_str, type(s))
+        # assert False, 'Internal error: %r should be of type %r, is %r' % (s, compat_str, type(s))
-    _VALID_URL = r'https?://techtv\.mit\.edu/(videos|embeds)/(?P<id>\d+)'
+    _VALID_URL = r'https?://techtv\.mit\.edu/(?:videos|embeds)/(?P<id>\d+)'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                #'subtitles': 'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/video-lectures/lecture-7-multiple-variables-expectations-independence/MIT6_041F11_lec07_300k.mp4.srt'
+                # 'subtitles': 'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/video-lectures/lecture-7-multiple-variables-expectations-independence/MIT6_041F11_lec07_300k.mp4.srt'
-                #'subtitles': 'http://ocw.mit.edu//courses/mathematics/18-01sc-single-variable-calculus-fall-2010/ocw-18.01-f07-lec01_300k.SRT'
+                # 'subtitles': 'http://ocw.mit.edu//courses/mathematics/18-01sc-single-variable-calculus-fall-2010/ocw-18.01-f07-lec01_300k.SRT'
-__version__ = '2014.12.16.1'
+__version__ = '2014.12.16.2'
-    _VALID_URL = r'https?://tvthek\.orf\.at/(?:programs/.+?/episodes|topics/.+?|program/[^/]+)/(?P<id>\d+)'
+    _VALID_URL = r'https?://tvthek\.orf\.at/(?:programs/.+?/episodes|topics?/.+?|program/[^/]+)/(?P<id>\d+)'
-    _TEST = {
+    _TESTS = [{
-    }
+        'skip': 'Blocked outside of Austria / Germany',
-                if data['name'] == 'Tracker::EPISODE_DETAIL_PAGE_OVER_PROGRAM':
+                if data['name'] in (
-                '&%40videoPlayer={0}'.format(brightcove_id),
+            'url': (
-    _VALID_URL = r'https?://.*brightcove\.com/(services|viewer).*?\?(?P<query>.*)'
+    _VALID_URL = r'(?:https?://.*brightcove\.com/(services|viewer).*?\?|brightcove:)(?P<query>.*)'
-readme = re.sub(r'(?s)# INSTALLATION.*?(?=# DESCRIPTION)', '', readme)
+PREFIX = '''%YOUTUBE-DL(1)
-__version__ = '2014.12.16'
+__version__ = '2014.12.16.1'
-                                       'Downloading page %s' % i)
+            info = self._download_json(
-    _VALID_URL = r'https?://(?:www\.)?allocine\.fr/(?P<typ>article|video|film)/(fichearticle_gen_carticle=|player_gen_cmedia=|fichefilm_gen_cfilm=)(?P<id>[0-9]+)(?:\.html)?'
+    _VALID_URL = r'https?://(?:www\.)?allocine\.fr/(?P<typ>article|video|film)/(fichearticle_gen_carticle=|player_gen_cmedia=|fichefilm_gen_cfilm=|video-)(?P<id>[0-9]+)(?:\.html)?'
-                self.to_screen('[download] Downloading video #%s of %s' % (i, n_entries))
+                self.to_screen('[download] Downloading video %s of %s' % (i, n_entries))
-__version__ = '2014.12.15'
+__version__ = '2014.12.16'
-import argparse
+import optparse
-    with io.open(args.INFILE, encoding='utf-8') as inf:
+    parser = optparse.OptionParser(usage='%prog INFILE OUTFILE')
-    with io.open(args.OUTFILE, 'w', encoding='utf-8') as outf:
+    with io.open(outfile, 'w', encoding='utf-8') as outf:
-    format:            Video format code.
+    format:            Video format code. See options.py for more information.
-        time.sleep(12)
+        self._sleep(12, video_id)
-        time.sleep(5)
+        self._sleep(5, video_id)
-__version__ = '2014.12.14'
+__version__ = '2014.12.15'
-                             youtube_dl/postprocessor/__init__.py for a list.
+                       * key:  The name of the postprocessor. See
-        """
+        # See YoutubeDl.py (search for progress_hooks) for a description of
-from .postprocessor import FFmpegMergerPP, FFmpegPostProcessor
+from .postprocessor import (
-)
+    # PostProcessors
-    FFmpegVideoConvertor,
+    FFmpegVideoConvertorPP,
-    'FFmpegVideoConvertor',
+    'FFmpegVideoConvertorPP',
-class FFmpegVideoConvertor(FFmpegPostProcessor):
+class FFmpegVideoConvertorPP(FFmpegPostProcessor):
-        super(FFmpegVideoConvertor, self).__init__(downloader)
+        super(FFmpegVideoConvertorPP, self).__init__(downloader)
-    OnDemandPagedList,
+    intlist_to_bytes,
-    parse_filesize,
+    xpath_with_ns,
-                    unrecognized='present'):
+                    version_re=None, unrecognized='present'):
-        out, err = subprocess.Popen(
+        out, _ = subprocess.Popen(
-    m = re.search(version_re, firstline)
+    if isinstance(out, bytes):  # Python 2.x
-                r'datetime="([^"]+)"', webpage, 'upload date', fatal=False, default=None))
+                r'datetime="([^"]+)"', submit_info, 'upload date', fatal=False, default=None))
-            r'.*-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player)?\.(?P<ext>[a-z]+)$',
+            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player)?\.(?P<ext>[a-z]+)$',
-__version__ = '2014.12.13.1'
+__version__ = '2014.12.14'
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?rtp\.pt/play/p(?P<program_id>[0-9]+)/(?P<id>[^/?#]+)/?'
-    }
+    }, {
-__version__ = '2014.12.13'
+__version__ = '2014.12.13.1'
-    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<title>[^?#]+))?'
+    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<title>[^?#]+)|/?(?:$|[?#]))'
-    elif sys.version_info < (3, 2):
+        try:
-__version__ = '2014.12.12.7'
+__version__ = '2014.12.13'
-from helper import assertRegexpMatches
+from test.helper import assertRegexpMatches
-            segment_duration = idoc.find('.//trt').text.strip()
+            segment_duration = float_or_none(
-            r'"vpid"\s*:\s*"([\da-z]{8})"', webpage, 'vpid', fatal=False)
+            r'"vpid"\s*:\s*"([\da-z]{8})"', webpage, 'vpid', fatal=False, default=None)
-    _VALID_URL = r'https://www.restudy.dk/video/play/id/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?restudy\.dk/video/play/id/(?P<id>[0-9]+)'
-            'ext': 'mp4',
+            'ext': 'flv',
-        title = self._og_search_title(webpage)
+
-            'protocol': 'rtmp',
+            'description': description,
-    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<title>[^?#]+))'
+    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<title>[^?#]+))?'
-            r'"vpid"\s*:\s*"([\da-z]{8})"', webpage, 'vpid', fatal=False)
+            r'"vpid"\s*:\s*"([\da-z]{8})"', webpage, 'vpid', fatal=False, default=None)
-            segment_duration = idoc.find('.//trt').text.strip()
+            segment_duration = float_or_none(
-from helper import assertRegexpMatches
+from test.helper import assertRegexpMatches
-        },
+        'url': 'http://tvthek.orf.at/program/Aufgetischt/2745173/Aufgetischt-Mit-der-Steirischen-Tafelrunde/8891389',
-        playlist_id = mobj.group('id')
+        playlist_id = self._match_id(url)
-
+        show_id = self._match_id(url)
-    _VALID_URL = r'https?://(?:www\.)?keek\.com/(?:!|\w+/keeks/)(?P<videoID>\w+)'
+    _VALID_URL = r'https?://(?:www\.)?keek\.com/(?:!|\w+/keeks/)(?P<id>\w+)'
-        'md5': '9b0636f8c0f7614afa4ea5e4c6e57e83',
+        'md5': '09c5c109067536c1cec8bac8c21fea05',
-            'uploader': 'ytdl',
+            'id': 'NODfbab',
-        video_id = m.group('videoID')
+        video_id = self._match_id(url)
-            webpage, 'uploader', fatal=False)
+        raw_desc = self._html_search_meta('description', webpage)
-            'uploader': uploader
+            'uploader': uploader,
-    compat_str,
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-
+from ..compat import compat_str
-    compat_str,
+from ..compat import compat_str
-
+from ..compat import compat_urlparse
-    compat_urlparse,
+from ..compat import compat_urllib_parse
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    compat_urllib_parse,
+from ..compat import compat_parse_qs
-
+        video_id = self._match_id(url)
-    compat_urllib_request,
+from ..compat import (
-
+    compat_urllib_request,
-    unsmuggle_url,
+    find_xpath_attr,
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    orderedSet,
+from ..utils import (
-    ExtractorError,
+from ..compat import (
-    compat_urllib_request,
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                                       webpage, 'video URL')
+        video_url = self._search_regex(
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-
+)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>extremetube\.com/.*?video/.+?(?P<videoid>[0-9]+))(?:[/?&]|$)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>extremetube\.com/.*?video/.+?(?P<id>[0-9]+))(?:[/?&]|$)'
-        video_id = mobj.group('videoid')
+        video_id = mobj.group('id')
-    ExtractorError,
+from ..compat import (
-    _VALID_URL = r'^http://video\.fc2\.com/((?P<lang>[^/]+)/)?content/(?P<id>[^/]+)'
+    _VALID_URL = r'^http://video\.fc2\.com/(?:[^/]+/)?content/(?P<id>[^/]+)'
-
+        video_id = self._match_id(url)
-    ExtractorError,
+from ..compat import (
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-    parse_duration,
+)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    ExtractorError,
+)
-    compat_urllib_parse_urlparse,
+    ExtractorError,
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    determine_ext,
+from ..compat import (
-            'ext': determine_ext(video_url),
+from ..compat import (
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-
+)
-    _VALID_URL = r'http://(?:www\.)?hypem\.com/track/([^/]+)/([^/]+)'
+    _VALID_URL = r'http://(?:www\.)?hypem\.com/track/(?P<id>[^/]+)/'
-        track_id = mobj.group(1)
+        track_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    _VALID_URL = r'^https?://(?:www\.)?keezmovies\.com/video/.+?(?P<videoid>[0-9]+)(?:[/?&]|$)'
+    _VALID_URL = r'https?://(?:www\.)?keezmovies\.com/video/.+?(?P<id>[0-9]+)(?:[/?&]|$)'
-        video_id = mobj.group('videoid')
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    compat_str,
+# coding: utf-8
-from ..utils import (
+from ..compat import (
-    _VALID_URL = r'^(?:https?://)?malemotion\.com/video/(.+?)\.(?P<id>.+?)(#|$)'
+    _VALID_URL = r'https?://malemotion\.com/video/(.+?)\.(?P<id>.+?)(#|$)'
-        'md5': 'b3cc49f953b107e4a363cdff07d100ce',
+        'url': 'http://malemotion.com/video/bete-de-concours.ltc',
-            "age_limit": 18,
+            'id': 'ltc',
-
+        video_id = self._match_id(url)
-        # Extract title
+        video_url = compat_urllib_parse.unquote(self._search_regex(
-        # Extract video thumbnail
+        self._sort_formats(formats)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    _VALID_URL = r'http://www\.mitele\.es/[^/]+/[^/]+/[^/]+/(?P<episode>[^/]+)/'
+    _VALID_URL = r'http://www\.mitele\.es/[^/]+/[^/]+/[^/]+/(?P<id>[^/]+)/'
-        episode = mobj.group('episode')
+        episode = self._match_id(url)
-            flags=re.DOTALL
+            r'(?s)MSV\.embedData\[.*?\]\s*=\s*({.*?});', webpage, 'embed data',
-from ..utils import (
+from ..compat import (
-    ExtractorError,
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    _VALID_URL = r'^https?://(?:www\.)?(?P<url>mofosex\.com/videos/(?P<videoid>[0-9]+)/.*?\.html)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>mofosex\.com/videos/(?P<id>[0-9]+)/.*?\.html)'
-        video_id = mobj.group('videoid')
+        video_id = mobj.group('id')
-from ..utils import (
+from ..compat import (
-
+        video_id = self._match_id(url)
-    ExtractorError,
+from ..compat import (
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-
+        display_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-
+)
-from ..utils import (
+from ..compat import (
-        video_id = mobj.group(1)
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    _VALID_URL = r'https?://(?:www\.)?(nfb|onf)\.ca/film/(?P<id>[\da-z_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:nfb|onf)\.ca/film/(?P<id>[\da-z_-]+)'
-        page = self._download_webpage('https://www.nfb.ca/film/%s' % video_id, video_id, 'Downloading film page')
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-    int_or_none,
+)
-    compat_urllib_request,
+from ..compat import (
-    ExtractorError,
+    compat_urllib_request,
-    compat_str,
+from ..compat import (
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-    compat_urlparse
+from ..compat import (
-    _VALID_URL = r'^https?://(?:www|m)\.nuvid\.com/video/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www|m)\.nuvid\.com/video/(?P<id>[0-9]+)'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-from ..utils import compat_urllib_parse
+from ..compat import compat_urllib_parse
-        'file': 'zpsc0c3b9fa.mp4',
+            'id': 'zpsc0c3b9fa',
-    ExtractorError,
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    compat_urllib_parse,
+    ExtractorError,
-    _VALID_URL = r'^https?://www\.playvid\.com/watch(\?v=|/)(?P<id>.+?)(?:#|$)'
+    _VALID_URL = r'https?://www\.playvid\.com/watch(\?v=|/)(?P<id>.+?)(?:#|$)'
-        'md5': '44930f8afa616efdf9482daf4fe53e1e',
+        'url': 'http://www.playvid.com/watch/RnmBNgtrrJu',
-            'id': 'agbDDi7WZTV',
+            'id': 'RnmBNgtrrJu',
-            'duration': 240,
+            'title': 'md5:9256d01c6317e3f703848b5906880dc8',
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-    compat_urllib_parse,
+)
-    _VALID_URL = r'^https?://(?:www\.)?pornhub\.com/view_video\.php\?viewkey=(?P<id>[0-9a-f]+)'
+    _VALID_URL = r'https?://(?:www\.)?pornhub\.com/view_video\.php\?viewkey=(?P<id>[0-9a-f]+)'
-    determine_ext,
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    compat_urllib_parse,
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    unified_strdate,
+)
-
+        video_id = self._match_id(url)
-        movie_id = mobj.group('id')
+        movie_id = self._match_id(url)
-    ExtractorError,
+from ..compat import (
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            raise ExtractorError('Video %s does not exist' % video_id, expected=True)
+        video_id = self._match_id(url)
-        download_form = dict(re.findall(r'<input type="hidden" name="([^"]+)" value="([^"]*)"', page))
+        if '>File does not exist<' in webpage:
-        request = compat_urllib_request.Request(url, compat_urllib_parse.urlencode(download_form))
+        download_form = dict(re.findall(
-        video_page = self._download_webpage(request, video_id, 'Downloading video page')
+        video_page = self._download_webpage(
-        filesize = int_or_none(self._html_search_meta('full:size', page, 'file size', fatal=False))
+        video_url = self._html_search_regex(
-            r'data-poster="([^"]+)"', video_page, 'thumbnail', fatal=False, default=None)
+            r'data-poster="([^"]+)"', video_page, 'thumbnail', default=None)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-    ExtractorError,
+import re
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-
+)
-from ..utils import (
+from ..compat import (
-    unified_strdate,
+)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-)
+from ..compat import (
-    compat_urllib_request,
+    ExtractorError,
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import compat_urlparse
+from ..compat import compat_urlparse
-from ..utils import (
+from ..compat import (
-from ..utils import compat_parse_qs
+from ..compat import compat_parse_qs
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-
+)
-    _VALID_URL = r'http://(www\.)?vbox7\.com/play:(?P<id>[^/]+)'
+    _VALID_URL = r'http://(?:www\.)?vbox7\.com/play:(?P<id>[^/]+)'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-    get_element_by_id,
+)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-
+from ..compat import compat_urlparse
-            'duration': 135,
+            'duration': 138,
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-
+        video_id = self._match_id(url)
-    compat_str,
+    orderedSet,
-    orderedSet)
+)
-from ..utils import (
+from ..compat import (
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-from ..utils import ExtractorError, compat_urllib_request
+from ..compat import compat_urllib_request
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-        # Get webpage content
+        video_id = self._match_id(url)
-from ..utils import (
+from ..compat import (
-    _VALID_URL = r'https?://(?:www\.)?(?P<url>xtube\.com/watch\.php\?v=(?P<videoid>[^/?&]+))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>xtube\.com/watch\.php\?v=(?P<id>[^/?&]+))'
-        video_id = mobj.group('videoid')
+        video_id = mobj.group('id')
-from ..utils import (
+from ..compat import (
-    ExtractorError,
+)
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?xvideos\.com/video([0-9]+)(?:.*)'
+    _VALID_URL = r'https?://(?:www\.)?xvideos\.com/video(?P<id>[0-9]+)(?:.*)'
-
+        video_id = self._match_id(url)
-    ExtractorError,
+from ..compat import (
-from ..utils import compat_urllib_parse
+from ..compat import compat_urllib_parse
-from ..utils import (
+from ..compat import (
-
+)
-    compat_str,
+from ..compat import (
-    _VALID_URL = r'https?://(?:www\.)?stream\.cz/.+/(?P<videoid>.+)'
+    _VALID_URL = r'https?://(?:www\.)?stream\.cz/.+/(?P<id>[0-9]+)'
-            'thumbnail': 'http://im.stream.cz/episode/52961d7e19d423f8f06f0100',
+            'description': 'TaÅ¡ka s grÃ³nskou pomazÃ¡nkou a dalÅ¡Ã­ pekelnosti ZDE',
-        'md5': '246272e753e26bbace7fcd9deca0650c',
+        'md5': 'e54a254fb8b871968fd8403255f28589',
-            'thumbnail': 'http://im.stream.cz/episode/537f838c50c11f8d21320000',
+            'description': 'md5:3862a00ba7bf0b3e44806b544032c859',
-        jsonData = json.loads(data)
+        video_id = self._match_id(url)
-
+        for quality, video in enumerate(data['video_qualities']):
-                    'url': video_format['source'],
+                    'format_note': '%s-%s' % (qlabel, typ) if qlabel else typ,
-
+        image = data.get('image')
-            'thumbnail': jsonData['episode_image_original_url'].replace('//', 'http://'),
+            'id': video_id,
-            'view_count': int_or_none(jsonData['stats_total']),
+            'description': data.get('web_site_text'),
-            self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))
+        if not playlist_id or self._downloader.params.get('noplaylist'):
-                playlist_html)]
+        webpage = self._download_webpage(url, playlist_id)
-            }
+        return {
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            return FiveMinIE._build_result(video_id)
+            return self.url_result('5min:%s' % video_id)
-                'entries': [FiveMinIE._build_result(id) for id in ids]
+                'entries': [self.url_result('5min:%s' % vid) for vid in ids]
-from ..utils import (
+from ..compat import (
-        (?:https?://[^/]*?5min\.com/Scripts/PlayerSeed\.js\?(.*?&)?playList=|
+        (?:https?://[^/]*?5min\.com/Scripts/PlayerSeed\.js\?(?:.*?&)?playList=|
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-    if sys.version_info < (3, 2):
+    if hasattr(ssl, 'create_default_context'):  # Python >= 3.4 or 2.7.9
-        return compat_urllib_request.HTTPSHandler(context=context, **kwargs)
+            'webpage_url': 'http://comediansincarsgettingcoffee.com/%s' % (video_data.get('urlSlug', video_data.get('slug'))),
-    _MORE_PAGES_URL = 'https://www.youtube.com/c4_browse_ajax?action_load_more_videos=1&flow=list&paging=%s&view=0&sort=da&channel_id=%s'
+            more_widget_html = content_html = channel_page
-                ids_in_page = self.extract_videos_from_page(page['content_html'])
+                ids_in_page = self.extract_videos_from_page(content_html)
-                if self._MORE_PAGES_INDICATOR not in page['load_more_widget_html']:
+                mobj = re.search(
-            'id': '33124-4',
+            'id': '33124-24',
-        json_url = 'http://urort.p3.no/breeze/urort/TrackDtos?$filter=' + fstr
+        json_url = 'http://urort.p3.no/breeze/urort/TrackDTOViews?$filter=%s&$orderby=Released%%20desc&$expand=Tags%%2CFiles' % fstr
-        } for s in songs]
+        entries = []
-        playlist_id = mobj.group('id')
+        playlist_id = self._match_id(url)
-    _VALID_URL = r'https?://(?:www\.)?comediansincarsgettingcoffee\.com/(?P<id>[a-z0-9\-]+)/?'
+    _VALID_URL = r'http://(?:www\.)?comediansincarsgettingcoffee\.com/(?P<id>[a-z0-9\-]*)'
-from .ccc import ComCarCoffIE
+from .comcarcoff import ComCarCoffIE
-        }
+# encoding: utf-8
-            'md5': '4b9754921fddb68106e48c142e2a01e6',
+            'uploader_id': 'UCdEH6EjDKwtTe-sO2f0_1XA',
-import re
+import json
-    unified_strdate,
+    int_or_none,
-    _VALID_URL = r'https?://(?:\w+\.)?pornotube\.com(/c/(?P<channel>[0-9]+))?(/m/(?P<videoid>[0-9]+))(/(?P<title>.+))$'
+    _VALID_URL = r'https?://(?:\w+\.)?pornotube\.com/(?:[^?#]*?)/video/(?P<id>[0-9]+)'
-        'md5': '374dd6dcedd24234453b295209aa69b6',
+        'url': 'http://www.pornotube.com/orientation/straight/video/4964/title/weird-hot-and-wet-science',
-            'age_limit': 18
+            'id': '4964',
-        mobj = re.match(self._VALID_URL, url)
+        video_id = self._match_id(url)
-        video_title = mobj.group('title')
+        # Fetch origin token
-        webpage = self._download_webpage(url, video_id)
+        # Get video URL
-        video_url = compat_urllib_parse.unquote(video_url)
+        # Get additional info (title etc.)
-        age_limit = self._rta_search(webpage)
+        timestamp = int_or_none(info.get('publishDate'), scale=1000)
-            'age_limit': age_limit,
+            'title': info['title'],
-__version__ = '2014.12.12.6'
+__version__ = '2014.12.12.7'
-__version__ = '2014.12.12.5'
+__version__ = '2014.12.12.6'
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:ch|sx|eu|at|ag|co)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:ch|sx|eu|at|ag|co|li)'}
-__version__ = '2014.12.12.4'
+__version__ = '2014.12.12.5'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-__version__ = '2014.12.12.3'
+__version__ = '2014.12.12.4'
-            time.sleep(max((byte_counter / rate_limit) - elapsed, 0))
+            time.sleep(max((byte_counter // rate_limit) - elapsed, 0))
-    filesystem.add_option(
+        '-A', '--auto-number',
-            'description': 'An emergency puts Dawson\'sf irefighter skills to the ultimate test in this four-part digital series.',
+    _VALID_URL = r'http://www\.nbc\.com/(?:[^/]+/)+(?P<id>n?\d+)'
-    }
+        {
-        theplatform_url = self._search_regex('class="video-player video-player-full" data-mpx-url="(.*?)"', webpage, 'theplatform url')
+        theplatform_url = self._search_regex(
-            note = 'Regexp didn\'t match: %r not found in %r' % (regexp, text)
+            note = 'Regexp didn\'t match: %r not found' % (regexp)
-                self.assertRegexpMatches(
+                assertRegexpMatches(
-                    r'(?:#.*\n*)?from __future__ import (?:[a-z_]+,\s*)*unicode_literals',
+                    r'(?:(?:#.*?|\s*)\n)*from __future__ import (?:[a-z_]+,\s*)*unicode_literals',
-__version__ = '2014.12.12.2'
+__version__ = '2014.12.12.3'
-        r'(?s)(#\s*DEVELOPER INSTRUCTIONS.*?)#\s*BUGS', readme).group(1)
+        r'(?s)(#\s*DEVELOPER INSTRUCTIONS.*?)#\s*EMBEDDING YOUTUBE-DL',
-__version__ = '2014.12.12.1'
+__version__ = '2014.12.12.2'
-                    new_result[f] = info[f]
+            force_properties = dict(
-            'ext': 'mp4',
+            'ext': 'flv',
-            'uploader_id': 'sarah.mitroff@cbsinteractive.com',
+            'uploader_id': '6085384d-619e-11e3-b231-14feb5ca9861',
-
+        display_id = self._match_id(url)
-            uploader_id = author.get('email')
+            uploader_id = author.get('id')
-
+            '_type': 'url_transparent',
-                        }
+        session_meta = {
-        return contents
+        return self.playlist_result(contents)
-
+from ..utils import js_to_json
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            })
+        params = self._parse_json(self._html_search_regex(
-from ..compat import compat_urlparse
+from ..compat import (
-    ExtractorError,
+    parse_duration,
-        'md5': '268b9f3c3229105c57859e166dd72b03',
+        'url': 'http://www.goshgay.com/video299069/diesel_sfw_xxx_video',
-            'id': '4116282',
+            'id': '299069',
-            'thumbnail': 're:http://.*\.jpg',
+            'title': 'DIESEL SFW XXX Video',
-        thumbnail = self._og_search_thumbnail(webpage)
+        title = self._html_search_regex(
-        ref = "%s://%s%s" % (url_comp[0], url_comp[1], url_comp[2])
+        flashvars = compat_parse_qs(self._html_search_regex(
-            'http_referer': ref,
+            'duration': duration,
-    _VALID_URL = r'^(?:https?://)www.goshgay.com/video(?P<id>\d+?)($|/)'
+    _VALID_URL = r'https?://www\.goshgay\.com/video(?P<id>\d+?)($|/)'
-
+
-    (lambda x: x)(**{'x': 0})
+    def _testfunc(x):
-    GetStdHandle = compat_WINFUNCTYPE(
+    GetStdHandle = ctypes.WINFUNCTYPE(
-    WriteConsoleW = compat_WINFUNCTYPE(
+    WriteConsoleW = ctypes.WINFUNCTYPE(
-    GetFileType = compat_WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)(("GetFileType", ctypes.windll.kernel32))
+    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)(("GetFileType", ctypes.windll.kernel32))
-    GetConsoleMode = compat_WINFUNCTYPE(
+    GetConsoleMode = ctypes.WINFUNCTYPE(
-from ..utils import find_xpath_attr
+from ..utils import (
-                'thumbnail': 'http://s.hswstatic.com/gif/videos/480x360/5266.jpg',
+                'display_id': 'cool-jobs-iditarod-musher',
-                'thumbnail': 'http://s.hswstatic.com/gif/videos/480x360/7199.jpg',
+                'display_id': 'survival-zone-food-and-water-in-the-savanna',
-                'thumbnail': 'http://s.hswstatic.com/gif/videos/480x360/118306353233.jpg',
+                'display_id': 'sword-swallowing-1-by-dan-meyer',
-        clip_info = self._search_regex('(?s)var clip = {(.*?)};', webpage, 'clip info')
+        clip_js = self._search_regex(
-        video_id = extract_clip_info('content_id', clip_info, 'video id')
+        video_id = clip_info['content_id']
-        for video in mp4:
+        m3u8_url = clip_info.get('m3u8')
-                vbr = int(video.attrib['system-bitrate']) / 1000
+                vbr = int_or_none(video.attrib['system-bitrate'], scale=1000)
-            'id': video_id,
+            'id': '%s' % video_id,
-            'duration': extract_clip_info('duration', clip_info),
+            'title': unescapeHTML(clip_info['clip_title']),
-    ExtractorError,
+import ctypes
-    GetStdHandle = ctypes.WINFUNCTYPE(
+    GetStdHandle = compat_WINFUNCTYPE(
-    WriteConsoleW = ctypes.WINFUNCTYPE(
+    WriteConsoleW = compat_WINFUNCTYPE(
-    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)(("GetFileType", ctypes.windll.kernel32))
+    GetFileType = compat_WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)(("GetFileType", ctypes.windll.kernel32))
-    GetConsoleMode = ctypes.WINFUNCTYPE(
+    GetConsoleMode = compat_WINFUNCTYPE(
-__version__ = '2014.12.12'
+__version__ = '2014.12.12.1'
-    description:    One-line video description.
+    description:    Full video description.
-__version__ = '2014.12.11'
+__version__ = '2014.12.12'
-
+        video_id = self._match_id(url)
-        ]
+        formats = [{
-
+        },
-    if n is None:
+    if n is None or n.text is None:
-def unified_strdate(date_str):
+def unified_strdate(date_str, day_first=True):
-
+    # Remove AM/PM + timezone
-        '%d/%m/%Y %H:%M:%S',
+    if day_first:
-            new_result = make_result(info)
+            new_result = ie_result.copy()
-from .screenwavemedia import ScreenwaveMediaIE
+from .screenwavemedia import CinemassacreIE, ScreenwaveMediaIE, TeamFourIE
-    month_by_name,
+    month_by_name,
-        }
+class ScreenwaveMediaIE(InfoExtractor):
-        video_id = mobj.group('video_id')
+    _TESTS = [{
-            r'\'vidtitle\'\s*:\s*"([^\']+)"', playerdata, 'vidtitle').replace('\\/', '/')
+            r'\'vidtitle\'\s*:\s*"([^"]+)"', playerdata, 'vidtitle').replace('\\/', '/')
-            r'\'pageurl\'\s*:\s*"([^\']+)"', playerdata, 'pageurl', fatal=False).replace('\\/', '/')
+            r'\'vidurl\'\s*:\s*"([^"]+)"', playerdata, 'vidurl').replace('\\/', '/')
-                bitrate = int_or_none(video.get('system-bitrate'))
+                bitrate = int_or_none(video.get('system-bitrate'), scale=1000)
-                        'tbr': bitrate // 1000 if bitrate else None,
+                        'tbr': bitrate,
-                        'abr': bitrate // 1000 if bitrate else None,
+                        'abr': bitrate,
-            self._sort_formats(formats)
+        self._sort_formats(formats)
-            '_episode_page': pageurl,
+
-        site_info = None
+        webpage = self._download_webpage(url, display_id)
-            mobj = re.match(self._VALID_URL, url)
+        playerdata_url = self._search_regex(
-                site_info = self._teamfourstar_get_info(url)
+        return {
-            raise ExtractorError("Failed to extract metadata for this URL")
+class TeamFourIE(InfoExtractor):
-            swm_info.update(site_info)
+    def _real_extract(self, url):
-        return swm_info
+        return {
-            r"(?s)'sources'\s*:\s*(\[.+?\])", webpage, 'sources')))]
+        quality = qualities(['sd', 'hd'])
-            r'<div class="cloudcast-play-button-container[^"]*?"'
+            r'<span class="play-button[^"]*?"'
-__version__ = '2014.12.10.3'
+__version__ = '2014.12.11'
-    _VALID_URL = r'^https?://www\.zdf\.de/ZDFmediathek(?P<hash>#)?/(.*beitrag/(?:video/)?)(?P<id>[0-9]+)(?:/[^/?]+)?(?:\?.*)?'
+    _VALID_URL = r'(?:zdf:|zdf:video:|https?://www\.zdf\.de/ZDFmediathek(?:#)?/(.*beitrag/(?:video/)?))(?P<id>[0-9]+)(?:/[^/?]+)?(?:\?.*)?'
-    def _extract_video(self, video_id):
+    def _real_extract(self, url):
-    _VALID_URL = r'^https?://www\.zdf\.de/ZDFmediathek(?P<hash>#)?/(.*kanaluebersicht/)(?P<id>[0-9]+)'
+class ZDFChannelIE(InfoExtractor):
-        'playlist_count': 3,
+        'playlist_count': 4,
-                        for video_id in channel['video_ids']],
+            'id': channel_id,
-                
+                'upload_date': '20120731',
-        }
+        },
-            else:
+            if dash_mpd:
-            video_webpage, 'categories', fatal=False)
+            video_webpage, 'categories', default=None)
-                'This content is not available in your country due to copyright reasons', expected=True)
+            self.report_warning(
-        elif len(video_info.get('url_encoded_fmt_stream_map', [])) >= 1 or len(video_info.get('adaptive_fmts', [])) >= 1:
+        elif len(video_info.get('url_encoded_fmt_stream_map', [''])[0]) >= 1 or len(video_info.get('adaptive_fmts', [''])[0]) >= 1:
-                'flash_ver': 'LNX 11,2,202,341',
+                'flash_version': 'LNX 11,2,202,341',
-        video_id =  url_basename(video_url).split('_')[0]
+        video_id = url_basename(video_url).split('_')[0]
-            'description': 'Getting a better understanding of the talent that comes through the doors of the Armory is one of our missions at Behind Kink. Asking the question what are you passionate about helps us get a littl...',
+            'description': 'md5:aee8e9611b4ff70186f752975d9b94b4',
-        video_id = video_id.split('_')[0]
+            r'<source src="([^"]+)"', webpage, 'video URL')
-        'md5': '41ad01222b8442089a55528fec43ec01',
+        'url': 'http://www.behindkink.com/2014/12/05/what-are-you-passionate-about-marley-blaze/',
-            'id': '36370',
+            'id': '37127',
-            'thumbnail': 'http://www.behindkink.com/wp-content/uploads/2014/08/36370_AB1576_Win.jpg',
+            'title': 'What are you passionate about â Marley Blaze',
-            webpage, 'URL base')
+            r'<source src="(.*?)" type="video/mp4" />', webpage, 'video URL')
-    if date_str == 'now'or date_str == 'today':
+    if date_str in ('now', 'today'):
-from ..utils import (
+from ..compat import (
-
+)
-    get_element_by_attribute,
+    get_element_by_attribute,
-from .zdf import ZDFIE
+from .zdf import ZDFIE, ZDFChannelIE
-
+    def _extract_video(self, video_id):
-            raise ExtractorError('Broadcast %s does not exist' % broadcast_id, expected=True)
+            raise ExtractorError(
-                                     'use --username and --password options to provide account credentials.', expected=True)
+                raise ExtractorError(
-            request = compat_urllib_request.Request(broadcast_url + '/?no_redirect=1', compat_urllib_parse.urlencode(login_form))
+            request = compat_urllib_request.Request(
-            broadcast_page = self._download_webpage(request, broadcast_id, 'Logging in and confirming age')
+            broadcast_page = self._download_webpage(
-            'window\.broadcast_control\.addFlashVar\\(\'file\', \'([^\']+)\'\\);',
+            r"window\.broadcast_control\.addFlashVar\('file'\s*,\s*'([^']+)'\)",
-        broadcast_json_page = self._download_webpage(url, broadcast_id, 'Downloading broadcast JSON')
+        broadcast_json_page = self._download_webpage(
-                raise ExtractorError('This broadcast is protected by a password, use the --video-password option', expected=True)
+                raise ExtractorError(
-            if not rtmp_url.startswith('rtmp://'):
+            mobj = re.search(r'^rtmp://[^/]+/(?P<app>.+)/?$', rtmp_url)
-            broadcast_title = broadcast_json['title']
+            broadcast_title = self._live_title(broadcast_json['title'])
-            'rtmp_conn': rtmp_conn
+            'rtmp_conn': rtmp_conn,
-__version__ = '2014.12.10.2'
+__version__ = '2014.12.10.3'
-    urlencode_postdata,
+    int_or_none,
-
+        video_id = self._match_id(url)
-            'thumbnail': video_data['thumbnail_src'],
+            'duration': int_or_none(video_data.get('video_duration')),
-__version__ = '2014.12.10.1'
+__version__ = '2014.12.10.2'
-    def _parse_dash_manifest(self, video_id, dash_manifest_url):
+    def _parse_dash_manifest(
-                        video_id, dash_manifest_url)
+                        video_id, dash_manifest_url, player_url, age_gate)
-__version__ = '2014.12.10'
+__version__ = '2014.12.10.1'
-                self.report_warning('Skipping DASH manifest: %r' % e, video_id)
+            dash_mpd = video_info.get('dashmpd')
-__version__ = '2014.12.06.1'
+__version__ = '2014.12.10'
-            elif not 'HOMEPATH' in os.environ:
+            elif 'HOMEPATH' not in os.environ:
-        if not '{}' in cmd:
+        if '{}' not in cmd:
-    if not 'signature' in versions_info:
+    if 'signature' not in versions_info:
-    if not '#__youtubedl_smuggle' in smug_url:
+    if '#__youtubedl_smuggle' not in smug_url:
-    resolved entity, for example "title" if the title of the referred video is
+    The key "ie_key" can be set to the class name (minus the trailing "IE",
-from ..utils import (
+
-    parse_iso8601,
+)
-    compat_str,
+    int_or_none,
-        }
+        },
-                    'vcodec': media_content.get(blip('vcodec')),
+                    'vcodec': media_content.get(blip('vcodec')) or 'none',
-                    'height': int(media_content.get('height')),
+                    'width': int_or_none(media_content.get('width')),
-    str_to_int,
+    parse_age_limit,
-    _VALID_URL = r'http://(?:www\.)?tvigle\.ru/(?:[^/]+/)+(?P<display_id>[^/]+)/$'
+    _VALID_URL = r'http://(?:www\.)?tvigle\.ru/(?:[^/]+/)+(?P<id>[^/]+)/$'
-            'md5': 'ff4344a4894b0524441fb6f8218dc716',
+            'url': 'http://www.tvigle.ru/video/sokrat/',
-                'age_limit': 16,
+                'id': '1848932',
-        display_id = mobj.group('display_id')
+        display_id = self._match_id(url)
-        age_limit = str_to_int(item['ageRestrictions'])
+        duration = float_or_none(item.get('durationMilliseconds'), 1000)
-from .cinemassacre import CinemassacreIE
+from .screenwavemedia import ScreenwaveMediaIE
-                'id': '19911',
+                'id': 'Cinemasssacre-19911',
-                'id': '521be8ef82b16',
+                'id': 'Cinemasssacre-521be8ef82b16',
-    def _real_extract(self, url):
+    def _cinemassacre_get_info(self, url):
-        display_id = mobj.group('display_id')
+        display_id = mobj.group('cm_display_id')
-        mobj = re.search(r'src="(?P<embed_url>http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?[^"]*\bid=(?P<full_video_id>(?:Cinemassacre-)?(?P<video_id>.+?)))"', webpage)
+        video_date = mobj.group('cm_date_Y') + mobj.group('cm_date_m') + mobj.group('cm_date_d')
-        playerdata = self._download_webpage(playerdata_url, video_id, 'Downloading player webpage')
+        return {
-            vidid = mobj.group('vidid') if mobj else full_video_id
+            vidid = mobj.group('vidid') if mobj else video_id
-            'title': video_title,
+            'title': vidtitle,
-            'thumbnail': video_thumbnail,
+            '_episode_page': pageurl,
-            path = parsed_url.path.replace('.', '_sd.', 1)
+            filename, ext = os.path.splitext(parsed_url.path)
-            self.to_stdout(info_dict['url'] + info_dict.get('play_path', ''))
+            if info_dict.get('requested_formats') is not None:
-                'description': 'Das finale und hÃ¤rteste Duell aller Zeiten ist vorbei! Der Weltmeister fÃ¼r dieses Jahr steht! Alle packenden Duelle der achten Episode von "Joko gegen Klaas - das Duell um die Welt" seht ihr hier noch einmal in voller LÃ¤nge!',
+                'description': 'md5:63b8963e71f481782aeea877658dec84',
-    _ITEM_TYPE_REGEXES = [
+    _PAGE_TYPE_REGEXES = [
-    _ITEM_ID_REGEXES = [
+    _PLAYLIST_ID_REGEXES = [
-        r'data-qvt=.+?<a href="([^"]+)"',
+    _PLAYLIST_CLIP_REGEXES = [
-
+    def _extract_clip(self, url, webpage):
-    def playlist_result(entries, playlist_id=None, playlist_title=None):
+    def playlist_result(entries, playlist_id=None, playlist_title=None, playlist_description=None):
-                'upload_date': '20140225',
+                'upload_date': '20140203',
-                'upload_date': '20140225',
+                'upload_date': '20141014',
-        ("GetStdHandle", ctypes.windll.kernel32))
+        (b"GetStdHandle", ctypes.windll.kernel32))
-        ctypes.wintypes.LPVOID)(("WriteConsoleW", ctypes.windll.kernel32))
+        ctypes.wintypes.LPVOID)((b"WriteConsoleW", ctypes.windll.kernel32))
-    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)(("GetFileType", ctypes.windll.kernel32))
+    GetFileType = ctypes.WINFUNCTYPE(ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)((b"GetFileType", ctypes.windll.kernel32))
-        ("GetConsoleMode", ctypes.windll.kernel32))
+        (b"GetConsoleMode", ctypes.windll.kernel32))
-                entries = ie_result['entries'][playliststart:playlistend]
+            ie_entries = ie_result['entries']
-                entries = ie_result['entries'].getslice(
+            elif isinstance(ie_entries, PagedList):
-    element of which is a valid dictionary under this specfication.
+    There must be a key "entries", which is a list, an iterable, or a PagedList
-            # Download all channel pages using the json-based channel_ajax query
+            entries = [
-                video_ids.extend(ids_in_page)
+                for video_id in ids_in_page:
-        return self.playlist_result(url_entries, channel_id)
+        return self.playlist_result(_entries(), channel_id)
-           {
+            {
-                webpage)
+                download_text)
-        self.assertEqual(version_tuple('10-6'), (10, 6))  # avconv style
+        self.assertEqual(version_tuple('10.1-6'), (10, 1, 6))  # avconv style
-    _VALID_URL = r"^(?:https?://)?(?:youtu\.be|(?:\w+\.)?youtube(?:-nocookie)?\.com)/channel/([0-9A-Za-z_-]+)"
+    _VALID_URL = r'https?://(?:youtu\.be|(?:\w+\.)?youtube(?:-nocookie)?\.com)/channel/(?P<id>[0-9A-Za-z_-]+)'
-            raise ExtractorError('Invalid URL: %s' % url)
+        channel_id = self._match_id(url)
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)([A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'
-        username = mobj.group(1)
+        username = self._match_id(url)
-        REQUIRED_VERSION = '1.0'
+        required_version = '10-0' if self._uses_avconv() else '1.0'
-                self._versions[self._executable], REQUIRED_VERSION):
+                self._versions[self._executable], required_version):
-                self._executable, self._executable, REQUIRED_VERSION)
+                self._executable, self._executable, required_version)
-    return [int(e) for e in v.split('.')]
+    return tuple(int(e) for e in re.split(r'[-.]', v))
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-
+        video_id = self._match_id(url)
-            self._html_search_meta('duration', webpage, 'duration', fatal=False))
+            self._html_search_meta('duration', webpage, 'duration'))
-    _VALID_URL = r'https?://(?:watch\.|www\.)?nba\.com/(?:nba/)?video(?P<id>/[^?]*?)(?:/index\.html)?(?:\?.*)?$'
+    _VALID_URL = r'https?://(?:watch\.|www\.)?nba\.com/(?:nba/)?video(?P<id>/[^?]*?)/?(?:/index\.html)?(?:\?.*)?$'
-                        ++download_tries
+                        download_tries += 1
-        'url': 'http://video.adultswim.com/rick-and-morty/close-rick-counters-of-the-rick-kind.html?x=y#title',
+    _VALID_URL = r'https?://(?:www\.)?adultswim\.com/videos/(?P<is_playlist>playlists/)?(?P<show_path>[^/]+)/(?P<episode_path>[^/?#]+)/?'
-                'md5': '4da359ec73b58df4575cd01a610ba5dc',
+           {
-                    'id': '8a250ba1450996e901453d7f02ca02f5',
+                    'id': 'rQxZvXQ4ROaSOqq-or2Mow-0',
-                }
+                    'title': 'Rick and Morty - Pilot Part 1',
-                'md5': 'ffbdf55af9331c509d95350bd0cc1819',
+                'md5': '77b0e037a4b20ec6b98671c4c379f48d',
-                    'id': '8a250ba1450996e901453d7f4bd102f6',
+                    'id': 'rQxZvXQ4ROaSOqq-or2Mow-3',
-                }
+                    'title': 'Rick and Morty - Pilot Part 4',
-                'md5': 'e8818891d60e47b29cd89d7b0278156d',
+                'md5': '2eb5c06d0f9a1539da3718d897f13ec5',
-                    'id': '8a250ba1450996e901453d7fc8ba02f8',
+                    'id': '-t8CamQlQ2aYZ49ItZCFog-0',
-                }
+                    'title': 'American Dad - Putting Francine Out of Business',
-    }
+        ],
-        description = episode_el.find('./description').text.strip()
+        show_path = mobj.group('show_path')
-        segment_els = episode_el.findall('./segments/segment')
+        for part_num, segment_id in enumerate(segment_ids):
-            duration = segment_el.attrib.get('duration')
+            segment_title = '%s - %s' % (show_title, episode_title)
-            segment_url = 'http://asfix.adultswim.com/asfix-svc/episodeservices/getCvpPlaylist?networkName=AS&id=%s' % segment_id
+            segment_duration = idoc.find('.//trt').text.strip()
-                width, height = self._video_dimensions.get(bitrate, (None, None))
+                ftype = file_el.attrib.get('type')
-                    'ext': self._video_extensions.get(bitrate, 'mp4'),
+                    'format_id': '%s_%s' % (bitrate, ftype),
-                    'width': width
+                    'quality': 1 if ftype == 'hd' else -1
-                'description': description
+                'duration': segment_duration,
-            'display_id': video_path,
+            'display_id': episode_path,
-            'thumbnail': thumbnail
+            'title': '%s - %s' % (show_title, episode_title),
-__version__ = '2014.12.06'
+__version__ = '2014.12.06.1'
-        json_params = self._search_regex(r'var currentVideo = new Video\((.*)\);', webpage, 'JSON parameters')
+        json_params = self._search_regex(
-__version__ = '2014.12.04.2'
+__version__ = '2014.12.06'
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/video/video(?P<id>-?[0-9]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/(?:sendung/ts|video/video)(?P<id>-?[0-9]+)\.html'
-            playerpage)
+        player_url = self._html_search_meta(
-            formats.append(f)
+            medias = re.findall(
-        thumbnail = re.findall(r'"(/multimedia/.+?\.jpg)"', playerpage)[-1]
+        thumbnail = 'http://www.tagesschau.de' + thumbnail_fn
-            'thumbnail': 'http://www.tagesschau.de' + thumbnail,
+            'title': title,
-            'description': self._og_search_description(webpage).strip(),
+            'description': description,
-            'url': 'http://adventure.howstuffworks.com/39521-deadliest-catch-nautical-collision-video.htm',
+            'url': 'http://adventure.howstuffworks.com/5266-cool-jobs-iditarod-musher-video.htm',
-                'thumbnail': 'http://s.hswstatic.com/gif/videos/480x360/39521.jpg',
+                'id': '450221',
-            'url': 'http://entertainment.howstuffworks.com/arts/34476-time-warp-fire-breathing-disaster-video.htm',
+            'url': 'http://entertainment.howstuffworks.com/arts/2706-sword-swallowing-1-by-dan-meyer-video.htm',
-                'thumbnail': 'http://s.hswstatic.com/gif/videos/480x360/34476.jpg',
+                'id': '440011',
-        video_id = self._extract_clip_info('content_id', clip_info, 'video id')
+
-        m3u8_url = self._extract_clip_info('m3u8', clip_info, 'm3u8 url', default=None)
+        m3u8_url = extract_clip_info('m3u8', clip_info, 'm3u8 url', default=None)
-            self._extract_clip_info(
+            extract_clip_info(
-                'tbr': int(video['bitrate'].rstrip('k')),
+                'vbr': int(video['bitrate'].rstrip('k')),
-            'duration': self._extract_clip_info('duration', clip_info),
+            'title': extract_clip_info('clip_title', clip_info, 'title'),
-            'url': 'http://adventure.howstuffworks.com/5266-cool-jobs-iditarod-musher-video.htm',
+            'url': 'http://adventure.howstuffworks.com/39521-deadliest-catch-nautical-collision-video.htm',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'id': '553475',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'description': 'Learn how to find both food and water while trekking in the African savannah. In this video from the Discovery Channel.',
-            'url': 'http://entertainment.howstuffworks.com/arts/2706-sword-swallowing-1-by-dan-meyer-video.htm',
+            'url': 'http://entertainment.howstuffworks.com/arts/34476-time-warp-fire-breathing-disaster-video.htm',
-                'thumbnail': 're:^https?://.*\.jpg$',
+                'id': '487036',
-            }
+    def _extract_clip_info(self, key, clip_info, name=None, **kargs):
-        display_id = mobj.group('id')
+        display_id = self._match_id(url)
-
+        clip_info = self._search_regex('(?s)var clip = {(.*?)};', webpage, 'clip info')
-
+        m3u8_url = self._extract_clip_info('m3u8', clip_info, 'm3u8 url', default=None)
-            'id': content_id,
+            'id': video_id,
-            'thumbnail': thumbnail,
+            'title': self._extract_clip_info('clip_title', clip_info, 'title'),
-
+        video_id = self._match_id(url)
-__version__ = '2014.12.04.1'
+__version__ = '2014.12.04.2'
-            r'(?s)<p class="fileLeng[ht][th]">.*?([0-9]+)\s*s',
+        duration = parse_duration(self._html_search_regex(
-            (?P<secs>[0-9]+)(?P<ms>\.[0-9]+)?\s*(?:s|secs?|seconds?)?$''', s)
+            (?P<secs>[0-9]+)(?P<ms>\.[0-9]+)?\s*(?:s|secs?|seconds?)?
-    res = int(m.group('secs'))
+    res = 0
-            res += int(m.group('hours')) * 60 * 60
+    if m.group('hours'):
-__version__ = '2014.12.04'
+__version__ = '2014.12.04.1'
-    m = re.match(r'(?P<num>[0-9]+(?:\.[0-9]*)?)\s*(?P<unit>%s)' % units_re, s)
+    m = re.match(
-    return int(float(m.group('num')) * _UNIT_TABLE[m.group('unit')])
+    num_str = m.group('num').replace(',', '.')
-    _VALID_URL = r'(?:https?://)?vine\.co/(?P<user>[^/]+)/?(\?.*)?$'
+    _VALID_URL = r'(?:https?://)?vine\.co/(?P<u>u/)?(?P<user>[^/]+)/?(\?.*)?$'
-            'id': 'Visa',
+    _TESTS = [
-    }
+        {
-            self._VINE_BASE_URL, user)
+        profile_url = "%sapi/users/profiles/%s%s" % (
-            timeline_url = "%sapi/timelines/users/%s?page=%s" % (
+            timeline_url = "%sapi/timelines/users/%s?page=%s&size=100" % (
-        webpage = self._force_download_webpage(url, display_id)
+        webpage = self._download_webpage(url, display_id, tries=5)
-        title = title.split(' / ', 2)[-1]
+            r'(?s) id=[\'"]path[\'"]>(?:.*? / ){2}(.*?)</span>', webpage, 'series')
-        playlist = self._force_download_webpage(
+        playlist = self._download_webpage(
-            'edId=0&sort=&page=0&pageSize=1000000' % playlist_id, display_id)
+            'edId=0&sort=&page=0&pageSize=10000' % playlist_id, display_id, tries=5)
-    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):
+    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, tries=1, timeout=5):
-        res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal)
+        success = False
-            'description': self._og_search_description(webpage, default=''),
+            'description': self._og_search_description(webpage),
-__version__ = '2014.12.03'
+__version__ = '2014.12.04'
-    _VALID_URL = r'http://(?:www\.)?myvidster\.com/video/(?P<id>\d+)/.*$'
+    _VALID_URL = r'http://(?:www\.)?myvidster\.com/video/(?P<id>\d+)/'
-            {
+            'info_dict': {
-                'upload_date':'20141016',
+                'uploader': 'Young Thug World',
-        cookie = compat_cookiejar.Cookie(0, name, value, None, None, domain, None,
+        cookie = compat_cookiejar.Cookie(
-        lecture_id = mobj.group('id')
+        lecture_id = self._match_id(url)
-        self._set_cookie('.youtube.com', 'PREF', 'f1=50000000&hl=en',
+        self._set_cookie(
-            expire_time=time.time() + 60*24*3600)
+            expire_time=time.time() + 2 * 30 * 24 * 3600)
-                    video_info_webpage = self._download_webpage(video_info_url,
+                    video_info_url = (
-import re
+            'thumbnail': 're:https?://.*\.jpg$',
-        # Download the initial webpage and extract all available data.
+
-            'file': '172419696.mp3',
+                'id': '172419696',
-        help='Do not read configuration files. When given in the global configuration file /etc/youtube-dl.conf: do not read the user configuration in ~/.config/youtube-dl.conf (%APPDATA%/youtube-dl/config.txt on Windows)')
+        help='Do not read configuration files. '
-from .tvp import TvpIE
+from .tvp import TvpIE, TvpSeriesIE
-            'description': '31.10.2013 - Odcinek 2',
+    _VALID_URL = r'https?://(?P<type>vod|www)\.tvp\.pl/.*/(?P<id>\d+)$'
-    }
+    ]
-        return {
+        mobj = re.match(self._VALID_URL, url)
-            'description': self._og_search_description(webpage),
+            'title': title,
-                'title': 'Hevnen er sÃ¸t episode 1:10 - Abu',
+                'title': 'Hevnen er sÃ¸t: Episode 10 - Abu',
-                'duration': 9056.000,
+                'duration': 9103.0,
-        'md5': '33aa4ff477ecd124d18d7b5d23b87ce5',
+            'add_ie': ['Soundcloud'],
-                'ext': 'mp3',
+                'description': 'md5:1fc3272ed7a635cce5be1568c2822997',
-                "uploader": "Young Thug World"
+                'uploader':'Young Thug World',
-        }
+        },
-                          (?:/?\?secret_token=(?P<secret_token>[^&]+?))?$)
+                          (?:/?\?secret_token=(?P<secret_token>[^&]+))?)
-        config = json.loads(config_json)
+            r'"pages\.jwplayer"\s*,\s*({.+?})\s*\)\s*</script>',
-                else:
+                if ext is None:
-__version__ = '2014.12.01'
+__version__ = '2014.12.03'
-            path = path[:extension_index] + '_sd' + path[extension_index:]
+            path = parsed_url.path.replace('.', '_sd.', 1)
-    _VALID_URL = r'https?://video\.(?P<team>[^.]*)\.nhl\.com/videocenter/(console\?.*?catid=(?P<catid>[0-9]+)(?![&?]id=).*?)?$'
+    _VALID_URL = r'https?://video\.(?P<team>[^.]*)\.nhl\.com/videocenter/(console\?[^(id=)]*catid=(?P<catid>[0-9]+)(?![&?]id=).*?)?$'
-                'path': initial_video_url.replace('.mp4', '_sd.mp4'),
+                'path': compat_urlparse.urlunparse(parsed_url[:2] + (path,) + parsed_url[3:])
-    _VALID_URL = r'^https?://(?:www\.)?rts\.ch/(?:(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html|play/tv/[^/]+/video/(?P<display_id_new>.+?)\?id=(?P<id_new>[0-9]+))'
+    _VALID_URL = r'https?://(?:www\.)?rts\.ch/(?:(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html|play/tv/[^/]+/video/(?P<display_id_new>.+?)\?id=(?P<id_new>[0-9]+))'
-    _VALID_URL = r'^https?://(?:www\.)?rts\.ch/(?:(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html|play/tv/-/video/(?P<display_id_new>.+?)\?id=(?P<id_new>[0-9]+))'
+    _VALID_URL = r'^https?://(?:www\.)?rts\.ch/(?:(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html|play/tv/[^/]+/video/(?P<display_id_new>.+?)\?id=(?P<id_new>[0-9]+))'
-    _VALID_URL = r'^https?://(?:www\.)?rts\.ch/(?:[^/]+/){2,}(?P<id>[0-9]+)-.*?\.html'
+    _VALID_URL = r'^https?://(?:www\.)?rts\.ch/(?:(?:[^/]+/){2,}(?P<id>[0-9]+)-(?P<display_id>.+?)\.html|play/tv/-/video/(?P<display_id_new>.+?)\?id=(?P<id_new>[0-9]+))'
-                'thumbnail': 're:^https?://.*\.image'
+                'thumbnail': 're:^https?://.*\.image',
-                'thumbnail': 're:^https?://.*\.image'
+                'thumbnail': 're:^https?://.*\.image',
-                'thumbnail': 're:^https?://.*\.image'
+                'thumbnail': 're:^https?://.*\.image',
-                'thumbnail': 're:^https?://.*\.image'
+                'thumbnail': 're:^https?://.*\.image',
-        video_id = m.group('id')
+        video_id = m.group('id') or m.group('id_new')
-                video_id)
+                display_id)
-            page = self._download_webpage(url, video_id)
+            page = self._download_webpage(url, display_id)
-            'ext': 'mp4',
+            'formats': formats,
-__version__ = '2014.11.27'
+__version__ = '2014.12.01'
-            url, station_id, note='Downloading station webpage')
+        station_info = self._download_json(
-            r'<p\s+(?:style="[^"]*"\s+)?class="description.*?"[^>]*>(.*?)</p>', webpage,
+            r'<p\s+(?:style="[^"]*"\s+)?class=".*?description.*?"[^>]*>(.*?)</p>', webpage,
-                self.to_screen(
+                # some songs in an album are not playable
-                    song_data, name, default='', group=2)
+                    r'''data-%s=([\'"])(?P<data>.*?)\1''' % name,
-            return
+            raise ExtractorError(
-            'title': title,
+            'title': self._og_search_title(webpage),
-            'url': 'https://myspace.com/coldplay/video/viva-la-vida/100008689',
+            'url': 'https://myspace.com/fiveminutestothestage/video/little-big-town/109594919',
-                'id': '100008689',
+                'id': '109594919',
-                'uploader_id': 'coldplay',
+                'title': 'Little Big Town',
-                'uploader': u'Three Days Grace',
+                'id': 'USZM20600099',
-from .myspace import MySpaceIE
+from .myspace import MySpaceIE, MySpaceAlbumIE
-        # song
+        # songs
-            'url': 'https://myspace.com/spiderbags/music/song/darkness-in-my-heart-39008454-27041242',
+            'url': 'https://myspace.com/killsorrow/music/song/of-weakened-soul...-93388656-103880681',
-                'id': '39008454',
+                'id': '93388656',
-                'uploader_id': 'spiderbags',
+                'playlist': 'The Demo',
-    (currently used by MTVIE)
+    (currently used by MTVIE and MySpaceIE)
-                    r'data-%s="(.*?)"' % name, webpage, name)
+                    r'''data-%s=([\'"])(.*?)\1''' % name,
-        }
+        },
-                    dash_manifest_url = ytplayer_config['args']['dashmpd']
+                dash_manifest_url = video_info.get('dashmpd')[0]
-                    break
+            try:
-        self.assertEqual(md5(subtitles['en']), '8062383cf4dec168fc40a088aa6d5888')
+        self.assertEqual(md5(subtitles['en']), '26399116d23ae3cf2c087cea94bc43b4')
-                'description': 'md5:9717375db5a9a3992be4668bbf3bc0a8',
+                'title': 'Afrojack, Spree Wilson - The Spark ft. Spree Wilson',
-        }
+        },
-                msg = 'Episode %s is no longer available' % group_id
+    def _download_media_selector(self, programme_id):
-            raise ExtractorError(msg, expected=True)
+                raise
-            description = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}summary').text
+        for media in self._extract_medias(media_selection):
-            duration = int(item.get('duration'))
+        return formats, subtitles
-                programme_id, 'Downloading media selection XML')
+    def _real_extract(self, url):
-                    subtitles = self._extract_captions(media, programme_id)
+            for item in self._extract_items(playlist):
-            r'data-mt="(.*?)"', webpage, 'enc_token')
+            r'minus_track\.tkn="(.+?)"', webpage, 'enc_token')
-            fatal=False))
+        self._set_cookie('.youtube.com', 'PREF', 'f1=50000000&hl=en',
-                return
+        self._set_language()
-            real_url = compat_urlparse.parse_qs(msg)['message'][0]
+            real_url = compat_urlparse.parse_qs(msg.strip())['message'][0]
-            video_id = mobj.group('id')
+            urlh = self._request_webpage(
-    def _call_api(self, path, video_id, note):
+    def _call_api(self, path, video_id, note, sub_lang=None):
-            })
+        for lang, lang_dict in medias['fr']['video_list'].items():
-__version__ = '2014.11.26.4'
+__version__ = '2014.11.27'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r'<div class="video-embed-videopost[^"]*".*?rel:bf_bucket_data=\'([^\']+)\'',
+            r'(?s)<div class="video-embed[^"]*"..*?rel:bf_bucket_data=\'([^\']+)\'',
-            if 'video' not in bd:
+            video = bd.get('video') or bd.get('progload_video')
-            entries.append(self.url_result(bd['video']['url']))
+            entries.append(self.url_result(video['url']))
-__version__ = '2014.11.26.3'
+__version__ = '2014.11.26.4'
-                return "'%s'" % v.replace('\\', '\\\\').replace("'", "\\'")
+                return "'%s'" % v.replace('\\', '\\\\').replace("'", "\\'").replace('\n', '\\n')
-__version__ = '2014.11.26.2'
+__version__ = '2014.11.26.3'
-__version__ = '2014.11.26.1'
+__version__ = '2014.11.26.2'
-__version__ = '2014.11.26'
+__version__ = '2014.11.26.1'
-json.dump(versions_info, open('update/versions.json', 'w'), indent=4, sort_keys=True)
+with open('update/versions.json', 'w') as versionsf:
-from __future__ import with_statement
+from __future__ import with_statement, unicode_literals
-    newc = re.sub(u'(?P<copyright>Copyright Â© 2006-)(?P<year>[0-9]{4})', u'Copyright Â© 2006-' + year, content)
+    newc = re.sub(r'(?P<copyright>Copyright Â© 2006-)(?P<year>[0-9]{4})', 'Copyright Â© 2006-' + year, content)
-                    ' %s  missing in %s' % (imps, fn))
+                self.assertRegexpMatches(
-EXPECTED_DESCRIPTION = u'''test chars:  "'/\Ã¤â­ð
+EXPECTED_DESCRIPTION = '''test chars:  "'/\Ã¤â­ð
-        self.assertEqual(jd['upload_date'], u'20121002')
+        self.assertEqual(jd['upload_date'], '20121002')
-        self.assertEqual(jd['title'], u'''youtube-dl test video "'/\Ã¤â­ð''')
+        self.assertEqual(jd['title'], '''youtube-dl test video "'/\Ã¤â­ð''')
-        # u'md5': 'fba8f7693e48fd4e8641b3fd5539a641',
+        # 'md5': 'fba8f7693e48fd4e8641b3fd5539a641',
-    IE_DESC = 'GorillaVid.in, daclips.in and movpod.in'
+    IE_DESC = 'GorillaVid.in, daclips.in, movpod.in and fastvideo.in'
-    def _download_json_cookies(self, url, video_id, note):
+    def _download_json(self, url_or_request, video_id, note='Downloading JSON metadata'):
-        return self._download_json(request, video_id, note)
+
-            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
+            self._LOGIN_URL, compat_urllib_parse.urlencode(login_form).encode('utf-8'))
-        lecture = self._download_json_cookies(
+        lecture = self._download_json(
-        response = self._download_json_cookies(
+        response = self._download_json(
-        response = self._download_json_cookies(
+        response = self._download_json(
-import time
+    def _download_json_cookies(self, url, video_id, note):
-        csrf = self._html_search_regex(r'<input type="hidden" name="csrf" value="(.+?)"', login_popup, 'csrf token')
+        csrf = self._html_search_regex(
-        response = self._download_json(request, None, 'Logging in as %s' % username)
+        request = compat_urllib_request.Request(
-            'https://www.udemy.com/api-1.1/lectures/%s' % lecture_id, lecture_id, 'Downloading lecture JSON')
+        lecture = self._download_json_cookies(
-            raise ExtractorError('Lecture %s is not a video' % lecture_id, expected=True)
+        asset_type = lecture.get('assetType') or lecture.get('asset_type')
-        stream_url = asset['streamUrl']
+        stream_url = asset.get('streamUrl') or asset.get('stream_url')
-        thumbnail = asset['thumbnailUrl']
+        thumbnail = asset.get('thumbnailUrl') or asset.get('thumbnail_url')
-        download_url = asset['downloadUrl']
+        download_url = asset.get('downloadUrl') or asset.get('download_url')
-                'url': download_url['Video480p'][0],
+                'url': video_480p[0],
-                'url': download_url['Video'][0],
+                'url': video[0],
-            'https://www.udemy.com/api-1.1/courses/%s' % course_path, course_path, 'Downloading course JSON')
+        response = self._download_json_cookies(
-            'https://www.udemy.com/course/subscribe/?courseId=%s' % course_id, course_id, 'Enrolling in the course')
+            'https://www.udemy.com/course/subscribe/?courseId=%s' % course_id,
-                                       course_id, 'Downloading course curriculum')
+        response = self._download_json_cookies(
-            for asset in response if asset.get('assetType') == 'Video'
+            self.url_result(
-            (?:daclips\.in|gorillavid\.in|movpod\.in))/
+            (?:daclips\.in|gorillavid\.in|movpod\.in|fastvideo\.in))/
-        thumbnail = self._search_regex(r'image\s*:\s*\'(http[^\']+)\',', webpage, 'thumbnail', fatal=False)
+        title = self._search_regex(
-        "Programming Language :: Python :: 3.3"
+        "Programming Language :: Python :: 3.2",
-                print_skipping(u'test depends on %sIE, marked as not WORKING' % other_ie.ie_key())
+                print_skipping('test depends on %sIE, marked as not WORKING' % other_ie.ie_key())
-                        report_warning(u'Failed due to network errors, skipping...')
+                        report_warning('Failed due to network errors, skipping...')
-        data = {u"Ã¶": u"Ã¶", u"abc": [3]}
+        data = {"Ã¶": "Ã¶", "abc": [3]}
-        return self.url_result(u'theplatform:%s' % real_id)
+        return self.url_result('theplatform:%s' % real_id)
-        u'skip': 'Blocked in the US'
+        'skip': 'Blocked in the US'
-            info_url, video_id, note=u'Downloading info page')
+            info_url, video_id, note='Downloading info page')
-                'title': track_data['performer'] + u' - ' + track_data['name'],
+                'title': track_data['performer'] + ' - ' + track_data['name'],
-        u'info_dict': {
+        'info_dict': {
-            raise ExtractorError(u'Video %s does not exist' % video_id, expected=True)
+            raise ExtractorError('Video %s does not exist' % video_id, expected=True)
-                webpage, u'mgid')
+                webpage, 'mgid')
-from ..utils import (
+from ..compat import (
-            self._downloader.report_warning(u'Got an empty reponse, trying '
+            self._downloader.report_warning('Got an empty reponse, trying '
-                note=u'Downloading JSON data for ' + str(vid_id))
+                note='Downloading JSON data for ' + str(vid_id))
-            raise ExtractorError(u'No formats available for this video')
+            raise ExtractorError('No formats available for this video')
-                note=u'Downloading part %d of %d' % (i + 1, part_count))
+                note='Downloading part %d of %d' % (i + 1, part_count))
-            raise ExtractorError(u'The webpage does not contain a video', expected=True)
+            raise ExtractorError(
-            self.to_screen(u'%s: found %s parts' % (video_id, len_parts))
+            self.to_screen('%s: found %s parts' % (video_id, len_parts))
-            raise ExtractorError(u'Invalid JSON')
+            raise ExtractorError('Invalid JSON')
-            raise ExtractorError(u'ERROR: no known formats available for video')
+            raise ExtractorError('ERROR: no known formats available for video')
-            raise FFmpegPostProcessorError(u'ffmpeg or avconv not found. Please install one.')
+            raise FFmpegPostProcessorError('ffmpeg or avconv not found. Please install one.')
-            warning = u'Your copy of %s is outdated, update %s to version %s or newer if you encounter any errors.' % (
+            warning = 'Your copy of %s is outdated, update %s to version %s or newer if you encounter any errors.' % (
-            self._downloader.to_screen(u'[debug] ffmpeg command line: %s' % shell_quote(cmd))
+            self._downloader.to_screen('[debug] ffmpeg command line: %s' % shell_quote(cmd))
-            return u'./' + fn
+        if fn.startswith('-'):
-            raise PostProcessingError(u'ffprobe or avprobe not found. Please install one.')
+            raise PostProcessingError('ffprobe or avprobe not found. Please install one.')
-            raise PostProcessingError(u'WARNING: unable to obtain file audio codec with ffprobe')
+            raise PostProcessingError('WARNING: unable to obtain file audio codec with ffprobe')
-        prefix, sep, ext = path.rpartition(u'.')  # not os.path.splitext, since the latter does not work on unicode in all setups
+        prefix, sep, ext = path.rpartition('.')  # not os.path.splitext, since the latter does not work on unicode in all setups
-                self._downloader.to_screen(u'[youtube] Post-process file %s exists, skipping' % new_path)
+                self._downloader.to_screen('[youtube] Post-process file %s exists, skipping' % new_path)
-                self._downloader.to_screen(u'[' + self._executable + '] Destination: ' + new_path)
+                self._downloader.to_screen('[' + self._executable + '] Destination: ' + new_path)
-                msg = u'audio conversion failed: ' + e.msg
+                msg = 'audio conversion failed: ' + e.msg
-                msg = u'error running ' + self._executable
+                msg = 'error running ' + self._executable
-                self._downloader.report_warning(u'Cannot update utime of audio file')
+                self._downloader.report_warning('Cannot update utime of audio file')
-        prefix, sep, ext = path.rpartition(u'.')
+        prefix, sep, ext = path.rpartition('.')
-            self._downloader.to_screen(u'[ffmpeg] Not converting video file %s - already is in target format %s' % (path, self._preferedformat))
+            self._downloader.to_screen('[ffmpeg] Not converting video file %s - already is in target format %s' % (path, self._preferedformat))
-        self._downloader.to_screen(u'[' + 'ffmpeg' + '] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)
+        self._downloader.to_screen('[' + 'ffmpeg' + '] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)
-            self._downloader.to_screen(u'[ffmpeg] Subtitles can only be embedded in mp4 files')
+        if information['ext'] != 'mp4':
-            self._downloader.to_screen(u'[ffmpeg] There aren\'t any subtitles to embed')
+            self._downloader.to_screen('[ffmpeg] There aren\'t any subtitles to embed')
-        self._downloader.to_screen(u'[ffmpeg] Embedding subtitles in \'%s\'' % filename)
+        temp_filename = filename + '.temp'
-            self._downloader.to_screen(u'[ffmpeg] There isn\'t any metadata to add')
+            self._downloader.to_screen('[ffmpeg] There isn\'t any metadata to add')
-        if info['ext'] == u'm4a':
+        if info['ext'] == 'm4a':
-        self._downloader.to_screen(u'[ffmpeg] Adding metadata to \'%s\'' % filename)
+        self._downloader.to_screen('[ffmpeg] Adding metadata to \'%s\'' % filename)
-        self._downloader.to_screen(u'[ffmpeg] Merging formats into "%s"' % filename)
+        self._downloader.to_screen('[ffmpeg] Merging formats into "%s"' % filename)
-        self._downloader.to_screen(u'[ffmpeg] Fixing audio file "%s"' % filename)
+        self._downloader.to_screen('[ffmpeg] Fixing audio file "%s"' % filename)
-    _VALID_URL = r'(?:https?://)?(?:www\.)?videopremium\.(?:tv|me)/(?P<id>\w+)(?:/.*)?'
+    _VALID_URL = r'https?://(?:www\.)?videopremium\.(?:tv|me)/(?P<id>\w+)(?:/.*)?'
-            u"title": u"youtube-dl_test_video____a_________-BaW_jenozKc.mp4.mp4"
+        'url': 'http://videopremium.tv/4w7oadjsf156',
-            u'skip_download': True,
+        'params': {
-        u'skip': u'Test file has been deleted.',
+        'skip': 'Test file has been deleted.',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                note=u'Downloading webpage again (with cookie)')
+                note='Downloading webpage again (with cookie)')
-            r'<h2(?:.*?)>\s*(.+?)\s*<', webpage, u'video title')
+            r'<h2(?:.*?)>\s*(.+?)\s*<', webpage, 'video title')
-import re
+from __future__ import unicode_literals
-    determine_ext,
+    int_or_none,
-    IE_NAME = u'videofy.me'
+    _VALID_URL = r'https?://(?:www\.videofy\.me/.+?|p\.videofy\.me/v)/(?P<id>\d+)(&|#|$)'
-            u'uploader_id': u'thisisvideofyme',
+        'url': 'http://www.videofy.me/thisisvideofyme/1100701',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                }
+        return {
-import re
+from __future__ import unicode_literals
-    IE_NAME = u'tvp.pl'
+    IE_NAME = 'tvp.pl'
-            u'description': u'31.10.2013 - Odcinek 2',
+        'url': 'http://www.tvp.pl/warszawa/magazyny/campusnews/wideo/31102013/12878238',
-        u'skip': u'Download has to use same server IP as extraction. Therefore, a good (load-balancing) DNS resolver will make the download fail.'
+        'skip': 'Download has to use same server IP as extraction. Therefore, a good (load-balancing) DNS resolver will make the download fail.'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        self.report_extraction(video_id)
+        params = self._download_json(
-            'title': title,
+            'title': self._og_search_title(webpage),
-    _VALID_URL = r'(?x)(?:https?://)?(?:www\.)?trilulilu\.ro/video-(?P<category>[^/]+)/(?P<video_id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?trilulilu\.ro/video-[^/]+/(?P<id>[^/]+)'
-            u"description": u":) pentru copilul din noi",
+        'url': 'http://www.trilulilu.ro/video-animatie/big-buck-bunny-1',
-            u"skip_download": True
+        'params': {
-
+        video_id = self._match_id(url)
-            r'block_flash_vars[ ]=[ ]({[^}]+})', webpage, u'log info')
+            r'block_flash_vars[ ]=[ ]({[^}]+})', webpage, 'log info')
-                      u'video-formats2' % log)
+        format_url = ('http://fs%(server)s.trilulilu.ro/%(hash)s/'
-            errnote=u'Error while downloading formats')
+            note='Downloading formats',
-            u'key=ministhebest&format=%%s&sig=&exp=' %
+            'http://fs%(server)s.trilulilu.ro/stream.php?type=video'
-            u'title': u'MVï¼Far East MovementãThe Illestã',
+        'url': 'http://tv.sohu.com/20130724/n382479172.shtml#super',
-        u'skip': u'Only available from China',
+        'skip': 'Only available from China',
-                base_data_url = u'http://hot.vrs.sohu.com/vrs_flash.action?vid='
+                base_data_url = 'http://hot.vrs.sohu.com/vrs_flash.action?vid='
-                                            webpage, u'video title')
+                                            webpage, 'video title')
-                                      u'video path')
+                                      'video path')
-        #'md5': u'7b8c22b5e7098a3e1c09709df1126d2d',
+            'id': '66418',
-        video_extension = 'mp4'
+        video_id = self._match_id(url)
-
+            r'<source src="(.+?)" type="video/mp4">', webpage, 'video URL')
-
+            webpage, 'title')
-            'ext': video_extension,
+            'ext': 'mp4',
-import json
+from __future__ import unicode_literals
-from ..utils import (
+from ..compat import (
-    IE_NAME = u'muzu.tv'
+    IE_NAME = 'muzu.tv'
-            u'uploader': u'MarcAshken featuring SOS',
+        'url': 'http://www.muzu.tv/defected/marcashken-featuring-sos-cat-walk-original-mix-music-video/1981454/',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        info = json.loads(video_info_page)
+        info_data = compat_urllib_parse.urlencode({
-        video_info = json.loads(player_info_page)['videos'][0]
+        player_info = self._download_json(
-        video_url_info = json.loads(video_url_page)
+        data = compat_urllib_parse.urlencode({
-                }
+        return {
-from ..utils import (
+from ..compat import (
-        'file': '1435540.mp3',
+            'id': '1435540',
-        webpage_src = self._download_webpage(url, video_id)
+        video_id = self._match_id(url)
-            r'data-path="(.*?)"', webpage_src, u'video URL', fatal=False)
+            r'data-path="(.*?)"', webpage, 'video URL', default=None)
-                r'"contentUrl" content="(.*?)"', webpage_src, u'video URL')
+                r'"contentUrl" content="(.*?)"', webpage, 'content URL')
-        video_title = self._og_search_title(webpage_src).strip()
+        video_title = self._og_search_title(webpage).strip()
-            'thumbnail': self._og_search_thumbnail(webpage_src),
+            'thumbnail': self._og_search_thumbnail(webpage),
-        self.to_screen(u'%s: Available subtitles for video: %s' %
+        self.to_screen('%s: Available subtitles for video: %s' %
-        self.to_screen(u'%s: Available automatic captions for video: %s' %
+        self.to_screen('%s: Available automatic captions for video: %s' %
-                    self._downloader.report_warning(u'no closed captions found in the specified language "%s"' % sub_lang)
+                    self._downloader.report_warning('no closed captions found in the specified language "%s"' % sub_lang)
-            self._downloader.report_warning(u'unable to download video subtitles for %s: %s' % (sub_lang, compat_str(err)))
+            self._downloader.report_warning('unable to download video subtitles for %s: %s' % (sub_lang, compat_str(err)))
-            self._downloader.report_warning(u'Did not fetch video subtitles')
+            self._downloader.report_warning('Did not fetch video subtitles')
-        self._downloader.report_warning(u'Automatic Captions not supported by this server')
+        self._downloader.report_warning('Automatic Captions not supported by this server')
-            timestamp = args[u'timestamp']
+            args = player_config['args']
-            s = '<html>' + s + u'</html>'
+            s = '<html>%s</html>' % s
-        video_id = m.group('id')
+        video_id = self._match_id(url)
-                req, video_id, note=u'Testing video URL %d' % i, errnote=False)
+                req, video_id, note='Testing video URL %d' % i, errnote=False)
-            raise ExtractorError(u'No working video URLs found')
+            raise ExtractorError('No working video URLs found')
-        title = self._search_regex(r'\s+title:\s*"([^"]+)"', webpage, u'title')
+        title = self._search_regex(r'\s+title:\s*"([^"]+)"', webpage, 'title')
-            r'\s+image:\s*"([^"]+)"', webpage, u'thumbnail', fatal=False)
+            r'\s+image:\s*"([^"]+)"', webpage, 'thumbnail', fatal=False)
-    _VALID_URL = r'^http://(?:\w+\.)?add-anime\.net/watch_video\.php\?(?:.*?)v=(?P<video_id>[\w_]+)(?:.*)'
+    _VALID_URL = r'^http://(?:\w+\.)?add-anime\.net/watch_video\.php\?(?:.*?)v=(?P<id>[\w_]+)(?:.*)'
-                raise ExtractorError(u'Cannot find redirect math task')
+                raise ExtractorError('Cannot find redirect math task')
-    from sys import version_info
+
-        playlist_id = m.group('id')
+        playlist_id = self._match_id(url)
-            r'<h1 class="playlist-name"[^>]*?>(.*?)</h1>', webpage, u'title')
+            r'<h1 class="playlist-name"[^>]*?>(.*?)</h1>', webpage, 'title')
-            webpage, u'description', fatal=False)
+            webpage, 'description', fatal=False)
-        args = ['mplayer', '-really-quiet', '-vo', 'null', '-vc', 'dummy', '-dumpstream', '-dumpfile', tmpfilename, url]
+        args = [
-            subprocess.call(['mplayer', '-h'], stdout=(open(os.path.devnull, 'w')), stderr=subprocess.STDOUT)
+            subprocess.call(
-            self.report_error(u'MMS or RTSP download detected but "%s" could not be run' % args[0])
+            self.report_error('MMS or RTSP download detected but "%s" could not be run' % args[0])
-            self.to_screen(u'\r[%s] %s bytes' % (args[0], fsize))
+            self.to_screen('\r[%s] %s bytes' % (args[0], fsize))
-            self.report_error(u'mplayer exited with code %d' % retval)
+            self.to_stderr('\n')
-            self.report_error(u'giving up after %s retries' % retries)
+            self.report_error('giving up after %s retries' % retries)
-                self.to_screen(u'\r[download] File is smaller than min-filesize (%s bytes < %s bytes). Aborting.' % (data_len, min_data_len))
+                self.to_screen('\r[download] File is smaller than min-filesize (%s bytes < %s bytes). Aborting.' % (data_len, min_data_len))
-                self.to_screen(u'\r[download] File is larger than max-filesize (%s bytes > %s bytes). Aborting.' % (data_len, max_data_len))
+                self.to_screen('\r[download] File is larger than max-filesize (%s bytes > %s bytes). Aborting.' % (data_len, max_data_len))
-                    self.report_error(u'unable to open for writing: %s' % str(err))
+                    self.report_error('unable to open for writing: %s' % str(err))
-                self.report_error(u'unable to write data: %s' % str(err))
+                self.to_stderr('\n')
-            self.report_error(u'Did not get any data blocks')
+            self.to_stderr('\n')
-        if tmpfilename != u'-':
+        if tmpfilename != '-':
-            self.report_error(u'm3u8 download detected but ffmpeg or avconv could not be found. Please install one.')
+            self.report_error('m3u8 download detected but ffmpeg or avconv could not be found. Please install one.')
-            self.to_screen(u'\r[%s] %s bytes' % (cmd[0], fsize))
+            self.to_screen('\r[%s] %s bytes' % (cmd[0], fsize))
-            self.report_error(u'%s exited with code %d' % (program, retval))
+            self.to_stderr('\n')
-from .utils import (
+from .compat import (
-    assert(type(message) == type(b('')))
+    assert isinstance(message, bytes)
-    if signature[0:2] != b('\x00\x01'):
+    signature = (block_size - len(raw_bytes)) * b'\x00' + b''.join(raw_bytes)
-    if not b('\x00') in signature:
+    if b'\x00' not in signature:
-    if not signature.startswith(b('\x30\x31\x30\x0D\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01\x05\x00\x04\x20')):
+    signature = signature[signature.index(b'\x00') + 1:]
-        to_screen(u'It looks like you installed youtube-dl with a package manager, pip, setup.py or a tarball. Please use that to update.')
+        to_screen('It looks like you installed youtube-dl with a package manager, pip, setup.py or a tarball. Please use that to update.')
-        to_screen(u'ERROR: can\'t find the current version. Please try again later.')
+        to_screen('ERROR: can\'t find the current version. Please try again later.')
-        to_screen(u'youtube-dl is up-to-date (' + __version__ + ')')
+        to_screen('youtube-dl is up-to-date (' + __version__ + ')')
-        to_screen(u'ERROR: can\'t obtain versions info. Please try again later.')
+        to_screen('ERROR: can\'t obtain versions info. Please try again later.')
-        to_screen(u'ERROR: the versions file is not signed or corrupted. Aborting.')
+        to_screen('ERROR: the versions file is not signed or corrupted. Aborting.')
-        to_screen(u'ERROR: the versions file signature is invalid. Aborting.')
+        to_screen('ERROR: the versions file signature is invalid. Aborting.')
-        to_screen(u'youtube-dl is up to date (%s)' % __version__)
+        to_screen('youtube-dl is up to date (%s)' % __version__)
-    to_screen(u'Updating to version ' + version_id + ' ...')
+    to_screen('Updating to version ' + version_id + ' ...')
-            filename += u'.exe'
+        if os.path.isfile(filename + '.exe'):
-        to_screen(u'ERROR: no write permissions on %s' % filename)
+        to_screen('ERROR: no write permissions on %s' % filename)
-            to_screen(u'ERROR: no write permissions on %s' % directory)
+            to_screen('ERROR: no write permissions on %s' % directory)
-            to_screen(u'ERROR: unable to download latest version')
+            to_screen('ERROR: unable to download latest version')
-            to_screen(u'ERROR: the downloaded file hash does not match. Aborting.')
+            to_screen('ERROR: the downloaded file hash does not match. Aborting.')
-            to_screen(u'ERROR: unable to write the new version')
+            to_screen('ERROR: unable to write the new version')
-                batfile.write(u"""
+                batfile.write('''
-                \n""" % (exe, exe, version_id))
+                \n''' % (exe, exe, version_id))
-            to_screen(u'ERROR: unable to overwrite current version')
+            to_screen('ERROR: unable to overwrite current version')
-            to_screen(u'ERROR: unable to download latest version')
+            to_screen('ERROR: unable to download latest version')
-            to_screen(u'ERROR: the downloaded file hash does not match. Aborting.')
+            to_screen('ERROR: the downloaded file hash does not match. Aborting.')
-            to_screen(u'ERROR: unable to overwrite current version')
+            to_screen('ERROR: unable to overwrite current version')
-    to_screen(u'Updated youtube-dl. Restart youtube-dl to use the new version.')
+    to_screen('Updated youtube-dl. Restart youtube-dl to use the new version.')
-        to_screen(u'PLEASE NOTE:')
+        to_screen('PLEASE NOTE:')
-        expr = xpath + u"[@%s='%s']" % (key, val)
+        expr = xpath + "[@%s='%s']" % (key, val)
-        assert type(s) == type(u'')
+        assert isinstance(s, compat_str)
-                       download the video, not the playlist.
+    no_playlist:       If the URL contains both a playlist and a video ID,
-        help='download only the currently playing video')
+        help='If the URL refers to a video and a playlist, download only the video.')
-__version__ = '2014.11.25.1'
+__version__ = '2014.11.26'
-    def _webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True):
+    def _webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None):
-            webpage = self._download_webpage(url, video_id)
+        if not full_response:
-__version__ = '2014.11.25'
+__version__ = '2014.11.25.1'
-__version__ = '2014.11.24'
+__version__ = '2014.11.25'
-from ..utils import int_or_none
+from ..compat import (
-        # TODO more code goes here, for example ...
+
-            r'minus_track.artist="(.+?)"', webpage, 'artist')
+            r'minus_track\.artist="(.+?)"', webpage, 'artist')
-            r'minus_track.title="(.+?)"', webpage, 'title')
+            r'minus_track\.title="(.+?)"', webpage, 'title')
-            r'minus_track.dur_sec=\'([0-9]+?)\'', webpage, 'duration'))
+            r'minus_track\.dur_sec=\'([0-9]*?)\'',
-        url = 'http://x-minus.org/dwlf/{}/{}.mp3'.format(video_id, token)
+        token = ''.join(
-            'url': url,
+            'url': video_url,
-        return token
+def parse_filesize(s):
-            'thumbnail': thumbnail_url,
+            'url': self._html_search_meta('VideoURL', webpage, fatal=True),
-__version__ = '2014.11.23.1'
+__version__ = '2014.11.24'
-
+
-		}
+    IE_DESC = 'Bundeszentrale fÃ¼r politische Bildung'
-        if ie.working() == False:
+        if not ie.working():
-    if opts.allsubtitles and (opts.writeautomaticsub == False):
+    if opts.allsubtitles and not opts.writeautomaticsub:
-        for _ in range(3 if key_size_bytes == 32  else 2 if key_size_bytes == 24 else 0):
+        for _ in range(3 if key_size_bytes == 32 else 2 if key_size_bytes == 24 else 0):
-                ).format(user=user, count=self._STEP, last=last_id)
+            req_url = (
-                }
+        common = {
-                                              video_id, note='Downloading subtitles for ' + sub_name)
+            sub_page = self._download_webpage(
-            }
+        }
-                }
+            b'Content-Type': b'application/x-www-form-urlencoded',
-            } for format in sources]
+        } for format in sources]
-                    ) % (url, url), expected=True)
+                    '%r is not a valid URL. '
-                    ' natural beauty take our breath away.',
+                'description': (
-         }
+        }
-          b'TnpsbA0KTVRkbU1tSTRNdz09'
+            b'WXpnME1EZGhNRGhpTTJNM01XVmhOREU0WldNNVpHTTJOakpt'
-                for t in data['tracks']]
+            for t in data['tracks']]
-            'description': 'Vier Amische und eine Mennonitin wagen in New York'
+            'description': (
-                ' ihrem spannenden Weg.',
+                ' ihrem spannenden Weg.'),
-    def _url_for_id(self, id, quality = None):
+    def _url_for_id(self, id, quality=None):
-        help='video format code, specify the order of preference using'
+        help=(
-            ' avconv), for example -f bestvideo+bestaudio.')
+            ' avconv), for example -f bestvideo+bestaudio.'))
-                       )
+            re.sub('[/<>:"\\|\\\\?\\*]', '#', path_part)
-                'Video %s has been removed from public access due to rightholder complaint.',
+            'Video %s has been removed from public access due to rightholder complaint.',
-                'Video %s does not exist.'
+            'Video %s is only available for registered users, '
-from ..utils import (
+from ..compat import (
-                                          name)
+                return self._search_regex(
-                                                    u'context'))
+            context = json.loads(self._search_regex(
-        self.report_extraction(id)
+        'md5': 'ead7ae13693b3205cbc89536a077daed',
-            'title': u'Xa MÃ£i Xa',
+            'title': 'Xa MÃ£i Xa',
-        webpage = self._download_webpage('http://mp3.zing.vn/bai-hat/%s/%s.html' % (slug, song_id), song_id)
+        webpage = self._download_webpage(
-        player_xml_url = self._search_regex(r'&amp;xmlURL=(?P<xml_url>[^&]+)&', webpage, 'player xml url')
+        player_xml_url = self._search_regex(
-            'title': u'LÃ¢u ÄÃ i TÃ¬nh Ãi - Báº±ng Kiá»u ft. Minh Tuyáº¿t | Album 320 lossless',
+            'title': 'LÃ¢u ÄÃ i TÃ¬nh Ãi - Báº±ng Kiá»u ft. Minh Tuyáº¿t | Album 320 lossless',
-        player_xml_url = self._search_regex(r'&amp;xmlURL=(?P<xml_url>[^&]+)&', webpage, 'player xml url')
+        webpage = self._download_webpage(
-        return self._extract_player_xml(player_xml_url, album_id, playlist_title=self._og_search_title(webpage))
+        return self._extract_player_xml(
-        #args = [argv_raw[i].value for i in range(argc)]
+        # args = [argv_raw[i].value for i in range(argc)]
-            help_msg = shell_quote([option.help])
+            shell_quote([option.help])
-                'Expected type %r for field %s, but got value %r of type %r' % (expected, info_field, got, type(got)))
+                            'Expected type %r for field %s, but got value %r of type %r' % (expected, info_field, got, type(got)))
-                'invalid value for field %s, expected %r, got %r' % (info_field, expected, got))
+                             'invalid value for field %s, expected %r, got %r' % (info_field, expected, got))
-        if value and key in ('title', 'description', 'uploader', 'upload_date', 'timestamp', 'uploader_id', 'location'))
+                          for key, value in got_dict.items()
-                       for _ in range(line_count))
+                      for _ in range(line_count))
-                self.add_extra_info(r,
+                self.add_extra_info(
-                    })
+                    }
-                            self.select_format(format_2, formats))
+                                        self.select_format(format_2, formats))
-                                    '"-f %s+%s"' % (format_2, format_1))
+                                                  'contain the video, try using '
-                            (info_dict['extractor'], info_dict['id'], thumb_filename))
+                                       (info_dict['extractor'], info_dict['id'], thumb_filename))
-                            (info_dict['thumbnail'], compat_str(err)))
+                                            (info_dict['thumbnail'], compat_str(err)))
-                                ' The formats won\'t be merged')
+                                                'formats but ffmpeg or avconv are not installed.'
-                encoding='utf-8', errors='replace'):
+                   encoding='utf-8', errors='replace'):
-                encoding='utf-8', errors='replace'):
+                        encoding='utf-8', errors='replace'):
-                        encoding=encoding, errors=errors)
+                           encoding=encoding, errors=errors)
-        http_dl = HttpQuietDownloader(self.ydl,
+        http_dl = HttpQuietDownloader(
-            })
+            }
-                (total_frags - state['frag_counter']) * frag_total_bytes)
+                              (total_frags - state['frag_counter']) * frag_total_bytes)
-                    frag_total_bytes)
+                                                  frag_total_bytes)
-                status.get('speed'), eta)
+                                 status.get('speed'), eta)
-                on_click, 'trailer info')
+                                                   on_click, 'trailer info')
-            '&api_key=%s&vid=%s' % (self._API_KEY, video_id))
+                    '&api_key=%s&vid=%s' % (self._API_KEY, video_id))
-                '&method=broadcast&format=json&vid_older_than={last}'
+                       '&sort=created&access_mode=0%2C1%2C2&limit={count}'
-                expected=True)
+                                 expected=True)
-            'Downloading playlist XML')
+                                      'Downloading playlist XML')
-    {
+    }, {
-            'duration': 187,
+    _TESTS = [
-                'please report this issue on http://yt-dl.org/bug' % _name)
+                                            'please report this issue on http://yt-dl.org/bug' % _name)
-            'twitter card player')
+                                      'twitter card player')
-            'video info', flags=re.MULTILINE)
+                                  'video info', flags=re.MULTILINE)
-                   for video_id in orderedSet(video_ids)]
+                for video_id in orderedSet(video_ids)]
-        r'ligthboxvideo/base-de-medias/webtv/(.*)')
+                  r'ligthboxvideo/base-de-medias/webtv/(.*)')
-            + video_id)
+                    + video_id)
-                                                  'Downloading JSON config')
+                                      'Downloading JSON config')
-                ' back.'),
+                            ' each other -- to the point of confusing Jamie\'s dog -- and '
-            webpage, 'video list', flags=re.DOTALL)
+                                             webpage, 'video list', flags=re.DOTALL)
-    },
+    _TESTS = [
-            webpage, 'video URL')
+                                       webpage, 'video URL')
-            errnote='Unable to download login page')
+                                            note='Downloading login page',
-                note='Logging in', errnote='unable to fetch login page')
+                                                   note='Logging in', errnote='unable to fetch login page')
-                note='Confirming login')
+                                                    note='Confirming login')
-            webpage, 'like count', fatal=False)
+                                             webpage, 'like count', fatal=False)
-            webpage, 'dislike count', fatal=False)
+                                                webpage, 'dislike count', fatal=False)
-            'Downloading embed page')
+                                            'Downloading embed page')
-            episode)
+                                               episode)
-            'playlist', flags=re.DOTALL)
+                                      'playlist', flags=re.DOTALL)
-            first_xml, 'node_id')
+                                          first_xml, 'node_id')
-                fatal=False)
+                                             fatal=False)
-            ie='Dailymotion')
+                               ie='Dailymotion')
-             re.search(r'OO.Player.create\([\'"].*?[\'"],\s*[\'"](?P<ec>.{32})[\'"]', webpage))
+                re.search(r'OO.Player.create\([\'"].*?[\'"],\s*[\'"](?P<ec>.{32})[\'"]', webpage))
-            webpage, 'video URL')
+                                       webpage, 'video URL')
-            webpage, 'description', fatal=False)
+                                                    webpage, 'description', fatal=False)
-            webpage, 'video description', flags=re.DOTALL)
+                                              webpage, 'video description', flags=re.DOTALL)
-            webpage, 'uploader id', fatal=False)
+                                         webpage, 'uploader id', fatal=False)
-            fatal=False)
+                                  fatal=False)
-            'Downloading flash configuration')
+                                                'Downloading flash configuration')
-            file_url)
+                          lambda m: self._clean_query(m.group()),
-            'Downloading video info')
+                                  'Downloading video info')
-                'jwplayer': 'http://developer.longtailvideo.com/trac/wiki/FlashFormats'})
+            return xpath_with_ns(
-                iframe_html, 'video url')
+                                           iframe_html, 'video url')
-            html, 'title')
+                                        html, 'title')
-            html, 'artist')
+                                         html, 'artist')
-                'life and mind of one of sports most elite athletes: Josh Grant.',
+            'description': (
-            'Downloading video JSON')
+                                      'Downloading video JSON')
-            'Downloading video RSS')
+                                 'Downloading video RSS')
-                webpage, 'uploader nickname', fatal=False)
+            r'submitter=(.*?);|googletag\.pubads\(\)\.setTargeting\("(?:channel|submiter)","([^"]+)"\);',
-            video_id, 'Downloading info xml', transform_source=fix_xml_ampersands)
+                                  video_id, 'Downloading info xml', transform_source=fix_xml_ampersands)
-            webpage, 'description', flags=re.DOTALL)
+                                              webpage, 'description', flags=re.DOTALL)
-            'Downloading mobile page')
+                                         'Downloading mobile page')
-                    'country, trying with the mobile version')
+                               'country, trying with the mobile version')
-                expected=True)
+                                 expected=True)
-            'Downloading video urls')
+                                          'Downloading video urls')
-                'scheme', 'urn:mtvn:id')
+                                       'scheme', 'urn:mtvn:id')
-            'context4/context5/config.xml'.format(site_id))
+                      'context4/context5/config.xml'.format(site_id))
-                    name)
+                                          name)
-                u'context'))
+                                                    u'context'))
-                webpage, 'title')
+                                                  webpage, 'title')
-            webpage, 'title')
+                                              webpage, 'title')
-            webpage)
+                         webpage)
-            page, 'director id', fatal=False)
+                                              page, 'director id', fatal=False)
-            page, 'director name', fatal=False)
+                                           page, 'director name', fatal=False)
-            compat_urllib_parse.urlencode({'getConfig': 'true'}).encode('ascii'))
+                                                compat_urllib_parse.urlencode({'getConfig': 'true'}).encode('ascii'))
-                playlist_title)
+                                              playlist_title)
-                expected=True)
+                                 expected=True)
-            webpage, 'entries')
+                                          webpage, 'entries')
-                entry['item_data']['video_id']),
+                    entry['item_data']['video_id']),
-    {
+    }, {
-            webpage, 'uploader')
+                                                 webpage, 'uploader')
-            webpage, 'date')
+                                                  webpage, 'date')
-            ie=cls.ie_key())
+                              ie=cls.ie_key())
-            webpage, 'info json')
+                                       webpage, 'info json')
-            webpage, 'json data', flags=re.MULTILINE)
+                                       webpage, 'json data', flags=re.MULTILINE)
-    {
+    }, {
-                r'class="tabSeperator">></span><span class="tabText">(.*?)<'],
+                 r'class="tabSeperator">></span><span class="tabText">(.*?)<'],
-            video_id, 'Downloading video url')
+                                     video_id, 'Downloading video url')
-            webpage, 'title').strip()
+                                              webpage, 'title').strip()
-                    'use --username and --password options to provide account credentials.', expected=True)
+                                     'use --username and --password options to provide account credentials.', expected=True)
-            'client_id={1}&secret_token={2}'.format(track_id, self._IPHONE_CLIENT_ID, secret_token))
+                       'client_id={1}&secret_token={2}'.format(track_id, self._IPHONE_CLIENT_ID, secret_token))
-                errnote='Unable to download course info page')
+                                              errnote='Unable to download course info page')
-            'description': 'Mary Kay is perhaps the most trusted name in female beauty, so of course Conan is a natural choice to sell their products.'
+        {
-                'actively fooling us.'),
+                            'argument that not only don\'t we understand our own '
-            webpage, 'info json')
+                                       webpage, 'info json')
-            'Downloading playlist webpage')
+                                         'Downloading playlist webpage')
-            'Downloading embed player page')
+                                            'Downloading embed player page')
-                'format=smil&mbr=true'.format(video_id))
+                        'format=smil&mbr=true'.format(video_id))
-            '\s+fo\.addVariable\("s",\s"(?P<serverid>\d+)"\);', webpage)
+                         '\s+fo\.addVariable\("s",\s"(?P<serverid>\d+)"\);', webpage)
-                webpage, 'video title').replace(' - Trailer Addict', '')
+                                   webpage, 'video title').replace(' - Trailer Addict', '')
-                info_webpage, 'Download url').replace('%3F', '?')
+                                       info_webpage, 'Download url').replace('%3F', '?')
-                info_webpage, 'thumbnail url')
+                                           info_webpage, 'thumbnail url')
-            iframe, 'video url')
+                                       iframe, 'video url')
-            course_id, 'Downloading course curriculum')
+                                       course_id, 'Downloading course curriculum')
-            webpage, 'title')
+                                              webpage, 'title')
-            webpage, 'uploader', fatal=False, flags=re.DOTALL)
+                                           webpage, 'uploader', fatal=False, flags=re.DOTALL)
-            webpage, 'thumbnail', fatal=False)
+                                            webpage, 'thumbnail', fatal=False)
-            redirect_page, 'redirect location')
+                                          redirect_page, 'redirect location')
-            'Downloading redirect page')
+                                         'Downloading redirect page')
-            webpage, 'title').split('/')[0].strip()
+                                        webpage, 'title').split('/')[0].strip()
-            webpage, 'uploader')
+                                              webpage, 'uploader')
-            webpage, 'thumbnail')
+                                       webpage, 'thumbnail')
-            webpage, 'description', flags=re.DOTALL)
+                                              webpage, 'description', flags=re.DOTALL)
-                'Downloading video page')
+                                          'Downloading video page')
-                                            video_id)
+                                    video_id)
-            for key in ['on', 'av', 'off']] if node is not None)
+                                          for key in ['on', 'av', 'off']] if node is not None)
-                    flags=re.DOTALL)
+                                            flags=re.DOTALL)
-            compat_urllib_parse.urlencode(login_form).encode('utf-8'))
+                                                compat_urllib_parse.urlencode(login_form).encode('utf-8'))
-            x = mobj.group(1) + ' ' + mobj.group(2)
+            mobj.group(1) + ' ' + mobj.group(2)
-            player_url)
+                          player_url)
-            webpage, 'upload date', fatal=False)
+                                              webpage, 'upload date', fatal=False)
-            webpage, 'uploader id', default='anonymous')
+                                              webpage, 'uploader id', default='anonymous')
-            webpage, 'duration', fatal=False))
+                                                          webpage, 'duration', fatal=False))
-            webpage, 'video URL')
+                                       webpage, 'video URL')
-            webpage, 'title')
+                                              webpage, 'title')
-            webpage, 'thumbnail', fatal=False)
+                                             webpage, 'thumbnail', fatal=False)
-                note='Downloading results page ' + str(pagenum + 1))
+                                       note='Downloading results page ' + str(pagenum + 1))
-                expected=True)
+                                 expected=True)
-            webpage, 'download list').strip()
+                                                webpage, 'download list').strip()
-                            (format_id, parts_sizes, player_desc))
+                                       (format_id, parts_sizes, player_desc))
-        ' (Example: "yttoplist:music:Top Tracks")')
+               ' (Example: "yttoplist:music:Top Tracks")')
-    signature = signature[signature.index(b('\x00')) +1:]
+    signature = signature[signature.index(b('\x00')) + 1:]
-        block += [0] *(BLOCK_SIZE_BYTES - len(block))
+        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]
-        block += [0] *(BLOCK_SIZE_BYTES - len(block))
+        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]
-        data += xor(temp, data[-key_size_bytes: 4 -key_size_bytes])
+        data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])
-            data += xor(temp, data[-key_size_bytes: 4 -key_size_bytes])
+            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])
-            data += xor(temp, data[-key_size_bytes: 4 -key_size_bytes])
+            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])
-            data += xor(temp, data[-key_size_bytes: 4 -key_size_bytes])
+            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])
-    for i in range(1, rounds +1):
+    for i in range(1, rounds + 1):
-        data = xor(data, expanded_key[i *BLOCK_SIZE_BYTES: (i +1) *BLOCK_SIZE_BYTES])
+        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])
-        data = xor(data, expanded_key[i *BLOCK_SIZE_BYTES: (i +1) *BLOCK_SIZE_BYTES])
+        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])
-    key = password[:key_size_bytes] + [0] *(key_size_bytes - len(password))
+    key = password[:key_size_bytes] + [0] * (key_size_bytes - len(password))
-        __value = nonce + [0] *(BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)
+        __value = nonce + [0] * (BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)
-    return [x^y for x, y in zip(data1, data2)]
+    return [x ^ y for x, y in zip(data1, data2)]
-        column = data[i *4: (i +1) *4]
+        column = data[i * 4: (i + 1) * 4]
-    for i in range(len(data) -1, -1, -1):
+    for i in range(len(data) - 1, -1, -1):
-        return real_size, box_type, self.read(real_size -header_end)
+        return real_size, box_type, self.read(real_size - header_end)
-    for (i, frag_number) in zip(range(1, n_frags +1), itertools.count(first_frag_number)):
+    for (i, frag_number) in zip(range(1, n_frags + 1), itertools.count(first_frag_number)):
-                    downloaded_data_len = int(float(mobj.group(1)) *1024)
+                    downloaded_data_len = int(float(mobj.group(1)) * 1024)
-                    speed = self.calc_speed(start, time.time(), downloaded_data_len -resume_downloaded_data_len)
+                    eta = self.calc_eta(start, time.time(), 100 - resume_percent, percent - resume_percent)
-                        downloaded_data_len = int(float(mobj.group(1)) *1024)
+                        downloaded_data_len = int(float(mobj.group(1)) * 1024)
-                        self.to_screen('[rtmpdump] ' +line)
+                        self.to_screen('[rtmpdump] ' + line)
-            baseurl = vidurl[:vidurl.rfind('/') +1]
+            baseurl = vidurl[:vidurl.rfind('/') + 1]
-            video_format = fmt +'p'
+            video_format = fmt + 'p'
-            streamdata_req.data = 'req=RpcApiVideoEncode%5FGetStreamInfo&video%5Fencode%5Fquality=' +stream_quality +'&media%5Fid=' +stream_id +'&video%5Fformat=' +stream_format
+            streamdata_req.data = 'req=RpcApiVideoEncode%5FGetStreamInfo&video%5Fencode%5Fquality=' + stream_quality + '&media%5Fid=' + stream_id + '&video%5Fformat=' + stream_format
-                                              video_id, note='Downloading subtitles for ' +sub_name)
+            sub_page = self._download_webpage('http://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml&subtitle_script_id=' + sub_id,\
-        date = time.gmtime(info['dateCreated'] /1000)  # The timestamp is in miliseconds
+        date = time.gmtime(info['dateCreated'] / 1000)  # The timestamp is in miliseconds
-            return self.url_result('http://blip.tv/a/a-' +mobj.group(1), 'BlipTV')
+            return self.url_result('http://blip.tv/a/a-' + mobj.group(1), 'BlipTV')
-            (floor(random() *1073741824), floor(random() *1073741824))
+            (floor(random() * 1073741824), floor(random() * 1073741824))
-            return [make_entry(video_id, media, video_number +1) for video_number, media in enumerate(videos)]
+            return [make_entry(video_id, media, video_number + 1) for video_number, media in enumerate(videos)]
-            webpage, 'view count', fatal=False, flags=re.MULTILINE|re.DOTALL)
+            webpage, 'view count', fatal=False, flags=re.MULTILINE | re.DOTALL)
-                note=u'Downloading part %d of %d' % (i +1, part_count))
+                note=u'Downloading part %d of %d' % (i + 1, part_count))
-                    'format_note': ['144p', '288p', '544p', '720p'][quality -1],
+                    'format_note': ['144p', '288p', '544p', '720p'][quality - 1],
-            'duration': info['duration'] //1000,
+            'duration': info['duration'] // 1000,
-        info_url = "http://v2.tudou.com/f?id=" +str(id)
+        info_url = "http://v2.tudou.com/f?id=" + str(id)
-            r'<strong>%s\'s Videos \(([0-9]+)\)</strong>' %username, profile_page,
+            r'<strong>%s\'s Videos \(([0-9]+)\)</strong>' % username, profile_page,
-                note='Downloading results page ' +str(pagenum +1))
+                note='Downloading results page ' + str(pagenum + 1))
-        self._downloader.to_screen(u'[' +'ffmpeg' +'] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)
+        self._downloader.to_screen(u'[' + 'ffmpeg' + '] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)
-            opts.extend(['-map', '%d:0' % (i +1), '-c:s:%d' % i, 'mov_text'])
+            opts.extend(['-map', '%d:0' % (i + 1), '-c:s:%d' % i, 'mov_text'])
-    signature = signature[signature.index(b('\x00')) +1:]
+    signature = signature[signature.index(b('\x00')) + 1:]
-    signature = signature[signature.index(b('\x00'))+1:]
+    signature = signature[signature.index(b('\x00')) +1:]
-                parser.error('wrong header formatting, it should be key:value, not "%s"'%h)
+                parser.error('wrong header formatting, it should be key:value, not "%s"' % h)
-                write_string('[debug] Adding header from command line option %s:%s\n'%(key, value))
+                write_string('[debug] Adding header from command line option %s:%s\n' % (key, value))
-            or DEFAULT_OUTTMPL)
+               or (opts.format == '-1' and opts.usetitle and '%(title)s-%(id)s-%(format)s.%(ext)s')
-        block += [0]*(BLOCK_SIZE_BYTES - len(block))
+        block = data[i *BLOCK_SIZE_BYTES: (i +1) *BLOCK_SIZE_BYTES]
-        block += [0]*(BLOCK_SIZE_BYTES - len(block))
+        block = data[i *BLOCK_SIZE_BYTES: (i +1) *BLOCK_SIZE_BYTES]
-        data += xor(temp, data[-key_size_bytes: 4-key_size_bytes])
+        data += xor(temp, data[-key_size_bytes: 4 -key_size_bytes])
-            data += xor(temp, data[-key_size_bytes: 4-key_size_bytes])
+            data += xor(temp, data[-key_size_bytes: 4 -key_size_bytes])
-            data += xor(temp, data[-key_size_bytes: 4-key_size_bytes])
+            data += xor(temp, data[-key_size_bytes: 4 -key_size_bytes])
-            data += xor(temp, data[-key_size_bytes: 4-key_size_bytes])
+            data += xor(temp, data[-key_size_bytes: 4 -key_size_bytes])
-    for i in range(1, rounds+1):
+    for i in range(1, rounds +1):
-        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES: (i+1)*BLOCK_SIZE_BYTES])
+        data = xor(data, expanded_key[i *BLOCK_SIZE_BYTES: (i +1) *BLOCK_SIZE_BYTES])
-        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES: (i+1)*BLOCK_SIZE_BYTES])
+        data = xor(data, expanded_key[i *BLOCK_SIZE_BYTES: (i +1) *BLOCK_SIZE_BYTES])
-    key = password[:key_size_bytes] + [0]*(key_size_bytes - len(password))
+    key = password[:key_size_bytes] + [0] *(key_size_bytes - len(password))
-        __value = nonce + [0]*(BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)
+        __value = nonce + [0] *(BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)
-        column = data[i*4: (i+1)*4]
+        column = data[i *4: (i +1) *4]
-    for i in range(len(data)-1, -1, -1):
+    for i in range(len(data) -1, -1, -1):
-        return real_size, box_type, self.read(real_size-header_end)
+        return real_size, box_type, self.read(real_size -header_end)
-    for (i, frag_number) in zip(range(1, n_frags+1), itertools.count(first_frag_number)):
+    for (i, frag_number) in zip(range(1, n_frags +1), itertools.count(first_frag_number)):
-                    downloaded_data_len = int(float(mobj.group(1))*1024)
+                    downloaded_data_len = int(float(mobj.group(1)) *1024)
-                    speed = self.calc_speed(start, time.time(), downloaded_data_len-resume_downloaded_data_len)
+                    eta = self.calc_eta(start, time.time(), 100 -resume_percent, percent -resume_percent)
-                        downloaded_data_len = int(float(mobj.group(1))*1024)
+                        downloaded_data_len = int(float(mobj.group(1)) *1024)
-                        self.to_screen('[rtmpdump] '+line)
+                        self.to_screen('[rtmpdump] ' +line)
-    return globals()[ie_name+'IE']
+    return globals()[ie_name + 'IE']
-                'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/%s'  % programme_id,
+                'http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/%s' % programme_id,
-            baseurl = vidurl[:vidurl.rfind('/')+1]
+            baseurl = vidurl[:vidurl.rfind('/') +1]
-            video_format = fmt+'p'
+            video_format = fmt +'p'
-            streamdata_req.data = 'req=RpcApiVideoEncode%5FGetStreamInfo&video%5Fencode%5Fquality='+stream_quality+'&media%5Fid='+stream_id+'&video%5Fformat='+stream_format
+            streamdata_req.data = 'req=RpcApiVideoEncode%5FGetStreamInfo&video%5Fencode%5Fquality=' +stream_quality +'&media%5Fid=' +stream_id +'&video%5Fformat=' +stream_format
-                                              video_id, note='Downloading subtitles for '+sub_name)
+            sub_page = self._download_webpage('http://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml&subtitle_script_id=' +sub_id,\
-            'title':       video_title,
+            'id': video_id,
-            'uploader':    video_uploader,
+            'thumbnail': video_thumbnail,
-            'formats':     formats,
+            'subtitles': subtitles,
-        date = time.gmtime(info['dateCreated']/1000)  # The timestamp is in miliseconds
+        date = time.gmtime(info['dateCreated'] /1000)  # The timestamp is in miliseconds
-            return self.url_result('http://blip.tv/a/a-'+mobj.group(1), 'BlipTV')
+            return self.url_result('http://blip.tv/a/a-' +mobj.group(1), 'BlipTV')
-            (floor(random()*1073741824), floor(random()*1073741824))
+            (floor(random() *1073741824), floor(random() *1073741824))
-            return [make_entry(video_id, media, video_number+1) for video_number, media in enumerate(videos)]
+            return [make_entry(video_id, media, video_number +1) for video_number, media in enumerate(videos)]
-    {
+    }, {
-    {
+    }, {
-            'url':  'http://metacafe.com/watch/yt-_aUehQsCQtM/the_electric_company_short_i_pbs_kids_go/',
+            'url': 'http://metacafe.com/watch/yt-_aUehQsCQtM/the_electric_company_short_i_pbs_kids_go/',
-                vevo_id = m_vevo.group(1);
+                vevo_id = m_vevo.group(1)
-                note=u'Downloading part %d of %d' % (i+1, part_count))
+                note=u'Downloading part %d of %d' % (i +1, part_count))
-            slug_title =  mobj.group('title')
+            slug_title = mobj.group('title')
-                    'format_note': ['144p', '288p', '544p', '720p'][quality-1],
+                    'format_note': ['144p', '288p', '544p', '720p'][quality -1],
-            'duration': info['duration']//1000,
+            'duration': info['duration'] //1000,
-            'uploader':    uploader,
+            'id': video_id,
-            'ext':         ext,
+            'title': title,
-        info_url = "http://v2.tudou.com/f?id="+str(id)
+        info_url = "http://v2.tudou.com/f?id=" +str(id)
-        u'file':  u'1100701.mp4',
+        u'file': u'1100701.mp4',
-            'title':       video_title,
+            'id': video_id,
-            r'<strong>%s\'s Videos \(([0-9]+)\)</strong>'%username, profile_page,
+            r'<strong>%s\'s Videos \(([0-9]+)\)</strong>' %username, profile_page,
-                note='Downloading results page '+str(pagenum+1))
+                note='Downloading results page ' +str(pagenum +1))
-            index  =  math.floor(seed / 65536 * len(source))
+            seed = (seed * 211 + 30031) % 65536
-                'hl': 'en_US',
+            'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',
-            compat_urllib_parse.urlencode(age_form).encode('ascii'))
+        req = compat_urllib_request.Request(
-                ends = (':%d' % (end+step)) if end + step >= 0 else ':'
+                ends = (':%d' % (end + step)) if end + step >= 0 else ':'
-             'Initial JS player signature function name')
+            'Initial JS player signature function name')
-                            lines)
+                          lines)
-                        % (video_id, el_type))
+                                  % (video_id, el_type))
-                                        errnote='unable to download video info webpage')
+                                                            note=False,
-            'annotations':  video_annotations,
+            'id': video_id,
-            'view_count':   view_count,
+            'view_count': view_count,
-            'formats':      formats,
+            'formats': formats,
-                'the "yttoplist" keyword, for example "youtube-dl \'yttoplist:music:Top Tracks\'"', expected=True)
+                                 'the "yttoplist" keyword, for example "youtube-dl \'yttoplist:music:Top Tracks\'"', expected=True)
-                                          'Downloading page %s' % i)
+                                       '%s feed' % self._FEED_NAME,
-        self._downloader.to_screen(u'['+'ffmpeg'+'] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)
+        self._downloader.to_screen(u'[' +'ffmpeg' +'] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) + outpath)
-            opts.extend(['-map', '%d:0' % (i+1), '-c:s:%d' % i, 'mov_text'])
+            opts.extend(['-map', '%d:0' % (i +1), '-c:s:%d' % i, 'mov_text'])
-    signature = signature[signature.index(b('\x00'))+1:]
+    signature = signature[signature.index(b('\x00')) +1:]
-            #for every long flag
+            # for every long flag
-        #just using the special char
+        # just using the special char
-    actionDict = { 'build': Builder, 'download': Builder } # They're the same, no more caching.
+    actionDict = {'build': Builder, 'download': Builder}  # They're the same, no more caching.
-	del versions_info['signature']
+    del versions_info['signature']
-	privkey += line.encode('ascii') + b'\n'
+    try:
-json.dump(versions_info, open('update/versions.json', 'w'), indent=4, sort_keys=True)
+json.dump(versions_info, open('update/versions.json', 'w'), indent=4, sort_keys=True)
-import io # For Python 2 compatibilty
+import io  # For Python 2 compatibilty
-
+
-except ImportError: # Python 2
+except ImportError:  # Python 2
-	input()
+    raw_input()
-setup(console=['youtube-dl.py'], options={ "py2exe": py2exe_options }, zipfile=None)
+setup(console=['youtube-dl.py'], options={"py2exe": py2exe_options}, zipfile=None)
-        else: return x.encode('latin1')
+        if version_info[0] == 2:
-    if signature[0:2] != b('\x00\x01'): return False
+    if signature[0:2] != b('\x00\x01'):
-    if not b('\x00') in signature: return False
+    if not b('\x00') in signature:
-    if not signature.startswith(b('\x30\x31\x30\x0D\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01\x05\x00\x04\x20')): return False
+    if not signature.startswith(b('\x30\x31\x30\x0D\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01\x05\x00\x04\x20')):
-    if signature != sha256(message).digest(): return False
+    if signature != sha256(message).digest():
-    \n""" %(exe, exe, bat))
+    \n""" % (exe, exe, bat))
-        
+
-            if re.match(regex, message): return
+            if re.match(regex, message):
-        assertPlaylist('UUBABnxM4Ar9ten8Mdjj1j0Q') #585
+        assertPlaylist('UUBABnxM4Ar9ten8Mdjj1j0Q')  # 585
-        assertPlaylist('https://www.youtube.com/watch?v=AV6J6_AeFEQ&playnext=1&list=PL4023E734DA416012') #668
+        assertPlaylist('https://www.youtube.com/watch?v=AV6J6_AeFEQ&playnext=1&list=PL4023E734DA416012')  # 668
-        self.assertFalse(YoutubeIE.suitable('https://www.youtube.com/watch?v=AV6J6_AeFEQ&playnext=1&list=PL4023E734DA416012')) #668
+        self.assertFalse(YoutubeIE.suitable('https://www.youtube.com/watch?v=AV6J6_AeFEQ&playnext=1&list=PL4023E734DA416012'))  # 668
-### Dynamically generate tests
+# Dynamically generate tests
-### And add them to TestDownload
+# And add them to TestDownload
-        #keep the list ordered
+        # keep the list ordered
-        
+
-        _20century = DateRange("19000101","20000101")
+        _20century = DateRange("19000101", "20000101")
-
+
-        expected = list(EXPECTED_ANNOTATIONS) #Two annotations could have the same text.
+        expected = list(EXPECTED_ANNOTATIONS)  # Two annotations could have the same text.
-                annoxml = xml.etree.ElementTree.parse(annof)
+            annoxml = xml.etree.ElementTree.parse(annof)
-        #Not all the annotations have TEXT children and the annotations are returned unsorted.
+        # Not all the annotations have TEXT children and the annotations are returned unsorted.
-        #We should have seen (and removed) all the expected annotation texts.
+            self.assertEqual(a.tag, 'annotation')
-    
+
-                if ie_result is None: # Finished already (backwards compatibility; listformats and friends should be moved here)
+                if ie_result is None:  # Finished already (backwards compatibility; listformats and friends should be moved here)
-            except ExtractorError as de: # An error we somewhat expected
+            except ExtractorError as de:  # An error we somewhat expected
-                                subfile.write(sub)
+                            subfile.write(sub)
-                #It also downloads the videos
+                # It also downloads the videos
-    outtmpl =((opts.outtmpl is not None and opts.outtmpl)
+    outtmpl = ((opts.outtmpl is not None and opts.outtmpl)
-
+
-    
+
-    decrypted_data=[]
+
-        block = data[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES]
+        block = data[i*BLOCK_SIZE_BYTES: (i+1)*BLOCK_SIZE_BYTES]
-        
+
-    
+
-    
+
-    decrypted_data=[]
+
-        block = data[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES]
+        block = data[i*BLOCK_SIZE_BYTES: (i+1)*BLOCK_SIZE_BYTES]
-        
+
-    
+
-    
+
-    @returns {int[]}     176/208/240-Byte expanded key 
+    @returns {int[]}     176/208/240-Byte expanded key
-    data = data[:] # copy
+    data = data[:]  # copy
-    
+
-        
+        data += xor(temp, data[-key_size_bytes: 4-key_size_bytes])
-        
+            data += xor(temp, data[-key_size_bytes: 4-key_size_bytes])
-        
+            data += xor(temp, data[-key_size_bytes: 4-key_size_bytes])
-            data += xor(temp, data[-key_size_bytes : 4-key_size_bytes])
+            data += xor(temp, data[-key_size_bytes: 4-key_size_bytes])
-    
+
-    
+
-    @param {int[]} expanded_key  176/208/240-Byte expanded key 
+    @param {int[]} expanded_key  176/208/240-Byte expanded key
-        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES])
+        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES: (i+1)*BLOCK_SIZE_BYTES])
-    
+
-    
+
-        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES : (i+1)*BLOCK_SIZE_BYTES])
+        data = xor(data, expanded_key[i*BLOCK_SIZE_BYTES: (i+1)*BLOCK_SIZE_BYTES])
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-                         (0xB,0xD,0x9,0xE))
+MIX_COLUMN_MATRIX = ((0x2, 0x3, 0x1, 0x1),
-    
+
-    if(a==0 or b==0):
+    if(a == 0 or b == 0):
-        column = data[i*4 : (i+1)*4]
+        column = data[i*4: (i+1)*4]
-            data_shifted.append( data[((column + row) & 0b11) * 4 + row] )
+            data_shifted.append(data[((column + row) & 0b11) * 4 + row])
-            data_shifted.append( data[((column - row) & 0b11) * 4 + row] )
+            data_shifted.append(data[((column - row) & 0b11) * 4 + row])
-    for i in range(len(data)-1,-1,-1):
+    data = data[:]  # copy
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-except ImportError: # Python 2
+except ImportError:  # Python 2
-    compat_str = unicode # Python 2
+    compat_str = unicode  # Python 2
-    compat_chr = unichr # Python 2
+    compat_chr = unichr  # Python 2
-    else: return ord(c)
+    if type(c) is int:
-            if i != 1: #~user
+            if i != 1:  # ~user
-        if current == 0 or dif < 0.001: # One millisecond
+        if current == 0 or dif < 0.001:  # One millisecond
-        if bytes == 0 or dif < 0.001: # One millisecond
+        if bytes == 0 or dif < 0.001:  # One millisecond
-        new_max = min(max(bytes * 2.0, 1.0), 4194304) # Do not surpass 4 MB
+        new_max = min(max(bytes * 2.0, 1.0), 4194304)  # Do not surpass 4 MB
-            time.sleep(5.0) # This seems to be needed
+            time.sleep(5.0)  # This seems to be needed
-#coding: utf-8
+# coding: utf-8
-# There are different sources of video in arte.tv, the extraction process 
+# There are different sources of video in arte.tv, the extraction process
-        #hosted on audiomack
+        # hosted on audiomack
-                'id' : 'roosh-williams/extraordinary',
+                'id': 'roosh-williams/extraordinary',
-        #hosted on soundcloud via audiomack
+        # hosted on soundcloud via audiomack
-        #Audiomack wraps a lot of soundcloud tracks in their branded wrapper
+        # Audiomack wraps a lot of soundcloud tracks in their branded wrapper
-        #u'md5': 'fba8f7693e48fd4e8641b3fd5539a641',
+        # u'md5': 'fba8f7693e48fd4e8641b3fd5539a641',
-        #We build the url we will use to get the final track url
+        # We build the url we will use to get the final track url
-        #in the "download_url" key
+        # in the "download_url" key
-        }
+        }
-        
+
-#coding: utf-8
+# coding: utf-8
-        }
+        }
-        }
+        }
-        
+
-                'session_speakers': [ 'Ed Blankenship', 'Andrew Coates', 'Brady Gaster', 'Patrick Klug', 'Mads Kristensen' ],
+                'session_speakers': ['Ed Blankenship', 'Andrew Coates', 'Brady Gaster', 'Patrick Klug', 'Mads Kristensen'],
-                'authors': [ 'Mike Wilmot' ],
+                'authors': ['Mike Wilmot'],
-            'filesize': self._restore_bytes(x.group('filesize')), # File size is approximate
+            'filesize': self._restore_bytes(x.group('filesize')),  # File size is approximate
-            d.update({ 'title': title + '-Slides', 'url': slides })
+            d.update({'title': title + '-Slides', 'url': slides})
-            d.update({ 'title': title + '-Zip', 'url': zip_ })
+            d.update({'title': title + '-Zip', 'url': zip_})
-            d.update({ 'title': title, 'formats': formats })
+            d.update({'title': title, 'formats': formats})
-        else: # Assuming list
+        else:  # Assuming list
-    #Methods for following #608
+    # Methods for following #608
-        #TODO: ie should be the class used for getting the info
+        # TODO: ie should be the class used for getting the info
-        
+
-            'url':video_url,
+            'url': video_url,
-        }
+        }
-
+
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-#coding: utf-8
+# coding: utf-8
-        
+
-        
+
-        date = time.gmtime(info['dateCreated']/1000) # The timestamp is in miliseconds
+        date = time.gmtime(info['dateCreated']/1000)  # The timestamp is in miliseconds
-            format(video_id, mimi, compat_urllib_request.quote(refer, safe='').replace('.','%2E')))
+            format(video_id, mimi, compat_urllib_request.quote(refer, safe='').replace('.', '%2E')))
-        }
+        }
-            "uploader_id": "forestwander-nature-pictures", 
+            "description": "Waterfalls in the Springtime at Dark Hollow Waterfalls. These are located just off of Skyline Drive in Virginia. They are only about 6/10 of a mile hike but it is a pretty steep hill and a good climb back up.",
-        }
+        }
-            
+
-        }
+        }
-        
+
-        
+
-            'description': 'The square knot, also known as the reef knot, is one of the oldest, most basic knots to tie, and can be used in many different ways. Here\'s the proper way to tie a square knot.', 
+            'description': 'The square knot, also known as the reef knot, is one of the oldest, most basic knots to tie, and can be used in many different ways. Here\'s the proper way to tie a square knot.',
-    
+
-        cleaned_dic = dict((k,v[0]) for (k,v) in query_dic.items() if k in NEEDED_ARGS)
+        cleaned_dic = dict((k, v[0]) for (k, v) in query_dic.items() if k in NEEDED_ARGS)
-        title = '%s - %s' % (compilation, title) if compilation is not None else title  
+        title = '%s - %s' % (compilation, title) if compilation is not None else title
-        if season_id is not None: # Season link
+        if season_id is not None:  # Season link
-        else: # Compilation link            
+        else:  # Compilation link
-            if len(seasons) == 0: # No seasons in this compilation
+            if len(seasons) == 0:  # No seasons in this compilation
-        return self.playlist_result(entries, playlist_id, playlist_title)
+        return self.playlist_result(entries, playlist_id, playlist_title)
-        
+
-        
+
-    
+
-        }
+        }
-            r'<time datetime=\'([^\']+)\'>', webpage, 'upload date',fatal=False)
+            r'<time datetime=\'([^\']+)\'>', webpage, 'upload date', fatal=False)
-            return [make_entry(video_id, media, video_number+1) for video_number, media in enumerate(videos)]
+            return [make_entry(video_id, media, video_number+1) for video_number, media in enumerate(videos)]
-        }        
+        }
-            response_json = json.loads(response)            
+            response_json = json.loads(response)
-        
+
-        return self.playlist_result(entries, course_id, course_title)
+        return self.playlist_result(entries, course_id, course_title)
-        }
+        }
-    
+
-        }
+        }
-        #Could be several links with different quality
+        # Could be several links with different quality
-        }
+        }
- 
+
-        formats =[{
+        formats = [{
-    }
+    }
-                
+
-        return [{'url': url,'ext': 'mp4'}]
+        return [{'url': url, 'ext': 'mp4'}]
-    
+
-    
+
-        }
+        }
-        for quality in ['1080' , '720', '480', '360']:
+        for quality in ['1080', '720', '480', '360']:
-    def __rc4crypt(self,data, key):
+    def __rc4crypt(self, data, key):
-    def __md5(self,s):
+    def __md5(self, s):
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        query = compat_urllib_parse.urlencode({'vid': vid, 'inKey': key,})
+        query = compat_urllib_parse.urlencode({'vid': vid, 'inKey': key, })
-                    'rtmp_protocol': '1', # rtmpt
+                    'rtmp_protocol': '1',  # rtmpt
-        }
+        }
-        
+
-        
+
-        }
+        }
-        }
+        }
-           video_url = initial_video_url
+            video_url = initial_video_url
-        }
+        }
-        }
+        }
-    }
+    }
-        }
+        }
-        }
+        }
-        }
+        }
-        }
+        }
-        video_urls = list(map(compat_urllib_parse.unquote , re.findall(r'"quality_[0-9]{3}p":"([^"]+)', webpage)))
+        video_urls = list(map(compat_urllib_parse.unquote, re.findall(r'"quality_[0-9]{3}p":"([^"]+)', webpage)))
-        #Get the uploaded date
+        # Get the uploaded date
-        }
+        }
-        return subtitles
+        return subtitles
-        
+
-        }
+        }
-        }
+        }
-        }
+        }
-        }
+        }
-    
+
-    
+
-    
+
-        }
+        }
-        }
+        }
-                if not sub_lang in available_subs_list:
+                if sub_lang not in available_subs_list:
-        
+
-        
+
-#coding: utf-8
+# coding: utf-8
-            config_url = url+ '&form=json'
+            config_url = url + '&form=json'
-#coding: utf-8
+# coding: utf-8
-        
+
-        
+
-        }
+        }
-        
+
-                webpage, 'video title').replace(' - Trailer Addict','')
+                webpage, 'video title').replace(' - Trailer Addict', '')
-        info_webpage = self._download_webpage(info_url, video_id , "Downloading the info webpage")
+        info_webpage = self._download_webpage(info_url, video_id, "Downloading the info webpage")
-                info_webpage, 'Download url').replace('%3F','?')
+                info_webpage, 'Download url').replace('%3F', '?')
- 
+
-        final_url = self._html_search_regex('>(.+?)</f>',webpage, 'video url')
+        final_url = self._html_search_regex('>(.+?)</f>', webpage, 'video url')
-        }
+        }
-        return self.playlist_result(entries, course_id, course_title)
+        return self.playlist_result(entries, course_id, course_title)
-        raise ExtractorError('No video found', expected=True)
+        raise ExtractorError('No video found', expected=True)
-        }
+        }
-        }
+        }
-        
+
-        url_node = next(node for node in [find_xpath_attr(sources, 'source', 'id', 'HQ %s' % key) 
+        url_node = next(node for node in [find_xpath_attr(sources, 'source', 'id', 'HQ %s' % key)
-        }
+        }
-    }
+    }
-#coding: utf-8
+# coding: utf-8
-        
+
-        
+
-            }  
+            }
-        }
+        }
-# TODO test _1
+# TODO test _1
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        }
+        }
-        random2 = random.randint(1000,9999)
+        random1 = random.randint(1000, 1998)
-        return "%d%d%d" %(nowTime,random1,random2)
+        return "%d%d%d" % (nowTime, random1, random2)
-        #return ''.join(mixed)
+        # return ''.join(mixed)
-        files_info=[]
+        files_info = []
-        #fileid[7:9] should be changed
+        # column 8,9 of fileid represent the segment number
-        
+
-        
+
-        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k,v in login_form_strs.items())
+        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k, v in login_form_strs.items())
-            tfa_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k,v in tfa_form_strs.items())
+            tfa_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k, v in tfa_form_strs.items())
-            if original_lang_node is None or original_lang_node.attrib.get('kind') != 'asr' :
+            if original_lang_node is None or original_lang_node.attrib.get('kind') != 'asr':
-                video_annotations = self._extract_annotations(video_id)
+            video_annotations = self._extract_annotations(video_id)
-            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts',[''])[0]
+            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts', [''])[0]
-                            # Top tracks, they can also include dots 
+                            # Top tracks, they can also include dots
-        
+
-    
+
-        else: return super(YoutubeUserIE, cls).suitable(url)
+        if any(ie.suitable(url) for ie in other_ies):
-        help='Execute a command on the file after downloading, similar to find\'s -exec syntax. Example: --exec \'adb push {} /sdcard/Music/ && rm {}\'' )
+        help='Execute a command on the file after downloading, similar to find\'s -exec syntax. Example: --exec \'adb push {} /sdcard/Music/ && rm {}\'')
-        prefix, sep, ext = path.rpartition(u'.') # not os.path.splitext, since the latter does not work on unicode in all setups
+        prefix, sep, ext = path.rpartition(u'.')  # not os.path.splitext, since the latter does not work on unicode in all setups
-            etype,e,tb = sys.exc_info()
+            etype, e, tb = sys.exc_info()
-        return self._nopostoverwrites,information
+        return self._nopostoverwrites, information
-    def __init__(self, downloader=None,preferedformat=None):
+    def __init__(self, downloader=None, preferedformat=None):
-        self._preferedformat=preferedformat
+        self._preferedformat = preferedformat
-        self._downloader.to_screen(u'['+'ffmpeg'+'] Converting video from %s to %s, Destination: ' % (information['ext'], self._preferedformat) +outpath)
+            return True, information
-        return False,information
+        return False, information
-            self._downloader.to_screen(u'[ffmpeg] There aren\'t any subtitles to embed') 
+            self._downloader.to_screen(u'[ffmpeg] There aren\'t any subtitles to embed')
-
+
-        else: return x.encode('latin1')
+        if version_info[0] == 2:
-    if signature[0:2] != b('\x00\x01'): return False
+    if signature[0:2] != b('\x00\x01'):
-    if not b('\x00') in signature: return False
+    if not b('\x00') in signature:
-    if not signature.startswith(b('\x30\x31\x30\x0D\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01\x05\x00\x04\x20')): return False
+    if not signature.startswith(b('\x30\x31\x30\x0D\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01\x05\x00\x04\x20')):
-    if signature != sha256(message).digest(): return False
+    if signature != sha256(message).digest():
-        if verbose: to_screen(compat_str(traceback.format_exc()))
+        if verbose:
-        if verbose: to_screen(compat_str(traceback.format_exc()))
+        if verbose:
-            if verbose: to_screen(compat_str(traceback.format_exc()))
+            if verbose:
-            if verbose: to_screen(compat_str(traceback.format_exc()))
+            if verbose:
-            if verbose: to_screen(compat_str(traceback.format_exc()))
+            if verbose:
-            if verbose: to_screen(compat_str(traceback.format_exc()))
+            if verbose:
-            if verbose: to_screen(compat_str(traceback.format_exc()))
+            if verbose:
-    for v,vdata in sorted(versions.items()):
+    for v, vdata in sorted(versions.items()):
-    #Replace commas
+    # Replace commas
-        #A bad aproximation?
+        # A bad aproximation?
-    
+
-        return cls(day,day)
+        return cls(day, day)
-        return '%s - %s' % ( self.start.isoformat(), self.end.isoformat())
+        return '%s - %s' % (self.start.isoformat(), self.end.isoformat())
-    name, real_ext = os.path.splitext(filename) 
+    name, real_ext = os.path.splitext(filename)
-    IE_DESC = 'YouTube.com recommended videos, "ytrec" keyword (requires authentication)'
+    IE_DESC = 'YouTube.com recommended videos, ":ytrec" for short (requires authentication)'
-    IE_DESC = 'Youtube watch later list, "ytwatchlater" keyword (requires authentication)'
+    IE_DESC = 'Youtube watch later list, ":ytwatchlater" for short (requires authentication)'
-    IE_DESC = 'Youtube watch history, "ythistory" keyword (requires authentication)'
+    IE_DESC = 'Youtube watch history, ":ythistory" for short (requires authentication)'
-    IE_DESC = 'YouTube.com favourite videos, "ytfav" keyword (requires authentication)'
+    IE_DESC = 'YouTube.com favourite videos, ":ytfav" for short (requires authentication)'
-    url_basename,
+    unified_strdate,
-    _VALID_URL = r'^https?://(?:www\.)?(?:smotri\.com/video/view/\?id=|pics\.smotri\.com/(?:player|scrubber_custom8)\.swf\?file=)(?P<videoid>v(?P<realvideoid>[0-9]+)[a-z0-9]{4})'
+    _VALID_URL = r'^https?://(?:www\.)?(?:smotri\.com/video/view/\?id=|pics\.smotri\.com/(?:player|scrubber_custom8)\.swf\?file=)(?P<id>v(?P<realvideoid>[0-9]+)[a-z0-9]{4})'
-        real_video_id = mobj.group('realvideoid')
+        video_id = self._match_id(url)
-        video_json = json.loads(video_json_page)
+        request = compat_urllib_request.Request(
-        if status == self._VIDEO_NOT_FOUND:
+        video = self._download_json(request, video_id, 'Downloading video JSON')
-        video_url = video_json['file_data']
+
-        video_page = self._download_webpage(video_page_url, video_id, 'Downloading video page')
+        webpage_url = 'http://smotri.com/video/view/?id=%s' % video_id
-            r'<div class="videoUnModer">(.*?)</div>', video_page,
+            r'<div class="videoUnModer">(.*?)</div>', webpage,
-        if re.search('EroConfirmText">', video_page) is not None:
+        if re.search('EroConfirmText">', webpage) is not None:
-            video_page = self._download_webpage(confirm_url, video_id, 'Downloading video page (age confirmed)')
+                webpage, 'confirm string')
-        video_view_count = self._html_search_regex(
+        view_count = self._html_search_regex(
-            video_page, 'view count', fatal=False, flags=re.MULTILINE|re.DOTALL)
+            webpage, 'view count', fatal=False, flags=re.MULTILINE|re.DOTALL)
-            'view_count': int_or_none(video_view_count),
+            'title': title,
-        video_urlpart = videopath.split('/flash/')[1][:-4]
+        video_urlpart = videopath.split('/flash/')[1][:-5]
-__version__ = '2014.11.23'
+__version__ = '2014.11.23.1'
-            else:
+            if opts.update_self or opts.rm_cachedir:
-        return "'" + s.replace("'", "'\"'\"'") + "'"
+        if re.match(r'^[-_\w./]+$', s):
-                       for video_id in video_ids]
+        video_ids = orderedSet(
-        {
+        {
-__version__ = '2014.11.21.1'
+__version__ = '2014.11.23'
-        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id
+        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1&bpctr=9999999999' % video_id
-    _VALID_URL = r'https?://(?:www\.)?telebruxelles\.be/(news|sport|dernier-jt)/?(?P<title>[^\?]+)'
+    _VALID_URL = r'https?://(?:www\.)?telebruxelles\.be/(news|sport|dernier-jt)/?(?P<id>[^/#?]+)'
-        'md5': '59439e568c9ee42fb77588b2096b214f', 
+        'url': 'http://www.telebruxelles.be/news/auditions-devant-parlement-francken-galant-tres-attendus/',
-        }
+            'title': 'Parlement : Francken et Galant rÃ©pondent aux interpellations de lâopposition',
-        'md5': '181d3fbdcf20b909309e5aef5c6c6047', 
+        'url': 'http://www.telebruxelles.be/sport/basket-brussels-bat-mons-80-74/',
-	}]
+            'description': 're:^Ils l\u2019on fait ! En basket, le B*',
-		title = mobj.group('title')
+        display_id = self._match_id(url)
-		rtmp_url = rtmp_url.replace("\" + \"", "")
+        article_id = self._html_search_regex(
-		}
+        rtmp_url = self._html_search_regex(
-            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/d=pc/fmt=adaptive/' % uuid,
+            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/fmt=flash/' % uuid,
-        videopath = material['videopath']
+        # Use unencrypted m3u8 streams (See https://github.com/rg3/youtube-dl/issues/4118)
-        video_urlpart = videopath.split('/adaptive/')[1][:-4]
+        video_urlpart = videopath.split('/flash/')[1][:-4]
-        return self.playlist_result(url_entries, page_id)
+        return self.playlist_result(url_entries, page_id)
-        page_id = mobj.group(1)
+        page_id = self._match_id(url)
-    unified_strdate)
+    unified_strdate,
-        video_ids = self.extract_videos_from_page(page)
+        video_ids = orderedSet(m.group(1) for m in re.finditer(r'href="/video([0-9_]+)"', page))
-    _VALID_URL = r'https?://(?:m\.)?vk\.com/videos([0-9]+)(?:m\?.*)?'
+    _VALID_URL = r'https?://vk\.com/videos(?P<id>[0-9]+)(?:m\?.*)?'
-    IE_DESC = 'All of a user\'s videos'
+    IE_DESC = 'vk.com:All of a user\'s videos'
-            'md5': 'f79bccb5cd182b1f43502ca5685b2b36',
+            'url': 'http://vk.com/video205387401_165548505',
-                'id': '163339118',
+                'id': '165548505',
-                'duration': 558,
+                'uploader': 'Tom Cruise',
-__version__ = '2014.11.21'
+__version__ = '2014.11.21.1'
-        elif result_type == 'playlist' or playlist == 'multi_video':
+        elif result_type == 'playlist' or result_type == 'multi_video':
-import re
+from __future__ import unicode_literals
-    _VALID_URL = r'(?:http://)?(?:(?:www\.)?sztv\.hu|www\.tvszombathely\.hu)/(?:[^/]+)/.+-(?P<id>[0-9]+)'
+    _VALID_URL = r'http://(?:(?:www\.)?sztv\.hu|www\.tvszombathely\.hu)/(?:[^/]+)/.+-(?P<id>[0-9]+)'
-            u"description": u'A zÃ¶ld nap jÃ¡tÃ©kos ismeretterjesztÅ programjait a Magyar CserkÃ©sz SzÃ¶vetsÃ©g szervezte, akik az orszÃ¡g nyolc vÃ¡rosÃ¡ban adjÃ¡k Ã¡t tudÃ¡sukat az Ã©rdeklÅdÅknek. A PET...',
+        'url': 'http://sztv.hu/hirek/cserkeszek-nepszerusitettek-a-kornyezettudatos-eletmodot-a-savaria-teren-20130909',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source[^>]*)?\s+src="([^"]+)"', webpage)
+            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source[^>]*)?\s+src=["\'](.*?)["\']', webpage)
-__version__ = '2014.11.20.1'
+__version__ = '2014.11.21'
-            r'^(?P<var>[a-zA-Z0-9_]+)\.(?P<member>[^(]+)(?:\(+(?P<args>[^()]*)\))?$',
+            r'^(?P<var>[$a-zA-Z0-9_]+)\.(?P<member>[^(]+)(?:\(+(?P<args>[^()]*)\))?$',
-        elif result_type == 'playlist':
+        elif result_type == 'playlist' or playlist == 'multi_video':
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?blip\.tv/)|bliptvuser:)(?!api\.swf)([^/]+)/*$'
+    _VALID_URL = r'(?:(?:https?://(?:\w+\.)?blip\.tv/)|bliptvuser:)(?!api\.swf)([^/]+)/*$'
-        return [self.playlist_result(url_entries, playlist_title=username)]
+        return self.playlist_result(
-            r"<h1>We're sorry.</h1>\s*<p>(.*?)</p>", webpage,
+            r"<h1>We're sorry.</h1>([\s\n]*<p>.*?</p>)+", webpage,
-        return [self._get_video_info(item) for item in idoc.findall('.//item')]
+        return self.playlist_result(
-    The dictionaries must include the following fields:
+    The type field determines the the type of the result.
-            raise ExtractorError('Invalid URL: %s' % url)
+        mobj = re.match(self._VALID_URL, url)
-    except TypeError as te:
+    except TypeError:
-    parse_duration,
+from __future__ import unicode_literals
-    _VALID_URL = r'^(?:https?://)?openclassroom\.stanford\.edu(?P<path>/?|(/MainFolder/(?:HomePage|CoursePage|VideoPage)\.php([?]course=(?P<course>[^&]+)(&video=(?P<video>[^&]+))?(&.*)?)?))$'
+    IE_NAME = 'stanfordoc'
-            u"title": u"Intro Environment"
+        'url': 'http://openclassroom.stanford.edu/MainFolder/VideoPage.php?course=PracticalUnix&video=intro-environment&speed=100',
-        if mobj.group('course') and mobj.group('video'): # A specific video
+        if mobj.group('course') and mobj.group('video'):  # A specific video
-        elif mobj.group('course'): # A course page
+                raise ExtractorError('Invalid metadata XML file')
-                'type': 'playlist',
+                '_type': 'playlist',
-                                        errnote='Unable to download course info page')
+            coursepage = self._download_webpage(
-            info['title'] = self._html_search_regex('<h1>([^<]+)</h1>', coursepage, 'title', default=info['id'])
+            info['title'] = self._html_search_regex(
-                coursepage, u'description', fatal=False)
+            info['description'] = self._html_search_regex(
-        else: # Root page
+            info['entries'] = [self.url_result(
-                'type': 'playlist',
+                '_type': 'playlist',
-            info['title'] = info['id']
+                errnote='Unable to download course info page')
-            return results
+            info['entries'] = [self.url_result(
-        return [self._get_video_info(item) for item in idoc.findall('.//item')]
+        return self.playlist_result(
-__version__ = '2014.11.20'
+__version__ = '2014.11.20.1'
-            msg = msg + '; please report this issue on https://yt-dl.org/bug . Be sure to call youtube-dl with the --verbose flag and include its complete output. Make sure you are using the latest version; type  youtube-dl -U  to update.'
+            if ytdl_is_updateable():
-    determine_ext,
+    qualities,
-        all_formats = []
+        formats = []
-                'tbr': int_or_none(format_info.get('bitrate')),
+            f = dict(format_dict)
-                info['ext'] = 'flv'
+
-        info_dict['formats'] = [_format(f) for f in formats]
+                format['url'] = f['url']
-__version__ = '2014.11.16'
+__version__ = '2014.11.20'
-    """ Encode obj as JSON and write it to fn, atomically """
+    """ Encode obj as JSON and write it to fn, atomically if possible """
-    if sys.version_info < (3, 0):
+    if sys.version_info < (3, 0) and sys.platform != 'win32':
-    except TypeError:
+        og.add_option('-t')
-                    write_json_file(info_dict, encodeFilename(infofn))
+                    write_json_file(info_dict, infofn)
-from .compat import compat_expanduser
+from .compat import compat_expanduser, compat_getenv
-            cache_root = os.environ.get('XDG_CACHE_HOME', '~/.cache')
+            cache_root = compat_getenv('XDG_CACHE_HOME', '~/.cache')
-            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/fmt=flash/' % uuid,
+            'http://www.rtl.nl/system/s4m/vfd/version=2/uuid=%s/d=pc/fmt=adaptive/' % uuid,
-        f4m_url = 'http://manifest.us.rtl.nl' + videopath
+        m3u8_url = 'http://manifest.us.rtl.nl' + videopath
-        formats = self._extract_f4m_formats(f4m_url, uuid)
+        formats = self._extract_m3u8_formats(m3u8_url, uuid, ext='mp4')
-        video_urlpart = videopath.split('/flash/')[1][:-4]
+        video_urlpart = videopath.split('/adaptive/')[1][:-4]
-)
+    unified_strdate)
-            'duration': data.get('duration')
+            'duration': data.get('duration'),
-    _VALID_URL = r'https?://(?:m\.)?vk\.com/videos([0-9]+)'
+    _VALID_URL = r'https?://(?:m\.)?vk\.com/videos([0-9]+)(?:m\?.*)?'
-from .vk import VKIE
+from .vk import (
-    _VALID_URL = r'https?://(?:m\.)?vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|(?:.+?\?.*?z=)?video(?P<videoid>.*?)(?:\?|%2F|$))'
+    _VALID_URL = r'https?://(?:m\.)?vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|(?:.+?\?.*?z=)?video(?P<videoid>[^s].*?)(?:\?|%2F|$))'
-                self.report_warning('Skipping DASH manifest: %s' % e, video_id)
+                self.report_warning('Skipping DASH manifest: %r' % e, video_id)
-    def __init__(self, name_idx, name):
+    def __init__(self, name_idx, name, static_properties=None):
-    def __boolean__(self):
+    def __bool__(self):
-        self._patched_functions = {}
+        self._patched_functions = {
-                trait_methods, constants = parse_traits_info()
+                trait_methods, trait_constants = parse_traits_info()
-                assert constants is None
+                if trait_constants:
-                self._classes_by_name, avm_class.variables])
+                self._classes_by_name, avm_class.constants, avm_class.variables])
-                        res = avm_class.constants[mname]
+                        # Assume unitialized
-                        assert isinstance(obj, (dict, _ScopeDict)), \
+                        if isinstance(obj, _AVMClass):
-            u30()  # cinit
+            avm_class.cinit_idx = u30()
-    def extract_class(self, class_name):
+    def extract_class(self, class_name, call_cinit=True):
-            return self._classes_by_name[class_name]
+            res = self._classes_by_name[class_name]
-        u'TEST'.encode(pref)
+        'TEST'.encode(pref)
-        if filename == u'-':
+        if filename == '-':
-                        re.sub(u'[/<>:"\\|\\\\?\\*]', u'#', path_part)
+                        re.sub('[/<>:"\\|\\\\?\\*]', '#', path_part)
-    result = u''.join(map(replace_insane, s))
+    result = ''.join(map(replace_insane, s))
-        if numstr.startswith(u'x'):
+        if numstr.startswith('x'):
-            numstr = u'0%s' % numstr
+            numstr = '0%s' % numstr
-    return (u'&%s;' % entity)
+    return ('&%s;' % entity)
-        # Pass u'' directly to use Unicode APIs on Windows 2000 and up
+        # Pass '' directly to use Unicode APIs on Windows 2000 and up
-            msg += u' (caused by %r)' % cause
+            msg += ' (caused by %r)' % cause
-            msg = msg + u'; please report this issue on https://yt-dl.org/bug . Be sure to call youtube-dl with the --verbose flag and include its complete output. Make sure you are using the latest version; type  youtube-dl -U  to update.'
+            msg = msg + '; please report this issue on https://yt-dl.org/bug . Be sure to call youtube-dl with the --verbose flag and include its complete output. Make sure you are using the latest version; type  youtube-dl -U  to update.'
-        return u''.join(traceback.format_tb(self.traceback))
+        return ''.join(traceback.format_tb(self.traceback))
-def determine_ext(url, default_ext=u'unknown_video'):
+def determine_ext(url, default_ext='unknown_video'):
-    guess = url.partition(u'?')[0].rpartition(u'.')[2]
+    guess = url.partition('?')[0].rpartition('.')[2]
-    return filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.' + sub_format
+    return filename.rsplit('.', 1)[0] + '.' + sub_lang + '.' + sub_format
-    return u' '.join(quoted_args)
+    return ' '.join(quoted_args)
-    return url + u'#' + sdata
+        {'__youtubedl_smuggle': json.dumps(data)})
-    jsond = compat_parse_qs(sdata)[u'__youtubedl_smuggle'][0]
+    url, _, sdata = smug_url.rpartition('#')
-        return u'N/A'
+        return 'N/A'
-    suffix = [u'B', u'KiB', u'MiB', u'GiB', u'TiB', u'PiB', u'EiB', u'ZiB', u'YiB'][exponent]
+    suffix = ['B', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB', 'ZiB', 'YiB'][exponent]
-    return u'%.2f%s' % (converted, suffix)
+    return '%.2f%s' % (converted, suffix)
-        u'July', u'August', u'September', u'October', u'November', u'December']
+        'January', 'February', 'March', 'April', 'May', 'June',
-        u'&amp;',
+        '&amp;',
-    return path.strip(u'/').split(u'/')[-1]
+    return path.strip('/').split('/')[-1]
-    int_str = re.sub(r'[,\.\+]', u'', int_str)
+    int_str = re.sub(r'[,\.\+]', '', int_str)
-    return u'{0}.{1}{2}'.format(name, ext, real_ext)
+    return '{0}.{1}{2}'.format(name, ext, real_ext)
-                    unrecognized=u'present'):
+                    unrecognized='present'):
-    struct.pack(u'!I', 0)
+    struct.pack('!I', 0)
-        BOM_UTF8 = u'\xef\xbb\xbf'
+        BOM_UTF8 = '\xef\xbb\xbf'
-            s32()
+            self.constant_ints.append(s32())
-            u32()
+            self.constant_uints.append(u32())
-            if kind in [0x00, 0x06]:  # Slot or Const
+            constants = None
-            elif kind in [0x01, 0x02, 0x03]:  # Method / Getter / Setter
+            elif kind == 0x06:  # Const
-            return methods
+            return methods, constants
-                trait_methods = parse_traits_info()
+                trait_methods, constants = parse_traits_info()
-                trait_methods = parse_traits_info()
+                trait_methods, trait_constants = parse_traits_info()
-                    res = scope.get(mname)
+
-                if opcode == 16:  # jump
+                if opcode == 9:  # label
-                    if isinstance(obj, _AVMClass_Object):
+                    if obj == StringClass:
-                        stack.append(StringClass)
+                    if mname not in res and mname in _builtin_classes:
-                            res = compat_str(args[0])
+                            assert isinstance(args[0], (
-                    res = None
+                    res = undefined
-                        assert res is None
+                        assert res is undefined
-                        assert res is None
+                        assert res is undefined
-                        res = obj.get(pname, None)
+                        res = obj.get(pname, undefined)
-                        stack.append(obj[pname])
+                        res = obj.get(pname, None)
-                    stack.append(res[mname])
+                    if mname not in res and mname == 'String':
-                        assert isinstance(obj, list)
+                        assert isinstance(obj, (compat_str, list))
-                if opcode == 17:  # iftrue
+                if opcode == 16:  # jump
-                            'Accessing member on %r' % obj
+                            'Accessing member %r on %r' % (pname, obj)
-        "outtmpl": "%(id)s.%(ext)s",
+        'outtmpl': '%(id)s.%(ext)s',
-        tname = 'test_'  + str(test_case['name']) + '_' + str(i)
+        tname = 'test_%s_%d' % (test_case['name'], i)
-    test_method.__name__ = tname
+    test_method.__name__ = str(tname)
-        if sys.version_info >= (2,7): # Python 2.6 doesn't support package execution
+        if sys.version_info >= (2, 7):  # Python 2.6 doesn't support package execution
-        self.DL.expect_warning(u'Video doesn\'t have automatic captions')
+        self.DL.expect_warning('Video doesn\'t have automatic captions')
-        self.DL.expect_warning(u'video doesn\'t have subtitles')
+        self.DL.expect_warning('video doesn\'t have subtitles')
-            self.assertTrue(subtitles.get(lang) is not None, u'Subtitles for \'%s\' not extracted' % lang)
+            self.assertTrue(subtitles.get(lang) is not None, 'Subtitles for \'%s\' not extracted' % lang)
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'video doesn\'t have subtitles')
+        self.DL.expect_warning('video doesn\'t have subtitles')
-            self.assertTrue(subtitles.get(lang) is not None, u'Subtitles for \'%s\' not extracted' % lang)
+            self.assertTrue(subtitles.get(lang) is not None, 'Subtitles for \'%s\' not extracted' % lang)
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-            self.assertTrue(subtitles.get(lang) is not None, u'Subtitles for \'%s\' not extracted' % lang)
+            self.assertTrue(subtitles.get(lang) is not None, 'Subtitles for \'%s\' not extracted' % lang)
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'video doesn\'t have subtitles')
+        self.DL.expect_warning('video doesn\'t have subtitles')
-            self.assertTrue(subtitles.get(lang) is not None, u'Subtitles for \'%s\' not extracted' % lang)
+            self.assertTrue(subtitles.get(lang) is not None, 'Subtitles for \'%s\' not extracted' % lang)
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'Automatic Captions not supported by this server')
+        self.DL.expect_warning('Automatic Captions not supported by this server')
-        self.DL.expect_warning(u'video doesn\'t have subtitles')
+        self.DL.expect_warning('video doesn\'t have subtitles')
-    setproctitle(u'youtube-dl')
+    setproctitle('youtube-dl')
-                parser.error(u'wrong header formatting, it should be key:value, not "%s"'%h)
+                parser.error('wrong header formatting, it should be key:value, not "%s"'%h)
-                write_string(u'[debug] Adding header from command line option %s:%s\n'%(key, value))
+                write_string('[debug] Adding header from command line option %s:%s\n'%(key, value))
-                write_string(u'[debug] Batch file urls: ' + repr(batch_urls) + u'\n')
+                write_string('[debug] Batch file urls: ' + repr(batch_urls) + '\n')
-            sys.exit(u'ERROR: batch file could not be read')
+            sys.exit('ERROR: batch file could not be read')
-                compat_print(u'  ' + mu)
+                compat_print('  ' + mu)
-                desc += u' (Example: "%s%s:%s" )' % (ie.SEARCH_KEY, random.choice(_COUNTS), random.choice(_SEARCHES))
+                _SEARCHES = ('cute kittens', 'slithering pythons', 'falling cat', 'angry poodle', 'purple fish', 'running tortoise', 'sleeping bunny')
-        parser.error(u'using .netrc conflicts with giving username/password')
+        parser.error('using .netrc conflicts with giving username/password')
-        parser.error(u'account username missing\n')
+        parser.error('account username missing\n')
-        parser.error(u'using output template conflicts with using title, video ID or auto number')
+        parser.error('using output template conflicts with using title, video ID or auto number')
-        parser.error(u'using title conflicts with using video ID')
+        parser.error('using title conflicts with using video ID')
-        opts.password = compat_getpass(u'Type account password and press [Return]: ')
+        opts.password = compat_getpass('Type account password and press [Return]: ')
-            parser.error(u'invalid rate limit specified')
+            parser.error('invalid rate limit specified')
-            parser.error(u'invalid min_filesize specified')
+            parser.error('invalid min_filesize specified')
-            parser.error(u'invalid max_filesize specified')
+            parser.error('invalid max_filesize specified')
-            parser.error(u'invalid retry count specified')
+            parser.error('invalid retry count specified')
-            parser.error(u'invalid buffer size specified')
+            parser.error('invalid buffer size specified')
-        raise ValueError(u'Playlist start must be positive')
+        raise ValueError('Playlist start must be positive')
-        raise ValueError(u'Playlist end must be greater than playlist start')
+        raise ValueError('Playlist end must be greater than playlist start')
-            parser.error(u'invalid audio format specified')
+            parser.error('invalid audio format specified')
-            parser.error(u'invalid audio quality specified')
+            parser.error('invalid audio quality specified')
-            parser.error(u'invalid video recode format specified')
+            parser.error('invalid video recode format specified')
-            or (opts.autonumber and u'%(autonumber)s-%(id)s.%(ext)s')
+            or (opts.format == '-1' and opts.usetitle and '%(title)s-%(id)s-%(format)s.%(ext)s')
-                     u' template'.format(outtmpl))
+        parser.error('Cannot download a video and extract audio into the same'
-                parser.error(u'you must provide at least one URL')
+                parser.error('you must provide at least one URL')
-            ydl.to_screen(u'--max-download limit reached, aborting.')
+            ydl.to_screen('--max-download limit reached, aborting.')
-        sys.exit(u'ERROR: fixed output name but more than one file to download')
+        sys.exit('ERROR: fixed output name but more than one file to download')
-        sys.exit(u'\nERROR: Interrupted by user')
+        sys.exit('\nERROR: Interrupted by user')
-        if self.params.get('nopart', False) or filename == u'-' or \
+        if self.params.get('nopart', False) or filename == '-' or \
-        return filename + u'.part'
+        return filename + '.part'
-            return filename[:-len(u'.part')]
+        if filename.endswith('.part'):
-            self.report_error(u'unable to rename file: %s' % compat_str(err))
+            self.report_error('unable to rename file: %s' % compat_str(err))
-        self.to_screen(u'[download] Destination: ' + filename)
+        self.to_screen('[download] Destination: ' + filename)
-        fullmsg = u'[download] ' + msg
+        fullmsg = '[download] ' + msg
-                    fullmsg += u' ' * (prev_len - len(fullmsg))
+                    fullmsg += ' ' * (prev_len - len(fullmsg))
-                clear_line = u'\r'
+                clear_line = '\r'
-                clear_line = (u'\r\x1b[K' if sys.stderr.isatty() else u'\r')
+                clear_line = ('\r\x1b[K' if sys.stderr.isatty() else '\r')
-        self.to_console_title(u'youtube-dl ' + msg)
+        self.to_console_title('youtube-dl ' + msg)
-        msg = (u'%s of %s at %s ETA %s' %
+        msg = ('%s of %s at %s ETA %s' %
-        msg = u'%s at %s (%s)' % (downloaded_str, speed_str, elapsed_str)
+        msg = '%s at %s (%s)' % (downloaded_str, speed_str, elapsed_str)
-            self.to_screen(u'[download] Download completed')
+            self.to_screen('[download] Download completed')
-                (u'100%% of %s in %s' %
+                ('100%% of %s in %s' %
-        self.to_screen(u'[download] Resuming download at byte %s' % resume_len)
+        self.to_screen('[download] Resuming download at byte %s' % resume_len)
-        self.to_screen(u'[download] Got server HTTP error. Retrying (attempt %d of %d)...' % (count, retries))
+        self.to_screen('[download] Got server HTTP error. Retrying (attempt %d of %d)...' % (count, retries))
-            self.to_screen(u'[download] %s has already been downloaded' % file_name)
+            self.to_screen('[download] %s has already been downloaded' % file_name)
-            self.to_screen(u'[download] The file has already been downloaded')
+            self.to_screen('[download] The file has already been downloaded')
-        self.to_screen(u'[download] Unable to resume')
+        self.to_screen('[download] Unable to resume')
-        raise NotImplementedError(u'This method must be implemented by subclasses')
+        raise NotImplementedError('This method must be implemented by subclasses')
-            'duration': 194,
+            'duration': 1838,
-            fatal=False))
+        duration = parse_duration(self._html_search_meta('duration', webpage))
-        r'(?i)(?:(?:(?P<hours>[0-9]+)\s*(?:[:h]|hours?)\s*)?(?P<mins>[0-9]+)\s*(?:[:m]|mins?|minutes?)\s*)?(?P<secs>[0-9]+)(?P<ms>\.[0-9]+)?\s*(?:s|secs?|seconds?)?$', s)
+        r'''(?ix)T?
-__version__ = '2014.11.15.1'
+__version__ = '2014.11.16'
-        webpage = self._download_webpage(url, video_id)
+        webpage, handle = self._download_webpage_handle(url, video_id)
-    _VALID_URL = r'https?://(?:www\.)?spiegel\.tv/filme/(?P<id>[\-a-z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?spiegel\.tv/(?:#/)?filme/(?P<id>[\-a-z0-9]+)'
-import re
+from ..utils import float_or_none
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-
+        video_id = self._match_id(url)
-            format = '4x3'
+        duration = float_or_none(media_json.get('duration_in_ms'), scale=1000)
-        'dir': os.path.dirname(fn),
+        'prefix': path_basename(fn) + '.',
-        # See https://github.com/rg3/youtube-dl/issues/857
+        # See https://github.com/rg3/youtube-dl/issues/857 and
-            video_id = self._search_regex(r'data-episode-id="([0-9]+)', info_page, 'video_id')
+            video_id = self._search_regex(r'config\.id\s*=\s*"([0-9]+)', info_page, 'video_id')
-__version__ = '2014.11.15'
+__version__ = '2014.11.15.1'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            r'<title>(.*?) - Golden Moustache</title>', webpage, 'title')
+            r'<title>(.*?)(?: - Golden Moustache)?</title>', webpage, 'title')
-    parser = optparse.OptionParser(**kw)
+    parser = optparse.OptionParser(**compat_kwargs(kw))
-__version__ = '2014.11.14'
+__version__ = '2014.11.15'
-                'id': '46301138',
+                'id': '46301138_76',
-                'id': '46843144',
+                'id': '46843144_1263',
-        uploader_id = author['id']
+        uploader_id = author.get('id') or author.get('email')
-        title = movie['title']
+        meta_data = video_data['meta']
-        view_count = video_data['views_count']
+        thumbnail = meta_data['poster']
-                'format_id': video['name'],
+                'format_id': video['key'],
-            'timestamp': video_data['timestamp'],
+            'timestamp': timestamp,
-        }
+        }
-__version__ = '2014.11.13.3'
+__version__ = '2014.11.14'
-        config_url = 'http://media.mtvnservices.com/pmt/e1/players/{0}/config.xml'.format(site_id)
+        config_url = ('http://media.mtvnservices.com/pmt/e1/players/{0}/'
-class ComedyCentralShowsIE(InfoExtractor):
+class ComedyCentralShowsIE(MTVServicesInfoExtractor):
-    return struct.pack('%dB' % len(xs), *xs)
+    return struct_pack('%dB' % len(xs), *xs)
-__version__ = '2014.11.13.2'
+__version__ = '2014.11.13.3'
-            transform_source=lambda j: re.sub(r'parseMetadata\((.*?)\);\n//.*$', r'\1', j)
+            transform_source=strip_jsonp,
-    return re.sub(r'(?s)^[a-zA-Z0-9_]+\s*\(\s*(.*)\);?\s*?\s*$', r'\1', code)
+    return re.sub(
-__version__ = '2014.11.13.1'
+__version__ = '2014.11.13.2'
-        }
+        },
-    _VALID_URL = r'http://new\.livestream\.com/.*?/(?P<event_name>.*?)(/videos/(?P<id>\d+))?/?$'
+    _VALID_URL = r'https?://new\.livestream\.com/.*?/(?P<event_name>.*?)(/videos/(?P<id>[0-9]+)(?:/player)?)?/?(?:$|[?#])'
-)
+from ..utils import ExtractorError
-    _VALID_URL = r'^http://www.freevideo.cz/vase-videa/(?P<videoid>[^.]+)\.html$'
+    _VALID_URL = r'^http://www.freevideo.cz/vase-videa/(?P<id>[^.]+)\.html(?:$|[?#])'
-        'file': 'vysukany-zadecek-22033.mp4',
+            'id': 'vysukany-zadecek-22033',
-        }
+        },
-            age_limit = 18
+        video_id = self._match_id(url)
-            raise ExtractorError('ERROR: unable to extract video url')
+        video_url = self._search_regex(
-            'url': url.groups()[0],
+            'url': video_url,
-            'age_limit': age_limit,
+            'age_limit': 18,
-__version__ = '2014.11.13'
+__version__ = '2014.11.13.1'
-        return bytes(xs)
+    return struct.pack('%dB' % len(xs), *xs)
-
+        video_id = self._match_id(url)
-
+        quality_arr = self._search_regex(
-            r'<title>([^<]+)\s*-\s*Sexu.Com</title>', webpage, 'title')
+            r'<title>([^<]+)\s*-\s*Sexu\.Com</title>', webpage, 'title')
-        description = self._html_search_meta('description', webpage, 'description')
+        description = self._html_search_meta(
-        categories_str = self._html_search_meta('keywords', webpage, 'categories', fatal=False)
+        categories_str = self._html_search_meta(
-from ..utils import compat_urlparse
+from ..compat import compat_urlparse
-    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<id>[0-9]+)(?:\.html)?(?:#.*)?$'
+    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<id>[0-9]+)(?:-embed)?(?:\.html)?(?:#.*)?$'
-            r'<div class="module-title">(.*?)</div>', webpage, 'title')
+        title = re.sub(r'\s+', ' ', self._html_search_regex(
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-
+
-        }
+            'video page URL', default=None)
-        write_string('\n"info_dict": {\n' + info_dict_str + '}\n', out=sys.stderr)
+        write_string(
-    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<videoID>[0-9]+)(?:\.html)?(?:#.*)?$'
+    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<id>[0-9]+)(?:\.html)?(?:#.*)?$'
-
+        video_id = self._match_id(url)
-        video_id = m.group('id')
+        video_id = self._match_id(url)
-            'title': 'md5:033cf4a71907aac2758e82f55894a129',
+            'title': 'md5:4d05a19a5fc049a63dbbaf05fb71d91b',
-            'title': str, # NSFW
+            'title': 'md5:033cf4a71907aac2758e82f55894a129',
-__version__ = '2014.11.12.1'
+__version__ = '2014.11.13'
-            r'signature=([$a-zA-Z]+)', jscode,
+            r'\.sig\|\|([a-zA-Z0-9]+)\(', jscode,
-            r'<link rel="video_src" href="[^"]*?vevo.com[^"]*?videoId=(?P<id>[\w]*)',
+            r'<link rel="video_src" href="[^"]*?vevo.com[^"]*?video=(?P<id>[\w]*)',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            'thumbnail': 'md5:fd41386bc1f932552622da4a7e9a7242',
+            'thumbnail': 're:^https?://.*\.jpg$',
-
+        video_id = self._match_id(url)
-
+        video_url = self._html_search_regex(
-            r'<strong>(\d+)</strong>\s*VUES</span>', webpage, 'view count', fatal=False))
+            r'<strong>([0-9]+)</strong>\s*VUES</span>',
-        'md5': '29f4c5e5a61ca39dfd7e8348a75d0aad',
+        stdout_encoding = getattr(
-                sys.stdout.encoding,
+                stdout_encoding,
-        'md5': 'dad6f8ad011a70d9ddf887ce6d5d0742',
+        'url': 'http://www.abc.net.au/news/2014-11-05/australia-to-staff-ebola-treatment-centre-in-sierra-leone/5868334',
-            'id': '5624716',
+            'id': '5868334',
-            'description': 'md5:ba36fa5e27e5c9251fd929d339aea4af',
+            'title': 'Australia to help staff Ebola treatment centre in Sierra Leone',
-            'description': 'md5:4a754271d9c6f16c72629a8a993ee884',
+            'description': 'md5:abcd09ce503c6560512c14ebfdb720d2',
-        'url': 'http://www.byutv.org/watch/44e80f7b-e3ba-43ba-8c51-b1fd96c94a79/granite-flats-talking',
+        'url': 'http://www.byutv.org/watch/6587b9a3-89d2-42a6-a7f7-fd2f81840a7d/studio-c-season-5-episode-5',
-            'id': 'granite-flats-talking',
+            'id': 'studio-c-season-5-episode-5',
-            'title': 'Talking',
+            'description': 'md5:5438d33774b6bdc662f9485a340401cc',
-from youtube_dl.utils import compat_str, compat_urlretrieve
+from youtube_dl.compat import compat_str, compat_urlretrieve
-    _VALID_URL = r'^https?://(?:\w+\.)?youjizz\.com/videos/(?P<videoid>[^.]+)\.html$'
+    _VALID_URL = r'https?://(?:\w+\.)?youjizz\.com/videos/[^/#?]+-(?P<id>[0-9]+)\.html(?:$|[?#])'
-        'file': '2189178.flv',
+            'id': '2189178',
-        # Get webpage content
+        video_id = self._match_id(url)
-        webpage = self._download_webpage(embed_page_url, video_id)
+        video_title = self._html_search_regex(
-        'file': '11741.mp4',
+            'id': '11741',
-                'file': '1353101989.mp3',
+                    'id': '1353101989',
-                'file': '38097443.mp3',
+                    'id': '38097443',
-__version__ = '2014.11.12'
+__version__ = '2014.11.12.1'
-                            return
+                            # The first format must contain the video and the
-__version__ = '2014.11.09'
+__version__ = '2014.11.12'
-        base = 'http://mtvnmobile.vo.llnwd.net/kip0/_pxn=1+_pxI0=Ripod-h264+_pxL0=undefined+_pxM0=+_pxK=18639+_pxE=mp4/44620/mtvnorigin/'
+        base = 'http://viacommtvstrmfs.fplive.net/'
-        audio_table = {'flv': 'mp3', 'webm': 'ogg'}
+        audio_table = {'flv': 'mp3', 'webm': 'ogg', '???': 'mp3'}
-        'md5': '1e546a18e1c22ac6e9adce17b8961ff5',
+        'url': 'http://jolka85.wrzuta.pl/audio/063jOPX5ue2/liber_natalia_szroeder_-_teraz_ty',
-            'id': '9oXJqdcndqv',
+            'id': '063jOPX5ue2',
-            'description': 'md5:4628f01c666bbaaecefa83476cfa794a',
+            'title': 'Liber & Natalia Szroeder - Teraz Ty',
-        audio_table = {'flv': 'mp3', 'webm': 'ogg', 'mp3': 'mp3'}
+        audio_table = {'flv': 'mp3', 'webm': 'ogg'}
-                ext = audio_table[media['type'].split('@')[0]]
+                ext = audio_table.get(fmt, fmt)
-                ext = media['type'].split('@')[0]
+                ext = fmt
-__version__ = '2014.11.04'
+__version__ = '2014.11.09'
-              '%(playlist_index)s for the position in the playlist and %% for a literal percent. '
+              '%(id)s for the video id, '
-    _VALID_URL = r'https?://streamcloud\.eu/(?P<id>[a-zA-Z0-9_-]+)/(?P<fname>[^#?]*)\.html'
+    _VALID_URL = r'https?://streamcloud\.eu/(?P<id>[a-zA-Z0-9_-]+)(?:/(?P<fname>[^#?]*)\.html)?'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        video_url = re.search(r'''3: \{src:'(?P<video>.+?)\.hi\.mp4', type:"video/mp4"},''', page)
+        video_url = re.search(r'''3: \{src:'(?P<video>.+?)\.(lo|hi|hq)\.mp4', type:"video/mp4"},''', page)
-                    'format_note': ['144p', '288p', '544p'][quality-1],
+                    'format_note': ['144p', '288p', '544p', '720p'][quality-1],
-        }
+        }
-        help='video format code, specify the order of preference using slashes: -f 22/17/18 .  -f mp4 , -f m4a and  -f flv  are also supported. You can also use the special names "best", "bestvideo", "bestaudio", "worst", "worstvideo" and "worstaudio". By default, youtube-dl will pick the best quality. Use commas to download multiple audio formats, such as  -f  136/137/mp4/bestvideo,140/m4a/bestaudio')
+        help='video format code, specify the order of preference using'
-            'url': 'http://www.nicovideo.jp/watch/%s' % entry['item_id'],
+            'url': ('http://www.nicovideo.jp/watch/%s' %
-        audio_table = {'flv': 'mp3', 'webm': 'ogg'}
+        audio_table = {'flv': 'mp3', 'webm': 'ogg', 'mp3': 'mp3'}
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        title = self._search_regex(r'class="video-title"><h1>(.+?)<', webpage, 'title')
+        title = self._og_search_title(webpage)
-        config_uri = player_vars.get('config')
+        config = self._download_xml(
-        if node is None:
+        if config is None:
-        if node.tag != 'config':
+        if config.tag != 'config':
-        if len(fns) != 1:
+        fns = config.findall('file')
-            'age_limit': 18,
+            'age_limit': 0 if family_friendly == 'true' else 18,
-from ..utils import (
+from ..compat import (
-    compat_html_parser,
+    compat_urllib_parse_urlparse,
-                    ext = 'flv'
+                    url_comp = compat_urllib_parse_urlparse(url)
-                'ext': 'flv',
+                'ext': 'mp4',
-                'skip_download': True,
+                'skip_download': True,  # m3u8 download
-        mobj = re.search(r'src="(?P<embed_url>http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?[^"]*\bid=(?:Cinemassacre-)?(?P<video_id>.+?))"', webpage)
+        mobj = re.search(r'src="(?P<embed_url>http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?[^"]*\bid=(?P<full_video_id>(?:Cinemassacre-)?(?P<video_id>.+?)))"', webpage)
-        videolist = self._download_xml(videolist_url, video_id, 'Downloading videolist XML')
+        videolist_url = None
-        self._sort_formats(formats)
+        mobj = re.search(r"'videoserver'\s*:\s*'(?P<videoserver>[^']+)'", playerdata)
-                'thumbnail': 'http://media.ch9.ms/ch9/9d51/03902f2d-fc97-4d3c-b195-0bfe15a19d51/KOS002_220.jpg',
+                'thumbnail': 'http://video.ch9.ms/ch9/9d51/03902f2d-fc97-4d3c-b195-0bfe15a19d51/KOS002_220.jpg',
-                'thumbnail': 'http://media.ch9.ms/ch9/87e1/0300391f-a455-4c72-bec3-4422f19287e1/selfservicenuk_512.jpg',
+                'thumbnail': 'http://video.ch9.ms/ch9/87e1/0300391f-a455-4c72-bec3-4422f19287e1/selfservicenuk_512.jpg',
-        if title is None:           
+        if title is None:
-        m = re.search(r'data-video_duration="(?P<hours>\d{2}):(?P<minutes>\d{2}):(?P<seconds>\d{2})"', html)
+        m = re.search(r'"length": *"(?P<hours>\d{2}):(?P<minutes>\d{2}):(?P<seconds>\d{2})"', html)
-        # Look for downloadable content        
+        # Look for downloadable content
-        if page_type == 'List':         # List page, may contain list of 'item'-like objects
+        page_type_m = re.search(r'<meta name="WT.entryid" content="(?P<pagetype>[^:]+)[^"]+"/>', webpage)
-    int_or_none,
+    get_element_by_id,
-                'timestamp': 1404298698,
+                'timestamp': 1404302298,
-                'timestamp': 1163318593,
+                'timestamp': 1163322193,
-        url = 'http://www.izlesene.com/video/%s' % video_id
+        video_id = self._match_id(url)
-__version__ = '2014.11.02.1'
+__version__ = '2014.11.04'
-                note='Refetching age-gated webpage',
+                note='Refetching age-gated info webpage',
-            self.result = attrs.get('content')
+    m = re.search(r'''(?xs)
-        return self.result
+    if res.startswith('"') or res.startswith("'"):
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        descr = get_element_by_attribute('itemprop', 'description', webpage)
+        descr = self._html_search_regex(
-
+        list_id = self._match_id(url)
-
+
-        channel_id = get_meta_content('ustream:channel_id', webpage)
+        channel_id = self._html_search_meta('ustream:channel_id', webpage)
-    def _search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0):
+    def _search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0, group=None):
-            return next(g for g in mobj.groups() if g is not None)
+            if group is None:
-    def _html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0):
+    def _html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0, group=None):
-        res = self._search_regex(pattern, string, name, default, fatal, flags)
+        res = self._search_regex(pattern, string, name, default, fatal, flags, group)
-            html, display_name, fatal=fatal, **kwargs)
+                    (?=[^>]+(?:itemprop|name|property)=(["\']?)%s\1)
-    get_meta_content,
+    determine_ext,
-            'format_id': 'mp4_720',
+            'format_id': 'mp4_720p',
-            'thumbnail': 're:https?://.*\.jpg$',
+            'thumbnail': 're:^https?://.*\.jpe?g$',
-            'timestamp': parse_iso8601(get_meta_content('date', webpage)),
+            'timestamp': parse_iso8601(
-        title = get_meta_content('fulltitle', webpage)
+        title = self._html_search_meta('fulltitle', webpage)
-                'url': source_node.attrib['file'],
+                'url': video_url,
-    _VALID_URL = r'(?:http://)?(?:www\.)?gamespot\.com/.*-(?P<page_id>\d+)/?'
+    _VALID_URL = r'(?:http://)?(?:www\.)?gamespot\.com/.*-(?P<id>\d+)/?'
-        page_id = mobj.group('page_id')
+        page_id = self._match_id(url)
-        data_video_json = self._search_regex(r'data-video=["\'](.*?)["\']', webpage, 'data video')
+        data_video_json = self._search_regex(
-        http_template = compat_urlparse.urljoin('http://video.gamespotcdn.com/', http_template)
+        http_template = compat_urlparse.urljoin(
-            'description': get_meta_content('description', webpage),
+            'description': self._html_search_meta('description', webpage),
-                    r'"sts"\s*:\s*(\d+)', video_webpage, 'sts'),
+                    r'"sts"\s*:\s*(\d+)', video_webpage, 'sts', default=''),
-                                    errnote='unable to download video info webpage')
+            video_info_webpage = self._download_webpage(
-        'file': 'sports_2013_06_09_nadal-1-on-1.cnn.mp4',
+            'id': 'sports_2013_06_09_nadal-1-on-1.cnn',
-        "file": "us_2013_08_21_sot-student-gives-epic-speech.georgia-institute-of-technology.mp4",
+            'id': 'us/2013/08/21/sot-student-gives-epic-speech.georgia-institute-of-technology',
-            r"'file'\s*:\s*'([^']+)'", webpage, 'video URL')
+            r"[\"']file[\"']\s*[:,]\s*[\"'](.+?)[\"']", webpage, 'video URL')
-    _VALID_URL = r'https?://.*brightcove\.com/(services|viewer).*\?(?P<query>.*)'
+    _VALID_URL = r'https?://.*brightcove\.com/(services|viewer).*?\?(?P<query>.*)'
-            dir(youtube_dl.compat)))
+            dir(youtube_dl.compat))) - set(['unicode_literals'])
-        title = xpath_text(config, './title', 'title')
+        title = xpath_text(config, './title', 'title').strip()
-compat_html_parser.locatestarttagend = re.compile(r"""<[a-zA-Z][-.a-zA-Z0-9:_]*(?:\s+(?:(?<=['"\s])[^\s/>][^\s/=>]*(?:\s*=+\s*(?:'[^']*'|"[^"]*"|(?!['"])[^>\s]*))?\s*)*)?\s*""", re.VERBOSE) # backport bugfix
+if sys.version_info < (2, 7):
-        super(FakeYDL, self).__init__(params)
+        super(FakeYDL, self).__init__(params, auto_init=False)
-        ydl = YoutubeDL(params)
+        ydl = YoutubeDL(params, auto_init=False)
-from youtube_dl.utils import (
+from youtube_dl.compat import (
-                subprocess.check_call(['mxmlc', '-output', swf_file, as_file])
+                subprocess.check_call([
-    return compat_urllib_parse.quote(s, "%/;:@&=+$,!~*'()?#[]")
+    return compat_urllib_parse.quote(s, b"%/;:@&=+$,!~*'()?#[]")
-import getpass
+#!/usr/bin/env python
-from .utils import (
+from .compat import (
-from .utils import (
+from .compat import (
-)
+from .compat import compat_expanduser
-from ..utils import (
+from ..compat import (
-
+)
-    ExtractorError,
+from ..compat import (
-    HEADRequest,
+from ..utils import (
-from ..utils import (
+from ..compat import (
-
+)
-from ..utils import compat_urllib_parse_unquote, url_basename
+from ..compat import compat_urllib_parse_unquote
-from ..utils import (
+from ..compat import (
-from ..utils import (
+from ..compat import (
-
+)
-    float_or_none,
+from ..compat import (
-from ..utils import (
+from ..compat import (
-
+)
-from ..utils import compat_urllib_parse_unquote
+from ..compat import compat_urllib_parse_unquote
-from ..utils import (
+from ..compat import (
-from .utils import (
+from .compat import (
-
+from ..compat import (
-)
+from ..compat import shlex_quote
-from ..utils import (
+from ..compat import (
-        compat_expanduser = os.path.expanduser
+from .compat import (
-
+from .downloader.rtmp import rtmpdump_version
-        return dict((program, get_version(program)) for program in programs)
+        return dict((p, get_exe_version(p, args=['-version'])) for p in programs)
-__version__ = '2014.11.02'
+__version__ = '2014.11.02.1'
-__version__ = '2014.10.30'
+__version__ = '2014.11.02'
-        videolist_url = 'http://%s/vod/smil:%s.smil/jwplayer.smil' % (videoserver, vidid)
+        videolist_url = self._search_regex(
-            r'<iframe[^>]+?src=(["\'])(?P<url>https?://m\.mlb\.com/shared/video/embed/embed\.html\?.+?)\1',
+            r'<iframe[^>]+?src=(["\'])(?P<url>https?://m(?:lb)?\.mlb\.com/shared/video/embed/embed\.html\?.+?)\1',
-    _VALID_URL = r'https?://m\.mlb\.com/(?:(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|shared/video/embed/embed\.html\?.*?\bcontent_id=)(?P<id>n?\d+)'
+    _VALID_URL = r'https?://m(?:lb)?\.mlb\.com/(?:(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|(?:shared/video/embed/embed\.html|[^/]+/video/play\.jsp)\?.*?\bcontent_id=)(?P<id>n?\d+)'
-from .d8 import D8IE
+    qualities,
-    _VALID_URL = r'https?://(?:www\.(?P<site>canal|piwi)plus\.fr/.*?/(?P<path>.*)|player\.canalplus\.fr/#/(?P<id>[0-9]+))'
+    IE_DESC = 'canalplus.fr, piwiplus.fr and d8.tv'
-        'piwi': 'teletoon',
+        'canalplus.fr': 'cplus',
-            'description': 'md5:',
+            'description': 'md5:4cea7a37153be42c1ba2c1d3064376ff',
-        preferences = ['MOBILE', 'BAS_DEBIT', 'HAUT_DEBIT', 'HD', 'HLS', 'HDS']
+        preference = qualities(['MOBILE', 'BAS_DEBIT', 'HAUT_DEBIT', 'HD', 'HLS', 'HDS'])
-        ]
+        formats = []
-    IE_NAME = 'canalplus.fr'
+    IE_DESC = 'canalplus.fr and piwiplus.fr'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            video_id = self._search_regex(r'<canal:player videoId="(\d+)"', webpage, 'video id')
+            video_id = self._search_regex(
-        info_url = self._VIDEO_INFO_TEMPLATE % video_id
+        info_url = self._VIDEO_INFO_TEMPLATE % (site_id, video_id)
-    _VALID_URL = r'https?://(?:www\.)?funnyordie\.com/(?P<type>embed|videos)/(?P<id>[0-9a-f]+)(?:$|[?#/])'
+    _VALID_URL = r'https?://(?:www\.)?funnyordie\.com/(?P<type>embed|articles|videos)/(?P<id>[0-9a-f]+)(?:$|[?#/])'
-__version__ = '2014.10.29'
+__version__ = '2014.10.30'
-)
+from ..utils import compat_urllib_parse_unquote
-    _VALID_URL = r'(?x)(?:https?://)?(?:www\.)?220\.ro/(?P<category>[^/]+)/(?P<shorttitle>[^/]+)/(?P<video_id>[^/]+)'
+    _VALID_URL = r'(?x)(?:https?://)?(?:www\.)?220\.ro/(?P<category>[^/]+)/(?P<shorttitle>[^/]+)/(?P<id>[^/]+)'
-        'file': 'LYV6doKo7f.mp4',
+        'url': 'http://www.220.ro/sport/Luati-Le-Banii-Sez-4-Ep-1/LYV6doKo7f/',
-            "description": "re:^Iata-ne reveniti dupa o binemeritata vacanta\. +Va astept si pe Facebook cu pareri si comentarii.$",
+            'id': 'LYV6doKo7f',
-        video_id = mobj.group('video_id')
+        video_id = self._match_id(url)
-        flashVars = compat_parse_qs(flashVars_str)
+        url = compat_urllib_parse_unquote(self._search_regex(
-            'thumbnail': flashVars['preview'][0],
+            'formats': formats,
-__version__ = '2014.10.27'
+__version__ = '2014.10.29'
-    def _convert_subtitles_to_srt(self, subtitles):
+    def _convert_subtitles_to_srt(self, sub_root):
-                continue
+
-    def _convert_subtitles_to_ass(self, subtitles):
+    def _convert_subtitles_to_ass(self, sub_root):
-
+            sub_root = xml.etree.ElementTree.fromstring(subtitle)
-                subtitles[lang_code] = self._convert_subtitles_to_ass(subtitle)
+                subtitles[lang_code] = self._convert_subtitles_to_ass(sub_root)
-                subtitles[lang_code] = self._convert_subtitles_to_srt(subtitle)
+                subtitles[lang_code] = self._convert_subtitles_to_srt(sub_root)
-            r'<iframe src="(?P<url>https?://(?:w\.)?soundcloud\.com/player[^"]+)"',
+            r'<iframe\s+(?:[a-zA-Z0-9_-]+="[^"]+"\s+)*src="(?P<url>https?://(?:w\.)?soundcloud\.com/player[^"]+)"',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        timestamp = parse_iso8601(data['CreatedTime'][:-5])
+        timestamp = parse_iso8601(data['CreatedTime'])
-        r'Z$| ?(?P<sign>\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$',
+        r'(\.[0-9]+)?(?:Z$| ?(?P<sign>\+|-)(?P<hours>[0-9]{2}):?(?P<minutes>[0-9]{2})$)',
-    date_format =  '%Y-%m-%d{0}%H:%M:%S'.format(delimiter)
+    date_format = '%Y-%m-%d{0}%H:%M:%S'.format(delimiter)
-
+from ..utils import xpath_text
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?trutube\.tv/(?:video/|nuevo/player/embed\.php\?v=)(?P<id>[0-9]+)'
-    }
+    }, {
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r"var splash_img = '([^']+)';", webpage, 'thumbnail', fatal=False)
+        config = self._download_xml(
-        self._sort_formats(formats)
+        # filehd is always 404
-            'formats': formats,
+            'url': video_url,
-        os.environ['YOUTUBE-DL-TEST'] = test_str.encode(get_filesystem_encoding())
+        os.environ['YOUTUBE-DL-TEST'] = (test_str if sys.version_info >= (3, 0)
-        os.environ['HOME'] = test_str.encode(get_filesystem_encoding())
+        os.environ['HOME'] = (test_str if sys.version_info >= (3, 0)
-from .niconico import NiconicoIE
+from .niconico import NiconicoIE, NiconicoPlaylistIE
-        bootstrap = base64.b64decode(doc.find(_add_ns('bootstrapInfo')).text)
+        bootstrap_node = doc.find(_add_ns('bootstrapInfo'))
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                'use --username and --password options to provide account credentials.', expected=True)
+        ERRORS = {
-                'Video %s does not exist' % video_id, expected=True)
+        for error_re, error_msg in ERRORS.items():
-            r's1\.addVariable\("file",\s*"([^"]+)"\);', webpage, 'video URL')
+            r"'file'\s*:\s*'([^']+)'", webpage, 'video URL')
-    def __init__(self, params=None):
+    def __init__(self, params=None, auto_init=True):
-        urls = json.loads(js_to_json(self._search_regex(
+        murls = json.loads(js_to_json(self._search_regex(
-        formats = [{'url': url} for url in urls]
+        formats = [{'url': murl} for murl in murls]
-    determine_ext,
+from .quickvid import QuickVidIE
-            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source[^>]+)? src="([^"]+)"', webpage)
+            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source[^>]*)?\s+src="([^"]+)"', webpage)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'<title>(.+?)</title>',
+        title = self._html_search_regex(
-version = youtube_dl.__version__
+from youtube_dl.version import __version__
-__version__ = '2014.10.26.2'
+__version__ = '2014.10.27'
-        }
+        return extract_from_xml_url(self, video_id, xml_url)
-
+        video_id = self._match_id(url)
-        title = self._search_regex(r'<h1 title=.*>(.*?)</h1>', webpage, 'title')
+
-        m3u8_doc = self._download_webpage(m3u8_url, video_id)
+        m3u8_doc = self._download_webpage(
-
+        video_id = self._match_id(url)
-    _VALID_URL = r'(?:http://)?(?:www\.)?fernsehkritik\.tv/folge-(?P<ep>[0-9]+)(?:/.*)?'
+    IE_NAME = 'fernsehkritik.tv'
-            u'description': u'md5:fb4818139c7cfe6907d4b83412a6864f',
+        'url': 'http://fernsehkritik.tv/folge-1',
-            u'playlist', flags=re.DOTALL)
+            'playlist', flags=re.DOTALL)
-    _VALID_URL = r'(?:http://)?(?:www\.)?fernsehkritik\.tv/inline-video/postecke\.php\?(.*&)?ep=(?P<ep>[0-9]+)(&|$)'
+    IE_NAME = 'fernsehkritik.tv:postecke'
-            u"title": u"Postecke 120"
+        'url': 'http://fernsehkritik.tv/inline-video/postecke.php?iframe=true&width=625&height=440&ep=120',
-            'title':    video_title,
+            'id': video_id,
-    _VALID_URL = r'^https?://www\.zdf\.de/ZDFmediathek(?P<hash>#)?/(.*beitrag/(?:video/)?)(?P<video_id>[0-9]+)(?:/[^/?]+)?(?:\?.*)?'
+    _VALID_URL = r'^https?://www\.zdf\.de/ZDFmediathek(?P<hash>#)?/(.*beitrag/(?:video/)?)(?P<id>[0-9]+)(?:/[^/?]+)?(?:\?.*)?'
-        video_id = mobj.group('video_id')
+        video_id = self._match_id(url)
-        config = self._download_json(json_url, video_id)
+
-            'thumbnail': config.get('poster'),
+            'thumbnail': self._og_search_thumbnail(webpage),
-
+        for source_node in doc.findall('.//{http://rss.jwpcdn.com/}source'):
-        ],
+        'info_dict': {
-        video_id = m.group('id')
+        video_id = self._match_id(url)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-                'ext': 'flv',
+                'ext': 'mp4',
-        meta = self._download_xml(smil_url, video_id)
+        meta = self._download_xml(smil_url, video_id)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        if re.search(self._FILE_NOT_FOUND_REGEX, webpage) is not None:
+        if re.search(r'<div.+id="not_found_msg".+>(?!We are).+</div>[^-]', webpage) is not None:
-                'title': 'Busty Blonde Siri Tit Fuck While Wank at Handjob Hub',
+                'title': 'Busty Blonde Siri Tit Fuck While Wank at HandjobHub.com',
-            'title': 'Micro Pig piglets ready on 16th July 2009',
+            'title': 'Micro Pig piglets ready on 16th July 2009-bG0PdrCdxUc',
-        },
+        }
-                self.assertTrue(os.path.exists(info_json_fn))
+                self.assertTrue(
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>pornhub\.com/view_video\.php\?viewkey=(?P<videoid>[0-9a-f]+))'
+    _VALID_URL = r'^https?://(?:www\.)?pornhub\.com/view_video\.php\?viewkey=(?P<id>[0-9a-f]+)'
-            "uploader": "BABES-COM",
+            'id': '648719015',
-        url = 'http://www.' + mobj.group('url')
+        video_id = self._match_id(url)
-            r'(?s)From:&nbsp;.+?<(?:a href="/users/|<span class="username)[^>]+>(.+?)<',
+            r'(?s)From:&nbsp;.+?<(?:a href="/users/|a href="/channels/|<span class="username)[^>]+>(.+?)<',
-                'description': 'md5:895b1df01639b5f61a04fc305a5cb94d',
+                'description': 're:^Im Therapiezentrum \'Sonnalm\' kommen durch eine Unachtsamkeit die fÃ¼r die B.handlung mit Phobikern gehaltenen Voglespinnen frei\. Eine AusreiÃerin',
-
+        video_id = self._match_id(url)
-            r'<title>([^<]+)&nbsp;&nbsp; RUHD.ru - ÐÐ¸Ð´ÐµÐ¾ ÐÑÑÐ¾ÐºÐ¾Ð³Ð¾ ÐºÐ°ÑÐµÑÑÐ²Ð° â1 Ð² Ð Ð¾ÑÑÐ¸Ð¸!</title>', webpage, 'title')
+            r'<title>([^<]+)&nbsp;&nbsp; RUHD.ru - ÐÐ¸Ð´ÐµÐ¾ ÐÑÑÐ¾ÐºÐ¾Ð³Ð¾ ÐºÐ°ÑÐµÑÑÐ²Ð° â1 Ð² Ð Ð¾ÑÑÐ¸Ð¸!</title>',
-            r'(?s)<div id="longdesc">(.+?)<span id="showlink">', webpage, 'description', fatal=False)
+            r'(?s)<div id="longdesc">(.+?)<span id="showlink">',
-            r'<param name="previewImage" value="([^"]+)"', webpage, 'thumbnail', fatal=False)
+            r'<param name="previewImage" value="([^"]+)"',
-        'playlist_mincount': 54,
+        'playlist_mincount': 17,
-                'title': 'Hevnen er sÃ¸t episode 10: Abu',
+                'title': 'Hevnen er sÃ¸t episode 1:10 - Abu',
-
+        video_id = self._match_id(url)
-            'title': 'Death by dogma versus assembling agile - Sander Hoogendoorn',
+            'title': 're:(?i)^Death by dogma versus assembling agile . Sander Hoogendoorn',
-        'playlist_mincount': 47,
+        'playlist_mincount': 46,
-            'description': 'surreal gay themed erotica...almost an ET kind of thing',
+            'description': 'http://www.xtube.com an ET kind of thing',
-            'title': 'Team Fortress 2 (Class-based LP)',
+            'title': '[OLD]Team Fortress 2 (Class-based LP)',
-    IE_NAME = 'SÃ¼ddeutscher Rundfunk'
+    IE_DESC = 'SÃ¼ddeutscher Rundfunk'
-import datetime
+
-
+        video_id = self._match_id(url)
-import re
+from __future__ import unicode_literals
-    IE_NAME = u'faz.net'
+    IE_NAME = 'faz.net'
-            u'description': u'md5:1453fbf9a0d041d985a47306192ea253',
+        'url': 'http://www.faz.net/multimedia/videos/stockholm-chemie-nobelpreis-fuer-drei-amerikanische-forscher-12610585.html',
-        self.to_screen(video_id)
+        video_id = self._match_id(url)
-            u'Downloading config xml')
+        config_xml_url = self._search_regex(
-        for code in ['LOW', 'HIGH', 'HQ']:
+        for pref, code in enumerate(['LOW', 'HIGH', 'HQ']):
-                'ext': determine_ext(encoding_url),
+                'quality': pref,
-        descr = self._html_search_regex(r'<p class="Content Copy">(.*?)</p>', webpage, u'description')
+        descr = self._html_search_regex(
-__version__ = '2014.10.26.1'
+__version__ = '2014.10.26.2'
-        return True
+            note='Confirming age', errnote='Unable to confirm age',
-            'play_path': 'mp4:trans/dv15/mogulus-{0}.mp4'.format(path),
+            'play_path': 'trans/dv15/mogulus-{0}'.format(path),
-            prefs = ('ffproe', 'avprobe')
+            prefs = ('ffprobe', 'avprobe')
-__version__ = '2014.10.26'
+__version__ = '2014.10.26.1'
-        if not self._exes['ffprobe'] and not self._exes['avprobe']:
+
-                self._exes['avprobe'] or self._exes['ffprobe'],
+                self._probe_executable,
-    def __init__(self, downloader, deletetempfiles=False):
+    def __init__(self, downloader=None, deletetempfiles=False):
-            self._downloader.report_warning(warning)
+            if self._downloader:
-            webpage = _webpage_read_content(url, video_id)
+            webpage = self._webpage_read_content(full_response, url, video_id)
-            },   
+            },
-            'duration': 1622963.0,
+            'duration': 1622.963,
-        duration = float_or_none(self._html_search_meta('duration', webpage, 'duration'))
+        duration = float_or_none(self._html_search_meta('duration', webpage, 'duration'), 1000)
-            del f['tbr']
+        f4m_formats = [{
-            stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
+            stdout=subprocess.PIPE, stderr=subprocess.STDOUT).communicate()
-__version__ = '2014.10.25'
+__version__ = '2014.10.26'
-    'Xavier Beynon'
+    'Xavier Beynon',
-    _TITLE_EXTR = r'<span\s+itemprop="name">\s*(?P<showtitle>[\w\s]+)'
+    _VALID_URL = r'https?://(?:(?P<prefix>www|m)\.)?(?P<url>crunchyroll\.com/(?!(?:news|anime-news|library|forum|launchcalendar|lineup|store|comics|freetrial|login))(?P<id>[\w\-]+))/?$'
-            'title' : 'Attack on Titan'
+        'url': 'http://www.crunchyroll.com/a-bridge-to-the-starry-skies-hoshizora-e-kakaru-hashi',
-        'playlist_count' : 15
+        'playlist_count': 13,
-        (title,entries) = self._extract_title_entries(show_id,webpage)
+        show_id = self._match_id(url)
-        }
+            '_type': 'playlist',
-
+        content = self._webpage_read_content(urlh, url_or_request, video_id, note, errnote, fatal)
-        return (content, urlh)
+        return content
-        response = self._request_webpage(
+        head_response = self._request_webpage(
-        if response is not False:
+        if head_response is not False:
-            new_url = response.geturl()
+            new_url = head_response.geturl()
-                }
+        full_response = None
-        try:
+        if full_response:
-                        if not merger._get_executable():
+                        if not merger._executable:
-    def __init__(self, downloader=None, deletetempfiles=False):
+    def __init__(self, downloader, deletetempfiles=False):
-    def _get_executable(self):
+    @property
-        return self._get_executable() == 'avconv'
+        return self._executable == 'avconv'
-            raise FFmpegPostProcessorError(u'ffmpeg or avconv not found. Please install one.')
+        self.check_version()
-        cmd = ([self._get_executable(), '-y'] + files_cmd
+        cmd = ([self._executable, '-y'] + files_cmd
-                self._downloader.to_screen(u'[' + self._get_executable() + '] Destination: ' + new_path)
+                self._downloader.to_screen(u'[' + self._executable + '] Destination: ' + new_path)
-                msg = u'error running ' + self._get_executable()
+                msg = u'error running ' + self._executable
-from .postprocessor import FFmpegMergerPP
+from .postprocessor import FFmpegMergerPP, FFmpegPostProcessor
-                     (platform.python_version(), platform_name()) + '\n')
+        self._write_string('[debug] Python version %s - %s\n' % (
-    FFmpegEmbedSubtitlePP,
+    'ExecAfterDownloadPP',
-    'ExecAfterDownloadPP',
+import re
-        self._exes = self.detect_executables()
+        self._versions = self.get_versions()
-    def detect_executables():
+    def get_versions():
-        return dict((program, check_executable(program, ['-version'])) for program in programs)
+        return dict((program, get_version(program)) for program in programs)
-            return self._exes['ffmpeg'] or self._exes['avconv']
+            prefs = ('ffmpeg', 'avconv')
-            return self._exes['avconv'] or self._exes['ffmpeg']
+            prefs = ('avconv', 'ffmpeg')
-        return self._get_executable() == self._exes['avconv']
+        return self._get_executable() == 'avconv'
-                embedSWF\(?:\s*
+                embedSWF\(?:\s*|
-        'skip_download': (opts.skip_download or opts.simulate or any_printing),
+        'simulate': opts.simulate or any_printing,
-from .belgiannational import BelgianNationalIE
+from .vrt import VRTIE
-        }
+# coding: utf-8
-    }
+        # deredactie.be
-            'description': 'md5:dfac39636969fe6bf1caa2d50405f069',
+            'description': 'md5:37db8211e40b50c7c44e95da14f630b7',
-            'title': '5SOS STRUM ;)',
+            'title': '5SOS STRUM ;]',
-            video_thumbnail = video_thumbnail.replace('\\\\/', '/')
+        iframe_url = self._search_regex(
-             'ext': ext,
+            'url': video_url,
-                "duration": 143,
+                'id': '62986583',
-                'description': 'md5:0170be75dd395c96025d210d261c784e',
+                'description': 'md5:0053ca6396e8d2fd7b7e1595ef12ab66',
-            'description': 'Kauno miesto ir apskrities naujienos',
+            'description': 'md5:24d84534c7dc76581e59f5689462411a',
-        id = self._match_id(url)
+        video_id = self._match_id(url)
-        apiresponse = self._download_json("http://www.audiomack.com/api/music/url/song/"+id+"?_="+str(rightnow), id)
+        api_response = self._download_json(
-        if "url" not in apiresponse:
+        if "url" not in api_response:
-        realurl = apiresponse["url"]
+        realurl = api_response["url"]
-            }
+
-        video_url = path_doc.find('path').text
+        if info['formats'] == '1':
-    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console(?:\?(?:.*?[?&])?)id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console(?:\?(?:.*?[?&])?)id=(?P<id>[0-9a-z-]+)'
-            return sc._real_extract(realurl)
+            return {'_type': 'url', 'url': realurl, 'ie_key': 'Soundcloud'}
-# Xavier Beynon 2014
+from ..utils import ExtractorError
-            'file': 'Roosh Williams - Extraordinary.mp3',
+                'id' : 'roosh-williams/extraordinary',
-        id = url[url.index("/song/")+5:]
+        id = self._match_id(url)
-            raise Exception("Unable to deduce api url of song")
+        rightnow = int(time.time())
-                'id': title,  # ignore id, which is not useful in song name
+                'id': id,  # ignore id, which is not useful in song name
-__version__ = '2014.10.24'
+__version__ = '2014.10.25'
-                self.extract_info(url)
+                res = self.extract_info(url)
-    any_printing = opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.getduration or opts.dumpjson
+    any_printing = opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.getduration or opts.dumpjson or opts.dump_single_json
-        write_string('\n"info_dict": {' + info_dict_str + '}\n', out=sys.stderr)
+        write_string('\n"info_dict": {\n' + info_dict_str + '}\n', out=sys.stderr)
-import re
+from __future__ import unicode_literals
-    _VALID_URL = r'(?P<domain>https?://(?:www\.)?viddler\.com)/(?:v|embed|player)/(?P<id>[a-z0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?viddler\.com/(?:v|embed|player)/(?P<id>[a-z0-9]+)'
-            u"duration": 100.89,
+        "url": "http://www.viddler.com/v/43903784",
-            webpage, u'thumbnail', fatal=False)
+        video_id = self._match_id(url)
-            'duration': duration,
+            'title': data['title'],
-import json
+from __future__ import unicode_literals
-from ..utils import determine_ext
+
-    _VALID_URL = r'https?://www\.hark\.com/clips/(.+?)-.+'
+    _VALID_URL = r'https?://www\.hark\.com/clips/(?P<id>.+?)-.+'
-            u'duration': 11,
+        'url': 'http://www.hark.com/clips/mmbzyhkgny-obama-beyond-the-afghan-theater-we-only-target-al-qaeda-on-may-23-2013',
-        final_url = info['url']
+        video_id = self._match_id(url)
-                }
+        return {
-    int_or_none,
+    str_to_int,
-
+    def _real_extract(self, url):
-        video_url = self._html_search_regex(r'setup\(\{\s+"file".+: "([^"]+)",', webpage, 'video_url')
+        title = self._html_search_regex(
-        view_count = self._html_search_regex(r'<strong>Views</strong>\s+([^<]+)<', webpage, 'view_count')
+        view_count = str_to_int(self._html_search_regex(
-        upload_date = self._html_search_regex(r'<strong>Uploaded</strong>\s+([^<]+)<', webpage, 'upload_date')
+        upload_date = self._html_search_regex(
-        uploader_id = self._html_search_regex(r'"thumb-member-username">\s+<a href="/m/([^"]+)"', webpage, 'uploader_id')
+        uploader_id = self._html_search_regex(
-            'like_count': int_or_none(like_count.replace(',', '')),
+            'view_count': view_count,
-    _VALID_URL = r'http://(?:www\.)?motherless\.com/(?P<id>[A-Z0-9]+)'
+    _VALID_URL = r'http://(?:www\.)?motherless\.com/(?:g/[a-z0-9_]+/)?(?P<id>[A-Z0-9]+)'
-            'md5': '5527fef81d2e529215dad3c2d744a7d9',
+            'md5': '310f62e325a9fafe64f68c0bccb6e75f',
-                'ext': 'flv',
+                'ext': 'mp4',
-        """ Either "https:" or "https:", depending on the user's preferences """
+        """ Either "http:" or "https:", depending on the user's preferences """
-            'thumbnail' : 'http://dk608k4lm7m9j.cloudfront.net/3ee7da5af87065a1eeb8c6c9a864ba5b_2.jpg'
+            'thumbnail': 're:^https?://.*?\.cloudfront\.net/.*\.jpg$',
-        thumbnail_url = self._search_regex(r'<img id="video-thumbnail" src="(.*?)" alt="Video thumbnail">', webpage, 'thumbnail_url')
+        title = self._html_search_regex(
-            'thumbnail' : 'http:' + thumbnail_url
+            'url': video_url,
-        'md5': '5c4c4a8ca2281a199c8eefe8f411d630',
+        'url': 'http://vidzi.tv/cghql9yq6emu.html',
-            'id': 'm1chxrwq7bx9',
+            'id': 'cghql9yq6emu',
-            'title': 'Watch Cadbury Dream Factory S01E04 HDTV x264 FiHTV mp4',
+            'title': 'youtube-dl test video  1\\\\2\'3/4<5\\\\6Ã¤7â­',
-            r'<Title>([^<]+)<\/Title>', webpage, 'title')
+            r'(?s)<h2 class="video-title">(.*?)</h2>', webpage, 'title')
-import re
+from __future__ import unicode_literals
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        title = self._html_search_regex(r'<Title>([^<]+)<\/Title>', webpage, u'vidzi title')
+        webpage = self._download_webpage(url, video_id)
-
+from .vidzi import VidziIE
-        }
+#coding: utf-8
-__version__ = '2014.10.23'
+__version__ = '2014.10.24'
-            if result_type in ('url', 'url_transparent'):
+        if result_type in ('url', 'url_transparent'):
-            'title': 'story-i-tell'
+    IE_NAME = 'audiomack'
-    }
+    ]
-        data = json.loads(j)
+        #id is what follows /song/ in url, usually the uploader name + title
-        }   
+        #Call the api, which gives us a json doc with the real url inside
-            video_play_path = self._search_regex(r'<file>([^<]+)', streamdata, 'video_play_path')
+            streamdata = self._download_xml(
-                'play_path':   video_play_path,
+                'play_path': video_play_path,
-        info_url = compat_urllib_parse.urljoin(
+        info_url = compat_urlparse.urljoin(
-                assert ':' in default_search
+                if ':' not in default_search:
-__version__ = '2014.10.18'
+__version__ = '2014.10.23'
-        info_url = embed_data['flashvars']['host']
+        domain = embed_data['mediaUrl']
-            'http://token.mitele.es/?' + token_query, episode,
+            embed_data['flashvars']['ov_tk'] + '?' + token_query,
-        links = re.findall(r'<source src="([^"]+/v)\d+\.([^"]+)" type=\'video', webpage)
+        links = re.findall(r'<source src="([^"]+/v)[^"]+\.([^"]+)" type=\'video', webpage)
-            r'(?:<meta content|<iframe[^>]+?src)=(["\'])(?P<url>(?:https?:)?//(?:fast\.)?wistia\.net/embed/iframe/.+?)\1', webpage)
+            r'<(?:meta[^>]+?content|iframe[^>]+?src)=(["\'])(?P<url>(?:https?:)?//(?:fast\.)?wistia\.net/embed/iframe/.+?)\1', webpage)
-                'title': 'Conversation about Hexagonal Rails Part 1',
+                'title': 'Conversation about Hexagonal Rails Part 1 - ThoughtWorks',
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:fast\.)?wistia\.net/embed/iframe/.+?)\1', webpage)
+            r'(?:<meta content|<iframe[^>]+?src)=(["\'])(?P<url>(?:https?:)?//(?:fast\.)?wistia\.net/embed/iframe/.+?)\1', webpage)
-                    'preference': 2,
+                    'preference': -1,
-        mobj = re.search(r'src="(?P<embed_url>http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?id=(?:Cinemassacre-)?(?P<video_id>.+?))"', webpage)
+        mobj = re.search(r'src="(?P<embed_url>http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?[^"]*\bid=(?:Cinemassacre-)?(?P<video_id>.+?))"', webpage)
-        videolist_url = self._search_regex(r'file: \'([^\']+\.smil)\'}', playerdata, 'videolist_url')
+        vidurl = self._search_regex(
-        baseurl = sd_url[:sd_url.rfind('/')+1]
+        baseurl = vidurl[:vidurl.rfind('/')+1]
-
+            # tabbed frontline videos
-            return
+        if self._get_login_info()[0] is not None:
-        if re.search(r'rss=true', url):
+        if re.search(r'[\?&]rss($|[=&])', url):
-                formats.extend(self._extract_m3u8_formats(video_url, video_id))
+                formats.extend(self._extract_m3u8_formats(video_url, video_id, 'mp4'))
-    compat_str,
+        title = player_info['VTI'].strip()
-            'title': player_info['VTI'],
+            'title': title,
-           self._downloader.report_warning('unable to log in: will be downloading in non authorized mode')
+           self.to_screen('unable to log in: will be downloading in non authorized mode') # report_warning
-            self._downloader.report_warning('unable to log in: bad username or password')
+            self.to_screen('unable to log in: bad username or password') # report_warning
-            self._downloader.report_warning('Error code was: %s... but still trying' % info['err_code'][0])
+            self.to_screen('Error code was: %s... but still trying' % info['err_code'][0]) # report_warning
-            
+            self._downloader.report_warning('Error code was: %s... but still trying' % info['err_code'][0])
-            raise ExtractorError('No file path for download. Maybe not logged?')
+            raise ExtractorError('Cannot download file. Are you logged?')
-    _VALID_URL = r'^http://video\.fc2\.com/((?P<lang>[^/]+)/)?content/(?P<id>[^/]+)'
+    _VALID_URL = r'^http://video\.fc2\.com/((?P<lang>[^/]+)/)?(a/)?content/(?P<id>[^/]+)'
-        refer = url.replace('/content/', '/a/content/')
+        refer = (url if '/a/content/' in url else url.replace('/content/', '/a/content/'));
-            raise ExtractorError('Error code: %s' % info['err_code'][0])
+            #raise ExtractorError('Error code: %s' % info['err_code'][0])
-        all_formats = player_info['VSR'].values()
+        all_formats = []
-                'height': height,
+                'format_id': format_info['format_id'],
-from .crunchyroll import CrunchyrollIE
+from .crunchyroll import (
-        (?P<path>.+?/(?P<title>[^/]+?)(?:\.cnn|(?=&)))'''
+        (?P<path>.+?/(?P<title>[^/]+?)(?:\.cnn(-ap)?|(?=&)))'''
-    _VALID_URL = r'https?://(?:www\.)?sexykarma\.com/gonewild/video/(?P<display_id>[^/]+)-(?P<id>[a-zA-Z0-9]+)\.html'
+    IE_DESC = 'Sexy Karma and Watch Indian Porn'
-            'duration': 81,
+            'duration': 22,
-            'description': 'tribute',
+    }, {
-            webpage, 'url')
+            r"url: escape\('([^']+)'\)", webpage, 'url')
-            fatal=False, default='').split(',')
+        categories = re.findall(
-    JustinTVIE,
+    TwitchIE,
-        self.assertTrue(JustinTVIE.suitable('http://www.twitch.tv/tsm_theoddone/c/2349361'))
+    def test_twitch_channelid_matching(self):
-__version__ = '2014.10.15'
+__version__ = '2014.10.18'
-import datetime
+
-    _VALID_URL = r'https?://(?:www\.)?sexykarma\.com/gonewild/video/.+\-(?P<id>[a-zA-Z0-9\-]+)(.html)'
+    _VALID_URL = r'https?://(?:www\.)?sexykarma\.com/gonewild/video/(?P<display_id>[^/]+)-(?P<id>[a-zA-Z0-9]+)\.html'
-            'uploader_id': 'wildginger7',
+            'description': '',
-            'view_count': int,
+            'uploader': 'wildginger7',
-            'uploader_id': 'banffite',
+            'description': 'tribute',
-            'view_count': int,
+            'uploader': 'banffite',
-        video_id = self._match_id(url)
+        mobj = re.match(self._VALID_URL, url)
-        duration = self._to_seconds(str_duration)
+        uploader = self._html_search_regex(
-        # print view_count
+        duration = parse_duration(self._search_regex(
-        upload_date = d.strftime('%Y%m%d')
+        view_count = int_or_none(self._search_regex(
-        categories = re.findall(r'http://www.sexykarma.com/gonewild/search/video/(?:.+?)"><span>(.*?)</span>', webpage)
+        categories = self._html_search_meta(
-            'url': url,
+            'description': description,
-            'upload_date': upload_date,
+            'comment_count': comment_count,
-            entry['id'] = '%s_%d' % (entry['id'], num),
+            entry['id'] = '%s_%d' % (entry['id'], num)
-                'url': unescapeHTML(match.group('url')),
+                'url': embed_url,
-        match = re.search(r'(?:id=["\']wistia_|data-wistiaid=["\']|Wistia\.embed\(["\'])(?P<id>[^"\']+)', webpage)
+        match = re.search(r'(?:id=["\']wistia_|data-wistia-?id=["\']|Wistia\.embed\(["\'])(?P<id>[^"\']+)', webpage)
-        'md5': 'ecaa8a790c22a40770901460af191c9a',
+    _TESTS = [{
-    }
+            'id': 'a577357806',
-        return entries
+        return self.playlist_result(entries, info['id'], info['title'])
-from .justintv import JustinTVIE
+from .twitch import TwitchIE
-    """Information extractor for justin.tv and twitch.tv"""
+class TwitchIE(InfoExtractor):
-    _VALID_URL = r"""(?x)^(?:http://)?(?:www\.)?(?:twitch|justin)\.tv/
+    _VALID_URL = r"""(?x)^(?:http://)?(?:www\.)?twitch\.tv/
-    IE_DESC = 'justin.tv and twitch.tv'
+    _PAGE_LIMIT = 100
-        response = super(JustinTVIE, self)._download_json(url, video_id, note)
+        response = super(TwitchIE, self)._download_json(url, video_id, note)
-        elif mobj.group('chapterid'):
+        if mobj.group('chapterid'):
-        else:
+        elif mobj.group('videoid'):
-        }
+        elif mobj.group('channelid'):
-                    config_re = r'%s=({.+?});' % re.escape(m_variable_name.group(1))
+                    config_re = r'%s=({[^}].+?});' % re.escape(m_variable_name.group(1))
-        api_base = 'http://api.justin.tv'
+        api_base = 'http://api.twitch.tv'
-            chapter_id = mobj.group('chapterid')
+            return self._extract_media('c', mobj.group('chapterid'))
-            api = api_base + '/broadcast/by_archive/%s.json' % video_id
+            return self._extract_media('a', mobj.group('videoid'))
-
+import re
-    _VALID_URL = r'https?://(?:www\.)?sexykarma\.com/gonewild/video/(?P<id>[a-zA-Z0-9\-]+)(.html)'
+    _VALID_URL = r'https?://(?:www\.)?sexykarma\.com/gonewild/video/.+\-(?P<id>[a-zA-Z0-9\-]+)(.html)'
-            'id': 'taking-a-quick-pee-yHI70cOyIHt',
+            'id': 'yHI70cOyIHt',
-            'uploader': 'wildginger7',
+            'uploader_id': 'wildginger7',
-            'id': 'pot-pixie-tribute-8Id6EZPbuHf',
+            'id': '8Id6EZPbuHf',
-            'uploader': 'banffite',
+            'uploader_id': 'banffite',
-        # TODO more code goes here, for example ...
+              
-        uploader = self._html_search_regex(r'class="aupa">\n*(.*?)</a>', webpage, 'uploader')
+        uploader_id = self._html_search_regex(r'class="aupa">\n*(.*?)</a>', webpage, 'uploader')
-            'url': url
+            'uploader_id': uploader_id,
-            return self.url_result(surl, 'Vimeo')
+            return self.url_result(surl)
-            r'<embed[^>]+?src="(https?://(?:www\.)?vimeo\.com/moogaloop\.swf.+?)"', webpage)
+            r'<embed[^>]+?src="((?:https?:)?//(?:www\.)?vimeo\.com/moogaloop\.swf.+?)"', webpage)
-            return self.url_result(mobj.group(1), 'Vimeo')
+            return self.url_result(mobj.group(1))
-__version__ = '2014.10.13'
+__version__ = '2014.10.15'
-                errnote='Failed to download song information')
+            
-        for url in url_list:
+    def _get_url(self, track_id, template_url):
-                self._request_webpage(HEADRequest(url), None, False)
+                self._request_webpage(
-                url = None
+                pass
-        final_song_url = self._get_url(template_url)
+        final_song_url = self._get_url(track_id, template_url)
-            final_song_url = self._get_url(template_url)
+            final_song_url = self._get_url(track_id, template_url)
-__version__ = '2014.10.12'
+__version__ = '2014.10.13'
-        args = ['-c', 'copy']
+        args = ['-c', 'copy', '-map', '0:v:0', '-map', '1:a:0', '-shortest']
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-            r'<title>(.+?) - Ð¢ÑÑÐ±Ð° Ð·Ð¾Ð²ÑÑ - ÐÐ½ÑÐµÑÐµÑÐ½ÑÐ¹ Ð²Ð¸Ð´ÐµÐ¾ÑÐ¾ÑÑÐ¸Ð½Ð³</title>', webpage, 'video title')
+            r'<title>(.+?)</title>', webpage, 'video title')
-        if (self._downloader.params.get('youtube_include_dash_manifest', False)):
+        if self._downloader.params.get('youtube_include_dash_manifest', True):
-        help='Try to download the DASH manifest on YouTube videos (experimental)')
+    video_format.add_option(
-        if option.takes_value(): opts.append(' %s' % option.metavar)
+        if option.takes_value():
-                opts[i+1] = 'PRIVATE'
+                opts[i + 1] = 'PRIVATE'
-    if columns: max_width = columns
+    max_width = columns if columns else 80
-        'conflict_handler' : 'resolve',
+        'version': __version__,
-            help='Output descriptions of all supported extractors', default=False)
+    general = optparse.OptionGroup(parser, 'General Options')
-        '--proxy', dest='proxy', default=None, metavar='URL',
+        '--list-extractors',
-        type=float, default=None, help=u'Time to wait before giving up, in seconds')
+        '--socket-timeout',
-        '--datebefore', metavar='DATE', dest='datebefore', default=None,
+        '--match-title',
-        '--dateafter', metavar='DATE', dest='dateafter', default=None,
+        '--dateafter',
-        help="Do not download any videos with less than COUNT views",)
+        '--min-views',
-                         help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')
+        '--max-views',
-        action='store_true',
+        '--no-playlist',
-        dest='youtube_include_dash_manifest', default=False,
+        '--youtube-include-dash-manifest',
-
+    authentication = optparse.OptionGroup(parser, 'Authentication Options')
-        '--encoding', dest='encoding', metavar='ENCODING',
+        '--encoding',
-        dest='no_check_certificate', default=False,
+        '--no-check-certificate',
-        '--prefer-insecure', '--prefer-unsecure', action='store_true', dest='prefer_insecure',
+        '--prefer-insecure',
-        dest='user_agent', help='specify a custom user agent')
+        '--user-agent',
-        dest='referer', default=None,
+        '--referer',
-        dest='headers', action='append',
+        '--add-header',
-        help=u'Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')
+        '--bidi-workaround',
-            action='store_true', dest='quiet', help='activates quiet mode', default=False)
+    verbosity = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')
-            dest='cookiefile', metavar='FILE', help='file to read cookies from and dump cookie jar in')
+    verbosity.add_option(
-        '--rm-cache-dir', action='store_true', dest='rm_cachedir',
+        '--rm-cache-dir',
-    postproc.add_option('--prefer-avconv', action='store_false', dest='prefer_ffmpeg',
+    postproc = optparse.OptionGroup(parser, 'Post-processing Options')
-    postproc.add_option('--prefer-ffmpeg', action='store_true', dest='prefer_ffmpeg',
+    postproc.add_option(
-        '--exec', metavar='CMD', dest='exec_cmd',
+        '--exec',
-            write_string(u'[debug] Override config: ' + repr(overrideArguments) + '\n')
+            write_string('[debug] Override config: ' + repr(overrideArguments) + '\n')
-            write_string(u'[debug] Command-line args: ' + repr(_hide_login_info(commandLineConf)) + '\n')
+            write_string('[debug] System config: ' + repr(_hide_login_info(systemConf)) + '\n')
-            dest='username', metavar='USERNAME', help='account username')
+            dest='username', metavar='USERNAME', help='login with this account ID')
-__version__ = '2014.10.05.2'
+__version__ = '2014.10.12'
-    _AUTHENTICATE = False
+    # Determine whether the downloader used authentication to download video
-            self._login()
+        self._login()
-        if self._AUTHENTICATE:
+        if self._AUTHENTICATED:
-                'description': 'md5:16d4d66907f541692e8182c33270f29a',
+                'description': 'md5:48c4c04dde604c8a9971b3d4e3b9eaa8',
-                expected=True)
+                'No sources found for video %s' % video_id, expected=True)
-            r'<div class="cloudcast-play-button-container"'
+            r'<div class="cloudcast-play-button-container[^"]*?"'
-        (?P<proto>(?:https?:)?//)?
+        https?://
-import datetime
+import codecs
-)
+from ..utils import unified_strdate
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        upload_date = self._html_search_regex(
+        title = self._og_search_description(webpage).splitlines()[0]
-        video_title = self._og_search_description(webpage).splitlines()[0]
+            webpage, 'upload date', fatal=False, flags=re.VERBOSE))
-        video_page = self._search_regex(r'<a href="((?:%s)?photos/.*?)"' % re.escape(DOMAIN),
+        video_page = self._search_regex(
-        links = sorted(mobj)
+        def unicode_escape(s):
-            video_url = bytes(video_url, 'ascii').decode('unicode-escape')
+        # Extract video links all sizes
-            'url': video_url,
+            'title': title,
-            'ext': 'flv',
+            'formats': formats,
-        pattern = r'\d+,\d+,(\d+),"(http\://redirector\.googlevideo\.com.*?)"'
+        pattern = r'\d+,\d+,(\d+),"(https\://redirector\.googlevideo\.com.*?)"'
-            'url': 'http://adventure.howstuffworks.com/39516-deadliest-catch-jakes-farewell-pots-video.htm',
+            'url': 'http://adventure.howstuffworks.com/7199-survival-zone-food-and-water-in-the-savanna-video.htm',
-                'display_id': 'deadliest-catch-jakes-farewell-pots',
+                'id': '453464',
-                'description': 'md5:9632c346d5e43ee238028c9cefd8dbbc',
+                'title': 'Survival Zone: Food and Water In the Savanna',
-            'md5': '4a4eeafd17c3058b65f0c8f091355855',
+            'url': 'http://www.ndr.de/fernsehen/sendungen/nordmagazin/Kartoffeltage-in-der-Lewitz,nordmagazin25866.html',
-                'id': '325',
+                'id': '25866',
-            },
+                'title': 'Kartoffeltage in der Lewitz',
-    YahooNewsIE,
+    #YahooNewsIE,
-    _VALID_URL = r'(?P<url>https?://(?:.+?\.)?(?:screen|movies)\.yahoo\.com/.*?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html)'
+    _VALID_URL = r'(?P<url>(?P<host>https?://(?:[a-zA-Z]{2}\.)?[\da-zA-Z_-]+\.yahoo\.com)/(?:[^/]+/)*(?P<display_id>.+?)-(?P<id>[0-9]+)(?:-[a-z]+)?\.html)'
-            'url': 'https://uk.screen.yahoo.com/editor-picks/cute-raccoon-freed-drain-using-091756545.html  ',
+            'url': 'https://uk.screen.yahoo.com/editor-picks/cute-raccoon-freed-drain-using-091756545.html',
-        video_id = mobj.group('id')
+        display_id = mobj.group('display_id')
-        webpage = self._download_webpage(url, video_id)
+        host = mobj.group('host')
-            video_id = long_id
+            video_id = self._search_regex(CONTENT_ID_REGEXES, webpage, 'content ID')
-        return self._get_info(long_id, video_id, webpage)
+            video_id = info['id']
-    def _get_info(self, long_id, video_id, webpage):
+    def _get_info(self, video_id, display_id, webpage):
-            r'"region"\s*:\s*"([^"]+)"', webpage, 'region', fatal=False, default='US')
+            r'\\?"region\\?"\s*:\s*\\?"([^"]+?)\\?"',
-                 ' AND protocol="http"' % (long_id, region))
+                 ' AND protocol="http"' % (video_id, region))
-            video_id, 'Downloading video info')
+            display_id, 'Downloading video info')
-        meta = info['meta']
+        meta = info.get('meta')
-
+# coding: utf-8
-    _VALID_URL = r'(?P<url>https?://(?:screen|movies)\.yahoo\.com/.*?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html)'
+    _VALID_URL = r'(?P<url>https?://(?:.+?\.)?(?:screen|movies)\.yahoo\.com/.*?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html)'
-                'description': 'Agent Topple\'s mustache does its dirty work, and Nicole brokers a deal for peace. But why is the NSA collecting millions of Instagram brunch photos? And if your waffles have nothing to hide, what are they so worried about?',
+                'description': 'md5:66b627ab0a282b26352136ca96ce73c1',
-                 ' AND protocol="http"' % long_id)
+                 ' AND plrs="86Gj0vCaSzV_Iuf6hNylf2" AND region="%s"'
-                and not params['restrictfilenames']):
+                and not params.get('restrictfilenames', False)):
-                'cannot encode all charactes. '
+                'cannot encode all characters. '
-class TestWallsSubtitles(BaseTestSubtitles):
+class TestWallaSubtitles(BaseTestSubtitles):
-            detail, './thumbnailScenarios/thumbnailScenario', 'type', '45').text
+        thumbnails = [{
-            'thumbnail': thumbnail,
+            'thumbnails': thumbnails,
-        found = re.findall(r'flashvars: [\'"](?:.*&)?file=(http[^\'"&]*)', webpage)
+        found = filter_video(re.findall(r'flashvars: [\'"](?:.*&)?file=(http[^\'"&]*)', webpage))
-            found = re.findall(r'''(?sx)
+            found = filter_video(re.findall(r'''(?sx)
-                .*?file\s*:\s*["\'](.*?)["\']''', webpage)
+                .*?file\s*:\s*["\'](.*?)["\']''', webpage))
-            found = re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\'"&]*)', webpage)
+            found = filter_video(re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\'"&]*)', webpage))
-            found = re.findall(r'[^A-Za-z0-9]?file["\']?:\s*["\'](http(?![^\'"]+\.[0-9]+[\'"])[^\'"]+)["\']', webpage)
+            found = filter_video(re.findall(
-            found = re.findall(r'''(?xs)
+            found = filter_video(re.findall(r'''(?xs)
-            ''', webpage)
+            ''', webpage))
-            found = re.findall(r'<meta (?:property|name)="twitter:player:stream" (?:content|value)="(.+?)"', webpage)
+            found = filter_video(re.findall(
-                    re.findall(r'<meta.*?property="og:video".*?content="(.*?)"', webpage)))
+                found = filter_video(re.findall(r'<meta.*?property="og:video".*?content="(.*?)"', webpage))
-from ..utils import int_or_none
+from ..utils import (
-    _VALID_URL = r'http://(?:www\.)?pornhd\.com/(?:[a-z]{2,4}/)?videos/(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www\.)?pornhd\.com/(?:[a-z]{2,4}/)?videos/(?P<id>\d+)(?:/(?P<display_id>.+))?'
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id or video_id)
-            })
+        quality = qualities(['SD', 'HD'])
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-    _VALID_URL = r'http://vod\.walla\.co\.il/\w+/(?P<id>\d+)'
+class WallaIE(SubtitlesInfoExtractor):
-        
+        display_id = mobj.group('display_id')
-        default_quality = self._html_search_regex(r'<qualities defaultType="(\d+)">', webpage, video_id, 0)
+        video = self._download_xml(
-        quality = default_quality if default_quality else '40'
+        item = video.find('./items/item')
-        playpath = 'mp4:media/%s/%s/%s-%s' % (series, session, media_id, quality) #self._html_search_regex(r'<quality type="%s">.*<src>(.*)</src>' % default_quality ,webpage, '', flags=re.DOTALL) 
+        title = xpath_text(item, './title', 'title')
-            subtitles['heb'] = subtitles_page
+        for subtitle in item.findall('./subtitles/subtitle'):
-            'ext': 'flv',
+            'description': description,
-        }
+        }
-__version__ = '2014.10.05.1'
+__version__ = '2014.10.05.2'
-__version__ = '2014.10.05'
+__version__ = '2014.10.05.1'
-
+        video_id = self._match_id(url)
-            view_count = str_to_int(view_count)
+        view_count = str_to_int(self._search_regex(
-            'id':       video_id,
+            'id': video_id,
-            'subtitles':    video_subtitles,
+            'upload_date': video_upload_date,
-            'title': 'Rebecca Black My Moment Official Music Video Reaction',
+            'title': 'Rebecca Black My Moment Official Music Video Reaction-6GK87Rc8bzQ',
-        url = self._search_regex(r'file: \'(http[^\']+)\',', webpage, 'file url')
+        title = self._search_regex(r'style="z-index: [0-9]+;">([^<]+)</span>', webpage, 'title')
-            'ext': determine_ext(url),
+            'url': video_url,
-__version__ = '2014.10.02'
+__version__ = '2014.10.05'
-    IE_DESC = 'GorillaVid.in and daclips.in'
+    IE_DESC = 'GorillaVid.in, daclips.in and movpod.in'
-            (?:daclips\.in|gorillavid\.in))/
+            (?:daclips\.in|gorillavid\.in|movpod\.in))/
-        return 0
+        return None
-    return int(m.group('age')) if m else US_RATINGS.get(s, 0)
+    return int(m.group('age')) if m else US_RATINGS.get(s, None)
-        video_url = info['videoUri']
+
-        final_url = video_url + '?' + info['AuthToken']
+        formats = [{
-            'url': final_url,
+            'duration': duration,
-    _TEST = {
+    _VALID_URL = r'http://(?:www\.)?break\.com/video/(?:[^/]+/)*.+-(?P<id>\d+)'
-        'md5': 'a3513fb1547fba4fb6cfac1bffc6c46b',
+        'md5': '33aa4ff477ecd124d18d7b5d23b87ce5',
-    }
+    }, {
-        info = json.loads(info_json)
+        video_id = self._match_id(url)
-__version__ = '2014.09.29.2'
+__version__ = '2014.10.02'
-            "duration": 9.8485,
+            'id': '1812978515',
-            webpage, re.MULTILINE | re.DOTALL).group('id')
+        video_id = self._search_regex(
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        upload_date = self._html_search_regex(
+        upload_date = unified_strdate(self._html_search_regex(
-            upload_date = unified_strdate(upload_date)
+            fatal=False))
-    _VALID_URL = r'https?://(?:www\.)?jpopsuki\.tv/(category/)?video/(.*?)/(?P<id>\S+)'
+    _VALID_URL = r'https?://(?:www\.)?jpopsuki\.tv/(?:category/)?video/[^/]+/(?P<id>\S+)'
-        'file': '00be659d23b0b40508169cdee4545771.mp4',
+            'ext': 'mp4',
-            ('?' if '?' in url else '&') + 'dl=1')
+        video_url = re.sub(r'[?&]dl=0', '', url)
-    _VALID_URL = r'https?://(?:www\.)?jpopsuki\.tv/video/(.*?)/(?P<id>\S+)'
+    _VALID_URL = r'https?://(?:www\.)?jpopsuki\.tv/(category/)?video/(.*?)/(?P<id>\S+)'
-                _, _, yt_id = song['filename'].split('/')
+                self.to_screen('YouTube video detected')
-        thumbnail = self._og_search_thumbnail(webpage)
+        thumbnail = self._proto_relative_url(
-            r'playerData\.screenShot\s*=\s*"([^"]+)"',
+            r'playerData\.screenShot\s*=\s*["\']([^"\']+)["\']',
-            re.findall(r'playerData\.cdnPath[0-9]{3,}\s*=\s*"([^"]+)', webpage)))
+            re.findall(r'playerData\.cdnPath[0-9]{3,}\s*=\s*["\']([^"\']+)["\']', webpage)))
-            r'<span>Duration: (\d+:\d+)</span>', webpage, 'duration', fatal=False))
+            r'Duration:\s*(\d+:\d+)\s*<', webpage, 'duration', fatal=False))
-            r'<span class="views">(\d+)</span>', webpage, 'view count', fatal=False))
+            r'class="views">\s*(\d+)\s*<', webpage, 'view count', fatal=False))
-# otherwise this results in issues like #3854 #2918 #3217
+    # Environment variables should be decoded with filesystem encoding.
-            userhome = os.path.join(drive, compat_getenv('HOMEPATH'))
+    # HACK: The default implementations of os.path.expanduser from cpython do not decode
-            userhome = os.path.join(os.path.dirname(userhome), path[1:i])
+            if i != 1: #~user
-        return userhome + path[i:]
+            return userhome + path[i:]
-    def test_js_to_json(self):
+    def test_js_to_json_realworld(self):
-                'clip':{'provider':'pseudo'}
+            'clip':{'provider':'pseudo'}
-                "clip":{"provider":"pseudo"}
+            "clip":{"provider":"pseudo"}
-            raise ExtractorError('Failed to download JSON', cause=ve)
+            errmsg = '%s: Failed to parse JSON ' % video_id
-        return m.group(1) + key + m.group(3) + value
+        v = m.group(0)
-            )
+        "(?:[^"\\]*(?:\\\\|\\")?)*"|
-            ([0-9.]+|true|false|"[^"]*"|\'[^\']*\'|\[|\{)
+            ([0-9.]+|true|false|"[^"]*"|\'[^\']*\'|
-    compat_urllib_parse,
+    compat_urllib_parse_urlparse,
-            parts = compat_urllib_parse.urlparse(cdn_data.get('uri'))
+            parts = compat_urllib_parse_urlparse(cdn_data.get('uri'))
-            tmpl = os.path.expanduser(outtmpl)
+            tmpl = compat_expanduser(outtmpl)
-    download_archive_fn = os.path.expanduser(opts.download_archive) if opts.download_archive is not None else opts.download_archive
+    download_archive_fn = compat_expanduser(opts.download_archive) if opts.download_archive is not None else opts.download_archive
-        return os.path.expanduser(res)
+        return compat_expanduser(res)
-        xdg_config_home = os.environ.get('XDG_CONFIG_HOME')
+        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')
-            userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl', 'config')
+            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')
-                userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl.conf')
+                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')
-            appdata_dir = os.environ.get('appdata')
+            appdata_dir = compat_getenv('appdata')
-                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf'),
+                os.path.join(compat_expanduser('~'), 'youtube-dl.conf'),
-                os.path.join(os.path.expanduser('~'), 'youtube-dl.conf.txt'),
+                os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'),
-        encoding = 'utf-8'
+    encoding = get_filesystem_encoding()
-    columns = os.environ.get('COLUMNS', None)
+    columns = compat_getenv('COLUMNS', None)
-            'md5': '72cb7eab33e54314e1790da402d3c9c3',
+            'url': 'http://www.tvigle.ru/video/brat/',
-                'display_id': 'brat-2',
+                'id': '5118490',
-                'age_limit': 0,
+                'title': 'ÐÑÐ°Ñ',
-                'ext': 'mp4',
+                'ext': 'flv',
-                'ext': 'mp4',
+                'ext': 'flv',
-            webpage, 'description', fatal=False)
+            r'(?s)<div\s+class="[^"]*description[^"]*"[^>]*>(.*?)</div>',
-        sys.stderr.write('\n"info_dict": ' + json.dumps(test_info_dict, ensure_ascii=False, indent=4) + '\n')
+        def _repr(v):
-        _msg_header = u'\033[0;33mWARNING:\033[0m'
+        _msg_header = '\033[0;33mWARNING:\033[0m'
-    output = u'%s %s\n' % (_msg_header, message)
+        _msg_header = 'WARNING:'
-                u'Expected a %s object, but got %s for field %s' % (
+                'Expected a %s object, but got %s for field %s' % (
-                u'field %s (value: %r) should match %r' % (info_field, got, match_str))
+                'field %s (value: %r) should match %r' % (info_field, got, match_str))
-                u'Expected type %r for field %s, but got value %r of type %r' % (expected, info_field, got, type(got)))
+                'Expected type %r for field %s, but got value %r of type %r' % (expected, info_field, got, type(got)))
-                u'invalid value for field %s, expected %r, got %r' % (info_field, expected, got))
+                'invalid value for field %s, expected %r, got %r' % (info_field, expected, got))
-        self.assertTrue(got_dict.get(key), u'Missing field: %s' % key)
+        self.assertTrue(got_dict.get(key), 'Missing field: %s' % key)
-        sys.stderr.write(u'\n"info_dict": ' + json.dumps(test_info_dict, ensure_ascii=False, indent=4) + u'\n')
+        sys.stderr.write('\n"info_dict": ' + json.dumps(test_info_dict, ensure_ascii=False, indent=4) + '\n')
-                    <a\s+href="fblike'|<div\s+class="social">
+                    <a\s+href="fblike|<div\s+class="social">
-        webpage = io.open('922692425_http_-_m.vuclip.com_wcid=922692425_fid=70295_z=1010_nvar_frm=index.html.dump', encoding='utf-8').read()
+        webpage = self._download_webpage(url, video_id)
-        title = self._html_search_regex(r'<h1>([^<]+)', webpage, 'title')
+        title = self._html_search_regex(
-            r'<div\s+id="descriptionContent">([^<]+)<', webpage, 'description', fatal=False)
+            r'<div\s+id="descriptionContent">([^<]+)<',
-            r'flashvars\.image_url = "([^"]+)', webpage, 'thumbnail', fatal=False)
+            r'playerData\.screenShot\s*=\s*"([^"]+)"',
-            r'by:\s*<a [^>]*>(.+?)</a>', webpage, 'uploader', fatal=False)
+            r'by:\s*<a [^>]*>(.+?)</a>',
-            r'<span id="spCommentCount">\s*(\d+)</span> Comments</div>', webpage, 'comment count', fatal=False))
+            r'by:\s*<a href="/Profile\.aspx\?.*?UserId=(\d+).*?"',
-        video_urls = list(map(compat_urllib_parse.unquote , re.findall(r'flashvars\.quality_[0-9]{3}p = "([^"]+)', webpage)))
+        view_count = str_to_int(self._html_search_regex(
-            video_urls = list(map(lambda s: aes_decrypt_text(s, password, 32).decode('utf-8'), video_urls))
+            password = self._html_search_regex(
-        'md5': '92ac9d1ccefec4f0bb474661ab144fcf',
+        'url': 'http://m.vuclip.com/w?cid=922692425&fid=70295&z=1010&nvar&frm=index.html',
-            'id': '843902317',
+            'id': '922692425',
-            'duration': 139,
+            'title': 'The Toy Soldiers - Hollywood Movie Trailer',
-        webpage = self._download_webpage(url, video_id)
+        #webpage = self._download_webpage(url, video_id)
-            'links')
+            r'''(?xs)
-                r'<a href="(?P<url>[^"]+)".*?>(?P<q>[^<]+)</a>', links_code):
+                r'<a\s+href="(?P<url>[^"]+)".*?>(?:<button[^>]*>)?(?P<q>[^<]+)(?:</button>)?</a>', links_code):
-            r'\(([0-9:]+)\)</span></h1>', webpage, 'duration', fatal=False))
+            r'\(([0-9:]+)\)</span>', webpage, 'duration', fatal=False))
-        {
+        self.assertEqual(unified_strdate('28/01/2014 21:00:00 +0100'), '20140128')
-            'upload_date': unified_strdate(player_info.get('VDA', '').split(' ')[0]),
+            'upload_date': unified_strdate(upload_date_str),
-            'duration': 153,
+            'duration': 149,
-            u'duration': 153,
+        'url': 'http://video.internetvideoarchive.net/flash/players/flashconfiguration.aspx?customerid=69249&publishedid=452693&playerid=247',
-            u'Downloading flash configuration')
+            'Downloading flash configuration')
-            u'Downloading video info')
+            'Downloading video info')
-        'md5': 'ff4d83318f89776ed0250634cfaa8d36',
+        'md5': '29f4c5e5a61ca39dfd7e8348a75d0aad',
-                'description': 'md5:8ba6301e70351ae0bedf8da00f7ba528',
+                'description': 'Romantischer Kurztrip zum Valentinstag? Wir verraten, was sich hier wirklich lohnt.',
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        clip_id = self._html_search_regex(self._CLIPID_REGEXES, page, 'clip id')
+        clip_id = self._html_search_regex(self._CLIPID_REGEXES, webpage, 'clip id')
-        thumbnail = self._og_search_thumbnail(page)
+        title = self._html_search_regex(self._TITLE_REGEXES, webpage, 'title')
-            self._UPLOAD_DATE_REGEXES, page, 'upload date', default=None))
+            self._UPLOAD_DATE_REGEXES, webpage, 'upload date', default=None))
-    _VALID_URL = r'^http://www\.jukebox?\..+?\/.+[,](?P<video_id>[a-z0-9\-]+)\.html'
+    _VALID_URL = r'^http://www\.jukebox?\..+?\/.+[,](?P<id>[a-z0-9\-]+)\.html'
-        video_id = mobj.group('video_id')
+        video_id = self._match_id(url)
-        'md5': '3b427ae4b9d60619106de3185c2987cd',
+        'md5': '39d486f046212d8e1b911c52ab4691f8',
-            'ext': 'flv',
+            'ext': 'mp4',
-        thumbnail = config.find('.//image').text
+        video_url = config.find('file').text
-        title = media.find('.//title').text
+        title = media.find('title').text
-        for e in config.findall('./*[url]'):
+        for e in config:
-        for e in config.findall('.//teaser[url]'):
+        for e in config.findall('.//teaser'):
-        display_id = mobj.group('id')
+        display_id = self._match_id(url)
-            'title': 'Did you know Kei Nishikori is the first Asian man to ever reach a Grand Slam fin...',
+            'title': 're:Did you know Kei Nishikori is the first Asian man to ever reach a Grand Slam',
-            'title': 'LIVE: Li-Ning Badminton Weltmeisterschaft 2014 Kopenhagen',
+            'title': 're:Li-Ning Badminton Weltmeisterschaft 2014 Kopenhagen',
-            'description': 're:^Die Badminton-WM 2014 aus Kopenhagen LIVE',
+            'description': 're:Die Badminton-WM 2014 aus Kopenhagen bei Sportdeutschland\.TV',
-            'md5': '002b44ee2f33d50363a1c153bed524cf',
+            'md5': '4b29cb57c3dddd57642b3f051f535b07',
-            'md5': '6455046ae1b48cf7e2b7cae285e53a16',
+            'md5': '8194c2ea221e9a639cac96b6b0753dc5',
-        
+        video_id = self._match_id(url)
-            'md5': 'deeeabcc1085eb2ba205474e7235a3d5',
+            'md5': '65fdff94098e4a607385a60c5177c638',
-                'id': '981',
+                'id': '1969',
-                'description': 'md5:ddb2a40ecd6b6a147e400e535874947b',
+                'title': 'Hidden miracles of the natural world',
-                'id': 'jpSGZsgga_I',
+                'id': '4vAffPZIT44',
-                'title': 'Asphalt 8: Airborne - Launch Trailer',
+                'title': 'Asphalt 8: Airborne - Update - Welcome to Dubai!',
-                'description': 'md5:87bd95f13d8be3e7da87a5f2c443106a',
+                'upload_date': '20140828',
-            'title': talk_info['title'],
+            'title': talk_info['title'].strip(),
-                return [self.url_result(u, ie='IGN') for u in multiple_urls]
+                entries = [self.url_result(u, ie='IGN') for u in multiple_urls]
-            "title": "Video: KO Of The Week: MMA Fighter Gets Knocked Out By Swift Head Kick!"
+            "title": "KO Of The Week: MMA Fighter Gets Knocked Out By Swift Head Kick!"
-        video_id = m.group('id')
+        video_id = self._match_id(url)
-                              webpage_src)
+        m_vevo_id = re.search(r'videoId=(.*?)&amp?', webpage)
-            r'so\.addVariable\("file","(.*?)"\)', webpage_src, 'video URL')
+            r'so\.addVariable\("file","(.*?)"\)', webpage, 'video URL')
-            r"<title>(.*)</title>", webpage_src, 'title')
+            r'(?s)<div class="content-heading">\s*<h1>(.*?)</h1>',
-            r'rel="image_src" href="(.*)" />', webpage_src, 'thumbnail',
+            r'rel="image_src" href="(.*)" />', webpage, 'thumbnail',
-            mobj = re.search(_title, webpage_src)
+            _title = r'candytitles.*>(.*)</span>'
-                raise
+        video_description = self._html_search_regex(
-__version__ = '2014.09.29.1'
+__version__ = '2014.09.29.2'
-           (?:www\.)?pbs\.org/(?:[^/]+/){2,5}(?P<presumptive_id>[^/]+)/?(?:$|[?\#]) |
+           # Direct video URL
-    def _extract_ids(self, url):
+    def _extract_webpage(self, url):
-                return media_id, presumptive_id
+                return media_id, presumptive_id, upload_date
-        return video_id, display_id
+        return video_id, display_id, None
-        video_id, display_id = self._extract_ids(url)
+        video_id, display_id, upload_date = self._extract_webpage(url)
-__version__ = '2014.09.29'
+__version__ = '2014.09.29.1'
-        video_webpage = self._download_webpage(req, video_id)
+        pref_cookies = [
-__version__ = '2014.09.28.1'
+__version__ = '2014.09.29'
-        video_webpage = self._download_webpage(url, video_id)
+        req = compat_urllib_request.Request(url)
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        list_title = self._html_search_regex(r'<h1 class="show_title">(.*?)<b id', webpage, 'playlist title')
+        playlist_id = self._match_id(url)
-        return self.playlist_result(entries, list_id, list_title)
+        return self.playlist_result(entries, playlist_id, list_title)
-    PagedList,
+    OnDemandPagedList,
-            pl = PagedList(get_page, pagesize)
+            pl = OnDemandPagedList(get_page, pagesize)
-    get_element_by_attribute,
+    compat_urlparse,
-    _VALID_URL = r'https?://(?:www\.)?vimeo\.com/user(?P<id>[0-9]+)/likes(?:$|[?#])'
+    _VALID_URL = r'https?://(?:www\.)?vimeo\.com/user(?P<id>[0-9]+)/likes/?(?:$|[?#]|sort:)'
-        'add_ies': ['Generic'],
+        'url': 'https://vimeo.com/user755559/likes/',
-            'extract_flat': False,
+            "description": "See all the videos urza likes",
-        })
+        webpage = self._download_webpage(url, user_id)
-            'url': surl,
+            '_type': 'playlist',
-    PagedList,
+    OnDemandPagedList,
-        url_results = PagedList(download_page, self._GDATA_PAGE_SIZE)
+        url_results = OnDemandPagedList(download_page, self._GDATA_PAGE_SIZE)
-
+
-                opts[i+1] = '<PRIVATE>'
+                opts[i+1] = 'PRIVATE'
-from .thvideo import THVideoIE
+from .thvideo import (
-            'thumbnail': 're:^https?://.*\.jpg$',
+    _VALID_URL = r'''(?x)https?://
-        video_id = mobj.group('id')
+        video_id, host = mobj.group('id'), mobj.group('host')
-        video_data = self._download_json(url_template.format(id=video_id), video_id)
+        webpage = self._download_webpage(url, video_id)
-            raise ExtractorError('Failed to get CDN data', expected=True)
+        config_url = NFLIE.prepend_host(host, self._search_regex(
-
+        cdn_data = video_data.get('cdnData', {})
-                if not path:
+                formats.append(
-                })
+                prefix = cdn.get('pathprefix', '')
-        # 'md5': '5eb8c40a727dda106d510e5d6ffa79e5',  # md5 checksum fluctuates
+        'md5': '394ef771ddcd1354f665b471d78ec4c6',
-            'title': 'Week 3: Washington Redskins vs. Philadelphia Eagles highlights',
+            'title': 'Week 3: Redskins vs. Eagles highlights',
-            elif 'prog' in name.lower():
+            elif 'prog' in name.lower():
-            'title': video_data.get('storyHeadline'),
+            'title': video_data.get('headline'),
-__version__ = '2014.09.28'
+__version__ = '2014.09.28.1'
-            if is_playlist and res_dict is not None:
+            if is_playlist and res_dict is not None and res_dict.get('entries'):
-    VimeoUserIE,
+    VimeoChannelIE,
-
+        is_intentional = smuggled_data and smuggled_data.get('to_generic')
-    _VALID_URL = r'https?://played\.to/(?P<id>[a-zA-Z0-9_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?played\.to/(?P<id>[a-zA-Z0-9_-]+)'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        fields = re.findall(r'type="hidden" name="(.+?)"\s* value="?(.+?)">', orig_webpage)
+        fields = re.findall(
-        time.sleep(2)
+        self._sleep(2, video_id)
-        }
+        }
-import json
+            'thumbnail': 're:^https?://.*\.jpg$'
-    )
+    _VALID_URL = r'''(?x)
-            'Owncloud-Tastaturen-Peilsender-Smartphone-2404147.html'
+            'http://www.heise.de/video/artikel/Podcast-c-t-uplink-3-3-Owncloud-Tastaturen-Peilsender-Smartphone-2404147.html'
-                "Peilsender Smartphone"
+                "Podcast: c't uplink 3.3 â Owncloud / Tastaturen / Peilsender Smartphone"
-        self._id = mobj.group('id')
+        video_id = self._match_id(url)
-        config = self._download_json(self._parse_config_url(html), self._id)
+        webpage = self._download_webpage(url, video_id)
-            'id': self._id
+            'id': video_id,
-        title = get_meta_content('fulltitle', html)
+        title = get_meta_content('fulltitle', webpage)
-            raise ExtractorError('No formats found')
+            info['title'] = self._og_search_title(webpage)
-                self._warn('formats: {0}: no resolutions', t)
+                self._downloader.report_warning(
-                format_id = '{0}_{1}'.format(t, res)
+            for height_str, obj in rs.items():
-                    self._warn('formats: {0}: no url', format_id)
+                    self._downloader.report_warning(
-                fmt = {
+                formats.append({
-                formats.append(fmt)
+                    'format_id': format_id,
-
+    float_or_none,
-from ..utils import compat_urlparse
+from ..utils import (
-            'duration': 300,
+            'duration': 300.44,
-        self._id = mobj.group('id')
+        video_id = self._match_id(url)
-        config = self._download_xml(self._CONFIG.format(self._id), self._id)
+        config = self._download_xml(
-            'title': config.findtext('./title', 'golem')
+            'id': video_id,
-                formats.append(fmt)
+            url = e.findtext('./url')
-                thumbnails.append(thumb)
+            url = e.findtext('./url')
-__version__ = '2014.09.25'
+__version__ = '2014.09.28'
-        video_id = mobj.group('id')
+        video_id = self._match_id(url)
-        title = self._og_search_title(webpage) + ' ' + now_str
+        title = self._live_title(self._og_search_title(webpage))
-    IE_NAME = u'eitb.tv'
+    IE_NAME = 'eitb.tv'
-            u'title': u'60 minutos (Lasa y Zabala, 30 aÃ±os)',
+        'add_ie': ['Brightcove'],
-            u'uploader': u'Euskal Telebista',
+            'description': '.',
-            raise ExtractorError(u'Could not extract the Brightcove url')
+            raise ExtractorError('Could not extract the Brightcove url')
-    _VALID_URL = r'http://.*ynet\.co\.il/.*/0,7340,(?P<id>L(?:-[0-9]+)+),00\.html'
+    _VALID_URL = r'http://(?:.+?\.)?ynet\.co\.il/(?:.+?/)?0,7340,(?P<id>L(?:-[0-9]+)+),00\.html'
-from youtube_dl.utils import compat_urllib_parse_urlparse, compat_urllib_parse
+from ..utils import compat_urllib_parse
-            'thumbnail': 'http://hot.ynet.co.il/PicServer4/2014/09/23/5606015/AMERICAN_COMMUNE1_T.jpg',
+    _VALID_URL = r'http://.*ynet\.co\.il/.*/0,7340,(?P<id>L(?:-[0-9]+)+),00\.html'
-    }
+    ]
-        webpage = self._download_webpage(url, id)
+        webpage = self._download_webpage(url, video_id)
-        title = re.sub(': Video$', '', self._og_search_title(webpage))
+        content = compat_urllib_parse.unquote_plus(self._og_search_video_url(webpage))
-            'id': id,
+            'id': video_id,
-            'formats': self._extract_f4m_formats(f4m_url, id),
+            'formats': self._extract_f4m_formats(f4m_url, video_id),
-
+        }
-        req_is_string = isinstance(req, basestring)
+        req_is_string = isinstance(req, basestring if sys.version_info < (3, 0) else compat_str)
-from .sportdeutschland import SportDeutschlandIE
+from .sportdeutschland import SportDeutschlandIE
-
+from ..utils import ExtractorError
-    _TESTS = [{
+    _VALID_URL = r'http://(?:www|vod)?\.sport5\.co\.il/.*\b(?:Vi|docID)=(?P<id>\d+)'
-            }
+                'title': '××× ×¡××-×§××¨×××× 0:3',
-            }
+                'title': 'GOALS_CELTIC_270914.mp4',
-        webpage = self._download_webpage(url, '')
+        webpage = self._download_webpage(url, media_id)
-        media_id = self._html_search_regex('clipId=(s5-\w+-\w+)', webpage, 'media id')
+        video_id = self._html_search_regex('clipId=([\w-]+)', webpage, 'video id')
-            media_id, 'Downloading media XML')
+        metadata = self._download_xml(
-        file_els = xml.findall('./PlaybackLinks/FileURL')
+        error = metadata.find('./Error')
-        formats = []
+        title = metadata.find('./Title').text
-            })
+        posters_el = metadata.find('./PosterLinks')
-            'id': media_id,
+            'id': video_id,
-            'thumbnail': thumbnail,
+            'description': description,
-                        not isinstance(obj['url'], str)):
+                if not obj or not obj.get('url'):
-        if config.get('poster') and isinstance(config['poster'], str):
+        if config.get('poster'):
-        if date and isinstance(date, str):
+        if date:
-        url = req if isinstance(req, compat_str) else req.get_full_url()
+        req_is_string = isinstance(req, basestring)
-            if isinstance(req, compat_str):
+            if req_is_string:
-    _CONFIG = 'https://video.golem.de/xml/{}.xml'
+    _CONFIG = 'https://video.golem.de/xml/{0}.xml'
-            self._warn("{}: url: empty, skipping", format_id)
+            self._warn("{0}: url: empty, skipping", format_id)
-            self._warn('{}: ext: missing extension', format_id)
+            self._warn('{0}: ext: missing extension', format_id)
-                self._warn('{}: filesize: {}', format_id, e)
+                self._warn('{0}: filesize: {1}', format_id, e)
-                self._warn('{}: width: {}', format_id, e)
+                self._warn('{0}: width: {1}', format_id, e)
-                self._warn('{}: height: {}', format_id, e)
+                self._warn('{0}: height: {1}', format_id, e)
-                self._warn('thumbnail: width: {}', e)
+                self._warn('thumbnail: width: {0}', e)
-                self._warn('thumbnail: height: {}', e)
+                self._warn('thumbnail: height: {0}', e)
-                self._warn('duration: {}', e)
+                self._warn('duration: {0}', e)
-            fatal=False)
+            r'Uploaded by:\s*</strong>\s*(.+?)\s*</div>',
-            r'<div class="description">([^<]+)</div>', webpage, 'description', fatal=False)
+            r'<div class="description"[^>]*>([^<]+)</div>', webpage, 'description', fatal=False)
-            r'<b>Duration:</b> (\d+:\d+)', webpage, 'duration', fatal=False))
+            r'<b>Duration:</b> (?:<q itemprop="duration">)?(\d+:\d+)', webpage, 'duration', fatal=False))
-            'ext': 'flv',
+            'ext': 'mp4',
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class CrunchyrollIE(InfoExtractor):
+class CrunchyrollIE(SubtitlesInfoExtractor):
-            }
+            },
-            }
+            },
-            }
+            },
-            u"title": u"youtube-dl test video \"'/\\Ã¤â­ð"
+    _VALID_URL = r'''(?x)
-        video_id = mobj.group('ID')
+        video_id = mobj.group('id')
-                ext = u'flv'
+        config = self._download_json(info_url, video_id)
-            raise ExtractorError(u'Unable to extract info section')
+        format = self._downloader.params.get('format', None)
-            download_url = 'http://f.youku.com/player/getFlvPath/sid/%s_%02X/st/flv/fileid/%s?k=%s' % (sid, index, temp_fileid, key)
+            download_url = 'http://k.youku.com/player/getFlvPath/sid/%s_%02X/st/flv/fileid/%s?k=%s' % (sid, index, temp_fileid, key)
-                if remaining_bytes:
+                if remaining_bytes is not None:
-                if remaining_bytes:
+                if remaining_bytes is not None:
-                if remaining_bytes <= 0:
+                if remaining_bytes is not None and remaining_bytes <= 0:
-__version__ = '2014.09.24.1'
+__version__ = '2014.09.25'
-                (?:embed|v)/.+?)
+                (?:embed|v|p)/.+?)
-                byte_counter += len(segment)
+                seg_req = compat_urllib_request.Request(segurl)
-        "md5": "06bea460acb744eab74a9d7dcb4bfd61",
+        "md5": "95ee28ee45e70130e3ab02b0f579ae23",
-        'md5': '893ec0e0d4426a1d96c01de8f2bdff58',
+        'md5': 'f6ab09b034f8c22969020b042e5ac7fc',
-__version__ = '2014.09.24'
+__version__ = '2014.09.24.1'
-
+from .hls import NativeHlsFD
-    def _extract_m3u8_formats(self, m3u8_url, video_id, ext=None):
+    def _extract_m3u8_formats(self, m3u8_url, video_id, ext=None,
-                    formats.append({'url': line})
+                    formats.append({'url': format_url(line)})
-                    'url': line.strip(),
+                    'url': format_url(line.strip()),
-__version__ = '2014.09.22.1'
+__version__ = '2014.09.24'
-            urlrs = orderedSet(self.url_result(getter(m), ie) for m in matches)
+            urlrs = orderedSet(
-                matches, lambda m: unescapeHTML(m[1]), ie='Youtube')
+                matches, lambda m: unescapeHTML(m[1]))
-    _VALID_URL = r'(?:https?://)?(?:www\.|secure\.)?flickr\.com/photos/(?P<uploader_id>[\w\-_@]+)/(?P<id>\d+).*'
+    _VALID_URL = r'https?://(?:www\.|secure\.)?flickr\.com/photos/(?P<uploader_id>[\w\-_@]+)/(?P<id>\d+).*'
-        'file': '5645318632.mp4',
+            'id': '5645318632',
-            'title':       self._og_search_title(webpage),
+        return {
-            'thumbnail':   self._og_search_thumbnail(webpage),
+            'thumbnail': self._og_search_thumbnail(webpage),
-        }]
+        }
-                             (?:(?:v|embed|e)/)                               # v/ or embed/ or e/
+                             (?:(?:v|embed|e)/(?!videoseries))                # v/ or embed/ or e/
-                           (?:course|view_play_list|my_playlists|artist|playlist|watch)
+                           (?:course|view_play_list|my_playlists|artist|playlist|watch|embed/videoseries)
-    _TESTS = []
+    _TESTS = [{
-        link = self._html_search_regex(playlist_re, channel_page, 'list')
+        channel_page = self._download_webpage(
-    _VALID_URL = r'https?://www\.youtube\.com/show/(.*)'
+    _VALID_URL = r'https?://www\.youtube\.com/show/(?P<id>[^?#]*)'
-        webpage = self._download_webpage(url, show_name, 'Downloading show webpage')
+        playlist_id = mobj.group('id')
-        return [self.url_result('https://www.youtube.com' + season.group(1), 'YoutubePlaylist') for season in m_seasons]
+        self.to_screen('%s: Found %s seasons' % (playlist_id, len(m_seasons)))
-            note=u'Setting language', errnote='unable to set language',
+            note='Setting language', errnote='unable to set language',
-                raise ExtractorError(u'No login info available, needed for using %s.' % self.IE_NAME, expected=True)
+                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)
-            errnote=u'unable to fetch login page', fatal=False)
+            note='Downloading login page',
-            note=u'Logging in', errnote=u'unable to log in', fatal=False)
+            note='Logging in', errnote='unable to log in', fatal=False)
-            raise ExtractorError(u'Please use your account password and a two-factor code instead of an application-specific password.', expected=True)
+            raise ExtractorError('Please use your account password and a two-factor code instead of an application-specific password.', expected=True)
-                self._downloader.report_warning(u'(Note that only TOTP (Google Authenticator App) codes work at this time.)')
+                self._downloader.report_warning('Two-factor authentication required. Provide it with --twofactor <code>')
-                self._downloader.report_warning(u'Failed to get secTok - did the page structure change?')
+                self._downloader.report_warning('Failed to get secTok - did the page structure change?')
-                self._downloader.report_warning(u'Failed to get timeStmp - did the page structure change?')
+                self._downloader.report_warning('Failed to get timeStmp - did the page structure change?')
-                note=u'Submitting TFA code', errnote=u'unable to submit tfa', fatal=False)
+                note='Submitting TFA code', errnote='unable to submit tfa', fatal=False)
-                self._downloader.report_warning(u'Two-factor code expired. Please try again, or use a one-use backup code instead.')
+                self._downloader.report_warning('Two-factor code expired. Please try again, or use a one-use backup code instead.')
-                self._downloader.report_warning(u'unable to log in - did the page structure change?')
+                self._downloader.report_warning('unable to log in - did the page structure change?')
-                self._downloader.report_warning(u'Your Google account has a security notice. Please log in on your web browser, resolve the notice, and try again.')
+                self._downloader.report_warning('Your Google account has a security notice. Please log in on your web browser, resolve the notice, and try again.')
-            self._downloader.report_warning(u'unable to log in: bad username or password')
+            self._downloader.report_warning('unable to log in: bad username or password')
-            note=u'Confirming age', errnote=u'Unable to confirm age')
+            note='Confirming age', errnote='Unable to confirm age')
-        self.to_screen(u'%s: Downloading video info webpage' % video_id)
+        self.to_screen('%s: Downloading video info webpage' % video_id)
-        self.to_screen(u'%s: Extracting video information' % video_id)
+        self.to_screen('%s: Extracting video information' % video_id)
-        self.to_screen(u'%s: Format %s not available' % (video_id, format))
+        self.to_screen('%s: Format %s not available' % (video_id, format))
-        self.to_screen(u'RTMP download detected')
+        self.to_screen('RTMP download detected')
-        cache_spec = self._downloader.cache.load(u'youtube-sigfuncs', func_id)
+        cache_spec = self._downloader.cache.load('youtube-sigfuncs', func_id)
-                errnote=u'Download of %s failed' % player_url)
+                note='Downloading %s player %s' % (player_type, player_id),
-                errnote=u'Download of %s failed' % player_url)
+                note='Downloading %s player %s' % (player_type, player_id),
-        self._downloader.cache.store(u'youtube-sigfuncs', func_id, cache_spec)
+        self._downloader.cache.store('youtube-sigfuncs', func_id, cache_spec)
-                steps = '' if step == 1 else (u':%d' % step)
+                ends = (':%d' % (end+step)) if end + step >= 0 else ':'
-        code = (u'if tuple(len(p) for p in s.split(\'.\')) == %s:\n'
+        code = ('if tuple(len(p) for p in s.split(\'.\')) == %s:\n'
-        self.to_screen(u'Extracted signature function:\n' + code)
+        self.to_screen('Extracted signature function:\n' + code)
-            raise ExtractorError(u'Cannot decrypt signature without player_url')
+            raise ExtractorError('Cannot decrypt signature without player_url')
-        if player_url.startswith(u'//'):
+        if player_url.startswith('//'):
-            self._downloader.report_warning(u'unable to download video subtitles: %s' % compat_str(err))
+            self._downloader.report_warning('unable to download video subtitles: %s' % compat_str(err))
-            self._downloader.report_warning(u'video doesn\'t have subtitles')
+            self._downloader.report_warning('video doesn\'t have subtitles')
-        self.to_screen(u'%s: Looking for automatic captions' % video_id)
+        self.to_screen('%s: Looking for automatic captions' % video_id)
-                self._downloader.report_warning(u'Video doesn\'t have automatic captions')
+                self._downloader.report_warning('Video doesn\'t have automatic captions')
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-        return self._download_webpage(url, video_id, note=u'Searching for annotations.', errnote=u'Unable to download video annotations.')
+        return self._download_webpage(url, video_id, note='Searching for annotations.', errnote='Unable to download video annotations.')
-            raise ExtractorError(u'"rental" videos not supported')
+            raise ExtractorError('"rental" videos not supported')
-            raise ExtractorError(u'Unable to extract uploader name')
+            raise ExtractorError('Unable to extract uploader name')
-            self._downloader.report_warning(u'unable to extract uploader nickname')
+            self._downloader.report_warning('unable to extract uploader nickname')
-            self._downloader.report_warning(u'Unable to extract video title')
+            self._downloader.report_warning('Unable to extract video title')
-            self._downloader.report_warning(u'unable to extract video thumbnail')
+            self._downloader.report_warning('unable to extract video thumbnail')
-        dislike_count = _extract_count(u'dislike')
+        like_count = _extract_count('like')
-            self._downloader.report_warning(u'unable to extract video duration')
+            self._downloader.report_warning('unable to extract video duration')
-                raise ValueError(u'No stream_map present')  # caught below
+                raise ValueError('No stream_map present')  # caught below
-                self.to_screen(u'%s: Encrypted signatures detected.' % video_id)
+                self.to_screen('%s: Encrypted signatures detected.' % video_id)
-                        self.to_screen(u'{%s} signature length %s, %s' %
+                        self.to_screen('{%s} signature length %s, %s' %
-            raise ExtractorError(u'no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')
+            raise ExtractorError('no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')
-                for r in dash_doc.findall(u'.//{urn:mpeg:DASH:schema:MPD:2011}Representation'):
+                    note='Downloading DASH manifest',
-                self.report_warning(u'Skipping DASH manifest: %s' % e, video_id)
+                self.report_warning('Skipping DASH manifest: %s' % e, video_id)
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-                self.to_screen(u'Downloading just video %s because of --no-playlist' % video_id)
+                self.to_screen('Downloading just video %s because of --no-playlist' % video_id)
-                self.to_screen(u'Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))
+                self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))
-            raise ExtractorError(u'For downloading YouTube.com top lists, use '
+            raise ExtractorError('For downloading YouTube.com top lists, use '
-    IE_DESC = (u'YouTube.com top lists, "yttoplist:{channel}:{list title}"'
+    IE_DESC = ('YouTube.com top lists, "yttoplist:{channel}:{list title}"'
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-                    url, channel_id, note=u'Downloading page #%s' % pagenum,
+                    url, channel_id, note='Downloading page #%s' % pagenum,
-        self._downloader.to_screen(u'[youtube] Channel %s: Found %i videos' % (channel_id, len(video_ids)))
+        self._downloader.to_screen('[youtube] Channel %s: Found %i videos' % (channel_id, len(video_ids)))
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-                raise ExtractorError(u'Invalid JSON in API response: ' + compat_str(err))
+                raise ExtractorError('Invalid JSON in API response: ' + compat_str(err))
-                errnote=u'Unable to download API page')
+                result_url, video_id='query "%s"' % query,
-        self.to_screen(u'%s: Found %s seasons' % (show_name, len(m_seasons)))
+        self.to_screen('%s: Found %s seasons' % (show_name, len(m_seasons)))
-                u"categories": [u'Science & Technology'],
+            'url': 'http://www.youtube.com/watch?v=BaW_jenozKc',
-                u"uploader_id": u"IconaPop"
+            'url': 'http://www.youtube.com/watch?v=UxxajLWwzqY',
-                u"uploader_id": u"justintimberlakeVEVO"
+            'url': 'https://www.youtube.com/watch?v=07FYdnEawAQ',
-                u"uploader_id": u"setindia"
+            'url': '//www.YouTube.com/watch?v=yZIXLfi8CZQ',
-                u"title": "UHDTV TEST 8K VIDEO.mp4"
+            'url': 'http://www.youtube.com/watch?v=a9LDPn-MO4I',
-                u"format": "141",
+            'params': {
-            u"params": {
+            'params': {
-        'skip_download': True,  # md5 sum fluctuates
+        # 'md5': '5eb8c40a727dda106d510e5d6ffa79e5',  # md5 checksum fluctuates
-from ..utils import unified_strdate
+from ..utils import (
-        tk = hashlib.md5(hashlib.md5(ts).hexdigest() + '#8S?uCraTedap6a').hexdigest()
+        tk = hashlib.md5((hashlib.md5(ts.encode('ascii')).hexdigest() + '#8S?uCraTedap6a').encode('ascii')).hexdigest()
-__version__ = '2014.09.22'
+__version__ = '2014.09.22.1'
-    _VALID_URL = r'https?://(?:www\.)?sbs\.com\.au/ondemand/video/single/(?P<id>[0-9]+)/'
+    _VALID_URL = r'https?://(?:www\.)?sbs\.com\.au/ondemand/video/(?:single/)?(?P<id>[0-9]+)'
-        view_count = int_or_none(recording.find('./stats/playcount').text)
+        view_count = str_to_int(recording.find('./stats/playcount').text)
-__version__ = '2014.09.19'
+__version__ = '2014.09.22'
-from .npo import NPOIE
+from .npo import (
-    _VALID_URL = r'https?://(?:www\.)?thvideo\.tv/v/th(?P<id>[0-9]+)'
+    _VALID_URL = r'http://(?:www\.)?thvideo\.tv/(?:v/th|mobile\.php\?cid=)(?P<id>[0-9]+)'
-        video_url = self._html_search_regex(r'<source src="(.*?)" type', webpage_player, 'video url')
+        webpage_player = self._download_webpage(
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(
-        upload_date = unified_strdate(upload_date_raw)
+        upload_date = unified_strdate(self._html_search_regex(
-        }
+        }
-            'ext': 'flv',
+            'ext': 'mp4',
-        if f4m_node is not None:
+        if f4m_node is not None and '.f4m' in f4m_node.attrib['src']:
-                })
+            switch = body.find(_x('smil:switch'))
-        'md5': '54d0fbc33e0b853a65d7b4de5c06d64e',
+        # md5 checksum is not stable
-            'id': 'u1RInQZRN7QJ',
+            'id': 'bTmnLCvIbaaH',
-            }]
+            formats = self._extract_f4m_formats(f4m_url, video_id)
-from ..utils import compat_urllib_parse_unquote
+from ..utils import compat_urllib_parse_unquote, url_basename
-    _TEST = {
+    _VALID_URL = r'https?://(?:www\.)?dropbox[.]com/sh?/(?P<id>[a-zA-Z0-9]{15})/.*'
-    }
+    },
-        fn = compat_urllib_parse_unquote(mobj.group('title'))
+        fn = compat_urllib_parse_unquote(url_basename(url))
-    }
+    _VALID_URL = r'https?://(?:www\.)?tube8\.com/(?:[^/]+/)+(?P<display_id>[^/]+)/(?P<id>\d+)'
-        webpage = self._download_webpage(req, video_id)
+        webpage = self._download_webpage(req, display_id)
-            raise  ExtractorError('Unable to login: %s' % clean_html(login['erreur']), expected=True)
+            raise ExtractorError('Unable to login: %s' % clean_html(login['erreur']), expected=True)
-            'https://api.noco.tv/1.0/video/medias/%s' % video_id, video_id, 'Downloading video JSON')
+        medias = self._call_api(
-            format_id = fmt['quality_key']
+        for format_id, fmt in medias['fr']['video_list']['none']['quality_list'].items():
-                'https://api.noco.tv/1.0/video/file/%s/fr/%s' % (format_id.lower(), video_id),
+            video = self._call_api(
-            file_url = file['file']
+            file_url = video['file']
-                    expected=True)
+            if file_url in ['forbidden', 'not found']:
-                'preference': fmt['priority'],
+                'format_note': qualities[format_id]['quality_name'],
-            'https://api.noco.tv/1.0/shows/show/%s' % video_id, video_id, 'Downloading show JSON')[0]
+        show = self._call_api(
-        upload_date = unified_strdate(show['indexed'])
+        upload_date = unified_strdate(show['online_date_start_utc'])
-        thumbnail = show['screenshot']
+
-            'thumbnail': thumbnail,
+            'thumbnails': thumbnails,
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'divxstage\.(?:eu|net|ch|co|at|ag)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'divxstage\.(?:eu|net|ch|co|at|ag|to)'}
-    }
+    }
-import json
+from ..utils import ExtractorError, compat_urllib_request
-        data = json.loads(data_json)
+        request = compat_urllib_request.Request(self._API_URL.format(video_id))
-    _VALID_URL = r'http://(?:www\.)?franceinter\.fr/player/reecouter\?play=(?P<id>[0-9]{6})'
+    _VALID_URL = r'http://(?:www\.)?franceinter\.fr/player/reecouter\?play=(?P<id>[0-9]+)'
-            "title": "LâHistoire dans les jeux vidÃ©o",
+            'id': '793962',
-            r'<span class="roll_overflow">(.*?)</span></h1>', webpage, 'title')
+
-            r'&urlAOD=(.*?)&startTime', webpage, 'video url')
+            r'<a id="player".+?href="([^"]+)"', webpage, 'video url')
-__version__ = '2014.09.18'
+__version__ = '2014.09.19'
-from .hypestat import HypestatIE
+from .moniker import MonikerIE
-class HypestatIE(InfoExtractor):
+class MonikerIE(InfoExtractor):
-    _VALID_URL = r'https?://api\.soundcloud\.com/playlists/(?P<id>[0-9]+)(?:/?\?secret_token=(?P<token>[^&]+?))$'
+    _VALID_URL = r'https?://api\.soundcloud\.com/playlists/(?P<id>[0-9]+)(?:/?\?secret_token=(?P<token>[^&]+?))?$'
-    ]
+    _TESTS = [{
-    _VALID_URL = r'https?://(?:allmyvideos|vidspot)\.net/(?P<id>[a-zA-Z0-9_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?(?:allmyvideos|vidspot)\.net/(?P<id>[a-zA-Z0-9_-]+)'
-from .allmyvideos import AllmyvideosIE
+from .hypestat import HypestatIE
-    _VALID_URL = r'https?://allmyvideos\.net/(?P<id>[a-zA-Z0-9_-]+)'
+class HypestatIE(InfoExtractor):
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-__version__ = '2014.09.16.1'
+__version__ = '2014.09.18'
-                        }
+            for rfstr in req_format.split(','):
-                    break
+                        selected_format = self.select_format(rf, formats)
-            help='video format code, specify the order of preference using slashes: -f 22/17/18 .  -f mp4 , -f m4a and  -f flv  are also supported. You can also use the special names "best", "bestvideo", "bestaudio", "worst", "worstvideo" and "worstaudio". By default, youtube-dl will pick the best quality.')
+            help='video format code, specify the order of preference using slashes: -f 22/17/18 .  -f mp4 , -f m4a and  -f flv  are also supported. You can also use the special names "best", "bestvideo", "bestaudio", "worst", "worstvideo" and "worstaudio". By default, youtube-dl will pick the best quality. Use commas to download multiple audio formats, such as  -f  136/137/mp4/bestvideo,140/m4a/bestaudio')
-            extensions = ['mp4', 'flv', 'webm', '3gp']
+            extensions = ['mp4', 'flv', 'webm', '3gp', 'm4a']
-            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported. You can also use the special names "best", "bestvideo", "bestaudio", "worst", "worstvideo" and "worstaudio". By default, youtube-dl will pick the best quality.')
+            help='video format code, specify the order of preference using slashes: -f 22/17/18 .  -f mp4 , -f m4a and  -f flv  are also supported. You can also use the special names "best", "bestvideo", "bestaudio", "worst", "worstvideo" and "worstaudio". By default, youtube-dl will pick the best quality.')
-    _VALID_URL = r'https?://gamevideos\.1up\.com/(?P<type>video)/id/(?P<name_or_id>.+)'
+    _VALID_URL = r'https?://gamevideos\.1up\.com/(?P<type>video)/id/(?P<name_or_id>.+)\.html'
-        'url': 'http://gamevideos.1up.com/video/id/34976',
+        'url': 'http://gamevideos.1up.com/video/id/34976.html',
-                '<param name="flashvars" value="[^"]*?url=(https?://www\.ign\.com/videos/.*?)["&]',
+                '<param name="flashvars"[^>]*value="[^"]*?url=(https?://www\.ign\.com/videos/.*?)["&]',
-            'categories': list,  # NSFW
+            'categories': ['Babe', 'Blonde', 'Erotic', 'Outdoor', 'Softcore', 'Solo'],
-        categories = None if cats_str is None else cats_str.split(' ')
+        cats_str = self._search_regex(
-    _VALID_URL = r'https?://(?:www\.)?soundcloud\.com/([\w\d-]+)/sets/([\w\d-]+)'
+    _VALID_URL = r'https?://(?:www\.)?soundcloud\.com/(?P<uploader>[\w\d-]+)/sets/(?P<slug_title>[\w\d-]+)(?:/(?P<token>[^?/]+))?'
-        uploader = mobj.group(1)
+        uploader = mobj.group('uploader')
-        slug_title = mobj.group(2)
+        slug_title = mobj.group('slug_title')
-            'entries': [self._extract_info_dict(track) for track in info['tracks']],
+            'entries': [self._extract_info_dict(track, secret_token=token) for track in info['tracks']],
-    _VALID_URL = r'https?://api\.soundcloud\.com/playlists/(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://api\.soundcloud\.com/playlists/(?P<id>[0-9]+)(?:/?\?secret_token=(?P<token>[^&]+?))$'
-        data = compat_urllib_parse.urlencode({
+        data_dict = {
-        })
+        }
-            self._extract_info_dict(t, quiet=True) for t in data['tracks']]
+            self._extract_info_dict(t, quiet=True, secret_token=token)
-                       |(?:api\.soundcloud\.com/tracks/(?P<track_id>\d+))
+                       |(?:api\.soundcloud\.com/tracks/(?P<track_id>\d+)
-            'unescape\("([^"]+)"\)', webpage, 'escaped data')
+            r'unescape\("([^"]+)"\)', webpage, 'escaped data')
-            title = remove_start(title, 'VideoMega.tv - ')
+        title = remove_start(self._html_search_regex(
-        formats.append({
+        formats = [{
-        })
+        }]
-            'upload_date': '20140622',
+    _TESTS = [
-    }
+        {
-        quality = qualities(['adaptive', 'h264_sb', 'h264_bb', 'h264_std'])
+        quality = qualities(['adaptive', 'wmv_sb', 'h264_sb', 'wmv_bb', 'h264_bb', 'wvc1_std', 'h264_std'])
-            streams_info = self._download_json(
+            format_info = self._download_json(
-                video_id, 'Downloading %s stream info' % format_id)
+                video_id, 'Downloading %s JSON' % format_id)
-                formats.extend(self._extract_m3u8_formats(stream_info['url'], video_id))
+                formats.extend(self._extract_m3u8_formats(video_url, video_id))
-                    'url': stream_info['url'],
+                    'url': video_url,
-            'upload_date': unified_strdate(metadata['gidsdatum']),
+            'thumbnail': metadata.get('images', [{'url': None}])[-1]['url'],
-__version__ = '2014.09.16'
+__version__ = '2014.09.16.1'
-        'md5': '8f26c1e7102556a0d7f24306d32c2092',
+        'md5': '710883dee1bfc370ecf9fa6a89307c88',
-        'md5': '8f26c1e7102556a0d7f24306d32c2092',
+        'md5': '710883dee1bfc370ecf9fa6a89307c88',
-            data[name] = value
+        data = dict(fields)
-        webpage = self._download_webpage(req, video_id, note='Downloading video page ...')
+        webpage = self._download_webpage(
-        }
+            'title': title,
-                r'(?:[a-z-]+="[^"]+"\s+)*?content="[0-9]{,2};url=\'([^\']+)\'"',
+                r'(?:[a-z-]+="[^"]+"\s+)*?content="[0-9]{,2};url=\'?([^\'"]+)',
-		}
+        mobj = re.match(self._VALID_URL, url)
-        thumbnail_path = info.find('image').text
+    def _extract_video(self, video_id, catalogue):
-            'title': info.find('titre').text,
+            'title': info['titre'],
-        return self._extract_video(video_id)
+        return self._extract_video(video_id, 'Pluzz')
-            'ext': 'mp4',
+            'ext': 'flv',
-            'skip_download': True,
+            'upload_date': '20130826',
-        }
+        },
-        return self._extract_video(video_id)
+        video_id, catalogue = self._search_regex(
-            'file': '75540104.mp4',
+            'md5': 'c03fc87cb85429ffd55df32b9fc05523',
-                'skip_download': True,
+                'id': '109169362',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'skip_download': True,
+                'upload_date': '20131113',
-                'ext': 'flv',
+                'ext': 'mp4',
-                'skip_download': True,
+                'upload_date': '20131106',
-                'ext': 'mp4',
+                'id': '108961659',
-                'skip_download': True,
+                'description': 'md5:1a4aeab476eb657bf57c4ff122129f81',
-                'title': 'InfÃ´-Afrique',
+                'id': '108634970',
-        return self._extract_video(video_id)
+        webpage = self._download_webpage(url, mobj.group('key') or mobj.group('id'))
-        'url': 'http://culturebox.francetvinfo.fr/einstein-on-the-beach-au-theatre-du-chatelet-146813',
+        'url': 'http://culturebox.francetvinfo.fr/festivals/dans-les-jardins-de-william-christie/dans-les-jardins-de-william-christie-le-camus-162553',
-            'skip_download': True,
+            'id': 'EV_22853',
-        return self._extract_video(video_id)
+        video_id, catalogue = self._search_regex(
-__version__ = '2014.09.15.1'
+__version__ = '2014.09.16'
-    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console\?.*?(?:[?&])id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console(?:\?(?:.*?[?&])?)id=(?P<id>[0-9]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        self.report_extraction(display_id)
+    'Hari Padmanaban',
-    _VALID_URL = r'http://(?:www\.)?einthusan\.com/movies/watch.php\?(.*)?id=(?P<id>[0-9]+).*?'
+    _VALID_URL = r'https?://(?:www\.)?einthusan\.com/movies/watch.php\?([^#]*?)id=(?P<id>[0-9]+)'
-        video_title = self._html_search_regex(r'''<h1><a class="movie-title".*?>(.*?)</a></h1>''', webpage, 'title')
+        video_title = self._html_search_regex(
-            r'''(?s)jwplayer\("mediaplayer"\)\.setup\({.*?'file': '([^']+)'.*?}\);''', webpage, 'video url')
+            r'''(?s)jwplayer\("mediaplayer"\)\.setup\({.*?'file': '([^']+)'.*?}\);''',
-        thumb_abs_url = re.sub('\.\.', 'http://www.einthusan.com', thumb_rel_url)
+        description = self._html_search_meta('description', webpage)
-            'thumbnail': thumb_abs_url,
+            'thumbnail': thumbnail,
-            'url': 'http://www.einthusan.com/movies/watch.php?hindimoviesonline=Ek+Villain&lang=hindi&id=2447',
+            'url': 'http://www.einthusan.com/movies/watch.php?id=2447',
-        thumbnail = _find(track, './xspf:image')
+        if track is None:
-__version__ = '2014.09.15'
+__version__ = '2014.09.15.1'
-    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/.*?clipid=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/(?:v/|.*?clipid=)(?P<id>[^?#&]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-                video_id, note=False)
+                video_id, note='Downloading video data for %s format' % profile)
-__version__ = '2014.09.14.3'
+__version__ = '2014.09.15'
-
+    limit_length,
-                video_title = video_title[:80] + '...'
+            video_title = limit_length(video_title, 80)
-    _VALID_URL = r'(?:http://)(?:www\.)?behindkink\.com/(?P<year>[0-9]{4})/(?P<month>[0-9]{2})/(?P<day>[0-9]{2})/(?P<id>[^/?_]+)'
+    _VALID_URL = r'http://(?:www\.)?behindkink\.com/(?P<year>[0-9]{4})/(?P<month>[0-9]{2})/(?P<day>[0-9]{2})/(?P<id>[^/#?_]+)'
-        webpage = self._download_webpage(webpage_url, display_id)
+        webpage = self._download_webpage(url, display_id)
-        self.report_extraction(video_id)
+from .turbo import TurboIE
-    }
+    _TESTS = [
-        for video in re.findall(r'flashvars\.videoUrl([^=]+?)\s*=\s*"([^"]+)"', webpage):
+        for video in re.findall(r'flashvars\.videoUrl([^=]+?)\s*=\s*"(https?://[^"]+)"', webpage):
-__version__ = '2014.09.14.2'
+__version__ = '2014.09.14.3'
-        video_id = mobj.group('id')
+    def _extract_video(self, video_host, video_id, file_key, error_url=None, try_num=0):
-        webpage = self._download_webpage(url, video_id)
+        if try_num > self._MAX_TRIES - 1:
-        data_url = self._API_URL % (video_host, compat_urllib_parse.urlencode({
+        form = {
-        }))
+        }
-        formats = []
+
-            })
+            try:
-            'formats': formats,
+
-__version__ = '2014.09.14.1'
+__version__ = '2014.09.14.2'
-__version__ = '2014.09.14'
+__version__ = '2014.09.14.1'
-__version__ = '2014.09.12'
+__version__ = '2014.09.14'
-    _VALID_URL = r'http://(?P<blog_name>.*?)\.tumblr\.com/((post)|(video))/(?P<id>\d*)($|/)'
+    _VALID_URL = r'http://(?P<blog_name>.*?)\.tumblr\.com/(?:post|video)/(?P<id>[0-9]+)(?:$|[/?#])'
-            webpage, 'title', flags=re.DOTALL)
+        video_title = self._html_search_regex(
-                 }]
+        return {
-        https?://(?:www\.)?cloudy\.ec/
+        https?://(?:www\.)?(?P<host>cloudy\.ec|videoraj\.ch)/
-            'title': 'Funny Cats and Animals Compilation june 2013',
+    _EMBED_URL = 'http://www.%s/embed.php?id=%s'
-    }
+    ]
-        url = 'http://www.cloudy.ec/embed.php?id=%s' % video_id
+        url = self._EMBED_URL % (video_host, video_id)
-        data_url = self._API_URL % compat_urllib_parse.urlencode({
+        data_url = self._API_URL % (video_host, compat_urllib_parse.urlencode({
-        })
+        }))
-            title = title.replace('&asdasdas', '').strip()
+            title = remove_end(title, '&asdasdas').strip()
-        })
+        video_url = data.get('url', [None])[0]
-    _VALID_URL = r'http://(?:www\.)?dr\.dk/tv/se/[^/]+/(?P<id>[\da-z-]+)'
+    _VALID_URL = r'http://(?:www\.)?dr\.dk/tv/se/(?:[^/]+/)+(?P<id>[\da-z-]+)(?:[/#?]|$)'
-
+        title = self._html_search_regex(
-            r'(\d+) views 	</span>', webpage, 'view count', fatal=False))
+            r'(\d+) views\s*</span>', webpage, 'view count', fatal=False))
-        ]
+        videos = re.findall(
-            ])
+            for key, quality in [('hashlink', 'low'), ('hd', 'high')]:
-    return compat_urllib_parse.quote(s, "%/;:@&=+$,!~*'()?#[]") #"%/;:@&=+$,!~*'()?#[]+"   #?#[]+
+    return compat_urllib_parse.quote(s, "%/;:@&=+$,!~*'()?#[]")
-    compat_urllib_parse_urlparse,
+    escape_url,
-
+        # To work around aforementioned issue we will replace request's original URL with
-        ).geturl()
+        url_escaped = escape_url(url)
-        episode_id = self._html_search_regex(r'<link rel="video_src" href="http://i\.adultswim\.com/adultswim/adultswimtv/tools/swf/viralplayer.swf\?id=([0-9a-f]+?)"\s*/?\s*>', webpage, 'episode_id')
+        episode_id = self._html_search_regex(
-            idoc = self._download_xml(segment_url, segment_title, 'Downloading segment information', 'Unable to download segment information')
+            idoc = self._download_xml(
-        thumbnail = video_node.find('.//teaserImage//variant/url').text
+        upload_date = unified_strdate(xpath_text(
-            'description': 'md5:a5f7ff82e2f7a9ed77473fe666954e84',
+            'description': 're:(?s)^Watch the making of - makingoficons.com.{300,}',
-        'md5': '48975a41ccc4b7a581abd68651c1a5a8',
+        'url': 'https://www.facebook.com/video.php?v=637842556329505&fref=nf',
-            'id': '120708114770723',
+            'id': '637842556329505',
-            'title': 'PEOPLE ARE AWESOME 2013',
+            'duration': 38,
-            r'<h2 class="uiHeaderTitle">([^<]*)</h2>', webpage, 'title')
+            r'<h2 class="uiHeaderTitle">([^<]*)</h2>', webpage, 'title',
-        'md5': '71ec5fcfddacf80f495efa8b6a8d9a89',
+from .options import (
-    parseOpts,
+from __future__ import unicode_literals
-    get_term_width,
+    parseOpts,
-
+import os.path
-                                  login_page, u'Login GALX parameter')
+                                  login_page, 'Login GALX parameter')
-                u'hl': u'en_US',
+                'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',
-                u'hl': u'en_US',
+                'continue': 'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',
-    IE_DESC = u'YouTube.com'
+    IE_DESC = 'YouTube.com'
-    IE_NAME = u'youtube'
+    IE_NAME = 'youtube'
-                u'upload_date': u'20131011',
+            'url': 'https://www.youtube.com/watch?v=IB3lcPjvWLA',
-                u'format': '141',
+                'youtube_include_dash_manifest': True,
-        return u'.'.join(compat_str(len(part)) for part in example_sig.split('.'))
+        return '.'.join(compat_str(len(part)) for part in example_sig.split('.'))
-            return lambda s: u''.join(s[i] for i in cache_spec)
+            return lambda s: ''.join(s[i] for i in cache_spec)
-            test_string = u''.join(map(compat_chr, range(len(example_sig))))
+            test_string = ''.join(map(compat_chr, range(len(example_sig))))
-                return u's[%s%s%s]' % (starts, ends, steps)
+                starts = '' if start == 0 else str(start)
-                    yield u's[%d]' % prev
+                    yield 's[%d]' % prev
-                yield u's[%d]' % i
+                yield 's[%d]' % i
-        test_string = u''.join(map(compat_chr, range(len(example_sig))))
+        test_string = ''.join(map(compat_chr, range(len(example_sig))))
-        expr_code = u' + '.join(gen_sig_code(cache_spec))
+        expr_code = ' + '.join(gen_sig_code(cache_spec))
-                u'    return %s\n') % (signature_id_tuple, expr_code)
+                '    return %s\n') % (signature_id_tuple, expr_code)
-             u'Initial JS player signature function name')
+             'Initial JS player signature function name')
-        TARGET_CLASSNAME = u'SignatureDecipher'
+        TARGET_CLASSNAME = 'SignatureDecipher'
-        initial_function = swfi.extract_function(searched_class, u'decipher')
+        initial_function = swfi.extract_function(searched_class, 'decipher')
-            player_url = u'https:' + player_url
+            player_url = 'https:' + player_url
-                u'Signature extraction failed: ' + tb, cause=e)
+                'Signature extraction failed: ' + tb, cause=e)
-            url = u'https://www.youtube.com/api/timedtext?' + params
+            url = 'https://www.youtube.com/api/timedtext?' + params
-        err_msg = u'Couldn\'t find automatic captions for %s' % video_id
+        err_msg = 'Couldn\'t find automatic captions for %s' % video_id
-        manifest = self._download_webpage(manifest_url, video_id, u'Downloading formats manifest')
+        manifest = self._download_webpage(manifest_url, video_id, 'Downloading formats manifest')
-            else u'https')
+            'http' if self._downloader.params.get('prefer_insecure', False)
-                    u'YouTube said: %s' % video_info['reason'][0],
+                    'YouTube said: %s' % video_info['reason'][0],
-                    u'"token" parameter not in video info for unknown reason',
+                    '"token" parameter not in video info for unknown reason',
-            video_title = u'_'
+            video_title = '_'
-                video_description = u''
+                video_description = ''
-            m_s = re_signature.search(args.get('adaptive_fmts', u''))
+            m_s = re_signature.search(args.get('adaptive_fmts', ''))
-                            video_webpage, u'JS player URL')
+                            video_webpage, 'JS player URL')
-                            video_webpage, u'age gate player URL')
+                            video_webpage, 'age gate player URL')
-                                    u'flash player', fatal=False)
+                                    'flash player', fatal=False)
-                                player_desc = u'html5 player %s' % player_version
+                                player_desc = 'html5 player %s' % player_version
-    IE_DESC = u'YouTube.com playlists'
+    IE_DESC = 'YouTube.com playlists'
-    IE_NAME = u'youtube:playlist'
+    IE_NAME = 'youtube:playlist'
-            url, playlist_id, u'Downloading Youtube mix')
+            url, playlist_id, 'Downloading Youtube mix')
-                u'the "yttoplist" keyword, for example "youtube-dl \'yttoplist:music:Top Tracks\'"', expected=True)
+                'the "yttoplist" keyword, for example "youtube-dl \'yttoplist:music:Top Tracks\'"', expected=True)
-                u'The playlist doesn\'t exist or is private, use --username or '
+                'The playlist doesn\'t exist or is private, use --username or '
-            page, u'title')
+            page, 'title')
-    IE_NAME = u'youtube:toplist'
+    IE_NAME = 'youtube:toplist'
-        u' (Example: "yttoplist:music:Top Tracks")')
+        ' (Example: "yttoplist:music:Top Tracks")')
-        link = self._html_search_regex(playlist_re, channel_page, u'list')
+        link = self._html_search_regex(playlist_re, channel_page, 'list')
-            msg = u'Downloading Youtube mix'
+            msg = 'Downloading Youtube mix'
-    IE_DESC = u'YouTube.com channels'
+    IE_DESC = 'YouTube.com channels'
-    IE_NAME = u'youtube:channel'
+    IE_NAME = 'youtube:channel'
-    IE_DESC = u'YouTube.com user videos (URL or "ytuser" keyword)'
+    IE_DESC = 'YouTube.com user videos (URL or "ytuser" keyword)'
-    IE_NAME = u'youtube:user'
+    IE_NAME = 'youtube:user'
-                u'Downloading video ids from %d to %d' % (
+                'Downloading video ids from %d to %d' % (
-    _API_URL = u'https://gdata.youtube.com/feeds/api/videos?q=%s&start-index=%i&max-results=50&v=2&alt=jsonc'
+    IE_DESC = 'YouTube.com searches'
-    IE_NAME = u'youtube:search'
+    IE_NAME = 'youtube:search'
-                    u'[youtube] No video results', expected=True)
+                    '[youtube] No video results', expected=True)
-    IE_DESC = u'YouTube.com searches, newest videos first'
+    IE_DESC = 'YouTube.com searches, newest videos first'
-    IE_NAME = u'youtube:search_url'
+    IE_DESC = 'YouTube.com search URLs'
-            r'(?s)<ol class="item-section"(.*?)</ol>', webpage, u'result HTML')
+            r'(?s)<ol class="item-section"(.*?)</ol>', webpage, 'result HTML')
-    IE_DESC = u'YouTube.com (multi-season) shows'
+    IE_DESC = 'YouTube.com (multi-season) shows'
-    IE_NAME = u'youtube:show'
+    IE_NAME = 'youtube:show'
-        webpage = self._download_webpage(url, show_name, u'Downloading show webpage')
+        webpage = self._download_webpage(url, show_name, 'Downloading show webpage')
-        return u'youtube:%s' % self._FEED_NAME
+        return 'youtube:%s' % self._FEED_NAME
-                                          u'Downloading page %s' % i)
+                                          '%s feed' % self._FEED_NAME,
-    IE_DESC = u'YouTube.com recommended videos, "ytrec" keyword (requires authentication)'
+    IE_DESC = 'YouTube.com recommended videos, "ytrec" keyword (requires authentication)'
-    _PLAYLIST_TITLE = u'Youtube Recommended videos'
+    _PLAYLIST_TITLE = 'Youtube Recommended videos'
-    IE_DESC = u'Youtube watch later list, "ytwatchlater" keyword (requires authentication)'
+    IE_DESC = 'Youtube watch later list, "ytwatchlater" keyword (requires authentication)'
-    _PLAYLIST_TITLE = u'Youtube Watch Later'
+    _PLAYLIST_TITLE = 'Youtube Watch Later'
-    _VALID_URL = u'https?://www\.youtube\.com/feed/history|:ythistory'
+    IE_DESC = 'Youtube watch history, "ythistory" keyword (requires authentication)'
-    _PLAYLIST_TITLE = u'Youtube Watch History'
+    _PLAYLIST_TITLE = 'Youtube Watch History'
-    IE_DESC = u'YouTube.com favourite videos, "ytfav" keyword (requires authentication)'
+    IE_NAME = 'youtube:favorites'
-        playlist_id = self._search_regex(r'list=(.+?)["&]', webpage, u'favourites playlist id')
+        playlist_id = self._search_regex(r'list=(.+?)["&]', webpage, 'favourites playlist id')
-    IE_DESC = u'YouTube.com subscriptions feed, "ytsubs" keyword (requires authentication)'
+    IE_NAME = 'youtube:subscriptions'
-        title = u'Youtube Subscriptions'
+        title = 'Youtube Subscriptions'
-            u' or simply  youtube-dl BaW_jenozKc  .',
+            'Did you forget to quote the URL? Remember that & is a meta '
-                u"description": "No description available.",
+                u"description": '',
-            self._UPLOAD_DATE_REGEXES, page, 'upload date', fatal=False))
+            self._UPLOAD_DATE_REGEXES, page, 'upload date', default=None))
-            return bitrate / 1000 if bitrate % 1000 == 0 else bitrate
+            return (bitrate // 1000) if bitrate % 1000 == 0 else bitrate
-
+    
-
+                     (?!.*?&list=)                                            # combined list/video URLs are handled by the playlist IE
-
+    }, {
-    parse_duration,
+
-            r'Views:\s*(\d+)', webpage, 'view count', fatal=False))
+            r'[vV]iews:\s*([0-9,]+)', webpage, 'view count', fatal=False))
-
+from .pornoxo import PornoXOIE
-from .spiegel import SpiegelIE
+from .spiegel import SpiegelIE, SpiegelArticleIE
-from .telemb import TelembIE
+from .telemb import TeleMBIE
-from .common import InfoExtractor
+from .common import InfoExtractor
-    }
+class TeleMBIE(InfoExtractor):
-        webpage = self._download_webpage(webpage_url, video_id)
+        display_id = mobj.group('display_id')
-        self.report_extraction(video_id)
+        formats = []
-            webpage, u'video URL')
+        title = remove_start(self._og_search_title(webpage), 'TÃ©lÃ©MB : ')
-        }]
+        return {
-__version__ = '2014.09.10.1'
+__version__ = '2014.09.12'
-                    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_SSLv3)
+                    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_TLSv1)
-        context = ssl.SSLContext(ssl.PROTOCOL_SSLv3)
+    elif hasattr(ssl, 'create_default_context'):  # Python >= 3.4
-                         (?:https?://|//)?                                    # http(s):// or protocol-independent URL (optional)
+                         (?:https?://|//)                                    # http(s):// or protocol-independent URL
-                         |https?://(?:www\.)?cleanvideosearch\.com/media/action/yt/watch\?videoId=
+                         |(?:www\.)?cleanvideosearch\.com/media/action/yt/watch\?videoId=
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?youjizz\.com/videos/(?P<videoid>[^.]+)\.html$'
+    _VALID_URL = r'^https?://(?:\w+\.)?youjizz\.com/videos/(?P<videoid>[^.]+)\.html$'
-    _VALID_URL = r'http://(?:www\.)?tvplay\.lv/parraides/[^/]+/(?P<id>\d+)'
+    IE_DESC = 'TV3Play and related services'
-            if not video_url:
+            if not video_url or not isinstance(video_url, compat_str):
-        'md5': '4b4ac54c6ad5d70ab88f2c2c6ccec71c',
+        'url': 'http://nosvideo.com/?v=mu8fle7g7rpq',
-            'id': 'drlp6s40kg54',
+            'id': 'mu8fle7g7rpq',
-    compat_urllib_parse,
+    ExtractorError,
-        req = compat_urllib_request.Request(url, post)
+        req = compat_urllib_request.Request(url, urlencode_postdata(fields))
-__version__ = '2014.09.10'
+__version__ = '2014.09.10.1'
-        }
+        fields = dict(re.findall(r'''(?x)<input\s+
-                (?P<url>(?:https?:)?//(?:www\.)?youtube\.com/
+                (?P<url>(?:https?:)?//(?:www\.)?youtube(?:-nocookie)?\.com/
-        duration = int_or_none(self._html_search_regex(
+        duration = float_or_none(self._html_search_regex(
-            duration /= 1000.0
+            webpage, 'duration', fatal=False), scale=1000)
-__version__ = '2014.09.06'
+__version__ = '2014.09.10'
-    _VALID_URL = r'https?://(?:(?:www|m)\.)?izlesene\.com/(?:video|embedplayer)/(?:[^/]+/)?(?P<id>[0-9]+)'
+    _VALID_URL = r'''(?x)
-    }
+    _TESTS = [
-            r"adduserUsername\s*=\s*'([^']+)';", webpage, 'uploader', fatal=False, default='')
+            r"adduserUsername\s*=\s*'([^']+)';",
-            r'"videoduration"\s*:\s*"([^"]+)"', webpage, 'duration', fatal=False))
+            r'"videoduration"\s*:\s*"([^"]+)"',
-            r'comment_count\s*=\s*\'([^\']+)\';', webpage, 'uploader', fatal=False)
+            r'comment_count\s*=\s*\'([^\']+)\';',
-            r'"quality"\s*:\s*"([^"]+)"', webpage, 'qualities', fatal=False, default='')
+        streams = self._html_search_regex(
-            )
+        if streams:
-                'url': json.get('streamurl'),
+                'format_id': 'sd',
-                'format_id': '%sp' % quality if quality else 'sd',
+from .hostingbulk import HostingBulkIE
-            r'<meta[^>]+?property=(["\'])og:video\1[^>]+?content=(["\'])(?P<url>http://player\.(?:rutv\.ru|vgtrk\.com)/flash2v/container\.swf\?id=.+?\2)',
+            r'<meta[^>]+?property=(["\'])og:video\1[^>]+?content=(["\'])(?P<url>https?://player\.(?:rutv\.ru|vgtrk\.com)/flash2v/container\.swf\?id=.+?\2)',
-    _VALID_URL = r'^https?://(?:www\.)?khanacademy\.org/(?P<key>[^/]+)/(?:[^/]+/){,2}(?P<id>[^?#/]+)(?:$|[?#])'
+    _VALID_URL = r'^https?://(?:(?:www|api)\.)?khanacademy\.org/(?P<key>[^/]+)/(?:[^/]+/){,2}(?P<id>[^?#/]+)(?:$|[?#])'
-                'filesize_approx': 17822500,
+                'filesize': 17822500,
-                'filesize_approx': 588257923,
+                'filesize': 588257923,
-            'filesize_approx': filesize,
+            'filesize': filesize,
-    IE_DESC = 'moevideo.net and playreplay.net'
+    IE_DESC = 'LetitBit video services: moevideo.net, playreplay.net and videochart.net'
-        (?:moevideo\.net|playreplay\.net))/
+        (?:(?:moevideo|playreplay|videochart)\.net))/
-    _VALID_URL = r'https?://(?:www\.)?tube8\.com/(?:[^/]+/){2}(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tube8\.com/(?:gay/|shemale/)?(?:[^/]+/){2}(?P<id>\d+)'
-    _VALID_URL = r'https?://(?:www\.)?tube8\.com/(?:[^/]+/){2}(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?tube8\.com/(?:gay/|shemale/)?(?:[^/]+/){2}(?P<id>\d+)'
-                'upload_date': '20140706'
+                'upload_date': '20140706',
-                'upload_date': '20140907'
+                'upload_date': '20140907',
-                'upload_date': '20140807'
+                'upload_date': '20140807',
-  }
+    _VALID_URL = r'http://(?:www\.)?vgtv\.no/#!/(?:.*)/(?P<id>[0-9]+)'
-    video_id = mobj.group('id')
+    def _real_extract(self, url):
-    data = self._download_json('http://svp.vg.no/svp/api/v1/vgtv/assets/%s?appName=vgtv-website' % video_id, video_id, 'Downloading media JSON')
+        data = self._download_json(
-      raise ExtractorError('Stream type \'%s\' is not yet supported.' % data['streamType'], expected=True)
+        streams = data['streamUrls']
-    thumbnail = data['images']['main'] + '?t[]=900x506q80'
+        formats = []
-    formats = []
+        hls_url = streams.get('hls')
-      raise ExtractorError('No download URL found for video: %s.' % video_id, expected=True)
+        hds_url = streams.get('hds')
-    }
+        mp4_url = streams.get('mp4')
-__version__ = '2014.09.04.3'
+__version__ = '2014.09.06'
-            u'description': u'md5:104892c71bd48e55d70b902736b81bbf',
+    _VALID_URL = r'http://utv\.unistra\.fr/(?:index|video)\.php\?id_video\=(?P<id>\d+)'
-    }
+        {
-        video_id = re.match(self._VALID_URL, url).group(1)
+        mobj = re.match(self._VALID_URL, url)
-        if files[1] != files[0]:
+
-            'ext': 'mp4'
+                'url': 'http://vod-flash.u-strasbg.fr:8080%s' % file_path,
-                }
+
-        stream.close()
+        if tmpfilename != u'-':
-  ExtractorError
+    float_or_none,
-      'duration': 69544,
+    _VALID_URL = r'http://dbtv\.no/(?P<id>[0-9]+)#(?P<display_id>.+)'
-    video = data['playlist'][0]
+    def _real_extract(self, url):
-        video_url = video['URL']
+        data = self._download_json(
-    thumbnail = video['splash']
+        video = data['playlist'][0]
-    duration = int(video['length'])
+        formats = [{
-    timestamp = float(str(video['publishedAt'])[0:-3])
+        if not formats:
-    formats = []
+        self._sort_formats(formats)
-    }
+        return {
-        file = re.search(r'file: "(.*?)",', webpage).group(1)
+        video_id = re.match(self._VALID_URL, url).group(1)
-        return {'id': id,
+        return {'id': video_id,
-                'url': video_url,
+                'formats': formats
-            [r'arte_vp_url="(.*?)"', r'data-url="([^"]+)"'],
+            [r'arte_vp_url=["\'](.*?)["\']', r'data-url=["\']([^"]+)["\']'],
-__version__ = '2014.09.04.2'
+__version__ = '2014.09.04.3'
-            r'arte_vp_url="(.*?)"', webpage, 'json vp url')
+            [r'arte_vp_url="(.*?)"', r'data-url="([^"]+)"'],
-        'md5': u'c0edcfc37607344e2ff8f13c378c88a4',
+        'md5': 'c0edcfc37607344e2ff8f13c378c88a4',
-            'description': 'Kevin Durant scores 32 points and dishes out six assists as the Thunder beat the Nets in Brooklyn.',
+            'description': 'Kevin Durant scores 32 points and dishes out six assists as the Thunder beat the Nets in Brooklyn.',
-        title = self._og_search_title(webpage, default=shortened_video_id).replace('NBA.com: ', '')
+        title = remove_end(
-        description = self._html_search_regex(r'<meta name="description" (?:content|value)="(.*?)" />', webpage, 'description', fatal=False)
+            'duration': duration,
-        u'playlist': [
+        'url': 'http://techtalks.tv/talks/learning-topic-models-going-beyond-svd/57758/',
-                    u'title': u'Learning Topic Models --- Going beyond SVD',
+                'info_dict': {
-                    u'title': u'Learning Topic Models --- Going beyond SVD',
+                'info_dict': {
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-            webpage, u'presenter play path')
+        rtmp_url = self._search_regex(
-            }
+            'id': talk_id,
-            ]
+            return {
-        'playlist_mincount': 9917,
+        'playlist_mincount': 19,
-__version__ = '2014.09.04.1'
+__version__ = '2014.09.04.2'
-translation_table = {
+_translation_table = {
-        'md5': '15e7740f30428abf70f4223478dc1225',
+        'md5': 'a2ba71eebf523859fe527a61018f723e',
-
+        video_url = _decode(pl_fiji)
-            'format_id': pl_c_qual,
+            'format_id': 'default-%s' % pl_c_qual,
-        c.store('test_cache', 'k', obj)
+        self.assertEqual(c.load('test_cache', 'k.'), None)
-        self.assertEqual(c.load('test_cache', 'k'), obj)
+        self.assertEqual(c.load('test_cache', 'k.'), obj)
-        self.assertEqual(c.load('test_cache2', 'k'), None)
+        self.assertEqual(c.load('test_cache2', 'k.'), None)
-        self.assertEqual(c.load('test_cache', 'k'), None)
+        self.assertEqual(c.load('test_cache', 'k.'), None)
-__version__ = '2014.09.04'
+__version__ = '2014.09.04.1'
-        assert re.match(r'^[a-zA-Z0-9_-]+$', key)
+        assert re.match(r'^[a-zA-Z0-9_.-]+$', section), \
-__version__ = '2014.09.01.2'
+__version__ = '2014.09.04'
-                       None to disable filesystem cache.
+                       False to disable filesystem cache.
-        '--cache-dir', dest='cachedir', default=get_cachedir(), metavar='DIR',
+        '--cache-dir', dest='cachedir', default=None, metavar='DIR',
-        '--no-cache-dir', action='store_const', const=None, dest='cachedir',
+        '--no-cache-dir', action='store_const', const=False, dest='cachedir',
-                    ydl.to_screen(u'.')
+            ydl.cache.remove()
-                    u'Cache %s failed (%s)' % (cache_fn, file_size))
+        cache_spec = self._downloader.cache.load(u'youtube-sigfuncs', func_id)
-                    u'Writing cache to %r failed: %s' % (cache_fn, tb))
+        if cache_spec is None:
-from .empflix import EmpflixIE
+from .empflix import EMPFlixIE
-import re
+from .tnaflix import TNAFlixIE
-from ..utils import fix_xml_ampersands
+class EMPFlixIE(TNAFlixIE):
-    _VALID_URL = r'^https?://www\.empflix\.com/videos/.*?-(?P<id>[0-9]+)\.html'
+            'display_id': 'Amateur-Finger-Fuck',
-    str_to_int,
+    fix_xml_ampersands,
-            #'duration': 84,
+            'duration': 91,
-        
+        title = self._html_search_regex(
-        for format_id, video_url in re.findall(r'<res>([^<]+)</res>\s*<videoLink>([^<]+)</videoLink>', sources, flags=re.MULTILINE|re.DOTALL):
+        for item in cfg_xml.findall('./quality/item'):
-            'url': video_url,
+            'description': description,
-            'age_limit': self._rta_search(webpage),
+            'duration': duration,
-        r'(?:(?:(?P<hours>[0-9]+)\s*(?:[:h]|hours?)\s*)?(?P<mins>[0-9]+)\s*(?:[:m]|mins?|minutes?)\s*)?(?P<secs>[0-9]+)(?P<ms>\.[0-9]+)?\s*(?:s|secs?|seconds?)?$', s)
+        r'(?i)(?:(?:(?P<hours>[0-9]+)\s*(?:[:h]|hours?)\s*)?(?P<mins>[0-9]+)\s*(?:[:m]|mins?|minutes?)\s*)?(?P<secs>[0-9]+)(?P<ms>\.[0-9]+)?\s*(?:s|secs?|seconds?)?$', s)
-    int_or_none,
+    float_or_none,
-    _VALID_URL = r'http://(?:www\.)?tvigle\.ru/category/.+?[\?&]v(?:ideo)?=(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www\.)?tvigle\.ru/(?:[^/]+/)+(?P<display_id>[^/]+)/$'
-            'md5': '09afba4616666249f087efc6dcf83cb3',
+            'url': 'http://www.tvigle.ru/video/brat-2/',
-                'ext': 'flv',
+                'id': '5119390',
-                'upload_date': '20110919',
+                'description': 'md5:5751f4fe345a58e1692585c361294bd8',
-            'md5': 'e7efe5350dd5011d0de6550b53c3ba7b',
+            'url': 'http://www.tvigle.ru/video/vladimir-vysotskii/vedushchii-teleprogrammy-60-minut-ssha-o-vladimire-vysotskom/',
-                'ext': 'flv',
+                'id': '5142516',
-                'upload_date': '20121218',
+                'duration': 186.080,
-        video_id = mobj.group('id')
+        display_id = mobj.group('display_id')
-            'http://www.tvigle.ru/xml/single.php?obj=%s' % video_id, video_id, 'Downloading video XML')
+        webpage = self._download_webpage(url, display_id)
-        video = video_data.find('./video')
+        video_id = self._html_search_regex(
-        like_count = int_or_none(video.get('vtp'))
+        video_data = self._download_json(
-            })
+        item = video_data['playlist']['items'][0]
-            'age_limit': 18,
+            'duration': duration,
-    int_str = re.sub(r'[,\.]', u'', int_str)
+    int_str = re.sub(r'[,\.\+]', u'', int_str)
-                'h': self._search_regex(r'name="h" value="(\w*?)"', login_results, 'h'),
+                'h': self._search_regex(
-    _VALID_URL = r'https?://(?:www\.)?eporner\.com/hd-porn/(?P<id>\d+)/(?P<title_dash>[\w-]+)/?'
+    _VALID_URL = r'https?://(?:www\.)?eporner\.com/hd-porn/(?P<id>\d+)/(?P<display_id>[\w-]+)'
-        webpage = self._download_webpage(url, video_id)
+        display_id = mobj.group('display_id')
-            r'file: "(.*?)",', player_code, 'video_url')
+            redirect_url, display_id, note='Downloading player config')
-            'url': video_url,
+            'display_id': display_id,
-            r"'480p'\s*:\s*'([^']+)'", webpage, 'video URL')
+        quality_arr = self._search_regex(
-            'url': video_url,
+            'formats': formats,
-    _VALID_URL = r'https?://(?:www\.)?drtuber\.com/video/(?P<id>\d+)/(?P<title_dash>[\w-]+)'
+    _VALID_URL = r'https?://(?:www\.)?drtuber\.com/video/(?P<id>\d+)/(?P<display_id>[\w-]+)'
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id)
-        }
+        },
-    _VALID_URL = r'https?://m\.mlb\.com/(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v(?P<id>n?\d+)'
+    _VALID_URL = r'https?://m\.mlb\.com/(?:(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v|shared/video/embed/embed\.html\?.*?\bcontent_id=)(?P<id>n?\d+)'
-__version__ = '2014.09.01.1'
+__version__ = '2014.09.01.2'
-        categories_str = self._html_search_regex(
+        cats_str = self._html_search_regex(
-        categories = categories_str.split(' ')
+        categories = None if cats_str is None else cats_str.split(' ')
-        categories = categories_str.split(',')
+        categories = (
-        webpage2 = self._download_webpage(redirect_url, video_id)
+        player_code = self._download_webpage(
-            r'file: "(.*?)",', webpage2, 'video_url')
+            r'file: "(.*?)",', player_code, 'video_url')
-from ..utils import int_or_none
+from ..utils import (
-            'duration': 550
+            'duration': 550,
-        redirect_url = self._html_search_regex(r'pg&settings=(.*?)\|0"\);', webpage, 'title')
+        webpage = self._download_webpage(
-        video_url = self._html_search_regex(r'flvMask:(.*?);', webpage2, 'video_url')
+        video_url = self._html_search_regex(
-        view_count = self._html_search_regex(r'<strong>Views:</strong>  (\d+)</div>', webpage, 'view count', fatal=False)
+        duration = parse_duration(self._search_regex(
-            'view_count': int_or_none(view_count),
+            'view_count': view_count,
-
+            'age_limit': 18,
-            'duration': 550
+            'duration': 550,
-                              (?:(?:guests/[^/]+|videos|video-playlists|special-editions)/[^/]+/(?P<videotitle>[^/?#]+))
+                              (?:(?:guests/[^/]+|videos|video-playlists|special-editions|news-team/[^/]+)/[^/]+/(?P<videotitle>[^/?#]+))
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                    ydl.to_screen(u'Not removing directory %s - this does not look like a cache dir')
+                    ydl.to_screen(u'Not removing directory %s - this does not look like a cache dir' % opts.cachedir)
-            'ext': 'mp4',
+            'ext': 'm4v',
-        )
+        token = self._search_regex(r'npoplayer\.token = "(.+?)"', token_page, 'token')
-        )
+        formats = []
-            'url': stream_info['url'],
+            'formats': formats,
-                    f['acodec'] = audio.partition('.')[0]
+                    # TODO: looks like video codec is not always necessarily goes first
-        fcntl.lockf(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)
+        fcntl.flock(f, fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH)
-        fcntl.lockf(f, fcntl.LOCK_UN)
+        fcntl.flock(f, fcntl.LOCK_UN)
-                       for vid_id in ids]
+        return [
-        webpage = self._download_webpage(url, playlist_id, u'Downloading Youtube mix')
+        webpage = self._download_webpage(
-            search_title('title long-title') or search_title('title'))
+        title_span = (
-        ids = orderedSet(re.findall(video_re, webpage, flags=re.DOTALL))
+        ids = orderedSet(re.findall(
-__version__ = '2014.09.01'
+__version__ = '2014.09.01.1'
-            u"title": u"å¡é©¬ä¹å½è¶³å¼å¤§èé¿ä¼ å²åéé¦"
+        'url': 'http://www.tudou.com/listplay/zzdE77v6Mmo/2xN2duXMxmw.html',
-            u'title': u'todo.mp4',
+    }, {
-        u'skip': u'Only works from China'
+        'add_ie': ['Youku'],
-                'url': u'youku:' + m.group(1),
+                'url': 'youku:' + m.group(1),
-            r",kw:\s*['\"](.+?)[\"']", webpage, u'title')
+            r",kw:\s*['\"](.+?)[\"']", webpage, 'title')
-            r",pic:\s*[\"'](.+?)[\"']", webpage, u'thumbnail URL', fatal=False)
+            r",pic:\s*[\"'](.+?)[\"']", webpage, 'thumbnail URL', fatal=False)
-                          }
+            part_info = {
-__version__ = '2014.08.29'
+__version__ = '2014.09.01'
-        video_url = self._html_search_regex(r"'480p'\s*:\s*'([^']+)'", webpage, 'video URL')
+        video_url = self._html_search_regex(
-        title = self._html_search_regex(r'<title>([^<]+)\s*-\s*beeg\.?</title>', webpage, 'title')
+        title = self._html_search_regex(
-        
+            r'<meta name="description" content="([^"]*)"',
-            r'\'previewer.url\'\s*:\s*"([^"]*)"', webpage, 'thumbnail', fatal=False)
+            r'\'previewer.url\'\s*:\s*"([^"]*)"',
-from ..utils import int_or_none
+from ..utils import (
-    _VALID_URL = r'http?://(?:www\.)?eporner\.com/hd-porn/(?P<id>\d+)/(?P<title_dash>[\w-]+)/?'
+    _VALID_URL = r'https?://(?:www\.)?eporner\.com/hd-porn/(?P<id>\d+)/(?P<title_dash>[\w-]+)/?'
-            'duration': 194
+            'duration': 194,
-        title = self._html_search_regex(r'<title>(.*?) - EPORNER', webpage, 'title')
+        title = self._html_search_regex(
-        redirect_url = 'http://www.eporner.com/config5/' + str(video_id) +'/'+ redirect_code
+        redirect_code = self._html_search_regex(
-        duration = int(mobj.group('minutes')) * 60 + int(mobj.group('seconds')) if mobj else None
+        video_url = self._html_search_regex(
-            pass
+        duration = parse_duration(self._search_regex(
-            'view_count': int_or_none(view_count),
+            'duration': duration,
-
+class YoutubeSubscriptionsIE(YoutubePlaylistIE):
-        m_cat_container = get_element_by_id("eow-category", video_webpage)
+        m_cat_container = self._search_regex(
-        quality = sorted(filter(lambda k: k.isdigit(), segments.keys()))[-1]
+        quality = sorted(filter(lambda k: k.isdigit(), segments.keys()),
-        quality = sorted(segments.keys())[-1]
+        # Also, filter non-number qualities (see issue #3643).
-        
+        title = self._html_search_regex(r'<title>([^<]+)</title>', webpage, 'title')
-            r'poster="([^"]*)"', webpage, 'thumbnail', fatal=False)
+            r'poster="([^"]+)"', webpage, 'thumbnail', fatal=False)
-            'url': video_url,
+            'comment_count': comment_count,
-        def _extract_count(klass):
+        def _extract_count(count_name):
-                video_webpage, klass, default=None)
+                r'id="watch-%s"[^>]*>.*?([\d,]+)\s*</span>' % re.escape(count_name),
-        dislike_count = _extract_count(u'dislikes-count')
+        like_count = _extract_count(u'like')
-from ..utils import int_or_none
+from ..utils import (
-    _VALID_URL = r'http?://(?:www\.)?anysex\.com/(?P<id>\d+)/?'
+    _VALID_URL = r'https?://(?:www\.)?anysex\.com/(?P<id>\d+)'
-        thumbnail = self._html_search_regex(r'preview_url: \'(.*?)\',', webpage, 'thumbnail')
+        description = self._html_search_regex(
-        duration = int(mobj.group('minutes')) * 60 + int(mobj.group('seconds')) if mobj else None
+        categories = re.findall(
-        view_count = self._html_search_regex(r'<b>Views:</b> (\d+)', webpage, 'view count', fatal=False)
+        duration = parse_duration(self._search_regex(
-            'ext': 'mp4',
+            'ext': 'mp4',
-            'view_count': int_or_none(view_count),
+            'description': description,
-from ..utils import int_or_none
+from ..utils import (
-    _VALID_URL = r'http?://(?:www\.)?vporn\.com/[a-z]+/(?P<title_dash>[a-z-]+)/(?P<id>\d+)/?'
+    _VALID_URL = r'https?://(?:www\.)?vporn\.com/[^/]+/(?P<display_id>[^/]+)/(?P<id>\d+)'
-            'title': 'Violet On Her 19th Birthday',
+            'title': 'Violet on her 19th birthday',
-            'duration': 393,
+            'uploader': 'kileyGrope',
-        thumbnail = 'http://www.vporn.com' + self._html_search_regex(r'flashvars.imageUrl = "(.*?)"', webpage, 'description')
+        categories = re.findall(r'<a href="/cat/[^"]+">([^<]+)</a>', webpage)
-        duration = int(mobj.group('minutes')) * 60 + int(mobj.group('seconds')) if mobj else None
+        duration = parse_duration(self._search_regex(
-            pass
+        view_count = str_to_int(self._html_search_regex(
-            'thumbnail': thumbnail,
+            'display_id': display_id,
-            'view_count': int_or_none(view_count),
+            'thumbnail': thumbnail,
-        r'(?:(?:(?P<hours>[0-9]+)[:h])?(?P<mins>[0-9]+)[:m])?(?P<secs>[0-9]+)s?(?::[0-9]+)?(?P<ms>\.[0-9]+)?$', s)
+        r'(?:(?:(?P<hours>[0-9]+)\s*(?:[:h]|hours?)\s*)?(?P<mins>[0-9]+)\s*(?:[:m]|mins?|minutes?)\s*)?(?P<secs>[0-9]+)(?P<ms>\.[0-9]+)?\s*(?:s|secs?|seconds?)?$', s)
-        view_count = int(mobj.group('thousands')) * 1000 + int(mobj.group('units')) if mobj else None
+        try:
-        view_count = int(mobj.group('thousands')) * 1000 + int(mobj.group('units')) if mobj else None
+        try:
-            'duration': duration,
+            'duration': int_or_none(duration),
-            r'<span class="f_right">duration (?P<minutes>\d+) min (?P<seconds>\d+) sec </span>', webpage)
+        mobj = re.search(r'<span class="f_right">duration (?P<minutes>\d+) min (?P<seconds>\d+) sec </span>', webpage)
-            'duration': duration,
+            'duration': int_or_none(duration),
-            'duration': 270
+            'duration': 270,
-            'view_count': view_count
+            'view_count': int_or_none(view_count),
-            subtitles[lang_code] = self._convert_subtitles_to_srt(subtitle)
+            if sub_format == 'ass':
-__version__ = '2014.08.28.2'
+__version__ = '2014.08.29'
-            'quality': 1,
+        self._sort_formats(formats)
-__version__ = '2014.08.28.1'
+__version__ = '2014.08.28.2'
-            'ext': 'flv',
+            'ext': 'mp4',
-                'onze mobiele apps.',
+            'description': 'md5:6b61f66510c8889923b11f2778c72dc5',
-        f4m_url = 'http://manifest.us.rtl.nl' + material['videopath']
+        videopath = material['videopath']
-            'formats': self._extract_f4m_formats(f4m_url, uuid),
+            'formats': formats,
-__version__ = '2014.08.28'
+__version__ = '2014.08.28.1'
-        'md5': '8a3d905427a6951ccb9eb292f154530b',
+        'url': 'https://www.dropbox.com/s/nelirfsxnmcfbfh/youtube-dl%20test%20video%20%27%C3%A4%22BaW_jenozKc.mp4?dl=0',
-        video_url = url + '?dl=1'
+        video_url = (
-                if last_info is none:
+                if last_info is None:
-    _TEST = {
+    _TESTS = [{
-            'thumbnail': 're:^https?://.*\.jpg',
+            'thumbnail': 're:^https?://.*\.jpg$',
-            'upload_date': '20140826',
+            'timestamp': int,
-    }
+    }, {
-        formats = self._extract_m3u8_formats(m3u8_url, video_id, ext='mp4')
+        if '.smil' in smil_url:
-            'rtmp_live': asset['live'],
+            'rtmp_live': asset.get('live'),
-__version__ = '2014.08.27.1'
+__version__ = '2014.08.28'
-        'file': '4686958.mp4',
+            'id': '4686958',
-                self.to_screen(u'%s' % (note,))
+                self.to_screen('%s' % (note,))
-                self.to_screen(u'%s: %s' % (video_id, note))
+                self.to_screen('%s: %s' % (video_id, note))
-            errmsg = u'%s: %s' % (errnote, compat_str(err))
+                errnote = 'Unable to download webpage'
-            self.to_screen(u'Dumping request to ' + url)
+            self.to_screen('Dumping request to ' + url)
-                h = u'___' + hashlib.md5(basen.encode('utf-8')).hexdigest()
+                h = '___' + hashlib.md5(basen.encode('utf-8')).hexdigest()
-            self.to_screen(u'Saving request to ' + filename)
+            self.to_screen('Saving request to ' + filename)
-            msg = u'Access to this webpage has been blocked by Websense filtering software in your network.'
+        if ('<title>Access to this site is blocked</title>' in content and
-                u'Websense information URL', default=None)
+                'Websense information URL', default=None)
-                msg += u' Visit %s for more details' % blocked_iframe
+                msg += ' Visit %s for more details' % blocked_iframe
-                      note=u'Downloading XML', errnote=u'Unable to download XML',
+                      note='Downloading XML', errnote='Unable to download XML',
-                       errnote=u'Unable to download JSON metadata',
+                       note='Downloading JSON metadata',
-        idstr = u'' if video_id is None else u'%s: ' % video_id
+        idstr = '' if video_id is None else '%s: ' % video_id
-            u'[%s] %s%s' % (self.IE_NAME, idstr, msg))
+            '[%s] %s%s' % (self.IE_NAME, idstr, msg))
-        self._downloader.to_screen(u'[%s] %s' % (self.IE_NAME, msg))
+        self._downloader.to_screen('[%s] %s' % (self.IE_NAME, msg))
-        self.to_screen(u'%s: Extracting information' % id_or_name)
+        self.to_screen('%s: Extracting information' % id_or_name)
-        self.to_screen(u'%s: Downloading webpage' % video_id)
+        self.to_screen('%s: Downloading webpage' % video_id)
-        self.to_screen(u'Confirming age')
+        self.to_screen('Confirming age')
-        self.to_screen(u'Logging in')
+        self.to_screen('Logging in')
-            _name = u'\033[0;34m%s\033[0m' % name
+            _name = '\033[0;34m%s\033[0m' % name
-            raise RegexNotFoundError(u'Unable to extract %s' % _name)
+            raise RegexNotFoundError('Unable to extract %s' % _name)
-                u'please report this issue on http://yt-dl.org/bug' % _name)
+            self._downloader.report_warning('unable to extract %s; '
-                self._downloader.report_warning(u'parsing .netrc: %s' % compat_str(err))
+                self._downloader.report_warning('parsing .netrc: %s' % compat_str(err))
-        return self._og_search_property('image', html, u'thumbnail url', fatal=False, **kargs)
+        return self._og_search_property('image', html, 'thumbnail url', fatal=False, **kargs)
-            raise ExtractorError(u'No video formats found')
+            raise ExtractorError('No video formats found')
-                    ORDER = [u'aac', u'mp3', u'm4a', u'webm', u'ogg', u'opus']
+                    ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']
-                    ORDER = [u'webm', u'opus', u'ogg', u'mp3', u'aac', u'm4a']
+                    ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']
-                    ORDER = [u'flv', u'mp4', u'webm']
+                    ORDER = ['flv', 'mp4', 'webm']
-                    ORDER = [u'webm', u'flv', u'mp4']
+                    ORDER = ['webm', 'flv', 'mp4']
-            msg_template = u'%(video_id)s: Waiting for %(timeout)s seconds'
+            msg_template = '%(video_id)s: Waiting for %(timeout)s seconds'
-            raise ExtractorError(u'Invalid search query "%s"' % query)
+            raise ExtractorError('Invalid search query "%s"' % query)
-                raise ExtractorError(u'invalid download number %s for query "%s"' % (n, query))
+                raise ExtractorError('invalid download number %s for query "%s"' % (n, query))
-                self._downloader.report_warning(u'%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))
+                self._downloader.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))
-                'Expected a %r object, but got %r' % (compat_str, type(got)))
+                u'Expected a %s object, but got %s for field %s' % (
-                        len(res_dict['entries']),
+                        test_case['playlist_count'],
-                        test_case['playlist_count']))
+                        len(res_dict['entries']),
-    unittest.main()
+    _TEST = {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            if len(results) == 0:
+            data = self._download_json(
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            return self.url_result(u'vevo:%s' % vevo_id, ie='Vevo')
+            self.to_screen('Vevo video detected: %s' % vevo_id)
-                                            u'Downloading embed page')
+                                            'Downloading embed page')
-            raise ExtractorError(u'Unable to extract video URL')
+            raise ExtractorError('Unable to extract video URL')
-            r'video_views_count[^>]+>\s+([\d\.,]+)', webpage, u'view count', fatal=False)
+            r'video_views_count[^>]+>\s+([\d\.,]+)', webpage, 'view count', fatal=False)
-            self._downloader.report_warning(u'unable to download video subtitles: %s' % compat_str(err))
+            self._downloader.report_warning('unable to download video subtitles: %s' % compat_str(err))
-        self._downloader.report_warning(u'video doesn\'t have subtitles')
+        self._downloader.report_warning('video doesn\'t have subtitles')
-    IE_NAME = u'dailymotion:playlist'
+    IE_NAME = 'dailymotion:playlist'
-                                             id, u'Downloading page %s' % pagenum)
+                                             id, 'Downloading page %s' % pagenum)
-    IE_NAME = u'dailymotion:user'
+    IE_NAME = 'dailymotion:user'
-            webpage, u'user', flags=re.DOTALL))
+            webpage, 'user'))
-    _TEST = {
+    _TESTS = [{
-        'file': '5bfseWNmlds.mp4',
+            'id': '5bfseWNmlds',
-    }
+    }, {
-    _TEST = {
+    _TESTS = [{
-        'file': 'one-time-pad.mp4',
+            'id': 'one-time-pad',
-    }
+    }, {
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        else:
+        og_video = self._og_search_video_url(
-            return self._extract_video_info(info)
+            if 'play_url' in query:
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        urls = orderedSet(re.findall(r'<a href="(https?://livestre\.am/.*?)"', webpage))
+        paths = orderedSet(re.findall(
-            } for video_url in urls],
+                'url': compat_urlparse.urljoin(url, p),
-    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console\?.*?(?<=[?&])id=(?P<id>\d+)'
+    _VALID_URL = r'https?://video(?P<team>\.[^.]*)?\.nhl\.com/videocenter/console\?.*?(?:[?&])id=(?P<id>[0-9]+)'
-    _VALID_URL = r'https?://video\.(?P<team>[^.]*)\.nhl\.com/videocenter/(console\?.*?catid=(?P<catid>[^&]+))?'
+    _VALID_URL = r'https?://video\.(?P<team>[^.]*)\.nhl\.com/videocenter/(console\?.*?catid=(?P<catid>[0-9]+)(?![&?]id=).*?)?$'
-                            (?!sets/)(?P<title>[\w\d-]+)/?
+                            (?!sets/|likes/?(?:$|[?#]))
-    _TESTS = []
+    _TESTS = [{
-                }
+        return {
-    _TESTS = []
+    _TESTS = [{
-    _TESTS = []
+        {
-        webpage = self._download_webpage(url, slug)
+        display_id = m.group('slug')
-            reply = json.loads(self._download_webpage(compat_urlparse.urljoin(BASE, next_url), channel_id))
+            reply = self._download_json(
-        return self.playlist_result(url_entries, channel_id)
+        entries = [
-            u'Downloading final video url')
+        path_doc = self._download_xml(
-    IE_NAME = u'nhl.com'
+    IE_NAME = 'nhl.com'
-            u'upload_date': u'20131006',
+        'url': 'http://video.canucks.nhl.com/videocenter/console?catid=6?id=453614',
-        return self._extract_video(info)
+        data = self._download_json(
-    IE_DESC = u'NHL videocenter category'
+    IE_NAME = 'nhl.com:videocenter'
-        return super(NHLVideocenterIE, cls).suitable(url)
+    _TEST = {
-            webpage, u'category id')
+            webpage, 'category id')
-            webpage, u'playlist title', flags=re.DOTALL).lower().capitalize()
+            webpage, 'playlist title', flags=re.DOTALL).lower().capitalize()
-                                            u'adding the "newvideos" parameter')
+                                            'adding the "newvideos" parameter')
-            'entries': [self._extract_video(i) for i in videos],
+            'entries': [self._extract_video(v) for v in videos],
-    IE_NAME = u'dailymotion'
+    IE_NAME = 'dailymotion'
-        (u'stream_h264_hd1080_url', u'hd180'),
+        ('stream_h264_ld_url', 'ld'),
-                u"title": u"Tutoriel de Youtubeur\"DL DES VIDEO DE YOUTUBE\""
+            'url': 'http://www.dailymotion.com/video/x33vw9_tutoriel-de-youtubeur-dl-des-video_tech',
-                u'upload_date': u'20130905',
+            'url': 'http://www.dailymotion.com/video/x149uew_katy-perry-roar-official_musi',
-                u'skip_download': True,
+            'params': {
-            u'skip': u'VEVO is only available in some countries',
+            'skip': 'VEVO is only available in some countries',
-                u'age_limit': 18,
+            'url': 'http://www.dailymotion.com/video/xyh2zz_leanna-decker-cyber-girl-of-the-year-desires-nude-playboy-plus_redband',
-
+from __future__ import unicode_literals
-        aumlaut = _compat_str('\xe4')
+        aumlaut = 'Ã¤'
-        tests = _compat_str('\u043a\u0438\u0440\u0438\u043b\u043b\u0438\u0446\u0430')
+        tests = '\u043a\u0438\u0440\u0438\u043b\u043b\u0438\u0446\u0430'
-        tests = _compat_str('a\xe4b\u4e2d\u56fd\u7684c')
+        tests = 'a\xe4b\u4e2d\u56fd\u7684c'
-        self.assertTrue(sanitize_filename(_compat_str('\xf6'), restricted=True) != '')  # No empty filename
+        self.assertTrue(sanitize_filename('\xf6', restricted=True) != '')  # No empty filename
-        self.assertEqual(sanitize_filename(_compat_str('\u603b\u7edf: Speech'), restricted=True), 'Speech')
+        self.assertEqual(sanitize_filename('\u5927\u58f0\u5e26 - Song', restricted=True), 'Song')
-        self.assertEqual(unescapeHTML(_compat_str('%20;')), _compat_str('%20;'))
+        self.assertEqual(unescapeHTML('%20;'), '%20;')
-        testxml = u'''<root>
+        testxml = '''<root>
-        testhtml = u'''
+        testhtml = '''
-        self.assertEqual(get_meta('description'), u'foo & bar')
+        self.assertEqual(get_meta('description'), 'foo & bar')
-        testxml = u'''<root xmlns:media="http://example.com/">
+        testxml = '''<root xmlns:media="http://example.com/">
-        self.assertEqual(find('media:song/url').text, u'http://server.com/download.mp3')
+        self.assertEqual(find('media:song/media:author').text, 'The Author')
-        self.assertEqual(shell_quote(args), u"""ffmpeg -i 'Ã±â¬Ã'"'"'.mp4'""")
+        args = ['ffmpeg', '-i', encodeFilename('Ã±â¬Ã\'.mp4')]
-        self.assertEqual(url_basename(u'http://foo.de/bar/baz/'), u'baz')
+        self.assertEqual(url_basename('http://foo.de/'), '')
-            u'trailer.mp4')
+            url_basename('http://media.w3.org/2010/05/sintel/trailer.mp4'),
-        self.assertEqual(struct_unpack(u'!B', b'\x00'), (0,))
+        self.assertEqual(struct_unpack('!B', b'\x00'), (0,))
-        f = io.StringIO(u'''\xef\xbb\xbf foo
+        f = io.StringIO('''\xef\xbb\xbf foo
-        self.assertEqual(read_batch_urls(f), [u'foo', u'bar', u'baz', u'bam'])
+        self.assertEqual(read_batch_urls(f), ['foo', 'bar', 'baz', 'bam'])
-        self.assertEqual(uppercase_escape(u'\\U0001d550'), u'ð')
+        self.assertEqual(uppercase_escape('aÃ¤'), 'aÃ¤')
-    return (u'&%s;' % entity)
+def _htmlentity_transform(entity):
-    return result
+    return re.sub(
-            for tc in test_cases:
+        res_dict = None
-                    'Expected at %d in playlist %s, but got %d.')
+                    'Expected %d entries in playlist %s, but got %d.' % (
-        except (OSError, IOError):
+        if not check_executable('rtmpdump', ['-h']):
-                subprocess.call([program, '-version'], stdout=(open(os.path.devnull, 'w')), stderr=subprocess.STDOUT)
+            if check_executable(program, ['-version']):
-            self.report_error(u'ffmpeg exited with code %d' % retval)
+            self.report_error(u'%s exited with code %d' % (program, retval))
-                r'root\.App\.Cache\.context\.videoCache\.curVideo = \{"([^"]+)"'
+                r'root\.App\.Cache\.context\.videoCache\.curVideo = \{"([^"]+)"',
-            'id': 'P9gjWjelt6iP',
+            'id': 'WWF_5KqY3PK1',
-
+        (?!channels/[^/?#]+/?(?:$|[?#])|album/)
-    _VALID_URL = r'(?:https?://)?vimeo\.com/channels/(?P<id>[^/]+)/?(\?.*)?$'
+    _VALID_URL = r'https?://vimeo\.com/channels/(?P<id>[^/?#]+)/?(?:$|[?#])'
-    _VALID_URL = r'(?:https?://)?vimeo\.com/(?P<name>[^/]+)(?:/videos|[#?]|$)'
+    _VALID_URL = r'https?://vimeo\.com/(?![0-9]+(?:$|[?#/]))(?P<name>[^/]+)(?:/videos|[#?]|$)'
-        return super(VimeoUserIE, cls).suitable(url)
+    _TESTS = [{
-    _VALID_URL = r'(?:https?://)?vimeo\.com/album/(?P<id>\d+)'
+    _VALID_URL = r'https?://vimeo\.com/album/(?P<id>\d+)'
-                    self.assertFalse(ie.suitable(url), '%s should not match URL %r' % (type(ie).__name__, url))
+                    self.assertFalse(
-    _TEST = {
+    _VALID_URL = r'https?://vimeo\.com/[^/]+/review/(?P<id>[^/]+)'
-    }
+    }, {
-        (?:video/video\.php|photo\.php|video/embed)\?(?:.*?)
+        (?:video/video\.php|photo\.php|video\.php|video/embed)\?(?:.*?)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-__version__ = '2014.08.27'
+__version__ = '2014.08.27.1'
-from .ard import ARDIE
+from .ard import ARDIE, ARDMediathekIE
-class ARDIE(InfoExtractor):
+class ARDMediathekIE(InfoExtractor):
-            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source.*?)? src="([^"]+)"', webpage)
+            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source[^>]+)? src="([^"]+)"', webpage)
-                    return '.' in vpath and not vpath.endswith('.swf')
+                    vext = determine_ext(vpath)
-__version__ = '2014.08.26'
+__version__ = '2014.08.27'
-    location:       Physical location of the video.
+    location:       Physical location where the video was filmed.
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>mofosex\.com/videos/(?P<videoid>[0-9]+)/.*?\.html)'
+    _VALID_URL = r'^https?://(?:www\.)?(?P<url>mofosex\.com/videos/(?P<videoid>[0-9]+)/.*?\.html)'
-            u"age_limit": 18,
+        'url': 'http://www.mofosex.com/videos/5018/japanese-teen-music-video.html',
-        video_url = compat_urllib_parse.unquote(self._html_search_regex(r'flashvars.video_url = \'([^\']+)', webpage, u'video_url'))
+        video_title = self._html_search_regex(r'<h1>(.+?)<', webpage, 'title')
-__version__ = '2014.08.25.3'
+__version__ = '2014.08.26'
-        title = self._html_search_regex(r'<h1>(.+)<strong>', webpage, 'title')
+        title = self._html_search_regex((
-            cfg_url, video_id, note='Downloading metadata')
+        cfg_xml = self._download_xml(
-                r'<item>\s*<res>([^>]+)</res>\s*<videoLink>([^<]+)</videoLink>\s*</item>', cfg_xml)
+                'url': item.find('videoLink').text,
-            r'<startThumb>([^<]+)</startThumb>', cfg_xml, 'thumbnail', fatal=False)
+        thumbnail = cfg_xml.find('./startThumb').text
-        elif page_type != 'video':
+        if page_type != 'video':
-        cfg_xml = self._download_xml(
+        # XML is malformed
-            } for item in cfg_xml.findall('./quality/item')
+                'url': item[1],
-                self._request_webpage(url, None, False)
+                self._request_webpage(HEADRequest(url), None, False)
-            req.add_header(h, v)
+        for h, v in std_headers.items():
-    ExtractorError,
+    compat_str,
-        u"playlist": [
+        "name": "EightTracks",
-                    u"uploader_id": u"ytdl"
+                "md5": "96ce57f24389fc8734ce47f4c1abcc55",
-                    u"uploader_id": u"ytdl"
+                "md5": "4ab26f05c1f7291ea460a3920be8021f",
-                    u"uploader_id": u"ytdl"
+                "md5": "d30b5b5f74217410f4689605c35d1fd7",
-                    u"uploader_id": u"ytdl"
+                "md5": "4eb0a669317cd725f6bbd336a29f923a",
-                    u"uploader_id": u"ytdl"
+                "md5": "1893e872e263a2705558d1d319ad19e8",
-                    u"uploader_id": u"ytdl"
+                "md5": "b673c46f47a216ab1741ae8836af5899",
-                    u"uploader_id": u"ytdl"
+                "md5": "1d74534e95df54986da7f5abf7d842b7",
-                    u"uploader_id": u"ytdl"
+                "md5": "f081f47af8f6ae782ed131d38b9cd1c0",
-        json_like = self._search_regex(r"PAGE.mix = (.*?);\n", webpage, u'trax information', flags=re.DOTALL)
+        json_like = self._search_regex(
-        res = []
+        entries = []
-                errnote=u'Failed to download song information')
+            api_json = self._download_webpage(
-            track_data = api_data[u'set']['track']
+            track_data = api_data['set']['track']
-                'id': track_data['id'],
+                'id': compat_str(track_data['id']),
-        return res
+            entries.append(info)
-__version__ = '2014.08.25.2'
+__version__ = '2014.08.25.3'
-                isinstance(got, compat_str) and match_rex.match(got),
+                isinstance(got, compat_str),
-                self.assertGreaterEqual(
+                assertGreaterEqual(
-
+        },
-    return xml.etree.ElementTree.XML(s.encode('utf-8'), **kwargs)
+    tree = xml.etree.ElementTree.XML(s.encode('utf-8'), **kwargs)
-    _VALID_URL = r'https?://(?:\w+\.)?blip\.tv/(?:(?:.+-|rss/flash/)(?P<id>\d+)|((?:play/|api\.swf#)(?P<lookup_id>[\da-zA-Z+_TESTS]+)))'
+    _VALID_URL = r'https?://(?:\w+\.)?blip\.tv/(?:(?:.+-|rss/flash/)(?P<id>\d+)|((?:play/|api\.swf#)(?P<lookup_id>[\da-zA-Z+_]+)))'
-
+    _TEST = {
-__version__ = '2014.08.25.1'
+__version__ = '2014.08.25.2'
-__version__ = '2014.08.25'
+__version__ = '2014.08.25.1'
-)
+from ..utils import unified_strdate
-            'duration': 120,
+    _TESTS = [
-    }
+    ]
-                'This content is marked as not available in your area. Trying anyway ..')
+        geo_list = video_info.get('geoList')
-            timestamp = '%08x' % int(time.time())
+            timestamp = '%08x' % int(self._download_webpage(
-                'http://www.wat.tv/get%s?token=%s&getURL=1' % (webid, compute_token(webid)),
+                'http://www.wat.tv/get%s?token=%s&getURL=1&country=%s' % (webid, compute_token(webid), country),
-        for media_el in manifest.findall('{http://ns.adobe.com/f4m/1.0}media'):
+        media_nodes = manifest.findall('{http://ns.adobe.com/f4m/1.0}media')
-                'tbr': int_or_none(media_el.attrib.get('bitrate')),
+                'tbr': tbr,
-            'title': '%s - %s' % (progname, subtitle), 
+            'title': '%s - %s' % (progname, subtitle),
-        r'(?:(?:(?P<hours>[0-9]+)[:h])?(?P<mins>[0-9]+)[:m])?(?P<secs>[0-9]+)s?(?::[0-9]+)?$', s)
+        r'(?:(?:(?P<hours>[0-9]+)[:h])?(?P<mins>[0-9]+)[:m])?(?P<secs>[0-9]+)s?(?::[0-9]+)?(?P<ms>\.[0-9]+)?$', s)
-        help='Execute a command on the file after downloading, similar to find\'s -exec syntax. Must be enclosed in quotes. Example: --exec \'adb push {} /sdcard/Music/ && rm {}\'' )
+    postproc.add_option(
-        'execstring': opts.execstring,
+        'exec_cmd': opts.exec_cmd,
-            ydl.add_post_processor(ExecAfterDownloadPP(verboseOutput=opts.verbose,commandString=opts.execstring))
+        if opts.exec_cmd:
-from ..utils import PostProcessingError
+
-import shlex
+
-    def __init__(self, downloader=None, verboseOutput=None, commandString=None):
+    def __init__(self, downloader=None, verboseOutput=None, exec_cmd=None):
-        self.commandString = commandString
+        self.exec_cmd = exec_cmd
-            print("[exec] Command exited with return code: " + str(self.retCode))
+        cmd = self.exec_cmd
-        return None, information  # by default, keep file and do nothing
+        cmd = cmd.replace('{}', shlex_quote(information['filepath']))
-    pass
+try:
-__version__ = '2014.08.24.6'
+__version__ = '2014.08.25'
-    ExecAfterDownload,
+    ExecAfterDownloadPP,
-            ydl.add_post_processor(ExecAfterDownload(commandString=opts.execstring))
+            ydl.add_post_processor(ExecAfterDownloadPP(verboseOutput=opts.verbose,commandString=opts.execstring))
-from .execafterdownload import ExecAfterDownload
+from .execafterdownload import ExecAfterDownloadPP
-    'ExecAfterDownload',
+    'ExecAfterDownloadPP',
-import os, re, shlex
+from __future__ import unicode_literals
-        self._downloader = downloader
+class ExecAfterDownloadPP(PostProcessor):
-        self._downloader = downloader
+    def run(self, information):
-        self.finalCommand = None;
+        # Replace all instances of '{}' with the file name and convert argument list to single string.
-            self.finalCommand = self.commandString + ' \'' + self.targetFile + '\''
+        if self.targetFile not in self.commandString:  # Assume user wants the file appended to the end of the command if no {}'s were given.
-            raise PostProcessingExecError( "Invalid syntax for --exec post processor" )
+        print("[exec] Executing command: " + self.commandString)
-class PostProcessingExecError( PostProcessingError ):
+
-
+    postproc.add_option('--exec', metavar='', action='store', dest='execstring',
-                template_dict['playlist_index'] = '%0*d' % (len(str(template_dict['n_playlist'])), template_dict['playlist_index'])
+                template_dict['playlist_index'] = '%0*d' % (len(str(template_dict['n_entries'])), template_dict['playlist_index'])
-                    'n_playlist': n_entries,
+                    'n_entries': n_entries,
-                template_dict['playlist_index'] = '%05d' % template_dict['playlist_index']
+                template_dict['playlist_index'] = '%0*d' % (len(str(template_dict['n_playlist'])), template_dict['playlist_index'])
-__version__ = '2014.08.24.5'
+__version__ = '2014.08.24.6'
-            raise ExtractorError('This content is not available in your area', expected=True)
+            self.report_warning(
-    compat_urllib_request,
+    'Ole Ernst',
-        assertGreaterEqual(self, len(result['entries']), 294)
+
-        entries = [self.url_result('http://www.gameone.de/tv/%d' % video_id, 'GameOne') for video_id in range(max_id, 0, -1)]
+        entries = [
-__version__ = '2014.08.24.4'
+__version__ = '2014.08.24.5'
-            response = self._send_head(url)
+        head_req = HEADRequest(url)
-__version__ = '2014.08.24.3'
+__version__ = '2014.08.24.4'
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?pornotube\.com(/c/(?P<channel>[0-9]+))?(/m/(?P<videoid>[0-9]+))(/(?P<title>.+))$'
+    _VALID_URL = r'https?://(?:\w+\.)?pornotube\.com(/c/(?P<channel>[0-9]+))?(/m/(?P<videoid>[0-9]+))(/(?P<title>.+))$'
-            u"age_limit": 18
+        'url': 'http://pornotube.com/c/173/m/1689755/Marilyn-Monroe-Bathing',
-        video_url = self._search_regex(VIDEO_URL_RE, webpage, u'video url')
+        video_url = self._search_regex(VIDEO_URL_RE, webpage, 'video url')
-        if upload_date: upload_date = unified_strdate(upload_date)
+        upload_date = self._html_search_regex(VIDEO_UPLOADED_RE, webpage, 'upload date', fatal=False)
-        return [info]
+        return {
-__version__ = '2014.08.24.2'
+__version__ = '2014.08.24.3'
-__version__ = '2014.08.24.1'
+__version__ = '2014.08.24.2'
-        video_id = os.path.splitext(url.rstrip('/').split('/')[-1])[0]
+
-from ..utils import determine_ext
+from .wayofthemaster import WayOfTheMasterIE
-            'ext': determine_ext(video_url),
+from __future__ import unicode_literals
-            u'uploader': u'jihadpizza',
+        'url': 'http://www.ebaumsworld.com/video/watch/83367677/',
-__version__ = '2014.08.24'
+__version__ = '2014.08.24.1'
-    _VALID_URL = r'https?://(?:\w+\.)?blip\.tv/(?:(?:.+-|rss/flash/)(?P<id>\d+)|((?:play/|api\.swf#)(?P<lookup_id>[\da-zA-Z+]+)))'
+    _VALID_URL = r'https?://(?:\w+\.)?blip\.tv/(?:(?:.+-|rss/flash/)(?P<id>\d+)|((?:play/|api\.swf#)(?P<lookup_id>[\da-zA-Z+_TESTS]+)))'
-        mobj = re.search(r'<(?:iframe|embed|object)\s[^>]*(https?://(?:\w+\.)?blip\.tv/(?:play/|api\.swf#)[a-zA-Z0-9]+)', webpage)
+        mobj = re.search(r'<(?:iframe|embed|object)\s[^>]*(https?://(?:\w+\.)?blip\.tv/(?:play/|api\.swf#)[a-zA-Z0-9_]+)', webpage)
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?blip\.tv/)|bliptvuser:)([^/]+)/*$'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?blip\.tv/)|bliptvuser:)(?!api\.swf)([^/]+)/*$'
-    _VALID_URL = r'https?://creative\.arte\.tv/(?P<lang>fr|de)/magazine?/(?P<id>.+)'
+    _VALID_URL = r'https?://creative\.arte\.tv/(?P<lang>fr|de)/(?:magazine?/)?(?P<id>[^?#]+)'
-    _TEST = {
+    _TESTS = [{
-            'id': '050489-002',
+            'id': '72176',
-            'title': 'Agentur Amateur / Agence Amateur #2 : Corporate Design',
+            'title': 'Folge 2 - Corporate Design',
-    }
+    }, {
-__version__ = '2014.08.23'
+__version__ = '2014.08.24'
-        url_m = re.search(r'<meta\s+property="og:video"\s+content="(http://c.brightcove.com/[^"]+)"', webpage)
+        url_m = re.search(
-            if 'playerKey' in url:
+            if 'playerKey' in url or 'videoId' in url:
-                    return not vpath.endswith('.swf')
+                    return '.' in vpath and not vpath.endswith('.swf')
-                found = re.findall(r'<meta.*?property="og:video".*?content="(.*?)"', webpage)
+                def check_video(vurl):
-        else:
+        elif 'playerKey' in query:
-urldefrag = compat_urlparse.urldefrag
+from ..utils import (
-        token = basename(hash.rstrip('/'))
+        token = os.path.basename(hash.rstrip('/'))
-        return (urlunparse((uri.scheme, uri.netloc, '/preload.php', None, query, None)), token)
+        query = 'getCommunicationToken=1&hash=%s&%d' % (compat_urllib_parse.quote(hash, safe=''), self.ts)
-        return (urlunparse((uri.scheme, uri.netloc, '/preload.php', None, query, None)), token)
+        query = 'hash=%s&%d' % (compat_urllib_parse.quote(hash, safe=''), self.ts)
-        return urlunparse(('http', meta['streamKey']['ip'], '/stream.php', None, None, None))
+        return compat_urlparse.urlunparse(('http', meta['streamKey']['ip'], '/stream.php', None, None, None))
-        return urlunparse((uri.scheme, uri.netloc, obj['attrs']['data'], None, None, None))
+        return compat_urlparse.urlunparse((uri.scheme, uri.netloc, obj['attrs']['data'], None, None, None))
-        headers = {'Referer': urldefrag(target)[0]}
+        headers = {'Referer': compat_urlparse.urldefrag(target)[0]}
-        headers = {'Referer': urldefrag(target)[0]}
+        headers = {'Referer': compat_urlparse.urldefrag(target)[0]}
-        post_data = urlencode(post_dict).encode('utf-8')
+        post_data = compat_urllib_parse.urlencode(post_dict).encode('utf-8')
-        'md5': 'bbccc50b19daca23b8f961152c1dc95b',
+        'md5': '7ecf8aefa59d6b2098517e1baa530023',
-        request = compat_urllib_request.Request(url, None, headers)
+        add_headers = info_dict.get('http_headers')
-urlparse = compat_urlparse.urlparse
+
-            'duration': 227
+            'duration': 227,
-        uri = urlparse(target)
+        uri = compat_urlparse.urlparse(target)
-        res = self._download_webpage(
+
-            return (res, [x for x in o if x['attrs']['id'] == 'jsPlayerEmbed'])
+        if webpage is not None:
-        return (res, None)
+        if webpage is not None:
-        if 'swf_referer' in locals():
+        if swf_referer is not None:
-        info_dict = {
+        return {
-            'headers': headers
+            'http_post_data': post_data,
-        return None
+import time
-    _VALID_URL = r'http://www\.wat\.tv/.*-(?P<shortID>.*?)_.*?\.html'
+    _VALID_URL = r'http://www\.wat\.tv/video/(?P<display_id>.*)-(?P<short_id>.*?)_.*?\.html'
-        'url': 'http://www.wat.tv/video/world-war-philadelphia-vost-6bv55_2fjr7_.html',
+        'url': 'http://www.wat.tv/video/soupe-figues-l-orange-aux-epices-6z1uz_2hvf7_.html',
-            'id': '10631273',
+            'id': '11713067',
-            'skip_download': True,
+            'title': 'Soupe de figues Ã  l\'orange et aux Ã©pices',
-        webpage = self._download_webpage(url, short_id)
+        short_id = mobj.group('short_id')
-            'url': 'http://wat.tv/get/android5/%s.mp4' % real_id,
+            'display_id': display_id,
-__version__ = '2014.08.22.3'
+__version__ = '2014.08.23'
-            r'id="file_title".*?>\s*(.*?)\s*<span', webpage, 'title')
+            r'id="file_title".*?>\s*(.*?)\s*<(?:br|span)', webpage, 'title')
-    _VALID_URL = r'http://(?:www\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.+?)\.html(?:\?.*)?'
+    _VALID_URL = r'http://(?:.+?\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.+?)\.html(?:\?.*)?'
-    _VALID_URL = r'http://www\.rtve\.es/(?:deportes/directo|noticias(?=/directo-la-1)|television)/(?P<id>[a-zA-Z0-9-]+)'
+    _VALID_URL = r'http://www\.rtve\.es/(?:deportes/directo|noticias|television)/(?P<id>[a-zA-Z0-9-]+)'
-__version__ = '2014.08.22.2'
+__version__ = '2014.08.22.3'
-from .rtve import RTVEALaCartaIE
+from .rtve import RTVEALaCartaIE, RTVELiveIE
-import re
+import re
-    _TEST = {
+    _TESTS = [{
-        return url
+    }, {
-        video_url = self._decrypt_url(png)
+        video_url = _decrypt_url(png)
-            'thumbnail': info['image'],
+            'thumbnail': info.get('image'),
-                'id': 'Ybd-qmqYYpA',
+                'id': 'jpSGZsgga_I',
-                'description': 'md5:9c6dca5dd75b7131ce482ccf080749d6'
+                'title': 'Asphalt 8: Airborne - Launch Trailer',
-                urlrs, playlist_id=video_id, playlist_title=video_title)
+            return _playlist_from_matches(
-                urlrs, playlist_id=video_id, playlist_title=video_title)
+            return _playlist_from_matches(
-                urlrs, playlist_id=video_id, playlist_title=video_title)
+            return _playlist_from_matches(
-            if age_limit < info_dict.get('age_limit', 0):
+            actual_age_limit = info_dict.get('age_limit')
-                r'<a href="([^"]+)"\s*>Continue to watch video', webpage, '%s video URL' % format_id, fatal=False)
+                r'<a\s+href="([^"]+)"\s+class="b_link">', webpage, '%s video URL' % format_id, fatal=False)
-            webpage, 'thumbnail URL', fatal=False)
+            [r'<span title="([^"]+)">',
-            r'Length:\s*<span>(\d{2}:\d{2})</span>',webpage, 'duration', fatal=False))
+            r'<i class="fa fa-clock-o"></i>\s*(\d{2}:\d{2})', webpage, 'duration', fatal=False))
-            r'Added:\s*<span>(\d{4}-\d{2}-\d{2})</span>', webpage, 'upload date', fatal=False))
+            r'<i class="fa fa-user"></i>\s*(\d{4}-\d{2}-\d{2})', webpage, 'upload date', fatal=False))
-            'thumbnail': 'http://m.nuvid.com%s' % thumbnail,
+            'thumbnails': thumbnails,
-            '141', '172', '140', '139', '171',
+            '141', '172', '140', '171', '139',
-__version__ = '2014.08.22.1'
+__version__ = '2014.08.22.2'
-                r'<iframe\s+id=["\']partnerPlayer["\'].*?\s+src=["\'](.*?)["\']>',
+                r'<iframe\s+(?:class|id)=["\']partnerPlayer["\'].*?\s+src=["\'](.*?)["\']>',
-__version__ = '2014.08.22'
+__version__ = '2014.08.22.1'
-__version__ = '2014.08.21.3'
+__version__ = '2014.08.22'
-    #compat_urllib_parse,
+    compat_urlparse,
-        # CSS names with "double" in the name, i.e. "boxwrapper double"
+                'thumbnail': 're:^https?://.*$',
-        return ret
+        webpage = self._download_webpage(url, video_id)
-            u"title": u"ØªÛÙ Ú¯ÙÚ©Ø³Û 11 - Ø²ÙÙÛØª",
+        'url': 'http://www.aparat.com/v/wP8On',
-        #u'skip': u'Extremely unreliable',
+        # 'skip': 'Extremely unreliable',
-                     video_id + u'/vt/frame')
+        embed_url = ('http://www.aparat.com/video/video/embed/videohash/' +
-)
+
-            u"title": u"He's one of us.",
+        'url': 'http://www.dump.com/oneus/',
-
+        video_url = self._search_regex(
-        title = self._search_regex(r'<b>([^"]+)</b>', webpage, u'title')
+        thumb = self._og_search_thumbnail(webpage)
-            'ext': 'flv',
+    int_or_none,
-            age_limit = 18
+        if isinstance(video_url, list):
-            age_limit = 0
+            formats = [{
-            'ext': video_ext,
+            'formats': formats,
-__version__ = '2014.08.21.2'
+__version__ = '2014.08.21.3'
-        encoding = None
+        args['mode'] = 'wb'
-        delete=False)
+        args.update({
-        else:
+        if video_url is None:
-                    r' name="flashvars" value="(.*?)"', webpage, 'flashvars')
+        if video_url is None:
-                vardict = compat_parse_qs(mobj.group(1))
+                flashvars = self._search_regex(
-        video_title = self._html_search_regex(r'(?im)<title>(.*) - Video</title>', webpage, 'title')
+        video_title = self._html_search_regex(
-            'thumbnail':thumbnail,
+            'thumbnail': thumbnail,
-        '171': {'ext': 'webm', 'vcodec': 'none', 'format_note': 'DASH audio', 'abr': 48, 'preference': -50},
+        '171': {'ext': 'webm', 'vcodec': 'none', 'format_note': 'DASH audio', 'abr': 128, 'preference': -50},
-__version__ = '2014.08.21.1'
+__version__ = '2014.08.21.2'
-        if secure: regexes = self._og_regexes('video:secure_url') + regexes
+        regexes = self._og_regexes('video') + self._og_regexes('video:url')
-        playerUrl = self._og_search_video_url(webpage, name=u'player URL')
+        playerUrl = self._og_search_video_url(webpage, name='player URL')
-if sys.version_info >= (2,7):
+def write_json_file(obj, fn):
-__version__ = '2014.08.21'
+__version__ = '2014.08.21.1'
-__version__ = '2014.08.10'
+__version__ = '2014.08.21'
-from .common import InfoExtractor, ExtractorError
+from .common import InfoExtractor
-            # * Any Python type (for example int or float)
+            'title': 'What\'s Wrong with These Photos? A Whole Lot',
-        id = mobj.group('id')
+        video_id = mobj.group('id')
-        webpage = self._download_webpage(url, id)
+        webpage = self._download_webpage(url, video_id)
-            'id': id,
+            'id': video_id,
-            'url': self._html_search_meta('VideoURL', webpage, 'url')
+            'url': self._html_search_meta('VideoURL', webpage, 'url'),
-    IE_NAME = u'ellentv:clips'
+    IE_NAME = 'EllenTV:clips'
-        }
+            'id': 'meryl-streep-vanessa-hudgens',
-        return [self.url_result(item[u'url'], 'EllenTV') for item in playlist]
+        return [self.url_result(item['url'], 'EllenTV') for item in playlist]
-        self.assertTrue(got_dict.get(key), 'Missing mandatory field %s' % key)
+    if got_dict.get('_type') != 'playlist':
-            if not test_case.get('file') and not (info_dict.get('id') and info_dict.get('ext')):
+
-                    ydl.download([test_case['url']])
+                    # We're not using .download here sine that is just a shim
-        result_type = ie_result.get('_type', 'video') # If not given we suppose it's a video, support the default old system
+        result_type = ie_result.get('_type', 'video')
-                r'<article class="video" data-id="(\d+?)"',
+                r'data-node-id="(\d+?)"',
-from ..utils import determine_ext, ExtractorError
+from ..utils import (
-    }
+    _TESTS = [
-        # Not the same as video_id.
+
-        )
+            video_id, note='Downloading chapters XML',
-        ext = determine_ext(video_url)
+        title = self._html_search_meta('citation_title', webpage, 'title')
-            'ext': ext,
+            'comment_count': comment_count,
-            'duration': 3190,
+    _TESTS = [
-    }
+    ]
-            # frontline video embed
+            MEDIA_ID_REGEXES = [
-                webpage, 'frontline video ID', fatal=False, default=None)
+                MEDIA_ID_REGEXES, webpage, 'media ID', fatal=False, default=None)
-        self.to_screen("param is None")
+    authentication.add_option('-2', '--twofactor',
-            return False
+            return True
-        f4m_info = self._download_xml(video_info.find('url').text, video_id)
+        f4m_info = self._download_xml(self._proto_relative_url(video_info.find('url').text.strip()), video_id)
-    _VALID_URL = r'https?://(?:screen|movies)\.yahoo\.com/.*?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html'
+    _VALID_URL = r'(?P<url>https?://(?:screen|movies)\.yahoo\.com/.*?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html)'
-        }
+        },
-            # This is an event page:
+        og_video = self._og_search_video_url(webpage, 'player url', fatal=False, default=None)
-            return self.playlist_result(videos, info['id'], info['full_name'])
+                      for video_data in info['feed']['data']
-        time.sleep(sleep_interval)
+        if sleep_interval > 0:
-        'md5': '53e1c58fc3e777ae1dfe9e57ba2f9c72',
+        'md5': '106fefed92a8a2adb8c98e6a0652f49b',
-            'title': 'Big Buck Bunny Trailer',
+            'title': 'Bmp4',
-from ..utils import unescapeHTML
+from ..utils import (
-            'description': 'How badly damaged does a drive have to be to defeat Russell and his crew? Apparently, smashed to bits.',
+    _TESTS = [
-    }
+    ]
-        videos_more_info = self._search_regex(r'eval\("\(({.*?\\"promo\\".*?})\)"', mobile_player, 'more info').replace('\\"','"')
+        # Looks like some videos are only available for particular devices
-        videos_more_info =json.loads(videos_more_info)
+        videos_more_info = json.loads(videos_more_info)
-__version__ = '2014.08.05'
+__version__ = '2014.08.10'
-                    'height': int(format['height']),
+                    'width': int_or_none(format['width']),
-        (?:[^#?]*\#!/)?
+        (?:[^#]*?\#!/)?
-    def test_uppercase_escpae(self):
+    def test_uppercase_escape(self):
-from ..utils import strip_jsonp
+from ..utils import str_or_none
-            "uploader_id": 216429,
+            "uploader_id": "216429",
-            'uploader_id': api_res.get('artist', {}).get('id'),
+            'uploader_id': str_or_none(api_res.get('artist', {}).get('id')),
-                % (song_id, int(time.time() * 1000)),
+            'https://api.reverbnation.com/song/%s' % song_id,
-        'file': '16965047.mp3',
+            "id": "16965047",
-            "thumbnail": "//gp1.wac.edgecastcdn.net/802892/production_public/Photo/13761700/image/1366002176_AVATAR_MONA_LISA.jpg"
+            "thumbnail": "re:^https://gp1\.wac\.edgecastcdn\.net/.*?\.jpg$"
-            'thumbnail': api_res.get('image', api_res.get('thumbnail')),
+            'thumbnail': self._proto_relative_url(
-        raise NotImplementedError(u'This method must be implemented by sublcasses')
+        raise NotImplementedError(u'This method must be implemented by subclasses')
-from .orf import ORFIE
+from .orf import (
-        }
+import calendar
-class ORFIE(InfoExtractor):
+class ORFTVthekIE(InfoExtractor):
-        return result
+    _VALID_URL = r'http://fm4\.orf\.at/7tage/?#(?P<date>[0-9]+)/(?P<show>\w+)'
-        entries = [ self._extract_entry_dict(t, data['title'], data['subtitle']) for t in data['streams']]
+        def extract_entry_dict(info, title, subtitle):
-        formats = list(formats) # in python3 filter returns an iterator
+        formats = list(formats)  # in python3 filter returns an iterator
-                raise ExtractorError(u'The formats list is empty')
+            # Sometimes there are neither videos of requested lang code
-    _VALID_URL = r'^https?://(www\.)?xboxclips\.com/video.php\?.*vid=(?P<id>[\w-]*)'
+    _VALID_URL = r'https?://(?:www\.)?xboxclips\.com/video\.php\?.*vid=(?P<id>[\w-]{36})'
-            } 
+        'url': 'https://xboxclips.com/video.php?uid=2533274823424419&gamertag=Iabdulelah&vid=074a69a9-5faf-46aa-b93b-9909c1720325',
-                webpage, 'title')
+        video_url = self._html_search_regex(
-                }
+            'id': video_id,
-    }
+    _VALID_URL = r'https?://(?:(?:www|cn)\.)?nowness\.com/[^?#]*?/(?P<id>[0-9]+)/(?P<slug>[^/]+?)(?:$|[?#])'
-from ..utils import int_or_none
+from ..utils import (
-                'uploader_id': 'Siren',
+                'uploader': 'Siren',
-        assert isinstance(video, dict)
+        video = self._download_json(
-        ]
+        formats = []
-        uploader_id = data.get('user', {}).get('name')
+        thumbnail = self._proto_relative_url(video.get('thumbnail_src'), scheme='http:')
-            dislike_count = video.get('total_hates')
+        like_count = video.get('total_likes')
-            'uploader_id': uploader_id,
+            'categories': categories,
-        data = json.loads(data_json)
+        json_url = 'http://vube.com/t-api/v1/video/%s?country=US&limit=120&region=US' % video_id
-            time.sleep((byte_counter / rate_limit) - elapsed)
+            time.sleep(max((byte_counter / rate_limit) - elapsed, 0))
-    _VALID_URL = r'https?://(?:www\.)?mojvideo\.com/video-.*/(?P<id>[a-f0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?mojvideo\.com/video-(?P<display_id>[^/]+)/(?P<id>[a-f0-9]+)'
-            'width':480
+            'thumbnail': 're:^http://.*\.jpg$',
-        width=int(self._search_regex(r'<meta name="video_width" content="([0-9]*)" />',webpage,"video width"))
+        if '<error>true</error>' in playerapi:
-            'width':width
+            'thumbnail': thumbnail,
-            r'file:\s?\'(http[^\']+)\',', webpage, 'file url')
+            r'file:\s?loadURL\(\'(http[^\']+)\'\),', webpage, 'file url')
-__version__ = '2014.08.02.1'
+__version__ = '2014.08.05'
-        'fancyboxhidden', 'box photo double', 'boxwrapper double',
+        'fancyboxhidden', 'box photo', 'boxwrapper',
-        'fancyboxhidden', 'box photo double', 'boxwrapper double',
+        'fancyboxhidden', 'box photo', 'boxwrapper',
-            if attrs_classes == self._ATTACH_CLASSES:
+            if self._match(attrs_classes, self._ATTACH_CLASSES):
-            if attrs_classes == self._INFO_CLASSES:
+            if self._match(attrs_classes, self._INFO_CLASSES):
-            'name': 'Patreon',
+        {
-                _, video_thumbnail = sorted((int(width), t_url) for (width, t_url) in video_thumbs.items())[-1]
+                _, video_thumbnail = sorted((int(width if width.isdigit() else 0), t_url) for (width, t_url) in video_thumbs.items())[-1]
-        #time.sleep(1)
+    downloader.add_option('--sleep-interval',
-            'height':37 8,
+            'height':378,
-            'height':378,
+            'height':37 8,
-            # TODO more properties (see youtube_dl/extractor/common.py)
+from .mojvideo import MojvideoIE
-from.ubu import UbuIE
+from .ubu import UbuIE
-__version__ = '2014.08.02'
+__version__ = '2014.08.02.1'
-    def _real_extract(self, url):
+    def _extract_ids(self, url):
-__version__ = '2014.07.30'
+__version__ = '2014.08.02'
-            player_id = (player_url, len(s))
+            player_id = (player_url, self._signature_cache_id(s))
-    def _extract_signature_function(self, video_id, player_url, slen):
+    def _signature_cache_id(self, example_sig):
-        func_id = '%s_%s_%d' % (player_type, player_id, slen)
+        func_id = '%s_%s_%s' % (
-                test_string = u''.join(map(compat_chr, range(slen)))
+                test_string = u''.join(map(compat_chr, range(len(example_sig))))
-    def _print_sig_code(self, func, slen):
+    def _print_sig_code(self, func, example_sig):
-        test_string = u''.join(map(compat_chr, range(slen)))
+        test_string = u''.join(map(compat_chr, range(len(example_sig))))
-        code = u'if len(s) == %d:\n    return %s\n' % (slen, expr_code)
+        signature_id_tuple = '(%s)' % (
-                    video_id, player_url, len(s)
+                    video_id, player_url, s
-                self._print_sig_code(func, len(s))
+                self._print_sig_code(func, s)
-                u'Automatic signature extraction failed: ' + tb, cause=e)
+                u'Signature extraction failed: ' + tb, cause=e)
-                        parts_sizes = u'.'.join(compat_str(len(part)) for part in encrypted_sig.split('.'))
+                        parts_sizes = self._signature_cache_id(encrypted_sig)
-                            (format_id, len(encrypted_sig), parts_sizes, url_data['itag'][0], player_desc))
+                        self.to_screen(u'{%s} signature length %s, %s' %
-                            player_url = json.loads(jsplayer_url_json)
+                if 'itag' not in url_data or 'url' not in url_data:
-                                player_desc = 'unknown'
+                            player_version = 'unknown'
-                    url_map[url_data['itag'][0]] = url
+                                player_version = self._search_regex(
-from ..utils import get_element_by_id, parse_iso8601, determine_ext, int_or_none
+from ..utils import (
-    _VALID_URL = r'https?://(?:www\.|m\.)?izlesene\.com/(?:video|embedplayer)/(?:[^/]+/)?(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?izlesene\.com/(?:video|embedplayer)/(?:[^/]+/)?(?P<id>[0-9]+)'
-            'duration': 95,
+            'title': 'SevinÃ§ten ÃÄ±ldÄ±rtan DoÄum GÃ¼nÃ¼ Hediyesi',
-                                           default='')
+
-            webpage, 'uploader', fatal=False)
+            r'comment_count\s*=\s*\'([^\']+)\';', webpage, 'uploader', fatal=False)
-        ext = determine_ext(content_url)
+        family_friendly = self._html_search_meta(
-                                            default='')
+        qualities = self._html_search_regex(
-                errnote=u'Failed to get video URL for "%s" quality' % quality
+                note='Getting video URL for "%s" quality' % quality,
-                'format_id': video_format,
+                'format_id': '%sp' % quality if quality else 'sd',
-            'formats': formats,
+            'uploader_id': uploader,
-            'uploader_id': uploader,
+            'age_limit': 18 if family_friendly == 'False' else 0,
-        webpage = self._download_webpage(url.encode('utf-8'), video_id)
+        urlp = compat_urllib_parse_urlparse(url)
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url.encode('utf-8'), video_id)
-        if current == 0 or dif < 0.001: # One millisecond
+        if current == 0 or dif < 0.001:  # One millisecond
-        if bytes == 0 or dif < 0.001: # One millisecond
+        if bytes == 0 or dif < 0.001:  # One millisecond
-        new_max = min(max(bytes * 2.0, 1.0), 4194304) # Do not surpass 4 MB
+        new_max = min(max(bytes * 2.0, 1.0), 4194304)  # Do not surpass 4 MB
-    def slow_down(self, start_time, byte_counter):
+    def slow_down(self, start_time, now, byte_counter):
-        now = time.time()
+        if now is None:
-            time.sleep((byte_counter - rate_limit * (now - start_time)) / rate_limit)
+            time.sleep((byte_counter / rate_limit) - elapsed)
-            after = time.time()
+            byte_counter += len(data_block)
-            # Open file just in time
+            # Open destination file just in time
-            speed = self.calc_speed(start, time.time(), byte_counter - resume_len)
+            speed = self.calc_speed(start, now, byte_counter - resume_len)
-            raise ExtractionError('Unable to retrieve creation URL')
+            raise ExtractorError('Unable to retrieve creation URL')
-__version__ = '2014.07.25.1'
+__version__ = '2014.07.30'
-    general.add_option(
+    workarounds.add_option(
-        help='Use this prefix for unqualified URLs. For example "gvsearch2:" downloads two videos from google videos for  youtube-dl "large apple". Use the value "auto" to let youtube-dl guess. The default value "error" just throws an error.')
+        help='Use this prefix for unqualified URLs. For example "gvsearch2:" downloads two videos from google videos for  youtube-dl "large apple". Use the value "auto" to let youtube-dl guess ("auto_warning" to emit a warning when guessing). "error" just throws an error. The default value "fixup_error" repairs broken URLs, but emits an error if this is not possible instead of searching.')
-    if opts.default_search not in ('auto', 'auto_warning', None) and ':' not in opts.default_search:
+    if opts.default_search not in ('auto', 'auto_warning', 'error', 'fixup_error', None) and ':' not in opts.default_search:
-                default_search = 'error'
+                default_search = 'fixup_error'
-            if default_search in ('auto', 'auto_warning'):
+            if default_search in ('auto', 'auto_warning', 'fixup_error'):
-                else:
+                elif default_search != 'fixup_error':
-            elif default_search == 'error':
+
-    _VALID_URL = r'https?://(?:www\.)?swrmediathek\.de/player\.htm\?show=(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})'
+    _VALID_URL = r'https?://(?:www\.)?swrmediathek\.de/(?:content/)?player\.htm\?show=(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})'
-        thumbnail = 'http:' + og_thumbnail
+        thumbnail = self._proto_relative_url(
-        upload_date_raw = self._html_search_regex(
+        upload_date = unified_strdate(self._html_search_regex(
-        upload_date = upload_date_raw[2] + upload_date_raw[1] + upload_date_raw[0]
+            webpage, 'upload_date', fatal=False))
-        duration = int(duration_raw[0])*60 + int(duration_raw[1])
+        duration = parse_duration(self._html_search_regex(
-        view_count = int(view_count_raw.replace('.', ''))
+        view_count = str_to_int(self._html_search_regex(
-        comment_count = int(comment_count_raw)
+        comment_count = int_or_none(self._html_search_regex(
-        manifest = self._download_xml(manifest_url, video_id)
+        manifest = self._download_xml(
-        rate, media = formats[-1]
+        if requested_bitrate is None:
-        'md5': '7bf08858ff7c203c870e8a6190e221e5',
+        # The md5 checksum changes
-            'ext': 'flv',
+            'formats': self._extract_f4m_formats(f4m_url, name),
-        if url.startswith('rtmp'):
+        if manifest_url.startswith('rtmp'):
-        video_url = video_url.replace('/z/', '/i/')
+        manifest_url = manifest_url.replace('/z/', '/i/')
-                }
+        return {
-                feed_html)
+                load_more_widget_html)
-                'description': 'md5:dfd224e5aa6819bc1fcbb7826a932021',
+                'title': 'Wenn das Traditions-Theater wackelt',
-                duration = m['d']
+                duration = float(m['d'])
-        result = ie.extract('http://mpallante.bandcamp.com/album/nightmare-night-ep')
+        result = ie.extract('http://nightbringer.bandcamp.com/album/hierophany-of-the-open-grave')
-        assertGreaterEqual(self, len(result['entries']), 4)
+        self.assertEqual(result['title'], 'Hierophany of the Open Grave')
-    IE_NAME = u'streamcloud.eu'
+    IE_NAME = 'streamcloud.eu'
-            u'duration': 9,
+        'url': 'http://streamcloud.eu/skp9j99s4bpz/youtube-dl_test_video_____________-BaW_jenozKc.mp4.html',
-        u'skip': u'Only available from the EU'
+        'skip': 'Only available from the EU'
-            req, video_id, note=u'Downloading video page ...')
+            req, video_id, note='Downloading video page ...')
-            r'<h1[^>]*>([^<]+)<', webpage, u'title')
+            r'<h1[^>]*>([^<]+)<', webpage, 'title')
-        duration = None if duration_str is None else int(duration_str)
+            r'file:\s*"([^"]+)"', webpage, 'video URL')
-            r'image:\s*"([^"]+)"', webpage, u'thumbnail URL', fatal=False)
+            r'image:\s*"([^"]+)"', webpage, 'thumbnail URL', fatal=False)
-            'duration': duration,
+from .izlesene import IzleseneIE
-        assert type(message) == type('')
+        assert isinstance(message, compat_str)
-        assert type(message) == type('')
+        assert isinstance(message, compat_str)
-        if not 'format' in info_dict:
+        if 'format' not in info_dict:
-                })
+            formats.extend(self._parse_smil(video_id, smil_url))
-                    (vn.attrib['src'], vn.attrib['clipBegin']))
+                    'http://livestream-f.akamaihd.net/%s?v=3.0.3&fp=WIN%%2014,0,0,145' %
-                                           'unable to download video info JSON')
+    def _parse_page(self, url, video_id, counter):
-                self.report_download_page(video_id, offset)
+        for counter in itertools.count(1):
-            page_count, page_info = self._parse_page(page_url, video_id)
+            page_count, page_info = self._parse_page(
-    compat_str,
+    ExtractorError,
-            video_data.get('progressive_url')
+        video_id = compat_str(video_data['id'])
-            'url': video_url,
+            'id': video_id,
-            'thumbnail': video_data['thumbnail_url'],
+            'thumbnail': video_data.get('thumbnail_url'),
-        assert re.match(r'^[a-zA-Z0-9@\s:._]*$', val)
+        assert re.match(r'^[a-zA-Z-]+$', key)
-__version__ = '2014.07.25'
+__version__ = '2014.07.25.1'
-        xml_root = self._html_search_regex(r'<iframe src="(?P<xml_root>.*?)player.html.*?".*?</iframe>', start_page, 'xml root', None, False)
+        direct_url = self._search_regex(
-            if start_page is None:
+            login_res = self._login(webpage_url, video_id)
-                xml_root = self._html_search_regex(r'<iframe src="(?P<xml_root>.*?)player.html.*?".*?</iframe>', start_page, 'xml root')
+                xml_root = self._html_search_regex(
-        xml_name = self._html_search_regex(r'<iframe src=".*?\?xml=(?P<xml_file>.+?\.xml).*?".*?</iframe>', start_page, 'xml filename', None, False)
+        xml_name = self._html_search_regex(
-                if mobj: break
+                if mobj:
-__version__ = '2014.07.24'
+__version__ = '2014.07.25'
-                    res.append(obj.pop(i))
+                    res.append(obj.pop(index))
-    m = re.match(r'.*-([a-zA-Z0-9_-]+)(?:/watch_as3)?\.[a-z]+$', url)
+    m = re.match(r'.*-([a-zA-Z0-9_-]+)(?:/watch_as3|/html5player)?\.[a-z]+$', url)
-            r'^(?P<var>[a-z]+)\.(?P<member>[^(]+)(?:\(+(?P<args>[^()]*)\))?$',
+            r'^(?P<var>[a-zA-Z0-9_]+)\.(?P<member>[^(]+)(?:\(+(?P<args>[^()]*)\))?$',
-                                        r'html5player-(.+?)\.js', video_webpage,
+                                        r'html5player-([^/]+?)(?:/html5player)?\.js',
-            raise IOError(errmsg)
+        write_string(encoding_str, encoding=None)
-            if not opts.update_self:
+            if not (opts.update_self or opts.rm_cachedir):
-            action='store_true', dest='usetitle', help='use title in file name (default)', default=False)
+            action='store_true', dest='usetitle', help='[deprecated] use title in file name (default)', default=False)
-            action='store_true', dest='usetitle', help='use title in file name (default)', default=False)
+    filesystem.add_option('-a', '--batch-file',
-            help='json file containing the video information (created with the "--write-json" option)')
+    filesystem.add_option('-t', '--title',
-            dest='cookiefile', metavar='FILE', help='file to read cookies from and dump cookie jar in')
+    filesystem.add_option('--load-info',
-    general.add_option(
+    filesystem.add_option(
-        help='Force the specified encoding (experimental)')
+    workarounds.add_option(
-        u'js',
+        'https://s.ytimg.com/yts/jsbin/html5player-vflHOr_nV.js',
-        u'>=<;:/.-[+*)(\'&%$#"!ZYX0VUTSRQPONMLKJIHGFEDCBA\\yxwvutsrqponmlkjihgfedcba987654321',
+        '>=<;:/.-[+*)(\'&%$#"!ZYX0VUTSRQPONMLKJIHGFEDCBA\\yxwvutsrqponmlkjihgfedcba987654321',
-        u'js',
+        'https://s.ytimg.com/yts/jsbin/html5player-vfldJ8xgI.js',
-        u'3456789a0cdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRS[UVWXYZ!"#$%&\'()*+,-./:;<=>?@',
+        '3456789a0cdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRS[UVWXYZ!"#$%&\'()*+,-./:;<=>?@',
-        u'js',
+        'https://s.ytimg.com/yts/jsbin/html5player-vfle-mVwz.js',
-        u']\\[@?>=<;:/.-,+*)(\'&%$#"hZYXWVUTSRQPONMLKJIHGFEDCBAzyxwvutsrqponmlkjiagfedcb39876',
+        ']\\[@?>=<;:/.-,+*)(\'&%$#"hZYXWVUTSRQPONMLKJIHGFEDCBAzyxwvutsrqponmlkjiagfedcb39876',
-        u'js',
+        'https://s.ytimg.com/yts/jsbin/html5player-en_US-vfl0Cbn9e.js',
-        u'O1I3456789abcde0ghijklmnopqrstuvwxyzABCDEFGHfJKLMN2PQRSTUVW@YZ!"#$%&\'()*+,-./:;<=',
+        'O1I3456789abcde0ghijklmnopqrstuvwxyzABCDEFGHfJKLMN2PQRSTUVW@YZ!"#$%&\'()*+,-./:;<=',
-        u'A52CB8B320D22032ABB3A41D773D2B6342034902.A22E87CDD37DBE75A5E52412DC874AC16A7CFCA2',
+        'https://s.ytimg.com/yts/jsbin/html5player-en_US-vflXGBaUN.js',
-        u'swf',
+        'http://s.ytimg.com/yts/swfbin/player-vfl5vIhK2/watch_as3.swf',
-        u'O1I3456789abcde0ghijklmnopqrstuvwxyzABCDEFGHfJKLMN2PQRSTUVWXY\\!"#$%&\'()*+,-./:;<=>?'
+        'O1I3456789abcde0ghijklmnopqrstuvwxyzABCDEFGHfJKLMN2PQRSTUVWXY\\!"#$%&\'()*+,-./:;<=>?'
-        u'9C29AA6D499282CD97F33DCED0A644E8128A5273.64C18E31F38361864D86834E6662FAADFA2FB57F'
+        'http://s.ytimg.com/yts/swfbin/player-vflmDyk47/watch_as3.swf',
-        u'js',
+        'https://s.ytimg.com/yts/jsbin/html5player-en_US-vflBb0OQx.js',
-        u'123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQ0STUVWXYZ!"#$%&\'()*+,@./:;<=>'
+        '123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQ0STUVWXYZ!"#$%&\'()*+,@./:;<=>'
-        u'js',
+        'https://s.ytimg.com/yts/jsbin/html5player-en_US-vfl9FYC6l.js',
-        u'123456789abcdefghijklmnopqr0tuvwxyzABCDETGHIJKLMNOPQRS>UVWXYZ!"#$%&\'()*+,-./:;<=F'
+        '123456789abcdefghijklmnopqr0tuvwxyzABCDETGHIJKLMNOPQRS>UVWXYZ!"#$%&\'()*+,-./:;<=F'
-            r'^(?P<func>[.a-zA-Z$]+)\((?P<args>[a-z0-9,]+)\)$', expr)
+            r'^(?P<func>[a-zA-Z$]+)\((?P<args>[a-z0-9,]+)\)$', expr)
-__version__ = '2014.07.23.2'
+__version__ = '2014.07.24'
-    )
+    ),
-                return obj[::-1]
+                obj.reverse()
-                'Cannot determine left side of statement in %r' % stmt)
+            # Try interpreting it as an expression
-        m = re.match(r'^(?P<in>[a-z]+)\.(?P<member>.*)$', expr)
+        try:
-            variable = m.group('in')
+            arg_str = m.group('args')
-            if variable not in local_vars:
+            if variable in local_vars:
-                return val[idx:]
+
-            r'^(?P<func>[a-zA-Z$]+)\((?P<args>[a-z0-9,]+)\)$', expr)
+            r'^(?P<func>[.a-zA-Z$]+)\((?P<args>[a-z0-9,]+)\)$', expr)
-                       for v in m.group('args').split(',')]
+from .krasview import KrasViewIE
-                'sts':'16268',
+                'sts': self._search_regex(
-        webpage = self._download_webpage('http://www.gameone.de/tv/year/%d' % this_year, this_year)
+        webpage = self._download_webpage('http://www.gameone.de/tv', 'TV')
-
+
-    def __init__(self,downloader=None,deletetempfiles=False):
+    def __init__(self, downloader=None, deletetempfiles=False):
-                os.remove(rempath)
+            for ipath in input_paths:
-                        merger = FFmpegMergerPP(self)
+                        merger = FFmpegMergerPP(self, not self.params.get('keepvideo'))
-    def __init__(self,downloader=None):
+    def __init__(self,downloader=None,deletetempfiles=False):
-    compat_parse_qs,
+    compat_urlparse,
-from .FileDownloader import (
+from .downloader import (
-__version__ = '2014.07.23.1'
+__version__ = '2014.07.23.2'
-        write_string(
+        encoding_str = (
-        )
+                self.get_encoding()))
-            r'.*-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3)?\.(?P<ext>[a-z]+)$',
+            r'.*-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player)?\.(?P<ext>[a-z]+)$',
-            r'\s*(?P<fields>([a-zA-Z$]+\s*:\s*function\(.*?\)\s*\{.*?\})*)' +
+            r'\s*(?P<fields>([a-zA-Z$0-9]+\s*:\s*function\(.*?\)\s*\{.*?\})*)' +
-            r'(?P<key>[a-zA-Z$]+)\s*:\s*function'
+            r'(?P<key>[a-zA-Z$0-9]+)\s*:\s*function'
-            'skip': 'Only works from Germany',
+            'only_matching': True,
-    compat_urlparse,
+    compat_parse_qs,
-        flashvars = compat_urlparse.parse_qs(
+        flashvars = compat_parse_qs(
-from ..utils import find_xpath_attr, compat_str
+from ..utils import (
-            self, result['description'], r'TILT Brass - Bowery Poetry Club')
+            self, result['description'], r'.*?TILT Brass - Bowery Poetry Club')
-        return self.assertRegexpMatches(text, regexp, msg)
+    if hasattr(self, 'assertRegexp'):
-            'md5': 'fee7b8747b09bb755cefd4b853e7249a',
+            'md5': '7624f2351f8a3b2e7cd51522496e7631',
-                'ext': 'wav',
+                'ext': 'mp3',
-            'description': 'md5:727900f130df3dc9a25e2721497c7910',
+            'description': 're:(?s).* Hi, my name is Rene Dreifuss\. And I\'m here to show you some MMA.*',
-__version__ = '2014.07.23'
+__version__ = '2014.07.23.1'
-        json_string = self._download_webpage(url_or_request, video_id, note, errnote)
+                       transform_source=None,
-                'duration': 170.56
+                'duration': 170.56,
-                'duration': 240.107
+                'duration': 240.107,
-        open('/dev/shm/f', 'w').write(json.dumps(data, indent=2))
+        if like_count is None:
-        comment_count = int_or_none(comment.get('total'))
+        comments = video.get('comments')
-__version__ = '2014.07.22'
+__version__ = '2014.07.23'
-                'thumbnail': 'http://frame.thestaticvube.com/snap/228x128/102e7e63057-5ebc-4f5c-4065-6ce4ebde131f.jpg',
+                'thumbnail': 're:^http://frame\.thestaticvube\.com/snap/[0-9x]+/102e7e63057-5ebc-4f5c-4065-6ce4ebde131f\.jpg$',
-                'thumbnail': 'http://frame.thestaticvube.com/snap/228x128/102265d5a9f-0f17-4f6b-5753-adf08484ee1e.jpg',
+                'thumbnail': 're:^http://frame\.thestaticvube\.com/snap/[0-9x]+/102265d5a9f-0f17-4f6b-5753-adf08484ee1e\.jpg$',
-                'uploader_id': 'XU9VE2BQ2q',
+        }, {
-            'http://vube.com/api/v2/video/%s' % video_id, video_id, 'Downloading video JSON')
+        webpage = self._download_webpage(url, video_id)
-        timestamp = int(video['upload_time'])
+        thumbnail = self._proto_relative_url(
-        dislike_count= video.get('total_hates')
+        like_count = video.get('rlikes')
-    _VALID_URL = r'http?://m\.mlb\.com/.*video/(?:topic/[\da-z_-]+/)?v(?P<id>n?\d+)'
+    _VALID_URL = r'https?://m\.mlb\.com/(?:.*?/)?video/(?:topic/[\da-z_-]+/)?v(?P<id>n?\d+)'
-    _VALID_URL = r'http?://m\.mlb\.com/video/(?:topic/[\da-z_-]+/)?v(?P<id>n?\d+)'
+    _VALID_URL = r'http?://m\.mlb\.com/.*video/(?:topic/[\da-z_-]+/)?v(?P<id>n?\d+)'
-    _VALID_URL = r'https?://(?:www\.)?cbs\.com/shows/[^/]+/(video|artist)/(?P<id>[^/]+)/.*'
+    _VALID_URL = r'https?://(?:www\.)?cbs\.com/shows/[^/]+/(?:video|artist)/(?P<id>[^/]+)/.*'
-            u'duration': 1495,
+        'url': 'http://www.cbs.com/shows/garth-brooks/video/_u7W953k6la293J7EPTd9oHkSPs6Xn6_/connect-chat-feat-garth-brooks/',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-            u'duration': 3221,
+        'url': 'http://www.cbs.com/shows/liveonletterman/artist/221752/st-vincent/',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-            webpage, u'real video ID')
+            webpage, 'real video ID')
-    _VALID_URL = r'https?://(?:www\.)?cbs\.com/shows/[^/]+/video/(?P<id>[^/]+)/.*'
+    _VALID_URL = r'https?://(?:www\.)?cbs\.com/shows/[^/]+/(video|artist)/(?P<id>[^/]+)/.*'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-__version__ = '2014.07.21'
+__version__ = '2014.07.22'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            webpage, 'title').rpartition('â Kickstarter')[0].strip()
+        title = self._html_search_regex(
-            'title': video_title,
+            'title': title,
-    _VALID_URL = r'https?://(?:www\.)?vodlocker.com/(?P<id>[0-9a-zA-Z]+)(?:\..*?)?'
+    _VALID_URL = r'https?://(?:www\.)?vodlocker\.com/(?P<id>[0-9a-zA-Z]+)(?:\..*?)?'
-                _SEARCHES = (u'cute kittens', u'slithering pythons', u'falling cat', u'angry poodle', u'purple fish', u'running tortoise')
+                _SEARCHES = (u'cute kittens', u'slithering pythons', u'falling cat', u'angry poodle', u'purple fish', u'running tortoise', u'sleeping bunny')
-    _VALID_URL = r'https?://(?:www\.)?br\.de/(?:[a-z0-9\-]+/)+(?P<id>[a-z0-9\-]+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?br\.de/(?:[a-z0-9\-_]+/)+(?P<id>[a-z0-9\-_]+)\.html'
-__version__ = '2014.07.20.2'
+__version__ = '2014.07.21'
-            info = next(v for v in all_videos if v['mpxId'] == mpxid)
+
-from ..utils import compat_urllib_parse
+from ..utils import compat_urllib_parse_unquote
-        fn = compat_urllib_parse.unquote(mobj.group('title'))
+        fn = compat_urllib_parse_unquote(mobj.group('title'))
-    def _unquote(string, encoding='utf-8', errors='replace'):
+    from urllib.parse import unquote as compat_urllib_parse_unquote
-                name = _unquote(name, encoding=encoding, errors=errors)
+                name = compat_urllib_parse_unquote(
-                value = _unquote(value, encoding=encoding, errors=errors)
+                value = compat_urllib_parse_unquote(
-            raise ExtractorError(u'Video %s does not exist' % video_id,
+            raise ExtractorError('Video %s does not exist' % video_id,
-        webpage = self._download_webpage(req, video_id, 'Downloading video page')
+        webpage = self._download_webpage(
-        video_url = self._html_search_regex(r'<a href="([^"]*)".+class="download_file_link"', webpage, 'file url')
+        video_url = self._html_search_regex(
-        ext = determine_ext(title)
+        thumbnail = self._html_search_regex(
-            'md5': '24e83813e832badb0a8d7d1ef9ef0691',
+            'url': 'http://www.funkhauseuropa.de/av/audioflaviacoelhoamaramar100-audioplayer.html',
-                'id': 'mdb-463528',
+                'id': 'mdb-478135',
-                'title': 'SÃ¼persong: Soul Bossa Nova',
+                'title': 'Flavia Coelho: Amar Ã© Amar',
-                'upload_date': '20140630',
+                'upload_date': '20140717',
-            'description': 'md5:3e1c0dc6047498d6728dcdaad0891762',
+            'description': 'md5:a5f7ff82e2f7a9ed77473fe666954e84',
-            'description': 'md5:2ed27d364f5a805a6dba199faaf6681d',
+            'description': 'Please use this to sell something.  www.jonlajoie.com',
-                'title': 'Kathy Sierra: Building the minimum Badass User, Business of Software',
+                'title': 'Kathy Sierra: Building the minimum Badass User, Business of Software 2012',
-        title = vdata['headline']
+        title = vdata.get('headline')
-        'md5': '8ae17c51172fb7f93bdd6a214cc8c896',
+        'url': 'https://www.dropbox.com/s/nelirfsxnmcfbfh/youtube-dl%20test%20video%20%27%C3%A4%22BaW_jenozKc.mp4',
-            'id': '0qr9sai2veej4f8',
+            'id': 'nelirfsxnmcfbfh',
-            'title': 'THE_DOCTOR_GAMES'
+            'title': 'youtube-dl test video \'Ã¤"BaW_jenozKc'
-        title = os.path.splitext(mobj.group('title'))[0]
+        fn = compat_urllib_parse.unquote(mobj.group('title'))
-                    (?=[^>]+(?:itemprop|name|property)=["\']%s["\'])
+                    (?=[^>]+(?:itemprop|name|property)=["\']?%s["\']?)
-        title = self._html_search_meta('title', webpage, 'title')
+        title = self._html_search_meta('title', webpage, 'title', fatal=True)
-    _MEDIA_RE = r'(?s)"sidebar_thumb_time">[0-9:]+</div>.+?<a href="(https?://(?:www\.)?teachertube\.com/(?:video|audio)/[^"]+)">'
+    _MEDIA_RE = r'''(?sx)
-        pages = re.findall(r'/ajax-user/user-videos/%s\?page=([0-9]+)' % user_id, webpage)[1:-1]
+        pages = re.findall(r'/ajax-user/user-videos/%s\?page=([0-9]+)' % user_id, webpage)[:-1]
-            entries.append(self.url_result(url, 'TeacherTube'))
+            webpage = self._download_webpage(more, user_id, 'Downloading page %s/%s' % (p, len(pages)))
-        self.assertTrue(len(result['entries']) >= 47)
+        assertGreaterEqual(self, len(result['entries']), 47)
-        self.assertTrue(len(result['entries']) >= 54)
+        assertGreaterEqual(self, len(result['entries']), 54)
-        self.assertTrue(len(result['entries']) >= 6)
+        assertGreaterEqual(self, len(result['entries']), 6)
-        self.assertTrue(len(result['entries']) >= 12)
+        assertGreaterEqual(self, len(result['entries']), 12)
-        self.assertTrue(len(result['entries']) >= 1)
+        assertGreaterEqual(self, len(result['entries']), 1)
-        self.assertTrue(len(result['entries']) >= 4)
+        assertGreaterEqual(self, len(result['entries']), 4)
-        self.assertTrue(len(result['entries']) >= 28)
+        assertGreaterEqual(self, len(result['entries']), 28)
-        self.assertTrue(len(result['entries']) >= 60)
+        assertGreaterEqual(self, len(result['entries']), 60)
-        self.assertTrue(len(result['entries']) >= 4)
+        assertGreaterEqual(self, len(result['entries']), 4)
-        self.assertTrue(len(result['entries']) >= 4)
+        assertGreaterEqual(self, len(result['entries']), 4)
-        self.assertTrue(len(result['entries']) >= 9)
+        assertGreaterEqual(self, len(result['entries']), 9)
-        self.assertTrue(len(result['entries']) >= 24)
+        assertGreaterEqual(self, len(result['entries']), 24)
-        self.assertTrue(len(result['entries']) >= 12)
+        assertGreaterEqual(self, len(result['entries']), 12)
-        self.assertTrue(len(result['entries']) >= 3)
+        assertGreaterEqual(self, len(result['entries']), 3)
-        self.assertTrue(len(result['entries']) >= 68)
+        assertGreaterEqual(self, len(result['entries']), 68)
-        self.assertTrue(len(result['entries']) >= 37)
+        assertGreaterEqual(self, len(result['entries']), 37)
-        self.assertTrue(len(result['entries']) >= 6)
+        assertGreaterEqual(self, len(result['entries']), 6)
-        self.assertTrue(len(result['entries']) >= 17)
+        assertGreaterEqual(self, len(result['entries']), 17)
-        self.assertTrue(len(result['entries']) >= 155)
+        assertGreaterEqual(self, len(result['entries']), 155)
-        self.assertTrue(len(result['entries']) >= 2)
+        assertGreaterEqual(self, len(result['entries']), 2)
-        self.assertTrue(len(result['entries']) >= 10)
+        assertGreaterEqual(self, len(result['entries']), 10)
-        self.assertTrue(len(result['entries']) >= 179)
+        assertGreaterEqual(self, len(result['entries']), 179)
-            'description': 'md5:6df4fe8dd494ae811869672b0767e025',
+            'description': 'md5:dc96a773669d0ca1b36c13c1f30250d9',
-            'description': 'md5:4f0aac94361a12e1ce57d74f85265175',
+            'description': 'md5:727900f130df3dc9a25e2721497c7910',
-        'md5': '18fcd45965bdd076efdb12cd7f6d7b9e',
+        'md5': '1d49b7e1ca7a7502c56a4bf1b60f1b43',
-import re
+            'description': 'A drone flying through Fourth of July Fireworks',
-
+            'description': description,
-
+    float_or_none,
-
+    parse_duration,
-    _TESTS =[ {
+    _TESTS = [{
-
+            'filesize_approx': 98566144,
-
+            'filesize_approx': 8912896,
-        view_count = str_to_int(self._html_search_regex(r'<p>\n<strong>Views:</strong>\n([\d,\.]+)</p>',webpage,'view count'))
+        view_count = str_to_int(self._html_search_regex(
-        duration = str_to_int(duration[:1])*60 + str_to_int(duration[2:4])
+        duration = parse_duration(self._html_search_regex(
-        file_size = str_to_int(re.match(r'\d+',file_size).group())*131072
+        filesize_approx = float_or_none(self._html_search_regex(
-        }
+            'url': video_url,
-def int_or_none(v, scale=1, default=None, get_attr=None):
+def int_or_none(v, scale=1, default=None, get_attr=None, invscale=1):
-    return default if v is None else (int(v) // scale)
+    return default if v is None else (int(v) * invscale // scale)
-    return default if v is None else (float(v) / scale)
+def float_or_none(v, scale=1, invscale=1, default=None):
-                     'Set --default-search "ytseach" (or run  youtube-dl "ytsearch:%s" ) to search YouTube'
+                     'Set --default-search "ytsearch" (or run  youtube-dl "ytsearch:%s" ) to search YouTube'
-                        obj, mname)
+
-u32 = _read_int
+_u32 = _read_int
-        video_url = video_data.get('progressive_url_hd') or video_data.get('progressive_url')
+        video_url = (
-                for video_data in info['feed']['data'] if video_data['type'] == 'video']
+                for video_data in info['feed']['data']
-__version__ = '2014.07.20.1'
+__version__ = '2014.07.20.2'
-import struct
+    struct_unpack,
-    framesize_nbits = struct.unpack('!B', content[:1])[0] >> 3
+    framesize_nbits = struct_unpack('!B', content[:1])[0] >> 3
-        header16 = struct.unpack('<H', content[pos:pos + 2])[0]
+        header16 = struct_unpack('<H', content[pos:pos + 2])[0]
-            tag_len = struct.unpack('<I', content[pos:pos + 4])[0]
+            tag_len = struct_unpack('<I', content[pos:pos + 4])[0]
-        b = struct.unpack('<B', buf)[0]
+        b = struct_unpack('<B', buf)[0]
-    return struct.unpack('<i', bs + last_byte)[0]
+    return struct_unpack('<i', bs + last_byte)[0]
-    res = struct.unpack('<B', resb)[0]
+    res = struct_unpack('<B', resb)[0]
-__version__ = '2014.07.20'
+__version__ = '2014.07.20.1'
-    _VALID_URL = r'^https?://(?:(?:www\.)?ardmediathek\.de|mediathek\.daserste\.de)/(?:.*/)(?P<video_id>[^/\?]+)(?:\?.*)?'
+    _VALID_URL = r'^https?://(?:(?:www\.)?ardmediathek\.de|mediathek\.daserste\.de)/(?:.*/)(?P<video_id>[0-9]+|[^0-9][^/\?]+)[^/\?]*(?:\?.*)?'
-        'md5': '515bf47ce209fb3f5a61b7aad364634c',
+    _TESTS = [{
-            'thumbnail': 'http://www.ardmediathek.de/ard/servlet/contentblob/19/28/87/90/19288790/bild/2250037',
+            'title': 'Vertrauen ist gut, Spionieren ist besser - Geht so deutsch-amerikanische Freundschaft?',
-    }
+    }, {
-                        'format_id': '%s-%s' % (determine_ext(url), quality)
+            'dcterms.abstract', webpage, 'description', default=None)
-                continue
+                    continue
-            }
+                format = {
-                determine_ext(format['url']), format['quality'])
+                format['format_id'] = '%s-%s' % (
-            formats.append(format)
+                formats.append(format)
-                                                  })
+            data = compat_urllib_parse.urlencode({
-                                        r'-(.+)\.swf$', player_url,
+                                        r'-(.+?)(?:/watch_as3)?\.swf$', player_url,
-            'description': 'md5:c4b1f7bd682a91de6491ada267ec0f4d',
+            'description': 'md5:eeaffe7c2d634525e21159b93acf3b1e',
-            'description': 'md5:e74a4dc750894bac300ece46c7036490',
+            'description': 'md5:71742e3a74b0d692c7fce0dd2017a4ac',
-__version__ = '2014.07.15'
+__version__ = '2014.07.20'
-        u'23456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!?#$%&\'()*+,-./:;<=>"'
+        u'O1I3456789abcde0ghijklmnopqrstuvwxyzABCDEFGHfJKLMN2PQRSTUVWXY\\!"#$%&\'()*+,-./:;<=>?'
-                    print('Setting %r.%r = %r' % (obj, idx, value))
+class _Multiname(object):
-                self.multinames.append('[MULTINAME kind: %d]' % kind)
+                self.multinames.append(_Multiname(kind))
-        self.variables = ScopeDict(self)
+        self.variables = _ScopeDict(self)
-
+    def __repr__(self):
-            classes.append(_AVMClass(name_idx, self.multinames[name_idx]))
+
-                parse_traits_info()
+                trait_methods = parse_traits_info()
-                    for name, idx in trait_methods.items()))
+                avm_class.register_methods(trait_methods)
-            raise ExtractorError('Cannot find function %r' % func_name)
+            raise ExtractorError('Cannot find function %s.%s' % (
-            scopes = collections.deque([avm_class.variables])
+            scopes = collections.deque([
-                        res = args[0].join(obj)
+
-                            % (mname, obj))
+                        continue
-                        obj.avm_class, mname)
+                        obj, mname)
-                    stack.append(obj)
+                    stack.append(obj.make_object())
-                    stack.append(res)
+                    stack.append(res[mname])
-                        res = scopes[0]
+                        res = avm_class.variables
-                        scope = scopes[0]
+                        scope = avm_class.variables
-from .utils import ExtractorError
+from .utils import (
-        self.variables = {}
+
-        constant_strings = ['']
+        self.constant_strings = ['']
-            constant_strings.append(s)
+            self.constant_strings.append(s)
-                self.multinames.append(constant_strings[name_idx])
+                self.multinames.append(self.constant_strings[name_idx])
-                    stack.append(constant_strings[idx])
+                    stack.append(self.constant_strings[idx])
-for testfile in os.listdir(TEST_DIR):
+def _make_testfunc(testfile):
-        continue
+        return
-                subprocess.check_call(['mxmlc', '--output', swf_file, as_file])
+                subprocess.check_call(['mxmlc', '-output', swf_file, as_file])
-    return struct.unpack('!i', first_byte + bs)
+    last_byte = b'\xff' if (ord(bs[2:3]) >= 0x80) else b'\x00'
-            registers = ['(this)'] + list(args) + [None] * m.local_count
+            registers = [avm_class.variables] + list(args) + [None] * m.local_count
-                    # ignore the popped value
+                    scopes.append(new_scope)
-                    res = avm_class.variables.get(mname)
+                    for s in reversed(scopes):
-                    res = avm_class.variables.get(mname, None)
+                    for s in reversed(scopes):
-    pos = 0
+def _extract_tags(file_contents):
-        assert pos + tag_len <= len(content)
+        assert pos + tag_len <= len(content), \
-        reader = code_reader
+    assert count >= 0
-                        for tag_code, tag in _extract_tags(content)
+                        for tag_code, tag in _extract_tags(file_contents)
-        read_bytes((double_count - 1) * 8)
+        read_bytes(max(0, (double_count - 1)) * 8)
-    _VALID_URL = r'https?://www\.francetvinfo\.fr/.*/(?P<title>.+)\.html'
+    _VALID_URL = r'https?://(?:www|mobile)\.francetvinfo\.fr/.*/(?P<title>.+)\.html'
-    _VALID_URL = r'https?://culturebox\.francetvinfo\.fr/(?P<name>.*?)(\?|$)'
+    _VALID_URL = r'https?://(?:m\.)?culturebox\.francetvinfo\.fr/(?P<name>.*?)(\?|$)'
-    _VALID_URL = r'http?://m\.mlb\.com/video/(?:topic/[\da-z_-]+/)?v(?P<id>n?\d+)'
+    _VALID_URL = r'https?://m\.mlb\.com/video/(?:topic/[\da-z_-]+/)?v(?P<id>n?\d+)'
-# coding: utf-8
+from ..utils import (
-    _VALID_URL = r'http?://.*?\.cracked\.com/video_+(?P<id>.*)_.*'
+    _VALID_URL = r'https?://(?:www\.)?cracked\.com/video_(?P<id>\d+)_[\da-z-]+\.html'
-
+        'url': 'http://www.cracked.com/video_19006_4-plot-holes-you-didnt-notice-in-your-favorite-movies.html',
-            'id': '18803',
+            'id': '19006',
-
+            'title': '4 Plot Holes You Didn\'t Notice in Your Favorite Movies',
-        height = re.findall(r'height="(.*?)"',webpage)[1]
+        video_url = self._html_search_regex(
-            'width':int(width)
+        view_count = str_to_int(self._html_search_regex(
-    assert m, '%r should follow URL format' % basename
+    m = re.match(r'.*-([a-zA-Z0-9_-]+)(?:/watch_as3)?\.[a-z]+$', url)
-
+        swfi = SWFInterpreter(file_contents)
-        initial_function = extract_function(searched_class, u'decipher')
+        searched_class = swfi.extract_class(TARGET_CLASSNAME)
-        searched_class_id = None
+        classes = []
-                searched_class_id = class_id
+            classes.append(AVMClass(name_idx))
-        if searched_class_id is None:
+        TARGET_CLASSNAME = u'SignatureDecipher'
-        for class_id in range(class_count):
+        for avm_class in classes:
-                        for name, idx in trait_methods.items()))
+                avm_class.method_names.update(trait_methods.items())
-                methods[method_idxs[method_idx]] = m
+            for avm_class in classes:
-            if func_name not in methods:
+        def extract_function(avm_class, func_name):
-            m = methods[func_name]
+            m = avm_class.methods[func_name]
-                    if opcode == 36:  # pushbyte
+                    if opcode == 17:  # iftrue
-                            stack.append(method_pyfunctions[mname](args))
+                        elif mname in avm_class.method_pyfunctions:
-                        res = extract_function(mname)
+                        res = extract_function(avm_class, mname)
-            method_pyfunctions[func_name] = resfunc
+            avm_class.method_pyfunctions[func_name] = resfunc
-        initial_function = extract_function(u'decipher')
+        initial_function = extract_function(searched_class, u'decipher')
-            transform_source=lambda j: re.sub(r'parseMetadata\((.*?)\);\n//epc', r'\1', j)
+            transform_source=lambda j: re.sub(r'parseMetadata\((.*?)\);\n//.*$', r'\1', j)
-                        player_url)
+        id_m = re.match(
-                                else:
+                            if player_url is None:
-                                player_desc = u'html5 player %s' % player_version
+                                    player_desc = 'flash player %s' % player_version
-            webpage, u'thumbnail', fatal=False)
+        video_thumbnail = self._og_search_thumbnail(webpage)
-                    'tbr': bitrate,
+                    # The bitrate may not be a number (for example: 'iphone')
-        title = self._html_search_regex(r'<meta property="og:title" content="\s*(.*?)\s*"\s*/?\s*>', webpage, 'title')
+        title = self._og_search_title(webpage)
-    _VALID_URL = r'''(?x)https?://(?:www\.)?(comedycentral|cc)\.com/
+    _VALID_URL = r'''(?x)https?://(?:www\.)?cc\.com/
-        'url': 'http://www.comedycentral.com/video-clips/kllhuv/stand-up-greg-fitzsimmons--uncensored---too-good-of-a-mother',
+        'url': 'http://www.cc.com/video-clips/kllhuv/stand-up-greg-fitzsimmons--uncensored---too-good-of-a-mother',
-        (video-clips|episodes|cc-studios|video-collections)
+        (video-clips|episodes|cc-studios|video-collections|full-episodes)
-            r'<div class="js-player-embed" data-video="([^"]+)"', page, 'data video'))['data']
+            r'<div class="js-player-embed(?: player-embed)?" data-video="([^"]+)"', page, 'data video'))['data']
-from .mlb import MlbIE
+from .mlb import MLBIE
-            'title': "Stanton prepares for Derby",
+class MLBIE(InfoExtractor):
-    }
+        {
-        webpage = self._download_webpage(url, video_id)
+        detail = self._download_xml(
-        thumbnail = self._html_search_regex(r'<meta itemprop="image" (?:content|value)="(.*?)" />', webpage, 'image', fatal=False)
+        formats = []
-                                    video_url = element.text
+        self._sort_formats(formats)
-            'format': 'mp4',
+            'duration': duration,
-__version__ = '2014.07.11.3'
+__version__ = '2014.07.15'
-                    video_url = base_url+'/'+video+'_'+video_id+'_600K.mp4'
+        mediadetails = self._download_xml(_mediadetail_url, video_id, "Downloading media detail...")
-                        video_url = base_url+'/'+video+'_'+video_id+'_300K.mp4'
+                    if scenario.startswith(u'FLASH_1500K'):
-                
+                        if (scenario.startswith(u'FLASH_1200K') and not has1500K):
-            val = local_vars[m.group('in')]
+            variable = m.group('in')
-            for stmt in func_m.group('code').split(';'):
+            for stmt in code.split(';'):
-
+
-)
+from ..utils import compat_parse_qs
-        'md5': '5eb766671f69b82e528dc1e7769c5cb2',
+        'url': 'http://tu.tv/videos/robots-futbolistas',
-            'title': 'Noah en pabellon cuahutemoc',
+            'id': '2973058',
-        video_url = base64.b64decode(data['kpt'][0]).decode('utf-8')
+        data_content = self._download_webpage(
-            'md5': '56a8b69568acaa967b4c49f9d1d52d19',
+            'url': 'https://soundcloud.com/oddsamples/bus-brakes',
-                'id': '105614606',
+                'id': '128590877',
-                #'duration': 42,
+                'title': 'Bus Brakes',
-    return re.sub(r'(?s)^[a-zA-Z0-9_]+\s*\(\s*(.*)\)\s*?\s*$', r'\1', code)
+    return re.sub(r'(?s)^[a-zA-Z0-9_]+\s*\(\s*(.*)\);?\s*?\s*$', r'\1', code)
-            r'<div class="section">.*?<h3(?:\s+class="[^"]*")?>([^>]+?)</h3>',
+            r'<div class="section">\s*<h3(?:\s+class="[^"]*"[^>]*)?>([^>]+?)</h3>',
-    SouthParkStudiosIE,
+from .southpark import (
-    _VALID_URL = r'https?://(www\.)?(?P<url>(?:southpark\.cc|southparkstudios)\.com/(clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
+class SouthParkIE(MTVServicesInfoExtractor):
-        'url': 'http://www.southparkstudios.com/clips/104437/bat-daded#tab=featured',
+        'url': 'http://southpark.cc.com/clips/104437/bat-daded#tab=featured',
-class SouthparkDeIE(SouthParkStudiosIE):
+class SouthparkDeIE(SouthParkIE):
-            'title': 'Bat Daded',
+            'title': 'South Park|Bat Daded',
-from .gameone import GameOneIE
+from .gameone import (
-    _VALID_URL = r'https?://(www\.)?(?P<url>southparkstudios\.com/(clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
+    _VALID_URL = r'https?://(www\.)?(?P<url>(?:southpark\.cc|southparkstudios)\.com/(clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
-    return re.sub(r'(?s)^[a-zA-Z_]+\s*\(\s*(.*)\);\s*?\s*$', r'\1', code)
+    return re.sub(r'(?s)^[a-zA-Z0-9_]+\s*\(\s*(.*)\)\s*?\s*$', r'\1', code)
-            'md5': 'e7a6079ca39d3568f4996cb858dd6708',
+            'url': 'http://www.ndr.de/fernsehen/media/dienordreportage325.html',
-                'id': '7959',
+                'id': '325',
-                'duration': 2655,
+                'title': 'Blaue Bohnen aus Blocken',
-            'thumbnail': 're:http://.*\.jpg',
+            'thumbnail': 're:^http://.*\.jpg$',
-            raise ExtractorError(u'Video %s does not exist' % video_id,
+            raise ExtractorError('Video %s does not exist' % video_id,
-                                 webpage, 'file url')
+                                       'thumbnail', fatal=False)
-            'quality': 1,
+            'url': video_url,
-            'thumbnail': "http:" + thumbnail,
+            'thumbnail': thumbnail,
-                r'class="tabSeperator">></span><span class="tabText">(.*?)<',
+                [r'<b>Title:</b> ([^<]*)</div>',
-            (?:daclips\.in|gorillavid\.in)/
+        https?://(?P<host>(?:www\.)?
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage('http://%s/%s' % (mobj.group('host'), video_id), video_id)
-__version__ = '2014.07.11.2'
+__version__ = '2014.07.11.3'
-        self.url = 'sAjKT8FhjI8'
+        self.url = 'n5BB19UTcdA'
-        self.assertTrue(len(result['entries']) >= 50)
+        self.assertTrue(len(result['entries']) >= 47)
-            help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm)')
+            help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv)')
-    def _html_search_meta(self, name, html, display_name=None, fatal=False):
+    def _html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs):
-            html, display_name, fatal=fatal)
+            html, display_name, fatal=fatal, **kwargs)
-    _TEST = {
+    _TESTS = [{
-            'thumbnail': 're:^https?://.*\.jpg$'
+            'thumbnail': 're:^https?://.*\.(?:gif|jpg)$',
-    }
+    }, {
-        flash_vars = compat_parse_qs(flash_vars_s)
+        video_url = self._html_search_regex(
-        description = self._og_search_description(webpage)
+        title = self._og_search_title(webpage, default=None)
-__version__ = '2014.07.11.1'
+__version__ = '2014.07.11.2'
-from ..utils import determine_ext
+
-    _VALID_URL = r'https?://www\.criterion\.com/films/(\d*)-.+'
+    _VALID_URL = r'https?://www\.criterion\.com/films/(?P<id>[0-9]+)-.+'
-            u"description" : u'md5:a2b4b116326558149bef81f76dcbb93f',
+        'url': 'http://www.criterion.com/films/184-le-samourai',
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-                                webpage, 'thumbnail url')
+        final_url = self._search_regex(
-                }
+        return {
-__version__ = '2014.07.11'
+__version__ = '2014.07.11.1'
-        'md5': 'c9dda6aac8f814352ad2aee8899b1612',
+        #'md5': 'd68703d9f73dc8fccf3320ab34202590',
-            'uploader': 'TENplay'
+            'uploader': 'TENplay',
-    _video_fields = ["id","name","shortDescription","longDescription","creationDate","publishedDate","lastModifiedDate","customFields","videoStillURL","thumbnailURL","referenceId","length","playsTotal","playsTrailingWeek","renditions","captioning","startDate","endDate"]
+    _video_fields = [
-        title = self._html_search_regex(r'<meta property="og:title" content="\s*(.*?)\s*"\s*/?\s*>', webpage, 'title')
+        video_id = self._html_search_regex(
-                })
+                'url': url,
-import zlib
+import re
-        player_url = self._html_search_regex(r'"(http://player.vimple.ru/flash/.+?)"', iframe, 'player url')
+        iframe = self._download_webpage(
-        player = self._request_webpage(player_url, video_id, note='Downloading swf player').read()
+        player = self._request_webpage(
-    determine_ext,
+
-            'duration': int(video.get('duration')),
+            'duration': int_or_none(video.get('duration')),
-    _VALID_URL = r'https?://(?:www\.)?gorillavid\.in/(?:embed-)?(?P<id>[0-9a-zA-Z]+)(?:-[0-9]+x[0-9]+\.html)?'
+    IE_DESC = 'GorillaVid.in and daclips.in'
-
+            'age_limit': 18,
-                                           fatal=True, flags=re.S)
+        player_config = self._search_regex(
-import netrc
+import time
-            time.sleep(3) #they do detect when requests happen too fast!
+            self._sleep(3, video_id)  # they do detect when requests happen too fast!
-            webpage = self._download_webpage(req, video_id, 'Downloading video page')
+            webpage = self._download_webpage(
-        url = self._search_regex(r'file:\s*"(http[^\"]+)",', webpage, 'file url')
+        title = self._search_regex(
-__version__ = '2014.07.10'
+__version__ = '2014.07.11'
-        u'2909FDCA8C5E6D92D34B34E7C7AFFD7CA57532DA.5BA2848AD58DAA15002012C7CD77187D24E048A5',
+        u'2ACFC7A61CA478CD21425E5A57EBD73DDC78E22A.2094302436B2D377D14A3BBA23022D023B8BC25AA',
-            (r'(?:function %s|%s\s*=\s*function)' % (
+            (r'(?:function %s|[{;]%s\s*=\s*function)' % (
-                    u'Automatic signature extraction failed: ' + tb, cause=e)
+        if player_url is None:
-            s, video_id, player_url, age_gate)
+        if player_url.startswith(u'//'):
-                return u''.join(val)
+                return ''.join(val)
-def make_tfunc(url, stype, sig_length, expected_sig):
+def make_tfunc(url, stype, sig_input, expected_sig):
-        src_sig = compat_str(string.printable[:sig_length])
+        src_sig = (
-            except Exception:
+            except Exception as e:
-                u'Warning: Falling back to static signature algorithm')
+                raise ExtractorError(
-__version__ = '2014.06.26'
+__version__ = '2014.07.10'
-            r"new FM\.Player\('[^']+',\s*(\{.*?)\);\n", webpage, 'json')
+            r"new FM\.Player\('[^']+',\s*(\{.*?)\).player;", webpage, 'json')
-    _VALID_URL = r'https?://(www\.)?soundcloud\.com/(?P<user>[^/]+)(/?(tracks/)?)?(\?.*)?$'
+    _VALID_URL = r'https?://(www\.)?soundcloud\.com/(?P<user>[^/]+)/?((?P<rsrc>tracks|likes)/?)?(\?.*)?$'
-        base_url = 'http://api.soundcloud.com/users/%s/tracks.json?' % uploader
+        base_url = 'http://api.soundcloud.com/users/%s/%s.json?' % (uploader, resource)
-            if len(new_entries) < 50:
+            if len(new_entries) == 0:
-            r'var postView = new app\.PostView\({\s*post:\s*({.+?}),', webpage, 'post view'))
+            r'var postView = new app\.PostView\({\s*post:\s*({.+?}),\s*posts:\s*prefetchedCurrentPost', webpage, 'post view'))
-            'url': q.text,
+            # The playpath starts at 'mp4:', if we don't manually
-        'url': 'http://newstube.ru/media/na-korable-progress-prodolzhaetsya-testirovanie-sistemy-kurs',
+        'url': 'http://www.newstube.ru/media/telekanal-cnn-peremestil-gorod-slavyansk-v-krym',
-            'id': 'd156a237-a6e9-4111-a682-039995f721f1',
+            'id': '728e0ef2-e187-4012-bac0-5a081fdcb1f6',
-            'duration': 20.04,
+            'title': 'Ð¢ÐµÐ»ÐµÐºÐ°Ð½Ð°Ð» CNN Ð¿ÐµÑÐµÐ¼ÐµÑÑÐ¸Ð» Ð³Ð¾ÑÐ¾Ð´ Ð¡Ð»Ð°Ð²ÑÐ½ÑÐº Ð² ÐÑÑÐ¼',
-        help='Use this prefix for unqualified URLs. For example "gvsearch2:" downloads two videos from google videos for  youtube-dl "large apple". By default (with value "auto") youtube-dl guesses.')
+        help='Use this prefix for unqualified URLs. For example "gvsearch2:" downloads two videos from google videos for  youtube-dl "large apple". Use the value "auto" to let youtube-dl guess. The default value "error" just throws an error.')
-                default_search = 'auto_warning'
+                default_search = 'error'
-                                'Falling back to youtube search for  %s . Set --default-search to "auto" to suppress this warning.' % url)
+                                'Falling back to youtube search for  %s . Set --default-search "auto" to suppress this warning.' % url)
-
+    parse_duration,
-    _VALID_URL = r'^https?://(?:www\.|secure\.)?nicovideo\.jp/watch/((?:[a-z][a-z])?[0-9]+)(?:.*)$'
+    _VALID_URL = r'https?://(?:www\.|secure\.)?nicovideo\.jp/watch/((?:[a-z]{2})?[0-9]+)'
-        # No need to fetch extra resources...new API has field for uploader's name
+        title = video_info.find('.//title').text
-            video_uploader = video_info.find('.//ch_name').text
+            uploader_id = video_info.find('.//ch_id').text
-            video_uploader = video_info.find('.//user_nickname').text
+            uploader_id = video_info.find('.//user_id').text
-            'ext': video_extension,
+            'title': title,
-            'webpage_url': video_webpage_url,
+            'thumbnail': thumbnail,
-            r'(?s)<ol id="search-results"(.*?)</ol>', webpage, u'result HTML')
+            r'(?s)<ol class="item-section"(.*?)</ol>', webpage, u'result HTML')
-                r'(?s)title="([^"]+)"', part_code, 'item title', fatal=False)
+                [r'(?s)title="([^"]+)"', r'>([^<]+)</a>'], part_code, 'item title', fatal=False)
-    _VALID_URL = r'https?://(?:www\.)?teachertube\.com/(viewVideo\.php\?video_id=|music\.php\?music_id=|video/|audio/)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?teachertube\.com/(viewVideo\.php\?video_id=|music\.php\?music_id=|video/(?:[\da-z-]+-)?|audio/)(?P<id>\d+)'
-            webpage))
+        urls.extend(re.findall(self._MEDIA_RE, webpage))
-                webpage))
+            urls.extend(re.findall(self._MEDIA_RE, webpage))
-    IE_NAME = u'anitube.se'
+    IE_NAME = 'anitube.se'
-            u'title': u'Recorder to Randoseru 01',
+        'url': 'http://www.anitube.se/video/36621',
-        u'skip': u'Blocked in the US',
+        'skip': 'Blocked in the US',
-                                      webpage, u'key')
+        key = self._html_search_regex(
-                                                key)
+        config_xml = self._download_xml(
-    _VALID_URL = r'^https?://(?:www\.|secure\.)?nicovideo\.jp/watch/([a-z][a-z][0-9]+)(?:.*)$'
+    _VALID_URL = r'^https?://(?:www\.|secure\.)?nicovideo\.jp/watch/((?:[a-z][a-z])?[0-9]+)(?:.*)$'
-            self._downloader.report_warning('Unable to download user info webpage: %s' % compat_str(err))
+        # No need to fetch extra resources...new API has field for uploader's name
-        self._login()
+        if self._downloader.params.get('username', None) is not None:
-            video_id, 'Downloading flv info')
+        if self._AUTHENTICATE:
-
+    }, {
-        (?:https?://)?[^/]+/watch\?(?:feature=[a-z_]+)?$|
+        (?:https?://)?[^/]+/watch\?(?:
-            }
+            },
-        'md5': '8aaa8bf3ae1ca2652309718c03019128',
+        'url': 'http://www.tagesschau.de/multimedia/video/video-5964.html',
-            'id': '196',
+            'id': '5964',
-            'description': 'md5:f22e4af75821d174fa6c977349682691',
+            'title': 'Nahost-Konflikt: Israel bombadiert Ziele im Gazastreifen und Westjordanland',
-            'md5': 'cfff440d4ee64114083ac44676df5d15',
+            'url': 'http://www.funkhauseuropa.de/av/audiosuepersongsoulbossanova100-audioplayer.html',
-                'id': 'mdb-363068',
+                'id': 'mdb-463528',
-                'title': 'Grenzenlos lecker - Baklava',
+                'title': 'SÃ¼persong: Soul Bossa Nova',
-                'upload_date': '20140311',
+                'upload_date': '20140630',
-        '_skip': 'Will be depublicized shortly'
+        'skip': 'Problems with loading data.'
-            r'"sidebar_thumb_time">[0-9:]+</div>\s+<a href="(https?://(?:www\.)?teachertube\.com/(video|audio)/[^"]+)">',
+            r'"sidebar_thumb_time">[0-9:]+</div>\s+<a href="(https?://(?:www\.)?teachertube\.com/(?:video|audio)/[^"]+)">',
-                r'"sidebar_thumb_time">[0-9:]+</div>\s+<a href="(https?://(?:www\.)?teachertube\.com/(video|audio)/[^"]+)">',
+                r'"sidebar_thumb_time">[0-9:]+</div>\s+<a href="(https?://(?:www\.)?teachertube\.com/(?:video|audio)/[^"]+)">',
-            webpage, 'title', default='NA')
+        video_title = self._og_search_description(webpage).splitlines()[0]
-    _VALID_URL = r'https?://(?:www\.)?ivi\.ru/watch(?:/(?P<compilationid>[^/]+))?/(?P<videoid>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?ivi\.ru/(?:watch/(?:[^/]+/)?|video/player\?.*?videoId=)(?P<videoid>\d+)'
-    _VALID_URL = r'https?://vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|(?:.+?\?.*?z=)?video(?P<videoid>.*?)(?:\?|%2F|$))'
+    _VALID_URL = r'https?://(?:m\.)?vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|(?:.+?\?.*?z=)?video(?P<videoid>.*?)(?:\?|%2F|$))'
-    _VALID_URL = r'https?://vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|(?:videos.*?\?.*?z=)?video(?P<videoid>.*?)(?:\?|%2F|$))'
+    _VALID_URL = r'https?://vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|(?:.+?\?.*?z=)?video(?P<videoid>.*?)(?:\?|%2F|$))'
-                'title': 'âº ÐÐ¾Ð¹ÑÐ¾Ð²ÑÐºÐ¸Ð¹ ÐºÐ»ÑÐ± / Fight Club 1999 [HD 720]\u00a0',
+                'title': 'âº ÐÐ¾Ð¹ÑÐ¾Ð²ÑÐºÐ¸Ð¹ ÐºÐ»ÑÐ± / Fight Club 1999 [HD 720]',
-    TeacherTubeClassroomIE,
+    TeacherTubeUserIE,
-    def test_TeacherTubeClassroom(self):
+    def test_TeacherTubeUser(self):
-        result = ie.extract('http://www.teachertube.com/view_classroom.php?user=rbhagwati2')
+        ie = TeacherTubeUserIE(dl)
-        self.assertTrue(len(result['entries']) >= 20)
+        self.assertTrue(len(result['entries']) >= 179)
-    TeacherTubeClassroomIE,
+    TeacherTubeUserIE,
-    IE_DESC = 'teachertube.com online classrooms'
+class TeacherTubeUserIE(InfoExtractor):
-    _VALID_URL = r'https?://(?:www\.)?teachertube\.com/view_classroom\.php\?user=(?P<user>[0-9a-zA-Z]+)'
+    _VALID_URL = r'https?://(?:www\.)?teachertube\.com/(user/profile|collection)/(?P<user>[0-9a-zA-Z]+)/?'
-            user_id, 'Downloading classroom RSS')
+        urls = []
-            entries.append(self.url_result(url.attrib['url'], 'TeacherTube'))
+        for url in urls:
-    _TEST = {
+    _TESTS = [{
-            "title": "tatiana maslany news"
+            'id': '54196191430',
-    }
+    }, {
-    _VALID_URL = r'http://videos\.toypics\.net/view/(?P<id>[0-9]+)/.*'
+    _VALID_URL = r'https?://videos\.toypics\.net/view/(?P<id>[0-9]+)/.*'
-                    r'<p class="video-entry-title">\n\s*<a href="(http://videos.toypics.net/view/[^"]+)">',
+                    r'<p class="video-entry-title">\s+<a href="(https?://videos.toypics.net/view/[^"]+)">',
-                'uploader': 'Noize MC',
+                'uploader': 're:Noize MC.*',
-from ..utils import str_to_int
+from ..utils import (
-                'thumbnail': 'http://thumbs.motherlessmedia.com/thumbs/AC3FFE1.jpg',
+                'thumbnail': 're:http://.*\.jpg',
-                'thumbnail': 'http://thumbs.motherlessmedia.com/thumbs/532291B.jpg',
+                'thumbnail': 're:http://.*\.jpg',
-                                                        'view_count', flags=re.DOTALL))
+        title = self._html_search_regex(r'id="view-upload-title">\s+([^<]+)<', webpage, 'title')
-                                              webpage, 'uploader_id', flags=re.DOTALL)
+        uploader_id = self._html_search_regex(r'"thumb-member-username">\s+<a href="/m/([^"]+)"', webpage, 'uploader_id')
-        if categories is not None:
+        if categories:
-            'thumbnail': thumbnail,
+            'thumbnail': self._og_search_thumbnail(webpage),
-            'like_count': like_count,
+            'view_count': int_or_none(view_count.replace(',', '')),
-from..utils import parse_iso8601
+from ..utils import parse_iso8601
-            if all(f['versionCode'] == 'VO' for f in all_formats):
+            if all(f['versionCode'] == 'VO' or f['versionCode'] == 'VA' for f in all_formats):
-            'id': '050940-003',
+            'id': '5201',
-__version__ = '2014.06.25'
+__version__ = '2014.06.26'
-from .livestream import LivestreamIE, LivestreamOriginalIE
+from .livestream import (
-    _VALID_URL = r'https?://www\.livestream\.com/(?P<user>[^/]+)/video\?.*?clipId=(?P<id>.*?)(&|$)'
+    _VALID_URL = r'''(?x)https?://www\.livestream\.com/
-        user = mobj.group('user')
+    def _extract_video(self, user, video_id):
-    _VALID_URL = r'https?://(?:www\.)?teachertube\.com/(viewVideo\.php\?video_id=|music\.php\?music_id=)(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?teachertube\.com/(viewVideo\.php\?video_id=|music\.php\?music_id=|video/|audio/)(?P<id>\d+)'
-            'thumbnail': self._html_search_regex(r'var\s+thumbUrl\s*=\s*"([^"]+)"', webpage, 'thumbnail'),
+            'thumbnail': self._html_search_regex(r'\'image\'\s*:\s*["\']([^"\']+)["\']', webpage, 'thumbnail'),
-from ..utils import unified_strdate
+from ..utils import (
-            'dislike_count': int(video['disliked']),
+            'view_count': int_or_none(video['view_count']),
-        audio_url = self._html_search_regex(r'(?s)m4a\:\s"([^"]+)"', webpage, 'audio URL')
+        webpage = self._download_webpage(url, display_id)
-        description = self._html_search_regex(r'(?s)<li>Description:\s(.*?)<\/li>', webpage, 'description', fatal=False, flags=re.DOTALL)
+        description = self._html_search_regex(
-__version__ = '2014.06.24.1'
+__version__ = '2014.06.25'
-            'uploader': info['owner_screenname'],
+            'uploader': info['owner.screenname'],
-        result = ie.extract('http://rutube.ru/tags/video/1409')
+        result = ie.extract('http://rutube.ru/tags/video/1800/')
-        self.assertTrue(len(result['entries']) >= 34)
+        self.assertEqual(result['id'], '1800')
-    _VALID_URL = r'https?://(?:\w+\.)?blip\.tv/(?:(?:.+-|rss/flash/)(?P<id>\d+)|((?:play/|api\.swf#)(?P<lookup_id>[\da-zA-Z]+)))'
+    _VALID_URL = r'https?://(?:\w+\.)?blip\.tv/(?:(?:.+-|rss/flash/)(?P<id>\d+)|((?:play/|api\.swf#)(?P<lookup_id>[\da-zA-Z+]+)))'
-    _VALID_URL = r'http://dsc\.discovery\.com\/[a-zA-Z0-9\-]*/[a-zA-Z0-9\-]*/videos/(?P<id>[a-zA-Z0-9\-]*)(.htm)?'
+    _VALID_URL = r'http://www\.discovery\.com\/[a-zA-Z0-9\-]*/[a-zA-Z0-9\-]*/videos/(?P<id>[a-zA-Z0-9\-]*)(.htm)?'
-        'url': 'http://dsc.discovery.com/tv-shows/mythbusters/videos/mission-impossible-outtakes.htm',
+        'url': 'http://www.discovery.com/tv-shows/mythbusters/videos/mission-impossible-outtakes.htm',
-    _VALID_URL = r'^https?://(?:fast\.)?wistia\.net/embed/iframe/(?P<id>[a-z0-9]+)'
+    _VALID_URL = r'https?://(?:fast\.)?wistia\.net/embed/iframe/(?P<id>[a-z0-9]+)'
-            u"title": u"cfh_resourceful_zdkh_final_1"
+        'url': 'http://fast.wistia.net/embed/iframe/sh7fpupwlt',
-            r'Wistia.iframeInit\((.*?), {}\);', webpage, u'video data')
+            r'Wistia\.iframeInit\((.*?), {}\);', webpage, 'video data')
-            epTitle = mobj.group('episode').rpartition('/')[-1]
+            epTitle = (mobj.group('episode') or mobj.group('videotitle')).rpartition('/')[-1]
-__version__ = '2014.06.24'
+__version__ = '2014.06.24.1'
-__version__ = '2014.06.19'
+__version__ = '2014.06.24'
-            'description': 'md5:a3e9853487185e9fcd7181a07164650b',
+            'title': 'Measures of dispersion from a frequency table',
-            'description': 'md5:2ca52b20cd727773d1dc418b3d6bd07b',
+            'description': 'Learn how to make paper dolls in this simple',
-            'description': 'RADIJSKA EMISIJA ZRAKOPLOVNE TEHNIÄKE Å KOLE PER ASPERA AD ASTRA',
+            'description': 'RADIJSKA EMISIJA ZRAKOPLOVNE TEHNI?KE ?KOLE P',
-        _, media_urls = zip(*re.findall(r'([\'"])file\1\s*:\s*"([^"]+)"', webpage))
+        media_urls = re.findall(r'data-contenturl="([^"]+)"', webpage)
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'title': title,
-            'description': self._og_search_description(webpage),
+            'description': description,
-                                      user_id, 'Downloading classroom RSS')
+        rss = self._download_xml(
-            self._FEED_URL + '?' + data, video_id,
+            feed_url + '?' + data, video_id,
-            'md5': 'c4f83cf0f023ba5875aba0bf46860df2',
+            'url': 'http://www.br.de/mediathek/video/sendungen/heimatsound/heimatsound-festival-2014-trailer-100.html',
-                'id': '2c8d81c5-6fb7-4a74-88d4-e768e5856532',
+                'id': '25e279aa-1ffd-40fd-9955-5325bd48a53a',
-                'upload_date': '20140301',
+                'title': 'Am 1. und 2. August in Oberammergau',
-        title = item.find('./title').text
+            'description': description,
-        'file': '1259285.mp4',
+            'id': '1259285',
-    {
+    }, {
-        'file': '1309159.mp4',
+            'id': '1309159',
-        video_title = self._html_search_regex(
+        title = self._html_search_regex(
-        )
+            r'var\s+server\s*=\s*"([^"]+)\"', webpage, 'server URL')
-            note='Downloading XML', errnote='Failed to download XML from "{0}"'.format(xml_url))
+        idoc = self._download_xml(xml_url, video_id)
-            'title': video_title,
+            'title': title,
-                'url': 'http://video2.spiegel.de/flash/' + n.find('./filename').text,
+                'url': base_url + n.find('./filename').text,
-        xml_url = 'http://video2.spiegel.de/flash/' + video_id + '.xml'
+        base_url = self._search_regex(
-            note='Downloading XML', errnote='Failed to download XML')
+            note='Downloading XML', errnote='Failed to download XML from "{0}"'.format(xml_url))
-            'http://api.noco.tv/1.0/video/medias/%s' % video_id, video_id, 'Downloading video JSON')
+            'https://api.noco.tv/1.0/video/medias/%s' % video_id, video_id, 'Downloading video JSON')
-                'http://api.noco.tv/1.0/video/file/%s/fr/%s' % (format_id.lower(), video_id),
+                'https://api.noco.tv/1.0/video/file/%s/fr/%s' % (format_id.lower(), video_id),
-            'http://api.noco.tv/1.0/shows/show/%s' % video_id, video_id, 'Downloading show JSON')[0]
+            'https://api.noco.tv/1.0/shows/show/%s' % video_id, video_id, 'Downloading show JSON')[0]
-__version__ = '2014.06.16'
+__version__ = '2014.06.19'
-            r'signature=([a-zA-Z]+)', jscode,
+            r'signature=([$a-zA-Z]+)', jscode,
-            'thumbnail': 'http://lifenews.ru/static/posts/2014/1/126342/.video.jpg',
+            'thumbnail': 're:http://.*\.jpg',
-            'description': "The final trailer for the Steam Greenlight launch. Hooray, progress! Here's the official Greenlight page: http://steamcommunity.com/sharedfiles/filedetails/?id=242472205",
+            'description': 'md5:6df4fe8dd494ae811869672b0767e025',
-        r'clipId=(\d+)',
+        r'clip[iI]d=(\d+)',
-        r'<div class="ep-femvideos-pi4-video-txt">\s*<h2>(.+?)</h2>',
+        r'<h1 class="att-name">\s*(.+?)</h1>',
-        r'<p>(.+?)</p>\s*<div class="ep-femvideos-pi4-video-footer">',
+        r'<p class="att-description">\s*(.+?)\s*</p>',
-    _VALID_URL = r'http://www\.bilibili\.tv/video/av(?P<id>[0-9]+)/'
+    _VALID_URL = r'http://www\.bilibili\.(?:tv|com)/video/av(?P<id>[0-9]+)/'
-            r'<iframe .*?class="player" src="https://secure.bilibili.tv/secure,([^"]+)"',
+            r'<iframe .*?class="player" src="https://secure\.bilibili\.(?:tv|com)/secure,([^"]+)"',
-        result = ie.extract('http://www.ustream.tv/channel/young-americans-for-liberty')
+        result = ie.extract('http://www.ustream.tv/channel/channeljapan')
-        self.assertTrue(len(result['entries']) >= 6)
+        self.assertEqual(result['id'], '10874166')
-# coding: utf-8
+# -*- coding: utf-8 -*-
-        'url': "http://gorillavid.in/z08zf8le23c6",
+    _VALID_URL = r'https?://(?:www\.)?gorillavid\.in/(?:embed-)?(?P<id>[0-9a-zA-Z]+)(?:-[0-9]+x[0-9]+\.html)?'
-    }
+            'thumbnail': 're:http://.*\.jpg',
-        url = self._html_search_regex(r'file:\s+["\'](http://.*?video.\w{3})["\']', webpage, url)
+        fields = dict(re.findall(r'''(?x)<input\s+
-        info_dict = {
+            webpage = self._download_webpage(req, video_id, 'Downloading video page')
-            'url': url,
+            'thumbnail': thumbnail,
-                'id': 'muhh48000314',
+                'id': 'MUHH48000314',
-    _VALID_URL = r'http://tv\.nrk(?:super)?\.no/(?:serie/[^/]+|program)/(?P<id>[a-z]{4}\d{8})'
+    _VALID_URL = r'http://tv\.nrk(?:super)?\.no/(?:serie/[^/]+|program)/(?P<id>[a-zA-Z]{4}\d{8})'
-            'url': 'http://tv.nrk.no/serie/20-spoersmaal-tv/muhh48000314/23-05-2014',
+            'url': 'http://tv.nrk.no/serie/20-spoersmaal-tv/MUHH48000314/23-05-2014',
-        }
+        }
-                    quality = s['_quality'] + reverse.index(i)
+                for index, url in enumerate(s['_stream'][::-1]):
-                        'format_id': '%s-%s' % (determine_ext(i), quality)
+                        'url': url,
-            }
+            },
-__version__ = '2014.06.09'
+__version__ = '2014.06.16'
-            renditions = sorted(renditions, key=lambda r: r['size'])
+                size = rend.get('size')
-            'file': '2371591881001.mp4',
+                'id': '2371591881001',
-            'file': '1785452137001.flv',
+                'id': '1785452137001',
-        }
+        },
-            } for rend in renditions]
+            formats = []
-        info = self._search_regex(r'var experienceJSON = ({.*?});', webpage, 'json')
+        info = self._search_regex(r'var experienceJSON = ({.*});', webpage, 'json')
-                            (?:PL|EC|UU|FL|RD)?[0-9A-Za-z-_]{10,}
+                            (?:PL|LL|EC|UU|FL|RD)?[0-9A-Za-z-_]{10,}
-                        ((?:PL|EC|UU|FL|RD)[0-9A-Za-z-_]{10,})
+                        ((?:PL|LL|EC|UU|FL|RD)[0-9A-Za-z-_]{10,})
-import xml.etree.ElementTree 
+import re
-    _VALID_URL = r'https?://player.vimple.ru/iframe/(?P<id>[a-f0-9]+)'
+    _VALID_URL = r'https?://(player.vimple.ru/iframe|vimple.ru)/(?P<id>[a-f0-9]{10,})'
-                'ext':'mp4',
+                'ext': 'mp4',
-         }
+            },
-    #http://jsunpack-n.googlecode.com/svn-history/r63/trunk/swf.py
+
-        
+
-        
+
-        #http://stackoverflow.com/a/12073686
+        # http://stackoverflow.com/a/6804758
-        
+
-        
+
-        
+
-        xml_pieces = re.findall(b'([a-zA-Z0-9 =\\+/]{500})', player)
+        xml_pieces = re.findall(b'([a-zA-Z0-9 =+/]{500})', player)
-    IE_NAME = u'livestream'
+    IE_NAME = 'livestream'
-            u'upload_date': u'20121012',
+        'url': 'http://new.livestream.com/CoheedandCambria/WebsterHall/videos/4719370',
-                }
+        return {
-                webpage, u'window config')
+            config_json = self._search_regex(
-                for video_data in info['feed']['data'] if video_data['type'] == u'video']
+                for video_data in info['feed']['data'] if video_data['type'] == 'video']
-            og_video = self._og_search_video_url(webpage, name=u'player url')
+            og_video = self._og_search_video_url(webpage, 'player url')
-                                                     u'Downloading video info'))
+            info = json.loads(self._download_webpage(
-    IE_NAME = u'livestream:original'
+    IE_NAME = 'livestream:original'
-            u'title': u'Spark 1 (BitCoin) with Cameron Winklevoss & Tyler Winklevoss of Winklevoss Capital',
+        'url': 'http://www.livestream.com/dealbook/video?clipId=pla_8aa4a3f1-ba15-46a4-893b-902210e138fb',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-        path = self._search_regex(r'(user-files/.+)_.*?\.jpg$', thumbnail_url, u'path')
+        path = self._search_regex(r'(user-files/.+)_.*?\.jpg$', thumbnail_url, 'path')
-        'md5': '4ea1dada91e4174b53dac2bb8ace429d',
+        'md5': 'fc94ac279feebbce69f21c0c6ee82810',
-)
+from ..utils import remove_start
-        'file': '8aQUy7GV.mp4',
+            'id': '8aQUy7GV',
-        api_url = (u'https://apib4.blinkx.com/api.php?action=play_video&' +
+        api_url = ('https://apib4.blinkx.com/api.php?action=play_video&' +
-                self.to_screen(u'Youtube video detected: %s' % yt_id)
+                self.to_screen('Youtube video detected: %s' % yt_id)
-                format_id = u'%s-%sk-%s' % (vcodec, tbr, m['w'])
+                format_id = '%s-%sk-%s' % (vcodec, tbr, m['w'])
-        'md5': 'e9e0b0c86734e5e3766e653509475db0',
+        'md5': '44bf12b98313827dd52d35b8706a4ea0',
-from ..utils import month_by_name
+from ..utils import (
-            u"thumbnail": u"http://i.ndtvimg.com/video/images/vod/medium/2013-12/big_300710_1386518307.jpg",
+        'url': 'http://www.ndtv.com/video/player/news/ndtv-exclusive-don-t-need-character-certificate-from-rahul-gandhi-says-arvind-kejriwal/300710',
-        video_url = (u'http://bitcast-b.bitgravity.com/ndtvod/23372/ndtv/%s' %
+            r"__filename='([^']+)'", webpage, 'video filename')
-        duration = None if duration_str is None else int(duration_str)
+        duration = int_or_none(self._search_regex(
-        assert date_m
+
-        READ_MORE = u' (Read more)'
+        READ_MORE = ' (Read more)'
-            'title': self._og_search_title(webpage),
+            'title': title,
-__version__ = '2014.06.07'
+__version__ = '2014.06.09'
-    compat_str,
+from .vulture import VultureIE
-    _VALID_URL = r'(?:http://)?(?:www\.)?hypem\.com/track/([^/]+)/([^/]+)'
+    _VALID_URL = r'http://(?:www\.)?hypem\.com/track/([^/]+)/([^/]+)'
-            u"title": u"Tame"
+        'url': 'http://hypem.com/track/1v6ga/BODYWORK+-+TAME',
-        response, urlh = self._download_webpage_handle(request, track_id, u'Downloading webpage with the url')
+        response, urlh = self._download_webpage_handle(
-            response, u'tracks', flags=re.MULTILINE|re.DOTALL).strip()
+        html_tracks = self._html_search_regex(
-            track = track_list[u'tracks'][0]
+            track = track_list['tracks'][0]
-            raise ExtractorError(u'Hypemachine contained invalid JSON.')
+            raise ExtractorError('Hypemachine contained invalid JSON.')
-        title = track[u"song"]
+        key = track['key']
-        request = compat_urllib_request.Request(serve_url, "" , {'Content-Type': 'application/json'})
+        serve_url = "http://hypem.com/serve/source/%s/%s" % (track_id, key)
-        final_url = song_data[u"url"]
+        song_data = self._download_json(request, track_id, 'Downloading metadata')
-        }]
+        return {
-        }
+        },
-            (["\'])(?P<url>(?:https?:)?//(?:www\.)?youtube\.com/
+            (?:
-            self.report_error(u'm3u8 download detected but ffmpeg or avconv could not be found')
+            self.report_error(u'm3u8 download detected but ffmpeg or avconv could not be found. Please install one.')
-            self.report_error('RTMP download detected but "rtmpdump" could not be run')
+            self.report_error('RTMP download detected but "rtmpdump" could not be run. Please install it.')
-            'thumbnail': 'http://m.nuvid.com/%s' % thumbnail,
+            'thumbnail': 'http://m.nuvid.com%s' % thumbnail,
-            "age_limit": 18,
+            'title': 'Horny babes show their awesome bodeis and',
-            webpage, 'title').strip()
+        formats = []
-        video_url = 'http://m.nuvid.com' + url_end
+        for dwnld_speed, format_id in [(0, '3gp'), (5, 'mp4')]:
-            'thumbnail': thumbnail,
+            'thumbnail': 'http://m.nuvid.com/%s' % thumbnail,
-        }
+            'formats': formats,
-            if rsp.get('stat') == 'ok':
+            stat = rsp.get('stat')
-# coding: utf-8
+from __future__ import unicode_literals
-)
+from ..utils import unified_strdate
-            u"upload_date": u"20130622"
+        'url': 'http://www.3sat.de/mediathek/index.php?obj=36983',
-        details_doc = self._download_xml(details_url, video_id, note=u'Downloading video details')
+        details_doc = self._download_xml(details_url, video_id, 'Downloading video details')
-            'height': te.attrib['key'].partition('x')[2],
+            'width': int(te.attrib['key'].partition('x')[0]),
-            } for media_url in set(zip(*re.findall(r'([\'"])file\1\s*:\s*"([^"]+)"', webpage))[1])
+            } for media_url in set(media_urls)
-    _VALID_URL = r'https?://(?:www.)?gorillavid.in/(?:embed-)?(?P<id>\w+)(?:\-\d+x\d+)?.html'
+    _VALID_URL = r'https?://(?:www.)?gorillavid.in/(?:embed-)?(?P<id>\w+)(?:\-\d+x\d+)?(?:.html)?'
-        'md5': '5a01b05ed3da82a10c6659e954b80108',
+        'url': "http://gorillavid.in/z08zf8le23c6",
-            'title': 'Full House 1x16 - But Seriously, Folks.avi',
+            'id': 'z08zf8le23c6',
-import json
+        title_info = info.get('title')
-            'title': info['title'][0],
+            'title': title,
-    int_or_none,
+    float_or_none,
-            'md5': '383650ece2b25ecec996ad7b5bb2a384',
+            'md5': 'af01795a31f1cf7265c8657534d8077b',
-            duration = float(duration)
+        duration = float_or_none(
-__version__ = '2014.06.04'
+__version__ = '2014.06.07'
-        '_skip': 'Blocked outside the US',
+        'skip': 'Blocked outside the US',
-        }
+        },
-        }
+        },
-        }
+        },
-)
+from .vh1 import VH1IE
-    IE_NAME = u'vh1.com'
+    IE_NAME = 'vh1.com'
-                    }
+    _TESTS = [{
-                u'description': u'The greatest documentary ever made about Heavy Metal begins as our host Sam Dunn travels the globe to seek out the origins and influences that helped create Heavy Metal. Sam speaks to legends like Kirk Hammett, Alice Cooper, Slash, Bill Ward, Geezer Butler, Tom Morello, Ace Frehley, Lemmy Kilmister, Dave Davies, and many many more. This episode is the prologue for the 11 hour series, and Sam goes back to the very beginning to reveal how Heavy Metal was created.'
+        ],
-            }
+    }, {
-            }
+    }, {
-    ]
+    }]
-        # difference from VH1IE._real_extract() is "vid" param instead of "id"
+        if mobj.group('music_id'):
-            self._FEED_URL + '?vid=' + video_id, video_id,
+            doc_url, video_id,
-    IE_NAME = u'cmt.com'
+    IE_NAME = 'cmt.com'
-            },
+    _TESTS = [{
-    ]
+    }]
-                "title": "Lostin Powers - She so Heavy (SneakPreview) Adrian Ackers Blueprint 1"
+                "title": "Lostin Powers - She so Heavy (SneakPreview) Adrian Ackers Blueprint 1",
-            u'title': u'techniques test',
+            'title': 'techniques test',
-        dataUrl = 'http://v.ku6.com/fetchVideo4Player/'+video_id+'.html'
+        dataUrl = 'http://v.ku6.com/fetchVideo4Player/%s.html' % video_id
-
+from .ku6 import Ku6IE
-        thumbs_dict = [{'resolution': res, 'url': t_url} for (res, t_url) in thumbnails]
+        thumbnails = [{
-            'thumbnails': thumbs_dict,
+            'thumbnails': thumbnails,
-                    "url") for the varying thumbnails
+    thumbnails:     A list of dictionaries, with the following entries:
-        apihost           = 'http://spiegeltv-ivms2-restapi.s3.amazonaws.com';
+        apihost = 'http://spiegeltv-ivms2-restapi.s3.amazonaws.com'
-        version_name      = version_json['version_name']
+        slug_json = self._download_json(
-        is_wide           = media_json['is_wide']
+        media_json = self._download_json(
-        server            = server_json[0]['endpoint']
+        server_json = self._download_json(
-          thumbnails.append({'url': image['url'], 'resolution': str(image['width']) + 'x' + str(image['height']) })
+            thumbnails.append({
-        duration = int(round(media_json['duration_in_ms'] / 1000))
+        duration = media_json['duration_in_ms'] / 1000.
-          format = '16x9'
+            format = '16x9'
-          format = '4x3'
+            format = '4x3'
-        return_dict = {
+        return {
-        return return_dict
+        }
-    _VALID_URL = r'https?://(?:www\.)?teachertube\.com/viewVideo\.php\?video_id=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?teachertube\.com/(viewVideo\.php\?video_id=|music\.php\?music_id=)(?P<id>\d+)'
-        }]
+        quality = qualities(['mp3', 'flv', 'mp4'])
-    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/video/video(?P<id>-?\d+)\.html'
+    _VALID_URL = r'https?://(?:www\.)?tagesschau\.de/multimedia/video/video(?P<id>-?[0-9]+)\.html'
-            'title': 'Ukraine-Konflikt: Klitschko in Kiew als B\xfcrgermeister vereidigt',
+            'title': 'Ukraine-Konflikt: Klitschko in Kiew als BÃ¼rgermeister vereidigt',
-    }]      
+    }]
-            'http://www.tagesschau.de/multimedia/video/video%s~player_autoplay-true.html' % video_id, display_id, 'Downloading player page')
+            'http://www.tagesschau.de/multimedia/video/video%s~player_autoplay-true.html' % video_id,
-        medias = re.findall(r'"(http://media.+?)", type:"video/(.+?)", quality:"(.+?)"', playerpage)
+        medias = re.findall(
-                'format_id': res+'_'+ext,
+            f = {
-            })
+            }
-            'thumbnail': 'http://www.tagesschau.de'+thumbnail,
+            'thumbnail': 'http://www.tagesschau.de' + thumbnail,
-        result = ie.extract('http://www.youtube.com/watch?v=lLJf9qJHR3E&list=RDrjFaenf1T-Y')
+        result = ie.extract('https://www.youtube.com/watch?v=W01L70IGBgE&index=2&list=RDOQpdSVF_k_w')
-        self.assertEqual(original_video['id'], 'rjFaenf1T-Y')
+        self.assertEqual(original_video['id'], 'OQpdSVF_k_w')
-        'md5': '1d0c835822f0a71a7bf011855db929d0',
+        'url': 'http://www.xvideos.com/video4588838/biker_takes_his_girl',
-            "age_limit": 18,
+            'id': '4588838',
-            u'upload_date': u'20130903',
+        'url': 'http://tvcast.naver.com/v/81652',
-            raise ExtractorError(u'couldn\'t extract vid and key')
+            raise ExtractorError('couldn\'t extract vid and key')
-            video_id, u'Downloading video info')
+            video_id, 'Downloading video info')
-            video_id, u'Downloading video formats info')
+            video_id, 'Downloading video formats info')
-            formats.append({
+            f = {
-            })
+            }
-        video_re = r'''(?x)data-video-username="(.*?)".*?
+        video_re = r'''(?x)data-video-username=".*?".*?
-        ids = [video_id for (username, video_id) in matches if username]
+        ids = orderedSet(re.findall(video_re, webpage, flags=re.DOTALL))
-            'http://www.tagesschau.de/multimedia/video/video%s~player_autoplay-true.html' % video_id, display_id)
+            'http://www.tagesschau.de/multimedia/video/video%s~player_autoplay-true.html' % video_id, display_id, 'Downloading player page')
-import json
+from .tagesschau import TagesschauIE
-        return self._get_info(long_id, video_id)
+        return self._get_info(long_id, video_id, webpage)
-    def _get_info(self, long_id, video_id):
+    def _get_info(self, long_id, video_id, webpage):
-            'thumbnail': meta.get('thumbnail'),
+            'thumbnail': meta['thumbnail'] if meta.get('thumbnail') else self._og_search_thumbnail(webpage),
-        return self._get_info(long_id, video_id)
+        return self._get_info(long_id, video_id, webpage)
-                'id': '214727115',
+                'id': '2d25e626-2378-391f-ada0-ddaf1417e588',
-                'id': '103000935',
+                'id': 'd1dedf8c-d58c-38c3-8963-e899929ae0a9',
-            long_id = self._search_regex(
+            CONTENT_ID_REGEXES = [
-                webpage, 'content ID')
+                r'root\.App\.Cache\.context\.videoCache\.curVideo = \{"([^"]+)"'
-            'thumbnail': meta['thumbnail'],
+            'thumbnail': meta.get('thumbnail'),
-__version__ = '2014.06.02'
+__version__ = '2014.06.04'
-                r'mediaCollection\.addMediaStream\((?P<media_type>\d+), (?P<quality>\d+), "(?P<rtmp_url>[^"]*)", "(?P<video_url>[^"]*)", "[^"]*"\)', webpage)]
+
-                'quality': int(s['quality']),
+                'quality': s['_quality'],
-                s['quality'])
+
-        'md5': '700d62dc485f3a81cf9d52144e5ead59',
+        },
-                r'(?s)id="watch-uploader-info".*?>.*?(?:Published|Uploaded) on (.*?)</strong>',
+                r'(?s)id="watch-uploader-info".*?>.*?(?:Published|Uploaded|Streamed live) on (.*?)</strong>',
-__version__ = '2014.05.31.4'
+__version__ = '2014.06.02'
-    _VALID_URL = r'http://(?:www\.)?my\.mail\.ru/video/.*#video=/?(?P<id>[^/]+/[^/]+/[^/]+/\d+)'
+    _VALID_URL = r'http://(?:www\.)?my\.mail\.ru/(?:video/.*#video=/?(?P<idv1>(?:[^/]+/){3}\d+)|(?:(?P<idv2prefix>(?:[^/]+/){2})video/(?P<idv2suffix>[^/]+/\d+))\.html)'
-    }
+    _TESTS = [
-        video_id = mobj.group('id')
+        video_id = mobj.group('idv1')
-            'http://videoapi.my.mail.ru/videos/%s.json?new=1' % video_id, video_id, 'Downloading video JSON')
+            'http://api.video.mail.ru/videos/%s.json?new=1' % video_id, video_id, 'Downloading video JSON')
-__version__ = '2014.05.31.3'
+__version__ = '2014.05.31.4'
-__version__ = '2014.05.31.2'
+__version__ = '2014.05.31.3'
-__version__ = '2014.05.31.1'
+__version__ = '2014.05.31.2'
-__version__ = '2014.05.31'
+__version__ = '2014.05.31.1'
-__version__ = '2014.05.30.1'
+__version__ = '2014.05.31'
-            r'<h1 [^>]*?title="([^"]+)"[^>]*>\1<', webpage, 'title')
+            r'<h1 [^>]*?title="([^"]+)"[^>]*>', webpage, 'title')
-        (?:https?://www\.vevo\.com/watch/(?:[^/]+/[^/]+/)?|
+        (?:https?://www\.vevo\.com/watch/(?:[^/]+/(?:[^/]+/)?)?|
-
+            # First, ensure we have a duplicate free list of entries
-    _VALID_URL = r'^http://video\.fc2\.com/(?P<lang>[^/]+)/content/(?P<id>[^/]+)'
+    _VALID_URL = r'^http://video\.fc2\.com/((?P<lang>[^/]+)/)?content/(?P<id>[^/]+)'
-        mimi = hashlib.md5(video_id + '_gGddgPfeaf_gzyr').hexdigest()
+        mimi = hashlib.md5((video_id + '_gGddgPfeaf_gzyr').encode('utf-8')).hexdigest()
-    _VALID_URL = r'http://tv\.nrk\.no/(?:serie/[^/]+|program)/(?P<id>[a-z]{4}\d{8})'
+    _VALID_URL = r'http://tv\.nrk(?:super)?\.no/(?:serie/[^/]+|program)/(?P<id>[a-z]{4}\d{8})'
-            u'duration': 247,
+        'url': 'http://link.theplatform.com/s/dJ5BDC/e9I_cZgTgIPd/meta.smil?format=smil&Tracking=true&mbr=true',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-                if n.attrib.get('title') == u'Geographic Restriction')
+                if n.attrib.get('title') == 'Geographic Restriction')
-            config = json.loads(config_json)
+            config = self._download_json(config_url, video_id, 'Downloading config')
-                    'url': rtmp_video_url,
+                    'url': rtmp_video_url.replace('viacomccstrm', 'viacommtvstrm'),
-				'md5': '700d62dc485f3a81cf9d52144e5ead59',
+        'md5': '700d62dc485f3a81cf9d52144e5ead59',
-        version_json      = json.loads(version_json_code)
+        version_json      = self._download_json('%s/version.json' % apihost, None)
-        slug_json         = json.loads(slug_json_code)
+        slug_json         = self._download_json('%s/%s/restapi/slugs/%s.json' % (apihost, version_name, video_id), None)
-
+        media_json        = self._download_json('%s/%s/restapi/media/%s.json' % (apihost, version_name, oid), None)
-        server_json       = json.loads(server_json_code)
+        server_json       = self._download_json('http://www.spiegel.tv/streaming_servers/', None)
-        # TODO more code goes here, for example ...
+from .spiegeltv import SpiegeltvIE
-        result = ie.extract('http://www.ivi.ru/watch/dezhurnyi_angel')
+        result = ie.extract('http://www.ivi.ru/watch/dvoe_iz_lartsa')
-        self.assertTrue(len(result['entries']) >= 16)
+        self.assertEqual(result['id'], 'dvoe_iz_lartsa')
-        result = ie.extract('http://www.ivi.ru/watch/dezhurnyi_angel/season1')
+        result = ie.extract('http://www.ivi.ru/watch/dvoe_iz_lartsa/season1')
-        self.assertTrue(len(result['entries']) >= 16)
+        self.assertEqual(result['id'], 'dvoe_iz_lartsa/season1')
-            'md5': '3e6cc9a848c1d2ebcc6476444967baa9',
+            'url': 'http://www.ivi.ru/watch/dvoe_iz_lartsa/9549',
-                'id': '74791',
+                'id': '9549',
-                'thumbnail': 'http://thumbs.ivi.ru/f7.vcp.digitalaccess.ru/contents/8/e/bc2f6c2b6e5d291152fdd32c059141.jpg',
+                'title': 'ÐÐ²Ð¾Ðµ Ð¸Ð· Ð»Ð°ÑÑÐ° - Ð¡ÐµÑÐ¸Ñ 1',
-            r'<h1(?:\s+class="boxTopHeadline")?>(.*?)</h1>', webpage, 'title')
+            [r'<h1(?:\s+class="boxTopHeadline")?>(.*?)</h1>',
-__version__ = '2014.05.30'
+__version__ = '2014.05.30.1'
-__version__ = '2014.05.19'
+__version__ = '2014.05.30'
-    _VALID_URL = r'https?://www\.nbcnews\.com/video/.+?/(?P<id>\d+)'
+    _VALID_URL = r'''(?x)https?://www\.nbcnews\.com/
-            'description': 'md5:24e632ffac72b35f8b67a12d1b6ddfc1',
+    _TESTS = [
-    }
+        {
-        info = all_info.find('video')
+        if video_id is not None:
-        }
+            return {
-            "title": "Young Americans for Liberty February 7, 2012 2:28 AM",
+            'id': '20274954',
-        if m.group('type') == 'embed/recorded': # some sites use this embed format (see: http://github.com/rg3/youtube-dl/issues/2990)
+        # some sites use this embed format (see: http://github.com/rg3/youtube-dl/issues/2990)
-            desktop_video_id = self._html_search_regex(r'ContentVideoIds=\["([^"]*?)"\]', webpage, 'desktop_video_id')
+            desktop_video_id = self._html_search_regex(
-    _VALID_URL = r'https?://www\.ustream\.tv/(?P<type>recorded|embed)/(?P<videoID>\d+)'
+    _VALID_URL = r'https?://www\.ustream\.tv/(?P<type>recorded|embed|embed/recorded)/(?P<videoID>\d+)'
-
+
-            'file': '19911.mp4',
+                'id': '19911',
-            'file': '521be8ef82b16.mp4',
+                'id': '521be8ef82b16',
-        video_thumbnail = self._search_regex(r'image: \'(?P<thumbnail>[^\']+)\'', playerdata, 'thumbnail', fatal=False)
+        playerdata = self._download_webpage(playerdata_url, video_id, 'Downloading player webpage')
-        videolist = self._download_webpage(videolist_url, video_id)
+
-        for match in re.finditer('<video src="mp4:(?P<file>[^"]+_(?P<format_id>[^"]+)\.[^"]+)" system-bitrate="(?P<br>\d+)"(?: width="(?P<width>\d+)" height="(?P<height>\d+)")?/>', videolist):
+        for video in videolist.findall('.//video'):
-                'format_id': match.group('format_id')
+                'url': baseurl + file_,
-            if match.group('width'):
+            if width or height:
-                    'height': int(match.group('height'))
+                    'tbr': bitrate // 1000 if bitrate else None,
-                    'vcodec': 'none'
+                    'abr': bitrate // 1000 if bitrate else None,
-            r'href="(/mp4/[^"]+)"[^>]*data-link_type="mp4"',
+            r'href="(/[^"]+)"[^>]*data-link_type="mp4"',
-        self.assertTrue(len(result['entries']) >= 23)
+        self.assertTrue(len(result['entries']) >= 16)
-        result = ie.extract('http://www.ivi.ru/watch/dezhurnyi_angel/season2')
+        result = ie.extract('http://www.ivi.ru/watch/dezhurnyi_angel/season1')
-        self.assertTrue(len(result['entries']) >= 7)
+        self.assertEqual(result['id'], 'dezhurnyi_angel/season1')
-from .nrk import NRKIE
+from .nrk import (
-from ..utils import ExtractorError
+from ..utils import (
-        'url': 'https://www.stream.cz/blanik/10002447-tri-roky-pro-mazanka',
+        'url': 'http://www.stream.cz/blanik/10002447-tri-roky-pro-mazanka',
-from ..utils import int_or_none
+from ..utils import (
-            'id': str(jsonData['episode_id']),
+            'id': compat_str(jsonData['episode_id']),
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-            'id': str(jsonData['id']),
+            'id': str(jsonData['episode_id']),
-        'md5': '5e5cc160f38ca9857f318eb97146e13e',
+        'md5': 'b1bc15b6412d33902d6e5952035fcabc',
-            'ext': 'flv',
+            'ext': 'mp4',
-        video_url = cfg_xml.find('videoLink').text
+
-            'ext': 'flv',
+            'description': video_description,
-            r'(?s)<div class="video-info-row">\s*From:&nbsp;.+?<(?:a href="/users/|<span class="username)[^>]+>(.+?)<',
+            r'(?s)From:&nbsp;.+?<(?:a href="/users/|<span class="username)[^>]+>(.+?)<',
-from ..utils import int_or_none
+from ..utils import parse_duration
-    _VALID_URL = r'https?://(?:www\.)?swrmediathek\.de/player\.htm\?show=(?P<videoid>[^?#&]+)'
+    _VALID_URL = r'https?://(?:www\.)?swrmediathek\.de/player\.htm\?show=(?P<id>[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12})'
-            'ext': 'flv',
+            'ext': 'mp4',
-            'skip_download': True,  # requires rtmpdump
+            'duration': 2602,
-            'ext': 'flv',
+            'ext': 'mp4',
-        },
+    }, {
-        webpage = self._download_webpage(url, video_id)
+        video_id = mobj.group('id')
-        smildoc = self._download_xml(smilurl % video_id, video_id, 'Downloading SMIL page')
+        video = self._download_json(
-        baseurl = smildoc.find('.//meta').attrib['base']
+        attr = video['attr']
-                vbr = int(vbr) / 1000
+        for entry in video['sub']:
-            })
+            fmt = {
-            'thumbnail': self._search_regex(r'<link rel="image_src".+href="(.+)" />', webpage, 'thumbnail'),
+            'title': attr['entry_title'],
-        }
+        }
-        smildoc = self._download_xml(smilurl % video_id, video_id, note='Downloading SMIL page')
+        smildoc = self._download_xml(smilurl % video_id, video_id, 'Downloading SMIL page')
-            'title': self._html_search_regex(r'<meta name="title" content="(.+)" />', webpage, 'title'),
+            'title': self._html_search_meta('title', webpage, 'title', fatal=True),
-            'description': self._html_search_regex(r'<meta name="description" content="(.+)" />', webpage, 'description'),
+            'description': self._html_search_meta('description', webpage, 'description'),
-            'md5': '782f8504ca95a0eba8fc9177c373eec7',
+            'md5': 'fde81fbafaee331785f58cd6c0d46190',
-            'md5': 'dec39ee5118f8d9cc067f45f9cbe3a35',
+            'md5': 'd72f10cd39eac4215048f62ab477a511',
-            })
+        video_thumbnail = self._search_regex(r'image: \'(?P<thumbnail>[^\']+)\'', playerdata, 'thumbnail', fatal=False)
-    """ Returns true iff the file has been downloaded """
+    """ Returns true if the file has been downloaded """
-            'description': 'md5:632e61a9f97d700e83f43d77ddafb6a4',
+            'description': 'md5:36fd701e57e8c15ac8682a2374c99731',
-        # No prefer_free_formats => prefer mp4 and flv for greater compatibilty
+        # No prefer_free_formats => prefer mp4 and flv for greater compatibility
-        }), '^x\s*10k$')
+        }), '^\s*10k$')
-from urlparse import urlparse, urlunparse, urldefrag
+
-        return re.split('^\s*try\s*{', js, flags=re.M)[0] \
+        return re.split('(?m)^\s*try\s*{', js)[0] \
-            'request': req
+            'headers': headers
-                    ext, abr_str = format_id.split('-', maxsplit=1)
+                    ext, abr_str = format_id.split('-', 1)
-            self._current_object = { 'attrs': attrs, 'params': [] }
+            self._current_object = {'attrs': attrs, 'params': []}
-    
+
-        
+
-    
+
-        
+
-        
+
-        
+
-    
+
-    
+
-        
+
-        
+
-            }
+        }
-            headers['Referer'] = swf_referer        
+            headers['Referer'] = swf_referer
-            
+
-        
+        }
-        
+            info_dict['http_referer'] = swf_referer
-
+    'Keith Beckman'
-# Credits go to XBox-Maniac http://board.jdownloader.org/showpost.php?p=185835&postcount=31 
+# Credits go to XBox-Maniac
-        age_limit = int(self._search_regex(r'age=(\d+)', self._html_search_meta('age-de-meta-label', webpage), 'age_limit', '0'))
+        age_limit = int(
-        content = self._download_xml(content_url, video_id, 'Downloading media:content')
+        content = self._download_xml(
-                }
+            {
-                            'Falling back to youtube search for  %s . Set --default-search to "auto" to suppress this warning.' % url)
+                        if re.match(r'^(?:url|URL)$', url):
-        }
+        'playlist': [
-        mp3_url = re.search(r'''{src:'(?P<audio>[^']+)', type:"audio/mp3"},''', page)
+        mp3_url = re.search(r'''\{src:'(?P<audio>[^']+)', type:"audio/mp3"},''', page)
-        video_url = re.search(r'''3: {src:'(?P<video>.+?)\.hi\.mp4', type:"video/mp4"},''', page)
+        video_url = re.search(r'''3: \{src:'(?P<video>.+?)\.hi\.mp4', type:"video/mp4"},''', page)
-            thumbnails = re.findall(r'''\d+: {src: "([^"]+)"(?: \|\| '[^']+')?, quality: '([^']+)'}''', page)
+            thumbnails = re.findall(r'''\d+: \{src: "([^"]+)"(?: \|\| '[^']+')?, quality: '([^']+)'}''', page)
-                thumbnail = 'http://www.ndr.de' + thumbnails[-1][0]
+                quality_key = qualities(['xs', 's', 'm', 'l', 'xl'])
-            for format_id in ['lo', 'hi', 'hq']:
+            for format_id in 'lo', 'hi', 'hq':
-)
+from ..utils import ExtractorError
-        'md5': '0ece2f70a7bd252c7b00f3070182d418',
+        'md5': '068bc0202558c2e391924cb8cc470676',
-__version__ = '2014.05.17'
+__version__ = '2014.05.19'
-            (?:<iframe[^>]+?src=|embedSWF\(\s*)
+            (?:<iframe[^>]+?src=|data-video-url=|embedSWF\(\s*)
-                thumbnails.sort(key=lambda thumb: QUALITIES.index(thumb[1]))
+                thumbnails.sort(key=lambda thumb: QUALITIES.index(thumb[1]) if thumb[1] in QUALITIES else -1)
-from ..utils import xpath_with_ns
+from ..utils import (
-            'age_limit': 16
+            'age_limit': 16,
-def parse_iso8601(date_str):
+def parse_iso8601(date_str, delimiter='T'):
-    dt = datetime.datetime.strptime(date_str, '%Y-%m-%dT%H:%M:%S') - timezone
+    date_format =  '%Y-%m-%d{0}%H:%M:%S'.format(delimiter)
-                'mit fiesen Fragen. Hier gibtâs die erste HÃ¤lfte, in Folge 289 gehtâs weiter.'
+            'description': 'FIFA-Pressepokal 2014, Star Citizen, Kingdom Come: Deliverance, Project Cars, SchÃ¶ner Trants Nerdquiz Folge 2 Runde 1',
-        return u''.join(t for t in description.itertext())
+import xml.etree.ElementTree as ET
-    _TESTS = {
+    _TEST = {
-            r'''(?x)<iframe[^>]+?src=(["\'])
+            r'''(?x)<(?:pagespeed_)?iframe[^>]+?src=(["\'])
-from ..utils import ExtractorError
+from ..utils import (
-        title = self._og_search_title(page)
+        title = self._og_search_title(page).strip()
-        duration = int(mobj.group('minutes')) * 60 + int(mobj.group('seconds')) if mobj else None
+        duration = int_or_none(self._html_search_regex(r'duration: (\d+),\n', page, 'duration', fatal=False))
-                thumbnail = 'http://www.ndr.de' + thumbnail
+            thumbnails = re.findall(r'''\d+: {src: "([^"]+)"(?: \|\| '[^']+')?, quality: '([^']+)'}''', page)
-import datetime
+            'timestamp': 1394142732,
-        META_URL = 'http://aftonbladet-play.drlib.aptoma.no/video/%s.json'
+        meta_url = 'http://aftonbladet-play.drlib.aptoma.no/video/%s.json'
-        internal_meta_url = META_URL % internal_meta_id
+        internal_meta_url = meta_url % internal_meta_id
-        FORMATS_URL = 'http://aftonbladet-play.videodata.drvideo.aptoma.no/actions/video/?id=%s'
+        format_url = 'http://aftonbladet-play.videodata.drvideo.aptoma.no/actions/video/?id=%s'
-        internal_formats_url = FORMATS_URL % internal_video_id
+        internal_formats_url = format_url % internal_video_id
-            'upload_date': upload_date,
+            'timestamp': internal_meta_json['timePublished'],
-                "url": "http://cdn.blinkx.com/stream/b/41/StupidVideos/20131215/1873969261/1873969261_tn_0.jpg",
+            'title': 'Police Car Rolls Away',
-                              m['w']))
+                format_id = u'%s-%sk-%s' % (vcodec, tbr, m['w'])
-            'upload_date': pload_date,
+            'timestamp': data['pubdate_epoch'],
-import datetime
+            'timestamp': 1393232740,
-            'upload_date': upload_date,
+            'timestamp': video_data['timestamp'],
-            "duration": 10,
+            "duration": 9.8485,
-        if m_download is None:
+        if not m_download:
-                d = data[0]
+                data = json.loads(json_code)[0]
-
+                for format_id, format_url in data['file'].items():
-                        'ext': format_id.partition('-')[0],
+                        'ext': ext,
-                        'abr': int(format_id.partition('-')[2]),
+                        'acodec': ext,
-                    'title': d['title'],
+                    'id': compat_str(data['id']),
-                    'duration': duration,
+                    'duration': float(data['duration']),
-                         download_webpage, re.MULTILINE).group(1)
+        download_webpage = self._download_webpage(download_link, video_id, 'Downloading free downloads page')
-    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<title>[^?#]+))?'
+    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<title>[^?#]+))'
-        'skip': 'Bancamp imposes download limits. See test_playlists:test_bandcamp_album for the playlist test'
+        'skip': 'Bandcamp imposes download limits. See test_playlists:test_bandcamp_album for the playlist test'
-        formats.sort(key=lambda x: int(x['format_id']))
+        self._sort_formats(formats)
-__version__ = '2014.05.16.1'
+__version__ = '2014.05.17'
-                r'(?s)id="watch-uploader-info".*?>.*?Published on (.*?)</strong>',
+                r'(?s)id="watch-uploader-info".*?>.*?(?:Published|Uploaded) on (.*?)</strong>',
-import datetime
+from utils import compat_urllib_parse
-            'url': info['downloadUrl'],
+            'url': url,
-            'upload_date': datetime.date.fromtimestamp(info['creationDate']).strftime('%Y%m%d'),
+            'timestamp': info['creationDate'],
-            if info['paging'] is None:
+            mobj = re.search(
-            paging = info['paging']
+            paging = mobj.group('paging')
-__version__ = '2014.05.16'
+__version__ = '2014.05.16.1'
-    _VALID_URL = r'https?://www\.francetvinfo\.fr/replay.*/(?P<title>.+)\.html'
+    _VALID_URL = r'https?://www\.francetvinfo\.fr/.*/(?P<title>.+)\.html'
-    _TEST = {
+    _TESTS = [{
-        'file': '84981923.mp4',
+            'id': '84981923',
-    }
+    }, {
-        video_id = self._search_regex(r'id-video=(\d+?)[@"]', webpage, 'video id')
+        video_id = self._search_regex(r'id-video=((?:[^0-9]*?_)?[0-9]+)[@"]', webpage, 'video id')
-               + opts +
+               + [encodeArgument(o) for o in opts] +
-            found = re.findall(
+            found = re.search(
-__version__ = '2014.05.13'
+__version__ = '2014.05.16'
-                        subprocess.check_output(cmd)
+                        subprocess_check_output(cmd)
-
+    parse_iso8601,
-            'title': 'Red vs. Blue Season 11 Episode 1',
+    _VALID_URL = r'https?://(?:\w+\.)?blip\.tv/(?:(?:.+-|rss/flash/)(?P<id>\d+)|((?:play/|api\.swf#)(?P<lookup_id>[\da-zA-Z]+)))'
-    }]
+    ]
-        presumptive_id = mobj.group('presumptive_id')
+        lookup_id = mobj.group('lookup_id')
-            data = json_data['Post']
+        if lookup_id:
-            data = json_data
+            video_id = mobj.group('id')
-                    continue
+        subtitles = {}
-                    'height': int(f['media_height']),
+                    'url': real_url,
-            'user_agent': 'iTunes/10.6.1',
+            'title': title,
-                r'(?s)<a[^<]+>(.*?)</a>', m_cat_container, 'cateory',
+                r'(?s)<a[^<]+>(.*?)</a>', m_cat_container, 'category',
-                u"description": u"test chars:  \"'/\\Ã¤â­ð\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de ."
+                u"description": u"test chars:  \"'/\\Ã¤â­ð\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de .",
-        mobj = re.search(r'id="eow-date.*?>(.*?)</span>', video_webpage, re.DOTALL)
+        mobj = re.search(r'(?s)id="eow-date.*?>(.*?)</span>', video_webpage)
-                                m_cat_container, re.DOTALL)
+            category = self._html_search_regex(
-            basen = video_id + '_' + url
+            basen = '%s_%s' % (video_id, url)
-            "title": "Arma 3 - Community Guide: SITREP I",
+        'url': 'http://www.gamespot.com/videos/arma-3-community-guide-sitrep-i/2300-6410818/',
-        }
+        },
-options = re.sub(r'^  (\w.+)$', r'## \1', options, flags=re.M)
+options = re.sub(r'(?m)^  (\w.+)$', r'## \1', options)
-__version__ = '2014.05.12'
+__version__ = '2014.05.13'
-    _VALID_URL = r'^https?://www\.empflix\.com/videos/(?P<videoid>[^\.]+)\.html'
+    _VALID_URL = r'^https?://www\.empflix\.com/videos/.*?-(?P<id>[0-9]+)\.html'
-            u"age_limit": 18,
+        'url': 'http://www.empflix.com/videos/Amateur-Finger-Fuck-33051.html',
-            webpage, u'title').strip()
+        video_title = self._html_search_regex(
-            webpage, u'flashvars.config').strip()
+        cfg_url = self._html_search_regex(
-        cfg_xml = self._download_xml(cfg_url, video_id, note=u'Downloading metadata')
+        cfg_xml = self._download_xml(
-        return [info]
+        return {
-    _VALID_URL = r'^https?://hentai\.animestigma\.com/(?P<videoid>[^/]+)'
+    _VALID_URL = r'^https?://hentai\.animestigma\.com/(?P<id>[^/]+)'
-            u"age_limit": 18,
+        'url': 'http://hentai.animestigma.com/inyouchuu-etsu-bonus/',
-        # Get wrapper content
+        title = self._html_search_regex(
-                'age_limit': 18}
+        video_url = self._html_search_regex(
-        return [info]
+        return {
-    _VALID_URL = r'^https?://(?:www|m)\.nuvid\.com/video/(?P<videoid>\d+)'
+    _VALID_URL = r'^https?://(?:www|m)\.nuvid\.com/video/(?P<id>[0-9]+)'
-            u"age_limit": 18,
+        'url': 'http://m.nuvid.com/video/1310741/',
-        murl = url.replace('//www.', '//m.')
+        murl = url.replace('://www.', '://m.')
-        return [info]
+        title = self._html_search_regex(
-    _VALID_URL = r'^https?://(?:\w+\.)?slutload\.com/video/[^/]+/(?P<videoid>[^/]+)/?$'
+    _VALID_URL = r'^https?://(?:\w+\.)?slutload\.com/video/[^/]+/(?P<id>[^/]+)/?$'
-            u"age_limit": 18,
+        'url': 'http://www.slutload.com/video/virginie-baisee-en-cam/TD73btpBqSxc/',
-        return [info]
+            webpage, 'title').strip()
-        return "%sapi/timelines/users/%s?page=%s"%(self._VINE_BASE_URL, user_id, page)
+    def _real_extract(self, url):
-        return self._download_json(self._profile_url(user), user)
+        profile_url = "%sapi/users/profiles/vanity/%s" % (
-            timeline_page = self._download_json(self._timeline_url(user_id, pagenum), user)
+            timeline_url = "%sapi/timelines/users/%s?page=%s" % (
-        entries = [self.url_result(e['permalinkUrl'], 'Vine') for e in timeline_data]
+        entries = [
-        return self._extract_videos(user)
+    def _proto_relative_url(self, url, scheme=None):
-    unified_strdate,
+    int_or_none,
-            raise ExtractorError(u'Unable to extract track url')
+            raise ExtractorError('Unable to extract track url')
-            'title': info['name'],
+            'title': title,
-            'view_count': info['play_count'],
+            'description': description,
-                u'Expected type %r, but got value %r of type %r' % (expected, got, type(got)))
+                u'Expected type %r for field %s, but got value %r of type %r' % (expected, info_field, got, type(got)))
-            raw_filename = ('%s_%s.dump' % (video_id, url))
+            basen = video_id + '_' + url
-__version__ = '2014.05.05'
+__version__ = '2014.05.12'
-        if re.search(r'<div class="yt-alert-message">[^<]*?The playlist does not exist[^<]*?</div>', page) is not None:
+        if re.search(r'<div class="yt-alert-message">[^<]*?(The|This) playlist (does not exist|is private)[^<]*?</div>', page) is not None:
-                'uploader': 'Elvira Dzhonik',
+                'uploader': 'Elya Iskhakova',
-            self.to_screen(u'Youtube video detected')
+            self.to_screen('Youtube video detected')
-from .vine import VineIE
+from .vine import (
-        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg']:
+        if opts.recodevideo not in ['mp4', 'flv', 'webm', 'ogg', 'mkv']:
-        video_info = self._download_json(json_url, video_id)['video']
+        response = self._download_json(json_url, video_id)
-    _VALID_URL = r'https?://player\.(?:rutv\.ru|vgtrk\.com)/(?:flash2v/container\.swf\?id=|iframe/(?P<type>swf|video|live)/id/)(?P<id>\d+)'
+    _VALID_URL = r'''(?x)
-            r'<iframe[^>]+?src=(["\'])(?P<url>https?://player\.rutv\.ru/iframe/(?:swf|video|live)/id/.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>https?://player\.rutv\.ru/(?:iframe/(?:swf|video|live)/id|index/iframe/cast_id)/.+?)\1', webpage)
-        video_type = mobj.group('type')
+        video_path = mobj.group('path')
-        if not video_type or video_type == 'swf':
+        if video_path.startswith('flash2v'):
-            video_id, 'Downloading video JSON')
+        video = self._download_json(
-                   } for fmt in video['mtm'] if fmt['transcoding_status'] == 'processed']
+        formats = [
-        dislike_count= video['total_hates']
+        view_count = video.get('raw_view_count')
-            video_id, 'Downloading video comment JSON')
+        comment = self._download_json(
-        comment_count = comment['total']
+        comment_count = int_or_none(comment.get('total'))
-    _VALID_URL = r'http://vube\.com/[^/]+/(?P<id>[\da-zA-Z]{10})'
+    _VALID_URL = r'http://vube\.com/(?:[^/]+/)+(?P<id>[\da-zA-Z]{10})\b'
-            'duration': 170.56
+    _TESTS = [
-    }
+    ]
-        upload_date = datetime.datetime.fromtimestamp(int(video['upload_time'])).strftime('%Y%m%d')
+        timestamp = int(video['upload_time'])
-            'upload_date': upload_date,
+            'timestamp': timestamp,
-                } for x in media.findall('assets/asset')]
+                for asset in media.findall('assets/asset'):
-                    int(f.get('bitrate',-1)),
+                    int(f.get('height', -1)),
-                    re.match(r'VO-ST(F|A)', f.get('versionCode', '')) is None,
+                    re.match(r'VO-ST(F|A)', versionCode) is None,
-                    re.match(r'VO?(F|A)-STM\1', f.get('versionCode', '')) is None,
+                    re.match(r'VO?(F|A)-STM\1', versionCode) is None,
-        'md5': 'f647e9e90064b53b6e046e75d0241fbd',
+        'md5': 'bcd81e0c4f26189ee09be362ad6e6ba9',
-        'md5': '0e0c5a7bf45c52b95cd16aa7f28be0b6',
+        'md5': 'ff4d83318f89776ed0250634cfaa8d36',
-            webpage, 'video URL', flags=re.DOTALL)
+        links = re.findall(r'<source src="([^"]+/v)\d+\.([^"]+)" type=\'video', webpage)
-            'ext': 'mp4',
+            'formats': formats,
-            'thumbnail': thumbnail,
+            'title': post['name'],
-    _TEST = {
+    _TESTS = [{
-                'and written by David A. Scott.'),
+            'id': '0732f586d7',
-    }
+    }, {
-            thumbnail = None
+        post_json = self._search_regex(
-        clip_id = extract(self._CLIPID_REGEXES, 'clip id', page, fatal=True)
+        clip_id = self._html_search_regex(self._CLIPID_REGEXES, page, 'clip id')
-        description = extract(self._DESCRIPTION_REGEXES, 'description', page)
+        title = self._html_search_regex(self._TITLE_REGEXES, page, 'title')
-            upload_date = unified_strdate(upload_date)
+        upload_date = unified_strdate(self._html_search_regex(
-from ..utils import unified_strdate
+from ..utils import (
-    _VALID_URL = r'https?://(www\.canalplus\.fr/.*?/(?P<path>.*)|player\.canalplus\.fr/#/(?P<id>\d+))'
+    _VALID_URL = r'https?://(?:www\.canalplus\.fr/.*?/(?P<path>.*)|player\.canalplus\.fr/#/(?P<id>[0-9]+))'
-        video_id = mobj.group('id')
+        video_id = mobj.groupdict().get('id')
-            webpage = self._download_webpage(url, mobj.group('path'))
+            webpage = self._download_webpage(url, display_id)
-__version__ = '2014.04.30.1'
+__version__ = '2014.05.05'
-from .soundcloud import SoundcloudIE, SoundcloudSetIE, SoundcloudUserIE
+from .soundcloud import (
-                    else 'https:') + url,
+                'url': self.http_scheme() + url,
-    _VALID_URL = r'''^(?:https?://)?
+    _VALID_URL = r'''(?x)^(?:https?://)?
-        stream_json = self._download_webpage(
+        format_dict = self._download_json(
-            return self.url_result(query['url'][0], ie='Soundcloud')
+            return self.url_result(query['url'][0])
-        info_json = self._download_webpage(info_json_url, full_title, 'Downloading info JSON')
+        info = self._download_json(info_json_url, full_title, 'Downloading info JSON')
-        info = json.loads(info_json)
+
-        slug_title =  mobj.group(2)
+        slug_title = mobj.group(2)
-        info_json = self._download_webpage(resolv_url, full_title)
+        info = self._download_json(resolv_url, full_title)
-        user = json.loads(user_json)
+        user = self._download_json(
-        tracks = []
+        entries = []
-            if len(new_tracks) < 50:
+            data = compat_urllib_parse.urlencode({
-            'entries': tracks,
+            'entries': entries,
-    _VALID_URL = r'http://.*?\.bandcamp\.com/track/(?P<title>.*)'
+    _VALID_URL = r'https?://.*?\.bandcamp\.com/track/(?P<title>.*)'
-    _VALID_URL = r'http://.*?\.bandcamp\.com/album/(?P<title>.*)'
+    _VALID_URL = r'https?://(?:(?P<subdomain>[^.]+)\.)?bandcamp\.com(?:/album/(?P<title>[^?#]+))?'
-        webpage = self._download_webpage(url, title)
+        display_id = title or playlist_id
-                raise ExtractorError(u'No login info available, needed for using %s.' % self.IE_NAME, expected=True)
+                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)
-            'file': '68093876.mp4',
+                'id': '68093876',
-            'file': '54469442.mp4',
+                'id': '54469442',
-            'file': '68375962.mp4',
+                'id': '68375962',
-                                              'token': token})
+        data = compat_urllib_parse.urlencode({
-            pass_url = url.replace('https','http')
+            pass_url = url.replace('https', 'http')
-        password_request = compat_urllib_request.Request(pass_url+'/password', data)
+        password_request = compat_urllib_request.Request(pass_url + '/password', data)
-                        %(video_id, sig, timestamp, quality, codec_name.upper())
+                        % (video_id, sig, timestamp, quality, codec_name.upper())
-                self._page_url(base_url, pagenum) ,list_id,
+                self._page_url(base_url, pagenum), list_id,
-        channel_id =  mobj.group('id')
+        channel_id = mobj.group('id')
-            if video_description: video_description = clean_html(video_description)
+            video_description = get_element_by_attribute("class", "description_wrapper", webpage)
-    _VALID_URL = r'https?://(www\.)?statigr\.am/p/(?P<id>[^/]+)'
+class IconosquareIE(InfoExtractor):
-        title = re.sub(r'(?: *\(Videos?\))? \| Statigram$', '', html_title)
+        title = re.sub(r'(?: *\(Videos?\))? \| (?:Iconosquare|Statigram)$', '', html_title)
-                'filesize': video['fileSize'],
+                'filesize': get_file_size(video['fileSize']),
-            return str.replace('/', '/%(ns)s') % {'ns': '{http://app1.newstube.ru/N2SiteWS/player.asmx}'}
+        def ns(s):
-                },
+                # rtmp download
-                },
+                # rtmp download
-                },
+                # rtmp download
-                },
+                # rtmp download
-                },
+                # rtmp download
-        r'<video restriction[^>]+><key>(\d+)</key>'
+        r'<video restriction[^>]+><key>(\d+)</key>',
-            raise ExtractorError('No media links available for %s' % video_id)
+        page = self._download_webpage(url, video_id)
-        video_id = mobj.group(1)
+        video_id = self._html_search_regex(self._VIDEO_ID_REGEXES, page, 'video id')
-        app = apps[puid22] if puid22 in apps else apps['4']
+        app = apps.get(puid22, apps['4'])
-        if conn:
+        if isinstance(conn, list):
-            return entries[1]
+            return entries[0]
-        if is_test and data_len > self._TEST_FILE_SIZE:
+        if is_test and (data_len is None or int(data_len) > self._TEST_FILE_SIZE):
-        print(json.dumps(data, indent=2))
+
-        'md5': '60c29434a416a83c15dae2587d47027d',
+        'md5': '3db39fb48b9685438ecf33a1078023e4',
-            'md5': '12618eef328c9a35c1b47d5583d9c30d',
+            'md5': 'a6eac35052f3b242bb6bb7f43aed5886',
-            'md5': '390b2ce15c0d6aa376ef5059ac9f865e',
+            'md5': '3471f2a51718195164e88f46bf427668',
-        #'md5': 'b16699b74c9e6a120f6772a44960304f',
+        'md5': 'b16699b74c9e6a120f6772a44960304f',
-__version__ = '2014.04.30'
+__version__ = '2014.04.30.1'
-    fileno = out.fileno()
+    try:
-            tmpl = os.path.expanduser(self.params['outtmpl'])
+            outtmpl = self.params.get('outtmpl', DEFAULT_OUTTMPL)
-                '%' not in self.params['outtmpl']
+                '%' not in outtmpl
-            raise SameFileError(self.params['outtmpl'])
+            raise SameFileError(outtmpl)
-            or u'%(title)s-%(id)s.%(ext)s')
+            or DEFAULT_OUTTMPL)
-
+        print(json.dumps(data, indent=2))
-        }
+        }
-        if mobj is None:
+        found = re.findall(r'flashvars: [\'"](?:.*&)?file=(http[^\'"&]*)', webpage)
-            mobj = re.search(r'''(?sx)
+            found = re.findall(r'''(?sx)
-        if mobj is None:
+        if not found:
-        if mobj is None:
+            found = re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\'"&]*)', webpage)
-        if mobj is None:
+            found = re.findall(r'<meta (?:property|name)="twitter:player:stream" (?:content|value)="(.+?)"', webpage)
-            m_video_type = re.search(r'<meta.*?property="og:video:type".*?content="video/(.*?)"', webpage)
+            m_video_type = re.findall(r'<meta.*?property="og:video:type".*?content="video/(.*?)"', webpage)
-        if mobj is None:
+                found = re.findall(r'<meta.*?property="og:video".*?content="(.*?)"', webpage)
-            mobj = re.search(
+            found = re.findall(r'(?s)<video[^<]*(?:>.*?<source.*?)? src="([^"]+)"', webpage)
-                new_url = mobj.group(1)
+            if found:
-        if mobj is None:
+        if not found:
-            raise ExtractorError('Did not find a valid video URL at %s' % url)
+        entries = []
-        video_id = compat_urllib_parse.unquote(os.path.basename(video_url))
+            # Sometimes, jwplayer extraction will result in a YouTube URL
-            return self.url_result(video_url, 'Youtube')
+            # here's a fun little line of code for you:
-        video_id = os.path.splitext(video_id)[0]
+            entries.append({
-__version__ = '2014.04.21.6'
+__version__ = '2014.04.30'
-from test.helper import FakeYDL
+from test.helper import FakeYDL, assertRegexpMatches
-                res += 'video@'
+    def _format_note(self, fdict):
-            return res
+                res += '@'
-                format_note(format),
+                self._format_note(format),
-            formats_s[-1] += (' ' if format_note(formats[-1]) else '') + '(best)'
+            formats_s[0] += (' ' if self._format_note(formats[0]) else '') + '(worst)'
-        '248': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH webm', 'preference': -40},
+        '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'acodec': 'none', 'container': 'webm', 'vcodec': 'VP8', 'preference': -40},
-        '172': {'ext': 'webm', 'vcodec': 'none', 'format_note': 'DASH webm audio', 'abr': 256, 'preference': -50},
+        '171': {'ext': 'webm', 'vcodec': 'none', 'format_note': 'DASH audio', 'abr': 48, 'preference': -50},
-            urlrs = [self.url_result(unescapeHTML(tuppl[1]), 'Dailymotion')
+            urlrs = [self.url_result(unescapeHTML(tuppl[1]))
-    _VALID_URL = r'https?://www\.syfy\.com/videos/.+?vid:(?P<id>\d+)'
+    _VALID_URL = r'https?://www\.syfy\.com/(?:videos/.+?vid:(?P<id>[0-9]+)|(?!videos)(?P<video_name>[^/]+)(?:$|[?#]))'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        video_id = mobj.group('id')
+        video_name = mobj.group('video_name')
-        f4m_node = body.find(_x('smil:seq/smil:video'))
+        f4m_node = body.find(_x('smil:seq//smil:video'))
-        info = self._download_json(
+        response = self._download_json(
-            video_id)['binding'][0]
+            video_id)
-from .rtbf import RTBFVideoIE
+from .rtbf import RTBFIE
-    _VALID_URL = r'https?://www.rtbf.be/video/(?P<title>[^?]+)\?.*id=(?P<id>[0-9]+)'
+
-            webpage, 'title', mobj.group('title'))
+        page = self._download_webpage('https://www.rtbf.be/video/embed?id=%s' % video_id, video_id)
-        iframe = self._download_webpage(iframe_url, video_id)
+        video_url = data.get('downloadUrl') or data.get('url')
-        video_data = json.loads(clean_html(iframe[json_data_start:json_data_end]))
+        if data['provider'].lower() == 'youtube':
-            'duration': video_data['data']['duration'],
+            'url': video_url,
-        print title
+from .rtbf import RTBFVideoIE
-        'md5': 'b16699b74c9e6a120f6772a44960304f',
+        #'md5': 'b16699b74c9e6a120f6772a44960304f',
-        }
+        },
-            request.add_header('Range', 'bytes=0-10240')
+        is_test = self.params.get('test', False)
-            data_block = data.read(block_size)
+            data_block = data.read(block_size if not is_test else min(block_size, data_len - byte_counter))
-            video_title = compat_urllib_parse.unquote_plus(video_info['title'][0])
+            video_title = video_info['title'][0]
-                u'description': u'md5:3199ed45ee8836572865580804d7ac0f',
+                u'description': u'md5:9717375db5a9a3992be4668bbf3bc0a8',
-                u"description": u"md5:5b292926389560516e384ac437c0ec07",
+                u"description": u"md5:fea86fda2d5a5784273df5c7cc994d9f",
-class VimeoIE(SubtitlesInfoExtractor):
+class VimeoBaseInfoExtractor(InfoExtractor):
-
+
-            r'var postView = new app\.PostView\({ post: ({.+?}),', webpage, 'post view'))
+            r'var postView = new app\.PostView\({\s*post:\s*({.+?}),', webpage, 'post view'))
-                                              })
+        data = urlencode_postdata({
-
+    unescapeHTML,
-            video_ids.extend(re.findall(r'data-id="(.+?)"', webpage))
+            video_ids.extend(re.findall(r'data-xid="(.+?)"', webpage))
-            webpage, u'user', flags=re.DOTALL)
+        full_user = unescapeHTML(self._html_search_regex(
-            'ext': 'flv',
+            'ext': 'mp4',
-            'skip_download': True,
+            'description': 'md5:5174aed4d0f16021b704120360f72b92',
-                raise ExtractorError(u'YouTube said: %s' % video_info['reason'][0], expected=True)
+                raise ExtractorError(
-                raise ExtractorError(u'"token" parameter not in video info for unknown reason')
+                raise ExtractorError(
-    def __init__(self, msg, tb=None, expected=False, cause=None):
+    def __init__(self, msg, tb=None, expected=False, cause=None, video_id=None):
-__version__ = '2014.04.21.5'
+__version__ = '2014.04.21.6'
-            mobj = re.search(r'(?s)(?:jw_plugins|JWPlayerOptions).*?file\s*:\s*["\'](.*?)["\']', webpage)
+            mobj = re.search(r'''(?sx)
-    _VALID_URL = r'http://(?:m)?\.vuclip\.com/w\?.*?cid=(?P<id>[0-9]+)'
+    _VALID_URL = r'http://(?:m\.)?vuclip\.com/w\?.*?cid=(?P<id>[0-9]+)'
-__version__ = '2014.04.21.4'
+__version__ = '2014.04.21.5'
-                'nh': self._search_regex(r'name="nh" value="(\w*?)"', login_results, 'nh'),
+                'h': self._search_regex(r'name="h" value="(\w*?)"', login_results, 'h'),
-__version__ = '2014.04.21.3'
+__version__ = '2014.04.21.4'
-            'http://rutube.ru/api/play/options/%s/?format=json' %video_id,
+            'http://rutube.ru/api/play/options/%s/?format=json' % video_id,
-        'md5': '5dc6477e74b1e37042ac5acedd8413e5',
+        'md5': '1574e9b4d6438446d5b7dbcdf2786276',
-                      transform_source=None):
+                      transform_source=None, fatal=True):
-        xml_string = self._download_webpage(url_or_request, video_id, note, errnote)
+        xml_string = self._download_webpage(
-def int_or_none(v, scale=1, default=None):
+def int_or_none(v, scale=1, default=None, get_attr=None):
-        self.assertEqual(len(subtitles.keys()), 28)
+        self.assertTrue(len(subtitles.keys()) >= 28)
-__version__ = '2014.04.21.2'
+__version__ = '2014.04.21.3'
-        mobj = re.search(r'<iframe src="(http://www\.aparat\.com/video/[^"]+)"', webpage)
+        mobj = re.search(r'<iframe .*?src="(http://www\.aparat\.com/video/[^"]+)"', webpage)
-            r'(?s)<h4 class="[^"]+" id="h3--about-this-talk">.*?</h4>(.*?)</div>',
+            [
-            self.url_result(u'http://www.ted.com/talks/' + talk['slug'], self.ie_key())
+            self.url_result('http://www.ted.com/talks/' + talk['slug'], self.ie_key())
-            self._downloader.report_warning(u'video doesn\'t have subtitles')
+            self._downloader.report_warning('video doesn\'t have subtitles')
-            r"<div class=\"cnetVideoPlayer\" data-cnet-video-options='([^']+)'",
+            r"<div class=\"cnetVideoPlayer\"\s+.*?data-cnet-video-options='([^']+)'",
-        json_url = self._html_search_regex(r'arte_vp_url="(.*?)"', webpage, 'json url')
+        json_url = self._html_search_regex(
-            if not include_onlymatching and getattr(t, 'only_matching', False):
+            if not include_onlymatching and t.get('only_matching', False):
-__version__ = '2014.04.21.1'
+__version__ = '2014.04.21.2'
-__version__ = '2014.04.21'
+__version__ = '2014.04.21.1'
-    _VALID_URL = r'^(?P<domain>(?:https?://)?(?:www\.)?mdr\.de)/mediathek/(?:.*)/(?P<type>video|audio)(?P<video_id>[^/_]+)_.*'
+    _VALID_URL = r'^(?P<domain>https?://(?:www\.)?mdr\.de)/(?:.*)/(?P<type>video|audio)(?P<video_id>[^/_]+)(?:_|\.html)'
-        title = self._html_search_regex(r'<h2>(.*?)</h2>', html, u'title')
+        title = self._html_search_regex(r'<h[12]>(.*?)</h[12]>', html, 'title')
-            r'(/mediathek/(?:.+)/(?:video|audio)[0-9]+-avCustom.xml)', html, u'XML URL')
+            r'dataURL:\'(/(?:.+)/(?:video|audio)[0-9]+-avCustom.xml)', html, 'XML URL')
-                    'format_id': u'%s-%d' % (media_type, abr),
+                    'format_id': '%s-%d' % (media_type, abr),
-                    'format_id': u'%s-%d' % (media_type, vbr),
+                    'format_id': '%s-%d' % (media_type, vbr),
-    _VALID_URL = r'https?://screen\.yahoo\.com/.*?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html'
+    IE_DESC = 'Yahoo screen and movies'
-        long_id = info['id']
+        items_json = self._search_regex(
-    _VALID_URL = r'http://(video|www)\.(?P<site>%s)\.com/(?P<type>watch|series|video)/(?P<id>.+)' % '|'.join(_SITES.keys())
+    _VALID_URL = r'http://(video|www|player)\.(?P<site>%s)\.com/(?P<type>watch|series|video|embed)/(?P<id>[^/?#]+)' % '|'.join(_SITES.keys())
-        'file': '5171b343c2b4c00dd0c1ccb3.mp4',
+            'id': '5171b343c2b4c00dd0c1ccb3',
-                                              fatal=False, flags=re.DOTALL)
+    def _extract_video(self, webpage, url_type):
-        id = mobj.group('id')
+        item_id = mobj.group('id')
-        webpage = self._download_webpage(url, id)
+        self.to_screen('Extracting from %s with the CondÃ© Nast extractor' % self._SITES[site])
-            return self._extract_video(webpage)
+            return self._extract_video(webpage, url_type)
-    while remaining > 0:
+    def next_nonbmp_pos(s):
-            h, s, min(remaining, 1024), ctypes.byref(written), None)
+            h, s, count if count else 2, ctypes.byref(written), None)
-        remaining -= written.value
+        if not count:  # We just wrote a non-BMP character
-        'md5': 'fcaa3d995e04080dcb9465d86b5eef62',
+        'md5': 'b5ca0e0a8c1fed93b0e65e48e462f9a2',
-        encoded_id = self._search_regex(r"jsclassref ?= ?'([^']*)'", webpage, 'encoded id')
+        encoded_id = self._search_regex(
-            }],
+            'formats': formats,
-            u'title': u'A Few of My Favorite [Python] Things',
+        'name': 'InfoQ',
-        return [{
+        return {
-        }]
+        }
-__version__ = '2014.04.19'
+__version__ = '2014.04.21'
-                """
+    _VALID_URL = r"""(?x)
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        webpage = self._download_webpage(videourl, gameID)
+        m = re.match(self._VALID_URL, url)
-            videourl = self._AGECHECK_TEMPLATE % gameID
+            videourl = self._AGECHECK_TEMPLATE % playlist_id
-            webpage = self._download_webpage(videourl, gameID)
+            webpage = self._download_webpage(videourl, playlist_id)
-                                             webpage, 'game title')
+            mweb = re.finditer(r'''(?x)
-        return self.playlist_result(videos, gameID, game_title)
+        return self.playlist_result(videos, playlist_id, playlist_title)
-        playpath = 'mp4:' + base64.b64decode(base64playpath).decode('utf-8')
+
-            "skip_download": True,
+        u'name': u'InfoQ',
-        video_url = 'rtmpe://video.infoq.com/cfx/st/' + real_id
+        self.report_extraction(video_id)
-            webpage, 'title')
+        video_title = self._html_search_regex(r'<title>(.*?)</title>', webpage, 'title')
-            webpage, 'description', fatal=False)
+        video_url = 'rtmpe://video.infoq.com/cfx/st/'
-        video_filename = video_url.split('/')[-1]
+        video_filename = playpath.split('/')[-1]
-        return {
+        return [{
-        }
+            'formats': [{
-        
+        self.assertTrue(len(result['entries']) >= 23)
-        self.assertTrue(len(result['entries']) >= 20)
+        self.assertTrue(len(result['entries']) >= 7)
-    _VALID_URL = r"""http://store\.steampowered\.com/
+    _VALID_URL = r"""(?x)http://store\.steampowered\.com/
-        ]
+        ],
-        thumbs = re.finditer(thumbsRE, webpage)
+        mweb = re.finditer(
-        for vid,vtitle,thumb in zip(mweb,titles,thumbs):
+        for vid, vtitle, thumb in zip(mweb, titles, thumbs):
-                'url':video_url,
+            videos.append({
-            videos.append(info)
+            })
-        u"playlist": [
+        "url": "http://store.steampowered.com/video/105600/",
-                        u'playlist_index': 1,
+                "md5": "f870007cee7065d7c76b88f0a45ecc07",
-                    u'playlist_index': 2,
+                "md5": "61aaf31a5c5c3041afb58fb83cbb5751",
-                raise ExtractorError(u'Cannot find video url for %s' % video_id)
+                raise ExtractorError('Cannot find video url for %s' % video_id)
-        return [self.playlist_result(videos, gameID, game_title)]
+        return self.playlist_result(videos, gameID, game_title)
-            u"age_limit": 18,
+        'url': 'http://www.extremetube.com/video/music-video-14-british-euro-brit-european-cumshots-swallow-652431',
-        video_url = compat_urllib_parse.unquote(self._html_search_regex(r'video_url=(.+?)&amp;', webpage, u'video_url'))
+        video_title = self._html_search_regex(
-def gettestcases():
+
-        for t in getattr(ie, '_TESTS', []):
+            assert not hasattr(ie, '_TESTS'), \
-        for tc in gettestcases():
+        for tc in gettestcases(include_onlymatching=True):
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _TEST = {
+    _TESTS = [{
-    _TESTS = []
+    }]
-    _TEST = {
+    _TESTS = [{
-    _TESTS = []
+    }]
-        self.assertTrue(JustinTVIE.suitable(u"http://www.twitch.tv/vanillatv/"))
+        self.assertTrue(JustinTVIE.suitable('justin.tv/vanillatv'))
-        self.assertTrue(JustinTVIE.suitable(u"http://www.twitch.tv/vanillatv/b/328087483"))
+        self.assertTrue(JustinTVIE.suitable('http://www.twitch.tv/vanillatv/b/328087483'))
-        self.assertTrue(JustinTVIE.suitable(u"http://www.twitch.tv/tsm_theoddone/c/2349361"))
+        self.assertTrue(JustinTVIE.suitable('http://www.twitch.tv/tsm_theoddone/c/2349361'))
-__version__ = '2014.04.13'
+__version__ = '2014.04.19'
-        m3u8_url = trackinfo['video_balancer'].get('m3u8')
+        author = video.get('author') or {}
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>extremetube\.com/video/.+?(?P<videoid>[0-9]+))(?:[/?&]|$)'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>extremetube\.com/.*?video/.+?(?P<videoid>[0-9]+))(?:[/?&]|$)'
-            'description': 'md5:6fcfdbbb73aee107a6b7553cefbcbeae',
+            'description': 'md5:4eaab46ab68fa4197a317a88a53d3b86',
-    }
+    _TESTS = [
-            json_url, video_id, note=u'Downloading video info')
+            json_url, video_id, 'Downloading video info')
-from .tlc import TlcDeIE
+from .tlc import TlcIE, TlcDeIE
-        },
+from __future__ import unicode_literals
-    IE_NAME = u'canalplus.fr'
+    IE_NAME = 'canalplus.fr'
-            u'upload_date': u'20130826',
+        'url': 'http://www.canalplus.fr/c-infos-documentaires/pid1830-c-zapping.html?vid=922470',
-            u'skip_download': True,
+        'params': {
-        video_id = mobj.groupdict().get('id')
+        video_id = mobj.group('id')
-            video_id = self._search_regex(r'<canal:player videoId="(\d+)"', webpage, u'video id')
+            video_id = self._search_regex(r'<canal:player videoId="(\d+)"', webpage, 'video id')
-                                           u'Downloading video info')
+        doc = self._download_xml(info_url, video_id, 'Downloading video XML')
-                }
+        infos = video_info.find('INFOS')
-                self.to_screen(u'Downloading playlist PL%s - add --no-playlist to just download video %s' % (playlist_id, video_id))
+                self.to_screen(u'Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))
-            'title': 'iPad Mini with Retina Display Review',
+    _TESTS = [
-    }
+        {
-            'playlist=%s&url=https' % video_id,
+            'https://syn.5min.com/handlers/SenseHandler.ashx?' + query,
-            else int(view_count_str.replace(',', '')))
+        post_view = json.loads(self._html_search_regex(
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': thumbnail,
-                f.update(finfo)
+        } for (format_id, format_url) in talk_info['nativeDownloads'].items() if format_url is not None]
-            'file': '3235767654.mp3',
+                'id': '3235767654',
-            'file': '3101154703001.mp4',
+                'id': '3101154703001',
-            'md5': '6e15c93721d7ec9e9ca3fdbf07982cfd',
+            'md5': '85b90ccc9d73b4acd9138d3af4c27f89',
-__version__ = '2014.04.11.2'
+__version__ = '2014.04.13'
-
+    AolIE,
-    _VALID_URL = r'http://on\.aol\.com/video/.*-(?P<id>\d+)($|\?)'
+    _VALID_URL = r'''(?x)
-        self.to_screen('Downloading 5min.com video %s' % video_id)
+
-import os
+from __future__ import unicode_literals
-)
+from ..aes import aes_decrypt_text
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>tube8\.com/.+?/(?P<videoid>\d+)/?)$'
+    _VALID_URL = r'https?://(?:www\.)?tube8\.com/(?:[^/]+/){2}(?P<id>\d+)'
-            u"age_limit": 18,
+        'url': 'http://www.tube8.com/teen/kasia-music-video/229795/',
-        url = 'http://www.' + mobj.group('url')
+        video_id = mobj.group('id')
-            video_url = aes_decrypt_text(video_url, password, 32).decode('utf-8')
+        flashvars = json.loads(self._html_search_regex(
-        format = "-".join(format)
+        format_id = '-'.join(path.split('/')[4].split('_')[:2])
-            'format_id': format,
+            'title': title,
-            return [unescapeHTML(url_m.group(1))]
+            url = unescapeHTML(url_m.group(1))
-import json
+
-            u'title': u'é­å£°è³æºææ°å¹¿åâAll Eyes On Usâ',
+        'url': 'http://video.weibo.com/v/weishipin/t_zjUw2kZ.htm',
-            u'skip_download': True,
+        'params': {
-        info = json.loads(info_page)
+        info = self._download_json(info_url, video_id)
-        videos_urls = sorted(videos_urls, key=lambda u: u'video.sina.com' in u)
+        # Prefer sina video since they have thumbnails
-        m_sina = re.match(r'https?://video.sina.com.cn/v/b/(\d+)-\d+.html', player_url)
+        m_sina = re.match(r'https?://video\.sina\.com\.cn/v/b/(\d+)-\d+\.html',
-            webpage, 'video URL')
+        data = self._download_xml(
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'title': title,
-__version__ = '2014.04.11.1'
+__version__ = '2014.04.11.2'
-                              (?:(?:guests/[^/]+|videos|video-playlists)/[^/]+/(?P<videotitle>[^/?#]+))
+                              (?:(?:guests/[^/]+|videos|video-playlists|special-editions)/[^/]+/(?P<videotitle>[^/?#]+))
-            r'<div class="section">.*?<h3>([^>]+?)</h3>', webpage, 'title', flags=re.DOTALL)
+            r'<div class="section">.*?<h3(?:\s+class="[^"]*")?>([^>]+?)</h3>',
-            r'<p class="description.*?"[^>]*>(.*?)</p>', webpage, 'description')
+            r'<p\s+(?:style="[^"]*"\s+)?class="description.*?"[^>]*>(.*?)</p>', webpage,
-                }
+        return {
-        'md5': '4167875aae411f903b751a21f357f1ee',
+        'md5': 'c4f48e9eda1b16dd10add0744344b6d8',
-__version__ = '2014.04.11'
+__version__ = '2014.04.11.1'
-__version__ = '2014.04.07.4'
+__version__ = '2014.04.11'
-    _VALID_URL = r'^https?://(?:www\.)?9gag\.tv/v/(?P<id>[0-9]+)'
+    _VALID_URL = r'''(?x)^https?://(?:www\.)?9gag\.tv/
-    _TEST = {
+    _TESTS = [{
-    }
+    },
-        video_id = mobj.group('id')
+        video_id = mobj.group('numid') or mobj.group('id')
-        webpage = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, display_id)
-            'title': self._og_search_title(webpage),
+            'display_id': display_id,
-)
+from ..utils import ExtractorError
-            'description': 'md5:1a7ae3e153359b7cc355ef3963441e5f',
+            'description': 'md5:4e9a7ce60f209a33eca0ac65b4918e1c',
-)
+from ..utils import int_or_none
-            'uploader': 'petenewman',
+            'uploader': 'Peter Newman Media',
-    _VALID_URL = r'https?://(?:www\.)?morningstar\.com/cover/video[cC]enter\.aspx\?id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?morningstar\.com/[cC]over/video[cC]enter\.aspx\?id=(?P<id>[0-9]+)'
-    _VALID_URL = r'https?://(?:www\.)?morningstar\.com/cover/videocenter\.aspx\?id=(?P<id>[0-9]+)'
+    _VALID_URL = r'https?://(?:www\.)?morningstar\.com/cover/video[cC]enter\.aspx\?id=(?P<id>[0-9]+)'
-from ..utils import ExtractorError
+from ..utils import (
-    _BASE_URL = "http://www.br.de"
+    IE_DESC = 'Bayerischer Rundfunk Mediathek'
-                "upload_date": "20140301"
+            'url': 'http://www.br.de/mediathek/video/anselm-gruen-114.html',
-                "upload_date": None
+            'url': 'http://www.br.de/mediathek/video/sendungen/unter-unserem-himmel/unter-unserem-himmel-alpen-ueber-den-pass-100.html',
-        }
+        },
-            r"return BRavFramework\.register\(BRavFramework\('avPlayer_(?:[a-f0-9-]{36})'\)\.setup\({dataURL:'(/mediathek/video/[a-z0-9/~_.-]+)'}\)\);", page, "XMLURL")
+            r"return BRavFramework\.register\(BRavFramework\('avPlayer_(?:[a-f0-9-]{36})'\)\.setup\({dataURL:'(/(?:[a-z0-9\-]+/)+[a-z0-9/~_.-]+)'}\)\);", page, 'XMLURL')
-                "webpage_url": xml_video.find("permalink").text
+        medias = []
-            videos.append(video)
+            if xml_media.find('author').text:
-        if len(videos) > 1:
+        if len(medias) > 1:
-                'found multiple videos; please '
+                'found multiple medias; please '
-        return videos[0]
+        if not medias:
-            if asset.find("downloadUrl") is not None]
+            'url': text_or_none(asset, 'downloadUrl'),
-        thumbnails.sort(key=lambda x: x["width"] * x["height"], reverse=True)
+            'url': self._BASE_URL + variant.find('url').text,
-                         (full-episodes/(?:[0-9a-z]{6}/)?(?P<episode>.*)|
+                         ((?:full-)?episodes/(?:[0-9a-z]{6}/)?(?P<episode>.*)|
-                              (?:(?:guests/[^/]+|videos)/[^/]+/(?P<videotitle>[^/?#]+))
+                              (?:(?:guests/[^/]+|videos|video-playlists)/[^/]+/(?P<videotitle>[^/?#]+))
-                    self.report_error('Cannot write subtitles file ' + descfn)
+                    self.report_error('Cannot write subtitles file ' + sub_filename)
-                'id': '750783',
+                'id': '758100',
-                'duration': 28,
+                'title': 'ÐÑÑÑÐ¾ÑÑÐ¶ÐµÑÐ½ÑÐ¹ ÑÐ¸Ð»ÑÐ¼ Â«ÐÐ¾Ð¼Ð°Â»',
-        p = subprocess.Popen(bcmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
-__version__ = '2014.04.07.3'
+__version__ = '2014.04.07.4'
-    remaining = len(s)
+    remaining = ucs2_len(s)
-            h, s, min(len(s), 1024), ctypes.byref(written), None)
+            h, s, min(remaining, 1024), ctypes.byref(written), None)
-        content = webpage_bytes.decode(encoding, 'replace')
+        try:
-__version__ = '2014.04.07.2'
+__version__ = '2014.04.07.3'
-        write_string(s, out=out, encoding=self.get_encoding())
+        write_string(s, out=out, encoding=self.params.get('encoding'))
-__version__ = '2014.04.07.1'
+__version__ = '2014.04.07.2'
-    try:
+        byt = s.encode(encoding or preferredencoding(), 'ignore')
-
+    def _write_string(self, s, out=None):
-            write_string(output, self._screen_file)
+            self._write_string(output, self._screen_file)
-            write_string(output, self._err_file)
+            self._write_string(output, self._err_file)
-            write_string('\033]0;%s\007' % message, self._screen_file)
+            self._write_string('\033]0;%s\007' % message, self._screen_file)
-            write_string('\033[22;0t', self._screen_file)
+            self._write_string('\033[22;0t', self._screen_file)
-            write_string('\033[23;0t', self._screen_file)
+            self._write_string('\033[23;0t', self._screen_file)
-        write_string('[debug] youtube-dl version ' + __version__ + '\n')
+        write_string(
-                write_string('[debug] Git HEAD: ' + out + '\n')
+                self._write_string('[debug] Git HEAD: ' + out + '\n')
-        write_string('[debug] Python version %s - %s' %
+        self._write_string('[debug] Python version %s - %s' %
-        write_string('[debug] Proxy map: ' + compat_str(proxy_map) + '\n')
+        self._write_string('[debug] Proxy map: ' + compat_str(proxy_map) + '\n')
-def write_string(s, out=None):
+def write_string(s, out=None, encoding=None):
-        s = s.encode(preferredencoding(), 'ignore')
+        s = s.encode(encoding or preferredencoding(), 'ignore')
-            out.write(s)
+        if sys.platform == 'win32':
-__version__ = '2014.04.07'
+__version__ = '2014.04.07.1'
-    _VALID_URL = r'http://teamcoco\.com/video/(?P<video_id>[0-9]+)?/?(?P<url_title>.*)'
+    _VALID_URL = r'http://teamcoco\.com/video/(?P<video_id>[0-9]+)?/?(?P<display_id>.*)'
-        webpage = self._download_webpage(url, url_title)
+
-        if video_id == '':
+        if not video_id:
-        data = self._download_xml(data_url, video_id, 'Downloading data webpage')
+        data = self._download_xml(
-__version__ = '2014.04.04.7'
+__version__ = '2014.04.07'
-        'high': 3,
+    _NATIVE_FORMATS = {
-            'preference': self._FORMATS_PREFERENCE.get(format_id, -1),
+        for f in formats:
-            'md5': 'c197f0b2421995c63a64cc73d800f42e',
+            'md5': 'c148457a27bdc9e5b1ffe081a7a8337b',
-                'description': '',
+                'duration': 3720,
-    IE_NAME = u'justin.tv'
+    IE_NAME = 'justin.tv'
-            u"title": u"Beginner Series - Scripting With Python Pt.1"
+        'url': 'http://www.twitch.tv/thegamedevhub/b/296128360',
-                                           u'unable to download video info JSON')
+                                           'Downloading video info JSON',
-            raise ExtractorError(u'Justin.tv API: %s' % error_text)
+            raise ExtractorError('Justin.tv API: %s' % error_text)
-                    'id': video_id,
+                    'id': compat_str(video_id),
-                raise ExtractorError(u'Cannot find archive of a chapter')
+                raise ExtractorError('Cannot find archive of a chapter')
-                                             errnote=u'Chapter information download failed')
+            doc = self._download_xml(
-                raise ExtractorError(u'Could not find chapter in chapter information')
+                raise ExtractorError('Could not find chapter in chapter information')
-            video_ext = video_url.rpartition('.')[2] or u'flv'
+            video_ext = video_url.rpartition('.')[2] or 'flv'
-            chapter_info = json.loads(chapter_info_json)
+            chapter_api_url = 'https://api.twitch.tv/kraken/videos/c' + chapter_id
-            #video_url += u'?start=' + TODO:start_timestamp
+            #video_url += '?start=' + TODO:start_timestamp
-                                            u'Chapter starts at %s and ends at %s' % (formatSeconds(bracket_start), formatSeconds(bracket_end)))
+            self._downloader.report_warning('Chapter detected, but we can just download the whole file. '
-                'id': u'c' + chapter_id,
+                'id': 'c' + chapter_id,
-            return [info]
+            return info
-        info = []
+        entries = []
-            info.extend(page_info)
+            entries.extend(page_info)
-        return info
+        return {
-    _VALID_URL_TEMPLATE = r'http://(?:(?:www\.)?%(host)s/(?:file|video)/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<videoid>[a-z\d]{13})'
+    _VALID_URL_TEMPLATE = r'http://(?:(?:www\.)?%(host)s/(?:file|video)/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<id>[a-z\d]{13})'
-        video_id = mobj.group('videoid')
+        video_id = mobj.group('id')
-            raise ExtractorError(u'Video %s does not exist' % video_id, expected=True)
+            raise ExtractorError('Video %s does not exist' % video_id, expected=True)
-        # Look for embedded NovaMov player
+        # Look for embedded NovaMov-based player
-            r'<iframe[^>]+?src=(["\'])(?P<url>http://(?:(?:embed|www)\.)?novamov\.com/embed\.php.+?)\1', webpage)
+            r'''(?x)<iframe[^>]+?src=(["\'])
-            return self.url_result(mobj.group('url'), 'VideoWeed')
+            return self.url_result(mobj.group('url'))
-    IE_NAME = 'divstage'
+    IE_NAME = 'divxstage'
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'movshare\.(?:net|sx)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'movshare\.(?:net|sx|ag)'}
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'divxstage\.(?:eu|net)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'divxstage\.(?:eu|net|ch|co|at|ag)'}
-            r'<iframe[^>]+?src=(["\'])(?P<url>http://(?:(?:embed|www)\.)?nowvideo\.(?:ch|sx|eu)/embed\.php.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>http://(?:(?:embed|www)\.)?nowvideo\.(?:ch|sx|eu|at|ag|co)/embed\.php.+?)\1', webpage)
-    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:ch|sx|eu)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:ch|sx|eu|at|ag|co)'}
-    _FILEKEY_REGEX = r'flashvars\.filekey="(?P<filekey>[^"]+)";'
+from .movshare import MovShareIE
-    _VALID_URL = r'http://(?:(?:www\.)?%(host)s/video/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<videoid>[a-z\d]{13})' % {'host': 'nowvideo\.(?:ch|sx|eu)'}
+    _VALID_URL = NovaMovIE._VALID_URL_TEMPLATE % {'host': 'nowvideo\.(?:ch|sx|eu)'}
-    _VALID_URL = r'http://(?:(?:www\.)?%(host)s/video/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<videoid>[a-z\d]{13})' % {'host': 'novamov\.com'}
+    _VALID_URL_TEMPLATE = r'http://(?:(?:www\.)?%(host)s/(?:file|video)/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<videoid>[a-z\d]{13})'
-import re
+from .novamov import NovaMovIE
-class VideoweedIE(InfoExtractor):
+class VideoWeedIE(NovaMovIE):
-    IE_DESC = 'VideoWEED'
+    IE_DESC = 'VideoWeed'
-    _FILE_DELETED_REGEX = r'>This file no longer exists on our servers.</'
+    _FILE_DELETED_REGEX = r'>This file no longer exists on our servers.<'
-        'md5': '7205f346a52bbeba427603ba10d4b935',
+        'url': 'http://www.videoweed.es/file/b42178afbea14',
-            'id': '89868b4aa3bdf',
+            'id': 'b42178afbea14',
-            'title': 'law and order svu 103 dvdrip',
+            'title': 'optical illusion  dissapeared image magic illusion',
-        }
+    }
-        print "itworks"
+        
-                'id': '5738317',
+                'id': '5624067',
-        def download_json(video_id):
+        def download_json(internal_id):
-                'http://www.rts.ch/a/%s.html?f=json/article' % video_id, video_id)
+                'http://www.rts.ch/a/%s.html?f=json/article' % internal_id,
-            all_info = download_json(video_id)
+            internal_id = self._html_search_regex(
-            "description": "Iata-ne reveniti dupa o binemeritata vacanta. Va astept si pe Facebook cu pareri si comentarii.",
+            "description": "re:^Iata-ne reveniti dupa o binemeritata vacanta\. +Va astept si pe Facebook cu pareri si comentarii.$",
-        h = hashlib.md5(s + base_video_url).hexdigest()
+        h = hashlib.md5((s + base_video_url).encode('utf-8')).hexdigest()
-__version__ = '2014.04.04.6'
+__version__ = '2014.04.04.7'
-        lambda m: m.group(0).decode('unicode-escape'), s)
+        lambda m: unicode_escape(m.group(0))[0],
-__version__ = '2014.04.04.5'
+__version__ = '2014.04.04.6'
-    _VALID_URL = r'http://teamcoco\.com/video/(?P<video_id>\d*)?/?(?P<url_title>.*)'
+    _VALID_URL = r'http://teamcoco\.com/video/(?P<video_id>[0-9]+)?/?(?P<url_title>.*)'
-__version__ = '2014.04.04.4'
+__version__ = '2014.04.04.5'
-    _VALID_URL = r'http://screen\.yahoo\.com/.*?-(?P<id>\d*?)\.html'
+    _VALID_URL = r'https?://screen\.yahoo\.com/.*?-(?P<id>[0-9]+)(?:-[a-z]+)?\.html'
-                'url': url,
+                'url': format_url,
-            } for format, quality, url in re.findall(
+            } for format, quality, format_url in re.findall(
-)
+import json
-__version__ = '2014.04.04.2'
+__version__ = '2014.04.04.4'
-        '--prefer-insecure', action='store_true', dest='prefer_insecure',
+        '--prefer-insecure', '--prefer-unsecure', action='store_true', dest='prefer_insecure',
-    _VALID_URL = r'http://teamcoco\.com/video/([^/]*)?/?(.*)'
+    _VALID_URL = r'http://teamcoco\.com/video/(?P<video_id>\d*)?/?(?P<url_title>.*)'
-            url_title = mobj.group(1)
+        url_title = mobj.group('url_title')
-        if mobj.group(2) == '':
+        video_id = mobj.group("video_id")
-    _VALID_URL = r'http://teamcoco\.com/video/(?P<video_id>\d*)?/?(?P<url_title>.*)'
+    _VALID_URL = r'http://teamcoco\.com/video/([^/]*)?/?(.*)'
-        url_title = mobj.group('url_title')
+        url_title = mobj.group(2)
-        if video_id == '':
+        video_id = mobj.group(1)
-    _TEST = {
+    _TESTS = [
-    _VALID_URL = r'http://teamcoco\.com/video/(?P<url_title>.*)'
+    _VALID_URL = r'http://teamcoco\.com/video/(?P<video_id>\d*)?/?(?P<url_title>.*)'
-
+        
-            return self.url_result(m_youtube.group(1), 'Youtube')
+        youtube_id = info.get('youtubeId')
-                'uploader': 'AU SPA: The NSA and Privacy',
+                'id': '45734260',
-    _TESTS = [{
+    _TEST = {
-    ]
+from __future__ import unicode_literals
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>keezmovies\.com/video/.+?(?P<videoid>[0-9]+))(?:[/?&]|$)'
+    _VALID_URL = r'^https?://(?:www\.)?keezmovies\.com/video/.+?(?P<videoid>[0-9]+)(?:[/?&]|$)'
-            u"age_limit": 18,
+        'url': 'http://www.keezmovies.com/video/petite-asian-lady-mai-playing-in-bathtub-1214711',
-            password = self._html_search_regex(r'video_title=(.+?)&amp;', webpage, u'password')
+        video_title = self._html_search_regex(r'<h1 [^>]*>([^<]+)', webpage, 'title')
-            'file': '214727115.mp4',
+                'id': '214727115',
-            'file': '103000935.mp4',
+                'id': '103000935',
-        query_result_json = self._download_webpage(
+        query_result = self._download_json(
-        for pagenum in itertools.count(0): 
+        entries = []
-            info = json.loads(webpage)
+            info = self._download_json(result_url, query,
-                if (pagenum * 30) +i >= n:
+                if (pagenum * 30) + i >= n:
-            if (pagenum * 30 +i >= n) or (m['last'] >= (m['total'] -1)):
+                entries.append(e)
-        return res
+        return {
-        'md5': '35272469887dca97abd30abecc6cdf75',
+        'md5': '956b8ca569f7f4d8ec563e2c41598441',
-from ..utils import compat_urllib_parse
+from ..utils import int_or_none
-    _VALID_URL = r'(?:http://)?(?:www\.)?pornhd\.com/(?:[a-z]{2,4}/)?videos/(?P<video_id>[0-9]+)/(?P<video_title>.+)'
+    _VALID_URL = r'http://(?:www\.)?pornhd\.com/(?:[a-z]{2,4}/)?videos/(?P<id>\d+)'
-            "age_limit": 18,
+            'id': '1962',
-        video_title = mobj.group('video_title')
+        video_id = mobj.group('id')
-        next_url = compat_urllib_parse.unquote(next_url)
+        title = self._og_search_title(webpage)
-        age_limit = 18
+        self._sort_formats(formats)
-            'age_limit': age_limit,
+            'title': title,
-    _VALID_URL = r'https?://www\.ustream\.tv/recorded/(?P<videoID>\d+)'
+    _VALID_URL = r'https?://www\.ustream\.tv/(?P<type>recorded|embed)/(?P<videoID>\d+)'
-    _TEST = {
+    _TESTS = [{
-            'thumbnail': 're:^https?://.*\.image'
+    _VALID_URL = r'^https?://(?:www\.)?rts\.ch/(?:[^/]+/){2,}(?P<id>[0-9]+)-.*?\.html'
-    }
+        {
-        info = all_info['video']['JSONinfo']
+        def download_json(video_id):
-        duration = parse_duration(info.get('duration'))
+        duration = info.get('duration') or info.get('cutout') or info.get('cutduration')
-                r'-([0-9]+)k\.', furl, 'bitrate', default=None)),
+            'tbr': extract_bitrate(furl),
-    timeconvert,
+    timeconvert,
-            self.report_error(u'unable to rename file: %s' % str(err))
+            self.report_error(u'unable to rename file: %s' % compat_str(err))
-__version__ = '2014.04.04.3'
+__version__ = '2014.04.04.2'
-                r'<h1 class="pl-header-title">\s*(.*?)\s*</h1>', page, u'title')
+            r'(?s)<h1 class="pl-header-title[^"]*">\s*(.*?)\s*</h1>',
-__version__ = '2014.04.04.1'
+__version__ = '2014.04.04.3'
-    _MORE_PAGES_INDICATOR = r'<div class="next">.*?<a.*?href="/playlist/.+?".*?>.*?</a>.*?</div>'
+    _MORE_PAGES_INDICATOR = r'(?s)<div class="pages[^"]*">.*?<a\s+class="[^"]*?icon-arrow_right[^"]*?"'
-            video_ids.extend(re.findall(r'data-id="(.+?)"', playlist_el))
+            video_ids.extend(re.findall(r'data-id="(.+?)"', webpage))
-            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:
+            if re.search(self._MORE_PAGES_INDICATOR, webpage) is None:
-    _MORE_PAGES_INDICATOR = r'<div class="next">.*?<a.*?href="/user/.+?".*?>.*?</a>.*?</div>'
+    _VALID_URL = r'https?://(?:www\.)?dailymotion\.[a-z]{2,3}/user/(?P<user>[^/]+)'
-        },
+def _make_result(formats, **kwargs):
-            {'ext': 'mp4',  'height': 460},
+            {'ext': 'webm', 'height': 460, 'url': 'x'},
-        info_dict = {'formats': formats, 'extractor': 'test'}
+        info_dict = _make_result(formats)
-            {'ext': 'mp4', 'height': 1080},
+            {'ext': 'webm', 'height': 720, 'url': 'a'},
-            {'ext': 'flv', 'height': 720},
+            {'ext': 'webm', 'height': 720, 'url': '_'},
-            {'ext': 'webm', 'height': 720},
+            {'ext': 'flv', 'height': 720, 'url': '_'},
-            'formats': formats, 'extractor': 'test', 'id': 'testvid'}
+        info_dict = _make_result(formats)
-            {'format_id': '2', 'ext': 'flv', 'preference': 4},
+            {'format_id': '35', 'ext': 'mp4', 'preference': 1, 'url': '_'},
-        info_dict = {'formats': formats, 'extractor': 'test'}
+        info_dict = _make_result(formats)
-            {'format_id': 'vid', 'ext': 'mp4', 'preference': 4},
+            {'format_id': 'audio-low', 'ext': 'webm', 'preference': 1, 'vcodec': 'none', 'url': '_'},
-        info_dict = {'formats': formats, 'extractor': 'test'}
+        info_dict = _make_result(formats)
-            {'format_id': 'vid-high', 'ext': 'mp4', 'preference': 2},
+            {'format_id': 'vid-low', 'ext': 'mp4', 'preference': 1, 'url': '_'},
-        info_dict = {'formats': formats, 'extractor': 'test'}
+        info_dict = _make_result(formats)
-            {'format_id': 'vid', 'ext': 'mp4', 'preference': 3},
+            {'format_id': 'dash-video-low', 'ext': 'mp4', 'preference': 1, 'acodec': 'none', 'url': '_'},
-        info_dict = {'formats': formats, 'extractor': 'test'}
+        info_dict = _make_result(formats)
-            info_dict = {'formats': [f1, f2], 'extractor': 'youtube'}
+            info_dict = _make_result([f1, f2], extractor='youtube')
-            info_dict = {'formats': [f2, f1], 'extractor': 'youtube'}
+            info_dict = _make_result([f2, f1], extractor='youtube')
-__version__ = '2014.04.04'
+__version__ = '2014.04.04.1'
-__version__ = '2014.04.03.3'
+__version__ = '2014.04.04'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        }
+        }
-                         (full-episodes/(?P<episode>.*)|
+                         (full-episodes/(?:[0-9a-z]{6}/)?(?P<episode>.*)|
-__version__ = '2014.04.03.2'
+__version__ = '2014.04.03.3'
-    return v if v is None else (int(v) // scale)
+def int_or_none(v, scale=1, default=None):
-    return v if v is None else (float(v) / scale)
+def float_or_none(v, scale=1, default=None):
-__version__ = '2014.04.03.1'
+__version__ = '2014.04.03.2'
-            if dn != '' and not os.path.exists(dn):
+            if dn and not os.path.exists(dn):
-    IE_DESC = u'YouTube.com subscriptions feed, "ytsubs" keyword(requires authentication)'
+    IE_DESC = u'YouTube.com subscriptions feed, "ytsubs" keyword (requires authentication)'
-    _VALID_URL = r'https?://((www|player)\.)?56\.com/(.+?/)?(v_|(play_album.+-))(?P<textid>.+?)\.(html|swf)'
+    _VALID_URL = r'https?://(?:(?:www|player)\.)?56\.com/(?:.+?/)?(?:v_|(?:play_album.+-))(?P<textid>.+?)\.(?:html|swf)'
-        'file': '93440716.flv',
+            'id': '93440716',
-        } for f in info['rfiles']]
+
-                              (?:videos/[^/]+/(?P<videotitle>[^/?#]+))
+                              (?:(?:guests/[^/]+|videos)/[^/]+/(?P<videotitle>[^/?#]+))
-__version__ = '2014.04.03'
+__version__ = '2014.04.03.1'
-                format['ext'] = determine_ext(format['url'])
+                format['ext'] = determine_ext(format['url']).lower()
-            msg = u'Access to URL %s has been blocked by Websense filtering software in your network.' % urlh.geturl()
+            msg = u'Access to this webpage has been blocked by Websense filtering software in your network.'
-__version__ = '2014.04.02'
+__version__ = '2014.04.03'
-        doc = self._download_xml('http://www.c-span.org/common/services/flashXml.php?programid=' + video_id,
+        doc = self._download_xml(
-            return find_xpath_attr(doc, './/string', 'name', s).text
+        title = find_xpath_attr(doc, './/string', 'name', 'title').text
-            'thumbnail': find_string('poster'),
+from .musicplayon import MusicPlayOnIE
-__version__ = '2014.04.01.3'
+__version__ = '2014.04.02'
-            info = self._download_webpage(self._FEED_TEMPLATE % paging,
+            info = self._download_json(self._FEED_TEMPLATE % paging,
-            feed_html = info['feed_html']
+            feed_html = info.get('feed_html') or info.get('content_html')
-            guid = itemEl.find('.//guid').text.rpartition(':')[-1]
+            guid = itemEl.find('./guid').text.rpartition(':')[-1]
-            'title': 'thedailyshow-kristen-stewart part 1',
+            'title': 'thedailyshow kristen-stewart part 1',
-        api_response = self._download_webpage(
+
-        api_response = self._download_webpage(
+
-        
+
-            api_response = self._download_webpage(
+            page = self._download_json(
-        api_response = self._download_webpage(
+        movie = self._download_json(
-        object_doc = xml.etree.ElementTree.fromstring(object_str)
+        object_doc = xml.etree.ElementTree.fromstring(object_str.encode('utf-8'))
-    _VALID_URL = r'https?://vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>\d+).*?\bid=(?P<id>\d+)|(?:videos.*?\?.*?z=)?video(?P<videoid>.*?)(?:\?|%2F|$))'
+    _VALID_URL = r'https?://vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>-?\d+).*?\bid=(?P<id>\d+)|(?:videos.*?\?.*?z=)?video(?P<videoid>.*?)(?:\?|%2F|$))'
-__version__ = '2014.04.01.2'
+__version__ = '2014.04.01.3'
-        lambda m: compat_chr(int(m.group(1), base=16)), s)
+        r'\\U[0-9a-fA-F]{8}',
-__version__ = '2014.04.01.1'
+__version__ = '2014.04.01.2'
-                'https://youtube.com/%s' % mobj.group('more'), playlist_id, 'Downloading page #%s' % page_num)
+                'https://youtube.com/%s' % mobj.group('more'), playlist_id,
-__version__ = '2014.04.01'
+__version__ = '2014.04.01.1'
-                              |(watch/(?P<date>[^/]*)/(?P<tdstitle>.*)))|
+                              |(watch/(?P<date>[^/]*)/(?P<tdstitle>.*))
-                     $'''
+                     (?:[?#].*|$)'''
-__version__ = '2014.03.30.1'
+__version__ = '2014.04.01'
-        self.assertMatch('http://thedailyshow.cc.com/extended-interviews/xm3fnq/andrew-napolitano-extended-interview', ['ComedyCentralShows'])
+        self.assertMatch(
-                              (the-colbert-report-(videos|collections)/(?P<clipID>[0-9]+)/[^/]*/(?P<cntitle>.*?))
+                              (?:videos/[^/]+/(?P<videotitle>[^/?#]+))
-            if mobj.group('showname') == 'thedailyshow':
+            if mobj.group('videotitle'):
-            u"uploader_id": u"NextDayVideo",
+    _VALID_URL = r'http://(?:www\.)?pyvideo\.org/video/(?P<id>\d+)/(.*)'
-            u'title': u'Gloriajw-SpotifyWithErikBernhardsson182',
+        {
-    },
+
-        m_youtube = re.search(r'(https?://www\.youtube\.com/watch\?v=.*)', webpage)
+        m_youtube = re.search(r'(https?://www\.youtube\.com/watch\?v=.*)', webpage)
-            webpage, u'video url', flags=re.DOTALL)
+        title = self._html_search_regex(
-__version__ = '2014.03.30'
+__version__ = '2014.03.30.1'
-            help='Use this prefix for unqualified URLs. For example "gvsearch2:" downloads two videos from google videos for  youtube-dl "large apple". By default (with value "auto") youtube-dl guesses.')
+    general.add_option(
-    if opts.default_search not in ('auto', None) and ':' not in opts.default_search:
+    if opts.default_search not in ('auto', 'auto_warning', None) and ':' not in opts.default_search:
-                default_search = 'auto'
+                default_search = 'auto_warning'
-            if default_search == 'auto':
+            if default_search in ('auto', 'auto_warning'):
-    _API_URL = 'https://gdata.youtube.com/feeds/api/videos?q=%s&start-index=%i&max-results=50&v=2&alt=jsonc'
+    _API_URL = u'https://gdata.youtube.com/feeds/api/videos?q=%s&start-index=%i&max-results=50&v=2&alt=jsonc'
-            result_url = self._API_URL % (compat_urllib_parse.quote_plus(query), (50*pagenum)+1)
+        while (PAGE_SIZE * pagenum) < limit:
-        'file': '3eac3b4561676c17df9132a9a1e62e3e.mp4',
+            'id': '3eac3b4561676c17df9132a9a1e62e3e',
-                                              video_id, 'Downloading video JSON')
+        api_response = self._download_webpage(
-                                              video_id, 'Downloading trackinfo JSON')
+        api_response = self._download_webpage(
-    _VALID_URL = 'http://(?:www\.)?wdrmaus\.de/(?:extras/|sachgeschichten/sachgeschichten/)?(?P<id>[^/?#]+)(?:/index\.php5|\.php5|/(?:$|[?#]))'
+    _VALID_URL = 'http://(?:www\.)?wdrmaus\.de/(?:[^/]+/){,2}(?P<id>[^/?#]+)(?:/index\.php5|(?<!index)\.php5|/(?:$|[?#]))'
-__version__ = '2014.03.29'
+__version__ = '2014.03.30'
-from .wdr import WDRIE
+from .wdr import (
-    unified_strdate,
+    compat_parse_qs,
-        }
+        }
-            r'function ' + re.escape(funcname) +
+            (r'(?:function %s|%s\s*=\s*function)' % (
-        initial_function = extract_function(funcname)
+             u'Initial JS player signature function name')
-                         (locale.getpreferredencoding(), sys.getfilesystemencoding(), sys.stdout.encoding, preferredencoding()))
+        'encoding': opts.encoding,
-        stdout,stderr = p.communicate()
+        bcmd = [self._downloader.encode(c) for c in cmd]
-
+from __future__ import unicode_literals
-    _VALID_URL=r'http://www\.wat\.tv/.*-(?P<shortID>.*?)_.*?\.html'
+    _VALID_URL = r'http://www\.wat\.tv/.*-(?P<shortID>.*?)_.*?\.html'
-            u'description': u'La menace est partout. Que se passe-t-il Ã  Philadelphia ?\r\nWORLD WAR Z, avec Brad Pitt, au cinÃ©ma le 3 juillet.\r\nhttp://www.worldwarz.fr',
+        'url': 'http://www.wat.tv/video/world-war-philadelphia-vost-6bv55_2fjr7_.html',
-    
+
-        info = json.loads(info)
+        info = self._download_json('http://www.wat.tv/interface/contentv3/' + real_id, real_id)
-
+        upload_date = None
-        return info
+        return {
-import json
+
-    _VALID_URL = r'http://videos\.tf1\.fr/.*-(.*?)\.html'
+    _VALID_URL = r'http://videos\.tf1\.fr/.*-(?P<id>.*?)\.html'
-            u'description': u'VidÃ©o officielle du nouveau CitroÃ«n Grand C4 Picasso, lancÃ© Ã  l\'automne 2013.',
+        'url': 'http://videos.tf1.fr/auto-moto/citroen-grand-c4-picasso-2013-presentation-officielle-8062060.html',
-        embed_page = self._download_webpage(embed_url, id, u'Downloading embed player page')
+        video_id = mobj.group('id')
-        return self.url_result(wat_url, 'Wat')
+        wat_info = self._download_json(
-    _VALID_URL = r'^(?:https?://)?(?:watch\.|www\.)?nba\.com/(?:nba/)?video(/[^?]*?)(?:/index\.html)?(?:\?.*)?$'
+    _VALID_URL = r'https?://(?:watch\.|www\.)?nba\.com/(?:nba/)?video(?P<id>/[^?]*?)(?:/index\.html)?(?:\?.*)?$'
-        'file': u'0021200253-okc-bkn-recap.nba.mp4',
+            'id': '0021200253-okc-bkn-recap.nba',
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-        'file': '3698222.mp4',
+            'id': '3698222',
-            u'description': u'Passion Pit performs "Take A Walk\" live at The Backyard in Austin, Texas. ',
+        'url': 'http://www.roxwel.com/player/passionpittakeawalklive.html',
-        u'skip': u'Requires rtmpdump',
+        'params': {
-                                           u'Downloading video info')
+        info = self._download_json(info_url, filename)
-        rtmp_url = self._download_webpage(url_page_url, filename, u'Downloading video url')
+        rtmp_url = self._download_webpage(url_page_url, filename, 'Downloading video url')
-                }
+        return {
-        'file': '52dd3e4b02a7602131000677.mp4',
+            'id': '52dd3e4b02a7602131000677',
-    IE_NAME = u'ign.com'
+    IE_NAME = 'ign.com'
-                       ]
+    _DESCRIPTION_RE = [
-                u'description': u'md5:c8946d4260a4d43a00d5ae8ed998870c',
+            'url': 'http://www.ign.com/videos/2013/06/05/the-last-of-us-review',
-            u'playlist': [
+            'url': 'http://me.ign.com/en/feature/15775/100-little-things-in-gta-5-that-will-blow-your-mind',
-                        u'description': u'Rockstar drops the mic on this generation of games. Watch our review of the masterly Grand Theft Auto V.',
+                    'info_dict': {
-                        u'description': u'The twisted beauty of GTA 5 in stunning slow motion.',
+                    'info_dict': {
-                u'skip_download': True,
+            'params': {
-                  ]
+        res_id = [
-            video_url = self._search_regex(r'var videoUrl = "(.+?)"', webpage, u'video url')
+            video_url = self._search_regex(r'var videoUrl = "(.+?)"', webpage, 'video url')
-                                              flags=re.DOTALL)
+            webpage, 'video description', flags=re.DOTALL)
-                            u'Downloading video info'))
+        config = self._download_json(config_url, video_id)
-                }
+        return {
-            u'description': u'md5:5d289b722f5a6d940ca3136e9dae89cf',
+        'url': 'http://gamevideos.1up.com/video/id/34976',
-        result['id'] = id
+        result['id'] = mobj.group('name_or_id')
-    _VALID_URL = r'https?://www\.kickstarter\.com/projects/(?P<id>\d*)/.*'
+    _VALID_URL = r'https?://www\.kickstarter\.com/projects/(?P<id>[^/]*)/.*'
-            u"title": u"Intersection: The Story of Josh Grant by Kyle Cowling",
+        'url': 'https://www.kickstarter.com/projects/1404461844/intersection-the-story-of-josh-grant?ref=home_location',
-        webpage_src = self._download_webpage(url, video_id)
+        webpage = self._download_webpage(url, video_id)
-            webpage_src, u'title').rpartition(u'\u2014 Kickstarter')[0].strip()
+        video_url = self._search_regex(r'data-video-url="(.*?)"',
-        return results
+        return {
-        'file': '614784.mp4',
+            'id': '614784',
-                {'url': f['src'], r'ext': r'mp4', 'tbr': int(f['bitrate'][:-1])})
+                {'url': f['src'], 'ext': 'mp4', 'tbr': int(f['bitrate'][:-1])})
-__version__ = '2014.03.28'
+__version__ = '2014.03.29'
-            u'skip_download': True,
+        'url': 'http://www.bloomberg.com/video/shah-s-presentation-on-foreign-exchange-strategies-qurhIVlJSB6hzkVi229d8g.html',
-        return OoyalaIE._build_url_result(embed_code)
+        f4m_url = self._search_regex(
-    RegexNotFoundError,
+    ExtractorError,
-            return None
+        for pattern in self._VIDEO_ID_REGEXES:
-        video_id = extract(self._VIDEO_ID_REGEXES, 'video id', page, fatal=True)
+        if not mobj:
-    _VALID_URL = r'http://oe1\.orf\.at/programm/(?P<id>\d+)'
+    IE_DESC = 'oe1.orf.at'
-        data = json.loads(self._download_webpage(
+
-        ))
+        )
-            'description': data['item']['info'],
+            'description': data['item'].get('info'),
-__version__ = '2014.03.27.1'
+__version__ = '2014.03.28'
-            help='simulate, quiet but print JSON information', default=False)
+            help='simulate, quiet but print JSON information. See --output for a description of available keys.', default=False)
-    int_or_none,
+    float_or_none,
-            duration = int_or_none(content.attrib.get('duration'))
+            duration = float_or_none(content.attrib.get('duration'))
-            app = apps[puid22] if puid22 in apps else apps['4']
+from .ntv import NTVIE
-    _VALID_URL = r'^https?://(?:www\.)?(?P<url>smotri\.com/video/view/\?id=(?P<videoid>v(?P<realvideoid>[0-9]+)[a-z0-9]{4}))'
+    _VALID_URL = r'^https?://(?:www\.)?(?:smotri\.com/video/view/\?id=|pics\.smotri\.com/(?:player|scrubber_custom8)\.swf\?file=)(?P<videoid>v(?P<realvideoid>[0-9]+)[a-z0-9]{4})'
-            'file': 'v261036632ab.mp4',
+                'id': 'v261036632ab',
-            'file': 'v57591cb20.flv',
+                'id': 'v57591cb20',
-            'file': 'v1390466a13c.mp4',
+                'id': 'v1390466a13c',
-            'file': 'v15408898bcf.flv',
+                'id': 'v15408898bcf',
-        }
+        },
-        video_page_url = 'http://' + mobj.group('url')
+        video_page_url = 'http://smotri.com/video/view/?id=%s' % video_id
-            'view_count': video_view_count,
+            'view_count': int_or_none(video_view_count),
-            video_id = self._search_regex(r'videoId = "(\d+)";', webpage, u'video id')
+            video_id = self._search_regex(r'<canal:player videoId="(\d+)"', webpage, u'video id')
-    _VALID_URL = r'(?:https?://)?(?:www\.)?ehow\.com/[^/_?]*_(?P<id>[0-9]+)'
+    IE_NAME = 'eHow'
-   			u"uploader": u"Erick Nathan"
+        'url': 'http://www.ehow.com/video_12245069_hardwood-flooring-basics.html',
-            webpage, u'uploader')
+            webpage, 'video URL')
-            'thumbnail':   self._og_search_thumbnail(webpage),
+            'id': video_id,
-            'uploader':    uploader,
+            'uploader': uploader,
-                "file": "manofsteel-trailer4.mov",
+                    "id": "manofsteel-trailer4",
-                "file": "manofsteel-trailer3.mov",
+                    "id": "manofsteel-trailer3",
-                "file": "manofsteel-trailer.mov",
+                    "id": "manofsteel-trailer",
-                "file": "manofsteel-teaser.mov",
+                    "id": "manofsteel-teaser",
-            }
+            },
-        playlist_url = compat_urlparse.urljoin(url, u'includes/playlists/itunes.inc')
+        playlist_url = compat_urlparse.urljoin(url, 'includes/playlists/itunes.inc')
-            s = re.sub(r'(?s)<script[^<]*?>.*?</script>', u'', s)
+            s = re.sub(r'(?s)<script[^<]*?>.*?</script>', '', s)
-                return u'iTunes.playURL(%s);' % m.group(1).replace('\'', '&#39;')
+                return 'iTunes.playURL(%s);' % m.group(1).replace('\'', '&#39;')
-            s = u'<html>' + s + u'</html>'
+            s = '<html>' + s + u'</html>'
-                on_click, u'trailer info')
+                on_click, 'trailer info')
-            settings = json.loads(settings_json)
+            settings = self._download_json(settings_json_url, trailer_id, 'Downloading settings json')
-                    'ext': determine_ext(format_url),
+from __future__ import unicode_literals
-    IE_DESC = u'ãã³ãã³åç»'
+    IE_NAME = 'niconico'
-            u'description': u'(c) copyright 2008, Blender Foundation / www.bigbuckbunny.org',
+        'url': 'http://www.nicovideo.jp/watch/sm22312215',
-            u'password': u'youtube-dl',
+        'params': {
-            return False
+            # Login is required
-            u'password': password,
+            'mail': username,
-        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k,v in login_form_strs.items())
+        login_form = dict((k.encode('utf-8'), v.encode('utf-8')) for k, v in login_form_strs.items())
-            u'https://secure.nicovideo.jp/secure/login', login_data)
+            'https://secure.nicovideo.jp/secure/login', login_data)
-            request, u'', note=u'Logging in', errnote=u'Unable to log in')
+            request, None, note='Logging in', errnote='Unable to log in')
-            self._downloader.report_warning(u'unable to log in: bad username or password')
+            self._downloader.report_warning('unable to log in: bad username or password')
-            note=u'Downloading video info page')
+            note='Downloading video info page')
-            video_id, u'Downloading flv info')
+            'http://flapi.nicovideo.jp/api/getflv?v=' + video_id,
-                url, video_id, note=u'Downloading user information')
+                url, video_id, note='Downloading user information')
-            self._downloader.report_warning(u'Unable to download user info webpage: %s' % compat_str(err))
+        except ExtractorError as err:
-            'thumbnail':   video_thumbnail,
+            'id': video_id,
-            'uploader':    video_uploader,
+            'uploader': video_uploader,
-            'view_count':  video_view_count,
+            'view_count': video_view_count,
-    _VALID_URL = r'http://mooshare\.biz/(?P<id>[\da-z]{12})'
+    _VALID_URL = r'http://(?:www\.)?mooshare\.biz/(?P<id>[\da-z]{12})'
-__version__ = '2014.03.27'
+__version__ = '2014.03.27.1'
-            u'duration': 612,
+        'url': 'http://www.clipsyndicate.com/video/play/4629301/brick_briscoe',
-            video_id, u'Downlaoding player')
+            video_id, 'Downlaoding player')
-        flvars = self._search_regex(r'flvars: "(.*?)"', js_player, u'flvars')
+        flvars = self._search_regex(r'flvars: "(.*?)"', js_player, 'flvars')
-            video_id, u'Downloading video info',
+            video_id, 'Downloading video info',
-__version__ = '2014.03.25.1'
+__version__ = '2014.03.27'
-        /(?P<name>\w+) # Here goes the name and then ".html"
+        /(?P<name>[\w-]+) # Here goes the name and then ".html"
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                              extended-interviews/(?P<interID>[0-9]+)/playlist_tds_extended_(?P<interview_title>.*?)/.*?)))
+                              extended-interviews/(?P<interID>[0-9a-z]+)/(?:playlist_tds_extended_)?(?P<interview_title>.*?)(/.*?)?)))
-            altMovieParams = re.findall('data-mgid="([^"]*(?:episode|video).*?:.*?)"', webpage)
+            altMovieParams = re.findall('data-mgid="([^"]*(?:episode|video|playlist).*?:.*?)"', webpage)
-            ydl.add_post_processor(FFmpegAudioFixPP())
+            if not opts.addmetadata:
-        options = ['-c', 'copy']
+        if info['ext'] == u'm4a':
-    FFmpegMediaFixPP,
+    FFmpegAudioFixPP,
-            ydl.add_post_processor(FFmpegMediaFixPP())
+            ydl.add_post_processor(FFmpegAudioFixPP())
-    FFmpegMediaFixPP,
+    FFmpegAudioFixPP,
-    'FFmpegMediaFixPP',
+    'FFmpegAudioFixPP',
-class FFmpegMediaFixPP(FFmpegPostProcessor):
+class FFmpegAudioFixPP(FFmpegPostProcessor):
-        self._downloader.to_screen(u'[ffmpeg] Fixing media file "%s"' % filename)
+        options = ['-vn', '-acodec', 'copy']
-        doc = self._download_xml('http://www.c-span.org/common/services/flashXml.php?programid=' + video_id + '&version=2014-01-23',
+        doc = self._download_xml('http://www.c-span.org/common/services/flashXml.php?programid=' + video_id,
-                process_node(stream, formats)
+        def find_string(s):
-            'title': find_string(doc, 'title'),
+            'title': find_string('title'),
-            'formats': formats,
+            'thumbnail': find_string('poster'),
-            virtual_id = show_name + '-' + epTitle + ' part ' + compat_str(part_num + 1)
+            virtual_id = show_name + ' ' + epTitle + ' part ' + compat_str(part_num + 1)
-            'title': title,
+            'title': show_name + ' ' + title,
-            headers['Referer'] = info_dict['referer']
+        if 'http_referer' in info_dict:
-            'referer': 'http://www.auengine.com/flowplayer/flowplayer.commercial-3.2.14.swf',
+            'http_referer': 'http://www.auengine.com/flowplayer/flowplayer.commercial-3.2.14.swf',
-        'file': 'lfvlytY6.mp4',
+            'id': 'lfvlytY6',
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-                webpage, 'title')
+        title = self._html_search_regex(r'<title>(?P<title>.+?)</title>', webpage, 'title')
-            raise ExtractorError(u'Could not find video URL')
+            raise ExtractorError('Could not find video URL')
-            'title':     title,
+            'id': video_id,
-        doc = self._download_xml('http://www.c-span.org/common/services/flashXml.php?programid=' + video_id,
+        doc = self._download_xml('http://www.c-span.org/common/services/flashXml.php?programid=' + video_id + '&version=2014-01-23',
-            return find_xpath_attr(doc, './/string', 'name', s).text
+        formats = [
-            'url': url,
+            'title': find_string(doc, 'title'),
-            'thumbnail': find_string('poster'),
+            'thumbnail': find_string(doc, 'poster'),
-__version__ = '2014.03.25'
+__version__ = '2014.03.25.1'
-__version__ = '2014.03.24.5'
+__version__ = '2014.03.25'
-
+    int_or_none,
-    IE_DESC = 'The Daily Show / Colbert Report'
+    IE_DESC = 'The Daily Show / The Colbert Report'
-                          (?P<showname>thedailyshow|colbertnation)\.com/
+    _VALID_URL = r'''(?x)^(:(?P<shortname>tds|thedailyshow|cr|colbert|colbertnation|colbertreport)
-                     $"""
+                     $'''
-        'file': '422212.mp4',
+        'url': 'http://thedailyshow.cc.com/watch/thu-december-13-2012/kristen-stewart',
-            "title": "thedailyshow-kristen-stewart part 1"
+            'id': 'ab9ab3e7-5a98-4dbe-8b21-551dc0523d55',
-                url = 'http://www.thedailyshow.com/full-episodes/'
+                url = 'http://thedailyshow.cc.com/full-episodes/'
-                url = 'http://www.colbertnation.com/full-episodes/'
+                url = 'http://thecolbertreport.cc.com/full-episodes/'
-        webpage,htmlHandle = self._download_webpage_handle(url, epTitle)
+        webpage, htmlHandle = self._download_webpage_handle(url, epTitle)
-            epTitle = mobj.group('episode')
+            epTitle = mobj.group('episode').rpartition('/')[-1]
-                                               'Downloading configuration for %s' % shortMediaId)
+        index_url = 'http://%s.cc.com/feeds/mrss?%s' % (show_name, compat_urllib_parse.urlencode({'uri': uri}))
-
+                    'format_id': 'vhttp-%s' % format,
-                    'format_id': format,
+                formats.append({
-                'id': shortMediaId,
+            virtual_id = show_name + '-' + epTitle + ' part ' + compat_str(part_num + 1)
-                'description': compat_str(officialTitle),
+                'uploader': show_name,
-        return results
+        return {
-__version__ = '2014.03.24.4'
+__version__ = '2014.03.24.5'
-        } for q in config.findall('.//quality')]
+        } for q in config.findall('./urls/url')]
-            'ext': 'flv',
+            'formats': formats,
-import json
+        mobj = re.match(self._VALID_URL, url)
-            'url': video_url,
+            'formats': formats,
-from ..utils import ExtractorError
+from ..utils import (
-    IE_NAME = u'clipfish'
+    IE_NAME = 'clipfish'
-            u'duration': 82,
+        'url': 'http://www.clipfish.de/special/game-trailer/video/3966754/fifa-14-e3-2013-trailer/',
-            raise ExtractorError(u'Cannot find video URL in document %r' %
+            raise ExtractorError('Cannot find video URL in document %r' %
-            duration = None
+        duration = parse_duration(doc.find('duration').text)
-        r'(?:(?:(?P<hours>[0-9]+)[:h])?(?P<mins>[0-9]+)[:m])?(?P<secs>[0-9]+)s?$', s)
+        r'(?:(?:(?P<hours>[0-9]+)[:h])?(?P<mins>[0-9]+)[:m])?(?P<secs>[0-9]+)s?(?::[0-9]+)?$', s)
-__version__ = '2014.03.24.3'
+__version__ = '2014.03.24.4'
-        info = json.loads(json_info)
+        info = self._download_json(json_url, video_id)
-    _VALID_URL = r'(?:http://)?videos\.arte\.tv/(?P<lang>fr|de)/.*-(?P<id>.*?)\.html'
+    _VALID_URL = r'http://videos\.arte\.tv/(?P<lang>fr|de)/.*-(?P<id>.*?)\.html'
-        config_xml = self._download_webpage(
+        config = self._download_xml(
-                'ext': 'flv',
+        formats = [{
-    _LIVE_URL = r'index-[0-9]+\.html$'
+class ArteTvIE(InfoExtractor):
-                }
+        }
-            '-bsf:a', 'aac_adtstoasc', tmpfilename]
+        args = [
-__version__ = '2014.03.24.2'
+__version__ = '2014.03.24.3'
-    _VALID_URL = r'https?://.+?\.ooyala\.com/.*?(?:embedCode|ec)=(?P<id>.+?)(&|$)'
+    _VALID_URL = r'(?:ooyala:|https?://.+?\.ooyala\.com/.*?(?:embedCode|ec)=)(?P<id>.+?)(&|$)'
-            u"title": u"One Piece 606"
+        'url': 'http://www.add-anime.net/watch_video.php?v=24MR3YO5SAS9',
-                redir_webpage, u'Redirect form')
+                redir_webpage, 'Redirect form')
-                redir_webpage, u'redirect vc value')
+                redir_webpage, 'redirect vc value')
-                parsed_url.scheme + u'://' + parsed_url.netloc +
+                parsed_url.scheme + '://' + parsed_url.netloc +
-                note=u'Confirming after redirect')
+                note='Confirming after redirect')
-            video_url = self._search_regex(rex, webpage, u'video file URLx',
+            video_url = self._search_regex(rex, webpage, 'video file URLx',
-            raise ExtractorError(u'Cannot find any video format!')
+        self._sort_formats(formats)
-            'id':  video_id,
+            'id': video_id,
-__version__ = '2014.03.24.1'
+__version__ = '2014.03.24.2'
-from ..utils import compat_urllib_request
+from ..utils import (
-            'description': 'At LUMOback, we believe straight backs are stronger.  The LUMOback Posture & Movement Sensor:  It gently vibrates when you slouch, inspiring improved posture and mobility.  Use the app to track your data and improve your posture over time. ',
+    _VALID_URL = r'http://(?:www\.)?veoh\.com/(?:watch|iphone/#_Watch)/(?P<id>(?:v|yapi-)[\da-zA-Z]+)'
-    }
+
-        m_youtube = re.search(r'http://www\.youtube\.com/v/(.*?)(\&|")', webpage)
+        m_youtube = re.search(r'http://www\.youtube\.com/v/(.*?)(\&|"|\?)', webpage)
-        video_url = info.get('fullPreviewHashHighPath') or info.get('fullPreviewHashLowPath')
+        info = json.loads(
-        }
+        video = self._extract_video(info)
-    _VALID_URL = r'http://(?:www\.)?cinemassacre\.com/(?P<date_Y>[0-9]{4})/(?P<date_m>[0-9]{2})/(?P<date_d>[0-9]{2})/.+?'
+    _VALID_URL = r'http://(?:www\.)?cinemassacre\.com/(?P<date_Y>[0-9]{4})/(?P<date_m>[0-9]{2})/(?P<date_d>[0-9]{2})/(?P<display_id>[^?#/]+)'
-            'md5': 'fde81fbafaee331785f58cd6c0d46190',
+            'md5': '782f8504ca95a0eba8fc9177c373eec7',
-            'md5': 'd72f10cd39eac4215048f62ab477a511',
+            'md5': 'dec39ee5118f8d9cc067f45f9cbe3a35',
-        webpage = self._download_webpage(url, None)  # Don't know video id yet
+        webpage = self._download_webpage(url, display_id)
-        video_description = self._html_search_regex(r'<div class="entry-content">(?P<description>.+?)</div>',
+        video_title = self._html_search_regex(
-        hd_url = self._html_search_regex(r'file: \'(?P<hd_file>[^\']+)\', label: \'HD\'', playerdata, 'hd_file')
+        sd_url = self._html_search_regex(r'file: \'([^\']+)\', label: \'SD\'', playerdata, 'sd_file')
-            {
+        formats = [{
-        ]
+                'quality': 2,
-__version__ = '2014.03.24'
+__version__ = '2014.03.24.1'
-__version__ = '2013.03.24.2'
+__version__ = '2014.03.24'
-__version__ = '2013.03.24.1'
+__version__ = '2013.03.24.2'
-__version__ = '2013.03.24'
+__version__ = '2013.03.24.1'
-            result['formats'] = [{
+            formats.append({
-                    })
+                'preference': 10,
-        self.to_screen(u'%s: Resolving id' % video_id)
+        self.to_screen('%s: Resolving id' % video_id)
-                if key.startswith(u'http'):
+                if key.startswith('http'):
-                elif key.startswith(u'rtmp'):
+                elif key.startswith('rtmp'):
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-                self._downloader.report_error(u'unable to download video webpage: %s' % compat_str(err['error_message']))
+                self._downloader.report_error('unable to download video webpage: %s' % compat_str(err['error_message']))
-__version__ = '2014.03.23'
+__version__ = '2013.03.24'
-                    'upload_timestamp': int_or_none(it.get('created_time')),
+                    'timestamp': int_or_none(it.get('created_time')),
-    assert type(s) == type(u'')
+    if s is None:
-    result = re.sub(u'(?u)&(.+?);', htmlentity_transform, s)
+    result = re.sub(r'(?u)&(.+?);', htmlentity_transform, s)
-    IE_NAME = u'radiofrance'
+    IE_NAME = 'radiofrance'
-            u"uploader": u"Thomas HercouÃ«t",
+        'url': 'http://maison.radiofrance.fr/radiovisions/one-one',
-        title = self._html_search_regex(r'<h1>(.*?)</h1>', webpage, u'title')
+        title = self._html_search_regex(r'<h1>(.*?)</h1>', webpage, 'title')
-            webpage, u'description', fatal=False)
+            webpage, 'description', fatal=False)
-            webpage, u'uploader', fatal=False)
+            webpage, 'uploader', fatal=False)
-            webpage, u'audio URLs')
+            webpage, 'audio URLs')
-            re.findall(r"([a-z0-9]+)\s*:\s*'([^']+)'", formats_str)
+            for i, fm in
-        # No sorting, we don't know any more about these formats
+        self._sort_formats(formats)
-                                 by this field.
+                                 by this field, regardless of all other values.
-__version__ = '2014.03.21.5'
+__version__ = '2014.03.23'
-
+from test.helper import (
-                    })
+                self.add_default_extra_info(ie_result, ie, url)
-from .instagram import InstagramIE
+from .instagram import InstagramIE, InstagramUserIE
-from youtube_dl.utils import preferredencoding
+from youtube_dl.utils import (
-    try_rm,
+    expect_info_dict,
-    report_warning
+    try_rm,
-                            u'invalid value for field %s, expected %r, got %r' % (info_field, expected, got))
+
-    buf.value = title.encode('utf-8')
+    title_bytes = title.encode('utf-8')
-        libc.prctl(15, ctypes.byref(buf), 0, 0, 0)
+        libc.prctl(15, buf, 0, 0, 0)
-        "file": "wshh6a7q1ny0G34ZwuIO.mp4",
+            "id": "wshh6a7q1ny0G34ZwuIO",
-            webpage_src, u'video URL')
+        video_url = self._search_regex(
-            webpage_src, u'title')
+        video_title = self._html_search_regex(
-
+        thumbnail = self._html_search_regex(
-        return results
+        return {
-        """Report disclaimer retrieval."""
+
-    _VALID_URL = r'(?:http://)?(?:www\.)?metacafe\.com/watch/([^/]+)/([^/]+)/.*'
+    _VALID_URL = r'http://(?:www\.)?metacafe\.com/watch/([^/]+)/([^/]+)/.*'
-                'title': 'The Electric Company | \"Short I\" | PBS KIDS GO!',
+                'title': 'The Electric Company | "Short I" | PBS KIDS GO!',
-
+        """Report disclaimer retrieval."""
-            'url': 'http://www.metacafe.com/watch/cb-0rOxMBabDXN6/samsung_galaxy_note_2_samsungs_next_generation_phablet/',
+            'url': 'http://www.metacafe.com/watch/cb-8VD4r_Zws8VP/open_this_is_face_the_nation_february_9/',
-                'id': '0rOxMBabDXN6',
+                'id': '8VD4r_Zws8VP',
-                'duration': 129,
+                'title': 'Open: This is Face the Nation, February 9',
-    """Information Extractor for metacafe.com."""
+class MetacafeIE(InfoExtractor):
-    IE_NAME = u'metacafe'
+    IE_NAME = 'metacafe'
-            u'description': u'Sony released a massive FAQ on the PlayStation Blog detailing the PS4\'s capabilities and limitations.',
+        # Youtube video
-            u"description": u"md5:38c711dd98f5bb87acf973d573442e67",
+        # Normal metacafe video
-            u'age_limit': 18,
+        # AnyClip video
-            u'duration': 129,
+        # age-restricted video
-            u'skip_download': True,
+        # cbs video
-        self.to_screen(u'Retrieving disclaimer')
+        self.to_screen('Retrieving disclaimer')
-        self._download_webpage(self._DISCLAIMER, None, False, u'Unable to retrieve disclaimer')
+        self._download_webpage(self._DISCLAIMER, None, False, 'Unable to retrieve disclaimer')
-            }
+        }
-        self._download_webpage(request, None, False, u'Unable to confirm age')
+        self._download_webpage(request, None, False, 'Unable to confirm age')
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-                    raise ExtractorError(u'Unable to extract media URL')
+                    raise ExtractorError('Unable to extract media URL')
-                mobj = re.search(r'"mediaURL":"(?P<mediaURL>http.*?)",(.*?)"key":"(?P<key>.*?)"', vardict['mediaData'][0])
+                    raise ExtractorError('Unable to extract media URL')
-                    raise ExtractorError(u'Unable to extract media URL')
+                    raise ExtractorError('Unable to extract media URL')
-        video_title = self._html_search_regex(r'(?im)<title>(.*) - Video</title>', webpage, u'title')
+        video_title = self._html_search_regex(r'(?im)<title>(.*) - Video</title>', webpage, 'title')
-                webpage, u'uploader nickname', fatal=False)
+                webpage, 'uploader nickname', fatal=False)
-            'url':      video_url,
+            'id': video_id,
-            'title':    video_title,
+            'title': video_title,
-            'ext':      video_ext,
+            'ext': video_ext,
-from .xtube import XTubeIE
+from .xtube import XTubeUserIE, XTubeIE
-        }
+        }
-        video_uploader = self._html_search_regex(r'<b>From: </b>(?:\s|<[^>]*>)*(.+?)<', webpage, 'uploader', fatal=False)
+        video_uploader = self._html_search_regex(
-                'url': url,
+                'url': eurl,
-            } for url in urls]
+            } for eurl in urls]
-                'url': url,
+                'url': furl,
-            } for format_id, url in player_quality_option.items()
+            } for format_id, furl in player_quality_option.items()
-from .toypics import ToypicsIE
+from .toypics import ToypicsUserIE, ToypicsIE
-    _VALID_URL = r'(?:http://)?videos\.toypics\.net/.*'
+    IE_DESC = 'Toypics user profile'
-        #'md5': '8a8b546956bbd0e769dbe28f6e80abb3', == $head -c10K 12929646011616163504.mp4 |md5sum //no idea why it fails
+        'md5': '16e806ad6d6f58079d210fe30985e08b',
-            'age_limit': 18
+            'age_limit': 18,
-        page = self._download_webpage(url, video_id, 'getting page: '+url)
+        mobj = re.match(self._VALID_URL, url)
-            'age_limit': 18
+            'age_limit': 18,
-        '102': {'ext': 'webm', 'height': 720, 'resolution': '720p', 'format_note': '3D', 'preference': -20},
+        '82': {'ext': 'mp4', 'height': 360, 'format_note': '3D', 'preference': -20},
-        '151': {'ext': 'mp4', 'height': 72, 'resolution': '72p', 'format_note': 'HLS', 'preference': -10},
+        '92': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'preference': -10},
-        '264': {'ext': 'mp4', 'height': 1440, 'resolution': '1440p', 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40},
+        '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40},
-        '248': {'ext': 'webm', 'height': 1080, 'resolution': '1080p', 'format_note': 'DASH webm', 'preference': -40},
+        '242': {'ext': 'webm', 'height': 240, 'format_note': 'DASH webm', 'preference': -40},
-                # If checkable fields are missing from the test case, print the info_dict
+                # Are checkable fields missing from the test case definition?
-                if not all(key in tc.get('info_dict', {}).keys() for key in test_info_dict.keys()):
+                missing_keys = set(test_info_dict.keys()) - set(tc.get('info_dict', {}).keys())
-        '160': {'ext': 'mp4', 'height': 192, 'resolution': '192p', 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40},
+        '160': {'ext': 'mp4', 'height': 144, 'resolution': '144p', 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40},
-        description = find_xpath_attr(smil, './/meta', 'name', 'abstract').attrib['content']
+        description_el = find_xpath_attr(smil, './/meta', 'name', 'abstract')
-
+from .toypics import ToypicsIE
-            u'description': u'How badly damaged does a drive have to be to defeat Russell and his crew? Apparently, smashed to bits.',
+        'url': 'http://player.ooyala.com/player.js?embedCode=pxczE2YjpfHfn1f3M-ykG_AmJRRn0PD8',
-                }
+        return {
-                                        player, u'mobile player url')
+                                        player, 'mobile player url')
-        videos_more_info = self._search_regex(r'eval\("\(({.*?\\"promo\\".*?})\)"', mobile_player, u'more info').replace('\\"','"')
+            mobile_player, 'info').replace('\\"','"')
-                    }
+            return {
-        mobj = re.search(r'player.ooyala.com/[^"?]+\?[^"]*?(?:embedCode|ec)=([^"&]+)', webpage)
+        mobj = (re.search(r'player.ooyala.com/[^"?]+\?[^"]*?(?:embedCode|ec)=(?P<ec>[^"&]+)', webpage) or
-            return OoyalaIE._build_url_result(mobj.group(1))
+            return OoyalaIE._build_url_result(mobj.group('ec'))
-import os
+import json
-        format = "-".join(format)
+        player_quality_option = json.loads(self._html_search_regex(
-            'format_id': format,
+            'formats': formats,
-        }
+        }
-__version__ = '2014.03.21.4'
+__version__ = '2014.03.21.5'
-__version__ = '2014.03.21.3'
+__version__ = '2014.03.21.4'
-    IE_NAME = u'daum.net'
+    IE_NAME = 'daum.net'
-            u'duration': 3868,
+        'url': 'http://tvpot.daum.net/clip/ClipView.do?clipid=52554690',
-            webpage, u'full id')
+            webpage, 'full id')
-            u'Downloading video info')
+            'Downloading video info')
-            video_id, u'Downloading video formats info')
+            video_id, 'Downloading video formats info')
-        # For whatever reason, the served vide oalternates between
+        # For whatever reason, the served video alternates between
-__version__ = '2014.03.21.2'
+__version__ = '2014.03.21.3'
-    _VALID_URL = r'http://(?:www\.)?c-span\.org/video/\?(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www\.)?c-span\.org/video/\?(?P<id>[0-9a-f]+)'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-        video_id = self._search_regex(r'data-progid=\'(\d+)\'>', webpage, 'video id')
+        video_id = self._search_regex(r'progid=\'?([0-9]+)\'?>', webpage, 'video id')
-__version__ = '2014.03.21.1'
+__version__ = '2014.03.21.2'
-__version__ = '2014.03.21'
+__version__ = '2014.03.21.1'
-from .extractor import gen_extractors, get_info_extractor
+from ..utils import (
-        age_limit = RATINGS.get(rating_str)
+        age_limit = US_RATINGS.get(rating_str)
-    IE_NAME = u'viki'
+    IE_NAME = 'viki'
-            u'age_limit': 13,
+        'url': 'http://www.viki.com/videos/1023585v-heirs-episode-14',
-        u'skip': u'Blocked in the US',
+        'skip': 'Blocked in the US',
-            u'rating information', default='').strip()
+            'rating information', default='').strip()
-            info_url, video_id, note=u'Downloading info page')
+            info_url, video_id, note='Downloading info page')
-                u'Video %s is blocked from your location.' % video_id,
+                'Video %s is blocked from your location.' % video_id,
-            r'<source[^>]+src="([^"]+)"', info_webpage, u'video URL')
+            r'<source[^>]+src="([^"]+)"', info_webpage, 'video URL')
-            r'"created_at":"([^"]+)"', info_webpage, u'upload date')
+            r'"created_at":"([^"]+)"', info_webpage, 'upload date')
-           video\.pbs\.org/partnerplayer/(?P<player_id>[^/]+)/
+           video\.pbs\.org/(?:widget/)?partnerplayer/(?P<player_id>[^/]+)/
-__version__ = '2014.03.20'
+__version__ = '2014.03.21'
-
+        'prefer_insecure': opts.prefer_insecure,
-            url = 'https://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')
+            url = proto + '://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')
-        url = 'https://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id
+        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id
-            video_info_url = 'https://www.youtube.com/get_video_info?' + data
+            video_info_url = proto + '://www.youtube.com/get_video_info?' + data
-                video_info_url = ('https://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en'
+                video_info_url = (proto + '://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en'
-            'webpage_url': 'https://www.youtube.com/watch?v=%s' % video_id,
+            'webpage_url': proto + '://www.youtube.com/watch?v=%s' % video_id,
-        "file": "1912.mp4",
+            "id": "1912",
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>youporn\.com/watch/(?P<videoid>[0-9]+)/(?P<title>[^/]+))'
+    _VALID_URL = r'^(?P<proto>https?://)(?:www\.)?(?P<url>youporn\.com/watch/(?P<videoid>[0-9]+)/(?P<title>[^/]+))'
-            u"age_limit": 18,
+        'url': 'http://www.youporn.com/watch/505835/sex-ed-is-it-safe-to-masturbate-daily/',
-        url = 'http://www.' + mobj.group('url')
+        url = mobj.group('proto') + 'www.' + mobj.group('url')
-        json_params = self._search_regex(r'var currentVideo = new Video\((.*)\);', webpage, u'JSON parameters')
+        json_params = self._search_regex(r'var currentVideo = new Video\((.*)\);', webpage, 'JSON parameters')
-            webpage, u'download list').strip()
+            webpage, 'download list').strip()
-            format = u'-'.join(format_parts) + u'-' + dn
+            format = '-'.join(format_parts) + '-' + dn
-            'video title')
+        title = self._html_search_regex(
-            webpage)
+        mobj = re.search(
-        view_count = int(view_count) if view_count is not None else None
+        view_count = self._html_search_regex(
-            fatal=False)
+        comment_str = self._html_search_regex(
-                comment_count = int(mobj.group('total'))
+                comment_count = mobj.group('total')
-            'comment_count': comment_count,
+            'view_count': int_or_none(view_count),
-__version__ = '2014.03.18.1'
+__version__ = '2014.03.20'
-            self.report_error('no suitable InfoExtractor: %s' % url)
+            self.report_error('no suitable InfoExtractor for URL %s' % url)
-    _VALID_URL = r'''(?x)http://(?P<type>www|embed)\.ted\.com/
+    _VALID_URL = r'''(?x)
-            return self.url_result(desktop_url, 'TED') # pass the desktop version to the extractor
+        if m.group('type') == 'embed':
-        'file': '050489-002.mp4',
+            'id': '050489-002',
-        'file': '050940-003.mp4',
+            'id': '050940-003',
-    _VALID_URL = r'http?://ddc\.arte\.tv/(?P<lang>emission|folge)/(?P<id>.+)'
+    _VALID_URL = r'https?://ddc\.arte\.tv/(?P<lang>emission|folge)/(?P<id>.+)'
-    _VALID_URL = r'''(?x)http://www\.ted\.com/
+    _VALID_URL = r'''(?x)http://(?P<type>www|embed)\.ted\.com/
-    _VALID_URL = r'https?://www\.arte.tv/guide/(?P<lang>fr|de)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
+    _VALID_URL = r'https?://(?:www\.)?arte\.tv/guide/(?P<lang>fr|de)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
-__version__ = '2014.03.18'
+__version__ = '2014.03.18.1'
-__version__ = '2014.03.17'
+__version__ = '2014.03.18'
-            prompt = prompt.encode(getpreferredencoding())
+            prompt = prompt.encode(preferredencoding())
-import getpass
+    compat_getpass,
-        opts.password = getpass.getpass(u'Type account password and press return:')
+        opts.password = compat_getpass(u'Type account password and press [Return]: ')
-        if re.search(r'NemÃ¡te oprÃ¡vnÄnÃ­ pÅistupovat na tuto strÃ¡nku.\s*</div>', webpage):
+        if re.search(r'NemÃ¡te oprÃ¡vnÄnÃ­ pÅistupovat na tuto strÃ¡nku\.\s*</div>', webpage):
-    _VALID_URL = r'''(?x)https?://(?:www\.)?comedycentral\.com/
+    _VALID_URL = r'''(?x)https?://(?:www\.)?(comedycentral|cc)\.com/
-                                       origin_req_host=req.get_origin_req_host(),
+                                       origin_req_host=origin_req_host,
-__version__ = '2014.03.12'
+__version__ = '2014.03.17'
-def get_testcases():
+def gettestcases():
-from test.helper import get_testcases
+from test.helper import gettestcases
-        for tc in get_testcases():
+        for tc in gettestcases():
-    get_testcases,
+    gettestcases,
-defs = get_testcases()
+defs = gettestcases()
-            }
+            },
-    _VALID_URL = r'http://(?:.+?\.)?(?:vesti\.ru|russia2?\.tv|tvkultura\.ru|rutv\.ru)/(?P<id>.+)'
+class RUTVIE(InfoExtractor):
-            'url': 'http://www.vesti.ru/videos?vid=575582&cid=1',
+            'url': 'http://player.rutv.ru/flash2v/container.swf?id=774471&sid=kultura&fbv=true&isPlay=true&ssl=false&i=560&acc_video_id=episode_id/972347/video_id/978186/brand_id/31724',
-                'id': '773865',
+                'id': '774471',
-                'duration': 210,
+                'title': 'ÐÐ¾Ð½Ð¾Ð»Ð¾Ð³Ð¸ Ð½Ð° Ð²ÑÐµ Ð²ÑÐµÐ¼ÐµÐ½Ð°',
-            'url': 'http://www.vesti.ru/only_video.html?vid=576180',
+            'url': 'https://player.vgtrk.com/flash2v/container.swf?id=774016&sid=russiatv&fbv=true&isPlay=true&ssl=false&i=560&acc_video_id=episode_id/972098/video_id/977760/brand_id/57638',
-                'id': '766048',
+                'id': '774016',
-                'duration': 87,
+                'title': 'Ð§ÑÐ¶Ð¾Ð¹ Ð² ÑÐµÐ¼ÑÐµ Ð¡ÑÐ°Ð»Ð¸Ð½Ð°',
-            'url': 'http://hitech.vesti.ru/news/view/id/4000',
+            'url': 'http://player.rutv.ru/iframe/swf/id/766888/sid/hitech/?acc_video_id=4000',
-            'url': 'http://sochi2014.vesti.ru/video/index/video_id/766403',
+            'url': 'http://player.rutv.ru/iframe/video/id/771852/start_zoom/true/showZoomBtn/false/sid/russiatv/?acc_video_id=episode_id/970443/video_id/975648/brand_id/5169',
-                'id': '766403',
+                'id': '771852',
-                'duration': 271,
+                'title': 'ÐÑÑÐ¼Ð¾Ð¹ ÑÑÐ¸Ñ. ÐÐµÑÑÐ²Ñ Ð·Ð°Ð³Ð°Ð´Ð¾ÑÐ½Ð¾Ð¹ Ð±Ð¾Ð»ÐµÐ·Ð½Ð¸: ÑÐ¼ÐµÑÑÑ Ð¾Ñ ÑÑÐ°ÑÐ¾ÑÑÐ¸ Ð² 17 Ð»ÐµÑ',
-            'url': 'http://sochi2014.vesti.ru/live/play/live_id/301',
+            'url': 'http://player.rutv.ru/iframe/live/id/51499/showZoomBtn/false/isPlay/true/sid/sochi2014',
-            },
+            'skip': 'Translation has finished',
-
+    @classmethod
-            page)
+            r'<iframe[^>]+?src=(["\'])(?P<url>https?://player\.rutv\.ru/iframe/(?:swf|video|live)/id/.+?)\1', webpage)
-                'Downloading video page')
+            return mobj.group('url')
-            r'<meta property="og:video" content="http://player\.rutv\.ru/flash2v/container\.swf\?id=(?P<id>\d+)', page)
+            r'<meta[^>]+?property=(["\'])og:video\1[^>]+?content=(["\'])(?P<url>http://player\.(?:rutv\.ru|vgtrk\.com)/flash2v/container\.swf\?id=.+?\2)',
-                page)
+            return mobj.group('url')
-                raise ExtractorError('No media found', expected=True)
+    def _real_extract(self, url):
-            video_id = mobj.group('id')
+        if not video_type or video_type == 'swf':
-            raise ExtractorError('vesti returned error: %s' % json_data['errors'], expected=True)
+            raise ExtractorError('%s said: %s' % (self.IE_NAME, json_data['errors']), expected=True)
-            raise ExtractorError('vesti returned error: %s' % media['errors'], expected=True)
+            raise ExtractorError('%s said: %s' % (self.IE_NAME, media['errors']), expected=True)
-            'thumbnail': talk_info['thumb'],
+            'thumbnail': thumbnail,
-    _TEST = {
+    _TESTS = [{
-    }
+    }]
-            'timestamp': 1372057200,
+            # timestamp and upload_date are often incorrect; seem to change randomly
-            'timestamp': 1392796919,
+            'timestamp': int,
-            # timestamp and upload_date are often incorrect; seem to change randomly
+# -*- coding: utf-8 -*-
-            r'<iframe[^>]+?src="((?:https?:)?//player\.vimeo\.com/video/.+?)"', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//player\.vimeo\.com/video/.+?)\1', webpage)
-            player_url = unescapeHTML(mobj.group(1))
+            player_url = unescapeHTML(mobj.group('url'))
-from ..utils import compat_urllib_request
+from ..utils import (
-            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported. You can also use the special names "best", "bestaudio", "worst", and "worstaudio". By default, youtube-dl will pick the best quality.')
+            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported. You can also use the special names "best", "bestvideo", "bestaudio", "worst", "worstvideo" and "worstaudio". By default, youtube-dl will pick the best quality.')
-        '264': {'ext': 'mp4', 'height': 1440, 'resolution': '1440p', 'format_note': 'DASH video', 'preference': -40},
+        '133': {'ext': 'mp4', 'height': 240, 'resolution': '240p', 'format_note': 'DASH video', 'acodec': 'none', 'preference': -40},
-        '219': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'VP8', 'acodec': 'none', 'preference': -40},
+        '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'acodec': 'none', 'container': 'webm', 'vcodec': 'VP8', 'acodec': 'none', 'preference': -40},
-            'timestamp': 1372906800,
+            # timestamp and upload_date are often incorrect; seem to change randomly
-                    if value and key in ('title', 'description', 'uploader', 'upload_date', 'uploader_id', 'location'))
+                    if value and key in ('title', 'description', 'uploader', 'upload_date', 'timestamp', 'uploader_id', 'location'))
-        if info_dict.get('upload_date') is None and info_dict.get('upload_timestamp') is not None:
+        if info_dict.get('upload_date') is None and info_dict.get('timestamp') is not None:
-                info_dict['upload_timestamp'])
+                info_dict['timestamp'])
-    upload_timestamp:UNIX timestamp of the upload moment.
+    timestamp:      UNIX timestamp of the moment the video became available.
-                    If not explicitly set, calculated from update_timestamp.
+                    If not explicitly set, calculated from timestamp.
-            'upload_timestamp': 1372906800,
+            'timestamp': 1372906800,
-            'upload_timestamp': timestamp_ms // 1000,
+            'timestamp': timestamp_ms // 1000,
-
+
-        title = self._og_search_title(page, default='VideoBam', fatal=False)
+        title = self._og_search_title(page, default='_', fatal=False)
-        self.assertTrue(len(result['entries']) == 15)
+        self.assertEqual(len(result['entries']), 15)
-            if (len(entries) >= n) or not re.search(r'class="pn" id="pnnext"', webpage):
+            if (len(entries) >= n) or not re.search(r'id="pnnext"', webpage):
-            "title": "\"People Are Awesome 2013\" Is Absolutely Awesome"
+            "title": "\"People Are Awesome 2013\" Is Absolutely Awesome",
-        data = json.loads(data_json)
+        youtube_id = self._html_search_regex(
-            'url': data['youtubeVideoId'],
+            'url': youtube_id,
-            'thumbnail': data['thumbnail_url'],
+            'title': self._og_search_title(webpage),
-            'upload_date': '20130703',
+            'upload_date': '20130704',
-        upload_date = datetime.datetime.utcfromtimestamp(timestamp_ms // 1000)
+
-            'upload_date': upload_date.strftime('%Y%m%d'),
+            'upload_timestamp': timestamp_ms // 1000,
-    _VALID_URL = r"^https?://(?:www\.)?br\.de/mediathek/video/(?:sendungen/)?(?P<id>[a-z0-9\-]+)\.html$"
+    _VALID_URL = r"^https?://(?:www\.)?br\.de/mediathek/video/(?:sendungen/)?(?:[a-z0-9\-/]+/)?(?P<id>[a-z0-9\-]+)\.html$"
-            "upload_date": "20140301"
+    _TESTS = [
-    }
+    ]
-        } for xml_video in xml.findall("video")]
+        videos = []
-            post = json.loads(post_json)['attachment']
+            post = json.loads(post_json)
-            'description': 'This video wasn\'t long enough,',
+            'description': "This video wasn't long enough, so we made it double-spaced.",
-            'description': 'Fans get creative this year',
+            'description': "Fans get creative this year at San Diego.  Too creative.  And yes, that's really Joss Whedon.",
-__version__ = '2014.03.11'
+__version__ = '2014.03.12'
-    _VALID_URL = r'(?:https?://)?vimeo\.com/channels/(?P<id>[^/]+)'
+    _VALID_URL = r'(?:https?://)?vimeo\.com/channels/(?P<id>[^/]+)/?(\?.*)?$'
-__version__ = '2014.03.10'
+__version__ = '2014.03.11'
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?funnyordie\.com/videos/(?P<id>[0-9a-f]+)/.*$'
+    _VALID_URL = r'https?://(?:www\.)?funnyordie\.com/(?P<type>embed|videos)/(?P<id>[0-9a-f]+)(?:$|[?#/])'
-            'description': self._og_search_description(webpage),
+            'title': title,
-        for (i, format) in enumerate(formats):
+        for i, format in enumerate(formats):
-    _VALID_URL = r'^(?:https?://)?www\.playvid\.com/watch(\?v=|/)(?P<id>.+?)(#|$)'
+class PlayvidIE(InfoExtractor):
-        'file': 'agbDDi7WZTV.mp4',
+            'id': 'agbDDi7WZTV',
-                    val = videovars_match.group(2)
+        flashvars = self._html_search_regex(
-                        video_thumbnail = val
+        infos = compat_urllib_parse.unquote(flashvars).split(r'&')
-                        })
+                if key == 'title':
-            raise ExtractorError,'no video url found'
+                videourl_match = re.match(
-        return self._opener.open(req)
+        return self._opener.open(req, timeout=self._socket_timeout)
-        timeout = 600 if timeout_val is None else float(timeout_val)
+        self._socket_timeout = 600 if timeout_val is None else float(timeout_val)
-from .vesti import VestiIE
+from .vgtrk import VGTRKIE
-    _VALID_URL = r'http://(?:.+?\.)?(?:vesti\.ru|russia\.tv|tvkultura\.ru|rutv\.ru)/(?P<id>.+)'
+class VGTRKIE(InfoExtractor):
-    _VALID_URL = r'http://(?:(?:.+?\.)?vesti\.ru|(?:2\.)?russia\.tv|tvkultura\.ru|rutv\.ru)/(?P<id>.+)'
+    _VALID_URL = r'http://(?:.+?\.)?(?:vesti\.ru|russia\.tv|tvkultura\.ru|rutv\.ru)/(?P<id>.+)'
-            'upload_date': '20130704',
+            'upload_date': '20130703',
-import xml.etree.ElementTree
+    parse_xml,
-            doc = xml.etree.ElementTree.fromstring(webpage.encode('utf-8'))
+            doc = parse_xml(webpage)
-            'skip': 'Blocked outside Russia'
+            'skip': 'Blocked outside Russia',
-            mobj = re.search(r';ytplayer.config = ({.*?});', video_webpage)
+            mobj = re.search(r';ytplayer\.config\s*=\s*({.*?});', video_webpage)
-            ytplayer_config = json.loads(mobj.group(1))
+            json_code = uppercase_escape(mobj.group(1))
-        upload_date = datetime.datetime.fromtimestamp(timestamp_ms // 1000)
+        upload_date = datetime.datetime.utcfromtimestamp(timestamp_ms // 1000)
-__version__ = '2014.03.07.1'
+__version__ = '2014.03.10'
-        result = ie.extract('http://www.escapistmagazine.com/rss/videos/list/1.xml')
+        result = ie.extract('http://phihag.de/2014/youtube-dl/rss.xml')
-        self.assertEqual(result['id'], 'http://www.escapistmagazine.com/rss/videos/list/1.xml')
+        self.assertEqual(result['id'], 'http://phihag.de/2014/youtube-dl/rss.xml')
-        u'info_dict': {
+        'url': 'http://media.photobucket.com/user/rachaneronas/media/TiredofLinkBuildingTryBacklinkMyDomaincom_zpsc0c3b9fa.mp4.html?filters[term]=search&filters[primary]=videos&filters[secondary]=images&sort=1&o=0',
-            'title': info[u'title'],
+            'url': info['downloadUrl'],
-            'thumbnail': info[u'thumbUrl'],
+            'thumbnail': info['thumbUrl'],
-    _VALID_URL = r'http://(?:.+?\.)?(?:vesti\.ru|russia\.tv)/(?P<id>.+)'
+    _VALID_URL = r'http://(?:(?:.+?\.)?vesti\.ru|(?:2\.)?russia\.tv|tvkultura\.ru|rutv\.ru)/(?P<id>.+)'
-            'url': 'http://sochi2014.vesti.ru/video/index/video_id/766403',
+            'url': 'http://2.russia.tv/video/show/brand_id/48863/episode_id/972920/video_id/978667/viewtype/picture',
-                'id': '766403',
+                'id': '775081',
-                'duration': 271,
+                'title': 'XXII Ð·Ð¸Ð¼Ð½Ð¸Ðµ ÐÐ»Ð¸Ð¼Ð¿Ð¸Ð¹ÑÐºÐ¸Ðµ Ð¸Ð³ÑÑ. Ð Ð¾ÑÑÐ¸ÑÐ½Ðµ Ð·Ð°Ð½ÑÐ»Ð¸ Ð²ÐµÑÑ Ð¿ÑÐµÐ´ÐµÑÑÐ°Ð» Ð² Ð»ÑÐ¶Ð½ÑÑ Ð³Ð¾Ð½ÐºÐ°Ñ',
-            'url': 'http://sochi2014.vesti.ru/live/play/live_id/301',
+            'url': 'http://tvkultura.ru/video/show/brand_id/31724/episode_id/972347/video_id/978186',
-                'description': 'md5:9e0ed5c9d2fa1efbfdfed90c9a6d179c',
+                'id': '774471',
-                # rtmp download
+                # m3u8 download
-        }
+        },
-                    res = '%sp' % template_dict['height']
+                    template_dict['resolution'] = '%sp' % template_dict['height']
-                    res = '?x%d' % template_dict['width']
+                    template_dict['resolution'] = '?x%d' % template_dict['width']
-    _VALID_URL = r'^http://tv\.aftonbladet\.se/webbtv.+(?P<video_id>article\d+)\.ab$'
+    _VALID_URL = r'^http://tv\.aftonbladet\.se/webbtv.+?(?P<video_id>article[0-9]+)\.ab(?:$|[?#])'
-        internal_meta_id = self._html_search_regex(r'data-aptomaId="([\w\d]+)"', webpage, 'internal_meta_id')
+        internal_meta_id = self._html_search_regex(
-        internal_meta_json = self._download_json(internal_meta_url, video_id, 'Downloading video meta data')
+        internal_meta_json = self._download_json(
-        internal_formats_json = self._download_json(internal_formats_url, video_id, 'Downloading video formats')
+        internal_formats_json = self._download_json(
-        for fmt in reversed(internal_formats_json['formats']['http']['pseudostreaming']['mp4']):
+        for fmt in internal_formats_json['formats']['http']['pseudostreaming']['mp4']:
-        return [{
+        return {
-        }]
+        }
-    IE_NAME = u'photobucket'
+    _VALID_URL = r'http://(?:[a-z0-9]+\.)?photobucket\.com/.*(([\?\&]current=)|_)(?P<id>.*)\.(?P<ext>(flv)|(mp4))'
-            u"title": u"Tired of Link Building? Try BacklinkMyDomain.com!"
+            'upload_date': '20130504',
-        }]
+        info_json = self._search_regex(r'Pb\.Data\.Shared\.put\(Pb\.Data\.Shared\.MEDIA, (.*?)\);',
-            password = compat_urllib_request.unquote(self._html_search_regex(r'"video_title":"([^"]+)', webpage, 'password').replace('+', ' '))
+            password = compat_urllib_parse.unquote_plus(self._html_search_regex(r'"video_title":"([^"]+)', webpage, 'password'))
-    IE_NAME = u'myvideo'
+    _VALID_URL = r'http://(?:www\.)?myvideo\.de/(?:[^/]+/)?watch/(?P<id>[0-9]+)/[^?/]+.*'
-            u"title": u"bowling-fail-or-win"
+        'url': 'http://www.myvideo.de/watch/8229274/bowling_fail_or_win',
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-            video_ext = self._search_regex('[.](.+?)$', video_url, u'extension')
+                webpage, 'title')
-            }]
+            return {
-                                              u'Downloading video info')
+                                              'Downloading video info')
-                    }
+            return {
-            raise ExtractorError(u'Unable to extract video')
+            raise ExtractorError('Unable to extract video')
-            self._downloader.report_warning(u'avoiding MTV player')
+            self._downloader.report_warning('avoiding MTV player')
-                    u'Rewriting URL to use unencrypted rtmp:// ...',
+                    'Rewriting URL to use unencrypted rtmp:// ...',
-                raise ExtractorError(u'unable to extract url')
+                raise ExtractorError('unable to extract url')
-        video_file = self._search_regex('source=\'(.*?)\'', dec_data, u'video file')
+        video_file = self._search_regex('source=\'(.*?)\'', dec_data, 'video file')
-        video_swfobj = self._search_regex('swfobject.embedSWF\(\'(.+?)\'', webpage, u'swfobj')
+        video_swfobj = self._search_regex('swfobject.embedSWF\(\'(.+?)\'', webpage, 'swfobj')
-        }]
+            webpage, 'title')
-        (?:https?://)?(?:\w+\.)?facebook\.com/
+        https?://(?:\w+\.)?facebook\.com/
-            'title': 'PEOPLE ARE AWESOME 2013'
+            'title': 'PEOPLE ARE AWESOME 2013',
-        info = {
+        return {
-            'thumbnail': thumbnail,
+            'duration': int(video_data['video_duration']),
-# coding: utf-8
+from __future__ import unicode_literals
-    _IS_YOUTUBE = r'config":{"file":"(?P<youtube_url>http:[\\][/][\\][/]www[.]youtube[.]com[\\][/]watch[?]v=[^"]+)"'
+    _TEST = {
-        iframe_url = unescapeHTML(mobj.group('iframe'))
+        iframe_url = unescapeHTML(self._search_regex(r'<iframe .*src="([^"]*)"', html, 'iframe url'))
-            raise ExtractorError(u'Video is not available(in your country?)!')
+        if re.search(r'class="jkb_waiting"', iframe_html) is not None:
-                 }]
+        try:
-    VIDEO_THUMB_RE = r'url_bigthumb=(.*?)&amp;'
+    _VALID_URL = r'^https?://(?:video|www)\.xnxx\.com/video(?P<id>[0-9]+)/(.*)'
-            u"age_limit": 18,
+        'url': 'http://video.xnxx.com/video1135332/lida_naked_funny_actress_5_',
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-            webpage, u'video URL')
+        video_url = self._search_regex(r'flv_url=(.*?)&amp;',
-            webpage, u'title')
+        video_title = self._html_search_regex(r'<title>(.*?)\s+-\s+XNXX.COM',
-            webpage, u'thumbnail', fatal=False)
+        video_thumbnail = self._search_regex(r'url_bigthumb=(.*?)&amp;',
-        return [{
+        return {
-        }]
+        }
-            password = self._html_search_regex(r'"video_title":"([^"]+)', webpage, 'password').replace('+', ' ')
+            password = compat_urllib_request.unquote(self._html_search_regex(r'"video_title":"([^"]+)', webpage, 'password').replace('+', ' '))
-            _msg_header = '\033[0;33mWARNING:\033[0m'
+        if self.params.get('logger') is not None:
-        self.to_stderr(warning_message)
+            if self._err_file.isatty() and os.name != 'nt':
-)
+from ..utils import compat_urlparse
-            u'duration': 135,
+        'url': 'http://www.videodetective.com/movies/kick-ass-2/194487',
-            ie=InternetVideoArchiveIE.ie_key())
+        return self.url_result(InternetVideoArchiveIE._build_url(query), ie=InternetVideoArchiveIE.ie_key())
-        'md5': 'f81dcf6d0448e3291f54380181695821',
+        'md5': 'db7aba89d4603dadd627e9d1973946fe',
-        }
+        }
-        self.assertTrue(len(result['entries']) >= 11)
+        self.assertTrue(len(result['entries']) >= 6)
-        u'file': u'20130811.mp4',
+        'url': 'http://www.gamekings.tv/videos/phoenix-wright-ace-attorney-dual-destinies-review/',
-        #u'md5': u'2f32b1f7b80fdc5cb616efb4f387f8a3',
+        # 'md5': '2f32b1f7b80fdc5cb616efb4f387f8a3',
-            u"description": u"Melle en Steven hebben voor de review een week in de rechtbank doorbracht met Phoenix Wright: Ace Attorney - Dual Destinies.",
+            'id': '20130811',
-        return [{'url': url,'ext': 'mp4',}]
+        metrics_url = unescapeHTML(self._search_regex(r'<a href="(http://metrics.+?)"', webpage, 'url'))
-                    'available from your country, trying with the mobile version')
+                self.to_screen('The normal version is not available from your '
-        'url': 'http://www.collegehumor.com/embed/6950457',
+        'url': 'http://www.collegehumor.com/embed/6950306',
-            'id': 'W5gMp3ZjYg4',
+            'id': 'Z-bao9fg6Yc',
-            'upload_date': '20140128',
+            'title': 'Young Americans Think President John F. Kennedy Died THIS MORNING IN A CAR ACCIDENT!!!',
-    _VALID_URL = r'https?://www\.spike\.com/(video-clips|episodes)/.+'
+    _VALID_URL = r'''(?x)https?://
-    def _extract_video_formats(self, mdoc):
+    def _extract_mobile_video_formats(self, mtvn_id):
-            'formats': self._extract_video_formats(mediagen_doc),
+            'formats': self._extract_video_formats(mediagen_doc, mtvn_id),
-            raise ExtractorError('This video is not available from your country.', expected=True)
+        if re.match(r'.*/(error_country_block\.swf|geoblock\.mp4)$', mdoc.find('.//src').text) is not None:
-            raise ExtractorError(u'Arte live streams are not yet supported, sorry')
+            raise ExtractorError('Arte live streams are not yet supported, sorry')
-        ref_xml_doc = self._download_xml(ref_xml_url, video_id, note=u'Downloading metadata')
+        ref_xml_doc = self._download_xml(
-        config_xml = self._download_webpage(config_xml_url, video_id, note=u'Downloading configuration')
+        config_xml = self._download_webpage(
-        webpage = self._download_webpage(request, video_id)
+        try:
-                        uf = compat_urllib_request.urlopen(info_dict['thumbnail'])
+                        uf = self.urlopen(info_dict['thumbnail'])
-                data = compat_urllib_request.urlopen(request)
+                data = self.ydl.urlopen(request)
-                        data = compat_urllib_request.urlopen(basic_request)
+                        data = self.ydl.urlopen(basic_request)
-        'file': '114408.mp4',
+            'id': '114408',
-                                      video_id, 'Downloading video JSON')
+        page = self._download_webpage('http://www.lynda.com/ajax/player?videoId=%s&type=video' % video_id, video_id,
-            raise ExtractorError('Video %s is only available for members. ' % video_id + self.ACCOUNT_CREDENTIALS_HINT, expected=True)
+            raise ExtractorError(
-        video_id = video_json['ID']
+        video_id = compat_str(video_json['ID'])
-        login_page = self._download_webpage(request, None, note='Logging in as %s' % username)
+        login_page = self._download_webpage(request, None, 'Logging in as %s' % username)
-                login_page = self._download_webpage(request, None, note='Confirming log in and log out from another device')
+                login_page = self._download_webpage(request, None, 'Confirming log in and log out from another device')
-        sub = self._download_webpage(url, None, note=False)
+        sub = self._download_webpage(url, None, False)
-__version__ = '2014.03.07'
+__version__ = '2014.03.07.1'
-        login_page = self._download_webpage(login_page_req, None, note=False,
+        login_page = self._download_webpage(login_page_req, None,
-        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
+        request = compat_urllib_request.Request(self._LOGIN_URL, urlencode_postdata(login_form))
-            login_results = compat_urllib_request.urlopen(request).read()
+            login_results = self._download_webpage(request, None,
-                'fb_dtsg': self._search_regex(r'"fb_dtsg":"(.*?)"', login_results, 'fb_dtsg'),
+                'fb_dtsg': self._search_regex(r'name="fb_dtsg" value="(.+?)"', login_results, 'fb_dtsg'),
-                'submit[Continue]': self._search_regex(r'<input value="(.*?)" name="submit\[Continue\]"', login_results, 'continue'),
+                'submit[Continue]': self._search_regex(r'<button[^>]+value="(.*?)"[^>]+name="submit\[Continue\]"', login_results, 'continue'),
-            check_req = compat_urllib_request.Request(self._CHECKPOINT_URL, compat_urllib_parse.urlencode(check_form))
+            check_req = compat_urllib_request.Request(self._CHECKPOINT_URL, urlencode_postdata(check_form))
-            check_response = compat_urllib_request.urlopen(check_req).read()
+            check_response = self._download_webpage(check_req, None,
-__version__ = '2014.03.06'
+__version__ = '2014.03.07'
-    ExtractorError
+    ExtractorError,
-    _SUCCESSFUL_LOGIN_REGEX = r'<a href="https://www.lynda.com/home/userAccount/ChangeContactInfo.aspx" data-qa="eyebrow_account_menu">My account'
+    _SUCCESSFUL_LOGIN_REGEX = r'isLoggedIn: true'
-        formats = [{'url': fmt['Url'],
+        formats = []
-                    } for fmt in video_json['Formats']]
+                } for fmt in fmts])
-__version__ = '2014.03.04.2'
+__version__ = '2014.03.06'
-    _VALID_URL = r'http://(?:.+?\.)?vesti\.ru/(?P<id>.+)'
+    _VALID_URL = r'http://(?:.+?\.)?(?:vesti\.ru|russia\.tv)/(?P<id>.+)'
-        mobj = re.search(r'<meta property="og:video" content=".+?\.swf\?v?id=(?P<id>\d+).*?" />', page)
+        mobj = re.search(
-                r'<iframe.+?src="http://player\.rutv\.ru/iframe/(?P<type>[^/]+)/id/(?P<id>\d+)[^"]*".*?></iframe>', page)
+                r'<iframe.+?src="http://player\.rutv\.ru/iframe/(?P<type>[^/]+)/id/(?P<id>\d+)[^"]*".*?></iframe>',
-                raise ExtractorError('No media found')
+                raise ExtractorError('No media found', expected=True)
-        args = basic_args + [[], ['--resume', '--skip', '1']][self.params.get('continuedl', False)]
+        args = basic_args + [[], ['--resume', '--skip', '1']][not live and self.params.get('continuedl', False)]
-        while (retval == RD_INCOMPLETE or retval == RD_FAILED) and not test:
+        while (retval == RD_INCOMPLETE or retval == RD_FAILED) and not test and not live:
-                line = u''
+                line = ''
-                    data_len_str = u'~' + format_bytes(data_len)
+                    data_len_str = '~' + format_bytes(data_len)
-                            self.to_screen(u'')
+                            self.to_screen('')
-                        self.to_screen(u'[rtmpdump] '+line)
+                        self.to_screen('[rtmpdump] '+line)
-                self.to_screen(u'')
+                self.to_screen('')
-            self.report_error(u'RTMP download detected but "rtmpdump" could not be run')
+            self.report_error('RTMP download detected but "rtmpdump" could not be run')
-            self.to_screen(u'[debug] rtmpdump command line: ' + shell_quote(str_args))
+            self.to_screen('[debug] rtmpdump command line: ' + shell_quote(str_args))
-            self.report_error(u'[rtmpdump] Could not connect to RTMP server.')
+            self.report_error('[rtmpdump] Could not connect to RTMP server.')
-            self.to_screen(u'[rtmpdump] %s bytes' % prevsize)
+            self.to_screen('[rtmpdump] %s bytes' % prevsize)
-                self.to_screen(u'[rtmpdump] Could not download the whole video. This can happen for some advertisements.')
+                self.to_screen('[rtmpdump] Could not download the whole video. This can happen for some advertisements.')
-            self.to_screen(u'[rtmpdump] %s bytes' % fsize)
+            self.to_screen('[rtmpdump] %s bytes' % fsize)
-            self.report_error(u'rtmpdump exited with code %d' % retval)
+            self.to_stderr('\n')
-            self.to_screen(u'[rtmpdump] Could not connect to RTMP server.')
+            self.report_error(u'[rtmpdump] Could not connect to RTMP server.')
-        while (retval == RD_INCOMPLETE or retval == RD_ FAILED) and not test:
+        while (retval == RD_INCOMPLETE or retval == RD_FAILED) and not test:
-        while (retval == 2 or retval == 1) and not test:
+        while (retval == RD_INCOMPLETE or retval == RD_ FAILED) and not test:
-            retval = run_rtmpdump(basic_args + ['-e'] + [[], ['-k', '1']][retval == 1])
+            retval = run_rtmpdump(basic_args + ['-e'] + [[], ['-k', '1']][retval == RD_FAILED])
-            if prevsize == cursize and retval == 1:
+            if prevsize == cursize and retval == RD_FAILED:
-            if prevsize == cursize and retval == 2 and cursize > 1024:
+            if prevsize == cursize and retval == RD_INCOMPLETE and cursize > 1024:
-                retval = 0
+                retval = RD_SUCCESS
-        if retval == 0 or (test and retval == 2):
+        if retval == RD_SUCCESS or (test and retval == RD_INCOMPLETE):
-        'file': '102.mp4',
+            'id': '102',
-        video_id = talk_info['id']
+        video_id = compat_str(talk_info['id'])
-        video_id = os.path.splitext(url.split('/')[-1])[0]
+        video_id = os.path.splitext(url.rstrip('/').split('/')[-1])[0]
-                   '''
+    _VALID_URL = r'''(?x)http://www\.ted\.com/
-            'description': 'Philosopher Dan Dennett makes a compelling argument that not only don\'t we understand our own consciousness, but that half the time our brains are actively fooling us.',
+            'description': ('Philosopher Dan Dennett makes a compelling '
-        info_json = self._search_regex(r'q\("\w+.init",({.+})\)</script>', webpage, 'info json')
+        info_json = self._search_regex(r'q\("\w+.init",({.+})\)</script>',
-        m=re.match(self._VALID_URL, url, re.VERBOSE)
+        m = re.match(self._VALID_URL, url, re.VERBOSE)
-            name=m.group('name')
+            return self._talk_info(url, name)
-        webpage = self._download_webpage(url, video_id, 'Downloading \"%s\" page' % video_name)
+    def _talk_info(self, url, video_name):
-                        ((?P<type_playlist>playlists)/(?P<playlist_id>\d+)) # We have a playlist
+                        (?P<type_playlist>playlists(?:/\d+)?) # We have a playlist
-            return [self._playlist_videos_info(url,name,playlist_id)]
+            return self._playlist_videos_info(url, name)
-    def _playlist_videos_info(self, url, name, playlist_id):
+    def _playlist_videos_info(self, url, name):
-                                                 webpage, 'playlist title')
+        webpage = self._download_webpage(url, name,
-            for m in matches
+            self.url_result(u'http://www.ted.com/talks/' + talk['slug'], self.ie_key())
-            playlist_entries, playlist_id=playlist_id, playlist_title=playlist_title)
+            playlist_entries,
-        talk_info = info['talks'][0]
+        talk_info = self._extract_info(webpage)['talks'][0]
-            'url': 'http://www.prosiebenmaxx.de/yep/one-piece/video/148-folge-48-gold-rogers-heimat-ganze-folge',
+            'url': 'http://www.prosiebenmaxx.de/tv/experience/video/144-countdown-fuer-die-autowerkstatt-ganze-folge',
-                'id': '2437108',
+                'id': '2429369',
-                'duration': 1401.48,
+                'title': 'Countdown fÃ¼r die Autowerkstatt',
-                    width, height = m_size.group(1), m_size.group(2)
+                    width, height = map(int_or_none, (m_size.group(1), m_size.group(2)))
-    _VALID_URL=r'''http://www\.ted\.com/
+    _VALID_URL=r'''(?x)http://www\.ted\.com/
-            "title": "Dan Dennett: The illusion of consciousness"
+            'title': 'The illusion of consciousness',
-        return re.match(cls._VALID_URL, url, re.VERBOSE) is not None
+    _FORMATS_PREFERENCE = {
-        m = re.match(self._VALID_URL, url,re.VERBOSE)
+        m = re.match(self._VALID_URL, url)
-        video_id = info['id']
+        info_json = self._search_regex(r'"talkPage.init",({.+})\)</script>', webpage, 'info json')
-        video_subtitles = self.extract_subtitles(video_id, webpage)
+        video_subtitles = self.extract_subtitles(video_id, talk_info)
-            self._list_available_subtitles(video_id, webpage)
+            self._list_available_subtitles(video_id, talk_info)
-            'description': desc,
+            'title': talk_info['title'],
-        except RegexNotFoundError:
+    def _get_available_subtitles(self, video_id, talk_info):
-        return {}
+            return {}
-__version__ = '2014.03.04.1'
+__version__ = '2014.03.04.2'
-        height = media['height']
+        width = int_or_none(media['width'])
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?soundcloud\.com/([\w\d-]+)/sets/([\w\d-]+)(?:[?].*)?$'
+    _VALID_URL = r'https?://(?:www\.)?soundcloud\.com/([\w\d-]+)/sets/([\w\d-]+)'
-    _VALID_URL = r'http://(?:www\.)?tvigle\.ru/category/.+?video=(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www\.)?tvigle\.ru/category/.+?[\?&]v(?:ideo)?=(?P<id>\d+)'
-    }
+    _TESTS = [
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>xtube\.com/watch\.php\?v=(?P<videoid>[^/?&]+))'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>xtube\.com/watch\.php\?v=(?P<videoid>[^/?&]+))'
-            "age_limit": 18,
+            'id': 'kVTUy_G222_',
-        video_url= self._html_search_regex(r'var videoMp4 = "([^"]+)', webpage, 'video_url').replace('\\/', '/')
+        video_title = self._html_search_regex(r'<p class="title">([^<]+)', webpage, 'title')
-            u"title": u"PEOPLE ARE AWESOME 2013"
+            'duration': 279,
-__version__ = '2014.03.04'
+__version__ = '2014.03.04.1'
-            r'<input type="hidden" name="lsd" value="([^""]*)"',
+            r'<input type="hidden" name="lsd" value="([^"]*)"',
-        lsd = self._search_regex(r'"lsd":"(\w*?)"', login_page, 'lsd')
+        lsd = self._search_regex(
-    IE_NAME = u'facebook'
+    IE_NAME = 'facebook'
-        u'info_dict': {
+        'url': 'https://www.facebook.com/photo.php?v=120708114770723',
-        self.to_screen(u'Logging in')
+        self.to_screen('Logging in')
-        lgnrnd = self._search_regex(r'name="lgnrnd" value="([^"]*?)"', login_page, u'lgnrnd')
+            errnote='Unable to download login page')
-                self._downloader.report_warning(u'unable to log in: bad username/password, or exceded login rate limit (~3/min). Check credentials or wait.')
+                self._downloader.report_warning('unable to log in: bad username/password, or exceded login rate limit (~3/min). Check credentials or wait.')
-                'nh': self._search_regex(r'name="nh" value="(\w*?)"', login_results, u'nh'),
+                'fb_dtsg': self._search_regex(r'"fb_dtsg":"(.*?)"', login_results, 'fb_dtsg'),
-                'submit[Continue]': self._search_regex(r'<input value="(.*?)" name="submit\[Continue\]"', login_results, u'continue'),
+                'submit[Continue]': self._search_regex(r'<input value="(.*?)" name="submit\[Continue\]"', login_results, 'continue'),
-                self._downloader.report_warning(u'Unable to confirm login, you have to login in your brower and authorize the login.')
+                self._downloader.report_warning('Unable to confirm login, you have to login in your brower and authorize the login.')
-            self._downloader.report_warning(u'unable to log in: %s' % compat_str(err))
+            self._downloader.report_warning('unable to log in: %s' % compat_str(err))
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-                    u'The video is not available, Facebook said: "%s"' % m_msg.group(1),
+                    'The video is not available, Facebook said: "%s"' % m_msg.group(1),
-                raise ExtractorError(u'Cannot parse data')
+                raise ExtractorError('Cannot parse data')
-            raise ExtractorError(u'Cannot find video URL')
+            raise ExtractorError('Cannot find video URL')
-            r'<h2 class="uiHeaderTitle">([^<]*)</h2>', webpage, u'title')
+            r'<h2 class="uiHeaderTitle">([^<]*)</h2>', webpage, 'title')
-__version__ = '2014.03.03'
+__version__ = '2014.03.04'
-        if 'display_id' not in info_dict:
+        if 'display_id' not in info_dict and 'id' in info_dict:
-    YoutubeSearchIE,
+    YoutubeRecommendedIE,
-    YoutubeChannelIE,
+    YoutubeSearchIE,
-    YoutubeRecommendedIE,
+    YoutubeTopListIE,
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?(?!(?:attribution_link|watch)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)([A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?(?!(?:attribution_link|watch|results)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)([A-Za-z0-9_-]+)'
-__version__ = '2014.02.28'
+__version__ = '2014.03.03'
-    IE_NAME = 'Canal13cl'
+    _VALID_URL = r'^http://(?:www\.)?13\.cl/(?:[^/?#]+/)*(?P<id>[^/?#]+)'
-            webpage, u'title')
+        mobj = re.match(self._VALID_URL, url)
-            webpage, u'thumbnail')
+            r'articuloVideo = \"(.*?)\"', webpage, 'url')
-            'video_id': video_id,
+            'id': real_id,
-            'thumbnail': thumbnail
+            'thumbnail': thumbnail,
-    def _html_search_meta(self, name, html, display_name=None):
+    def _html_search_meta(self, name, html, display_name=None, fatal=False):
-            html, display_name, fatal=False)
+            html, display_name, fatal=fatal)
-        sdata = all_data[0]['values']['segments']
+
-from youtube_dl.utils import ExtractorError
+from ..utils import ExtractorError
-    _VALID_URL = r'^http://(?:www\.)?13\.cl/programa/'
+    _VALID_URL = r'^http://(?:www\.)?13\.cl/'
-        webpage = self._download_webpage(url)
+        webpage = self._download_webpage(url, url)
-            r'articuloTitulo = \'(.*?)\'',
+            r'(articuloTitulo = \"(.*?)\"|(.*?)\|)',
-            r'articuloVideo = \'(.*?)\'',
+            r'articuloVideo = \"(.*?)\"',
-            r'articuloImagen = \'(.*?)\'',
+            r'articuloImagen = \"(.*?)\"',
-from .canal13cl import Canal13cslIE
+from .canal13cl import Canal13clIE
-        like_count = video.get('vtp')
+        like_count = int_or_none(video.get('vtp'))
-        playlistpage = self._download_webpage(req, video_id)
+        playlistpage = self._download_json(req, video_id)
-        req = compat_urllib_request.Request(compat_urllib_parse.unquote(json.loads(playlistpage)['url']))
+        req = compat_urllib_request.Request(compat_urllib_parse.unquote(playlistpage['url']))
-            'duration': 3107.4,
+    _TESTS = [
-            'skip_download': True,  # requires rtmpdump
+        {
-            'duration': 6754.1,
+        {
-    }]
+    ]
-            raise ExtractorError(msg.replace('<br />', ' '))
+        NOT_AVAILABLE_STRING = 'This content is not available at your territory due to limited copyright.'
-    compat_urllib_parse_urlparse
+    compat_urllib_parse_urlparse,
-        req = compat_urllib_request.Request(unquote(json.loads(playlistpage)['url']))
+        req = compat_urllib_request.Request(compat_urllib_parse.unquote(json.loads(playlistpage)['url']))
-    _VALID_URL = r'https?://vk\.com/(?:videos.*?\?.*?z=)?video(?P<id>.*?)(?:\?|%2F|$)'
+    _VALID_URL = r'https?://vk\.com/(?:video_ext\.php\?.*?\boid=(?P<oid>\d+).*?\bid=(?P<id>\d+)|(?:videos.*?\?.*?z=)?video(?P<videoid>.*?)(?:\?|%2F|$))'
-        }
+        },
-        video_id = mobj.group('id')
+        video_id = mobj.group('videoid')
-    unified_strdate
+    unified_strdate,
-            r'<video.*?poster="([^"]+)".*?"></video>', webpage, 'video thumbnail')
+        videos = re.findall(r'<video.*?poster="(?P<poster>[^"]+)".*?src="(?P<video>[^"]+)".*?></video>', webpage)
-        }
+        def make_entry(video_id, media, video_number=None):
-               'skip_download': True,  # Requires rtmpdump
+            'params': {
-            })
+            'url': 'rtmp://' + akami_url + '/' + slide_video_path,
-            })
+            'url': 'rtmp://' + akami_url + '/' + speaker_video_path,
-        login_content = self._download_webpage(request, video_id, 'Logging in')
+        self._download_webpage(request, video_id, 'Logging in')
-        logout_content = self._download_webpage(logout_url, video_id, 'Logging out')
+        self._download_webpage(logout_url, video_id, 'Logging out')
-__version__ = '2014.02.27.1'
+__version__ = '2014.02.28'
-            _, video_thumbnail = sorted((int(width), t_url) for (width, t_url) in config["video"]["thumbs"].items())[-1]
+        if video_thumbnail is None:
-        if video_thumbnail is None:
+        if video_thumbnail is None and config["video"].get("thumbs"):
-            'uploader': 'Funnyplox TV',
+            'uploader': 'FunnyPlox TV',
-        'file': 'dholbach-cryptkeeper.mp3',
+            'id': 'dholbach-cryptkeeper',
-        track_id = '-'.join((uploader, cloudcast_name))
+        track_id = compat_urllib_parse.unquote('-'.join((uploader, cloudcast_name)))
-__version__ = '2014.02.27'
+__version__ = '2014.02.27.1'
-        webpage = self._download_webpage('http://lifenews.ru/mobile/news/%s' % video_id, video_id, 'Downloading page')
+        webpage = self._download_webpage('http://lifenews.ru/news/%s' % video_id, video_id, 'Downloading page')
-            r'<div class=\'comments\'>(\d+)</div>', webpage, 'comment count', fatal=False)
+            r'<div class=\'comments\'>\s*<span class=\'counter\'>(\d+)</span>', webpage, 'comment count', fatal=False)
-                u"title": u"Doki-Doki Universe: Sweet, Simple and Genuine (GDC Next 10)"
+            'url': 'http://www.gdcvault.com/play/1019721/Doki-Doki-Universe-Sweet-Simple',
-                u"title": u"Embracing the Dark Art of Mathematical Modeling in AI"
+            'url': 'http://www.gdcvault.com/play/1015683/Embracing-the-Dark-Art-of',
-            self.report_warning(u'It looks like ' + webpage_url + u' requires a login. Try specifying a username and password and try again.')
+            self.report_warning('It looks like ' + webpage_url + ' requires a login. Try specifying a username and password and try again.')
-                self.report_warning(u'Could not login.')
+                self.report_warning('Could not login.')
-        return [{
+        return {
-        }]
+        }
-                    'vbr': fix_bitrate(sources['bitrate']),
+                    'vbr': fix_bitrate(source['bitrate']),
-                mobj = re.search(r'^(?P<url>rtmp://[^/]+/(?P<app>[^/]+))/(?P<playpath>.+)$', source['url'])
+            protocol = source['protocol']
-
+from ..utils import (
-        {
+        {
-        self.report_extraction(video_id)
+        xml_root = self._html_search_regex(r'<iframe src="(?P<xml_root>.*?)player.html.*?".*?</iframe>', start_page, 'xml root', None, False)
-        xml_root = self._html_search_regex(r'<iframe src="(?P<xml_root>.*?)player.html.*?".*?</iframe>', start_page, 'xml root')
+        self.report_extraction(video_id)
-                })
+        video_formats = self._parse_mp4(xml_description)
-__version__ = '2014.02.26'
+__version__ = '2014.02.27'
-            'file': 'trailer.mp4',
+                'ext': 'mp4',
-            'file': 'BwY2RxaTrTkslxOfcan0UCf0YqyvWysJ.mp4',
+        # google redirect
-    }
+    _TESTS = [
-        xml_name = self._html_search_regex(r'<iframe src=".*?\?xml=(?P<xml_file>.+?\.xml).*?".*?</iframe>', start_page, 'xml filename')
+        xml_name = self._html_search_regex(r'<iframe src=".*?\?xml=(?P<xml_file>.+?\.xml).*?".*?</iframe>', start_page, 'xml filename', None, False)
-        formats = xml_description.findall('./metadata/MBRVideos/MBRVideo')
+        video_details = {
-            vbr = format.find('bitrate').text
+
-            })
+                    'url': 'rtmp://' + akami_url + '/' + speaker_video_path,
-            'formats': video_formats,
+            'formats': video_formats,
-    parse_duration,
+        mobj = re.search(r'<meta itemprop="duration" content="PT(?P<seconds>\d+)S" />', webpage)
-
+        
-            'url': 'http://www.n-tvnow.de/top-gear/episode-1-2013-01-01-00-00-00.php?film_id=124903&player=1&season=10',
+            'url': 'http://www.n-tvnow.de/deluxe-alles-was-spass-macht/thema-ua-luxushotel-fuer-vierbeiner.php?container_id=153819&player=1&season=0',
-                'id': '124903',
+                'id': '153819',
-                'skip_download': True,
+                'title': 'Deluxe - Alles was SpaÃ macht - Thema u.a.: Luxushotel fÃ¼r Vierbeiner',
-    clean_html,
+    clean_html,
-            'skip_download': True,
+    _VALID_URL = r'''(?x)
-            'thumbnail': 'http://autoimg.static-fra.de/superrtlnow/287529/1500x1500/image2.jpg'
+        {
-            'skip_download': True,
+        {
-            'description': 'Episode 1',
+        {
-            'skip_download': True,
+        {
-    }]
+    ]
-        video_page_url = 'http://' + mobj.group('domain') + '/'
+        video_page_url = 'http://%s/' % mobj.group('domain')
-        webpage = self._download_webpage(webpage_url, video_id)
+        webpage = self._download_webpage('http://' + mobj.group('url'), video_id)
-            raise ExtractorError(msg)
+        upload_date = unified_strdate(self._html_search_meta('uploadDate', webpage, 'upload date'))
-            webpage, 'playerdata_url')
+            r"'playerdata': '(?P<playerdata_url>[^']+)'", webpage, 'playerdata_url')
-            self._downloader.report_warning('Unable to extract description and upload date')
+        playerdata = self._download_xml(playerdata_url, video_id, 'Downloading player data XML')
-            video_thumbnail = None
+        videoinfo = playerdata.find('./playlist/videoinfo')
-        video_player_url = video_page_url + 'includes/vodplayer.swf'
+        formats = []
-        }
+            'title': title,
-__version__ = '2014.02.25.1'
+__version__ = '2014.02.26'
-    IE_NAME = u'ocw.mit.edu'
+    IE_NAME = 'ocw.mit.edu'
-    _BASE_URL = u'http://ocw.mit.edu/'
+    _BASE_URL = 'http://ocw.mit.edu/'
-                u'subtitles': u'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/video-lectures/lecture-7-multiple-variables-expectations-independence/MIT6_041F11_lec07_300k.mp4.srt'
+            'url': 'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/video-lectures/lecture-7-multiple-variables-expectations-independence/',
-                u'subtitles': u'http://ocw.mit.edu//courses/mathematics/18-01sc-single-variable-calculus-fall-2010/ocw-18.01-f07-lec01_300k.SRT'
+            'url': 'http://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/1.-differentiation/part-a-definition-and-basic-rules/session-1-introduction-to-derivatives/',
-        description = self._html_search_meta(u'Description', webpage)
+        mobj = re.match(self._VALID_URL, url)
-            metadata = re.sub(r'[\'"]', u'', embed_chapter_media.group(1))
+            metadata = re.sub(r'[\'"]', '', embed_chapter_media.group(1))
-                metadata = re.sub(r'[\'"]', u'', embed_media.group(1))
+                metadata = re.sub(r'[\'"]', '', embed_media.group(1))
-        return data
+        return {
-                return
+                raise Exception('Test definition incorrect. The output file cannot be known. Are both \'id\' and \'ext\' keys present?')
-    IE_NAME = u'techtv.mit.edu'
+    IE_NAME = 'techtv.mit.edu'
-            u'description': u'md5:82313335e8a8a3f243351ba55bc1b474',
+        'url': 'http://techtv.mit.edu/videos/25418-mit-dna-learning-center-set',
-        clean_page = re.compile(u'<!--.*?-->', re.S).sub(u'', raw_page)
+        clean_page = re.compile(r'<!--.*?-->', re.S).sub('', raw_page)
-            u'video formats')
+        base_url = self._search_regex(
-            raw_page, u'thumbnail', flags=re.DOTALL)
+        thumbnail = self._search_regex(
-                }
+        return {
-    IE_NAME = u'video.mit.edu'
+    IE_NAME = 'video.mit.edu'
-            u'description': u'md5:ad5795fe1e1623b73620dbfd47df9afd',
+        'url': 'http://video.mit.edu/watch/the-government-is-profiling-you-13222/',
-            u'embed url')
+        embed_url = self._search_regex(
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?mixcloud\.com/([\w\d-]+)/([\w\d-]+)'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?mixcloud\.com/([^/]+)/([^/]+)'
-from .nbc import NBCNewsIE
+from .nbc import (
-           (?P<config>[^/\?]+/(?:swf|config)/select/)?
+           (?P<config>(?:[^/\?]+/(?:swf|config)|onsite)/select/)?
-                'url': f4m_node.attrib['src'] + '?g=UXWGVKRWHFSP&hdcore=3.0.3',
+                'url': f4m_url,
-            smil_url = config['releaseUrl'] + '&format=SMIL&formats=MPEG4'
+            smil_url = config['releaseUrl'] + '&format=SMIL&formats=MPEG4&manifest=f4m'
-        thumbnail = self._html_search_regex(r'<meta property="og:image" content="([^"].+?)(?is)"', webpage, u'thumbnail',default='')
+        thumbnail = self._og_search_thumbnail(webpage)
-from .mit import TechTVMITIE, MITIE
+from .mit import TechTVMITIE, MITIE, OCWMITIE
-        for start, end, text in re.findall(r'<event [^>]*?start="([^"]+)" [^>]*?end="([^"]+)" [^>]*?text="([^"]+)"[^>]*?>', subtitles):
+        for i, (start, end, text) in enumerate(re.findall(r'<event [^>]*?start="([^"]+)" [^>]*?end="([^"]+)" [^>]*?text="([^"]+)"[^>]*?>', subtitles), 1):
-        }
+        }
-            lang_code = self._search_regex(r'lang_code=\'([^\']+)', subtitle, 'subtitle_lang_code', fatal=False)
+            lang_code = self._search_regex(r'lang_code=["\']([^"\']+)', subtitle, 'subtitle_lang_code', fatal=False)
-import re, base64, zlib
+import re
-    _TESTS = [{
+    _VALID_URL = r'https?://(?:(?P<prefix>www|m)\.)?(?P<url>crunchyroll\.com/(?:[^/]*/[^/?&]*?|media/\?id=)(?P<video_id>[0-9]+))(?:[/?&]|$)'
-        'file': '645513.flv',
+            'id': '645513',
-    }]
+    }
-        
+
-        i=1
+        i = 1
-            i+=1
+            i += 1
-        
+
-        }
+        }
-__version__ = '2014.02.25'
+__version__ = '2014.02.25.1'
-        'file': 'GB1101300280.mp4',
+            'id': 'GB1101300280',
-                self._SMIL_BASE_URL, video_id, video_id.lower())
+        else:
-        '138': {'ext': 'mp4', 'height': 1081, 'resolution': '>1080p', 'format_note': 'DASH video', 'preference': -40},
+        '138': {'ext': 'mp4', 'height': 2160, 'resolution': '2160p', 'format_note': 'DASH video', 'preference': -40},
-        '264': {'ext': 'mp4', 'height': 1080, 'resolution': '1080p', 'format_note': 'DASH video', 'preference': -40},
+        '264': {'ext': 'mp4', 'height': 1440, 'resolution': '1440p', 'format_note': 'DASH video', 'preference': -40},
-__version__ = '2014.02.24'
+__version__ = '2014.02.25'
-    batchurls = []
+    batch_urls = []
-            batchurls = [x for x in batchurls if len(x) > 0 and not re.search(r'^[#/;]', x)]
+                batchfd = io.open(opts.batchfile, 'r', encoding='utf-8', errors='ignore')
-                write_string(u'[debug] Batch file urls: ' + repr(batchurls) + u'\n')
+                write_string(u'[debug] Batch file urls: ' + repr(batch_urls) + u'\n')
-    all_urls = batchurls + args
+    all_urls = batch_urls + args
-        # Look for embedded Novamov player
+        # Look for embedded NovaMov player
-            return self.url_result(mobj.group('url'), 'Novamov')
+            return self.url_result(mobj.group('url'), 'NovaMov')
-            u"duration": 446,
+        "url": "http://scienceteachingtips.podomatic.com/entry/2009-01-02T16_03_35-08_00",
-        duration = int(data['length'] / 1000.0)
+        duration = int_or_none(data.get('length'), 1000)
-import re
+from __future__ import unicode_literals
-from ..utils import compat_urlparse
+from .novamov import NovaMovIE
-            u'Downloading embed page')
+class NowVideoIE(NovaMovIE):
-        self.report_extraction(video_id)
+    _VALID_URL = r'http://(?:(?:www\.)?%(host)s/video/|(?:(?:embed|www)\.)%(host)s/embed\.php\?(?:.*?&)?v=)(?P<videoid>[a-z\d]{13})' % {'host': 'nowvideo\.(?:ch|sx|eu)'}
-            webpage, u'video title')
+    _HOST = 'www.nowvideo.ch'
-            embed_page, u'video key')
+    _FILE_DELETED_REGEX = r'>This file no longer exists on our servers.<'
-        }]
+    _TEST = {
-from .novamov import NovamovIE
+from .novamov import NovaMovIE
-    _VALID_URL = r'http://(?:(?:www\.)?novamov\.com/video/|(?:(?:embed|www)\.)novamov\.com/embed\.php\?(?:.*?&)?v=)(?P<videoid>[a-z\d]{13})'
+class NovaMovIE(InfoExtractor):
-        'file': '4rurhn9x446jj.flv',
+            'id': '4rurhn9x446jj',
-                                      video_id, 'Downloading video page')
+        page = self._download_webpage(
-        if re.search(r'This file no longer exists on our servers!</h2>', page) is not None:
+        if re.search(self._FILE_DELETED_REGEX, page) is not None:
-            r'flashvars\.filekey="(?P<filekey>[^"]+)";', page, 'filekey')
+        filekey = self._search_regex(self._FILEKEY_REGEX, page, 'filekey')
-            page, 'title', fatal=False)
+        title = self._html_search_regex(self._TITLE_REGEX, page, 'title', fatal=False)
-            page, 'description', fatal=False)
+        description = self._html_search_regex(self._DESCRIPTION_REGEX, page, 'description', default='', fatal=False)
-            video_id, 'Downloading video api response')
+            'http://%s/api/player.api.php?key=%s&file=%s' % (self._HOST, filekey, video_id), video_id,
-            raise ExtractorError('novamov returned error: %s' % response['error_msg'][0], expected=True)
+            raise ExtractorError('%s returned error: %s' % (self.IE_NAME, response['error_msg'][0]), expected=True)
-        }
+        }
-    _VALID_URL = r'http://(?:(?:www\.)?novamov\.com/video/|(?:(?:embed|www)\.)novamov\.com/embed\.php\?v=)(?P<videoid>[a-z\d]{13})'
+    _VALID_URL = r'http://(?:(?:www\.)?novamov\.com/video/|(?:(?:embed|www)\.)novamov\.com/embed\.php\?(?:.*?&)?v=)(?P<videoid>[a-z\d]{13})'
-            u'title': u'The Mummyâs Hand (1940)',
+    _VALID_URL = r'http://(?:www\.)?cinemassacre\.com/(?P<date_Y>[0-9]{4})/(?P<date_m>[0-9]{2})/(?P<date_d>[0-9]{2})/.+?'
-    }]
+        {
-        webpage = self._download_webpage(webpage_url, None) # Don't know video id yet
+        webpage = self._download_webpage(url, None)  # Don't know video id yet
-        video_id = mobj.group(u'video_id')
+            raise ExtractorError('Can\'t extract embed url and video id')
-            webpage, u'title')
+            webpage, 'title')
-            webpage, u'description', flags=re.DOTALL, fatal=False)
+            webpage, 'description', flags=re.DOTALL, fatal=False)
-        video_thumbnail = self._html_search_regex(r'image: \'(?P<thumbnail>[^\']+)\'', playerdata, u'thumbnail', fatal=False)
+        sd_url = self._html_search_regex(r'file: \'(?P<sd_file>[^\']+)\', label: \'SD\'', playerdata, 'sd_file')
-        u'file': u'19911.flv',
+        u'file': u'19911.mp4',
-        u'file': u'521be8ef82b16.flv',
+        u'file': u'521be8ef82b16.mp4',
-        video_thumbnail = self._html_search_regex(r'\'image\': \'(?P<thumbnail>[^\']+)\'', playerdata, u'thumbnail', fatal=False)
+        sd_url = self._html_search_regex(r'file: \'(?P<sd_file>[^\']+)\', label: \'SD\'', playerdata, u'sd_file')
-                'ext': 'flv',
+                'url': sd_url,
-                'ext': 'flv',
+                'url': hd_url,
-        result = ie.extract('http://academicearth.org/courses/building-dynamic-websites/')
+        result = ie.extract('http://academicearth.org/playlists/laws-of-nature/')
-        self.assertEqual(len(result['entries']), 10)
+        self.assertEqual(result['id'], 'laws-of-nature')
-    _VALID_URL = r'^https?://(?:www\.)?academicearth\.org/(?:courses|playlists)/(?P<id>[^?#/]+)'
+    _VALID_URL = r'^https?://(?:www\.)?academicearth\.org/playlists/(?P<id>[^?#/]+)'
-            r'<h1 class="playlist-name">(.*?)</h1>', webpage, u'title')
+            r'<h1 class="playlist-name"[^>]*?>(.*?)</h1>', webpage, u'title')
-            r'<p class="excerpt">(.*?)</p>',
+            r'<p class="excerpt"[^>]*?>(.*?)</p>',
-            r'<h3 class="lecture-title"><a target="_blank" href="([^"]+)">',
+            r'<li class="lecture-preview">\s*?<a target="_blank" href="([^"]+)">',
-            u'description': u'md5:24e632ffac72b35f8b67a12d1b6ddfc1',
+        'url': 'http://www.nbcnews.com/video/nbc-news/52753292',
-                }
+        return {
-            'skip_download': True,
+            'skip_download': True,  # requires rtmpdump
-    ]
+    }, {
-                         floor(random()*1073741824))
+        player_url = (
-                r'Prima-[0-9]{10}-([0-9]+)_', filename, 'real video id')
+                r'Prima-(?:[0-9]{10}|WEB)-([0-9]+)[-_]',
-    _VALID_URL = r'https?://play\.iprima\.cz/(?P<videogroup>.+)/(?P<videoid>.+)'
+    _VALID_URL = r'https?://play\.iprima\.cz/[^?#]+/(?P<id>[^?#]+)'
-        video_id = mobj.group('videoid')
+        video_id = mobj.group('id')
-            base_url = base_url.replace('token', 'token_'+zoneGEO)
+            base_url = base_url.replace('token', 'token_' + zoneGEO)
-            filename = self._html_search_regex(r'"%s_id":(.+?),' % format_id, webpage, 'filename')
+            filename = self._html_search_regex(
-            real_id = self._search_regex(r'Prima-[0-9]{10}-([0-9]+)_', filename, 'real video id')
+            real_id = self._search_regex(
-                filename = 'hq/'+filename
+                filename = 'hq/' + filename
-                'play_path': 'mp4:'+filename.replace('"', '')[:-4],
+                'play_path': 'mp4:' + filename.replace('"', '')[:-4],
-__version__ = '2014.02.22.1'
+__version__ = '2014.02.24'
-            u"title": u"ZDFspezial - Ende des Machtpokers"
+        'url': 'http://www.zdf.de/ZDFmediathek/beitrag/video/2037704/ZDFspezial---Ende-des-Machtpokers--?bc=sts;stt',
-        u"skip": u"Videos on ZDF.de are depublicised in short order",
+        'skip': 'Videos on ZDF.de are depublicised in short order',
-        xml_url = u'http://www.zdf.de/ZDFmediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id
+        xml_url = 'http://www.zdf.de/ZDFmediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id
-            errnote=u'Failed to download video info')
+            note='Downloading video info',
-        )
+        uploader_id_node = doc.find('.//details/originChannelId')
-            is_available = u'http://www.metafilegenerator' not in video_url
+            is_available = 'http://www.metafilegenerator' not in video_url
-            vbr = int(fnode.find('./videoBitrate').text) // 1000
+            vbr_node = fnode.find('./videoBitrate')
-            format_note = u''
+            width_node = fnode.find('./width')
-                'format_id': format_id + u'-' + quality,
+                'format_id': format_id + '-' + quality,
-                'height': int_or_none(fnode.find('./height').text),
+                'width': width,
-            'uploader': uploader,
+            'uploader': uploader,
-        }
+            'formats': formats,
-                       data-video-username="(.*?)".*?
+        video_re = r'''(?x)data-video-username="(.*?)".*?
-        # Some of the videos may have beend deleted, their username field is empty
+        # Some of the videos may have been deleted, their username field is empty
-    ExtractorError,
+
-    _VALID_URL = r'(?:http://)?(?:www\.)?normalboots\.com/video/(?P<videoid>[0-9a-z-]*)/?$'
+    _VALID_URL = r'http://(?:www\.)?normalboots\.com/video/(?P<videoid>[0-9a-z-]*)/?$'
-            u'upload_date': u'20140125',
+        'url': 'http://normalboots.com/video/home-alone-games-jontron/',
-    
+
-        
+
-        raw_upload_date = self._html_search_regex('<span style="text-transform:uppercase; font-size:inherit;">[A-Za-z]+, (?P<date>.*)</span>', 
+        raw_upload_date = self._html_search_regex('<span style="text-transform:uppercase; font-size:inherit;">[A-Za-z]+, (?P<date>.*)</span>',
-            
+
-        return info
+
-        video_url = u'http://player.screenwavemedia.com/' + self._html_search_regex(r"'file':\s'(?P<file>[0-9A-Za-z-_\.]+)'", player_page, 'file')
+        video_url = self._html_search_regex(r"file:\s'(?P<file>[^']+\.mp4)'", player_page, 'file')
-            get_element_by_attribute('class', 'title ', webpage))
+        search_title = lambda class_name: get_element_by_attribute('class', class_name, webpage)
-        ids = orderedSet(re.findall(video_re, webpage))
+        video_re = r'''(?x)data-index="\d+".*?
-            'uploader': 'Jack Dorsey',
+            'description': 'Chicken.',
-        self.report_extraction(video_id)
+        webpage = self._download_webpage('https://vine.co/v/' + video_id, video_id)
-            'video URL')
+        data = json.loads(self._html_search_regex(
-        uploader = re.sub('\'s post on Vine', '', twitter_title)
+        formats = [
-        }
+            'description': data['description'],
-            'webpage', 'info json', flags=re.DOTALL)
+            webpage, 'info json', flags=re.DOTALL)
-                                       'info json', flags=re.DOTALL)
+        info_json = self._search_regex(r'var embedVars = ({.*})\s*?</script>',
-            webpage, 'uploader', fatal=False, flags=re.DOTALL)
+        twitter_title  = self._html_search_meta('twitter:title', webpage,
-__version__ = '2014.02.22'
+__version__ = '2014.02.22.1'
-        bootstrap_info_version = self.read_unsigned_int()
+
-        movie_identifier = self.read_string()
+
-        for i in range(server_count):
+        for i in range(quality_count):
-    _BASE_URL = u"http://www.br.de"
+class BRIE(InfoExtractor):
-            }
+    _TEST = {
-    ]
+    }
-        xml_url = self._search_regex(r"return BRavFramework\.register\(BRavFramework\('avPlayer_(?:[a-f0-9-]{36})'\)\.setup\({dataURL:'(/mediathek/video/[a-z0-9/~_.-]+)'}\)\);", page, "XMLURL")
+        mobj = re.match(self._VALID_URL, url)
-            videos.append(video)
+        videos = [{
-                u'report this with the video URL to http://yt-dl.org/bug')
+            self._downloader.report_warning(
-        return vformats
+        formats = [{
-        thumbnails.sort(key = lambda x: x["width"] * x["height"], reverse=True)
+        thumbnails = [{
-__version__ = '2014.02.21.1'
+__version__ = '2014.02.22'
-                    else:
+                    if isinstance(expected, compat_str) and expected.startswith('re:'):
-                        u'invalid value for field %s, expected %r, got %r' % (info_field, expected, got))
+                        match_str = expected[len('re:'):]
-    _VALID_URL = r'(?:https?://)?(?:www\.)?(?P<url>trutube\.tv/video/(?P<videoid>.*/.*))'
+    _VALID_URL = r'https?://(?:www\.)?trutube\.tv/video/(?P<id>[0-9]+)/.*'
-        'md5': '9973aa3c2870626799d2ac4e36cfc3dc',
+        'url': 'http://trutube.tv/video/14880/Ramses-II-Proven-To-Be-A-Red-Headed-Caucasoid-',
-            u"ext": u"mp4"
+            'id': '14880',
-        ext = video_url[-3:]
+        video_title = self._og_search_title(webpage).strip()
-            }
+            'formats': formats,
-            u'title': u'Terrasses du NumÃ©rique'
+        'url': 'http://www.canalc2.tv/video.asp?idVideo=12163&voir=oui',
-                }
+            r'class="evenement8">(.*?)</a>', webpage, 'title')
-            r'by:\s*<a href="/Profile.aspx?.*?UserId=(\d+).*?"', webpage, 'uploader id', fatal=False)
+            r'by:\s*<a href="/Profile\.aspx\?.*?UserId=(\d+).*?"', webpage, 'uploader id', fatal=False)
-import os
+    unified_strdate,
-)
+from ..aes import aes_decrypt_text
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>spankwire\.com/[^/]*/video(?P<videoid>[0-9]+)/?)'
+    _VALID_URL = r'https?://(?:www\.)?(?P<url>spankwire\.com/[^/]*/video(?P<videoid>[0-9]+)/?)'
-        'md5': '1b3f55e345500552dbc252a3e9c1af43',
+        'md5': '8bbfde12b101204b39e4b9fe7eb67095',
-            "age_limit": 18,
+            'id': '103545',
-            r'flashvars\.image_url = "([^"]+)', webpage, 'thumbnail', fatal=False)
+        title = self._html_search_regex(r'<h1>([^<]+)', webpage, 'title')
-
+            height = int(resolution.rstrip('Pp'))
-            'thumbnail': thumbnail,
+            'title': title,
-        
+                              webpage_src)
-__version__ = '2014.02.21'
+__version__ = '2014.02.21.1'
-    _TESTS = []
+    _TESTS = [
-            doc = xml.etree.ElementTree.fromstring(webpage)
+            doc = xml.etree.ElementTree.fromstring(webpage.encode('utf-8'))
-        except xml.etree.ElementTree.ParseError:
+        except compat_xml_parse_error:
-            args = info['args']
+            ytplayer_config = json.loads(mobj.group(1))
-                    dash_manifest_url = video_info.get('dashmpd')[0];
+                    dash_manifest_url = video_info.get('dashmpd')[0]
-                    dash_manifest_url = x['args']['dashmpd']
+                    dash_manifest_url = ytplayer_config['args']['dashmpd']
-__version__ = '2014.02.20'
+__version__ = '2014.02.21'
-    _VALID_URL = r'(?:http://)?(?:www\.)?wimp\.com/([^/]+)/'
+    _VALID_URL = r'http://(?:www\.)?wimp\.com/([^/]+)/'
-        'md5': '8b215e2e0168c6081a1cf84b2846a2b5',
+        'url': 'http://www.wimp.com/maruexhausted/',
-            "description": "These deer look as fluid as running water when they jump over this fence as a herd. This video is one that needs to be watched until the very end for the true majesty to be witnessed, but once it comes, it's sure to take your breath away.",
+            'id': 'maruexhausted',
-        }
+        }
-    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s&page=%s'
+    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s'
-    _VIDEO_RE = r'href="/watch\?v=(?P<id>[0-9A-Za-z_-]{11})&amp;[^"]*?index=(?P<index>\d+)'
+    _VIDEO_RE = r'href="\s*/watch\?v=(?P<id>[0-9A-Za-z_-]{11})&amp;[^"]*?index=(?P<index>\d+)'
-            matches = re.finditer(self._VIDEO_RE, page)
+            matches = re.finditer(self._VIDEO_RE, content_html)
-            if re.search(self._MORE_PAGES_INDICATOR, page) is None:
+            mobj = re.search(r'data-uix-load-more-href="/?(?P<more>[^"]+)"', more_widget_html)
-                r'<h1 class="pl-header-title">(.*?)</h1>', page, u'title')
+            more = self._download_json(
-                self._downloader.params.get('youtube_include_dash_manifest', False)):
+        if (self._downloader.params.get('youtube_include_dash_manifest', False)):
-                    dash_manifest_url_lst[0], video_id,
+                    dash_manifest_url, video_id,
-__version__ = '2014.02.19.1'
+__version__ = '2014.02.20'
-            action='store_true', dest='ignoreerrors', help='continue on download errors, for example to to skip unavailable videos in a playlist', default=False)
+            action='store_true', dest='ignoreerrors', help='continue on download errors, for example to skip unavailable videos in a playlist', default=False)
-    compat_urllib_parse,
+    unified_strdate,
-            "age_limit": 18,
+    _VALID_URL = r'http://(?:www\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.+?)\.html(?:\?.*)?'
-    }]
+    ]
-            mp4 = re.search(r'<a href=\"(.+?)\" class=\"mp4Play\"',webpage)
+            mp4 = re.search(r'<video\s+.*?file="([^"]+)".*?>', webpage)
-                return None
+                raise ExtractorError('Unable to extract media URL')
-            r'<title>(?P<title>.+?) - xHamster\.com</title>', webpage, 'title')
+        title = self._html_search_regex(r'<title>(?P<title>.+?) - xHamster\.com</title>', webpage, 'title')
-        video_description = mobj.group(1) if mobj else None
+        description = mobj.group(1) if mobj else None
-            self._downloader.report_warning('Unable to extract upload date')
+        upload_date = self._html_search_regex(r'hint=\'(\d{4}-\d{2}-\d{2}) \d{2}:\d{2}:\d{2} [A-Z]{3,4}\'',
-            r'<a href=\'/user/[^>]+>(?P<uploader_id>[^<]+)',
+        uploader_id = self._html_search_regex(r'<a href=\'/user/[^>]+>(?P<uploader_id>[^<]+)',
-            webpage, 'thumbnail', fatal=False)
+        thumbnail = self._html_search_regex(r'<video\s+.*?poster="([^"]+)".*?>', webpage, 'thumbnail', fatal=False)
-            'preference': 0,
+            'preference': 1,
-                mrss_url + '?hd', video_id, note='Downloading HD webpage')
+            webpage = self._download_webpage(mrss_url + '?hd', video_id, note='Downloading HD webpage')
-            'thumbnail': video_thumbnail,
+            'title': title,
-__version__ = '2014.02.19'
+__version__ = '2014.02.19.1'
-        'file': '757_1364311680.mp4',
+            'id': '757_1364311680',
-        'file': 'f93_1390833151.mp4',
+            'id': 'f93_1390833151',
-
+
-                self._search_regex(r'(file: ".*?"),', webpage, 'video URL'))
+            alt_source = self._search_regex(
-
+            'age_limit': age_limit,
-__version__ = '2014.02.17'
+__version__ = '2014.02.19'
-            u'uploader': u'TechMedia Networks',
+        'add_ie': ['Brightcove'],
-            'url': 'http://www.bbc.co.uk/programmes/p01q7wz1',
+            'url': 'http://www.bbc.co.uk/programmes/b039g8p7',
-                'id': 'p01q7wz4',
+                'id': 'b039d07m',
-                'duration': 1936,
+                'title': 'Kaleidoscope: Leonard Cohen',
-                                 (?:(?:watch|movie)(?:_popup)?(?:\.php)?)?    # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
+                                 (?:(?:watch|movie)(?:_popup)?(?:\.php)?/?)?  # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
-            }
+            },
-        (?:https?://)?[^/]+/watch\?feature=[a-z_]+$|
+        (?:https?://)?[^/]+/watch\?(?:feature=[a-z_]+)?$|
-                "uploader": "Filippo Valsorda", 
+                'id': '56015672',
-__version__ = '2014.02.13'
+__version__ = '2014.02.17'
-        'md5': 'cd829201b890905682eb194cbdea55d7',
+            'description': 'md5:f5c904224d43c133225130fe156a5ee0',
-        webpage = self._download_webpage(url, vid)
+        video_id = mobj.group('id')
-        })
+
-            'id': vid,
+            'id': video_id,
-            'formats': formats
+            'formats': formats,
-from ..utils import compat_urllib_request
+from ..utils import (
-    _VALID_URL = r'(?:https?://)?www\.4tube\.com/videos/(?P<id>\d+)/.*'
+    _VALID_URL = r'https?://(?:www\.)?4tube\.com/videos/(?P<id>\d+)'
-            }
+        'url': 'http://www.4tube.com/videos/209733/hot-babe-holly-michaels-gets-her-ass-stuffed-by-black',
-        title = self._search_regex(r'title:\s*"([^"]*)', playlist_json, u'Title')
+        playlist_json = self._html_search_regex(r'var playerConfigPlaylist\s+=\s+([^;]+)', webpage, 'Playlist')
-        return [{
+        self._sort_formats(formats)
-            }]
+        }
-        r'(?:(?:(?P<hours>[0-9]+):)?(?P<mins>[0-9]+):)?(?P<secs>[0-9]+)$', s)
+        r'(?:(?:(?P<hours>[0-9]+)[:h])?(?P<mins>[0-9]+)[:m])?(?P<secs>[0-9]+)s?$', s)
-            'uploader': 'Noize MC',
+    _TESTS = [
-            'title': 'Dream Theater - Hollow Years Live at Budokan 720*',
+        {
-    }]
+    ]
-                    'url': x.find('default/streamerURI').text + '/',
+                    'url': x.find('default/streamerURI').text,
-        http_dl = HttpQuietDownloader(self.ydl, {'continuedl': True, 'quiet': True, 'noprogress': True})
+        http_dl = HttpQuietDownloader(self.ydl,
-                raise ExtractorError(u'[youtube] No video results')
+                raise ExtractorError(
-from struct import unpack, pack
+    struct_pack,
-        return unpack('!Q', self.read(8))[0]
+        return struct_unpack('!Q', self.read(8))[0]
-        return unpack('!I', self.read(4))[0]
+        return struct_unpack('!I', self.read(4))[0]
-        return unpack('!B', self.read(1))[0]
+        return struct_unpack('!B', self.read(1))[0]
-    stream.write(pack('!L', len(metadata))[1:])
+    stream.write(struct_pack('!L', len(metadata))[1:])
-        result = ie.extract('http://www.dailymotion.com/user/generation-quoi/')
+        result = ie.extract('https://www.dailymotion.com/user/nqtv')
-        self.assertTrue(len(result['entries']) >= 26)
+        self.assertEqual(result['title'], 'RÃ©mi Gaillard')
-            'md5': '41ed601768534dd18a9ae34d84798129',
+            'url': 'http://www.ndr.de/info/audio51535.html',
-                'id': '191719',
+                'id': '51535',
-                'duration': 112,
+                'title': 'La Valette entgeht der Hinrichtung',
-                page)
+                r'<iframe.+?src="http://player\.rutv\.ru/iframe/(?P<type>[^/]+)/id/(?P<id>\d+)[^"]*".*?></iframe>', page)
-__version__ = '2014.02.10'
+__version__ = '2014.02.13'
-import json
+from __future__ import unicode_literals
-    _VALID_URL = r'^https?://?(www\.)?escapistmagazine\.com/videos/view/(?P<showname>[^/]+)/(?P<episode>[^/?]+)[/?]?.*$'
+    _VALID_URL = r'^https?://?(www\.)?escapistmagazine\.com/videos/view/(?P<showname>[^/]+)/(?P<id>[0-9]+)-'
-            u"title": u"Breaking Down Baldur's Gate"
+        'url': 'http://www.escapistmagazine.com/videos/view/the-escapist-presents/6618-Breaking-Down-Baldurs-Gate',
-        videoId = mobj.group('episode')
+        video_id = mobj.group('id')
-        webpage = self._download_webpage(url, videoId)
+        self.report_extraction(video_id)
-            webpage, u'description', fatal=False)
+            webpage, 'description', fatal=False)
-            webpage, u'title').split(' : ')[-1]
+            webpage, 'title').split(' : ')[-1]
-        configUrl = self._search_regex('config=(.*)$', playerUrl, u'config URL')
+        configUrl = self._search_regex('config=(.*)$', playerUrl, 'config URL')
-            configJSON = configJSON.replace("'", '"')
+        def _add_format(name, cfgurl, quality):
-                raise ExtractorError(u'Invalid JSON in configuration file: ' + compat_str(err))
+                'quality': quality,
-        _add_format(u'normal', configUrl)
+        _add_format('normal', configUrl, quality=0)
-            _add_format(u'hq', hq_url)
+            _add_format('hq', hq_url, quality=1)
-            'id': videoId,
+            'id': video_id,
-            'description': 'md5:3e5e8e839f076a637c6b9406c8f25c4c',
+            'description': 'md5:3e1c0dc6047498d6728dcdaad0891762',
-            'description': 'md5:11812366244110c3523968aa74f02521',
+            'description': 'md5:7ded37421526d54afdf005e25bc2b7a3',
-            'title': 'Mirror\'s Edge 2|E3 2013: Debut Trailer',
+            'id': '70e9a5d7-cf25-4a10-9104-6f3e7342ae0d',
-            title_el = itemdoc.find('./title')
+            title_el = itemdoc.find('.//title')
-            title_el = itemdoc.find('.//title')
+            title_el = itemdoc.find('.//{http://search.yahoo.com/mrss/}title')
-            title_el = itemdoc.find('.//{http://search.yahoo.com/mrss/}title')
+            title_el = itemdoc.find('./item/title')
-        'md5': 'f6d65b1b326e82fd7ab7720bea3dacae',
+        'url': 'https://www.dropbox.com/s/0qr9sai2veej4f8/THE_DOCTOR_GAMES.mp4',
-            'title': '20131219_085616'
+            'id': '0qr9sai2veej4f8',
-            'md5': '20eba151ff165f386643dad9c1da08f7',
+            'url': 'http://www.ndr.de/fernsehen/sendungen/markt/markt7959.html',
-                'id': '19925',
+                'id': '7959',
-                'duration': 1722,
+                'title': 'Markt - die ganze Sendung',
-        # audio
+            'note': 'Audio file',
-from .cnn import CNNIE
+from .cnn import (
-        video_uploader = self._html_search_regex(r'so_s\.addVariable\("owner_", "([^"]+)', webpage, 'uploader', fatal=False)
+        video_uploader = self._html_search_regex(r'so_s\.addVariable\("owner_u", "([^"]+)', webpage, 'uploader', fatal=False)
-            u"age_limit": 18,
+        'url': 'http://www.xtube.com/watch.php?v=kVTUy_G222_',
-        video_url= self._html_search_regex(r'var videoMp4 = "([^"]+)', webpage, u'video_url').replace('\\/', '/')
+        video_title = self._html_search_regex(r'<div class="p_5px[^>]*>([^<]+)', webpage, 'title')
-    IE_DESC = u'Yahoo screen'
+    IE_DESC = 'Yahoo screen'
-                u'description': u'Julian and Travis watch Julian Smith',
+            'url': 'http://screen.yahoo.com/julian-smith-travis-legg-watch-214727115.html',
-                u'description': u'Agent Topple\'s mustache does its dirty work, and Nicole brokers a deal for peace. But why is the NSA collecting millions of Instagram brunch photos? And if your waffles have nothing to hide, what are they so worried about?',
+            'url': 'http://screen.yahoo.com/wired/codefellas-s1-ep12-cougar-lies-103000935.html',
-            webpage, u'items', flags=re.MULTILINE)
+            webpage, 'items', flags=re.MULTILINE)
-            video_id, u'Downloading video info')
+            video_id, 'Downloading video info')
-            u'description': u'md5:9900ab8cd5808175c7b3fe55b979bed0',
+        'url': 'http://news.yahoo.com/video/china-moses-crazy-blues-104538833.html',
-        long_id = self._search_regex(r'contentId: \'(.+?)\',', webpage, u'long id')
+        long_id = self._search_regex(r'contentId: \'(.+?)\',', webpage, 'long id')
-    IE_DESC = u'Yahoo screen search'
+    IE_DESC = 'Yahoo screen search'
-    IE_NAME = u'screen.yahoo:search'
+    IE_NAME = 'screen.yahoo:search'
-            result_url = u'http://video.search.yahoo.com/search/?p=%s&fr=screen&o=js&gs=0&b=%d' % (compat_urllib_parse.quote_plus(query), pagenum * 30)
+            result_url = 'http://video.search.yahoo.com/search/?p=%s&fr=screen&o=js&gs=0&b=%d' % (compat_urllib_parse.quote_plus(query), pagenum * 30)
-            results = info[u'results']
+            m = info['m']
-            if (pagenum * 30 +i >= n) or (m[u'last'] >= (m[u'total'] -1)):
+            if (pagenum * 30 +i >= n) or (m['last'] >= (m['total'] -1)):
-        }
+        },
-    _VALID_URL = r'https?://www\.stream\.cz/((?P<category>.+)/)?(?P<videogroup>.+)/(?P<videoid>.+)'
+    _VALID_URL = r'https?://(?:www\.)?stream\.cz/.+/(?P<videoid>.+)'
-    _TESTS = [{
+    _TEST = {
-    ]
+    }
-            format_id = video['instances'][0]['quality']
+            for video_format in video['instances']:
-                quality = 3
+                if format_id == '240p':
-            })
+                formats.append({
-from ..utils import determine_ext
+
-    _VALID_URL = r'(?:https?://)?(?:www\.)?freesound\.org/people/([^/]+)/sounds/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?freesound\.org/people/([^/]+)/sounds/(?P<id>[^/]+)'
-            u'description': u'the sounds of seagulls in the city',
+        'url': 'http://www.freesound.org/people/miklovan/sounds/194503/',
-                                webpage, 'description', fatal=False, flags=re.DOTALL)
+        title = self._html_search_regex(
-            'url':      music_url,
+        return {
-        }]
+        }
-    _SOUNDCLOUD_URL = r'(?:http://)?(?:www\.)?api\.soundcloud\.com/tracks/([^/]+)/stream'
+    IE_NAME = 'exfm'
-                u'description': u'Test House \"Love Is Not Enough\" (Extended Mix) DeadJournalist Exclusive',
+            'url': 'http://ex.fm/song/eh359',
-            u'skip': u'The site is down too often',
+            'note': 'Soundcloud song',
-                u'uploader': u'Capital Cities',
+            'url': 'http://ex.fm/song/wddt8',
-            u'skip': u'The site is down too often',
+            'skip': 'The site is down too often',
-        song_url = info['song']['url']
+        song_id = mobj.group('id')
-        }]
+            return self.url_result(song_url.replace('/stream', ''), 'Soundcloud')
-    _VALID_URL = r'(?:http://)?(?:www\.)?dotsub\.com/view/([^/]+)'
+    _VALID_URL = r'http://(?:www\.)?dotsub\.com/view/(?P<id>[^/]+)'
-            u'upload_date': u'20101213',
+        'url': 'http://dotsub.com/view/aed3b8b2-1889-4df5-ae63-ad85f5572f27',
-        info = json.loads(webpage)
+        video_id = mobj.group('id')
-            'thumbnail':   info['screenshotURI'],
+        return {
-        }]
+            'uploader': info['user'],
-    _VALID_URL = r'(?:http://)?(?:www\.)?break\.com/video/([^/]+)'
+    _VALID_URL = r'http://(?:www\.)?break\.com/video/([^/]+)'
-            u"title": u"When Girls Act Like D-Bags"
+        'url': 'http://www.break.com/video/when-girls-act-like-guys-2468056',
-                                       u'info json', flags=re.DOTALL)
+                                       'info json', flags=re.DOTALL)
-            'title':     info['contentName'],
+        return {
-        }]
+        }
-    _VALID_URL = r'(?:https?://)?(?:www\.)?howcast\.com/videos/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?howcast\.com/videos/(?P<id>\d+)'
-            u"title": u"How to Tie a Square Knot Properly"
+        'url': 'http://www.howcast.com/videos/390161-How-to-Tie-a-Square-Knot-Properly',
-            webpage, u'title')
+            webpage, 'video URL')
-            webpage, u'description', fatal=False)
+            webpage, 'description', fatal=False)
-            'title':    video_title,
+        return {
-        }]
+            'thumbnail': self._og_search_thumbnail(webpage),
-    IE_NAME = u'plus.google'
+    IE_DESC = 'Google Plus'
-            u"title": u"åãã®å¤©ä½¿ éè¨"
+        'url': 'https://plus.google.com/u/0/108897254135232129896/posts/ZButuJc6CtH',
-        video_extension = 'flv'
+        video_id = mobj.group('id')
-        webpage = self._download_webpage(post_url, video_id, u'Downloading entry webpage')
+        webpage = self._download_webpage(url, video_id, 'Downloading entry webpage')
-            webpage, u'upload date', fatal=False, flags=re.VERBOSE)
+            webpage, 'upload date', fatal=False, flags=re.VERBOSE)
-            webpage, u'uploader', fatal=False)
+            webpage, 'uploader', fatal=False)
-            webpage, 'title', default=u'NA')
+            webpage, 'title', default='NA')
-            webpage, u'video page URL')
+            webpage, 'video page URL')
-        webpage = self._download_webpage(video_page, video_id, u'Downloading video page')
+        webpage = self._download_webpage(video_page, video_id, 'Downloading video page')
-        """Extract video links of all sizes"""
+        # Extract video links all sizes
-            raise ExtractorError(u'Unable to extract video links')
+            raise ExtractorError('Unable to extract video links')
-            'url':      video_url,
+        return {
-        }]
+            'upload_date': upload_date,
-    _VALID_URL = r'(?:http://)?instagram\.com/p/(.*?)/'
+    _VALID_URL = r'http://instagram\.com/p/(?P<id>.*?)/'
-            u'description': u'md5:1f17f0ab29bd6fe2bfad705f58de3cb8',
+        'url': 'http://instagram.com/p/aye83DjauH/?foo=bar#abc',
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-        desc = self._search_regex(r'"caption":"(.*?)"', webpage, u'description',
+            webpage, 'uploader id', fatal=False)
-            'title':     u'Video by %s' % uploader_id,
+        return {
-            'uploader_id' : uploader_id,
+            'uploader_id': uploader_id,
-        }]
+        }
-            r'''(?s)jwplayer\('flashvideoportal_1'\).setup\({.*?'file': '([^']+)'.*?}\);''', webpage, 'video URL')
+            r'''(?s)jwplayer\('flashvideoportal_1'\)\.setup\({.*?'file': '([^']+)'.*?}\);''', webpage, 'video URL')
-from ..utils import unified_strdate
+from ..utils import (
-    
+
-        'file': '126342.mp4',
+            'id': '126342',
-        
+
-            r'<div class=\'views\'>(\d+)</div>', webpage, 'view count')
+            r'<div class=\'views\'>(\d+)</div>', webpage, 'view count', fatal=False)
-            r'<div class=\'comments\'>(\d+)</div>', webpage, 'comment count')
+            r'<div class=\'comments\'>(\d+)</div>', webpage, 'comment count', fatal=False)
-            r'<time datetime=\'([^\']+)\'>', webpage, 'upload date')
+            r'<time datetime=\'([^\']+)\'>', webpage, 'upload date',fatal=False)
-            'upload_date': unified_strdate(upload_date),
+            'view_count': int_or_none(view_count),
-            return [url_m.group(1)]
+            return [unescapeHTML(url_m.group(1))]
-__version__ = '2014.02.08.2'
+__version__ = '2014.02.10'
-                            (?:www\.)?pwnyoutube\.com|
+                            (?:www\.)?pwnyoutube\.com/|
-    date_str = date_str.replace(',',' ')
+    date_str = date_str.replace(',', ' ')
-    date_str = re.sub(r' ?(\+|-)[0-9:]*$', '', date_str)
+    date_str = re.sub(r' ?(\+|-)[0-9]{2}:?[0-9]{2}$', '', date_str)
-                       errnote=u'Unable to download JSON metadata'):
+                       errnote=u'Unable to download JSON metadata',
-    
+                page = self._download_json(
-            u'description': u'This was a keynote presentation at the NoSQL Now! 2013 Conference & Expo (http://www.nosqlnow.com). This presentation was given by Adrian Cockcroft from Netflix',
+        'url': 'http://www.slideshare.net/Dataversity/keynote-presentation-managing-scale-and-complexity',
-            webpage, u'slideshare object')
+            webpage, 'slideshare object')
-            raise ExtractorError(u'Webpage type is "%s": only video extraction is supported for Slideshare' % info['slideshow']['type'], expected=True)
+        if info['slideshow']['type'] != 'video':
-            'description': self._og_search_description(webpage),
+            'description': description,
-        return self.url_result(ooyala_url, OoyalaIE.ie_key())
+        embed_code = self._search_regex(
-    _VALID_URL = r'(?:https?://link\.theplatform\.com/s/[^/]+/|theplatform:)(?P<id>[^/\?]+)'
+    _VALID_URL = r'''(?x)
-            'format=smil&mbr=true'.format(video_id))
+    def _get_info(self, video_id, smil_url):
-        self._sort_formats(formats)
+        f4m_node = body.find(_x('smil:seq/smil:video'))
-        return self._get_info(video_id)
+        if mobj.group('config'):
-                'duration': 1800,
+                'title': 'The Voice UK: Series 3: Blind Auditions 5',
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class BBCCoUkIE(InfoExtractor):
+class BBCCoUkIE(SubtitlesInfoExtractor):
-    IE_DESC = 'BBC - iPlayer Radio'
+    IE_DESC = 'BBC iPlayer'
-            'duration': 1936,
+    _TESTS = [
-            'skip_download': True,
+        {
-    }
+    ]
-            radio_programme_id, 'Downloading media selection XML')
+        no_items = playlist.find('./{http://bbc.co.uk/2008/emp/playlist}noItems')
-                })
+        subtitles = None
-            'id': radio_programme_id,
+            'id': programme_id,
-__version__ = '2014.02.08.1'
+__version__ = '2014.02.08.2'
-        assertExtractId = lambda url, id: self.assertEqual(YoutubeIE()._extract_id(url), id)
+        assertExtractId = lambda url, id: self.assertEqual(YoutubeIE.extract_id(url), id)
-        ytie_results = [YoutubeIE()._extract_id(url['url']) for url in result['entries']]
+        ytie_results = [YoutubeIE().extract_id(url['url']) for url in result['entries']]
-        self.assertEqual(YoutubeIE()._extract_id(result['url']), 'FXxLjLQi3Fg')
+        self.assertEqual(YoutubeIE().extract_id(result['url']), 'FXxLjLQi3Fg')
-        ytie_results = [YoutubeIE()._extract_id(url['url']) for url in result['entries']]
+        ytie_results = [YoutubeIE().extract_id(url['url']) for url in result['entries']]
-        self.assertEqual(YoutubeIE()._extract_id(entries[0]['url']), 'j9WZyLZCBzs')
+        self.assertEqual(YoutubeIE().extract_id(entries[0]['url']), 'j9WZyLZCBzs')
-        self.assertEqual(YoutubeIE()._extract_id(entries[-1]['url']), 'rYefUsYuEp0')
+        self.assertEqual(YoutubeIE().extract_id(entries[-1]['url']), 'rYefUsYuEp0')
-        mobj = re.match(self._VALID_URL, url, re.VERBOSE)
+    @classmethod
-        video_id = self._extract_id(url)
+        video_id = self.extract_id(url)
-            u'description': u'Lorsque les dÃ©veloppeurs de LittleBigPlanet proposent un nouveau titre, on ne peut que s\'attendre Ã  un rÃ©sultat original et fort attrayant.\n',
+        'url': 'http://www.jeuxvideo.com/reportages-videos-jeux/0004/00046170/tearaway-playstation-vita-gc-2013-tearaway-nous-presente-ses-papiers-d-identite-00115182.htm',
-            webpage, u'config URL')
+            webpage, 'config URL')
-            xml_link, u'video ID')
+            xml_link, 'video ID')
-            xml_link, title, u'Downloading XML config')
+            xml_link, title, 'Downloading XML config')
-__version__ = '2014.02.08'
+__version__ = '2014.02.08.1'
-        self.assertFalse('youtube:playlist' in self.matching_ies(u'PLtS2H6bU1M'))
+        assertPlaylist('ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8')
-        self.assertFalse(YoutubeIE.suitable(u'https://www.youtube.com/watch?v=AV6J6_AeFEQ&playnext=1&list=PL4023E734DA416012')) #668
+        self.assertTrue(YoutubeIE.suitable('PLtS2H6bU1M'))
-        self.assertTrue(FacebookIE.suitable(u'https://www.facebook.com/Shiniknoh#!/photo.php?v=10153317450565268'))
+        self.assertTrue(FacebookIE.suitable('https://www.facebook.com/Shiniknoh#!/photo.php?v=10153317450565268'))
-            video\.pbs\.org/video/(?P<id>[0-9]+)/? |
+            video\.pbs\.org/(?:viralplayer|video)/(?P<id>[0-9]+)/? |
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(programmes|iplayer/episode)/(?P<id>[\da-z]{8})'
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(?:programmes|iplayer/episode)/(?P<id>[\da-z]{8})'
-    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/programmes/(?P<id>[\da-z]{8})'
+    _VALID_URL = r'https?://(?:www\.)?bbc\.co\.uk/(programmes|iplayer/episode)/(?P<id>[\da-z]{8})'
-__version__ = '2014.02.06.3'
+__version__ = '2014.02.08'
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>tube8\.com/[^/]+/[^/]+/(?P<videoid>[0-9]+)/?)'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>tube8\.com/.+?/(?P<videoid>\d+)/?)$'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-    _VALID_URL = r'^https?://(?:www\.)?channel9\.msdn\.com/(?P<contentpath>.+)/?'
+    _VALID_URL = r'https?://(?:www\.)?channel9\.msdn\.com/(?P<contentpath>.+)/?'
-            'file': 'Events_TechEd_Australia_2013_KOS002.mp4',
+                'id': 'Events/TechEd/Australia/2013/KOS002',
-            'file': 'posts_Self-service-BI-with-Power-BI-nuclear-testing.mp4',
+                'id': 'posts/Self-service-BI-with-Power-BI-nuclear-testing',
-    _VALID_URL = r'^https?://(?:www\.)?ivi\.ru/watch(?:/(?P<compilationid>[^/]+))?/(?P<videoid>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?ivi\.ru/watch(?:/(?P<compilationid>[^/]+))?/(?P<videoid>\d+)'
-            'file': '53141.mp4',
+                'id': '53141',
-            'file': '74791.mp4',
+                'id': '74791',
-    _VALID_URL = r'^https?://(?:www\.)?ivi\.ru/watch/(?!\d+)(?P<compilationid>[a-z\d_-]+)(?:/season(?P<seasonid>\d+))?$'
+    _VALID_URL = r'https?://(?:www\.)?ivi\.ru/watch/(?!\d+)(?P<compilationid>[a-z\d_-]+)(?:/season(?P<seasonid>\d+))?$'
-        description = video.find('description').text
+        title = None
-        } for x in video.findall('assets/asset')]
+        def extract_thumbnail(media):
-                return self.url_result(video_id, ie='Youtube')
+                return self.url_result(native_video_id, ie='Youtube')
-from ..utils import clean_html
+from ..utils import (
-import urllib
+from ..utils import clean_html
-    _VALID_URL = r'(?:https?://)?(?:www\.)?chilloutzone\.net/video/(?P<id>[\w|-]+).html'
+    _VALID_URL = r'https?://(?:www\.)?chilloutzone\.net/video/(?P<id>[\w|-]+)\.html'
-        webpage_url = 'http://www.chilloutzone.net/video/' + video_id + '.html'
+        webpage = self._download_webpage(url, video_id)
-        # decode string and find video file
+        base64_video_info = self._html_search_regex(
-        description = video_info_dict['description']
+        video_url = video_info_dict['mediaUrl']
-        #print media_url
+        if native_platform is None:
-                return self.url_result(video_url, ie='Youtube') 
+                return self.url_result(video_id, ie='Youtube')
-            return []
+                return self.url_result(
-            'title':     title,
+        return {
-
+        }
-__version__ = '2014.02.06.2'
+__version__ = '2014.02.06.3'
-	}
+        'url': 'http://www.chilloutzone.net/video/enemene-meck-alle-katzen-weg.html',
-    	    if native_platform == 'youtube':
+        video_id = mobj.group('id')
-    	        self.to_screen(u'Vimeo video detected:')
+                self.to_screen(u'Vimeo video detected:')
-			return []
+            self.report_warning(u'Url does not contain a video container')
-		}]
+            'id':        video_id,
-            compat_urllib_parse.urlencode({'getConfig': 'true'}))
+            compat_urllib_parse.urlencode({'getConfig': 'true'}).encode('ascii'))
-    _VALID_URL = r"""(?:
+    _VALID_URL = r"""(?x)(?:
-                        ((?:PL|EC|UU|FL|RD)?[0-9A-Za-z-_]{10,})
+                        (
-        mobj = re.match(self._VALID_URL, url, re.VERBOSE)
+        mobj = re.match(self._VALID_URL, url)
-    IE_DESCR = 'El PaÃ­s'
+    IE_DESC = 'El PaÃ­s'
-__version__ = '2014.02.06.1'
+__version__ = '2014.02.06.2'
-    _VALID_URL = r'https?://(?:www\.)?nfb\.ca/film/(?P<id>[\da-z_-]+)'
+    _VALID_URL = r'https?://(?:www\.)?(nfb|onf)\.ca/film/(?P<id>[\da-z_-]+)'
-        page = self._download_webpage(url, video_id, 'Downloading film page')
+        page = self._download_webpage('https://www.nfb.ca/film/%s' % video_id, video_id, 'Downloading film page')
-            'http://mooshare.biz/8dqtk4bjbp8g', compat_urllib_parse.urlencode(download_form))
+            'http://mooshare.biz/%s' % video_id, compat_urllib_parse.urlencode(download_form))
-        }
+        }
-__version__ = '2014.02.06'
+__version__ = '2014.02.06.1'
-    date_str = re.sub(r' (\+|-)[\d]*$', '', date_str)
+    date_str = re.sub(r' ?(\+|-)[0-9:]*$', '', date_str)
-        except:
+        except ValueError:
-                    if not err.exc_info[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError) or (err.exc_info[0] == compat_HTTPError and err.exc_info[1].code == 503):
+                    if not err.exc_info[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError, compat_http_client.BadStatusLine) or (err.exc_info[0] == compat_HTTPError and err.exc_info[1].code == 503):
-import json
+from ..utils import int_or_none
-        'file': '6902724.mp4',
+            'id': '6902724',
-            'description': 'Fans get creative this year at San Diego.  Too',
+            'description': 'Fans get creative this year',
-        'file': '3505939.mp4',
+            'id': '3505939',
-            'description': 'This video wasn\'t long enough, so we made it double-spaced.',
+            'description': 'This video wasn\'t long enough,',
-        if title_el is None:
+            if title_el.text is None:
-__version__ = '2014.02.05'
+__version__ = '2014.02.06'
-    _MORE_PAGES_INDICATOR = r'id="pnnext" class="pn"'
+    IE_DESC = 'Google Video search'
-    IE_NAME = u'video.google:search'
+    IE_NAME = 'video.google:search'
-            'entries': []
+            'title': query,
-                                             note='Downloading result page ' + str(pagenum))
+        for pagenum in itertools.count():
-                e = {
+                entries.append({
-                res['entries'].append(e)
+                })
-            if (pagenum * 10 > n) or not re.search(self._MORE_PAGES_INDICATOR, webpage):
+            if (len(entries) >= n) or not re.search(r'class="pn" id="pnnext"', webpage):
-    _VALID_URL = r'http://(?:www\.)?ina\.fr/video/(?P<id>I?[A-F0-9]+)/.*'
+    _VALID_URL = r'http://(?:www\.)?ina\.fr/video/(?P<id>I?[A-Z0-9]+)'
-__version__ = '2014.02.04.1'
+__version__ = '2014.02.05'
-)
+from ..utils import determine_ext
-            u"uploader_id": u"dj7970"
+        'url': 'http://www.thisav.com/video/47734/%98%26sup1%3B%83%9E%83%82---just-fit.html',
-        title = self._html_search_regex(r'<h1>([^<]*)</h1>', webpage, u'title')
+        title = self._html_search_regex(r'<h1>([^<]*)</h1>', webpage, 'title')
-            r"addVariable\('file','([^']+)'\);", webpage, u'video url')
+            r"addVariable\('file','([^']+)'\);", webpage, 'video url')
-            webpage, u'uploader name', fatal=False)
+            webpage, 'uploader name', fatal=False)
-            webpage, u'uploader id', fatal=False)
+            webpage, 'uploader id', fatal=False)
-            '_type':       'video',
+from __future__ import unicode_literals
-    IE_NAME = u'tou.tv'
+    IE_NAME = 'tou.tv'
-            u'thumbnail': u'http://static.tou.tv/medias/images/2013-11-18_19_00_00_30VIES_0341_01_L.jpeg',
+        'url': 'http://www.tou.tv/30-vies/S04E41',
-            u'skip_download': True,  # Requires rtmpdump
+        'params': {
-        u'skip': 'Only available in Canada'
+        'skip': 'Only available in Canada'
-            r'"idMedia":\s*"([^"]+)"', webpage, u'media ID')
+            r'"idMedia":\s*"([^"]+)"', webpage, 'media ID')
-        streams_url = u'http://release.theplatform.com/content.select?pid=' + mediaId
+        streams_url = 'http://release.theplatform.com/content.select?pid=' + mediaId
-            streams_url, video_id, note=u'Downloading stream list')
+            streams_url, video_id, note='Downloading stream list')
-                         if u'//ad.doubleclick' not in n.text)
+                         if '//ad.doubleclick' not in n.text)
-                u'Access to this video is blocked from outside of Canada',
+                'Access to this video is blocked from outside of Canada',
-            'video:duration', webpage, u'duration')
+            'video:duration', webpage, 'duration')
-            'video:release_date', webpage, u'upload date')
+            'video:release_date', webpage, 'upload date')
-__version__ = '2014.02.04'
+__version__ = '2014.02.04.1'
-    _VALID_URL = r'(?:http://)?(?:www\.)?ina\.fr/video/(?P<id>I?[A-F0-9]+)/.*'
+    _VALID_URL = r'http://(?:www\.)?ina\.fr/video/(?P<id>I?[A-F0-9]+)/.*'
-            u"title": u"Fran\u00e7ois Hollande \"Je crois que c'est clair\""
+        'url': 'http://www.ina.fr/video/I12055569/francois-hollande-je-crois-que-c-est-clair-video.html',
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        webpage = self._download_webpage(mrss_url, video_id)
+        mrss_url = 'http://player.ina.fr/notices/%s.mrss' % video_id
-            webpage, u'title')
+        video_url = info_doc.find('.//{http://search.yahoo.com/mrss/}player').attrib['url']
-        }]
+        return {
-    _VALID_URL = r'(?:http://)?(?:www\.)?vbox7\.com/play:([^/]+)'
+    _VALID_URL = r'http://(www\.)?vbox7\.com/play:(?P<id>[^/]+)'
-        }
+        'url': 'http://vbox7.com/play:249bb972c2',
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-        new_location = self._search_regex(r'window\.location = \'(.*)\';', redirect_page, u'redirect location')
+        new_location = self._search_regex(r'window\.location = \'(.*)\';',
-        webpage = self._download_webpage(redirect_url, video_id, u'Downloading redirect page')
+        webpage = self._download_webpage(redirect_url, video_id,
-            webpage, u'title').split('/')[0].strip()
+            webpage, 'title').split('/')[0].strip()
-        data = compat_urllib_parse.urlencode({'as3':'1','vid':video_id})
+        data = compat_urllib_parse.urlencode({'as3': '1', 'vid': video_id})
-        info_response = self._download_webpage(info_request, video_id, u'Downloading info webpage')
+        info_response = self._download_webpage(info_request, video_id, 'Downloading info webpage')
-            raise ExtractorError(u'Unable to extract the media url')
+            raise ExtractorError('Unable to extract the media url')
-            'title':     title,
+        return {
-        }]
+        }
-    _VALID_URL = r'(?:http://)?(?:www\.)?statigr\.am/p/([^/]+)'
+    _VALID_URL = r'https?://(www\.)?statigr\.am/p/(?P<id>[^/]+)'
-            u'title': u'Instagram photo by @aguynamedpatrick (Patrick Janelle)',
+        'url': 'http://statigr.am/p/522207370455279102_24101272',
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-            webpage, u'title')
+            webpage, 'title')
-        ext = 'mp4'
+            r'@([^ ]+)', title, 'uploader name', fatal=False)
-            'title':     title,
+        return {
-        }]
+            'uploader_id': uploader_id
-    _VALID_URL = r'(?:https?://)?(?:www\.)?vine\.co/v/(?P<id>\w+)'
+    _VALID_URL = r'https?://(?:www\.)?vine\.co/v/(?P<id>\w+)'
-        }
+        'url': 'https://vine.co/v/b9KOOWX7HUx',
-            webpage, u'video URL')
+        video_url = self._html_search_meta('twitter:player:stream', webpage,
-            webpage, u'uploader', fatal=False, flags=re.DOTALL)
+            webpage, 'uploader', fatal=False, flags=re.DOTALL)
-            'title':     self._og_search_title(webpage),
+        return {
-        }]
+            'uploader': uploader,
-                r'^(?P<func>[a-zA-Z]+)\((?P<args>[a-z0-9,]+)\)$', expr)
+                r'^(?P<func>[a-zA-Z$]+)\((?P<args>[a-z0-9,]+)\)$', expr)
-__version__ = '2014.02.03.1'
+__version__ = '2014.02.04'
-    _VALID_URL = r'https?://video\.pbs\.org/video/(?P<id>\d+)/?'
+    _VALID_URL = r'''(?x)https?://
-            u'duration': 3190,
+        'url': 'http://www.pbs.org/tpt/constitution-usa-peter-sagal/watch/a-more-perfect-union/',
-        video_id = mobj.group('id')
+
-                }
+        info = self._download_json(info_url, display_id)
-            r'<video.*?src="([^"]+)"></video>', webpage, 'video URL')
+            r'<video.*?src="([^"]+)".*?></video>', webpage, 'video URL')
-            'description': 'md5:506f69f7a297ed698ced3375f2363b0e',
+            'description': 'md5:11812366244110c3523968aa74f02521',
-            return self._download_subtitle_url(sub_lang, url)
+            sub = self._download_subtitle_url(sub_lang, url)
-                })
+            })
-        }
+        }
-__version__ = '2014.02.03'
+__version__ = '2014.02.03.1'
-        """Try to extract the brightcove url from the wepbage, returns None
+        """Try to extract the brightcove url from the webpage, returns None
-            return url_m.group(1)
+            return [url_m.group(1)]
-        m_brightcove = re.search(
+        matches = re.findall(
-                [^>]+?class=([\'"])[^>]*?BrightcoveExperience.*?\1 |
+                [^>]+?class=[\'"][^>]*?BrightcoveExperience.*?[\'"] |
-            return None
+        return [cls._build_brighcove_url(m) for m in matches]
-        if bc_url is not None:
+        bc_urls = BrightcoveIE._extract_brightcove_urls(webpage)
-            return self.url_result(surl, 'Brightcove')
+            entries = [{
-   
+
-            'id':       video_id,
+            'id': video_id,
-            'description':  video_description,
+            'upload_date': video_upload_date,
-class VimeoIE(InfoExtractor):
+class VimeoIE(SubtitlesInfoExtractor):
-__version__ = '2014.01.30.2'
+__version__ = '2014.02.03'
-
+        if '--ignore-config' in commandLineConf:
-class BlipTVIE(InfoExtractor):
+class BlipTVIE(SubtitlesInfoExtractor):
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?blip\.tv/((.+/)|(play/)|(api\.swf#))(.+)$'
+    _VALID_URL = r'https?://(?:\w+\.)?blip\.tv/((.+/)|(play/)|(api\.swf#))(?P<presumptive_id>.+)$'
-    _TEST = {
+    _TESTS = [{
-        'file': '5779306.mov',
+            'id': '5779306',
-        self.to_screen('%s: Direct download detected' % title)
+    }, {
-            raise ExtractorError('Invalid URL: %s' % url)
+        presumptive_id = mobj.group('presumptive_id')
-        embed_mobj = re.search(r'^(?:https?://)?(?:\w+\.)?blip\.tv/(?:play/|api\.swf#)([a-zA-Z0-9]+)', url)
+        embed_mobj = re.match(r'https?://(?:\w+\.)?blip\.tv/(?:play/|api\.swf#)([a-zA-Z0-9]+)', url)
-            video_id = self._search_regex(r'data-episode-id="(\d+)', info_page,  'video_id')
+            video_id = self._search_regex(
-            cchar = '?'
+        
-            else:
+        json_data = self._download_json(request, video_id=presumptive_id)
-                    'height': int(data['media']['height']),
+                    'url': f['url'],
-            raise ExtractorError('Unable to parse video information: %s' % repr(err))
+    def _download_subtitle_url(self, sub_lang, url):
-                                          'Downloading video ids from page %d' % pagenum)
+            page = self._download_webpage(
-        return [self.playlist_result(url_entries, playlist_title = username)]
+        return [self.playlist_result(url_entries, playlist_title=username)]
-            sub = self._download_webpage(url, None, note=False)
+            return self._download_subtitle_url(sub_lang, url)
-        pass
+
-    _TEST = {
+    _TESTS = [{
-        'file': '5779306.mov',
+            'id': '5779306',
-    }
+    }, {
-import json
+    find_xpath_attr,
-    _VALID_URL = r'http://(?:www\.)?c-spanvideo\.org/program/(?P<name>.*)'
+    _VALID_URL = r'http://(?:www\.)?c-span\.org/video/\?(?P<id>\d+)'
-        'file': '315139.mp4',
+        'url': 'http://www.c-span.org/video/?313572-1/HolderonV',
-            'description': 'Attorney General Eric Holder spoke to reporters following the Supreme Court decision in [Shelby County v. Holder] in which the court ruled that the preclearance provisions of the Voting Rights Act could not be enforced until Congress established new guidelines for review.',
+            'description': 'Attorney General Eric Holder spoke to reporters following the Supreme Court decision in Shelby County v. Holder in which the court ruled that the preclearance provisions of the Voting Rights Act could not be enforced until Congress established new guidelines for review.',
-        description = self._og_search_description(webpage)
+        page_id = mobj.group('id')
-        data = json.loads(data_json)
+        data = self._download_json(info_url, video_id)
-            'title': title,
+            'title': find_string('title'),
-            'thumbnail': self._og_search_thumbnail(webpage),
+            'thumbnail': find_string('poster'),
-        'file': 'YL2qNPkqon.mp4',
+            'id': 'YL2qNPkqon',
-            u"description": u"Trailer for Prince Avalanche.Two highway road workers spend the summer of 1988 away from their city lives. The isolated landscape becomes a place of misadventure as the men find themselves at odds with each other and the women they left behind."
+        'url': 'http://www.traileraddict.com/trailer/prince-avalanche/trailer',
-        video_id = self._og_search_property('video', webpage, 'Video id').split('=')[1]
+        view_count_str = self._search_regex(
-        }]
+
-            'description': 'md5:7e8899d3f749db50fa089eb243cba17f',
+            'description': 'md5:506f69f7a297ed698ced3375f2363b0e',
-)
+
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?infoq\.com/[^/]+/[^/]+$'
+    _VALID_URL = r'https?://(?:www\.)?infoq\.com/[^/]+/(?P<id>[^/]+)$'
-        self.report_extraction(url)
+        webpage = self._download_webpage(url, video_id)
-            'ext': extension, # Extension is always(?) mp4, but seems to be flv
+            'ext': extension,  # Extension is always(?) mp4, but seems to be flv
-    _VALID_URL = r'(?:https?://)?(?:www\.)?newgrounds\.com/audio/listen/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?newgrounds\.com/audio/listen/(?P<id>[0-9]+)'
-            "uploader": "Burn7",
+            'id': '549479',
-        'file': 'ford-lopatin-live-at-primavera-sound-2011.mp3',
+            'id': 'ford-lopatin-live-at-primavera-sound-2011',
-import re
+from __future__ import unicode_literals
-    _VALID_URL = r'(https?://)?(www\.)?(?P<url>southparkstudios\.com/(clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
+    IE_NAME = 'southparkstudios.com'
-            u'description': u'Randy disqualifies South Park by getting into a fight with Bat Dad.',
+        'url': 'http://www.southparkstudios.com/clips/104437/bat-daded#tab=featured',
-    _VALID_URL = r'(https?://)?(www\.)?(?P<url>southpark\.de/(clips|alle-episoden)/(?P<id>.+?)(\?|#|$))'
+    IE_NAME = 'southpark.de'
-            u'description': u'Cartman explains the benefits of "Shitter" to Stan, Kyle and Craig.',
+        'url': 'http://www.southpark.de/clips/uygssh/the-government-wont-respect-my-privacy#tab=featured',
-            u'description': u'Jon is late for Christmas. Typical. Thanks to: Paul Ritchey for Co-Writing/Filming: http://www.youtube.com/user/ContinueShow Micha Frar for Christmas Intro Animation: http://michafrar.tumblr.com/ Jerrod Waters for Christmas Intro Music: http://www.youtube.com/user/xXJerryTerryXx Casey Ormond for \u2018Tense Battle Theme\u2019:\xa0http://www.youtube.com/Kiamet/',
+            u'description': u'Jon is late for Christmas. Typical. Thanks to: Paul Ritchey for Co-Writing/Filming: http://www.youtube.com/user/ContinueShow Michael Azzi for Christmas Intro Animation: http://michafrar.tumblr.com/ Jerrod Waters for Christmas Intro Music: http://www.youtube.com/user/xXJerryTerryXx Casey Ormond for \u2018Tense Battle Theme\u2019:\xa0http://www.youtube.com/Kiamet/',
-        description = video['description']
+        description = video.get('description')
-# encoding: utf-8
+from .vube import VubeIE
-            'title': 'ÐÐÐ ÑÐ°Ð·ÑÑÐºÐ¸Ð²Ð°ÐµÑ ÑÑÐ¾Ð¸Ñ Ð¼ÑÐ¶ÑÐ¸Ð½, Ð¾ÑÑÐ°Ð²Ð¸Ð²ÑÐ¸Ñ Ð² IKEA ÑÑÐ¼ÐºÑ Ñ Ð°Ð²ÑÐ¾Ð¼Ð°ÑÐ¾Ð¼',
+            'title': 'ÐÐÐ ÑÐ°Ð·ÑÑÐºÐ¸Ð²Ð°ÐµÑ Ð¼ÑÐ¶ÑÐ¸Ð½, Ð¾ÑÑÐ°Ð²Ð¸Ð²ÑÐ¸Ñ Ð² IKEA ÑÑÐ¼ÐºÑ Ñ Ð°Ð²ÑÐ¾Ð¼Ð°ÑÐ¾Ð¼',
-        u'md5': u'8b215e2e0168c6081a1cf84b2846a2b5',
+        u'file': u'home-alone-games-jontron.mp4',
-            'description': 'md5:b20fc87608e2837596bbc8df85a3c34d',
+            'description': 'md5:7e8899d3f749db50fa089eb243cba17f',
-            u"description": u"Iata-ne reveniti dupa o binemeritata vacanta. Va astept si pe Facebook cu pareri si comentarii.",
+        "url": "http://www.220.ro/sport/Luati-Le-Banii-Sez-4-Ep-1/LYV6doKo7f/",
-            webpage, u'flashVars')
+            webpage, 'flashVars')
-        info = {
+        return {
-        return info
+from __future__ import unicode_literals
-    IE_NAME = u'ustream'
+    IE_NAME = 'ustream'
-        }
+        'url': 'http://www.ustream.tv/recorded/20274954',
-        video_url = u'http://tcdn.ustream.tv/video/%s' % video_id
+        video_url = 'http://tcdn.ustream.tv/video/%s' % video_id
-            webpage, u'title')
+            webpage, 'title')
-            webpage, u'uploader', fatal=False, flags=re.DOTALL)
+            webpage, 'uploader', fatal=False, flags=re.DOTALL)
-        return info
+            webpage, 'thumbnail', fatal=False)
-    IE_NAME = u'ustream:channel'
+    IE_NAME = 'ustream:channel'
-        }
+        'url': 'http://www.spiegel.de/video/vulkan-tungurahua-in-ecuador-ist-wieder-aktiv-video-1259285.html',
-        }
+        'url': 'http://www.spiegel.de/video/schach-wm-videoanalyse-des-fuenften-spiels-video-1309159.html',
-            r'<div class="module-title">(.*?)</div>', webpage, u'title')
+            r'<div class="module-title">(.*?)</div>', webpage, 'title')
-        xml_url = u'http://video2.spiegel.de/flash/' + video_id + u'.xml'
+        xml_url = 'http://video2.spiegel.de/flash/' + video_id + '.xml'
-            note=u'Downloading XML', errnote=u'Failed to download XML')
+            note='Downloading XML', errnote='Failed to download XML')
-                'url': u'http://video2.spiegel.de/flash/' + n.find('./filename').text,
+                'url': 'http://video2.spiegel.de/flash/' + n.find('./filename').text,
-        info = {
+        return {
-        return info
+from __future__ import unicode_literals
-            u"height": 1080,
+        'url': 'http://www.vevo.com/watch/hurts/somebody-to-die-for/GB1101300280',
-            raise ExtractorError(u'Unable to extract last version of the video')
+            raise ExtractorError('Unable to extract last version of the video')
-                'format_id': u'SMIL_' + m.group('cbr'),
+                'format_id': 'SMIL_' + m.group('cbr'),
-        video_info = json.loads(info_json)['video']
+        video_info = self._download_json(json_url, video_id)['video']
-                                              u'Downloading SMIL info')
+                                              'Downloading SMIL info')
-                u'Cannot download SMIL information, falling back to JSON ..')
+                'Cannot download SMIL information, falling back to JSON ..')
-            r'/Date\((\d+)\)/', video_info['launchDate'], u'launch date'))
+            r'/Date\((\d+)\)/', video_info['launchDate'], 'launch date'))
-        info = {
+        return {
-        content_re = r'content=(?:"([^>]+?)"|\'(.+?)\')'
+        content_re = r'content=(?:"([^>]+?)"|\'([^>]+?)\')'
-__version__ = '2014.01.30.1'
+__version__ = '2014.01.30.2'
-            mgid = self._search_regex(r'data-mgid="(.*?)"', webpage, u'mgid')
+            mgid = self._search_regex(
-    }]
+    },
-            for qname, qurl in vdata[format_key].items():
+            for qname, qurl in vdata.get(format_key, {}).items():
-                    if not int(f['media_width']): # filter m3u8
+                for f in sorted(data['additionalMedia'], key=lambda f: int(0 if f['media_height'] is None else f['media_height'])):
-        }
+        },
-    IE_NAME = u'pluzz.francetv.fr'
+    IE_NAME = 'pluzz.francetv.fr'
-    IE_NAME = u'francetvinfo.fr'
+    IE_NAME = 'francetvinfo.fr'
-            u'title': u'Soir 3',
+        'url': 'http://www.francetvinfo.fr/replay-jt/france-3/soir-3/jt-grand-soir-3-lundi-26-aout-2013_393427.html',
-            u'skip_download': True,
+        'params': {
-        video_id = self._search_regex(r'id-video=(\d+?)[@"]', webpage, u'video id')
+        video_id = self._search_regex(r'id-video=(\d+?)[@"]', webpage, 'video id')
-    IE_DESC = u'France 2, 3, 4, 5 and Ã'
+    IE_NAME = 'francetv'
-                u'description': u'md5:2e5b58ba7a2d3692b35c792be081a03d',
+            'url': 'http://www.france2.fr/emissions/13h15-le-samedi-le-dimanche/videos/75540104',
-            u'params': {
+            'params': {
-                u'skip_download': True,
+                'skip_download': True,
-                u'description': u'md5:1384089fbee2f04fc6c9de025ee2e9ce',
+            'url': 'http://www.france3.fr/emissions/pieces-a-conviction/diffusions/13-11-2013_145575',
-            u'params': {
+            'params': {
-                u'skip_download': True,
+                'skip_download': True,
-                u'description': u'md5:c87d54871b1790679aec1197e73d650a',
+            'url': 'http://www.france4.fr/emissions/hero-corp/videos/rhozet_herocorp_bonus_1_20131106_1923_06112013172108_F4',
-            u'params': {
+            'params': {
-                u'skip_download': True,
+                'skip_download': True,
-                u'description': u'md5:fb1db1cbad784dcce7c7a7bd177c8e2f',
+            'url': 'http://www.france5.fr/emissions/c-a-dire/videos/92837968',
-            u'params': {
+            'params': {
-                u'skip_download': True,
+                'skip_download': True,
-                u'description': u'md5:ebf346da789428841bee0fd2a935ea55',
+            'url': 'http://www.franceo.fr/jt/info-afrique/04-12-2013',
-            u'params': {
+            'params': {
-                u'skip_download': True,
+                'skip_download': True,
-            u'skip': u'The id changes frequently',
+            'skip': 'The id changes frequently',
-            video_id = self._html_search_regex(id_res, webpage, u'video ID')
+            video_id = self._html_search_regex(id_res, webpage, 'video ID')
-    IE_NAME = u'france2.fr:generation-quoi'
+    IE_NAME = 'france2.fr:generation-quoi'
-            u'uploader': u'GÃ©nÃ©ration Quoi',
+        'url': 'http://generation-quoi.france2.fr/portrait/garde-a-vous',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-    IE_NAME = u'culturebox.francetvinfo.fr'
+    IE_NAME = 'culturebox.francetvinfo.fr'
-            u'description': u'md5:9ce2888b1efefc617b5e58b3f6200eeb',
+        'url': 'http://culturebox.francetvinfo.fr/einstein-on-the-beach-au-theatre-du-chatelet-146813',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-        video_id = self._search_regex(r'"http://videos\.francetv\.fr/video/(.*?)"', webpage, u'video id')
+        video_id = self._search_regex(r'"http://videos\.francetv\.fr/video/(.*?)"', webpage, 'video id')
-        video_id = self._search_regex(r'id-video=(\d+?)"', webpage, u'video id')
+        video_id = self._search_regex(r'id-video=(\d+?)[@"]', webpage, u'video id')
-    _TEST = {
+    _TESTS = [{
-    }
+    },
-            r'(?s)sources:\s*(\[.*?\]),', webpage, 'video URLs')
+            r'(?s)sources:\s*(\[.*?\]),', webpage, 'video URLs', default=None)
-__version__ = '2014.01.30'
+__version__ = '2014.01.30.1'
-            mobj = re.search(r'(?s)jw_plugins.*?file:\s*["\'](.*?)["\']', webpage)
+            mobj = re.search(r'(?s)(?:jw_plugins|JWPlayerOptions).*?file\s*:\s*["\'](.*?)["\']', webpage)
-__version__ = '2014.01.29'
+__version__ = '2014.01.30'
-            r'file: "(.*?)",', webpage, 'video URL')
+        sources_raw = self._search_regex(
-            'uploader': video_uploader
+            'uploader': video_uploader,
-    _VALID_URL = r'(?:https?://)?(?:www\.)?(?P<url>crunchyroll\.com/[^/]*/[^/?&]*?(?P<video_id>[0-9]+))(?:[/?&]|$)'
+    _VALID_URL = r'(?:https?://)?(?:(?P<prefix>www|m)\.)?(?P<url>crunchyroll\.com/(?:[^/]*/[^/?&]*?|media/\?id=)(?P<video_id>[0-9]+))(?:[/?&]|$)'
-            u'upload_date': u'20131013',
+        'url': 'http://www.crunchyroll.com/wanna-be-the-strongest-in-the-world/episode-1-an-idol-wrestler-is-born-645513',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-        u'1080': (u'80', u'108'),
+        '360': ('60', '106'),
-            shaHash = bytes_to_intlist(sha1(prefix + str(num4).encode(u'ascii')).digest())
+            shaHash = bytes_to_intlist(sha1(prefix + str(num4).encode('ascii')).digest())
-        output = u''
+        output = ''
-            end = end.replace(u'.', u',')
+            start = start.replace('.', ',')
-            text = text.replace(u'\\N', u'\n')
+            text = text.replace('\\N', '\n')
-            output += u'%d\n%s --> %s\n%s\n\n' % (i, start, end, text)
+            output += '%d\n%s --> %s\n%s\n\n' % (i, start, end, text)
-        note_m = self._html_search_regex(r'<div class="showmedia-trailer-notice">(.+?)</div>', webpage, u'trailer-notice', default=u'')
+        webpage = self._download_webpage(webpage_url, video_id, 'Downloading webpage')
-        video_description = self._html_search_regex(r'"description":"([^"]+)', webpage, u'video_description', default=u'')
+        video_title = self._html_search_regex(r'<h1[^>]*>(.+?)</h1>', webpage, 'video_title', flags=re.DOTALL)
-        video_upload_date = self._html_search_regex(r'<div>Availability for free users:(.+?)</div>', webpage, u'video_upload_date', fatal=False, flags=re.DOTALL)
+        video_upload_date = self._html_search_regex(r'<div>Availability for free users:(.+?)</div>', webpage, 'video_upload_date', fatal=False, flags=re.DOTALL)
-        video_uploader = self._html_search_regex(r'<div>\s*Publisher:(.+?)</div>', webpage, u'video_uploader', fatal=False, flags=re.DOTALL)
+        video_uploader = self._html_search_regex(r'<div>\s*Publisher:(.+?)</div>', webpage, 'video_uploader', fatal=False, flags=re.DOTALL)
-        playerdata_url = compat_urllib_parse.unquote(self._html_search_regex(r'"config_url":"([^"]+)', webpage, u'playerdata_url'))
+        playerdata_url = compat_urllib_parse.unquote(self._html_search_regex(r'"config_url":"([^"]+)', webpage, 'playerdata_url'))
-        playerdata = self._download_webpage(playerdata_req, video_id, note=u'Downloading media info')
+        playerdata_req.data = compat_urllib_parse.urlencode({'current_page': webpage_url})
-        video_thumbnail = self._search_regex(r'<episode_image_url>([^<]+)', playerdata, u'thumbnail', fatal=False)
+        stream_id = self._search_regex(r'<media_id>([^<]+)', playerdata, 'stream_id')
-            streamdata_req = compat_urllib_request.Request(u'http://www.crunchyroll.com/xml/')
+            video_format = fmt+'p'
-            video_play_path = self._search_regex(r'<file>([^<]+)', streamdata, u'video_play_path')
+            streamdata_req.data = 'req=RpcApiVideoEncode%5FGetStreamInfo&video%5Fencode%5Fquality='+stream_quality+'&media%5Fid='+stream_id+'&video%5Fformat='+stream_format
-                u'format_id': video_format,
+                'url': video_url,
-            data = self._search_regex(r'<data>([^<]+)', sub_page, u'subtitle_data', fatal=False)
+            sub_page = self._download_webpage('http://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml&subtitle_script_id='+sub_id,\
-            lang_code = self._search_regex(r'lang_code=\'([^\']+)', subtitle, u'subtitle_lang_code', fatal=False)
+            subtitle = self._decrypt_subtitles(data, iv, id).decode('utf-8')
-            u'formats':     formats,
+            'id':          video_id,
-    _VALID_URL = r'''(?x)https?://(?:www.)?comedycentral.com/
+    _VALID_URL = r'''(?x)https?://(?:www\.)?comedycentral\.com/
-        m = re.match(r'^rtmpe?://.*?/(?P<finalid>gsp.comedystor/.*)$', rtmp_video_url)
+        m = re.match(r'^rtmpe?://.*?/(?P<finalid>gsp\.comedystor/.*)$', rtmp_video_url)
-            r'<iframe[^>]+?src="((?:https?:)?//player.vimeo.com/video/.+?)"', webpage)
+            r'<iframe[^>]+?src="((?:https?:)?//player\.vimeo\.com/video/.+?)"', webpage)
-            r'<embed[^>]+?src="(https?://(?:www\.)?vimeo.com/moogaloop.swf.+?)"', webpage)
+            r'<embed[^>]+?src="(https?://(?:www\.)?vimeo\.com/moogaloop\.swf.+?)"', webpage)
-        mobj = re.search(r'<iframe .*?src="(http://mpora\.com/videos/[^"]+)"', webpage)
+        mobj = re.search(r'<iframe .*?src="(http://mpora\.(?:com|de)/videos/[^"]+)"', webpage)
-            r'<iframe[^>]+?src=(["\'])(?P<url>https?://embed\.live.huffingtonpost\.com/.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>https?://embed\.live\.huffingtonpost\.com/.+?)\1', webpage)
-        return OoyalaIE._build_url_result(ooyala_code)
+        ooyala_url = self._twitter_search_player(webpage)
-    _VALID_URL = r'https?://.+?\.ooyala\.com/.*?embedCode=(?P<id>.+?)(&|$)'
+    _VALID_URL = r'https?://.+?\.ooyala\.com/.*?(?:embedCode|ec)=(?P<id>.+?)(&|$)'
-        }
+        'url': 'http://www.myspass.de/myspass/shows/tvshows/absolute-mehrheit/Absolute-Mehrheit-vom-17022013-Die-Highlights-Teil-2--/11741/',
-            raise ExtractorError(u'Unable to extract download url')
+            raise ExtractorError('Unable to extract download url')
-            raise ExtractorError(u'Unable to extract title')
+            raise ExtractorError('Unable to extract title')
-        info = {
+
-            'description': description
+            'description': description,
-        return [info]
+from __future__ import unicode_literals
-            u"age_limit": 18,
+        'url': 'http://www.youjizz.com/videos/zeichentrick-1-2189178.html',
-            webpage, u'title').strip()
+            webpage, 'title').strip()
-            raise ExtractorError(u'ERROR: unable to extract embed page')
+            raise ExtractorError('ERROR: unable to extract embed page')
-                                                   u'Downloading playlist page')
+                                                   'Downloading playlist page')
-                raise ExtractorError(u'Unable to extract video url')
+                raise ExtractorError('Unable to extract video url')
-                'age_limit': age_limit}
+                                           webpage, 'video URL')
-        return [info]
+        return {
-        }
+        'url': 'http://www.rbmaradio.com/shows/ford-lopatin-live-at-primavera-sound-2011',
-            webpage, u'json data', flags=re.MULTILINE)
+            webpage, 'json data', flags=re.MULTILINE)
-            raise ExtractorError(u'Invalid JSON: ' + str(e))
+            raise ExtractorError('Invalid JSON: ' + str(e))
-                'duration': data.get('duration'),
+
-        return [info]
+from __future__ import unicode_literals
-            u"title": u"A Few of My Favorite [Python] Things"
+        "name": "InfoQ",
-        real_id = compat_urllib_parse.unquote(base64.b64decode(mobj.group(1).encode('ascii')).decode('utf-8'))
+        encoded_id = self._search_regex(r"jsclassref ?= ?'([^']*)'", webpage, 'encoded id')
-            webpage, u'title')
+            webpage, 'title')
-            webpage, u'description', fatal=False)
+            webpage, 'description', fatal=False)
-        info = {
+        return {
-        return [info]
+from __future__ import unicode_literals
-    _VALID_URL=r'https?://(?:www\.)?tu\.tv/videos/(?P<id>[^/?]+)'
+    _VALID_URL = r'https?://(?:www\.)?tu\.tv/videos/(?P<id>[^/?]+)'
-        }
+        'url': 'http://tu.tv/videos/noah-en-pabellon-cuahutemoc',
-        internal_id = self._search_regex(r'codVideo=([0-9]+)', webpage, u'internal video ID')
+        internal_id = self._search_regex(r'codVideo=([0-9]+)', webpage, 'internal video ID')
-        data_content = self._download_webpage(data_url, video_id, note=u'Downloading video info')
+        data_url = 'http://tu.tv/flvurl.php?codVideo=' + str(internal_id)
-        info = {
+        return {
-        return [info]
+from __future__ import unicode_literals
-        }
+        'url': 'http://www.nba.com/video/games/nets/2012/12/04/0021200253-okc-bkn-recap.nba/index.html',
-        video_url = u'http://ht-mobile.cdn.turner.com/nba/big' + video_id + '_nba_1280x720.mp4'
+        video_url = 'http://ht-mobile.cdn.turner.com/nba/big' + video_id + '_nba_1280x720.mp4'
-        info = {
+        return {
-__version__ = '2014.01.28.1'
+__version__ = '2014.01.29'
-                    'id': 'video_id',
+                    'id': video_id,
-            u"title": u"Most unlucky car accident"
+        'url': 'http://www.liveleak.com/view?i=757_1364311680',
-            webpage, u'video URL')
+        video_url = self._search_regex(
-
+        video_uploader = self._html_search_regex(
-            'id':  video_id,
+        return {
-        return [info]
+from __future__ import unicode_literals
-    IE_NAME = u'ivi'
+    IE_DESC = 'ivi.ru'
-                u'thumbnail': u'http://thumbs.ivi.ru/f20.vcp.digitalaccess.ru/contents/d/1/c3c885163a082c29bceeb7b5a267a6.jpg',
+            'url': 'http://www.ivi.ru/watch/53141',
-            u'skip': u'Only works from Russia',
+            'skip': 'Only works from Russia',
-                u'thumbnail': u'http://thumbs.ivi.ru/f7.vcp.digitalaccess.ru/contents/8/e/bc2f6c2b6e5d291152fdd32c059141.jpg',
+            'url': 'http://www.ivi.ru/watch/dezhurnyi_angel/74791',
-            u'skip': u'Only works from Russia',
+            'skip': 'Only works from Russia',
-    
+
-        m = re.search(u'(?s)<a href="#" id="view-comments" class="action-button dim gradient">\s*ÐÐ¾Ð¼Ð¼ÐµÐ½ÑÐ°ÑÐ¸Ð¸:\s*(?P<commentcount>\d+)\s*</a>', html)
+        m = re.search('(?s)<a href="#" id="view-comments" class="action-button dim gradient">\s*ÐÐ¾Ð¼Ð¼ÐµÐ½ÑÐ°ÑÐ¸Ð¸:\s*(?P<commentcount>\d+)\s*</a>', html)
-                            ]
+        data = {'method': 'da.content.get',
-        video_json_page = self._download_webpage(request, video_id, u'Downloading video JSON')
+        video_json_page = self._download_webpage(request, video_id, 'Downloading video JSON')
-            raise ExtractorError(u'Unable to download video %s: %s' % (video_id, error[u'message']), expected=True)
+        if 'error' in video_json:
-        result = video_json[u'result']
+        result = video_json['result']
-        } for x in result[u'files'] if x[u'content_format'] in self._known_formats]
+            'url': x['url'],
-            raise ExtractorError(u'No media links available for %s' % video_id)
+            raise ExtractorError('No media links available for %s' % video_id)
-        title = result[u'title']
+        duration = result['duration']
-        previews = result[u'preview']
+        previews = result['preview']
-        thumbnail = previews[-1][u'url'] if len(previews) > 0 else None
+        thumbnail = previews[-1]['url'] if len(previews) > 0 else None
-        video_page = self._download_webpage(url, video_id, u'Downloading video page')
+        video_page = self._download_webpage(url, video_id, 'Downloading video page')
-    IE_NAME = u'ivi:compilation'
+    IE_DESC = 'ivi.ru compilations'
-            season_page = self._download_webpage(url, compilation_id, u'Downloading season %s web page' % season_id)
+            season_page = self._download_webpage(url, compilation_id, 'Downloading season %s web page' % season_id)
-            playlist_title = self._html_search_meta(u'title', season_page, u'title')
+            playlist_title = self._html_search_meta('title', season_page, 'title')
-            compilation_page = self._download_webpage(url, compilation_id, u'Downloading compilation web page')
+            compilation_page = self._download_webpage(url, compilation_id, 'Downloading compilation web page')
-            playlist_title = self._html_search_meta(u'title', compilation_page, u'title')
+            playlist_title = self._html_search_meta('title', compilation_page, 'title')
-                                                         compilation_id, u'Downloading season %s web page' % season_id)
+                    season_page = self._download_webpage(
-# encoding: utf-8
+from __future__ import unicode_literals
-    not always possible to do.    
+    not always possible to do.
-    IE_NAME = u'channel9'
+    IE_DESC = 'Channel 9'
-                u'session_speakers': [ u'Ed Blankenship', u'Andrew Coates', u'Brady Gaster', u'Patrick Klug', u'Mads Kristensen' ],
+            'url': 'http://channel9.msdn.com/Events/TechEd/Australia/2013/KOS002',
-                u'authors': [ u'Mike Wilmot' ],
+            'url': 'http://channel9.msdn.com/posts/Self-service-BI-with-Power-BI-nuclear-testing',
-            exponent = [u'B', u'KB', u'MB', u'GB', u'TB', u'PB', u'EB', u'ZB', u'YB'].index(units.upper())
+            exponent = ['B', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'].index(units.upper())
-            'format': u'%s (%s)' % (x.group('quality'), x.group('note')),
+            'format': '%s (%s)' % (x.group('quality'), x.group('note')),
-        title = self._html_search_meta(u'title', html, u'title')
+        title = self._html_search_meta('title', html, 'title')
-            TITLE_SUFFIX = u' (Channel 9)'
+            TITLE_SUFFIX = ' (Channel 9)'
-        return self._html_search_meta(u'description', html, u'description')
+        return self._html_search_meta('description', html, 'description')
-            self._downloader.report_warning(u'None of recording, slides or zip are available for %s' % content_path)
+            self._downloader.report_warning('None of recording, slides or zip are available for %s' % content_path)
-        rss = self._download_xml(self._RSS_URL % content_path, content_path, u'Downloading RSS')
+        rss = self._download_xml(self._RSS_URL % content_path, content_path, 'Downloading RSS')
-        webpage = self._download_webpage(url, content_path, u'Downloading web page')
+        webpage = self._download_webpage(url, content_path, 'Downloading web page')
-            raise ExtractorError(u'Search.PageType not found, don\'t know how to process this page', expected=True)
+            raise ExtractorError('Search.PageType not found, don\'t know how to process this page', expected=True)
-            raise ExtractorError(u'Unexpected Search.PageType %s' % page_type, expected=True)
+            raise ExtractorError('Unexpected Search.PageType %s' % page_type, expected=True)
-    IE_NAME = u'smotri'
+    IE_DESC = 'Smotri.com'
-                u'thumbnail': u'http://frame6.loadup.ru/8b/a9/2610366.3.3.jpg',
+            'url': 'http://smotri.com/video/view/?id=v261036632ab',
-                u'thumbnail': u'http://frame4.loadup.ru/03/ed/57591.2.3.jpg',
+            'url': 'http://smotri.com/video/view/?id=v57591cb20',
-                u'description': u'TOCCA_A_NOI_-_LE_COSE_NON_VANNO_CAMBIAMOLE_ORA-1, Ð²Ð¸Ð´ÐµÐ¾ TOCCA_A_NOI_-_LE_COSE_NON_VANNO_CAMBIAMOLE_ORA-1',
+            'url': 'http://smotri.com/video/view/?id=v1390466a13c',
-                u'videopassword': u'qwerty',
+            'params': {
-                u'description': u'ÑÑÐ¾Ñ ÑÐ¾Ð»Ð¸Ðº Ð½Ðµ Ð¿Ð¾ÐºÐ°Ð¶ÑÑ Ð¿Ð¾ Ð¢Ð, Ð²Ð¸Ð´ÐµÐ¾ ÑÑÐ¾Ñ ÑÐ¾Ð»Ð¸Ðº Ð½Ðµ Ð¿Ð¾ÐºÐ°Ð¶ÑÑ Ð¿Ð¾ Ð¢Ð',
+            'url': 'http://smotri.com/video/view/?id=v15408898bcf',
-                u'videopassword': u'333'
+            'params': {
-    
+
-        video_json_page = self._download_webpage(video_json_url, video_id, u'Downloading video JSON')
+        video_json_page = self._download_webpage(video_json_url, video_id, 'Downloading video JSON')
-        
+
-        elif status == self._PASSWORD_DETECTED:  # The video is protected by a password, retry with
+            raise ExtractorError('Video %s does not exist' % video_id, expected=True)
-                raise ExtractorError(u'This video is protected by a password, use the --video-password option', expected=True)
+                raise ExtractorError('This video is protected by a password, use the --video-password option', expected=True)
-            video_json_page = self._download_webpage(video_json_url, video_id, u'Downloading video JSON (video-password set)')
+            video_json_page = self._download_webpage(video_json_url, video_id, 'Downloading video JSON (video-password set)')
-        
+                raise ExtractorError('Video password is invalid', expected=True)
-        
+            raise ExtractorError('Unexpected status value %s' % status)
-        
+
-        video_page = self._download_webpage(video_page_url, video_id, u'Downloading video page')
+        video_page = self._download_webpage(video_page_url, video_id, 'Downloading video page')
-            u'warning message', default=None)
+            'warning message', default=None)
-                u'Video %s may not be available; smotri said: %s ' %
+                'Video %s may not be available; smotri said: %s ' %
-        if re.search(u'EroConfirmText">', video_page) is not None:
+        if re.search('EroConfirmText">', video_page) is not None:
-                video_page, u'confirm string')
+                video_page, 'confirm string')
-            video_page = self._download_webpage(confirm_url, video_id, u'Downloading video page (age confirmed)')
+            video_page = self._download_webpage(confirm_url, video_id, 'Downloading video page (age confirmed)')
-        
+
-        video_title = self._search_meta(u'name', video_page, u'title')
+        video_title = self._search_meta('name', video_page, 'title')
-        END_TEXT = u' Ð½Ð° ÑÐ°Ð¹ÑÐµ Smotri.com'
+        video_description = self._search_meta('description', video_page)
-        START_TEXT = u'Ð¡Ð¼Ð¾ÑÑÐµÑÑ Ð¾Ð½Ð»Ð°Ð¹Ð½ ÑÐ¾Ð»Ð¸Ðº '
+        START_TEXT = 'Ð¡Ð¼Ð¾ÑÑÐµÑÑ Ð¾Ð½Ð»Ð°Ð¹Ð½ ÑÐ¾Ð»Ð¸Ðº '
-        video_thumbnail = self._search_meta(u'thumbnail', video_page)
+        video_thumbnail = self._search_meta('thumbnail', video_page)
-        upload_date_str = self._search_meta(u'uploadDate', video_page, u'upload date')
+        upload_date_str = self._search_meta('uploadDate', video_page, 'upload date')
-        duration_str = self._search_meta(u'duration', video_page)
+
-        
+
-        
+            '<div class="DescrUser"><div>ÐÐ²ÑÐ¾Ñ.*?onmouseover="popup_user_info[^"]+">(.*?)</a>',
-        
+            '<div class="DescrUser"><div>ÐÐ²ÑÐ¾Ñ.*?onmouseover="popup_user_info\\(.*?\'([^\']+)\'\\);">',
-                
+            'ÐÐ±ÑÐµÐµ ÐºÐ¾Ð»Ð¸ÑÐµÑÑÐ²Ð¾ Ð¿ÑÐ¾ÑÐ¼Ð¾ÑÑÐ¾Ð².*?<span class="Number">(\\d+)</span>',
-    IE_NAME = u'smotri:community'
+    IE_DESC = 'Smotri.com community videos'
-        rss = self._download_xml(url, community_id, u'Downloading community RSS')
+        rss = self._download_xml(url, community_id, 'Downloading community RSS')
-            u'^ÐÐ¸Ð´ÐµÐ¾ ÑÐ¾Ð¾Ð±ÑÐµÑÑÐ²Ð° "([^"]+)"$', description_text, u'community title')
+            '^ÐÐ¸Ð´ÐµÐ¾ ÑÐ¾Ð¾Ð±ÑÐµÑÑÐ²Ð° "([^"]+)"$', description_text, 'community title')
-    IE_NAME = u'smotri:user'
+    IE_DESC = 'Smotri.com user videos'
-        rss = self._download_xml(url, user_id, u'Downloading user RSS')
+        rss = self._download_xml(url, user_id, 'Downloading user RSS')
-            u'user nickname')
+            '^ÐÐ¸Ð´ÐµÐ¾ ÑÐµÐ¶Ð¸ÑÑÐµÑÐ° (.*)$', description_text,
-    IE_NAME = u'smotri:broadcast'
+    IE_DESC = 'Smotri.com broadcasts'
-        broadcast_page = self._download_webpage(broadcast_url, broadcast_id, u'Downloading broadcast page')
+        broadcast_page = self._download_webpage(broadcast_url, broadcast_id, 'Downloading broadcast page')
-            raise ExtractorError(u'Broadcast %s does not exist' % broadcast_id, expected=True)
+        if re.search('>Ð ÐµÐ¶Ð¸ÑÑÐµÑ Ñ Ð»Ð¾Ð³Ð¸Ð½Ð¾Ð¼ <br/>"%s"<br/> <span>Ð½Ðµ ÑÑÑÐµÑÑÐ²ÑÐµÑ<' % broadcast_id, broadcast_page) is not None:
-        if re.search(u'EroConfirmText">', broadcast_page) is not None:
+        if re.search('EroConfirmText">', broadcast_page) is not None:
-                u'password': password,
+                raise ExtractorError('Erotic broadcasts allowed only for registered users, '
-            request = compat_urllib_request.Request(login_url, login_data)
+
-                request, broadcast_id, note=u'Logging in and confirming age')
+            broadcast_page = self._download_webpage(request, broadcast_id, 'Logging in and confirming age')
-                raise ExtractorError(u'Unable to log in: bad username or password', expected=True)
+            if re.search('>ÐÐµÐ²ÐµÑÐ½ÑÐ¹ Ð»Ð¾Ð³Ð¸Ð½ Ð¸Ð»Ð¸ Ð¿Ð°ÑÐ¾Ð»Ñ<', broadcast_page) is not None:
-            broadcast_page, u'broadcast ticket')
+            'window\.broadcast_control\.addFlashVar\\(\'file\', \'([^\']+)\'\\);',
-        broadcast_json_page = self._download_webpage(url, broadcast_id, u'Downloading broadcast JSON')
+        broadcast_json_page = self._download_webpage(url, broadcast_id, 'Downloading broadcast JSON')
-                raise ExtractorError(u'This broadcast is protected by a password, use the --video-password option', expected=True)
+                raise ExtractorError('This broadcast is protected by a password, use the --video-password option', expected=True)
-                raise ExtractorError(u'Broadcast %s is offline' % broadcast_id, expected=True)
+                raise ExtractorError('Broadcast %s is offline' % broadcast_id, expected=True)
-                raise ExtractorError(u'Unexpected broadcast rtmp URL')
+                raise ExtractorError('Unexpected broadcast rtmp URL')
-            raise ExtractorError(u'Unexpected broadcast JSON')
+                raise ExtractorError('Bad broadcast password', expected=True)
-            u"title": u"\"People Are Awesome 2013\" Is Absolutely Awesome"
+        "url": "http://9gag.tv/v/1912",
-        u'add_ie': [u'Youtube']
+        'add_ie': ['Youtube']
-                data-video-meta="([^"]+)"''', webpage, u'video metadata')
+                data-video-meta="([^"]+)"''', webpage, 'video metadata')
-    IE_NAME = u'keek'
+    IE_NAME = 'keek'
-        }
+        'url': 'https://www.keek.com/ytdl/keeks/NODfbab',
-        thumbnail = u'http://cdn.keek.com/keek/thumbnail/%s/w100/h75' % video_id
+        video_url = 'http://cdn.keek.com/keek/video/%s' % video_id
-                'uploader': uploader
+        uploader = self._html_search_regex(
-        return [info]
+from __future__ import unicode_literals
-        }
+        'url': 'http://www.funnyordie.com/videos/0732f586d7/heart-shaped-box-literal-video-version',
-            webpage, u'video URL', flags=re.DOTALL)
+            webpage, 'video URL', flags=re.DOTALL)
-        info = {
+        return {
-        return [info]
+from __future__ import unicode_literals
-            u"age_limit": 18,
+        'url': 'http://www.pornhd.com/videos/1962/sierra-day-gets-his-cum-all-over-herself-hd-porn-video',
-        video_url = compat_urllib_parse.unquote(video_url)
+        next_url = self._html_search_regex(
-__version__ = '2014.01.28'
+__version__ = '2014.01.28.1'
-__version__ = '2014.01.27.2'
+__version__ = '2014.01.28'
-            }
+        {
-    IE_DESC = 'Rutube videos'    
+    IE_DESC = 'Rutube videos'
-    IE_DESC = 'Rutube channels'    
+    IE_DESC = 'Rutube channels'
-                                                   channel_id, 'Downloading page %s' % pagenum)
+            api_response = self._download_webpage(
-                break;
+            if not results:
-                break;
+            if not page['has_next']:
-    IE_DESC = 'Rutube movies'    
+    IE_DESC = 'Rutube movies'
-                                            'Downloading movie JSON')
+        api_response = self._download_webpage(
-    _PAGE_TEMPLATE = 'http://rutube.ru/api/video/person/%s/?page=%s&format=json'
+    _PAGE_TEMPLATE = 'http://rutube.ru/api/video/person/%s/?page=%s&format=json'
-        result = ie.extract('http://www.imdb.com/list/sMjedvGDd8U')
+        result = ie.extract('http://www.imdb.com/list/JFs9NWw6XI0')
-        self.assertTrue(len(result['entries']) >= 48)
+        self.assertEqual(result['id'], 'JFs9NWw6XI0')
-            for m in re.findall(r'href="(/video/imdb/vi[^"]+)"', webpage)]
+            for m in re.findall(r'href="(/video/imdb/vi[^"]+)"\s+data-type="playlist"', webpage)]
-    RutubeMovieIE
+    RutubeMovieIE,
-    _VALID_URL = r'https?://rutube\.ru/video/(?P<long_id>\w+)'
+    _VALID_URL = r'https?://rutube\.ru/video/(?P<id>[\da-z]{32})'
-        long_id = mobj.group('long_id')
+        video_id = mobj.group('id')
-                                              long_id, 'Downloading video JSON')
+        api_response = self._download_webpage('http://rutube.ru/api/video/%s/?format=json' % video_id,
-                                              long_id, 'Downloading trackinfo JSON')
+        api_response = self._download_webpage('http://rutube.ru/api/play/trackinfo/%s/?format=json' % video_id,
-        return self._extract_videos(movie_id, movie_name)
+        return self._extract_videos(movie_id, movie_name)
-    compat_urlparse,
+    unified_strdate,
-        trackinfo = self._get_api_response(short_id, 'trackinfo')
+        
-            'title': trackinfo['title'],
+            'id': video['id'],
-            'thumbnail': options['thumbnail_url'],
+            'thumbnail': video['thumbnail_url'],
-            response_json = self._download_webpage(self._PAGE_TEMPLATE % (channel_id, pagenum),
+            api_response = self._download_webpage(self._PAGE_TEMPLATE % (channel_id, pagenum),
-                raise ExtractorError('Channel %s does not exist' % channel_id, expected=True)
+            page = json.loads(api_response)
-            entries.extend(self.url_result(v['video_url'], 'Rutube') for v in results)
+            entries.extend(self.url_result(result['video_url'], 'Rutube') for result in results)
-        movie_json = self._download_webpage(self._MOVIE_TEMPLATE % movie_id, movie_id,
+        api_response = self._download_webpage(self._MOVIE_TEMPLATE % movie_id, movie_id,
-            raise ExtractorError('Movie %s does not exist' % movie_id, expected=True)
+        movie = json.loads(api_response)
-    _VALID_URL = r'http://(?P<blog_name>.*?)\.tumblr\.com/((post)|(video))/(?P<id>\d*)/(.*?)'
+    _VALID_URL = r'http://(?P<blog_name>.*?)\.tumblr\.com/((post)|(video))/(?P<id>\d*)($|/)'
-    _PLAYLIST_URL_TEMPLATE = 'http://c.brightcove.com/services/json/experience/runtime/?command=get_programming_for_experience&playerKey=%s'
+        {
-                                               player_key, 'Downloading playlist information')
+        info_url = 'http://c.brightcove.com/services/json/experience/runtime/?command=get_programming_for_experience&playerKey=%s' % player_key
-from .rutube import RutubeIE
+from .rutube import (
-            u'uploader_id': u'29790',
+        'url': 'http://rutube.ru/video/3eac3b4561676c17df9132a9a1e62e3e/',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-            u'Downloading %s json' % subpath)
+            'Downloading %s json' % subpath)
-            raise ExtractorError(u'Couldn\'t find m3u8 manifest url')
+            raise ExtractorError('Couldn\'t find m3u8 manifest url')
-        }
+        },
-__version__ = '2014.01.27.1'
+__version__ = '2014.01.27.2'
-    _MEDIA_STREAM = r'mediaCollection\.addMediaStream\((?P<media_type>\d+), (?P<quality>\d+), "(?P<rtmp_url>[^"]*)", "(?P<video_url>[^"]*)", "[^"]*"\)'
+    _VALID_URL = r'^https?://(?:(?:www\.)?ardmediathek\.de|mediathek\.daserste\.de)/(?:.*/)(?P<video_id>[^/\?]+)(?:\?.*)?'
-            u"title": u"11.04.2013 09:23 Uhr - Tagesschau in 100 Sekunden"
+        'url': 'http://www.ardmediathek.de/das-erste/guenther-jauch/edward-snowden-im-interview-held-oder-verraeter?documentId=19288786',
-        u'skip': u'Requires rtmpdump'
+        'skip': 'Blocked outside of Germany',
-        streams = [mo.groupdict() for mo in re.finditer(self._MEDIA_STREAM, html)]
+        webpage = self._download_webpage(url, video_id)
-        return [info]
+            if '"fsk"' in webpage:
-        'file': 'mission-impossible-outtakes.mp4',
+        'file': '614784.mp4',
-        }
+            'title': 'MythBusters: Mission Impossible Outtakes',
-        formats_json = json.loads(formats_raw)
+
-        for f in formats_json:
+        for f in info['mp4']:
-            'formats': formats
+            'id': info['contentId'],
-)
+translation_table = {
-    _TESTS = {
+    _VALID_URL = r'''(?x)http://(?:www\.)?cliphunter\.com/w/
-        video_title = self._search_regex(r'mediaTitle = "([^"]+)"', webpage, 'title')
+        pl_fiji = self._search_regex(
-        video_url = string.translate(pl_fiji.encode(), translation_table)
+        video_url = ''.join(translation_table.get(c, c) for c in pl_fiji)
-            'format': pl_c_qual,
+from __future__ import unicode_literals
-    IE_NAME = u'cliphunter'
+    IE_NAME = 'cliphunter'
-            u'title': u'Fun Jynx Maze solo',
+    _TESTS = {
-    }]
+    }
-        video_title = re.search(r'mediaTitle = "([^"]+)"', webpage).group(1)
+        pl_fiji = self._search_regex(r'pl_fiji = \'([^\']+)\'', webpage, 'video data')
-            'ext': determine_ext(video_url),
+    'Mike Col',
-        video_thumbnail = self._search_regex(r'posters(.*?)\[\\x22(?P<thumb>.*?)\\x22',
+        video_thumbnail = self._search_regex(
-        if video_thumbnail: video_thumbnail = video_thumbnail.replace('\\', '')
+        if video_thumbnail:
-            u"title": u"tatiana maslany news"
+        'url': 'http://tatianamaslanydaily.tumblr.com/post/54196191430/orphan-black-dvd-extra-behind-the-scenes',
-           raise ExtractorError(u'Unable to extract video')
+            raise ExtractorError('Unable to extract video')
-            webpage, u'thumbnail', fatal=False)  # We pick the first poster
+            webpage, 'thumbnail', fatal=False)  # We pick the first poster
-            webpage, u'title', flags=re.DOTALL)
+            webpage, 'title', flags=re.DOTALL)
-__version__ = '2014.01.27'
+__version__ = '2014.01.27.1'
-    _VALID_URL = r'https?://(?:www\.)?la7\.tv/richplayer/\?assetid=(?P<id>[0-9]+)'
+    _VALID_URL = r'''(?x)
-__version__ = '2014.01.23.4'
+__version__ = '2014.01.27'
-        'md5': 'TODO',
+        'md5': '55f5e8981c1c80a64706a44b74833de8',
-            'description': 'TODO',
+            'title': 'Legalese It! with @MikeSacksHP',
-        upload_date = unified_strdate(data['schedule']['started_at'])
+        upload_date = unified_strdate(data['schedule']['starts_at'])
-        ]
+        'data_files': data_files,
-    if determine_ext(url) == u'm3u8':
+    if (protocol == 'm3u8') or (protocol is None and determine_ext(url) == 'm3u8'):
-                                 "http", "https", "rtsp", "rtmp" or so.
+                                 "http", "https", "rtsp", "rtmp", "m3u8" or so.
-            r'<iframe[^>]+?src=(["\'])(?P<url>https://www.facebook.com/video/embed.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>https://www\.facebook\.com/video/embed.+?)\1', webpage)
-        req = compat_urllib_request.Request(self._AGE_URL, compat_urllib_parse.urlencode(age_form))
+        req = compat_urllib_request.Request(self._AGE_URL,
-    _AGE_URL = 'http://www.youtube.com/verify_age?next_url=/&gl=US&hl=en'
+    _AGE_URL = 'https://www.youtube.com/verify_age?next_url=/&gl=US&hl=en'
-                'http://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id,
+                'https://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id,
-            url = u'http://www.youtube.com/api/timedtext?' + params
+            url = u'https://www.youtube.com/api/timedtext?' + params
-    _MORE_PAGES_URL = 'http://www.youtube.com/c4_browse_ajax?action_load_more_videos=1&flow=list&paging=%s&view=0&sort=da&channel_id=%s'
+    _MORE_PAGES_URL = 'https://www.youtube.com/c4_browse_ajax?action_load_more_videos=1&flow=list&paging=%s&view=0&sort=da&channel_id=%s'
-    _TEMPLATE_URL = 'http://gdata.youtube.com/feeds/api/users/%s'
+    _TEMPLATE_URL = 'https://gdata.youtube.com/feeds/api/users/%s'
-    _GDATA_URL = 'http://gdata.youtube.com/feeds/api/users/%s/uploads?max-results=%d&start-index=%d&alt=json'
+    _GDATA_URL = 'https://gdata.youtube.com/feeds/api/users/%s/uploads?max-results=%d&start-index=%d&alt=json'
-        return 'http://www.youtube.com/feed_ajax?%s=1&feed_name=%s&paging=%%s' % (action, self._FEED_NAME)
+        return 'https://www.youtube.com/feed_ajax?%s=1&feed_name=%s&paging=%%s' % (action, self._FEED_NAME)
-        result = ie.extract('yttoplist:music:Top Tracks')
+        result = ie.extract('yttoplist:music:Trending')
-        playlist_re = 'href="([^"]+?%s[^"]+?)"' % re.escape(query)
+        playlist_re = 'href="([^"]+?%s.*?)"' % re.escape(query)
-    
+
-        if formats[0] is not info_dict: 
+        if formats[0] is not info_dict:
-            # element in the 'formats' field in info_dict is info_dict itself, 
+            # element in the 'formats' field in info_dict is info_dict itself,
-            request.add_header('Range','bytes=0-10240')
+            request.add_header('Range', 'bytes=0-10240')
-                request.add_header('Range','bytes=%d-' % resume_len)
+                request.add_header('Range', 'bytes=%d-' % resume_len)
-            max_data_len =  self.params.get("max_filesize", None)
+            max_data_len = self.params.get("max_filesize", None)
-            self.report_error(u'MMS or RTSP download detected but "%s" could not be run' % args[0] )
+            self.report_error(u'MMS or RTSP download detected but "%s" could not be run' % args[0])
-        # Download using mplayer. 
+        # Download using mplayer.
-                h = u'___' + hashlib.md5(url).hexdigest()
+                h = u'___' + hashlib.md5(url.encode('utf-8')).hexdigest()
-            u'description': u'Folge 1 - Der Einzug',
+        'url': 'http://rtl-now.rtl.de/ahornallee/folge-1.php?film_id=90419&player=1&season=1',
-            u'skip_download': True,
+        'params': {
-        u'skip': u'Only works from Germany',
+        'skip': 'Only works from Germany',
-            u'thumbnail': u'http://autoimg.static-fra.de/rtl2now/219850/1500x1500/image2.jpg',
+        'url': 'http://rtl2now.rtl2.de/aerger-im-revier/episode-15-teil-1.php?film_id=69756&player=1&season=2&index=5',
-            u'skip_download': True,
+        'params': {
-        u'skip': u'Only works from Germany',
+        'skip': 'Only works from Germany',
-            u'description': u'SÃ¼dafrika-Reporter II',
+        'url': 'http://www.voxnow.de/voxtours/suedafrika-reporter-ii.php?film_id=13883&player=1&season=17',
-            u'skip_download': True,
+        'params': {
-            u'thumbnail': u'http://autoimg.static-fra.de/superrtlnow/287529/1500x1500/image2.jpg'
+        'url': 'http://superrtlnow.de/medicopter-117/angst.php?film_id=99205&player=1',
-            u'skip_download': True,
+        'params': {
-            u'description': u'Episode 1',
+        'url': 'http://www.n-tvnow.de/top-gear/episode-1-2013-01-01-00-00-00.php?film_id=124903&player=1&season=10',
-            u'skip_download': True,
+        'params': {
-        u'skip': u'Only works from Germany',
+        'skip': 'Only works from Germany',
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        video_id = mobj.group(u'video_id')
+        webpage_url = 'http://' + mobj.group('url')
-            webpage, u'playerdata_url')
+        video_title = self._html_search_regex(
-            video_description = mobj.group(u'description')
+            video_description = mobj.group('description')
-                video_upload_date = u'20' + mobj.group('upload_date_y')
+                video_upload_date = '20' + mobj.group('upload_date_y')
-                video_upload_date += mobj.group('upload_date_m')+mobj.group('upload_date_d')
+                video_upload_date += mobj.group('upload_date_m') + mobj.group('upload_date_d')
-            self._downloader.report_warning(u'Unable to extract description and upload date')
+            self._downloader.report_warning('Unable to extract description and upload date')
-            video_thumbnail = mobj.group(u'thumbnail')
+            video_thumbnail = mobj.group('thumbnail')
-        video_player_url = video_page_url + u'includes/vodplayer.swf'
+            raise ExtractorError('Unable to extract media URL')
-            'title':       video_title,
+        return {
-        }]
+            'thumbnail': video_thumbnail,
-    _VALID_URL = r'http://(video|www).(?P<site>%s).com/(?P<type>watch|series|video)/(?P<id>.+)' % '|'.join(_SITES.keys())
+    _VALID_URL = r'http://(video|www)\.(?P<site>%s)\.com/(?P<type>watch|series|video)/(?P<id>.+)' % '|'.join(_SITES.keys())
-    _VALID_URL = r'https://www.freespeech.org/video/(?P<title>.+)'
+    _VALID_URL = r'https://www\.freespeech\.org/video/(?P<title>.+)'
-    _VALID_URL = r'http://www\.hotnewhiphop.com/.*\.(?P<id>.*)\.html'
+    _VALID_URL = r'http://www\.hotnewhiphop\.com/.*\.(?P<id>.*)\.html'
-    _VALID_URL = r'(?:https?://)?vimeo.\com/channels/(?P<id>[^/]+)'
+    _VALID_URL = r'(?:https?://)?vimeo\.com/channels/(?P<id>[^/]+)'
-    _VALID_URL = r'(?:https?://)?vimeo.\com/(?P<name>[^/]+)(?:/videos|[#?]|$)'
+    _VALID_URL = r'(?:https?://)?vimeo\.com/(?P<name>[^/]+)(?:/videos|[#?]|$)'
-    _VALID_URL = r'(?:https?://)?vimeo.\com/album/(?P<id>\d+)'
+    _VALID_URL = r'(?:https?://)?vimeo\.com/album/(?P<id>\d+)'
-    _VALID_URL = r'(?:https?://)?vimeo.\com/groups/(?P<name>[^/]+)'
+    _VALID_URL = r'(?:https?://)?vimeo\.com/groups/(?P<name>[^/]+)'
-    _VALID_URL = r'(?:https?://)?vimeo.\com/[^/]+/review/(?P<id>[^/]+)'
+    _VALID_URL = r'(?:https?://)?vimeo\.com/[^/]+/review/(?P<id>[^/]+)'
-        u'md5': u'49f72e2fd2977e6e518be9836dcf861e',
+        u'md5': u'15e7740f30428abf70f4223478dc1225',
-            u"title": u"Fun Jynx Maze solo",
+            u'title': u'Fun Jynx Maze solo',
-    ]
+    }]
-            'description': '',
+from .cliphunter import CliphunterIE
-__version__ = '2014.01.23.3'
+__version__ = '2014.01.23.4'
-        '168': {'ext': 'webm', 'height': 1080, 'width': 1920, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'VP8', 'acodec': 'none', 'preference': -40},
+        '169': {'ext': 'webm', 'height': 720, 'width': 1280, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'VP8', 'acodec': 'none', 'preference': -40},
-__version__ = '2014.01.23.2'
+__version__ = '2014.01.23.3'
-                res += '%-5s' % fdict['vcodec']
+                if res:
-                res += '%-5s' % fdict['acodec']
+                if fdict['acodec'] == 'none':
-                dct.update(self._formats[itag])
+                if itag in self._formats:
-__version__ = '2014.01.23.1'
+__version__ = '2014.01.23.2'
-        self.increment_downloads()
+
-                raise MaxDownloadsReached()
+        self._num_downloads += 1
-            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported. You can also use the special names "best", "bestaudio", "worst", and "worstaudio"')
+            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported. You can also use the special names "best", "bestaudio", "worst", and "worstaudio". By default, youtube-dl will pick the best quality.')
-    _VALID_URL = r'(?:https?://)?[^/]+/watch\?feature=[a-z_]+$'
+    _VALID_URL = r'''(?x)
-                            (.+?/(((?P<pseudo_id>\d+).html)|(.*?(\#|(vid=))(?P<id>\d+?)($|&))))
+                            (.+?/(((?P<pseudo_id>\d+).html)|(.*?(\#|(vid=)|b/)(?P<id>\d+?)($|&|\-))))
-    }
+    _TESTS = [
-            u'title': u'ãä¸­å½æ°é»ã æé²è¦æ±å·´æ¿é©¬ç«å³éæ¾è¢«æ£è¹å',
+        'url': 'http://video.sina.com.cn/news/vlist/zt/chczlj2013/?opsubject_id=top12#110028898',
-            video_id, u'Downloading video url')
+            video_id, 'Downloading video url')
-            video_id, u'Downloading thumbnail info')
+            video_id, 'Downloading thumbnail info')
-            self.to_screen(u'Getting video id')
+            self.to_screen('Getting video id')
-            video_id = self._search_regex(r'vid:\'(\d+?)\'', webpage, u'video id')
+            video_id = self._search_regex(r'vid:\'(\d+?)\'', webpage, 'video id')
-__version__ = '2014.01.23'
+__version__ = '2014.01.23.1'
-    to_screen(u'Updating to version ' + version_id + '...')
+    to_screen(u'Updating to version ' + version_id + ' ...')
-            u'description': u'From the creators of the beloved TOY STORY films, comes a story that will reunite the gang in a whole new way.',
+        'url': 'http://www.rottentomatoes.com/m/toy_story_3/trailers/11028566/',
-        'md5': '9f48e0e8d58e3076bb236ff412ab62fa',
+        'file': '1509445.mp4',
-            "uploader_id": "Ruseful2011", 
+            "upload_date": "20121014",
-                raise ExtractorError(u'Unable to extract media URL')
+                raise ExtractorError('Unable to extract media URL')
-            return webpage.find('<div class=\'icon iconHD\'') != -1
+            return '<div class=\'icon iconHD\'' in webpage
-            webpage, 'title')
+        video_title = self._html_search_regex(
-            video_description = None
+        mobj = re.search(r'<span>Description: </span>([^<]+)', webpage)
-            self._downloader.report_warning(u'Unable to extract upload date')
+            self._downloader.report_warning('Unable to extract upload date')
-            webpage, 'uploader id', default=u'anonymous')
+        video_uploader_id = self._html_search_regex(
-        video_thumbnail = self._search_regex(r'\'image\':\'(?P<thumbnail>[^\']+)\'',
+        video_thumbnail = self._search_regex(
-            'format': 'hd' if hd else 'sd',
+            'preference': 0,
-        if (not video_mp4_url is None) and (formats[0]['ext'] != 'mp4'):
+        if video_mp4_url is not None:
-                'format_id': 'hd' if hd else 'sd',
+                'format_id': 'mp4-hd' if hd else 'mp4-sd',
-            webpage = self._download_webpage(mrss_url+'?hd', video_id)
+            webpage = self._download_webpage(
-                    'format': 'hd',
+                    'preference': 2,
-            u"age_limit": 18,
+        'url': 'http://xhamster.com/movies/1509445/femaleagent_shy_beauty_takes_the_bait.html',
-            u"age_limit": 18,
+        'url': 'http://xhamster.com/movies/2221348/britney_spears_sexy_booty.html?hd',
-            webpage, u'title')
+            webpage, 'title')
-            webpage, u'uploader id', default=u'anonymous')
+            webpage, 'uploader id', default=u'anonymous')
-            webpage, u'thumbnail', fatal=False)
+            webpage, 'thumbnail', fatal=False)
-        })
+            formats.append({
-        video_url = extract_video_url(webpage)
+
-__version__ = '2014.01.22.5'
+__version__ = '2014.01.23'
-            'title': video_info['displayName'],
+            'title': video_info['displayName'].strip(),
-        data_video_json = self._search_regex(r'data-video=\'(.*?)\'', webpage, u'data video')
+        data_video_json = self._search_regex(r'data-video=["\'](.*?)["\']', webpage, 'data video')
-        qualities = self._search_regex(QUALITIES_RE, f4m_path, u'qualities').strip(',').split(',')
+        qualities = self._search_regex(QUALITIES_RE, f4m_path, 'qualities').strip(',').split(',')
-    verbosity.add_option(
+    selection.add_option(
-__version__ = '2014.01.22.4'
+__version__ = '2014.01.22.5'
-            help=optparse.SUPPRESS_HELP)
+            help='Display sent and read HTTP traffic')
-            }
+            },
-        if dash_manifest_url_lst and dash_manifest_url_lst[0]:
+        if (dash_manifest_url_lst and dash_manifest_url_lst[0] and
-            u"uploader": u"Burn7",
+        'url': 'http://www.newgrounds.com/audio/listen/549479',
-        uploader = self._html_search_regex(r',"artist":"([^"]+)",', webpage, u'music uploader')
+        title = self._html_search_regex(
-        music_url_json_string = self._html_search_regex(r'({"url":"[^"]+"),', webpage, u'music url') + '}'
+        music_url_json_string = self._html_search_regex(
-            'url':      music_url,
+            'id': music_id,
-__version__ = '2014.01.22.3'
+__version__ = '2014.01.22.4'
-            u"age_limit": 18,
+        'url': 'http://www.xvideos.com/video939581/funny_porns_by_s_-1',
-            webpage, u'video URL'))
+        video_url = compat_urllib_parse.unquote(
-            webpage, u'title')
+        video_title = self._html_search_regex(
-             webpage, u'thumbnail', fatal=False)
+        video_thumbnail = self._search_regex(
-        info = {
+        return {
-            webpage, u'thumbnail', fatal=False)
+        video_thumbnail = self._search_regex(r'url_bigthumb=(.+?)&amp',
-            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported. You can also use the special names "best", "bestaudio", and "worst"')
+            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported. You can also use the special names "best", "bestaudio", "worst", and "worstaudio"')
-__version__ = '2014.01.22.2'
+__version__ = '2014.01.22.3'
-        req_format = self.params.get('format', 'best')
+        req_format = self.params.get('format')
-            action='store', dest='format', metavar='FORMAT', default='best',
+            action='store', dest='format', metavar='FORMAT', default=None,
-            {u'ext': u'mp4',  u'height': 460},
+            {'ext': 'webm', 'height': 460},
-        info_dict = {u'formats': formats, u'extractor': u'test'}
+        info_dict = {'formats': formats, 'extractor': 'test'}
-        self.assertEqual(downloaded[u'ext'], u'webm')
+        self.assertEqual(downloaded['ext'], 'webm')
-            {u'ext': u'mp4', u'height': 1080},
+            {'ext': 'webm', 'height': 720},
-        info_dict[u'formats'] = formats
+        info_dict['formats'] = formats
-        self.assertEqual(downloaded[u'ext'], u'mp4')
+        self.assertEqual(downloaded['ext'], 'mp4')
-            {u'ext': u'flv', u'height': 720},
+            {'ext': 'webm', 'height': 720},
-        info_dict[u'formats'] = formats
+        info_dict['formats'] = formats
-        self.assertEqual(downloaded[u'ext'], u'mp4')
+        self.assertEqual(downloaded['ext'], 'mp4')
-            {u'ext': u'webm', u'height': 720},
+            {'ext': 'flv', 'height': 720},
-        info_dict[u'formats'] = formats
+        info_dict['formats'] = formats
-        self.assertEqual(downloaded[u'ext'], u'flv')
+        self.assertEqual(downloaded['ext'], 'flv')
-            {u'format_id': u'excellent', u'url': u'http://example.com/exc', 'preference': 4},
+            {'format_id': 'meh', 'url': 'http://example.com/meh', 'preference': 1},
-            u'formats': formats, u'extractor': u'test', 'id': 'testvid'}
+            'formats': formats, 'extractor': 'test', 'id': 'testvid'}
-        self.assertEqual(downloaded[u'format_id'], u'excellent')
+        self.assertEqual(downloaded['format_id'], 'excellent')
-        self.assertEqual(downloaded[u'format_id'], u'good')
+        self.assertEqual(downloaded['format_id'], 'good')
-        self.assertEqual(ydl.downloaded_info_dicts[2][u'format_id'], u'great')
+        self.assertEqual(ydl.downloaded_info_dicts[0]['format_id'], 'meh')
-        self.assertEqual(downloaded[u'format_id'], u'excellent')
+        self.assertEqual(downloaded['format_id'], 'excellent')
-            {u'format_id': u'2', u'ext': u'flv', 'preference': 4},
+            {'format_id': '35', 'ext': 'mp4', 'preference': 1},
-        info_dict = {u'formats': formats, u'extractor': u'test'}
+        info_dict = {'formats': formats, 'extractor': 'test'}
-        ydl = YDL({'format': u'20/47'})
+        ydl = YDL({'format': '20/47'})
-        self.assertEqual(downloaded['format_id'], u'47')
+        self.assertEqual(downloaded['format_id'], '47')
-        ydl = YDL({'format': u'20/71/worst'})
+        ydl = YDL({'format': '20/71/worst'})
-        self.assertEqual(downloaded['format_id'], u'35')
+        self.assertEqual(downloaded['format_id'], '35')
-        self.assertEqual(downloaded['format_id'], u'2')
+        self.assertEqual(downloaded['format_id'], '2')
-        ydl = YDL({'format': u'webm/mp4'})
+        ydl = YDL({'format': 'webm/mp4'})
-        self.assertEqual(downloaded['format_id'], u'47')
+        self.assertEqual(downloaded['format_id'], '47')
-        ydl = YDL({'format': u'3gp/40/mp4'})
+        ydl = YDL({'format': '3gp/40/mp4'})
-        self.assertEqual(downloaded['format_id'], u'35')
+        self.assertEqual(downloaded['format_id'], '35')
-            {u'format_id': u'vid', u'ext': u'mp4', 'preference': 4},
+            {'format_id': 'audio-low', 'ext': 'webm', 'preference': 1, 'vcodec': 'none'},
-        info_dict = {u'formats': formats, u'extractor': u'test'}
+        info_dict = {'formats': formats, 'extractor': 'test'}
-        ydl = YDL({'format': u'bestaudio'})
+        ydl = YDL({'format': 'bestaudio'})
-        self.assertEqual(downloaded['format_id'], u'audio-high')
+        self.assertEqual(downloaded['format_id'], 'audio-high')
-        ydl = YDL({'format': u'worstaudio'})
+        ydl = YDL({'format': 'worstaudio'})
-        self.assertEqual(downloaded['format_id'], u'audio-low')
+        self.assertEqual(downloaded['format_id'], 'audio-low')
-            {u'format_id': u'vid-high', u'ext': u'mp4', 'preference': 2},
+            {'format_id': 'vid-low', 'ext': 'mp4', 'preference': 1},
-        info_dict = {u'formats': formats, u'extractor': u'test'}
+        info_dict = {'formats': formats, 'extractor': 'test'}
-        ydl = YDL({'format': u'bestaudio/worstaudio/best'})
+        ydl = YDL({'format': 'bestaudio/worstaudio/best'})
-        self.assertEqual(downloaded['format_id'], u'vid-high')
+        self.assertEqual(downloaded['format_id'], 'vid-high')
-            u'width': None,
+            'id': '1234',
-        self.assertEqual(fname(u'%(id)s-%(width)s.%(ext)s'), u'1234-NA.mp4')
+        self.assertEqual(fname('%(id)s.%(ext)s'), '1234.mp4')
-        self.assertEqual(fname(u'%(uploader_date)s-%(id)s.%(ext)s'), u'NA-1234.mp4')
+        self.assertEqual(fname('%(uploader_date)s-%(id)s.%(ext)s'), 'NA-1234.mp4')
-            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported')
+            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported. You can also use the special names "best", "bestaudio", and "worst"')
-__version__ = '2014.01.22.1'
+__version__ = '2014.01.22.2'
-
+    general.add_option('--default-search',
-            return self.url_result('http://' + url)
+            default_search = self._downloader.params.get('default_search')
-            mgid = url_basename(fb_url).rpartition('.')[0]
+            # the url can be http://media.mtvnservices.com/fb/{mgid}.swf
-    _VALID_URL = r'https?://www\.space\.com/\d+-(?P<title>[^/\.\?]*?)-video\.html'
+    _VALID_URL = r'https?://(?:(?:www|m)\.)?space\.com/\d+-(?P<title>[^/\.\?]*?)-video\.html'
-    _VALID_URL = r'http://www\.c-spanvideo\.org/program/(.*)'
+    _VALID_URL = r'http://(?:www\.)?c-spanvideo\.org/program/(?P<name>.*)'
-        prog_name = mobj.group(1)
+        prog_name = mobj.group('name')
-        video_id = self._search_regex(r'programid=(.*?)&', webpage, 'video id')
+        video_id = self._search_regex(r'prog(?:ram)?id=(.*?)&', webpage, 'video id')
-        return self._get_videos_info(mgid)
+from __future__ import unicode_literals
-    _FEED_URL = u'http://comedycentral.com/feeds/mrss/'
+    _FEED_URL = 'http://comedycentral.com/feeds/mrss/'
-            u'description': u'After a certain point, breastfeeding becomes c**kblocking.',
+        'url': 'http://www.comedycentral.com/video-clips/kllhuv/stand-up-greg-fitzsimmons--uncensored---too-good-of-a-mother',
-                                  webpage, u'mgid')
+                                  webpage, 'mgid')
-    IE_DESC = u'The Daily Show / Colbert Report'
+    IE_DESC = 'The Daily Show / Colbert Report'
-            u"title": u"thedailyshow-kristen-stewart part 1"
+        'url': 'http://www.thedailyshow.com/watch/thu-december-13-2012/kristen-stewart',
-            raise ExtractorError(u'Cannot transform RTMP url')
+            raise ExtractorError('Cannot transform RTMP url')
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-                url = u'http://www.thedailyshow.com/full-episodes/'
+                url = 'http://www.thedailyshow.com/full-episodes/'
-                url = u'http://www.colbertnation.com/full-episodes/'
+                url = 'http://www.colbertnation.com/full-episodes/'
-                raise ExtractorError(u'Invalid redirected URL: ' + url)
+                raise ExtractorError('Invalid redirected URL: ' + url)
-                raise ExtractorError(u'Redirected URL is still not specific: ' + url)
+                raise ExtractorError('Redirected URL is still not specific: ' + url)
-                raise ExtractorError(u'unable to find Flash URL in webpage ' + url)
+                raise ExtractorError('unable to find Flash URL in webpage ' + url)
-                                          u'unable to download episode index')
+                                          'Downloading show index',
-                                               u'Downloading configuration for %s' % shortMediaId)
+                                               'Downloading configuration for %s' % shortMediaId)
-                self._downloader.report_error(u'unable to download ' + mediaId + ': No videos found')
+                self._downloader.report_error('unable to download ' + mediaId + ': No videos found')
-            effTitle = showId + u'-' + epTitle + u' part ' + compat_str(partNum+1)
+            effTitle = showId + '-' + epTitle + ' part ' + compat_str(partNum+1)
-            u'title': u'Uncensored - Greg Fitzsimmons - Too Good of a Mother',
+            u'title': u'CC:Stand-Up|Greg Fitzsimmons: Life on Stage|Uncensored - Too Good of a Mother',
-        
+
-from __future__ import unicode_literal
+from __future__ import unicode_literals
-    IE_NAME = u'd8.tv'
+    IE_NAME = 'd8.tv'
-            u'upload_date': u'20131108',
+        'url': 'http://www.d8.tv/d8-docs-mags/pid6589-d8-campagne-intime.html',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-        }
+        },
-__version__ = '2014.01.22'
+__version__ = '2014.01.22.1'
-    _VALID_URL = r'(?:http://)?(?:www\.)?ringtv\.craveonline\.com/videos/video/([^/]+)'
+    _VALID_URL = r'(?:http://)?(?:www\.)?ringtv\.craveonline\.com/(?P<type>news|videos/video)/(?P<id>[^/?#]+)'
-            u"description": u"Saul \\\"Canelo\\\" Alvarez spoke to the media about his Sept. 14 showdown with Floyd Mayweather after their kick-off presser in NYC. Canelo is motivated and confident that he will have the speed and gameplan to beat the pound-for-pound king."
+        "url": "http://ringtv.craveonline.com/news/310833-luis-collazo-says-victor-ortiz-better-not-quit-on-jan-30",
-        video_id = mobj.group(1).split('-')[0]
+        video_id = mobj.group('id').split('-')[0]
-        }]
+
-            'title': 'Short',
+            'title': 'Arcade Fire: Behind the Scenes at the Biggest Music Experiment Yet',
-            'title': 'Can Allen Ride A Hundred Year-Old Motorcycle?',
+            'title': 'Auction Hunters|Can Allen Ride A Hundred Year-Old Motorcycle?',
-        assert re.match(r'^[a-zA-Z0-9@\s:.]*$', val)
+        assert re.match(r'^[a-zA-Z0-9@\s:._]*$', val)
-            u"description": u"These deer look as fluid as running water when they jump over this fence as a herd. This video is one that needs to be watched until the very end for the true majesty to be witnessed, but once it comes, it's sure to take your breath away.",
+        'url': 'http://www.wimp.com/deerfence/',
-        final_url = self._search_regex('","(.*?)"', googleString, u'final video url')
+        video_url = self._search_regex(
-            'url': final_url,
+            'url': video_url,
-            u"title": u'Freddie Gibbs "Lay It Down"'
+        'url': 'http://www.hotnewhiphop.com/freddie-gibbs-lay-it-down-song.1435540.html',
-            webpage_src, u'video URL', fatal=False)
+        video_url_base64 = self._search_regex(
-                u'video URL')
+        if video_url_base64 is None:
-        video_url = base64.b64decode(video_url_base64).decode('utf-8')
+        reqdata = compat_urllib_parse.urlencode([
-            webpage_src, u'title')
+        video_title = self._og_search_title(webpage_src).strip()
-        return results
+        return {
-        assert re.match(r'^[a-zA-Z0-9@\s]*$', val)
+        assert re.match(r'^[a-zA-Z0-9@\s:.]*$', val)
-        }
+        },
-__version__ = '2014.01.21.1'
+__version__ = '2014.01.22'
-            u'description': u'Faith is back!  Check out the World Premiere trailer for Mirror\'s Edge 2 straight from the EA Press Conference at E3 2013!',
+        'url': 'http://www.gametrailers.com/videos/zbvr8i/mirror-s-edge-2-e3-2013--debut-trailer',
-                                  webpage, u'mgid')
+                                  webpage, 'mgid')
-            raise ExtractorError(u'This video is not available from your country.', expected=True)
+            raise ExtractorError('This video is not available from your country.', expected=True)
-        mediagen_url = re.sub(r'&[^=]*?={.*?}(?=(&|$))', u'', mediagen_url)
+        mediagen_url = re.sub(r'&[^=]*?={.*?}(?=(&|$))', '', mediagen_url)
-                                               u'Downloading video urls')
+                                               'Downloading video urls')
-            u'Downloading info', transform_source=fix_xml_ampersands)
+            'Downloading info', transform_source=fix_xml_ampersands)
-                u'description': u'Album: Taylor Swift performs "Ours" for VH1 Storytellers at Harvey Mudd College.',
+            'url': 'http://www.mtv.com/videos/misc/853555/ours-vh1-storytellers.jhtml',
-                u'uploader': u'Taylor Swift',
+            'add_ie': ['Vevo'],
-            u'skip': u'VEVO is only available in some countries',
+            'skip': 'VEVO is only available in some countries',
-                self.to_screen(u'Vevo video detected: %s' % vevo_id)
+                self.to_screen('Vevo video detected: %s' % vevo_id)
-            uri = self._html_search_regex(r'/uri/(.*?)\?', webpage, u'uri')
+            uri = self._html_search_regex(r'/uri/(.*?)\?', webpage, 'uri')
-            u'title': u'E3 2013: Debut Trailer',
+            u'title': u'Mirror\'s Edge 2|E3 2013: Debut Trailer',
-            'title': itemdoc.find('title').text,
+            'title': title,
-            for k, v in compat_parse_qs(fv_el.attrib['value']).items())
+        if fv_el is not None:
-                :[^>]+?class=([\'"])[^>]*?BrightcoveExperience.*?\1 |
+                [^>]+?class=([\'"])[^>]*?BrightcoveExperience.*?\1 |
-        if 'url' not in info:
+        if 'url' not in info and not info.get('formats'):
-from .mtv import MTVIE
+from .mtv import (
-        if '/error_country_block.swf' in metadataXml:
+    def _extract_video_formats(self, mdoc):
-                                               'Downloading video urls')
+        mediagen_doc = self._download_xml(mediagen_url, video_id,
-            'formats': self._extract_video_formats(mediagen_page),
+            'formats': self._extract_video_formats(mediagen_doc),
-            raise ExtractorError(u'This video is not available from your country.', expected=True)
+            raise ExtractorError('This video is not available from your country.', expected=True)
-        mediagen_url = re.sub(r'&[^=]*?={.*?}(?=(&|$))', u'', mediagen_url)
+        mediagen_url = re.sub(r'&[^=]*?={.*?}(?=(&|$))', '', mediagen_url)
-                                               u'Downloading video urls')
+                                               'Downloading video urls')
-            u'Downloading info', transform_source=fix_xml_ampersands)
+            'Downloading info', transform_source=fix_xml_ampersands)
-                u'description': u'Album: Taylor Swift performs "Ours" for VH1 Storytellers at Harvey Mudd College.',
+            'url': 'http://www.mtv.com/videos/misc/853555/ours-vh1-storytellers.jhtml',
-                u'uploader': u'Taylor Swift',
+            'add_ie': ['Vevo'],
-            u'skip': u'VEVO is only available in some countries',
+            'skip': 'VEVO is only available in some countries',
-                self.to_screen(u'Vevo video detected: %s' % vevo_id)
+                self.to_screen('Vevo video detected: %s' % vevo_id)
-            uri = self._html_search_regex(r'/uri/(.*?)\?', webpage, u'uri')
+            uri = self._html_search_regex(r'/uri/(.*?)\?', webpage, 'uri')
-__version__ = '2014.01.21'
+__version__ = '2014.01.21.1'
-    _TEST = {
+    _TESTS = [{
-    }
+    },
-            'url': data['url240'],
+            'formats': formats,
-            'uploader': data['md_author'],
+            'thumbnail': data.get('jpg'),
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?facebook\.com/(?:[^#?]*#!/)?(?:video/video|photo)\.php\?(?:.*?)v=(?P<ID>\d+)(?:.*)'
+    _VALID_URL = r'''(?x)
-        video_id = mobj.group('ID')
+        video_id = mobj.group('id')
-    IE_NAME = u'vk.com'
+    IE_NAME = 'vk.com'
-            u'uploader': u'Noize MC',
+        'url': 'http://vk.com/videos-77521?z=video-77521_162222515%2Fclub77521',
-        data_json = self._search_regex(r'var vars = ({.*?});', info_page, u'vars')
+        data_json = self._search_regex(r'var vars = ({.*?});', info_page, 'vars')
-        vars = json.loads(vars_json)
+        data_json = self._search_regex(r'var vars = ({.*?});', info_page, u'vars')
-            'uploader': vars['md_author'],
+            'id': compat_str(data['vid']),
-        u'file': u'66418.mp4',
+        'url': 'http://www.redtube.com/66418',
-            u"age_limit": 18,
+        #'md5': u'7b8c22b5e7098a3e1c09709df1126d2d',
-            'title':     video_title,
+            'id': video_id,
-__version__ = '2014.01.20'
+__version__ = '2014.01.21'
-
+    selection.add_option(
-        }
+
-            webpage, re.DOTALL)
+            r'''(?sx)<object
-        else:
+
-                h = hashlib.md5(url).hexdigest()
+                h = u'___' + hashlib.md5(url).hexdigest()
-                'title': '2cc213299525360.mov', #that's what we get
+                'title': '2cc213299525360.mov',  # that's what we get
-    fix_xml_all_ampersand,
+    fix_xml_ampersands
-            transform_source=fix_xml_all_ampersand) 
+            transform_source=fix_xml_ampersands)
-    fix_xml_all_ampersand,
+    fix_xml_ampersands,
-            video_id, 'Downloading info xml', transform_source=fix_xml_all_ampersand)
+            video_id, 'Downloading info xml', transform_source=fix_xml_ampersands)
-            u'Downloading info', transform_source=fix_ampersand)
+            u'Downloading info', transform_source=fix_xml_ampersands)
-def fix_xml_all_ampersand(xml_str):
+def fix_xml_ampersands(xml_str):
-    return xml_str.replace(u'&', u'&amp;')
+    return re.sub(
-__version__ = '2014.01.17.2'
+__version__ = '2014.01.20'
-                (ie_result['extractor'], playlist, n_all_entries, n_entries))
+            if isinstance(ie_result['entries'], list):
-        for pagenum in itertools.count(0):
+        def download_page(pagenum):
-                                          u'Downloading video ids from %d to %d' % (start_index, start_index + self._GDATA_PAGE_SIZE))
+            page = self._download_webpage(
-                break
+                return
-                url_results.append({
+                yield {
-                break
+                }
-        playlist_title = self._og_search_title(page)
+        try:
-    _VALID_URL = r'https?://myspace\.com/([^/]+)/(?:video/[^/]+/|music/song/.*?)(?P<id>\d+)'
+    _VALID_URL = r'https?://myspace\.com/([^/]+)/(?P<mediatype>video/[^/]+/|music/song/.*?)(?P<id>\d+)'
-        if 'music/song' in url:
+        if mobj.group('mediatype').startswith('music/song'):
-            u'uploader_id': u'coldplay',
+    _VALID_URL = r'https?://myspace\.com/([^/]+)/(?:video/[^/]+/|music/song/.*?)(?P<id>\d+)'
-            u'skip_download': True,
+        # song
-    }
+    ]
-            'title': video['title'],
+
-        }
+        })
-        'md5': '2cec58eb277054eca0dbaaf3bdc72564',
+        'md5': 'f6d65b1b326e82fd7ab7720bea3dacae',
-        title = mobj.group('title')
+        title = os.path.splitext(mobj.group('title'))[0]
-            u'title': '20131219_085616'
+        'url': 'https://www.dropbox.com/s/mcnzehi9wo55th4/20131219_085616.mp4',
-    def _real_extract(self,url):
+
-        
+        video_id = mobj.group('id')
-from .dropbox import DropBoxIE
+from .dropbox import DropboxIE
-    _VALID_URL = r'https?://(?:www\.)?dropbox.com/s/(?P<id>[a-zA-Z0-9]{15})/(?P<title>.*)'
+class DropboxIE(InfoExtractor):
-        
+        u'url': u'https://www.dropbox.com/s/mcnzehi9wo55th4/20131219_085616.mp4',
-                          }]
+               'url':video_url
-
+        def _map_to_format_list(urlmap):
-            video_url_list = [('_rtmp', video_info['conn'][0])]
+            formats = [{
-            video_url_list = self._get_video_url_list(url_map)
+            formats = _map_to_format_list(url_map)
-            video_url_list = self._get_video_url_list(url_map)
+            formats = _map_to_format_list(url_map)
-            formats.append(dct)
+        # Look for the DASH manifest
-    return v if v is None else int(v)
+def int_or_none(v, scale=1):
-            u"description": "A Georgia Tech student welcomes the incoming freshmen with an epic speech backed by music from \"2001: A Space Odyssey.\""
+        "url": "http://edition.cnn.com/video/?/video/us/2013/08/21/sot-student-gives-epic-speech.georgia-institute-of-technology&utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+rss%2Fcnn_topstories+%28RSS%3A+Top+Stories%29",
-__version__ = '2013.01.17.1'
+__version__ = '2014.01.17.2'
-from ..utils import determine_ext
+
-            u'title': u'Ready To Go',
+        'url': 'http://yinyue.kankan.com/vod/48/48863.shtml',
-        title = self._search_regex(r'(?:G_TITLE=|G_MOVIE_TITLE = )[\'"](.+?)[\'"]', webpage, u'video title')
+        title = self._search_regex(r'(?:G_TITLE=|G_MOVIE_TITLE = )[\'"](.+?)[\'"]', webpage, 'video title')
-        param2 = self._search_regex(r'param2:(\d+)', video_info_page, u'param2')
+        info_url = 'http://p2s.cl.kankan.com/getCdnresource_flv?gcid=%s' % gcid
-                }
+        return {
-import json
+from __future__ import unicode_literals
-    IE_NAME = u'mixcloud'
+    IE_NAME = 'mixcloud'
-            u'upload_date': u'20111115',
+        'url': 'http://www.mixcloud.com/dholbach/cryptkeeper/',
-            api_url, track_id, u'Downloading cloudcast info')
+            api_url, track_id, 'Downloading cloudcast info')
-            r'\s(?:data-preview-url|m-preview)="(.+?)"', webpage, u'preview url')
+            r'\s(?:data-preview-url|m-preview)="(.+?)"', webpage, 'preview url')
-        api_url = 'http://api.mixcloud.com/%s/%s/' % (uploader, cloudcast_name)
+
-        preview_url = self._search_regex(r'data-preview-url="(.+?)"', webpage, u'preview url')
+        api_url = 'http://api.mixcloud.com/%s/%s/' % (uploader, cloudcast_name)
-        uploader = data['info_overlay']['name']
+        uploader = data['info_overlay'].get('username')
-        self.assertEqual(md5(subtitles['en']), '2154f31ff9b9f89a0aa671537559c21d')
+        self.assertEqual(md5(subtitles['en']), '4262c1665ff928a2dada178f62cb8d14')
-        self.assertEqual(md5(subtitles['fr']), '7616cbc6df20ec2c1204083c83871cf6')
+        self.assertEqual(md5(subtitles['fr']), '66a63f7f42c97a50f8c0e90bc7797bb5')
-        'md5': '2d76ee1576672e0bd8f187513267adf6',
+        'md5': '4ea1dada91e4174b53dac2bb8ace429d',
-            u"title": u"Dan Dennett: The illusion of consciousness"
+        'url': 'http://www.ted.com/talks/dan_dennett_on_our_consciousness.html',
-            url, playlist_id, u'Downloading playlist webpage')
+            url, playlist_id, 'Downloading playlist webpage')
-        best_format = sorted(video_info['sources'][0], key=_formats_sort_key)[-1]
+        formats = [{
-                }
+        return {
-              }
+    _SITES = {
-    IE_DESC = u'CondÃ© Nast media group: %s' % ', '.join(sorted(_SITES.values()))
+    IE_DESC = 'CondÃ© Nast media group: %s' % ', '.join(sorted(_SITES.values()))
-            u'description': u'Check out these beautiful 3D printed LED speakers.  You can\'t actually buy them, but LumiGeek is working on a board that will let you make you\'re own.',
+        'url': 'http://video.wired.com/watch/3d-printed-speakers-lit-with-led',
-                                        webpage, u'series title', flags=re.DOTALL)
+                                        webpage, 'series title', flags=re.DOTALL)
-                                              webpage, u'description',
+                                              webpage, 'description',
-        target = self._search_regex(r'target: [\'"](.+?)[\'"]', params, u'target')
+                                    'player params', flags=re.DOTALL)
-                                           webpage, u'base info url',
+                                           webpage, 'base info url',
-        video_info = self._search_regex(r'var video = ({.+?});', info_page, u'video info')
+                                           'Downloading video info')
-    IE_NAME = u'soundcloud'
+    IE_NAME = 'soundcloud'
-                u"title": u"Lostin Powers - She so Heavy (SneakPreview) Adrian Ackers Blueprint 1"
+            'url': 'http://soundcloud.com/ethmusic/lostin-powers-she-so-heavy',
-                u'upload_date': u'20120521',
+            'url': 'https://soundcloud.com/the-concept-band/goldrushed-mastered?in=the-concept-band/sets/the-royal-concept-ep',
-            u'params': {
+            'params': {
-                u'skip_download': True,
+                'skip_download': True,
-                u'upload_date': u'20131209',
+            'url': 'https://soundcloud.com/jaimemf/youtube-dl-test-video-a-y-baw/s-8Pjrp',
-                u'upload_date': u'20130815',
+            'url': 'https://soundcloud.com/simgretina/just-your-problem-baby-1',
-        ext = u'mp3'
+        ext = 'mp3'
-                u'https://api.soundcloud.com/tracks/{0}/download?client_id={1}'.format(
+                'https://api.soundcloud.com/tracks/{0}/download?client_id={1}'.format(
-                'ext': info.get('original_format', u'mp3'),
+                'ext': info.get('original_format', 'mp3'),
-                track_id, u'Downloading track url')
+                track_id, 'Downloading track url')
-                    'format_id': u'fallback',
+                    'format_id': 'fallback',
-            def format_pref(f):
+            for f in formats:
-                    return 2
+                    f['protocol'] = 'http'
-                return 0
+                    f['protocol'] = 'rtmp'
-            formats.sort(key=format_pref)
+            self._sort_formats(formats)
-        info_json = self._download_webpage(info_json_url, full_title, u'Downloading info JSON')
+        info_json = self._download_webpage(info_json_url, full_title, 'Downloading info JSON')
-    IE_NAME = u'soundcloud:set'
+    IE_NAME = 'soundcloud:set'
-    IE_NAME = u'soundcloud:user'
+    IE_NAME = 'soundcloud:user'
-            u'Downloading user info')
+            'Downloading user info')
-                u'Downloading tracks page %s' % (i+1))
+                'Downloading tracks page %s' % (i+1))
-            u"age_limit": 18,
+        'url': 'http://www.spankwire.com/Buckcherry-s-X-Rated-Music-Video-Crazy-Bitch/video103545/',
-        video_title = self._html_search_regex(r'<h1>([^<]+)', webpage, u'title')
+        video_title = self._html_search_regex(r'<h1>([^<]+)', webpage, 'title')
-            r'by:\s*<a [^>]*>(.+?)</a>', webpage, u'uploader', fatal=False)
+            r'by:\s*<a [^>]*>(.+?)</a>', webpage, 'uploader', fatal=False)
-            r'flashvars\.image_url = "([^"]+)', webpage, u'thumbnail', fatal=False)
+            r'flashvars\.image_url = "([^"]+)', webpage, 'thumbnail', fatal=False)
-            r'<div\s+id="descriptionContent">([^<]+)<', webpage, u'description', fatal=False)
+            r'<div\s+id="descriptionContent">([^<]+)<', webpage, 'description', fatal=False)
-            password = self._html_search_regex(r'flashvars\.video_title = "([^"]+)', webpage, u'password').replace('+', ' ')
+            password = self._html_search_regex(r'flashvars\.video_title = "([^"]+)', webpage, 'password').replace('+', ' ')
-        formats.sort(key=lambda format: list(map(lambda s: s.zfill(6), format['format'].split('-'))))
+        self._sort_formats(formats)
-            if file.attrib.get('playmode') == 'all':
+        for filed in data.findall('files/file'):
-            file_url = file.text
+            file_url = filed.text
-                format_id = file.attrib['bitrate']
+                format_id = filed.attrib['bitrate']
-            raise ExtractorError('Unable to extract video URL')
+
-            u"title": u"Louis C.K. Interview Pt. 1 11/3/11"
+        'url': 'http://teamcoco.com/video/louis-ck-interview-george-w-bush',
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-            webpage, u'video id')
+        video_id = self._html_search_regex(
-            raise ExtractorError(u'Unable to extract video URL')
+            raise ExtractorError('Unable to extract video URL')
-            'id':          video_id,
+            'id': video_id,
-            'thumbnail':   self._og_search_thumbnail(webpage),
+            'title': self._og_search_title(webpage),
-            u'description': u'Check out this video where some of the basics of Arma 3 is explained.',
+        "url": "http://www.gamespot.com/arma-iii/videos/arma-iii-community-guide-sitrep-i-6410818/",
-        
+
-        
+    'Saimadhav Heblikar',
-    def _real_extract(self,url):
+    _VALID_URL = r'http://(?:www\.)?franceinter\.fr/player/reecouter\?play=(?P<id>[0-9]{6})'
-        
+        webpage = self._download_webpage(url, video_id)
-            u"title": u"Dark Hollow Waterfalls"
+        'url': 'http://www.flickr.com/photos/forestwander-nature-pictures/5645318632/in/photostream/',
-        secret = self._search_regex(r"photo_secret: '(\w+)'", webpage, u'secret')
+        secret = self._search_regex(r"photo_secret: '(\w+)'", webpage, 'secret')
-            first_xml, u'node_id')
+            first_xml, 'node_id')
-            raise ExtractorError(u'Unable to extract video url')
+            raise ExtractorError('Unable to extract video url')
-__version__ = '2013.01.17'
+__version__ = '2013.01.17.1'
-                    sys.stderr.write(u'\n"info_dict": ' + json.dumps(test_info_dict, ensure_ascii=False, indent=2) + u'\n')
+                    sys.stderr.write(u'\n"info_dict": ' + json.dumps(test_info_dict, ensure_ascii=False, indent=4) + u'\n')
-__version__ = '2014.01.08'
+__version__ = '2013.01.17'
-            mobj = re.search(r'[^A-Za-z0-9]?file["\']?:\s*["\'](http[^\'"]*)', webpage)
+            mobj = re.search(r'[^A-Za-z0-9]?file["\']?:\s*["\'](http(?![^\'"]+\.[0-9]+[\'"])[^\'"]+)["\']', webpage)
-    _VALID_URL = r'(?:http://)?(?:www\.)?redtube\.com/(?P<id>[0-9]+)'
+    _VALID_URL = r'http://(?:www\.)?redtube\.com/(?P<id>[0-9]+)'
-                        info_dict['__postprocessors'] = [FFmpegMergerPP(self)]
+                        info_dict['__postprocessors'] = postprocessors
-    IE_NAME='FranceInter'
+    _VALID_URL=r'http://(?:www\.)?franceinter\.fr/player/reecouter\?play=(?P<id>[0-9]{6})'
-           
+                  
-    def get_download_url(self,webpage):
+   
-        return webpage[start:end]
+   
-        title=self.get_title(webpage)
+        title=self._search_regex(u'(?<=<span class="roll_overflow">)(.*)(?=</span></h1>)', webpage, u'title')
-        video_url=self.get_download_url(webpage)
+        video_url='http://www.franceinter.fr/'+self._search_regex(u'(?<=&urlAOD=)(.*)(?=&startTime)', webpage, u'video url')
-        
+        
-        u'url': u'www.ina.fr/video/I12055569/francois-hollande-je-crois-que-c-est-clair-video.html',
+        u'url': u'http://www.ina.fr/video/I12055569/francois-hollande-je-crois-que-c-est-clair-video.html',
-        u'url': u'www.voxnow.de/voxtours/suedafrika-reporter-ii.php?film_id=13883&player=1&season=17',
+        u'url': u'http://www.voxnow.de/voxtours/suedafrika-reporter-ii.php?film_id=13883&player=1&season=17',
-        continue
+    if METHOD == 'EURISTIC':
-    webpage = webpage.decode('utf8', 'replace')
+        RESULT = ('.' + domain + '\n' in LIST or '\n' + domain + '\n' in LIST)
-                                      or test['info_dict']['age_limit'] != 18):
+    if RESULT and ('info_dict' not in test or 'age_limit' not in test['info_dict']
-                                            test['info_dict']['age_limit'] == 18):
+    elif not RESULT and ('info_dict' in test and 'age_limit' in test['info_dict']
-            action='store_true', dest='listformats', help='list all available formats (currently youtube only)')
+            action='store_true', dest='listformats', help='list all available formats')
-    _VALID_URL = r'(?:https?://)?(?:www\.)?nowvideo\.ch/video/(?P<id>\w+)'
+    _VALID_URL = r'(?:https?://)?(?:www\.)?nowvideo\.(?:ch|sx)/video/(?P<id>\w+)'
-        'download_archive': opts.download_archive,
+        'download_archive': download_archive_fn,
-    _VALID_URL = r'(?:https?://)?(?:www\.)?nowvideo\.ch/video/(?P<id>\w+)'
+    _VALID_URL = r'(?:https?://)?(?:www\.)?nowvideo\.(?:ch|sx)/video/(?P<id>\w+)'
-            dest='videopassword', metavar='PASSWORD', help='video password (vimeo only)')
+            dest='videopassword', metavar='PASSWORD', help='video password (vimeo, smotri)')
-            help='print downloaded pages to debug problems(very verbose)')
+            help='print downloaded pages to debug problems (very verbose)')
-                  '%(format_id)s for the unique id of the format (like Youtube\'s itags: "137"),'
+                  '%(format)s for the format description (like "22 - 1280x720" or "HD"), '
-                  '%(id)s for the video id , %(playlist)s for the playlist the video is in, '
+                  '%(id)s for the video id, %(playlist)s for the playlist the video is in, '
-            help='json file containing the video information (created with the "--write-json" option')
+            help='json file containing the video information (created with the "--write-json" option)')
-        parser.error(u' account username missing\n')
+        parser.error(u'account username missing\n')
-from ..utils import ExtractorError
+from ..utils import (
-    
+
-            raise ExtractorError('Video %s does not exist' % video_id, expected=True)
+        if 'Status' in video_json:
-            raise ExtractorError('Video %s is only available for members' % video_id, expected=True)
+            raise ExtractorError('Video %s is only available for members. ' % video_id + self.ACCOUNT_CREDENTIALS_HINT, expected=True)
-        
+
-        
+
-        
+
-    _TIMECODE_REGEX = r'\[(?P<timecode>\d+:\d+:\d+[\.,]\d+)\]'
+
-        
+
-
+        
-                if video['HasAccess'] is not True:
+                if username is None and video['HasAccess'] is False:
-            self._downloader.report_warning('%s videos are only available for members and will not be downloaded' % unaccessible_videos)
+            self._downloader.report_warning('%s videos are only available for members and will not be downloaded. '
-        return self.playlist_result(entries, course_id, course_title)
+        return self.playlist_result(entries, course_id, course_title)
-                  }
+        params = {
-            'uploader': info['artist'],
+            'thumbnail': info.get('thumb_url'),
-        final_url_webpage = self._download_webpage(request_url, id, 'Requesting download url')
+        final_url_webpage = self._download_webpage(request_url, video_id, 'Requesting download url')
-            video_url_list = [(None, video_info['conn'][0])]
+            video_url_list = [('_rtmp', video_info['conn'][0])]
-                'name': l[0].encode('utf-8'),
+                'name': unescapeHTML(l[0]).encode('utf-8'),
-__version__ = '2014.01.07.5'
+__version__ = '2014.01.08'
-            r'<iframe[^>]+?src="(https?://player.vimeo.com/video/.+?)"', webpage)
+            r'<iframe[^>]+?src="((?:https?:)?//player.vimeo.com/video/.+?)"', webpage)
-        (?P<proto>https?://)?
+        (?P<proto>(?:https?:)?//)?
-
+from .ooyala import OoyalaIE
-        return self.url_result(ooyala_url, ie='Ooyala')
+        ooyala_code = self._search_regex(r'<source src="http://player.ooyala.com/player/[^/]+/([^".]+)', webpage, u'ooyala url')
-        if not self._exes['ffmpeg'] and not self._exes['avconv']:
+        if not self._get_executable():
-        cmd = ([self._exes['avconv'] or self._exes['ffmpeg'], '-y'] + files_cmd
+        cmd = ([self._get_executable(), '-y'] + files_cmd
-            raise AudioConversionError('ffmpeg or avconv not found. Please install one.')
+        uses_avconv = self._uses_avconv()
-                more_opts = [self._exes['avconv'] and '-bsf:a' or '-absf', 'aac_adtstoasc']
+                more_opts = ['-bsf:a' if uses_avconv else '-absf', 'aac_adtstoasc']
-                        more_opts += [self._exes['avconv'] and '-q:a' or '-aq', self._preferredquality]
+                        more_opts += ['-q:a' if uses_avconv else '-aq', self._preferredquality]
-                        more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality + 'k']
+                        more_opts += ['-b:a' if uses_avconv else '-ab', self._preferredquality + 'k']
-                    more_opts += [self._exes['avconv'] and '-q:a' or '-aq', self._preferredquality]
+                    more_opts += ['-q:a' if uses_avconv else '-aq', self._preferredquality]
-                    more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality + 'k']
+                    more_opts += ['-b:a' if uses_avconv else '-ab', self._preferredquality + 'k']
-                more_opts += [self._exes['avconv'] and '-bsf:a' or '-absf', 'aac_adtstoasc']
+                more_opts += ['-bsf:a' if uses_avconv else '-absf', 'aac_adtstoasc']
-                self._downloader.to_screen(u'[' + (self._exes['avconv'] and 'avconv' or 'ffmpeg') + '] Destination: ' + new_path)
+                self._downloader.to_screen(u'[' + self._get_executable() + '] Destination: ' + new_path)
-                msg = u'error running ' + (self._exes['avconv'] and 'avconv' or 'ffmpeg')
+                msg = u'error running ' + self._get_executable()
-    GenerationQuoiIE
+    GenerationQuoiIE,
-            self.to_screen(u'\r[%s] %s bytes' % (args[0], fsize))
+            self.to_screen(u'\r[%s] %s bytes' % (cmd[0], fsize))
-        
+
-    _VALID_URL = r'http://(?:www\.novamov\.com/video/|embed\.novamov\.com/embed\.php\?v=)(?P<videoid>[a-z\d]{13})'
+    _VALID_URL = r'http://(?:(?:www\.)?novamov\.com/video/|(?:(?:embed|www)\.)novamov\.com/embed\.php\?v=)(?P<videoid>[a-z\d]{13})'
-        filekey = mobj.group('filekey')
+        filekey = self._search_regex(
-                                              video_id, 'Downloading video api response')
+        api_response = self._download_webpage(
-        }
+        }
-            u' (or simply  youtube-dl BaW_jenozKc  ).',
+            u'"http://www.youtube.com/watch?feature=foo&v=BaW_jenozKc" '
-        mobj = re.search(r'<iframe src="(http://www.aparat.com/video/[^"]+)"', webpage)
+        mobj = re.search(r'<iframe src="(http://www\.aparat\.com/video/[^"]+)"', webpage)
-        mobj = re.search(r'<iframe .*?src="(http://mpora.com/videos/[^"]+)"', webpage)
+        mobj = re.search(r'<iframe .*?src="(http://mpora\.com/videos/[^"]+)"', webpage)
-            u'duration': 221,
+        'url': 'http://www.metacritic.com/game/playstation-4/infamous-second-son/trailers/3698222',
-            video_id, u'Downloading info xml', transform_source=fix_xml_all_ampersand)
+            video_id, 'Downloading info xml', transform_source=fix_xml_all_ampersand)
-                'rate': int(rate_str),
+                'tbr': int(rate_str),
-        formats.sort(key=operator.itemgetter('rate'))
+        self._sort_formats(formats)
-            webpage, u'description', flags=re.DOTALL)
+            webpage, 'description', flags=re.DOTALL)
-            u"age_limit": 18
+        'url': 'http://www.pornhub.com/view_video.php?viewkey=648719015',
-        thumbnail = self._html_search_regex(r'"image_url":"([^"]+)', webpage, u'thumbnail', fatal=False)
+        video_title = self._html_search_regex(r'<h1 [^>]+>([^<]+)', webpage, 'title')
-            password = self._html_search_regex(r'"video_title":"([^"]+)', webpage, u'password').replace('+', ' ')
+            password = self._html_search_regex(r'"video_title":"([^"]+)', webpage, 'password').replace('+', ' ')
-        formats.sort(key=lambda format: list(map(lambda s: s.zfill(6), format['format'].split('-'))))
+        self._sort_formats(formats)
-from ..utils import determine_ext
+
-            u'title': u'ç½äºç¥å¤å° ç¬¬32æï¼è½¦æ',
+    IE_NAME = '56.com'
-                                           text_id, u'Downloading video info')
+                                           text_id, 'Downloading video info')
-        video_url = best_format['url']
+        formats = [{
-                }
+        return {
-        formats = [{
+        formats = [
-            for fn,fdata in data['files'].items()
+            for fn, fdata in data['files'].items()
-            f['ext'] = determine_ext(f['url'])
+
-__version__ = '2014.01.07.4'
+__version__ = '2014.01.07.5'
-    selection.add_option('--dateafter', metavar='DATE', dest='dateafter', help='download only videos uploaded after this date', default=None)
+    selection.add_option(
-    IE_NAME = u'AcademicEarth:Course'
+    IE_NAME = 'AcademicEarth:Course'
-        u"playlist": [
+        "url": "http://trailers.apple.com/trailers/wb/manofsteel/",
-                    u"uploader_id": u"wb",
+                "file": "manofsteel-trailer4.mov",
-                    u"uploader_id": u"wb",
+                "file": "manofsteel-trailer3.mov",
-                    u"uploader_id": u"wb",
+                "file": "manofsteel-trailer.mov",
-                    u"uploader_id": u"wb",
+                "file": "manofsteel-teaser.mov",
-            u"uploader": u"SRI International"
+        "url": "http://archive.org/details/XD300-23_68HighlightsAResearchCntAugHumanIntellect",
-        json_url = url + (u'?' if u'?' in url else '&') + u'output=json'
+        json_url = url + ('?' if '?' in url else '&') + 'output=json'
-    IE_NAME = u'arte.tv'
+    IE_NAME = 'arte.tv'
-    #             (1, 'url', u'Invalid URL: %s' % url)
+    #             (1, 'url', 'Invalid URL: %s' % url)
-    #             (3, 'url',    u'could not extract video url: %s' % url)
+    #             (1, 'path',   'could not extract video path: %s' % url),
-    #     video_url = u'%s/%s' % (info.get('url'), info.get('path'))
+    #     video_url = '%s/%s' % (info.get('url'), info.get('path'))
-        video_id = self._search_regex(r'eventId=(\d+?)("|&)', webpage, u'event id')
+        video_id = self._search_regex(r'eventId=(\d+?)("|&)', webpage, 'event id')
-                                            video_id, u'Downloading information')
+                                            video_id, 'Downloading information')
-    IE_NAME = u'arte.tv:+7'
+    IE_NAME = 'arte.tv:+7'
-                format_id = u'%s-%s' % (quality, format_info['versionCode'])
+                format_id = '%s-%s' % (quality, format_info['versionCode'])
-            if format_info['mediaType'] == u'rtmp':
+            if format_info['mediaType'] == 'rtmp':
-    IE_NAME = u'arte.tv:creative'
+    IE_NAME = 'arte.tv:creative'
-            u'title': u'Agentur Amateur / Agence Amateur #2 : Corporate Design',
+        'url': 'http://creative.arte.tv/de/magazin/agentur-amateur-corporate-design',
-    IE_NAME = u'arte.tv:future'
+    IE_NAME = 'arte.tv:future'
-            u'title': u'Les champignons au secours de la planÃ¨te',
+        'url': 'http://future.arte.tv/fr/sujet/info-sciences#article-anchor-7081',
-    IE_NAME = u'arte.tv:ddc'
+    IE_NAME = 'arte.tv:ddc'
-            u"title": u"[Commie]The Legend of the Legendary Heroes - 03 - Replication Eye (Alpha Stigma)[F9410F5A]"
+        'url': 'http://auengine.com/embed.php?file=lfvlytY6&w=650&h=370',
-                webpage, u'title')
+                webpage, 'title')
-        ext = u'.' + determine_ext(video_url)
+        ext = '.' + determine_ext(video_url)
-    IE_NAME = u'bambuser'
+    IE_NAME = 'bambuser'
-        u'url': u'http://bambuser.com/v/4050584',
+        'url': 'http://bambuser.com/v/4050584',
-            u'uploader_id': u'344706',
+        #u'md5': 'fba8f7693e48fd4e8641b3fd5539a641',
-        u'params': {
+        'params': {
-            u'skip_download': True,
+            'skip_download': True,
-    IE_NAME = u'bambuser:channel'
+    IE_NAME = 'bambuser:channel'
-                u'Downloading page %d' % i)
+                'Downloading page %d' % i)
-            u"duration": 10,
+        'url': 'http://youtube-dl.bandcamp.com/track/youtube-dl-test-song',
-        u'skip': u'There is a limit of 200 free downloads / month for the test song'
+        '_skip': 'There is a limit of 200 free downloads / month for the test song'
-                raise ExtractorError(u'No free songs found')
+                raise ExtractorError('No free songs found')
-        mp3_info = info[u'downloads'][u'mp3-320']
+        mp3_info = info['downloads']['mp3-320']
-        initial_url = mp3_info[u'url']
+        initial_url = mp3_info['url']
-            'title': info[u'title'],
+            'title': info['title'],
-            'uploader': info[u'artist'],
+            'thumbnail': info['thumb_url'],
-    IE_NAME = u'Bandcamp:album'
+    IE_NAME = 'Bandcamp:album'
-        u'playlist': [
+        'url': 'http://blazo.bandcamp.com/album/jazz-format-mixtape-vol-1',
-                    u'title': u'Intro',
+                'file': '1353101989.mp3',
-                    u'title': u'Kero One - Keep It Alive (Blazo remix)',
+                'file': '38097443.mp3',
-            u'playlistend': 2
+        'params': {
-        u'skip': u'Bancamp imposes download limits. See test_playlists:test_bandcamp_album for the playlist test'
+        'skip': 'Bancamp imposes download limits. See test_playlists:test_bandcamp_album for the playlist test'
-            raise ExtractorError(u'The page doesn\'t contain any tracks')
+            raise ExtractorError('The page doesn\'t contain any tracks')
-        title = self._search_regex(r'album_title : "(.*?)"', webpage, u'title')
+        title = self._search_regex(r'album_title : "(.*?)"', webpage, 'title')
-            u'upload_date': u'20130609',
+        'url': 'http://edition.cnn.com/video/?/video/sports/2013/06/09/nadal-1-on-1.cnn',
-        info_url = u'http://cnn.com/video/data/3.0/%s/index.xml' % path
+        info_url = 'http://cnn.com/video/data/3.0/%s/index.xml' % path
-__version__ = '2014.01.07.3'
+__version__ = '2014.01.07.4'
-                return self._real_extract(url)
+                config = self._verify_player_video_password(url, video_id)
-    _IE_NAME = 'blinkx'
+    IE_NAME = 'blinkx'
-    _IE_NAME = 'defense.gouv.fr'
+    IE_NAME = 'defense.gouv.fr'
-    _IE_NAME = 'MPORA'
+    IE_NAME = 'MPORA'
-    _IE_NAME = u'blinkx'
+    _IE_NAME = 'blinkx'
-            u"thumbnails": [{
+        'url': 'http://www.blinkx.com/ce/8aQUy7GVFYgFzpKhT0oqsilwOGFRVXk3R1ZGWWdGenBLaFQwb3FzaWx3OGFRVXk3R1ZGWWdGenB',
-        m = re.match(self._VALID_URL, url)
+    def _real_extract(self, rl):
-                   u'video=%s' % video_id)
+                   'video=%s' % video_id)
-        upload_date = dt.strftime('%Y%m%d')
+        pload_date = dt.strftime('%Y%m%d')
-            'upload_date': upload_date,
+            'upload_date': pload_date,
-        u'md5': u'75bba6124da7e63d2d60b5244ec9430c',
+        'url': 'http://www.defense.gouv.fr/layout/set/ligthboxvideo/base-de-medias/webtv/attaque-chimique-syrienne-du-21-aout-2013-1',
-    preferredencoding,
+from __future__ import unicode_literals
-        self.assertEqual(result['title'], u'SPORT')
+        self.assertEqual(result['title'], 'SPORT')
-        self.assertEqual(result['title'], u'GÃ©nÃ©ration Quoi')
+        self.assertEqual(result['title'], 'GÃ©nÃ©ration Quoi')
-        self.assertEqual(result['title'], u'Vimeo Tributes')
+        self.assertEqual(result['title'], 'Vimeo Tributes')
-        self.assertEqual(result['title'], u'Nki')
+        self.assertEqual(result['title'], 'Nki')
-        self.assertEqual(result['title'], u'Staff Favorites: November 2013')
+        self.assertEqual(result['title'], 'Staff Favorites: November 2013')
-        self.assertEqual(result['title'], u'Rolex Awards for Enterprise')
+        self.assertEqual(result['title'], 'Rolex Awards for Enterprise')
-        self.assertEqual(result['id'], u'5124905')
+        self.assertEqual(result['id'], '5124905')
-        self.assertEqual(result['title'], u'The Royal Concept EP')
+        self.assertEqual(result['title'], 'The Royal Concept EP')
-        self.assertEqual(result['id'], u'9615865')
+        self.assertEqual(result['id'], '9615865')
-        self.assertEqual(result['title'], u'TEDCity2.0 (English)')
+        self.assertEqual(result['title'], 'TEDCity2.0 (English)')
-        self.assertEqual(result['title'], u'Highlights')
+        self.assertEqual(result['id'], '999')
-        self.assertEqual(result['title'], u'pixelversity')
+        self.assertEqual(result['title'], 'pixelversity')
-        self.assertEqual(result['title'], u'Nightmare Night EP')
+        self.assertEqual(result['title'], 'Nightmare Night EP')
-        self.assertEqual(result['title'], u'ÐÐÐ Ð¤')
+        self.assertEqual(result['id'], 'kommuna')
-        self.assertEqual(result['title'], u'Inspector')
+        self.assertEqual(result['id'], 'inspector')
-        result = ie.extract(u'http://academicearth.org/courses/building-dynamic-websites/')
+        result = ie.extract('http://academicearth.org/courses/building-dynamic-websites/')
-        self.assertEqual(result['title'], u'Building Dynamic Websites')
+        self.assertEqual(result['id'], 'building-dynamic-websites')
-        self.assertEqual(result['title'], u'ÐÐµÐ¶ÑÑÐ½ÑÐ¹ Ð°Ð½Ð³ÐµÐ» (2010 - 2012)')
+        self.assertEqual(result['id'], 'dezhurnyi_angel')
-        self.assertEqual(result['title'], u'ÐÐµÐ¶ÑÑÐ½ÑÐ¹ Ð°Ð½Ð³ÐµÐ» (2010 - 2012) 2 ÑÐµÐ·Ð¾Ð½')
+        self.assertEqual(result['id'], 'dezhurnyi_angel/season2')
-        self.assertEqual(result['title'], u'Animated and Family Films')
+        self.assertEqual(result['id'], 'sMjedvGDd8U')
-        self.assertEqual(result['description'], u'How have humans protected their secret messages through history? What has changed today?')
+        self.assertEqual(result['id'], 'cryptography')
-    IE_DESC = u'Internet Movie Database trailers'
+    IE_NAME = 'imdb'
-            u'description': u'md5:9061c2219254e5d14e03c25c98e96a81',
+        'url': 'http://www.imdb.com/video/imdb/vi2524815897',
-                u'Downloading info for %s format' % f_id)
+                'Downloading info for %s format' % f_id)
-                format_page, u'json data', flags=re.DOTALL)
+                format_page, 'json data', flags=re.DOTALL)
-    IE_DESC = u'Internet Movie Database lists'
+    IE_NAME = 'imdb:list'
-        list_title = self._html_search_regex(r'<title>(.*?)</title>', rss, u'list title')
+        rss = self._download_webpage('http://rss.imdb.com/list/%s' % list_id, list_id, 'Downloading list RSS')
-                                     list_id, u'Downloading list CSV')
+                                     list_id, 'Downloading list CSV')
-        return self.playlist_result(entries, list_id, list_title)
+        return self.playlist_result(entries, list_id, list_title)
-
+    KhanAcademyIE,
-__version__ = '2014.01.07.2'
+__version__ = '2014.01.07.3'
-__version__ = '2014.01.07.1'
+__version__ = '2014.01.07.2'
-__version__ = '2014.01.07'
+__version__ = '2014.01.07.1'
-                res += '%-5s@' % fdict['vcodec']
+                res += '%-5s' % fdict['vcodec']
-    
+    _TIMECODE_REGEX = r'\[(?P<timecode>\d+:\d+:\d+[\.,]\d+)\]'
-                seq_current = subs[pos]                
+                seq_current = subs[pos]
-                seq_next = subs[pos+1]
+                    continue
-                    continue                
+                    continue
-        u"info_dict": {
+        'info_dict': {
-    _VALID_URL = r'(?:https?://)?vimeo.\com/(?P<name>[^/]+)(?:[#?]|$)'
+    _VALID_URL = r'(?:https?://)?vimeo.\com/(?P<name>[^/]+)(?:/videos|[#?]|$)'
-                    assert(os.path.exists(path))
+                    assert ':' not in key
-                    with open(ads_fn, "w") as f:
+                    with open(ads_fn, "wb") as f:
-                    byte_value = value.encode(preferredencoding())
+                    byte_value = value.encode('utf-8')
-                user_has_xattr    = which("xattr")
+                    ads_fn = path + ":" + key
-                            raise  # Reraise unhandled error
+                        subprocess.check_output(cmd)
-        self._downloader.to_screen('[metadata] Writing metadata to file\'s xattrs...')
+        self._downloader.to_screen('[metadata] Writing metadata to file\'s xattrs')
-        except OSError:
+        except (subprocess.CalledProcessError, OSError):
-        return dict((program, executable(program)) for program in programs)
+        return dict((program, check_executable(program, ['-version'])) for program in programs)
-                        self._downloader.report_error("Couldn't find a tool to set the xattrs. Install either the python 'xattr' module, or the 'xattr' binary.")
+                        self._downloader.report_error(
-                            raise # Reraise unhandled error
+                            raise  # Reraise unhandled error
-                    write_xattr(filename, xattrname, value)
+                    byte_value = value.encode(preferredencoding())
-    subtitles_filename,
+from .ffmpeg import (
-
+from .xattrpp import XAttrMetadataPP
-                    response = self._request_webpage(
+                    self._request_webpage(
-    packages=['youtube_dl', 'youtube_dl.extractor', 'youtube_dl.downloader'],
+    packages=[
-from .PostProcessor import FFmpegMergerPP
+from .postprocessor import FFmpegMergerPP
-from .PostProcessor import (
+from .postprocessor import (
-from .utils import (
+from ..utils import (
-
+
-                    f.close()
+                    ads_fn = path + ":" + key
-                'user.xdg.referrer.url':       'webpage_url',
+                'user.xdg.referrer.url': 'webpage_url',
-                'user.dublincore.date':        'upload_date',
+                'user.dublincore.title': 'title',
-                'user.dublincore.format':      'format',
+                'user.dublincore.format': 'format',
-__version__ = '2014.01.06.1'
+__version__ = '2014.01.07'
-                referer=url)
+            # We set the original url as the default 'Referer' header
-            return self.url_result(bc_url, 'Brightcove')
+            surl = smuggle_url(bc_url, {'Referer': url})
-def unsmuggle_url(smug_url):
+def unsmuggle_url(smug_url, default=None):
-        return smug_url, None
+        return smug_url, default
-                u'description': u'md5:a950cc4285c43e44d763d036710cd9cd',
+            'url': 'http://c.brightcove.com/services/viewer/htmlFederated?playerID=1654948606001&flashID=myExperience&%40videoPlayer=2371591881001',
-                u'uploader': u'Oracle',
+            'url': 'http://c.brightcove.com/services/viewer/htmlFederated?playerID=1217746023001&flashID=myPlayer&%40videoPlayer=1785452137001',
-                u'uploader': u'Mashable',
+            'url': 'http://c.brightcove.com/services/viewer/federated_f9?&playerID=1265504713001&publisherID=AQ%7E%7E%2CAAABBzUwv1E%7E%2CxP-xFHVUstiMFlNYfvF4G9yFnNaqCw_9&videoID=2750934548001',
-                u'uploader': u'National Ballet of Canada',
+            'url': 'http://link.brightcove.com/services/player/bcpid756015033001?bckey=AQ~~,AAAApYJi_Ck~,GxhXCegT1Dp39ilhXuxMJxasUhVNZiil&bctid=2878862109001',
-        object_str = object_str.replace(u'<--', u'<!--')
+        object_str = object_str.replace('<--', '<!--')
-        assert u'BrightcoveExperience' in object_doc.attrib['class']
+        assert 'BrightcoveExperience' in object_doc.attrib['class']
-                                               player_key, u'Downloading playlist information')
+                                               player_key, 'Downloading playlist information')
-            raise ExtractorError(u'Empty playlist')
+            raise ExtractorError('Empty playlist')
-            raise ExtractorError(u'Unable to extract video url for %s' % info['id'])
+            raise ExtractorError('Unable to extract video url for %s' % info['id'])
-        token = re.search(r'xsrft: \'(.*?)\'', webpage).group(1)
+        token = self._search_regex(r'xsrft: \'(.*?)\'', webpage, 'login token')
-        token = re.search(r'xsrft: \'(.*?)\'', webpage).group(1)
+        token = self._search_regex(r'xsrft: \'(.*?)\'', webpage, 'login token')
-    IE_NAME = u'vimeo'
+    IE_NAME = 'vimeo'
-                u"title": u"youtube-dl test video - \u2605 \" ' \u5e78 / \\ \u00e4 \u21ad \U0001d550",
+            'url': 'http://vimeo.com/56015672#at=0',
-                u'title': u'Andy Allan - Putting the Carto into OpenStreetMap Cartography',
+            'url': 'http://vimeopro.com/openstreetmapus/state-of-the-map-us-2013/video/68093876',
-                u'uploader': u'The BLN & Business of Software',
+            'url': 'http://player.vimeo.com/video/54469442',
-                u'uploader': u'Jaime MarquÃ­nez FerrÃ¡ndiz',
+            'url': 'http://vimeo.com/68375962',
-                u'videopassword': u'youtube-dl',
+            'params': {
-        self._download_webpage(login_request, None, False, u'Wrong login info')
+        self._download_webpage(login_request, None, False, 'Wrong login info')
-            raise ExtractorError(u'This video is protected by a password, use the --video-password option')
+            raise ExtractorError('This video is protected by a password, use the --video-password option')
-                               u'Wrong password')
+                               'Verifying the password',
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-                    r' data-config-url="(.+?)"', webpage, u'config URL')
+                    r' data-config-url="(.+?)"', webpage, 'config URL')
-                config = self._search_regex(config_re, webpage, u'info section',
+                config = self._search_regex(config_re, webpage, 'info section',
-                raise ExtractorError(u'The author has restricted the access to this video, try with the "--referer" option')
+                raise ExtractorError('The author has restricted the access to this video, try with the "--referer" option')
-                raise ExtractorError(u'Unable to extract info section',
+                raise ExtractorError('Unable to extract info section',
-            comment_count = int(self._search_regex(r'UserComments:(\d+)', webpage, u'comment count'))
+            view_count = int(self._search_regex(r'UserPlays:(\d+)', webpage, 'view count'))
-            raise ExtractorError(u'No known codec found')
+            raise ExtractorError('No known codec found')
-    IE_NAME = u'vimeo:channel'
+    IE_NAME = 'vimeo:channel'
-        return self._html_search_regex(self._TITLE_RE, webpage, u'list title')
+        return self._html_search_regex(self._TITLE_RE, webpage, 'list title')
-                u'Downloading page %s' % pagenum)
+                'Downloading page %s' % pagenum)
-    IE_NAME = u'vimeo:user'
+    IE_NAME = 'vimeo:user'
-    IE_NAME = u'vimeo:album'
+    IE_NAME = 'vimeo:album'
-    IE_NAME = u'vimeo:group'
+    IE_NAME = 'vimeo:group'
-    IE_DESC = u'Review pages on vimeo'
+    IE_NAME = 'vimeo:review'
-__version__ = '2014.01.06'
+__version__ = '2014.01.06.1'
-__version__ = '2014.01.05.6'
+__version__ = '2014.01.06'
-    _VALID_URL = r'(?:https?://)?vimeo.\com/(?P<name>[^/]+)'
+    _VALID_URL = r'(?:https?://)?vimeo.\com/(?P<name>[^/]+)(?:[#?]|$)'
-        album_id =  mobj.group('id')
+        album_id = mobj.group('id')
-import xml.etree.ElementTree
+import re
-    find_xpath_attr,
+    HEADRequest,
-    _VALID_URL = r'https?://tvthek\.orf\.at/(programs/.+?/episodes|topics/.+?)/(?P<id>\d+)'
+    _VALID_URL = r'https?://tvthek\.orf\.at/(?:programs/.+?/episodes|topics/.+?|program/[^/]+)/(?P<id>\d+)'
-            videos.append({
+        data_json = self._search_regex(
-        return videos
+                'id': video_id,
-            u'description': u'md5:f0094c4cf3a72e22bc4e4239ef767ad7',
+        'url': 'http://veehd.com/video/4686958',
-            webpage, u'player path')
+        player_path = self._search_regex(
-            player_page, u'config json')
+
-            webpage, u'uploader')
+            webpage, 'uploader')
-            webpage, u'thumbnail')
+            webpage, 'thumbnail')
-            webpage, u'description', flags=re.DOTALL)
+            webpage, 'description', flags=re.DOTALL)
-    IE_DESC = u'Generic downloader that works on some sites'
+    IE_DESC = 'Generic downloader that works on some sites'
-    IE_NAME = u'generic'
+    IE_NAME = 'generic'
-                u"title": u"R\u00e9gis plante sa Jeep"
+            'url': 'http://www.hodiho.fr/2013/02/regis-plante-sa-jeep.html',
-                u"uploader": u"Skills Matter",
+            'add_ie': ['Vimeo'],
-                u'uploader': u'M_Pallante',
+            'add_ie': ['Bandcamp'],
-            u'skip': u'There is a limit of 200 free downloads / month for the test song',
+            'skip': 'There is a limit of 200 free downloads / month for the test song',
-                u'uploader': u'BFM BUSINESS',
+            'add_ie': ['Brightcove'],
-                u'skip_download': True,
+            'params': {
-                u'upload_date': u'20100513',
+            'url': 'http://media.w3.org/2010/05/sintel/trailer.mp4',
-                u'title': u'2cc213299525360.mov', #that's what we get
+            'url': 'http://www.rollingstone.com/music/videos/norwegian-dj-cashmere-cat-goes-spartan-on-with-me-premiere-20131219',
-            self._downloader.report_warning(u'Falling back on generic information extractor.')
+            self._downloader.report_warning('Falling back on generic information extractor.')
-        self._downloader.to_screen(u'[redirect] Following redirect to %s' % new_url)
+        self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)
-            raise ExtractorError(u'Invalid URL protocol')
+            raise ExtractorError('Invalid URL protocol')
-        self.to_screen(u'%s: Requesting header' % video_id)
+        self.to_screen('%s: Requesting header' % video_id)
-                        'vcodec': u'none' if m.group('type') == 'audio' else None
+                        'vcodec': 'none' if m.group('type') == 'audio' else None
-            raise ExtractorError(u'Failed to download URL: %s' % url)
+            raise ExtractorError('Failed to download URL: %s' % url)
-            default=u'video')
+            r'(?s)<title>(.*?)</title>', webpage, 'video title',
-            r'^(?:https?://)?([^/]*)/.*', url, u'video uploader')
+            r'^(?:https?://)?([^/]*)/.*', url, 'video uploader')
-            self.to_screen(u'Brightcove video detected.')
+            self.to_screen('Brightcove video detected.')
-            raise ExtractorError(u'Unsupported URL: %s' % url)
+            raise ExtractorError('Unsupported URL: %s' % url)
-            raise ExtractorError(u'Did not find a valid video URL at %s' % url)
+            raise ExtractorError('Did not find a valid video URL at %s' % url)
-            'url':      video_url,
+            'id': video_id,
-            'title':    video_title,
+            'title': video_title,
-class LyndaIE(InfoExtractor):
+class LyndaIE(SubtitlesInfoExtractor):
-
+    
-                    'format_id': fmt['Resolution']
+                    'format_id': str(fmt['Resolution'])
-
+        
-__version__ = '2014.01.05.5'
+__version__ = '2014.01.05.6'
-    all_urls = [url.decode(_enc, 'ignore') if isinstance(url, bytes) else url]
+    all_urls = [url.decode(_enc, 'ignore') if isinstance(url, bytes) else url for url in all_urls]
-__version__ = '2014.01.05.4'
+__version__ = '2014.01.05.5'
-    compat_urllib_parse_urlparse,
+from __future__ import unicode_literals
-)
+
-            u'description': u'At LUMOback, we believe straight backs are stronger.  The LUMOback Posture & Movement Sensor:  It gently vibrates when you slouch, inspiring improved posture and mobility.  Use the app to track your data and improve your posture over time. ',
+        'url': 'http://www.veoh.com/watch/v56314296nk7Zdmz3',
-            self.to_screen(u'%s: detected Youtube video.' % video_id)
+            self.to_screen('%s: detected Youtube video.' % video_id)
-                }
+        video_url = info.get('fullPreviewHashHighPath') or info.get('fullPreviewHashLowPath')
-    _VALID_URL = r'http://www\.veoh\.com/watch/v(?P<id>\d*)'
+    _VALID_URL = r'http://(?:www\.)?veoh\.com/(?:watch|iphone/#_Watch)/v(?P<id>\d*)'
-__version__ = '2014.01.05.3'
+__version__ = '2014.01.05.4'
-__version__ = '2014.01.05.02'
+__version__ = '2014.01.05.3'
-__version__ = '2014.01.05.1'
+__version__ = '2014.01.05.02'
-    entry = entry_template.replace('@TIMESTAMP@', v.replace('.', '-') + 'T00:00:00Z')
+    fields = v.split('.')
-        <atom:updated>@TIMESTAMP@</atom:updated>
+    <?xml version="1.0" encoding="utf-8"?>
-    </atom:feed>""")
+    </feed>""")
-        <atom:content type="xhtml">
+    <entry>
-    </atom:entry>
+        </content>
-now_iso = now.isoformat()
+now_iso = now.isoformat() + 'Z'
-
+entries = []
-    entry = entry.replace('@VERSION@',v)
+    entry = entry_template.replace('@TIMESTAMP@', v.replace('.', '-') + 'T00:00:00Z')
-
+import io
-								""")
+atom_template = textwrap.dedent("""\
-atom_template = atom_template.replace('@TIMESTAMP@',now_iso)
+atom_template = atom_template.replace('@TIMESTAMP@', now_iso)
-	entries.append(entry)
+    entry = entry_template.replace('@TIMESTAMP@',v.replace('.','-'))
-	atom_file.write(atom_template)
+with io.open('update/releases.atom', 'w', encoding='utf-8') as atom_file:
-__version__ = '2014.01.05'
+__version__ = '2014.01.05.1'
-options = helptext[helptext.index('  General Options:')+19:]
+options = helptext[helptext.index('  General Options:') + 19:]
-from __future__ import print_function, unicode_literals
+from __future__ import print_function
-with open(README_FILE) as f:
+with io.open(README_FILE, encoding='utf-8') as f:
-with open(README_FILE, 'w') as f:
+with io.open(README_FILE, 'w', encoding='utf-8') as f:
-        type=float, default=None, help=optparse.SUPPRESS_HELP)
+        type=float, default=None, help=u'Time to wait before giving up, in seconds')
-__version__ = '2014.01.03'
+__version__ = '2014.01.05'
-    compat_urllib_parse,
+    unescapeHTML,
-            u"title": u"Attorney General Eric Holder on Voting Rights Act Decision"
+        'url': 'http://www.c-spanvideo.org/program/HolderonV',
-                }
+
-            # We can accept formats requestd in the format: 34/5/best, we pick
+            # We can accept formats requested in the format: 34/5/best, we pick
-                        selected_format = {'requested_formats': formats_info}
+                        selected_format = {
-        'md5': '80baf1ec5c3d2019037c1c707d676b9f',
+        'file': '5779306.mov',
-    IE_NAME = u'blip.tv'
+    IE_NAME = 'blip.tv'
-            u"title": u"CBR EXCLUSIVE: \"Gotham City Imposters\" Bats VS Jokerz Short 3"
+        'url': 'http://blip.tv/cbr/cbr-exclusive-gotham-city-imposters-bats-vs-jokerz-short-3-5796352',
-        self.to_screen(u'%s: Direct download detected' % title)
+        self.to_screen('%s: Direct download detected' % title)
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-            u'unable to download video info webpage')
+            'unable to download video info webpage')
-            raise ExtractorError(u'Unable to read video info webpage: %s' % compat_str(err))
+            raise ExtractorError('Unable to read video info webpage: %s' % compat_str(err))
-            raise ExtractorError(u'Unable to parse video information: %s' % repr(err))
+            raise ExtractorError('Unable to parse video information: %s' % repr(err))
-    IE_NAME = u'blip.tv:user'
+    IE_NAME = 'blip.tv:user'
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError('Invalid URL: %s' % url)
-        page = self._download_webpage(url, username, u'Downloading user page')
+        page = self._download_webpage(url, username, 'Downloading user page')
-                                          u'Downloading video ids from page %d' % pagenum)
+                                          'Downloading video ids from page %d' % pagenum)
-        urls = [u'http://blip.tv/%s' % video_id for video_id in video_ids]
+        urls = ['http://blip.tv/%s' % video_id for video_id in video_ids]
-    _VALID_URL = r'(?:http://)?(?:www\.)?pornhd\.com/videos/(?P<video_id>[0-9]+)/(?P<video_title>.+)'
+    _VALID_URL = r'(?:http://)?(?:www\.)?pornhd\.com/(?:[a-z]{2,4}/)?videos/(?P<video_id>[0-9]+)/(?P<video_title>.+)'
-            files_cmd.extend(['-i', encodeFilename(path)])
+            files_cmd.extend(['-i', encodeFilename(path, True)])
-               [encodeFilename(self._ffmpeg_filename_argument(out_path))])
+               [encodeFilename(self._ffmpeg_filename_argument(out_path), True)])
-            cmd = [self._exes['avprobe'] or self._exes['ffprobe'], '-show_streams', encodeFilename(self._ffmpeg_filename_argument(path))]
+            cmd = [
-def encodeFilename(s):
+
-    assert type(s) == type(u'')
+    assert type(s) == compat_str
-        return s
+        if not for_subprocess:
-        return s.encode(encoding, 'ignore')
+    if encoding is None:
-    assert type(s) == type(u'')
+    assert type(s) == compat_str
-    out.write(s)
+    try:
-    assert isinstance(title, type(u''))
+    assert isinstance(title, compat_str)
-            u'age_limit': 13,
+        'url': 'http://www.collegehumor.com/video/6902724/comic-con-cosplay-catastrophe',
-            u'age_limit': 10,
+        'url': 'http://www.collegehumor.com/video/3505939/font-conference',
-            jsonUrl, video_id, u'Downloading info JSON'))
+            jsonUrl, video_id, 'Downloading info JSON'))
-
+            'age_limit': age_limit,
-        u'md5': u'1264c12ad95dca142a9f0bf7968105a0',
+        u'md5': u'dcc0f5c1c8be98dc33889a191f4c26bd',
-            u'description': u'Fans get creative this year at San Diego.  Too creative.  And yes, that\'s really Joss Whedon.',
+            u'description': u'Fans get creative this year at San Diego.  Too',
-        u'md5': u'c51ca16b82bb456a4397987791a835f5',
+        u'md5': u'72fa701d8ef38664a4dbb9e2ab721816',
-        info = {
+        jsonUrl = 'http://www.collegehumor.com/moogaloop/video/' + video_id + '.json'
-            'upload_date': None,
+            'title': vdata['title'],
-        print('Skipping this test (not yet fully implemtned)')
+        print('Skipping this test (not yet fully implemented)')
-from __future__ import print_function
+from __future__ import print_function, unicode_literals
-from __future__ import absolute_import
+from __future__ import absolute_import, unicode_literals
-                    self.report_warning(u'Could not find fribidi executable, ignoring --bidi-workaround . Make sure that  fribidi  is an executable file in one of the directories in your $PATH.')
+                    self.report_warning('Could not find fribidi executable, ignoring --bidi-workaround . Make sure that  fribidi  is an executable file in one of the directories in your $PATH.')
-                u'Set the LC_ALL environment variable to fix this.')
+                'Assuming --restrict-filenames since file system encoding '
-            self.report_warning(u'%(stitle)s is deprecated. Use the %(title)s and the --restrict-filenames flag(which also secures %(uploader)s et al) instead.')
+            self.report_warning('%(stitle)s is deprecated. Use the %(title)s and the --restrict-filenames flag(which also secures %(uploader)s et al) instead.')
-        self._output_process.stdin.write((message + u'\n').encode('utf-8'))
+        assert type(message) == type('')
-        res = u''.join(self._output_channel.readline().decode('utf-8')
+        res = ''.join(self._output_channel.readline().decode('utf-8')
-        return res[:-len(u'\n')]
+        return res[:-len('\n')]
-            terminator = [u'\n', u''][skip_eol]
+            terminator = ['\n', ''][skip_eol]
-        assert type(message) == type(u'')
+        assert type(message) == type('')
-            output = message + u'\n'
+            output = message + '\n'
-            write_string(u'\033]0;%s\007' % message, self._screen_file)
+            write_string('\033]0;%s\007' % message, self._screen_file)
-            write_string(u'\033[22;0t', self._screen_file)
+            write_string('\033[22;0t', self._screen_file)
-            write_string(u'\033[23;0t', self._screen_file)
+            write_string('\033[23;0t', self._screen_file)
-                    tb = u''
+                    tb = ''
-                        tb += u''.join(traceback.format_exception(*sys.exc_info()[1].exc_info))
+                        tb += ''.join(traceback.format_exception(*sys.exc_info()[1].exc_info))
-                    tb = u''.join(tb_data)
+                    tb = ''.join(tb_data)
-            _msg_header = u'\033[0;33mWARNING:\033[0m'
+            _msg_header = '\033[0;33mWARNING:\033[0m'
-        warning_message = u'%s %s' % (_msg_header, message)
+            _msg_header = 'WARNING:'
-            _msg_header = u'\033[0;31mERROR:\033[0m'
+            _msg_header = '\033[0;31mERROR:\033[0m'
-        error_message = u'%s %s' % (_msg_header, message)
+            _msg_header = 'ERROR:'
-            self.to_screen(u'[download] %s has already been downloaded' % file_name)
+            self.to_screen('[download] %s has already been downloaded' % file_name)
-            self.to_screen(u'[download] The file has already been downloaded')
+            self.to_screen('[download] The file has already been downloaded')
-            autonumber_templ = u'%0' + str(autonumber_size) + u'd'
+            autonumber_templ = '%0' + str(autonumber_size) + 'd'
-                template_dict['playlist_index'] = u'%05d' % template_dict['playlist_index']
+                template_dict['playlist_index'] = '%05d' % template_dict['playlist_index']
-                is_id=(k == u'id'))
+                is_id=(k == 'id'))
-            template_dict = collections.defaultdict(lambda: u'NA', template_dict)
+            template_dict = collections.defaultdict(lambda: 'NA', template_dict)
-            self.report_error(u'Error in output template: ' + str(err) + u' (encoding: ' + repr(preferredencoding()) + ')')
+            self.report_error('Error in output template: ' + str(err) + ' (encoding: ' + repr(preferredencoding()) + ')')
-        video_title = info_dict.get('title', info_dict.get('id', u'video'))
+        video_title = info_dict.get('title', info_dict.get('id', 'video'))
-                    return u'"' + title + '" title did not match pattern "' + matchtitle + '"'
+                    return '"' + title + '" title did not match pattern "' + matchtitle + '"'
-                    return u'"' + title + '" title matched reject pattern "' + rejecttitle + '"'
+                    return '"' + title + '" title matched reject pattern "' + rejecttitle + '"'
-                return u'%s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)
+                return '%s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)
-                return u'Skipping %s, because it has not reached minimum view count (%d/%d)' % (video_title, view_count, min_views)
+                return 'Skipping %s, because it has not reached minimum view count (%d/%d)' % (video_title, view_count, min_views)
-                return u'Skipping %s, because it has exceeded the maximum view count (%d/%d)' % (video_title, view_count, max_views)
+                return 'Skipping %s, because it has exceeded the maximum view count (%d/%d)' % (video_title, view_count, max_views)
-                return u'Skipping "' + title + '" because it is age restricted'
+                return 'Skipping "' + title + '" because it is age restricted'
-            return u'%s has already been recorded in archive' % video_title
+            return '%s has already been recorded in archive' % video_title
-                                    u'and will probably not work.')
+                self.report_warning('The program functionality for this site has been marked as broken, '
-            self.report_error(u'no suitable InfoExtractor: %s' % url)
+            self.report_error('no suitable InfoExtractor: %s' % url)
-            self.to_screen(u'[download] Downloading playlist: %s' % playlist)
+            self.to_screen('[download] Downloading playlist: %s' % playlist)
-                u"[%s] playlist '%s': Collected %d video ids (downloading %d of them)" %
+                "[%s] playlist '%s': Collected %d video ids (downloading %d of them)" %
-                self.to_screen(u'[download] Downloading video #%s of %s' % (i, n_entries))
+                self.to_screen('[download] Downloading video #%s of %s' % (i, n_entries))
-                    self.to_screen(u'[download] ' + reason)
+                    self.to_screen('[download] ' + reason)
-            extensions = [u'mp4', u'flv', u'webm', u'3gp']
+            extensions = ['mp4', 'flv', 'webm', '3gp']
-        if info_dict['extractor'] in [u'Youku']:
+        if info_dict['extractor'] in ['Youku']:
-                format['format'] = u'{id} - {res}{note}'.format(
+                format['format'] = '{id} - {res}{note}'.format(
-                    note=u' ({0})'.format(format['format_note']) if format.get('format_note') is not None else '',
+                    note=' ({0})'.format(format['format_note']) if format.get('format_note') is not None else '',
-            raise ExtractorError(u'requested format not available',
+            raise ExtractorError('requested format not available',
-                self.to_screen(u'[info] %s: downloading video in %s formats' % (info_dict['id'], len(formats_to_download)))
+                self.to_screen('[info] %s: downloading video in %s formats' % (info_dict['id'], len(formats_to_download)))
-            info_dict['title'] = info_dict['title'][:197] + u'...'
+            info_dict['title'] = info_dict['title'][:197] + '...'
-            self.to_screen(u'[download] ' + reason)
+            self.to_screen('[download] ' + reason)
-            self.to_stdout(info_dict['url'] + info_dict.get('play_path', u''))
+            self.to_stdout(info_dict['url'] + info_dict.get('play_path', ''))
-            self.report_error(u'unable to create directory ' + compat_str(err))
+            self.report_error('unable to create directory ' + compat_str(err))
-            descfn = filename + u'.description'
+            descfn = filename + '.description'
-                self.to_screen(u'[info] Video description is already present')
+                self.to_screen('[info] Video description is already present')
-                    self.to_screen(u'[info] Writing video description to: ' + descfn)
+                    self.to_screen('[info] Writing video description to: ' + descfn)
-                    self.report_warning(u'There\'s no description to write.')
+                    self.report_warning('There\'s no description to write.')
-                    self.report_error(u'Cannot write description file ' + descfn)
+                    self.report_error('Cannot write description file ' + descfn)
-            annofn = filename + u'.annotations.xml'
+            annofn = filename + '.annotations.xml'
-                self.to_screen(u'[info] Video annotations are already present')
+                self.to_screen('[info] Video annotations are already present')
-                    self.to_screen(u'[info] Writing video annotations to: ' + annofn)
+                    self.to_screen('[info] Writing video annotations to: ' + annofn)
-                    self.report_warning(u'There are no annotations to write.')
+                    self.report_warning('There are no annotations to write.')
-                    self.report_error(u'Cannot write annotations file: ' + annofn)
+                    self.report_error('Cannot write annotations file: ' + annofn)
-                        self.to_screen(u'[info] Video subtitle %s.%s is already_present' % (sub_lang, sub_format))
+                        self.to_screen('[info] Video subtitle %s.%s is already_present' % (sub_lang, sub_format))
-                        self.to_screen(u'[info] Writing video subtitles to: ' + sub_filename)
+                        self.to_screen('[info] Writing video subtitles to: ' + sub_filename)
-                    self.report_error(u'Cannot write subtitles file ' + descfn)
+                    self.report_error('Cannot write subtitles file ' + descfn)
-            infofn = os.path.splitext(filename)[0] + u'.info.json'
+            infofn = os.path.splitext(filename)[0] + '.info.json'
-                self.to_screen(u'[info] Video description metadata is already present')
+                self.to_screen('[info] Video description metadata is already present')
-                self.to_screen(u'[info] Writing video description metadata as JSON to: ' + infofn)
+                self.to_screen('[info] Writing video description metadata as JSON to: ' + infofn)
-                    self.report_error(u'Cannot write metadata to JSON file ' + infofn)
+                    self.report_error('Cannot write metadata to JSON file ' + infofn)
-                thumb_filename = os.path.splitext(filename)[0] + u'.' + thumb_format
+                thumb_format = determine_ext(info_dict['thumbnail'], 'jpg')
-                    self.to_screen(u'[%s] %s: Thumbnail is already present' %
+                    self.to_screen('[%s] %s: Thumbnail is already present' %
-                    self.to_screen(u'[%s] %s: Downloading thumbnail ...' %
+                    self.to_screen('[%s] %s: Downloading thumbnail ...' %
-                        self.to_screen(u'[%s] %s: Writing thumbnail to: %s' %
+                        self.to_screen('[%s] %s: Writing thumbnail to: %s' %
-                        self.report_warning(u'Unable to download thumbnail "%s": %s' %
+                        self.report_warning('Unable to download thumbnail "%s": %s' %
-                    self.report_error(u'unable to download video data: %s' % str(err))
+                    self.report_error('unable to download video data: %s' % str(err))
-                    self.report_error(u'content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))
+                    self.report_error('content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))
-                    self.report_error(u'postprocessing: %s' % str(err))
+                    self.report_error('postprocessing: %s' % str(err))
-                self.report_error(u'unable to download video')
+                self.report_error('unable to download video')
-                self.to_screen(u'[info] Maximum number of downloaded files reached.')
+                self.to_screen('[info] Maximum number of downloaded files reached.')
-                self.report_warning(u'The info failed to download, trying with "%s"' % webpage_url)
+                self.report_warning('The info failed to download, trying with "%s"' % webpage_url)
-                self.to_screen(u'Deleting original file %s (pass -k to keep)' % filename)
+                self.to_screen('Deleting original file %s (pass -k to keep)' % filename)
-                self.report_warning(u'Unable to remove downloaded video file')
+                self.report_warning('Unable to remove downloaded video file')
-        return extractor.lower() + u' ' + info_dict['id']
+        return extractor.lower() + ' ' + info_dict['id']
-            archive_file.write(vid_id + u'\n')
+            archive_file.write(vid_id + '\n')
-                res = u'%sx%s' % (format['width'], format['height'])
+                res = '%sx%s' % (format['width'], format['height'])
-                res = u'%sp' % format['height']
+                res = '%sp' % format['height']
-            res = u'?x%d' % format['width']
+            res = '?x%d' % format['width']
-            res = u''
+            res = ''
-                res += u'(unsupported) '
+                res += '(unsupported) '
-                res += fdict['format_note'] + u' '
+                res += fdict['format_note'] + ' '
-                res += u'%4dk ' % fdict['tbr']
+                res += '%4dk ' % fdict['tbr']
-                res += u'%-5s@' % fdict['vcodec']
+                res += '%-5s@' % fdict['vcodec']
-                res += u'video@'
+                res += 'video@'
-                res += u'%4dk' % fdict['vbr']
+                res += '%4dk' % fdict['vbr']
-                res += u'%-5s' % fdict['acodec']
+                    res += ', '
-                    res += u', '
+                    res += ', '
-                res += u'@%3dk' % fdict['abr']
+                res += '@%3dk' % fdict['abr']
-                    res += u', '
+                    res += ', '
-            return ((u'%-' + compat_str(idlen + 1) + u's%-10s%-12s%s') % (
+            return (('%-' + compat_str(idlen + 1) + 's%-10s%-12s%s') % (
-        idlen = max(len(u'format code'),
+        idlen = max(len('format code'),
-                       (info_dict['id'], header_line, u"\n".join(formats_s)))
+            'format_id': 'format code', 'ext': 'extension',
-        write_string(u'[debug] youtube-dl version ' + __version__ + u'\n')
+        write_string('[debug] youtube-dl version ' + __version__ + '\n')
-                write_string(u'[debug] Git HEAD: ' + out + u'\n')
+                write_string('[debug] Git HEAD: ' + out + '\n')
-                     (platform.python_version(), platform_name()) + u'\n')
+        write_string('[debug] Python version %s - %s' %
-        write_string(u'[debug] Proxy map: ' + compat_str(proxy_map) + u'\n')
+        write_string('[debug] Proxy map: ' + compat_str(proxy_map) + '\n')
-                selected_format = self.select_format(rf, formats)
+                if re.match(r'.+?\+.+?', rf) is not None:
-                    success = fd.download(filename, info_dict)
+                    def dl(name, info):
-        for pp in self._pps:
+        pps_chain = []
-    IE_DESC = u'MacGameStore trailers'
+    IE_NAME = 'macgamestore'
-            u'title': u'Crow',
+        'url': 'http://www.macgamestore.com/mediaviewer.php?trailer=2450',
-        
+
-        
+            raise ExtractorError('Trailer %s does not exist' % video_id, expected=True)
-        }
+        }
-        temp_filename = filename + u'.temp'
+        temp_filename = prepend_extension(filename, 'temp')
-        options.extend(['-f', ext])
+
-        property_re = r'property=[\'"]og:%s[\'"]' % re.escape(prop)
+        property_re = r'(?:name|property)=[\'"]og:%s[\'"]' % re.escape(prop)
-from ..utils import unified_strdate
+
-    IE_NAME = u'jpopsuki.tv'
+    IE_NAME = 'jpopsuki.tv'
-            'upload_date': u'20121101'
+        'url': 'http://www.jpopsuki.tv/video/ayumi-hamasaki---evolution/00be659d23b0b40508169cdee4545771',
-            r'<source src="(.*?)" type', webpage, u'video url')
+            r'<source src="(.*?)" type', webpage, 'video url')
-            r'<meta name="og:image" content="(.*?)" />', webpage, u'video thumbnail')
+        video_title = self._og_search_title(webpage)
-            r'<li>from: <a href="/user/view/user/(.*?)/uid/', webpage, u'video uploader')
+            r'<li>from: <a href="/user/view/user/(.*?)/uid/',
-            r'<li>from: <a href="/user/view/user/\S*?/uid/(\d*)', webpage, u'video uploader_id')
+            r'<li>from: <a href="/user/view/user/\S*?/uid/(\d*)',
-            r'<li>uploaded: (.*?)</li>', webpage, u'video upload_date')
+            r'<li>uploaded: (.*?)</li>', webpage, 'video upload_date',
-            r'<h2>(\d*?) comments</h2>', webpage, u'video comment_count')
+        view_count_str = self._html_search_regex(
-        }
+            'view_count': int_or_none(view_count_str),
-__version__ = '2013.12.26'
+__version__ = '2014.01.03'
-    _VALID_URL = r'(?:http://)?(?:www\.)?3sat\.de/mediathek/index\.php\?(?:(?:mode|display)=[^&]+&)*obj=(?P<id>[0-9]+)$'
+    _VALID_URL = r'(?:http://)?(?:www\.)?3sat\.de/mediathek/(?:index\.php)?\?(?:(?:mode|display)=[^&]+&)*obj=(?P<id>[0-9]+)$'
-        help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl .')
+        help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')
-        help='Location in the filesystem where youtube-dl can store downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl .')
+        help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl .')
-                       |(?P<widget>w\.soundcloud\.com/player/?.*?url=.*)
+                       |(?P<player>(?:w|player|p.)\.soundcloud\.com/player/?.*?url=.*)
-        elif mobj.group('widget'):
+        elif mobj.group('player'):
-            help='add metadata to the files')
+            help='write metadata to the video file')
-    _VALID_URL = r'https?://(?:www.)?comedycentral.com/(video-clips|episodes|cc-studios)/(?P<title>.*)'
+    _VALID_URL = r'''(?x)https?://(?:www.)?comedycentral.com/
-        song_url = preview_url.replace('/previews/', '/cloudcasts/originals/')
+        song_url = preview_url.replace('/previews/', '/c/originals/')
-                                 present, the formats get sorted by this field.
+                                 present and not None, the formats get sorted
-    _URL_EXT = r'^.*\.([a-z0-9]+)$'
+            formats = []
-                video_url = best_format['url']
+                for f in sorted(data['additionalMedia'], key=lambda f: int(f['media_height'])):
-            ext = umobj.group(1)
+                formats.append({
-                'player_url': data['embedUrl'],
+                'formats': formats,
-        u'md5': u'57c97d0469d71cf874f6815aa2b7c944',
+        u'file': u'36983.mp4',
-        uri = mobj.group('mgid')
+        uri = mobj.groupdict().get('mgid')
-            except (IOError, OSError):
+            except (IOError, OSError) as err:
-        self.params = {} if params is None else params
+        self.params = params
-            if f.get('ext') in ['f4f', 'f4m']:
+            if fdict.get('ext') in ['f4f', 'f4m']:
-        mobj = re.search(r'<meta\s[^>]*https?://api.blip.tv/\w+/redirect/\w+/(\d+)', webpage)
+        mobj = re.search(r'<meta\s[^>]*https?://api\.blip\.tv/\w+/redirect/\w+/(\d+)', webpage)
-        mobj = re.search(r'<(?:iframe|embed|object)\s[^>]*https?://(?:\w+\.)?blip.tv/(?:play/|api\.swf#)([a-zA-Z0-9]+)', webpage)
+            return self.url_result('http://blip.tv/a/a-'+mobj.group(1), 'BlipTV')
-                return self.url_result('http://blip.tv/seo/-'+blip_video_id, 'BlipTV')
+            return self.url_result(mobj.group(1), 'BlipTV')
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?blip\.tv/((.+/)|(play/)|(api\.swf#))(.+)$'
+    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?blip\.tv/((.+/)|(play/)|(api\.swf#))(.+)$'
-            return self._real_extract(url)
+        embed_mobj = re.search(r'^(?:https?://)?(?:\w+\.)?blip\.tv/(?:play/|api\.swf#)([a-zA-Z0-9]+)', url)
-            self.params.get('nocheckcertificate', False))
+            self.params.get('nocheckcertificate', False), debuglevel=debuglevel)
-            https_handler, proxy_handler, cookie_processor, YoutubeDLHandler())
+            https_handler, proxy_handler, cookie_processor, ydlh)
-
+    verbosity.add_option('--print-traffic',
-def make_HTTPS_handler(opts_no_check_certificate):
+
-        return HTTPSHandlerV3()
+        return HTTPSHandlerV3(**kwargs)
-        return compat_urllib_request.HTTPSHandler(context=context)
+        return compat_urllib_request.HTTPSHandler(context=context, **kwargs)
-__version__ = '2013.12.23.4'
+__version__ = '2013.12.26'
-                                 ("mp4_h264_opus" or "19")
+                                 ("mp4_h264_opus" or "19").
-                'vbr': int(attr['system-bitrate']),
+                'width': width,
-        formats.sort(key=lambda f: (f['height'], f['width'], f['vbr']))
+
-        formats.sort(key=lambda fmt: self._known_formats.index(fmt['format_id']))
+        formats = [{
-    determine_ext,
+            width = int(attr['width'])
-                'bitrate': int(attr['bitrate']),
+                'width': width,
-        formats = sorted(formats, key=lambda f: f['bitrate'])
+
-                              (int(m['vbr']) + int(m['abr'])) // 1000,
+                              tbr,
-        formats.sort(key=lambda f: (f['width'], f['vbr'], f['abr']))
+
-            return
+        formats = [{
-import os
+
-            u"uploader": u"Ask Dan And Jennifer", 
+            u"upload_date": u"20101221",
-            format = path.split('/')[4].split('_')[:2]
+            format_parts = path.split('/')[4].split('_')[:2]
-            # title = u'%s-%s-%s' % (video_title, size, bitrate)
+            dn = compat_urllib_parse_urlparse(video_url).netloc.partition('.')[0]
-                'ext': extension,
+                'height': height,
-                del formats[i]
+        self._sort_formats(formats)
-        u'md5': u'cdeb30cdae1921719a3cbcab696ef53c',
+        u'md5': u'c557841d5e50261777a6585648adf439',
-            u"title": u"youtube-dl test song \"'/\\\u00e4\u21ad"
+            u"title": u"youtube-dl  \"'/\\\u00e4\u21ad - youtube-dl test song \"'/\\\u00e4\u21ad",
-            data = json.loads(json_code)
+            if m_trackinfo:
-                } for format_id, format_url in sorted(d['file'].items())]
+                    'duration': duration,
-            raise ExtractorError(u'No free songs found')
+            else:
-                       webpage, re.MULTILINE|re.DOTALL).group('id')
+        video_id = re.search(
-        download_webpage = self._download_webpage(download_link, id,
+        download_webpage = self._download_webpage(download_link, video_id,
-        request_url = '%s/statdownload/track?enc=mp3-320&fsig=%s&id=%s&ts=%s&.rand=665028774616&.vrs=1' % (m_url.group('server'), m_url.group('fsig'), id, m_url.group('ts'))
+        request_url = '%s/statdownload/track?enc=mp3-320&fsig=%s&id=%s&ts=%s&.rand=665028774616&.vrs=1' % (m_url.group('server'), m_url.group('fsig'), video_id, m_url.group('ts'))
-        return [track_info]
+        return {
-            raise ExtractorError(u'The page doesn\'t contain any track')
+            raise ExtractorError(u'The page doesn\'t contain any tracks')
-from ..utils import determine_ext
+from ..utils import (
-        video_url = 'http://ht.cdn.turner.com/cnn/big%s' % video_path
+            video_url = 'http://ht.cdn.turner.com/cnn/big%s' % (f.text.strip())
-                }
+        metas_el = info.find('metas')
-import operator
+    int_or_none,
-            proto = format_m.group('proto')
+            proto = format_m.group('proto').lower()
-                'filesize': int(fnode.find('./filesize').text),
+                'width': int_or_none(fnode.find('./width').text),
-                'protocol': format_m.group('proto').lower(),
+                'protocol': proto,
-            formats = sorted(formats, key=lambda f: (f['height'], f['width']))
+
-        formats.sort(key=lambda a: a['filesize'])
+
-    determine_ext,
+    int_or_none,
-                'bitrate': s.get('bitrate'),
+                'width': int_or_none(s.get('width')),
-        formats = sorted(formats, key=lambda f:(f['height'], f['width']))
+
-            u'warning messagef', default=None)
+            u'warning message', default=None)
-    IviCompilationIE
+    IviCompilationIE,
-from .imdb import ImdbIE
+from .imdb import (
-        formats.sort(key=lambda f: (f.get('vbr'), f['abr']))
+        self._sort_formats(formats)
-                preference = 0 if f.get('url', '').startswith('http') else -0.1
+                proto = f.get('protocol')
-                proto_pref = -999
+            proto = format_m.group('proto')
-                '_pref': pref,
+                'protocol': format_m.group('proto').lower(),
-                         key=operator.itemgetter('_pref'))
+        formats = list(filter(
-        formats.sort(key=lambda f: f['vbr'])
+        self._sort_formats(formats)
-        formats = sorted(formats, key=lambda f: f['bitrate'])
+        formats_mit = json.loads(formats_json)
-                'ext': 'mp4',
+                'formats': formats,
-        formats.sort(key=_sortkey)
+        self._sort_formats(formats)
-        '46': 'webm',
+    _formats = {
-        '102': 'webm',
+        '82': {'ext': 'mp4', 'height': 360, 'resolution': '360p', 'format_note': '3D', 'preference': -20},
-        '160': 'mp4',
+        '92': {'ext': 'mp4', 'height': 240, 'resolution': '240p', 'format_note': 'HLS', 'preference': -10},
-        '141': 'm4a',
+        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'vcodec': 'none', 'abr': 48, 'preference': -50},
-        '248': 'DASH Video',
+        '242': {'ext': 'webm', 'height': 240, 'resolution': '240p', 'format_note': 'DASH webm', 'preference': -40},
-        existing_formats = [x for x in self._available_formats if x in url_map]
+        existing_formats = [x for x in self._formats if x in url_map]
-            })
+            dct = {
-        # No prefer_free_formats => keep original formats order
+        # No prefer_free_formats => prefer mp4 and flv for greater compatibilty
-            {u'format_id': u'excellent', u'url': u'http://example.com/exc'},
+            {u'format_id': u'meh', u'url': u'http://example.com/meh', 'preference': 1},
-            {u'format_id': u'2', u'ext': u'flv'},
+            {u'format_id': u'35', u'ext': u'mp4', 'preference': 1},
-            formats = sorted(formats, key=_free_formats_key)
+
-        formats.sort(key=_formats_key)
+        self._sort_formats(formats)
-            return format['_resolution']
+        if format.get('resolution') is not None:
-                res += u'video'
+                res += u'%-5s@' % fdict['vcodec']
-                res += u'@%4dk' % fdict['vbr']
+                res += u'%4dk' % fdict['vbr']
-            '_resolution': u'resolution', 'format_note': u'note'}, idlen=idlen)
+            'resolution': u'resolution', 'format_note': u'note'}, idlen=idlen)
-    Additionally, it must contain either a formats entry or url and ext:
+    Additionally, it must contain either a formats entry or a url one:
-                    be ordered from worst to best quality. Potential fields:
+    formats:        A list of dictionaries for each format available, ordered
-            self.report_error(u'unable to rename file')
+            self.report_error(u'unable to rename file: %s' % str(err))
-            return self.real_download(filename, info_dict)
+
-        info = None
+        url = info_dict['url']
-                video_url = video_url.replace('rtmpe://', 'rtmpt://')
+                self.report_warning(
-                          'entries', 'urlhandle', 'ie_key', 'duration',
+                          'entries', 'ie_key', 'duration',
-                    write_json_file(json_info_dict, encodeFilename(infofn))
+                    write_json_file(info_dict, encodeFilename(infofn))
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?blip\.tv/((.+/)|(play/)|(api\.swf#))(.+)$'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?blip\.tv/((.+/)|(play/)|(api\.swf#))(.+)$'
-        ydl.process_ie_result(info_dict)
+        ydl.process_ie_result(info_dict.copy())
-        ydl.process_ie_result(info_dict)
+        ydl.process_ie_result(info_dict.copy())
-        ydl.process_ie_result(info_dict)
+        ydl.process_ie_result(info_dict.copy())
-        ydl.process_ie_result(info_dict)
+        ydl.process_ie_result(info_dict.copy())
-        ydl.process_ie_result(info_dict)
+        ydl.process_ie_result(info_dict.copy())
-        ydl.process_ie_result(info_dict)
+        ydl.process_ie_result(info_dict.copy())
-        ydl.process_ie_result(info_dict)
+        ydl.process_ie_result(info_dict.copy())
-        ydl.process_ie_result(info_dict)
+        ydl.process_ie_result(info_dict.copy())
-        ydl.add_downloader_progress_hook(_hook)
+        ydl.add_progress_hook(_hook)
-        self._fd_progress_hooks = []
+        self._progress_hooks = []
-        self._fd_progress_hooks.append(ph)
+    def add_progress_hook(self, ph):
-                    for ph in self._fd_progress_hooks:
+                    for ph in self._progress_hooks:
-        info_dict['formats'] = formats
+        if formats[0] is not info_dict: 
-__version__ = '2013.12.23.3'
+__version__ = '2013.12.23.4'
-        formats = sorted(formats, key=_formats_key)
+            note = f.get('format_note')
-__version__ = '2013.12.23.2'
+__version__ = '2013.12.23.3'
-__version__ = '2013.12.23.1'
+__version__ = '2013.12.23.2'
-            info = {
+            return {
-        return [info]
+
-__version__ = '2013.12.23'
+__version__ = '2013.12.23.1'
-                    ['fribidi', '-c', 'UTF-8'] + width_args,
+                sp_kwargs = dict(
-                self._fribidi_channel = os.fdopen(master, 'rb')
+                try:
-        if not hasattr(self, '_fribidi_channel'):
+        if not hasattr(self, '_output_channel'):
-        res = u''.join(self._fribidi_channel.readline().decode('utf-8')
+        self._output_process.stdin.write((message + u'\n').encode('utf-8'))
-        help=u'Work around terminals that lack bidirectional text support. Requires fribidi executable in PATH')
+        help=u'Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')
-__version__ = '2013.12.20'
+__version__ = '2013.12.23'
-        
+
-            video_title = video_url.rsplit('/', 1)[-1]
+            video_title = os.path.splitext(url_basename(video_url))[0]
-        if video_description.endswith(END_TEXT):
+        if video_description and video_description.endswith(END_TEXT):
-        if video_description.startswith(START_TEXT):
+        if video_description and video_description.startswith(START_TEXT):
-                upload_date_m.group('day')
+        if upload_date_str:
-        )
+        else:
-                int(duration_m.group('seconds'))
+        if duration_str:
-        )
+        else:
-    _VALID_URL = r'^(?:https?://(?:www\.)blinkx\.com/ce/|blinkx:)(?P<id>[^?]+)'
+    _VALID_URL = r'^(?:https?://(?:www\.)blinkx\.com/#?ce/|blinkx:)(?P<id>[^?]+)'
-        video_ids = []
+        url_results = []
-            video_ids.extend(ids_in_page)
+            entries = response['feed']['entry']
-            if len(ids_in_page) < self._GDATA_PAGE_SIZE:
+            if len(entries) < self._GDATA_PAGE_SIZE:
-        # Look for embedded Vimeo player
+        # Look for embedded (iframe) Vimeo player
-        (?P<direct_link>play_redirect_hls\?clip_id=)?
+        (?:(?:play_redirect_hls|moogaloop\.swf)\?clip_id=)?
-        /?(?:[?].*)?(?:[#].*)?$'''
+        /?(?:[?&].*)?(?:[#].*)?$'''
-            all_urls = [url for url in all_urls if url not in matchedUrls]
+
-    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|(?P<player>player))\.)?vimeo(?P<pro>pro)?\.com/(?:.*?/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?(?:#.*)?$'
+    _VALID_URL = r'''(?x)
-            u'md5': u'8eccab865181d29ec2958f32a6a754f5',
+            u'md5': u'5423e113865d26e40624dce2e4b45d95',
-        u'md5': u'9c70d6d956f888bdc08c124acc120cfe',
+        u'md5': u'99f65c0c9ef9b682b97313e052734c3f',
-    }]
+    
-            u'title': u'Wanna be the Strongest in the World â Episode 1 â An Idol-Wrestler is Born!',
+            u'title': u'Wanna be the Strongest in the World Episode 1 â An Idol-Wrestler is Born!',
-        u'720':  (u'62', u'106'),
+        u'360': (u'60', u'106'),
-        video_title = re.sub(r' {5} *â? *', u' â ', video_title)
+        video_title = re.sub(r' {2,}', u' ', video_title)
-__version__ = '2013.12.17.2'
+__version__ = '2013.12.20'
-            HeadRequest also on the redirected URL
+            HEADRequest also on the redirected URL
-                    return HeadRequest(newurl,
+                    return HEADRequest(newurl,
-        response = opener.open(HeadRequest(url))
+        response = opener.open(HEADRequest(url))
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?youtube\.com/embed/.+?)\1', webpage)
+        matches = re.findall(r'''(?x)
-    def url_result(self, url, ie=None, video_id=None):
+    @staticmethod
-    def playlist_result(self, entries, playlist_id=None, playlist_title=None):
+    @staticmethod
-        }
+        },
-    _VALID_URL = r'http://www\.imdb\.com/video/imdb/vi(?P<id>\d+)'
+    _VALID_URL = r'http://(?:www|m)\.imdb\.com/video/imdb/vi(?P<id>\d+)'
-        webpage = self._download_webpage(url,video_id)
+        webpage = self._download_webpage('http://www.imdb.com/video/imdb/vi%s' % video_id, video_id)
-                    (?:(?:(?:www\.)?soundcloud\.com/
+                    (?:(?:(?:www\.|m\.)?soundcloud\.com/
-    _VALID_URL = r'^https?://(?:www\.)?(?P<url>ivi\.ru/watch(?:/(?P<compilationid>[^/]+))?/(?P<videoid>\d+))'
+    _VALID_URL = r'^https?://(?:www\.)?ivi\.ru/watch(?:/(?P<compilationid>[^/]+))?/(?P<videoid>\d+)'
-
+        video_page = self._download_webpage(url, video_id, u'Downloading video page')
-            'video_duration': video_duration,
+            'duration': video_duration,
-    SmotriUserIE
+    SmotriUserIE,
-                return (f.get('height'), f.get('width'), ext_ord)
+                return (f.get('height') if f.get('height') is not None else -1,
-
+        info_dict['formats'] = formats
-        '248': '1080p',
+        '5': {'width': 400, 'height': 240},
-                                              self._video_dimensions.get(itag, '???'),
+                                              '%dx%d' % (width, height) if width is not None and height is not None else (resolution if resolution is not None else '???'),
-            resolution = self._video_dimensions.get(itag, None)
+                'width':       width,
-        if info_dict['extractor'] in [u'youtube', u'Youku']:
+        if info_dict['extractor'] in [u'Youku']:
-        existing_formats = [x for x in format_list if x in url_map]
+        existing_formats = [x for x in self._available_formats if x in url_map]
-                raise ExtractorError(u'requested format not available')
+        video_url_list = [(f, url_map[f]) for f in existing_formats] # All formats
-        results = []
+        formats = []
-                'dislike_count': dislike_count,
+            note = self._special_itags.get(itag, None)
-        return results
+
-            m = re.match(r'^(?:audio|video)/(?P<format_id>.+)$', content_type)
+            m = re.match(r'^(?P<type>audio|video|application(?=/ogg$))/(?P<format_id>.+)$', content_type)
-                assert (url_basename(url) == 'trailer.mp4')
+                        'vcodec': u'none' if m.group('type') == 'audio' else None
-    return m.group(1)
+    path = compat_urlparse.urlparse(url).path
-__version__ = '2013.12.17.1'
+__version__ = '2013.12.17.2'
-                'url': m[1],
+                'format_id': fm[0],
-            for m in
+            for fm in
-)
+    unified_strdate,
-    def _test_redirect(self, url):
+    def _send_head(self, url):
-        return new_url
+        return response
-            if new_url:
+            response = self._send_head(url)
-        video_id = url.split('/')[-1]
+        '%Y-%m-%dT%H:%M:%S',
-    m = re.match(r'(?:https?:|)//[^/]+/(?:[^/?#]+/)?([^/?#]+)/?(?:[?#]|$)', url)
+    m = re.match(r'(?:https?:|)//[^/]+/(?:[^?#]+/)?([^/?#]+)/?(?:[?#]|$)', url)
-                return [self.url_result(new_url)]
+                return self.url_result(new_url)
-__version__ = '2013.12.17'
+__version__ = '2013.12.17.1'
-    unified_strdate,
+    encodeFilename,
-    unsmuggle_url,
+    orderedSet,
-    encodeFilename,
+    smuggle_url,
-__version__ = '2013.12.16.7'
+__version__ = '2013.12.17'
-    def _search_regex(self, pattern, string, name, default=None, fatal=True, flags=0):
+    def _search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0):
-        elif default is not None:
+        elif default is not _NO_DEFAULT:
-    def _html_search_regex(self, pattern, string, name, default=None, fatal=True, flags=0):
+    def _html_search_regex(self, pattern, string, name, default=_NO_DEFAULT, fatal=True, flags=0):
-        video_description = self._html_search_regex(r'<p class="video_description">([^<]+)', webpage, u'description', default=None)
+        video_description = self._html_search_regex(r'<p class="video_description">([^<]+)', webpage, u'description', fatal=False)
-            count = self._search_regex(r'class="%s">([\d,]+)</span>' % re.escape(klass), video_webpage, klass, fatal=False)
+            count = self._search_regex(
-    _VALID_URL = r'^https?://(?:www\.)?academicearth\.org/courses/(?P<id>[^?#/]+)'
+    _VALID_URL = r'^https?://(?:www\.)?academicearth\.org/(?:courses|playlists)/(?P<id>[^?#/]+)'
-        u'md5': u'todo',
+        u'file': u'one-one.ogg',
-            u"uploader": u"ferdi",
+            u"uploader": u"Thomas HercouÃ«t",
-    _VALID_URL = r'(?:http://)?(?P<url>(?P<base_url>rtl-now\.rtl\.de|rtl2now\.rtl2\.de|(?:www\.)?voxnow\.de|(?:www\.)?rtlnitronow\.de|(?:www\.)?superrtlnow\.de|(?:www\.)?n-tvnow\.de)/+[a-zA-Z0-9-]+/[a-zA-Z0-9-]+\.php\?(?:container_id|film_id)=(?P<video_id>[0-9]+)&player=1(?:&season=[0-9]+)?(?:&.*)?)'
+    _VALID_URL = r'(?:http://)?(?P<url>(?P<domain>rtl-now\.rtl\.de|rtl2now\.rtl2\.de|(?:www\.)?voxnow\.de|(?:www\.)?rtlnitronow\.de|(?:www\.)?superrtlnow\.de|(?:www\.)?n-tvnow\.de)/+[a-zA-Z0-9-]+/[a-zA-Z0-9-]+\.php\?(?:container_id|film_id)=(?P<video_id>[0-9]+)&player=1(?:&season=[0-9]+)?(?:&.*)?)'
-        video_page_url = u'http://' + mobj.group('base_url')
+        video_page_url = u'http://' + mobj.group('domain') + u'/'
-        self.assertEqual(result['description'], "Today's websites are increasingly dynamic. Pages are no longer static HTML files but instead generated by scripts and database calls. User interfaces are more seamless, with technologies like Ajax replacing traditional page reloads. This course teaches students how to build dynamic websites with Ajax and with Linux, Apache, MySQL, and PHP (LAMP), one of today's most popular frameworks. Students learn how to set up domain names with DNS, how to structure pages with XHTML and CSS, how to program in JavaScript and PHP, how to configure Apache and MySQL, how to design and query databases with SQL, how to use Ajax with both XML and JSON, and how to build mashups. The course explores issues of security, scalability, and cross-browser support and also discusses enterprise-level deployments of websites, including third-party hosting, virtualization, colocation in data centers, firewalling, and load-balancing.")
+        self.assertEqual(result['description'], u"Today's websites are increasingly dynamic. Pages are no longer static HTML files but instead generated by scripts and database calls. User interfaces are more seamless, with technologies like Ajax replacing traditional page reloads. This course teaches students how to build dynamic websites with Ajax and with Linux, Apache, MySQL, and PHP (LAMP), one of today's most popular frameworks. Students learn how to set up domain names with DNS, how to structure pages with XHTML and CSS, how to program in JavaScript and PHP, how to configure Apache and MySQL, how to design and query databases with SQL, how to use Ajax with both XML and JSON, and how to build mashups. The course explores issues of security, scalability, and cross-browser support and also discusses enterprise-level deployments of websites, including third-party hosting, virtualization, colocation in data centers, firewalling, and load-balancing.")
-__version__ = '2013.12.16.6'
+__version__ = '2013.12.16.7'
-from .appletrailers import AppleTrailersIE
+from .academicearth import AcademicEarthCourseIE
-    _VALID_URL = r'^https?://(?:www\.)?mtv\.com/videos/.+?/(?P<videoid>[0-9]+)/[^/]+$'
+    _VALID_URL = r'''(?x)^https?://
-        uri = self._html_search_regex(r'/uri/(.*?)\?', webpage, u'uri')
+        uri = mobj.group('mgid')
-        if sys.stderr.isatty() and os.name != 'nt':
+        if os.name != 'nt' and sys.stderr.isatty():
-__version__ = '2013.12.16.5'
+__version__ = '2013.12.16.6'
-    _VALID_URL = r'((http://www\.vevo\.com/watch/(?:[^/]+/[^/]+/)?)|(vevo:))(?P<id>.*?)(\?|$)'
+    _VALID_URL = r'''(?x)
-__version__ = '2013.12.16.4'
+__version__ = '2013.12.16.5'
-__version__ = '2013.12.16.3'
+__version__ = '2013.12.16.4'
-                if type(ie).__name__ in ['GenericIE', tc['name'] + 'IE']:
+                if type(ie).__name__ in ('GenericIE', tc['name'] + 'IE'):
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?facebook\.com/(?:video/video|photo)\.php\?(?:.*?)v=(?P<ID>\d+)(?:.*)'
+    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?facebook\.com/(?:[^#?]*#!/)?(?:video/video|photo)\.php\?(?:.*?)v=(?P<ID>\d+)(?:.*)'
-            u"duration": 279, 
+            u"duration": 279,
-                if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(infofn)):
+                if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(thumb_filename)):
-__version__ = '2013.12.16.2'
+__version__ = '2013.12.16.3'
-    buf.value = title
+    buf.value = title.encode('utf-8')
-__version__ = '2013.12.16.1'
+__version__ = '2013.12.16.2'
-    Instead of url and ext, formats can also specified.
+    format:         The video format, defaults to ext (used for --get-format)
-                    * filesize  The number of bytes, if known in advance
+from .blinkx import BlinkxIE
-
+            playlistend = self.params.get('playlistend', None)
-                entries = ie_result['entries'][playliststart:playlistend]
+                playlistend = None
-            self.to_screen(u"[%s] playlist '%s': Collected %d video ids (downloading %d of them)" %
+            self.to_screen(
-            dest='playlistend', metavar='NUMBER', help='playlist video to end at (default is last)', default=-1)
+    selection.add_option(
-        parser.error(u'invalid playlist end number specified')
+    if opts.playliststart <= 0:
-            raise ValueError('Could not find any valid formats')
+            raise ExtractorError(u'Could not find any valid formats')
-__version__ = '2013.12.16'
+__version__ = '2013.12.16.1'
-        u'md5': u'95165945756198b8fa2dea10f0b04614',
+        u'md5': u'ae785f36ecbf2f19b42edf1bc9c85815',
-        u'md5': u'4a5b1fbb5519fb0d929c384b6ff7cb8b',
+        u'url': u'http://www.mdr.de/mediathek/radio/mdr1-radio-sachsen/audio718370_zc-67b21197_zs-1b9b2483.html',
-        return [info]
+        title = self._html_search_regex(r'<h2>(.*?)</h2>', html, u'title')
-        u'md5': u'4fe06e5108e8b524c35896f4c54c7155',
+        u'file': u'1962.flv',
-            'title':     video_title,
+            'id': video_id,
-__version__ = '2013.12.11.2'
+__version__ = '2013.12.16'
-                return
+            descfn = filename + u'.description'
-                return
+            annofn = filename + u'.annotations.xml'
-                            subfile.write(sub)
+                    if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(sub_filename)):
-                return
+            if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(infofn)):
-                        (info_dict['thumbnail'], compat_str(err)))
+                if self.params.get('nooverwrites', False) and os.path.exists(encodeFilename(infofn)):
-        'quiet': (opts.quiet or opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.dumpjson),
+        'quiet': (opts.quiet or any_printing),
-        'skip_download': (opts.skip_download or opts.simulate or opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.dumpjson),
+        'skip_download': (opts.skip_download or opts.simulate or any_printing),
-    url:            Final video URL.
+    url:            Final video URL.
-            video_duration = ''
+            video_duration = None
-            video_duration = compat_urllib_parse.unquote_plus(video_info['length_seconds'][0])
+            video_duration = int(compat_urllib_parse.unquote_plus(video_info['length_seconds'][0]))
-                if n.attrib['title'] == u'Geographic Restriction')
+                if n.attrib.get('title') == u'Geographic Restriction')
-    download_archive:   File name of a file where all downloads are recorded.
+    min_views:         An integer representing the minimum view count the video
-                    return u'[download] "' + title + '" title did not match pattern "' + matchtitle + '"'
+                    return u'"' + title + '" title did not match pattern "' + matchtitle + '"'
-                return u'[download] %s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)
+                return u'%s upload date is not in range %s' % (date_from_str(date).isoformat(), dateRange)
-                    % info_dict.get('title', info_dict.get('id', u'video')))
+            return u'%s has already been recorded in archive' % video_title
-    if '%(ext)s' not in outtmpl and opts.extractaudio:
+    if not os.path.splitext(outtmpl)[1] and opts.extractaudio:
-                     determine_ext(outtmpl, u''))
+                     u' file! Use "{0}.%(ext)s" instead of "{0}" as the output'
-    _VALID_URL = r'(?i)(?:https?://)?(?:www\.)?dailymotion\.[a-z]{2,3}/(?:embed/)?video/([^/]+)'
+    _VALID_URL = r'(?i)(?:https?://)?(?:(www|touch)\.)?dailymotion\.[a-z]{2,3}/(?:(embed|#)/)?video/(?P<id>[^/?_]+)'
-        video_id = mobj.group(1).split('_')[0].split('?')[0]
+        video_id = mobj.group('id')
-                        u'title': u'GTA 5\'s Twisted Beauty in Super Slow Motion',
+                        u'title': u'26 Twisted Moments from GTA 5 in Slow Motion',
-        u'Januar', u'February', u'March', u'April', u'May', u'June',
+        u'January', u'February', u'March', u'April', u'May', u'June',
-    _VALID_URL = r'https?://tvpot\.daum\.net/.*?clipid=(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:m\.)?tvpot\.daum\.net/.*?clipid=(?P<id>\d+)'
-    _VALID_URL = r'https?://tvcast\.naver\.com/v/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:m\.)?tvcast\.naver\.com/v/(?P<id>\d+)'
-                u'description': u'md5:a6d5cfd9ee46d1851cf6e40ea61cfc10',
+                u'description': u'md5:d1e6ecaafa7fb52a2cacdf9599829f5b',
-)
+from ..utils import ExtractorError
-            return self.playlist_result(entries, content_path, title_text)
+        entries = [self.url_result(session_url.text, 'Channel9')
-    packages=['youtube_dl', 'youtube_dl.extractor'],
+    packages=['youtube_dl', 'youtube_dl.extractor', 'youtube_dl.downloader'],
-            return False
+# Legacy file for backwards compatibility, use youtube_dl.downloader instead!
-    def _hook_progress(self, status):
+        real_fd = get_suitable_downloader(info_dict)(self.ydl, self.params)
-        self._progress_hooks.append(ph)
+            real_fd.add_progress_hook(ph)
-from .FileDownloader import FileDownloader
+from .downloader import get_suitable_downloader
-                    fd = FileDownloader(self, self.params)
+                    fd = get_suitable_downloader(info_dict)(self, self.params)
-                    success = fd._do_download(filename, info_dict)
+                    success = fd.download(filename, info_dict)
-        ydl.fd.add_progress_hook(_hook)
+        ydl.add_downloader_progress_hook(_hook)
-        self._progress_hooks = []
+        self._fd_progress_hooks = []
-
+    def add_downloader_progress_hook(self, ph):
-                    success = self.fd._do_download(filename, info_dict)
+                    fd = FileDownloader(self, self.params)
-__version__ = '2013.12.11.1'
+__version__ = '2013.12.11.2'
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>pornhub\.com/view_video\.php\?viewkey=(?P<videoid>[0-9]+))'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>pornhub\.com/view_video\.php\?viewkey=(?P<videoid>[0-9a-f]+))'
-__version__ = '2013.12.11'
+__version__ = '2013.12.11.1'
-                thumb_filename = filename.rpartition('.')[0] + u'.' + thumb_format
+                thumb_filename = os.path.splitext(filename)[0] + u'.' + thumb_format
-__version__ = '2013.12.10'
+__version__ = '2013.12.11'
-        playlist_html = u'<html>' + playlist_cleaned + u'</html>'
+        def fix_html(s):
-import xml.etree.ElementTree
+    fix_xml_all_ampersand,
-        playlist_page = self._download_webpage(
+        pdoc = self._download_xml(
-        pdoc = xml.etree.ElementTree.fromstring(playlist_page.encode('utf-8'))
+            video_id, u'Downloading video info',
-import xml.etree.ElementTree
+from ..utils import (
-        info = xml.etree.ElementTree.fromstring(info_xml.encode('utf-8'))
+        info = self._download_xml('http://www.metacritic.com/video_data?video=' + video_id,
-    def _real_extract(self, url, new_video=True):
+    def _real_extract(self, url):
-                    webpage, u'info section', flags=re.DOTALL)
+                # We try to find out to which variable is assigned the config dic
-            r'video_views_value[^>]+>([\d\.,]+)<', webpage, u'view count'))
+        view_count = self._search_regex(
-            'uploader': video_uploader,
+            'uploader': info['owner_screenname'],
-        final_song_url = self.check_urls(template_url % i for i in range(30))
+        final_song_url = self._get_url(template_url)
-            'ext': 'mp3',
+        # downloadable song
-                'ext': ext,
+                'ext': info.get('original_format', u'mp3'),
-                      note=u'Downloading XML', errnote=u'Unable to download XML'):
+                      note=u'Downloading XML', errnote=u'Unable to download XML',
-                                         u'Downloading info')
+
-__version__ = '2013.12.09.4'
+__version__ = '2013.12.10'
-                proto_pref = 999
+                proto_pref = -999
-                quality_pref = 999
+                quality_pref = -999
-        ext = info.get('original_format', u'mp3')
+        ext = u'mp3'
-                u'NA' if v is None else compat_str(v),
+                compat_str(v),
-                                 for k, v in template_dict.items())
+                                 for k, v in template_dict.items()
-__version__ = '2013.12.09.3'
+__version__ = '2013.12.09.4'
-                u'uploader': u'National Ballet of Canada',                
+                u'uploader': u'National Ballet of Canada',
-            return self._get_video_info(videoPlayer[0], query_str, query)
+            return self._get_video_info(videoPlayer[0], query_str, query,
-    def _get_video_info(self, video_id, query_str, query):
+    def _get_video_info(self, video_id, query_str, query, referer=None):
-            req.add_header('Referer', linkBase[0])
+            referer = linkBase[0]
-                            (?P<uploader>[\w\d-]+)/(?P<title>[\w\d-]+)/?
+                            (?P<uploader>[\w\d-]+)/
-__version__ = '2013.12.09.2'
+__version__ = '2013.12.09.3'
-    _VALID_URL = r'(?:http://)?(?P<url>(?P<base_url>rtl-now\.rtl\.de/|rtl2now\.rtl2\.de/|(?:www\.)?voxnow\.de/|(?:www\.)?rtlnitronow\.de/|(?:www\.)?superrtlnow\.de/|(?:www\.)?n-tvnow\.de/)[a-zA-Z0-9-]+/[a-zA-Z0-9-]+\.php\?(?:container_id|film_id)=(?P<video_id>[0-9]+)&player=1(?:&season=[0-9]+)?(?:&.*)?)'
+    _VALID_URL = r'(?:http://)?(?P<url>(?P<base_url>rtl-now\.rtl\.de|rtl2now\.rtl2\.de|(?:www\.)?voxnow\.de|(?:www\.)?rtlnitronow\.de|(?:www\.)?superrtlnow\.de|(?:www\.)?n-tvnow\.de)/+[a-zA-Z0-9-]+/[a-zA-Z0-9-]+\.php\?(?:container_id|film_id)=(?P<video_id>[0-9]+)&player=1(?:&season=[0-9]+)?(?:&.*)?)'
-            u'upload_date': u'20070416', 
+            u'upload_date': u'20070416',
-__version__ = '2013.12.09.1'
+__version__ = '2013.12.09.2'
-                        raise
+            try:
-import subprocess
+    get_term_width,
-    columns = _find_term_columns()
+    columns = get_term_width()
-                    (?:(?:(?:www\.)?soundcloud\.com/([\w\d-]+)/([\w\d-]+)/?(?:[?].*)?$)
+                    (?:(?:(?:www\.)?soundcloud\.com/
-    def _extract_info_dict(self, info, full_title=None, quiet=False):
+    def _extract_info_dict(self, info, full_title=None, quiet=False, secret_token=None):
-                'http://api.soundcloud.com/i1/tracks/{0}/streams?client_id={1}'.format(track_id, self._IPHONE_CLIENT_ID),
+                streams_url,
-            uploader = mobj.group(1)
+            uploader = mobj.group('uploader')
-            full_title = '%s/%s' % (uploader, slug_title)
+            slug_title =  mobj.group('title')
-            url = 'http://soundcloud.com/%s/%s' % (uploader, slug_title)
+            url = 'http://soundcloud.com/%s' % resolve_title
-        return self._extract_info_dict(info, full_title)
+        return self._extract_info_dict(info, full_title, secret_token=token)
-            # TODO: Check for errors
+        with io.open(info_filename, 'r', encoding='utf-8') as f:
-        final_url = self._search_regex('","(.*?)"', googleString,'final video url')
+        final_url = self._search_regex('","(.*?)"', googleString, u'final video url')
-        self.assertTrue(len(entries) >= 9)
+        self.assertTrue(len(entries) >= 5)
-__version__ = '2013.12.09'
+__version__ = '2013.12.09.1'
-        elif not self.params.get('quiet', False):
+        elif not check_quiet or not self.params.get('quiet', False):
-            sys.stderr.write(output)
+            write_string(output, self._err_file)
-        if sys.stderr.isatty() and os.name != 'nt':
+        if self._err_file.isatty() and os.name != 'nt':
-        if sys.stderr.isatty() and os.name != 'nt':
+        if self._err_file.isatty() and os.name != 'nt':
-            compat_print(info_dict['fulltitle'])
+            self.to_stdout(info_dict['fulltitle'])
-            compat_print(info_dict['id'])
+            self.to_stdout(info_dict['id'])
-            compat_print(info_dict['url'] + info_dict.get('play_path', u''))
+            self.to_stdout(info_dict['url'] + info_dict.get('play_path', u''))
-            compat_print(info_dict['thumbnail'])
+            self.to_stdout(info_dict['thumbnail'])
-            compat_print(info_dict['description'])
+            self.to_stdout(info_dict['description'])
-            compat_print(filename)
+            self.to_stdout(filename)
-            compat_print(info_dict['format'])
+            self.to_stdout(info_dict['format'])
-            compat_print(json.dumps(info_dict))
+            self.to_stdout(json.dumps(info_dict))
-__version__ = '2013.12.08.1'
+__version__ = '2013.12.09'
-                if self._tunnel_host:
+                if getattr(self, '_tunnel_host', False):
-    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None):
+    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):
-            self.to_screen(u'%s: %s' % (video_id, note))
+            if video_id is None:
-            raise ExtractorError(u'%s: %s' % (errnote, compat_str(err)), sys.exc_info()[2], cause=err)
+            errmsg = u'%s: %s' % (errnote, compat_str(err))
-    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None):
+    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True):
-        urlh = self._request_webpage(url_or_request, video_id, note, errnote)
+        urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal)
-    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None):
+    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True):
-        return self._download_webpage_handle(url_or_request, video_id, note, errnote)[0]
+        res = self._download_webpage_handle(url_or_request, video_id, note, errnote, fatal)
-        return True
+        return bool(self._download_webpage(
-            u'Unable to fetch login page')
+        login_page = self._download_webpage(
-            self._downloader.report_warning(u'unable to log in: %s' % compat_str(err.cause))
+
-        self._download_webpage(request, None, False, u'Unable to confirm age')
+            'next_url': '/',
-            if not 'items' in api_response:
+            data_json = self._download_webpage(
-            response = compat_urllib_request.urlopen(request)
+            response = self._request_webpage(url, None, False)
-            raise ExtractorError(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
+        urlh = self._request_webpage(request, None, False,
-            raise ExtractorError(u'Unable to retrieve disclaimer: %s' % compat_str(err))
+        self.report_disclaimer()
-            raise ExtractorError(u'Unable to confirm age: %s' % compat_str(err))
+        self.report_age_confirmation()
-    compat_urllib_request,
+    ExtractorError,
-                compat_urllib_request.urlopen(url)
+                # We only want to know if the request succeed
-            except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error):
+            except ExtractorError:
-            mdoc = xml.etree.ElementTree.fromstring(metaXml)
+            mdoc = self._download_xml(xmlUrl, info['id'])
-                raise ExtractorError(u'Unable to download course info page: ' + compat_str(err))
+            rootpage = self._download_webpage(rootURL, info['id'],
-            self._downloader.report_warning(u'unable to set language: %s' % compat_str(err))
+            self._download_webpage(self._LANG_URL, None, False)
-            return False
+        login_page = self._download_webpage(self._LOGIN_URL, None, False,
-            login_results = compat_urllib_request.urlopen(request).read().decode('utf-8')
+            login_results = self._download_webpage(request, None, False)
-            self._downloader.report_warning(u'unable to log in: %s' % compat_str(err))
+        except ExtractorError as err:
-            raise ExtractorError(u'Unable to confirm age: %s' % compat_str(err))
+        self.report_age_confirmation()
-                raise ExtractorError(u'Unable to download API page: %s' % compat_str(err))
+            data = self._download_webpage(result_url, u'query "%s"' % query,
-        u'file': u'Mit offenen Karten-049881-009_PLUS7-D.flv',
+        u'file': u'049881-009_PLUS7-D.flv',
-            u'title': u'neues-aus-mauretanien',
+            u'title': u'Mit offenen Karten',
-__version__ = '2013.12.08'
+__version__ = '2013.12.08.1'
-            autogenerated = False
+        autogenerated = re.search(r'''(?x)
-            u"title": u"Watch Till End: Herd of deer jump over a fence."
+            u"title": u"Watch Till End: Herd of deer jump over a fence.",
-        thumbnail_url = self._search_regex(r'<meta property="og\:image" content="(.+?)" />', webpage,'video thumbnail')
+        title = self._html_search_meta('description', webpage, u'video title')
-        }]
+        return {
-__version__ = '2013.12.04'
+__version__ = '2013.12.08'
-        
+        context.set_default_verify_paths()
-        clear_line = (u'\x1b[K' if sys.stderr.isatty() and os.name != 'nt' else u'')
+        fullmsg = u'[download] ' + msg
-            self.to_screen(u'[download] ' + msg)
+            self.to_screen(fullmsg)
-                           skip_eol=not is_last_line)
+            if os.name == 'nt':
-                (percent_str, data_len_str, speed_str, eta_str))
+
-                (percent_str.strip(), data_len_str.strip(), speed_str.strip(), eta_str.strip()))
+            self._report_progress_status(
-        u'md5': u'970a94178ca4118c5aa3aaea21211b81',
+        u'md5': u'e767b9475de189320f691f49c679c4c7',
-            return webpage.find('<div class=\'icon iconHD\'>') != -1
+            return webpage.find('<div class=\'icon iconHD\'') != -1
-    _TEST = {
+    _VALID_URL = r'(?:http://)?(?:www\.)?pyvideo\.org/video/(?P<id>\d+)/(.*)'
-    }
+    },
-        video_id = mobj.group(2)
+        video_id = mobj.group('id')
-        u'md5': u'bf08cae24e1601027f98ae1262c299ad',
+        u'file': u'24_4WWkSmNo.mp4',
-        }
+            u"title": u"Become a logging expert in 30 minutes",
-    _VALID_URL = r'(?:http://)?(?:www\.)?break\.com/video/([^/]+)'
+from .pyvideo import PyvideoIE
-    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|(?P<player>player))\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?(?:#.*)?$'
+    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|(?P<player>player))\.)?vimeo(?P<pro>pro)?\.com/(?:.*?/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?(?:#.*)?$'
-                'title': list_title,
+                'title': self._extract_list_title(webpage),
-        if VimeoChannelIE.suitable(url) or VimeoIE.suitable(url) or VimeoAlbumIE.suitable(url):
+        if VimeoChannelIE.suitable(url) or VimeoIE.suitable(url) or VimeoAlbumIE.suitable(url) or VimeoGroupsIE.suitable(url):
-    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|(?P<player>player))\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?(?:#.*)?$'
+    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|(?P<player>player))\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?(?:#.*)?$'
-                '%s/videos/page:%d/' % (base_url, pagenum),list_id,
+                self._page_url(base_url, pagenum) ,list_id,
-        if VimeoChannelIE.suitable(url) or VimeoIE.suitable(url):
+        if VimeoChannelIE.suitable(url) or VimeoIE.suitable(url) or VimeoAlbumIE.suitable(url):
-            u'duration': 151,
+            f_path = f_path.strip()
-            u"duration": 230,
+            u"duration": 230.12,
-                        ((?:PL|EC|UU|FL)?[0-9A-Za-z-_]{10,})
+                        ((?:PL|EC|UU|FL|RD)?[0-9A-Za-z-_]{10,})
-                        ((?:PL|EC|UU|FL)[0-9A-Za-z-_]{10,})
+                        ((?:PL|EC|UU|FL|RD)[0-9A-Za-z-_]{10,})
-        url = 'https://youtube.com/watch?v=%s&list=%s' % (playlist_id[2:], playlist_id)
+        url = 'https://youtube.com/watch?v=%s&list=%s' % (playlist_id[-11:], playlist_id)
-        if len(playlist_id) == 13:  # 'RD' + 11 characters for the video id
+        if playlist_id.startswith('RD'):
-            r'video_views_value[^>]+>([\d\.]+)<', webpage, u'view count'))
+            r'video_views_value[^>]+>([\d\.,]+)<', webpage, u'view count'))
-        video_webpage = video_webpage_bytes.decode('utf-8', 'ignore')
+        video_webpage = self._download_webpage(url, video_id)
-                          'subtitles', 'annotations', 'format'):
+                          'subtitles', 'annotations', 'format',
-            webpage, u'video title', default=u'video', flags=re.DOTALL)
+        video_title = self._html_search_regex(
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?youtube.com/embed/.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?youtube\.com/embed/.+?)\1', webpage)
-            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?dailymotion.com/embed/video/.+?)\1', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>(?:https?:)?//(?:www\.)?dailymotion\.com/embed/video/.+?)\1', webpage)
-            'upload_date':  None,
+import json
-        |   (emission|jt)/(?P<key>[^/?]+)
+        |   (emissions?|jt)/(?P<key>[^/?]+)
-            u'url': u'http://www.france3.fr/emissions/pieces-a-conviction/videos/rhozet_pac_ba_20131204_1933_03122013164521_F3',
+            u'url': u'http://www.france3.fr/emissions/pieces-a-conviction/diffusions/13-11-2013_145575',
-                u'id': u'rhozet_pac_ba_20131204_1933_03122013164521_F3',
+                u'id': u'000702326_CAPP_PicesconvictionExtrait313022013_120220131722_Au',
-                u'description': u'md5:1cf14ea302ba5f10d992c9eb2bff30dd',
+                u'title': u'Le scandale du prix des mÃ©dicaments',
-    France2IE,
+    FranceTVIE,
-                'ext': 'mp4',
+                'ext': 'flv' if video_url.startswith('rtmp') else 'mp4',
-    _VALID_URL = r'''(?x)https?://www\.france2\.fr/
+class FranceTVIE(FranceTVBaseInfoExtractor):
-        |   emission/(?P<key>[^/?]+)
+            emissions/.*?/(videos|emissions)/(?P<id>[^/?]+)
-            u'description': u'md5:2e5b58ba7a2d3692b35c792be081a03d',
+    _TESTS = [
-            u'skip_download': True,
+        # france3
-    }
+        # france4
-                r'''(?x)<div\s+class="video-player">\s*
+            id_res = [
-                webpage, u'video ID')
+                    class="francetv-video-player">'''),
-        return self._get_info(info['id'], video_id)
+        return self._get_info(long_id, video_id)
-    def extract_info(self, url, download=True, ie_key=None, extra_info={}):
+    def extract_info(self, url, download=True, ie_key=None, extra_info={},
-                return self.process_ie_result(ie_result, download, extra_info)
+                if process:
-
+from .ninegag import NineGagIE
-    _VALID_URL = r'((http://www\.vevo\.com/watch/.*?/.*?/)|(vevo:))(?P<id>.*?)(\?|$)'
+    _VALID_URL = r'((http://www\.vevo\.com/watch/(?:[^/]+/[^/]+/)?)|(vevo:))(?P<id>.*?)(\?|$)'
-            return [self.url_result('http://www.youtube.com/watch?v=%s' % mobj2.group(1), 'Youtube')]
+        # the video may come from an external site
-    _VALID_URL = r'https?://link\.theplatform\.com/s/[^/]+/(?P<id>[^/\?]+)'
+    _VALID_URL = r'(?:https?://link\.theplatform\.com/s/[^/]+/|theplatform:)(?P<id>[^/\?]+)'
-            u"title": u"Freddie Gibbs - Lay It Down"
+            u"title": u'Freddie Gibbs "Lay It Down"'
-    _VALID_URL = r'^http://(?:\w+\.)?add-anime\.net/watch_video.php\?(?:.*?)v=(?P<video_id>[\w_]+)(?:.*)'
+    _VALID_URL = r'^http://(?:\w+\.)?add-anime\.net/watch_video\.php\?(?:.*?)v=(?P<video_id>[\w_]+)(?:.*)'
-    _VALID_URL = r'https?://(?:www\.)?trailers.apple.com/trailers/(?P<company>[^/]+)/(?P<movie>[^/]+)'
+    _VALID_URL = r'https?://(?:www\.)?trailers\.apple\.com/trailers/(?P<company>[^/]+)/(?P<movie>[^/]+)'
-    _VALID_URL = r'(?:https?://)?(?:www\.)?archive.org/details/(?P<id>[^?/]+)(?:[?].*)?$'
+    _VALID_URL = r'(?:https?://)?(?:www\.)?archive\.org/details/(?P<id>[^?/]+)(?:[?].*)?$'
-    _LIVEWEB_URL = r'(?:http://)?liveweb.arte.tv/(?P<lang>fr|de)/(?P<subpage>.+?)/(?P<name>.+)'
+    _VIDEOS_URL = r'(?:http://)?videos\.arte\.tv/(?P<lang>fr|de)/.*-(?P<id>.*?)\.html'
-    _VALID_URL = r'(?:http://)?(?:www\.)?auengine\.com/embed.php\?.*?file=([^&]+).*?'
+    _VALID_URL = r'(?:http://)?(?:www\.)?auengine\.com/embed\.php\?.*?file=([^&]+).*?'
-    _VALID_URL = r'http://bambuser.com/channel/(?P<user>.*?)(?:/|#|\?|$)'
+    _VALID_URL = r'https?://bambuser\.com/channel/(?P<user>.*?)(?:/|#|\?|$)'
-    _VALID_URL = r'https?://www\.bloomberg\.com/video/(?P<name>.+?).html'
+    _VALID_URL = r'https?://www\.bloomberg\.com/video/(?P<name>.+?)\.html'
-    _VALID_URL = r'http://www.comedycentral.com/(video-clips|episodes|cc-studios)/(?P<title>.*)'
+    _VALID_URL = r'https?://(?:www\.)?comedycentral\.com/(video-clips|episodes|cc-studios)/(?P<title>.*)'
-    _VALID_URL = r'http://www.c-spanvideo.org/program/(.*)'
+    _VALID_URL = r'http://www\.c-spanvideo\.org/program/(.*)'
-    _VALID_URL = r'(?:http://)?(?:www\.)?3sat.de/mediathek/index.php\?(?:(?:mode|display)=[^&]+&)*obj=(?P<id>[0-9]+)$'
+    _VALID_URL = r'(?:http://)?(?:www\.)?3sat\.de/mediathek/index\.php\?(?:(?:mode|display)=[^&]+&)*obj=(?P<id>[0-9]+)$'
-    _VALID_URL = r'https?://8tracks.com/(?P<user>[^/]+)/(?P<id>[^/#]+)(?:#.*)?$'
+    _VALID_URL = r'https?://8tracks\.com/(?P<user>[^/]+)/(?P<id>[^/#]+)(?:#.*)?$'
-    _SOUNDCLOUD_URL = r'(?:http://)?(?:www\.)?api\.soundcloud.com/tracks/([^/]+)/stream'
+    _SOUNDCLOUD_URL = r'(?:http://)?(?:www\.)?api\.soundcloud\.com/tracks/([^/]+)/stream'
-    _VALID_URL = r'https?://www\.faz\.net/multimedia/videos/.*?-(?P<id>\d+).html'
+    _VALID_URL = r'https?://www\.faz\.net/multimedia/videos/.*?-(?P<id>\d+)\.html'
-    _VALID_URL = r'(?:http://)?(?:www\.)?fernsehkritik.tv/folge-(?P<ep>[0-9]+)(?:/.*)?'
+    _VALID_URL = r'(?:http://)?(?:www\.)?fernsehkritik\.tv/folge-(?P<ep>[0-9]+)(?:/.*)?'
-    _VALID_URL = r'(?:http://)?(?:www\.)?fernsehkritik.tv/inline-video/postecke.php\?(.*&)?ep=(?P<ep>[0-9]+)(&|$)'
+    _VALID_URL = r'(?:http://)?(?:www\.)?fernsehkritik\.tv/inline-video/postecke\.php\?(.*&)?ep=(?P<ep>[0-9]+)(&|$)'
-    _VALID_URL = r'https?://www\.francetvinfo\.fr/replay.*/(?P<title>.+).html'
+    _VALID_URL = r'https?://www\.francetvinfo\.fr/replay.*/(?P<title>.+)\.html'
-    _VALID_URL = r'http?://www\.gamekings\.tv/videos/(?P<name>[0-9a-z\-]+)'
+    _VALID_URL = r'http://www\.gamekings\.tv/videos/(?P<name>[0-9a-z\-]+)'
-    _VALID_URL = r'http://www.gametrailers.com/(?P<type>videos|reviews|full-episodes)/(?P<id>.*?)/(?P<title>.*)'
+    _VALID_URL = r'http://www\.gametrailers\.com/(?P<type>videos|reviews|full-episodes)/(?P<id>.*?)/(?P<title>.*)'
-    _VALID_URL = r'https?://gamevideos.1up.com/(?P<type>video)/id/(?P<name_or_id>.+)'
+    _VALID_URL = r'https?://gamevideos\.1up\.com/(?P<type>video)/id/(?P<name_or_id>.+)'
-    _VALID_URL = r'(?:http://)?instagram.com/p/(.*?)/'
+    _VALID_URL = r'(?:http://)?instagram\.com/p/(.*?)/'
-    _VALID_URL = r'^http://www\.jukebox?\..+?\/.+[,](?P<video_id>[a-z0-9\-]+).html'
+    _VALID_URL = r'^http://www\.jukebox?\..+?\/.+[,](?P<video_id>[a-z0-9\-]+)\.html'
-    _VALID_URL = r'^(?:http?://)?(?:\w+\.)?liveleak\.com/view\?(?:.*?)i=(?P<video_id>[\w_]+)(?:.*)'
+    _VALID_URL = r'^(?:http://)?(?:\w+\.)?liveleak\.com/view\?(?:.*?)i=(?P<video_id>[\w_]+)(?:.*)'
-    _VALID_URL = r'http://new.livestream.com/.*?/(?P<event_name>.*?)(/videos/(?P<id>\d+))?/?$'
+    _VALID_URL = r'http://new\.livestream\.com/.*?/(?P<event_name>.*?)(/videos/(?P<id>\d+))?/?$'
-    _VALID_URL = r'https?://www.muzu.tv/(.+?)/(.+?)/(?P<id>\d+)'
+    _VALID_URL = r'https?://www\.muzu\.tv/(.+?)/(.+?)/(?P<id>\d+)'
-    _VALID_URL = r'http://www.myspass.de/.*'
+    _VALID_URL = r'http://www\.myspass\.de/.*'
-    _VALID_URL = r'https?://tvthek.orf.at/(programs/.+?/episodes|topics/.+?)/(?P<id>\d+)'
+    _VALID_URL = r'https?://tvthek\.orf\.at/(programs/.+?/episodes|topics/.+?)/(?P<id>\d+)'
-    _VALID_URL = r'https?://video.pbs.org/video/(?P<id>\d+)/?'
+    _VALID_URL = r'https?://video\.pbs\.org/video/(?P<id>\d+)/?'
-    _VALID_URL = r'https?://rutube.ru/video/(?P<long_id>\w+)'
+    _VALID_URL = r'https?://rutube\.ru/video/(?P<long_id>\w+)'
-    _VALID_URL = r'https?://tv.slashdot.org/video/\?embed=(?P<id>.*?)(&|$)'
+    _VALID_URL = r'https?://tv\.slashdot\.org/video/\?embed=(?P<id>.*?)(&|$)'
-                       |(?P<widget>w.soundcloud.com/player/?.*?url=.*)
+                       |(?P<widget>w\.soundcloud\.com/player/?.*?url=.*)
-    _VALID_URL = r'https?://(www\.)?soundcloud.com/(?P<user>[^/]+)(/?(tracks/)?)?(\?.*)?$'
+    _VALID_URL = r'https?://(www\.)?soundcloud\.com/(?P<user>[^/]+)(/?(tracks/)?)?(\?.*)?$'
-    _VALID_URL = r'https?://www\.space\.com/\d+-(?P<title>[^/\.\?]*?)-video.html'
+    _VALID_URL = r'https?://www\.space\.com/\d+-(?P<title>[^/\.\?]*?)-video\.html'
-    _VALID_URL = r'^(?:https?://)?openclassroom.stanford.edu(?P<path>/?|(/MainFolder/(?:HomePage|CoursePage|VideoPage)\.php([?]course=(?P<course>[^&]+)(&video=(?P<video>[^&]+))?(&.*)?)?))$'
+    _VALID_URL = r'^(?:https?://)?openclassroom\.stanford\.edu(?P<path>/?|(/MainFolder/(?:HomePage|CoursePage|VideoPage)\.php([?]course=(?P<course>[^&]+)(&video=(?P<video>[^&]+))?(&.*)?)?))$'
-    _VALID_URL = r'http://videos.tf1.fr/.*-(.*?).html'
+    _VALID_URL = r'http://videos\.tf1\.fr/.*-(.*?)\.html'
-    _VALID_URL = r'http://utv.unistra.fr/(?:index|video).php\?id_video\=(\d+)'
+    _VALID_URL = r'http://utv\.unistra\.fr/(?:index|video)\.php\?id_video\=(\d+)'
-    _VALID_URL = r'https?://veehd.com/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://veehd\.com/video/(?P<id>\d+)'
-    _VALID_URL = r'((http://www.vevo.com/watch/.*?/.*?/)|(vevo:))(?P<id>.*?)(\?|$)'
+    _VALID_URL = r'((http://www\.vevo\.com/watch/.*?/.*?/)|(vevo:))(?P<id>.*?)(\?|$)'
-    _VALID_URL = r'http://www.vice.com/.*?/(?P<name>.+)'
+    _VALID_URL = r'http://www\.vice\.com/.*?/(?P<name>.+)'
-    _VALID_URL = r'(?P<domain>https?://(?:www\.)?viddler.com)/(?:v|embed|player)/(?P<id>[a-z0-9]+)'
+    _VALID_URL = r'(?P<domain>https?://(?:www\.)?viddler\.com)/(?:v|embed|player)/(?P<id>[a-z0-9]+)'
-    _VALID_URL = r'https?://(www.videofy.me/.+?|p.videofy.me/v)/(?P<id>\d+)(&|#|$)'
+    _VALID_URL = r'https?://(www\.videofy\.me/.+?|p\.videofy\.me/v)/(?P<id>\d+)(&|#|$)'
-    _VALID_URL=r'http://www.wat.tv/.*-(?P<shortID>.*?)_.*?.html'
+    _VALID_URL=r'http://www\.wat\.tv/.*-(?P<shortID>.*?)_.*?\.html'
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?youjizz\.com/videos/(?P<videoid>[^.]+).html$'
+    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?youjizz\.com/videos/(?P<videoid>[^.]+)\.html$'
-__version__ = '2013.12.03'
+__version__ = '2013.12.04'
-                u"description": u"test chars:  \"'/\\Ã¤â­ð\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de ."
+                u"description": u"test chars:  \"'/\\Ã¤â­ð\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de ."
-            u'window.broadcast_control.addFlashVar\\(\'file\', \'([^\']+)\'\\);',
+            u'window\.broadcast_control\.addFlashVar\\(\'file\', \'([^\']+)\'\\);',
-    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url, live):
+    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url, live, conn):
-                    self.to_screen(u'[rtmpdump] '+line)
+                else:
-                                                info_dict.get('rtmp_live', False))
+                                                info_dict.get('rtmp_live', False),
-    determine_ext,
+    compat_urllib_parse,
-        self.process_ie_result(info, download=True)
+        try:
-        if len(all_urls) < 1:
+        if (len(all_urls) < 1) and (opts.load_info_filename is None):
-            retcode = ydl.download(all_urls)
+            if opts.load_info_filename is not None:
-from .mtv import MTVIE, _media_xml_tag
+from .mtv import MTVServicesInfoExtractor
-class ComedyCentralIE(MTVIE):
+class ComedyCentralIE(MTVServicesInfoExtractor):
-from .mtv import MTVIE, _media_xml_tag
+from .mtv import MTVServicesInfoExtractor
-    """
+
-    ]
+class MTVServicesInfoExtractor(InfoExtractor):
-        return 'http://mtv.mtvnimages.com/uri/' + uri
+        search_path = '%s/%s' % (_media_xml_tag('group'), _media_xml_tag('thumbnail'))
-from .mtv import MTVIE, _media_xml_tag
+from .mtv import MTVServicesInfoExtractor
-class SouthParkStudiosIE(MTVIE):
+class SouthParkStudiosIE(MTVServicesInfoExtractor):
-            info = {
+            playlist.append({
-            playlist.append(info)
+            })
-        info = {
+        return {
-            info = {
+            results.append({
-            results.append(info)
+            })
-        info = {
+        return {
-        info = {
+        return {
-        info = {
+        return {
-        info = {
+        return {
-        info = {
+        return {
-        info = {
+        return {
-        info = {
+        return {
-        info = {
+        return {
-        info = {
+        return {
-        full_id = self._search_regex(r'<link rel="video_src" href=".+?vid=(.+?)"',
+        full_id = self._search_regex(
-            r'<h1 class="videoTitle slidePanelMovable">(.+?)</h1>',
+            r'<h1 class="videoTitle[^"]*">(.+?)</h1>',
-        u'md5': u'e767b9475de189320f691f49c679c4c7',
+        u'md5': u'970a94178ca4118c5aa3aaea21211b81',
-    general.add_option('--proxy', dest='proxy', default=None, help='Use the specified HTTP/HTTPS proxy', metavar='URL')
+    general.add_option(
-__version__ = '2013.12.02'
+__version__ = '2013.12.03'
-            res = [shlex.split(l, comments=True) for l in optionf]
+            res = []
-    def _readOptions(filename_bytes, def=[]):
+    def _readOptions(filename_bytes, default=[]):
-            return def  # silently skip if file is not present
+            return default  # silently skip if file is not present
-                    def=None)
+                    default=None)
-            userConfFile = _readOptions(
+            userConf = _readOptions(
-                def=None)
+                default=None)
-    def _readOptions(filename_bytes):
+    def _readOptions(filename_bytes, def=[]):
-            return [] # silently skip if file is not present
+            return def  # silently skip if file is not present
-                res += shlex.split(l, comments=True)
+            res = [shlex.split(l, comments=True) for l in optionf]
-        userConf = _readOptions(userConfFile)
+        userConf = _readOptions(userConfFile, None)
-                         help='Download only videos not present in the archive file. Record the IDs of all downloaded videos in it.')
+                         help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')
-            r'''(?ix)<meta(?=[^>]+(?:name|property)=["\']%s["\'])
+            r'''(?ix)<meta
-    
+    _VALID_URL = r'^https?://(?:www\.)?(?P<url>smotri\.com/video/view/\?id=(?P<videoid>v(?P<realvideoid>[0-9]+)[a-z0-9]{4}))'
-            u'md5': u'46a72e83a6ad8862b64fa6953fa93f8a',
+            u'md5': u'2a7b08249e6f5636557579c368040eb9',
-                u'thumbnail': u'http://frame6.loadup.ru/8b/a9/2610366.3.3.jpg'
+                u'description': u'ÐºÐ°ÑÐ°ÑÑÑÐ¾ÑÐ° Ñ ÐºÐ°Ð¼ÐµÑ Ð²Ð¸Ð´ÐµÐ¾Ð½Ð°Ð±Ð»ÑÐ´ÐµÐ½Ð¸Ñ, Ð²Ð¸Ð´ÐµÐ¾ ÐºÐ°ÑÐ°ÑÑÑÐ¾ÑÐ° Ñ ÐºÐ°Ð¼ÐµÑ Ð²Ð¸Ð´ÐµÐ¾Ð½Ð°Ð±Ð»ÑÐ´ÐµÐ½Ð¸Ñ',
-            u'md5': u'9eae59f6dda7087bf39a140e2fff5757',
+            u'md5': u'830266dfc21f077eac5afd1883091bcd',
-            },            
+                u'description': u'test, Ð²Ð¸Ð´ÐµÐ¾ test',
-            u'md5': u'fe4dd9357558d5ee3c8fc0ef0d39de66',
+            u'md5': u'f6331cef33cad65a0815ee482a54440b',
-                u'thumbnail': u'http://frame7.loadup.ru/af/3f/1390466.3.3.jpg'
+                u'thumbnail': u'http://frame7.loadup.ru/af/3f/1390466.3.3.jpg',
-            u'md5': u'c66a5d61379ac6fde06f07eebe436316',
+            u'md5': u'91e909c9f0521adf5ee86fbe073aad70',
-            },     
+                u'age_limit': 18,
-    
+
-        
+        return self._html_search_meta(name, html, display_name)
-        elif status == self._PASSWORD_DETECTED: # The video is protected by a password, retry with
+        elif status == self._PASSWORD_DETECTED:  # The video is protected by a password, retry with
-            video_json_url += '&md5pass=%s' % hashlib.md5(video_password).hexdigest()
+            video_json_url += '&md5pass=%s' % hashlib.md5(video_password.encode('utf-8')).hexdigest()
-                ur'<a href="/video/view/\?id=%s&confirm=([^"]+)" title="[^"]+">' % video_id,
+                r'<a href="/video/view/\?id=%s&confirm=([^"]+)" title="[^"]+">' % video_id,
-        
+
-        upload_date_str = self._search_meta(u'uploadDate', video_page, u'upload date')        
+
-            ur'<div class="DescrUser"><div>ÐÐ²ÑÐ¾Ñ.*?onmouseover="popup_user_info[^"]+">(.*?)</a>',
+            u'<div class="DescrUser"><div>ÐÐ²ÑÐ¾Ñ.*?onmouseover="popup_user_info[^"]+">(.*?)</a>',
-            ur'<div class="DescrUser"><div>ÐÐ²ÑÐ¾Ñ.*?onmouseover="popup_user_info\(.*?\'([^\']+)\'\);">',
+            u'<div class="DescrUser"><div>ÐÐ²ÑÐ¾Ñ.*?onmouseover="popup_user_info\\(.*?\'([^\']+)\'\\);">',
-            ur'ÐÐ±ÑÐµÐµ ÐºÐ¾Ð»Ð¸ÑÐµÑÑÐ²Ð¾ Ð¿ÑÐ¾ÑÐ¼Ð¾ÑÑÐ¾Ð².*?<span class="Number">(\d+)</span>',
+            u'ÐÐ±ÑÐµÐµ ÐºÐ¾Ð»Ð¸ÑÐµÑÑÐ²Ð¾ Ð¿ÑÐ¾ÑÐ¼Ð¾ÑÑÐ¾Ð².*?<span class="Number">(\\d+)</span>',
-            'ext': video_ext,
+
-    _VALID_URL = r'^(?:http://)?(?:www\.)?smotri\.com/community/video/(?P<communityid>[0-9A-Za-z_\'-]+)'
+    _VALID_URL = r'^https?://(?:www\.)?smotri\.com/community/video/(?P<communityid>[0-9A-Za-z_\'-]+)'
-        
+
-    
+
-      
+
-            ur'^ÐÐ¸Ð´ÐµÐ¾ ÑÐ¾Ð¾Ð±ÑÐµÑÑÐ²Ð° "([^"]+)"$', rss.find('./channel/description').text, u'community title')
+            u'^ÐÐ¸Ð´ÐµÐ¾ ÑÐ¾Ð¾Ð±ÑÐµÑÑÐ²Ð° "([^"]+)"$', description_text, u'community title')
-     
+
-    
+    _VALID_URL = r'^https?://(?:www\.)?smotri\.com/user/(?P<userid>[0-9A-Za-z_\'-]+)'
-        mobj = re.match(self._VALID_URL, url);
+        mobj = re.match(self._VALID_URL, url)
-        
+
-        
+
-        
+
-            ur'^ÐÐ¸Ð´ÐµÐ¾ ÑÐµÐ¶Ð¸ÑÑÐµÑÐ° (.*)$', rss.find('./channel/description').text, u'user nickname')
+            u'^ÐÐ¸Ð´ÐµÐ¾ ÑÐµÐ¶Ð¸ÑÑÐµÑÐ° (.*)$', description_text,
-    BandcampAlbumIE
+    BandcampAlbumIE,
-__version__ = '2013.11.29'
+__version__ = '2013.12.02'
-        timeout = float(self.params.get('socket_timeout', 600))
+        timeout_val = self.params.get('socket_timeout')
-from .vimeo import VimeoIE, VimeoChannelIE
+from .vimeo import (
-        channel_id =  mobj.group('id')
+    def _extract_videos(self, list_id, base_url):
-                                             channel_id, u'Downloading page %s' % pagenum)
+            webpage = self._download_webpage(
-                                                webpage, u'channel title')
+        list_title = self._html_search_regex(self._TITLE_RE, webpage,
-                'title': channel_title,
+                'id': list_id,
-    def _setup_opener(self, timeout=20):
+    def _setup_opener(self):
-        }
+        },
-            help='Write downloaded pages to files in the current directory')
+            help='Write downloaded intermediary pages to files in the current directory to debug problems')
-            u'file': u'214727115.flv',
+            u'file': u'214727115.mp4',
-            u'file': u'103000935.flv',
+            u'file': u'103000935.mp4',
-                 ' AND plrs="86Gj0vCaSzV_Iuf6hNylf2" AND region="US"' % long_id)
+                 ' AND plrs="86Gj0vCaSzV_Iuf6hNylf2" AND region="US"'
-            u'ext': u'flv',
+            u'ext': u'mp4',
-                         help='Download only videos not present in the archive file. Record all downloaded videos in it.')
+                         help='Download only videos not present in the archive file. Record the IDs of all downloaded videos in it.')
-from .yahoo import YahooIE, YahooSearchIE
+from .yahoo import (
-                 ' AND plrs="86Gj0vCaSzV_Iuf6hNylf2"' % long_id)
+                 ' AND plrs="86Gj0vCaSzV_Iuf6hNylf2" AND region="US"' % long_id)
-    def __init__(self, params={}):
+    def __init__(self, params=None):
-        self.params = params
+        self.params = {} if params is None else params
-            help='video format code, specifiy the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported')
+            help='video format code, specify the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported')
-                'width': format_info['width'],
+                'height': int(info['titleObject']['encoding']['selected'][:-1]),
-__version__ = '2013.11.28.1'
+__version__ = '2013.11.29'
-                format_page)
+            json_data = self._search_regex(
-__version__ = '2013.11.28'
+__version__ = '2013.11.28.1'
-        self.assertEqual(md5(subtitles['en']), '356cdc577fde0c6783b9b822e7206ff7')
+        self.assertEqual(md5(subtitles['en']), '3cb210999d3e021bd6c7f0ea751eab06')
-        u'md5': u'5e38bda8c329fbfb42be0386a3f5a382',
+        u'url': u'http://www.clipfish.de/special/game-trailer/video/3966754/fifa-14-e3-2013-trailer/',
-            u'duration': 399,
+            u'title': u'FIFA 14 - E3 2013 Trailer',
-__version__ = '2013.11.26'
+__version__ = '2013.11.28'
-    def _download_xml(self, url_or_request, video_id, note=u'Downloading XML', errnote=u'Unable to downloand XML'):
+    def _download_xml(self, url_or_request, video_id,
-        doc = parse_xml_doc(info_xml)
+        doc = self._download_xml(
-
+# coding: utf-8
-    _VALID_URL = r'^http://www\.zdf\.de\/ZDFmediathek(?P<hash>#)?\/(.*beitrag\/video\/)(?P<video_id>[^/\?]+)(?:\?.*)?'
+    _VALID_URL = r'^https?://www\.zdf\.de/ZDFmediathek(?P<hash>#)?/(.*beitrag/(?:video/)?)(?P<video_id>[0-9]+)(?:/[^/?]+)?(?:\?.*)?'
-            paging = i*self._PAGING_STEP
+        paging = 0
-        items_json = self._search_regex(r'YVIDEO_INIT_ITEMS = ({.*?});$',
+        items_json = self._search_regex(r'mediaItems: ({.*?})$',
-        info = {
+        return {
-        title = clean_html(get_element_by_attribute('class', 'title long-title', webpage))
+        title_span = (get_element_by_attribute('class', 'title long-title', webpage) or
-    _VALID_URL = r'(?:https?://)?(?:www\.)?videopremium\.tv/(?P<id>\w+)(?:/.*)?'
+    _VALID_URL = r'(?:https?://)?(?:www\.)?videopremium\.(?:tv|me)/(?P<id>\w+)(?:/.*)?'
-        }
+        }
-                       for vid_id in ids]
+        url_results = self._ids_to_results(ids)
-        webpage_config = self._download_webpage('http://www.anitube.se/nuevo/econfig.php?key=%s' % key,
+        config_xml = self._download_xml('http://www.anitube.se/nuevo/econfig.php?key=%s' % key,
-        ref_xml_doc = xml.etree.ElementTree.fromstring(ref_xml)
+        ref_xml_doc = self._download_xml(ref_xml_url, video_id, note=u'Downloading metadata')
-        config_xml = self._download_webpage('http://download.liveweb.arte.tv/o21/liveweb/events/event-%s.xml' % video_id,
+        config_doc = self._download_xml('http://download.liveweb.arte.tv/o21/liveweb/events/event-%s.xml' % video_id,
-        info_page = self._download_webpage(info_url,video_id, 
+        doc = self._download_xml(info_url,video_id, 
-        info_xml = self._download_webpage(
+        doc = self._download_xml(
-        info = xml.etree.ElementTree.fromstring(info_xml.encode('utf-8'))
+        info = self._download_xml(info_url, page_title)
-        indexXml = self._download_webpage(indexUrl, epTitle,
+        idoc = self._download_xml(indexUrl, epTitle,
-            configXml = self._download_webpage(configUrl, epTitle,
+            cdoc = self._download_xml(configUrl, epTitle,
-        info_xml = self._download_webpage(
+        info = self._download_xml(
-        urls_xml = self._download_webpage(
+        urls = self._download_xml(
-            url_xml = self._download_webpage(
+            url_doc = self._download_xml(
-        details_doc = xml.etree.ElementTree.fromstring(details_xml.encode('utf-8'))
+        details_doc = self._download_xml(details_url, video_id, note=u'Downloading video details')
-        config_xml = self._download_webpage(
+        config = self._download_xml(
-        config_xml = self._download_webpage(config_xml_url, video_id,
+        config = self._download_xml(config_xml_url, video_id,
-        xml_desc = self._download_webpage(
+        info = self._download_xml(
-        flashconfiguration_xml = self._download_webpage(url, video_id,
+        flashconfiguration = self._download_xml(url, video_id,
-        info_xml = self._download_webpage(file_url, video_id,
+        info = self._download_xml(file_url, video_id,
-        xml_config = self._download_webpage(
+        config = self._download_xml(
-            xml_config, u'JSON information')
+        info_json = config.find('format.json').text
-            chapter_info_xml = self._download_webpage(api, chapter_id,
+            doc = self._download_xml(api, chapter_id,
-        info = xml.etree.ElementTree.fromstring(api_response.encode('utf-8'))
+        info = self._download_xml(api_url, video_id)
-        infoXml = self._download_webpage(self._FEED_URL +'?' + data, video_id,
+        idoc = self._download_xml(self._FEED_URL +'?' + data, video_id,
-        metadata = xml.etree.ElementTree.fromstring(metadata_text.encode('utf-8'))
+        metadata = self._download_xml(metadata_url, video_id)
-        info_xml = self._download_webpage(
+        info = self._download_xml(
-        urls_xml = self._download_webpage(
+        urls = self._download_xml(
-        info = xml.etree.ElementTree.fromstring(info_xml.encode('utf-8')).find('video')
+        all_info = self._download_xml('http://www.nbcnews.com/id/%s/displaymode/1219' % video_id, video_id)
-        path_response = self._download_webpage(path_url, video_id,
+        path_doc = self._download_xml(path_url, video_id,
-        video_info_webpage = self._download_webpage(
+        video_info = self._download_xml(
-            user_info_webpage = self._download_webpage(
+            user_info = self._download_xml(
-        url_page = self._download_webpage('http://v.iask.com/v_play.php?%s' % data,
+        url_doc = self._download_xml('http://v.iask.com/v_play.php?%s' % data,
-        xml_code = self._download_webpage(
+        idoc = self._download_xml(
-        data = xml.etree.ElementTree.fromstring(data_xml.encode('utf-8'))
+        data = self._download_xml(data_url, video_id, 'Downloading data webpage')
-        streams_webpage = self._download_webpage(
+        streams_doc = self._download_xml(
-        format_str = self._download_webpage(
+        format_doc = self._download_xml(
-        config_xml = self._download_webpage('http://sunshine.videofy.me/?videoId=%s' % video_id,
+        config = self._download_xml('http://sunshine.videofy.me/?videoId=%s' % video_id,
-            caption_list = xml.etree.ElementTree.fromstring(list_page.encode('utf-8'))
+            caption_list = self._download_xml(list_url, video_id)
-    _VIDEO_RE = r'href="/watch\?v=([0-9A-Za-z_-]{11})&amp;'
+    _VIDEO_RE = r'href="/watch\?v=(?P<id>[0-9A-Za-z_-]{11})&amp;[^"]*?index=(?P<index>\d+)'
-            new_ids = orderedSet(re.findall(self._VIDEO_RE, page))
+            matches = re.finditer(self._VIDEO_RE, page)
-            params['restrictfilenames'] = True
+            self.params['restrictfilenames'] = True
-__version__ = '2013.11.25.3'
+__version__ = '2013.11.26'
-        extractor = info_dict.get('extractor')
+        extractor = info_dict.get('extractor_key')
-    downloadarchive:   File name of a file where all downloads are recorded.
+    download_archive:   File name of a file where all downloads are recorded.
-__version__ = '2013.11.25.2'
+__version__ = '2013.11.25.3'
-            if fdict.get('vcodec') is not None:
+            if (fdict.get('vcodec') is not None and
-                shell_quote = lambda args: ' '.join(map(pipes.quote, args))
+                shell_quote = lambda args: ' '.join(map(pipes.quote, str_args))
-            self.to_screen(u'[debug] rtmpdump command line: ' + shell_quote(args))
+            self.to_screen(u'[debug] rtmpdump command line: ' + shell_quote(str_args))
-        if len(url_list) > 1 and self.fixed_template():
+        if (len(url_list) > 1 and
-    selection.add_option('--max-downloads', metavar='NUMBER', dest='max_downloads', help='Abort after downloading NUMBER files', default=None)
+    selection.add_option('--max-downloads', metavar='NUMBER',
-    def __init__(self, params):
+    def __init__(self, params={}):
-        if '%(stitle)s' in self.params['outtmpl']:
+        if '%(stitle)s' in self.params.get('outtmpl', ''):
-        if quiet == False:
+        if quiet:
-            'id':       track_id,
+            'id': track_id,
-            'ext':      info.get('original_format', u'mp3'),
+            'title': info['title'],
-            result['url'] = 'https://api.soundcloud.com/tracks/{0}/download?client_id={1}'.format(track_id, self._CLIENT_ID)
+            format_url = (
-            else:
+
-                result['url'] = info['stream_url'] + '?client_id=' + self._CLIENT_ID,
+                formats.append({
-    def _setup_opener(self, timeout=300):
+    def _setup_opener(self, timeout=20):
-__version__ = '2013.11.25.1'
+__version__ = '2013.11.25.2'
-        extractor = info_dict.get('extractor_id')
+    def _make_archive_id(self, info_dict):
-        vid_id = extractor + u' ' + info_dict['id']
+
-        vid_id = info_dict['extractor'] + u' ' + info_dict['id']
+        vid_id = self._make_archive_id(info_dict)
-                    data_len_str = u'~'+self.format_bytes(data_len)
+                    data_len_str = u'~' + format_bytes(data_len)
-__version__ = '2013.11.25'
+__version__ = '2013.11.25.1'
-        for sturl in re.findall(r'<track src="([^"]+)"/>', info_webpage):
+        for sturl_html in re.findall(r'<track src="([^"]+)"/>', info_webpage):
-                except ssl.SSLError as e:
+                except ssl.SSLError:
-        for sturl in re.findall(r'<track src="([^"]+)"/>'):
+        for sturl in re.findall(r'<track src="([^"]+)"/>', info_webpage):
-            uploader = uploader.group(1).strip()
+            uploader = uploader_m.group(1).strip()
-global_setup()
+from test.helper import try_rm
-global_setup()
+from test.helper import FakeYDL
-global_setup()
+from test.helper import FakeYDL, md5
-global_setup()
+from test.helper import get_params, try_rm
-global_setup()
+from test.helper import get_params
-global_setup()
+from test.helper import FakeYDL
-__version__ = '2013.11.24.1'
+__version__ = '2013.11.25'
-            mobj = re.search(r'[^A-Za-z0-9]?file["\']?:\s*["\'](http[^\'"&]*)', webpage)
+            mobj = re.search(r'[^A-Za-z0-9]?file["\']?:\s*["\'](http[^\'"]*)', webpage)
-        return [{
+        return {
-        }]
+        }
-                    * quality_name Human-readable name of the video quality.
+            ext = format_m.group('container')
-            pref = (is_available, proto_pref, quality_pref, vbr, abr)
+            pref = (is_available, is_supported,
-                'format_id': format_id,
+                'format_id': format_id + u'-' + quality,
-                'ext': format_m.group('container'),
+                'ext': ext,
-                'format_note': None if is_available else u'(unavailable)',
+                'format_note': format_note,
-        formats = sorted(map(xml_to_format, format_nodes),
+        formats = sorted(filter(lambda f: f['_available'],
-import math
+    format_bytes,
-        return '%10s' % ('%s/s' % FileDownloader.format_bytes(speed))
+        return '%10s' % ('%s/s' % format_bytes(speed))
-        data_len_str = self.format_bytes(data_len)
+        data_len_str = format_bytes(data_len)
-                return fdict['format_note']
+            if fdict.get('format_note') is not None:
-            return (u'%-20s%-10s%-12s%s' % (
+        def line(format, idlen=20):
-            )
+            ))
-        formats_s = list(map(line, formats))
+        idlen = max(len(u'format code'),
-            '_resolution': u'resolution', 'format_note': u'note'})
+            '_resolution': u'resolution', 'format_note': u'note'}, idlen=idlen)
-    ExtractorError,
+    parse_xml_doc,
-            url = url.replace(u'#', u'', 1)
+        xml_url = u'http://www.zdf.de/ZDFmediathek/xmlservice/web/beitragsDetails?ak=web&id=%s' % video_id
-            raise ExtractorError(u'No media url found.')
+        title = doc.find('.//information/title').text
-            TYPE_ORDER = ['ostreaming', 'hstreaming', 'wstreaming']
+        def xml_to_format(fnode):
-                type_pref = TYPE_ORDER.index(s['media_type'])
+                proto_pref = -PROTO_ORDER.index(format_m.group('proto'))
-                type_pref = 999
+                proto_pref = 999
-            QUALITY_ORDER = ['veryhigh', '300']
+            quality = fnode.find('./quality').text
-                quality_pref = QUALITY_ORDER.index(s['quality'])
+                quality_pref = -QUALITY_ORDER.index(quality)
-        RTSP_STREAM = r'(?P<video_url>rtsp://[^"]*.mp4)'
+            abr = int(fnode.find('./audioBitrate').text) // 1000
-        video_url = mobj.group('video_url')
+            return {
-            html, u'title')
+        format_nodes = doc.findall('.//formitaeten/formitaet')
-            'ext': determine_ext(video_url)
+            'formats': formats,
-            uploader = uploader.strip()
+        uploader_m = re.search(
-        self.assertMatch(':cr', ['ComedyCentral'])
+        self.assertMatch(':thedailyshow', ['ComedyCentralShows'])
-from .comedycentral import ComedyCentralIE
+from .comedycentral import ComedyCentralIE, ComedyCentralShowsIE
-class ComedyCentralIE(InfoExtractor):
+class ComedyCentralIE(MTVIE):
-        }
+        },
-        info_webpage = self._download_webpage(info_url, video_id)
+        info_webpage = self._download_webpage(
-    nocheckcertificate Do not verify SSL certificates
+    nocheckcertificate:Do not verify SSL certificates
-        metaXml = self._download_webpage(xmlUrl, video_id,
+        mdoc = self._download_xml(xmlUrl, video_id,
-            manifestXml = self._download_webpage(manifest_url, video_id,
+            adoc = self._download_xml(manifest_url, video_id,
-            adoc = xml.etree.ElementTree.fromstring(manifestXml)
+import xml.etree.ElementTree
-            'description': info['description'],
+            'description': info.get('description'),
-            return find_xpath_attr(object_doc, './param', 'name', name)
+            node = find_xpath_attr(object_doc, './param', 'name', name)
-            params['playerKey'] = playerKey.attrib['value']
+            params['playerKey'] = playerKey
-            params['@videoPlayer'] = videoPlayer.attrib['value']
+            params['@videoPlayer'] = videoPlayer
-            params['linkBaseURL'] = linkBase.attrib['value']
+            params['linkBaseURL'] = linkBase
-__version__ = '2013.11.24'
+__version__ = '2013.11.24.1'
-__version__ = '2013.11.22.2'
+__version__ = '2013.11.24'
-                       for video_id in ids]
+        url_results = [self.url_result(vid_id, 'Youtube', video_id=vid_id)
-            'http://www.nicovideo.jp/watch/' + video_id, video_id)
+        # Get video webpage. We are not actually interested in it, but need
-    if version_tuple(__version__) >= version_tuple(version_str):
+    if version_tuple(__version__) >= version_tuple(version_id):
-    _LOGIN_URL = 'https://secure.nicovideo.jp/secure/login'
+    _VALID_URL = r'^https?://(?:www\.|secure\.)?nicovideo\.jp/watch/([a-z][a-z][0-9]+)(?:.*)$'
-                u'password': password,
+            u'mail': username,
-            self._downloader.report_warning(u'unable to log in: %s' % compat_str(err))
+        login_data = compat_urllib_parse.urlencode(login_form).encode('utf-8')
-        video_id = self._extract_id(url)
+        mobj = re.match(self._VALID_URL, url)
-            raise ExtractorError(u'Unable to download video webpage: %s' % compat_str(err))
+        video_webpage = self._download_webpage(
-            raise ExtractorError(u'Unable to download video info webpage: %s' % compat_str(err))
+        video_info_webpage = self._download_webpage(
-            raise ExtractorError(u'Unable to download flv info webpage: %s' % compat_str(err))
+        flv_info_webpage = self._download_webpage(
-        # uploader_id
+        video_upload_date = unified_strdate(video_info.find('.//first_retrieve').text.split('+')[0])
-            user_info_webpage = compat_urllib_request.urlopen(request).read()
+            user_info_webpage = self._download_webpage(
-        video_webpage_url = video_info.find('.//watch_url').text
+        else:
-        self.to_screen(u'%s: Extracting video information' % video_id)
+import ssl
-        return compat_urllib_request.HTTPSHandler()
+    if sys.version_info < (3, 2):
-        context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
+        context = ssl.SSLContext(ssl.PROTOCOL_SSLv3)
-	logger:            Log messages to a logging.Logger instance.
+    logger:            Log messages to a logging.Logger instance.
-        if self.params.get('logger', False):
+        if self.params.get('logger'):
-        if self.params.get('logger', False):
+        if self.params.get('logger'):
-        playerKey = find_xpath_attr(object_doc, './param', 'name', 'playerKey')
+        def find_param(name):
-        videoPlayer = find_xpath_attr(object_doc, './param', 'name', '@videoPlayer')
+        # The three fields hold the id of the video
-        linkBase = find_xpath_attr(object_doc, './param', 'name', 'linkBaseURL')
+        linkBase = find_param('linkBaseURL')
-        if not self.params.get('quiet', False):
+        if self.params.get('logger', False):
-        sys.stderr.write(output)
+        if self.params.get('logger', False):
-__version__ = '2013.11.22.1'
+__version__ = '2013.11.22.2'
-        result = ie.extract('https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w')[0]
+        result = ie.extract('https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w')
-        result = ie.extract('https://www.youtube.com/channel/HCtnHdj3df7iM/videos')[0]
+        result = ie.extract('https://www.youtube.com/channel/HCtnHdj3df7iM/videos')
-        result = ie.extract('https://www.youtube.com/user/TheLinuxFoundation')[0]
+        result = ie.extract('https://www.youtube.com/user/TheLinuxFoundation')
-                return u'"' + title + '" title matched reject pattern "' + rejecttitle + '"'
+        if 'title' in info_dict:
-                    % info_dict)
+            return (u'%s has already been recorded in archive'
-            self.add_extra_info(ie_result, extra_info)
+
-        vid_id = info_dict['extractor'] + u' ' + info_dict['id']
+        extractor = info_dict.get('extractor_id')
-    def url_result(self, url, ie=None):
+    def url_result(self, url, ie=None, video_id=None):
-                return self.url_result('https://www.youtube.com/watch?v=' + video_id, 'Youtube')
+                return self.url_result(video_id, 'Youtube', video_id=video_id)
-        url_results = [self.url_result(vid, 'Youtube') for vid in ids]
+        url_results = [self.url_result(video_id, 'Youtube', video_id=video_id)
-        return [self.playlist_result(url_entries, channel_id)]
+        url_entries = [self.url_result(video_id, 'Youtube', video_id=video_id)
-        return [self.playlist_result(url_results, playlist_title = username)]
+        url_results = [
-        videos = [self.url_result('http://www.youtube.com/watch?v=%s' % id, 'Youtube') for id in video_ids]
+        videos = [self.url_result(video_id, 'Youtube', video_id=video_id)
-            feed_entries.extend(self.url_result(id, 'Youtube') for id in ids)
+            feed_entries.extend(
-        self.assertTrue(len(result['entries']) >= 66)
+        self.assertTrue(len(result['entries']) >= 60)
-        u'md5': u'1d7ba54e2c9d7dc6935ef39e00529138',
+        u'md5': u'8b743df908c42f60cf6496586c7f12c3',
-                entries.append({
+                return {
-            return self.playlist_result(entries, title, title)
+                }
-__version__ = '2013.11.22'
+__version__ = '2013.11.22.1'
-            compat_print(info_dict['title'])
+            compat_print(info_dict['fulltitle'])
-                videos = self.extract_info(url)
+                self.extract_info(url)
-from .version import __version__
+from .version import __version__
-        except (TypeError, ValueError) as err:
+        except (TypeError, ValueError):
-    except (TypeError, ValueError) as err:
+    except (TypeError, ValueError):
-    except (TypeError, ValueError) as err:
+    except (TypeError, ValueError):
-
+        ydl.print_debug_header()
-    compat_urllib_request,
+
-            return compat_urllib_request.urlopen(url_or_request)
+            return self._downloader.urlopen(url_or_request)
-def make_HTTPS_handler(opts):
+def make_HTTPS_handler(opts_no_check_certificate):
-                               if opts.no_check_certificate
+                               if opts_no_check_certificate
-        except (IOError, OSError) as err:
+        except (IOError, OSError):
-        except (IOError, OSError) as err:
+        except (IOError, OSError):
-        except (IOError, OSError) as err:
+        except (IOError, OSError):
-        except (IOError, OSError) as err:
+        except (IOError, OSError):
-        except (IOError, OSError) as err:
+        except (IOError, OSError):
-        }
+        },
-                config = self._search_regex([r' = {config:({.+?}),assets:', r'c=({.+?);'],
+                config = self._search_regex([r' = {config:({.+?}),assets:', r'(?:c|b)=({.+?});'],
-__version__ = '2013.11.21'
+__version__ = '2013.11.22'
-    _TEST = {
+    _TESTS = [{
-    }
+    }, {
-                resut['url'] = info['stream_url'] + '?client_id=' + self._CLIENT_ID,
+                result['url'] = info['stream_url'] + '?client_id=' + self._CLIENT_ID,
-        # TODO test from de
+    BandcampAlbumIE
-from .bandcamp import BandcampIE
+from .bandcamp import BandcampIE, BandcampAlbumIE
-            return self.url_result(burl, 'Bandcamp')
+            # Don't set the extractor because it can be a track url or an album
-            ('share/man/man1/', ['youtube-dl.1'])
+            ('share/man/man1', ['youtube-dl.1'])
-    return ' '.join(map(pipes.quote, args))
+    quoted_args = []
-__version__ = '2013.11.20'
+__version__ = '2013.11.21'
-            'url':      info['stream_url'] + '?client_id=' + self._CLIENT_ID,
+            # We can build a direct link to the song
-            # We have to get the rtmp url
+        else:
-                'http://api.soundcloud.com/i1/tracks/{0}/streams?client_id={1}'.format(track_id, self._CLIENT_ID),
+                'http://api.soundcloud.com/i1/tracks/{0}/streams?client_id={1}'.format(track_id, self._IPHONE_CLIENT_ID),
-            })
+            # There should be only one entry in the dictionary
-        }
+        },
-    IE_DESC = u'Download the first 12 videos from a videocenter category'
+    IE_DESC = u'NHL videocenter category'
-            r'>\s*Description:</div>\s*<[^>]+>([^<]+)', webpage, u'description', fatal=False)
+            r'<div\s+id="descriptionContent">([^<]+)<', webpage, u'description', fatal=False)
-            description = None
+        video_uploader = self._html_search_regex(
-        self.report_extraction(video_id)
+        if re.match(r"^<html><head><script[^>]*>window.location\s*=", webpage):
-            webpage, u'video title')
+        video_title = self._html_search_regex(
-        return [{
+        return {
-        }]
+        }
-        u'xskip': 'Only available in Canada'
+        u'skip': 'Only available in Canada'
-    json_filename = filename + '.info.json'
+    json_filename = os.path.splitext(filename)[0] + '.info.json'
-__version__ = '2013.11.19'
+__version__ = '2013.11.20'
-        playerUrl = self._og_search_video_url(webpage, name='player URL')
+        playerUrl = self._og_search_video_url(webpage, name=u'player URL')
-            webpage, u'player url').split(' : ')[-1]
+            r'<meta name="title" content="([^"]*)"',
-        playerUrl = self._og_search_video_url(webpage, name='player url')
+        playerUrl = self._og_search_video_url(webpage, name='player URL')
-        configUrl = self._search_regex('config=(.*)$', playerUrl, u'config url')
+        configUrl = self._search_regex('config=(.*)$', playerUrl, u'config URL')
-                pass  # That's fine, we'll just use normal quality
+            _add_format(u'hq', hq_url)
-    _VALID_URL = r'^(https?://)?(www\.)?escapistmagazine\.com/videos/view/(?P<showname>[^/]+)/(?P<episode>[^/?]+)[/?]?.*$'
+    _VALID_URL = r'^https?://?(www\.)?escapistmagazine\.com/videos/view/(?P<showname>[^/]+)/(?P<episode>[^/?]+)[/?]?.*$'
-        u'md5': u'c6793dbda81388f4264c1ba18684a74d',
+        u'md5': u'ab3a706c681efca53f0a35f1415cf0d1',
-        videoDesc = self._html_search_regex('<meta name="description" content="([^"]*)"',
+        videoDesc = self._html_search_regex(
-        title = self._html_search_regex('<meta name="title" content="([^"]*)"',
+        title = self._html_search_regex(
-                                            u'unable to download configuration')
+        formats = []
-        configJSON = configJSON.replace("'", '"')
+        def _add_format(name, cfgurl):
-            raise ExtractorError(u'Invalid JSON in configuration file: ' + compat_str(err))
+            # Technically, it's JavaScript, not JSON
-        videoUrl = playlist[1]['url']
+            try:
-        info = {
+        _add_format(u'normal', configUrl)
-            'url': videoUrl,
+            'formats': formats,
-        return [info]
+    'Anton Larionov',
-    _VALID_URL = r'http?://(?:www\.)?anitube\.se/video/(?P<id>\d+)'
+    _VALID_URL = r'https?://(?:www\.)?anitube\.se/video/(?P<id>\d+)'
-        u'md5': u'0c4e4f1051bf50f5982f829f7230f539',
+        u'md5': u'59d0eeae28ea0bc8c05e7af429998d43',
-                try_rm(tc_filename + '.info.json')
+                try_rm(os.path.splitext(tc_filename)[0] + '.info.json')
-                self.assertTrue(os.path.exists(tc_filename + '.info.json'))
+                info_json_fn = os.path.splitext(tc_filename)[0] + '.info.json'
-                with io.open(tc_filename + '.info.json', encoding='utf-8') as infof:
+                with io.open(info_json_fn, encoding='utf-8') as infof:
-            except IndexError as err:
+            except IndexError:
-        page_id = video_id = mobj.group('page_id')
+        page_id = mobj.group('page_id')
-        title = re.match(self._VALID_URL, url).group(1)
+        title = mobj.group(1)
-        except RegexNotFoundError as err:
+        except RegexNotFoundError:
-        MMS_STREAM = r'href="(?P<video_url>mms://[^"]*)"'
+        #MMS_STREAM = r'href="(?P<video_url>mms://[^"]*)"'
-            raise RegexNotFoundError(u'Unable to extract video URL')
+            raise ExtractorError(u'Unable to extract video URL')
-    forcejson:         Force printing json information.
+    forcejson:         Force printing info_dict as JSON.
-            help='simulate, quiet but print json information', default=False)
+            help='simulate, quiet but print JSON information', default=False)
-        'quiet': (opts.quiet or opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat),
+        'quiet': (opts.quiet or opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.dumpjson),
-        'skip_download': (opts.skip_download or opts.simulate or opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat),
+        'skip_download': (opts.skip_download or opts.simulate or opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat or opts.dumpjson),
-        video_id = mobj.group('id')
+        video_id = mobj.groupdict().get('id')
-import xml.etree.ElementTree
+from .canalplus import CanalplusIE
-class D8IE(InfoExtractor):
+class D8IE(CanalplusIE):
-__version__ = '2013.11.18.1'
+__version__ = '2013.11.19'
-    _VALID_URL = r"""(?xi)^
+    _VALID_URL = r"""(?x)^
-                         (?:(?:(?:(?:\w+\.)?youtube(?:-nocookie)?\.com/|
+                         (?:(?:(?:(?:\w+\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie)?\.com/|
-            write_string(u'\033[22t', self._screen_file)
+            # Save the title on stack
-            write_string(u'\033[23t', self._screen_file)
+            # Restore the title from stack
-__version__ = '2013.11.18'
+__version__ = '2013.11.18.1'
-    compat_urllib_parse_urlparse,
+    determine_ext,
-        links = [compat_urllib_parse.unquote(l) for l in links]
+        links = re.findall(r'\s(?:file|url):\s*["\']([^\'"]+)["\']', webpage)
-            if pathext == '.png':
+            if link.endswith('.png'):
-                ext = pathext
+            elif '/videos/' in link:
-        return [{
+
-            'url':       url,
+            'url':       video_url,
-        }]
+        }
-    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0 (Chrome) (iPhone)',
+    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0 (Chrome)',
-__version__ = '2013.11.17'
+__version__ = '2013.11.18'
-            return self.url_result(surl, 'Youtube')
+        matches = re.findall(
-                         (?:https?://)?                                       # http(s):// (optional)
+                         (?:https?://|//)?                                    # http(s):// or protocol-independent URL (optional)
-            u"url":  u"https://www.YouTube.com/watch?v=yZIXLfi8CZQ",
+            u"url":  u"//www.YouTube.com/watch?v=yZIXLfi8CZQ",
-    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0 (Chrome)',
+    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0 (Chrome) (iPhone)',
-    _VALID_URL = r"""^
+    _VALID_URL = r"""(?xi)^
-        return re.match(cls._VALID_URL, url, re.VERBOSE) is not None
+        return re.match(cls._VALID_URL, url) is not None
-                                                  'el': 'embedded',
+                                                  'el': 'player_embedded',
-__version__ = '2013.11.15.1'
+__version__ = '2013.11.17'
-            raise ExtractorError(u'Cannot transform RTMP url')
+            return rtmp_video_url
-            self.to_screen('\033]0;%s\007' % message, skip_eol=True)
+            write_string(u'\033]0;%s\007' % message, self._screen_file)
-            self.to_screen('\033[22t')
+            write_string(u'\033[22t', self._screen_file)
-            self.to_screen('\033[23t')
+            write_string(u'\033[23t', self._screen_file)
-    ydl = YoutubeDL({
+    ydl_opts = {
-        })
+    }
-        except:
+    with YoutubeDL(ydl_opts) as ydl:
-                sys.exc_clear()
+                sp = subprocess.Popen(
-            sys.exit()
+                try:
-        retcode = 101
+        try:
-from .southparkstudios import SouthParkStudiosIE
+from .southparkstudios import (
-    _TEST = {
+    # Overwrite MTVIE properties we don't want
-    _TESTS = []
+    }]
-    _VALID_URL = r'https?://www\.southparkstudios\.com/(clips|full-episodes)/(?P<id>.+?)(\?|#|$)'
+    _VALID_URL = r'(https?://)?(www\.)?(?P<url>southparkstudios\.com/(clips|full-episodes)/(?P<id>.+?)(\?|#|$))'
-from .utils import *
+from .utils import (
-        except (UnicodeEncodeError) as err:
+        except UnicodeEncodeError:
-from .utils import *
+from .utils import (
-            self.to_screen('\033]0;%s\007' % message, skip_eol=True)
+    def to_console_title(self, message):
-        self.to_cons_title(u'youtube-dl - %s of %s at %s ETA %s' %
+        self.to_console_title(u'youtube-dl - %s of %s at %s ETA %s' %
-        if re.search(self._LIVE_URL, video_id) is not None:
+        if re.search(self._LIVE_URL, url) is not None:
-            url_node = video_doc.find('urlSd')
+            url_node = event_doc.find('urlSd')
-        u'md5': u'7b8c22b5e7098a3e1c09709df1126d2d',
+        # md5 varies from time to time, as in
-        u'md5': u'2f32b1f7b80fdc5cb616efb4f387f8a3',
+        # MD5 is flaky, seems to change regularly
-)
+        u'skip': u'Download has to use same server IP as extraction. Therefore, a good (load-balancing) DNS resolver will make the download fail.'
-        u'md5': u'fba8f7693e48fd4e8641b3fd5539a641',
+        # MD5 seems to be flaky, see https://travis-ci.org/rg3/youtube-dl/jobs/14051016#L388
-            playlist_el = get_element_by_attribute(u'class', u'video_list', webpage)
+            playlist_el = get_element_by_attribute(u'class', u'row video_list', webpage)
-            formats_s[-1] += (' ' if formats[-1].get('format_note') else '') + '(best)'
+            formats_s[0] += (' ' if format_note(formats[0]) else '') + '(worst)'
-                res += fdict['vcodec']
+                res += u'%-5s' % fdict['vcodec']
-                res += fdict['acodec']
+                res += u'%-5s' % fdict['acodec']
-    _TEST = {
+    _TESTS = [{
-    }
+    },
-            webpage, u'title')
+        video_title = self._html_search_regex(
-                    note=u'Downloading XML', errnote=u'Failed to download XML')
+        xml_code = self._download_webpage(
-        video_ext = filename.rpartition('.')[2]
+        formats = [
-            'ext': video_ext,
+            'formats': formats,
-        return [info]
+        return info
-                format.get('format_note', ''),
+                format_note(format),
-                'format_note': format_note,
+                'vcodec': m.group('vcodec'),
-__version__ = '2013.11.15'
+__version__ = '2013.11.15.1'
-    def _playlist_videos_info(self,url,name,playlist_id=0):
+
-        m_names=re.finditer(video_name_RE,webpage)
+
-        return self.playlist_result(playlist_entries, playlist_id = playlist_id, playlist_title = playlist_title)
+        playlist_entries = [
-            } for stream in info['htmlStreams']]
+        } for stream in info['htmlStreams']]
-        info = {
+        return {
-        esc_prop = re.escape(prop)
+        content_re = r'content=(?:"([^>]+?)"|\'(.+?)\')'
-            r'<meta[^>]+?content=(?:"(.+?)"|\'(.+?)\')[^>]+?property=[\'"]og:%s[\'"]' % esc_prop,
+            template % (property_re, content_re),
-        return r'<meta.+?property=[\'"]og:%s[\'"].+?content=(?:"(.+?)"|\'(.+?)\')' % re.escape(prop)
+    def _og_regexes(prop):
-        escaped = self._search_regex(self._og_regex(prop), html, name, flags=re.DOTALL, **kargs)
+        escaped = self._search_regex(self._og_regexes(prop), html, name, flags=re.DOTALL, **kargs)
-        if secure: regexes.insert(0, self._og_regex('video:secure_url'))
+        regexes = self._og_regexes('video')
-            u'description': u'31.10.2013',
+            u'title': u'31.10.2013 - Odcinek 2',
-                break
+        if autogenerated:
-            return self.process_video_result(ie_result)
+            return self.process_video_result(ie_result, download=download)
-__version__ = '2013.11.13'
+__version__ = '2013.11.15'
-            'ext':      u'mp3',
+            'ext':      info.get('original_format', u'mp3'),
-from .livestream import LivestreamIE
+from .livestream import LivestreamIE, LivestreamOriginalIE
-INFO_JSON_FILE = TEST_ID + '.mp4.info.json'
+INFO_JSON_FILE = TEST_ID + '.info.json'
-            infofn = filename + u'.info.json'
+            infofn = os.path.splitext(filename)[0] + u'.info.json'
-            sub_format = self.params.get('subtitlesformat')
+            sub_format = self.params.get('subtitlesformat', 'srt')
-                'fmt': self._downloader.params.get('subtitlesformat'),
+                'fmt': self._downloader.params.get('subtitlesformat', 'srt'),
-        sub_format = self._downloader.params.get('subtitlesformat')
+        sub_format = self._downloader.params.get('subtitlesformat', 'srt')
-        u'md5': u'17f6088f7d0149ff2b46f2714bdb1954',
+        u'md5': u'2f32b1f7b80fdc5cb616efb4f387f8a3',
-class YoutubePlaylistIE(InfoExtractor):
+class YoutubePlaylistIE(YoutubeBaseInfoExtractor):
-        result = ie.extract('https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re')[0]
+        result = ie.extract('https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re')
-        result = ie.extract('PLBB231211A4F62143')[0]
+        result = ie.extract('PLBB231211A4F62143')
-        result = ie.extract('https://www.youtube.com/playlist?list=UUBABnxM4Ar9ten8Mdjj1j0Q')[0]
+        result = ie.extract('https://www.youtube.com/playlist?list=UUBABnxM4Ar9ten8Mdjj1j0Q')
-        result = ie.extract('https://www.youtube.com/playlist?list=PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC')[0]
+        result = ie.extract('https://www.youtube.com/playlist?list=PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC')
-        result = ie.extract('https://www.youtube.com/playlist?list=PLtPgu7CB4gbZDA7i_euNxn75ISqxwZPYx')[0]
+        result = ie.extract('https://www.youtube.com/playlist?list=PLtPgu7CB4gbZDA7i_euNxn75ISqxwZPYx')
-        result = ie.extract('https://www.youtube.com/course?list=ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8')[0]
+        result = ie.extract('https://www.youtube.com/course?list=ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8')
-        result = ie.extract('PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl')[0]
+        result = ie.extract('PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl')
-    _MAX_RESULTS = 50
+    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s&page=%s'
-        videos = []
+        # Extract the video ids from the playlist pages
-            url = self._TEMPLATE_URL % (playlist_id, self._MAX_RESULTS, start_index)
+            url = self._TEMPLATE_URL % (playlist_id, page_num)
-                # Number of videos is a multiple of self._MAX_RESULTS
+            if re.search(self._MORE_PAGES_INDICATOR, page) is None:
-        videos = [v[1] for v in sorted(videos)]
+        playlist_title = self._og_search_title(page)
-        return [self.playlist_result(url_results, playlist_id, playlist_title)]
+        url_results = [self.url_result(vid, 'Youtube') for vid in ids]
-__version__ = '2013.11.11'
+__version__ = '2013.11.13'
-import re
+import re
-)
+
-        u'file': u'31.10.2013-12878238.wmv',
+        u'md5': u'148408967a6a468953c0a75cbdaf0d7a',
-            raise ExtractorError(u'Invalid JSON')
+        webpage = self._download_webpage(url, video_id)
-            raise ExtractorError('Missing JSON parameter: ' + sys.exc_info()[1])
+        video_url = params['video_url']
-        info = {
+        title = self._og_search_title(webpage, fatal=True)
-        return info
+    'Jelle van der Waa',
-    _VALID_URL = r'http?://www\.gamekings\.tv/videos/(?P<name>[0-9a-z\-])'
+    _VALID_URL = r'http?://www\.gamekings\.tv/videos/(?P<name>[0-9a-z\-]+)'
-        u'md5': u'8d42d15381e2dfa81dee86c7956d35ff',
+        u'file': u'20130811.mp4',
-            u"title": u"Phoenix Wright: Ace Attorney &#8211; Dual Destinies Review",
+            u"title": u"Phoenix Wright: Ace Attorney \u2013 Dual Destinies Review",
-        gamekings_url = self._og_search_video_url(webpage)
+        video_url = self._og_search_video_url(webpage)
-        video = re.search(r'[0-9]+',gamekings_url)
+        video = re.search(r'[0-9]+', video_url)
-        gamekings_url = gamekings_url.replace(video_id,'large/' + video_id)
+        # Todo: add medium format
-                }
+        return {
-        uploader = self._html_search_regex(r'<div class="user">.*?<h2>(.+?)</h2>',
+        uploader = self._html_search_regex(r'<p class="username">(.*?)</p>',
-            options.extend(['-metadata', '%s="%s"' % (name, value)])
+            options.extend(['-metadata', '%s=%s' % (name, value)])
-        return None
+        if escaped is None:
-__version__ = '2013.11.07'
+__version__ = '2013.11.11'
-            action='store_true', dest='continue_dl', help='resume partially downloaded files', default=True)
+            action='store_true', dest='continue_dl', help='force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.', default=True)
-            return False
+        args = ['-y', '-i', url, '-f', 'mp4', '-c', 'copy',
-        retval = subprocess.call(args)
+        for program in ['avconv', 'ffmpeg']:
-                                                info_dict.get('live', False))
+                                                info_dict.get('rtmp_live', False))
-                'live': True, # workaround
+                'rtmp_live': True, # workaround
-                'live': True, # workaround
+                'rtmp_live': True, # workaround
-    unittest.main()
+#!/usr/bin/env python
-md5 = lambda s: hashlib.md5(s.encode('utf-8')).hexdigest()
+from test.helper import FakeYDL, md5
-        return info_dict[0]['subtitles']
+        return info_dict['subtitles']
-        self.assertEqual(info_dict, [None])
+        self.assertEqual(info_dict, None)
-            return [self._talk_info(url)]
+            return self._talk_info(url)
-            help='Specifies the number of digits in %(autonumber)s when it is present in output filename template or --autonumber option is given')
+            help='Specifies the number of digits in %(autonumber)s when it is present in output filename template or --auto-number option is given')
-            return (u'%-15s%-10s%-12s%s' % (
+            return (u'%-20s%-10s%-12s%s' % (
-        # We order the formats by quality
+
-            sort_key = lambda f: ['HQ', 'MQ', 'EQ', 'SQ'].index(f['quality'])
+            def sort_key(f):
-            sort_key = lambda f: int(f.get('height',-1))
+            def sort_key(f):
-        # Pick the best quality
+    compat_str,
-                quality = m_quality.group(1)
+            quality = ''
-                'height': format_info.get('height'),
+                'height': height,
-    _VALID_URL = r'''(?x)https?://(edition\.)?cnn\.com/video/(data/.+?|\?)/
+    _VALID_URL = r'''(?x)https?://((edition|www)\.)?cnn\.com/video/(data/.+?|\?)/
-        bc_url += '&%40videoPlayer={}'.format(chapter_id)
+        bc_url += '&%40videoPlayer={0}'.format(chapter_id)
-    }
+    _TESTS = [
-        name = full_title or video_id
+        track_id = compat_str(info['id'])
-            'id':       info['id'],
+        result = {
-    }
+    # it's in tests/test_playlists.py
-    _TEST = None
+    _TESTS = []
-        video_url = 'http://%s%s' % (ip, path)
+        param1 = self._search_regex(r'param1:(\d+)', video_info_page, u'param1')
-        args = ['ffmpeg', '-y', '-i', url, '-f', 'mp4', tmpfilename]
+        args = ['ffmpeg', '-y', '-i', url, '-f', 'mp4', '-c', 'copy',
-__all__ = ['aes_encrypt', 'key_expansion', 'aes_ctr_decrypt', 'aes_decrypt_text']
+__all__ = ['aes_encrypt', 'key_expansion', 'aes_ctr_decrypt', 'aes_cbc_decrypt', 'aes_decrypt_text']
-    
+
-                     (3,1,1,2))
+SBOX_INV = (0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38, 0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb,
-def mix_column(data):
+def rijndael_mul(a, b):
-            mixed ^= addend & 0xff
+            # xor is (+) and (-)
-def mix_columns(data):
+def mix_columns(data, matrix=MIX_COLUMN_MATRIX):
-        data_mixed += mix_column(column)
+        data_mixed += mix_column(column, matrix)
-        basic_args = ['rtmpdump', verbosity_option, '-r', url, '-o', tmpfilename]
+        basic_args = ['rtmpdump', '--verbose', '-r', url, '-o', tmpfilename]
-        retval = subprocess.call(args)
+
-            self.to_screen(u'\r[rtmpdump] %s bytes' % prevsize, skip_eol=True)
+            self.to_screen(u'[rtmpdump] %s bytes' % prevsize)
-            retval = subprocess.call(basic_args + ['-e'] + [[], ['-k', '1']][retval == 1])
+            retval = run_rtmpdump(basic_args + ['-e'] + [[], ['-k', '1']][retval == 1])
-                self.to_screen(u'\r[rtmpdump] Could not download the whole video. This can happen for some advertisements.')
+                self.to_screen(u'[rtmpdump] Could not download the whole video. This can happen for some advertisements.')
-            self.to_screen(u'\r[rtmpdump] %s bytes' % fsize)
+            self.to_screen(u'[rtmpdump] %s bytes' % fsize)
-            return self._get_video_info(videoPlayer[0], query_str)
+            return self._get_video_info(videoPlayer[0], query_str, query)
-        webpage = self._download_webpage(request_url, video_id)
+    def _get_video_info(self, video_id, query_str, query):
-            u'url': u'http://www.scientificamerican.com/article.cfm?id=soap-bubble-physics',
+            u'url': u'http://www.bfmtv.com/video/bfmbusiness/cours-bourse/cours-bourse-l-analyse-technique-154522/',
-                u'id': u'2365799484001',
+                u'id': u'2765128793001',
-                u'uploader': u'Scientific American',
+                u'title': u'Le cours de bourse : lâanalyse technique',
-__version__ = '2013.11.06.1'
+__version__ = '2013.11.07'
-        percent_str = self.format_percent(percent)
+        if eta is not None:
-                eta = None
+                eta = percent = None
-                self.report_progress(percent, data_len_str, speed, eta)
+            self.report_progress(percent, data_len_str, speed, eta)
-    _VALID_URL = r'^(?:https?://)?video\.xnxx\.com/video([0-9]+)/(.*)'
+    _VALID_URL = r'^(?:https?://)?(?:video|www)\.xnxx\.com/video([0-9]+)/(.*)'
-__version__ = '2013.11.06'
+__version__ = '2013.11.06.1'
-        url = re.sub(r'(?<=[?&])videoI(d|D)', '%40videoPlayer', url)
+        # Change the 'videoId' and others field to '@videoPlayer'
-                                      u'Downloading page #%s' % pagenum)
+        # Download all channel pages using the json-based channel_ajax query
-        video_ids.extend(ids_in_page)
+            page = json.loads(page)
-                video_ids.extend(ids_in_page)
+            ids_in_page = self.extract_videos_from_page(page['content_html'])
-                    break
+            if self._MORE_PAGES_INDICATOR not in page['load_more_widget_html']:
-            })
+            info['formats'] = [{
-            'id': video_info['id'],
+            'id': compat_str(video_info['id']),
-        if m_brightcove is not None:
+        bc_url = BrightcoveIE._extract_brightcove_url(webpage)
-            bc_url = BrightcoveIE._build_brighcove_url(m_brightcove.group())
+from youtube_dl.extractor import get_info_extractor
-        if not ie._WORKING:
+        if not ie.working():
-__version__ = '2013.11.03'
+__version__ = '2013.11.06'
-                self.report_progress('Unknown %', data_len_str, speed_str, 'Unknown ETA')
+                self.report_progress('Unknown %', data_len_str, speed, 'Unknown ETA')
-from .utils import *
+from .utils import (
-        except (IOError, OSError) as err:
+        except (IOError, OSError):
-        except (UnicodeEncodeError) as err:
+        except UnicodeEncodeError:
-        return unescapeHTML(escaped)
+        if not escaped is None:
-            return sub_lang_list
+        try:
-            r'<iframe[^>]+?src="(https?://(?:www\.)?youtube.com/embed/.+?)"', webpage)
+            r'<iframe[^>]+?src=(["\'])(?P<url>https?://(?:www\.)?youtube.com/embed/.+?)\1', webpage)
-            surl = unescapeHTML(mobj.group(1))
+            surl = unescapeHTML(mobj.group(u'url'))
-    _VALID_URL = r'http://.*?\.canalc2\.tv/video\.asp\?idVideo=(\d+)&voir=oui'
+    _VALID_URL = r'http://.*?\.canalc2\.tv/video\.asp\?.*?idVideo=(?P<id>\d+)'
-        video_id = re.match(self._VALID_URL, url).group(1)
+        video_id = re.match(self._VALID_URL, url).group('id')
-        data = self._download_webpage(data_url, video_id, 'Downloading data webpage')
+        data_xml = self._download_webpage(data_url, video_id, 'Downloading data webpage')
-            regex = r'<file [^>]*type="(?:high|standard)".*?>(.*%s.*)</file>' % quality
+        qualities = ['500k', '480p', '1000k', '720p', '1080p']
-        if not video_url:
+                return qualities.index(f['format_id'])
-        return [{
+        return {
-            'ext':         'mp4',
+            'formats': formats,
-        }]
+        }
-__version__ = '2013.11.02'
+__version__ = '2013.11.03'
-    _VALID_URL = r'(?P<domain>https?://(?:www\.)?viddler.com)/(?:v|embed|player)/(?P<id>[0-9]+)'
+    _VALID_URL = r'(?P<domain>https?://(?:www\.)?viddler.com)/(?:v|embed|player)/(?P<id>[a-z0-9]+)'
-        free_download_indication = { 'gateway_result' : '1' }
+        free_download_indication = {'gateway_result' : '1'}
-        extension = os.path.splitext( path )[1][1:]
+        path = compat_urllib_parse_urlparse(video_url).path
-        format = "-".join( format )
+        format = "-".join(format)
-        data = { 'ax': 1, 'ts': time.time() }
+        data = {'ax': 1, 'ts': time.time()}
-        }]
+        }]
-        extension = os.path.splitext( path )[1][1:]
+        path = compat_urllib_parse_urlparse(video_url).path
-        format = "-".join( format )
+        format = "-".join(format)
-        extension = os.path.splitext( path )[1][1:]
+        path = compat_urllib_parse_urlparse(video_url).path
-        format = "-".join( format )
+        format = "-".join(format)
-            extension = os.path.splitext( path )[1][1:]
+            path = compat_urllib_parse_urlparse(video_url).path
-            format = "-".join( format )
+            format = "-".join(format)
-            extension = os.path.splitext( path )[1][1:]
+            path = compat_urllib_parse_urlparse(video_url).path
-            format = "-".join( format )
+            format = "-".join(format)
-        extension = os.path.splitext( path )[1][1:]
+        path = compat_urllib_parse_urlparse(video_url).path
-        format = "-".join( format )
+        format = "-".join(format)
-        files = { 'hd': [], 'sd': [], 'other': []}
+        files = {'hd': [], 'sd': [], 'other': []}
-        extension = os.path.splitext( path )[1][1:]
+        path = compat_urllib_parse_urlparse(video_url).path
-        format = "-".join( format )
+        format = "-".join(format)
-            if (pagenum * 30 +i >= n) or (m[u'last'] >= (m[u'total'] -1 )):
+            if (pagenum * 30 +i >= n) or (m[u'last'] >= (m[u'total'] -1)):
-        u"params": { u"test": False },
+        u"params": {u"test": False},
-            index  =  math.floor(seed / 65536 * len(source) )
+            seed  =  (seed * 211 + 30031) % 65536
-            extension = os.path.splitext( path )[1][1:]
+            video_url = unescapeHTML(link)
-            format = "-".join( format )
+            format = "-".join(format)
-                for key in ['webpage_url', 'extractor']:
+                for key in ['webpage_url', 'extractor', 'extractor_key']:
-                        'webpage_url': url
+                        'webpage_url': url,
-                    ie_result['extractor'] = ie.IE_NAME
+                self.add_extra_info(ie_result,
-                    {'extractor': ie_result['extractor']})
+                    {
-    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?(?:#.*)?$'
+    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|(?P<player>player))\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?(?:#.*)?$'
-        elif mobj.group('pro'):
+        if mobj.group('pro') or mobj.group('player'):
-        elif mobj.group('direct_link'):
+        else:
-        return [{
+        return {
-        }]
+            'webpage_url': url,
-                'annotations':  video_annotations
+                'annotations':  video_annotations,
-                return self.process_ie_result(ie_result, download=download)
+                return self.process_ie_result(ie_result, download, extra_info)
-            ie_result.update(extra_info)
+            self.add_extra_info(ie_result, extra_info)
-                r.setdefault('extractor', ie_result['extractor'])
+                self.add_extra_info(r,
-                self.process_ie_result(_fixup(r), download=download)
+                self.process_ie_result(_fixup(r), download, extra_info)
-        uploader = self._html_search_regex(r'>Posted by:(?=<)(\s|<[^>]*>)*(.+?)\|', webpage, u'uploader', fatal=False)
+        uploader = self._html_search_regex(r'>Posted by:(?=<)(?:\s|<[^>]*>)*(.+?)\|', webpage, u'uploader', fatal=False)
-            'age_limit': age_limit,
+            'age_limit': 18,
-            u'md5': u'9e80619e0a94663f0bdc849b4566af19',
+            u'md5': u'8eccab865181d29ec2958f32a6a754f5',
-                'ext': 'flv',
+            u'skip': u'The site is down too often',
-        {
+    BambuserChannelIE,
-from .bambuser import BambuserIE
+from .bambuser import BambuserIE, BambuserChannelIE
-            'thumbnail': info['preview'],
+            'thumbnail': info.get('preview'),
-from .common import InfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class TEDIE(InfoExtractor):
+class TEDIE(SubtitlesInfoExtractor):
-            'id': info['id'],
+            'id': video_id,
-        video_subtitles = self.extract_subtitles(video_id)
+        video_subtitles = self.extract_subtitles(video_id, webpage)
-            self._list_available_subtitles(video_id)
+            self._list_available_subtitles(video_id, webpage)
-    def _get_available_subtitles(self, video_id):
+    def _get_available_subtitles(self, video_id, webpage):
-    def _list_available_subtitles(self, video_id, webpage=None):
+    def _list_available_subtitles(self, video_id, webpage):
-        sub_lang_list = self._get_available_subtitles(video_id)
+        sub_lang_list = self._get_available_subtitles(video_id, webpage)
-    def extract_subtitles(self, video_id, video_webpage=None):
+    def extract_subtitles(self, video_id, webpage):
-            available_subs_list.update(self._get_available_automatic_caption(video_id, video_webpage))
+            available_subs_list.update(self._get_available_automatic_caption(video_id, webpage))
-            available_subs_list.update(self._get_available_subtitles(video_id))
+            available_subs_list.update(self._get_available_subtitles(video_id, webpage))
-    def _get_available_subtitles(self, video_id):
+    def _get_available_subtitles(self, video_id, webpage):
-    def _get_available_subtitles(self, video_id):
+    def _get_available_subtitles(self, video_id, webpage):
-    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url):
+    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url, live):
-                                                info_dict.get('tc_url', None))
+                                                info_dict.get('tc_url', None),
-__version__ = '2013.10.30'
+__version__ = '2013.11.02'
-                'name': l[0],
+                'name': l[0].encode('utf-8'),
-    _TESTS = [{
+    _TESTS = [
-    }]
+            u"description": u"md5:38c711dd98f5bb87acf973d573442e67",
-        req.headers['Cookie'] = 'flashVersion=0;'
+
-        mobj = re.search(r'src="(?P<embed_url>http://player\.screenwavemedia\.com/play/(?:embed|player)\.php\?id=(?:Cinemassacre-)?(?P<video_id>.+?))"', webpage)
+        mobj = re.search(r'src="(?P<embed_url>http://player\.screenwavemedia\.com/play/[a-zA-Z]+\.php\?id=(?:Cinemassacre-)?(?P<video_id>.+?))"', webpage)
-        u'md5': u'27b6f7527da5acf534b15f21b032656e',
+        u'md5': u'cde9ba0fa3506f5f017ce11ead928f9a',
-            data, u'video URL')
+
-                                                     u'Downloading event info'))
+            config_json = self._search_regex(r'window.config = ({.*?});',
-        return info_dict[0]['subtitles']
+        return info_dict['subtitles']
-                                            webpage, 'video uploader')
+                                            webpage, 'video uploader', fatal=False)
-        return [{
+        return {
-        }]
+            'thumbnail': info['thumbnail_url'],
-__version__ = '2013.10.29'
+__version__ = '2013.10.30'
-                    note=u' ({})'.format(format['format_note']) if format.get('format_note') is not None else '',
+                    note=u' ({0})'.format(format['format_note']) if format.get('format_note') is not None else '',
-    determine_ext,
+    compat_HTTPError,
-    _TEST = {
+    _TESTS = [{
-            u'duration': 230,
+            u"duration": 230,
-    }
+    }]
-        video_info = json.loads(info_json)['video']
+    def _formats_from_json(self, video_info):
-            format_note = '%(videoCodec)s@%(videoBitrate)4sK, %(audioCodec)s@%(audioBitrate)3sK' % attr
+            format_note = '%(videoCodec)s@%(videoBitrate)4sk, %(audioCodec)s@%(audioBitrate)3sk' % attr
-                                Calculated from the format_id, width, height 
+                                Calculated from the format_id, width, height.
-            formats_s[-1] += (' ' if formats_s[-1] else '') + '(best)'
+        formats = info_dict.get('formats', [info_dict])
-            u'md5': u'ae7a1d8b183758a0506b0622f37dfa14',
+            u'md5': u'8879b6cc097e987f02484baf890129e5',
-        formats = player_info['VSR'].values()
+        all_formats = player_info['VSR'].values()
-        # We order the formats by quality
+        formats = filter(_match_lang, all_formats)
-            f_url = attr['url']
+            format_note = '%(videoCodec)s@%(videoBitrate)4sK, %(audioCodec)s@%(audioBitrate)3sK' % attr
-                'ext': determine_ext(f_url),
+                'url': attr['url'],
-
+        if format.get('_resolution') is not None:
-            formats_s.append(u'%-15s%-7s     %-15s%s' % (
+        def line(format):
-                format.get('format_note', ''),
+                format.get('format_note', ''),
-                info_dict['id'], formats_s))
+            formats_s[0] += (' ' if formats_s[0] else '') + '(worst)'
-        upload_date = datetime.datetime.fromtimestamp(date_epoch)
+        timestamp_ms = int(self._search_regex(
-__version__ = '2013.10.28'
+__version__ = '2013.10.29'
-          dsh = match.group(1)
+        galx = self._search_regex(r'(?s)<input.+?name="GALX".+?value="(.+?)"',
-                u'dsh': dsh,
+    compat_HTTPError,
-                    if not err.exc_info[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):
+                    if not err.exc_info[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError) or (err.exc_info[0] == compat_HTTPError and err.exc_info[1].code == 503):
-            {u'format_id': u'excellent'},
+            {u'format_id': u'meh', u'url': u'http://example.com/meh'},
-from test.helper import get_params, get_testcases, global_setup, try_rm, md5
+from test.helper import (
-            for retry in range(1, RETRIES + 1):
+            try_num = 1
-                    print('Retrying: {0} failed tries\n\n##########\n\n'.format(retry))
+                    if try_num == RETRIES:
-            return
+        if 'playlist' not in test_case:
-            try_rm(tc['file'] + '.info.json')
+        def try_rm_tcs_files():
-                self.assertTrue(os.path.exists(tc['file'] + '.info.json'))
+                    self.assertTrue(os.path.exists(tc_filename), msg='Missing file ' + tc_filename)
-                    md5_for_file = _file_md5(tc['file'])
+                    md5_for_file = _file_md5(tc_filename)
-                with io.open(tc['file'] + '.info.json', encoding='utf-8') as infof:
+                with io.open(tc_filename + '.info.json', encoding='utf-8') as infof:
-                try_rm(tc['file'] + '.info.json')
+            try_rm_tcs_files()
-            if template_dict['playlist_index'] is not None:
+            if template_dict.get('playlist_index') is not None:
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>keezmovies\.com/video/.+?(?P<videoid>[0-9]+))'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>keezmovies\.com/video/.+?(?P<videoid>[0-9]+))(?:[/?&]|$)'
-        if self.params.get('forcethumbnail', False) and 'thumbnail' in info_dict:
+        if self.params.get('forcethumbnail', False) and info_dict.get('thumbnail') is not None:
-        if self.params.get('forcedescription', False) and 'description' in info_dict:
+        if self.params.get('forcedescription', False) and info_dict.get('description') is not None:
-            raise ExtractorError(u'requested format not available')
+            raise ExtractorError(u'requested format not available',
-        if info_dict['extractor'] in [u'youtube', u'Youku', u'mixcloud']:
+        if info_dict['extractor'] in [u'youtube', u'Youku']:
-__version__ = '2013.10.23.2'
+__version__ = '2013.10.28'
-    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?$'
+    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?(?:#.*)?$'
-            u'url': u'http://vimeo.com/56015672',
+            u'url': u'http://vimeo.com/56015672#at=0',
-    def format_resolution(format):
+    def format_resolution(format, default='unknown'):
-            res = '???'
+            res = default
-            formats_s.append(u'%-15s: %-5s     %-15s[%s]' % (
+            formats_s.append(u'%-15s%-7s     %-15s%s' % (
-                format.get('format_note') or '-',
+                format.get('format_note', ''),
-            if not isinstance(ee.cause, compat_HTTPError):
+            if not isinstance(ee.cause, compat_HTTPError) or \
-        video_extension = video_url[-3:]  # mp4 or flv ?
+        formats = []
-            'ext': video_extension,
+            'formats': formats,
-                                       html, name, **kargs)
+    def _og_search_video_url(self, html, name='video url', secure=True, **kargs):
-            'url':       self._og_search_video_url(webpage),
+            'url':       self._og_search_video_url(webpage, secure=False),
-    unescapeHTML,
+            u"age_limit": 18,
-            u"title": u"Marilyn-Monroe-Bathing"
+            u"title": u"Marilyn-Monroe-Bathing",
-            u"title": u"Zeichentrick 1"
+            u"title": u"Zeichentrick 1",
-                'player_url': embed_page_url}
+                'player_url': embed_page_url,
-            u'md5': u'8a7967a3fef10e59a1d6f86240fd41cf',
+            u'url': u'http://ex.fm/song/eh359',
-                u'description': u'Download "We Can\'t Stop" \r\niTunes: http://smarturl.it/WeCantStop?IQid=SC\r\nAmazon: http://smarturl.it/WeCantStopAMZ?IQid=SC',
+                u"title": u"Test House \"Love Is Not Enough\" (Extended Mix) DeadJournalist Exclusive",
-                                           webpage, u'video file URL')
+        video_url = self._search_regex(r"var (?:hq|normal)_video_file = '(.*?)';",
-        }
+        },
-        u'file': u'127367.flv',
+        u'url': u'http://www.rtlnitronow.de/recht-ordnung/stadtpolizei-frankfurt-gerichtsvollzieher-leipzig.php?film_id=129679&player=1&season=1',
-            u'thumbnail': u'http://autoimg.static-fra.de/nitronow/344787/1500x1500/image2.jpg',
+            u'upload_date': u'20131016', 
-            u'md5': u'85b90ccc9d73b4acd9138d3af4c27f89',
+            u'md5': u'6e15c93721d7ec9e9ca3fdbf07982cfd',
-        descr_html = get_element_by_attribute('class', 'Content Copy', webpage)
+        descr = self._html_search_regex(r'<p class="Content Copy">(.*?)</p>', webpage, u'description')
-            'description': clean_html(descr_html),
+            'description': descr,
-            return self.playlist_result([self.url_result(embedded_url)], playlist_id=video_id)
+            return self.url_result(embedded_url)
-                err_msg = u'The video is not available, Facebook said: "%s"' % m_msg.group(1)
+                raise ExtractorError(
-            raise ExtractorError(err_msg)
+                raise ExtractorError(u'Cannot parse data')
-            raise ExtractorError(u'Cannot parse data')
+            m_msg = re.search(r'class="[^"]*uiInterstitialContent[^"]*"><div>(.*?)</div>', webpage)
-    _LOGIN_URL = 'https://login.facebook.com/login.php?m&next=http%3A%2F%2Fm.facebook.com%2Fhome.php&'
+    _LOGIN_URL = 'https://www.facebook.com/login.php?next=http%3A%2F%2Ffacebook.com%2Fhome.php&login_attempt=1'
-
+    def _login(self):
-        # Log in
+        login_page_req = compat_urllib_request.Request(self._LOGIN_URL)
-            'login': 'Log+In'
+            'lsd': lsd,
-            self.report_login()
+
-        u'md5': u'3f8e232ad52163c87fa23897e736cb2c',
+        u'md5': u'72954ea10bc979ab5e2eb288b21425a0',
-        if not video_url:  # if there's no hq_video_file, get normal_video_file
+        try:
-        video_uploader = self._html_search_regex(r'>Submitted by:</strong>(?:\w|<[^>]*>)*(.+?)<', webpage, u'uploader', fatal=False)
+        video_uploader = self._html_search_regex(r'>Submitted by:</strong>(?:\s|<[^>]*>)*(.+?)<', webpage, u'uploader', fatal=False)
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>tube8.com/[^/]+/[^/]+/(?P<videoid>[0-9]+)/?)'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>tube8\.com/[^/]+/[^/]+/(?P<videoid>[0-9]+)/?)'
-        u'md5': u'1036a0e0cd307b95bd8a8c3a5c8cfaf1',
+        u'file': u'24MR3YO5SAS9.mp4',
-        video_url = self._search_regex(r"var normal_video_file = '(.*?)';",
+        video_url = self._search_regex(r"var hq_video_file = '(.*?)';",
-            'ext': 'flv',
+            'ext': video_extension,
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?youporn\.com/watch/(?P<videoid>[0-9]+)/(?P<title>[^/]+)'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?(?P<url>youporn\.com/watch/(?P<videoid>[0-9]+)/(?P<title>[^/]+))'
-        if info_dict['extractor'] in [u'youtube', u'Youku', u'YouPorn', u'mixcloud']:
+        if info_dict['extractor'] in [u'youtube', u'Youku', u'mixcloud']:
-        # Get all of the formats available
+        # Get all of the links from the page
-        LINK_RE = r'(?s)<a href="(?P<url>[^"]+)">'
+        LINK_RE = r'<a href="([^"]+)">'
-            links = [video_url] + links
+
-
+
-                'age_limit': age_limit,
+                'format_id': format,
-            return [format]
+        # Sort and remove doubles
-        mrss_url = 'http://xhamster.com/movies/%s/%s.html?hd' % (video_id, seo)
+        mrss_url = 'http://xhamster.com/movies/%s/%s.html' % (video_id, seo)
-            'title':    video_title,
+        video_url = extract_video_url(webpage)
-        }]
+        }
-        for i in itertools.count():
+        for i in range(track_count):
-                  '%(format)s for the format description (like "22 - 1280x720" or "HD")'
+                  '%(format)s for the format description (like "22 - 1280x720" or "HD"),'
-        for format_param, video_real_url in video_url_list:
+        for itag, video_real_url in video_url_list:
-            video_extension = self._video_extensions.get(format_param, 'flv')
+            video_extension = self._video_extensions.get(itag, 'flv')
-                                              ' ('+self._special_itags[format_param]+')' if format_param in self._special_itags else '')
+            video_format = '{0} - {1}{2}'.format(itag if itag else video_extension,
-        u"file":  u"_aUehQsCQtM.flv",
+        u"file":  u"_aUehQsCQtM.mp4",
-            u"file":  u"1ltcDfZMA3U.flv",
+            u"file":  u"1ltcDfZMA3U.mp4",
-            m_s = re.search(r'[&,]s=', args['url_encoded_fmt_stream_map'])
+            re_signature = re.compile(r'[&,]s=')
-            m_s = re.search(r'[&,]s=', args.get('adaptive_fmts', u''))
+            m_s = re_signature.search(args.get('adaptive_fmts', u''))
-                    video_info['url_encoded_fmt_stream_map'][0] += ',' + args['adaptive_fmts']
+                if 'adaptive_fmts' in video_info:
-                    video_info['url_encoded_fmt_stream_map'] = video_info['adaptive_fmts']
+                    video_info['adaptive_fmts'] = [args['adaptive_fmts']]
-            if 'rtmpe%3Dyes' in video_info['url_encoded_fmt_stream_map'][0]:
+        elif len(video_info.get('url_encoded_fmt_stream_map', [])) >= 1 or len(video_info.get('adaptive_fmts', [])) >= 1:
-            for url_data_str in video_info['url_encoded_fmt_stream_map'][0].split(','):
+            for url_data_str in encoded_url_map.split(','):
-        info = {
+        return {
-__version__ = '2013.10.23.1'
+__version__ = '2013.10.23.2'
-        else:
+        formats = []
-            'url':      video_url,
+            'formats': formats,
-            'ext':      video_extension,
+        embed_url = 'http://embed.nowvideo.ch/embed.php?v=' + video_id
-            webpage, u'video key')
+            embed_page, u'video key')
-        for private_opt in ['-p', '--password', '-u', '--username']:
+        for private_opt in ['-p', '--password', '-u', '--username', '--video-password']:
-        }
+        },
-            config = json.loads(config)
+            try:
-            if re.search('If so please provide the correct password.', webpage):
+            if re.search('<form[^>]+?id="pw_form"', webpage) is not None:
-__version__ = '2013.10.23'
+__version__ = '2013.10.23.1'
-        ExtractorError, depending on fatal, specifying the field name.
+        RegexNotFoundError, depending on fatal, specifying the field name.
-            raise ExtractorError(u'Unable to extract %s' % _name)
+            raise RegexNotFoundError(u'Unable to extract %s' % _name)
-            u'md5': u'8879b6cc097e987f02484baf890129e5',
+            u'md5': u'ae7a1d8b183758a0506b0622f37dfa14',
-        except:
+            config_url = self._html_search_regex(
-                raise ExtractorError(u'Unable to extract info section')
+                raise ExtractorError(u'Unable to extract info section',
-__version__ = '2013.10.22'
+__version__ = '2013.10.23'
-__version__ = '2013.10.18.2'
+__version__ = '2013.10.22'
-            sanitize = lambda k,v: sanitize_filename(
+            sanitize = lambda k, v: sanitize_filename(
-            template_dict = dict((k, sanitize(k, v)) for k,v in template_dict.items())
+                is_id=(k == u'id'))
-            filename = self.params['outtmpl'] % template_dict
+            tmpl = os.path.expanduser(self.params['outtmpl'])
-            u'title': u'Agentur Amateur #2 - Corporate Design',
+            u'title': u'Agentur Amateur / Agence Amateur #2 : Corporate Design',
-            webpage, u'playlist title', flags=re.DOTALL)
+            r'tab0"[^>]*?>(.*?)</td>',
-    
+
-            _msg_header=u'\033[0;33mWARNING:\033[0m'
+            _msg_header = u'\033[0;33mWARNING:\033[0m'
-        warning_message=u'%s %s' % (_msg_header,message)
+            _msg_header = u'WARNING:'
-            sanitize = lambda k,v: sanitize_filename(
+            sanitize = lambda k, v: sanitize_filename(
-            template_dict = dict((k, sanitize(k, v)) for k,v in template_dict.items())
+                is_id=k == u'id')
-        
+
-        
+
-        
+
-            self.to_screen(u'[download] Downloading playlist: %s'  % playlist)
+            self.to_screen(u'[download] Downloading playlist: %s' % playlist)
-                self.to_screen(u'[download] Downloading video #%s of %s' %(i, n_entries))
+            for i, entry in enumerate(entries, 1):
-                         }
+                    'playlist': playlist,
-            matches = list(filter(filter_f ,available_formats))
+            matches = list(filter(filter_f, available_formats))
-                    note = u' ({})'.format(format['format_note']) if format.get('format_note') is not None else '',
+                    note=u' ({})'.format(format['format_note']) if format.get('format_note') is not None else '',
-                   annofile.write(info_dict['annotations'])
+                annofn = filename + u'.annotations.xml'
-                 return
+                self.report_error(u'Cannot write annotations file: ' + annofn)
-        if  subtitles_are_requested and 'subtitles' in info_dict and info_dict['subtitles']:
+        if subtitles_are_requested and 'subtitles' in info_dict and info_dict['subtitles']:
-                json_info_dict = dict((k, v) for k,v in info_dict.items() if not k in ['urlhandle'])
+                json_info_dict = dict((k, v) for k, v in info_dict.items() if not k in ['urlhandle'])
-                keep_video_wish,new_info = pp.run(info)
+                keep_video_wish, new_info = pp.run(info)
-            res =  '???'
+            res = '???'
-            formats_s[0]  += ' (worst)'
+            formats_s[0] += ' (worst)'
-            self.process_info(info_dict)
+            if download:
-        codecs = [('h264', 'mp4'), ('vp8', 'flv'), ('vp6', 'flv')]
+        codecs = [('vp6', 'flv'), ('vp8', 'flv'), ('h264', 'mp4')]
-                    files['sd'].append((codec_name, codec_extension, 'sd'))
+            for quality in config_files.get(codec_name, []):
-        else:
+                    file_info = {}
-            'ext':      video_extension,
+            'formats': formats,
-            if not original_lang_node or original_lang_node.attrib.get('kind') != 'asr' :
+            if original_lang_node is None or original_lang_node.attrib.get('kind') != 'asr' :
-            u'duration': 156,
+            u'duration': 153,
-        info = {
+        return {
-            u'duration': 138,
+            u'duration': 135,
-            r'''(?x)<a.+?class="o-T-s\s[^"]+"\s+style="display:\s*none"\s*>
+            r'''(?x)<a.+?class="o-U-s\s[^"]+"\s+style="display:\s*none"\s*>
-            webpage, u'upload date', fatal=False)
+            webpage, u'upload date', fatal=False, flags=re.VERBOSE)
-        formats = sorted(formats, key=lambda f: int(f.get('height',-1)))
+        formats = list(formats) # in python3 filter returns an iterator
-                format['format'] = format_desc
+            if format.get('format') is None:
-                            )
+            formats_s.append(u'%-15s: %-5s     %-15s[%s]' % (
-        self.to_screen(u"[info] Available formats for %s:\nformat code\textension\n%s" % (info_dict['id'], formats_s)) 
+        self.to_screen(u'[info] Available formats for %s:\n'
-                                Calculated from width and height if missing.
+                                Calculated from the format_id, width, height 
-            {u'format_id': u'2'},
+            {u'format_id': u'35', u'ext': u'mp4'},
-            matches = list(filter(lambda f:f['format_id'] == format_spec ,available_formats))
+            extensions = [u'mp4', u'flv', u'webm', u'3gp']
-        elif req_format in ('-1', 'all'):
+        if req_format in ('-1', 'all'):
-            # We can accept formats requestd in the format: 34/10/5, we pick
+            # We can accept formats requestd in the format: 34/5/best, we pick
-                    formats_to_download = [matches[0]]
+                selected_format = self.select_format(rf, formats)
-            u"title": u"FemaleAgent Shy beauty takes the bait"
+            u"title": u"FemaleAgent Shy beauty takes the bait",
-            u"title": u"Britney Spears  Sexy Booty"
+            u"upload_date": u"20130914",
-            'thumbnail': video_thumbnail
+            'thumbnail': video_thumbnail,
-            u"title": u"Sucked on a toilet"
+            u"title": u"Sucked on a toilet",
-            u"title": u"FemaleAgent Shy beauty takes the bait"
+            u"title": u"FemaleAgent Shy beauty takes the bait",
-            u"title": u"Britney Spears  Sexy Booty"
+            u"title": u"Britney Spears  Sexy Booty",
-            'thumbnail': video_thumbnail
+            'thumbnail': video_thumbnail,
-        '5': '240x400',
+        '5': '400x240',
-        '46': '1080x1920',
+        '17': '176x144',
-        video_thumbnail = 'http://image.screenwavemedia.com/Cinemassacre/Cinemassacre-%s_thumb_640x360.jpg' % video_id
+        url = self._html_search_regex(r'\'streamer\': \'(?P<url>[^\']+)\'', playerdata, u'url')
-                'url': base_url + sd_file,
+                'url': url,
-                'url': base_url + hd_file,
+                'url': url,
-            u"title": u"Funny Porns By >>>>S<<<<<< -1"
+            u"title": u"Funny Porns By >>>>S<<<<<< -1",
-            u"title": u"Sex Ed: Is It Safe To Masturbate Daily?"
+            u"title": u"Sex Ed: Is It Safe To Masturbate Daily?",
-        '139': 'mp4',
+        '160': 'mp4',
-            u"title": u"lida \u00bb Naked Funny Actress  (5)"
+            u"title": u"lida \u00bb Naked Funny Actress  (5)",
-__version__ = '2013.10.18.1'
+__version__ = '2013.10.18.2'
-                  '%(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), '
+                  '%(ext)s for the filename extension, '
-        '160': 'mp4',
+        '140': 'm4a',
-        'scripts': ['bin/youtube-dl'],
+    if setuptools_available:
-        '--cache-dir', dest='cachedir', default=get_cachedir(),
+        '--cache-dir', dest='cachedir', default=get_cachedir(), metavar='DIR',
-__version__ = '2013.10.18'
+__version__ = '2013.10.18.1'
-            r'<iframe\s+src="(https?://player.vimeo.com/video/.*?)"', webpage)
+            r'<iframe[^>]+?src="(https?://player.vimeo.com/video/.+?)"', webpage)
-__version__ = '2013.10.17'
+__version__ = '2013.10.18'
-        title = self._search_regex(r",kw:['\"](.+?)[\"']", webpage, u'title')
+        title = self._search_regex(
-            # the first that is availble, starting from left
+            # the first that is available, starting from left
-        raise NotImplementedError("This method must be implemented by sublclasses")
+        raise NotImplementedError("This method must be implemented by subclasses")
-    def __init__(self):
+    def __init__(self, override=None):
-        params = get_params()
+        params = get_params(override=override)
-        super(YDL, self).__init__()
+    def __init__(self, *args, **kwargs):
-            formats = [f for f in formats if f['format_id'] <= format_limit]
+            formats = list(takewhile_inclusive(
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+from test.helper import FakeYDL
-from helper import FakeYDL, parameters
+
-        formats = [{u'ext': u'webm', u'height': 460},{u'ext': u'mp4',  u'height': 460}]
+        formats = [
-        formats = [{u'ext': u'webm', u'height': 720},{u'ext': u'mp4',u'height': 1080}]
+        formats = [
-        formats = [{u'ext': u'webm', u'height': 720},{u'ext': u'flv',u'height': 720}]
+        formats = [
-__version__ = '2013.10.15'
+__version__ = '2013.10.17'
-            if original_lang_node.attrib.get('kind') != 'asr' :
+            if not original_lang_node or original_lang_node.attrib.get('kind') != 'asr' :
-        playlist_info = json.loads(playlist_info)['videoList']
+        json_data = json.loads(playlist_info)
-__version__ = '2013.10.09'
+__version__ = '2013.10.15'
-        },
+        }
-        request = compat_urllib_request.Request(url, None, std_headers)
+        request = compat_urllib_request.Request(url, None, headers)
-            r'<meta name="title" content="([^"]*) - [^-]*"',
+            r'<meta name="title" content="([^"]*?) - [^-]*? - [^-]*?"',
-        self.assertTrue(len(result) >= 4)
+        self.assertTrue(len(result) >= 3)
-        }
+        },
-            dest='ratelimit', metavar='LIMIT', help='maximum download rate in bytes per second (e.g. 50k or 44.6m)')
+            dest='ratelimit', metavar='LIMIT', help='maximum download rate in bytes per second (e.g. 50K or 4.2M)')
-            dest='buffersize', metavar='SIZE', help='size of download buffer (e.g. 1024 or 16k) (default is %default)', default="1024")
+            dest='buffersize', metavar='SIZE', help='size of download buffer (e.g. 1024 or 16K) (default is %default)', default="1024")
-from .utils import *
+
-import warnings
+import traceback
-from .utils import *
+from .utils import (
-from .FileDownloader import *
+from .FileDownloader import (
-from .PostProcessor import *
+from .PostProcessor import (
-        except (IOError, OSError) as err:
+        except (IOError, OSError):
-)
+from youtube_dl import YoutubeDL
-    parameters = json.load(pf)
+def global_setup():
-        params = dict(parameters)
+        params = get_params()
-from .helper import try_rm
+# Allow direct execution
-from .helper import get_testcases
+from test.helper import get_testcases
-import hashlib
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+from test.helper import FakeYDL, global_setup, md5
-md5 = lambda s: hashlib.md5(s.encode('utf-8')).hexdigest()
+from youtube_dl.extractor import DailymotionIE
-PARAMETERS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "parameters.json")
+from youtube_dl.utils import (
-        params.update(test_case.get('params', {}))
+        params = get_params(test_case.get('params', {}))
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+import sys
-
+# Allow direct execution
-import xml.etree.ElementTree
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+
-import xml.etree.ElementTree
+# Allow direct execution
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+from test.helper import get_params, global_setup, try_rm
-PARAMETERS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "parameters.json")
+from youtube_dl.utils import True
-params['format'] = 'flv'
+params = get_params({
-import json
+# Allow direct execution
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+from test.helper import get_params, global_setup
-params['writedescription'] = True
+params = get_params({
-import json
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-from youtube_dl.utils import *
+from youtube_dl.extractor import (
-    def assertIsPlaylist(self,info):
+    def assertIsPlaylist(self, info):
-import string
+# Allow direct execution
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+from test.helper import global_setup
-import hashlib
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-md5 = lambda s: hashlib.md5(s.encode('utf-8')).hexdigest()
+
-        return info_dict[0]['subtitles']        
+        return info_dict[0]['subtitles']
-    _VALID_URL = r'(?:http://)?(?:(?:www\.)?sztv\.hu|www\.tvszombathely\.hu)/([^/]+)/(?P<name>.+)'
+    _VALID_URL = r'(?:http://)?(?:(?:www\.)?sztv\.hu|www\.tvszombathely\.hu)/(?:[^/]+)/.+-(?P<id>[0-9]+)'
-        u'md5': u'0047eacedc0afd1ceeac99e69173a07e',
+        u'file': u'20130909.mp4',
-            u"description" : u'A zÃ¶ld nap jÃ¡tÃ©kos ismeretterjesztÅ programjait a Magyar CserkÃ©sz SzÃ¶vetsÃ©g szervezte, akik az orszÃ¡g nyolc vÃ¡rosÃ¡ban adjÃ¡k Ã¡t tudÃ¡sukat az Ã©rdeklÅdÅknek. A PET...',
+            u"description": u'A zÃ¶ld nap jÃ¡tÃ©kos ismeretterjesztÅ programjait a Magyar CserkÃ©sz SzÃ¶vetsÃ©g szervezte, akik az orszÃ¡g nyolc vÃ¡rosÃ¡ban adjÃ¡k Ã¡t tudÃ¡sukat az Ã©rdeklÅdÅknek. A PET...',
-                                webpage, 'video description')
+        video_id = mobj.group('id')
-        video_url = 'http://media.sztv.hu/vod/' + file
+        video_url = 'http://media.sztv.hu/vod/' + video_file
-                }
+        return {
-    _TEST = {
+    _VALID_URL = r'(?:http://)?(?:www\.)?tudou\.com/(?:listplay|programs|albumplay)/(?:view|(.+?))/(?:([^/]+)|([^/]+))(?:\.html)?'
-    }
+    },
-        thumbnail_url = thumbnail_url.group(1)
+
-import xml.etree.ElementTree
+import json
-    unified_strdate,
+    compat_urlparse,
-        u"file": u"6410818.mp4",
+        u"file": u"gs-2300-6410818.mp4",
-            u"upload_date": u"20130627", 
+            u'description': u'Check out this video where some of the basics of Arma 3 is explained.',
-        page_id = mobj.group('page_id')
+        page_id = video_id = mobj.group('page_id')
-        clip_el = doc.find('./playList/clip')
+        data_video_json = self._search_regex(r'data-video=\'(.*?)\'', webpage, u'data video')
-        upload_date = unified_strdate(clip_el.find('./postDate').text)
+        # Transform the manifest url to a link to the mp4 files
-        }]
+        info = {
-    _VALID_URL =  r'(?:http://)?(v|player)\.youku\.com/(v_show/id_|player\.php/sid/)(?P<ID>[A-Za-z0-9]+)(\.html|/v.swf)'
+    _VALID_URL =  r'(?:(?:http://)?(?:v|player)\.youku\.com/(?:v_show/id_|player\.php/sid/)|youku:)(?P<ID>[A-Za-z0-9]+)(?:\.html|/v\.swf|)'
-        mobj = re.match(self._VALID_URL, url)
+    @classmethod
-from .arte import ArteTvIE
+from .arte import (
-        return any(re.match(regex, url) for regex in (cls._EMISSION_URL, cls._VIDEOS_URL, cls._LIVEWEB_URL))
+        return any(re.match(regex, url) for regex in (cls._VIDEOS_URL, cls._LIVEWEB_URL))
-
+
-            u'duration': 135,
+            u'duration': 138,
-from helper import try_rm
+from .helper import try_rm
-from helper import get_testcases
+from .helper import get_testcases
-from helper import FakeYDL
+from .helper import FakeYDL
-from helper import get_testcases, try_rm
+import test.helper as helper  # Set up remaining global configuration
-from helper import FakeYDL
+from .helper import FakeYDL
-from helper import FakeYDL
+from .helper import FakeYDL
-from helper import FakeYDL
+from .helper import FakeYDL
-                if int(self._preferredquality) < 10:
+                # The opus codec doesn't support the -aq option
-        m_brightcove = re.search(r'<object.+?class=([\'"]).*?BrightcoveExperience.*?\1.+?</object>', webpage, re.DOTALL)
+        m_brightcove = re.search(r'<object[^>]+?class=([\'"])[^>]*?BrightcoveExperience.*?\1.+?</object>', webpage, re.DOTALL)
-        u'file': u'19911.mp4',
+        u'file': u'19911.flv',
-            u'upload_date': u'20121110', 
+            u'upload_date': u'20121110',
-        u'file': u'521be8ef82b16.mp4',
+        u'file': u'521be8ef82b16.flv',
-            u'upload_date': u'20131002', 
+            u'upload_date': u'20131002',
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        
+
-        base_url = self._html_search_regex(r'\'streamer\': \'(?P<base_url>rtmp://[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})/(?:vod|Cinemassacre)\'',
+        base_url = self._html_search_regex(r'\'streamer\': \'(?P<base_url>rtmp://.*?)/(?:vod|Cinemassacre)\'',
-         # Important: The file names in playerdata are not used by the player and even wrong for some videos
+        # Important: The file names in playerdata are not used by the player and even wrong for some videos
-            print(u'%s\t\t%s'  % (format['ext'], format['format']))
+        formats = [
-        return None
+        info = {
-                    format_desc = compat_str(i)
+                    format_desc = '???'
-                format['format_id'] = '???'
+                format['format_id'] = compat_str(i)
-                format['format'] = compat_str(i)
+                if format.get('height') is not None:
-                format['format_id'] = compat_str(i)
+                format['format_id'] = '???'
-            return ie_result
+            return self.process_video_result(ie_result)
-            action='store', dest='format', metavar='FORMAT',
+            action='store', dest='format', metavar='FORMAT', default='best',
-            info_dict['url'] = format_info['url']
+        def _format(format_info):
-from .nhl import NHLIE
+from .nhl import NHLIE, NHLVideocenterIE
-class NHLIE(InfoExtractor):
+class NHLBaseInfoExtractor(InfoExtractor):
-        info_json = info_json.replace('\\\'', '\'')
+        info_json = self._fix_json(info_json)
-            'path': initial_video_url.replace('.mp4', '_sd.mp4'),
+            'cid': cat_id,
-        video_url = path_doc.find('path').text
+        path = '/videocenter/servlets/browse?' + data
-            'upload_date': unified_strdate(info['releaseDate'].split('.')[0]),
+            '_type': 'playlist',
-        if self.params.get('test', False):
+        if test:
-        while retval == 2 or retval == 1:
+        while (retval == 2 or retval == 1) and not test:
-        if retval == 0:
+        if retval == 0 or (test and retval == 2):
-            description = description_node.text
+            description = description_node.text.strip()
-        try:
+        ie_desc = getattr(ie, 'IE_DESC', None)
-            pass
+from .nhl import NHLIE
-__version__ = '2013.10.07'
+__version__ = '2013.10.09'
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?(?!watch(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)([A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?(?!(?:attribution_link|watch)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)([A-Za-z0-9_-]+)'
-                u'Assuming --restrict-filenames isnce file system encoding '
+                u'Assuming --restrict-filenames since file system encoding '
-            u"title": u"Somebody to Die For"
+            u"title": u"Somebody to Die For",
-        videos_url = '%s/Video/V2/VFILE/%s/%sr.smil' % (base_url, video_id, video_id.lower())
+        json_url = 'http://videoplayer.vevo.com/VideoService/AuthenticateVideo?isrc=%s' % video_id
-                }
+        video_info = json.loads(info_json)['video']
-    _setup_opener(jar=jar, opts=opts)
+    opener = _setup_opener(jar=jar, opts=opts)
-        write_string(u'[debug] Proxy map: ' + str(proxy_handler.proxies) + u'\n')
+
-compat_urllib_request.install_opener(opener)
+youtube_dl._setup_opener(timeout=10)
-
+import helper  # Set up remaining global configuration
-    socket.setdefaulttimeout(300) # 5 minutes should be enough (famous last words)
+    _setup_opener(jar=jar, opts=opts)
-__version__ = '2013.10.06'
+__version__ = '2013.10.07'
-        xml_link = m_download.group(1)
+        xml_link = self._html_search_regex(
-        id = re.search(r'http://www.jeuxvideo.com/config/\w+/0011/(.*?)/\d+_player\.xml', xml_link).group(1)
+        video_id = self._search_regex(
-                                                  'Downloading XML config')
+        xml_config = self._download_webpage(
-        info = json.loads(info)['versions'][0]
+        info_json = self._search_regex(
-                }
+        return {
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?)|ytuser:)(?!feed/)([A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?(?!watch(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)([A-Za-z0-9_-]+)'
-    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url, test):
+    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url):
-        if test:
+        if self.params.get('test', False):
-                                                self.params.get('test', False))
+                                                info_dict.get('tc_url', None))
-    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)(?:[?].*)?$'
+    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)/?(?:[?].*)?$'
-    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url):
+    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url, test):
-                                                info_dict.get('tc_url', None))
+                                                info_dict.get('tc_url', None),
-            'title':    video_title,
+            'id':        video_id,
-            return (u'%(title)s) has already been recorded in archive'
+            return (u'%(title)s has already been recorded in archive'
-            if age_limit < info_dict.get('age_restriction', 0):
+            if age_limit < info_dict.get('age_limit', 0):
-                'age_restriction': age_limit}
+                'age_limit': age_limit}
-                'age_restriction': age_limit,
+                'age_limit': age_limit,
-                'age_restriction': 18 if age_gate else 0,
+                'age_limit':    18 if age_gate else 0,
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError(u'Failed to download URL: %s' % url)
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError(u'Unsupported URL: %s' % url)
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError(u'Did not find a valid video URL at %s' % url)
-__version__ = '2013.10.04'
+__version__ = '2013.10.06'
-    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0',
+    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0 (Chrome)',
-                'format': 'flv'}
+                'format': 'flv',
-                'description': video_description
+                'description': video_description,
-                'duration':     video_duration
+                'duration':     video_duration,
-    def to_screen(self, s):
+        params = dict(parameters)
-from helper import get_testcases
+from helper import get_testcases, try_rm
-            _try_rm(tc['file'] + '.info.json')
+            try_rm(tc['file'])
-                _try_rm(tc['file'] + '.info.json')
+                try_rm(tc['file'])
-    #     self.report_warning = types.MethodType(report_warning, self)
+import re
-import io
+        self.DL.expect_warning(u'Automatic Captions not supported by this server')
-import io
+        self.DL.expect_warning(u'Video doesn\'t have automatic captions')
-            ['title="Timestamp">(.*?)</a>', r'<a.+?class="g-M.+?>(.+?)</a>'],
+            r'''(?x)<a.+?class="o-T-s\s[^"]+"\s+style="display:\s*none"\s*>
-                    'id': data['item_id'],
+                    'id': compat_str(data['item_id']),
-            #u'description': u'âAngry Video Game Nerd: The Movieâ is...', # Description is too long
+            u'description': u'md5:fb87405fcb42a331742a0dce2708560b',
-    """Information Extractor for Cinemassacre"""
+    },
-        video_title = self._html_search_regex(r'<h1 class="entry-title">(?P<title>.+?)</h1>[^<]*</div>',
+        mobj = re.search(r'src="(?P<embed_url>http://player\.screenwavemedia\.com/play/(?:embed|player)\.php\?id=(?:Cinemassacre-)?(?P<video_id>.+?))"', webpage)
-        base_url = self._html_search_regex(r'\'streamer\': \'(?P<base_url>rtmp://[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})/vod\'',
+        base_url = self._html_search_regex(r'\'streamer\': \'(?P<base_url>rtmp://[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})/(?:vod|Cinemassacre)\'',
-         # The file names in playerdata are wrong for some videos???
+         # Important: The file names in playerdata are not used by the player and even wrong for some videos
-            video_ids.extend(re.findall(r'data-id="(.+?)" data-ext-id', playlist_el))
+            video_ids.extend(re.findall(r'data-id="(.+?)"', playlist_el))
-                   for video_id in video_ids]
+                   for video_id in orderedSet(video_ids)]
-            u'file': u'214727115.mp4',
+            u'file': u'214727115.flv',
-                u'title': u'The Cougar Lies with Spanish Moss',
+                u'title': u'Codefellas - The Cougar Lies with Spanish Moss',
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        video_extension = 'mp4'        
+        video_extension = 'mp4'
-            webpage, u'video URL')
+        video_url = self._html_search_regex(
-        video_title = self._html_search_regex('<h1 class="videoTitle slidePanelMovable">(.+?)</h1>',
+        video_title = self._html_search_regex(
-        return [{
+        return {
-        }]
+        }
-        u'md5': u'e0fdb0cd3ce98713ef9c1e1e025779d0',
+        u'md5': u'046e491afb32a8aaac1f44dd4ddd54ee',
-                if player_url not in self._player_cache:
+                player_id = (player_url, len(s))
-                func = self._player_cache[player_url]
+                    self._player_cache[player_id] = func
-    IE_NAME = u'http://generation-quoi.france2.fr'
+    IE_NAME = u'france2.fr:generation-quoi'
-        '400': '384x216',
+        '3500': (1280, 720),
-
+    @staticmethod
-            video_url = base + m.group('finalid')
+            formats = []
-                'url': video_url,
+                'formats': formats,
-                'format': format,
+
-    def _extract_video_url(self, metadataXml):
+    def _extract_video_formats(self, metadataXml):
-        return {'ext': ext, 'url': video_url, 'format': format}
+        formats = []
-        return video_info
+
-    The fields should all be Unicode strings.
+    formats:        A list of dictionaries for each format available, it must
-                }
+            'id': info['id'],
-    _VALID_URL = r'(?:https?://)?(?:www\.)?flickr\.com/photos/(?P<uploader_id>[\w\-_@]+)/(?P<id>\d+).*'
+    _VALID_URL = r'(?:https?://)?(?:www\.|secure\.)?flickr\.com/photos/(?P<uploader_id>[\w\-_@]+)/(?P<id>\d+).*'
-        webpage = compat_urllib_request.urlopen(request).read()
+        webpage = self._download_webpage(self._LOGIN_URL, '', 'Logging in')
-        request = compat_urllib_request.Request(url)
+        request = compat_urllib_request.Request(self._LOGIN_URL)
-            compat_urllib_request.urlopen(request).read(), 'utf-8')
+        if webpage != 'OK':
-            return s[12] + s[79:12:-1] + s[80] + s[11::-1]
+            return s[80:37:-1] + s[7] + s[36:7:-1] + s[0] + s[6:0:-1] + s[37]
-__version__ = '2013.10.01.1'
+__version__ = '2013.10.04'
-    _VALID_URL = r'https?://www\.france2\.fr/emissions/.*?/videos/(?P<id>\d+)'
+    _VALID_URL = r'''(?x)https?://www\.france2\.fr/
-        video_id = mobj.group('id')
+        if mobj.group('key'):
-    _VALID_URL = r'https?://.+?\.ign\.com/(?P<type>videos|show_videos|articles)(/.+)?/(?P<name_or_id>.+)'
+    _VALID_URL = r'https?://.+?\.ign\.com/(?P<type>videos|show_videos|articles|(?:[^/]*/feature))(/.+)?/(?P<name_or_id>.+)'
-    }
+    _TESTS = [
-        help='Location in the filesystem where youtube-dl can store downloaded information permanently. %default by default')
+        help='Location in the filesystem where youtube-dl can store downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl .')
-        '--cache-dir', dest='cachedir', default=userCacheDir,
+        '--cache-dir', dest='cachedir', default=get_cachedir(),
-        cache_dir = self._downloader.params.get('cachedir', userCacheDir)
+        cache_dir = get_cachedir(self._downloader.params)
-            return s[80:73:-1] + s[81] + s[72:54:-1] + s[2] + s[53:43:-1] + s[0] + s[42:2:-1] + s[43] + s[1] + s[54]
+            return s[12] + s[79:12:-1] + s[80] + s[11::-1]
-        video_title = compat_urllib_parse.unquote_plus(video_info['title'][0])
+        if 'title' in video_info:
-import urlparse
+    compat_urlparse,
-        query_dict = urlparse.parse_qs(urlparse.urlparse(url).query)
+        query_dict = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)
-    }
+    _TESTS = [
-__version__ = '2013.10.01'
+__version__ = '2013.10.01.1'
-            if 'url_encoded_fmt_stream_map':
+            if 'url_encoded_fmt_stream_map' not in args:
-__version__ = '2013.09.29'
+__version__ = '2013.10.01'
-        mobj = re.search(r'<title><!\[CDATA\[(?P<description>.+?)\s+- (?:Sendung )?vom (?P<upload_date_d>[0-9]{2})\.(?P<upload_date_m>[0-9]{2})\.(?:(?P<upload_date_Y>[0-9]{4})|(?P<upload_date_y>[0-9]{2})) [0-9]{2}:[0-9]{2} Uhr\]\]></title>', playerdata)
+        mobj = re.search(r'<title><!\[CDATA\[(?P<description>.+?)(?:\s+- (?:Sendung )?vom (?P<upload_date_d>[0-9]{2})\.(?P<upload_date_m>[0-9]{2})\.(?:(?P<upload_date_Y>[0-9]{4})|(?P<upload_date_y>[0-9]{2})) [0-9]{2}:[0-9]{2} Uhr)?\]\]></title>', playerdata)
-            else:
+            elif mobj.group('upload_date_y'):
-            video_upload_date += mobj.group('upload_date_m')+mobj.group('upload_date_d')
+            else:
-    _VALID_URL = r'(?:http://)?(?P<url>(?P<base_url>rtl-now\.rtl\.de/|rtl2now\.rtl2\.de/|(?:www\.)?voxnow\.de/|(?:www\.)?rtlnitronow\.de/|(?:www\.)?superrtlnow\.de/)[a-zA-Z0-9-]+/[a-zA-Z0-9-]+\.php\?(?:container_id|film_id)=(?P<video_id>[0-9]+)&player=1(?:&season=[0-9]+)?(?:&.*)?)'
+    """Information Extractor for RTL NOW, RTL2 NOW, RTL NITRO, SUPER RTL NOW, VOX NOW and n-tv NOW"""
-        '--cache-dir', dest='cachedir', default=u'~/.youtube-dl/cache',
+        '--cache-dir', dest='cachedir', default=userCacheDir,
-            userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')
+            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')
-            userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl.conf')
+            userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl', 'config')
-                                                u'~/.youtube-dl/cache')
+        xdg_cache_home = os.environ.get('XDG_CACHE_HOME')
-        u'file': u'124311.flv',
+        u'url': u'http://www.rtlnitronow.de/recht-ordnung/lebensmittelkontrolle-erlangenordnungsamt-berlin.php?film_id=127367&player=1&season=1',
-            u'thumbnail': u'http://autoimg.static-fra.de/nitronow/338273/1500x1500/image2.jpg'
+            u'upload_date': u'20130926', 
-            trailer_id = first_url.split('/')[-1].rpartition('_')[0]
+            trailer_id = first_url.split('/')[-1].rpartition('_')[0].lower()
-                u"md5": u"11874af099d480cc09e103b189805d5f",
+                u"md5": u"d97a8e575432dbcb81b7c3acb741f8a8",
-                u"md5": u"07a0a262aae5afe68120eed61137ab34",
+                u"md5": u"b8017b7131b721fb4e8d6f49e1df908c",
-                u"md5": u"e401fde0813008e3307e54b6f384cff1",
+                u"md5": u"d0f1e1150989b9924679b441f3404d48",
-                u"md5": u"76b392f2ae9e7c98b22913c10a639c97",
+                u"md5": u"5fe08795b943eb2e757fa95cb6def1cb",
-                    u"thumbnail": u"http://trailers.apple.com/trailers/wb/manofsteel/images/thumbnail_6899.jpg",
+    _JSON_RE = r'iTunes.playURL\((.*?)\);'
-        playlist_url = url.partition(u'?')[0] + u'/includes/playlists/web.inc'
+        playlist_url = compat_urlparse.urljoin(url, u'includes/playlists/itunes.inc')
-        playlist_cleaned = re.sub(r'(?s)<script>.*?</script>', u'', playlist_snippet)
+        playlist_cleaned = re.sub(r'(?s)<script[^<]*?>.*?</script>', u'', playlist_snippet)
-            title = li.find('.//h3').text
+            on_click = li.find('.//a').attrib['onClick']
-            m = re.search(r':\s?(?P<minutes>[0-9]+):(?P<seconds>[0-9]{1,2})', runtime_el.tail)
+            runtime = trailer_info['runtime']
-                    continue
+            first_url = trailer_info['url']
-                    })
+            formats = []
-__version__ = '2013.09.24.2'
+__version__ = '2013.09.29'
-    version = versions_info['versions'][versions_info['latest']]
+    version_id = versions_info['latest']
-echo Updating youtube-dl...
+            with io.open(bat, 'w') as batfile:
-            b.close()
+move /Y "%s.new" "%s" > NUL
-            os.startfile(bat)
+            subprocess.Popen([bat])  # Continues to run in the background
-        update_self(ydl.to_screen, opts.verbose, sys.argv[0])
+        update_self(ydl.to_screen, opts.verbose)
-def update_self(to_screen, verbose, filename):
+def update_self(to_screen, verbose):
-
+    filename = sys.argv[0]
-class DailymotionIE(SubtitlesInfoExtractor):
+class DailymotionIE(DailymotionBaseInfoExtractor, SubtitlesInfoExtractor):
-        request.add_header('Cookie', 'family_filter=off')
+        request = self._build_request(url)
-class DailymotionPlaylistIE(InfoExtractor):
+class DailymotionPlaylistIE(DailymotionBaseInfoExtractor):
-            webpage = self._download_webpage(self._PAGE_TEMPLATE % (id, pagenum),
+            request = self._build_request(self._PAGE_TEMPLATE % (id, pagenum))
-    ExtractorError,
+    compat_urlparse,
-            u"title": u"Julian Smith & Travis Legg Watch Julian Smith"
+    _TESTS = [
-    }
+        {
-                raise ExtractorError(u'Unable to extract video url')
+        items_json = self._search_regex(r'YVIDEO_INIT_ITEMS = ({.*?});$',
-            video_date = None # I can't find it
+        return info
-        return info_dict
+    determine_ext,
-    unescapeHTML,
+
-    _TITLE = r'<h1(?: class="beitragHeadline")?>(?P<title>.*)</h1>'
+    _VALID_URL = r'^http://www\.zdf\.de\/ZDFmediathek(?P<hash>#)?\/(.*beitrag\/video\/)(?P<video_id>[^/\?]+)(?:\?.*)?'
-    _RTSP_STREAM = r'(?P<video_url>rtsp://[^"]*.mp4)'
+        if mobj.group('hash'):
-        if stream_ is None:
+        def stream_pref(s):
-        media_link = self._download_webpage(stream_['video_url'], video_id,'Get stream URL')
+        media_link = self._download_webpage(
-        title = unescapeHTML(mobj.group('title'))
+        MMS_STREAM = r'href="(?P<video_url>mms://[^"]*)"'
-        mobj = re.search(self._MMS_STREAM, media_link)
+        mobj = re.search(self._MEDIA_STREAM, media_link)
-            mobj = re.search(self._RTSP_STREAM, media_link)
+            mobj = re.search(RTSP_STREAM, media_link)
-        mms_url = mobj.group('video_url')
+        video_url = mobj.group('video_url')
-        ext = mobj.group('ext')
+        title = self._html_search_regex(
-                 }]
+        return {
-            raise ExtractorError(u'no conn or url_encoded_fmt_stream_map information found in video info')
+            raise ExtractorError(u'no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')
-            video_thumbnail = ''
+            video_thumbnail = None
-                u"description": u"md5:bdac09887d209a4ed54b8f76b2bdaa8b",
+                u"description": u"md5:5b292926389560516e384ac437c0ec07",
-                               (info_dict['extractor'], info_dict['id'], thumb_filename))
+                try:
-        sub_langs = [key for key in information['subtitles']]
+        if not information.get('subtitles'):
-            return s[81:64:-1] + s[82] + s[63:52:-1] + s[45] + s[51:45:-1] + s[1] + s[44:1:-1] + s[0]
+            return s[80:63:-1] + s[0] + s[62:0:-1] + s[63]
-        video_title = self._html_search_regex(r'<title>(?P<title>[^<]+)</title>',
+        video_title = self._html_search_regex(r'<title>(?P<title>[^<]+?)( \| [^<]*)?</title>',
-    _VALID_URL = r'(?:http://)?(?P<url>(?P<base_url>rtl-now\.rtl\.de/|rtl2now\.rtl2\.de/|(?:www\.)?voxnow\.de/|(?:www\.)?superrtlnow\.de/)[a-zA-Z0-9-]+/[a-zA-Z0-9-]+\.php\?(?:container_id|film_id)=(?P<video_id>[0-9]+)&player=1(?:&season=[0-9]+)?(?:&.*)?)'
+    """Information Extractor for RTL NOW, RTL2 NOW, RTL NITRO, SUPER RTL NOW and VOX NOW"""
-            u'url': u'http://www.8tv.cat/8aldia/videos/xavier-sala-i-martin-aquesta-tarda-a-8-al-dia/',
+            # From http://www.8tv.cat/8aldia/videos/xavier-sala-i-martin-aquesta-tarda-a-8-al-dia/
-            u'url': u'http://medianetwork.oracle.com/video/player/1785452137001',
+            # From http://medianetwork.oracle.com/video/player/1785452137001
-    # and the detection of videos, and we don't have to find an URL that is always valid
+
-        best_format = renditions[-1]
+        info = {
-                'url': best_format['defaultURL'], 
+        renditions = video_info.get('renditions')
-                }
+            })
-__version__ = '2013.09.24.1'
+__version__ = '2013.09.24.2'
-    raise ValueError(repr(opts.cachedir))
+
-__version__ = '2013.09.24'
+__version__ = '2013.09.24.1'
-            u'description': u'Randy finally gets the chance to fight Bat Dad and gets the boys disqualified from the season championships.',
+            u'description': u'Randy disqualifies South Park by getting into a fight with Bat Dad.',
-        mgid = self._search_regex(r'data-mgid="(mgid:.*?)"',
+        mgid = self._search_regex(r'swfobject.embedSWF\(".*?(mgid:.*?)"',
-__version__ = '2013.09.20.1'
+__version__ = '2013.09.24'
-    general.add_option('--cache-dir', dest='cachedir', default=u'~/.youtube-dl/cache', help='Location in the filesystem where youtube-dl can store downloaded information permanently. NONE to disable filesystem caching, %default by default')
+    general.add_option(
-
+    raise ValueError(repr(opts.cachedir))
-        'cachedir': opts.cachedir if opts.cachedir != 'NONE' else None,
+        'cachedir': opts.cachedir,
-            return s[5:34] + s[0] + s[35:38] + s[3] + s[39:45] + s[38] + s[46:53] + s[73] + s[54:73] + s[85] + s[74:85] + s[53]
+            return s[80:72:-1] + s[16] + s[71:39:-1] + s[72] + s[38:16:-1] + s[82] + s[15::-1]
-                steps = u'' if step == 1 else (':%d' % step)
+                ends = (u':%d' % (end+step)) if end + step >= 0 else u':'
-                       "NONE" to disable filesystem cache.
+                       None to disable filesystem cache.
-        'cachedir': opts.cachedir,
+        'cachedir': opts.cachedir if opts.cachedir != 'NONE' else None,
-        cache_enabled = cache_dir != u'NONE'
+        cache_enabled = cache_dir is not None
-                u"description": u"md5:3e2666e0a55044490499ea45fe9037b7",
+                u"description": u"md5:bdac09887d209a4ed54b8f76b2bdaa8b",
-    # 86 - vfluy6kdb 2013/09/06
+    # 86 - vflHql6Pr 2013/09/24
-     "yuioplkjhgfdsazxcvbnm12345678q0QWrRTYUIOELKJHGFD-AZXCVBNM!@#$%^&*()_<+={[|};?/>.S"),
+     ";}|[{=+-d)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYT_EWQ0987654321mnbvcxzas/fghjklpoiuytrewq"),
-    # 84 - vflg0g8PQ 2013/08/29 (sporadic)
+    # 84 - vflHql6Pr 2013/09/24 (sporadic)
-     ">?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWq0987654321mnbvcxzasdfghjklpoiuytr"),
+     "}[{=+-_)g*&^%$#@!MNBVCXZASDFGHJKLPOIUYTRE(Q0987654321mnbvcxzasdf?hjklpoiuytrewq"),
-            return s[5:34] + s[0] + s[35:38] + s[3] + s[39:45] + s[38] + s[46:53] + s[73] + s[54:73] + s[85] + s[74:85] + s[53]
+            return s[80:72:-1] + s[16] + s[71:39:-1] + s[72] + s[38:16:-1] + s[82] + s[:16][::-1]
-            return s[81:36:-1] + s[0] + s[35:2:-1]
+            return s[78:70:-1] + s[14] + s[69:37:-1] + s[70] + s[36:14:-1] + s[80] + s[:14][::-1]
-            webpage, u'title')
+        video_title = self._html_search_regex(
-        return '%6s' % ('%3.1f%%' % (float(byte_counter) / float(data_len) * 100.0))
+        return '%6s' % ('%3.1f%%' % percent)
-            return '--:--'
+            return None
-            return '--:--'
+            return None
-        eta = int((float(total) - float(current)) / rate)
+        return int((float(total) - float(current)) / rate)
-        return '%10s' % ('%s/s' % FileDownloader.format_bytes(float(bytes) / dif))
+        return '%10s' % ('%s/s' % FileDownloader.format_bytes(speed))
-    def report_progress(self, percent_str, data_len_str, speed_str, eta_str):
+    def report_progress(self, percent, data_len_str, speed, eta):
-            speed_str = self.calc_speed(start, time.time(), byte_counter - resume_len)
+            speed = self.calc_speed(start, time.time(), byte_counter - resume_len)
-                self.report_progress(percent_str, data_len_str, speed_str, eta_str)
+                percent = self.calc_percent(byte_counter, data_len)
-                cache_res = res(map(compat_chr, range(slen)))
+                test_string = u''.join(map(compat_chr, range(slen)))
-        cache_res = func(map(compat_chr, range(slen)))
+        test_string = u''.join(map(compat_chr, range(slen)))
-            u'Warning: Falling back to static signature algorithm')
+            self._downloader.report_warning(
-                                    'flash player', fatal=False)
+                                if player_url is None:
-def make_testfunc(url, stype, sig_length, expected_sig):
+def make_tfunc(url, stype, sig_length, expected_sig):
-    make_testfunc(*test_spec)
+    make_tfunc(*test_spec)
-                       "NONE" to disable filesystem cache.
+    cachedir:          Location of the cache files in the filesystem.
-        'youtube_print_sig_code': opts.youtube_print_sig_code
+        'cachedir': opts.cachedir,
-        if cache_dir != u'NONE':
+        cache_enabled = cache_dir != u'NONE'
-        if cache_dir is not False:
+        if cache_enabled:
-        self.to_screen(u'Extracted signature:\n' + code)
+        self.to_screen(u'Extracted signature function:\n' + code)
-import itertools
+import itertools
-import operator
+import xml.etree.ElementTree
-            except Exception as e:
+            except Exception:
-                raise ExctractorError(u'Recursion limit reached')
+                raise ExtractorError(u'Recursion limit reached')
-        def string(reader=None):
+        def read_string(reader=None):
-        _ = read_bytes(2 + 2)
+        read_bytes(2 + 2)
-            _ = s32()
+            s32()
-            _ = u32()
+            u32()
-        _ = read_bytes((double_count-1) * 8)
+        read_bytes((double_count-1) * 8)
-            s = string()
+            s = read_string()
-            _ = u30()  # name
+            read_bytes(1)  # kind
-                _ = u30()
+                u30()
-                namespace_idx = u30()
+                u30()  # namespace_idx
-                    _ = u30()
+                    u30()
-            _ = u30()  # return type
+            u30()  # return type
-            _ = u30()  # name index (always 0 for youtube)
+                u30()  # param type
-                    _ = read_bytes(1)  # kind
+                    u30()  # val
-                    _ = u30()  # param name
+                    u30()  # param name
-            _ = u30()  # name
+            u30()  # name
-                _ = u30()  # value
+                u30()  # key
-                type_name_idx = u30()
+                u30()  # Slot id
-                    _ = read_byte()  # vkind
+                    read_byte()  # vkind
-                _ = u30()  # disp_id
+                u30()  # disp_id
-                _ = u30()  # classi
+                u30()  # slot_id
-                _ = u30()  # slot_id
+                u30()  # slot_id
-                    _ = u30()
+                    u30()  # metadata index
-            _ = u30()  # super_name idx
+            u30()  # super_name idx
-                protected_ns_idx = u30()
+                u30()  # protected_ns_idx
-            _ = u30()  # iinit
+                u30()
-                _ = parse_traits_info()
+                parse_traits_info()
-            _ = u30()  # cinit
+            u30()  # cinit
-            _ = u30()  # init
+            u30()  # init
-                _ = parse_traits_info()
+                parse_traits_info()
-            max_stack = u30()
+            u30()  # max_stack
-            max_scope_depth = u30()
+            u30()  # init_scope_depth
-                _ = u30()  # var_name
+                u30()  # from
-                _ = parse_traits_info()
+                parse_traits_info()
-                        _ = u30(coder)
+                        u30(coder)
-            except Exception as e:
+            except Exception:
-        if len(s) == 92:
+        if len(s) == 93:
-                       False to disable filesystem cache.
+                       "NONE" to disable filesystem cache.
-import shutil
+    compat_chr,
-                                               u'~/.youtube-dl/cache')
+        cache_dir = self._downloader.params.get('cachedir',
-        if cache_dir is not False:
+        if cache_dir != u'NONE':
-                with io.open(cache_fn, '', encoding='utf-8') as cachef:
+                with io.open(cache_fn, 'r', encoding='utf-8') as cachef:
-            except OSError:
+            except IOError:
-            write_json_file(cache_spec, cache_fn)
+            try:
-                return self._player_cache[player_url](s)
+                func = self._player_cache[player_url]
-import netrc
+import operator
-        id_m = re.match(r'.*-(?P<id>[a-zA-Z0-9]+)\.(?P<ext>[a-z]+)$',
+    def _extract_signature_function(self, video_id, player_url, slen):
-        # TODO read from filesystem cache
+        # Read from filesystem cache
-        elif player_tpye == 'swf':
+        elif player_type == 'swf':
-        # TODO write cache
+        if cache_dir is not False:
-                        video_id, player_url
+                        video_id, player_url, len(s)
-        _ = read_bytes(4)
+        _ = read_bytes(2 + 2)
-        return self._static_decrypt_signature(s)
+        return self._static_decrypt_signature(
-    def _static_decrypt_signature(self, s):
+    def _static_decrypt_signature(self, s, video_id, player_url, age_gate):
-                pos = p
+        def read_int(reader=None):
-                pos += 1
+                buf = reader.read(1)
-                assert res & 0xf0000000 == 0
+            return res
-            v, pos = read_int(data, pos)
+        def s32(reader=None):
-            return (res, pos + 1)
+            return v
-        p += 2 + 2
+        _ = read_bytes(4)
-        int_count, p = u30()
+        int_count = u30()
-        uint_count, p = u30()
+            _ = s32()
-        string_count, p = u30()
+            _ = u32()
-            s, p = string()
+            s = string()
-        namespace_count, p = u30()
+        namespace_count = u30()
-        ns_set_count, p = u30()
+            _ = read_bytes(1)  # kind
-            count, p = u30()
+            count = u30()
-        multiname_count, p = u30()
+                _ = u30()
-            kind, p = u30()
+            kind = u30()
-                name_idx, p = u30()
+                namespace_idx = u30()
-                    _, p = u30()
+                    _ = u30()
-        method_count, p = u30()
+        method_count = u30()
-            _, p = u30()  # return type
+            param_count = u30()
-            flags, p = read_byte()
+                _ = u30()  # param type
-                option_count, p = u30()
+                option_count = u30()
-                    p += 1        # kind
+                    _ = u30()  # val
-                    _, p = u30()  # param name
+                    _ = u30()  # param name
-        metadata_count, p = u30()
+        metadata_count = u30()
-            item_count, p = u30()
+            _ = u30()  # name
-            kind_full, pos = read_byte(pos=pos)
+                _ = u30()  # key
-                vindex, pos = u30(pos=pos)
+                _ = u30()  # Slot id
-                    _, pos = read_byte(pos=pos)  # vkind
+                    _ = read_byte()  # vkind
-                method_idx, pos = u30(pos=pos)
+                _ = u30()  # disp_id
-                _, pos = u30(pos=pos)  # classi
+                _ = u30()  # slot_id
-                function_idx, pos = u30(pos=pos)
+                _ = u30()  # slot_id
-                metadata_count, pos = u30(pos=pos)
+                metadata_count = u30()
-                    _, pos = u30(pos=pos)
+                    _ = u30()
-            return (methods, pos)
+            return methods
-        class_count, p = u30()
+        class_count = u30()
-            name_idx, p = u30()
+            name_idx = u30()
-            flags, p = read_byte()
+            _ = u30()  # super_name idx
-            intrf_count, p = u30()
+                protected_ns_idx = u30()
-            trait_count, p = u30()
+                _ = u30()
-                _, p = parse_traits_info()
+                _ = parse_traits_info()
-            trait_count, p = u30()
+            _ = u30()  # cinit
-                trait_methods, p = parse_traits_info()
+                trait_methods = parse_traits_info()
-        script_count, p = u30()
+        script_count = u30()
-            trait_count, p = u30()
+            _ = u30()  # init
-                _, p = parse_traits_info()
+                _ = parse_traits_info()
-        method_body_count, p = u30()
+        method_body_count = u30()
-            code_length, p = u30()
+            method_idx = u30()
-                m = Method(code_tag[p:p+code_length], local_count)
+                m = Method(code, local_count)
-            exception_count, p = u30()
+            exception_count = u30()
-            trait_count, p = u30()
+                _ = u30()  # from
-                _, p = parse_traits_info()
+                _ = parse_traits_info()
-        assert p == len(code_tag)
+        assert p + code_reader.tell() == len(code_tag)
-        self._jsplayer_cache = {}
+        self._player_cache = {}
-        id_m = re.match(r'.*-(?P<id>[^.]+)\.(?P<ext>[^.]+)$', player_url)
+        id_m = re.match(r'.*-(?P<id>[a-zA-Z0-9]+)\.(?P<ext>[a-z]+)$',
-                note=u'Downloading %s player %s' % (player_type, jsplayer_id),
+                note=u'Downloading %s player %s' % (player_type, player_id),
-            return self._parse_sig_js(code)
+            res = self._parse_sig_js(code)
-                note=u'Downloading %s player %s' % (player_type, jsplayer_id),
+                note=u'Downloading %s player %s' % (player_type, player_id),
-            return self._parse_sig_swf(code)
+            res = self._parse_sig_swf(code)
-    def _decrypt_signature(self, s, video_id, jsplayer_url, age_gate=False):
+    def _decrypt_signature(self, s, video_id, player_url, age_gate=False):
-        if jsplayer_url is not None:
+        if player_url is not None:
-                        video_id, jsplayer_url
+                if player_url not in self._player_cache:
-                return self._jsplayer_cache[jsplayer_url]([s])
+                    self._player_cache[player_url] = func
-                self._downloader.report_warning(u'Automatic signature extraction failed: ' + tb)
+                self._downloader.report_warning(
-        self._downloader.report_warning(u'Warning: Falling back to static signature algorithm')
+        self._downloader.report_warning(
-                                    player_url if player_url else 'NOT FOUND',
+                                player_version = self._search_regex(
-                                player_version = self._search_regex(r'html5player-(.+?)\.js', video_webpage,
+                                player_version = self._search_regex(
-                        else:
+                        if not age_gate:
-                            jsplayer_url = json.loads(jsplayer_url_json)
+                            player_url = json.loads(jsplayer_url_json)
-                        signature = self._decrypt_signature(encrypted_sig, video_id, jsplayer_url, age_gate)
+                        signature = self._decrypt_signature(
-        u'23456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!?#$%&\'()*+,-./:;<=>"'
+        u':/.-,+*)=\'&%$#"!ZYX0VUTSRQPONMLKJIHGFEDCBAzyxw>utsrqponmlkjihgfedcba987654321'
-                    elif opcode == 36:  # pushbyte
+                    if opcode == 36:  # pushbyte
-import xml.etree.ElementTree
+import string
-    def _decrypt_signature(self, s):
+    def _extract_signature_function(self, video_id, player_url):
-        elif len(s) == 92:
+        if jsplayer_url is not None:
-        mobj = re.search(r'swfConfig.*?"(http:\\/\\/.*?watch.*?-.*?\.swf)"', video_webpage)
+        mobj = re.search(r'swfConfig.*?"(https?:\\/\\/.*?watch.*?-.*?\.swf)"', video_webpage)
-                                player = 'flash player'
+                                player_version = self._search_regex(r'-(.+)\.swf$',
-                                player = u'html5 player %s' % self._search_regex(r'html5player-(.+?)\.js', video_webpage,
+                                player_version = self._search_regex(r'html5player-(.+?)\.js', video_webpage,
-                            parts_sizes = u'.'.join(compat_str(len(part)) for part in s.split('.'))
+                                player_desc = u'html5 player %s' % player_version
-                        encrypted_sig = url_data['s'][0]
+                                (len(encrypted_sig), parts_sizes, url_data['itag'][0], player_desc))
-                            signature = self._decrypt_signature_age_gate(encrypted_sig)
+                            jsplayer_url = None
-                            signature = self._decrypt_signature(encrypted_sig)
+                            jsplayer_url_json = self._search_regex(
-from ..utils import compat_urllib_parse_urlparse, compat_urlparse
+from ..utils import (
-                                         webpage, 'api url')
+            player = get_meta_content('twitter:player', webpage)
-from youtube_dl.extractor import DailymotionPlaylistIE, VimeoChannelIE, UstreamChannelIE, SoundcloudUserIE
+from youtube_dl.extractor import (
-from .dailymotion import DailymotionIE, DailymotionPlaylistIE
+from .dailymotion import (
-        playlist_id =  mobj.group('id')
+    def _extract_entries(self, id):
-                                             playlist_id, u'Downloading page %s' % pagenum)
+            webpage = self._download_webpage(self._PAGE_TEMPLATE % (id, pagenum),
-        entries = [self.url_result('http://www.dailymotion.com/video/%s' % video_id, 'Dailymotion')
+        return [self.url_result('http://www.dailymotion.com/video/%s' % video_id, 'Dailymotion')
-                'entries': entries,
+                'entries': self._extract_entries(playlist_id),
-    _VALID_URL = r'https?://www\.southparkstudios\.com/clips/(?P<id>\d+)'
+    _VALID_URL = r'https?://www\.southparkstudios\.com/(clips|full-episodes)/(?P<id>.+?)(\?|#|$)'
-        return itemdoc.find(search_path).attrib['url']
+        thumb_node = itemdoc.find(search_path)
-            u'description': u'Randy disqualifies South Park by getting into a fight with Bat Dad.',
+            u'description': u'Randy finally gets the chance to fight Bat Dad and gets the boys disqualified from the season championships.',
-        mgid = self._search_regex(r'swfobject.embedSWF\(".*?(mgid:.*?)"',
+        mgid = self._search_regex(r'data-mgid="(mgid:.*?)"',
-__version__ = '2013.09.20'
+__version__ = '2013.09.20.1'
-                    raise UnavailableVideoError(err)
+                except (OSError, IOError) as err:
-        video_url = self._search_regex(r'type="video/mp4" src="(.*?)"',
+        video_url = self._search_regex(
-__version__ = '2013.09.17'
+__version__ = '2013.09.20'
-        if len(s) == 92:
+        if len(s) == 93:
-import re,random
+import re
-    """Information Extractor for Fernsehkritik-TV"""
+    IE_NAME = u'fernsehkritik.tv'
-    def _real_extract(self,url):
+    _TEST = {
-        server = random.randint(2,4)
+
-        for i in range(1,4):
+        for i, _ in enumerate(files, 1):
-            video_url = 'http://dl%d.fernsehkritik.tv/fernsehkritik%d%s.flv' % (server, episode, '' if i==1 else '-%d'%i)
+            video_url = 'http://dl%d.fernsehkritik.tv/fernsehkritik%d%s.flv' % (server, episode, '' if i == 1 else '-%d' % i)
-                'title':    video_title,
+                'id': video_id,
-    """Information Extractor for Fernsehkritik-TV Postecke"""
+    IE_NAME = u'fernsehkritik.tv:postecke'
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        server = random.randint(2,4)
+
-        return[{
+        return {
-        }]
+        }
-            u"uploader" : u"Burn7",
+            u"uploader": u"Burn7",
-        uploader = self._html_search_regex(r',"artist":"([^"]+)",', webpage, 'music uploader', flags=re.DOTALL)
+        title = self._html_search_regex(r',"name":"([^"]+)",', webpage, u'music title')
-        music_url_json_string = '{"url":"' + self._html_search_regex(r'{"url":"([^"]+)",', webpage, 'music url', flags=re.DOTALL) + '"}'
+        music_url_json_string = self._html_search_regex(r'({"url":"[^"]+"),', webpage, u'music url') + '}'
-        return [{
+        return {
-            'title':    title,            
+            'title':    title,
-        }]
+        }
-        u'md5': u'2924d938f60415cd7afbe7ae9042a99e',
+        u'md5': u'fe6033d297591288fa1c1f780386f07a',
-        u'file': u'549479_B7---BusMode.mp3',
+        u'file': u'549479.mp3',
-            action='store_true', dest='ignoreerrors', help='continue on download errors', default=False)
+            action='store_true', dest='ignoreerrors', help='continue on download errors, for example to to skip unavailable videos in a playlist', default=False)
-    def _real_extract(self, url):
+    def _real_initialize(self):
-        login_results = compat_urllib_request.urlopen(request).info()
+        compat_urllib_request.urlopen(request).info()
-        webpage = compat_urllib_request.urlopen(request).read()
+    def _real_extract(self, url):
-                    r'name="description" content="(.*?)" />', webpage).group(1),
+                'title': self._og_search_title(webpage),
-                ).group(1)
+                'thumbnail': self._og_search_thumbnail(webpage)
-    _TEST = {
+    _VALID_URL = r'(?:http://)?(?:www\.)?xhamster\.com/movies/(?P<id>[0-9]+)/(?P<seo>.+?)\.html(?:\?.*)?'
-    }
+    },
-        mrss_url = 'http://xhamster.com/movies/%s/.html?hd' % video_id
+        seo = mobj.group('seo')
-    }
+    # Can't use tests, videos expire in 7 days
-        u'url': u"http://www.hotnewhiphop.com/freddie-gibbs-lay-it-down-song.1435540.html'",
+        u'url': u"http://www.hotnewhiphop.com/freddie-gibbs-lay-it-down-song.1435540.html",
-            u"title": u"Freddie Gibbs Songs - Lay It Down"
+            u"title": u"Freddie Gibbs - Lay It Down"
-                                player = 'flash player %s' % player_version
+                                player = 'flash player'
-__version__ = '2013.09.16'
+__version__ = '2013.09.17'
-     "T>/?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOvUY.REWQ0987654321mnbqcxzasdfghjklpoiuytr"),
+    ('0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&\'()*+,-./:;<=>?@[',
-            return s[40] + s[82:43:-1] + s[22] + s[42:40:-1] + s[83] + s[39:22:-1] + s[0] + s[21:2:-1]
+            return s[3:11] + s[0] + s[12:55] + s[84] + s[56:84]
-                'url': info['url'],
+                'url': info.get('ipad_url') or info['url'],
-        videos_info = self._search_regex(r'eval\("\((\[{.*?stream_redirect.*?}\])\)"\);', mobile_player, u'info').replace('\\"','"')
+        videos_info = self._search_regex(
-            self._screen_file.flush()
+            write_string(output, self._screen_file)
-            sys.stderr.write(u'[debug] Override config: ' + repr(overrideArguments) + '\n')
+            write_string(u'[debug] Override config: ' + repr(overrideArguments) + '\n')
-            sys.stderr.write(u'[debug] Command-line args: ' + repr(_hide_login_info(commandLineConf)) + '\n')
+            write_string(u'[debug] System config: ' + repr(_hide_login_info(systemConf)) + '\n')
-            sys.stderr.write(u'ERROR: unable to open cookie file\n')
+            write_string(u'ERROR: unable to open cookie file\n')
-                sys.stderr.write(u'[debug] Batch file urls: ' + repr(batchurls) + u'\n')
+                write_string(u'[debug] Batch file urls: ' + repr(batchurls) + u'\n')
-        sys.stderr.write(u'[debug] youtube-dl version ' + __version__ + u'\n')
+        write_string(u'[debug] youtube-dl version ' + __version__ + u'\n')
-                sys.stderr.write(u'[debug] Git HEAD: ' + out + u'\n')
+                write_string(u'[debug] Git HEAD: ' + out + u'\n')
-        sys.stderr.write(u'[debug] Proxy map: ' + str(proxy_handler.proxies) + u'\n')
+        write_string(u'[debug] Python version %s - %s' %(platform.python_version(), platform_name()) + u'\n')
-__version__ = '2013.09.12'
+__version__ = '2013.09.16'
-    res = advapi32.OpenSCManagerA(None, None, SC_MANAGER_ALL_ACCESS)
+    res = advapi32.OpenSCManagerW(None, None, SC_MANAGER_ALL_ACCESS)
-        h = advapi32.CreateServiceA(
+        h = advapi32.CreateServiceW(
-        h = advapi32.OpenServiceA(manager, service_name, DELETE)
+        h = advapi32.OpenServiceW(manager, service_name, DELETE)
-    win_install_service('youtubedl_builder', cmdline)
+def win_service_report_event(service_name, msg, is_error=True):
-    win_uninstall_service('youtubedl_builder')
+def win_service_main(service_name, real_main, argc, argv_raw):
-def main(argv):
+
-                        action='store_const', dest='action', const='servce',
+                        action='store_const', dest='action', const='service',
-    options = parser.parse_args()
+    options = parser.parse_args(args=args)
-        return install_service(options.bind)
+        fn = os.path.abspath(__file__).replace('v:', '\\\\vboxsrv\\vbox')
-        return uninstall_service()
+        win_uninstall_service(SVCNAME)
-    main(sys.argv[1:])
+    main()
-                            tube\.majestyc\.net/)                             # the various hostnames, with wildcard subdomains
+                            tube\.majestyc\.net/|
-from youtube_dl.extractor import DailymotionPlaylistIE, VimeoChannelIE, UstreamChannelIE
+from youtube_dl.extractor import DailymotionPlaylistIE, VimeoChannelIE, UstreamChannelIE, SoundcloudUserIE
-from .soundcloud import SoundcloudIE, SoundcloudSetIE
+from .soundcloud import SoundcloudIE, SoundcloudSetIE, SoundcloudUserIE
-    def _extract_info_dict(self, info, full_title=None):
+    def _extract_info_dict(self, info, full_title=None, quiet=False):
-        self.report_extraction(name)
+        if quiet == False:
-        info['ext'] = determine_ext(formats[-1]['url'])
+        info.update(formats[-1])
-        return info
+        return info
-        info['ext'] = determine_ext(formats[-1]['url'])
+        info.update(formats[-1])
-        return info
+        return info
-        info['ext'] = formats[-1]['format'].partition('-')[0]
+        info.update(formats[-1])
-    ExtractorError,
+    unified_strdate,
-        return url_list
+    _TEST = {
-        }]
+        uploader = mobj.group(1)
-    format_expressions = ['%d %B %Y', '%B %d %Y', '%b %d %Y', '%Y-%m-%d', '%d/%m/%Y', '%Y/%m/%d %H:%M:%S', '%d.%m.%Y %H:%M']
+    format_expressions = [
-                                       self.params.get('allsubtitles', False)])
+                                       self.params.get('writeautomaticsub')])
-                    self._downloader.params.get('allsubtitles', False)])
+                    self._downloader.params.get('writeautomaticsub')])
-        if self._downloader.params.get('writesubtitles', False) or self._downloader.params.get('allsubtitles', False):
+        if self._downloader.params.get('writesubtitles', False):
-        upload_date = self._html_search_regex('title="Timestamp">(.*?)</a>',
+        upload_date = self._html_search_regex(
-    _VALID_URL = r'(?:http://)?(?:www.)?xhamster\.com/movies/(?P<id>[0-9]+)/.*\.html'
+    _VALID_URL = r'(?:http://)?(?P<url>(?:www\.)?xhamster\.com/movies/(?P<id>[0-9]+)/.*\.html(?:\?.*)?)'
-        mrss_url = 'http://xhamster.com/movies/%s/.html' % video_id
+        mrss_url = 'http://' +  mobj.group('url')
-from youtube_dl.utils import find_xpath_attr
+from youtube_dl.utils import (
-    compat_html_parser,
+    get_meta_content,
-
+        webpage = self._download_webpage(url, slug)
-        p = SocialstreamParser()
+        video_ids = []
-            p.feed(reply['data'])
+            video_ids.extend(re.findall(r'data-content-id="(\d.*)"', reply['data']))
-class AttrParser(compat_html_parser.HTMLParser):
+class BaseHTMLParser(compat_html_parser.HTMLParser):
-        compat_html_parser.HTMLParser.__init__(self)
+        BaseHTMLParser.__init__(self)
-
+class MetaParser(BaseHTMLParser):
-#!/usr/bin/python
+#!/usr/bin/python3
-import getopt, threading, sys, urlparse, _winreg, os, subprocess, shutil, tempfile
+from http.server import HTTPServer, BaseHTTPRequestHandler
-    sys.exit(0)
+advapi32 = ctypes.windll.advapi32
-    print 'Listening on %s:%d' % (host, port)
+def win_OpenSCManager():
-    raw_input('Hit <ENTER> to stop...\n')
+    input('Press ENTER to shut down')
-            os.chmod(fname, 0666)
+            os.chmod(fname, 0o666)
-            print 'WARNING deleting "%s": %s' % (self.basePath, e)
+            print('WARNING deleting "%s": %s' % (self.basePath, e))
-            u"title": u"Arma III - Community Guide: SITREP I",
+            u"title": u"Arma 3 - Community Guide: SITREP I",
-    # 82 - vflZK4ZYR 2013/08/23
+    # 82 - vflGNjMhJ 2013/09/12
-     "wertyuioplkjhgfdsaqxcvbnm1234567890QWERTYUIOPLKHGFDSAZXCVBNM!@#$%^&z(-+={[};?/>.<"),
+     ".>/?;}[<=+-(*&^%$#@!MNBVCXeASDFGHKLPOqUYTREWQ0987654321mnbvcxzasdfghjklpoiuytrIwZ"),
-            return s[1:19] + s[0] + s[20:68] + s[19] + s[69:82]
+            return s[80:73:-1] + s[81] + s[72:54:-1] + s[2] + s[53:43:-1] + s[0] + s[42:2:-1] + s[43] + s[1] + s[54]
-    _VALID_URL = r'https?://(www\.canalplus\.fr/.*?\?vid=|player\.canalplus\.fr/#/)(?P<id>\d+)'
+    _VALID_URL = r'https?://(www\.canalplus\.fr/.*?/(?P<path>.*)|player\.canalplus\.fr/#/(?P<id>\d+))'
-        u'md5': u'590a888158b5f0d6832f84001fbf3e99',
+        u'url': u'http://www.canalplus.fr/c-infos-documentaires/pid1830-c-zapping.html?vid=922470',
-            u'upload_date': u'20130620',
+            u'title': u'Zapping - 26/08/13',
-        u'skip': u'Requires rtmpdump'
+        if video_id is None:
-
+#!/usr/bin/python
-from .ustream import UstreamIE
+from .ustream import UstreamIE, UstreamChannelIE
-        video_url = self._search_regex(r'type: "video/mp4", src: "(.*?)"',
+        video_url = self._search_regex(r'type="video/mp4" src="(.*?)"',
-__version__ = '2013.11.09'
+__version__ = '2013.09.12'
-        else:
+        """
-            original_lang = caption_list.find('track').attrib['lang_code']
+            original_lang_node = caption_list.find('track')
-    def _list_available_subtitles(self, video_id):
+    def _list_available_subtitles(self, video_id, webpage=None):
-            self._list_available_subtitles(video_id)
+            self._list_available_subtitles(video_id, video_webpage)
-    def _extract_subtitles(self, video_id):
+    def extract_subtitles(self, video_id, video_webpage=None):
-        available_subs_list = self._get_available_subtitles(video_id)
+        if self._downloader.params.get('writesubtitles', False) or self._downloader.params.get('allsubtitles', False):
-                    requested_langs = [list(available_subs_list.keys())[0]]
+            if self._downloader.params.get('subtitleslangs', False):
-                    sub_lang_list[sub_lang] = available_subs_list[sub_lang]
+            sub_lang_list = {}
-    def _request_automatic_caption(self, video_id, webpage):
+    def _get_available_automatic_caption(self, video_id, webpage):
-        returns {sub_lang: sub} or {} if not available
+        returns {sub_lang: url} or {} if not available
-        return video_subtitles
+import xml.etree.ElementTree
-    def _request_automatic_caption(self, video_id, webpage):
+    def _get_available_automatic_caption(self, video_id, webpage):
-        err_msg = u'Couldn\'t find automatic captions for "%s"' % sub_lang
+        err_msg = u'Couldn\'t find automatic captions for %s' % video_id
-                'kind': 'asr',
+            # We get the available subtitles
-            return {sub_lang: sub}
+            list_url = caption_url + '&' + list_params
-        webpage = self._download_webpage(webpage_url, video_id)
+        webpage = self._download_webpage(url, video_id)
-        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
+            sub_list = self._download_webpage(
-    compat_urllib_request,
+    ExtractorError,
-        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
+            sub = self._download_webpage(url, None, note=False)
-        except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
+            sub_list = self._download_webpage(
-from .subtitles import NoAutoSubtitlesInfoExtractor
+from .subtitles import SubtitlesInfoExtractor
-class DailymotionIE(NoAutoSubtitlesInfoExtractor):
+class DailymotionIE(SubtitlesInfoExtractor):
-
+        video_subtitles = self.extract_subtitles(video_id)
-        """ Must be redefined by the subclasses """
+        """
-        pass
+        """
-            video_subtitles = self._request_automatic_caption(video_id, video_webpage)
+        video_subtitles = self.extract_subtitles(video_id, video_webpage)
-from .subtitles import NoAutoSubtitlesIE
+from .subtitles import NoAutoSubtitlesInfoExtractor
-class DailymotionIE(NoAutoSubtitlesIE):
+class DailymotionIE(NoAutoSubtitlesInfoExtractor):
-class SubtitlesIE(InfoExtractor):
+class SubtitlesInfoExtractor(InfoExtractor):
-class NoAutoSubtitlesIE(SubtitlesIE):
+class NoAutoSubtitlesInfoExtractor(SubtitlesInfoExtractor):
-from .subtitles import SubtitlesIE
+from .subtitles import SubtitlesInfoExtractor
-class YoutubeBaseInfoExtractor(SubtitlesIE):
+class YoutubeBaseInfoExtractor(InfoExtractor):
-class YoutubeIE(YoutubeBaseInfoExtractor):
+class YoutubeIE(YoutubeBaseInfoExtractor, SubtitlesInfoExtractor):
-class DailymotionIE(DailyMotionSubtitlesIE, InfoExtractor):
+class DailymotionIE(NoAutoSubtitlesIE):
-class YoutubeBaseInfoExtractor(InfoExtractor):
+class YoutubeBaseInfoExtractor(SubtitlesIE):
-class YoutubeIE(YoutubeSubtitlesIE, YoutubeBaseInfoExtractor):
+class YoutubeIE(YoutubeBaseInfoExtractor):
-    for ie in sorted(youtube_dl.gen_extractors(), key=lambda i: i.IE_NAME):
+    for ie in sorted(youtube_dl.gen_extractors(), key=lambda i: i.IE_NAME.lower()):
-__version__ = '2013.09.10'
+__version__ = '2013.11.09'
-    # 85
+    # 85 - vflkuzxcs 2013/09/11
-     ".>/?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWQ0q876543r1mnbvcx9asdfghjklpoiuyt2"),
+     "T>/?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOvUY.REWQ0987654321mnbqcxzasdfghjklpoiuytr"),
-            return s[83:34:-1] + s[0] + s[33:27:-1] + s[3] + s[26:19:-1] + s[34] + s[18:3:-1] + s[27]
+            return s[40] + s[82:43:-1] + s[22] + s[42:40:-1] + s[83] + s[39:22:-1] + s[0] + s[21:2:-1]
-from .francetv import PluzzIE
+from .francetv import (
-class PluzzIE(InfoExtractor):
+class FranceTVBaseInfoExtractor(InfoExtractor):
-        thumbnail_path = info.find('image').text
+class FranceTvInfoIE(FranceTVBaseInfoExtractor):
-                }
+    _TEST = {
-    _IE_NAME = 'canalc2.tv'
+    IE_NAME = 'canalc2.tv'
-__version__ = '2013.09.07'
+__version__ = '2013.09.10'
-    _VALID_URL = r'https?://tv\.sohu\.com/\d+?/n(?P<id>\d+)\.shtml.*?'
+    _VALID_URL = r'https?://(?P<mytv>my\.)?tv\.sohu\.com/.+?/(?(mytv)|n)(?P<id>\d+)\.shtml.*?'
-            base_data_url = u'http://hot.vrs.sohu.com/vrs_flash.action?vid='
+        def _fetch_data(vid_id, mytv=False):
-        vid = self._html_search_regex(r'var vid="(\d+)"', webpage,
+        vid = self._html_search_regex(r'var vid ?= ?["\'](\d+)["\']', webpage,
-        data = _fetch_data(vid)
+        data = _fetch_data(vid, mytv)
-        format_data = data if vid == vid_id else _fetch_data(vid_id)
+        format_data = data if vid == vid_id else _fetch_data(vid_id, mytv)
-        (hours, eta_mins) = divmod(mins, 60)
+        (hours, mins) = divmod(mins, 60)
-        self.assertEqual(YoutubeIE()._extract_id('https://www.youtube.com/watch_popup?v=BaW_jenozKc'), 'BaW_jenozKc')
+        assertExtractId = lambda url, id: self.assertEqual(YoutubeIE()._extract_id(url), id)
-                     ([0-9A-Za-z_-]+)                                         # here is it! the YouTube video ID
+                     ([0-9A-Za-z_-]{11})                                      # here is it! the YouTube video ID
-            itag = self._search_regex(r'itag%3D(\d+?)/', format_url, 'itag')
+            itag = self._search_regex(r'itag/(\d+?)/', format_url, 'itag')
-__version__ = '2013.09.06.1'
+__version__ = '2013.09.07'
-    _VALID_URL = r'(?i)(?:https?://)?(?:www\.)?dailymotion\.[a-z]{2,3}/video/([^/]+)'
+    _VALID_URL = r'(?i)(?:https?://)?(?:www\.)?dailymotion\.[a-z]{2,3}/(?:embed/)?video/([^/]+)'
-        self.DL.params['subtitleslang'] = 'fr'
+        self.DL.params['subtitleslangs'] = ['fr']
-    def test_list_subtitles(self): #ojo
+    def test_list_subtitles(self):
-        self.DL.params['subtitleslang'] = 'en'
+        self.DL.params['subtitleslang'] = ['en']
-        self.DL.params['subtitleslang'] = 'it'
+        self.DL.params['subtitleslangs'] = ['it']
-        self.DL.params['subtitleslang'] = 'it'
+        self.DL.params['subtitleslangs'] = ['it']
-
+    def test_youtube_multiple_langs(self):
-    subtitleslang:     Language of the subtitles to download
+    subtitleslangs:     Language of the subtitles to download
-            help='language of the subtitles to download (optional) use IETF language tags like \'en\'')
+    subtitles.add_option('--sub-lang', '--sub-langs', '--srt-lang',
-        'subtitleslang': opts.subtitleslang,
+        'subtitleslangs': opts.subtitleslangs,
-        if not sub_lang_list:  # error, it didn't get the available subtitles
+        available_subs_list = self._get_available_subtitles(video_id)
-            sub_lang_list = {sub_lang: sub_lang_list[sub_lang]}
+                sub_lang_list = {}
-        for sub_lang, url in sub_lang_list.iteritems():
+        for sub_lang, url in sub_lang_list.items():
-        sub_lang = self._downloader.params.get('subtitleslang') or 'en'
+        sub_lang = (self._downloader.params.get('subtitleslangs') or ['en'])[0]
-        self.assertFalse(YoutubePlaylistIE.suitable(u'PLtS2H6bU1M'))
+        assertPlaylist = lambda url: self.assertMatch(url, ['youtube:playlist'])
-        self.assertTrue(YoutubeChannelIE.suitable('https://www.youtube.com/channel/HCtnHdj3df7iM/videos'))
+        assertChannel = lambda url: self.assertMatch(url, ['youtube:channel'])
-        if YoutubePlaylistIE.suitable(url) or YoutubeSubscriptionsIE.suitable(url): return False
+        if YoutubePlaylistIE.suitable(url): return False
-        if YoutubeIE.suitable(url) or YoutubeFavouritesIE.suitable(url): return False
+        # Don't return True if the url can be extracted with other youtube
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?)|ytuser:)([A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?)|ytuser:)(?!feed/)([A-Za-z0-9_-]+)'
-        if YoutubeIE.suitable(url): return False
+        if YoutubeIE.suitable(url) or YoutubeFavouritesIE.suitable(url): return False
-import urllib.request
+import os.path
-__version__ = '2013.09.06'
+__version__ = '2013.09.06.1'
-    data = urllib.request.urlopen(url).read()
+    fn = os.path.join(build_dir, filename)
-    _VIDEO_INDICATOR = r'/watch\?v=(.+?)[\<&]'
+    _GDATA_URL = 'http://gdata.youtube.com/feeds/api/users/%s/uploads?max-results=%d&start-index=%d&alt=json'
-
+            for entry in response['feed']['entry']:
-            itag = self._search_regex(r'itag/(\d+?)/', format_url, 'itag')
+            itag = self._search_regex(r'itag%3D(\d+?)/', format_url, 'itag')
-__version__ = '2013.09.05'
+__version__ = '2013.09.06'
-            return s[81:73:-1] + s[84] + s[72:58:-1] + s[0] + s[57:35:-1] + s[85] + s[34:0:-1]
+            return s[5:34] + s[0] + s[35:38] + s[3] + s[39:45] + s[38] + s[46:53] + s[73] + s[54:73] + s[85] + s[74:85] + s[53]
-        self.assertEqual(matching_ies(':cr'), ['ComedyCentral'])
+        self.assertMatch(':ytsubs', ['youtube:subscriptions'])
-                         (?:youtu\.be/|(?:\w+\.)?youtube(?:-nocookie)?\.com/|
+                         (?:(?:(?:(?:\w+\.)?youtube(?:-nocookie)?\.com/|
-                         )?                                                   # optional -> youtube.com/xxxx is OK
+                         ))
-    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/user/)|ytuser:)([A-Za-z0-9_-]+)'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:user/)?)|ytuser:)([A-Za-z0-9_-]+)'
-__version__ = '2013.09.04'
+__version__ = '2013.09.05'
-                    videos.append((index, entry['media$group']['media$player']['url']))
+                if 'media$group' in entry and 'yt$videoid' in entry['media$group']:
-            mobj = re.search(r'<video[^<]*>.*?<source .*?src="([^"]+)"', webpage, flags=re.DOTALL)
+            mobj = re.search(r'<video[^<]*(?:>.*?<source.*?)? src="([^"]+)"', webpage, flags=re.DOTALL)
-        video_url = compat_urllib_parse.unquote(mobj.group(1))
+        video_url = mobj.group(1)
-        video_id = os.path.basename(video_url)
+        video_id = compat_urllib_parse.unquote(os.path.basename(video_url))
-        webpage = self._download_webpage(url, video_id)
+        canonical_url = 'http://tvpot.daum.net/v/%s' % video_id
-__version__ = '2013.08.30'
+__version__ = '2013.09.04'
-                          # AHLS
+                          # Apple HTTP Live Streaming
-                                      # AHLS
+                                      # Apple HTTP Live Streaming
-        # AHLS
+        # Apple HTTP Live Streaming
-        'ligthboxvideo/base-de-medias/webtv/(.*)')
+        r'ligthboxvideo/base-de-medias/webtv/(.*)')
-        'base-de-medias/webtv/attaque-chimique-syrienne-du-21-aout-2013-1')
+        u'url': (u'http://www.defense.gouv.fr/layout/set/ligthboxvideo/'
-        info = self._search_regex(r'var info = ({.*?}),', embed_page, 'video info')
+        info = self._search_regex(r'var info = ({.*?}),$', embed_page,
-        else: video_description = u''
+        video_description = None
-            config = webpage.split(' = {config:')[1].split(',assets:')[0]
+            config = self._search_regex([r' = {config:({.+?}),assets:', r'c=({.+?);'],
-        video_thumbnail = config["video"]["thumbnail"]
+        video_thumbnail = config["video"].get("thumbnail")
-                if 'hd' in config["video"]["files"][codec_name]:
+            if codec_name in config_files:
-                elif 'sd' in config["video"]["files"][codec_name]:
+                elif 'sd' in config_files[codec_name]:
-                    files['other'].append((codec_name, codec_extension, config["video"]["files"][codec_name][0]))
+                    files['other'].append((codec_name, codec_extension, config_files[codec_name][0]))
-                    %(video_id, sig, timestamp, video_quality, video_codec.upper())
+        video_url = None
-                r'submitter=(.*?);|googletag\.pubads\(\)\.setTargeting\("channel","([^"]+)"\);',
+                r'submitter=(.*?);|googletag\.pubads\(\)\.setTargeting\("(?:channel|submiter)","([^"]+)"\);',
-            help='video format code, specifiy the order of preference using slashes: "-f 22/17/18"')
+            help='video format code, specifiy the order of preference using slashes: "-f 22/17/18". "-f mp4" and "-f flv" are also supported')
-                          '95', '94', '93', '92', '132', '151',
+    _available_formats = ['38', '37', '46', '22', '45', '35', '44', '34', '18', '43', '6', '5', '36', '17', '13',
-                                      '95', '94', '93', '92', '132', '151',
+    _available_formats_prefer_free = ['38', '46', '37', '45', '22', '44', '35', '43', '34', '18', '6', '5', '36', '17', '13',
-        '17': 'mp4',
+        '17': '3gp',
-        # videos that use m3u8
+        # AHLS
-            # For example, if '1/2/3/4' is requested and '2' and '4' are available, we pick '2'.
+            # Format can be specified as itag or 'mp4' or 'flv' etc. We pick the highest quality
-__version__ = '2013.08.29'
+__version__ = '2013.08.30'
-    # 86 - vflg0g8PQ 2013/08/29
+    # 86 - vflHOr_nV 2013/08/30
-     ">/?;}|[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWq0987654321mnbvcxzasdfghjklpoiuytr"),
+     "?;}|[{=+._)(*&^%$#@!MNBqCXZASDFGHJKLPOIUYTREWQ<987654321mnbvcxzasdfghjklpoiuytrew"),
-            return s[83:36:-1] + s[0] + s[35:2:-1]
+            return s[81:73:-1] + s[84] + s[72:58:-1] + s[0] + s[57:35:-1] + s[85] + s[34:0:-1]
-    _VALID_URL = r'https?://www\.youtube\.com/my_favorites|:ytfav(?:o?rites)?'
+    _VALID_URL = r'https?://www\.youtube\.com/my_favorites|:ytfav(?:ou?rites)?'
-__version__ = '2013.08.28.1'
+__version__ = '2013.08.29'
-    # 84 - vflh9ybst 2013/08/23 (sporadic)
+    # 84 - vflg0g8PQ 2013/08/29 (sporadic)
-     "yuioplkjhgfdsazxcvbnm1234567890QWERrYUIOPLKqHGFDSAZXCVBNM!@#$%^&*()_-+={[};?>.<"),
+     ">?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWq0987654321mnbvcxzasdfghjklpoiuytr"),
-            return s[5:40] + s[3] + s[41:48] + s[0] + s[49:84]
+            return s[81:36:-1] + s[0] + s[35:2:-1]
-    # 86 - vflh9ybst 2013/08/23
+    # 86 - vflg0g8PQ 2013/08/29
-     "yuioplkjhgfdsazxcvbnm1234567890QWERrYUIOPLKqHGFDSAZXCVBNM!@#$%^&*()_-+={[|};?/>.<"),
+     ">/?;}|[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWq0987654321mnbvcxzasdfghjklpoiuytr"),
-            return s[5:40] + s[3] + s[41:48] + s[0] + s[49:86]
+            return s[83:36:-1] + s[0] + s[35:2:-1]
-    _VALID_URL = r'https?://gamevideos.1up.com/video/id/(?P<name_or_id>.+)'
+    _VALID_URL = r'https?://gamevideos.1up.com/(?P<type>video)/id/(?P<name_or_id>.+)'
-    _VALID_URL = r'https?://.+?\.ign\.com/(?:videos|show_videos)(/.+)?/(?P<name_or_id>.+)'
+    _VALID_URL = r'https?://.+?\.ign\.com/(?P<type>videos|show_videos|articles)(/.+)?/(?P<name_or_id>.+)'
-        assert re.match(r'^[a-zA-Z@\s]*$', val)
+        assert re.match(r'^[a-zA-Z0-9@\s]*$', val)
-            u'description': u'md5:75e8439a3e2981cd5d4b6db232e8fdfc',
+            u'description': u'md5:104892c71bd48e55d70b902736b81bbf',
-                u"description": u"md5:b085c9804f5ab69f4adea963a2dceb3c",
+                u"description": u"md5:3e2666e0a55044490499ea45fe9037b7",
-                        self.assertEqual(expected, 'md5:' + md5(info_dict.get(info_field)))
+                        got = 'md5:' + md5(info_dict.get(info_field))
-                            u'invalid value for field %s, expected %r, got %r' % (info_field, expected, got))
+                    self.assertEqual(expected, got,
-            m = re.search(br'<meta[^>]+charset="?([^"]+)[ /">]',
+            m = re.search(br'<meta[^>]+charset=[\'"]?([^\'")]+)[ /\'">]',
-        webpage = self._download_webpage(
+        raw_page = self._download_webpage(
-            note=u'Downloading embed page')
+        clean_page = re.compile(u'<!--.*?-->', re.S).sub(u'', raw_page)
-        formats_json = self._search_regex(r'bitrates: (\[.+?\])', embed_page,
+            raw_page, u'base url')
-        description = clean_html(get_element_by_id('edit-description', webpage))
+        title = get_element_by_id('edit-title', clean_page)
-            embed_page, u'thumbnail', flags=re.DOTALL)
+            raw_page, u'thumbnail', flags=re.DOTALL)
-__version__ = '2013.08.28'
+__version__ = '2013.08.28.1'
-        if video_url.split('/')[6].split('_')[0] == u'720p': # only add if 720p to avoid duplicates
+        # Get link of hd video if available
-from .utils import bytes_to_intlist
+from .utils import bytes_to_intlist, intlist_to_bytes
-    plaintext = ''.join(map(lambda x: chr(x), decrypted_data))
+    plaintext = intlist_to_bytes(decrypted_data)
-    block_count = int(ceil(float(len(data)) // BLOCK_SIZE_BYTES))
+    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))
-            sys.stderr.write(u'[debug] Command-line args: ' + repr(commandLineConf) + '\n')
+            sys.stderr.write(u'[debug] System config: ' + repr(_hide_login_info(systemConf)) + '\n')
-    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))
+    block_count = int(ceil(float(len(data)) // BLOCK_SIZE_BYTES))
-    expanded_key_size_bytes = (key_size_bytes/4 + 7) * BLOCK_SIZE_BYTES
+    expanded_key_size_bytes = (key_size_bytes // 4 + 7) * BLOCK_SIZE_BYTES
-    rounds = len(expanded_key) / BLOCK_SIZE_BYTES - 1
+    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1
-    password = map(lambda c: ord(c), password.encode('utf-8'))
+    data = bytes_to_intlist(base64.b64decode(data))
-    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes / BLOCK_SIZE_BYTES)
+    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)
-    return map(lambda x: SBOX[x], data)
+    return [SBOX[x] for x in data]
-    return map(lambda (x,y): x^y, zip(data1, data2))
+    return [x^y for x, y in zip(data1, data2)]
-        encrypted_video_url = self._html_search_regex(r'var encryptedURL = \'(?P<encrypted_video_url>[a-zA-Z0-9+/]+={0,2})\';',
+        encrypted_video_url = self._html_search_regex(
-        video_url = unicode( aes_decrypt_text(encrypted_video_url, video_title, 32), 'utf-8')
+        video_url = aes_decrypt_text(encrypted_video_url, video_title, 32)
-        if(len(links) == 0):
+        if not links:
-        req_format = self._downloader.params.get('format', None)
+        req_format = self._downloader.params.get('format', 'best')
-        webpage_bytes = urlh.read()
+            m = re.search(br'<meta[^>]+charset="?([^"]+)[ /">]',
-import urllib2
+import re
-from ..utils import compat_urllib_request, clean_html
+from ..utils import ExtractorError
-        u'md5': u'cc84eed6b6fbf0f2f9a8d3cb9da1939b',
+        u'file': u'382479172.mp4',
-            u'title': u'The Illest - Far East Movement Riff Raff',
+            u'title': u'MVï¼Far East MovementãThe Illestã',
-
+
-            download_url = '%s%s?key=%s' % (middle_info[0], su[i], middle_info[3])
+        raw_title = self._html_search_regex(r'(?s)<title>(.+?)</title>',
-            info = {
+        vid = self._html_search_regex(r'var vid="(\d+)"', webpage,
-                'url': download_url,
+                'url': video_url,
-            info =  files_info[0]
+            playlist.append(video_info)
-        return files_info
+        else:
-            raise AudioConversionError(err.message)
+            raise AudioConversionError(err.msg)
-                msg = u'audio conversion failed: ' + e.message
+                msg = u'audio conversion failed: ' + e.msg
-        sys.stderr.write(u'[debug] Python version %s - %s' %(platform.python_version(), platform.platform()) + u'\n')
+        sys.stderr.write(u'[debug] Python version %s - %s' %(platform.python_version(), platform_name()) + u'\n')
-import datetime
+
-    compat_urllib_parse_urlparse,
+    compat_urlparse,
-                             up.path.rpartition('/')[0] + '/' + video_url)
+        video_url = compat_urlparse.urljoin(url, video_url)
-            compat_print(info_dict['url'])
+            # For RTMP URLs, also include the playpath
-            video_url = url + ('' if url.endswith('/') else '/') + video_url
+            up = compat_urllib_parse_urlparse(url)
-            resp = self.addinfourl_wrapper(gz, old_resp.headers, old_resp.url, old_resp.code)
+            content = resp.read()
-            return '%02d:%02d:%02d' % (eta_hours, eta_mins, eta_secs)
+        return FileDownloader.format_seconds(eta)
-                (clear_line, data_len_str, int(tot_time)))
+            self.to_screen(u'\r%s[download] 100%% of %s in %s' %
-    # 88
+    # 88 - vflapUV9V 2013/08/28
-     "J:|}][{=+-_)(*&;%$#@>MNBVCXZASDFGH^KLPOIUYTREWQ0987654321mnbvcxzasdfghrklpoiuytej"),
+     "ioplkjhgfdsazxcvbnm12<4567890QWERTYUIOZLKJHGFDSAeXCVBNM!@#$%^&*()_-+={[]}|:;?/>.3"),
-            return s[48] + s[81:67:-1] + s[82] + s[66:62:-1] + s[85] + s[61:48:-1] + s[67] + s[47:12:-1] + s[3] + s[11:3:-1] + s[2] + s[12]
+            return s[7:28] + s[87] + s[29:45] + s[55] + s[46:55] + s[2] + s[56:87] + s[28]
-    from http.error import HTTPError as compat_HTTPError
+    from urllib.error import HTTPError as compat_HTTPError
-    _VALID_URL = r'https?://(edition\.)?cnn\.com/video/(data/.+?|\?)/(?P<path>.+?/(?P<title>[^/]+?)\.cnn)'
+    _VALID_URL = r'''(?x)https?://(edition\.)?cnn\.com/video/(data/.+?|\?)/
-    _TEST = {
+    _TESTS = [{
-    }
+    },
-            'http://cnn.com/video/data/3.0/%s/index.xml' % path, page_title)
+        info_url = u'http://cnn.com/video/data/3.0/%s/index.xml' % path
-__version__ = '2013.08.27'
+__version__ = '2013.08.28'
-        return YoutubeDLHandlerHTTPS()
+        return compat_urllib_request.HTTPSHandler()
-        return YoutubeDLHandlerHTTPS(context=context)
+        return compat_urllib_request.HTTPSHandler(context=context)
-class YoutubeDLHandler_Template:  # Old-style class, like HTTPHandler
+class YoutubeDLHandler(compat_urllib_request.HTTPHandler):
-        for h, v in std_headers.items():
+    def http_request(self, req):
-    def _http_response(self, req, resp):
+    def http_response(self, req, resp):
-
+    https_request = http_request
-        video_page = self._search_regex(r'<a href="((?:%s)?/photos/.*?)"' % re.escape(DOMAIN),
+        DOMAIN = 'https://plus.google.com/'
-"""Extractor for canalc2.tv"""
+
-    """Extractor for canalc2.tv"""
+    _IE_NAME = 'canalc2.tv'
-        u'md5': u'c00fa80517373764ff5c0b5eb5a58780',
+        u'md5': u'060158428b650f896c542dfbb3d6487f',
-        
+        file_name = self._search_regex(
-            webpage, u'title')
+        title = self._html_search_regex(
-                'title' : title
+                'ext': 'mp4',
-            u"title": u"Obama: 'Beyond The Afghan Theater, We Only Target Al Qaeda' On May 23, 2013 ",
+            u'title': u"Obama: 'Beyond The Afghan Theater, We Only Target Al Qaeda' on May 23, 2013",
-                                'Sound Clip , Quote, MP3, and Ringtone - Hark','')
+        json_url = "http://www.hark.com/clips/%s.json" %(video_id)
-                'title': title,
+                'title': info['name'],
-    _VALID_URL = r'https?://www\.canalplus\.fr/.*?\?vid=(?P<id>\d+)'
+    _VALID_URL = r'https?://(www\.canalplus\.fr/.*?\?vid=|player\.canalplus\.fr/#/)(?P<id>\d+)'
-__version__ = '2013.08.23'
+__version__ = '2013.08.27'
-from .ustream import UstreamIE
+from .ustream import UstreamIE
-from .c56 import C56IE
+import json
-        u'md5': u'9dc07b5c8e978112a6441f9e75d2b59e',
+        u'file': u'93440716.flv',
-            u"uploader": u"Alex and Van .", 
+            u"uploader": u"Amphora Alex and Van .", 
-        # Look for BrigthCove:
+        # Look for BrightCove:
-                u"uploader": u"www.hodiho.fr", 
+                u"uploader": u"www.hodiho.fr",
-        return compat_urllib_request.HTTPSHandler()
+        return YoutubeDLHandlerHTTPS()
-        return compat_urllib_request.HTTPSHandler(context=context)
+        return YoutubeDLHandlerHTTPS(context=context)
-class YoutubeDLHandler(compat_urllib_request.HTTPHandler):
+
-        for h,v in std_headers.items():
+    def _http_request(self, req):
-    def http_response(self, req, resp):
+    def _http_response(self, req, resp):
-    https_response = http_response
+
-    _VALID_URL = r'(?:http://)?(?P<url>(?P<base_url>rtl(?:(?P<is_rtl2>2)|-)now\.rtl(?(is_rtl2)2|)\.de/|(?:www\.)?voxnow\.de/)[a-zA-Z0-9-]+/[a-zA-Z0-9-]+\.php\?(?:container_id|film_id)=(?P<video_id>[0-9]+)&player=1(?:&season=[0-9]+)?(?:&.*)?)'
+    """Information Extractor for RTL NOW, RTL2 NOW, SUPER RTL NOW and VOX NOW"""
-    # 84
+    # 84 - vflh9ybst 2013/08/23 (sporadic)
-     "<.>?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWQ09876543q1mnbvcxzasdfghjklpoiuew2"),
+     "yuioplkjhgfdsazxcvbnm1234567890QWERrYUIOPLKqHGFDSAZXCVBNM!@#$%^&*()_-+={[};?>.<"),
-            return s[83:27:-1] + s[0] + s[26:5:-1] + s[2:0:-1] + s[27]
+            return s[5:40] + s[3] + s[41:48] + s[0] + s[49:84]
-	sys.exit()
+    print('Specify the version number as parameter')
-	f.write(version)
+    f.write(version)
-	del versions_info['signature']
+    del versions_info['signature']
-filenames = {'bin': 'youtube-dl', 'exe': 'youtube-dl.exe', 'tar': 'youtube-dl-%s.tar.gz' % version}
+filenames = {
-	new_version[key] = (url, sha256sum)
+    print('Downloading and checksumming %s...' % filename)
-json.dump(versions_info, open('update/versions.json', 'w'), indent=4, sort_keys=True)
+with open('update/versions.json', 'w') as jsonf:
-											Downloads available at <a href="http://youtube-dl.org/downloads/@VERSION@/">http://youtube-dl.org/downloads/@VERSION@/</a>
+											Downloads available at <a href="https://yt-dl.org/downloads/@VERSION@/">https://yt-dl.org/downloads/@VERSION@/</a>
-__version__ = '2013.08.22'
+__version__ = '2013.08.23'
-    # 86
+    # 86 - vflh9ybst 2013/08/23
-     "yuioplkjhgfdsazecvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!@#$%^&*()_-+={[|};?/>.<"),
+     "yuioplkjhgfdsazxcvbnm1234567890QWERrYUIOPLKqHGFDSAZXCVBNM!@#$%^&*()_-+={[|};?/>.<"),
-            return s[5:20] + s[2] + s[21:]
+            return s[5:40] + s[3] + s[41:48] + s[0] + s[49:86]
-        DL.params['subtitleslang'] = 'it'
+        DL.params['subtitleslangs'] = ['it']
-        DL.params['subtitleslang'] = 'it'
+        DL.params['subtitleslangs'] = ['it']
-    subtitleslang:     Language of the subtitles to download
+    subtitleslangs:    List of languages of the subtitles to download
-            help='language of the subtitles to download (optional) use IETF language tags like \'en\'')
+    subtitles.add_option('--sub-lang', '--sub-langs', '--srt-lang',
-        'subtitleslang': opts.subtitleslang,
+        'subtitleslangs': opts.subtitleslang,
-        sub_lang = self._downloader.params.get('subtitleslang') or 'en'
+        sub_lang = (self._downloader.params.get('subtitleslangs') or ['en'])[0]
-        sub_lang_list = self._get_available_subtitles(video_id)
+        available_subs_list = self._get_available_subtitles(video_id)
-        if  not sub_lang_list: #There was some error, it didn't get the available subtitles
+        if  not available_subs_list: #There was some error, it didn't get the available subtitles
-            pass
+            sub_lang_list = available_subs_list
-                sub_lang = 'en'
+            if self._downloader.params.get('subtitleslangs', False):
-            sub_lang_list = {sub_lang: sub_lang_list[sub_lang]}
+                reqested_langs = [list(available_subs_list.keys())[0]]
-            'ext':      video_extension,
+            'ext':      determine_ext(video_url),
-
+    unescapeHTML,
-        # if video_description: video_description = unescapeHTML(video_description)
+        # Only a few videos have an description
-            # 'description': video_description,
+            'description': video_description,
-        video_extension = video_url.split('.')[-1]
+        video_extension = video_url.split('.')[-1].split('?')[0]
-    def run_ffmpeg(self, path, out_path, opts):
+    def run_ffmpeg_multiple_files(self, input_paths, out_path, opts):
-        cmd = ([self._exes['avconv'] or self._exes['ffmpeg'], '-y', '-i', encodeFilename(path)]
+
-                    sub_filename = filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.' + sub_format
+                    sub_filename = subtitles_filename(filename, sub_lang, sub_format)
-        if self._downloader.params.get('writesubtitles', False):
+        if self._downloader.params.get('allsubtitles', False):
-    # 82
+    # 82 - vflZK4ZYR 2013/08/23
-__version__ = '2013.08.21'
+__version__ = '2013.08.22'
-        u'md5': u'2046dd5758541d630bfa93e741e2fd79',
+        u'md5': u'c77d700bdc16ae2e9f3c26019bd96143',
-            url_node = find_xpath_attr(sources, 'source', 'id', 'HQ off')
+        url_node = next(node for node in [find_xpath_attr(sources, 'source', 'id', 'HQ %s' % key) 
-    video_format.add_option('--write-sub', '--write-srt',
+
-    video_format.add_option('--write-auto-sub', '--write-automatic-sub',
+    subtitles.add_option('--write-auto-sub', '--write-automatic-sub',
-    video_format.add_option('--only-sub',
+    subtitles.add_option('--only-sub',
-    video_format.add_option('--all-subs',
+    subtitles.add_option('--all-subs',
-    video_format.add_option('--list-subs',
+            help='downloads all the available subtitles of the video', default=False)
-    video_format.add_option('--sub-format',
+            help='lists all available subtitles for the video', default=False)
-    video_format.add_option('--sub-lang', '--srt-lang',
+            help='subtitle format (default=srt) ([sbv/vtt] youtube only)', default='srt')
-        commandLineConf = sys.argv[1:] 
+        commandLineConf = sys.argv[1:]
-    
+
-     "Q>/?;}[{=+-(*<^%$#@!MNBVCXZASDFGHKLPOIUY8REWT0q&7654321mnbvcxzasdfghjklpoiuytrew9"),
+     "wertyuioplkjhgfdsaqxcvbnm1234567890QWERTYUIOPLKHGFDSAZXCVBNM!@#$%^&z(-+={[};?/>.<"),
-            return s[36] + s[79:67:-1] + s[81] + s[66:40:-1] + s[33] + s[39:36:-1] + s[40] + s[35] + s[0] + s[67] + s[32:0:-1] + s[34]
+            return s[1:19] + s[0] + s[20:68] + s[19] + s[69:82]
-                          '172', '171',                                       # Dash audio webm
+                          # 3D
-                                      '141', '140', '139',                                # Dash auido mp4
+                                      # Dash video
-        title = html.cssselect('.evenement8')[0].text_content()
+
-from .utv import UTVIE
+from .unistra import UnistraIE
-        return [track_info]
+from .utv import UTVIE
-
+# coding: utf-8
-        return [track_info]
+        return {'id': id,
-                u"uploader": u"IconaPop",
+                u"uploader": u"Icona Pop",
-        u'md5': u'deda4ff333abe2e118740321e992605b',
+        u'url': u'http://statigr.am/p/522207370455279102_24101272',
-        }
+            u'uploader_id': u'aguynamedpatrick',
-        video_url = self._html_search_regex(r'<video[^>]*>\s*<source[^>]*>\s*<source src="(?P<url>[^"]+)"',
+        video_url = self._search_regex(r'type: "video/mp4", src: "(.*?)"',
-            'title': title,
+            'title': self._og_search_title(webpage),
-    _VALID_URL = r'((http://www.vevo.com/watch/.*?/.*?/)|(vevo:))(?P<id>.*)$'
+    _VALID_URL = r'((http://www.vevo.com/watch/.*?/.*?/)|(vevo:))(?P<id>.*?)(\?|$)'
-            u"uploader": u"Hurts", 
+            u"upload_date": u"20130624",
-    }
+    _TESTS = [
-        if mobj.group('direct_link') or mobj.group('pro'):
+        elif mobj.group('pro'):
-                video_info['url_encoded_fmt_stream_map'][0] += ','+args['adaptive_fmts']
+                if 'url_encoded_fmt_stream_map' in video_info:
-
+                if 'url_encoded_fmt_stream_map' in video_info:
-            if m_s is not None and 'adaptive_fmts' in args:
+            if 'url_encoded_fmt_stream_map' not in video_info or not video_info['url_encoded_fmt_stream_map']:
-            m_s = re.search(r'[&,]s=', args['adaptive_fmts'] if 'adaptive_fmts' in args else '')
+            m_s = re.search(r'[&,]s=', args.get('adaptive_fmts', u''))
-        return '%02d:%02d' % (eta_mins, eta_secs)
+        (eta_hours, eta_mins) = divmod(eta_mins, 60)
-from ..utils import ExtractorError
+from ..utils import (
-__version__ = '2013.08.17'
+__version__ = '2013.08.21'
-        if new_url: return [self.url_result(new_url)]
+        try:
-        return re.match(cls._VALID_URL, url) is not None
+
-    _TEST = {
+    _TESTS = [{
-    }
+    },
-            manifest_url = videoNode.findall('./file')[0].text
+            next_url = videoNode.findall('./file')[0].text
-            raise ExtractorError(u'Invalid manifest file')
+        if next_url.endswith(u'manifest.f4m'):
-        url_pr = compat_urllib_parse_urlparse(info['thumbnail'])
+            adoc = xml.etree.ElementTree.fromstring(manifestXml)
-        return [info]
+        return info
-            if m_s is not None:
+            m_s = re.search(r'[&,]s=', args['adaptive_fmts'] if 'adaptive_fmts' in args else '')
-            else:
+            elif 'adaptive_fmts' in video_info:
-                          '85', '84', '102', '83', '101', '82', '100',
+                          '85', '84', '102', '83', '101', '82', '100',        # 3D
-        
+
-        '102': '720p',        
+        '102': '720p',
-    _3d_itags = ['85', '84', '102', '83', '101', '82', '100']
+
-                                        ' (3D)' if x in self._3d_itags else ''))
+                                        ' ('+self._special_itags[x]+')' if x in self._special_itags else ''))
-                                              ' (3D)' if format_param in self._3d_itags else '')
+                                              ' ('+self._special_itags[format_param]+')' if format_param in self._special_itags else '')
-                                 (?:watch|movie(?:_popup)?(?:\.php)?)?              # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
+                                 (?:(?:watch|movie)(?:_popup)?(?:\.php)?)?    # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
-    _VALID_URL = r'(?:http://)?(?P<url>(?P<base_url>rtl(?:(?P<is_rtl2>2)|-)now\.rtl(?(is_rtl2)2|)\.de/)[a-zA-Z0-9-]+/[a-zA-Z0-9-]+\.php\?(?:container_id|film_id)=(?P<video_id>[0-9]+)&player=1(?:&season=[0-9]+)?(?:&.*)?)'
+    """Information Extractor for RTLnow, RTL2now and VOXnow"""
-    },]
+    },
-     "/?;:|}][{=+-_)(*&^$#@!MNBVCXZArDFGHJKLPOIUY<REWQ0987654321mnbvcxzasdfghjkqpoiuytS"),
+     "uioplkjhgfdsazxcvbnm1t34567890QWE2TYUIOPLKJHGFDSAZXCVeNM!@#$^&*()_-+={[]}|:;?/>.<"),
-    # 85 - vflSAFCP9 2013/07/19
+    # 85
-     "ertyuiqplkjhgfdsazx$vbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!@#<%^&*()_-+={[};?/c"),
+     ".>/?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWQ0q876543r1mnbvcx9asdfghjklpoiuyt2"),
-    # 83 - vflTWC9KW 2013/08/01
+    # 83
-     "qwertyuioplkjhg>dsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!#$%^&*()_+={[};?/f"),
+     ".>/?;}[{=+_)(*&^%<#!MNBVCXZASPFGHJKLwOIUYTREWQ0987654321mnbvcxzasdfghjklpoiuytreq"),
-__version__ = '2013.08.15'
+__version__ = '2013.08.17'
-            webpage, u'video URL')
+
-            'uploader': video_uploader
+            'description': video_description
-            return s[2:8] + s[0] + s[9:21] + s[65] + s[22:65] + s[84] + s[66:82] + s[21]
+            return s[83:34:-1] + s[0] + s[33:27:-1] + s[3] + s[26:19:-1] + s[34] + s[18:3:-1] + s[27]
-__version__ = '2013.08.14'
+__version__ = '2013.08.15'
-            return s[83:53:-1] + s[3] + s[52:40:-1] + s[86] + s[39:10:-1] + s[0] + s[9:3:-1] + s[53]
+            return s[6:27] + s[4] + s[28:39] + s[27] + s[40:59] + s[2] + s[60:]
-__version__ = '2013.08.09'
+__version__ = '2013.08.14'
-            return s[:15] + s[80] + s[16:80] + s[15]
+            return s[81:64:-1] + s[82] + s[63:52:-1] + s[45] + s[51:45:-1] + s[1] + s[44:1:-1] + s[0]
-    # 87 - vflART1Nf 2013/07/24
+    # 87
-    # 86 - vflm_D8eE 2013/07/31
+     "/?;:|}][{=+-_)(*&^$#@!MNBVCXZArDFGHJKLPOIUY<REWQ0987654321mnbvcxzasdfghjkqpoiuytS"),
-     ">.1}|[{=+-_)(*&^%$#@!MNBVCXZASDFGHJK<POIUYTREW509876L432/mnbvcxzasdfghjklpoiuytre"),
+     "yuioplkjhgfdsazecvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!@#$%^&*()_-+={[|};?/>.<"),
-     "<.>?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWe098765432rmnbvcxzasdfghjklpoiuyt1"),
+     "<.>?;}[{=+-_)(*&^%$#@!MNBVCXZASDFGHJKLPOIUYTREWQ09876543q1mnbvcxzasdfghjklpoiuew2"),
-    Accecps urls from vevo.com or in the format 'vevo:{id}'
+    Accepts urls from vevo.com or in the format 'vevo:{id}'
-            u"title": u"Somebody To Die For"
+            u"title": u"Somebody to Die For"
-            msg = msg + u'; please report this issue on https://yt-dl.org/bug . Be sure to call youtube-dl with the --verbose flag and include its complete output.'
+            msg = msg + u'; please report this issue on https://yt-dl.org/bug . Be sure to call youtube-dl with the --verbose flag and include its complete output. Make sure you are using the latest version; type  youtube-dl -U  to update.'
-
+from ..aes import (
-        u'md5': u'c37ddbaaa39058c76a7e86c6813423c1',
+        u'md5': u'71ec5fcfddacf80f495efa8b6a8d9a89',
-__version__ = '2013.08.08.1'
+__version__ = '2013.08.09'
-    def test_no_subtitles(self):
+    def test_no_writesubtitles(self):
-    def test_subtitles_fr(self):
+    def test_subtitles_lang(self):
-    def test_youtube_no_subtitles(self):
+    def test_youtube_no_writesubtitles(self):
-    def test_youtube_subtitles_it(self):
+    def test_youtube_subtitles_lang(self):
-__version__ = '2013.08.08'
+__version__ = '2013.08.08.1'
-            return s[83:85] + s[26] + s[79:46:-1] + s[85] + s[45:36:-1] + s[30] + s[35:30:-1] + s[46] + s[29:26:-1] + s[82] + s[25:1:-1]
+            return s[5:20] + s[2] + s[21:]
-        self.to_screen(u'[info] Writing video subtitles to: ' + sub_filename)
+        self.to_screen(u'[info] Writing subtitle: ' + sub_filename)
-            
+
-from .subtitles import SubtitlesIE
+from .subtitles import NoAutoSubtitlesIE
-class DailyMotionSubtitlesIE(SubtitlesIE):
+class DailyMotionSubtitlesIE(NoAutoSubtitlesIE):
-        """Report available subtitles."""
+    def _list_available_subtitles(self, video_id):
-        """
+        """ returns {sub_lang: sub} or {} if subtitles not found """
-        """or {} if not available. Must be redefined by the subclasses."""
+        """ returns {sub_lang: url} or {} if not available """
-        # return [(err_msg, None, None)]
+        """ returns {sub_lang: sub} or {} if not available """
-        DL.params['listsubtitles'] = False
+        self.DL = FakeYDL()
-        subtitles = info_dict[0]['subtitles']
+        subtitles = self.getSubtitles()
-        self.assertEqual(md5(sub), '976553874490cba125086bbfea3ff76f')
+        self.DL.params['writesubtitles'] = True
-        self.assertEqual(md5(sub), '594564ec7d588942e384e920e5341792')
+        self.DL.params['writesubtitles'] = True
-        subtitles = info_dict[0]['subtitles']
+        self.DL.params['allsubtitles'] = True
-        info_dict = IE.extract(TEST_URL)
+    def test_list_subtitles(self): #ojo
-        self.assertTrue(len(sub) == 0)
+        self.DL.params['writeautomaticsub'] = True
-        DL.params['listsubtitles'] = False
+        self.DL = FakeYDL()
-        subtitles = info_dict[0]['subtitles']
+        self.DL.params['writesubtitles'] = False
-        self.assertEqual(md5(sub), '4cd9278a35ba2305f47354ee13472260')
+        self.DL.params['writesubtitles'] = True
-        self.assertEqual(md5(sub), '164a51f16f260476a05b50fe4c2f161d')
+        self.DL.params['writesubtitles'] = True
-        subtitles = info_dict[0]['subtitles']
+        self.DL.params['allsubtitles'] = True
-        self.assertEqual(md5(sub), '13aeaa0c245a8bed9a451cb643e3ad8b')
+        self.DL.params['writesubtitles'] = True
-        self.assertEqual(md5(sub), '356cdc577fde0c6783b9b822e7206ff7')
+        self.DL.params['writesubtitles'] = True
-        info_dict = IE.extract('QRS8MkLhQmM')
+        self.DL.params['listsubtitles'] = True
-        self.assertTrue(sub is not None)
+        self.url = '8YoUxe5ncPo'
-            help='[deprecated] alias of --skip-download', default=False)
+    subtitles      = optparse.OptionGroup(parser, 'Subtitle Options')
-    video_format.add_option('--write-sub', '--write-srt',
+
-    video_format.add_option('--write-auto-sub', '--write-automatic-sub',
+    subtitles.add_option('--write-auto-sub', '--write-automatic-sub',
-    video_format.add_option('--only-sub',
+    subtitles.add_option('--only-sub',
-    video_format.add_option('--all-subs',
+    subtitles.add_option('--all-subs',
-    video_format.add_option('--list-subs',
+    subtitles.add_option('--list-subs',
-    video_format.add_option('--sub-format',
+    subtitles.add_option('--sub-format',
-    video_format.add_option('--sub-lang', '--srt-lang',
+    subtitles.add_option('--sub-lang', '--srt-lang',
-            self.report_error(u'Insufficient system charset ' + repr(preferredencoding()))
+            self.report_error(u'Error in output template: ' + str(err) + u' (encoding: ' + repr(preferredencoding()) + ')')
-        self._downloader.report_warning(u'Automatic Captions not supported by dailymotion')
+        self._downloader.report_warning(u'Automatic Captions not supported by this server')
-class DailymotionIE(DailyMotionSubtitlesIE): #,InfoExtractor):
+class DailymotionIE(DailyMotionSubtitlesIE):
-        self.to_screen(u'%s: Available subtitles for video: %s' % (video_id, sub_lang))
+        self.to_screen(u'%s: Available subtitles for video: %s' %
-        if  not sub_lang_list: #There was some error, it didn't get the available subtitles
+        if not sub_lang_list:  # error, it didn't get the available subtitles
-            subtitle = self._request_subtitle(sub_lang, sub_lang_list[sub_lang].encode('utf-8'), video_id, sub_format)
+        for sub_lang, url in sub_lang_list.iteritems():
-        url = self._get_subtitle_url(sub_lang, sub_name, video_id, format)
+    def _request_subtitle_url(self, sub_lang, url):
-        """returns the url for the given subtitle. Redefine in subclasses."""
+        """returns the list of available subtitles like this {lang: url} """
-class YoutubeIE(InfoExtractor):
+class YoutubeSubtitlesIE(SubtitlesIE):
-__version__ = '2013.08.02'
+__version__ = '2013.08.08'
-            for sub_lang in subtitles:
+            for sub_lang in subtitles.keys():
-    unittest.main()
+#!/usr/bin/env python
-            help='write subtitle file (currently youtube only)', default=False)
+            help='write subtitle file', default=False)
-            help='write automatic subtitle file (currently youtube only)', default=False)
+            help='write automatic subtitle file (youtube only)', default=False)
-            help='downloads all the available subtitles of the video (currently youtube only)', default=False)
+            help='downloads all the available subtitles of the video', default=False)
-            help='lists all available subtitles for the video (currently youtube only)', default=False)
+            help='lists all available subtitles for the video', default=False)
-            help='subtitle format [srt/sbv/vtt] (default=srt) (currently youtube only)', default='srt')
+            help='subtitle format (default=srt) ([sbv/vtt] youtube only)', default='srt')
-class DailymotionIE(InfoExtractor):
+
-            u"uploader": u"Alex and Van .", 
+            u"uploader": u"Alex and Van .",
-                    'stream_h264_hq_url','stream_h264_url',
+        for key in ['stream_h264_hd1080_url', 'stream_h264_hd_url',
-            if info.get(key):#key in info and info[key]:
+            if info.get(key):  # key in info and info[key]:
-                self.to_screen(u'Using %s' % key)
+                self.to_screen(u'%s: Using %s' % (video_id, key))
-            for sub_lang in subtitles.keys():
+            
-            return s[4:23] + s[86] + s[24:85]
+            return s[83:53:-1] + s[3] + s[52:40:-1] + s[86] + s[39:10:-1] + s[0] + s[9:3:-1] + s[53]
-            return s[83:36:-1] + s[2] + s[35:26:-1] + s[3] + s[25:3:-1] + s[26]
+            return s[83:27:-1] + s[0] + s[26:5:-1] + s[2:0:-1] + s[27]
-                    raise UnavailableVideoError()
+                    raise UnavailableVideoError(err)
-        pattern = r'<h1 id="video-title">\n*?(.+?)\n*?</h1>'
+        pattern = r'<title>(.+?)</title>'
-        title = clean_html(title)
+        title = self._search_regex(compiled, webpage, u'video title')
-        json_1 = json.loads(urllib2.urlopen(url_1).read())
+        webpage = self._download_webpage(url_1, vid)
-    def report_finish(self):
+    def report_finish(self, data_len_str, tot_time):
-            self.to_screen(u'')
+	    clear_line = (u'\x1b[K' if sys.stderr.isatty() and os.name != 'nt' else u'')
-        self.report_finish()
+        self.report_finish(data_len_str, (time.time() - start))
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?collegehumor\.com/(video|embed|e)/(?P<videoid>[0-9]+)/(?P<shorttitle>.*)$'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?collegehumor\.com/(video|embed|e)/(?P<videoid>[0-9]+)/?(?P<shorttitle>.*)$'
-        assert re.match(r'^[a-zA-Z@]*$', val)
+        assert re.match(r'^[a-zA-Z@\s]*$', val)
-        return any(re.match(regex, url) for regex in (cls._EMISSION_URL, cls._VIDEOS_URL))
+        return any(re.match(regex, url) for regex in (cls._EMISSION_URL, cls._VIDEOS_URL, cls._LIVEWEB_URL))
-                     'description': player_info['VDE'],
+                     'description': player_info.get('VDE'),
-from ..utils import compat_urllib_request
+from ..utils import compat_urllib_request, clean_html
-        title = self._clearn_html(title)
+        title = clean_html(title)
-
+        if num_of_parts == 1:
-    _VALID_URL = r'(?:http://)?(?:www\.)?myvideo\.de/watch/([0-9]+)/([^?/]+).*'
+    _VALID_URL = r'(?:http://)?(?:www\.)?myvideo\.de/(?:[^/]+/)?watch/([0-9]+)/([^?/]+).*'
-                                    fatal=False)
+                                    video_info['ad3_module'][0] if 'ad3_module' in video_info else 'NOT FOUND',
-__version__ = '2013.07.31'
+__version__ = '2013.08.02'
-    # 83 - vflcaqGO8 2013/07/11
+    # 83 - vflTWC9KW 2013/08/01
-     "urty8ioplkjhgfdsazxcvbqm1234567S90QWERTYUIOPLKJHGFDnAZXCVBNM!#$%^&*()_+={[};?/>.<"),
+     "qwertyuioplkjhg>dsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!#$%^&*()_+={[};?/f"),
-        right = "urty8ioplkjhgfdsazxcvbqm1234567S90QWERTYUIOPLKJHGFDnAZXCVBNM!#$%^&*()_+={[};?/>.<"
+        right = "qwertyuioplkjhg>dsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!#$%^&*()_+={[};?/f"
-            return s[6] + s[3:6] + s[33] + s[7:24] + s[0] + s[25:33] + s[53] + s[34:53] + s[24] + s[54:]
+            return s[:15] + s[80] + s[16:80] + s[15]
-            print('%s\t:\t%s\t[%s]' %(x, self._video_extensions.get(x, 'flv'), self._video_dimensions.get(x, '???')))
+            print('%s\t:\t%s\t[%s]%s' %(x, self._video_extensions.get(x, 'flv'),
-                                              self._video_dimensions.get(format_param, '???'))
+            video_format = '{0} - {1}{2}'.format(format_param if format_param else video_extension,
-        gcid = self._search_regex(r'lurl:[\'"]http://.+?/.+?/(.+?)/', webpage, u'gcid')
+        title = self._search_regex(r'(?:G_TITLE=|G_MOVIE_TITLE = )[\'"](.+?)[\'"]', webpage, u'video title')
-            regexes = [r'VO?%s' % l, r'V%s-ST.' % l]
+            regexes = [r'VO?%s' % l, r'VO?.-ST%s' % l]
-    _available_formats_prefer_free = ['38', '46', '37', '45', '22', '44', '35', '43', '34', '18', '6', '5', '17', '13']
+    _available_formats = ['38', '37', '46', '22', '45', '35', '44', '34', '18', '43', '6', '5', '17', '13',
-                self._print_formats(existing_formats)
+            video_url_list = self._get_video_url_list(url_map)
-                    raise ExtractorError(u'requested format not available')
+        elif video_info.get('hlsvp'):
-        if not self._exes['ffprobe'] and not self._exes['avprobe']: return None
+        if not self._exes['ffprobe'] and not self._exes['avprobe']:
-                self._downloader.to_stderr(u'WARNING: Cannot update utime of audio file')
+                self._downloader.report_warning(u'Cannot update utime of audio file')
-                self.to_stderr(u'ERROR: ' + e.msg)
+                self.report_error(e.msg)
-__version__ = '2013.07.25.2'
+__version__ = '2013.07.31'
-            self._decrypt_signature(s)
+            return self._decrypt_signature(s)
-    # 86 - vfl_ymO4Z 2013/06/27
+    # 86 - vflm_D8eE 2013/07/31
-     "ertyuioplkjhgfdsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!/#$%^&*()_-+={[|};?@"),
+     ">.1}|[{=+-_)(*&^%$#@!MNBVCXZASDFGHJK<POIUYTREW509876L432/mnbvcxzasdfghjklpoiuytre"),
-sig = YoutubeIE(FakeYDL())._decrypt_signature
+ie = YoutubeIE(FakeYDL())
-        right = "ertyuioplkjhgfdsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!/#$%^&*()_-+={[|};?@"
+        right = ">.1}|[{=+-_)(*&^%$#@!MNBVCXZASDFGHJK<POIUYTREW509876L432/mnbvcxzasdfghjklpoiuytre"
-            return s[2:63] + s[82] + s[64:82] + s[63]
+            return s[83:85] + s[26] + s[79:46:-1] + s[85] + s[45:36:-1] + s[30] + s[35:30:-1] + s[46] + s[29:26:-1] + s[82] + s[25:1:-1]
-                        signature = self._decrypt_signature(url_data['s'][0])
+                        encrypted_sig = url_data['s'][0]
-        }
+        },
-        }
+        },
-        video_url = re.search(r'videoId=(.*?)&amp?',
+        m_vevo_id = re.search(r'videoId=(.*?)&amp?',
-        if video_url:
+        if m_vevo_id is not None:
-            return self.url_result('vevo:%s' % video_url.group(1), ie='Vevo')
+            return self.url_result('vevo:%s' % m_vevo_id.group(1), ie='Vevo')
-            webpage_src, u'video URL', fatal=False)
+        video_url = re.search(r'videoId=(.*?)&amp?',
-            return self.url_result('vevo:%s' % video_url, ie='Vevo')
+            return self.url_result('vevo:%s' % video_url.group(1), ie='Vevo')
-        if video_url == None:
+        if video_url is None:
-    _WORKING = False
+    """TF1 uses the wat.tv player."""
-        u'md5': u'66789d3e91278d332f75e1feb7aea327',
+        u'md5': u'2e378cc28b9957607d5e88f274e637d8',
-        u'md5': u'0a4fe7870f31eaeabb5e25fd8da8414a',
+        # Sometimes wat serves the whole file with the --test option
-                'url': video_url,
+                'url': 'http://wat.tv/get/android5/%s.mp4' % real_id,
-        m_urls = list(re.finditer(r'<video src="(?P<ext>.*?):(?P<url>.*?)"', links_webpage))
+        m_urls = list(re.finditer(r'<video src="(?P<ext>.*?):/?(?P<url>.*?)"', links_webpage))
-        video_url = base_url + m_url.group('url')
+        video_url = base_url + '/' + m_url.group('url')
-        video_url = self._search_regex('videoId=(.*?)&amp?',
+        video_url = self._search_regex(r'videoId=(.*?)&amp?',
-
+        
-            self.url_result(vevo_id)
+            return self.url_result('vevo:%s' % video_url, ie='Vevo')
-from youtube_dl.extractor import DailymotionPlaylistIE
+from youtube_dl.extractor import DailymotionPlaylistIE, VimeoChannelIE
-from .vimeo import VimeoIE
+from .vimeo import VimeoIE, VimeoChannelIE
-from .dailymotion import DailymotionIE
+from .dailymotion import DailymotionIE, DailymotionPlaylistIE
-__version__ = '2013.07.25.1'
+__version__ = '2013.07.25.2'
-    # 81
+    # 81 - vflLC8JvQ 2013/07/25
-     "urty8ioplkjhgfdsazxcvbqm1234567e90QWERTYUIOPLKHGFDSnZXCVBNM!@#$%^&*(-+={[};?/>."),
+     "C>/?;}[{=+-(*&^%$#@!MNBVYXZASDFGHKLPOIU.TREWQ0q87659321mnbvcxzasdfghjkl4oiuytrewp"),
-        right = "urty8ioplkjhgfdsazxcvbqm1234567e90QWERTYUIOPLKHGFDSnZXCVBNM!@#$%^&*(-+={[};?/>."
+        right = "C>/?;}[{=+-(*&^%$#@!MNBVYXZASDFGHKLPOIU.TREWQ0q87659321mnbvcxzasdfghjkl4oiuytrewp"
-            return s[6] + s[3:6] + s[33] + s[7:24] + s[0] + s[25:33] + s[2] + s[34:53] + s[24] + s[54:81]
+            return s[56] + s[79:56:-1] + s[41] + s[55:41:-1] + s[80] + s[40:34:-1] + s[0] + s[33:29:-1] + s[34] + s[28:9:-1] + s[29] + s[8:0:-1] + s[9]
-        u'url': u'https?://www.keek.com/ytdl/keeks/NODfbab',
+        u'url': u'https://www.keek.com/ytdl/keeks/NODfbab',
-__version__ = '2013.07.25'
+__version__ = '2013.07.25.1'
-    _VALID_URL = r'(?:http://)?(?:www\.)?ina\.fr/video/(?P<id>[A-F0-9]+)/.*'
+    _VALID_URL = r'(?:http://)?(?:www\.)?ina\.fr/video/(?P<id>I?[A-F0-9]+)/.*'
-    _VALID_URL = r'http://(?:www\.)?keek\.com/(?:!|\w+/keeks/)(?P<videoID>\w+)'
+    _VALID_URL = r'https?://(?:www\.)?keek\.com/(?:!|\w+/keeks/)(?P<videoID>\w+)'
-        u'url': u'http://www.keek.com/ytdl/keeks/NODfbab',
+        u'url': u'https?://www.keek.com/ytdl/keeks/NODfbab',
-__version__ = '2013.07.24.2'
+__version__ = '2013.07.25'
-    _VALID_URL = r'(?:http://)?(?:www\.)?ina\.fr/video/(?P<id>I[0-9]+)/.*'
+    _VALID_URL = r'(?:http://)?(?:www\.)?ina\.fr/video/(?P<id>[A-F0-9]+)/.*'
-        video_url = self._html_search_regex(r'<file type="high".*?>(.*?)</file>',
+        video_url = self._html_search_regex(r'<file [^>]*type="high".*?>(.*?)</file>',
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?collegehumor\.com/(video|embed)/(?P<videoid>[0-9]+)/(?P<shorttitle>.*)$'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?collegehumor\.com/(video|embed|e)/(?P<videoid>[0-9]+)/(?P<shorttitle>.*)$'
-        while True:
+        for page_num in itertools.count(1):
-
+            for pagenum in itertools.count(1):
-        while True:
+        for pagenum in itertools.count(0):
-
+    YoutubeWatchLaterIE,
-        return 'http://www.youtube.com/feed_ajax?action_load_system_feed=1&feed_name=%s&paging=%%s' % self._FEED_NAME
+        action = 'action_load_system_feed'
-            m_ids = re.finditer(r'"/watch\?v=(.*?)"', feed_html)
+            m_ids = re.finditer(r'"/watch\?v=(.*?)["&]', feed_html)
-__version__ = '2013.07.24.1'
+__version__ = '2013.07.24.2'
-                        ((?:PL|EC|UU)?[0-9A-Za-z-_]{10,})
+                        ((?:PL|EC|UU|FL)?[0-9A-Za-z-_]{10,})
-                        ((?:PL|EC|UU)[0-9A-Za-z-_]{10,})
+                        ((?:PL|EC|UU|FL)[0-9A-Za-z-_]{10,})
-class YoutubeIE(InfoExtractor):
+        # Log in
-class YoutubeFeedsInfoExtractor(YoutubeIE):
+class YoutubeFeedsInfoExtractor(YoutubeBaseInfoExtractor):
-        super(YoutubeFeedsInfoExtractor, self)._real_initialize()
+        self._login()
-            url = self._TEMPLATE_URL % (playlist_id, self._MAX_RESULTS, self._MAX_RESULTS * (page_num - 1) + 1)
+            start_index = self._MAX_RESULTS * (page_num - 1) + 1
-    }
+    _SOUNDCLOUD_URL = r'(?:http://)?(?:www\.)?api\.soundcloud.com/tracks/([^/]+)/stream'
-        	song_url = info['song']['url']
+        song_url = info['song']['url']
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?soundcloud\.com/([\w\d-]+)/([\w\d-]+)/?(?:[?].*)?$'
+    _VALID_URL = r'''^(?:https?://)?
-        mobj = re.match(self._VALID_URL, url)
+        mobj = re.match(self._VALID_URL, url, flags=re.VERBOSE)
-        info_json = self._download_webpage(resolv_url, full_title, u'Downloading info JSON')
+        track_id = mobj.group('track_id')
-        resolv_url = 'http://api.soundcloud.com/resolve.json?url=' + url + '&client_id=b45b1aa10f1ac2941910a7f0d10f8e28'
+        resolv_url = self._resolv_url(url)
-     """
+        return self._extract_info_dict(info, full_title)
-        resolv_url = 'http://api.soundcloud.com/resolve.json?url=' + url + '&client_id=b45b1aa10f1ac2941910a7f0d10f8e28'
+        resolv_url = self._resolv_url(url)
-        return videos
+        return {'_type': 'playlist',
-__version__ = '2013.07.24'
+__version__ = '2013.07.24.1'
-    # 87
+    # 87 - vflART1Nf 2013/07/24
-    _VALID_URL = r'(?:http://)?(?:www\.)?traileraddict\.com/trailer/([^/]+)/(?:[^/]*trailer[^/]*)'
+    _VALID_URL = r'(?:http://)?(?:www\.)?traileraddict\.com/(?:trailer|clip)/(?P<movie>.+?)/(?P<trailer_name>.+)'
-        webpage = self._download_webpage(url, video_id)
+        name = mobj.group('movie') + '/' + mobj.group('trailer_name')
-__version__ = '2013.07.23.1'
+__version__ = '2013.07.24'
-     "!?;:|}][{=+-_)(*&^$#@/MNBVCXZASqFGHJKLPOIUYTREWQ0987654321mnbvcxzasdfghjklpoiuytr"),
+     "tyuioplkjhgfdsazxcv<nm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!@#$^&*()_-+={[]}|:;?/>"),
-        right = "!?;:|}][{=+-_)(*&^$#@/MNBVCXZASqFGHJKLPOIUYTREWQ0987654321mnbvcxzasdfghjklpoiuytr"
+        right = "tyuioplkjhgfdsazxcv<nm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!@#$^&*()_-+={[]}|:;?/>"
-            return s[62] + s[82:62:-1] + s[83] + s[61:52:-1] + s[0] + s[51:2:-1]
+            return s[4:23] + s[86] + s[24:85]
-        
+
-        info_url = "http://www.traileraddict.com/fvar.php?tid=%s" %(str(video_id))
+        # Presence of (no)watchplus function indicates HD quality is available
-        
+
-        
+
-    _VALID_URL = r'(?:http://)?(?:www\.)?traileraddict\.com/trailer/([^/]+)/(?:trailer|feature-trailer)'
+    _VALID_URL = r'(?:http://)?(?:www\.)?traileraddict\.com/trailer/([^/]+)/(?:[^/]*trailer[^/]*)'
-__version__ = '2013.07.23'
+__version__ = '2013.07.23.1'
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?soundcloud\.com/([\w\d-]+)/([\w\d-]+)(?:[?].*)?$'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?soundcloud\.com/([\w\d-]+)/([\w\d-]+)/?(?:[?].*)?$'
-    _MORE_PAGES_URL = 'http://www.youtube.com/channel_ajax?action_load_more_videos=1&flow=list&paging=%s&view=0&sort=da&channel_id=%s'
+    _MORE_PAGES_URL = 'http://www.youtube.com/c4_browse_ajax?action_load_more_videos=1&flow=list&paging=%s&view=0&sort=da&channel_id=%s'
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?collegehumor\.com/video/(?P<videoid>[0-9]+)/(?P<shorttitle>.*)$'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?collegehumor\.com/(video|embed)/(?P<videoid>[0-9]+)/(?P<shorttitle>.*)$'
-__version__ = '2013.07.19'
+__version__ = '2013.07.23'
-        ext = video_url.split('.')[-1]
+        embed_url = 'http://www.break.com/embed/%s' % video_id
-            'thumbnail': thumbnail_url,
+            'ext':       determine_ext(final_url),
-        self.to_screen(u'%s: Downloading XML manifest' % video_id)
+    _TEST = {
-            raise ExtractorError(u'Unable to download video info XML: %s' % compat_str(err))
+        metaXml = self._download_webpage(xmlUrl, video_id,
-            raise ExtractorError(u'Unable to download video info XML: %s' % compat_str(err))
+        manifestXml = self._download_webpage(manifest_url, video_id,
-        url = url_pr.scheme + '://' + url_pr.netloc + '/z' + video_id[:-2] + '/' + node_id + 'Seg1-Frag1'
+        url_pr = compat_urllib_parse_urlparse(info['thumbnail'])
-        info['ext'] = 'f4f'
+        info['url'] = url_pr.scheme + '://' + url_pr.netloc + video_id[:-2].replace('.csmil','').replace(',','')
-                              |(watch/(?P<date>[^/]*)/(?P<tdstitle>.*)))))
+                              |(watch/(?P<date>[^/]*)/(?P<tdstitle>.*)))|
-    _FEED_TEMPLATE = 'http://www.youtube.com/feed_ajax?action_load_system_feed=1&feed_name=subscriptions&paging=%s'
+class YoutubeFeedsInfoExtractor(YoutubeIE):
-        super(YoutubeSubscriptionsIE, self)._real_initialize()
+        super(YoutubeFeedsInfoExtractor, self)._real_initialize()
-            info = self._download_webpage(self._FEED_TEMPLATE % paging, 'feed',
+            info = self._download_webpage(self._FEED_TEMPLATE % paging,
-        return self.playlist_result(feed_entries, playlist_title='Youtube Subscriptions')
+        return self.playlist_result(feed_entries, playlist_title=self._PLAYLIST_TITLE)
-        except KeyError:
+        # An extractor error can be raise by the download process if there are
-    def _extract_subtitle(self, video_id):
+    
-        sub_format = self._downloader.params.get('subtitlesformat')
+        if self._downloader.params.get('writesubtitles', False):
-            video_subtitles = self._extract_subtitle(video_id)
+        if self._downloader.params.get('writesubtitles', False) or self._downloader.params.get('allsubtitles', False):
-        self.assertEqual(md5(sub[2]), '4cd9278a35ba2305f47354ee13472260')
+        sub = info_dict[0]['subtitles']['en']
-        self.assertEqual(md5(sub[2]), '164a51f16f260476a05b50fe4c2f161d')
+        sub = info_dict[0]['subtitles']['it']
-        self.assertEqual(md5(sub[2]), '4cd9278a35ba2305f47354ee13472260')
+        sub = info_dict[0]['subtitles']['en']
-        self.assertEqual(len(subtitles), 13)
+        self.assertEqual(len(subtitles.keys()), 13)
-        self.assertEqual(md5(sub[2]), '13aeaa0c245a8bed9a451cb643e3ad8b')
+        sub = info_dict[0]['subtitles']['en']
-        self.assertEqual(md5(sub[2]), '356cdc577fde0c6783b9b822e7206ff7')
+        sub = info_dict[0]['subtitles']['en']
-        self.assertTrue(sub[2] is not None)
+        sub = info_dict[0]['subtitles']['it']
-                        return
+            for sub_lang in subtitles.keys():
-    subtitles:      The subtitle file contents.
+    subtitles:      The subtitle file contents as a dictionary in the format
-            return (u'unable to download video subtitles: %s' % compat_str(err), None)
+            self._downloader.report_warning(u'unable to download video subtitles: %s' % compat_str(err))
-            return (u'video doesn\'t have subtitles', None)
+            self._downloader.report_warning(u'video doesn\'t have subtitles')
-        (error_message, sub_lang, sub)
+        Return the subtitle as a string or None if they are not found
-            return (u'unable to download video subtitles: %s' % compat_str(err), None, None)
+            self._downloader.report_warning(u'unable to download video subtitles for %s: %s' % (sub_lang, compat_str(err)))
-        return (None, sub_lang, sub)
+            self._downloader.report_warning(u'Did not fetch video subtitles')
-            return [(err_msg, None, None)]
+            self._downloader.report_warning(err_msg)
-            return [(None, sub_lang, sub)]
+            return {sub_lang: sub}
-            return [(err_msg, None, None)]
+            self._downloader.report_warning(err_msg)
-        [(error_message, sub_lang, sub)]
+        Return a dictionary: {language: subtitles} or {} if the subtitles
-            return [(sub_lang_list[0], None, None)]
+        if  not sub_lang_list: #There was some error, it didn't get the available subtitles
-            return [(u'no closed captions found in the specified language "%s"' % sub_lang, None, None)]
+            self._downloader.report_warning(u'no closed captions found in the specified language "%s"' % sub_lang)
-        return [subtitle]
+        if subtitle:
-        subtitles = []
+        subtitles = {}
-            subtitles.append(subtitle)
+            if subtitle:
-        if self._downloader.params.get('writeautomaticsub', False):
+        elif self._downloader.params.get('writeautomaticsub', False):
-        if (self.params.get('writesubtitles', False) or self.params.get('writeautomaticsub')) and 'subtitles' in info_dict and info_dict['subtitles']:
+        subtitles_are_requested = any([self.params.get('writesubtitles', False),
-        if self.params.get('allsubtitles', False) and 'subtitles' in info_dict and info_dict['subtitles']:
+    IE_NAME = u'exfm'
-__version__ = '2013.07.18'
+__version__ = '2013.07.19'
-                                        u'player url')
+        info_url = 'http://video.weibo.com/?s=v&a=play_list&format=json&mix_video_id=t_%s' % video_id
-    # 85
+    # 85 - vflSAFCP9 2013/07/19
-     "{>/?;}[.=+-_)(*&^%$#@!MqBVCXZASDFwHJKLPOIUYTREWQ0987654321mnbvcxzasdfghjklpoiuytr"),
+     "ertyuiqplkjhgfdsazx$vbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!@#<%^&*()_-+={[};?/c"),
-        right = "{>/?;}[.=+-_)(*&^%$#@!MqBVCXZASDFwHJKLPOIUYTREWQ0987654321mnbvcxzasdfghjklpoiuytr"
+        right = "ertyuiqplkjhgfdsazx$vbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!@#<%^&*()_-+={[};?/c"
-            return s[76] + s[82:76:-1] + s[83] + s[75:60:-1] + s[0] + s[59:50:-1] + s[1] + s[49:2:-1]
+            return s[2:8] + s[0] + s[9:21] + s[65] + s[22:65] + s[84] + s[66:82] + s[21]
-        title = self._html_search_regex(r'<span id="altHeadline" >(?P<title>.*)</span>',
+        title = self._html_search_regex(r'<span .*?id="altHeadline".+?>(?P<title>.*)</span>',
-    _VALID_URL =  r'(?:http://)?v\.youku\.com/v_show/id_(?P<ID>[A-Za-z0-9]+)\.html'
+    _VALID_URL =  r'(?:http://)?(v|player)\.youku\.com/(v_show/id_|player\.php/sid/)(?P<ID>[A-Za-z0-9]+)(\.html|/v.swf)'
-            u"title": u"Video by naomipq"
+            u"title": u"Video by naomipq",
-        ext = 'mp4'
+        uploader_id = self._search_regex(r'"owner":{"username":"(.+?)"',
-            'title':     title,
+            'ext':       'mp4',
-            'uploader_id' : uploader_id
+            'uploader_id' : uploader_id,
-            action='store_true', dest='update_self', help='update this program to latest version')
+            action='store_true', dest='update_self', help='update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')
-__version__ = '2013.07.17.1'
+__version__ = '2013.07.18'
-
+    # 90
-        if len(s) == 88:
+        if len(s) == 92:
-            return s[25] + s[3:25] + s[0] + s[26:42] + s[79] + s[43:79] + s[91] + s[80:83];
+import json
-        webpage = self._download_webpage(info_url, video_id)
+        song_id = mobj.group(1)
-            'id':          video_id,
+            'id':          song_id,
-                                (len(s), len(s.split('.')[0]), len(s.split('.')[1]), url_data['itag'][0], player))
+                            parts_sizes = u'.'.join(compat_str(len(part)) for part in s.split('.'))
-__version__ = '2013.07.17'
+__version__ = '2013.07.17.1'
-        return s;
+        if len(s) == 88:
-            u"uploader": u"AnyClip",
+            u"uploader": u"anyclip",
-        return [{
+        return {
-        }]
+        }
-        video_uploader = self._html_search_regex(r'submitter=(.*?);|<p class="By">\s*By\s*<a[^>]*>(.*?)</a>', webpage, u'uploader nickname', fatal=False)
+        video_uploader = self._html_search_regex(
-        return self._html_search_regex(self._og_regex(prop), html, name, flags=re.DOTALL, **kargs)
+        escaped = self._search_regex(self._og_regex(prop), html, name, flags=re.DOTALL, **kargs)
-            raise ExtractorError(u'Unable to decrypt signature, key length %d not supported; retrying might work' % (len(s)))
+        def voodoo(a, b):
-
+        video_title = self._html_search_regex(r'(?im)<title>(.*) - Video</title>', webpage, u'title')
-            sys.exc_clear()
+            try:
-        ydl.to_screen(u'[debug] youtube-dl version ' + __version__)
+        sys.stderr.write(u'[debug] youtube-dl version ' + __version__ + u'\n')
-                ydl.to_screen(u'[debug] Git HEAD: ' + out)
+                sys.stderr.write(u'[debug] Git HEAD: ' + out + u'\n')
-        ydl.to_screen(u'[debug] Proxy map: ' + str(proxy_handler.proxies))
+        sys.stderr.write(u'[debug] Python version %s - %s' %(platform.python_version(), platform.platform()) + u'\n')
-__version__ = '2013.07.12'
+__version__ = '2013.07.17'
-
+    determine_ext,
-    _TEST = {
+    _TESTS = [{
-    }
+    },
-        webpage = self._download_webpage('http://www.metacafe.com/watch/%s/' % video_id, video_id)
+        req = compat_urllib_request.Request('http://www.metacafe.com/watch/%s/' % video_id)
-            video_extension = mediaURL[-3:]
+            video_ext = mediaURL[-3:]
-            video_url = '%s?__gda__=%s' % (mediaURL, mobj.group('key'))
+            mobj = re.search(r'<video src="([^"]+)"', webpage)
-        video_uploader = mobj.group(1)
+        video_uploader = self._html_search_regex(r'submitter=(.*?);|<p class="By">\s*By\s*<a[^>]*>(.*?)</a>', webpage, u'uploader nickname', fatal=False)
-            'uploader': video_uploader.decode('utf-8'),
+            'id':       video_id,
-            'ext':      video_extension.decode('utf-8'),
+            'ext':      video_ext,
-from .freesound import FreeSoundIE
+from .freesound import FreesoundIE
-# -*- coding: utf-8 -*-
+from ..utils import determine_ext
-    _VALID_URL = r'(?:http://)?(?:www\.)?freesound\.org/people/([^/]+)/sounds/([^/]+)'
+class FreesoundIE(InfoExtractor):
-            u"uploader" : u"miklovan"
+            u"title": u"gulls in the city.wav",
-        music_id = mobj.group(2)
+        music_id = mobj.group('id')
-        ext = music_url.split('.')[-1]
+        title = self._html_search_regex(r'<div id="single_sample_header">.*?<a href="#">(.+?)</a>',
-        }]
+            'uploader': self._og_search_property('audio:artist', webpage, 'music uploader'),
-    compat_urllib_parse,
+from .mtv import MTVIE, _media_xml_tag
-class GametrailersIE(InfoExtractor):
+class GametrailersIE(MTVIE):
-        u'md5': u'c3edbc995ab4081976e16779bd96a878',
+        u'file': u'70e9a5d7-cf25-4a10-9104-6f3e7342ae0d.mp4',
-            u"title": u"E3 2013: Debut Trailer"
+            u'title': u'E3 2013: Debut Trailer',
-        u'skip': u'Requires rtmpdump'
+    # Overwrite MTVIE properties we don't want
-
+        return self._get_videos_info(mgid)
-        return base + m.group('finalid') 
+        return base + m.group('finalid')
-                           'thumbnail': 'http://mtv.mtvnimages.com/uri/' + uri,
+                           'thumbnail': self._get_thumbnail_url(uri, itemdoc),
-        mediagen_url = itemdoc.find('media:group/media:content', media_namespace).attrib['url']
+        mediagen_url = itemdoc.find('%s/%s' % (_media_xml_tag('group'), _media_xml_tag('content'))).attrib['url']
-
+    compat_urllib_parse,
-    _WORKING = False
+    _VALID_URL = r'^https?://(?:www\.)?mtv\.com/videos/.+?/(?P<videoid>[0-9]+)/[^/]+$'
-        return [info]
+        uri = self._html_search_regex(r'/uri/(.*?)\?', webpage, u'uri')
-from ..utils import compat_urllib_parse_urlparse, compat_urlparse,
+from ..utils import compat_urllib_parse_urlparse, compat_urlparse
-            dest='ratelimit', metavar='LIMIT', help='maximum download rate (e.g. 50k or 44.6m)')
+            dest='ratelimit', metavar='LIMIT', help='maximum download rate in bytes per second (e.g. 50k or 44.6m)')
-            webpage, u'uploader name', fatal=False)
+        uploader_id = self._html_search_regex(
-        u'url': u'http://instagram.com/p/aye83DjauH/#',
+        u'url': u'http://instagram.com/p/aye83DjauH/?foo=bar#abc',
-        uploader_id = self._html_search_regex(r'content="(.*?)\'s video on Instagram',
+        uploader_id = self._html_search_regex(r'<div class="media-user" id="media_user"><h2><a href="[^"]*">([^<]*)</a></h2>',
-        return r'<meta.+?property=[\'"]og:%s[\'"].+?content=(?:"(.+?)"|\'(.+?)\')' % property
+    def _og_regex(prop):
-    def _og_search_property(self, property, html, name=None, **kargs):
+    def _og_search_property(self, prop, html, name=None, **kargs):
-        return self._html_search_regex(self._og_regex(property), html, name, flags=re.DOTALL, **kargs)
+            name = 'OpenGraph %s' % prop
-        return self._og_search_property('image', html, 'thumbnail url', fatal=False, **kargs)
+        return self._og_search_property('image', html, u'thumbnail url', fatal=False, **kargs)
-    _VALID_URL = r'http://www.criterion.com/films/(.*)'
+    _VALID_URL = r'https?://www\.criterion\.com/films/(\d*)-.+'
-            u"description" : u"In a career-defining performance, Alain Delon plays a contract killer with samurai instincts. A razor-sharp cocktail of 1940s American gangster cinema and 1960s French pop culture, maverick director Jean-Pierre Melville&#x27;s masterpiece _Le SamouraÃ¯_ defines cool. "
+            u"description" : u'md5:a2b4b116326558149bef81f76dcbb93f',
-        video_id = mobj.group(1).split('-')[0]
+        video_id = mobj.group(1)
-        title = self._search_regex(r'<meta content="(.+?)" property="og:title" />',
+        title = self._html_search_regex(r'<meta content="(.+?)" property="og:title" />',
-        description = self._search_regex(r'<meta name="description" content="(.+?)" />',
+        description = self._html_search_regex(r'<meta name="description" content="(.+?)" />',
-                'ext': ext,
+                'ext': determine_ext(final_url),
-            webpage, u'video URL')
+        m_playlist = re.search(r'so.addVariable\("playlist", ?"(?P<playlist>.+?)"\);', webpage)
-        return self._html_search_regex(self._og_regex(property), html, name, **kargs)
+        return self._html_search_regex(self._og_regex(property), html, name, flags=re.DOTALL, **kargs)
-            'description': self._og_search_description(webpage, flags=re.DOTALL),
+            'description': self._og_search_description(webpage),
-                'thumbnail': thumbnail,
+                'thumbnail': self._og_search_thumbnail(webpage),
-            'title':    video_title,
+            'title':    self._og_search_title(webpage),
-            webpage, u'video description')
+        title = self._og_search_title(webpage).replace(' | eHow', '')
-            'description': description,
+            'thumbnail':   self._og_search_thumbnail(webpage),
-            webpage, u'player url')
+        playerUrl = self._og_search_video_url(webpage, name='player url')
-            'thumbnail': imgUrl,
+            'thumbnail': self._og_search_thumbnail(webpage),
-            'thumbnail':   thumbnail,
+            'title':       self._og_search_title(webpage),
-            'description': video_description,
+            'description': self._og_search_description(webpage, flags=re.DOTALL),
-                    'thumbnail' : thumbnail,
+                    'thumbnail' : self._og_search_thumbnail(webpage_src),
-        return results
+        return results
-            'url':       video_url,
+            'url':       self._og_search_video_url(webpage),
-            'thumbnail': thumbnail_url,
+            'thumbnail': self._og_search_thumbnail(webpage),
-            webpage, u'title')
+        video_title = self._og_search_title(webpage)
-            webpage, u'title').replace('LiveLeak.com -', '').strip()
+        video_title = self._og_search_title(webpage).replace('LiveLeak.com -', '').strip()
-            webpage, u'description', fatal=False)
+        video_description = self._og_search_description(webpage)
-            webpage, 'title', default=shortened_video_id).replace('NBA.com: ', '')
+        title = self._og_search_title(webpage, default=shortened_video_id).replace('NBA.com: ', '')
-            'url':       video_url,
+            'url':       self._og_search_video_url(webpage),
-            'thumbnail': thumbnail_url,
+            'thumbnail': self._og_search_thumbnail(webpage),
-            'description': video_description,
+            'title':       self._og_search_title(webpage),
-        
+        video_id = self._og_search_property('video', webpage, 'Video id').split('=')[1]
-            'description' : description,
+            'description' : self._og_search_description(webpage),
-            'title': title,
+            'title': self._og_search_title(webpage),
-            'thumbnail': thumbnail,
+            'title':     self._og_search_title(webpage),
-            if 'thumbnail' in info_dict:
+            if info_dict.get('thumbnail') is not None:
-                    thumb_format = 'jpg'
+                thumb_format = determine_ext(info_dict['thumbnail'], u'jpg')
-def determine_ext(url):
+def determine_ext(url, default_ext=u'unknown_video'):
-        return u'unknown_video'
+        return default_ext
-        query = mobj.group('query')
+        query_str = mobj.group('query')
-            return self._get_video_info(video_id, query)
+        videoPlayer = query.get('@videoPlayer')
-            return self._get_playlist_info(player_key)
+            player_key = query['playerKey']
-        m_brightcove = re.search(r'<object.+?class=".*?BrightcoveExperience.*?".+?</object>', webpage, re.DOTALL)
+        m_brightcove = re.search(r'<object.+?class=([\'"]).*?BrightcoveExperience.*?\1.+?</object>', webpage, re.DOTALL)
-from .ign import IGNIE
+from .ign import IGNIE, OneUPIE
-    _VALID_URL = r'http://www.ign.com/videos/.+/(?P<name>.+)'
+    """
-                                              webpage, 'video description', flags=re.DOTALL)
+        name_or_id = mobj.group('name_or_id')
-                'thumbnail': media['poster'][0]['url'].replace('{size}', 'small'),
+                'thumbnail': media['poster'][0]['url'].replace('{size}', 'grande'),
-        
+class OneUPIE(IGNIE):
-__version__ = '2013.07.11'
+__version__ = '2013.07.12'
-__version__ = '2013.07.10'
+__version__ = '2013.07.11'
-    # 83 - vfl26ng3K 2013/07/10
+    # 83 - vflcaqGO8 2013/07/11
-     "qwertyuioplkjhgfdsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!#$%^&*()_+={[};?/>"),
+     "urty8ioplkjhgfdsazxcvbqm1234567S90QWERTYUIOPLKJHGFDnAZXCVBNM!#$%^&*()_+={[};?/>.<"),
-        right = "qwertyuioplkjhgfdsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!#$%^&*()_+={[};?/>"
+        right = "urty8ioplkjhgfdsazxcvbqm1234567S90QWERTYUIOPLKJHGFDnAZXCVBNM!#$%^&*()_+={[};?/>.<"
-            return s[:81]
+            return s[6] + s[3:6] + s[33] + s[7:24] + s[0] + s[25:33] + s[53] + s[34:53] + s[24] + s[54:]
-        u'file': u'zbvr8i.flv',
+        u'file': u'70e9a5d7-cf25-4a10-9104-6f3e7342ae0d.flv',
-        data = compat_urllib_parse.urlencode({'uri': mgid, 'acceptMethods': 'fms'})
+        mgid = self._search_regex([r'data-video="(?P<mgid>mgid:.*?)"',
-        links_webpage = self._download_webpage('http://www.gametrailers.com/feeds/mediagen/?' + data,
+        doc = xml.etree.ElementTree.fromstring(info_page.encode('utf-8'))
-        if m_urls is None or len(m_urls) == 0:
+        doc = xml.etree.ElementTree.fromstring(links_webpage)
-        video_url = m_urls[-1].group('url')
+        return urls[-1].text
-                }
+    find_xpath_attr,
-                  'playerID': object_doc.find('./param[@name="playerID"]').attrib['value'],
+                  'playerID': find_xpath_attr(object_doc, './param', 'name', 'playerID').attrib['value'],
-        playerKey = object_doc.find('./param[@name="playerKey"]')
+        playerKey = find_xpath_attr(object_doc, './param', 'name', 'playerKey')
-        videoPlayer = object_doc.find('./param[@name="@videoPlayer"]')
+        videoPlayer = find_xpath_attr(object_doc, './param', 'name', '@videoPlayer')
-        assert re.match(r'^[a-z]*$', val)
+        assert re.match(r'^[a-zA-Z]+$', key)
-        config_node = ref_xml_doc.find('.//video[@lang="%s"]' % lang)
+        config_node = find_xpath_attr(ref_xml_doc, './/video', 'lang', lang)
-        return self.video_result(info)
+        return info
-        return video_info
+            '_type': 'video',
-        return self.video_result(info)
+        return info
-from .ehow import EhowIE
+from .ehow import EHowIE
-from ..utils import compat_urllib_parse
+
-    _VALID_URL = r'(?:http://)?(?:www\.)?ehow\.com/([^/]+)'
+class EHowIE(InfoExtractor):
-        video_id = mobj.group(1).split("_")[1]
+        video_id = mobj.group('id')
-        video_url = self._search_regex(r'[^A-Za-z0-9]?(?:file|source)=(http[^\'"&]*)',
+        video_url = self._search_regex(r'(?:file|source)=(http[^\'"&]*)',
-            webpage, u'Video title').replace(' | eHow','')
+            webpage, u'Video title').replace(' | eHow', '')
-        return [{
+        ext = determine_ext(final_url)
-        }]
+        }
-        u'md5': u'a3513fb1547fba4fb6cfac1bffc6c46b',
+        u'url': u'http://www.ehow.com/video_12245069_hardwood-flooring-basics.html',
-            u"title": u"When Girls Act Like D-Bags"
+            u"title": u"Hardwood Flooring Basics",
-        assert object_doc.attrib['class'] == u'BrightcoveExperience'
+        assert u'BrightcoveExperience' in object_doc.attrib['class']
-        m_brightcove = re.search(r'<object.+?class="BrightcoveExperience".+?</object>', webpage, re.DOTALL)
+        m_brightcove = re.search(r'<object.+?class=".*?BrightcoveExperience.*?".+?</object>', webpage, re.DOTALL)
-    _VALID_URL = r'http://.*brightcove\.com/.*\?(?P<query>.*videoPlayer=(?P<id>\d*).*)'
+    _VALID_URL = r'https?://.*brightcove\.com/(services|viewer).*\?(?P<query>.*)'
-                  '@videoPlayer': object_doc.find('./param[@name="@videoPlayer"]').attrib['value'],
+        videoPlayer = object_doc.find('./param[@name="@videoPlayer"]')
-        video_id = mobj.group('id')
+        m_video_id = re.search(r'videoPlayer=(\d+)', query)
-        return {'id': video_id,
+
-                        u"title": u"Terraria 1.1 Trailer"
+                        u"title": u"Terraria 1.1 Trailer",
-                    u"title": u"Terraria Trailer"
+                    u"title": u"Terraria Trailer",
-        request_url = 'http://c.brightcove.com/services/viewer/htmlFederated?%s' % query
+        request_url = self._FEDERATED_URL_TEMPLATE % query
-    }
+    _TESTS = [
-__version__ = '2013.07.08.1'
+__version__ = '2013.07.10'
-    # 83
+    # 83 - vfl26ng3K 2013/07/10
-     "D.>/?;}[{=+_)(*&^%$#!MNBVCXeAS<FGHJKLPOIUYTREWZ0987654321mnbvcxzasdfghjklpoiuytrQ"),
+     "qwertyuioplkjhgfdsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!#$%^&*()_+={[};?/>"),
-        right = "D.>/?;}[{=+_)(*&^%$#!MNBVCXeAS<FGHJKLPOIUYTREWZ0987654321mnbvcxzasdfghjklpoiuytrQ"
+        right = "qwertyuioplkjhgfdsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!#$%^&*()_+={[};?/>"
-            return s[52] + s[81:55:-1] + s[2] + s[54:52:-1] + s[82] + s[51:36:-1] + s[55] + s[35:2:-1] + s[36]
+            return s[:81]
-    _VALID_URL = r'(?:http://)?(?:www\.)?gamespot\.com/([^/]+)/videos/([^/]+)-([^/d]+)/'
+    _VALID_URL = r'(?:http://)?(?:www\.)?gamespot\.com/.*-(?P<page_id>\d+)/?'
-        u"md5": u"5569d64ca98db01f0177c934fe8c1e9b",
+        u"md5": u"b2a30deaa8654fcccd43713a6b6a4825",
-        info_url = "http://www.gamespot.com/pages/video_player/xml.php?id="+str(video_id)
+        page_id = mobj.group('page_id')
-        video_url = clip_el.find('./URI').text
+        http_urls = [{'url': node.find('filePath').text,
-        }
+        },
-                    % (video_id, el_type))
+        if re.search(r'player-age-gate-content">', video_webpage) is not None:
-                break
+        else:
-                            self.to_screen('encrypted signature length %d (%d.%d), itag %s, html5 player %s' %
+                            if age_gate:
-        self.to_screen(video_url)
+
-            u'thumbnail': u'http://dotsub.com/media/aed3b8b2-1889-4df5-ae63-ad85f5572f27/p'
+            u'thumbnail': u'http://dotsub.com/media/aed3b8b2-1889-4df5-ae63-ad85f5572f27/p',
-        ext = 'flv'
+        date = time.gmtime(info['dateCreated']/1000) # The timestamp is in miliseconds
-            'view_count':  view_count,
+            'url':         info['mediaURI'],
-
+from .dotsub import DotsubIE
-            ies = [ie]
+            ies = [self.get_info_extractor(ie_key)]
-
+        (username, password) = self._get_login_info()
-
+    # from ..utils import compat_urllib_parse
-        streams = [m.groupdict() for m in re.finditer(self._MEDIA_STREAM, html)]
+        streams = [mo.groupdict() for mo in re.finditer(self._MEDIA_STREAM, html)]
-        url_entries = [self.url_result(url, 'BlipTV') for url in urls]
+        url_entries = [self.url_result(vurl, 'BlipTV') for vurl in urls]
-        url_results = [self.url_result(url, 'Youtube') for url in videos]
+        url_results = [self.url_result(vurl, 'Youtube') for vurl in videos]
-        url_entries = [self.url_result(url, 'Youtube') for url in urls]
+        url_entries = [self.url_result(eurl, 'Youtube') for eurl in urls]
-        url_results = [self.url_result(url, 'Youtube') for url in urls]
+        url_results = [self.url_result(rurl, 'Youtube') for rurl in urls]
-__version__ = '2013.07.08'
+__version__ = '2013.07.08.1'
-__version__ = '2013.07.07.01'
+__version__ = '2013.07.08'
-            json_url = self._html_search_regex(r'arte_vp_url="(.*?)"', webpage, 'json url')
+        webpage = self._download_webpage(url, video_id)
-    format_expressions = ['%d %B %Y', '%B %d %Y', '%b %d %Y', '%Y-%m-%d', '%d/%m/%Y', '%Y/%m/%d %H:%M:%S']
+    format_expressions = ['%d %B %Y', '%B %d %Y', '%b %d %Y', '%Y-%m-%d', '%d/%m/%Y', '%Y/%m/%d %H:%M:%S', '%d.%m.%Y %H:%M']
-        if 'thumbnail_url' not in video_info:
+        # We try first to get a high quality image:
-__version__ = '2013.07.07'
+__version__ = '2013.07.07.01'
-    _VALID_URL = r'https?://www\.youtube\.com/feed/subscriptions|ytsubscriptions'
+    IE_DESC = u'YouTube.com subscriptions feed, "ytsubs" keyword(requires authentication)'
-__version__ = '2013.07.05'
+__version__ = '2013.07.07'
-from .youtube import YoutubeIE, YoutubePlaylistIE, YoutubeSearchIE, YoutubeUserIE, YoutubeChannelIE, YoutubeShowIE
+from .youtube import (
-        if YoutubePlaylistIE.suitable(url): return False
+        if YoutubePlaylistIE.suitable(url) or YoutubeSubscriptionsIE.suitable(url): return False
-__version__ = '2013.07.04'
+__version__ = '2013.07.05'
-    unescapeHTML,
+        video_title = self._html_search_regex(r'<meta property="og:title" content="(.*?)" />',
-        video_uploader = None
+import json
-        # TODO: support choosing qualities
+        embed_url = 'http://www.dailymotion.com/embed/video/%s' % video_id
-        json_url = 'http://org-www.arte.tv/papi/tvguide/videos/stream/player/F/%s_PLUS7-F/ALL/ALL.json' % video_id
+        if video_id.replace('-','').isdigit():
-__version__ = '2013.07.02'
+__version__ = '2013.07.04'
-    _VIDEOS_URL = r'(?:http://)?videos.arte.tv/(?:fr|de)/.*-(?P<id>.*?).html'
+    _VIDEOS_URL = r'(?:http://)?videos.arte.tv/(?P<lang>fr|de)/.*-(?P<id>.*?).html'
-            return self._extract_video(url, id)
+            lang = mobj.group('lang')
-    def _extract_video(self, url, video_id):
+    def _extract_video(self, url, video_id, lang):
-        config_xml = self._download_webpage(config_xml_url, video_id)
+        ref_xml_url = url.replace('/videos/', '/do_delegate/videos/')
-    _EMISSION_URL = r'(?:http://)?www\.arte.tv/guide/(?:fr|de)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
+    _EMISSION_URL = r'(?:http://)?www\.arte.tv/guide/(?P<lang>fr|de)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
-            return self._extract_emission(url, video_id)
+            return self._extract_emission(url, video_id, lang)
-    def _extract_emission(self, url, video_id):
+    def _extract_emission(self, url, video_id, lang):
-        json_url = self._html_search_regex(r'arte_vp_url="(.*?)"', webpage, 'json url')
+        json_url = 'http://org-www.arte.tv/papi/tvguide/videos/stream/player/F/%s_PLUS7-F/ALL/ALL.json' % video_id
-    _VALID_URL = r'(?:http://)?(?:www\.)?tudou\.com/(?:listplay|programs)/(?:view|(.+?))/(?:([^/]+)|([^/]+)\.html)'
+    _VALID_URL = r'(?:http://)?(?:www\.)?tudou\.com/(?:listplay|programs)/(?:view|(.+?))/(?:([^/]+)|([^/]+))(?:\.html)?'
-        u'md5': u'ad7c358a01541e926a1e413612c6b10a',
+        u'file': u'159448201.f4v',
-            u"title": u"\u5361\u9a6c\u4e54\u56fd\u8db3\u5f00\u5927\u811a\u957f\u4f20\u51b2\u540a\u96c6\u9526"
+            u"title": u"å¡é©¬ä¹å½è¶³å¼å¤§èé¿ä¼ å²åéé¦"
-        video_id = mobj.group(2).replace('.html','')
+        video_id = mobj.group(2)
-        }]
+
-        u'md5': u'b2d849efcf7ee18917e4b4d9ff37cafe',
+        u'md5': u'80baf1ec5c3d2019037c1c707d676b9f',
-                video_url = data['media']['url']
+                if 'additionalMedia' in data:
-__version__ = '2013.06.34.4'
+__version__ = '2013.07.02'
-                raise ExtractorError(u'YouTube said: %s' % video_info['reason'][0])
+                raise ExtractorError(u'YouTube said: %s' % video_info['reason'][0], expected=True)
-        if not sys.exc_info()[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):
+    def __init__(self, msg, tb=None, expected=False):
-            pass
+            sys.exc_clear()
-                                  cwd=os.path.dirname(os.path.abspath(__file__)))
+            sp = subprocess.Popen(
-    packages = ['youtube_dl', 'youtube_dl.extractor'],
+    name='youtube_dl',
-    #test_requires = ['nosetest'],
+    # test_suite = 'nose.collector',
-    classifiers = [
+    classifiers=[
-    'options': { "py2exe": py2exe_options },
+    'options': {"py2exe": py2exe_options},
-                       ('share/man/man1/', ['youtube-dl.1'])]
+        'data_files': [  # Installing system-wide would require sudo...
-exec(compile(open('youtube_dl/version.py').read(), 'youtube_dl/version.py', 'exec'))
+exec(compile(open('youtube_dl/version.py').read(),
-    """This will create an exe that needs Microsoft Visual C++ 2008 Redistributable Package"""
+from .instagram import InstagramIE
-            webpage, u'video title', default=u'video')
+            webpage, u'video title', default=u'video', flags=re.DOTALL)
-    general.add_option('--list-extractor-descriptions',
+    general.add_option('--extractor-descriptions',
-
+    IE_DESC = u'The Daily Show / Colbert Report'
-
+    IE_DESC = u'Generic downloader that works on some sites'
-
+    IE_DESC = u'Google Plus'
-    """Information Extractor for Google Video search queries."""
+    IE_DESC = u'Google Video search'
-    _VALID_URL = r'^(?:https?://)?openclassroom.stanford.edu(?P<path>/?|(/MainFolder/(?:HomePage|CoursePage|VideoPage)\.php([?]course=(?P<course>[^&]+)(&video=(?P<video>[^&]+))?(&.*)?)?))$'
+    IE_DESC = u'Stanford Open ClassRoom'
-    """Information extractor for screen.yahoo.com."""
+    IE_DESC = u'Yahoo screen'
-
+    IE_DESC = u'Yahoo screen search'
-
+    IE_DESC = u'YouTube.com'
-
+    IE_DESC = u'YouTube.com playlists'
-
+    IE_DESC = u'YouTube.com channels'
-
+    IE_DESC = u'YouTube.com user videos (URL or "ytuser" keyword)'
-    """Information Extractor for YouTube search queries."""
+    IE_DESC = u'YouTube.com searches'
-        for ie in extractors:
+        for ie in sorted(extractors, key=lambda ie: ie.IE_NAME.lower()):
-from youtube_dl.extractor import YoutubeUserIE, YoutubePlaylistIE, YoutubeIE, YoutubeChannelIE
+from youtube_dl.extractor import YoutubeUserIE, YoutubePlaylistIE, YoutubeIE, YoutubeChannelIE, YoutubeShowIE
-from .youtube import YoutubeIE, YoutubePlaylistIE, YoutubeSearchIE, YoutubeUserIE, YoutubeChannelIE
+from .youtube import YoutubeIE, YoutubePlaylistIE, YoutubeSearchIE, YoutubeUserIE, YoutubeChannelIE, YoutubeShowIE
-                video_url_list = [(existing_formats[len(existing_formats)-1], url_map[existing_formats[len(existing_formats)-1]])] # worst quality
+                video_url_list = [(existing_formats[-1], url_map[existing_formats[-1]])] # worst quality
-                                 (?:watch(?:_popup)?(?:\.php)?)?              # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
+                                 (?:watch|movie(?:_popup)?(?:\.php)?)?              # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
-    general.add_option('--test', action='store_true', dest='test', default=False, help=optparse.SUPPRESS_HELP)
+
-        to_screen(u'It looks like you installed youtube-dl with pip, setup.py or a tarball. Please use that to update.')
+        to_screen(u'It looks like you installed youtube-dl with a package manager, pip, setup.py or a tarball. Please use that to update.')
-            u"title": u"Instagram photo by @videoseconds (Video)"
+            u"title": u"Instagram photo by @videoseconds"
-        title = html_title.rpartition(u' | Statigram')[0]
+        title = re.sub(r'(?: *\(Videos?\))? \| Statigram$', '', html_title)
-            u"title": u"Instagram photo by @videoseconds (Videos)"
+            u"title": u"Instagram photo by @videoseconds (Video)"
-        u'md5': u'0716d3dd51baf68a28b40fdf1251494e',
+        u'url': u'http://tatianamaslanydaily.tumblr.com/post/54196191430/orphan-black-dvd-extra-behind-the-scenes',
-            u"title": u"Rafael Lemos"
+            u"title": u"tatiana maslany news"
-    _VALID_URL = r'(?:http://)?www\.arte.tv/guide/(?:fr|de)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
+    """
-        video_id = mobj.group('id')
+        mobj = re.match(self._EMISSION_URL, url)
-            info_dict['ext'] = 'mp4'
+
-__version__ = '2013.06.34.3'
+__version__ = '2013.06.34.4'
-    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)'
+    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)(?:[?].*)?$'
-    html5 player enabled, it cannot download HD videos or the news.
+    html5 player enabled, it cannot download HD videos.
-        u'file': u'6bysb.mp4',
+        u'file': u'10635995.mp4',
-            u"title": u"CitroÃ«n Grand C4 Picasso 2013 : prÃ©sentation officielle"
+            u'title': u'CitroÃ«n Grand C4 Picasso 2013 : prÃ©sentation officielle',
-        u'file': u'6bv55.mp4',
+        u'file': u'10631273.mp4',
-            u"title": u"World War Z - Philadelphia VOST"
+            u'title': u'World War Z - Philadelphia VOST',
-                                             short_id, u'Downloading player info')
+                                             real_id, u'Downloading player info')
-        player_webpage = self._download_webpage(html5_player, short_id,
+        player_webpage = self._download_webpage(html5_player, real_id,
-        return {'id': short_id,
+        info = {'id': real_id,
-                'thumbnail': thumbnail,
+                'title': first_chapter['title'],
-        ext = video_url.partition('?')[0].rpartition('.')[2]
+        video_url = base64.b64decode(data['kpt'][0]).decode('utf-8')
-__version__ = '2013.06.34.2'
+__version__ = '2013.06.34.3'
-        u'md5': u'8cd9dfa41ee000ce658fd48fb5d89a61',
+        u'md5': u'2d76ee1576672e0bd8f187513267adf6',
-from .wat import WatIE, TF1IE
+from .wat import WatIE
-from .wat import WatIE
+from .wat import WatIE, TF1IE
-        """Decrypt the key"""
+        """Turn the encrypted s field into a working signature"""
-            msg = msg + u'; please report this issue on http://yt-dl.org/bug with the complete output by running the same command with --verbose flag'
+            msg = msg + u'; please report this issue on https://yt-dl.org/bug . Be sure to call youtube-dl with the --verbose flag and include its complete output.'
-            msg = msg + u'; please report this issue on http://yt-dl.org/bug'
+            msg = msg + u'; please report this issue on http://yt-dl.org/bug with the complete output by running the same command with --verbose flag'
-            print('Skipping: IE marked as not _WORKING')
+            print_skipping('IE marked as not _WORKING')
-            print('Skipping: No output file specified')
+            print_skipping('No output file specified')
-            print('Skipping: {0}'.format(test_case['skip']))
+            print_skipping(test_case['skip'])
-            ydl.add_info_extractor(ie)
+        ydl.add_default_info_extractors()
-from .extractor import get_info_extractor
+from .extractor import get_info_extractor, gen_extractors
-        ydl.add_info_extractor(extractor)
+    ydl.add_default_info_extractors()
-from youtube_dl.extractor import YoutubeIE, YoutubePlaylistIE, YoutubeChannelIE, JustinTVIE
+from youtube_dl.extractor import YoutubeIE, YoutubePlaylistIE, YoutubeChannelIE, JustinTVIE, gen_extractors
-            u"title": u"Rafael Lemos | Tumblr"
+            u"title": u"Rafael Lemos"
-        video_title = self._html_search_regex(r'<title>(?P<title>.*?)</title>',
+        video_title = self._html_search_regex(r'<title>(?P<title>.*?)(?: \| Tumblr)?</title>',
-        self.result.append(x)
+        self.result.append(x)
-
+from helper import get_testcases
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?soundcloud\.com/([\w\d-]+)/([\w\d-]+)'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?soundcloud\.com/([\w\d-]+)/([\w\d-]+)(?:[?].*)?$'
-    _VALID_URL = r'^(?:https?://)?(?:www\.)?soundcloud\.com/([\w\d-]+)/sets/([\w\d-]+)'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?soundcloud\.com/([\w\d-]+)/sets/([\w\d-]+)(?:[?].*)?$'
-__version__ = '2013.06.34.1'
+__version__ = '2013.06.34.2'
-    )
+    'Albert Kim',
-            u"skip_download": true
+            u"skip_download": True
-        u"params": { u"test": false },
+        u"params": { u"test": False },
-        u"name": u"Steam",
+    _TEST =   {
-            webpage, u'video title')
+            webpage, u'video title', default=u'video')
-            mobj = re.search(r'[^A-Za-z0-9]?file:\s*["\'](http[^\'"&]*)', webpage)
+            mobj = re.search(r'[^A-Za-z0-9]?file["\']?:\s*["\'](http[^\'"&]*)', webpage)
-              "description": "test chars:  \"'/\\Ã¤â­ð\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de ."
+            u"url":  u"http://www.youtube.com/watch?v=BaW_jenozKc",
-              "uploader_id": "MuteUSA"
+        },
-              "uploader_id": "IconaPop"
+        },
-          }
+        }
-        tname = 'test_'  + test_case['name'] + '_' + str(i)
+        tname = 'test_'  + str(test_case['name']) + '_' + str(i)
-        test_method.__name__ = "test_{0}_{1}".format(test_case["name"], n)
+    tname = 'test_' + str(test_case['name'])
-    ]
+    return [klass() for klass in _ALL_CLASSES]
-    IE_NAME = u'WorldStarHipHop'
+    _TEST = {
-from .auengine import AuengineIE
+from .auengine import AUEngineIE
-        AuengineIE(),
+        AUEngineIE(),
-class AuengineIE(InfoExtractor):
+class AUEngineIE(InfoExtractor):
-__version__ = '2013.06.34'
+__version__ = '2013.06.34.1'
-    IE_NAME = u'HotNewHipHop'
+    _VALID_URL = r'http://www\.hotnewhiphop.com/.*\.(?P<id>.*)\.html'
-        video_url = base64.b64decode(video_url_base64)
+        video_url = base64.b64decode(video_url_base64).decode('utf-8')
-            webpage_src, u'video URL')
+            webpage_src, u'video URL', fatal=False)
-import urlparse
+from ..utils import (
-        links = [urllib.unquote(l) for l in links]
+        links = [compat_urllib_parse.unquote(l) for l in links]
-            root, pathext = os.path.splitext(urlparse.urlparse(link).path)
+            root, pathext = os.path.splitext(compat_urllib_parse_urlparse(link).path)
-        """Decrypt the key the two subkeys must have a length of 43"""
+        """Decrypt the key"""
-            raise ExtractorError(u'Unable to decrypt signature, subkeys length %d not supported; retrying might work' % (len(s)))
+            raise ExtractorError(u'Unable to decrypt signature, key length %d not supported; retrying might work' % (len(s)))
-__version__ = '2013.06.33'
+__version__ = '2013.06.34'
-            self.to_screen('encrypted signature length %d' % (len(s)))
+                        if self._downloader.params.get('verbose'):
-     "ertyuioplkjhgfdqazxcvbnm1234567890QWERT}UIOPLKJHGFDSAZXCVBNM!@#$%^&*()_-+={[|/;?Y"),
+     "ertyuioplkjhgfdsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!/#$%^&*()_-+={[|};?@"),
- 
+
- 
+
-        right = "ertyuioplkjhgfdqazxcvbnm1234567890QWERT}UIOPLKJHGFDSAZXCVBNM!@#$%^&*()_-+={[|/;?Y"
+        right = "ertyuioplkjhgfdsazxcvbnm1234567890QWERTYUIOPLKJHGFDSAZXCVBNM!/#$%^&*()_-+={[|};?@"
- 
+
- 
+
- 
+
- 
+
-            return s[2:17] + s[0] + s[18:41] + s[79] + s[42:79] + s[82] + s[80:82] + s[41]
+            return s[2:63] + s[82] + s[64:82] + s[63]
-            return s[48] + s[81] + s[80] + s[79] + s[78] + s[77] + s[76] + s[75] + s[74] + s[73] + s[72] + s[71] + s[70] + s[69] + s[68] + s[82] + s[66] + s[65] + s[64] + s[63] + s[85] + s[61] + s[60] + s[59] + s[58] + s[57] + s[56] + s[55] + s[54] + s[53] + s[52] + s[51] + s[50] + s[49] + s[67] + s[47] + s[46] + s[45] + s[44] + s[43] + s[42] + s[41] + s[40] + s[39] + s[38] + s[37] + s[36] + s[35] + s[34] + s[33] + s[32] + s[31] + s[30] + s[29] + s[28] + s[27] + s[26] + s[25] + s[24] + s[23] + s[22] + s[21] + s[20] + s[19] + s[18] + s[17] + s[16] + s[15] + s[14] + s[13] + s[3] + s[11] + s[10] + s[9] + s[8] + s[7] + s[6] + s[5] + s[4] + s[2] + s[12]
+            return s[48] + s[81:67:-1] + s[82] + s[66:62:-1] + s[85] + s[61:48:-1] + s[67] + s[47:12:-1] + s[3] + s[11:3:-1] + s[2] + s[12]
-            return s[62] + s[82] + s[81] + s[80] + s[79] + s[78] + s[77] + s[76] + s[75] + s[74] + s[73] + s[72] + s[71] + s[70] + s[69] + s[68] + s[67] + s[66] + s[65] + s[64] + s[63] + s[83] + s[61] + s[60] + s[59] + s[58] + s[57] + s[56] + s[55] + s[54] + s[53] + s[0] + s[51] + s[50] + s[49] + s[48] + s[47] + s[46] + s[45] + s[44] + s[43] + s[42] + s[41] + s[40] + s[39] + s[38] + s[37] + s[36] + s[35] + s[34] + s[33] + s[32] + s[31] + s[30] + s[29] + s[28] + s[27] + s[26] + s[25] + s[24] + s[23] + s[22] + s[21] + s[20] + s[19] + s[18] + s[17] + s[16] + s[15] + s[14] + s[13] + s[12] + s[11] + s[10] + s[9] + s[8] + s[7] + s[6] + s[5] + s[4] + s[3]
+            return s[62] + s[82:62:-1] + s[83] + s[61:52:-1] + s[0] + s[51:2:-1]
-            return s[2] + s[3] + s[4] + s[5] + s[6] + s[7] + s[8] + s[9] + s[10] + s[11] + s[12] + s[13] + s[14] + s[15] + s[16] + s[0] + s[18] + s[19] + s[20] + s[21] + s[22] + s[23] + s[24] + s[25] + s[26] + s[27] + s[28] + s[29] + s[30] + s[31] + s[32] + s[33] + s[34] + s[35] + s[36] + s[37] + s[38] + s[39] + s[40] + s[79] + s[42] + s[43] + s[44] + s[45] + s[46] + s[47] + s[48] + s[49] + s[50] + s[51] + s[52] + s[53] + s[54] + s[55] + s[56] + s[57] + s[58] + s[59] + s[60] + s[61] + s[62] + s[63] + s[64] + s[65] + s[66] + s[67] + s[68] + s[69] + s[70] + s[71] + s[72] + s[73] + s[74] + s[75] + s[76] + s[77] + s[78] + s[82] + s[80] + s[81] + s[41]
+            return s[2:17] + s[0] + s[18:41] + s[79] + s[42:79] + s[82] + s[80:82] + s[41]
-            return s[76] + s[82] + s[81] + s[80] + s[79] + s[78] + s[77] + s[83] + s[75] + s[74] + s[73] + s[72] + s[71] + s[70] + s[69] + s[68] + s[67] + s[66] + s[65] + s[64] + s[63] + s[62] + s[61] + s[0] + s[59] + s[58] + s[57] + s[56] + s[55] + s[54] + s[53] + s[52] + s[51] + s[1] + s[49] + s[48] + s[47] + s[46] + s[45] + s[44] + s[43] + s[42] + s[41] + s[40] + s[39] + s[38] + s[37] + s[36] + s[35] + s[34] + s[33] + s[32] + s[31] + s[30] + s[29] + s[28] + s[27] + s[26] + s[25] + s[24] + s[23] + s[22] + s[21] + s[20] + s[19] + s[18] + s[17] + s[16] + s[15] + s[14] + s[13] + s[12] + s[11] + s[10] + s[9] + s[8] + s[7] + s[6] + s[5] + s[4] + s[3]
+            return s[76] + s[82:76:-1] + s[83] + s[75:60:-1] + s[0] + s[59:50:-1] + s[1] + s[49:2:-1]
-            return s[83] + s[82] + s[81] + s[80] + s[79] + s[78] + s[77] + s[76] + s[75] + s[74] + s[73] + s[72] + s[71] + s[70] + s[69] + s[68] + s[67] + s[66] + s[65] + s[64] + s[63] + s[62] + s[61] + s[60] + s[59] + s[58] + s[57] + s[56] + s[55] + s[54] + s[53] + s[52] + s[51] + s[50] + s[49] + s[48] + s[47] + s[46] + s[45] + s[44] + s[43] + s[42] + s[41] + s[40] + s[39] + s[38] + s[37] + s[2] + s[35] + s[34] + s[33] + s[32] + s[31] + s[30] + s[29] + s[28] + s[27] + s[3] + s[25] + s[24] + s[23] + s[22] + s[21] + s[20] + s[19] + s[18] + s[17] + s[16] + s[15] + s[14] + s[13] + s[12] + s[11] + s[10] + s[9] + s[8] + s[7] + s[6] + s[5] + s[4] + s[26]
+            return s[83:36:-1] + s[2] + s[35:26:-1] + s[3] + s[25:3:-1] + s[26]
-            return s[52] + s[81] + s[80] + s[79] + s[78] + s[77] + s[76] + s[75] + s[74] + s[73] + s[72] + s[71] + s[70] + s[69] + s[68] + s[67] + s[66] + s[65] + s[64] + s[63] + s[62] + s[61] + s[60] + s[59] + s[58] + s[57] + s[56] + s[2] + s[54] + s[53] + s[82] + s[51] + s[50] + s[49] + s[48] + s[47] + s[46] + s[45] + s[44] + s[43] + s[42] + s[41] + s[40] + s[39] + s[38] + s[37] + s[55] + s[35] + s[34] + s[33] + s[32] + s[31] + s[30] + s[29] + s[28] + s[27] + s[26] + s[25] + s[24] + s[23] + s[22] + s[21] + s[20] + s[19] + s[18] + s[17] + s[16] + s[15] + s[14] + s[13] + s[12] + s[11] + s[10] + s[9] + s[8] + s[7] + s[6] + s[5] + s[4] + s[3] + s[36]
+            return s[52] + s[81:55:-1] + s[2] + s[54:52:-1] + s[82] + s[51:36:-1] + s[55] + s[35:2:-1] + s[36]
-            return s[36] + s[79] + s[78] + s[77] + s[76] + s[75] + s[74] + s[73] + s[72] + s[71] + s[70] + s[69] + s[68] + s[81] + s[66] + s[65] + s[64] + s[63] + s[62] + s[61] + s[60] + s[59] + s[58] + s[57] + s[56] + s[55] + s[54] + s[53] + s[52] + s[51] + s[50] + s[49] + s[48] + s[47] + s[46] + s[45] + s[44] + s[43] + s[42] + s[41] + s[33] + s[39] + s[38] + s[37] + s[40] + s[35] + s[0] + s[67] + s[32] + s[31] + s[30] + s[29] + s[28] + s[27] + s[26] + s[25] + s[24] + s[23] + s[22] + s[21] + s[20] + s[19] + s[18] + s[17] + s[16] + s[15] + s[14] + s[13] + s[12] + s[11] + s[10] + s[9] + s[8] + s[7] + s[6] + s[5] + s[4] + s[3] + s[2] + s[1] + s[34]
+            return s[36] + s[79:67:-1] + s[81] + s[66:40:-1] + s[33] + s[39:36:-1] + s[40] + s[35] + s[0] + s[67] + s[32:0:-1] + s[34]
-
+from .hotnewhiphop import HotNewHipHopIE
-        return s_dec
+            self.to_screen('encrypted signature length %d' % (len(s)))
-import socket
+import json
-    compat_urllib_error,
+    # This is used by the not implemented extractLiveStream method
-    _VALID_URL = r'(?:http://)?videos\.arte\.tv/(?:fr|de)/videos/.*'
+    _VALID_URL = r'(?:http://)?www\.arte.tv/guide/(?:fr|de)/(?:(?:sendungen|emissions)/)?(?P<id>.*?)/(?P<name>.*?)(\?.*)?'
-        self.report_extraction(video_id)
+        mobj = re.match(self._VALID_URL, url)
-            info = self.extractPlus7Stream(url)
+            info_dict['url'] = format_info['url']
-        return [info]
+        return info_dict
-        return url
+from helper import FakeYDL
-        self.result.append(x)
+from helper import FakeYDL
-                'description': officialTitle,
+                'description': compat_str(officialTitle),
-    unified_strdate,
+from .cspan import CSpanIE
-        final_url = self._search_regex(b'","(.*?)"', googleString,'final video url')
+        googleString = base64.b64decode(googleString).decode('ascii')
-        self.ydl.error(*args, **kargs)
+        self.ydl.report_error(*args, **kargs)
-        final_url = self._search_regex('","(.*?)"', googleString,'final video url')
+        final_url = self._search_regex(b'","(.*?)"', googleString,'final video url')
-        final_url = re.search('","(.*?)"', googleString).group(1)
+        title = self._search_regex('\<meta name\="description" content="(.+?)" \/\>',webpage, 'video title')
-    subtitlesformat:   Subtitle format [srt/sbt/vtt] (default=srt)
+    subtitlesformat:   Subtitle format [srt/sbv/vtt] (default=srt)
-    def test_youtube_subtitles_format(self):
+    def test_youtube_subtitles_sbv_format(self):
-    subtitlesformat:   Subtitle format [sbv/srt] (default=srt)
+    subtitlesformat:   Subtitle format [srt/sbt/vtt] (default=srt)
-            help='subtitle format [srt/sbv] (default=srt) (currently youtube only)', default='srt')
+            help='subtitle format [srt/sbv/vtt] (default=srt) (currently youtube only)', default='srt')
-        DL.params['writesubtitles'] = True
+        DL.params['writeautomaticsub'] = True
-        if self.params.get('writesubtitles', False) and 'subtitles' in info_dict and info_dict['subtitles']:
+        if (self.params.get('writesubtitles', False) or self.params.get('writeautomaticsub')) and 'subtitles' in info_dict and info_dict['subtitles']:
-                        self._downloader.report_warning(sub_error)
+                    self._downloader.report_warning(sub_error)
-__version__ = '2013.06.32'
+__version__ = '2013.06.33'
-        sys.stderr.write(u'WARNING: account username missing\n')
+        parser.error(u' account username missing\n')
-        password = self._downloader.params.get('password', None)
+        password = self._downloader.params.get('videopassword', None)
-            raise ExtractorError(u'This video is protected by a password, use the --password option')
+            raise ExtractorError(u'This video is protected by a password, use the --video-password option')
-    _VALID_URL = r'^http://www\.jukebox\.es\/.+[,](?P<video_id>[a-z0-9]+).html'
+    _VALID_URL = r'^http://www\.jukebox?\..+?\/.+[,](?P<video_id>[a-z0-9\-]+).html'
-        mobj = re.search(self._NOT_AVAILABLE, iframe_html)
+        mobj = re.search(r'class="jkb_waiting"', iframe_html)
-from .comedycentral import ComedyCentralIE
+from .comedycentral import ComedyCentralIE
-from .justintv import JustinTVIE
+from .justintv import JustinTVIE
-from .statigram import StatigramIE
+from .statigram import StatigramIE
-from .xnxx import XNXXIE
+from .xnxx import XNXXIE
-from .tudou import TudouIE
+
-__version__ = '2013.06.31'
+__version__ = '2013.06.32'
-__version__ = '2013.06.30'
+__version__ = '2013.06.31'
-        video_page = self._search_regex('"(https\://plus\.google\.com/photos/.*?)",,"image/jpeg","video"\]',
+        # Step 2, Simulate clicking the image box to launch video
-        pattern = '\d+,\d+,(\d+),"(http\://redirector\.googlevideo\.com.*?)"'
+        pattern = r'\d+,\d+,(\d+),"(http\://redirector\.googlevideo\.com.*?)"'
-            raise ExtractorError(u'found YT video. Please run youtube-dl again and use the following link: '+youtube_url+' ')
+            self.to_screen(u'Youtube video detected')
-                u'please report this issue on GitHub.' % _name)
+                u'please report this issue on http://yt-dl.org/bug' % _name)
-    def _decrypt_signature(s):
+    def _decrypt_signature(self, s):
-            raise ExtractorError(u'Unable to decrypt signature, subkeys lengths not valid')
+            raise ExtractorError(u'Unable to decrypt signature, subkeys lengths %d.%d not supported; retrying might work' % (len(a), len(b)))
-            msg = msg + u'; please report this issue on GitHub.'
+            msg = msg + u'; please report this issue on http://yt-dl.org/bug'
-for test_case in defs:
+for n, test_case in enumerate(defs):
-__version__ = '2013.06.29'
+__version__ = '2013.06.30'
-                self.to_screen(u'%s: Vevo video detected.' % video_id)
+            # Easy way to know if the 's' value is in url_encoded_fmt_stream_map
-            print(u'[debug] Override config: ' + repr(overrideArguments))
+            sys.stderr.write(u'[debug] Override config: ' + repr(overrideArguments) + '\n')
-            print(u'[debug] Command-line args: ' + repr(commandLineConf))
+            sys.stderr.write(u'[debug] System config: ' + repr(systemConf) + '\n')
-        print(std_headers['User-Agent'])
+        compat_print(std_headers['User-Agent'])
-            print(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else ''))
+            compat_print(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else ''))
-                print(u'  ' + mu)
+                compat_print(u'  ' + mu)
-        print(u'WARNING: account username missing')
+        sys.stderr.write(u'WARNING: account username missing\n')
-__version__ = '2013.06.28'
+__version__ = '2013.06.29'
-    _VALID_URL = r'http://www.vevo.com/watch/.*?/.*?/(?P<id>.*)$'
+    """
-__version__ = '2013.06.27'
+__version__ = '2013.06.28'
-__version__ = '2013.06.26'
+__version__ = '2013.06.27'
-from youtube_dl.FileDownloader import FileDownloader
+from youtube_dl import YoutubeDL
-class FakeDownloader(FileDownloader):
+class FakeYDL(YoutubeDL):
-        dl = FakeDownloader()
+        dl = FakeYDL()
-        dl = FakeDownloader()
+        dl = FakeYDL()
-        dl = FakeDownloader()
+        dl = FakeYDL()
-        dl = FakeDownloader()
+        dl = FakeYDL()
-        dl = FakeDownloader()
+        dl = FakeYDL()
-        dl = FakeDownloader()
+        dl = FakeYDL()
-        dl = FakeDownloader()
+        dl = FakeYDL()
-        dl = FakeDownloader()
+        dl = FakeYDL()
-        dl = FakeDownloader()
+        dl = FakeYDL()
-from youtube_dl import FileDownloader
+from youtube_dl import YoutubeDL
-class FakeDownloader(FileDownloader):
+class FakeYDL(YoutubeDL):
-        DL = FakeDownloader()
+        DL = FakeYDL()
-        DL = FakeDownloader()
+        DL = FakeYDL()
-        DL = FakeDownloader()
+        DL = FakeYDL()
-        DL = FakeDownloader()
+        DL = FakeYDL()
-        DL = FakeDownloader()
+        DL = FakeYDL()
-        DL = FakeDownloader()
+        DL = FakeYDL()
-        DL = FakeDownloader()
+        DL = FakeYDL()
-        DL = FakeDownloader()
+        DL = FakeYDL()
-        DL = FakeDownloader()
+        DL = FakeYDL()
-import youtube_dl.FileDownloader
+import youtube_dl.YoutubeDL
-class FileDownloader(youtube_dl.FileDownloader):
+class YoutubeDL(youtube_dl.YoutubeDL):
-        return youtube_dl.FileDownloader.__init__(self, *args, **kwargs)
+        super(YoutubeDL, self).__init__(*args, **kwargs)
-        return youtube_dl.FileDownloader.process_info(self, info_dict)
+        return super(YoutubeDL, self).process_info(info_dict)
-        fd = FileDownloader(params)
+        ydl = YoutubeDL(params)
-            fd.add_info_extractor(ie)
+            ydl.add_info_extractor(ie)
-        fd.add_progress_hook(_hook)
+        ydl.fd.add_progress_hook(_hook)
-                    fd.download([test_case['url']])
+                    ydl.download([test_case['url']])
-import youtube_dl.FileDownloader
+import youtube_dl.YoutubeDL
-class FileDownloader(youtube_dl.FileDownloader):
+class YoutubeDL(youtube_dl.YoutubeDL):
-        youtube_dl.FileDownloader.__init__(self, *args, **kwargs)
+        super(YoutubeDL, self).__init__(*args, **kwargs)
-        fd.download([TEST_ID])
+        ydl = YoutubeDL(params)
-    downloading the video.
+    actual video file and writing it to disk.
-    that are added to it, so this is a "mutual registration".
+    options instead.
-    usenetrc:          Use netrc for authentication instead.
+    verbose:           Print additional info to stdout.
-    def __init__(self, params):
+    def __init__(self, ydl, params):
-        self._pps = []
+        self.ydl = ydl
-            self._screen_file.flush()
+    def to_screen(self, *args, **kargs):
-        sys.stderr.write(output)
+        self.ydl.to_screen(message)
-        """Determine action to take when a download problem appears.
+    def trouble(self, *args, **kargs):
-        not when errors are found, after printing the message.
+    def report_warning(self, *args, **kargs):
-        self.trouble(error_message, tb)
+    def report_error(self, *args, **kargs):
-
+#!/usr/bin/env python
-    fd = FileDownloader({
+    # YoutubeDL
-        fd.to_screen(u'[debug] youtube-dl version ' + __version__)
+        ydl.to_screen(u'[debug] youtube-dl version ' + __version__)
-                fd.to_screen(u'[debug] Git HEAD: ' + out)
+                ydl.to_screen(u'[debug] Git HEAD: ' + out)
-        fd.to_screen(u'[debug] Proxy map: ' + str(proxy_handler.proxies))
+        ydl.to_screen(u'[debug] Python version %s - %s' %(platform.python_version(), platform.platform()))
-        fd.add_info_extractor(extractor)
+        ydl.add_info_extractor(extractor)
-        fd.add_post_processor(FFmpegExtractAudioPP(preferredcodec=opts.audioformat, preferredquality=opts.audioquality, nopostoverwrites=opts.nopostoverwrites))
+        ydl.add_post_processor(FFmpegExtractAudioPP(preferredcodec=opts.audioformat, preferredquality=opts.audioquality, nopostoverwrites=opts.nopostoverwrites))
-        fd.add_post_processor(FFmpegVideoConvertor(preferedformat=opts.recodevideo))
+        ydl.add_post_processor(FFmpegVideoConvertor(preferedformat=opts.recodevideo))
-        update_self(fd.to_screen, opts.verbose, sys.argv[0])
+        update_self(ydl.to_screen, opts.verbose, sys.argv[0])
-        retcode = fd.download(all_urls)
+        retcode = ydl.download(all_urls)
-        fd.to_screen(u'--max-download limit reached, aborting.')
+        ydl.to_screen(u'--max-download limit reached, aborting.')
-            if args.get('ptk','') == 'vevo' or 'dashmpd':
+            if args.get('ptk','') == 'vevo' or 'dashmpd' in args:
-        '38': 'video', # You actually don't know if this will be MOV, AVI or whatever
+        '38': 'mp4',
-__version__ = '2013.06.25'
+__version__ = '2013.06.26'
-__version__ = '2013.06.24'
+__version__ = '2013.06.25'
-__version__ = '2013.06.23'
+__version__ = '2013.06.24'
-    "dll_excludes": ['w9xpopen.exe']
+    "dll_excludes": ['w9xpopen.exe'],
-    packages = ['youtube_dl'],
+    packages = ['youtube_dl', 'youtube_dl.extractor'],
-__version__ = '2013.06.21'
+__version__ = '2013.06.23'
-import youtube_dl.extractors
+import youtube_dl.extractor
-        ie = youtube_dl.extractors.get_info_extractor(test_case['name'])
+        ie = youtube_dl.extractor.get_info_extractor(test_case['name'])
-        for ie in youtube_dl.extractors.gen_extractors():
+        for ie in youtube_dl.extractor.gen_extractors():
-                                         u'unable to download video info JSON')
+        info_json = self._download_webpage(url, video_id,
-        response = json.loads(webpage)
+        response = json.loads(info_json)
-from youtube_dl.InfoExtractors import YoutubeIE, YoutubePlaylistIE, YoutubeChannelIE, JustinTVIE
+from youtube_dl.extractor import YoutubeIE, YoutubePlaylistIE, YoutubeChannelIE, JustinTVIE
-import youtube_dl.InfoExtractors
+import youtube_dl.extractors
-        ie = youtube_dl.InfoExtractors.get_info_extractor(test_case['name'])
+        ie = youtube_dl.extractors.get_info_extractor(test_case['name'])
-        for ie in youtube_dl.InfoExtractors.gen_extractors():
+        for ie in youtube_dl.extractors.gen_extractors():
-import youtube_dl.InfoExtractors
+import youtube_dl.extractor
-        ie = youtube_dl.InfoExtractors.YoutubeIE()
+        ie = youtube_dl.extractor.YoutubeIE()
-from youtube_dl.InfoExtractors import YoutubeUserIE, YoutubePlaylistIE, YoutubeIE, YoutubeChannelIE
+from youtube_dl.extractor import YoutubeUserIE, YoutubePlaylistIE, YoutubeIE, YoutubeChannelIE
-from youtube_dl.InfoExtractors import YoutubeIE
+from youtube_dl.extractor import YoutubeIE
-from .InfoExtractors import get_info_extractor
+from .extractor import get_info_extractor
-from .InfoExtractors import gen_extractors
+from .extractor import gen_extractors
-from .extractor import *
+from .extractor import gen_extractors, get_info_extractor
-from .extractor.zdf import ZDFIE
+
-    return globals()[ie_name+'IE']
+from .extractor import *
-
+from .extractor.xhamster import XHamsterIE
-        }]
+import re
-        }]
+import re
-        }]
+import re
-        }]
+import re
-        }]
+import json
-        }]
+import re
-            raise ExtractorError(u'Invalid URL: %s' % url)
+from .extractor.redtube import RedTubeIE
-        
+import re
-        }]
+import re
-        }]
+import re
-        return [track_info]
+import json
-                 }]
+import re
-        return [info]
+import re
-        return [info]
+import re
-        return [info]
+import os.path
-        return [info]
+import re
-        return res
+import itertools
-        return [info]
+import re
-        return [info]
+import re
-            return [format]
+import json
-        return [info]
+import json
-        return info
+import re
-        return info
+import json
-)
+from .extractor.funnyordie import FunnyOrDieIE
-        return [info]
+import re
-        return results
+import re
-        return [self.playlist_result(videos, gameID, game_title)]
+import re
-        return files_info
+import json
-        }]
+import json
-        return info
+import json
-            webpage, u'song name', fatal=False)
+        #song_name = self._html_search_regex(r'<meta name="mtv_vt" content="([^"]+)"/>',
-            'uploader': performer,
+import re
-                        self.assertEqual(value, 'md5:' + md5(info_dict.get(info_field)))
+                for (info_field, expected) in tc.get('info_dict', {}).items():
-                        self.assertEqual(value, info_dict.get(info_field), u'invalid value for field ' + info_field)
+                        got = info_dict.get(info_field)
-        return [info]
+from .extractor.nba import NBAIE
-        return [info]
+import re
-            return results
+import re
-
+import base64
-
+import re
-
+import re
-        return [info]
+import json
-    IE_NAME = u'escapist'
+from .extractor.depositfiles import DepositFilesIE
-        }]
+import re
-        return [info]
+import json
-        return videos
+import json
-from .extractor.google import GoogleSearchIE
+from .extractor.googleplus import GooglePlusIE
-        }]
+import datetime
-        return results
+import re
-
+import binascii
-        return [info]
+import datetime
-from .extractor.yahoo import YahooIE
+from .extractor.yahoo import YahooIE, YahooSearchIE
-        return res
+import itertools
-from .common import InfoExtractor
+from .common import InfoExtractor, SearchInfoExtractor
-                return res
+import itertools
-        }]
+import os
-                }
+import re
-from .extractor.youtube import YoutubeIE, YoutubePlaylistIE, YoutubeUserIE, YoutubeChannelIE
+from .extractor.youtube import YoutubeIE, YoutubePlaylistIE, YoutubeSearchIE, YoutubeUserIE, YoutubeChannelIE
-from .common import InfoExtractor
+from .common import InfoExtractor, SearchInfoExtractor
-        video_url = u'%s/%s' % (info.get('url'), info.get('path'))
+    # TODO implement Live Stream
-            return
+            raise ExtractorError(u'Arte live streams are not yet supported, sorry')
-
+
-                 }]
+import re
-        }]
+import json
-
+import datetime
-        }]
+import datetime
-        }]
+import re
-
+import re
-            age_results = compat_urllib_request.urlopen(request).read().decode('utf-8')
+            compat_urllib_request.urlopen(request).read().decode('utf-8')
-            sub_lang_list = self._list_available_subtitles(video_id)
+            self._list_available_subtitles(video_id)
-
+from .extractor.youtube import YoutubeIE, YoutubePlaylistIE, YoutubeUserIE, YoutubeChannelIE
-
+# coding: utf-8
-        raise NotImplementedError("This method must be implemented by sublclasses")
+from .extractor.common import InfoExtractor, SearchInfoExtractor
-                self.to_screen(u'Vevo video detected.')
+                self.to_screen(u'%s: Vevo video detected.' % video_id)
-                    if 's' in url_data:
+                    elif 's' in url_data:
-            r'@(.+) \(Videos\)', title, u'uploader name', fatal=False)
+        uploader_id = self._html_search_regex(
-            'uploader' : uploader
+            'uploader_id' : uploader_id
-                        self.assertEqual(value, info_dict.get(info_field))
+                        self.assertEqual(value, info_dict.get(info_field), u'invalid value for field ' + info_field)
-class StatigrIE(InfoExtractor):
+class StatigramIE(InfoExtractor):
-            raise ExtractorError(u'Invalid URL: %s' % url)
+
-        ext = "mp4"
+        video_url = self._html_search_regex(
-        StatigrIE(),
+        StatigramIE(),
-        print uploader
+class StatigrIE(InfoExtractor):
-            action='store', dest='subtitlesformat', metavar='LANG',
+            action='store', dest='subtitlesformat', metavar='FORMAT',
-                        self._downloader.report_error(sub_error)
+                        self._downloader.report_warning(sub_error)
-                    self._downloader.report_error(sub_error)
+                    self._downloader.report_warning(sub_error)
-                        url += '&signature=' + key
+                        signature = self._decrypt_signature(url_data['s'][0])
-            if 'dashmpd' in info['args']:
+            args = info['args']
-                video_info['url_encoded_fmt_stream_map'] = [info['args']['url_encoded_fmt_stream_map']]
+                video_info['url_encoded_fmt_stream_map'] = [args['url_encoded_fmt_stream_map']]
-        sub_lang = self._downloader.params.get('subtitleslang')
+        sub_lang = self._downloader.params.get('subtitleslang') or 'en'
-                    if not 'ratebypass' in url: url += '&ratebypass=yes'
+                    url = url_data['url'][0]
-__version__ = '2013.05.23'
+__version__ = '2013.06.21'
-        playlist_title = m_playlist.group('playlist_title')
+        playlist_title = self._html_search_regex(r'div class="headline">\s*?<h1>\s*?<span>(.*?)</span>',
-        webpage=self._download_webpage(url, video_id, 'Downloading \"%s\" page' % videoName)
+        m = re.match(self._VALID_URL, url,re.VERBOSE)
-        video_url=self._talk_video_link(mediaSlug)
+        title = self._html_search_regex(r'<span id="altHeadline" >(?P<title>.*)</span>',
-                'url': video_url,
+                'id': info['id'],
-                'thumbnail': thumb_match.group('thumbnail')
+                'thumbnail': thumbnail,
-                        if 'content' in entry ]
+            for entry in response['feed']['entry']:
-            webpage, u'json data')
+        json_data = self._search_regex(r'window\.gon.*?gon\.show=(.+?);$',
-            video_uploader = mobj.group(1)
+        video_uploader = self._search_regex([r'(?im)<span class="owner[^\"]+?">[^<]+?<a [^>]+?>([^<]+?)</a>',
-        video_page = self._search_regex('href="(https\://plus\.google\.com/photos/.*?)"',
+        video_page = self._search_regex('"(https\://plus\.google\.com/photos/.*?)",,"image/jpeg","video"\]',
-        self.report_age_confirmation()
+
-        
+
-        video_page = self._search_regex('"(https\://plus\.google\.com/photos/.*?)",,"image/jpeg","video"\]',
+        video_page = self._search_regex('href="(https\://plus\.google\.com/photos/.*?)"',
-        redirect_url = urlh.geturl() + re.search(r'window\.location = \'(.*)\';', redirect_page).group(1)
+        new_location = self._search_regex(r'window\.location = \'(.*)\';', redirect_page, u'redirect location')
-        title = (title.group(1)).split('/')[0].strip()
+        title = self._html_search_regex(r'<title>(.*)</title>',
-        mgid = m_mgid.group(1)
+        mgid = self._search_regex(mgid_re, webpage, u'mgid')
-        if m_urls is None:
+        m_urls = list(re.finditer(r'<src>(?P<url>.*)</src>', links_webpage))
-        video_url = list(m_urls)[-1].group('url')
+        video_url = m_urls[-1].group('url')
-        video_title = mobj.group(1)
+        video_title = self._html_search_regex(r'<title>(.*)</title>',
-        video_uploader = mobj.group(1)
+        video_uploader = self._search_regex(r'(?:https?://)?([^/]*)/.*',
-        parser.error(u'account username missing')
+        print(u'WARNING: account username missing')
-        self.assertTrue(len(result['entries']) > 40)
+        self.assertTrue(len(result['entries']) > 25)
-    _TEMPLATE_URL = 'https://gdata.youtube.com/feeds/api/playlists/%s?max-results=%i&start-index=%i&v=2&alt=json'
+    _TEMPLATE_URL = 'https://gdata.youtube.com/feeds/api/playlists/%s?max-results=%i&start-index=%i&v=2&alt=json&safeSearch=none'
-        query = query.decode(preferredencoding())
+        verbosity_option = '--verbose' if self.params.get('verbose', False) else '--quiet'
-        if self.params.get('verbose', False): basic_args[1] = '-v'
+        basic_args = ['rtmpdump', verbosity_option, '-r', url, '-o', tmpfilename]
-            basic_args += ['-W', player_url]
+            basic_args += ['--swfVfy', player_url]
-            basic_args += ['-y', play_path]
+            basic_args += ['--playpath', play_path]
-        args = basic_args + [[], ['-e', '-k', '1']][self.params.get('continuedl', False)]
+        args = basic_args + [[], ['--resume', '--skip', '1']][self.params.get('continuedl', False)]
-        proxies = {'http': opts.proxy, 'https': opts.proxy}
+    if opts.proxy is not None:
-    return '%08x' % (binascii.crc32(value.encode('utf8')) & 0xffffffff)
+md5 = lambda s: hashlib.md5(s.encode('utf-8')).hexdigest()
-                        self.assertEqual(value, 'crc32:' + crc32(info_dict.get(info_field)))
+                    if isinstance(value, compat_str) and value.startswith('md5:'):
-                test_info_dict = dict((key, value if not isinstance(value, compat_str) or len(value) < 250 else 'crc32:' + crc32(value))
+                test_info_dict = dict((key, value if not isinstance(value, compat_str) or len(value) < 250 else 'md5:' + md5(value))
-import hashlib
+import binascii
-                    self.assertEqual(value, info_dict.get(info_field))
+                    if isinstance(value, compat_str) and value.startswith('crc32:'):
-        webpage = self._download_webpage(url, showName)
+        self.report_extraction(videoId)
-        configJSON = self._download_webpage(configUrl, showName,
+        configJSON = self._download_webpage(configUrl, videoId,
-            'title': showName,
+            'title': title,
-            title = u'%s-%s-%s' % (video_title, size, bitrate)
+            # title = u'%s-%s-%s' % (video_title, size, bitrate)
-                'title': title,
+                'title': video_title,
-        video_uploader_id = self._html_search_regex(r'<a href=\'/user/[^>]+>(?P<uploader_id>[^>]+)',
+        video_uploader_id = self._html_search_regex(r'<a href=\'/user/[^>]+>(?P<uploader_id>[^<]+)',
-        video_title = self._search_regex('<h2 class="uiHeaderTitle">([^<]+)</h2>',
+        video_title = self._html_search_regex('<h2 class="uiHeaderTitle">([^<]+)</h2>',
-            video_title = self._search_regex('<title>([^<]+)</title>',
+            video_title = self._html_search_regex('<title>([^<]+)</title>',
-        video_title = self._search_regex("<h1(?: class='globalHd')?>(.*?)</h1>",
+        video_title = self._html_search_regex("<h1(?: class='globalHd')?>(.*?)</h1>",
-        videoDesc = self._search_regex('<meta name="description" content="([^"]*)"',
+        videoDesc = self._html_search_regex('<meta name="description" content="([^"]*)"',
-        imgUrl = self._search_regex('<meta property="og:image" content="([^"]*)"',
+        imgUrl = self._html_search_regex('<meta property="og:image" content="([^"]*)"',
-        playerUrl = self._search_regex('<meta property="og:video" content="([^"]*)"',
+        playerUrl = self._html_search_regex('<meta property="og:video" content="([^"]*)"',
-        video_title = self._search_regex(r'<title>(.*?)\s+-\s+XVID',
+        video_title = self._html_search_regex(r'<title>(.*?)\s+-\s+XVID',
-        video_description = self._search_regex(r'<meta name="description" content="(.*)"(?:\s*/)?>',
+        video_description = self._html_search_regex(r'<meta name="description" content="(.*)"(?:\s*/)?>',
-            info['title'] = unescapeHTML(info['title'])
+            info['title'] = self._html_search_regex('<h1>([^<]+)</h1>', coursepage, 'title', default=info['id'])
-            info['description'] = self._search_regex('<description>([^<]+)</description>',
+            info['description'] = self._html_search_regex('<description>([^<]+)</description>',
-        song_name = self._search_regex(r'<meta name="mtv_vt" content="([^"]+)"/>',
+        song_name = self._html_search_regex(r'<meta name="mtv_vt" content="([^"]+)"/>',
-        video_title = self._search_regex(r'<meta name="mtv_an" content="([^"]+)"/>',
+        video_title = self._html_search_regex(r'<meta name="mtv_an" content="([^"]+)"/>',
-        mtvn_uri = self._search_regex(r'<meta name="mtvn_uri" content="([^"]+)"/>',
+        mtvn_uri = self._html_search_regex(r'<meta name="mtvn_uri" content="([^"]+)"/>',
-        video_title = self._search_regex(self.VIDEO_TITLE_RE,
+        video_title = self._html_search_regex(self.VIDEO_TITLE_RE,
-        upload_date = self._search_regex('title="Timestamp">(.*?)</a>',
+        upload_date = self._html_search_regex('title="Timestamp">(.*?)</a>',
-        uploader = self._search_regex(r'rel\="author".*?>(.*?)</a>',
+        uploader = self._html_search_regex(r'rel\="author".*?>(.*?)</a>',
-        video_title = self._search_regex(r'<meta name\=\"Description\" content\=\"(.*?)[\n<"]',
+        video_title = self._html_search_regex(r'<meta name\=\"Description\" content\=\"(.*?)[\n<"]',
-        title = self._search_regex(r'<meta property="og:title" content="(.*?)"',
+        title = self._html_search_regex(r'<meta property="og:title" content="(.*?)"',
-        # uploader_date = self._search_regex(r'<b>Date:</b> (.*?)</div>', webpage, 'upload_date', fatal=False)
+        # uploader_date = self._html_search_regex(r'<b>Date:</b> (.*?)</div>', webpage, 'upload_date', fatal=False)
-        description = self._search_regex(r'<meta name="description" (?:content|value)="(.*?)" />', webpage, 'description', fatal=False)
+        description = self._html_search_regex(r'<meta name="description" (?:content|value)="(.*?)" />', webpage, 'description', fatal=False)
-        video_url = self._search_regex(r'<video[^>]*>\s*<source[^>]*>\s*<source src="(?P<url>[^"]+)"',
+        video_url = self._html_search_regex(r'<video[^>]*>\s*<source[^>]*>\s*<source src="(?P<url>[^"]+)"',
-        title = self._search_regex((r"<h1 class='player_page_h1'.*?>(?P<title>.*?)</h1>",
+        title = self._html_search_regex((r"<h1 class='player_page_h1'.*?>(?P<title>.*?)</h1>",
-        video_description = self._search_regex(r'<meta property="og:description" content="(?P<desc>.*?)"',
+        video_description = self._html_search_regex(r'<meta property="og:description" content="(?P<desc>.*?)"',
-        video_title = self._search_regex(r'data-title="(?P<title>.+)"',
+        video_title = self._html_search_regex(r'data-title="(?P<title>.+)"',
-        uploader = self._search_regex(r'data-content-type="channel".*?>(?P<uploader>.*?)</a>',
+        uploader = self._html_search_regex(r'data-content-type="channel".*?>(?P<uploader>.*?)</a>',
-        thumbnail = self._search_regex(r'<link rel="image_src" href="(?P<thumb>.*?)"',
+        thumbnail = self._html_search_regex(r'<link rel="image_src" href="(?P<thumb>.*?)"',
-        video_title = self._search_regex(r"<title>(.*)</title>",
+        video_title = self._html_search_regex(r"<title>(.*)</title>",
-        thumbnail = self._search_regex(r'rel="image_src" href="(.*)" />',
+        thumbnail = self._html_search_regex(r'rel="image_src" href="(.*)" />',
-        upload_date = self._search_regex(VIDEO_UPLOADED_RE, webpage, u'upload date', fatal=False)
+        upload_date = self._html_search_regex(VIDEO_UPLOADED_RE, webpage, u'upload date', fatal=False)
-        video_title = self._search_regex(r'<title>(?P<title>.*)</title>',
+        video_title = self._html_search_regex(r'<title>(?P<title>.*)</title>',
-        video_title = self._search_regex(r'<meta property="og:title" content="(?P<title>.*?)"',
+        video_title = self._html_search_regex(r'<meta property="og:title" content="(?P<title>.*?)"',
-        uploader = self._search_regex(r'<div class="user-name-and-bio">[\S\s]+?<h2>(?P<uploader>.+?)</h2>',
+        uploader = self._html_search_regex(r'<div class="user-name-and-bio">[\S\s]+?<h2>(?P<uploader>.+?)</h2>',
-        video_title = self._search_regex(r'<div class="module-title">(.*?)</div>',
+        video_title = self._html_search_regex(r'<div class="module-title">(.*?)</div>',
-        video_title = unescapeHTML(video_title).replace('LiveLeak.com -', '').strip()
+        video_title = self._html_search_regex(r'<meta property="og:title" content="(?P<title>.*?)"',
-        video_description = self._search_regex(r'<meta property="og:description" content="(?P<desc>.*?)"',
+        video_description = self._html_search_regex(r'<meta property="og:description" content="(?P<desc>.*?)"',
-        video_uploader = self._search_regex(r'By:.*?(\w+)</a>',
+        video_uploader = self._html_search_regex(r'By:.*?(\w+)</a>',
-        video_title = self._search_regex(r'<title>(?P<title>.*?)</title>',
+        video_title = self._html_search_regex(r'<title>(?P<title>.*?)</title>',
-        video_url = self._search_regex(r'<source src="(.+?)" type="video/mp4">',
+        video_url = self._html_search_regex(r'<source src="(.+?)" type="video/mp4">',
-        video_title = self._search_regex('<h1 class="videoTitle slidePanelMovable">(.+?)</h1>',
+        video_title = self._html_search_regex('<h1 class="videoTitle slidePanelMovable">(.+?)</h1>',
-        video_url = self._search_regex(r'<media:player url="(?P<mp4url>http://mp4.ina.fr/[^"]+\.mp4)',
+        video_url = self._html_search_regex(r'<media:player url="(?P<mp4url>http://mp4.ina.fr/[^"]+\.mp4)',
-        video_title = self._search_regex(r'<meta content=(?:"([^"]+)"|\'([^\']+)\') property=\'og:title\'',
+        video_title = self._html_search_regex(r'<meta content=(?:"([^"]+)"|\'([^\']+)\') property=\'og:title\'',
-        video_description = self._search_regex(r'<meta content=(?:"([^"]+)"|\'([^\']+)\') name=\'description\'',
+        video_description = self._html_search_regex(r'<meta content=(?:"([^"]+)"|\'([^\']+)\') name=\'description\'',
-        thumbnail = self._search_regex(r'<meta content=\'(.+?)\' property=\'og:image\'',
+        thumbnail = self._html_search_regex(r'<meta content=\'(.+?)\' property=\'og:image\'',
-        video_url = self._search_regex(r'<meta property="twitter:player:stream" content="(.+?)"',
+        video_url = self._html_search_regex(r'<meta property="twitter:player:stream" content="(.+?)"',
-        video_title = self._search_regex(r'<meta property="og:title" content="(.+?)"',
+        video_title = self._html_search_regex(r'<meta property="og:title" content="(.+?)"',
-        thumbnail = self._search_regex(r'<meta property="og:image" content="(.+?)(\?.*?)?"',
+        thumbnail = self._html_search_regex(r'<meta property="og:image" content="(.+?)(\?.*?)?"',
-        uploader = self._search_regex(r'<div class="user">.*?<h2>(.+?)</h2>',
+        uploader = self._html_search_regex(r'<div class="user">.*?<h2>(.+?)</h2>',
-        node_id = self._search_regex(r'<Item id="id">(\d+-\d+)</Item>',
+        node_id = self._html_search_regex(r'<Item id="id">(\d+-\d+)</Item>',
-        video_title = self._search_regex(r'<meta property="og:title" content=(?:"([^"]+)"|\'([^\']+)\')',
+        video_title = self._html_search_regex(r'<meta property="og:title" content=(?:"([^"]+)"|\'([^\']+)\')',
-        video_description = self._search_regex(r'<meta property="og:description" content=(?:"([^"]+)"|\'([^\']+)\')',
+        video_description = self._html_search_regex(r'<meta property="og:description" content=(?:"([^"]+)"|\'([^\']+)\')',
-        thumbnail = self._search_regex(r'<meta property="og:image" content=(?:"([^"]+)"|\'([^\']+)\')',
+        thumbnail = self._html_search_regex(r'<meta property="og:image" content=(?:"([^"]+)"|\'([^\']+)\')',
-        video_id = self._search_regex(r'<article class="video" data-id="(\d+?)"',
+        video_id = self._html_search_regex(r'<article class="video" data-id="(\d+?)"',
-        video_title = self._search_regex(r'<meta property="og:title" content="(.+?)"',
+        video_title = self._html_search_regex(r'<meta property="og:title" content="(.+?)"',
-        thumbnail = self._search_regex(r'<meta property="og:image" content="(.+?)"',
+        thumbnail = self._html_search_regex(r'<meta property="og:image" content="(.+?)"',
-        video_description = self._search_regex(r'<meta property="og:description" content="(.*?)"',
+        video_description = self._html_search_regex(r'<meta property="og:description" content="(.*?)"',
-        video_url = self._search_regex(r'<file type="high".*?>(.*?)</file>',
+        video_url = self._html_search_regex(r'<file type="high".*?>(.*?)</file>',
-        video_title = self._search_regex(r'<title>(?P<title>.+?) - xHamster\.com</title>',
+        video_title = self._html_search_regex(r'<title>(?P<title>.+?) - xHamster\.com</title>',
-        # video_description = self._search_regex(r'<span>Description: </span>(?P<description>[^<]+)',
+        # video_description = self._html_search_regex(r'<span>Description: </span>(?P<description>[^<]+)',
-        video_uploader_id = self._search_regex(r'<a href=\'/user/[^>]+>(?P<uploader_id>[^>]+)',
+        video_uploader_id = self._html_search_regex(r'<a href=\'/user/[^>]+>(?P<uploader_id>[^>]+)',
-        html_tracks = self._search_regex(r'<script type="application/json" id="displayList-data">(.*?)</script>',
+        html_tracks = self._html_search_regex(r'<script type="application/json" id="displayList-data">(.*?)</script>',
-import json
+import socket
-        msg = msg + u'; please report this issue on GitHub.'
+
-                u'please report this issue on GitHub.' % _name)
+            raise ExtractorError(u'Unable to extract %s' % _name)
-        if video_description: video_description = unescapeHTML(video_description)
+        # Can't see the description anywhere in the UI
-            'description': video_description,
+            # 'description': video_description,
-            webpage, u'description', flags=re.DOTALL)
+            webpage, u'description', fatal=False, flags=re.DOTALL)
-        
+
-        mrss_url='http://xhamster.com/movies/%s/.html' % video_id
+        mrss_url = 'http://xhamster.com/movies/%s/.html' % video_id
-        video_title = unescapeHTML(mobj.group('title'))
+        video_title = self._search_regex(r'<title>(?P<title>.+?) - xHamster\.com</title>',
-            video_description = unescapeHTML(mobj.group('description'))
+        video_description = self._search_regex(r'<span>Description: </span>(?P<description>[^<]+)',
-            video_uploader_id = u'anonymous'
+        if mobj:
-            video_uploader_id = mobj.group('uploader_id')
+            video_upload_date = None
-        video_thumbnail = mobj.group('thumbnail')
+        video_uploader_id = self._search_regex(r'<a href=\'/user/[^>]+>(?P<uploader_id>[^>]+)',
-        html_tracks = mobj.group(1).strip()
+
-        self._to_stderr(warning_message)
+        # Don't accept warnings during tests
-    _VALID_URL = r'^(?:https?://)?(?:watch\.|www\.)?nba\.com/(?:nba/)?video(/[^?]*)(\?.*)?$'
+    _VALID_URL = r'^(?:https?://)?(?:watch\.|www\.)?nba\.com/(?:nba/)?video(/[^?]*?)(?:/index\.html)?(?:\?.*)?$'
-        uploader_date = self._search_regex(r'<b>Date:</b> (.*?)</div>', webpage, 'upload_date', fatal=False)
+        # It isn't there in the HTML it returns to us
-            'uploader_date': uploader_date,
+            # 'uploader_date': uploader_date,
-        if upload_date: upload_date = unified_strdate(upload_date.strip())
+        # Get JSON parameters
-        if video_uploader: video_uploader = clean_html(video_uploader.strip())
+        self.report_extraction(video_id)
-                'player_url': None
+                'thumbnail': thumbnail,
-        description = self._search_regex(r'<div class="description">(.*?)</h1>', webpage, 'description', fatal=False)
+        description = self._search_regex(r'<meta name="description" (?:content|value)="(.*?)" />', webpage, 'description', fatal=False)
-        if mobj is None and fatal:
+    def _search_regex(self, pattern, string, name, default=None, fatal=True, flags=0):
-        elif mobj is None:
+                u'please report this issue on GitHub.' % _name)
-                u'please report this issue on GitHub.' % name)
+                u'please report this issue on GitHub.' % _name)
-                info['title'] = info['id']
+            info['title'] = self._search_regex('<h1>([^<]+)</h1>', coursepage, 'title', default=info['id'])
-            video_title = mobj.group(1)
+        video_title = self._search_regex(r'<meta name\=\"Description\" content\=\"(.*?)[\n<"]',
-        title = _findProp(r'<meta property="og:title" content="(.*?)"', shortened_video_id).replace('NBA.com: ', '')
+        title = self._search_regex(r'<meta property="og:title" content="(.*?)"',
-            'description': _findProp(r'<div class="description">(.*?)</h1>'),
+            'uploader_date': uploader_date,
-        title = clean_html(m.group('title'))
+        title = self._search_regex((r"<h1 class='player_page_h1'.*?>(?P<title>.*?)</h1>",
-        video_url = mediaURL
+        video_url = self._search_regex(r'<link rel="video_src" href=".*\?file=([^"]+)" />',
-        file_title = mobj.group(1).decode('utf-8')
+        file_title = self._search_regex(r'<b title="(.*?)">', webpage, u'title')
-        video_title = unescapeHTML(m.group(1))
+        video_title = self._search_regex('<h2 class="uiHeaderTitle">([^<]+)</h2>',
-            video_title = mobj.group(1)
+            video_title = self._search_regex('<title>([^<]+)</title>',
-            video_ext = mobj.group(1)
+            video_ext = self._search_regex('[.](.+?)$', video_url, u'extension')
-        if (video_rtmpurl is None) or (video_rtmpurl == ''):
+        if mobj:
-            video_rtmpurl = compat_urllib_parse.unquote(mobj.group(1)) + compat_urllib_parse.unquote(mobj.group(2))
+            video_url = compat_urllib_parse.unquote(mobj.group(1)) + compat_urllib_parse.unquote(mobj.group(2))
-        video_file     = compat_urllib_parse.unquote(mobj.group(1))
+        video_file = self._search_regex('source=\'(.*?)\'', dec_data, u'video file')
-        video_swfobj = compat_urllib_parse.unquote(mobj.group(1))
+        video_swfobj = self._search_regex('swfobject.embedSWF\(\'(.+?)\'', webpage, u'swfobj')
-        video_title = mobj.group(1)
+        video_title = self._search_regex("<h1(?: class='globalHd')?>(.*?)</h1>",
-            'tc_url':             video_rtmpurl,
+            'url':                video_url,
-        webPage = self._download_webpage(url, showName)
+        webpage = self._download_webpage(url, showName)
-        configUrl = compat_urllib_parse.unquote(configUrlMatch.group(1))
+        imgUrl = self._search_regex('<meta property="og:image" content="([^"]*)"',
-            'description': description,
+            'description': videoDesc,
-
+        video_url = compat_urllib_parse.unquote(self._search_regex(r'flv_url=(.+?)&',
-
+        video_title = self._search_regex(r'<title>(.*?)\s+-\s+XVID',
-        video_thumbnail = mobj.group(0)
+        video_thumbnail = self._search_regex(r'http://(?:img.*?\.)xvideos.com/videos/thumbs/[a-fA-F0-9]+/[a-fA-F0-9]+/[a-fA-F0-9]+/[a-fA-F0-9]+/([a-fA-F0-9.]+jpg)',
-        video_title = mobj.group(1)
+        video_title = self._search_regex(r'contentTitle = "(.*?)";',
-            video_description = mobj.group(1)
+        video_description = self._search_regex(r'<meta name="description" content="(.*)"(?:\s*/)?>',
-                info['description'] = unescapeHTML(m.group(1))
+            info['description'] = self._search_regex('<description>([^<]+)</description>',
-        video_title = performer + ' - ' + song_name
+        song_name = self._search_regex(r'<meta name="mtv_vt" content="([^"]+)"/>',
-        mtvn_uri = mobj.group(1)
+        video_title = self._search_regex(r'<meta name="mtv_an" content="([^"]+)"/>',
-        content_id = mobj.group(1)
+        mtvn_uri = self._search_regex(r'<meta name="mtvn_uri" content="([^"]+)"/>',
-        video_url = compat_urllib_parse.unquote(result.group(1))
+        video_url = self._search_regex(self.VIDEO_URL_RE,
-        video_title = result.group(1)
+        video_title = self._search_regex(self.VIDEO_TITLE_RE,
-        video_thumbnail = result.group(1)
+        video_thumbnail = self._search_regex(self.VIDEO_THUMB_RE,
-        self.report_extract_entry(post_url)
+        self.report_extraction(video_id)
-            upload_date = mobj.group(1)
+        upload_date = self._search_regex('title="Timestamp">(.*?)</a>',
-        self.report_uploader(uploader)
+        uploader = self._search_regex(r'rel\="author".*?>(.*?)</a>',
-        video_page = mobj.group(1)
+        video_page = self._search_regex('"(https\://plus\.google\.com/photos/.*?)",,"image/jpeg","video"\]',
-
+
-        video_url = unescapeHTML(m.group('url'))
+        video_url = self._search_regex(r'<video[^>]*>\s*<source[^>]*>\s*<source src="(?P<url>[^"]+)"',
-            desc = None
+        video_description = self._search_regex(r'<meta property="og:description" content="(?P<desc>.*?)"',
-            'description': desc,
+            'description': video_description,
-            raise ExtractorError(u'Unable to extract info')
+
-                'url':video_url,
+                'id': video_id,
-                'title': title,
+                'title': video_title,
-                  }
+                'thumbnail': thumbnail,
-        webpage_src = self._download_webpage(url, video_id) 
+        webpage_src = self._download_webpage(url, video_id)
-        mobj = re.search(_src_url, webpage_src)
+        video_url = self._search_regex(r'so\.addVariable\("file","(.*?)"\)',
-                ext = 'flv'
+        if 'mp4' in video_url:
-        mobj = re.search(r"<title>(.*)</title>", webpage_src)
+            ext = 'flv'
-        title = mobj.group(1)
+        video_title = self._search_regex(r"<title>(.*)</title>",
-        else:
+        thumbnail = self._search_regex(r'rel="image_src" href="(.*)" />',
-            thumbnail = None
+                video_title = mobj.group(1)
-                    'title' : title,
+                    'title' : video_title,
-        json_data = m.group(1)
+
-        video_title = result.group('title').strip()
+        video_title = self._search_regex(r'<h1.*?>(?P<title>.*)</h1>',
-            upload_date = unified_strdate(result.group('date').strip())
+        upload_date = self._search_regex(r'Date:</label>(?P<date>.*) </li>',
-            video_uploader = clean_html( video_uploader )
+        video_uploader = self._search_regex(r'Submitted:</label>(?P<uploader>.*)</li>',
-        download_list_html = result.group('download_list').strip()
+        download_list_html = self._search_regex(DOWNLOAD_LIST_RE,
-        video_url = compat_urllib_parse.unquote(result.group('url'))
+        video_url = self._search_regex(VIDEO_URL_RE, webpage, u'video url')
-        upload_date = unified_strdate(result.group('date'))
+        upload_date = self._search_regex(VIDEO_UPLOADED_RE, webpage, u'upload date', fatal=False)
-        video_title = result.group('title').strip()
+        video_title = self._search_regex(r'<title>(?P<title>.*)</title>',
-        video_url = result.group('source')
+        video_url = self._search_regex(r'so.addVariable\("file",encodeURIComponent\("(?P<source>[^"]+)"\)\);',
-        json_like = m.group(1)
+        json_like = self._search_regex(r"PAGE.mix = (.*?);\n", webpage, u'trax information', flags=re.DOTALL)
-        uploader = clean_html(m.group('uploader'))
+
-                'title': title,
+                'title': video_title,
-        video_title = unescapeHTML(m.group(1))
+
-        video_url = m.group(1)
+        video_url = self._search_regex(r'file: "(.*?)",',
-        title = unescapeHTML(m.group('title')).replace('LiveLeak.com -', '').strip()
+        video_title = self._search_regex(r'<meta property="og:title" content="(?P<title>.*?)"',
-            desc = None
+        video_description = self._search_regex(r'<meta property="og:description" content="(?P<desc>.*?)"',
-            uploader = None
+        video_uploader = self._search_regex(r'By:.*?(\w+)</a>',
-            'uploader': uploader
+            'title': video_title,
-            return []
+           raise ExtractorError(u'Unable to extract video')
-        thumb = re.search(re_thumb, webpage).group('thumb').replace('\\', '')
+        video_thumbnail = self._search_regex(r'posters(.*?)\[\\x22(?P<thumb>.*?)\\x22',
-        title = unescapeHTML(re.search(re_title, webpage, re.DOTALL).group('title'))
+        video_title = self._search_regex(r'<title>(?P<title>.*?)</title>',
-                 'thumbnail': thumb,
+                 'title': video_title,
-            raise ExtractorError(u'No free songs founded')
+            raise ExtractorError(u'No free songs found')
-                      'url' : final_url,
+                      'ext' :   'mp3',
-                      'uploader' : info[u'artist']
+                      'uploader' :  info[u'artist']
-            raise ExtractorError(u'Unable to extract media URL')
+        video_url = self._search_regex(r'<source src="(.+?)" type="video/mp4">',
-        video_title = mobj.group(1)
+        video_title = self._search_regex('<h1 class="videoTitle slidePanelMovable">(.+?)</h1>',
-        video_url = mobj.group(1)
+        self.report_extraction(video_id)
-        video_title = mobj.group(1)
+        video_url = self._search_regex(r'<media:player url="(?P<mp4url>http://mp4.ina.fr/[^"]+\.mp4)',
-        video_url = mobj.group(1)
+        video_url = self._search_regex(r'\'?file\'?: "(http://mobile-media\.howcast\.com/[0-9]+\.mp4)',
-        video_title = mobj.group(1) or mobj.group(2)
+        video_title = self._search_regex(r'<meta content=(?:"([^"]+)"|\'([^\']+)\') property=\'og:title\'',
-            video_description = mobj.group(1) or mobj.group(2)
+        video_description = self._search_regex(r'<meta content=(?:"([^"]+)"|\'([^\']+)\') name=\'description\'',
-        thumbnail = mobj.group(1)
+        thumbnail = self._search_regex(r'<meta content=\'(.+?)\' property=\'og:image\'',
-        video_url = mobj.group(1)
+        video_url = self._search_regex(r'<meta property="twitter:player:stream" content="(.+?)"',
-        video_title = mobj.group(1)
+        video_title = self._search_regex(r'<meta property="og:title" content="(.+?)"',
-        thumbnail = mobj.group(1)
+        thumbnail = self._search_regex(r'<meta property="og:image" content="(.+?)(\?.*?)?"',
-        uploader = mobj.group(1)
+        uploader = self._search_regex(r'<div class="user">.*?<h2>(.+?)</h2>',
-        secret = mobj.group(1)
+        secret = self._search_regex(r"photo_secret: '(\w+)'", webpage, u'secret')
-        node_id = mobj.group(1)
+        node_id = self._search_regex(r'<Item id="id">(\d+-\d+)</Item>',
-        video_title = mobj.group(1) or mobj.group(2)
+        video_title = self._search_regex(r'<meta property="og:title" content=(?:"([^"]+)"|\'([^\']+)\')',
-            video_description = mobj.group(1) or mobj.group(2)
+        video_description = self._search_regex(r'<meta property="og:description" content=(?:"([^"]+)"|\'([^\']+)\')',
-        thumbnail = mobj.group(1) or mobj.group(2)
+        thumbnail = self._search_regex(r'<meta property="og:image" content=(?:"([^"]+)"|\'([^\']+)\')',
-        video_id = mobj.group(1)
+        video_id = self._search_regex(r'<article class="video" data-id="(\d+?)"',
-        video_title = mobj.group(1)
+        video_title = self._search_regex(r'<meta property="og:title" content="(.+?)"',
-        thumbnail = mobj.group(1)
+        thumbnail = self._search_regex(r'<meta property="og:image" content="(.+?)"',
-        description = mobj.group(1)
+        video_description = self._search_regex(r'<meta property="og:description" content="(.*?)"',
-        video_url = mobj.group(1)
+
-            'description': description,
+            'description': video_description,
-    def _real_extract(self,url):
+    def _real_extract(self, url):
-        id = mobj.group(1)
+        track_id = mobj.group(1)
-        complete_url = url + "?"+data_encoded
+        complete_url = url + "?" + data_encoded
-        response,urlh = self._download_webpage_handle(request, id, u'Downloading webpage with the url')
+        response, urlh = self._download_webpage_handle(request, track_id, u'Downloading webpage with the url')
-            tracks = track_list
+
-            tracks = track_list[u'tracks']
+            track = track_list[u'tracks'][0]
-        self.report_extraction(id)
+            raise ExtractorError(u'Hypemachine contained invalid JSON.')
-        song_data = json.loads(song_data_json)
+        song_data_json = self._download_webpage(request, track_id, u'Downloading metadata')
-            'id':       id,
+            'id':       track_id,
-        m = re.search(r'<div class="spVideoTitle">(.*?)</div>', webpage)
+        m = re.search(r'<div class="module-title">(.*?)</div>', webpage)
-from youtube_dl.InfoExtractors import YoutubeIE, YoutubePlaylistIE, YoutubeChannelIE
+from youtube_dl.InfoExtractors import YoutubeIE, YoutubePlaylistIE, YoutubeChannelIE, JustinTVIE
-    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo\.com/(?:(?:groups|album)/[^/]+/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)'
+    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo(?P<pro>pro)?\.com/(?:(?:(?:groups|album)/[^/]+)|(?:.*?)/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)'
-        if mobj.group('direct_link'):
+        if mobj.group('direct_link') or mobj.group('pro'):
-        video_uploader_id = config["video"]["owner"]["url"].split('/')[-1]
+        video_uploader_id = config["video"]["owner"]["url"].split('/')[-1] if config["video"]["owner"]["url"] else None
-        self.params = parameters
+        # Different instances of the downloader can't share the same dictionary
-                    self._downloader.report_error(sub_error)
+                    # We try with the automatic captions
-    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?blip\.tv(/.+)$'
+    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?blip\.tv/((.+/)|(play/)|(api\.swf#))(.+)$'
-        BlipTVUserIE(),
+        BlipTVUserIE(),
-__version__ = '2013.05.14'
+__version__ = '2013.05.23'
-        mobj = re.search(r'\'file\': "(http://mobile-media\.howcast\.com/\d+\.mp4)"', webpage)
+        mobj = re.search(r'\'?file\'?: "(http://mobile-media\.howcast\.com/[0-9]+\.mp4)"', webpage)
-            self.to_screen("No video founded")
+            self.to_screen("No video found")
-    _VALID_URL = r'(?:https?://)?(?:www\.)?flickr\.com/photos/(?P<uploader_id>[\w\-]+)/(?P<id>\d+).*'
+    _VALID_URL = r'(?:https?://)?(?:www\.)?flickr\.com/photos/(?P<uploader_id>[\w\-_@]+)/(?P<id>\d+).*'
-        first_xml = self._download_webpage(first_url, video_id)
+        first_xml = self._download_webpage(first_url, video_id, 'Downloading first data webpage')
-        second_xml = self._download_webpage(second_url, video_id)
+        second_xml = self._download_webpage(second_url, video_id, 'Downloading second data webpage')
-            'title':    video_title,
+            'id':          video_id,
-            'thumbnail': thumbnail,
+            'thumbnail':   thumbnail,
-#     Copyright (C) 2013 Tristan Fischer (sphere@dersphere.de) - GPLv3
+    # Original Code from: https://github.com/dersphere/plugin.video.myvideo_de.git
-            x = (x + box[i] + ord(key[i % len(key)])) % 256
+            x = (x + box[i] + compat_ord(key[i % len(key)])) % 256
-        out = []
+        out = ''
-        return ''.join(out)
+            out += chr(compat_ord(char) ^ box[(box[x] + box[y]) % 256])
-        return hashlib.md5(s).hexdigest()
+        return hashlib.md5(s).hexdigest().encode()
-        sec = re.search('var flashvars={(.+?)}', webpage).group(1)
+        sec = mobj.group(1)
-            ).encode('utf-8') 
+        sk = self.__md5(
-#            'file_path':          video_filepath,
+def compat_ord(c):
-        mobj = re.search(r'<meta property="twitter:player:stream" content="([^"]+)"', webpage)
+        self.report_extraction(video_id)
-        mobj = re.search(r'<meta property="og:title" content="([^"]+)"', webpage)
+        mobj = re.search(r'<meta property="og:title" content="(.+?)"', webpage)
-            'title':    video_title,
+            'id':        video_id,
-    _VALID_URL = r'(?:https?://)?(?:www\.)?howcast\.com/videos/(?P<id>[\d]+)'
+    """Information Extractor for Howcast.com"""
-    _VALID_URL = r'(?:http://)?(?:www.)?ina\.fr/video/(?P<id>I[0-9]+)/.*'
+    _VALID_URL = r'(?:http://)?(?:www\.)?ina\.fr/video/(?P<id>I[0-9]+)/.*'
-        uploader = m.group('uploader')
+        self.report_extraction(video_id)
-                'uploader': uploader
+                'uploader': uploader,
-        return [info]
+        return info
-    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path):
+    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path, tc_url):
-                                                info_dict.get('play_path', None))
+                                                info_dict.get('play_path', None),
-            raise ExtractorError(u'Invalid URL: %s' % url)
+            raise ExtractorError(u'invalid URL: %s' % url)
-                 webpage)
+
-        video_url = mobj.group(1) + ('/%s.flv' % video_id)
+            raise ExtractorError(u'unable to extract rtmpurl')
-        mobj = re.search('<title>([^<]+)</title>', webpage)
+        mobj = re.search('source=\'(.*?)\'', dec_data)
-            raise ExtractorError(u'Unable to extract title')
+            raise ExtractorError(u'unable to extract swfobj')
-            'ext':      u'flv',
+            'id':                 video_id,
-    def extract_info(self, url, download=True, ie_key=None):
+    def extract_info(self, url, download=True, ie_key=None, extra_info={}):
-    def process_ie_result(self, ie_result, download=True):
+    def process_ie_result(self, ie_result, download=True, extra_info={}):
-            return self.extract_info(ie_result['url'], download, ie_key=ie_result.get('ie_key'))
+            # We have to add extra_info to the results because it may be
-                entry_result = self.process_ie_result(entry, download=download)
+                extra = {
-    Base class for search queries extractors
+    Base class for paged search queries extractors.
-        return r'%s(?P<prefix>|\d+|all):(?P<query>[\s\S]+)' % cls._SEARCH_KEY
+    def _make_valid_url(cls):
-        return re.match(cls._VALID_URL() , url) is not None
+        return re.match(cls._make_valid_url(), url) is not None
-        mobj = re.match(self._VALID_URL(), query)
+        mobj = re.match(self._make_valid_url(), query)
-            return self._get_n_results(query, self._max_results)
+            return self._get_n_results(query, self._MAX_RESULTS)
-                n = self._max_results
+            elif n > self._MAX_RESULTS:
-    _max_results = 1000
+    _MAX_RESULTS = 1000
-    _max_results = 1000
+    _MAX_RESULTS = 1000
-    _max_results = 1000
+    _MAX_RESULTS = 1000
-class YoutubeSearchIE(InfoExtractor):
+class YoutubeSearchIE(SearchInfoExtractor):
-    _max_youtube_results = 1000
+    _max_results = 1000
-class GoogleSearchIE(InfoExtractor):
+class GoogleSearchIE(SearchInfoExtractor):
-    _max_google_results = 1000
+    _max_results = 1000
-            return self._get_n_results(query, n)
+    _SEARCH_KEY = 'gvsearch'
-class YahooSearchIE(InfoExtractor):
+class YahooSearchIE(SearchInfoExtractor):
-    _max_yahoo_results = 1000
+    _max_results = 1000
-                return self._get_n_results(query, 1)
+    _SEARCH_KEY = 'yvsearch'
-__version__ = '2013.05.13'
+__version__ = '2013.05.14'
-__version__ = '2013.05.10'
+__version__ = '2013.05.13'
-        filename = re.sub(u'[/<>:"\\|\\\\?\\*]', u'#', filename)
+        if err.errno in (errno.EACCES,):
-        return (stream, filename)
+        # In case of error, try to remove win32 forbidden chars
-    onlysubtitles:     Downloads only the subtitles of the video
+    skip_download:     Skip the actual download of the video file
-            if dn != '' and not os.path.exists(dn): # dn is already encoded
+            if dn != '' and not os.path.exists(dn):
-            help='downloads only the subtitles (no video)', default=False)
+            action='store_true', dest='skip_download',
-        return videos
+        return self.playlist_result(videos, query)
-            raise FFmpegPostProcessorError(msg.decode('utf-8', 'replace'))
+            raise FFmpegPostProcessorError(msg)
-    _MORE_PAGES_INDICATOR = r'class="pn" id="pnnext"'
+    _MORE_PAGES_INDICATOR = r'id="pnnext" class="pn"'
-            result_url = u'http://video.google.com/videosearch?q=%s&start=%s&hl=en' % (compat_urllib_parse.quote_plus(query), pagenum*10)
+            result_url = u'http://www.google.com/search?tbm=vid&q=%s&start=%s&hl=en' % (compat_urllib_parse.quote_plus(query), pagenum*10)
-        self.to_screen(u'query "%s": Downloading page %s' % (query, pagenum))
+    _max_yahoo_results = 1000
-            return
+            return self._get_n_results(query, 1)
-            return
+            return self._get_n_results(query, self._max_yahoo_results)
-                return
+                return self._get_n_results(query, n)
-        pagenum = 1
+                return self._get_n_results(query, 1)
-                raise ExtractorError(u'Unable to download webpage: %s' % compat_str(err))
+    def _get_n_results(self, query, n):
-                return
+        res = {
-            pagenum = pagenum + 1
+        return res
-            raise ExtractorError(u'Unable to extract video url')
+        webpage = self._download_webpage(url, video_id)
-                     'play_path': m_rest.group('path'),
+                     'url': video_url,
-    """Information extractor for video.yahoo.com."""
+    """Information extractor for screen.yahoo.com."""
-        # Extract ID from URL
+    def _real_extract(self, url):
-        # Extract uploader and title from webpage
+        # TODO: Check which url parameters are required
-        }]
+        m_info = re.search(info_re, webpage, re.VERBOSE|re.DOTALL)
-class FakeDownloader(object):
+class FakeDownloader(FileDownloader):
-__version__ = '2013.05.07'
+__version__ = '2013.05.10'
-            url_map = dict((ud['itag'][0], ud['url'][0] + '&signature=' + ud['sig'][0]) for ud in url_data)
+            url_map = {}
-        'quiet': (opts.quiet or opts.geturl or opts.gettitle or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat),
+        'quiet': (opts.quiet or opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat),
-        'skip_download': (opts.skip_download or opts.simulate or opts.geturl or opts.gettitle or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat),
+        'skip_download': (opts.skip_download or opts.simulate or opts.geturl or opts.gettitle or opts.getid or opts.getthumbnail or opts.getdescription or opts.getfilename or opts.getformat),
-            return self._download_n_results(query, 1)
+            return self._get_n_results(query, 1)
-            return self._download_n_results(query, self._max_google_results)
+            return self._get_n_results(query, self._max_google_results)
-            return self._download_n_results(query, n)
+            return self._get_n_results(query, n)
-        """Downloads a specified number of results for a query"""
+    def _get_n_results(self, query, n):
-__version__ = '2013.05.06'
+__version__ = '2013.05.07'
-__version__ = '2013.05.05'
+__version__ = '2013.05.06'
-    IE_NAME = u'Ina'
+
-            raise ExtractorError(u'Invalid URL: %s' % url)
+
-        mobj = re.search(reg1,webpage)
+        mrss_url='http://player.ina.fr/notices/%s.mrss' % video_id
-        mobj = re.search(reg2,webpage)
+
-        InaIE,
+        InaIE(),
-    _VIDEO_INDICATOR = r'<a href="http://video\.google\.com/videoplay\?docid=([^"\&]+)'
+    _VALID_URL = r'gvsearch(?P<prefix>|\d+|all):(?P<query>[\s\S]+)'
-        query = query.encode('utf-8')
+        prefix = mobj.group('prefix')
-            return
+            return self._download_n_results(query, 1)
-            return
+            return self._download_n_results(query, self._max_google_results)
-                return
+            n = int(prefix)
-        pagenum = 0
+        res = {
-                return
+        for pagenum in itertools.count(1):
-            pagenum = pagenum + 1
+            for mobj in re.finditer(r'<h3 class="r"><a href="([^"]+)"', webpage):
-    def extract_info(self, url, download = True, ie_name = None):
+    def extract_info(self, url, download=True, ie_key=None):
-            ies.insert(0, first_ie)
+        if ie_key:
-            suitable_found = True
+                self.report_warning(u'The program functionality for this site has been marked as broken, '
-                if ie_results is None: # Finished already (backwards compatibility; listformats and friends should be moved here)
+                ie_result = ie.extract(url)
-                return results
+                if isinstance(ie_result, list):
-                self.report_error(u'no suitable InfoExtractor: %s' % url)
+        else:
-    def process_ie_result(self, ie_result, download = True):
+    def process_ie_result(self, ie_result, download=True):
-        
+        Take the result of the ie(may be modified) and resolve all unresolved
-        result_type = ie_result.get('_type', 'video') #If not given we suppose it's a video, support the dafault old system
+
-                #It isn't part of a playlist
+                # It isn't part of a playlist
-            return result
+            return self.extract_info(ie_result['url'], download, ie_key=ie_result.get('ie_key'))
-            #We process each entry in the playlist
+            # We process each entry in the playlist
-                    self.process_info(entry_result)
+                entry['playlist'] = playlist
-            return result
+            ie_result['entries'] = playlist_results
-        """Process a single dictionary returned by an InfoExtractor."""
+        """Process a single resolved IE result."""
-        
+
-            self._downloader.report_error(u'unable to extract video page URL')
+            raise ExtractorError(u'Unable to extract video page URL')
-            self._downloader.report_error(u'unable to extract video links')
+            raise ExtractorError(u'Unable to extract video links')
-            self._downloader.report_error(u'unable to find video information')
+            raise ExtractorError(u'Unable to find video information')
-                self._downloader.report_error(u'Cannot find video title')
+                raise ExtractorError(u'Cannot find video title')
-                self._downloader.report_error(u'Cannot find video url for %s' % video_id)
+                raise ExtractorError(u'Cannot find video url for %s' % video_id)
-            self._downloader.report_error(u'Cannot find video title')
+            raise ExtractorError(u'Cannot find video title')
-    _VALID_URL = r'(?:http://)?(?:[a-z0-9]+\.)?photobucket\.com/.*[\?\&]current=(.*\.flv)'
+    # TODO: the original _VALID_URL was:
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-        video_extension = 'flv'
+        video_extension = mobj.group('ext')
-            raise ExtractorError(u'Unable to retrieve video webpage: %s' % compat_str(err))
+        webpage = self._download_webpage(url, video_id)
-            'upload_date':  info.get('date'),
+            'upload_date':  unified_strdate(info.get('date')),
-            return
+            raise ExtractorError(u'Unable to confirm age: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to download video webpage: %s' % compat_str(err))
-                self._downloader.report_error(u'YouTube said: %s' % video_info['reason'][0])
+                raise ExtractorError(u'YouTube said: %s' % video_info['reason'][0])
-            return
+                raise ExtractorError(u'"token" parameter not in video info for unknown reason')
-            return
+            raise ExtractorError(u'"rental" videos not supported')
-            return
+            raise ExtractorError(u'Unable to extract uploader name')
-            return
+            raise ExtractorError(u'Unable to extract video title')
-            return
+            raise ExtractorError(u'Unable to retrieve disclaimer: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Unable to confirm age: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-                return
+                raise ExtractorError(u'Unable to extract media URL')
-                return
+                raise ExtractorError(u'Unable to extract media URL')
-                return
+                raise ExtractorError(u'Unable to extract media URL')
-            return
+            raise ExtractorError(u'Unable to extract title')
-            return
+            raise ExtractorError(u'Unable to extract uploader nickname')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract media URL')
-            return
+            raise ExtractorError(u'Unable to extract video URL')
-            return
+            raise ExtractorError(u'Unable to extract video URL')
-            return
+            raise ExtractorError(u'Unable to extract title')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Unable to extract media URL')
-            return
+            raise ExtractorError(u'Unable to extract title')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-                return
+                raise ExtractorError(u'Unable to retrieve video webpage: %s' % compat_str(err))
-                return
+                raise ExtractorError(u'Unable to extract id field')
-                return
+                raise ExtractorError(u'Unable to extract vid field')
-            return
+            raise ExtractorError(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Unable to extract video title')
-            return
+            raise ExtractorError(u'Unable to extract video uploader')
-            return
+            raise ExtractorError(u'Unable to extract video thumbnail')
-            return
+            raise ExtractorError(u'Unable to extract video description')
-            return
+            raise ExtractorError(u'Unable to extract video height')
-            return
+            raise ExtractorError(u'Unable to extract video width')
-            return
+            raise ExtractorError(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Unable to extract media URL')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-                self._downloader.report_error(u'The author has restricted the access to this video, try with the "--referer" option')
+                raise ExtractorError(u'The author has restricted the access to this video, try with the "--referer" option')
-            return
+                raise ExtractorError(u'Unable to extract info section')
-            return
+            raise ExtractorError(u'No known codec found')
-            return
+            raise ExtractorError(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-                return
+                raise ExtractorError(err)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract title')
-            return
+            raise ExtractorError(u'Unable to extract title')
-            return
+            raise ExtractorError(u'Invalid search query "%s"' % query)
-                    return
+                    raise ExtractorError(u'Invalid download number %s for query "%s"' % (n, query))
-                return
+                raise ExtractorError(u'Unable to download API page: %s' % compat_str(err))
-                return
+                raise ExtractorError(u'[youtube] No video results')
-            return
+            raise ExtractorError(u'Invalid search query "%s"' % query)
-                    return
+                    raise ExtractorError(u'Invalid download number %s for query "%s"' % (n, query))
-                return
+                raise ExtractorError(u'Unable to download webpage: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Invalid search query "%s"' % query)
-                    return
+                    raise ExtractorError(u'Invalid download number %s for query "%s"' % (n, query))
-                return
+                raise ExtractorError(u'Unable to download webpage: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-                return
+                raise ExtractorError(u'Invalid JSON in API response: ' + compat_str(err))
-                return
+                raise ExtractorError(u'Got a malformed response from YouTube API')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to retrieve file webpage: %s' % compat_str(err))
-                self._downloader.report_error(u'%s' % restriction_message)
+                raise ExtractorError(u'%s' % restriction_message)
-            return
+                raise ExtractorError(u'Unable to extract download URL from: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract title')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-                return
+                raise ExtractorError(u'Unable to read video info webpage: %s' % compat_str(err))
-                return
+                raise ExtractorError(u'Unable to parse video information: %s' % repr(err))
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract media URL')
-            return
+            raise ExtractorError(u'Unable to extract title')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid JSON in configuration file: ' + compat_str(err))
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to download video info XML: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Invalid metadata XML file')
-            return
+            raise ExtractorError(u'Unable to download video info XML: %s' % compat_str(err))
-            return
+            raise ExtractorError(u'Invalid manifest file')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract video url')
-            return
+            raise ExtractorError(u'Unable to extract video title')
-            return
+            raise ExtractorError(u'Unable to extract video thumbnail')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract video url')
-            return
+            raise ExtractorError(u'Unable to extract video title')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to retrieve file: %s' % compat_str(err))
-                return
+                raise ExtractorError(u'Format is not available')
-                return
+                raise ExtractorError(u'Unable to download video info XML: %s' % compat_str(err))
-                return
+                raise ExtractorError(u'Invalid metadata XML file')
-                return
+                raise ExtractorError(u'Unable to download course info page: ' + compat_str(err))
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract song name')
-            return
+            raise ExtractorError(u'Unable to extract performer')
-            return
+            raise ExtractorError(u'Unable to mtvn_uri')
-            return
+            raise ExtractorError(u'Unable to extract content id')
-            return
+            raise ExtractorError(u'Unable to download video metadata: %s' % compat_str(err))
-            return
+            raise ExtractorError('Invalid rendition field.')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract info section')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract video url')
-            return
+            raise ExtractorError(u'Unable to extract video title')
-            return
+            raise ExtractorError(u'Unable to extract video thumbnail')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-                return
+                raise ExtractorError(u'Requested format not available')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract video url')
-            return
+            raise ExtractorError(u'Unable to extract video title')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to extract download url')
-            return
+            raise ExtractorError(u'Unable to extract title')
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            return
+            raise ExtractorError(u'Unable to find video url')
-            return
+            raise ExtractorError(u'This video is only available after 8:00 pm')
-            return
+            raise ExtractorError(u'No free songs founded')
-__version__ = '2013.05.04'
+__version__ = '2013.05.05'
-    https_handler = compat_urllib_request.HTTPSHandler()
+    https_handler = make_HTTPS_handler(opts)
-            self._downloader.report_warning(u'Chapter detected, but we do not know how to calculate start position. Downloading the whole file ... (See https://github.com/rg3/youtube-dl/issues/810 )')
+            #video_url += u'?start=' + TODO:start_timestamp
-            chapter_info_json = self._download_webpage(chapter_api_url, video_id,
+            chapter_info_json = self._download_webpage(chapter_api_url, u'c' + chapter_id,
-            video_title = m.group(1)
+            chapter_api_url = u'https://api.twitch.tv/kraken/videos/c' + chapter_id
-                'title': video_title,
+                'title': chapter_info['title'],
-                raise ExtractorError('Cannot find archive of a chapter')
+                raise ExtractorError(u'Cannot find archive of a chapter')
-            raise NotImplementedError('twitch.tv chapters are not yet supported, sorry (See https://github.com/rg3/youtube-dl/issues/810 )')
+            info = {
-        ([^/]+)(?:/b/([^/]+))?/?(?:\#.*)?$"""
+        (?:
-            return
+            raise ExtractorError(u'invalid URL: %s' % url)
-        video_id = mobj.group(mobj.lastindex)
+        api_base = 'http://api.justin.tv'
-        if mobj.lastindex == 1:
+        if mobj.group('channelid'):
-            api += '/channel/archives/%s.json'
+            video_id = mobj.group('channelid')
-        api = api % (video_id,)
+            video_id = mobj.group('videoid')
-            return
+            raise ExtractorError(u'Justin.tv API: %s' % error_text)
-            return
+            raise ExtractorError(u'invalid URL: %s' % url)
-    _VALID_URL = r'http://(?:www|m)\.worldstar(?:candy|hiphop)\.com/videos/video\.php\?v=(?P<id>.*)'
+    _VALID_URL = r'https?://(?:www|m)\.worldstar(?:candy|hiphop)\.com/videos/video\.php\?v=(?P<id>.*)'
-        mobj = re.search(_title, webpage_src)
+            raise ExtractorError(u'Cannot find video url for %s' % video_id)
-            title = 'World Start Hip Hop - %s' % time.ctime()
+        mobj = re.search(r"<title>(.*)</title>", webpage_src)
-        mobj = re.search(_thumbnail, webpage_src)
+        if mobj is None:
-        _src_url = r"""(http://(hw-videos|hw-post)[0-9]*.*(?:mp4|flv))"""
+        _src_url = r'so\.addVariable\("file","(.*?)"\)'
-            video_url = mobj.group()
+            video_url = mobj.group(1)
-        _src_url = r"""(http://(hw-videos|hw-post1).*(?:mp4|flv))"""
+        _src_url = r"""(http://(hw-videos|hw-post)[0-9]*.*(?:mp4|flv))"""
-    _LANG_URL = r'http://www.youtube.com/?hl=en&persist_hl=1&gl=US&persist_gl=1&opt_out_ackd=1'
+    _LANG_URL = r'https://www.youtube.com/?hl=en&persist_hl=1&gl=US&persist_gl=1&opt_out_ackd=1'
-                u'continue': u'http://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',
+                u'continue': u'https://www.youtube.com/signin?action_handle_signin=true&feature=sign_in_button&hl=en_US&nomobiletemp=1',
-            url = 'http://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')
+            url = 'https://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')
-        url = 'http://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id
+        url = 'https://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id
-__version__ = '2013.05.01'
+__version__ = '2013.05.04'
-        """ Returns the data of the page as a string """
+    def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None):
-        return webpage_bytes.decode(encoding, 'replace')
+        content = webpage_bytes.decode(encoding, 'replace')
-        webpage = self._download_webpage(url, epTitle)
+        webpage,htmlHandle = self._download_webpage_handle(url, epTitle)
-                return
+                raise ExtractorError(u'Invalid redirected URL: ' + url)
-                return
+                raise ExtractorError(u'Redirected URL is still not specific: ' + url)
-                return
+                raise ExtractorError(u'unable to find Flash URL in webpage ' + url)
-class RedtubeIE(InfoExtractor):
+class RedTubeIE(InfoExtractor):
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-            video_title = 'Redtube - %s' % time.ctime()
+
-        RedtubeIE(),
+        RedTubeIE(),
-    opener = compat_urllib_request.build_opener(proxy_handler, cookie_processor, YoutubeDLHandler())
+    https_handler = compat_urllib_request.HTTPSHandler()
-
+class RedtubeIE(InfoExtractor):
-        RedtubeIE(),
+        RedtubeIE(),
-            return
+        webpage = self._download_webpage(request, video_id)
-                return
+            page = self._download_webpage(url, playlist_id, u'Downloading page #%s' % page_num)
-            return
+        page = self._download_webpage(url, channel_id,
-                    return
+                page = self._download_webpage(url, channel_id,
-                return
+            gdata_url = self._GDATA_URL % (username, self._GDATA_PAGE_SIZE, start_index)
-            return
+        page = self._download_webpage(url, username, u'Downloading user page')
-                return
+            page = self._download_webpage(url, username,
-            return
+        webpage = self._download_webpage(url, epTitle)
-            return
+        indexXml = self._download_webpage(indexUrl, epTitle,
-                return
+            configXml = self._download_webpage(configUrl, epTitle,
-            return
+        webPage = self._download_webpage(url, showName)
-            return
+        configJSON = self._download_webpage(configUrl, showName,
-        self.report_resolve('%s/%s' % (uploader, slug_title))
+        self.report_resolve(full_title)
-            return
+        info_json = self._download_webpage(resolv_url, full_title, u'Downloading info JSON')
-        self.report_extraction('%s/%s' % (uploader, slug_title))
+        self.report_extraction(full_title)
-            return
+        stream_json = self._download_webpage(streams_url, full_title,
-        self.report_resolve('%s/sets/%s' % (uploader, slug_title))
+        self.report_resolve(full_title)
-            return
+        info_json = self._download_webpage(resolv_url, full_title)
-                return
+            stream_json = self._download_webpage(streams_url, video_id, u'Downloading track info JSON')
-            return
+        jsondata = self._download_webpage(info_url, video_id)
-            config = json.loads(jsonstr)
+            config = json.loads(jsondata)
-            return
+        webpage = self._download_webpage(url, video_id)
-            return
+        webpage = self._download_webpage(post_url, video_id, u'Downloading entry webpage')
-            return
+        webpage = self._download_webpage(video_page, video_id, u'Downloading video page')
-            return
+    def _parse_page(self, url, video_id):
-            page_count, page_info = self._parse_page(page_url)
+            page_count, page_info = self._parse_page(page_url, video_id)
-
+        webpage_src = self._download_webpage(url, video_id) 
-    _VALID_URL = r"""http://store.steampowered.com/
+    _VALID_URL = r"""http://store\.steampowered\.com/
-    _VALID_URL=r'''http://www.ted.com/
+    _VALID_URL=r'''http://www\.ted\.com/
-    _VALID_URL = r'http://(?P<blog_name>.*?).tumblr.com/((post)|(video))/(?P<id>\d*)/(.*?)'
+    _VALID_URL = r'http://(?P<blog_name>.*?)\.tumblr\.com/((post)|(video))/(?P<id>\d*)/(.*?)'
-        re_video = r'src=\\x22(?P<video_url>http://%s.tumblr.com/video_file/%s/(.*?))\\x22 type=\\x22video/(?P<ext>.*?)\\x22' % (blog, video_id)
+        re_video = r'src=\\x22(?P<video_url>http://%s\.tumblr\.com/video_file/%s/(.*?))\\x22 type=\\x22video/(?P<ext>.*?)\\x22' % (blog, video_id)
-    _VALID_URL = r'http://.*?.bandcamp.com/track/(?P<title>.*)'
+    _VALID_URL = r'http://.*?\.bandcamp\.com/track/(?P<title>.*)'
-        re_url = r'(?P<server>http://(.*?).bandcamp.com)/download/track\?enc=mp3-320&fsig=(?P<fsig>.*?)&id=(?P<id>.*?)&ts=(?P<ts>.*)$'
+        re_url = r'(?P<server>http://(.*?)\.bandcamp\.com)/download/track\?enc=mp3-320&fsig=(?P<fsig>.*?)&id=(?P<id>.*?)&ts=(?P<ts>.*)$'
-        title = unescapeHTML(re.search(re_title, webpage).group('title'))
+        re_title = r'<title>(?P<title>.*?)</title>'
-        _src_url = r"""(http://hw-videos.*(?:mp4|flv))"""
+        _src_url = r"""(http://(hw-videos|hw-post1).*(?:mp4|flv))"""
-__version__ = '2013.04.31'
+__version__ = '2013.05.01'
-        'daterange': date
+        'daterange': date,
-__version__ = '2013.04.30'
+__version__ = '2013.04.31'
-                (percent_str, data_len_str, speed_str, eta_str), skip_eol=True)
+            self.to_screen(u'\r%s[download] %s of %s at %s ETA %s' %
-    def trouble(self, s):
+    def trouble(self, s, tb=None):
-    def trouble(self, s):
+    def trouble(self, s, tb=None):
-    general.add_option('--proxy', dest='proxy', default=None, help='Use the specified HTTP/HTTPS proxy')
+    general.add_option('--proxy', dest='proxy', default=None, help='Use the specified HTTP/HTTPS proxy', metavar='URL')
-__version__ = '2013.04.28'
+__version__ = '2013.04.30'
-        proxies['https'] = proxies['http']
+    if opts.proxy:
-        ie = youtube_dl.InfoExtractors.get_info_extractor(test_case['name'])#getattr(youtube_dl.InfoExtractors, test_case['name'] + 'IE')
+        ie = youtube_dl.InfoExtractors.get_info_extractor(test_case['name'])
-                'upload_date':  track['created_at'],
+                'upload_date':  unified_strdate(track['created_at']),
-                self.to_stderr(u'WARNING: the program functionality for this site has been marked as broken, '
+                self.report_warning(u'the program functionality for this site has been marked as broken, '
-__version__ = '2013.04.27'
+__version__ = '2013.04.28'
-            action='store_true', dest='usetitle', help='use title in file name', default=False)
+            action='store_true', dest='usetitle', help='use title in file name (default)', default=False)
-            action='store_true', dest='useid', help='use video ID in file name', default=False)
+            action='store_true', dest='useid', help='use only video ID in file name', default=False)
-            or u'%(id)s.%(ext)s')
+            or u'%(title)s-%(id)s.%(ext)s')
-    print_notes(versions_info['versions'])
+    print_notes(to_screen, versions_info['versions'])
-def print_notes(versions, fromVersion=__version__):
+def get_notes(versions, fromVersion):
-__version__ = '2013.04.22'
+__version__ = '2013.04.27'
-        self.assertTrue(len(result['entries']) > 20)
+        self.assertTrue(len(result['entries']) >= 18)
-    proxy_handler = compat_urllib_request.ProxyHandler()
+    proxies = compat_urllib_request.getproxies()
-        
+
-    """Return a datetime object from a string in the format YYYYMMDD"""
+    """
-        if self.start >= self.end:
+        if self.start > self.end:
-        return self.start <= date and date <= self.end
+        if not isinstance(date, datetime.date):
-    IE_NAME = u'soundcloud'
+    IE_NAME = u'soundcloud:set'
-                    pass
+            upload_date = unified_strdate(upload_date)
-            officialDate = itemEl.findall('./pubDate')[0].text
+            officialDate = unified_strdate(itemEl.findall('./pubDate')[0].text)
-            'upload_date':  info['created_at'],
+            'upload_date': upload_date,
-            upload_date = result.group('date').strip()
+            upload_date = unified_strdate(result.group('date').strip())
-        upload_date = result.group('date')
+        upload_date = unified_strdate(result.group('date'))
-    
+
-        'max_filesize': opts.max_filesize
+        'max_filesize': opts.max_filesize,
-
+
-        return False,information
+        return self._nopostoverwrites,information
-        if note is not False:
+            self.report_download_webpage(video_id)
-        self.to_screen(u'%s: Downloading webpage' % video_id)
+        super(GenericIE, self).report_download_webpage(video_id)
-        self.report_webpage(video_id)
+        self.report_download_webpage(video_id)
-        mobj = re.search(r"jsclassref='([^']*)'", webpage)
+        mobj = re.search(r"jsclassref ?= ?'([^']*)'", webpage)
-            video_description = u''
+            fd_mobj = re.search(r'<meta name="description" content="([^"]+)"', video_webpage)
-            video_description = ''
+            video_description = u''
-            self.trouble(u'ERROR: Erroneous output template')
+            self.report_error(u'Erroneous output template')
-            self.trouble(u'ERROR: Insufficient system charset ' + repr(preferredencoding()))
+            self.report_error(u'Insufficient system charset ' + repr(preferredencoding()))
-                self.trouble(u'ERROR: ' + compat_str(de), de.format_traceback())
+                self.report_error(compat_str(de), de.format_traceback())
-                    self.trouble(u'ERROR: ' + compat_str(e), tb=compat_str(traceback.format_exc()))
+                    self.report_error(compat_str(e), tb=compat_str(traceback.format_exc()))
-                self.trouble(u'ERROR: no suitable InfoExtractor: %s' % url)
+                self.report_error(u'no suitable InfoExtractor: %s' % url)
-                        self.trouble(u'ERROR: Cannot write subtitles file ' + descfn)
+                        self.report_error(u'Cannot write subtitles file ' + descfn)
-                self.trouble(u'\nERROR: unable to download video')
+                self.report_error(u'unable to download video')
-                self._downloader.trouble(err)
+                self._downloader.report_error(err)
-                (1, 'url', u'ERROR: Invalid URL: %s' % url)
+                (1, 'url', u'Invalid URL: %s' % url)
-                (3, 'url',    u'ERROR: could not extract video url: %s' % url)
+                (1, 'path',   u'could not extract video path: %s' % url),
-                (1, 'url', u'ERROR: Invalid URL: %s' % url)
+                (1, 'url', u'Invalid URL: %s' % url)
-                (1, 'url', u'ERROR: Could not find <video> tag: %s' % url)
+                (1, 'url', u'Could not find <video> tag: %s' % url)
-                (4, 'url',   u'ERROR: could not extract video url: %s' % url)
+                (1, 'id',    u'could not extract video id: %s' % url),
-                self._downloader.trouble(u'[youtube] No video results')
+                self._downloader.report_error(u'[youtube] No video results')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download video webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err['error_message']))
+                self._downloader.report_error(u'unable to download video webpage: %s' % compat_str(err['error_message']))
-                self._downloader.trouble(u'ERROR: unable to download stream definitions: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download stream definitions: %s' % compat_str(err))
-            self._downloader.trouble('Invalid rendition field.')
+            self._downloader.report_error('Invalid rendition field.')
-                self._downloader.trouble(u'Cannot find video title')
+                self._downloader.report_error(u'Cannot find video title')
-            self._downloader.trouble(u'ERROR: Cannot find video url for %s' % video_id)
+            self._downloader.report_error(u'Cannot find video url for %s' % video_id)
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'Cannot find video title')
+            self._downloader.report_error(u'Cannot find video title')
-        if sys.stderr.isatty():
+        if sys.stderr.isatty() and os.name != 'nt':
-        if sys.stderr.isatty():
+        if sys.stderr.isatty() and os.name != 'nt':
-            action='store', dest='format', metavar='FORMAT', help='video format code')
+            action='store', dest='format', metavar='FORMAT',
-        print(u'[debug] Command-line args: ' + repr(commandLineConf))
+        if opts.verbose:
-def parseOpts(arguments):
+def parseOpts(overrideArguments=None):
-        userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')
+    if overrideArguments is not None:
-    opts, args = parser.parse_args(argv)
+        xdg_config_home = os.environ.get('XDG_CONFIG_HOME')
-__version__ = '2013.04.21'
+__version__ = '2013.04.22'
-                return
+                raise ExtractorError(u'no known formats available for video')
-                    return
+                    raise ExtractorError(u'requested format not available')
-            return
+            raise ExtractorError(u'no conn or url_encoded_fmt_stream_map information found in video info')
-    argv = systemConf + userConf + commandLineConf if not arguments else arguments
+    argv = (systemConf + userConf + commandLineConf) if not arguments else arguments
-            dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(title)s to get the title, %(uploader)s for the uploader name, %(uploader_id)s for the uploader nickname if different, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(extractor)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout. Can also be used to download to a different directory, for example with -o \'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\' .')
+            dest='outtmpl', metavar='TEMPLATE',
-        urlRE = r"'movie_(?P<videoID>\d+)': \{\s*FILENAME: \"(?P<videoURL>[\w:/\.\?=]+)\"(,\s*MOVIE_NAME: \"(?P<videoName>[\w:/\.\?=\+-]+)\")?\s*\},"
+        game_title = re.search(r'<h2 class="pageheader">(?P<game_title>.*?)</h2>', webpage).group('game_title')
-        return videos
+        return [self.playlist_result(videos, gameID, game_title)]
-        videourl = 'http://store.steampowered.com/video/%s/' % gameID
+        videourl = 'http://store.steampowered.com/agecheck/video/%s/?snr=1_agecheck_agecheck__age-gate&ageDay=1&ageMonth=January&ageYear=1970' % gameID
-__version__ = '2013.04.18'
+__version__ = '2013.04.21'
-        suffix = 'bkMGTPEZY'[exponent]
+        suffix = ['B','KiB','MiB','GiB','TiB','PiB','EiB','ZiB','YiB'][exponent]
-            self._downloader.to_screen(u'[%s] %s: %s' % (self.IE_NAME, video_id, note))
+            self.to_screen(u'%s: %s' % (video_id, note))
-            self._downloader.to_screen(u'Dumping request to ' + url)
+            self.to_screen(u'Dumping request to ' + url)
-        
+
-        self._downloader.to_screen(u'[youtube] Setting language')
+        self.to_screen(u'Setting language')
-        self._downloader.to_screen(u'[youtube] Logging in')
+        self.to_screen(u'Logging in')
-        self._downloader.to_screen(u'[youtube] Confirming age')
+        self.to_screen(u'Confirming age')
-        self._downloader.to_screen(u'[youtube] %s: Downloading video webpage' % video_id)
+        self.to_screen(u'%s: Downloading video webpage' % video_id)
-        self._downloader.to_screen(u'[youtube] %s: Downloading video info webpage' % video_id)
+        self.to_screen(u'%s: Downloading video info webpage' % video_id)
-        self._downloader.to_screen(u'[youtube] %s: Checking available subtitles' % video_id)
+        self.to_screen(u'%s: Checking available subtitles' % video_id)
-        self._downloader.to_screen(u'[youtube] %s: Downloading video subtitles for %s.%s' % (video_id, sub_lang, format))
+        self.to_screen(u'%s: Downloading video subtitles for %s.%s' % (video_id, sub_lang, format))
-        self._downloader.to_screen(u'[youtube] %s: Available subtitles for video: %s' % (video_id, sub_lang))
+        self.to_screen(u'%s: Available subtitles for video: %s' % (video_id, sub_lang))
-        self._downloader.to_screen(u'[youtube] %s: Extracting video information' % video_id)
+        self.to_screen(u'%s: Extracting video information' % video_id)
-        self._downloader.to_screen(u'[youtube] %s: Format %s not available' % (video_id, format))
+        self.to_screen(u'%s: Format %s not available' % (video_id, format))
-        self._downloader.to_screen(u'[youtube] RTMP download detected')
+        self.to_screen(u'RTMP download detected')
-        self._downloader.to_screen(u'[metacafe] Retrieving disclaimer')
+        self.to_screen(u'Retrieving disclaimer')
-        self._downloader.to_screen(u'[metacafe] Confirming age')
+        self.to_screen(u'Confirming age')
-        self._downloader.to_screen(u'[metacafe] %s: Downloading webpage' % video_id)
+        self.to_screen(u'%s: Downloading webpage' % video_id)
-        self._downloader.to_screen(u'[metacafe] %s: Extracting information' % video_id)
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[dailymotion] %s: Extracting information' % video_id)
+        self.to_screen(u'%s: Extracting information' % video_id)
-                self._downloader.to_screen(u'[dailymotion] Using %s' % key)
+                self.to_screen(u'Using %s' % key)
-        self._downloader.to_screen(u'[photobucket] %s: Downloading webpage' % video_id)
+        self.to_screen(u'%s: Downloading webpage' % video_id)
-        self._downloader.to_screen(u'[photobucket] %s: Extracting information' % video_id)
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[video.yahoo] %s: Downloading webpage' % video_id)
+        self.to_screen(u'%s: Downloading webpage' % video_id)
-        self._downloader.to_screen(u'[video.yahoo] %s: Extracting information' % video_id)
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[vimeo] %s: Downloading webpage' % video_id)
+        self.to_screen(u'%s: Downloading webpage' % video_id)
-        self._downloader.to_screen(u'[vimeo] %s: Extracting information' % video_id)
+        self.to_screen(u'%s: Extracting information' % video_id)
-                self._downloader.to_screen(u'[vimeo] %s: Downloading %s file at %s quality' % (video_id, video_codec.upper(), video_quality))
+                self.to_screen(u'%s: Downloading %s file at %s quality' % (video_id, video_codec.upper(), video_quality))
-        self._downloader.to_screen(u'[arte.tv] %s: Downloading webpage' % video_id)
+        self.to_screen(u'%s: Downloading webpage' % video_id)
-        self._downloader.to_screen(u'[arte.tv] %s: Extracting information' % video_id)
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[generic] %s: Downloading webpage' % video_id)
+            self._downloader.report_warning(u'Falling back on generic information extractor.')
-        self._downloader.to_screen(u'[generic] %s: Extracting information' % video_id)
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[video.google] query "%s": Downloading page %s' % (query, pagenum))
+        self.to_screen(u'query "%s": Downloading page %s' % (query, pagenum))
-        self._downloader.to_screen(u'[video.yahoo] query "%s": Downloading page %s' % (query, pagenum))
+        self.to_screen(u'query "%s": Downloading page %s' % (query, pagenum))
-                (self.IE_NAME, username, pagenum))
+        self.to_screen(u'user %s: Downloading video ids from page %d' %
-        self._downloader.to_screen(u'[DepositFiles] %s: Downloading webpage' % file_id)
+        self.to_screen(u'%s: Downloading webpage' % file_id)
-        self._downloader.to_screen(u'[DepositFiles] %s: Extracting information' % file_id)
+        self.to_screen(u'%s: Extracting information' % file_id)
-        self._downloader.to_screen(u'[%s] Logging in' % self.IE_NAME)
+        self.to_screen(u'Logging in')
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, file_id))
+        self.to_screen(u'%s: Extracting information' % file_id)
-        self._downloader.to_screen(u'[%s] %s: Direct download detected' % (self.IE_NAME, title))
+        self.to_screen(u'%s: Direct download detected' % title)
-        self._downloader.to_screen(u'[myvideo] %s: Extracting information' % video_id)
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[comedycentral] %s: Extracting information' % episode_id)
+        self.to_screen(u'%s: Extracting information' % episode_id)
-        self._downloader.to_screen(u'[comedycentral] %s: Downloading configuration for %s' % (episode_id, media_id))
+        self.to_screen(u'%s: Downloading configuration for %s' % (episode_id, media_id))
-        self._downloader.to_screen(u'[comedycentral] %s: Downloading show index' % episode_id)
+        self.to_screen(u'%s: Downloading show index' % episode_id)
-        self._downloader.to_screen(u'[escapist] %s: Extracting information' % showName)
+        self.to_screen(u'%s: Extracting information' % showName)
-        self._downloader.to_screen(u'[escapist] %s: Downloading configuration' % showName)
+        self.to_screen(u'%s: Downloading configuration' % showName)
-        self._downloader.to_screen(u'[%s] %s: Downloading XML manifest' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Downloading XML manifest' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Resolving id' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Resolving id' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Retrieving stream' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Retrieving stream' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Resolving id' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Resolving id' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Retrieving stream' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Retrieving stream' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[%s] Downloading json' % self.IE_NAME)
+        self.to_screen(u'Downloading json')
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, file_id))
+        self.to_screen(u'%s: Extracting information' % file_id)
-        self._downloader.to_screen(u'[%s] %s: Downloading webpage' % (self.IE_NAME, objid))
+        self.to_screen(u'%s: Downloading webpage' % objid)
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Downloading webpage' % (self.IE_NAME, file_id))
+        self.to_screen(u'%s: Downloading webpage' % file_id)
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, file_id))
+        self.to_screen(u'%s: Extracting information' % file_id)
-        self._downloader.to_screen(u'[%s] %s: Downloading webpage' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Downloading webpage' % video_id)
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, video_id))
+        self.to_screen(u'%s: Extracting information' % video_id)
-        self._downloader.to_screen(u'[plus.google] Downloading entry: %s' % url)
+        self.to_screen(u'Downloading entry: %s' % url)
-        self._downloader.to_screen(u'[plus.google] Entry date: %s' % upload_date)
+        self.to_screen(u'Entry date: %s' % upload_date)
-        self._downloader.to_screen(u'[plus.google] Uploader: %s' % uploader)
+        self.to_screen(u'Uploader: %s' % uploader)
-        self._downloader.to_screen(u'[plus.google] Title: %s' % video_title)
+        self.to_screen(u'Title: %s' % video_title)
-        self._downloader.to_screen(u'[plus.google] Extracting video page: %s' % video_page)
+        self.to_screen(u'Extracting video page: %s' % video_page)
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, file_id))
+        self.to_screen(u'%s: Extracting information' % file_id)
-                (self.IE_NAME, channel, offset, offset + self._JUSTIN_PAGE_LIMIT))
+        self.to_screen(u'%s: Downloading video information from %d to %d' %
-        self._downloader.to_screen(u'[youporn] Links found: %d' % len(links))
+        self.to_screen(u'Links found: %d' % len(links))
-        self._downloader.to_screen(u'[youporn] Format: %s' % req_format)
+        self.to_screen(u'Format: %s' % req_format)
-            self._downloader.to_screen(u'[%s] Getting info of playlist %s: "%s"' % (self.IE_NAME,playlist_id,name))
+            self.to_screen(u'Getting info of playlist %s: "%s"' % (playlist_id,name))
-            self._downloader.to_screen(u'[%s] RTMP download detected' % self.IE_NAME)
+            self.to_screen(u'RTMP download detected')
-            return
+            return self._get_n_results(query, 1)
-            return
+            self._get_n_results(query, self._max_youtube_results)
-                return
+                return self._get_n_results(query, n)
-                return
+                return self._get_n_results(query, 1)
-        """Downloads a specified number of results for a query"""
+    def _get_n_results(self, query, n):
-        return
+        videos = [self.url_result('http://www.youtube.com/watch?v=%s' % id, 'Youtube') for id in video_ids]
-        return [self.playlist_result(url_results, playlist_id)]
+        return [self.playlist_result(url_results, playlist_id, playlist_title)]
-            return self._playlist_videos_info(url,name,playlist_id)
+            return [self._playlist_videos_info(url,name,playlist_id)]
-        info=[]
+
-        return info
+            playlist_entries.append(self.url_result(talk_url, 'TED'))
-    def extract_info(self, url, download = True):
+    def extract_info(self, url, download = True, ie_name = None):
-        for ie in self._ies:
+        
-            result = self.extract_info(ie_result['url'], download)[0]
+            result = self.extract_info(ie_result['url'], download, ie_name = ie_result['ie_key'])[0]
-                      'url': url}
+                      'url': url,
-            return [self.url_result('http://www.youtube.com/watch?v=%s' % mobj2.group(1))]
+            return [self.url_result('http://www.youtube.com/watch?v=%s' % mobj2.group(1), 'Youtube')]
-        url_results = [self.url_result(url) for url in videos]
+        url_results = [self.url_result(url, 'Youtube') for url in videos]
-        url_entries = [self.url_result(url) for url in urls]
+        url_entries = [self.url_result(url, 'Youtube') for url in urls]
-        url_results = [self.url_result(url) for url in urls]
+        url_results = [self.url_result(url, 'Youtube') for url in urls]
-        url_entries = [self.url_result(url) for url in urls]
+        url_entries = [self.url_result(url, 'BlipTV') for url in urls]
-        ie = getattr(youtube_dl.InfoExtractors, test_case['name'] + 'IE')
+        ie = youtube_dl.InfoExtractors.get_info_extractor(test_case['name'])#getattr(youtube_dl.InfoExtractors, test_case['name'] + 'IE')
-        webpage = self._download_webpage(request, video_id)
+        webpage = self._download_webpage('http://www.metacafe.com/watch/%s/' % video_id, video_id)
-            mobj = re.search(r'"mediaURL":"(http.*?)","key":"(.*?)"', vardict['mediaData'][0])
+            mobj = re.search(r'"mediaURL":"(?P<mediaURL>http.*?)",(.*?)"key":"(?P<key>.*?)"', vardict['mediaData'][0])
-            mediaURL = mobj.group(1).replace('\\/', '/')
+            mediaURL = mobj.group('mediaURL').replace('\\/', '/')
-            video_url = '%s?__gda__=%s' % (mediaURL, mobj.group(2))
+            video_url = '%s?__gda__=%s' % (mediaURL, mobj.group('key'))
-            return
+        webpage = self._download_webpage(request, video_id)
-        self.assertEqual(len(subtitles), 12)
+        self.assertEqual(len(subtitles), 13)
-from youtube_dl.InfoExtractors import YoutubeIE, YoutubePlaylistIE
+from youtube_dl.InfoExtractors import YoutubeIE, YoutubePlaylistIE, YoutubeChannelIE
-from youtube_dl.InfoExtractors import YoutubeUserIE, YoutubePlaylistIE, YoutubeIE
+from youtube_dl.InfoExtractors import YoutubeUserIE, YoutubePlaylistIE, YoutubeIE, YoutubeChannelIE
-        pass # TODO
+        dl = FakeDownloader()
-    _VALID_URL = r"^(?:https?://)?(?:youtu\.be|(?:\w+\.)?youtube(?:-nocookie)?\.com)/channel/([0-9A-Za-z_-]+)(?:/.*)?$"
+    _VALID_URL = r"^(?:https?://)?(?:youtu\.be|(?:\w+\.)?youtube(?:-nocookie)?\.com)/channel/([0-9A-Za-z_-]+)"
-    _MORE_PAGES_INDICATOR = u"Next \N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}"
+    _MORE_PAGES_INDICATOR = 'yt-uix-load-more'
-        # Download channel pages
+        # Download channel page
-                return
+        self.report_download_page(channel_id, pagenum)
-            video_ids.extend(ids_in_page)
+        # Extract video identifiers
-            pagenum = pagenum + 1
+        # Download any subsequent channel pages using the json-based channel_ajax query
-            if not 'feed' in response or not 'entry' in response['feed']:
+            if 'feed' not in response:
-__version__ = '2013.04.11'
+__version__ = '2013.04.18'
-            self._downloader.trouble(u'Cannot find video title')
+            m = re.search(r'<title>(?P<title>[^<]+?)</title>', webpage)
-        BEFORE = '[["allowFullScreen","true"],["allowScriptAccess","always"],["salign","tl"],["scale","noscale"],["wmode","opaque"]].forEach(function(param) {swf.addParam(param[0], param[1]);});\n'
+        BEFORE = '{swf.addParam(param[0], param[1]);});\n'
-        video_url = params['hd_src']
+        video_data = params['video_data'][0]
-            video_url = params['sd_src']
+            video_url = video_data['sd_src']
-        video_duration = int(params['video_duration'])
+        video_duration = int(video_data['video_duration'])
-            'thumbnail': params['thumbnail_src'],
+            'thumbnail': thumbnail,
-            url_map = dict((ud['itag'][0], ud['url'][0] + '&signature=' + ud['sig'][0] + '&ratebypass=yes') for ud in url_data)
+            url_map = dict((ud['itag'][0], ud['url'][0] + '&signature=' + ud['sig'][0]) for ud in url_data)
-            url_map = dict((ud['itag'][0], ud['url'][0] + '&signature=' + ud['sig'][0]) for ud in url_data)
+            url_map = dict((ud['itag'][0], ud['url'][0] + '&signature=' + ud['sig'][0] + '&ratebypass=yes') for ud in url_data)
-def parseOpts():
+def parseOpts(arguments):
-    argv = systemConf + userConf + commandLineConf
+    commandLineConf = sys.argv[1:] 
-    parser, opts, args = parseOpts()
+def _real_main(argv=None):
-def main():
+def main(argv=None):
-        _real_main()
+        _real_main(argv)
-__version__ = '2013.04.03'
+__version__ = '2013.04.11'
-        m = re.search(r'<meta property="og:title" content="(?P<title>.+)"', webpage)
+        m = re.search(r'<meta property="og:title" content="(?P<title>.*?)"', webpage)
-        self._downloader.to_screen(u'[%s] %s: %s' % (self.IE_NAME, video_id, note))
+        if note is not False:
-            video_info_url = ('http://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en'
+            video_info_url = ('https://www.youtube.com/get_video_info?&video_id=%s%s&ps=default&eurl=&gl=US&hl=en'
-                return
+            video_info_webpage = self._download_webpage(video_info_url, video_id,
-            autonumber_size = self.params.get('autonumber_size', 5)
+            autonumber_size = self.params.get('autonumber_size')
-            template_dict['autonumber'] = u'%05d' % self._num_downloads
+            autonumber_size = self.params.get('autonumber_size', 5)
-    _TITLE = r'<h1 class="boxTopHeadline">(?P<title>.*)</h1>'
+    _VALID_URL = r'^(?:https?://)?(?:(?:www\.)?ardmediathek\.de|mediathek\.daserste\.de)/(?:.*/)(?P<video_id>[^/\?]+)(?:\?.*)?'
-        video_id = m.group('video_id')
+
-        #stream = streams[-1]
+        stream = max([s for s in streams if int(s["media_type"]) == 0],
-    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+    path = os.path.realpath(os.path.abspath(__file__))
-        else: video_description = ''
+        else: video_description = u''
-            n_videos = len(ie_result['entries'])
+
-                self.to_screen(u'[download] Downloading video #%s of %s' %(i, n_videos))
+
-            return
+            return [self.url_result('http://www.youtube.com/watch?v=%s' % mobj2.group(1))]
-    def extract_info(self, url):
+    def extract_info(self, url, download = True):
-                results = self.process_ie_results(ie_results, ie)
+                results = []
-    def process_ie_results(self, ie_results, ie):
+    def process_ie_result(self, ie_result, download = True):
-        For url elements it will seartch the suitable ie and get the videos
+        Take the result of the ie and return a list of videos.
-        return results
+        result_type = ie_result.get('_type', 'video') #If not given we suppose it's a video, support the dafault old system
-            return
+        #We increment the download the download count here to match the previous behaviour.
-                    raise
+            try:
-            for video in info_dict['entries']:
+            n_videos = len(info_dict['entries'])
-    def _download_with_rtmpdump(self, filename, url, player_url, page_url):
+    def _download_with_rtmpdump(self, filename, url, player_url, page_url, play_path):
-                                                info_dict.get('page_url', None))
+                                                info_dict.get('page_url', None),
-									<atom:link href="http://rg3.github.com/youtube-dl" />
+									<atom:link href="http://rg3.github.io/youtube-dl" />
-UPDATE_URL = "http://rg3.github.com/youtube-dl/update/"
+UPDATE_URL = "http://rg3.github.io/youtube-dl/update/"
-    UPDATE_URL = "http://rg3.github.com/youtube-dl/update/"
+    UPDATE_URL = "http://rg3.github.io/youtube-dl/update/"
-__version__ = '2013.03.29'
+__version__ = '2013.04.03'
-                return
+            if sub_error:
-                    return
+                if sub_error:
-            return (u'WARNING: unable to download video subtitles: %s' % compat_str(err), None)
+            return (u'unable to download video subtitles: %s' % compat_str(err), None)
-            return (u'WARNING: video doesn\'t have subtitles', None)
+            return (u'video doesn\'t have subtitles', None)
-            return (u'WARNING: unable to download video subtitles: %s' % compat_str(err), None, None)
+            return (u'unable to download video subtitles: %s' % compat_str(err), None, None)
-            return (u'WARNING: Did not fetch video subtitles', None, None)
+            return (u'Did not fetch video subtitles', None, None)
-            return [(u'WARNING: no closed captions found in the specified language "%s"' % sub_lang, None, None)]
+            return [(u'no closed captions found in the specified language "%s"' % sub_lang, None, None)]
-                    self._downloader.trouble(sub_error)
+                    self._downloader.report_error(sub_error)
-                    self._downloader.trouble(sub_error)
+                    self._downloader.report_error(sub_error)
-                    if not err.exc_info[0] in (ZeroDivisionError, compat_urllib_error.URLError, socket.timeout):
+                    if not err.exc_info[0] in (compat_urllib_error.URLError, socket.timeout, UnavailableVideoError):
-            fd.add_info_extractor(getattr(youtube_dl.InfoExtractors, ien + 'IE')())
+        for ie in youtube_dl.InfoExtractors.gen_extractors():
-        
+
-        
+
-            return (u'WARNING: unable to download video subtitles: %s' % compat_str(err), None)
+            return (u'WARNING: unable to download video subtitles: %s' % compat_str(err), None, None)
-            return (u'WARNING: Did not fetch video subtitles', None)
+            return (u'WARNING: Did not fetch video subtitles', None, None)
-            return (u'WARNING: no closed captions found in the specified language "%s"' % sub_lang, None)
+            return [(u'WARNING: no closed captions found in the specified language "%s"' % sub_lang, None, None)]
-with open('update/atom.atom','w',encoding='utf-8') as atom_file:
+with open('update/releases.atom','w',encoding='utf-8') as atom_file:
-									<atom:subtitle>Updates feed.</atom:subtitle>
+								<atom:feed xmlns:atom="http://www.w3.org/2005/Atom">
-__version__ = '2013.02.25'
+__version__ = '2013.03.29'
-in_file = out_file
+import textwrap
-atom_url = "http://www.w3.org/2005/Atom"
+atom_template = atom_template.replace('@TIMESTAMP@',now_iso)
-		
+versions_info = json.load(open('update/versions.json'))
-atom = ET.parse(in_file)
+for v in versions:
-root = atom.getroot()
+entries_str = textwrap.indent(''.join(entries), '\t')
-ET.register_namespace("atom",atom_url)
+with open('update/atom.atom','w',encoding='utf-8') as atom_file:
-        mobj = re.search(r'<link rel=\'image_src\' href=\'(http://is[0-9].myvideo\.de/de/movie[0-9]+/[a-f0-9]+)/thumbs/.*?\.jpg\' />',
+        mobj = re.search(r'<link rel=\'image_src\' href=\'(http://is[0-9].myvideo\.de/de/movie[0-9]+/[a-f0-9]+)/thumbs/.*?\.jpg\'',
-        m = re.search(r"class='player_page_h1'>\s+<a.*?>(?P<title>.*?)</a>", webpage)
+        m = re.search(r"<h1 class='player_page_h1'.*?>(?P<title>.*?)</h1>", webpage, flags=re.DOTALL)
-        title = unescapeHTML(m.group('title'))
+        title = clean_html(m.group('title'))
-        title_RE=r'<h1><span id="altHeadline" >(?P<title>.*)</span></h1>'
+        title_RE=r'<span id="altHeadline" >(?P<title>.*)</span>'
-    return html
+    return html.strip()
-    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<videoID>[0-9]+)(?:\.html)?(?:#.*)$'
+    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<videoID>[0-9]+)(?:\.html)?(?:#.*)?$'
-class liveleakIE(InfoExtractor):
+class LiveLeakIE(InfoExtractor):
-    _VALID_URL = r'^(?:http?://)?(?:\w+\.)?liveleak\.com/view\?(?:.*?)i=(?P<video_id>\d+)(?:.*)'
+    _VALID_URL = r'^(?:http?://)?(?:\w+\.)?liveleak\.com/view\?(?:.*?)i=(?P<video_id>[\w_]+)(?:.*)'
-            video_id = video_id[:-len('/index.html')]
+        video_id = mobj.group('video_id')
-        video_url = u'http://edge.liveleak.com/80281E/u/u/ll2_player_files/mp55/player.swf?config=http://www.liveleak.com/player?a=config%26item_token=' + video_id
+        m = re.search(r'file: "(.*?)",', webpage)
-        title = unescapeHTML(m.group('title'))
+        title = unescapeHTML(m.group('title')).replace('LiveLeak.com -', '').strip()
-            'description': desc
+            'description': desc,
-        liveleakIE(),
+        LiveLeakIE(),
-                results.extend(entries_result)
+                result['entries'] = entries_result
-    def playlist_result(self, entries):
+    def playlist_result(self, entries, playlist_id=None, playlist_title=None):
-        return [self.playlist_result(url_results)]
+        return [self.playlist_result(url_results, playlist_id)]
-        return [self.playlist_result(url_entries)]
+        return [self.playlist_result(url_entries, channel_id)]
-        return [self.playlist_result(url_results)]
+        return [self.playlist_result(url_results, playlist_title = username)]
-        return [self.playlist_result(url_entries)]
+        return [self.playlist_result(url_entries, playlist_title = username)]
-            return (sys.stdout.buffer, filename)
+            return (sys.stdout.buffer if hasattr(sys.stdout, 'buffer') else sys.stdout, filename)
-            return (sys.stdout, filename)
+            return (sys.stdout.buffer, filename)
-        uploader = unescapeHTML(m.group('uploader'))
+        m = re.search(r'<div class="user-name-and-bio">[\S\s]+?<h2>(?P<uploader>.+?)</h2>', webpage)
-                'url':video_url,
+                'id': video_id,
-    video_format.add_option('--write-sub',
+    video_format.add_option('--write-sub', '--write-srt',
-    video_format.add_option('--sub-lang',
+    video_format.add_option('--sub-lang', '--srt-lang',
-            return (u'WARNING: video doesn\'t have download', None)
+            return (u'WARNING: video doesn\'t have subtitles', None)
-        self._downloader.to_screen(u'[youtube] %s: Downloading video subtitles' % video_id)
+        self._downloader.to_screen(u'[youtube] %s: Checking available subtitles' % video_id)
-    def report_video_subtitles_request(self, video_id, lang):
+    def report_video_subtitles_request(self, video_id, sub_lang, format):
-        self._downloader.to_screen(u'[youtube] %s: Downloading video subtitles for lang: %s' % (video_id,lang))
+        self._downloader.to_screen(u'[youtube] %s: Downloading video subtitles for %s.%s' % (video_id, sub_lang, format))
-            return (u'WARNING: video has no closed captions', None)
+            return (u'WARNING: video doesn\'t have download', None)
-        self.report_video_subtitles_request(video_id, sub_lang)
+        self.report_video_subtitles_request(video_id, sub_lang, format)
-        self.report_video_subtitles_download(video_id)
+        if self._downloader.params.get('listsubtitles', False):
-        
+        DL.params['subtitlesformat'] = 'srt'
-    writesubtitles:    Write the video subtitles to a file (default=srt)
+    writesubtitles:    Write the video subtitles to a file
-                sub_filename = filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.srt'
+                sub_filename = filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.' + sub_format
-                    sub_filename = filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.srt'
+                    sub_filename = filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.' + sub_format
-    def _request_subtitle(self, sub_lang, sub_name, video_id, format = 'srt'):
+    def _request_subtitle(self, sub_lang, sub_name, video_id, format):
-
+        sub_format = self._downloader.params.get('subtitlesformat')
-        subtitle = self._request_subtitle(sub_lang, sub_lang_list[sub_lang].encode('utf-8'), video_id)
+        subtitle = self._request_subtitle(sub_lang, sub_lang_list[sub_lang].encode('utf-8'), video_id, sub_format)
-            subtitle = self._request_subtitle(sub_lang, sub_lang_list[sub_lang].encode('utf-8'), video_id)
+            subtitle = self._request_subtitle(sub_lang, sub_lang_list[sub_lang].encode('utf-8'), video_id, sub_format)
-        # closed captions
+        # subtitles
-    writesubtitles:    Write the video subtitles to a .srt file
+    writesubtitles:    Write the video subtitles to a file (default=srt)
-    def report_writesubtitles(self, srtfn):
+    def report_writesubtitles(self, sub_filename):
-        self.to_screen(u'[info] Writing video subtitles to: ' + srtfn)
+        self.to_screen(u'[info] Writing video subtitles to: ' + sub_filename)
-            (srt_error, srt_lang, srt) = subtitle
+            (sub_error, sub_lang, sub) = subtitle
-                    srtfile.write(srt)
+                sub_filename = filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.srt'
-                (srt_error, srt_lang, srt) = subtitle
+                (sub_error, sub_lang, sub) = subtitle
-                            srtfile.write(srt)
+                    sub_filename = filename.rsplit('.', 1)[0] + u'.' + sub_lang + u'.srt'
-    subtitles:      The .srt file contents.
+    subtitles:      The subtitle file contents.
-            srt_list = compat_urllib_request.urlopen(request).read().decode('utf-8')
+            sub_list = compat_urllib_request.urlopen(request).read().decode('utf-8')
-        if not srt_lang_list:
+        sub_lang_list = re.findall(r'name="([^"]*)"[^>]+lang_code="([\w\-]+)"', sub_list)
-        return srt_lang_list
+        return sub_lang_list
-        self.report_video_subtitles_request(video_id, str_lang)
+    def _request_subtitle(self, sub_lang, sub_name, video_id, format = 'srt'):
-            'name': str_name,
+            'lang': sub_lang,
-            srt = compat_urllib_request.urlopen(url).read().decode('utf-8')
+            sub = compat_urllib_request.urlopen(url).read().decode('utf-8')
-        if not srt:
+        if not sub:
-        return (None, str_lang, srt)
+        return (None, sub_lang, sub)
-        srt_lang_list = self._get_available_subtitles(video_id)
+        sub_lang_list = self._get_available_subtitles(video_id)
-            srt_lang = 'en'
+            sub_lang = self._downloader.params.get('subtitleslang')
-            return (u'WARNING: no closed captions found in the specified language "%s"' % srt_lang, None)
+            sub_lang = list(sub_lang_list.keys())[0]
-        return [sub]
+        subtitle = self._request_subtitle(sub_lang, sub_lang_list[sub_lang].encode('utf-8'), video_id)
-        return subs
+        sub_lang_list = self._get_available_subtitles(video_id)
-                    self._downloader.trouble(srt_error)
+                (sub_error, sub_lang, sub) = video_subtitles[0]
-                    self._downloader.trouble(srt_error)
+                (sub_error, sub_lang, sub) = video_subtitle
-    video_format.add_option('--write-srt',
+    video_format.add_option('--write-sub',
-    video_format.add_option('--only-srt',
+            help='write subtitle file (currently youtube only)', default=False)
-    video_format.add_option('--all-srt',
+            help='downloads only the subtitles (no video)', default=False)
-    video_format.add_option('--srt-lang',
+    video_format.add_option('--sub-lang',
-            help='language of the closed captions to download (optional) use IETF language tags like \'en\'')
+            help='language of the subtitles to download (optional) use IETF language tags like \'en\'')
-
+        sub = info_dict[0]['subtitles'][0]
-
+        sub = info_dict[0]['subtitles'][0]
-        self.assertEqual(md5(info_dict[0]['subtitles']), '4cd9278a35ba2305f47354ee13472260')
+        sub = info_dict[0]['subtitles'][0]
-                    srtfn = filename.rsplit('.', 1)[0] + u'.' + self.params['subtitleslang'] + u'.srt'
+                srtfn = filename.rsplit('.', 1)[0] + u'.' + srt_lang + u'.srt'
-                    return 
+                    srtfile.write(srt)
-        self.report_video_subtitles_download(video_id)
+    def _get_available_subtitles(self, video_id):
-            return (u'WARNING: no closed captions found in the specified language "%s"' % srt_lang, None)
+        return srt_lang_list
-            'name': srt_lang_list[srt_lang].encode('utf-8'),
+            'lang': str_lang,
-            'fmt': 'srt',
+            'fmt': format,
-        return (None, srt)
+        return (None, str_lang, srt)
-            self._downloader.params['writesubtitles'] = True
+
-                self._downloader.trouble(srt_error)
+            video_subtitles = self._extract_subtitle(video_id)
-    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<videoID>[0-9]+)(?:\.html)?$'
+    _VALID_URL = r'https?://(?:www\.)?spiegel\.de/video/[^/]*-(?P<videoID>[0-9]+)(?:\.html)?(?:#.*)$'
-        return webpage_bytes.decode('utf-8', 'replace')
+        return webpage_bytes.decode(encoding, 'replace')
-        userConf = os.path.join(xdg_config_home, 'youtube-dl.conf')
+        userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')
-    argv = _readOptions('/etc/youtube-dl.conf') + _readOptions(userConf) + sys.argv[1:]
+        userConfFile = os.path.join(os.path.expanduser('~'), '.config', 'youtube-dl.conf')
-            fd.download([test_case['url']])
+            for retry in range(1, RETRIES + 1):
-                tb = u''.join(tb_data)
+                if sys.exc_info()[0]:  # if .trouble has been called from an except block
-            raise DownloadError(message)
+            if sys.exc_info()[0] and hasattr(sys.exc_info()[1], 'exc_info') and sys.exc_info()[1].exc_info[0]:
-    pass
+    def __init__(self, msg, exc_info=None):
-            ext = None
+            self._downloader.trouble(u'ERROR: Cannot find video url for %s' % video_id)
-        webpage_src = compat_urllib_request.urlopen(str(url)).read()
+        webpage_src = compat_urllib_request.urlopen(url).read()
-        self._downloader.to_screen(u'WARNING: Falling back on generic information extractor.')
+        if not self._downloader.params.get('test', False):
-            return
+            webpage = self._download_webpage(url, video_id)
-            self.trouble(u'ERROR: invalid system charset or erroneous output template')
+        except KeyError as err:
-    _VALID_URL = r"""(http://(?:www|m).worldstar(?:candy|hiphop)\.com.*)"""
+    _VALID_URL = r'http://(?:www|m)\.worldstar(?:candy|hiphop)\.com/videos/video\.php\?v=(?P<id>.*)'
-        print title
+        m = re.match(self._VALID_URL, url)
-
+        webpage_src = webpage_src.decode('utf-8')
-                ext = '.mp4'
+                ext = 'mp4'
-                ext = '.flv'
+                ext = 'flv'
-            title = None
+            title = 'World Start Hip Hop - %s' % time.ctime()
-
+        results = [{
-            'ext': 'flv',
+            'ext': 'mp4',
-            'ext': 'mp4',
+            'ext': 'flv',
-            'ext': 'flv',
+            'ext': 'mp4',
-        """Check if it is a redirect, like url shorteners, in case restart chain."""
+        """Check if it is a redirect, like url shorteners, in case return the new url."""
-        return True
+        return new_url
-        if self._test_redirect(url): return
+        new_url = self._test_redirect(url)
-            self._downloader.trouble(u'WARNING: unable to extract uploader nickname')
+            self._downloader.report_warning(u'unable to extract uploader nickname')
-            self._downloader.trouble(u'WARNING: unable to extract video thumbnail')
+            self._downloader.report_warning(u'unable to extract video thumbnail')
-            self._downloader.trouble(u'WARNING: unable to extract video duration')
+            self._downloader.report_warning(u'unable to extract video duration')
-                self._downloader.trouble(u'WARNING: unable to extract uploader nickname')
+                self._downloader.report_warning(u'unable to extract uploader nickname')
-                self._downloader.trouble(u'\nERROR: unable to download ' + mediaId + ': No videos found')
+                self._downloader.report_error(u'unable to download ' + mediaId + ': No videos found')
-            self._downloader.trouble(u'\nERROR: Invalid metadata XML file')
+            self._downloader.report_error(u'Invalid metadata XML file')
-            self._downloader.trouble(u'\nERROR: Invalid manifest file')
+            self._downloader.report_error(u'Invalid manifest file')
-                self._downloader.trouble(u'\nERROR: Invalid metadata XML file')
+                self._downloader.report_error(u'Invalid metadata XML file')
-        ytie_results = [YoutubeIE()._extract_id(url) for url in dl.result]
+        result = ie.extract('https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re')[0]
-        self.assertTrue(len(dl.result) > 40)
+        result = ie.extract('PLBB231211A4F62143')[0]
-        self.assertTrue(len(dl.result) >= 799)
+        result = ie.extract('https://www.youtube.com/playlist?list=UUBABnxM4Ar9ten8Mdjj1j0Q')[0]
-        ytie_results = [YoutubeIE()._extract_id(url) for url in dl.result]
+        result = ie.extract('https://www.youtube.com/playlist?list=PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC')[0]
-        self.assertEqual(YoutubeIE()._extract_id(dl.result[-1]), 'rYefUsYuEp0')
+        result = ie.extract('https://www.youtube.com/course?list=ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8')[0]
-        self.assertTrue(len(dl.result) >= 320)
+        result = ie.extract('https://www.youtube.com/user/TheLinuxFoundation')[0]
-        return self._downloader.extract_info_iterable(videos)
+        url_results = [self.url_result(url) for url in videos]
-        return self._downloader.extract_info_iterable(urls)
+        url_entries = [self.url_result(url) for url in urls]
-        return self._downloader.extract_info_iterable(urls)
+        url_results = [self.url_result(url) for url in urls]
-        return self._downloader.extract_info_iterable(urls)
+        url_entries = [self.url_result(url) for url in urls]
-                return videos
+                ie_results = ie.extract(url)
-        return
+        urls = ['http://www.youtube.com/watch?v=%s' % id for id in video_ids]
-            self._downloader.download([u'http://blip.tv/'+video_id])
+        urls = [u'http://blip.tv/%s' % video_id for video_id in video_ids]
-class FakeDownloader(object):
+class FakeDownloader(FileDownloader):
-        self.result.append(x)
+    def extract_info(self, url):
-        ytie_results = [YoutubeIE()._extract_id(r[0]) for r in dl.result]
+        ytie_results = [YoutubeIE()._extract_id(url) for url in dl.result]
-        ytie_results = [YoutubeIE()._extract_id(r[0]) for r in dl.result]
+        ytie_results = [YoutubeIE()._extract_id(url) for url in dl.result]
-        self.assertEqual(YoutubeIE()._extract_id(dl.result[0][0]), 'j9WZyLZCBzs')
+        self.assertEqual(YoutubeIE()._extract_id(dl.result[0]), 'j9WZyLZCBzs')
-        self.assertEqual(YoutubeIE()._extract_id(dl.result[-1][0]), 'rYefUsYuEp0')
+        self.assertEqual(YoutubeIE()._extract_id(dl.result[-1]), 'rYefUsYuEp0')
-        return
+        return self._downloader.extract_info_iterable(videos)
-            self._downloader.download(['http://www.youtube.com/watch?v=%s' % video_id])
+        urls = ['http://www.youtube.com/watch?v=%s' % video_id for video_id in video_ids]
-            self._downloader.trouble(u'ERROR: unable to confirm age: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to confirm age: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download video webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download video info webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: YouTube said: %s' % video_info['reason'][0])
+                self._downloader.report_error(u'YouTube said: %s' % video_info['reason'][0])
-                self._downloader.trouble(u'ERROR: "token" parameter not in video info for unknown reason')
+                self._downloader.report_error(u'"token" parameter not in video info for unknown reason')
-            self._downloader.trouble(u'ERROR: "rental" videos not supported')
+            self._downloader.report_error(u'"rental" videos not supported')
-            self._downloader.trouble(u'ERROR: unable to extract uploader name')
+            self._downloader.report_error(u'unable to extract uploader name')
-            self._downloader.trouble(u'ERROR: unable to extract video title')
+            self._downloader.report_error(u'unable to extract video title')
-                self._downloader.trouble(u'ERROR: no known formats available for video')
+                self._downloader.report_error(u'no known formats available for video')
-                    self._downloader.trouble(u'ERROR: requested format not available')
+                    self._downloader.report_error(u'requested format not available')
-            self._downloader.trouble(u'ERROR: no conn or url_encoded_fmt_stream_map information found in video info')
+            self._downloader.report_error(u'no conn or url_encoded_fmt_stream_map information found in video info')
-            self._downloader.trouble(u'ERROR: unable to retrieve disclaimer: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to retrieve disclaimer: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to confirm age: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to confirm age: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'unable retrieve video webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: unable to extract media URL')
+                self._downloader.report_error(u'unable to extract media URL')
-                self._downloader.trouble(u'ERROR: unable to extract media URL')
+                self._downloader.report_error(u'unable to extract media URL')
-                self._downloader.trouble(u'ERROR: unable to extract media URL')
+                self._downloader.report_error(u'unable to extract media URL')
-            self._downloader.trouble(u'ERROR: unable to extract title')
+            self._downloader.report_error(u'unable to extract title')
-            self._downloader.trouble(u'ERROR: unable to extract uploader nickname')
+            self._downloader.report_error(u'unable to extract uploader nickname')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract media URL')
+            self._downloader.report_error(u'unable to extract media URL')
-            self._downloader.trouble(u'ERROR: unable to extract video URL')
+            self._downloader.report_error(u'unable to extract video URL')
-            self._downloader.trouble(u'ERROR: unable to extract video URL')
+            self._downloader.report_error(u'unable to extract video URL')
-            self._downloader.trouble(u'ERROR: unable to extract title')
+            self._downloader.report_error(u'unable to extract title')
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to extract media URL')
+            self._downloader.report_error(u'unable to extract media URL')
-            self._downloader.trouble(u'ERROR: unable to extract title')
+            self._downloader.report_error(u'unable to extract title')
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-                self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: Unable to extract id field')
+                self._downloader.report_error(u'Unable to extract id field')
-                self._downloader.trouble(u'ERROR: Unable to extract vid field')
+                self._downloader.report_error(u'Unable to extract vid field')
-            self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to extract video title')
+            self._downloader.report_error(u'unable to extract video title')
-            self._downloader.trouble(u'ERROR: unable to extract video uploader')
+            self._downloader.report_error(u'unable to extract video uploader')
-            self._downloader.trouble(u'ERROR: unable to extract video thumbnail')
+            self._downloader.report_error(u'unable to extract video thumbnail')
-            self._downloader.trouble(u'ERROR: unable to extract video description')
+            self._downloader.report_error(u'unable to extract video description')
-            self._downloader.trouble(u'ERROR: unable to extract video height')
+            self._downloader.report_error(u'unable to extract video height')
-            self._downloader.trouble(u'ERROR: unable to extract video width')
+            self._downloader.report_error(u'unable to extract video width')
-            self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: Unable to extract media URL')
+            self._downloader.report_error(u'Unable to extract media URL')
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to extract info section')
+            self._downloader.report_error(u'unable to extract info section')
-            self._downloader.trouble(u'ERROR: no known codec found')
+            self._downloader.report_error(u'no known codec found')
-            self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract title')
+            self._downloader.report_error(u'unable to extract title')
-            self._downloader.trouble(u'ERROR: unable to extract title')
+            self._downloader.report_error(u'unable to extract title')
-            self._downloader.trouble(u'ERROR: invalid search query "%s"' % query)
+            self._downloader.report_error(u'invalid search query "%s"' % query)
-                    self._downloader.trouble(u'ERROR: invalid download number %s for query "%s"' % (n, query))
+                    self._downloader.report_error(u'invalid download number %s for query "%s"' % (n, query))
-                self._downloader.trouble(u'ERROR: unable to download API page: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download API page: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid search query "%s"' % query)
+            self._downloader.report_error(u'invalid search query "%s"' % query)
-                    self._downloader.trouble(u'ERROR: invalid download number %s for query "%s"' % (n, query))
+                    self._downloader.report_error(u'invalid download number %s for query "%s"' % (n, query))
-                self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid search query "%s"' % query)
+            self._downloader.report_error(u'invalid search query "%s"' % query)
-                    self._downloader.trouble(u'ERROR: invalid download number %s for query "%s"' % (n, query))
+                    self._downloader.report_error(u'invalid download number %s for query "%s"' % (n, query))
-                self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid url: %s' % url)
+            self._downloader.report_error(u'invalid url: %s' % url)
-                self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: Invalid JSON in API response: ' + compat_str(err))
+                self._downloader.report_error(u'Invalid JSON in API response: ' + compat_str(err))
-                self._downloader.trouble(u'ERROR: Got a malformed response from YouTube API')
+                self._downloader.report_error(u'Got a malformed response from YouTube API')
-            self._downloader.trouble(u'ERROR: invalid url: %s' % url)
+            self._downloader.report_error(u'invalid url: %s' % url)
-                self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid url: %s' % url)
+            self._downloader.report_error(u'invalid url: %s' % url)
-                self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid url: %s' % url)
+            self._downloader.report_error(u'invalid url: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: unable to download webpage: %s' % str(err))
+                self._downloader.report_error(u'unable to download webpage: %s' % str(err))
-            self._downloader.trouble(u'ERROR: Unable to retrieve file webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve file webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: %s' % restriction_message)
+                self._downloader.report_error(u'%s' % restriction_message)
-                self._downloader.trouble(u'ERROR: unable to extract download URL from: %s' % url)
+                self._downloader.report_error(u'unable to extract download URL from: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract title')
+            self._downloader.report_error(u'unable to extract title')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-                self._downloader.trouble(u'ERROR: unable to read video info webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to read video info webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: unable to parse video information: %s' % repr(err))
+                self._downloader.report_error(u'unable to parse video information: %s' % repr(err))
-            self._download.trouble(u'ERROR: invalid URL: %s' % url)
+            self._download.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract media URL')
+            self._downloader.report_error(u'unable to extract media URL')
-            self._downloader.trouble(u'ERROR: unable to extract title')
+            self._downloader.report_error(u'unable to extract title')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download webpage: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: Invalid redirected URL: ' + url)
+                self._downloader.report_error(u'Invalid redirected URL: ' + url)
-                self._downloader.trouble(u'ERROR: Redirected URL is still not specific: ' + url)
+                self._downloader.report_error(u'Redirected URL is still not specific: ' + url)
-                self._downloader.trouble(u'ERROR: unable to find Flash URL in webpage ' + url)
+                self._downloader.report_error(u'unable to find Flash URL in webpage ' + url)
-            self._downloader.trouble(u'ERROR: unable to download episode index: ' + compat_str(err))
+            self._downloader.report_error(u'unable to download episode index: ' + compat_str(err))
-                self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download webpage: ' + compat_str(err))
+            self._downloader.report_error(u'unable to download webpage: ' + compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to download configuration: ' + compat_str(err))
+            self._downloader.report_error(u'unable to download configuration: ' + compat_str(err))
-            self._downloader.trouble(u'ERROR: Invalid JSON in configuration file: ' + compat_str(err))
+            self._downloader.report_error(u'Invalid JSON in configuration file: ' + compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download video info XML: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download video info XML: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract video url')
+            self._downloader.report_error(u'unable to extract video url')
-            self._downloader.trouble(u'ERROR: unable to extract video title')
+            self._downloader.report_error(u'unable to extract video title')
-            self._downloader.trouble(u'ERROR: unable to extract video thumbnail')
+            self._downloader.report_error(u'unable to extract video thumbnail')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to download stream definitions: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download stream definitions: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract video url')
+            self._downloader.report_error(u'unable to extract video url')
-            self._downloader.trouble(u'ERROR: unable to extract video title')
+            self._downloader.report_error(u'unable to extract video title')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Unable to retrieve file: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve file: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: format is not available')
+                self._downloader.report_error(u'format is not available')
-                self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % compat_str(err))
+                self._downloader.report_error(u'unable to download video info XML: %s' % compat_str(err))
-                self._downloader.trouble(u'ERROR: unable to download course info page: ' + compat_str(err))
+                self._downloader.report_error(u'unable to download course info page: ' + compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract song name')
+            self._downloader.report_error(u'unable to extract song name')
-            self._downloader.trouble(u'ERROR: unable to extract performer')
+            self._downloader.report_error(u'unable to extract performer')
-            self._downloader.trouble(u'ERROR: unable to mtvn_uri')
+            self._downloader.report_error(u'unable to mtvn_uri')
-            self._downloader.trouble(u'ERROR: unable to extract content id')
+            self._downloader.report_error(u'unable to extract content id')
-            self._downloader.trouble(u'ERROR: unable to download video metadata: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download video metadata: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to extract info section')
+            self._downloader.report_error(u'unable to extract info section')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % err)
+            self._downloader.report_error(u'unable to download video webpage: %s' % err)
-            self._downloader.trouble(u'ERROR: unable to extract video url')
+            self._downloader.report_error(u'unable to extract video url')
-            self._downloader.trouble(u'ERROR: unable to extract video title')
+            self._downloader.report_error(u'unable to extract video title')
-            self._downloader.trouble(u'ERROR: unable to extract video thumbnail')
+            self._downloader.report_error(u'unable to extract video thumbnail')
-            self._downloader.trouble(u'ERROR: Invalid URL: %s' % url)
+            self._downloader.report_error(u'Invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: Unable to retrieve entry webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve entry webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to extract video page URL')
+            self._downloader.report_error(u'unable to extract video page URL')
-            self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+            self._downloader.report_error(u'Unable to retrieve video webpage: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: unable to extract video links')
+            self._downloader.report_error(u'unable to extract video links')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to download video info JSON: %s' % compat_str(err))
+            self._downloader.report_error(u'unable to download video info JSON: %s' % compat_str(err))
-            self._downloader.trouble(u'ERROR: Justin.tv API: %s' % error_text)
+            self._downloader.report_error(u'Justin.tv API: %s' % error_text)
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to find video information')
+            self._downloader.report_error(u'unable to find video information')
-                self._downloader.trouble(u'ERROR: Cannot find video url for %s' % video_id)
+                self._downloader.report_error(u'Cannot find video url for %s' % video_id)
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-                self._downloader.trouble(u'ERROR: requested format not available')
+                self._downloader.report_error(u'requested format not available')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract video url')
+            self._downloader.report_error(u'unable to extract video url')
-            self._downloader.trouble(u'ERROR: unable to extract video title')
+            self._downloader.report_error(u'unable to extract video title')
-            self._downloader.trouble(u'ERROR: invalid URL: %s' % url)
+            self._downloader.report_error(u'invalid URL: %s' % url)
-            self._downloader.trouble(u'ERROR: unable to extract download url')
+            self._downloader.report_error(u'unable to extract download url')
-            self._downloader.trouble(u'ERROR: unable to extract title')
+            self._downloader.report_error(u'unable to extract title')
-            self.trouble(u'ERROR: unable to rename file')
+            self.report_error(u'unable to rename file')
-            self.trouble(u'ERROR: invalid system charset or erroneous output template')
+            self.report_error(u'invalid system charset or erroneous output template')
-            self.trouble(u'ERROR: unable to create directory ' + compat_str(err))
+            self.report_error(u'unable to create directory ' + compat_str(err))
-                self.trouble(u'ERROR: Cannot write description file ' + descfn)
+                self.report_error(u'Cannot write description file ' + descfn)
-                self.trouble(u'ERROR: Cannot write subtitles file ' + descfn)
+                self.report_error(u'Cannot write subtitles file ' + descfn)
-                self.trouble(u'ERROR: Cannot write metadata to JSON file ' + infofn)
+                self.report_error(u'Cannot write metadata to JSON file ' + infofn)
-                    self.trouble(u'ERROR: unable to download video data: %s' % str(err))
+                    self.report_error(u'unable to download video data: %s' % str(err))
-                    self.trouble(u'ERROR: content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))
+                    self.report_error(u'content too short (expected %s bytes and served %s)' % (err.expected, err.downloaded))
-                    self.trouble(u'ERROR: postprocessing: %s' % str(err))
+                    self.report_error(u'postprocessing: %s' % str(err))
-                        self.trouble(u'ERROR: ' + compat_str(e), tb=compat_str(traceback.format_exc()))
+                        self.report_error(u'' + compat_str(e), tb=compat_str(traceback.format_exc()))
-                        self.trouble(u'\nERROR: unable to download video')
+                        self.to_stderr(u"\n")
-                self.trouble(u'ERROR: no suitable InfoExtractor: %s' % url)
+                self.report_error(u'no suitable InfoExtractor: %s' % url)
-            self.trouble(u'ERROR: RTMP download detected but "rtmpdump" could not be run')
+            self.report_error(u'RTMP download detected but "rtmpdump" could not be run')
-            self.trouble(u'\nERROR: rtmpdump exited with code %d' % retval)
+            self.to_stderr(u"\n")
-            self.trouble(u'ERROR: giving up after %s retries' % retries)
+            self.report_error(u'giving up after %s retries' % retries)
-                    self.trouble(u'ERROR: unable to open for writing: %s' % str(err))
+                    self.report_error(u'unable to open for writing: %s' % str(err))
-                self.trouble(u'\nERROR: unable to write data: %s' % str(err))
+                self.to_stderr(u"\n")
-            self.trouble(u'\nERROR: Did not get any data blocks')
+            self.to_stderr(u"\n")
-            subprocess.call(['rtmpdump', '-h'], stdout=(file(os.path.devnull, 'w')), stderr=subprocess.STDOUT)
+            subprocess.call(['rtmpdump', '-h'], stdout=(open(os.path.devnull, 'w')), stderr=subprocess.STDOUT)
-            dest='ratelimit', metavar='LIMIT', help='download rate limit (e.g. 50k or 44.6m)')
+            dest='ratelimit', metavar='LIMIT', help='maximum download rate (e.g. 50k or 44.6m)')
-        if '/play/' in url:
+        urlp = compat_urllib_parse_urlparse(url)
-                        url = 'http://blip.tv/a/a-'+file_id
+            rurlp = compat_urllib_parse_urlparse(redirecturl)
-                self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % compat_str(err))
+                self._downloader.report_warning(u'parsing .netrc: %s' % compat_str(err))
-            self._downloader.to_stderr(u'WARNING: unable to set language: %s' % compat_str(err))
+            self._downloader.report_warning(u'unable to set language: %s' % compat_str(err))
-            self._downloader.to_stderr(u'WARNING: unable to fetch login page: %s' % compat_str(err))
+            self._downloader.report_warning(u'unable to fetch login page: %s' % compat_str(err))
-                self._downloader.to_stderr(u'WARNING: unable to log in: bad username or password')
+                self._downloader.report_warning(u'unable to log in: bad username or password')
-            self._downloader.to_stderr(u'WARNING: unable to log in: %s' % compat_str(err))
+            self._downloader.report_warning(u'unable to log in: %s' % compat_str(err))
-                    self._downloader.to_stderr(u'WARNING: ytsearch returns max %i results (you requested %i)' % (self._max_youtube_results, n))
+                    self._downloader.report_warning(u'ytsearch returns max %i results (you requested %i)' % (self._max_youtube_results, n))
-                    self._downloader.to_stderr(u'WARNING: gvsearch returns max %i results (you requested %i)' % (self._max_google_results, n))
+                    self._downloader.report_warning(u'gvsearch returns max %i results (you requested %i)' % (self._max_google_results, n))
-                    self._downloader.to_stderr(u'WARNING: yvsearch returns max %i results (you requested %i)' % (self._max_yahoo_results, n))
+                    self._downloader.report_warning(u'yvsearch returns max %i results (you requested %i)' % (self._max_yahoo_results, n))
-                self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % compat_str(err))
+                self._downloader.report_warning(u'parsing .netrc: %s' % compat_str(err))
-                self._downloader.to_stderr(u'WARNING: unable to log in: bad username/password, or exceded login rate limit (~3/min). Check credentials or wait.')
+                self._downloader.report_warning(u'unable to log in: bad username/password, or exceded login rate limit (~3/min). Check credentials or wait.')
-            self._downloader.to_stderr(u'WARNING: unable to log in: %s' % compat_str(err))
+            self._downloader.report_warning(u'unable to log in: %s' % compat_str(err))
-            self._downloader.to_stderr(u'WARNING: unable to extract video date')
+            self._downloader.report_warning(u'unable to extract video date')
-            self._downloader.to_stderr(u'WARNING: unable to extract uploader')
+            self._downloader.report_warning(u'unable to extract uploader')
-            self.to_stderr(u'WARNING: %(stitle)s is deprecated. Use the %(title)s and the --restrict-filenames flag(which also secures %(uploader)s et al) instead.')
+            self.report_warning(u'%(stitle)s is deprecated. Use the %(title)s and the --restrict-filenames flag(which also secures %(uploader)s et al) instead.')
-                                   u'and will probably not work. If you want to go on, use the -i option.')
+                    self.report_warning(u'the program functionality for this site has been marked as broken, '
-                self.to_stderr(u'WARNING: Unable to remove downloaded video file')
+                self.report_warning(u'Unable to remove downloaded video file')
-                                   u'and will probably not work. If you want to go on, use the -i option.')
+            videos = self.extract_info(url)
-                # Extract information from URL and process it
+            for video in videos or []:
-                self.trouble(u'ERROR: no suitable InfoExtractor: %s' % url)
+                    self.increment_downloads()
-
+        videos = [v[1] for v in sorted(videos)]
-            [ 'bV9L5Ht9LgY', 'FXxLjLQi3Fg', 'tU3Bgo5qJZE' ])
+        ytie_results = [YoutubeIE()._extract_id(r[0]) for r in dl.result]
-        #661
+    def test_issue_661(self):
-        #673
+    def test_issue_673(self):
-        self.assertFalse('KdPEApIVdWM' in map(lambda x: YoutubeIE()._extract_id(x[0]), dl.result))
+        ytie_results = [YoutubeIE()._extract_id(r[0]) for r in dl.result]
-        self.assertEqual(map(lambda x: YoutubeIE()._extract_id(x[0]), DL.result),
+        dl = FakeDownloader()
-        self.assertTrue(len(DL.result) > 20)
+        dl = FakeDownloader()
-        self.assertTrue(len(DL.result) > 40)
+        dl = FakeDownloader()
-        self.assertTrue(len(DL.result) >= 799)
+        dl = FakeDownloader()
-        self.assertFalse('KdPEApIVdWM' in map(lambda x: YoutubeIE()._extract_id(x[0]), DL.result))
+        dl = FakeDownloader()
-        IE = YoutubePlaylistIE(DL)
+        dl = FakeDownloader()
-        self.assertEqual(YoutubeIE()._extract_id(DL.result[-1][0]), 'rYefUsYuEp0')
+        ie.extract('https://www.youtube.com/course?list=ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8')
-        self.assertTrue(len(DL.result) >= 320)
+        dl = FakeDownloader()
-        self.assertFalse(YoutubePlaylistIE().suitable(u'PLtS2H6bU1M'))
+        self.assertTrue(YoutubePlaylistIE.suitable(u'ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8'))
-        self.assertTrue(YoutubeIE().suitable(u'PLtS2H6bU1M'))
+        self.assertTrue(YoutubeIE.suitable(u'PLtS2H6bU1M'))
-    def suitable(self, url):
+    @classmethod
-        return re.match(self._VALID_URL, url) is not None
+        return re.match(cls._VALID_URL, url) is not None
-    def working(self):
+    @classmethod
-        return self._WORKING
+        return cls._WORKING
-    def suitable(self, url):
+    @classmethod
-        return re.match(self._VALID_URL, url, re.VERBOSE) is not None
+        if YoutubePlaylistIE.suitable(url): return False
-                           \? .*? (p|a|list)=
+                           (?:course|view_play_list|my_playlists|artist|playlist|watch)
-                     .*"""
+                        ((?:PL|EC|UU)?[0-9A-Za-z-_]{10,})
-    def suitable(self, url):
+    @classmethod
-        return re.match(self._VALID_URL, url, re.VERBOSE) is not None
+        return re.match(cls._VALID_URL, url, re.VERBOSE) is not None
-        playlist_id = mobj.group(2)
+        playlist_id = mobj.group(1) or mobj.group(2)
-            videos += [(entry['yt$position']['$t'], entry['content']['src']) for entry in response['feed']['entry']]
+            if not 'feed' in response or not 'entry' in response['feed']:
-    def suitable(self, url):
+    @classmethod
-        return re.match(self._VALID_URL, url, re.VERBOSE) is not None
+        return re.match(cls._VALID_URL, url, re.VERBOSE) is not None
-    def suitable(self, url):
+    @classmethod
-        return re.match(self._VALID_URL, url, re.VERBOSE) is not None
+        return re.match(cls._VALID_URL, url, re.VERBOSE) is not None
-    def suitable(self, url):
+    @classmethod
-        return re.match(self._VALID_URL, url, re.VERBOSE) is not None
+        return re.match(cls._VALID_URL, url, re.VERBOSE) is not None
-from youtube_dl.InfoExtractors import YoutubeUserIE,YoutubePlaylistIE
+from youtube_dl.InfoExtractors import YoutubeUserIE, YoutubePlaylistIE, YoutubeIE
-        ])
+        self.assertEqual(map(lambda x: YoutubeIE()._extract_id(x[0]), DL.result),
-        self.assertEqual(DL.result[0], ['http://www.youtube.com/watch?v=j9WZyLZCBzs'])
+        self.assertEqual(YoutubeIE()._extract_id(DL.result[0][0]), 'j9WZyLZCBzs')
-        self.assertEqual(DL.result[-1], ['http://www.youtube.com/watch?v=rYefUsYuEp0'])
+        self.assertEqual(YoutubeIE()._extract_id(DL.result[-1][0]), 'rYefUsYuEp0')
-    _MORE_PAGES_INDICATOR = u"Next \N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}"
+    _VALID_URL = r"""(?:
-        mobj = re.match(self._VALID_URL, url)
+        mobj = re.match(self._VALID_URL, url, re.VERBOSE)
-            playlist_access = 'view_play_list'
+        # Download playlist videos from API
-        pagenum = 1
+        page_num = 1
-            request = compat_urllib_request.Request(url)
+            self.report_download_page(playlist_id, page_num)
-                page = compat_urllib_request.urlopen(request).read().decode('utf-8')
+                page = compat_urllib_request.urlopen(url).read().decode('utf8')
-            video_ids.extend(ids_in_page)
+            try:
-            if self._MORE_PAGES_INDICATOR not in page:
+            videos += [(entry['yt$position']['$t'], entry['content']['src']) for entry in response['feed']['entry']]
-            pagenum = pagenum + 1
+            page_num += 1
-        total = len(video_ids)
+        videos = map(operator.itemgetter(1), sorted(videos))
-            video_ids = video_ids[playliststart:]
+            videos = videos[playliststart:]
-            video_ids = video_ids[playliststart:playlistend]
+            videos = videos[playliststart:playlistend]
-        if len(video_ids) == total:
+        if len(videos) == total:
-            self._downloader.to_screen(u'[youtube] PL %s: Found %i videos, downloading %i' % (playlist_id, total, len(video_ids)))
+            self._downloader.to_screen(u'[youtube] PL %s: Found %i videos, downloading %i' % (playlist_id, total, len(videos)))
-            self._downloader.download(['http://www.youtube.com/watch?v=%s' % id])
+        for video in videos:
-        
+
-    _VALID_URL = r"""http://store.steampowered.com/ 
+    _VALID_URL = r"""http://store.steampowered.com/
-   
+
-        self._downloader.to_screen(u'[youporn] Links found: %d' % len(links))   
+
-        
+
-    
+
-    
+
-        
+
-        
+
-__version__ = '2013.02.22'
+__version__ = '2013.02.25'
-    print_notes(version_info['versions'])
+    print_notes(versions_info['versions'])
-
+            url = page_base + "&page=" + str(pagenum)
-__version__ = '2012.02.22'
+__version__ = '2013.02.22'
-                self.to_stderr(u'Deleting original file %s (pass -k to keep)' % filename)
+                self.to_screen(u'Deleting original file %s (pass -k to keep)' % filename)
-                data = compat_urllib_request.urlopen(request).read()
+                data = compat_urllib_request.urlopen(request).read().decode('utf-8')
-        video_name_RE=r'<p\ class="talk-title"><a href="/talks/(.+).html">(?P<fullname>.+?)</a></p>'
+        video_name_RE=r'<p\ class="talk-title"><a href="(?P<talk_url>/talks/(.+).html)">(?P<fullname>.+?)</a></p>'
-            info.append(video_dic)
+            video_id=m_video.group('video_id')
-        title_RE=r'<h1><span id="altHeadline" >(?P<title>[\s\w:/\.\?=\+-\\\']*)</span></h1>'
+        title_RE=r'<h1><span id="altHeadline" >(?P<title>.*)</span></h1>'
-                'title': title
+                'title': title,
-        for vid,vtitle in zip(mweb,titles):
+        for vid,vtitle,thumb in zip(mweb,titles,thumbs):
-                'title': unescapeHTML(title)
+                'title': unescapeHTML(title),
-__version__ = '2013.02.19'
+__version__ = '2012.02.22'
-            to_screen(note)
+
-            return (u'WARNING: no closed captions found in the specified language', None)
+            return (u'WARNING: no closed captions found in the specified language "%s"' % srt_lang, None)
-        self.assertEqual(md5(info_dict[0]['subtitles']), 'c3228550d59116f3c29fba370b55d033')
+        self.assertEqual(md5(info_dict[0]['subtitles']), '4cd9278a35ba2305f47354ee13472260')
-        self.assertEqual(md5(info_dict[0]['subtitles']), '132a88a0daf8e1520f393eb58f1f646a')
+        self.assertEqual(md5(info_dict[0]['subtitles']), '164a51f16f260476a05b50fe4c2f161d')
-
+            'fmt': 'srt',
-            srt_xml = compat_urllib_request.urlopen(url).read().decode('utf-8')
+            srt = compat_urllib_request.urlopen(url).read().decode('utf-8')
-        if not srt_xml:
+        if not srt:
-        return (None, self._closed_captions_xml_to_srt(srt_xml))
+        return (None, srt)
-            rejecttitle = rejecttitle.decode('utf8')
+
-        'rejecttitle': opts.rejecttitle,
+        'matchtitle': decodeOption(opts.matchtitle),
-                        compat_urllib_error.HTTPErrorProcessor, compat_urllib_request.HTTPSHandler]:
+                        compat_urllib_request.HTTPErrorProcessor, compat_urllib_request.HTTPSHandler]:
-__version__ = '2013.02.18'
+__version__ = '2013.02.19'
-__version__ = '2013.02.02'
+__version__ = '2013.02.18'
-        result = re.search(r'videoTitleArea">(?P<title>.*)</h1>', webpage)
+        result = re.search(r'<h1.*?>(?P<title>.*)</h1>', webpage)
-            raise ExtractorError(u'ERROR: unable to extract video title')
+            raise ExtractorError(u'Unable to extract video title')
-        result = re.search(r'Date:</b>(?P<date>.*)</li>', webpage)
+        result = re.search(r'Date:</label>(?P<date>.*) </li>', webpage)
-        result = re.search(r'Submitted:</b>(?P<uploader>.*)</li>', webpage)
+        result = re.search(r'Submitted:</label>(?P<uploader>.*)</li>', webpage)
-            self._downloader.to_stderr(u'ERROR: unable to extract uploader')
+            self._downloader.to_stderr(u'WARNING: unable to extract uploader')
-        mobj = re.search(r'<link rel=\'image_src\' href=\'(http://is[0-9].myvideo\.de/de/movie[0-9]+/[a-f0-9]+)/thumbs/[^.]+\.jpg\' />',
+        mobj = re.search(r'<link rel=\'image_src\' href=\'(http://is[0-9].myvideo\.de/de/movie[0-9]+/[a-f0-9]+)/thumbs/.*?\.jpg\' />',
-    _VALID_URL=r'http://www.ted.com/talks/(?P<videoName>\w+)'
+    _VALID_URL=r'''http://www.ted.com/
-        #If the url includes the language we get the title translated
+        m=re.match(self._VALID_URL, url, re.VERBOSE)
-        video_url='http://download.ted.com/talks/%s.mp4' % mediaSlug
+        video_url=self._talk_video_link(mediaSlug)
-                'url':video_url,
+                'id': video_id,
-        return [info]
+                }
-        m = re.search(r"new TRAX.Mix\((.*?)\);\n*\s*TRAX.initSearchAutocomplete\('#search'\);", webpage, flags=re.DOTALL)
+        m = re.search(r"PAGE.mix = (.*?);\n", webpage, flags=re.DOTALL)
-        if self.params.get('newline', True):
+        if self.params.get('progress_with_newline', False):
-        else: self.to_screen(u'\r[download] %s of %s at %s ETA %s' %
+        else:
-            action='store_true', dest='newline', help='output progress bar as new lines', default=False)
+            action='store_true', dest='progress_with_newline', help='output progress bar as new lines', default=False)
-        title_RE=r'<h1><span id="altHeadline" >(?P<title>[\s\w:/\.\?=\+-]*)</span></h1>'
+        title_RE=r'<h1><span id="altHeadline" >(?P<title>[\s\w:/\.\?=\+-\\\']*)</span></h1>'
-            action='store_true', dest='newline', help='Output progress bar as new lines', default=False)
+            action='store_true', dest='newline', help='output progress bar as new lines', default=False)
-            self.to_screen(u'\r[download] %s of %s at %s ETA %s' %
+            self.to_screen(u'[download] %s of %s at %s ETA %s' %
-        self.to_screen(u'\r[download] %s of %s at %s ETA %s' %
+        if self.params.get('newline', True):
-            sys.stderr.write('\033]0;%s\007' % message.encode(preferredencoding()))
+            self.to_screen('\033]0;%s\007' % message, skip_eol=True)
-        title = m.group('title')
+        title = unescapeHTML(m.group('title'))
-        uploader = m.group('uploader')
+        uploader = unescapeHTML(m.group('uploader'))
-                  }
+        }
-    _LOGIN_URL = 'https://www.youtube.com/signup?next=/&gl=US&hl=en'
+    _LOGIN_URL = 'https://accounts.google.com/ServiceLogin'
-        request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
+        login_form_strs = {
-            if re.search(r'(?i)<form[^>]* name="loginForm"', login_results) is not None:
+            if re.search(r'(?i)<form[^>]* id="gaia_loginform"', login_results) is not None:
-    _VALID_URL = r'(?:https?://)?(?:(?:www|player).)?vimeo\.com/(?:(?:groups|album)/[^/]+/)?(?:videos?/)?([0-9]+)'
+    _VALID_URL = r'(?P<proto>https?://)?(?:(?:www|player)\.)?vimeo\.com/(?:(?:groups|album)/[^/]+/)?(?P<direct_link>play_redirect_hls\?clip_id=)?(?:videos?/)?(?P<id>[0-9]+)'
-        video_id = mobj.group(1)
+        video_id = mobj.group('id')
-        request = compat_urllib_request.Request('http://www.youtube.com/api/timedtext?lang=%s&name=%s&v=%s' % (srt_lang, srt_lang_list[srt_lang], video_id))
+        params = compat_urllib_parse.urlencode({
-            srt_xml = compat_urllib_request.urlopen(request).read().decode('utf-8')
+            srt_xml = compat_urllib_request.urlopen(url).read().decode('utf-8')
-            return (u'WARNING: unable to download video subtitles', None)
+            return (u'WARNING: Did not fetch video subtitles', None)
-    selection.add_option('--max-filesize', metavar='SIZE', dest='max_filesize', help="Skip files larger than this size", default=None)
+    selection.add_option('--min-filesize', metavar='SIZE', dest='min_filesize', help="Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)", default=None)
-__version__ = '2013.02.01'
+__version__ = '2013.02.02'
-            if os.path.isfile(opts.cookiefile) and os.access(opts.cookiefile, os.R_OK):
+            if os.access(opts.cookiefile, os.R_OK):
-            sys.exit(u'ERROR: unable to open cookie file')
+            if opts.verbose:
-            if self._preferredcodec == 'm4a' and filecodec == 'aac':
+            if filecodec == 'aac' and self._preferredcodec in ['m4a', 'best']:
-                extension = self._preferredcodec
+                extension = 'm4a'
-__version__ = '2013.01.28'
+__version__ = '2013.02.01'
-        video_duration = int(data['video_duration'])
+        params_raw = compat_urllib_parse.unquote(data['params'])
-            'thumbnail': data['thumbnail_src'],
+            'thumbnail': params['thumbnail_src'],
-                    self.assertTrue(os.path.exists(tc['file']))
+                    self.assertTrue(os.path.exists(tc['file']), msg='Missing file ' + tc['file'])
-from distutils.core import setup
+    from setuptools import setup
-__version__ = '2013.01.27'
+__version__ = '2013.01.28'
-            return
+            raise ExtractorError(u'Invalid URL: %s' % url)
-                return
+            coursepage = self._download_webpage(url, info['id'],
-    _VALID_URL = r'https?://8tracks.com/(?P<user>[^/]+)/(?P<id>[^/]+)'
+    _VALID_URL = r'https?://8tracks.com/(?P<user>[^/]+)/(?P<id>[^/#]+)(?:#.*)?$'
-                'uploader': track_data['performer'],
+                'title': track_data['performer'] + u' - ' + track_data['name'],
-__version__ = '2013.01.13'
+__version__ = '2013.01.27'
-
+class EightTracksIE(InfoExtractor):
-        return video_info
+        self._downloader.to_screen(u'[%s] Logging in' % self.IE_NAME)
-        video_description = video_info.get('description', 'No description available.')
+        url = 'https://www.facebook.com/video/video.php?v=%s' % video_id
-            format_limit = self._downloader.params.get('format_limit', None)
+        BEFORE = '[["allowFullScreen","true"],["allowScriptAccess","always"],["salign","tl"],["scale","noscale"],["wmode","opaque"]].forEach(function(param) {swf.addParam(param[0], param[1]);});\n'
-                video_url_list = [(req_format, url_map[req_format])] # Specific format
+        m = re.search('<h2 class="uiHeaderTitle">([^<]+)</h2>', webpage)
-            video_extension = self._video_extensions.get(format_param, 'mp4')
+        info = {
-                        self.assertEqual(value, info_dict.get(info_field))
+                    self.assertEqual(value, info_dict.get(info_field))
-        return s.encode(sys.getfilesystemencoding(), 'ignore')
+        encoding = sys.getfilesystemencoding()
-                    'id': clip['id'],
+                    'id': video_id,
-                    'title': clip['title'],
+                    'title': video_title,
-__version__ = '2013.01.12'
+__version__ = '2013.01.13'
-
+    # Update version
-            self.to_screen(u'\r[rtmpdump] %s bytes' % os.path.getsize(encodeFilename(tmpfilename)))
+            fsize = os.path.getsize(encodeFilename(tmpfilename))
-                'thumbnail': data.get('image').get('large_url_2x'),
+                'thumbnail': data.get('image', {}).get('large_url_2x'),
-        for h in std_headers:
+        for h,v in std_headers.items():
-            req.add_header(h, std_headers[h])
+            req.add_header(h, v)
-            req.headers['User-Agent'] = req.headers['Youtubedl-user-agent']
+            if 'User-agent' in req.headers:
-#!/usr/bin/env python
+#!/usr/bin/env python3
-#!/usr/bin/env python3
+#!/usr/bin/env python
-privkey = ''
+privkey = b''
-privkey = bytes(privkey, 'ascii')
+	privkey += line.encode('ascii') + b'\n'
-__version__ = '2013.01.11'
+__version__ = '2013.01.12'
-    upload_date:    Video upload date (YYYYMMDD).
+    uploader:       Full name of the video uploader.
-            return
+            raise ExtractorError(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
-                    'player_url': data['embedUrl']
+                    'player_url': data['embedUrl'],
-        std_headers['User-Agent'] = 'iTunes/10.6.1'
+        if 'Youtubedl-user-agent' in req.headers:
-        result = re.search(VIDEO_TITLE_RE, webpage)
+        result = re.search(r'<title>(?P<title>.*)</title>', webpage)
-            return
+            raise ExtractorError(u'ERROR: unable to extract video title')
-        result = re.search(EMBED_PAGE_RE, webpage)
+        result = re.search(r'https?://www.youjizz.com/videos/embed/(?P<videoid>[0-9]+)', webpage)
-            return
+            raise ExtractorError(u'ERROR: unable to extract embed page')
-        result = re.search(SOURCE_RE, webpage)
+        result = re.search(r'so.addVariable\("file",encodeURIComponent\("(?P<source>[^"]+)"\)\);', webpage)
-            return
+            raise ExtractorError(u'ERROR: unable to extract video url')
-        webpage = self._download_webpage(url, video_id)
+        req = compat_urllib_request.Request(url)
-        result = re.search(VIDEO_TITLE_RE, webpage)
+        result = re.search(r'videoTitleArea">(?P<title>.*)</h1>', webpage)
-            return
+            raise ExtractorError(u'ERROR: unable to extract video title')
-        result = re.search(VIDEO_DATE_RE, webpage)
+        result = re.search(r'Date:</b>(?P<date>.*)</li>', webpage)
-        upload_date = result.group('date').strip()
+            self._downloader.to_stderr(u'WARNING: unable to extract video date')
-        result = re.search(VIDEO_UPLOADER_RE, webpage)
+        result = re.search(r'Submitted:</b>(?P<uploader>.*)</li>', webpage)
-        video_uploader = clean_html( video_uploader )
+            self._downloader.to_stderr(u'ERROR: unable to extract uploader')
-            return
+            raise ExtractorError(u'Unable to extract download list')
-            return
+            raise ExtractorError(u'ERROR: no known formats available for video')
-    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None):
+    def _request_webpage(self, url_or_request, video_id, note=None, errnote=None):
-            return webpage_bytes.decode('utf-8', 'replace')
+            return compat_urllib_request.urlopen(url_or_request)
-        print('Available formats:')
+        print(u'Available formats:')
-                'player_url': None}
+                'format': 'flv'}
-        if not keep_video and not self.params.get('keepvideo', False):
+        if keep_video is False and not self.params.get('keepvideo', False):
-        """Run the postprocessing chain on the given file."""
+        """Run all the postprocessors on the given file."""
-                break
+            try:
-        changing some fields.
+        This method returns a tuple, the first element of which describes
-        it was called from.
+        exception if post processing fails.
-        return information # by default, do nothing
+        return None, information # by default, keep file and do nothing
-        self.message = message
+class FFmpegPostProcessorError(PostProcessingError):
-        self.message = message
+class AudioConversionError(PostProcessingError):
-            raise FFmpegPostProcessorError('ffmpeg or avconv not found. Please install one.')
+            raise FFmpegPostProcessorError(u'ffmpeg or avconv not found. Please install one.')
-            raise FFmpegPostProcessorError(msg)
+            raise FFmpegPostProcessorError(msg.decode('utf-8', 'replace'))
-    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, keepvideo=False, nopostoverwrites=False):
+    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, nopostoverwrites=False):
-            return None
+            raise PostProcessingError(u'WARNING: unable to obtain file audio codec with ffprobe')
-                self._downloader.to_stderr(u'ERROR: audio conversion failed: ' + e.message)
+                msg = u'audio conversion failed: ' + e.message
-            return None
+                msg = u'error running ' + (self._exes['avconv'] and 'avconv' or 'ffmpeg')
-        return information
+        return False,information
-        FFmpegPostProcessor.__init__(self,downloader)
+        super(FFmpegVideoConvertor, self).__init__(downloader)
-        self._downloader.to_screen(u'['+'ffmpeg'+'] Converting video from %s to %s, Destination: ' % (information['format'], self._preferedformat) +outpath)
+        if information['ext'] == self._preferedformat:
-        return information
+        information['ext'] = self._preferedformat
-
+    postproc.add_option('--recode-video', metavar='FORMAT', dest='recodevideo', default=None,
-        fd.add_post_processor(FFmpegExtractAudioPP(preferredcodec=opts.audioformat, preferredquality=opts.audioquality, keepvideo=opts.keepvideo, nopostoverwrites=opts.nopostoverwrites))
+        fd.add_post_processor(FFmpegExtractAudioPP(preferredcodec=opts.audioformat, preferredquality=opts.audioquality, nopostoverwrites=opts.nopostoverwrites))
-    pass
+    def __init__(self, msg):
-        
+
-    _VALID_URL = r'http://www.ustream.tv/recorded/(?P<videoID>\d+)'
+    _VALID_URL = r'https?://www\.ustream\.tv/recorded/(?P<videoID>\d+)'
-    
+
-
+class FFmpegPostProcessorError(BaseException):
-    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, keepvideo=False, nopostoverwrites=False):
+class FFmpegPostProcessor(PostProcessor):
-        self._nopostoverwrites = nopostoverwrites
+    def run_ffmpeg(self, path, out_path, opts):
-            raise AudioConversionError(msg)
+        opts = ['-vn'] + acodec_opts + more_opts
-        return fn
+class FFmpegVideoConvertor(FFmpegPostProcessor):
-__version__ = '2013.01.08'
+__version__ = '2013.01.11'
-            elif filecodec in ['aac', 'mp3', 'vorbis']:
+            elif filecodec in ['aac', 'mp3', 'vorbis', 'opus']:
-            acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'vorbis': 'libvorbis', 'wav': None}[self._preferredcodec]
+            acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'opus': 'opus', 'vorbis': 'libvorbis', 'wav': None}[self._preferredcodec]
-            help='"best", "aac", "vorbis", "mp3", "m4a", or "wav"; best by default')
+            help='"best", "aac", "vorbis", "mp3", "m4a", "opus", or "wav"; best by default')
-        if opts.audioformat not in ['best', 'aac', 'mp3', 'vorbis', 'm4a', 'wav']:
+        if opts.audioformat not in ['best', 'aac', 'mp3', 'm4a', 'opus', 'vorbis', 'wav']:
-            cmd = [self._exes['avprobe'] or self._exes['ffprobe'], '-show_streams', '--', encodeFilename(path)]
+            cmd = [self._exes['avprobe'] or self._exes['ffprobe'], '-show_streams', encodeFilename(self._ffmpeg_filename_argument(path))]
-               ['--', encodeFilename(out_path)])
+               [encodeFilename(self._ffmpeg_filename_argument(out_path))])
-__version__ = '2013.01.06'
+__version__ = '2013.01.08'
-                video_date = re.sub('-', '', clip['created_on'][:10])
+                video_date = re.sub('-', '', clip['start_time'][:10])
-                    'uploader': clip.get('user_id', clip.get('channel_id')),
+                    'uploader': clip.get('channel_name', video_uploader_id),
-            api += '/clip/show/%s.json'
+            api += '/broadcast/by_archive/%s.json'
-__version__ = '2013.01.02'
+__version__ = '2013.01.06'
-        YouPornIE(),       # jefftimesten
+        YouJizzIE(),
-
+   
-        self._downloader.to_screen(u'[youporn] Video ID: %s' % video_id)
+    # def report_id(self, video_id):
-        self._downloader.to_screen(u'[youporn] Downloaded page: %s' % url)
+    # def report_webpage(self, url):
-        self._downloader.to_screen(u'[youporn] Title: %s' % video_title)
+    # def report_title(self, video_title):
-        self._downloader.to_screen(u'[youporn] Uploader: %s' % uploader)
+    # def report_uploader(self, uploader):
-        self._downloader.to_screen(u'[youporn] Date: %s' % video_date)
+    # def report_upload_date(self, video_date):
-        print u'---------------------------------'
+        print('Available formats:')
-            print u'%s\t\t%s'  % (format['ext'], format['format'])
+            print(u'%s\t\t%s'  % (format['ext'], format['format']))
-        self.report_id(video_id)
+        video_id = mobj.group('videoid')
-        self.report_webpage(url)
+        webpage = self._download_webpage(url, video_id)
-        result = re.search(self.VIDEO_TITLE_RE, webpage)
+        VIDEO_TITLE_RE = r'videoTitleArea">(?P<title>.*)</h1>'
-        self.report_title(video_title)
+        video_title = result.group('title').strip()
-        result = re.search(self.VIDEO_DATE_RE, webpage)
+        VIDEO_DATE_RE = r'Date:</b>(?P<date>.*)</li>'
-        self.report_upload_date(upload_date)
+        upload_date = result.group('date').strip()
-        result = re.search(self.VIDEO_UPLOADER_RE, webpage)
+        VIDEO_UPLOADER_RE = r'Submitted:</b>(?P<uploader>.*)</li>'
-        video_uploader = result.group('uploader').decode('utf-8').strip()
+        video_uploader = result.group('uploader').strip()
-        self.report_uploader(video_uploader)
+        #self.report_uploader(video_uploader)
-        result = re.search(self.DOWNLOAD_LIST_RE, webpage)
+        DOWNLOAD_LIST_RE = r'(?s)<ul class="downloadList">(?P<download_list>.*?)</ul>'
-        download_list_html = result.group('download_list').decode('utf-8').strip()
+        download_list_html = result.group('download_list').strip()
-        links = re.findall(self.LINK_RE, download_list_html)
+        LINK_RE = r'(?s)<a href="(?P<url>[^"]+)">'
-            path = urlparse( video_url ).path
+            video_url = unescapeHTML( link )
-    VIDEO_UPLOADED_RE = r'<div class="video_added_by">Added (?P<date>[0-9\/]+) by'
+    # def __init__(self, downloader=None):
-        self._downloader.to_screen(u'[pornotube] Downloading entry: %s' % url.decode('utf-8'))
+    # def report_extract_entry(self, url):
-        self._downloader.to_screen(u'[pornotube] Entry date: %s' % upload_date)
+    # def report_date(self, upload_date):
-        self._downloader.to_screen(u'[pornotube] Downloaded page: %s' % url)
+    # def report_webpage(self, url):
-        self._downloader.to_screen(u'[pornotube] Title: %s' % video_title.decode('utf-8'))
+    # def report_title(self, video_title):
-        self.report_title(video_title);
+        video_id = mobj.group('videoid')
-        self.report_webpage(url)
+        webpage = self._download_webpage(url, video_id)
-        result = re.search(self.VIDEO_URL_RE, webpage)
+        VIDEO_URL_RE = r'url: "(?P<url>http://video[0-9].pornotube.com/.+\.flv)",'
-        self.report_extract_entry(video_url)
+        video_url = compat_urllib_parse.unquote(result.group('url'))
-        result = re.search(self.VIDEO_UPLOADED_RE, webpage)
+        VIDEO_UPLOADED_RE = r'<div class="video_added_by">Added (?P<date>[0-9\/]+) by'
-
+        upload_date = result.group('date')
-    SOURCE_RE = r'so.addVariable\("file",encodeURIComponent\("(?P<source>[^"]+)"\)\);'
+    _VALID_URL = r'^(?:https?://)?(?:\w+\.)?youjizz\.com/videos/(?P<videoid>[^.]+).html$'
-        self._downloader.to_screen(u'[youjizz] Downloading entry: %s' % url.decode('utf-8'))
+    # def report_extract_entry(self, url):
-        self._downloader.to_screen(u'[youjizz] Downloaded page: %s' % url)
+    # def report_webpage(self, url):
-        self._downloader.to_screen(u'[youjizz] Title: %s' % video_title.decode('utf-8'))
+    # def report_title(self, video_title):
-        self._downloader.to_screen(u'[youjizz] Embed Page: %s' % embed_page.decode('utf-8'))
+    # def report_embed_page(self, embed_page):
-            self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % err)
+        mobj = re.match(self._VALID_URL, url)
-        self.report_webpage(url)
+
-        result = re.search(self.VIDEO_TITLE_RE, webpage)
+        VIDEO_TITLE_RE = r'<title>(?P<title>.*)</title>'
-        self.report_title(video_title)
+        video_title = result.group('title').strip()
-        result = re.search(self.EMBED_PAGE_RE, webpage)
+        EMBED_PAGE_RE = r'http://www.youjizz.com/videos/embed/(?P<videoid>[0-9]+)'
-        self.report_embed_page(embed_page_url)
+        embed_page_url = result.group(0).strip()
-        
+        webpage = self._download_webpage(embed_page_url, video_id)
-        result = re.search(self.SOURCE_RE, webpage)
+        SOURCE_RE = r'so.addVariable\("file",encodeURIComponent\("(?P<source>[^"]+)"\)\);'
-        self.report_extract_entry(video_url)
+        video_url = result.group('source')
-        YouPornIE(),
+        YouJizzIE(),       # jefftimesten
-        mMovieParams = re.findall('(?:<param name="movie" value="|var url = ")(http://media.mtvnservices.com/([^"]*(?:episode|video).*?:.*?))"', html)
+        mMovieParams = re.findall('(?:<param name="movie" value="|var url = ")(http://media.mtvnservices.com/([^"]*(?:episode|video).*?:.*?))"', webpage)
-            altMovieParams = re.findall('data-mgid="([^"]*(?:episode|video).*?:.*?)"', html)
+            altMovieParams = re.findall('data-mgid="([^"]*(?:episode|video).*?:.*?)"', webpage)
-        for itemEl in itemEls:
+        for partNum,itemEl in enumerate(itemEls):
-            effTitle = showId + u'-' + epTitle
+            effTitle = showId + u'-' + epTitle + u' part ' + compat_str(partNum+1)
-        self._downloader.to_screen(u'[comedycentral] %s: Downloading configuration' % episode_id)
+    def report_config_download(self, episode_id, media_id):
-            self.report_config_download(epTitle)
+            self.report_config_download(epTitle, shortMediaId)
-            format,video_url = turls[-1]
+            format,rtmp_video_url = turls[-1]
-                    format, video_url = f, v
+                    format, rtmp_video_url = f, v
-                video_url = video_url.replace(broken_cdn, better_cdn)
+            m = re.match(r'^rtmpe?://.*?/(?P<finalid>gsp.comedystor/.*)$', rtmp_video_url)
-    _VALID_URL = r'^http://video\.xnxx\.com/video([0-9]+)/(.*)'
+    _VALID_URL = r'^(?:https?://)?video\.xnxx\.com/video([0-9]+)/(.*)'
-        titles = list(re.finditer(namesRE, webpage))
+        namesRE = r'<span class="title">(?P<videoName>.+?)</span>'
-                'title': unescaper.unescape(title)
+                'title': unescapeHTML(title)
-        namesRE = r'<span class=\"title\">(?P<videoName>[\w:/\.\?=\+\s-]+)</span>'
+        namesRE = r'<span class="title">(?P<videoName>.+)</span>'
-                'title': title
+                'title': unescaper.unescape(title)
-    def _download_with_rtmpdump(self, filename, url, player_url):
+    def _download_with_rtmpdump(self, filename, url, player_url, page_url):
-        basic_args = ['rtmpdump', '-q'] + [[], ['-W', player_url]][player_url is not None] + ['-r', url, '-o', tmpfilename]
+        basic_args = ['rtmpdump', '-q', '-r', url, '-o', tmpfilename]
-            return self._download_with_rtmpdump(filename, url, player_url)
+            return self._download_with_rtmpdump(filename, url,
-                tb = u''.join(traceback.format_list(traceback.extract_stack()))
+                tb_data = traceback.format_list(traceback.extract_stack())
-                    self.trouble(u'ERROR: ' + compat_str(de), compat_str(u''.join(traceback.format_tb(de.traceback))))
+                    self.trouble(u'ERROR: ' + compat_str(de), de.format_traceback())
-            raise ExtractorError(u'%s: %s' % (errnote, compat_str(err)))
+            raise ExtractorError(u'%s: %s' % (errnote, compat_str(err)), sys.exc_info()[2])
-        """ tb is the original traceback (so that it can be printed out) """
+        """ tb, if given, is the original traceback (so that it can be printed out). """
-            tb = sys.exc_info()[2]
+    def format_traceback(self):
-__version__ = '2012.12.11'
+__version__ = '2013.01.02'
-URL = 'https://github.com/downloads/rg3/youtube-dl/youtube-dl'
+versions_info = json.load(open('update/versions.json'))
-    version = subprocess.check_output(['python3', ytdl_file.name, '--version']).decode('ascii').strip()
+data = urllib.request.urlopen(URL).read()
-#! /usr/bin/env python3
+#!/usr/bin/env python3
-        mobj = re.search(r'<link itemprop="url" href="http://www.youtube.com/user/([^"]+)">', video_webpage)
+        mobj = re.search(r'<link itemprop="url" href="http://www.youtube.com/(?:user|channel)/([^"]+)">', video_webpage)
-    def _download_webpage(self, url, video_id, note=None, errnote=None):
+    def _download_webpage(self, url_or_request, video_id, note=None, errnote=None):
-            urlh = compat_urllib_request.urlopen(url)
+            urlh = compat_urllib_request.urlopen(url_or_request)
-            return
+        webpage = self._download_webpage(request, video_id)
-    IE_NAME = u'infoq'
+import base64
-
+        webpage = self._download_webpage(url, video_id=url)
-
+        real_id = compat_urllib_parse.unquote(base64.b64decode(mobj.group(1).encode('ascii')).decode('utf-8'))
-        video_title = mobj.group(1).decode('utf-8')
+        video_title = mobj.group(1)
-            video_description = mobj.group(1).decode('utf-8')
+            video_description = mobj.group(1)
-                self.assertTrue(os.path.exists(tc['file']))
+                if not test_case.get('params', {}).get('skip_download', False):
-            return
+        webpage_url = 'http://www.myvideo.de/watch/%s' % video_id
-            return
+        webpage = self._download_webpage(url, video_id)
-            self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+            self._downloader.trouble(u'ERROR: unable to download stream definitions: %s' % compat_str(err))
-            return
+        webpage = self._download_webpage(url, video_id)
-            return
+        webpage = self._download_webpage(url, video_id)
-            return
+        webpage = self._download_webpage(url, video_id)
-            return
+        webpage = self._download_webpage(url, video_id)
-        
+
-            return
+        webpage = self._download_webpage(videourl, gameID)
-        for vid in mweb:
+        for vid,vtitle in zip(mweb,titles):
-            video_url=vid.group('videoURL')
+            title = vtitle.group('videoName')
-            i += 1
+    def _download_webpage(self, url, video_id, note=None, errnote=None):
-            raise ExtractorError(u'unable to download webpage: %s' % compat_str(err))
+        webpage = self._download_webpage(url, video_id)
-    def trouble(self, message=None):
+    def trouble(self, message=None, tb=None):
-            self.to_stderr(u''.join(traceback.format_list(traceback.extract_stack())))
+            if tb is None:
-                                 u'and will probably not work. If you want to go on, use the -i option.')
+                    self.to_stderr(u'WARNING: the program functionality for this site has been marked as broken, '
-                videos = ie.extract(url)
+                try:
-            return
+            raise ExtractorError(u'unable to download webpage: %s' % compat_str(err))
-        self._downloader.to_screen(u'[Youku] %s: Downloading webpage' % file_id)
+        self._downloader.to_screen(u'[%s] %s: Downloading webpage' % (self.IE_NAME, file_id))
-        self._downloader.to_screen(u'[Youku] %s: Extracting information' % file_id)
+        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, file_id))
-    
+
-    pass
+
-from .InfoExtractors import *
+from .InfoExtractors import gen_extractors
-            params[p] = test_case['params'][p]
+        params = self.parameters.copy()
-        if not test_case['file']:
+        if 'playlist' not in test_case and not test_case['file']:
-                self.assertEqual(value, info_dict.get(info_field))
+
-                    os.remove(fn)
+        for fn in [ test.get('file', False) for test in self.defs ]:
-                self.assertEqual(md5_for_file, md5)
+        self.assertTrue(os.path.exists(test_case['file']))
-### Dinamically generate tests
+### Dynamically generate tests
-                os.remove(fn)
+        for files in [ test['files'] for test in self.defs ]:
-            self.assertEqual(md5_for_file, test_case['md5'])
+        for filename, md5 in test_case['files']:
-                if len(videos) > 1 and self.fixed_template():
+                if len(videos or []) > 1 and self.fixed_template():
-        self._downloader.increment_downloads()
+from .update import update_self
-
+import json
-from .version import __version__, __version_codename__
+from .version import __version__
-        if verbose: to_screen(traceback.format_exc().decode())
+        if verbose: to_screen(enforce_unicode(traceback.format_exc()))
-        if verbose: to_screen(traceback.format_exc().decode())
+        if verbose: to_screen(enforce_unicode(traceback.format_exc()))
-            if verbose: to_screen(traceback.format_exc().decode())
+            if verbose: to_screen(enforce_unicode(traceback.format_exc()))
-            if verbose: to_screen(traceback.format_exc().decode())
+            if verbose: to_screen(enforce_unicode(traceback.format_exc()))
-            if verbose: to_screen(traceback.format_exc().decode())
+            if verbose: to_screen(enforce_unicode(traceback.format_exc()))
-            if verbose: to_screen(traceback.format_exc().decode())
+            if verbose: to_screen(enforce_unicode(traceback.format_exc()))
-            if verbose: to_screen(traceback.format_exc().decode())
+            if verbose: to_screen(enforce_unicode(traceback.format_exc()))
-        fd.to_screen(u'[debug] youtube-dl version %s - %s' %(__version__, __version_codename__))
+        fd.to_screen(u'[debug] youtube-dl version ' + __version__)
-            sp = subprocess.Popen(['git', 'rev-parse', '--short', 'HEAD'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+            sp = subprocess.Popen(['git', 'rev-parse', '--short', 'HEAD'], stdout=subprocess.PIPE, stderr=subprocess.PIPE,
-__version_codename__ = ''
+import platform
-from .version import __version__
+from .version import __version__, __version_codename__
-    if not rsa_verify(json.dumps(versions_info, sort_keys=True), signature, UPDATES_RSA_KEY):
+    if not rsa_verify(json.dumps(versions_info, sort_keys=True).encode('utf-8'), signature, UPDATES_RSA_KEY):
-sys.stderr.write(u'The new location of the binaries is https://github.com/rg3/youtube-dl/downloads, not the git repository.\n\n')
+sys.stderr.write(u'From now on, get the binaries from http://rg3.github.com/youtube-dl/download.html, not from the git repository.\n\n')
-EXE_URL = "https://github.com/downloads/rg3/youtube-dl/youtube-dl.exe"
+UPDATE_URL = "http://rg3.github.com/youtube-dl/update/"
-    urlh = urllib2.urlopen(EXE_URL)
+    versions_info = urllib2.urlopen(JSON_URL).read().decode('utf-8')
-    sys.exit('ERROR: unable to download latest version')
+    sys.exit(u'ERROR: unable to write the new version')
-def updateSelf(downloader, filename):
+def update_self(to_screen, verbose, filename):
-
+    import json, traceback, hashlib
-    EXE_URL = "https://github.com/downloads/rg3/youtube-dl/youtube-dl.exe"
+    UPDATE_URL = "http://rg3.github.com/youtube-dl/update/"
-        downloader.to_screen(u'Updating to latest version...')
+    if not isinstance(globals().get('__loader__'), zipimporter) and not hasattr(sys, "frozen"):
-        urla.close()
+    # Check if there is a new version
-            sys.exit('ERROR: no write permissions on %s' % directory)
+            to_screen(u'ERROR: no write permissions on %s' % directory)
-            urlh = compat_urllib_request.urlopen(EXE_URL)
+            urlh = compat_urllib_request.urlopen(version['exe'][0])
-            sys.exit('ERROR: unable to download latest version')
+            if verbose: to_screen(traceback.format_exc().decode())
-            downloader.to_screen(u'ERROR: can\'t find the current version. Please try again later.')
+            if verbose: to_screen(traceback.format_exc().decode())
-        urla.close()
+    # Zip unix package
-            urlh = compat_urllib_request.urlopen(BIN_URL)
+            urlh = compat_urllib_request.urlopen(version['bin'][0])
-            sys.exit('ERROR: unable to download latest version')
+            if verbose: to_screen(traceback.format_exc().decode())
-        return
+            if verbose: to_screen(traceback.format_exc().decode())
-    downloader.to_screen(u'Updated youtube-dl. Restart youtube-dl to use the new version.')
+    to_screen(u'Updated youtube-dl. Restart youtube-dl to use the new version.')
-        updateSelf(fd, sys.argv[0])
+        update_self(fd.to_screen, opts.verbose, sys.argv[0])
-    def fetch_webpage(self, url):
+        request = compat_urllib_request.Request(url)
-    def test_playlist_matching(self):
+class TestAllURLsMatching(unittest.TestCase):
-                                 (?:.+&)?                                     # any other preceding param (like /?s=tuff&v=xxxx)
+                                 (?:.*?&)?                                    # any other preceding param (like /?s=tuff&v=xxxx)
-        # Extract video id from URL
+    def _extract_id(self, url):
-        request = compat_urllib_request.Request('http://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id)
+        url = 'http://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id
-    upload_date:    Video upload date (YYYYMMDD).
+    uploader:       Full name of the video uploader.
-        print(video_url)
+
-        if len(list(url_map.keys())) > 0:
+        if url_map:
-            if req_format not in list(formats.keys()):
+            if req_format not in formats:
-        cmd = ([self._exes['avconv'] or self._exes['ffmpeg'], overwrite_opts, '-i', encodeFilename(path), '-vn']
+        cmd = ([self._exes['avconv'] or self._exes['ffmpeg'], '-y', '-i', encodeFilename(path), '-vn']
-            self.run_ffmpeg(path, new_path, acodec, more_opts)
+            if self._nopostoverwrites and os.path.exists(encodeFilename(new_path)):
-        if self._nopostoverwrites:
+        if self._nopostoverwrites and self._exes['ffmpeg']:
-    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, keepvideo=False):
+    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, keepvideo=False, nopostoverwrites=False):
-            raise AudioConversionError('ffmpeg or avconv not found. Please install one.')   
+            raise AudioConversionError('ffmpeg or avconv not found. Please install one.')
-        cmd = ([self._exes['avconv'] or self._exes['ffmpeg'], '-y', '-i', encodeFilename(path), '-vn']
+        if self._nopostoverwrites:
-        fd.add_post_processor(FFmpegExtractAudioPP(preferredcodec=opts.audioformat, preferredquality=opts.audioquality, keepvideo=opts.keepvideo))
+        fd.add_post_processor(FFmpegExtractAudioPP(preferredcodec=opts.audioformat, preferredquality=opts.audioquality, keepvideo=opts.keepvideo, nopostoverwrites=opts.nopostoverwrites))
-import socket
+import socket
-        for (info_element, value) in test_case.get('info_dict', {}).items():
+        for (info_field, value) in test_case.get('info_dict', {}).items():
-                md5_info_value = hashlib.md5(info_dict[info_element]).hexdigest()
+                md5_info_value = hashlib.md5(info_dict.get(info_field, '')).hexdigest()
-                self.assertEqual(value, info_dict[info_element])
+                self.assertEqual(value, info_dict.get(info_field))
-        mobj = re.search(r'<span id="clip-date" style="display:none">[^:]*: (.*?)( \([^\(]*\))?</span>', webpage)
+        mobj = re.search(r'<meta itemprop="dateCreated" content="(\d{4})-(\d{2})-(\d{2})T', webpage)
-            video_upload_date = mobj.group(1)
+            video_upload_date = mobj.group(1) + mobj.group(2) + mobj.group(3)
-    html = re.sub('\s*<\s*br\s*/?\s*>\s*', '\n', html)
+    html = re.sub(r'\s*<\s*br\s*/?\s*>\s*', '\n', html)
-    uploader:       Nickname of the video uploader, unescaped.
+    uploader:       Full name of the video uploader, unescaped.
-            self._downloader.trouble(u'ERROR: unable to extract uploader nickname')
+            self._downloader.trouble(u'ERROR: unable to extract uploader name')
-        # Extract uploader
+        # Extract uploader and uploader_id
-            dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(title)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(extractor)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout. Can also be used to download to a different directory, for example with -o \'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\' .')
+            dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(title)s to get the title, %(uploader)s for the uploader name, %(uploader_id)s for the uploader nickname if different, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(extractor)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout. Can also be used to download to a different directory, for example with -o \'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\' .')
-                    srtfile.close()
+                with io.open(encodeFilename(srtfn), 'w', encoding='utf-8') as srtfile:
-            srt_lang = srt_lang_list.keys()[0]
+            srt_lang = list(srt_lang_list.keys())[0]
-            url_data = filter(lambda ud: 'itag' in ud and 'url' in ud, url_data)
+            url_data = [ud for ud in url_data if 'itag' in ud and 'url' in ud]
-        if len(url_map.keys()) > 0:
+        if len(list(url_map.keys())) > 0:
-            if req_format not in formats.keys():
+            if req_format not in list(formats.keys()):
-            supported_format = config['data'][0]['streamfileids'].keys()
+            supported_format = list(config['data'][0]['streamfileids'].keys())
-            all_urls = filter(lambda url: url not in matchedUrls, all_urls)
+            matchedUrls = [url for url in all_urls if ie.suitable(url)]
-        youtube_dl.FileDownloader.__init__(self, *args, **kwargs)
+        self.processed_info_dicts = []
-                self._downloader.trouble(str(trouble))
+            (srt_error, video_subtitles) = self._extract_subtitles(video_id)
-        video_description = get_element_by_id("description", webpage)
+        video_description = get_element_by_attribute("itemprop", "description", webpage)
-        self.id = id
+class AttrParser(compat_html_parser.HTMLParser):
-        if 'id' in attrs and attrs['id'] == self.id:
+        if self.attribute in attrs and attrs[self.attribute] == self.value:
-    parser = IDParser(id)
+    """Return the content of the tag with the specified ID in the passed HTML document"""
-        self.assertEquals(sanitize_filename('N0Y__7-UOdI', is_id=True), 'N0Y__7-UOdI')
+        self.assertEqual(sanitize_filename('_n_cd26wFpw', is_id=True), '_n_cd26wFpw')
-                    descfile.close()
+                with io.open(encodeFilename(descfn), 'w', encoding='utf-8') as descfile:
-                    json.dump(json_info_dict, infof)
+                json_info_dict = dict((k, v) for k,v in info_dict.items() if not k in ['urlhandle'])
-    others. The information is stored in a dictionary which is then 
+    others. The information is stored in a dictionary which is then
-    }   
+    }
-        
+
-        
+
-            Subclass the HTTPRedirectHandler to make it use our 
+            Subclass the HTTPRedirectHandler to make it use our
-            def redirect_request(self, req, fp, code, msg, headers, newurl): 
+            def redirect_request(self, req, fp, code, msg, headers, newurl):
-                    newurl = newurl.replace(' ', '%20') 
+                    newurl = newurl.replace(' ', '%20')
-                    return HeadRequest(newurl, 
+                    return HeadRequest(newurl,
-                    raise compat_urllib_error.HTTPError(req.get_full_url(), code, msg, headers, fp) 
+                                       origin_req_host=req.get_origin_req_host(),
-            def http_error_405(self, req, fp, code, msg, headers): 
+            def http_error_405(self, req, fp, code, msg, headers):
-                                                 origin_req_host=req.get_origin_req_host(), 
+                return self.parent.open(compat_urllib_request.Request(req.get_full_url(),
-        opener = compat_urllib_request.OpenerDirector() 
+        opener = compat_urllib_request.OpenerDirector()
-    
+
-    # urls for episodes like: 
+    # urls for episodes like:
-    #                     or: http://www.colbertnation.com/the-colbert-report-collections/422008/festival-of-lights/79524    
+    #                     or: http://www.colbertnation.com/the-colbert-report-collections/422008/festival-of-lights/79524
-                     $"""                        
+                     $"""
-        
+
-            
+
-            
+
-            
+
-        video_title = performer + ' - ' + song_name 
+        video_title = performer + ' - ' + song_name
-        
+
-        
+
-        
+
-        
+
-                    json_info_dict = dict((k, info_dict[k]) for k in info_dict if not k in ['urlhandle'])
+                with io.open(encodeFilename(infofn), 'w', 'utf-8') as infof:
-                    infof.close()
+    _WORKING = False
-            'title':        info.get('title'),
+            'title':        info.get('title').decode('utf-8'),
-            webpage = compat_urllib_request.urlopen(request).read()
+            webpage = compat_urllib_request.urlopen(request).read().decode('utf-8')
-            configJSON = compat_urllib_request.urlopen(configUrl).read()
+            configJSON = compat_urllib_request.urlopen(configUrl)
-    _VALID_URL = r'(?:https://)?plus\.google\.com/(?:\w+/)*?(\d+)/posts/(\w+)'
+    _VALID_URL = r'(?:https://)?plus\.google\.com/(?:[^/]+/)*?posts/(\w+)'
-        self._downloader.to_screen(u'[plus.google] Downloading entry: %s' % url.decode('utf-8'))
+        self._downloader.to_screen(u'[plus.google] Downloading entry: %s' % url)
-        self._downloader.to_screen(u'[plus.google] Uploader: %s' % uploader.decode('utf-8'))
+        self._downloader.to_screen(u'[plus.google] Uploader: %s' % uploader)
-        self._downloader.to_screen(u'[plus.google] Title: %s' % video_title.decode('utf-8'))
+        self._downloader.to_screen(u'[plus.google] Title: %s' % video_title)
-        self._downloader.to_screen(u'[plus.google] Extracting video page: %s' % video_page.decode('utf-8'))
+        self._downloader.to_screen(u'[plus.google] Extracting video page: %s' % video_page)
-        video_id = mobj.group(2)
+        video_id = mobj.group(1)
-            webpage = compat_urllib_request.urlopen(request).read()
+            webpage = compat_urllib_request.urlopen(request).read().decode('utf-8')
-            webpage = compat_urllib_request.urlopen(request).read()
+            webpage = compat_urllib_request.urlopen(request).read().decode('utf-8')
-        video_url = unicode(video_url, "unicode_escape")
+        try:
-            'id':       video_id.decode('utf-8'),
+            'id':       video_id,
-            'ext':      video_extension.decode('utf-8'),
+            'uploader': uploader,
-                infof = open(encodeFilename(infofn), 'wb')
+                infof = open(encodeFilename(infofn), 'w')
-                    json_info_dict = dict((k,v) for k,v in info_dict.iteritems() if not k in ('urlhandle',))
+                    json_info_dict = dict((k, info_dict[k]) for k in info_dict if not k in ['urlhandle'])
-            login_results = compat_urllib_request.urlopen(request).read()
+            login_results = compat_urllib_request.urlopen(request).read().decode('utf-8')
-            age_results = compat_urllib_request.urlopen(request).read()
+            age_results = compat_urllib_request.urlopen(request).read().decode('utf-8')
-                    srt_list = compat_urllib_request.urlopen(request).read()
+                    srt_list = compat_urllib_request.urlopen(request).read().decode('utf-8')
-                    srt_xml = compat_urllib_request.urlopen(request).read()
+                    srt_xml = compat_urllib_request.urlopen(request).read().decode('utf-8')
-                video_subtitles = self._closed_captions_xml_to_srt(srt_xml.decode('utf-8'))
+                video_subtitles = self._closed_captions_xml_to_srt(srt_xml)
-                self._downloader.trouble(trouble[0])
+                self._downloader.trouble(str(trouble))
-                page = compat_urllib_request.urlopen(request).read().decode('utf8')
+                page = compat_urllib_request.urlopen(request).read().decode('utf-8')
-                page = compat_urllib_request.urlopen(request).read()
+                page = compat_urllib_request.urlopen(request).read().decode('utf-8')
-        self.params = {}
+        self.params = parameters
-            handle = subprocess.Popen(cmd, stderr=file(os.path.devnull, 'w'), stdout=subprocess.PIPE)
+            handle = subprocess.Popen(cmd, stderr=compat_subprocess_get_DEVNULL(), stdout=subprocess.PIPE)
-        for line in output.split('\n'):
+        for line in output.decode('ascii', 'ignore').split('\n'):
-    _VALID_URL = r'^http://www.twitch.tv/(.*)$'
+    _VALID_URL = r"""(?x)^(?:http://)?(?:www\.)?(?:twitch|justin)\.tv/
-    _justin_page_limit = 100
+    def report_download_page(self, channel, offset):
-                    'uploader': clip['user_id'] or clip['channel_id'],
+                    'uploader': clip.get('user_id', clip.get('channel_id')),
-        while offset < self._max_justin_results:
+        limit = self._JUSTIN_PAGE_LIMIT
-    
+    # TODO: One broadcast may be split into multiple videos. The key
-        # starts at 1 and increases. Can we treat all parts as one video?
+    # Return count of items, list of *valid* items
-            urlh = compat_urllib_request.urlopen(api)
+            urlh = compat_urllib_request.urlopen(url)
-		# Get the video URL
+		# Get the video title
-		
+		YouJizzIE(),
-	_VALID_URL = r'^http://video\.xnxx\.com/video([0-9]+)/(.*)'
+	_VALID_URL = r'^(?:https?://)?video\.xnxx\.com/video([0-9]+)/(.*)'
-			self._print_formats(results)
+			self._print_formats(formats)
-        opts.outtmpl = opts.outtmpl.decode(preferredencoding())
+        if opts.outtmpl is not None:
-            webpage = compat_urllib_request.urlopen(request).read()
+            webpage_bytes = compat_urllib_request.urlopen(request).read()
-        video_description = get_element_by_id("description", webpage.decode('utf8'))
+        video_description = get_element_by_id("description", webpage)
-        video_title = mobj.group(1).decode('utf-8')
+        video_title = mobj.group(1)
-        video_uploader = mobj.group(1).decode('utf-8')
+        video_uploader = mobj.group(1)
-            'url':      video_url.decode('utf-8'),
+            'id':       video_id,
-            'ext':      video_extension.decode('utf-8'),
+            'ext':      video_extension,
-            webpage = compat_urllib_request.urlopen(request).read()
+            webpage_bytes = compat_urllib_request.urlopen(request).read()
-        video_title = unescapeHTML(mobj.group('title').decode('utf-8'))
+        video_title = unescapeHTML(mobj.group('title'))
-            'uploader': video_uploader.decode('utf-8'),
+            'id':       video_id,
-            'ext':      video_extension.decode('utf-8'),
+            'ext':      video_extension,
-        video_id = mobj.group(1).decode('utf-8')
+        video_id = mobj.group(1)
-            webpage = compat_urllib_request.urlopen(url).read()
+            webpage_bytes = compat_urllib_request.urlopen(url).read()
-        video_url = compat_urllib_parse.unquote(result.group(1).decode('utf-8'))
+        video_url = compat_urllib_parse.unquote(result.group(1))
-        video_title = result.group(1).decode('utf-8')
+        video_title = result.group(1)
-        video_thumbnail = result.group(1).decode('utf-8')
+        video_thumbnail = result.group(1)
-            config = json.loads(jsondata)
+            jsonstr = jsondata.decode('utf-8')
-        except (ValueError, KeyError):
+        except (UnicodeDecodeError, ValueError, KeyError):
-        except:
+            keys = [s['k'] for s in config['data'][0]['segs'][format]]
-        video_id = mobj.group(1).decode('utf-8')
+        video_id = mobj.group(1)
-            webpage = compat_urllib_request.urlopen(request).read()
+            webpage_bytes = compat_urllib_request.urlopen(request).read()
-        video_url = compat_urllib_parse.unquote(mobj.group(1).decode('utf-8'))
+        video_url = compat_urllib_parse.unquote(mobj.group(1))
-        video_title = mobj.group(1).decode('utf-8')
+        video_title = mobj.group(1)
-        video_thumbnail = mobj.group(0).decode('utf-8')
+        video_thumbnail = mobj.group(0)
-            or u'%(id)s.%(ext)s'),
+        'outtmpl': outtmpl,
-            fn = test['file']
+        for fn in [ test.get('file', False) for test in self.defs ]:
-def make_test_method(test_case):
+### Dinamically generate tests
-    # TODO proper skipping annotations
+### And add them to TestDownload
-    test_method = make_test_method(test_case)
+    test_method = generator(test_case)
-        for fn in [ test.get('file', False) for test in self.defs ]:
+        for test in self.defs:
-
+def make_test_method(test_case):
-    test_method = generator(test_case)
+    test_method = make_test_method(test_case)
-#!/usr/bin/env python2
+#!/usr/bin/env python
-import youtube_dl
+import youtube_dl.FileDownloader
-)
+PARAMETERS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "parameters.json")
-    pass
+    def setUp(self):
-        return md5.hexdigest()
+### Dinamically generate tests
-        self.assertEqual(md5_for_file(file), md5)
+        ie = getattr(youtube_dl.InfoExtractors, test_case['name'] + 'IE')
-        del ff
+
-        """I give up, please find a channel that does paginate and test this like test_youtube_playlist_long"""
+        # I give up, please find a channel that does paginate and test this like test_youtube_playlist_long
-    _VALID_URL = r'^(:(?P<shortname>tds|thedailyshow|cr|colbert|colbertnation|colbertreport))|(https?://)?(www\.)?(?P<showname>thedailyshow|colbertnation)\.com/full-episodes/(?P<episode>.*)$'
+    # urls can be abbreviations like :thedailyshow or :colbert
-        mobj = re.match(self._VALID_URL, url)
+        mobj = re.match(self._VALID_URL, url, re.VERBOSE)
-            mobj = re.match(self._VALID_URL, url)
+            mobj = re.match(self._VALID_URL, url, re.VERBOSE)
-            epTitle = mobj.group('showname')
+        if mobj.group('clip'):
-            epTitle = mobj.group('episode')
+            dlNewest = not mobj.group('episode')
-            mobj = re.match(self._VALID_URL, url)
+            mobj = re.match(self._VALID_URL, url, re.VERBOSE)
-        mMovieParams = re.findall('(?:<param name="movie" value="|var url = ")(http://media.mtvnservices.com/([^"]*episode.*?:.*?))"', html)
+        mMovieParams = re.findall('(?:<param name="movie" value="|var url = ")(http://media.mtvnservices.com/([^"]*(?:episode|video).*?:.*?))"', html)
-            altMovieParams = re.findall('data-mgid="([^"]*episode.*?:.*?)"', html)
+            altMovieParams = re.findall('data-mgid="([^"]*(?:episode|video).*?:.*?)"', html)
-
+#!/usr/bin/env python2
-            os.remove(u'XNDgyMDQ2NTQw_part00.flv')
+from youtube_dl.FileDownloader import FileDownloader
-BASH_COMPLETION_TEMPLATE = "devscripts/bash-completion.template"
+BASH_COMPLETION_TEMPLATE = "devscripts/bash-completion.in"
-BASH_COMPLETION_TEMPLATE = "devscripts/bash-completion.template"
+BASH_COMPLETION_TEMPLATE = "devscripts/bash-completion.in"
-from youtube_dl.InfoExtractors import YoutubePlaylistIE
+from youtube_dl.InfoExtractors import YoutubeUserIE,YoutubePlaylistIE
-        IE = YoutubePlaylistIE(DL)
+        IE = YoutubeUserIE(DL)
-        filename = u'BaW_jenozKc.mp4'
+        filename = 'BaW_jenozKc.mp4'
-        fd.download([u'http://www.youtube.com/watch?v=BaW_jenozKc'])
+        fd.download(['http://www.youtube.com/watch?v=BaW_jenozKc'])
-        filename = u'x33vw9.mp4'
+        filename = 'x33vw9.mp4'
-        fd.download([u'http://www.dailymotion.com/video/x33vw9_tutoriel-de-youtubeur-dl-des-video_tech'])
+        fd.download(['http://www.dailymotion.com/video/x33vw9_tutoriel-de-youtubeur-dl-des-video_tech'])
-        self.assertEqual(md5_for_file, u'392c4b85a60a90dc4792da41ce3144eb')
+        self.assertEqual(md5_for_file, '392c4b85a60a90dc4792da41ce3144eb')
-        filename = u'_aUehQsCQtM.flv'
+        filename = '_aUehQsCQtM.flv'
-        fd.download([u'http://www.metacafe.com/watch/yt-_aUehQsCQtM/the_electric_company_short_i_pbs_kids_go/'])
+        fd.download(['http://www.metacafe.com/watch/yt-_aUehQsCQtM/the_electric_company_short_i_pbs_kids_go/'])
-        filename = u'5779306.m4v'
+        filename = '5779306.m4v'
-        fd.download([u'http://blip.tv/cbr/cbr-exclusive-gotham-city-imposters-bats-vs-jokerz-short-3-5796352'])
+        fd.download(['http://blip.tv/cbr/cbr-exclusive-gotham-city-imposters-bats-vs-jokerz-short-3-5796352'])
-        self.assertEqual(md5_for_file, u'b2d849efcf7ee18917e4b4d9ff37cafe')
+        self.assertEqual(md5_for_file, 'b2d849efcf7ee18917e4b4d9ff37cafe')
-        filename = u'939581.flv'
+        filename = '939581.flv'
-        fd.download([u'http://www.xvideos.com/video939581/funny_porns_by_s_-1'])
+        fd.download(['http://www.xvideos.com/video939581/funny_porns_by_s_-1'])
-        self.assertEqual(md5_for_file, u'1d0c835822f0a71a7bf011855db929d0')
+        self.assertEqual(md5_for_file, '1d0c835822f0a71a7bf011855db929d0')
-        filename = u'14160053.mp4'
+        filename = '14160053.mp4'
-        fd.download([u'http://vimeo.com/14160053'])
+        fd.download(['http://vimeo.com/14160053'])
-        self.assertEqual(md5_for_file, u'60540a4ec7cc378ec84b919c0aed5023')
+        self.assertEqual(md5_for_file, '60540a4ec7cc378ec84b919c0aed5023')
-        filename = u'62986583.mp3'
+        filename = '62986583.mp3'
-        fd.download([u'http://soundcloud.com/ethmusic/lostin-powers-she-so-heavy'])
+        fd.download(['http://soundcloud.com/ethmusic/lostin-powers-she-so-heavy'])
-        self.assertEqual(md5_for_file, u'ebef0a451b909710ed1d7787dddbf0d7')
+        self.assertEqual(md5_for_file, 'ebef0a451b909710ed1d7787dddbf0d7')
-        filename = u'PracticalUnix_intro-environment.mp4'
+        filename = 'PracticalUnix_intro-environment.mp4'
-        fd.download([u'http://openclassroom.stanford.edu/MainFolder/VideoPage.php?course=PracticalUnix&video=intro-environment&speed=100'])
+        fd.download(['http://openclassroom.stanford.edu/MainFolder/VideoPage.php?course=PracticalUnix&video=intro-environment&speed=100'])
-        self.assertEqual(md5_for_file, u'544a9468546059d4e80d76265b0443b8')
+        self.assertEqual(md5_for_file, '544a9468546059d4e80d76265b0443b8')
-        filename = u'1135332.flv'
+        filename = '1135332.flv'
-        fd.download([u'http://video.xnxx.com/video1135332/lida_naked_funny_actress_5_'])
+        fd.download(['http://video.xnxx.com/video1135332/lida_naked_funny_actress_5_'])
-        self.assertEqual(md5_for_file, u'0831677e2b4761795f68d417e0b7b445')
+        self.assertEqual(md5_for_file, '0831677e2b4761795f68d417e0b7b445')
-        filename = u'XNDgyMDQ2NTQw_part00.flv'
+        filename = 'XNDgyMDQ2NTQw_part00.flv'
-        fd.download([u'http://v.youku.com/v_show/id_XNDgyMDQ2NTQw.html'])
+        fd.download(['http://v.youku.com/v_show/id_XNDgyMDQ2NTQw.html'])
-        self.assertEqual(md5_for_file, u'ffe3f2e435663dc2d1eea34faeff5b5b')
+        self.assertEqual(md5_for_file, 'ffe3f2e435663dc2d1eea34faeff5b5b')
-            os.remove(u'XNDgyMDQ2NTQw_part00.flv')
+        if os.path.exists('BaW_jenozKc.mp4'):
-__version__ = '2012.11.29'
+__version__ = '2012.12.11'
-        request = compat_urllib_request.Request(json_url.encode('utf-8'))
+        request = compat_urllib_request.Request(json_url)
-                json_code = urlh.read()
+                json_code_bytes = urlh.read()
-        assert not YoutubePlaylistIE().suitable(u'PLtS2H6bU1M')
+        self.assertTrue(YoutubePlaylistIE().suitable(u'ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8'))
-        assert YoutubeIE().suitable(u'PLtS2H6bU1M')
+        self.assertTrue(YoutubeIE().suitable(u'PLtS2H6bU1M'))
-    _MORE_PAGES_INDICATOR = r'yt-uix-pager-next'
+    _MORE_PAGES_INDICATOR = u"Next \N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}"
-                page = compat_urllib_request.urlopen(request).read()
+                page = compat_urllib_request.urlopen(request).read().decode('utf8')
-            if re.search(self._MORE_PAGES_INDICATOR, page) is None:
+            if self._MORE_PAGES_INDICATOR not in page:
-    _MORE_PAGES_INDICATOR = r'yt-uix-button-content">Next' # TODO
+    _MORE_PAGES_INDICATOR = u"Next \N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}"
-                page = compat_urllib_request.urlopen(request).read()
+                page = compat_urllib_request.urlopen(request).read().decode('utf8')
-            if re.search(self._MORE_PAGES_INDICATOR, page) is None:
+            if self._MORE_PAGES_INDICATOR not in page:
-                write('    self.assertEqual(os.path.getsize(filename), ' + repr(d['size']) + ')')
+import socket
-from youtube_dl.FileDownloader import FileDownloader
+import youtube_dl.FileDownloader
-        fd = FileDownloader(self.parameters)
+        filename = u'BaW_jenozKc.mp4'
-        fd.download(['http://www.youtube.com/watch?v=BaW_jenozKc'])
+        fd.download([u'http://www.youtube.com/watch?v=BaW_jenozKc'])
-        fd = FileDownloader(self.parameters)
+        filename = u'x33vw9.mp4'
-        fd.download(['http://www.dailymotion.com/video/x33vw9_tutoriel-de-youtubeur-dl-des-video_tech'])
+        fd.download([u'http://www.dailymotion.com/video/x33vw9_tutoriel-de-youtubeur-dl-des-video_tech'])
-        self.assertEqual(md5_for_file, 'd363a50e9eb4f22ce90d08d15695bb47')
+        self.assertEqual(md5_for_file, u'392c4b85a60a90dc4792da41ce3144eb')
-        fd = FileDownloader(self.parameters)
+        filename = u'_aUehQsCQtM.flv'
-        fd.download(['http://www.metacafe.com/watch/yt-_aUehQsCQtM/the_electric_company_short_i_pbs_kids_go/'])
+        fd.download([u'http://www.metacafe.com/watch/yt-_aUehQsCQtM/the_electric_company_short_i_pbs_kids_go/'])
-        fd = FileDownloader(self.parameters)
+        filename = u'5779306.m4v'
-        fd.download(['http://blip.tv/cbr/cbr-exclusive-gotham-city-imposters-bats-vs-jokerz-short-3-5796352'])
+        fd.download([u'http://blip.tv/cbr/cbr-exclusive-gotham-city-imposters-bats-vs-jokerz-short-3-5796352'])
-        self.assertEqual(md5_for_file, '4962f94441605832eb1008eb820ef47a')
+        self.assertEqual(md5_for_file, u'b2d849efcf7ee18917e4b4d9ff37cafe')
-        fd = FileDownloader(self.parameters)
+        filename = u'939581.flv'
-        fd.download(['http://www.xvideos.com/video939581/funny_porns_by_s_-1'])
+        fd.download([u'http://www.xvideos.com/video939581/funny_porns_by_s_-1'])
-        self.assertEqual(md5_for_file, 'aecab2ea59b7996110a7e409f0c55da3')
+        self.assertEqual(md5_for_file, u'1d0c835822f0a71a7bf011855db929d0')
-        fd = FileDownloader(self.parameters)
+        filename = u'14160053.mp4'
-        fd.download(['http://vimeo.com/14160053'])
+        fd.download([u'http://vimeo.com/14160053'])
-        self.assertEqual(md5_for_file, '1ab4dedc01f771cb2a65e91caa801aaf')
+        self.assertEqual(md5_for_file, u'60540a4ec7cc378ec84b919c0aed5023')
-        fd = FileDownloader(self.parameters)
+        filename = u'62986583.mp3'
-        fd.download(['http://soundcloud.com/ethmusic/lostin-powers-she-so-heavy'])
+        fd.download([u'http://soundcloud.com/ethmusic/lostin-powers-she-so-heavy'])
-        self.assertEqual(md5_for_file, 'c1b9b9ea8bfd620b96b2628664576e1c')
+        self.assertEqual(md5_for_file, u'ebef0a451b909710ed1d7787dddbf0d7')
-        fd = FileDownloader(self.parameters)
+        filename = u'PracticalUnix_intro-environment.mp4'
-        fd.download(['http://www.collegehumor.com/video/6830834/mitt-romney-style-gangnam-style-parody'])
+        fd.download([u'http://openclassroom.stanford.edu/MainFolder/VideoPage.php?course=PracticalUnix&video=intro-environment&speed=100'])
-        self.assertEqual(md5_for_file, '')
+        self.assertEqual(md5_for_file, u'544a9468546059d4e80d76265b0443b8')
-        fd = FileDownloader(self.parameters)
+        filename = u'1135332.flv'
-        fd.download(['http://video.xnxx.com/video1135332/lida_naked_funny_actress_5_'])
+        fd.download([u'http://video.xnxx.com/video1135332/lida_naked_funny_actress_5_'])
-        self.assertEqual(md5_for_file, 'c5c67df477eb0d9b058200351448ba4c')
+        self.assertEqual(md5_for_file, u'0831677e2b4761795f68d417e0b7b445')
-        fd = FileDownloader(self.parameters)
+        filename = u'XNDgyMDQ2NTQw_part00.flv'
-        fd.download(['http://v.youku.com/v_show/id_XNDgyMDQ2NTQw.html'])
+        fd.download([u'http://v.youku.com/v_show/id_XNDgyMDQ2NTQw.html'])
-        self.assertEqual(md5_for_file, 'ffe3f2e435663dc2d1eea34faeff5b5b')
+        self.assertEqual(md5_for_file, u'ffe3f2e435663dc2d1eea34faeff5b5b')
-            os.remove('XNDgyMDQ2NTQw_part00.flv')
+        if os.path.exists(u'BaW_jenozKc.mp4'):
-            write('    fd = FileDownloader(self.parameters)')
+            write('    params = self.parameters')
-from youtube_dl.FileDownloader import FileDownloader
+import youtube_dl.FileDownloader
-        write = lambda l: testf.write(spaces + l + '\n')
+        write = lambda l: testf.write(spaces + l + u'\n')
-            testf.write('\n')
+            testf.write(u'\n')
-        testf.write('\n\n')
+        testf.write(u'\n\n')
-        testf.write('\n')
+        testf.write(u'\n')
-        config = webpage.split(' = {config:')[1].split(',assets:')[0]
+            config = webpage.split(' = {config:')[1].split(',assets:')[0]
-    # Note: downloader only used for options
+    """Update the program file with the latest version from the repository"""
-        sys.exit('ERROR: no write permissions on %s' % filename)
+    # TODO: at least, check https certificates
-    downloader.to_screen(u'Updating to latest version...')
+    from zipimport import zipimporter
-    urlv.close()
+    API_URL = "https://api.github.com/repos/rg3/youtube-dl/downloads"
-            urlh = compat_urllib_request.urlopen(UPDATE_URL_EXE)
+            urlh = compat_urllib_request.urlopen(EXE_URL)
-    else:
+    elif isinstance(globals().get('__loader__'), zipimporter): # UNIX ZIP
-            urlh = compat_urllib_request.urlopen(UPDATE_URL)
+            urlh = compat_urllib_request.urlopen(BIN_URL)
-BASH_COMPLETION_TEMPLATE = "devscripts/bash_completion.template"
+BASH_COMPLETION_FILE = "youtube-dl.bash-completion"
-#!/usr/bin/env python2
+#!/usr/bin/env python
-        print opts_flag
+README_FILE = 'README.md'
-f.close()
+with open(README_FILE) as f:
-f.close()
+with open(README_FILE, 'w') as f:
-
+py2exe_params = {
-        'zipfile': None
+if len(sys.argv) >= 2 and sys.argv[1] == 'py2exe':
-    **py2exe_params
+    **params
-if __package__ is None:
+if __package__ is None and not hasattr(sys, "frozen"):
-    "script":"./youtube_dl/__main__.py",
+    "script": "./youtube_dl/__main__.py",
-    description = 'Small command-line program to download videos from YouTube.com and other video sites',
+    description = 'YouTube video downloader',
-    options = { "py2exe": py2exe_options },
+    # Provokes warning on most systems (why?!)
-    zipfile = None,
+    data_files = [('etc/bash_completion.d', ['youtube-dl.bash-completion']), # Installing system-wide would require sudo...
-    ]
+    ],
-        filename = 'n6FLbx6ZzMiu.mp3'
+        filename = '62986583.mp3'
-            os.remove('n6FLbx6ZzMiu.mp3')
+        if os.path.exists('62986583.mp3'):
-        request = compat_urllib_request.Request(resolv_url)
+        request = compat_urllib_request.Request(streams_url)
-        request = compat_urllib_request.Request('http://media.soundcloud.com/crossdomain.xml', std_headers)
+        mediaURL = streams['http_mp3_128_url']
-            'id':       video_id,
+            'id':       info['id'],
-            'title':    title,
+            'uploader': info['user']['username'],
-            'description': description
+            'description': info['description'],
-    def report_webpage(self, video_id):
+    def report_resolve(self, video_id):
-        self._downloader.to_screen(u'[%s] %s: Downloading webpage' % (self.IE_NAME, video_id))
+        self._downloader.to_screen(u'[%s] %s: Resolving id' % (self.IE_NAME, video_id))
-        self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, video_id))
+        self._downloader.to_screen(u'[%s] %s: Retrieving stream' % (self.IE_NAME, video_id))
-        self.report_webpage('%s/%s' % (uploader, slug_title))
+        self.report_resolve('%s/%s' % (uploader, slug_title))
-        request = compat_urllib_request.Request(url)
+        url = 'http://soundcloud.com/%s/%s' % (uploader, slug_title)
-            webpage = webpage_bytes.decode('utf-8')
+            info_json_bytes = compat_urllib_request.urlopen(request).read()
-            self._downloader.trouble(u'ERROR: unable to find video ID in Soundcloud file')
+        streams_url = 'https://api.sndcdn.com/i1/tracks/' + str(video_id) + '/streams?client_id=b45b1aa10f1ac2941910a7f0d10f8e28'
-            urlo = compat_urllib_request.urlopen(request).read()
+            webpage_bytes = compat_urllib_request.urlopen(request).read()
-        request = compat_urllib_request.Request('http://soundcloud.com/%s/%s' % (uploader, slug_title))
+        url = 'https://soundcloud.com/%s/%s' % (uploader, slug_title)
-            webpage_bytes = compat_urllib_request.urlopen(request).read()
+            urlo = compat_urllib_request.urlopen(request).read()
-            dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(title)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(extractor)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout.')
+            dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(title)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(extractor)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout. Can also be used to download to a different directory, for example with -o \'/my/downloads/%(uploader)s/%(title)s-%(id)s.%(ext)s\' .')
-    _VALID_URL = r'(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:(?:course|view_play_list|my_playlists|artist|playlist)\?.*?(p|a|list)=|user/.*?/user/|p/|user/.*?#[pg]/c/)(?:PL|EC)?|PL|EC)([0-9A-Za-z-_]+)(?:/.*?/([0-9A-Za-z_-]+))?.*'
+    _VALID_URL = r'(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:(?:course|view_play_list|my_playlists|artist|playlist)\?.*?(p|a|list)=|user/.*?/user/|p/|user/.*?#[pg]/c/)(?:PL|EC)?|PL|EC)([0-9A-Za-z-_]{10,})(?:/.*?/([0-9A-Za-z_-]+))?.*'
-        filename = 'aUehQsCQtM.flv'
+        filename = '_aUehQsCQtM.flv'
-            os.remove('aUehQsCQtM.flv')
+        if os.path.exists('_aUehQsCQtM.flv'):
-            template_dict = dict((k, sanitize_filename(compat_str(v), self.params.get('restrictfilenames'))) for k,v in template_dict.items())
+            sanitize = lambda k,v: sanitize_filename(
-def sanitize_filename(s, restricted=False):
+def sanitize_filename(s, restricted=False, is_id=False):
-        result = '_'
+    if not is_id:
-    unittest.main()
+    @_skip_unless(youtube_dl.InfoExtractors.YoukuIE._WORKING, "IE marked as not _WORKING")
-        uploader = mobj.group(1).decode('utf-8')
+        uploader = mobj.group(1)
-        slug_title =  mobj.group(2).decode('utf-8')
+        slug_title =  mobj.group(2)
-            webpage = compat_urllib_request.urlopen(request).read()
+            webpage_bytes = compat_urllib_request.urlopen(request).read()
-            title = mobj.group(1).decode('utf-8')
+            title = mobj.group(1)
-            'id':       video_id.decode('utf-8'),
+            'id':       video_id,
-            'uploader': uploader.decode('utf-8'),
+            'uploader': uploader,
-            'description': description.decode('utf-8')
+            'description': description
-        self.assertEqual(md5_for_file, '93c24d2f4e0782af13b8a7606ea97ba7')
+        self.assertEqual(md5_for_file, '4962f94441605832eb1008eb820ef47a')
-        self.assertEqual(md5_for_file, '1ab4dedc01f771cb2a65e91caa801aaf')
+        self.assertEqual(md5_for_file, 'aecab2ea59b7996110a7e409f0c55da3')
-        self.assertEqual(md5_for_file, 'ce3775768ebb6432fa8495d446a078ed')
+        self.assertEqual(md5_for_file, 'c1b9b9ea8bfd620b96b2628664576e1c')
-        self.assertEqual(md5_for_file, '22c8206291368c4e2c9c1a307f0ea0f4')
+        self.assertEqual(md5_for_file, '8aac7873a07dcfaed66b1559ab128514')
-        self.assertEqual(md5_for_file, '5f0469c8d1dfd1bc38c8e6deb5e0a21d')
+        self.assertEqual(md5_for_file, 'c5c67df477eb0d9b058200351448ba4c')
-    print >> sys.stderr, "Cannot import py2exe"
+    print("Cannot import py2exe", file=sys.stderr)
-execfile('youtube_dl/version.py')
+exec(compile(open('youtube_dl/version.py').read(), 'youtube_dl/version.py', 'exec'))
-from distutils.core import setup, Command
+from distutils.core import setup
-"""
+    print >> sys.stderr, "Cannot import py2exe"
-options = {
+py2exe_options = {
-console = [{
+py2exe_console = [{
-init_file = open('./youtube_dl/__init__.py')
+execfile('youtube_dl/version.py')
-    version = ''
+setup(
-)
+    test_suite = 'nose.collector',
-#shutil.rmtree("build")
+    console = py2exe_console,
-__version__ = '2012.11.29'
+from .version import __version__
-            def wfunc(*args, **kwargs):
+            # Start the function name with test to appease nosetests-2.6
-            return wfunc
+            return test_wfunc
-            def wfunc(*args, **kwargs):
+            # Start the function name with test to appease nosetests-2.6
-            return wfunc
+            return test_wfunc
-# Execute with python -m youtube_dl
+# Execute with
-from distutils.core import setup
+from distutils.core import setup, Command
-import os
+   The test suite can be run with
-    sys.argv.append("py2exe")
+#if len(sys.argv) == 1:
-      description='Small command-line program to download videos from YouTube.com and other video sites',
+      long_description='Small command-line program to download videos from YouTube.com and other video sites',
-      zipfile = None,
+      #test suite
-shutil.rmtree("build")
+#import shutil
-                write('@unittest.skip("No output file specified")')
+            write('@_skip_unless(youtube_dl.InfoExtractors.' + name + 'IE._WORKING, "IE marked as not _WORKING")')
-                write('@unittest.skip(' + repr(d['skip']) + ')')
+                write('@_skip(' + repr(d['skip']) + ')')
-            write('    fd.add_info_extractor(' + name + 'IE())')
+            write('    fd.add_info_extractor(youtube_dl.InfoExtractors.' + name + 'IE())')
-        fd.add_info_extractor(YoutubeIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.YoutubeIE())
-        fd.add_info_extractor(DailymotionIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.DailymotionIE())
-        fd.add_info_extractor(MetacafeIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.MetacafeIE())
-        fd.add_info_extractor(BlipTVIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.BlipTVIE())
-        fd.add_info_extractor(XVideosIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.XVideosIE())
-    @unittest.skip("No output file specified")
+    @_skip_unless(youtube_dl.InfoExtractors.VimeoIE._WORKING, "IE marked as not _WORKING")
-        fd.add_info_extractor(VimeoIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.VimeoIE())
-        fd.add_info_extractor(SoundcloudIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.SoundcloudIE())
-        fd.add_info_extractor(StanfordOpenClassroomIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.StanfordOpenClassroomIE())
-    @unittest.skip("IE marked as not _WORKING")
+    @_skip_unless(youtube_dl.InfoExtractors.CollegeHumorIE._WORKING, "IE marked as not _WORKING")
-        fd.add_info_extractor(CollegeHumorIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.CollegeHumorIE())
-        fd.add_info_extractor(XNXXIE())
+        fd.add_info_extractor(youtube_dl.InfoExtractors.XNXXIE())
-"""This will create an exe that needs Microsoft Visual C++ 2008 Redistributable Package"""
+"""The p2exe option will create an exe that needs Microsoft Visual C++ 2008 Redistributable Package.
-sys.path.append('./youtube_dl')
+#sys.path.append('./youtube_dl')
-else:
+
-import sys, os
+import sys
-      
+
-    BLIP_MD5 = "93c24d2f4e0782af13b8a7606ea97ba7"
+    BLIP_MD5 = "4962f94441605832eb1008eb820ef47a"
-    XVIDEO_MD5 = "1ab4dedc01f771cb2a65e91caa801aaf"
+    XVIDEO_MD5 = "aecab2ea59b7996110a7e409f0c55da3"
-    SOUNDCLOUD_MD5 = "ce3775768ebb6432fa8495d446a078ed"
+    SOUNDCLOUD_MD5 = "c1b9b9ea8bfd620b96b2628664576e1c"
-    STANDFORD_MD5 = "22c8206291368c4e2c9c1a307f0ea0f4"
+    STANDFORD_MD5 = "8aac7873a07dcfaed66b1559ab128514"
-    XNXX_MD5 = "5f0469c8d1dfd1bc38c8e6deb5e0a21d"
+    XNXX_MD5 = "c5c67df477eb0d9b058200351448ba4c"
-            return md5.hexdigest()
+        return md5.hexdigest()
-                    raise UnavailableVideoError
+                    raise UnavailableVideoError()
-            print(ie.IE_NAME)
+            print(ie.IE_NAME + (' (CURRENTLY BROKEN)' if not ie._WORKING else ''))
-import unittest
+#!/usr/bin/env python
-from youtube_dl.InfoExtractors import  CollegeHumorIE, XNXXIE
+import youtube_dl.InfoExtractors
-        self.assertEqual(os.path.getsize(DownloadTest.YOUTUBE_FILE), DownloadTest.YOUTUBE_SIZE)
+    PARAMETERS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "parameters.json")
-            fd = FileDownloader(json.load(f))
+    def setUp(self):
-            fd = FileDownloader(json.load(f))
+        fd.download(['http://www.dailymotion.com/video/x33vw9_tutoriel-de-youtubeur-dl-des-video_tech'])
-            fd = FileDownloader(json.load(f))
+        fd.add_info_extractor(youtube_dl.InfoExtractors.YoutubeIE())
-            fd = FileDownloader(json.load(f))
+        fd.download(['http://blip.tv/cbr/cbr-exclusive-gotham-city-imposters-bats-vs-jokerz-short-3-5796352'])
-            fd = FileDownloader(json.load(f))
+        fd.download(['http://www.xvideos.com/video939581/funny_porns_by_s_-1'])
-            fd = FileDownloader(json.load(f))
+        fd.download(['http://vimeo.com/14160053'])
-            fd = FileDownloader(json.load(f))
+        fd.download(['http://soundcloud.com/ethmusic/lostin-powers-she-so-heavy'])
-            fd = FileDownloader(json.load(f))
+        fd.download(['http://openclassroom.stanford.edu/MainFolder/VideoPage.php?course=PracticalUnix&video=intro-environment&speed=100'])
-            fd = FileDownloader(json.load(f))
+        fd.download(['http://www.collegehumor.com/video/6830834/mitt-romney-style-gangnam-style-parody'])
-        self.assertEqual(md5_down_file, DownloadTest.XNXX_MD5)
+        fd.download(['http://video.xnxx.com/video1135332/lida_naked_funny_actress_5_'])
-            return md5.hexdigest()
+    def tearDown(self):
-if sys.version_info < (3,0):
+if sys.version_info < (3, 0):
-        tests =_compat_str('a\xe4b\u4e2d\u56fd\u7684c')
+        tests = _compat_str('a\xe4b\u4e2d\u56fd\u7684c')
-        self.assertTrue(sanitize_filename(_compat_str('\xf6'), restricted=True) != '') # No empty filename
+        self.assertTrue(sanitize_filename(_compat_str('\xf6'), restricted=True) != '')  # No empty filename
-        forbidden = '"\0\\/&!: \'\t\n'
+        forbidden = '"\0\\/&!: \'\t\n()[]{}$;`^,#'
-        self.assertEqual(orderedSet([1,1,2,3,4,4,5,6,7,3,5]), [1,2,3,4,5,6,7])
+        self.assertEqual(orderedSet([1, 1, 2, 3, 4, 4, 5, 6, 7, 3, 5]), [1, 2, 3, 4, 5, 6, 7])
-        self.assertEqual(orderedSet([135,1,1,1]), [135,1])
+        self.assertEqual(orderedSet([135, 1, 1, 1]), [135, 1])
-        if restricted and (char in '!&\'' or char.isspace()):
+        if restricted and (char in '!&\'()[]{}$;`^,#' or char.isspace()):
-    METACAFE_FILE = "_aUehQsCQtM.flv"
+    METACAFE_FILE = "aUehQsCQtM.flv"
-                                            self._video_dimensions.get(format_param, '???'))
+            video_format = '{0} - {1}'.format(format_param if format_param else video_extension,
-    def report_webpage(self, video_id):
+    def report_manifest(self, video_id):
-        self._downloader.to_screen(u'[%s] %s: Downloading webpage' % (self.IE_NAME, video_id))
+        self._downloader.to_screen(u'[%s] %s: Downloading XML manifest' % (self.IE_NAME, video_id))
-        xmlUrl = 'http://www.collegehumor.com/moogaloop/video:' + internal_video_id
+        xmlUrl = 'http://www.collegehumor.com/moogaloop/video/' + video_id
-            info['ext'] = info['url'].rpartition('.')[2]
+            manifest_url = videoNode.findall('./file')[0].text
-# -*- coding: utf-8 -*-
+
-from utils import *
+from .utils import *
-from utils import *
+from .utils import *
-from utils import *
+from .utils import *
-from PostProcessor import *
+from .utils import *
-import __init__
+import youtube_dl
-    __init__.main()
+    youtube_dl.main()
-			os.remove(DownloadTest.XNXX_FILE)
+    PARAMETERS_FILE = "test/parameters.json"
-			return md5.hexdigest()
+    with open(filename) as f:
-		subprocess.check_call([sys.executable, '-c', 'import youtube_dl'], cwd=rootDir)
+    def test_import(self):
-	unittest.main()
+    unittest.main()
-	_compat_str = lambda b: b.decode('unicode-escape')
+    _compat_str = lambda b: b.decode('unicode-escape')
-	_compat_str = lambda s: s
+    _compat_str = lambda s: s
-		self.assertEqual(unescapeHTML(_compat_str('%20;')), _compat_str('%20;'))
+    def test_timeconvert(self):
-	unittest.main()
+    unittest.main()
-	import ctypes
+    import ctypes
-		return True
+    """File Downloader class.
-	"""Information Extractor class.
+    """Information Extractor class.
-	other possible outcomes.
+    Information extractors are the classes that, given a URL, extract
-	The dictionaries must include the following fields:
+    The dictionaries must include the following fields:
-	ext:            Video filename extension.
+    id:             Video identifier.
-	The following fields are optional:
+    The following fields are optional:
-	                like returned by urllib.request.urlopen
+    format:         The video format, defaults to ext (used for --get-format)
-	The fields should all be Unicode strings.
+    The fields should all be Unicode strings.
-	Probably, they should also be added to the list of extractors.
+    Subclasses of this one should re-define the _real_initialize() and
-	described above.
+    _real_extract() must return a *list* of information dictionaries as
-	"""
+    Finally, the _WORKING attribute should be set to False for broken IEs
-	_WORKING = True
+    _ready = False
-		self.set_downloader(downloader)
+    def __init__(self, downloader=None):
-		return re.match(self._VALID_URL, url) is not None
+    def suitable(self, url):
-		return self._WORKING
+    def working(self):
-			self._ready = True
+    def initialize(self):
-		return self._real_extract(url)
+    def extract(self, url):
-		self._downloader = downloader
+    def set_downloader(self, downloader):
-		pass
+    def _real_initialize(self):
-		pass
+    def _real_extract(self, url):
-		return results
+    """Information extractor for youtube.com."""
-		}]
+    """Information Extractor for metacafe.com."""
-		}]
+    """Information Extractor for Dailymotion"""
-		}]
+    """Information extractor for video.google.com."""
-		}]
+    """Information extractor for photobucket.com."""
-		}]
+    """Information extractor for video.yahoo.com."""
-		}]
+    """Information extractor for vimeo.com."""
-		return [info]
+    """arte.tv information extractor."""
-		}]
+    """Generic last-resort information extractor."""
-		return
+    """Information Extractor for YouTube search queries."""
-			pagenum = pagenum + 1
+    """Information Extractor for Google Video search queries."""
-			pagenum = pagenum + 1
+    """Information Extractor for Yahoo! Video search queries."""
-		return
+    """Information Extractor for YouTube playlists."""
-		return
+    """Information Extractor for YouTube channels."""
-	"""Information Extractor for YouTube users."""
+    """Information Extractor for YouTube users."""
-	IE_NAME = u'youtube:user'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?youtube\.com/user/)|ytuser:)([A-Za-z0-9_-]+)'
-		InfoExtractor.__init__(self, downloader)
+    def __init__(self, downloader=None):
-				(username, start_index, start_index + self._GDATA_PAGE_SIZE))
+    def report_download_page(self, username, start_index):
-			return
+    def _real_extract(self, url):
-		username = mobj.group(1)
+        username = mobj.group(1)
-		# all of them.
+        # Download video ids using YouTube Data API. Result size per
-		pagenum = 0
+        video_ids = []
-			self.report_download_page(username, start_index)
+        while True:
-			request = compat_urllib_request.Request(self._GDATA_URL % (username, self._GDATA_PAGE_SIZE, start_index))
+            request = compat_urllib_request.Request(self._GDATA_URL % (username, self._GDATA_PAGE_SIZE, start_index))
-				return
+            try:
-			ids_in_page = []
+            # Extract video identifiers
-					ids_in_page.append(mobj.group(1))
+            for mobj in re.finditer(self._VIDEO_INDICATOR, page):
-			video_ids.extend(ids_in_page)
+            video_ids.extend(ids_in_page)
-			# again.
+            # A little optimization - if current page is not
-				break
+            if len(ids_in_page) < self._GDATA_PAGE_SIZE:
-			pagenum += 1
+            pagenum += 1
-		playlistend = self._downloader.params.get('playlistend', -1)
+        all_ids_count = len(video_ids)
-			video_ids = video_ids[playliststart:playlistend]
+        if playlistend == -1:
-				(username, all_ids_count, len(video_ids)))
+        self._downloader.to_screen(u"[youtube] user %s: Collected %d video ids (downloading %d of them)" %
-			self._downloader.download(['http://www.youtube.com/watch?v=%s' % video_id])
+        for video_id in video_ids:
-	"""Information Extractor for blip.tv users."""
+    """Information Extractor for blip.tv users."""
-	IE_NAME = u'blip.tv:user'
+    _VALID_URL = r'(?:(?:(?:https?://)?(?:\w+\.)?blip\.tv/)|bliptvuser:)([^/]+)/*$'
-		InfoExtractor.__init__(self, downloader)
+    def __init__(self, downloader=None):
-				(self.IE_NAME, username, pagenum))
+    def report_download_page(self, username, pagenum):
-			return
+    def _real_extract(self, url):
-		username = mobj.group(1)
+        username = mobj.group(1)
-		page_base = 'http://m.blip.tv/pr/show_get_full_episode_list?users_id=%s&lite=0&esi=1'
+        page_base = 'http://m.blip.tv/pr/show_get_full_episode_list?users_id=%s&lite=0&esi=1'
-		request = compat_urllib_request.Request(url)
+        request = compat_urllib_request.Request(url)
-			return
+        try:
-		# all of them.
+        # Download video ids using BlipTV Ajax calls. Result size per
-		pagenum = 1
+        video_ids = []
-			self.report_download_page(username, pagenum)
+        while True:
-			request = compat_urllib_request.Request( page_base + "&page=" + str(pagenum) )
+            request = compat_urllib_request.Request( page_base + "&page=" + str(pagenum) )
-				return
+            try:
-			ids_in_page = []
+            # Extract video identifiers
-					ids_in_page.append(unescapeHTML(mobj.group(1)))
+            for mobj in re.finditer(r'href="/([^"]+)"', page):
-			video_ids.extend(ids_in_page)
+            video_ids.extend(ids_in_page)
-			# again.
+            # A little optimization - if current page is not
-				break
+            if len(ids_in_page) < self._PAGE_SIZE:
-			pagenum += 1
+            pagenum += 1
-		playlistend = self._downloader.params.get('playlistend', -1)
+        all_ids_count = len(video_ids)
-			video_ids = video_ids[playliststart:playlistend]
+        if playlistend == -1:
-				(self.IE_NAME, username, all_ids_count, len(video_ids)))
+        self._downloader.to_screen(u"[%s] user %s: Collected %d video ids (downloading %d of them)" %
-			self._downloader.download([u'http://blip.tv/'+video_id])
+        for video_id in video_ids:
-		}]
+    """Information extractor for depositfiles.com"""
-		return results
+    """Information Extractor for Facebook"""
-		return [info]
+    """Information extractor for blip.tv"""
-		}]
+    """Information Extractor for myvideo.de."""
-		return results
+    """Information extractor for The Daily Show and Colbert Report """
-		return [info]
+    """Information extractor for The Escapist """
-		return [info]
+    """Information extractor for collegehumor.com"""
-	"""Information extractor for xvideos.com"""
+    """Information extractor for xvideos.com"""
-	IE_NAME = u'xvideos'
+    _VALID_URL = r'^(?:https?://)?(?:www\.)?xvideos\.com/video([0-9]+)(?:.*)'
-		self._downloader.to_screen(u'[%s] %s: Downloading webpage' % (self.IE_NAME, video_id))
+    def report_webpage(self, video_id):
-		self._downloader.to_screen(u'[%s] %s: Extracting information' % (self.IE_NAME, video_id))
+    def report_extraction(self, video_id):
-		video_id = mobj.group(1).decode('utf-8')
+    def _real_extract(self, url):
-		self.report_webpage(video_id)
+        self.report_webpage(video_id)
-			return
+        request = compat_urllib_request.Request(r'http://www.xvideos.com/video' + video_id)
-		self.report_extraction(video_id)
+        self.report_extraction(video_id)
-		video_url = compat_urllib_parse.unquote(mobj.group(1).decode('utf-8'))
+        # Extract video URL
-		video_title = mobj.group(1).decode('utf-8')
+        # Extract title
-		video_thumbnail = mobj.group(0).decode('utf-8')
+        # Extract video thumbnail
-		}
+        info = {
-		return [info]
+        return [info]
-		}]
+    """Information extractor for soundcloud.com
-		return [info]
+    """Information extractor for infoq.com"""
-		}]
+    """Information extractor for www.mixcloud.com"""
-			return results
+    """Information extractor for Stanford's Open ClassRoom"""
-		return [info]
+    """Information extractor for MTV.com"""
-		return files_info
+    _VALID_URL =  r'(?:http://)?v\.youku\.com/v_show/id_(?P<ID>[A-Za-z0-9]+)\.html'
-		}]
+    """Information extractor for xnxx.com"""
-		}]
+    """Information extractor for plus.google.com."""
-	"""Post Processor class.
+    """Post Processor class.
-	PostProcessor.
+    PostProcessor objects can be added to downloaders with their
-	of the chain is reached.
+    The chain will be stopped if one of them ever returns None or the end
-	"""
+    PostProcessor objects follow a "mutual registration" process similar
-	_downloader = None
+    _downloader = None
-		self._downloader = downloader
+    def __init__(self, downloader=None):
-		self._downloader = downloader
+    def set_downloader(self, downloader):
-		"""Run the PostProcessor.
+    def run(self, information):
-		downloaded file.
+        The "information" argument is a dictionary like the ones
-		changing some fields.
+        When this method returns None, the postprocessing chain is
-		return information # by default, do nothing
+        In addition, this method may raise a PostProcessingError
-		self.message = message
+    def __init__(self, message):
-		return information
+    def __init__(self, downloader=None, preferredcodec=None, preferredquality=None, keepvideo=False):
-	)
+    'Ricardo Garcia Gonzalez',
-			b.write("""
+    ''' Update the program file with the latest version from the repository '''
-			b.close()
+            \n""" %(exe, exe, bat))
-			sys.exit('ERROR: unable to overwrite current version')
+            os.startfile(bat)
-			sys.exit('ERROR: unable to download latest version')
+    else:
-			sys.exit('ERROR: unable to overwrite current version')
+        try:
-	downloader.to_screen(u'Updated youtube-dl. Restart youtube-dl to use the new version.')
+    downloader.to_screen(u'Updated youtube-dl. Restart youtube-dl to use the new version.')
-	return parser, opts, args
+    def _readOptions(filename_bytes):
-	]
+    """ Return a list of an instance of every supported extractor.
-	sys.exit(retcode)
+    parser, opts, args = parseOpts()
-		sys.exit(u'\nERROR: Interrupted by user')
+    try:
-	__init__.main()
+    __init__.main()
-	import urllib.request as compat_urllib_request
+    import urllib.request as compat_urllib_request
-	import urllib2 as compat_urllib_request
+    import urllib2 as compat_urllib_request
-	import urllib.error as compat_urllib_error
+    import urllib.error as compat_urllib_error
-	import urllib2 as compat_urllib_error
+    import urllib2 as compat_urllib_error
-	import urllib.parse as compat_urllib_parse
+    import urllib.parse as compat_urllib_parse
-	import urllib as compat_urllib_parse
+    import urllib as compat_urllib_parse
-	import http.cookiejar as compat_cookiejar
+    import http.cookiejar as compat_cookiejar
-	import cookielib as compat_cookiejar
+    import cookielib as compat_cookiejar
-	import html.entities as compat_html_entities
+    import html.entities as compat_html_entities
-	import htmlentitydefs as compat_html_entities
+    import htmlentitydefs as compat_html_entities
-	import html.parser as compat_html_parser
+    import html.parser as compat_html_parser
-	import HTMLParser as compat_html_parser
+    import HTMLParser as compat_html_parser
-	import http.client as compat_http_client
+    import http.client as compat_http_client
-	import httplib as compat_http_client
+    import httplib as compat_http_client
-	from urllib.parse import parse_qs as compat_parse_qs
+    from urllib.parse import parse_qs as compat_parse_qs
-		return parsed_result
+    # HACK: The following is the correct parse_qs implementation from cpython 3's stdlib.
-	compat_str = unicode # Python 2
+    compat_str = unicode # Python 2
-	compat_str = str
+    compat_str = str
-	compat_chr = unichr # Python 2
+    compat_chr = unichr # Python 2
-	compat_chr = chr
+    compat_chr = chr
-	'Accept-Language': 'en-us,en;q=0.5',
+    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0',
-	"""Get preferred encoding.
+    """Get preferred encoding.
-		pref = 'UTF-8'
+    Returns the best encoding scheme for the system, based on
-	return pref
+    return pref
-		print(s.encode(preferredencoding(), 'xmlcharrefreplace'))
+    def compat_print(s):
-		print(s)
+    def compat_print(s):
-	return (u'&%s;' % entity)
+    """Transforms an HTML entity to a character.
-		return '\n'.join(lines).strip()
+    """Modified HTMLParser that isolates a tag with the specified id"""
-	return parser.get_result()
+    """Return the content of the tag with the specified id in the passed HTML document"""
-	return html
+    """Clean an HTML snippet into a readable string"""
-		return (stream, filename)
+    """Try to open the given filename, and slightly tweak it if this fails.
-	return timestamp
+    """Convert RFC 2822 defined time string into system timestamp"""
-	return result
+    """Sanitizes a string so it could be used as part of a filename.
-	return res
+    """ Remove all duplicates from the input iterable """
-	assert type(s) == type(u'')
+    """
-	return result
+    result = re.sub(u'(?u)&(.+?);', htmlentity_transform, s)
-	"""
+    """
-	assert type(s) == type(u'')
+    assert type(s) == type(u'')
-		return s
+    # Python 3 has a Unicode API
-		return s.encode(sys.getfilesystemencoding(), 'ignore')
+    if sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:
-	"""Download Error exception.
+    """Download Error exception.
-	pass
+    This exception may be thrown by FileDownloader objects if they are not
-	"""Same File exception.
+    """Same File exception.
-	pass
+    This exception will be thrown by FileDownloader objects if they detect
-	"""Post Processing exception.
+    """Post Processing exception.
-	pass
+    This exception may be raised by PostProcessor's .run() method to
-	pass
+    """ --max-downloads limit has been reached. """
-	"""Unavailable Format exception.
+    """Unavailable Format exception.
-	pass
+    This exception will be thrown when a video is requested
-	"""Content Too Short exception.
+    """Content Too Short exception.
-	expected = None
+    This exception may be raised by FileDownloader objects when a file they
-		self.expected = expected
+    def __init__(self, downloaded, expected):
-	"""Trouble helper exception
+    """Trouble helper exception
-	"""
+    This is an exception to be handled with
-		return resp
+    """Handler for HTTP requests and responses.
-	from urlparse import parse_qs as compat_parse_qs
+	# HACK: The following is the correct parse_qs implementation from cpython 3's stdlib.
-			compat_print(info_dict['title'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['title'])
-			compat_print(info_dict['url'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['url'])
-			compat_print(info_dict['thumbnail'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['thumbnail'])
-			compat_print(info_dict['description'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['description'])
-			compat_print(filename.encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(filename)
-			compat_print(info_dict['format'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['format'])
-if sys.version < (3,0):
+if sys.version_info < (3,0):
-			print(info_dict['title'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['title'].encode(preferredencoding(), 'xmlcharrefreplace'))
-			print(info_dict['url'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['url'].encode(preferredencoding(), 'xmlcharrefreplace'))
-			print(info_dict['thumbnail'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['thumbnail'].encode(preferredencoding(), 'xmlcharrefreplace'))
-			print(info_dict['description'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['description'].encode(preferredencoding(), 'xmlcharrefreplace'))
-			print(filename.encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(filename.encode(preferredencoding(), 'xmlcharrefreplace'))
-			print(info_dict['format'].encode(preferredencoding(), 'xmlcharrefreplace'))
+			compat_print(info_dict['format'].encode(preferredencoding(), 'xmlcharrefreplace'))
-				self._downloader.trouble(u'ERROR: YouTube said: %s' % video_info['reason'][0].decode('utf-8'))
+				self._downloader.trouble(u'ERROR: YouTube said: %s' % video_info['reason'][0])
-
+if sys.version_info < (3,0):
-		sys.stderr.write((message + u'\n').encode(preferredencoding()))
+		output = message + u'\n'
-			video_webpage = compat_urllib_request.urlopen(request).read()
+			video_webpage_bytes = compat_urllib_request.urlopen(request).read()
-				video_info_webpage = compat_urllib_request.urlopen(request).read()
+				video_info_webpage_bytes = compat_urllib_request.urlopen(request).read()
-			
+		video_description = get_element_by_id("eow-description", video_webpage)
-			video_format = '{} - {}'.format(format_param.decode('utf-8') if format_param else video_extension.decode('utf-8'),
+			video_format = '{} - {}'.format(format_param if format_param else video_extension,
-				'uploader':	video_uploader.decode('utf-8'),
+				'id':		video_id,
-				'ext':		video_extension.decode('utf-8'),
+				'ext':		video_extension,
-				'thumbnail':	video_thumbnail.decode('utf-8'),
+				'thumbnail':	video_thumbnail,
-	import http.client as compat_html_client
+	import http.client as compat_http_client
-	import httplib as compat_html_client
+	import httplib as compat_http_client
-	all_urls = map(lambda url: url.strip(), all_urls)
+	all_urls = [url.strip() for url in all_urls]
-	from urllib.parse.parse_qs import parse_qs as compat_parse_qs
+	from urllib.parse import parse_qs as compat_parse_qs
-				video_info = parse_qs(video_info_webpage)
+				video_info = compat_parse_qs(video_info_webpage)
-			url_data = [parse_qs(uds) for uds in url_data_strs]
+			url_data = [compat_parse_qs(uds) for uds in url_data_strs]
-			vardict = parse_qs(mobj.group(1))
+			vardict = compat_parse_qs(mobj.group(1))
-except NameError: # Python 2
+except ImportError: # Python 2
-except NameError: # Python 2
+except ImportError: # Python 2
-except NameError: # Python 2
+except ImportError: # Python 2
-				self._downloader.to_stderr(compat_str(e))
+			except Exception as err:
-				except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+				except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-				except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+				except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-				except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+				except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error) as err:
-
+import io
-			gz = gzip.GzipFile(fileobj=StringIO.StringIO(resp.read()), mode='r')
+			gz = gzip.GzipFile(fileobj=io.BytesIO(resp.read()), mode='r')
-			gz = StringIO.StringIO(self.deflate(resp.read()))
+			gz = io.BytesIO(self.deflate(resp.read()))
-import HTMLParser
+	import html.parser as compat_html_parser
-class IDParser(HTMLParser.HTMLParser):
+compat_html_parser.locatestarttagend = re.compile(r"""<[a-zA-Z][-.a-zA-Z0-9:_]*(?:\s+(?:(?<=['"\s])[^\s/>][^\s/=>]*(?:\s*=+\s*(?:'[^']*'|"[^"]*"|(?!['"])[^>\s]*))?\s*)*)?\s*""", re.VERBOSE) # backport bugfix
-		HTMLParser.HTMLParser.__init__(self)
+		compat_html_parser.HTMLParser.__init__(self)
-			raise HTMLParser.HTMLParseError(message, self.getpos())
+			raise compat_html_parser.HTMLParseError(message, self.getpos())
-	except HTMLParser.HTMLParseError:
+	except compat_html_parser.HTMLParseError:
-
+try:
-		return unichr(htmlentitydefs.name2codepoint[entity])
+	if entity in compat_html_entities.name2codepoint:
-		return unichr(int(numstr, base))
+		return compat_chr(int(numstr, base))
-	import urllib2 as compat_urllib_parse
+	import urllib as compat_urllib_parse
-		return (re.search(ur'(?u)%\(.+?\)s', self.params['outtmpl']) is None)
+		return (re.search(u'(?u)%\\(.+?\\)s', self.params['outtmpl']) is None)
-	mobj = re.match(ur'(?u)#(x?\d+)', entity)
+	mobj = re.match(u'(?u)#(x?\\d+)', entity)
-		filename = re.sub(ur'[/<>:"\|\?\*]', u'#', filename)
+		filename = re.sub(u'[/<>:"\\|\\\\?\\*]', u'#', filename)
-	result = re.sub(ur'(?u)&(.+?);', htmlentity_transform, s)
+	result = re.sub(u'(?u)&(.+?);', htmlentity_transform, s)
-				except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		request = urllib2.Request(url, None, headers)
+		basic_request = compat_urllib_request.Request(url, None, headers)
-				data = urllib2.urlopen(request)
+				data = compat_urllib_request.urlopen(request)
-			except (urllib2.HTTPError, ) as err:
+			except (compat_urllib_error.HTTPError, ) as err:
-						data = urllib2.urlopen(basic_request)
+						data = compat_urllib_request.urlopen(basic_request)
-					except (urllib2.HTTPError, ) as err:
+					except (compat_urllib_error.HTTPError, ) as err:
-	                like returned by urllib2.urlopen
+	                like returned by urllib.request.urlopen
-		request = urllib2.Request(self._LANG_URL)
+		request = compat_urllib_request.Request(self._LANG_URL)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(self._LOGIN_URL, urllib.urlencode(login_form))
+		request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
-			login_results = urllib2.urlopen(request).read()
+			login_results = compat_urllib_request.urlopen(request).read()
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		request = urllib2.Request(self._AGE_URL, urllib.urlencode(age_form))
+		request = compat_urllib_request.Request(self._AGE_URL, compat_urllib_parse.urlencode(age_form))
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			age_results = compat_urllib_request.urlopen(request).read()
-			url = 'http://www.youtube.com/' + urllib.unquote(mobj.group(1)).lstrip('/')
+			url = 'http://www.youtube.com/' + compat_urllib_parse.unquote(mobj.group(1)).lstrip('/')
-		request = urllib2.Request('http://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id)
+		request = compat_urllib_request.Request('http://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1' % video_id)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			video_webpage = compat_urllib_request.urlopen(request).read()
-			request = urllib2.Request(video_info_url)
+			request = compat_urllib_request.Request(video_info_url)
-				video_info_webpage = urllib2.urlopen(request).read()
+				video_info_webpage = compat_urllib_request.urlopen(request).read()
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		video_uploader = urllib.unquote_plus(video_info['author'][0])
+		video_uploader = compat_urllib_parse.unquote_plus(video_info['author'][0])
-		video_title = urllib.unquote_plus(video_info['title'][0])
+		video_title = compat_urllib_parse.unquote_plus(video_info['title'][0])
-			video_thumbnail = urllib.unquote_plus(video_info['thumbnail_url'][0])
+			video_thumbnail = compat_urllib_parse.unquote_plus(video_info['thumbnail_url'][0])
-				request = urllib2.Request('http://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id)
+				request = compat_urllib_request.Request('http://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id)
-				except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+					srt_list = compat_urllib_request.urlopen(request).read()
-				request = urllib2.Request('http://www.youtube.com/api/timedtext?lang=%s&name=%s&v=%s' % (srt_lang, srt_lang_list[srt_lang], video_id))
+				request = compat_urllib_request.Request('http://www.youtube.com/api/timedtext?lang=%s&name=%s&v=%s' % (srt_lang, srt_lang_list[srt_lang], video_id))
-				except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+					srt_xml = compat_urllib_request.urlopen(request).read()
-			video_duration = urllib.unquote_plus(video_info['length_seconds'][0])
+			video_duration = compat_urllib_parse.unquote_plus(video_info['length_seconds'][0])
-		video_token = urllib.unquote_plus(video_info['token'][0])
+		video_token = compat_urllib_parse.unquote_plus(video_info['token'][0])
-		request = urllib2.Request(self._DISCLAIMER)
+		request = compat_urllib_request.Request(self._DISCLAIMER)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			disclaimer = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(self._FILTER_POST, urllib.urlencode(disclaimer_form))
+		request = compat_urllib_request.Request(self._FILTER_POST, compat_urllib_parse.urlencode(disclaimer_form))
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			disclaimer = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request('http://www.metacafe.com/watch/%s/' % video_id)
+		request = compat_urllib_request.Request('http://www.metacafe.com/watch/%s/' % video_id)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-			mediaURL = urllib.unquote(mobj.group(1))
+			mediaURL = compat_urllib_parse.unquote(mobj.group(1))
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		flashvars = urllib.unquote(mobj.group(1))
+		flashvars = compat_urllib_parse.unquote(mobj.group(1))
-		video_url = urllib.unquote(mobj.group(1)).replace('\\/', '/')
+		video_url = compat_urllib_parse.unquote(mobj.group(1)).replace('\\/', '/')
-		request = urllib2.Request('http://video.google.com/videoplay?docid=%s&hl=en&oe=utf-8' % video_id)
+		request = compat_urllib_request.Request('http://video.google.com/videoplay?docid=%s&hl=en&oe=utf-8' % video_id)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		mediaURL = urllib.unquote(mobj.group(1))
+		mediaURL = compat_urllib_parse.unquote(mobj.group(1))
-			request = urllib2.Request('http://video.google.com/videosearch?q=%s+site:video.google.com&hl=en' % abs(int(video_id)))
+			request = compat_urllib_request.Request('http://video.google.com/videosearch?q=%s+site:video.google.com&hl=en' % abs(int(video_id)))
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				webpage = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		mediaURL = urllib.unquote(mobj.group(1))
+		mediaURL = compat_urllib_parse.unquote(mobj.group(1))
-			request = urllib2.Request(url)
+			request = compat_urllib_request.Request(url)
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				webpage = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request('http://cosmos.bcst.yahoo.com/up/yep/process/getPlaylistFOP.php?node_id=' + video_id +
+		request = compat_urllib_request.Request('http://cosmos.bcst.yahoo.com/up/yep/process/getPlaylistFOP.php?node_id=' + video_id +
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		video_url = urllib.unquote(mobj.group(1) + mobj.group(2)).decode('utf-8')
+		video_url = compat_urllib_parse.unquote(mobj.group(1) + mobj.group(2)).decode('utf-8')
-		request = urllib2.Request(url, None, std_headers)
+		request = compat_urllib_request.Request(url, None, std_headers)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		next_url = 'http://%s%s' % (http_host, urllib.unquote(info.get('url')))
+		next_url = 'http://%s%s' % (http_host, compat_urllib_parse.unquote(info.get('url')))
-		next_url = urllib.unquote(info.get('url'))
+		next_url = compat_urllib_parse.unquote(info.get('url'))
-		next_url = urllib.unquote(info.get('url'))
+		next_url = compat_urllib_parse.unquote(info.get('url'))
-			'url':          urllib.unquote(info.get('url')),
+			'url':          compat_urllib_parse.unquote(info.get('url')),
-		class HeadRequest(urllib2.Request):
+		class HeadRequest(compat_urllib_request.Request):
-		class HEADRedirectHandler(urllib2.HTTPRedirectHandler):
+		class HEADRedirectHandler(compat_urllib_request.HTTPRedirectHandler):
-					raise urllib2.HTTPError(req.get_full_url(), code, msg, headers, fp) 
+					raise compat_urllib_error.HTTPError(req.get_full_url(), code, msg, headers, fp) 
-		class HTTPMethodFallback(urllib2.BaseHandler):
+		class HTTPMethodFallback(compat_urllib_request.BaseHandler):
-				return self.parent.open(urllib2.Request(req.get_full_url(), 
+				return self.parent.open(compat_urllib_request.Request(req.get_full_url(), 
-		for handler in [urllib2.HTTPHandler, urllib2.HTTPDefaultErrorHandler,
+		opener = compat_urllib_request.OpenerDirector() 
-						urllib2.HTTPErrorProcessor, urllib2.HTTPSHandler]:
+						compat_urllib_error.HTTPErrorProcessor, compat_urllib_request.HTTPSHandler]:
-		
+
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		video_url = urllib.unquote(mobj.group(1))
+		video_url = compat_urllib_parse.unquote(mobj.group(1))
-			request = urllib2.Request(result_url)
+			result_url = self._API_URL % (compat_urllib_parse.quote_plus(query), (50*pagenum)+1)
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				data = compat_urllib_request.urlopen(request).read()
-			request = urllib2.Request(result_url)
+			result_url = self._TEMPLATE_URL % (compat_urllib_parse.quote_plus(query), pagenum*10)
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				page = compat_urllib_request.urlopen(request).read()
-			request = urllib2.Request(result_url)
+			result_url = self._TEMPLATE_URL % (compat_urllib_parse.quote_plus(query), pagenum)
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				page = compat_urllib_request.urlopen(request).read()
-			request = urllib2.Request(url)
+			request = compat_urllib_request.Request(url)
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				page = compat_urllib_request.urlopen(request).read()
-			request = urllib2.Request(url)
+			request = compat_urllib_request.Request(url)
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				page = compat_urllib_request.urlopen(request).read()
-			request = urllib2.Request(self._GDATA_URL % (username, self._GDATA_PAGE_SIZE, start_index))
+			request = compat_urllib_request.Request(self._GDATA_URL % (username, self._GDATA_PAGE_SIZE, start_index))
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				page = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-			page = urllib2.urlopen(request).read().decode('utf-8')
+			page = compat_urllib_request.urlopen(request).read().decode('utf-8')
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-			request = urllib2.Request( page_base + "&page=" + str(pagenum) )
+			request = compat_urllib_request.Request( page_base + "&page=" + str(pagenum) )
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				page = compat_urllib_request.urlopen(request).read().decode('utf-8')
-		request = urllib2.Request(url, urllib.urlencode(free_download_indication))
+		request = compat_urllib_request.Request(url, compat_urllib_parse.urlencode(free_download_indication))
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-				video_info[piece] = urllib.unquote_plus(mobj.group(1).decode("unicode_escape"))
+				video_info[piece] = compat_urllib_parse.unquote_plus(mobj.group(1).decode("unicode_escape"))
-				video_urls[fmt] = urllib.unquote_plus(mobj.group(1).decode("unicode_escape"))
+				video_urls[fmt] = compat_urllib_parse.unquote_plus(mobj.group(1).decode("unicode_escape"))
-		request = urllib2.Request(self._LOGIN_URL, urllib.urlencode(login_form))
+		request = compat_urllib_request.Request(self._LOGIN_URL, compat_urllib_parse.urlencode(login_form))
-			login_results = urllib2.urlopen(request).read()
+			login_results = compat_urllib_request.urlopen(request).read()
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		request = urllib2.Request('https://www.facebook.com/video/video.php?v=%s' % video_id)
+		request = compat_urllib_request.Request('https://www.facebook.com/video/video.php?v=%s' % video_id)
-			page = urllib2.urlopen(request)
+			page = compat_urllib_request.urlopen(request)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		request = urllib2.Request(json_url.encode('utf-8'))
+		request = compat_urllib_request.Request(json_url.encode('utf-8'))
-			urlh = urllib2.urlopen(request)
+			urlh = compat_urllib_request.urlopen(request)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		request = urllib2.Request('http://www.myvideo.de/watch/%s' % video_id)
+		request = compat_urllib_request.Request('http://www.myvideo.de/watch/%s' % video_id)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		req = urllib2.Request(url)
+		req = compat_urllib_request.Request(url)
-			htmlHandle = urllib2.urlopen(req)
+			htmlHandle = compat_urllib_request.urlopen(req)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-			urlHandle = urllib2.urlopen(playerUrl_raw)
+			urlHandle = compat_urllib_request.urlopen(playerUrl_raw)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		indexUrl = 'http://shadow.comedycentral.com/feeds/video_player/mrss/?' + urllib.urlencode({'uri': uri})
+		indexUrl = 'http://shadow.comedycentral.com/feeds/video_player/mrss/?' + compat_urllib_parse.urlencode({'uri': uri})
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			indexXml = compat_urllib_request.urlopen(indexUrl).read()
-			configReq = urllib2.Request(configUrl)
+						compat_urllib_parse.urlencode({'uri': mediaId}))
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				configXml = compat_urllib_request.urlopen(configReq).read()
-			webPage = urllib2.urlopen(url)
+			webPage = compat_urllib_request.urlopen(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+		except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		configUrl = urllib2.unquote(configUrlMatch.group(1))
+		configUrl = compat_urllib_parse.unquote(configUrlMatch.group(1))
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			configJSON = compat_urllib_request.urlopen(configUrl).read()
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			metaXml = compat_urllib_request.urlopen(xmlUrl).read()
-		request = urllib2.Request(r'http://www.xvideos.com/video' + video_id)
+		request = compat_urllib_request.Request(r'http://www.xvideos.com/video' + video_id)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		video_url = urllib2.unquote(mobj.group(1).decode('utf-8'))
+		video_url = compat_urllib_parse.unquote(mobj.group(1).decode('utf-8'))
-		request = urllib2.Request('http://soundcloud.com/%s/%s' % (uploader, slug_title))
+		request = compat_urllib_request.Request('http://soundcloud.com/%s/%s' % (uploader, slug_title))
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request('http://media.soundcloud.com/crossdomain.xml', std_headers)
+		request = compat_urllib_request.Request('http://media.soundcloud.com/crossdomain.xml', std_headers)
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		video_url = 'rtmpe://video.infoq.com/cfx/st/' + urllib2.unquote(mobj.group(1).decode('base64'))
+		video_url = 'rtmpe://video.infoq.com/cfx/st/' + compat_urllib_parse.unquote(mobj.group(1).decode('base64'))
-				urllib2.urlopen(url)
+				compat_urllib_request.urlopen(url)
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			except (compat_urllib_error.URLError, httplib.HTTPException, socket.error) as err:
-		request = urllib2.Request(file_url)
+		request = compat_urllib_request.Request(file_url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			jsonData = compat_urllib_request.urlopen(request).read()
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				metaXml = compat_urllib_request.urlopen(xmlUrl).read()
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				coursepage = compat_urllib_request.urlopen(url).read()
-			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+				rootpage = compat_urllib_request.urlopen(rootURL).read()
-		request = urllib2.Request(url)
+		request = compat_urllib_request.Request(url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(videogen_url)
+		request = compat_urllib_request.Request(videogen_url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			metadataXml = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(info_url, None, std_headers)
+		request = compat_urllib_request.Request(info_url, None, std_headers)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			jsondata = compat_urllib_request.urlopen(request).read()
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(url).read()
-		video_url = urllib.unquote(result.group(1).decode('utf-8'))
+		video_url = compat_urllib_parse.unquote(result.group(1).decode('utf-8'))
-		request = urllib2.Request(post_url)
+		request = compat_urllib_request.Request(post_url)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-		request = urllib2.Request(video_page)
+		request = compat_urllib_request.Request(video_page)
-		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
+			webpage = compat_urllib_request.urlopen(request).read()
-	urlv = urllib2.urlopen(UPDATE_URL_VERSION)
+	urlv = compat_urllib_request.urlopen(UPDATE_URL_VERSION)
-			urlh = urllib2.urlopen(UPDATE_URL_EXE)
+			urlh = compat_urllib_request.urlopen(UPDATE_URL_EXE)
-			urlh = urllib2.urlopen(UPDATE_URL)
+			urlh = compat_urllib_request.urlopen(UPDATE_URL)
-		jar = cookielib.CookieJar()
+		jar = compat_cookiejar.CookieJar()
-			jar = cookielib.MozillaCookieJar(opts.cookiefile)
+			jar = compat_cookiejar.MozillaCookieJar(opts.cookiefile)
-	urllib2.install_opener(opener)
+	cookie_processor = compat_urllib_request.HTTPCookieProcessor(jar)
-import urllib2
+try:
-class YoutubeDLHandler(urllib2.HTTPHandler):
+class YoutubeDLHandler(compat_urllib_request.HTTPHandler):
-		ret = urllib2.addinfourl(stream, headers, url)
+		if hasattr(compat_urllib_request.addinfourl, 'getcode'):
-		except (IOError, OSError), err:
+		except (IOError, OSError) as err:
-		except (UnicodeEncodeError), err:
+		except (UnicodeEncodeError) as err:
-		except (ValueError, KeyError), err:
+		except (ValueError, KeyError) as err:
-		except (OSError, IOError), err:
+		except (OSError, IOError) as err:
-				except (OSError, IOError), err:
+				except (OSError, IOError) as err:
-				except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+				except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-				except (ContentTooShortError, ), err:
+				except (ContentTooShortError, ) as err:
-				except (PostProcessingError), err:
+				except (PostProcessingError) as err:
-			except (urllib2.HTTPError, ), err:
+			except (urllib2.HTTPError, ) as err:
-					except (urllib2.HTTPError, ), err:
+					except (urllib2.HTTPError, ) as err:
-				except (OSError, IOError), err:
+				except (OSError, IOError) as err:
-			except (IOError, OSError), err:
+			except (IOError, OSError) as err:
-			except (IOError, netrc.NetrcParseError), err:
+			except (IOError, netrc.NetrcParseError) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-				except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+				except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-				except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+				except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except ValueError, err:
+		except ValueError as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except ValueError, err:
+		except ValueError as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (IOError, netrc.NetrcParseError), err:
+			except (IOError, netrc.NetrcParseError) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (ValueError,KeyError), err:
+			except (ValueError,KeyError) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (ValueError,), err:
+		except (ValueError,) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-			except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+			except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (urllib2.URLError, httplib.HTTPException, socket.error), err:
+		except (urllib2.URLError, httplib.HTTPException, socket.error) as err:
-		except (IOError, OSError), err:
+		except (IOError, OSError) as err:
-		except (IOError, OSError), err:
+		except (IOError, OSError) as err:
-		except (IOError, OSError), err:
+		except (IOError, OSError) as err:
-		except (IOError, OSError), err:
+		except (IOError, OSError) as err:
-		except (IOError, OSError), err:
+		except (IOError, OSError) as err:
-		print std_headers['User-Agent']
+		print(std_headers['User-Agent'])
-		except (TypeError, ValueError), err:
+		except (TypeError, ValueError) as err:
-	except (TypeError, ValueError), err:
+	except (TypeError, ValueError) as err:
-	except (TypeError, ValueError), err:
+	except (TypeError, ValueError) as err:
-		except (IOError, OSError), err:
+		except (IOError, OSError) as err:
-	except (IOError, OSError), err:
+	except (IOError, OSError) as err:
-			template_dict = dict((k, sanitize_filename(u(v), self.params.get('restrictfilenames'))) for k,v in template_dict.items())
+			template_dict = dict((k, sanitize_filename(compat_str(v), self.params.get('restrictfilenames'))) for k,v in template_dict.items())
-			self.trouble(u'ERROR: unable to create directory ' + u(err))
+			self.trouble(u'ERROR: unable to create directory ' + compat_str(err))
-				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % u(err))
+				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % compat_str(err))
-			self._downloader.to_stderr(u'WARNING: unable to set language: %s' % u(err))
+			self._downloader.to_stderr(u'WARNING: unable to set language: %s' % compat_str(err))
-			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % u(err))
+			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
-					raise Trouble(u'WARNING: unable to download video subtitles: %s' % u(err))
+					raise Trouble(u'WARNING: unable to download video subtitles: %s' % compat_str(err))
-					raise Trouble(u'WARNING: unable to download video subtitles: %s' % u(err))
+					raise Trouble(u'WARNING: unable to download video subtitles: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to retrieve disclaimer: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to retrieve disclaimer: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download API page: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download API page: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve file webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve file webpage: %s' % compat_str(err))
-				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % u(err))
+				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % compat_str(err))
-			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % u(err))
+			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to read video info webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to read video info webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to find out player URL: ' + u(err))
+			self._downloader.trouble(u'ERROR: unable to find out player URL: ' + compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download episode index: ' + u(err))
+			self._downloader.trouble(u'ERROR: unable to download episode index: ' + compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download webpage: ' + u(err))
+			self._downloader.trouble(u'ERROR: unable to download webpage: ' + compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download configuration: ' + u(err))
+			self._downloader.trouble(u'ERROR: unable to download configuration: ' + compat_str(err))
-			self._downloader.trouble(u'ERROR: Invalid JSON in configuration file: ' + u(err))
+			self._downloader.trouble(u'ERROR: Invalid JSON in configuration file: ' + compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-				self._downloader.to_stderr(u(e))
+				self._downloader.to_stderr(compat_str(e))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve file: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve file: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % u(err))
+				self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download course info page: ' + u(err))
+				self._downloader.trouble(u'ERROR: unable to download course info page: ' + compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download course info page: ' + u(err))
+				self._downloader.trouble(u'ERROR: unable to download course info page: ' + compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video metadata: %s' % u(err))
+			self._downloader.trouble(u'ERROR: unable to download video metadata: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve entry webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve entry webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-	u = unicode # Python 2
+	compat_str = unicode # Python 2
-	u = str
+	compat_str = str
-
+import sys
-		self.assertEqual(sanitize_filename(u'abc_d-e'), u'abc_d-e')
+		self.assertEqual(sanitize_filename('abc'), 'abc')
-		self.assertEqual(sanitize_filename(u'123'), u'123')
+		self.assertEqual(sanitize_filename('123'), '123')
-		self.assertFalse(u'/' in sanitize_filename(u'abc/de///'))
+		self.assertEqual('abc_de', sanitize_filename('abc/de'))
-		self.assertEqual(u'this - that', sanitize_filename(u'this: that'))
+		self.assertEqual('abc_de', sanitize_filename('abc/<>\\*|de'))
-		self.assertEqual(sanitize_filename(u'ÐºÐ¸ÑÐ¸Ð»Ð»Ð¸ÑÐ°'), u'ÐºÐ¸ÑÐ¸Ð»Ð»Ð¸ÑÐ°')
+		self.assertEqual(sanitize_filename('AT&T'), 'AT&T')
-		forbidden = u'"\0\\/'
+		forbidden = '"\0\\/'
-		self.assertEqual(sanitize_filename(u'abc_d-e', restricted=True), u'abc_d-e')
+		self.assertEqual(sanitize_filename('abc', restricted=True), 'abc')
-		self.assertEqual(sanitize_filename(u'123', restricted=True), u'123')
+		self.assertEqual(sanitize_filename('123', restricted=True), '123')
-		self.assertFalse(u'/' in sanitize_filename(u'abc/de///', restricted=True))
+		self.assertEqual('abc_de', sanitize_filename('abc/de', restricted=True))
-		self.assertEqual(u'this_-_that', sanitize_filename(u'this: that', restricted=True))
+		self.assertEqual('abc_de', sanitize_filename('abc/<>\\*|de', restricted=True))
-		self.assertTrue(sanitize_filename(u'Ã¶', restricted=True) != u'') # No empty filename
+		tests =_compat_str('a\xe4b\u4e2d\u56fd\u7684c')
-		forbidden = u'"\0\\/&!: \'\t\n'
+		forbidden = '"\0\\/&!: \'\t\n'
-		self.assertEqual(sanitize_filename(u'æ»ç»: Speech', restricted=True), u'Speech')
+		self.assertEqual(sanitize_filename(_compat_str('\u5927\u58f0\u5e26 - Song'), restricted=True), 'Song')
-		self.assertTrue(sanitize_filename(u':', restricted=True) != u'')
+		self.assertTrue(sanitize_filename('-', restricted=True) != '')
-		self.assertEqual(unescapeHTML(u"%20;"), u"%20;")
+		self.assertEqual(unescapeHTML(_compat_str('%20;')), _compat_str('%20;'))
-		upload_date = u'NA'
+		upload_date = None
-			'upload_date':	u'NA',
+			'upload_date':	None,
-		video_uploader = u'NA'
+		video_uploader = None
-		video_upload_date = u'NA'
+		video_upload_date = None
-			'upload_date':	u'NA',
+			'uploader':	None,
-			'upload_date':	u'NA',
+			'upload_date':	None,
-			'upload_date':	u'NA',
+			'upload_date':	None,
-		video_upload_date = u'NA'
+		video_upload_date = None
-			'upload_date':	u'NA',
+			'upload_date':	None,
-			'upload_date':	u'NA',
+			'uploader':	None,
-		upload_date = u'NA'
+		upload_date = None
-					'upload_date': u'NA',
+					'uploader': None,
-			'upload_date':  u'NA',
+			'uploader':	None,
-			'upload_date': u'NA',
+			'upload_date': None,
-			'upload_date': u'NA',
+			'uploader': None,
-			'upload_date': u'NA',
+			'uploader': None,
-		upload_date = u'NA'
+		upload_date = None
-			'upload_date': u'NA',
+			'uploader': None,
-			'upload_date': u'NA',
+			'upload_date': None,
-				'upload_date': u'NA',
+				'uploader': None,
-				'upload_date': u'NA',
+				'uploader': None,
-				'upload_date': u'NA',
+				'uploader': None,
-			'upload_date': u'NA',
+			'upload_date': None,
-				'upload_date': u'NA',
+				'uploader': None,
-			'upload_date': u'NA',
+			'uploader': None,
-		upload_date = u'NA'
+		upload_date = None
-		uploader = u'NA'
+		uploader = None
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-			if 'b' not in self._screen_file.mode or sys.version_info[0] < 3: # Python 2 lies about the mode of sys.stdout/sys.stderr
+			if 'b' in getattr(self._screen_file, 'mode', '') or sys.version_info[0] < 3: # Python 2 lies about the mode of sys.stdout/sys.stderr
-			exponent = long(math.log(bytes, 1024.0))
+			exponent = int(math.log(bytes, 1024.0))
-		eta = long((float(total) - float(current)) / rate)
+		eta = int((float(total) - float(current)) / rate)
-								(resume_len - 100 < long(content_length) < resume_len + 100)):
+								(resume_len - 100 < int(content_length) < resume_len + 100)):
-			data_len = long(data_len) + resume_len
+			data_len = int(data_len) + resume_len
-			raise ContentTooShortError(byte_counter, long(data_len))
+			raise ContentTooShortError(byte_counter, int(data_len))
-				n = long(prefix)
+				n = int(prefix)
-				n = long(prefix)
+				n = int(prefix)
-				n = long(prefix)
+				n = int(prefix)
-			opts.retries = long(opts.retries)
+			opts.retries = int(opts.retries)
-		if len(opts) > 1: opts.insert(1, ', ')
+		if option._short_opts:
-			template_dict = dict((k, sanitize_filename(compat_str(v), self.params.get('restrictfilenames'))) for k,v in template_dict.items())
+			template_dict = dict((k, sanitize_filename(u(v), self.params.get('restrictfilenames'))) for k,v in template_dict.items())
-			self.trouble(u'ERROR: unable to create directory ' + unicode(err))
+			self.trouble(u'ERROR: unable to create directory ' + u(err))
-				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % compat_str(err))
+				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % u(err))
-			self._downloader.to_stderr(u'WARNING: unable to set language: %s' % compat_str(err))
+			self._downloader.to_stderr(u'WARNING: unable to set language: %s' % u(err))
-			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % compat_str(err))
+			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % u(err))
-					raise Trouble(u'WARNING: unable to download video subtitles: %s' % compat_str(err))
+					raise Trouble(u'WARNING: unable to download video subtitles: %s' % u(err))
-					raise Trouble(u'WARNING: unable to download video subtitles: %s' % compat_str(err))
+					raise Trouble(u'WARNING: unable to download video subtitles: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to retrieve disclaimer: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to retrieve disclaimer: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download API page: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: unable to download API page: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve file webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve file webpage: %s' % u(err))
-				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % compat_str(err))
+				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % u(err))
-			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % compat_str(err))
+			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to read video info webpage: %s' % compat_str(err))
+				self._downloader.trouble(u'ERROR: unable to read video info webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % unicode(err))
+			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to find out player URL: ' + unicode(err))
+			self._downloader.trouble(u'ERROR: unable to find out player URL: ' + u(err))
-			self._downloader.trouble(u'ERROR: unable to download episode index: ' + unicode(err))
+			self._downloader.trouble(u'ERROR: unable to download episode index: ' + u(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % unicode(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download webpage: ' + unicode(err))
+			self._downloader.trouble(u'ERROR: unable to download webpage: ' + u(err))
-			self._downloader.trouble(u'ERROR: unable to download configuration: ' + unicode(err))
+			self._downloader.trouble(u'ERROR: unable to download configuration: ' + u(err))
-			self._downloader.trouble(u'ERROR: Invalid JSON in configuration file: ' + unicode(err))
+			self._downloader.trouble(u'ERROR: Invalid JSON in configuration file: ' + u(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
-				self._downloader.to_stderr(compat_str(e))
+				self._downloader.to_stderr(u(e))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve file: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve file: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % unicode(err))
+				self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % u(err))
-				self._downloader.trouble(u'ERROR: unable to download course info page: ' + unicode(err))
+				self._downloader.trouble(u'ERROR: unable to download course info page: ' + u(err))
-				self._downloader.trouble(u'ERROR: unable to download course info page: ' + unicode(err))
+				self._downloader.trouble(u'ERROR: unable to download course info page: ' + u(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: unable to download video metadata: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: unable to download video metadata: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve entry webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve entry webpage: %s' % u(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % u(err))
-	compat_str = unicode # Python 2
+	u = unicode # Python 2
-	compat_str = str
+	u = str
-	"""Transforms an HTML entity to a Unicode character.
+	"""Transforms an HTML entity to a character.
-		return unichr(long(numstr, base))
+		return unichr(int(numstr, base))
-	@param s a string (of type unicode)
+	@param s a string
-	@param s The name of the file (of type unicode)
+	@param s The name of the file
-		if len(self.result) != 3: return None
+		if self.result is None:
-    compat_str = unicode # Python 2
+	compat_str = unicode # Python 2
-    compat_str = str
+	compat_str = str
-__version__ = '2012.11.28'
+__version__ = '2012.11.29'
-			template_dict['autonumber'] = unicode('%05d' % self._num_downloads)
+			template_dict['epoch'] = int(time.time())
-		filename = sanitize_filename(filename, self.params.get('restrictfilenames'))
+	subtitles:      The .srt file contents.
-	uploader:       Nickname of the video uploader.
+	uploader:       Nickname of the video uploader, unescaped.
-			'thumbnail':	video_thumbnail,
+					'uploader': u'NA',
-			'upload_date': None,
+			'upload_date': u'NA',
-			'upload_date': None,
+			'uploader': u'NA',
-		upload_date = None
+		upload_date = u'NA'
-			'upload_date': None,
+			'uploader': u'NA',
-				'uploader': None,
+				'uploader': u'NA',
-			'upload_date': None,
+			'uploader': u'NA',
-	ext:        Video filename extension.
+	id:             Video identifier.
-	description     One-line video description.
+	description:    One-line video description.
-	format:         The video format, defaults to ext. Used by --get-format
+	format:         The video format, defaults to ext (used for --get-format)
-		return [info]
+		return [{
-			'player_url':	None,
+		if not 'format' in info_dict:
-	description:	One-line video description.
+	information about the video (or videos) the URL refers to. This
-				'format':	(format_param is None and u'NA' or format_param.decode('utf-8')),
+				'format':	video_format,
-			'format': extension, # Extension is always(?) mp4, but seems to be flv
+			'ext': extension, # Extension is always(?) mp4, but seems to be flv
-			'format':	u'NA',
+	'Christian Albrecht',
-		forbidden = u'"\0\\/&: \'\t\n'
+		forbidden = u'"\0\\/&!: \'\t\n'
-		if restricted and (char in '&\'' or char.isspace()):
+		if restricted and (char in '!&\'' or char.isspace()):
-	
+
-		block_size = 1024
+		block_size = self.params.get('buffersize', 1024)
-			block_size = self.best_block_size(after - before, len(data_block))
+			if not self.params.get('noresizebuffer', False):
-__version__ = '2012.11.27b'
+__version__ = '2012.11.28'
-__version__ = '2012.11.27'
+__version__ = '2012.11.27b'
-		self.assertEqual(sanitize_filename(u'aÃ¤b', restricted=True), u'a_b')
+		self.assertEqual(sanitize_filename(u'aÃ¤bä¸­å½çc', restricted=True), u'a_b_c')
-			return
+			# The Colbert Report embeds the information in a without
-		            return
+				self._print_formats([i[0] for i in turls])
-            
+				if f == req_format:
-            
+
-                    
+				video_url = video_url.replace(broken_cdn, better_cdn)
-	
+
-			template_dict['epoch'] = unicode(long(time.time()))
+			template_dict['epoch'] = unicode(int(time.time()))
-		info_dict['stitle'] = sanitize_filename(info_dict['title'], self.params.get('restrictfilenames'))
+		# Keep for backwards compatibility
-		self.assertEqual(u'abc-de', sanitize_filename(u'abc/de'))
+		self.assertEqual(u'abc_de', sanitize_filename(u'abc/de'))
-		self.assertEqual(u'abc-de', sanitize_filename(u'abc/<>\\*|de'))
+		self.assertEqual(u'abc_de', sanitize_filename(u'abc/<>\\*|de'))
-		self.assertEqual(u'abc-de', sanitize_filename(u'abc/de', restricted=True))
+		self.assertEqual(u'abc_de', sanitize_filename(u'abc/de', restricted=True))
-		self.assertEqual(u'abc-de', sanitize_filename(u'abc/<>\\*|de', restricted=True))
+		self.assertEqual(u'abc_de', sanitize_filename(u'abc/<>\\*|de', restricted=True))
-			help='Avoid some characters such as "&" and spaces in filenames', default=False)
+			help='Restrict filenames to only ASCII characters, and avoid "&" and spaces in filenames', default=False)
-			return '-'
+			return '_'
-	return result.strip('-')
+	while '__' in result:
- 			format,video_url = turls[-1]
+			format,video_url = turls[-1]
-
+			# For now, just pick the highest bitrate
-			format,video_url = turls[-1]
+			
-			print "HELLO, WORLD!", video_url
+			# Patch to download from alternative CDN, which does not 
-				'player_url': playerUrl
+				'player_url': None #playerUrl
-__version__ = '2012.11.17'
+__version__ = '2012.11.27'
-			return '' if restricted else 'FOO\''
+			return '' if restricted else '\''
-			self.assertTrue(forbidden not in sanitize_filename(forbidden))
+		forbidden = u'"\0\\/'
-	subtitleslang:    Language of the subtitles to download
+	username:          Username for authentication purposes.
-		info_dict['stitle'] = sanitize_filename(info_dict['title'])
+		info_dict['stitle'] = sanitize_filename(info_dict['title'], self.params.get('restrictfilenames'))
-	"""Sanitizes a string so it could be used as part of a filename."""
+
-			return '\''
+			return '' if restricted else 'FOO\''
-			return ' -'
+			return '_-' if restricted else ' -'
-		print >>sys.stderr, message.encode(preferredencoding())
+		assert type(message) == type(u'')
-				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % str(err))
+				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % compat_str(err))
-			self._downloader.to_stderr(u'WARNING: unable to set language: %s' % str(err))
+			self._downloader.to_stderr(u'WARNING: unable to set language: %s' % compat_str(err))
-			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % str(err))
+			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
-					raise Trouble(u'WARNING: unable to download video subtitles: %s' % str(err))
+					raise Trouble(u'WARNING: unable to download video subtitles: %s' % compat_str(err))
-					raise Trouble(u'WARNING: unable to download video subtitles: %s' % str(err))
+					raise Trouble(u'WARNING: unable to download video subtitles: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to retrieve disclaimer: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to retrieve disclaimer: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to confirm age: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download API page: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download API page: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve file webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve file webpage: %s' % compat_str(err))
-				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % str(err))
+				self._downloader.to_stderr(u'WARNING: parsing .netrc: %s' % compat_str(err))
-			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % str(err))
+			self._downloader.to_stderr(u'WARNING: unable to log in: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video info webpage: %s' % compat_str(err))
-				self._downloader.trouble(u'ERROR: unable to read video info webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to read video info webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-		
+
-				self._downloader.to_stderr(str(e))
+				self._downloader.to_stderr(compat_str(e))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve file: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve file: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: unable to download video metadata: %s' % str(err))
+			self._downloader.trouble(u'ERROR: unable to download video metadata: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve entry webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve entry webpage: %s' % compat_str(err))
-			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % str(err))
+			self._downloader.trouble(u'ERROR: Unable to retrieve video webpage: %s' % compat_str(err))
-			return long(new_max)
+			return int(new_max)
-			return long(new_max)
+			return int(new_max)
-		return long(rate)
+			return int(new_min)
-		"""Parse a string indicating a byte quantity into a long integer."""
+		"""Parse a string indicating a byte quantity into an integer."""
-		return long(round(number * multiplier))
+		return int(round(number * multiplier))
-			print info_dict['title'].encode(preferredencoding(), 'xmlcharrefreplace')
+			print(info_dict['title'].encode(preferredencoding(), 'xmlcharrefreplace'))
-			print info_dict['url'].encode(preferredencoding(), 'xmlcharrefreplace')
+			print(info_dict['url'].encode(preferredencoding(), 'xmlcharrefreplace'))
-			print info_dict['thumbnail'].encode(preferredencoding(), 'xmlcharrefreplace')
+			print(info_dict['thumbnail'].encode(preferredencoding(), 'xmlcharrefreplace'))
-			print info_dict['description'].encode(preferredencoding(), 'xmlcharrefreplace')
+			print(info_dict['description'].encode(preferredencoding(), 'xmlcharrefreplace'))
-			print filename.encode(preferredencoding(), 'xmlcharrefreplace')
+			print(filename.encode(preferredencoding(), 'xmlcharrefreplace'))
-			print info_dict['format'].encode(preferredencoding(), 'xmlcharrefreplace')
+			print(info_dict['format'].encode(preferredencoding(), 'xmlcharrefreplace'))
-		print 'Available formats:'
+		print('Available formats:')
-			print '%s\t:\t%s\t[%s]' %(x, self._video_extensions.get(x, 'flv'), self._video_dimensions.get(x, '???'))
+			print('%s\t:\t%s\t[%s]' %(x, self._video_extensions.get(x, 'flv'), self._video_dimensions.get(x, '???')))
-		print 'Available formats:'
+		print('Available formats:')
-					print '%s\t%s\t[%s]' % (fmt, b, ext.split('.')[-1])
+					print('%s\t%s\t[%s]' % (fmt, b, ext.split('.')[-1]))
-					print '%s\t%s\t[%s]' % (fmt, '??', ext.split('.')[-1])
+					print('%s\t%s\t[%s]' % (fmt, '??', ext.split('.')[-1]))
-	
+
-			
+
-			
+
-			print >> b, """
+			b.write("""
-			
+			\n""" %(exe, exe, bat))
-			
+
-		#print >> sys.stderr, self.getpos()
+			template_dict['title'] = template_dict['stitle'] # Keep both for backwards compatibility
-			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(extractor)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout.')
+			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(title)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(extractor)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout.')
-			or (opts.format == '-1' and opts.usetitle and u'%(stitle)s-%(id)s-%(format)s.%(ext)s')
+			or (opts.format == '-1' and opts.usetitle and u'%(title)s-%(id)s-%(format)s.%(ext)s')
-			or (opts.usetitle and u'%(stitle)s-%(id)s.%(ext)s')
+			or (opts.usetitle and opts.autonumber and u'%(autonumber)s-%(title)s-%(id)s.%(ext)s')
-			action='store_true', dest='useliteral', help='use literal title in file name', default=False)
+			action='store_true', dest='usetitle', help='[deprecated] alias of --title', default=False)
-		parser.error(u'using title conflicts with using literal title')
+	if opts.outtmpl is not None and (opts.usetitle or opts.autonumber or opts.useid):
-	_VALID_URL = r'(?:https?://)?(?:(?:www|player).)?vimeo\.com/(?:groups/[^/]+/)?(?:videos?/)?([0-9]+)'
+	_VALID_URL = r'(?:https?://)?(?:(?:www|player).)?vimeo\.com/(?:(?:groups|album)/[^/]+/)?(?:videos?/)?([0-9]+)'
-__version__ = '2012.10.09'
+__version__ = '2012.11.17'
-				else: quality = 'sd'
+		files = { 'hd': [], 'sd': [], 'other': []}
-					%(video_id, sig, timestamp, quality, video_codec.upper())
+					%(video_id, sig, timestamp, video_quality, video_codec.upper())
-from urlparse import parse_qs
+from urlparse import parse_qs, urlparse
-
+		YouPornIE(),
-			return u'[download] "' + title + '" title did not match pattern "' + matchtitle + '"'
+		if matchtitle:
-			return u'"' + title + '" title matched reject pattern "' + rejecttitle + '"'
+		if rejecttitle:
-		print >> sys.stderr, self.getpos()
+		#print >> sys.stderr, self.getpos()
-			self._downloader.trouble(u'WARNING: unable to extract uploader nickname')
+			# lookin for official user
-		mobj = re.search(r'(?ms)By:\s*<a .*?>(.+?)<', webpage)
+		mobj = re.search(r'submitter=(.*?);', webpage)
-	postproc.add_option('--extract-audio', action='store_true', dest='extractaudio', default=False,
+	postproc.add_option('-x', '--extract-audio', action='store_true', dest='extractaudio', default=False,
-		parser.error(u'using output template conflicts with using title, literal title or auto number')
+	if opts.outtmpl is not None and (opts.useliteral or opts.usetitle or opts.autonumber or opts.useid):
-		self.assertTrue(u'de' in sanitize_filename(u'abc/de'))
+		self.assertEqual(u'abc-de', sanitize_filename(u'abc/de'))
-		self.assertTrue(u'de' in  sanitize_filename(u'abc\\de'))
+		self.assertEqual(u'abc-de', sanitize_filename(u'abc/<>\\*|de'))
-			return '_'
+		if char == '?' or ord(char) < 32 or ord(char) == 127:
-	return u''.join(map(replace_insane, s)).strip('_')
+
-		mobj = re.search(r'(?im)<span class="owner[^\"]+?">[^<]+?<a [^>]+?>([^<]+?)</a></span>', webpage)
+		mobj = re.search(r'(?im)<span class="owner[^\"]+?">[^<]+?<a [^>]+?>([^<]+?)</a>', webpage)
-        return
+		#skipped for the moment produce an error
-from youtube_dl.InfoExtractors import  CollegeHumorIE
+from youtube_dl.InfoExtractors import  CollegeHumorIE, XNXXIE
-from youtube_dl.InfoExtractors import  SoundcloudIE
+from youtube_dl.InfoExtractors import  SoundcloudIE, StanfordOpenClassroomIE
-	XVIDEO_FILE = ""
+	XVIDEO_MD5 = "1ab4dedc01f771cb2a65e91caa801aaf"
-            return md5.hexdigest()
+	with open(filename) as f:
-						more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality]
+						more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality + 'k']
-					more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality]
+					more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality + 'k']
-				'subtitles':	video_subtitles
+				'subtitles':	video_subtitles,
-	_VALID_URL = r'(?:https?://)?(?:\w+\.)?youtube\.com/(?:(?:course|view_play_list|my_playlists|artist|playlist)\?.*?(p|a|list)=|user/.*?/user/|p/|user/.*?#[pg]/c/)(?:PL|EC)?([0-9A-Za-z-_]+)(?:/.*?/([0-9A-Za-z_-]+))?.*'
+	_VALID_URL = r'(?:(?:https?://)?(?:\w+\.)?youtube\.com/(?:(?:course|view_play_list|my_playlists|artist|playlist)\?.*?(p|a|list)=|user/.*?/user/|p/|user/.*?#[pg]/c/)(?:PL|EC)?|PL|EC)([0-9A-Za-z-_]+)(?:/.*?/([0-9A-Za-z_-]+))?.*'
-				subprocess.check_output([exe, '-version'])
+				subprocess.Popen([exe, '-version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
-	YOUTUBE_MD5 = "ab62e120445e8f68e8c8fddb7bd3ed76"
+	YOUTUBE_SIZE = 1993883
-		self.assertEqual(md5_down_file, DownloadTest.YOUTUBE_MD5)
+		self.assertEqual(os.path.getsize(DownloadTest.YOUTUBE_FILE), DownloadTest.YOUTUBE_SIZE)
-from youtube_dl.InfoExtractors import VimeoIE, XVideosIE
+from youtube_dl.InfoExtractors import  MetacafeIE, BlipTVIE
-
+	METACAFE_SIZE = 5754305
-	BLIP_FILE = ""
+	BLIP_MD5 = "93c24d2f4e0782af13b8a7606ea97ba7"
-	VIMEO_FILE = ""
+	VIMEO_URL = "http://vimeo.com/3156959"
-		return
+		fd.add_info_extractor(YoutubeIE())
-		self.assertEqual(md5_down_file, DownloadTest.FACEBOOK_MD5)
+		self.assertEqual(os.path.getsize(DownloadTest.METACAFE_FILE), DownloadTest.METACAFE_SIZE)
-		with open("test/json") as f:
+		#this emulate a skip,to be 2.6 compatible
-		fd = FileDownloader({})
+		return
-		fd = FileDownloader({})
+		return
-		fd = FileDownloader({})
+		return
-		fd = FileDownloader({})
+		return
-		fd = FileDownloader({})
+		return
-		self.assertIsNone(timeconvert('bougrg'))
+		self.assertTrue(timeconvert('') is None)
-		self.assertNotIn(u'/', sanitize_filename(u'abc/de///'))
+		self.assertTrue(u'de' in sanitize_filename(u'abc/de'))
-		self.assertIn(u'de', sanitize_filename(u'abc\\de'))
+		self.assertTrue(u'de' in  sanitize_filename(u'abc\\de'))
-	YOUTUBE_MD5 = "8547978241cb87dd6782b10b8e90acc3"
+
-	YOUTUBE_FILE = "BaW_jenozKc.flv"
+	YOUTUBE_FILE = "BaW_jenozKc.mp4"
-	DAILYMOTION_MD5 = ""
+	DAILYMOTION_MD5 = "d363a50e9eb4f22ce90d08d15695bb47"
-	DAILYMOTION_FILE = ""
+	DAILYMOTION_FILE = "x33vw9.mp4"
-	PHOTOBUCKET_URL = "http://www.metacafe.com/watch/yt-bV9L5Ht9LgY/download_youtube_playlist_with_youtube_dl/"
+	PHOTOBUCKET_URL = ""
-	FACEBOOK_URL = "https://www.facebook.com/video/video.php?v=207446242657384"
+	FACEBOOK_URL = ""
-	BLIP_URL = "https://www.facebook.com/video/video.php?v=207446242657384"
+	BLIP_URL = ""
-	VIMEO_URL = "https://www.facebook.com/video/video.php?v=207446242657384"
+	VIMEO_URL = ""
-	XVIDEO_URL = "https://www.facebook.com/video/video.php?v=207446242657384"
+	XVIDEO_URL = ""
-		fd = FileDownloader({})
+		with open(DownloadTest.PARAMETERS_FILE) as f:
-		fd = FileDownloader({})
+		with open(DownloadTest.PARAMETERS_FILE) as f:
-
+	@unittest.skip("no suitable ie")
-		fd = FileDownloader({})
+		with open("test/json") as f:
-
+	@unittest.skip("no suitable url")
-
+	@unittest.skip("no suitable url")
-
+	@unittest.skip("no suitable url")
-	def cleanUp(self):
+	def tearDown(self):
-		return md5.digest()
+def md5_for_file(filename, block_size=2**20):
-from youtube_dl.InfoExtractors import FacebookIE
+from youtube_dl.InfoExtractors import FacebookIE, BlipTVIE
-	#	md5sum (GNU coreutils) 8.19
+	#md5sum (GNU coreutils) 8.19
-from youtube_dl.InfoExtractors  import YoutubeIE, DailymotionIE, MetacafeIE, PhotobucketIE
+from youtube_dl.InfoExtractors  import YoutubeIE, DailymotionIE
-from youtube_dl.InfoExtractors  import YoutubeIE, DailymotionIE, MetacafeIE
+from youtube_dl.InfoExtractors  import YoutubeIE, DailymotionIE, MetacafeIE, PhotobucketIE
-from youtube_dl.InfoExtractors  import YoutubeIE, DailymotionIE
+from youtube_dl.InfoExtractors  import YoutubeIE, DailymotionIE, MetacafeIE
-from youtube_dl.InfoExtractors  import YoutubeIE
+from youtube_dl.InfoExtractors  import YoutubeIE, DailymotionIE
-    YOUTUBE_FILE = "BaW_jenozKc.flv"
+	#calculated with md5sum:
-        self.assertEqual(md5_down_file, DownloadTest.YOUTUBE_MD5)
+	def test_youtube(self):
-            os.remove(DownloadTest.YOUTUBE_FILE)
+	def cleanUp(self):
-        return md5.digest()
+	md5 = hashlib.md5()
-        self.assertIsNone(timeconvert('bougrg'))
+	def test_timeconvert(self):
-        self.assertEqual(sanitize_filename(u'abc_d-e'), u'abc_d-e')
+	def test_sanitize_filename(self):
-        self.assertEqual(sanitize_filename(u'123'), u'123')
+		self.assertEqual(sanitize_filename(u'123'), u'123')
-        self.assertNotIn(u'/', sanitize_filename(u'abc/de///'))
+		self.assertEqual(u'abc_de', sanitize_filename(u'abc/de'))
-        self.assertIn(u'de', sanitize_filename(u'abc\\de'))
+		self.assertEqual(u'abc_de', sanitize_filename(u'abc\\de'))
-        self.assertEqual(unescapeHTML(u"%20;"), u"%20;")
+		self.assertEqual(sanitize_filename(u'Ã¤'), u'Ã¤')
-	
+
-		
+
-				
+
-			# that way it will silently go on when used with unsupporting IE 
+			# that way it will silently go on when used with unsupporting IE
-	
+
-    YOUTUBE_FILE = "u0VbyYcljx8.flv"
+    YOUTUBE_MD5 = "8547978241cb87dd6782b10b8e90acc3"
-        self.assertNotIn(u'abc', sanitize_filename(u'abc/de'))
+        self.assertEqual(u'abc_de', sanitize_filename(u'abc/de'))
-        self.assertIn(u'abc', sanitize_filename(u'abc\\de'))
+        self.assertEqual(u'abc_de', sanitize_filename(u'abc\\de'))
-        self.assertEqual(unescapeHTML(u"gre&tre&yre"), [u'gre', u'tre', u'yre'])
+#!/usr/bin/env python2
-	assert sanitize_filename(u'abc_d-e') == u'abc_d-e'
+        self.assertEqual(sanitize_filename(u'Ã¤'), u'Ã¤')
-	assert sanitize_filename(u'123') == u'123'
+    def test_ordered_set(self):
-	assert u'/' not in sanitize_filename(u'abc/de///')
+    def test_unescape_html(self):
-	assert youtube_dl._simplify_title(u'\'a_') == u'a'
+# -*- coding: utf-8 -*-
-	_VALID_URL = r'(?:https?://)?(?:\w+\.)?youtube\.com/(?:(?:course|view_play_list|my_playlists|artist|playlist)\?.*?(p|a|list)=|user/.*?/user/|p/|user/.*?#[pg]/c/)(?:PL)?([0-9A-Za-z-_]+)(?:/.*?/([0-9A-Za-z_-]+))?.*'
+	_VALID_URL = r'(?:https?://)?(?:\w+\.)?youtube\.com/(?:(?:course|view_play_list|my_playlists|artist|playlist)\?.*?(p|a|list)=|user/.*?/user/|p/|user/.*?#[pg]/c/)(?:PL|EC)?([0-9A-Za-z-_]+)(?:/.*?/([0-9A-Za-z_-]+))?.*'
-	_VIDEO_INDICATOR_TEMPLATE = r'/watch\?v=(.+?)&amp;list=.*?%s'
+	_VIDEO_INDICATOR_TEMPLATE = r'/watch\?v=(.+?)&amp;([^&"]+&amp;)*list=.*?%s'
-__version__ = '2012.09.27'
+__version__ = '2012.10.09'
-		else: max_quality = 'ldURL'
+
-			self._downloader.trouble(u'ERROR: unable to extract media URL')
+			self._downloader.trouble(u'ERROR: unable to extract video URL')
-		video_uploader = mobj.group(1)
+			self._downloader.trouble(u'WARNING: unable to extract uploader nickname')
-		return available
+		def executable(exe):
-			'upload_date':	u'NA',
+			'upload_date':	video_upload_date,
-			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(provider)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout.')
+			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(extractor)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout.')
-		video_id = mobj.group(1)
+		video_id = mobj.group(1).split('_')[0].split('?')[0]
-			mobj = re.search(r'"video_url":"(.*?)",', urllib.unquote(webpage))
+			mobj = re.search(r'"video_url":"(.*?)",', flashvars)
-	_VALID_URL = r'(?i)(?:https?://)?(?:www\.)?dailymotion\.[a-z]{2,3}/video/([^_/]+)_([^/]+)'
+	_VALID_URL = r'(?i)(?:https?://)?(?:www\.)?dailymotion\.[a-z]{2,3}/video/([^/]+)'
-		video_url = mobj.group(1).replace('\\/', '/')
+		video_url = urllib.unquote(mobj.group(1)).replace('\\/', '/')
-		mobj = re.search(r'"hqURL":"(.+?)"', flashvars)
+		if 'hqURL' in flashvars: max_quality = 'hqURL'
-		hqURL = mobj.group(1).replace('\\/', '/')
+		video_url = mobj.group(1).replace('\\/', '/')
-		# TODO: support ldurl and sdurl qualities
+		# TODO: support choosing qualities
-			'url':		hqURL.decode('utf-8'),
+			'url':		video_url.decode('utf-8'),
-		video_extension = 'flv'
+		video_extension = 'mp4'
-		mobj = re.search(r'(?i)addVariable\(\"sequence\"\s*,\s*\"([^\"]+?)\"\)', webpage)
+		mobj = re.search(r'\s*var flashvars = (.*)', webpage)
-		mobj = re.search(r',\"sdURL\"\:\"([^\"]+?)\",', sequence)
+		flashvars = urllib.unquote(mobj.group(1))
-		mediaURL = urllib.unquote(mobj.group(1)).replace('\\', '')
+		hqURL = mobj.group(1).replace('\\/', '/')
-		video_url = mediaURL
+		# TODO: support ldurl and sdurl qualities
-			'url':		video_url.decode('utf-8'),
+			'url':		hqURL.decode('utf-8'),
-			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), and %% for a literal percent. Use - to output to stdout.')
+			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), %(provider)s for the provider (youtube, metacafe, etc), %(id)s for the video id and %% for a literal percent. Use - to output to stdout.')
-	'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:5.0.1) Gecko/20100101 Firefox/5.0.1',
+	'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0',
-			dest='retries', metavar='RETRIES', help='number of retries (default is 10)', default=10)
+			dest='retries', metavar='RETRIES', help='number of retries (default is %default)', default=10)
-			action='store', dest='useragent', help='specify a custom user agent')
+			dest='user_agent', help='specify a custom user agent', metavar='UA')
-			dest='playliststart', metavar='NUMBER', help='playlist video to start at (default is 1)', default=1)
+			dest='playliststart', metavar='NUMBER', help='playlist video to start at (default is %default)', default=1)
-		
+	if opts.user_agent is not None:
-	_VIDEO_INDICATOR_TEMPLATE = r'/watch\?v=(.+?)&amp;list=(PL)?%s&'
+	_VIDEO_INDICATOR_TEMPLATE = r'/watch\?v=(.+?)&amp;list=.*?%s'
-__version__ = '2012.02.27'
+__version__ = '2012.09.27'
-			url_map = dict((ud['itag'][0], ud['url'][0]) for ud in url_data)
+			url_map = dict((ud['itag'][0], ud['url'][0] + '&signature=' + ud['sig'][0]) for ud in url_data)
-	def process_info(self, info_dict, provider):
+	def process_info(self, info_dict):
-						self.process_info(video, ie.IE_NAME)
+						self.process_info(video)
-	def process_info(self, info_dict):
+	def process_info(self, info_dict, provider):
-						self.process_info(video)
+						self.process_info(video, ie.IE_NAME)
-			'provider': IE_NAME,
+				'provider': IE_NAME,
-
+	# Set user agent
-	_VALID_URL = r'^((?:https?://)?(?:youtu\.be/|(?:\w+\.)?youtube(?:-nocookie)?\.com/)(?!view_play_list|my_playlists|artist|playlist)(?:(?:(?:v|embed|e)/)|(?:(?:watch(?:_popup)?(?:\.php)?)?(?:\?|#!?)(?:.+&)?v=))?)?([0-9A-Za-z_-]+)(?(1).+)?$'
+	_VALID_URL = r"""^
-		mobj = re.match(self._VALID_URL, url)
+		mobj = re.match(self._VALID_URL, url, re.VERBOSE)
-			help='ffmpeg/avconv audio quality specification, insert a value between 0 (highest) and 9 (lowest) or a specific bitrate like 128 (default 5)')
+			help='ffmpeg/avconv audio quality specification, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default 5)')
-
+		result = re.search(self.VIDEO_URL_RE, webpage)
-				'url': self.extract_video_url(webpage),
+				'url': video_url,
-				'title': self.extract_video_title(webpage),
+				'title': video_title,
-				'thumbnail': self.extract_video_thumbnail(webpage),
+				'thumbnail': video_thumbnail,
-			if ch is not '':
+			if ch:
-			print download_url
+
-	if sys.platform == 'win32' and sys.getwindowsversion().major >= 5:
+	if sys.platform == 'win32' and sys.getwindowsversion()[0] >= 5:
-				'id': '%s_part%d' % (video_id, index),
+				'id': '%s_part%02d' % (video_id, index),
-				'title': video_title
+				'title': video_title,
-			download_url = 'http://f.youku.com/player/getFlvPath/sid/%s_%02x/st/flv/fileid/%s?k=%s' % (sid, index, temp_fileid, key)
+			temp_fileid = '%s%02X%s' % (fileid[0:8], index, fileid[10:])
-				'id': '%s_part%02x' % (video_id, index),
+				'id': '%s_part%d' % (video_id, index),
-			format = 'flv'
+
-				'ext': u'flv',
+				'title': video_title
-	_VALID_URL = r'^((?:https?://)?(?:youtu\.be/|(?:\w+\.)?youtube(?:-nocookie)?\.com/)(?!view_play_list|my_playlists|artist|playlist)(?:(?:(?:v|embed|e)/)|(?:(?:watch(?:_popup)?(?:\.php)?)?(?:\?|#!?)(?:.+&)?v=))?)?([0-9A-Za-z_-]+)(?(1).+)?$'
+	_VALID_URL = r'^((?:https?://)?(?:youtu\.be/|(?:\w+\.)?youtube(?:-nocookie)?\.com/|tube.majestyc.net/)(?!view_play_list|my_playlists|artist|playlist)(?:(?:(?:v|embed|e)/)|(?:(?:watch(?:_popup)?(?:\.php)?)?(?:\?|#!?)(?:.+&)?v=))?)?([0-9A-Za-z_-]+)(?(1).+)?$'
-	_PAGE_SIZE = 10
+	_PAGE_SIZE = 12
-		page_base = None
+		page_base = 'http://m.blip.tv/pr/show_get_full_episode_list?users_id=%s&lite=0&esi=1'
-			page_base = "http://blip.tv" + unescapeHTML(mobj.group(1))
+			mobj = re.search(r'data-users-id="([^"]+)"', page)
-		# query is limited (currently to 10 videos) so we need to query
+		# Download video ids using BlipTV Ajax calls. Result size per
-		pagenum = 0
+		pagenum = 1
-			request = urllib2.Request( page_base + "&page=" + str(pagenum+1) )
+			request = urllib2.Request( page_base + "&page=" + str(pagenum) )
-	'User-Agent': 'iTunes/10.6.1',
+	'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:5.0.1) Gecko/20100101 Firefox/5.0.1',
-				srt_lang_list = re.findall(r'lang_code="([\w\-]+)"', srt_list)
+				srt_lang_list = re.findall(r'name="([^"]*)"[^>]+lang_code="([\w\-]+)"', srt_list)
-					srt_lang = srt_lang_list[0]
+					srt_lang = srt_lang_list.keys()[0]
-				request = urllib2.Request('http://video.google.com/timedtext?hl=en&lang=%s&v=%s' % (srt_lang, video_id))
+				request = urllib2.Request('http://www.youtube.com/api/timedtext?lang=%s&name=%s&v=%s' % (srt_lang, srt_lang_list[srt_lang], video_id))
-		mobj = re.search(r'http://(?:img.*?\.)xvideos.com/videos/thumbs/[a-fA-F0-9]/[a-fA-F0-9]/[a-fA-F0-9]/([a-fA-F0-9.]+jpg)', webpage)
+		mobj = re.search(r'http://(?:img.*?\.)xvideos.com/videos/thumbs/[a-fA-F0-9]+/[a-fA-F0-9]+/[a-fA-F0-9]+/[a-fA-F0-9]+/([a-fA-F0-9.]+jpg)', webpage)
-		video_thumbnail = mobj.group(1).decode('utf-8')
+		video_thumbnail = mobj.group(0).decode('utf-8')
-			webPageBytes = urllib2.urlopen(url).read()
+			webPage = urllib2.urlopen(url)
-	general.add_option('-b', '--buffer-size',
+	general.add_option('--buffer-size',
-			help='do not automatically adjust the buffer size', default=False)
+			help='do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.', default=False)
-		block_size = 1024
+		block_size = self.params.get('buffersize', 1024)
-			block_size = self.best_block_size(after - before, len(data_block))
+			if not self.params.get('noresizebuffer', False):
-					more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality]
+					if int(self._preferredquality) < 10:
-				more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality]
+				if int(self._preferredquality) < 10:
-			help='ffmpeg/avconv audio bitrate specification, 128k by default')
+	postproc.add_option('--audio-quality', metavar='QUALITY', dest='audioquality', default='5',
-		self._downloader.to_screen(u'[' + self._exes['avconv'] and 'avconv' or 'ffmpeg' + '] Destination: ' + new_path)
+		self._downloader.to_screen(u'[' + (self._exes['avconv'] and 'avconv' or 'ffmpeg') + '] Destination: ' + new_path)
-				self._downloader.to_stderr(u'ERROR: error running ' + self._exes['avconv'] and 'avconv' or 'ffmpeg')
+				self._downloader.to_stderr(u'ERROR: error running ' + (self._exes['avconv'] and 'avconv' or 'ffmpeg'))
-	return yield_preferredencoding().next()
+	try:
-		"""Report attempt to download playlist page with given number."""
+		"""Report attempt to download search page with given number."""
-	_MORE_PAGES_INDICATOR = r'(?m)>\s*Next\s*</a>'
+	_VIDEO_INDICATOR_TEMPLATE = r'/watch\?v=(.+?)&amp;list=(PL)?%s&'
-			srt += str(n) + '\n'
+			srt += str(n+1) + '\n'
-		request = urllib2.Request(json_url)
+		request = urllib2.Request(json_url.encode('utf-8'))
-	'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:5.0.1) Gecko/20100101 Firefox/5.0.1',
+	'User-Agent': 'iTunes/10.6.1',
-			raise AudioConversionError('ffmpeg or avconv not found. Please install avconv.')	
+			raise AudioConversionError('ffmpeg or avconv not found. Please install one.')	
-		self._downloader.to_screen(u'[ffmpeg] Destination: ' + new_path)
+		self._downloader.to_screen(u'[' + self._exes['avconv'] and 'avconv' or 'ffmpeg' + '] Destination: ' + new_path)
-				self._downloader.to_stderr(u'ERROR: error running ffmpeg')
+				self._downloader.to_stderr(u'ERROR: error running ' + self._exes['avconv'] and 'avconv' or 'ffmpeg')
-			help='convert video files to audio-only files (requires ffmpeg and ffprobe)')
+			help='convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')
-			help='ffmpeg audio bitrate specification, 128k by default')
+			help='ffmpeg/avconv audio bitrate specification, 128k by default')
-
+		self._exes = self.detect_executables()
-	def get_audio_codec(path):
+	def detect_executables():
-			cmd = ['ffprobe', '-show_streams', '--', encodeFilename(path)]
+			cmd = [self._exes['avprobe'] or self._exes['ffprobe'], '-show_streams', '--', encodeFilename(path)]
-	def run_ffmpeg(path, out_path, codec, more_opts):
+	def run_ffmpeg(self, path, out_path, codec, more_opts):
-				raise e
+		cmd = ([self._exes['avconv'] or self._exes['ffmpeg'], '-y', '-i', encodeFilename(path), '-vn']
-				more_opts = ['-absf', 'aac_adtstoasc']
+				more_opts = [self._exes['avconv'] and '-bsf:a' or '-absf', 'aac_adtstoasc']
-					more_opts += ['-ab', self._preferredquality]
+					more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality]
-				more_opts += ['-ab', self._preferredquality]
+				more_opts += [self._exes['avconv'] and '-b:a' or '-ab', self._preferredquality]
-				more_opts += ['-absf', 'aac_adtstoasc']
+				more_opts += [self._exes['avconv'] and '-bsf:a' or '-absf', 'aac_adtstoasc']
-			caption = unescapeHTML(caption) # double cycle, inentional
+			caption = unescapeHTML(caption) # double cycle, intentional
-				print str(e)
+				self._downloader.to_stderr(str(e))
-
+
-		print self.getpos()
+		print >> sys.stderr, self.getpos()
-		directory = os.path.dirname(filename)
+		directory = os.path.dirname(exe)
-			urllib.urlretrieve(UPDATE_URL_EXE, exe + '.new')
+			urlh = urllib2.urlopen(UPDATE_URL_EXE)
-			try:
+			with open(filename, 'wb') as outf:
-			webPage = urllib2.urlopen(url).read()
+			webPageBytes = urllib2.urlopen(url).read()
-		simple_title = uploader + '-' + slug_title
+		simple_title = uploader + u'-' + slug_title
-			title = mobj.group(1)
+			title = mobj.group(1).decode('utf-8')
-			'stitle':	simple_title.decode('utf-8'),
+			'title':	title,
-				'id': simplify_title(course + '_' + video),
+				'id': course + '_' + video,
-				'id': simplify_title(course),
+				'id': course,
-	return expr.sub(u'_', title).strip(u'_')
+	
-			else:
+				self.report_video_subtitles_download(video_id)
-							video_subtitles = self._closed_captions_xml_to_srt(srt_xml.decode('utf-8'))
+				if not srt_lang_list:
-					self._downloader.trouble(u'WARNING: video has no closed captions')
+					srt_lang = srt_lang_list[0]
-	return res
+import json
-	_available_formats_prefer_free = ['38', '37', '45', '22', '44', '35', '43', '34', '18', '6', '5', '17', '13']
+	_available_formats = ['38', '37', '46', '22', '45', '35', '44', '34', '18', '43', '6', '5', '17', '13']
-		if video_description: video_description = clean_html(video_description.decode('utf8'))
+		video_description = get_element_by_id("eow-description", video_webpage.decode('utf8'))
-		if video_description: video_description = clean_html(video_description.decode('utf8'))
+		video_description = get_element_by_id("description", webpage.decode('utf8'))
-
+HTMLParser.locatestarttagend = re.compile(r"""<[a-zA-Z][-.a-zA-Z0-9:_]*(?:\s+(?:(?<=['"\s])[^\s/>][^\s/=>]*(?:\s*=+\s*(?:'[^']*'|"[^"]*"|(?!['"])[^>\s]*))?\s*)*)?\s*""", re.VERBOSE) # backport bugfix
-	parser.loads(html)
+	try:
-	html = re.sub(ur'(?u)&(.+?);', htmlentity_transform, html)
+	html = _unescapeHTML(html)
-	utitle = re.sub(ur'(?u)&(.+?);', htmlentity_transform, utitle)
+	utitle = _unescapeHTML(utitle)
-	return htmlParser.unescape(s)
+	result = re.sub(ur'(?u)&(.+?);', htmlentity_transform, s)
-			caption = re.sub(ur'(?u)&(.+?);', htmlentity_transform, caption) # double cycle, inentional
+			caption = _unescapeHTML(caption)
-		video_url = re.sub(r'(?u)&(.+?);', htmlentity_transform, video_url)
+		video_url = _unescapeHTML(video_url)
-		description = unescapeHTML(descMatch.group(1))
+		description = _unescapeHTML(descMatch.group(1))
-		imgUrl = unescapeHTML(imgMatch.group(1))
+		imgUrl = _unescapeHTML(imgMatch.group(1))
-		playerUrl = unescapeHTML(playerUrlMatch.group(1))
+		playerUrl = _unescapeHTML(playerUrlMatch.group(1))
-				info['title'] = unescapeHTML(m.group(1))
+				info['title'] = _unescapeHTML(m.group(1))
-				info['description'] = unescapeHTML(m.group(1))
+				info['description'] = _unescapeHTML(m.group(1))
-					'url': 'http://openclassroom.stanford.edu/MainFolder/' + unescapeHTML(vpage),
+					'url': 'http://openclassroom.stanford.edu/MainFolder/' + _unescapeHTML(vpage),
-					'url': 'http://openclassroom.stanford.edu/MainFolder/' + unescapeHTML(cpage),
+					'url': 'http://openclassroom.stanford.edu/MainFolder/' + _unescapeHTML(cpage),
-try:
+
-	html = re.sub('<\s*br\s*/?\s*>', '\n', html)
+	html = re.sub('\s*<\s*br\s*/?\s*>\s*', '\n', html)
-			# TODO use another parser
+		video_description = get_element_by_id("eow-description", video_webpage)
-			# TODO use another parser
+		video_description = get_element_by_id("description", webpage)
-from Utils import *
+from utils import *
-from Utils import *
+from utils import *
-from Utils import *
+from utils import *
-from Utils import *
+from utils import *
-from PostProcessing import *
+from PostProcessor import *
-			return res
+"""trivialjson (https://github.com/phihag/trivialjson)"""
-		description = htmlParser.unescape(descMatch.group(1))
+		description = unescapeHTML(descMatch.group(1))
-		imgUrl = htmlParser.unescape(imgMatch.group(1))
+		imgUrl = unescapeHTML(imgMatch.group(1))
-		playerUrl = htmlParser.unescape(playerUrlMatch.group(1))
+		playerUrl = unescapeHTML(playerUrlMatch.group(1))
-
+"""This will create an exe that needs Microsoft Visual C++ 2008 Redistributable Package"""
-os.chdir(os.path.dirname(sys.argv[0]))
+# os.chdir(os.path.dirname(os.path.abspath(sys.argv[0]))) # conflict with wine-py2exe.sh
-timeout /t 5 /nobreak
+ping 127.0.0.1 -n 5 -w 1000 > NUL
-import sys
+import sys, os
-    zipfile = None,
+init_file = open('./youtube_dl/__init__.py')
-	try:
+	urlv = urllib2.urlopen(UPDATE_URL_VERSION)
-		sys.exit('ERROR: unable to download latest version')
+		except (IOError, OSError), err:
-		sys.exit('ERROR: unable to overwrite current version')
+			outf = open(filename, 'wb')
-				                       unverifiable=True) 
+					newurl = newurl.replace(' ', '%20') 
-				    
+					raise urllib2.HTTPError(req.get_full_url(), code, msg, headers, fp) 
-				                  if k.lower() not in ("content-length", "content-type"))
+								  if k.lower() not in ("content-length", "content-type"))
-				                                 unverifiable=True))
+												 headers=newheaders, 
-				        urllib2.HTTPErrorProcessor, urllib2.HTTPSHandler]:
+						HTTPMethodFallback, HEADRedirectHandler,
-				ie.extract(url)
+				videos = ie.extract(url)
-				self._downloader.trouble(u'\nERROR: unable to download video')
+			results.append({
-	def __init__(self, youtube_ie, downloader=None):
+	def __init__(self, downloader=None):
-			self._youtube_ie.extract('http://www.youtube.com/watch?v=%s' % mobj2.group(1))
+			self._downloader.download(['http://www.youtube.com/watch?v=%s' % mobj2.group(1)])
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [{
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [{
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [{
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [{
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [{
-			self._downloader.trouble(u'ERROR: unable to download video')
+		return [{
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [{
-	def __init__(self, youtube_ie, downloader=None):
+	def __init__(self, downloader=None):
-			self._youtube_ie.extract('http://www.youtube.com/watch?v=%s' % id)
+			self._downloader.download(['http://www.youtube.com/watch?v=%s' % id])
-	def __init__(self, google_ie, downloader=None):
+	def __init__(self, downloader=None):
-							self._google_ie.extract('http://video.google.com/videoplay?docid=%s' % id)
+							self._downloader.download(['http://video.google.com/videoplay?docid=%s' % id])
-					self._google_ie.extract('http://video.google.com/videoplay?docid=%s' % id)
+					self._downloader.download(['http://video.google.com/videoplay?docid=%s' % id])
-	def __init__(self, yahoo_ie, downloader=None):
+	def __init__(self, downloader=None):
-							self._yahoo_ie.extract('http://video.yahoo.com/watch/%s' % id)
+							self._downloader.download(['http://video.yahoo.com/watch/%s' % id])
-					self._yahoo_ie.extract('http://video.yahoo.com/watch/%s' % id)
+					self._downloader.download(['http://video.yahoo.com/watch/%s' % id])
-	def __init__(self, youtube_ie, downloader=None):
+	def __init__(self, downloader=None):
-			self._youtube_ie.extract(mobj.group(3))
+			self._downloader.download([mobj.group(3)])
-			self._youtube_ie.extract('http://www.youtube.com/watch?v=%s' % id)
+			self._downloader.download(['http://www.youtube.com/watch?v=%s' % id])
-	def __init__(self, youtube_ie, downloader=None):
+	def __init__(self, downloader=None):
-			self._youtube_ie.extract('http://www.youtube.com/watch?v=%s' % video_id)
+			self._downloader.download(['http://www.youtube.com/watch?v=%s' % video_id])
-			self._downloader.trouble(u'ERROR: unable to download file')
+		return [{
-				self._downloader.trouble(u'\nERROR: unable to download video')
+			results.append({
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [info]
-			self._downloader.trouble(u'\nERROR: Unable to download video')
+		return [{
-				continue
+			results.append(info)
-			self._downloader.trouble(u'\nERROR: unable to download ' + videoId)
+		return [info]
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [info]
-			self._downloader.trouble(u'\nERROR: unable to download ' + video_id)
+		return [info]
-			self._downloader.trouble(u'\nERROR: unable to download video')
+		return [{
-			self._downloader.trouble(u'\nERROR: unable to download ' + video_url)
+		return [info]
-			self._downloader.trouble(u'ERROR: unable to download file')
+		return [{
-				self._downloader.trouble(u'\nERROR: unable to download video')
+			return [info]
-
+			results = []
-				self.extract(entry['url'])
+				results += self.extract(entry['url'])
-				self.extract(entry['url'])
+				results += self.extract(entry['url'])
-			self._downloader.trouble(u'\nERROR: unable to download ' + video_id)
+		return [info]
-		MetacafeIE(youtube_ie),
+		YoutubePlaylistIE(),
-		GoogleSearchIE(google_ie),
+		GoogleIE(),
-		YahooSearchIE(yahoo_ie),
+		YahooIE(),
-		return information
+from Utils import *
-			urlh = urllib.urlopen(UPDATE_URL)
+			urlh = urllib2.urlopen(UPDATE_URL)
-# vim: set ts=4 sw=4 sts=4 noet ai si filetype=python:
+#!/usr/bin/env python
-	
+
-	
+
-	
+
-	
+
-	
+
-	_VIDEO_INDICATOR = r'/watch\?v=(.+?)&'
+	_VIDEO_INDICATOR_TEMPLATE = r'/watch\?v=(.+?)&amp;list=PL%s&'
-			for mobj in re.finditer(self._VIDEO_INDICATOR, page):
+			for mobj in re.finditer(self._VIDEO_INDICATOR_TEMPLATE % playlist_id, page):
-		video_ids = video_ids[playliststart:playlistend]
+		if playlistend == -1:
-		request = urllib2.Request("http://vimeo.com/moogaloop/load/clip:%s" % video_id, None, std_headers)
+		request = urllib2.Request(url, None, std_headers)
-			self._downloader.trouble(u'ERROR: unable to extract video title')
+		# Extract the config JSON
-		video_title = mobj.group(1).decode('utf-8')
+		
-		video_uploader = mobj.group(1).decode('utf-8')
+		video_uploader = config["video"]["owner"]["name"]
-		video_thumbnail = mobj.group(1).decode('utf-8')
+		video_thumbnail = config["video"]["thumbnail"]
-			quality = 'hd'
+		# Extract video description
-			quality = 'sd'
+			html_parser = lxml.etree.HTMLParser()
-			self._downloader.trouble(u'ERROR: unable to extract request signature expiration')
+		# Extract upload date
-		video_url = "http://vimeo.com/moogaloop/play/clip:%s/%s/%s/?q=%s" % (video_id, sig, sig_exp, quality)
+		video_url = "http://player.vimeo.com/play_redirect?clip_id=%s&sig=%s&time=%s&quality=%s&codecs=%s&type=moogaloop_local&embed_location=" \
-				'id':		video_id.decode('utf-8'),
+				'id':		video_id,
-				'upload_date':	u'NA',
+				'upload_date':	video_upload_date,
-				'description':	video_description,
+				'ext':		video_extension,
-	_MORE_PAGES_INDICATOR = r'(?m)>\s*Next\s*</a>'
+	_API_URL = 'https://gdata.youtube.com/feeds/api/videos?q=%s&start-index=%i&max-results=50&v=2&alt=jsonc'
-		pagenum = 1
+		pagenum = 0
-			result_url = self._TEMPLATE_URL % (urllib.quote_plus(query), pagenum)
+		while (50 * pagenum) < limit:
-				page = urllib2.urlopen(request).read()
+				data = urllib2.urlopen(request).read()
-				self._downloader.trouble(u'ERROR: unable to download webpage: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download API page: %s' % str(err))
-						return
+			new_ids = list(video['id'] for video in api_response['items'])
-				return
+			limit = min(n, api_response['totalItems'])
-			pagenum = pagenum + 1
+		if len(video_ids) > n:
-	_MORE_PAGES_INDICATOR = r'<span>Next</span>'
+	_VIDEO_INDICATOR = r'<a href="http://video\.google\.com/videoplay\?docid=([^"\&]+)'
-		pagenum = 1
+		pagenum = 0
-			result_url = self._TEMPLATE_URL % (urllib.quote_plus(query), pagenum)
+			result_url = self._TEMPLATE_URL % (urllib.quote_plus(query), pagenum*10)
-				if video_id not in already_seen:
+				if video_id not in video_ids:
-__version__ = '2012.02.26'
+__version__ = '2012.02.27'
-		if self.params['verbose']:
+		if self.params.get('verbose', False):
-					video_description = mobj.group(1).decode('utf-8')
+			mobj = re.search(r'<meta name="description" content="(.*?)">', video_webpage)
-__version__ = '2012.01.25'
+__version__ = '2012.02.26'
-__version__ = '2012.01.08b'
+__version__ = '2012.01.25'
-		retval = subprocess.call(basic_args + [[], ['-e', '-k', '1']][self.params.get('continuedl', False)])
+		args = basic_args + [[], ['-e', '-k', '1']][self.params.get('continuedl', False)]
-			action='store_true', dest='continue_dl', help='resume partially downloaded files', default=False)
+			action='store_true', dest='continue_dl', help='resume partially downloaded files', default=True)
-	opener = urllib2.build_opener(urllib2.ProxyHandler(), cookie_processor, YoutubeDLHandler())
+	proxy_handler = urllib2.ProxyHandler()
-	return s.encode(sys.getfilesystemencoding(), 'ignore')
+
-__version__ = '2012.01.08'
+__version__ = '2012.01.08b'
-		self._downloader.to_screen("[youtube] user %s: Collected %d video ids (downloading %d of them)" %
+		self._downloader.to_screen(u"[youtube] user %s: Collected %d video ids (downloading %d of them)" %
-	downloader.to_screen('Updating to latest version...')
+	downloader.to_screen(u'Updating to latest version...')
-				downloader.to_screen('youtube-dl is up-to-date (' + __version__ + ')')
+				downloader.to_screen(u'youtube-dl is up-to-date (' + __version__ + ')')
-	downloader.to_screen('Updated youtube-dl. Restart youtube-dl to use the new version.')
+	downloader.to_screen(u'Updated youtube-dl. Restart youtube-dl to use the new version.')
-__version__ = '2012.01.05'
+__version__ = '2012.01.08'
-		stream = open(filename, open_mode)
+		stream = open(_encodeFilename(filename), open_mode)
-		stream = open(filename, open_mode)
+		stream = open(_encodeFilename(filename), open_mode)
-    assert type(s) == type(u'')
+	"""
-    return htmlParser.unescape(s)
+def _encodeFilename(s):
-	def to_screen(self, message, skip_eol=False, ignore_encoding_errors=False):
+	def to_screen(self, message, skip_eol=False):
-				print >>self._screen_file, (u'%s%s' % (message, terminator)).encode(preferredencoding()),
+		assert type(message) == type(u'')
-				(os.path.exists(filename) and not os.path.isfile(filename)):
+				(os.path.exists(_encodeFilename(filename)) and not os.path.isfile(_encodeFilename(filename))):
-			os.rename(old_filename, new_filename)
+			os.rename(_encodeFilename(old_filename), _encodeFilename(new_filename))
-		if not os.path.isfile(filename):
+		if not os.path.isfile(_encodeFilename(filename)):
-		self.to_screen(u'[info] Writing video description to: %s' % descfn, ignore_encoding_errors=True)
+		self.to_screen(u'[info] Writing video description to: ' + descfn)
-		self.to_screen(u'[info] Video description metadata as JSON to: %s' % infofn, ignore_encoding_errors=True)
+		self.to_screen(u'[info] Video description metadata as JSON to: ' + infofn)
-		self.to_screen(u'[download] Destination: %s' % filename, ignore_encoding_errors=True)
+		self.to_screen(u'[download] Destination: ' + filename)
-			if dn != '' and not os.path.exists(dn):
+			dn = os.path.dirname(_encodeFilename(filename))
-				descfn = filename + '.description'
+				descfn = filename + u'.description'
-				descfile = open(descfn, 'wb')
+				descfile = open(_encodeFilename(descfn), 'wb')
-			infofn = filename + '.info.json'
+			infofn = filename + u'.info.json'
-				infof = open(infofn, 'wb')
+				infof = open(_encodeFilename(infofn), 'wb')
-			if self.params.get('nooverwrites', False) and os.path.exists(filename):
+			if self.params.get('nooverwrites', False) and os.path.exists(_encodeFilename(filename)):
-			prevsize = os.path.getsize(tmpfilename)
+			prevsize = os.path.getsize(_encodeFilename(tmpfilename))
-			cursize = os.path.getsize(tmpfilename)
+			cursize = os.path.getsize(_encodeFilename(tmpfilename))
-			self.to_screen(u'\r[rtmpdump] %s bytes' % os.path.getsize(tmpfilename))
+			self.to_screen(u'\r[rtmpdump] %s bytes' % os.path.getsize(_encodeFilename(tmpfilename)))
-		if self.params.get('continuedl', False) and os.path.isfile(filename) and not self.params.get('nopart', False):
+		if self.params.get('continuedl', False) and os.path.isfile(_encodeFilename(filename)) and not self.params.get('nopart', False):
-			resume_len = os.path.getsize(tmpfilename)
+		if os.path.isfile(_encodeFilename(tmpfilename)):
-				'url':		file_url.decode('utf-8'),
+				'id': file_id.decode('utf-8'),
-				'player_url':	player_url.decode('utf-8'),
+				'upload_date': u'NA',
-            self._downloader.trouble(u'\nERROR: unable to download ' + video_id)
+	"""Information extractor for MTV.com"""
-			cmd = ['ffprobe', '-show_streams', '--', path]
+			cmd = ['ffprobe', '-show_streams', '--', _encodeFilename(path)]
-		cmd = ['ffmpeg', '-y', '-i', path, '-vn'] + acodec_opts + more_opts + ['--', out_path]
+		cmd = ['ffmpeg', '-y', '-i', _encodeFilename(path), '-vn'] + acodec_opts + more_opts + ['--', _encodeFilename(out_path)]
-		self._downloader.to_screen(u'[ffmpeg] Destination: %s' % new_path)
+		prefix, sep, ext = path.rpartition(u'.') # not os.path.splitext, since the latter does not work on unicode in all setups
-				os.utime(new_path, (time.time(), information['filetime']))
+				os.utime(_encodeFilename(new_path), (time.time(), information['filetime']))
-				os.remove(path)
+				os.remove(_encodeFilename(path))
-	def _readOptions(filename):
+	def _readOptions(filename_bytes):
-			optionf = open(filename)
+			optionf = open(filename_bytes)
-__version__ = '2011.12.18'
+__version__ = '2012.01.05'
-		video_title = htmlParser.unescape(mobj.group('title')).decode('utf-8')
+		video_title = _unescapeHTML(mobj.group('title').decode('utf-8'))
-		mMovieParams = re.findall('(?:<param name="movie" value=")|(?:var url = ")(http://media.mtvnservices.com/([^"]*episode.*?:.*?))"', html)
+		mMovieParams = re.findall('(?:<param name="movie" value="|var url = ")(http://media.mtvnservices.com/([^"]*episode.*?:.*?))"', html)
-__author__  = (
+__authors__  = (
-		mMovieParams = re.findall('<param name="movie" value="(http://media.mtvnservices.com/([^"]*episode.*?:.*?))"/>', html)
+		mMovieParams = re.findall('(?:<param name="movie" value=")|(?:var url = ")(http://media.mtvnservices.com/([^"]*episode.*?:.*?))"', html)
-__version__ = '2011.12.15'
+__version__ = '2011.12.18'
-			return (ret == 0)
+			p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
-			return False
+			e = sys.exc_info()[1]
-			acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'vorbis': 'libvorbis'}[self._preferredcodec]
+			acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'vorbis': 'libvorbis', 'wav': None}[self._preferredcodec]
-			self._downloader.to_stderr(u'WARNING: error running ffmpeg')
+		try:
-			help='"best", "aac", "vorbis", "mp3", or "m4a"; best by default')
+			help='"best", "aac", "vorbis", "mp3", "m4a", or "wav"; best by default')
-		if opts.audioformat not in ['best', 'aac', 'mp3', 'vorbis', 'm4a']:
+		if opts.audioformat not in ['best', 'aac', 'mp3', 'vorbis', 'm4a', 'wav']:
-				return
+			if self.params.get('nooverwrites', False) and os.path.exists(filename):
-__version__ = '2011.12.08'
+__version__ = '2011.12.15'
-		mobj = re.search(r'(?im)<title>\s*(.+)\s*-\s*Video\s+Dailymotion</title>', webpage)
+		mobj = re.search(r'<meta property="og:title" content="(?P<title>[^"]*)" />', webpage)
-		video_title = mobj.group(1).decode('utf-8')
+		video_title = htmlParser.unescape(mobj.group('title')).decode('utf-8')
-__version__ = '2011.11.23'
+__version__ = '2011.12.08'
-				format_list = self._available_formats[self._available_formats.index(format_limit):]
+			available_formats = self._available_formats_prefer_free if self._downloader.params.get('prefer_free_formats', False) else self._available_formats
-				format_list = self._available_formats
+				format_list = available_formats
-			if filecodec in ['aac', 'mp3', 'vorbis']:
+		if self._preferredcodec == 'best' or self._preferredcodec == filecodec or (self._preferredcodec == 'm4a' and filecodec == 'aac'):
-			acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'vorbis': 'libvorbis'}[self._preferredcodec]
+			acodec = {'mp3': 'libmp3lame', 'aac': 'aac', 'm4a': 'aac', 'vorbis': 'libvorbis'}[self._preferredcodec]
-			help='"best", "aac", "vorbis" or "mp3"; best by default')
+			help='"best", "aac", "vorbis", "mp3", or "m4a"; best by default')
-		if opts.audioformat not in ['best', 'aac', 'mp3', 'vorbis']:
+		if opts.audioformat not in ['best', 'aac', 'mp3', 'vorbis', 'm4a']:
-				return
+				raise MaxDownloadsReached()
-	retcode = fd.download(all_urls)
+	
-	_VALID_URL = r'^(?:https?://)?openclassroom.stanford.edu(?P<path>/|(/MainFolder/(?:HomePage|CoursePage|VideoPage)\.php([?]course=(?P<course>[^&]+)(&video=(?P<video>[^&]+))?(&.*)?)?))$'
+	_VALID_URL = r'^(?:https?://)?openclassroom.stanford.edu(?P<path>/?|(/MainFolder/(?:HomePage|CoursePage|VideoPage)\.php([?]course=(?P<course>[^&]+)(&video=(?P<video>[^&]+))?(&.*)?)?))$'
-				self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % str(err))
+				self._downloader.trouble(u'ERROR: unable to download video info XML: %s' % unicode(err))
-			1/0
+		elif mobj.group('course'): # A course page
-		mobj = re.search(r'(?im)<title>Dailymotion\s*-\s*(.+)\s*-\s*[^<]+?</title>', webpage)
+		mobj = re.search(r'(?im)<title>\s*(.+)\s*-\s*Video\s+Dailymotion</title>', webpage)
-			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), and %% for a literal percent')
+			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), and %% for a literal percent. Use - to output to stdout.')
-	argv = _readOptions('/etc/youtube-dl.conf') + _readOptions(os.path.expanduser('~/.youtube-dl.conf')) + sys.argv[1:]
+	xdg_config_home = os.environ.get('XDG_CONFIG_HOME')
-		
+
-		max_downloads = int(self.params.get('max_downloads'))
+		max_downloads = self.params.get('max_downloads')
-			if self._num_downloads > max_downloads:
+			if self._num_downloads > int(max_downloads):
-	opts, args = parser.parse_args()
+	argv = _readOptions('/etc/youtube-dl.conf') + _readOptions(os.path.expanduser('~/.youtube-dl.conf')) + sys.argv[1:]
-		'max_downloads': int(opts.max_downloads),
+		'max_downloads': opts.max_downloads,
-			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, and %% for a literal percent')
+			dest='outtmpl', metavar='TEMPLATE', help='output filename template. Use %(stitle)s to get the title, %(uploader)s for the uploader name, %(autonumber)s to get an automatically incremented number, %(ext)s for the filename extension, %(upload_date)s for the upload date (YYYYMMDD), and %% for a literal percent')
-__version__ = '2011.11.22'
+__version__ = '2011.11.23'
-		simple_title = _simple_title(video_title)
+		simple_title = _simplify_title(video_title)
-				'stitle': self._simplify_title(effTitle),
+				'stitle': _simplify_title(effTitle),
-__version__ = '2011.11.21'
+__version__ = '2011.11.22'
-			except Exception as e:
+			except Exception, e:
-__version__ = '2011.10.19'
+__version__ = '2011.11.21'
-	#assert youtube_dl._simplify_title(u'Ã¤') == u'Ã¤'
+	assert youtube_dl._simplify_title(u'Ã¤') == u'Ã¤'
-	return re.sub(ur'[^\w\d_\-]+', u'_', title).strip(u'_')
+	expr = re.compile(ur'[^\w\d_\-]+', flags=re.UNICODE)
-				url = 'http://www.thedailyshow.com/full-episodes/'
+				url = u'http://www.thedailyshow.com/full-episodes/'
-				url = 'http://www.colbertnation.com/full-episodes/'
+				url = u'http://www.colbertnation.com/full-episodes/'
-			effTitle = showId + '-' + epTitle
+			effTitle = showId + u'-' + epTitle
-	assert youtube_dl._simplify_title('abc_d-e') == 'abc_d-e'
+	assert youtube_dl._simplify_title(u'abc') == u'abc'
-	assert 'de' in youtube_dl._simplify_title('abc/de')
+	assert youtube_dl._simplify_title(u'123') == u'123'
-	assert 'de' in youtube_dl._simplify_title('abc\\de')
+	assert u'/' not in youtube_dl._simplify_title(u'abc/de')
-	return re.sub(ur'[^\w\d_\-]+', u'_', title)
+	return re.sub(ur'[^\w\d_\-]+', u'_', title).strip(u'_')
-		simple_title = simple_title.strip(ur'_')
+		simple_title = _simplify_title(video_title)
-		simple_title = re.sub(ur'(?u)([^%s]+)' % simple_title_chars, ur'_', video_title)
+		simple_title = _simplify_title(video_title)
-		simple_title = re.sub(ur'(?u)([^%s]+)' % simple_title_chars, ur'_', video_title)
+		simple_title = _simplify_title(vide_title)
-		simple_title = re.sub(ur'(?u)([^%s]+)' % simple_title_chars, ur'_', video_title)
+		simple_title = _simplify_title(video_title)
-		simple_title = re.sub(ur'(?u)([^%s]+)' % simple_title_chars, ur'_', video_title)
+		simple_title = _simple_title(video_title)
-		simple_title = re.sub(ur'(?u)([^%s]+)' % simple_title_chars, ur'_', video_title)
+		simple_title = _simplify_title(video_title)
-		simple_title = simple_title.strip(ur'_')
+		simple_title = _simplify_title(video_title)
-					'stitle': self._simplify_title(title),
+					'stitle': _simplify_title(title),
-					'stitle': self._simplify_title(data['title']),
+					'stitle': _simplify_title(data['title']),
-		simple_title = re.sub(ur'(?u)([^%s]+)' % simple_title_chars, ur'_', simple_title)
+		simple_title = _simplify_title(video_title)
-			'stitle': self._simplify_title(showName),
+			'stitle': _simplify_title(showName),
-			info['stitle'] = self._simplify_title(info['title'])
+			info['stitle'] = _simplify_title(info['title'])
-			'stitle': self._simplify_title(video_title),
+			'stitle': _simplify_title(video_title),
-			'stitle': self._simplify_title(video_title),
+			'stitle': _simplify_title(video_title),
