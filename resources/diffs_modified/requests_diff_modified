-copyright = u'MMXVII. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'MMXVIII. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-    from .packages.urllib3.contrib import pyopenssl
+    from urllib3.contrib import pyopenssl
-    """Replace nonexistant paths that look like they refer to a member of a zip
+    """Replace nonexistent paths that look like they refer to a member of a zip
-        self.add_headers(request)
+        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
-            # The scheme should be lower case...
+            # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)
-    netloc = urlparse(url).netloc
+    parsed = urlparse(url)
-        # the end of the netloc, both with and without the port.
+        # the end of the hostname, both with and without the port.
-        if is_ipv4_address(ip):
+        if is_ipv4_address(parsed.hostname):
-                    if address_in_network(ip, proxy_ip):
+                    if address_in_network(parsed.hostname, proxy_ip):
-                elif ip == proxy_ip:
+                elif parsed.hostname == proxy_ip:
-                if netloc.endswith(host) or netloc.split(':')[0].endswith(host):
+                if parsed.hostname.endswith(host) or host_with_port.endswith(host):
-            bypass = proxy_bypass(netloc)
+            bypass = proxy_bypass(parsed.hostname)
-    monkeypatch.setenv('NO_PROXY', '192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1')
+    monkeypatch.setenv('no_proxy', '192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1, google.com:6000')
-intersphinx_mapping = {'urllib3': ('http://urllib3.readthedocs.io/en/latest', None)}
+intersphinx_mapping = {'urllib3': ('https://urllib3.readthedocs.io/en/latest', None)}
-            'multipart/form-data; boundary = something ; \"boundary2=something_else\" ; no_equals ',
+            'multipart/form-data; boundary = something ; "boundary2=something_else" ; no_equals ',
-                value = param[after_equals].strip(items_to_strip)
+                key = param[:index_of_equals].strip(items_to_strip)
-    params_dict = {} 
+    params_dict = {}
-            param = param.strip()
+        param = param.strip()
-                key, value = param_tokens[0], param_tokens[1]
+            index_of_equals = param.find("=")
-            ('application/xml', dict())
+            ('application/xml', {})
-            ('text/plain', dict())
+            ('text/plain', {})
-            ('application/json', dict())
+            'multipart/form-data; boundary = something ; \"boundary2=something_else\" ; no_equals ',
-    params_dict = {}  # Using dict is actually slower than a dictionary literal. Weird but tru
+    params_dict = {} 
-    for param in params.split(';'):
+
-        (
+def _parse_content_type_header(header):
-    content_type, params = parse_header(content_type)
+    content_type, params = _parse_content_type_header(content_type)
-    get_auth_from_url, get_encoding_from_headers,
+    get_auth_from_url, _parse_content_type_header, get_encoding_from_headers,
-
+        content_type_and_params_delimiter = ';'
-import cgi
+    def parse_header(content_type):
-    content_type, params = cgi.parse_header(content_type)
+    content_type, params = parse_header(content_type)
-            import _winreg as winreg
+        try:
-            setattr(codes, title.upper(), code)
+def _init():
-                                              'ProxyEnable')[0]
+            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it
-                return [1]
+                # this could be a string (REG_SZ) or a 32-bit number (REG_DWORD)
-        """Returns True if :attr:`status_code` is less than 400.
+        """Returns True if :attr:`status_code` is less than 400, False if not.
-        the status code, is between 200 and 400, this will return True. This
+        the status code is between 200 and 400, this will return True. This
-                         ProxyError, RetryError, InvalidSchema)
+                         ProxyError, RetryError, InvalidSchema, InvalidProxyURL)
-    ProxyError, InvalidHeader, UnrewindableBodyError, SSLError)
+    ProxyError, InvalidHeader, UnrewindableBodyError, SSLError, InvalidProxyURL)
-                    select_proxy)
+from .utils import (DEFAULT_CA_BUNDLE_PATH, extract_zipped_paths,
-                cert_loc = DEFAULT_CA_BUNDLE_PATH
+                cert_loc = extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)
-    address_in_network, dotted_netmask,
+    address_in_network, dotted_netmask, extract_zipped_paths,
-import platform
+import sys
-if platform.system() == 'Windows':
+if sys.platform == 'win32':
-import platform
+import sys
-if platform.system() == 'Windows':
+if sys.platform == 'win32':
-    def test_session_get_adapter_prefix_matching_is_case_insensitive(self, httpbin):
+    def test_session_get_adapter_prefix_matching_mixed_case(self, httpbin):
-        url_matching_prefix_with_different_case = 'HtTpS://exaMPLe.cOm/MiXeD_caSE_preFIX/another_url'
+
-            if url.lower().startswith(prefix):
+            if url.lower().startswith(prefix.lower()):
-    try:  # Python 3.3+
+    try:  # Python 3.4+
-        with open('requirements.txt') as f:
+        with open('Pipfile') as f:
-        with open('requirements.txt') as f:
+        with open('Pipfile') as f:
-        with open('requirements.txt') as f:
+        with open('Pipfile') as f:
-copyright = u'MMXVII. A <a href="http://kennethreitz.com/bitcoin">Kenneth Reitz</a> Project'
+copyright = u'MMXVII. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-    'show_related': False
+    'github_banner': True,
-html_use_smartypants = True
+html_use_smartypants = False
-copyright = u'MMXVII. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'MMXVII. A <a href="http://kennethreitz.com/bitcoin">Kenneth Reitz</a> Project'
-    'github_banner': True,
+    'github_banner': False,
-html_use_smartypants = False
+html_use_smartypants = True
-    """Return a dict of parsed link headers proxies.
+    """Return a list of parsed link headers proxies.
-__build__ = 0x021803
+__version__ = '2.18.4'
-        with pytest.raises(InvalidHeader):
+        with pytest.raises(InvalidHeader) as excinfo:
-        with pytest.raises(InvalidHeader):
+        with pytest.raises(InvalidHeader) as excinfo:
-        with pytest.raises(InvalidHeader):
+        with pytest.raises(InvalidHeader) as excinfo:
-        raise InvalidHeader("Value for header {%s:%s} must be of type str or "
+        raise InvalidHeader("Value for header {%s: %s} must be of type str or "
-        raise InvalidHeader("Value for header {%s:%s} must be of type str or " 
+        raise InvalidHeader("Value for header {%s:%s} must be of type str or "
-                            "not %s" % (name, value, type(value)))
+        raise InvalidHeader("Value for header {%s:%s} must be of type str or " 
-                            "not %s" % (value, type(value)))
+        raise InvalidHeader("Header %s value %s must be of type str or bytes, "
-    'idna>=2.5,<2.6',
+    'idna>=2.5,<2.7',
-__build__ = 0x021802
+__version__ = '2.18.3'
-    ProxyError, InvalidHeader, UnrewindableBodyError)
+    ProxyError, InvalidHeader, UnrewindableBodyError, SSLError)
-
+        # Due to the nature of how requests processes redirects this method will
-    # urllib3 >= 1.21.1, < 1.22
+    # urllib3 >= 1.21.1, <= 1.22
-__build__ = 0x021801
+__version__ = '2.18.2'
-    'urllib3>=1.21.1,<1.22',
+    'urllib3>=1.21.1,<1.23',
-        Adapters are sorted in descending order by key length.
+        Adapters are sorted in descending order by prefix length.
-        },
+        'system_ssl': system_ssl_info,
-    # because of u'...' Unicode literals.
+except ImportError:
-__build__ = 0x021800
+__version__ = '2.18.1'
-__build__ = 0x021703
+__version__ = '2.18.0'
-        Setting paramters for nonstandard schemes is allowed if those schemes
+        Setting parameters for nonstandard schemes is allowed if those schemes
-    if value is not None:
+    value_changed = value is not None
-            os.environ[env_name] = old_value
+        if value_changed:
-    urldefragauth, add_dict_to_cookiejar)
+    urldefragauth, add_dict_to_cookiejar, set_environ)
-    assert should_bypass_proxies(url, no_proxy=None) == expected
+
-    r"""Sends a OPTIONS request.
+    r"""Sends an OPTIONS request.
-try:
+import chardet
-try:
+    # Check chardet for compatibility.
-    raise RuntimeError('Requests dependency \'chardet\' must be version >= 3.0.2, < 3.1.0!')
+
-
+
-    """Return a dict with the Python implementation and verison.
+    """Return a dict with the Python implementation and version.
-        self.pytest_args = ['-n', str(cpu_count()), '--boxed']
+        try:
-    'github_user': 'kennethreitz',
+    'github_user': 'requests',
-    + "0123456789-._~")
+    "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz" + "0123456789-._~")
-        hist = [] # keep track of history
+        hist = []  # keep track of history
-        json=None):
+            params=None, data=None, headers=None, cookies=None, files=None,
-            hooks = hooks,
+            method=method.upper(),
-        return self.request('PATCH', url,  data=data, **kwargs)
+        return self.request('PATCH', url, data=data, **kwargs)
-        data=None, params=None, auth=None, cookies=None, hooks=None, json=None):
+    def __init__(self,
-        data=None, params=None, auth=None, cookies=None, hooks=None, json=None):
+    def prepare(self,
-                ])
+            ])
-                                                or cookie.path == path):
+            if (
-                )
+            )
-    return request('patch', url,  data=data, **kwargs)
+    return request('patch', url, data=data, **kwargs)
-
+from .__version__ import __title__, __description__, __url__, __version__
-__build__ = 0x021702
+__version__ = '2.17.3'
-__build__ = 0x021701
+__version__ = '2.17.2'
-    __import__(package)
+    locals()[package] = __import__(package)
-__build__ = 0x021700
+__version__ = '2.17.1'
-# Kinda cool, though, right?
+for package in ('urllib3', 'idna', 'chardet'):
-__build__ = 0x021605
+__version__ = '2.17.0'
-        # See https://github.com/kennethreitz/requests/issues/3772
+        # See https://github.com/requests/requests/issues/3772
-# such as in Embedded Python. See https://github.com/kennethreitz/requests/issues/3578.
+# such as in Embedded Python. See https://github.com/requests/requests/issues/3578.
-        #: https://github.com/kennethreitz/requests/pull/2238
+        #: https://github.com/requests/requests/pull/2238
-            # https://github.com/kennethreitz/requests/issues/1084
+            # https://github.com/requests/requests/issues/1084
-                # https://github.com/kennethreitz/requests/issues/3490
+                # https://github.com/requests/requests/issues/3490
-                # https://github.com/kennethreitz/requests/issues/1846
+                # https://github.com/requests/requests/issues/1846
-    See https://github.com/kennethreitz/requests/issues/1979.
+    See https://github.com/requests/requests/issues/1979.
-    See https://github.com/kennethreitz/requests/issues/3772.
+    See https://github.com/requests/requests/issues/3772.
-        heads = {key: 'Mozilla/5.0 (github.com/kennethreitz/requests)'}
+        heads = {key: 'Mozilla/5.0 (github.com/requests/requests)'}
-        """See: https://github.com/kennethreitz/requests/issues/2316"""
+        """See: https://github.com/requests/requests/issues/2316"""
-    """See: https://github.com/kennethreitz/requests/issues/2356"""
+    """See: https://github.com/requests/requests/issues/2356"""
-        self.pytest_args = ['-n', '8', '--boxed']
+        self.pytest_args = ['-n', str(cpu_count()), '--boxed']
-__build__ = 0x021604
+__version__ = '2.16.5'
-    chardet_info = chardet.__version__
+    urllib3_info = {'version': urllib3.__version__}
-        self.pytest_args = []
+        self.pytest_args = ['-n', '8', '--boxed']
-test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov', 'pytest-mock', 'pytest-xdist', 'PySocks>=1.5.6, !=1.5.7']
+test_requirements = ['pytest-httpbin==0.0.7', 'pytest-cov', 'pytest-mock', 'pytest-xdist', 'PySocks>=1.5.6, !=1.5.7', 'pytest>=2.8.0']
-test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov', 'pytest-mock', 'PySocks>=1.5.6, !=1.5.7']
+test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov', 'pytest-mock', 'pytest-xdist', 'PySocks>=1.5.6, !=1.5.7']
-        with open('Pipfile') as f:
+        with open('requirements.txt') as f:
-        with open('Pipfile') as f:
+        with open('requirements.txt') as f:
-        with open('Pipfile') as f:
+        with open('requirements.txt') as f:
-test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov', 'pytest-mock']
+test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov', 'pytest-mock', 'PySocks>=1.5.6, !=1.5.7']
-__build__ = 0x021603
+__version__ = '2.16.4'
-def information():
+def info():
-    print(json.dumps(information(), sort_keys=True, indent=2))
+    print(json.dumps(info(), sort_keys=True, indent=2))
-def print_information():
+def main():
-__cake__ = u'â¨ ð° â¨'
+__cake__ = u'\u2728 \U0001f370 \u2728'
-with open(os.path.join(here, 'requests', '__version__.py')) as f:
+with open(os.path.join(here, 'requests', '__version__.py'), 'r', 'utf-8') as f:
-__build__ = 0x021602
+__version__ = '2.16.3'
-major, minor, patch= urllib3_version
+major, minor, patch = urllib3_version
-__build__ = 0x021600
+__version__ = '2.16.2'
-import chardet
+import sys
-import idna
+sys.modules['requests.packages.urllib3'] = urllib3
-    ]
+packages = ['requests']
-    'requests.packages.idna',
+    # 'requests.packages.chardet',
-packages = ['requests']
+packages = [
-major, minor, patch = urllib3.__version__.split('.')[:3]
+urllib3_version = urllib3.__version__.split('.')
-__build__ = 0x021501
+__version__ = '2.16.0'
-This module returns the preferred default CA certificate bundle.
+This module returns the preferred default CA certificate bundle. There is
-        return os.path.join(os.path.dirname(__file__), 'cacert.pem')
+from certifi import where
-    from .packages.urllib3.contrib.socks import SOCKSProxyManager
+    from urllib3.contrib.socks import SOCKSProxyManager
-        :rtype: requests.packages.urllib3.ProxyManager
+        :rtype: urllib3.ProxyManager
-        :rtype: requests.packages.urllib3.ConnectionPool
+        :rtype: urllib3.ConnectionPool
-            sys.modules['requests.packages.idna'] = idna
+        import idna
-    from requests.packages.urllib3.util import Retry
+    from urllib3.util import Retry
-    from .packages.urllib3.contrib import pyopenssl
+    from urllib3.contrib import pyopenssl
-from .packages.urllib3.exceptions import DependencyWarning
+from urllib3.exceptions import DependencyWarning
-import urllib3 as urllib3_package
+import urllib3
-from .packages import chardet
+import chardet
-    from .packages.urllib3.packages.ordered_dict import OrderedDict
+
-from .packages.urllib3.exceptions import HTTPError as BaseHTTPError
+from urllib3.exceptions import HTTPError as BaseHTTPError
-    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)
+from urllib3._collections import RecentlyUsedContainer
-from .structures import CaseInsensitiveDict
+from .structures import CaseInsensitiveDict
-    from requests.packages.urllib3.exceptions import SNIMissingWarning
+import urllib3 as urllib3_package
-from requests.packages.urllib3.util import Timeout as Urllib3Timeout
+from urllib3.util import Timeout as Urllib3Timeout
-    'urllib3 >=1.21.1,<1.22'
+    'urllib3>=1.21.1,<1.22',
-]
+packages = ['requests']
-requires = []
+]
-__build__ = 0x021500
+__version__ = '2.15.1'
-                r._next = self.resolve_redirects(r, request, yield_requests=True, **kwargs).next()
+                r._next = next(self.resolve_redirects(r, request, yield_requests=True, **kwargs))
-__cake__ = u'â¨ ð° â¨ Thanks for using my software. It means the world to me. --kennethreitz'
+__cake__ = u'â¨ ð° â¨'
-    os.system('python setup.py sdist upload')
+    os.system('python setup.py sdist bdist_wheel')
-__build__ = 0x021402
+__version__ = '2.15.0'
-
+    @property
-            return self._next
+        return self._next
-                          verify=True, cert=None, proxies=None, yield_responses=True, **adapter_kwargs):
+                          verify=True, cert=None, proxies=None, yield_requests=False, **adapter_kwargs):
-            if not yield_responses:
+            if yield_requests:
-                r._next = self.resolve_redirects(r, request, yield_responses=False, **kwargs).next()
+                r._next = self.resolve_redirects(r, request, yield_requests=True, **kwargs).next()
-        """True if this Response one of the permanent versions of redirect"""
+        """True if this Response one of the permanent versions of redirect."""
-        """The apparent encoding, provided by the chardet library"""
+        """The apparent encoding, provided by the chardet library."""
-        Send a given PreparedRequest.
+        """Send a given PreparedRequest.
-            r._next = self.resolve_redirects(r, request, yield_responses=False, **kwargs).next()
+            try:
-        """Receives a Response. Returns a generator of Responses."""
+                          verify=True, cert=None, proxies=None, yield_responses=True, **adapter_kwargs):
-            )
+            if not yield_responses:
-            extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)
+                resp = self.send(
-            yield resp
+                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)
-from .__about__ import __copyright__, __cake__
+from .__version__ import __title__, __description__, __url__, __version__
-from .__about__ import __version__
+from .__version__ import __version__
-with open(os.path.join(here, 'requests', '__about__.py')) as f:
+with open(os.path.join(here, 'requests', '__version__.py')) as f:
-from .__about__ import *
+from .__about__ import __title__, __description__, __url__, __version__
-from . import __version__
+from .__about__ import __version__
-version = __version__
+version = requests.__version__
-release = __version__
+release = requests.__version__
-from requests.__version__ import __version__
+from requests import __version__
-from .__version__ import *
+from .__about__ import *
-with open(os.path.join(here, 'requests', '__version__.py')) as f:
+with open(os.path.join(here, 'requests', '__about__.py')) as f:
-from requests import __version__
+from requests.__version__ import __version__
-    name='requests',
+    name=about['__title__'],
-    description='Python HTTP for Humans.',
+    description=about['__description__'],
-    url='http://python-requests.org',
+    author=about['__author__'],
-    license='Apache 2.0',
+    license=about['__license__'],
-with open(os.path.join(here, "requests", "__version__.py")) as f:
+with open(os.path.join(here, 'requests', '__version__.py')) as f:
-__cake__ = u'â¨ ð° â¨ Thanks for using my software. It means the world to me. --kennethreitz'
+from .__version__ import *
-
+# 'setup.py publish' shortcut.
-    raise RuntimeError('Cannot find version information')
+about = {}
-    version=version,
+    version=about['__version__'],
-with open('requests/__init__.py', 'r') as fd:
+with open('requests/__init__.py', 'r', 'utf-8') as fd:
-Requests HTTP library
+Requests HTTP Library
-:copyright: (c) 2016 by Kenneth Reitz.
+:copyright: (c) 2017 by Kenneth Reitz.
-__copyright__ = 'Copyright 2016 Kenneth Reitz'
+__copyright__ = 'Copyright 2017 Kenneth Reitz'
-def get_environ_proxies(url, no_proxy):
+def get_environ_proxies(url, no_proxy=None):
-                cert_loc = None
+        if url.lower().startswith('https') and verify:
-                    cert_loc = verify
+            cert_loc = None
-                    cert_loc = DEFAULT_CA_BUNDLE_PATH
+            # Allow self-specified cert location.
-                                  "invalid path: {0}".format(cert_loc))
+            if not cert_loc:
-                conn.cert_reqs = 'CERT_REQUIRED'
+            if not cert_loc or not os.path.exists(cert_loc):
-                    conn.ca_cert_dir = cert_loc
+            conn.cert_reqs = 'CERT_REQUIRED'
-                                  "invalid path: {0}".format(conn.key_file))
+                conn.cert_file = cert
-        if url.lower().startswith('https') and verify:
+        if url.lower().startswith('https'):
-            cert_loc = None
+                # Allow self-specified cert location.
-                cert_loc = verify
+                if not cert_loc:
-                cert_loc = DEFAULT_CA_BUNDLE_PATH
+                if not cert_loc or not os.path.exists(cert_loc):
-                              "invalid path: {0}".format(cert_loc))
+                conn.cert_reqs = 'CERT_REQUIRED'
-                conn.key_file = cert[1]
+                if not os.path.isdir(cert_loc):
-                              "invalid path: {0}".format(conn.key_file))
+                conn.cert_reqs = 'CERT_NONE'
-__build__ = 0x021401
+__version__ = '2.14.2'
-        'socks:sys_platform == "win32" and python_version<"3.3"': ['win_inet_pton'],
+        'socks:sys_platform == "win32" and (python_version == "2.7" or python_version == "2.6")': ['win_inet_pton'],
-__build__ = 0x021400
+__version__ = '2.14.1'
-        'socks:platform_system == "Windows" and python_version<"3.3"': ['win_inet_pton'],
+        'socks:sys_platform == "win32" and python_version<"3.3"': ['win_inet_pton'],
-__build__ = 0x021300
+__version__ = '2.14.0'
-                u"http+unix://%2fvar%2frun%2fsocket/path",
+                b"http+unix://%2Fvar%2Frun%2Fsocket/path%7E",
-                u"http+unix://%2fvar%2frun%2fsocket/path",
+                u"http+unix://%2Fvar%2Frun%2Fsocket/path%7E",
-                u"http+unix://%2fvar%2frun%2fsocket/path?key=value",
+                u"http+unix://%2Fvar%2Frun%2Fsocket/path?key=value",
-                u"http+unix://%2fvar%2frun%2fsocket/path?key=value",
+                u"http+unix://%2Fvar%2Frun%2Fsocket/path?key=value",
-            if joining_type == 'T':
+            if joining_type == ord('T'):
-            if joining_type in ['L', 'D']:
+            if joining_type in [ord('L'), ord('D')]:
-            if joining_type == 'T':
+            if joining_type == ord('T'):
-            if joining_type in ['R', 'D']:
+            if joining_type in [ord('R'), ord('D')]:
-        return True
+            if _is_script(cp, 'Hiragana') or _is_script(cp, 'Katakana') or _is_script(cp, 'Han'):
-        except:
+        except IDNAError:
-    except UnicodeError:
+    except UnicodeEncodeError:
-        except UnicodeError:
+        except UnicodeEncodeError:
-        (0x1d200, 0x1d246),
+        0x37000000374,
-        (0x2f800, 0x2fa1e),
+        0x2e8000002e9a,
-        (0xfb46, 0xfb50),
+        0x591000005c8,
-        (0x1f200, 0x1f201),
+        0x304100003097,
-        (0x1b000, 0x1b001),
+        0x30a1000030fb,
-    0xa873: 'U',
+    0x600: 85,
-        (0x2b740, 0x2b81e),
+        0x2d0000002e,
-        (0x200c, 0x200e),
+        0x200c0000200e,
-        (0x30fb, 0x30fc),
+        0xb7000000b8,
-        ranges.append(range_tuple)
+        ranges.append(_encode_range(current_range[0], current_range[-1] + 1))
-    tuple_ = (int_, int_)
+    tuple_ = _encode_range(int_, 0)
-        left, right = ranges[pos-1]
+        left, right = _decode_range(ranges[pos-1])
-        left, _ = ranges[pos]
+        left, _ = _decode_range(ranges[pos])
-from sys import version_info
+from .compat import PY2, PY3
-    return u.result
+def detect(byte_str):
-Big5CharToFreqOrder = (
+BIG5_CHAR_TO_FREQ_ORDER = (
-13968,13969,13970,13971,13972) #13973
+2299, 208,3546,4161,2020, 330,4438,3944,2906,2499,3799,4439,4811,5796,5797,5798, # 5376
-from .mbcssm import Big5SMModel
+from .mbcssm import BIG5_SM_MODEL
-        self._mDistributionAnalyzer = Big5DistributionAnalysis()
+        super(Big5Prober, self).__init__()
-    def get_charset_name(self):
+    @property
-from .euctwfreq import (EUCTWCharToFreqOrder, EUCTW_TABLE_SIZE,
+from .euctwfreq import (EUCTW_CHAR_TO_FREQ_ORDER, EUCTW_TABLE_SIZE,
-from .euckrfreq import (EUCKRCharToFreqOrder, EUCKR_TABLE_SIZE,
+from .euckrfreq import (EUCKR_CHAR_TO_FREQ_ORDER, EUCKR_TABLE_SIZE,
-from .gb2312freq import (GB2312CharToFreqOrder, GB2312_TABLE_SIZE,
+from .gb2312freq import (GB2312_CHAR_TO_FREQ_ORDER, GB2312_TABLE_SIZE,
-from .big5freq import (Big5CharToFreqOrder, BIG5_TABLE_SIZE,
+from .big5freq import (BIG5_CHAR_TO_FREQ_ORDER, BIG5_TABLE_SIZE,
-from .jisfreq import (JISCharToFreqOrder, JIS_TABLE_SIZE,
+from .jisfreq import (JIS_CHAR_TO_FREQ_ORDER, JIS_TABLE_SIZE,
-MINIMUM_DATA_THRESHOLD = 3
+class CharDistributionAnalysis(object):
-        self._mTableSize = None  # Size of above table
+        self._char_to_freq_order = None
-        self._mTypicalDistributionRatio = None
+        self.typical_distribution_ratio = None
-        self._mTotalChars = 0  # Total characters encountered
+        self._done = False
-        self._mFreqChars = 0
+        self._freq_chars = 0
-    def feed(self, aBuf, aCharLen):
+    def feed(self, char, char_len):
-        if aCharLen == 2:
+        if char_len == 2:
-            order = self.get_order(aBuf)
+            order = self.get_order(char)
-            self._mTotalChars += 1
+            self._total_chars += 1
-                    self._mFreqChars += 1
+            if order < self._table_size:
-            return SURE_NO
+        if self._total_chars <= 0 or self._freq_chars <= self.MINIMUM_DATA_THRESHOLD:
-            if r < SURE_YES:
+        if self._total_chars != self._freq_chars:
-        return SURE_YES
+        return self.SURE_YES
-        return self._mTotalChars > ENOUGH_DATA_THRESHOLD
+        return self._total_chars > self.ENOUGH_DATA_THRESHOLD
-    def get_order(self, aBuf):
+    def get_order(self, byte_str):
-        self._mTypicalDistributionRatio = EUCTW_TYPICAL_DISTRIBUTION_RATIO
+        super(EUCTWDistributionAnalysis, self).__init__()
-    def get_order(self, aBuf):
+    def get_order(self, byte_str):
-        first_char = wrap_ord(aBuf[0])
+        first_char = byte_str[0]
-            return 94 * (first_char - 0xC4) + wrap_ord(aBuf[1]) - 0xA1
+            return 94 * (first_char - 0xC4) + byte_str[1] - 0xA1
-        self._mTypicalDistributionRatio = EUCKR_TYPICAL_DISTRIBUTION_RATIO
+        super(EUCKRDistributionAnalysis, self).__init__()
-    def get_order(self, aBuf):
+    def get_order(self, byte_str):
-        first_char = wrap_ord(aBuf[0])
+        first_char = byte_str[0]
-            return 94 * (first_char - 0xB0) + wrap_ord(aBuf[1]) - 0xA1
+            return 94 * (first_char - 0xB0) + byte_str[1] - 0xA1
-        self._mTypicalDistributionRatio = GB2312_TYPICAL_DISTRIBUTION_RATIO
+        super(GB2312DistributionAnalysis, self).__init__()
-    def get_order(self, aBuf):
+    def get_order(self, byte_str):
-        first_char, second_char = wrap_ord(aBuf[0]), wrap_ord(aBuf[1])
+        first_char, second_char = byte_str[0], byte_str[1]
-        self._mTypicalDistributionRatio = BIG5_TYPICAL_DISTRIBUTION_RATIO
+        super(Big5DistributionAnalysis, self).__init__()
-    def get_order(self, aBuf):
+    def get_order(self, byte_str):
-        first_char, second_char = wrap_ord(aBuf[0]), wrap_ord(aBuf[1])
+        first_char, second_char = byte_str[0], byte_str[1]
-        self._mTypicalDistributionRatio = JIS_TYPICAL_DISTRIBUTION_RATIO
+        super(SJISDistributionAnalysis, self).__init__()
-    def get_order(self, aBuf):
+    def get_order(self, byte_str):
-        first_char, second_char = wrap_ord(aBuf[0]), wrap_ord(aBuf[1])
+        first_char, second_char = byte_str[0], byte_str[1]
-        self._mTypicalDistributionRatio = JIS_TYPICAL_DISTRIBUTION_RATIO
+        super(EUCJPDistributionAnalysis, self).__init__()
-    def get_order(self, aBuf):
+    def get_order(self, byte_str):
-        char = wrap_ord(aBuf[0])
+        char = byte_str[0]
-            return 94 * (char - 0xA1) + wrap_ord(aBuf[1]) - 0xa1
+            return 94 * (char - 0xA1) + byte_str[1] - 0xa1
-# 
+#
-# 
+#
-# 
+#
-# 
+#
-import sys
+from .enums import ProbingState
-        self._mBestGuessProber = None
+    def __init__(self, lang_filter=None):
-        for prober in self._mProbers:
+        super(CharSetGroupProber, self).reset()
-        self._mBestGuessProber = None
+                self._active_num += 1
-        if not self._mBestGuessProber:
+    @property
-            if not self._mBestGuessProber:
+            if not self._best_guess_prober:
-        return self._mBestGuessProber.get_charset_name()
+        return self._best_guess_prober.language
-        for prober in self._mProbers:
+    def feed(self, byte_str):
-            if not st:
+            state = prober.feed(byte_str)
-            elif st == constants.eNotMe:
+            if state == ProbingState.FOUND_IT:
-        return self.get_state()
+                self._active_num -= 1
-        if st == constants.eFoundIt:
+        state = self.state
-        elif st == constants.eNotMe:
+        elif state == ProbingState.NOT_ME:
-        for prober in self._mProbers:
+        best_conf = 0.0
-                                     + ' not active\n')
+                self.logger.debug('%s not active', prober.charset_name)
-        if not self._mBestGuessProber:
+            conf = prober.get_confidence()
-#            return self._mBestGuessProber.get_confidence()
+        return best_conf
-from . import constants
+import logging
-        pass
+
-        self._mState = constants.eDetecting
+        self._state = ProbingState.DETECTING
-    def get_charset_name(self):
+    @property
-    def feed(self, aBuf):
+    def feed(self, buf):
-        return self._mState
+    @property
-        return aBuf
+    @staticmethod
-        return aBuf
+        # If we're not in a tag...
-        return aBuf
+        return filtered
-from io import open
+from chardet.compat import PY2
-    '''
+    """
-    '''
+    """
-        conflict_handler='resolve')
+                     encodings")
-                        help='File whose encoding we would like to determine.',
+                        help='File whose encoding we would like to determine. \
-                        default=[sys.stdin])
+                        default=[sys.stdin if PY2 else sys.stdin.buffer])
-from .compat import wrap_ord
+import logging
-class CodingStateMachine:
+
-        self._mCurrentCharLen = 0
+        self._model = sm
-        self._mCurrentState = eStart
+        self._curr_state = MachineState.START
-        return self._mCurrentState
+        byte_class = self._model['class_table'][c]
-        return self._mCurrentCharLen
+        return self._curr_char_len
-        return self._mModel['name']
+        return self._model['name']
-#   Ian Cordasco - port to Python
+#   Dan Blanchard
-        return a
+    text_type = str
-from .mbcssm import CP949SMModel
+from .codingstatemachine import CodingStateMachine
-        self._mCodingSM = CodingStateMachine(CP949SMModel)
+        super(CP949Prober, self).__init__()
-        self._mDistributionAnalyzer = EUCKRDistributionAnalysis()
+        self.distribution_analyzer = EUCKRDistributionAnalysis()
-    def get_charset_name(self):
+    @property
-from .compat import wrap_ord
+from .enums import LanguageFilter, ProbingState, MachineState
-        ]
+    """
-            if not codingSM:
+        super(EscCharSetProber, self).reset()
-        self._mDetectedCharset = None
+            coding_sm.active = True
-        return self._mDetectedCharset
+    @property
-        if self._mDetectedCharset:
+        if self._detected_charset:
-                if not codingSM.active:
+    def feed(self, byte_str):
-                    return self.get_state()
+                coding_state = coding_sm.next_state(c)
-        return self.get_state()
+        return self.state
-from .constants import eStart, eError, eItsMe
+from .enums import MachineState
-HZ_cls = (
+HZ_CLS = (
-     4,eItsMe,eStart,eStart,eStart,eStart,eStart,eStart,# 28-2f
+HZ_ST = (
-HZCharLenTable = (0, 0, 0, 0, 0, 0)
+HZ_CHAR_LEN_TABLE = (0, 0, 0, 0, 0, 0)
-             'name': "HZ-GB-2312"}
+HZ_SM_MODEL = {'class_table': HZ_CLS,
-ISO2022CN_cls = (
+ISO2022CN_CLS = (
-eError,eError,eError,eError,eError,eItsMe,eError,eStart,# 38-3f
+ISO2022CN_ST = (
-ISO2022CNCharLenTable = (0, 0, 0, 0, 0, 0, 0, 0, 0)
+ISO2022CN_CHAR_LEN_TABLE = (0, 0, 0, 0, 0, 0, 0, 0, 0)
-                    'name': "ISO-2022-CN"}
+ISO2022CN_SM_MODEL = {'class_table': ISO2022CN_CLS,
-ISO2022JP_cls = (
+ISO2022JP_CLS = (
-eError,eError,eError,eError,eItsMe,eError,eStart,eStart,# 40-47
+ISO2022JP_ST = (
-ISO2022JPCharLenTable = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
+ISO2022JP_CHAR_LEN_TABLE = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
-                    'name': "ISO-2022-JP"}
+ISO2022JP_SM_MODEL = {'class_table': ISO2022JP_CLS,
-ISO2022KR_cls = (
+ISO2022KR_CLS = (
-eError,eError,eError,eItsMe,eStart,eStart,eStart,eStart,# 20-27
+ISO2022KR_ST = (
-ISO2022KRCharLenTable = (0, 0, 0, 0, 0, 0)
+ISO2022KR_CHAR_LEN_TABLE = (0, 0, 0, 0, 0, 0)
-from . import constants
+from .enums import ProbingState, MachineState
-from .mbcssm import EUCJPSMModel
+from .mbcssm import EUCJP_SM_MODEL
-        self._mContextAnalyzer = EUCJPContextAnalysis()
+        super(EUCJPProber, self).__init__()
-        self._mContextAnalyzer.reset()
+        super(EUCJPProber, self).reset()
-    def get_charset_name(self):
+    @property
-                self._mState = constants.eNotMe
+    @property
-                self._mState = constants.eFoundIt
+            elif coding_state == MachineState.ITS_ME:
-                charLen = self._mCodingSM.get_current_charlen()
+            elif coding_state == MachineState.START:
-                    self._mDistributionAnalyzer.feed(self._mLastChar, charLen)
+                    self._last_char[1] = byte_str[0]
-                                                     charLen)
+                    self.context_analyzer.feed(byte_str[i - 1:i + 1],
-        self._mLastChar[0] = aBuf[aLen - 1]
+        self._last_char[0] = byte_str[-1]
-                self._mState = constants.eFoundIt
+        if self.state == ProbingState.DETECTING:
-        return self.get_state()
+        return self.state
-        return max(contxtCf, distribCf)
+        context_conf = self.context_analyzer.get_confidence()
-# 
+#
-# 
+#
-# Typical Distribution Ratio  
+#
-EUCKRCharToFreqOrder = ( \
+# Char to FreqOrder table ,
-8736,8737,8738,8739,8740,8741)
+)
-from .mbcssm import EUCKRSMModel
+from .mbcssm import EUCKR_SM_MODEL
-        self._mDistributionAnalyzer = EUCKRDistributionAnalysis()
+        super(EUCKRProber, self).__init__()
-    def get_charset_name(self):
+    @property
-EUCTW_TABLE_SIZE = 8102
+EUCTW_TABLE_SIZE = 5376
-8726,8727,8728,8729,8730,8731,8732,8733,8734,8735,8736,8737,8738,8739,8740,8741) # 8742
+EUCTW_CHAR_TO_FREQ_ORDER = (
-# 
+#
-# 
+#
-from .mbcssm import EUCTWSMModel
+from .mbcssm import EUCTW_SM_MODEL
-        self._mDistributionAnalyzer = EUCTWDistributionAnalysis()
+        super(EUCTWProber, self).__init__()
-    def get_charset_name(self):
+    @property
-GB2312CharToFreqOrder = (
+GB2312_CHAR_TO_FREQ_ORDER = (
-4866,4899,6099,6100,5559,6478,6765,3599,5868,6101,5869,5870,6275,6766,4527,6767)
+ 852,1221,1400,1486, 882,2299,4036, 351,  28,1122, 700,6479,6480,6481,6482,6483,  #last 512
-# 
+#
-# 
+#
-from .mbcssm import GB2312SMModel
+from .mbcssm import GB2312_SM_MODEL
-        self._mDistributionAnalyzer = GB2312DistributionAnalysis()
+        super(GB2312Prober, self).__init__()
-    def get_charset_name(self):
+    @property
-from .compat import wrap_ord
+from .enums import ProbingState
-MIN_FINAL_CHAR_DISTANCE = 5
+class HebrewProber(CharSetProber):
-MIN_MODEL_DISTANCE = 0.01
+    # Minimum Visual vs Logical final letter score difference.
-LOGICAL_HEBREW_NAME = "windows-1255"
+    # Minimum Visual vs Logical model score difference.
-        self._mVisualProber = None
+        super(HebrewProber, self).__init__()
-        self._mFinalCharVisualScore = 0
+        self._final_char_logical_score = 0
-        self._mBeforePrev = ' '
+        self._prev = ' '
-        self._mVisualProber = visualProber
+        self._logical_prober = logicalProber
-                               FINAL_TSADI]
+        return c in [self.FINAL_KAF, self.FINAL_MEM, self.FINAL_NUN,
-        return wrap_ord(c) in [NORMAL_KAF, NORMAL_MEM, NORMAL_NUN, NORMAL_PE]
+        return c in [self.NORMAL_KAF, self.NORMAL_MEM,
-    def feed(self, aBuf):
+    def feed(self, byte_str):
-        if self.get_state() == eNotMe:
+        if self.state == ProbingState.NOT_ME:
-            return eNotMe
+            return ProbingState.NOT_ME
-        aBuf = self.filter_high_bit_only(aBuf)
+        byte_str = self.filter_high_byte_only(byte_str)
-        for cur in aBuf:
+        for cur in byte_str:
-                    # next-to-last char was not a space so self._mPrev is not a
+                if self._before_prev != ' ':
-                    if self.is_final(self._mPrev):
+                    if self.is_final(self._prev):
-                    elif self.is_non_final(self._mPrev):
+                        self._final_char_logical_score += 1
-                        self._mFinalCharVisualScore += 1
+                        self._final_char_visual_score += 1
-                        (self.is_final(self._mPrev)) and (cur != ' ')):
+                if ((self._before_prev == ' ') and
-            self._mPrev = cur
+                    self._final_char_visual_score += 1
-        return eDetecting
+        # ProbingState.NOT_ME (handled above)
-    def get_charset_name(self):
+    @property
-            return VISUAL_HEBREW_NAME
+        finalsub = self._final_char_logical_score - self._final_char_visual_score
-            return VISUAL_HEBREW_NAME
+        modelsub = (self._logical_prober.get_confidence()
-            return VISUAL_HEBREW_NAME
+            return self.VISUAL_HEBREW_NAME
-        return LOGICAL_HEBREW_NAME
+        return self.LOGICAL_HEBREW_NAME
-    def get_state(self):
+    @property
-        return eDetecting
+        if (self._logical_prober.state == ProbingState.NOT_ME) and \
-JISCharToFreqOrder = (
+JIS_CHAR_TO_FREQ_ORDER = (
-8256,8257,8258,8259,8260,8261,8262,8263,8264,8265,8266,8267,8268,8269,8270,8271) # 8272
+)
-class JapaneseContextAnalysis:
+class JapaneseContextAnalysis(object):
-        self._mRelSample = [0] * NUM_OF_CATEGORY
+        self._total_rel = 0  # total sequence received
-        self._mLastCharOrder = -1  # The order of previous char
+        self._need_to_skip_char_num = 0
-        self._mDone = False
+        self._done = False
-        if self._mDone:
+    def feed(self, byte_str, num_bytes):
-                self._mLastCharOrder = -1
+        i = self._need_to_skip_char_num
-                        self._mDone = True
+                if (order != -1) and (self._last_char_order != -1):
-                self._mLastCharOrder = order
+                    self._rel_sample[jp2CharContext[self._last_char_order][order]] += 1
-        return self._mTotalRel > ENOUGH_REL_THRESHOLD
+        return self._total_rel > self.ENOUGH_REL_THRESHOLD
-            return (self._mTotalRel - self._mRelSample[0]) / self._mTotalRel
+        if self._total_rel > self.MINIMUM_DATA_THRESHOLD:
-            return DONT_KNOW
+            return self.DONT_KNOW
-    def get_order(self, aBuf):
+    def get_order(self, byte_str):
-        self.charset_name = "SHIFT_JIS"
+        super(SJISContextAnalysis, self).__init__()
-        return self.charset_name
+    @property
-        if not aBuf:
+    def get_order(self, byte_str):
-            charLen = 2
+        first_char = byte_str[0]
-                self.charset_name = "CP932"
+                self._charset_name = "CP932"
-            charLen = 1
+            char_len = 1
-            second_char = wrap_ord(aBuf[1])
+        if len(byte_str) > 1:
-                return second_char - 0x9F, charLen
+                return second_char - 0x9F, char_len
-        return -1, charLen
+        return -1, char_len
-        if not aBuf:
+    def get_order(self, byte_str):
-        first_char = wrap_ord(aBuf[0])
+        first_char = byte_str[0]
-            charLen = 2
+            char_len = 2
-            charLen = 3
+            char_len = 3
-            charLen = 1
+            char_len = 1
-            second_char = wrap_ord(aBuf[1])
+        if len(byte_str) > 1:
-                return second_char - 0xA1, charLen
+                return second_char - 0xA1, char_len
-  'charsetName': "ISO-8859-5"
+  'char_to_order_map': Latin5_BulgarianCharToOrderMap,
-  'charsetName': "windows-1251"
+  'char_to_order_map': win1251BulgarianCharToOrderMap,
-KOI8R_CharToOrderMap = (
+KOI8R_char_to_order_map = (
-win1251_CharToOrderMap = (
+win1251_char_to_order_map = (
-latin5_CharToOrderMap = (
+latin5_char_to_order_map = (
-macCyrillic_CharToOrderMap = (
+macCyrillic_char_to_order_map = (
-IBM855_CharToOrderMap = (
+IBM855_char_to_order_map = (
-IBM866_CharToOrderMap = (
+IBM866_char_to_order_map = (
-  'charsetName': "KOI8-R"
+  'char_to_order_map': KOI8R_char_to_order_map,
-  'charsetName': "windows-1251"
+  'char_to_order_map': win1251_char_to_order_map,
-  'charsetName': "ISO-8859-5"
+  'char_to_order_map': latin5_char_to_order_map,
-};
+  'char_to_order_map': macCyrillic_char_to_order_map,
-  'charsetName': "IBM866"
+  'char_to_order_map': IBM866_char_to_order_map,
-  'charsetName': "IBM855"
+  'char_to_order_map': IBM855_char_to_order_map,
-Latin7_CharToOrderMap = (
+Latin7_char_to_order_map = (
-win1253_CharToOrderMap = (
+win1253_char_to_order_map = (
-  'charsetName': "ISO-8859-7"
+  'char_to_order_map': Latin7_char_to_order_map,
-  'charsetName': "windows-1253"
+  'char_to_order_map': win1253_char_to_order_map,
-win1255_CharToOrderMap = (
+WIN1255_CHAR_TO_ORDER_MAP = (
-HebrewLangModel = (
+HEBREW_LANG_MODEL = (
-  'charsetName': "windows-1255"
+  'char_to_order_map': WIN1255_CHAR_TO_ORDER_MAP,
-  'charsetName': "ISO-8859-2"
+  'char_to_order_map': Latin2_HungarianCharToOrderMap,
-  'charsetName': "windows-1250"
+  'char_to_order_map': win1250HungarianCharToOrderMap,
-  'charsetName': "TIS-620"
+  'char_to_order_map': TIS620CharToOrderMap,
-# flake8: noqa
+# -*- coding: utf-8 -*-
-from .compat import wrap_ord
+from .enums import ProbingState
-    # UDF OTH ASC ASS ACV ACO ASV ASO
+# UDF OTH ASC ASS ACV ACO ASV ASO
-        CharSetProber.__init__(self)
+        super(Latin1Prober, self).__init__()
-        self._mFreqCounter = [0] * FREQ_CAT_NUM
+        self._last_char_class = OTH
-        return "windows-1252"
+    @property
-                                    + charClass]
+    @property
-                self._mState = eNotMe
+                self._state = ProbingState.NOT_ME
-            self._mLastCharClass = charClass
+            self._freq_counter[freq] += 1
-        return self.get_state()
+        return self.state
-        if self.get_state() == eNotMe:
+        if self.state == ProbingState.NOT_ME:
-        total = sum(self._mFreqCounter)
+        total = sum(self._freq_counter)
-            confidence = ((self._mFreqCounter[3] - self._mFreqCounter[1] * 20.0)
+            confidence = ((self._freq_counter[3] - self._freq_counter[1] * 20.0)
-from . import constants
+from .enums import ProbingState, MachineState
-        self._mLastChar = [0, 0]
+    """
-        self._mLastChar = [0, 0]
+        super(MultiByteCharSetProber, self).reset()
-        pass
+    @property
-                self._mState = constants.eNotMe
+    def feed(self, byte_str):
-                self._mState = constants.eFoundIt
+            elif coding_state == MachineState.ITS_ME:
-                charLen = self._mCodingSM.get_current_charlen()
+            elif coding_state == MachineState.START:
-                    self._mDistributionAnalyzer.feed(self._mLastChar, charLen)
+                    self._last_char[1] = byte_str[0]
-                                                     charLen)
+                    self.distribution_analyzer.feed(byte_str[i - 1:i + 1],
-        self._mLastChar[0] = aBuf[aLen - 1]
+        self._last_char[0] = byte_str[-1]
-                self._mState = constants.eFoundIt
+        if self.state == ProbingState.DETECTING:
-        return self.get_state()
+        return self.state
-        return self._mDistributionAnalyzer.get_confidence()
+        return self.distribution_analyzer.get_confidence()
-        self._mProbers = [
+    def __init__(self, lang_filter=None):
-from .constants import eStart, eError, eItsMe
+from .enums import MachineState
-BIG5_cls = (
+BIG5_CLS = (
-    eError,eStart,eStart,eStart,eStart,eStart,eStart,eStart#10-17
+BIG5_ST = (
-Big5CharLenTable = (0, 1, 1, 2, 0)
+BIG5_CHAR_LEN_TABLE = (0, 1, 1, 2, 0)
-               'name': 'Big5'}
+BIG5_SM_MODEL = {'class_table': BIG5_CLS,
-CP949_cls  = (
+CP949_CLS  = (
-CP949_st = (
+CP949_ST = (
-    eError,eStart,eStart,eStart,eStart,eError,eError,eStart,eStart,eStart, # 6
+    MachineState.ERROR,MachineState.START,     3,MachineState.ERROR,MachineState.START,MachineState.START,     4,     5,MachineState.ERROR,     6, # MachineState.START
-CP949CharLenTable = (0, 1, 2, 0, 1, 1, 2, 2, 0, 2)
+CP949_CHAR_LEN_TABLE = (0, 1, 2, 0, 1, 1, 2, 2, 0, 2)
-                'name': 'CP949'}
+CP949_SM_MODEL = {'class_table': CP949_CLS,
-EUCJP_cls = (
+EUCJP_CLS = (
-          3,eError,eError,eError,eStart,eStart,eStart,eStart#20-27
+EUCJP_ST = (
-EUCJPCharLenTable = (2, 2, 2, 3, 1, 0)
+EUCJP_CHAR_LEN_TABLE = (2, 2, 2, 3, 1, 0)
-                'name': 'EUC-JP'}
+EUCJP_SM_MODEL = {'class_table': EUCJP_CLS,
-EUCKR_cls  = (
+EUCKR_CLS  = (
-    eItsMe,eItsMe,eItsMe,eItsMe,eError,eError,eStart,eStart #08-0f
+EUCKR_ST = (
-EUCKRCharLenTable = (0, 1, 2, 0)
+EUCKR_CHAR_LEN_TABLE = (0, 1, 2, 0)
-                'charLenTable': EUCKRCharLenTable,
+EUCKR_SM_MODEL = {'class_table': EUCKR_CLS,
-EUCTW_cls = (
+EUCTW_CLS = (
-    eStart,eError,eStart,eStart,eStart,eStart,eStart,eStart #28-2f
+EUCTW_ST = (
-EUCTWCharLenTable = (0, 0, 1, 2, 2, 2, 3)
+EUCTW_CHAR_LEN_TABLE = (0, 0, 1, 2, 2, 2, 3)
-                'charLenTable': EUCTWCharLenTable,
+EUCTW_SM_MODEL = {'class_table': EUCTW_CLS,
-GB2312_cls = (
+GB2312_CLS = (
-    eError,eError,eStart,eStart,eStart,eStart,eStart,eStart #28-2f
+GB2312_ST = (
-# it is used for frequency analysis only, and we are validing
+# it is used for frequency analysis only, and we are validating
-GB2312CharLenTable = (0, 1, 1, 1, 1, 1, 2)
+GB2312_CHAR_LEN_TABLE = (0, 1, 1, 1, 1, 1, 2)
-                  'name': 'GB2312'}
+GB2312_SM_MODEL = {'class_table': GB2312_CLS,
-SJIS_cls = (
+SJIS_CLS = (
-    eItsMe,eItsMe,eError,eError,eStart,eStart,eStart,eStart #10-17
+SJIS_ST = (
-SJISCharLenTable = (0, 1, 1, 2, 0, 0)
+SJIS_CHAR_LEN_TABLE = (0, 1, 1, 2, 0, 0)
-               'charLenTable': SJISCharLenTable,
+SJIS_SM_MODEL = {'class_table': SJIS_CLS,
-UCS2BE_cls = (
+UCS2BE_CLS = (
-          6,     6,     6,     6,eError,eError,eStart,eStart #30-37
+UCS2BE_ST  = (
-UCS2BECharLenTable = (2, 2, 2, 0, 2, 2)
+UCS2BE_CHAR_LEN_TABLE = (2, 2, 2, 0, 2, 2)
-                 'name': 'UTF-16BE'}
+UCS2BE_SM_MODEL = {'class_table': UCS2BE_CLS,
-UCS2LE_cls = (
+UCS2LE_CLS = (
-          5,     5,     5,eError,     5,eError,eStart,eStart #30-37
+UCS2LE_ST = (
-UCS2LECharLenTable = (2, 2, 2, 2, 2, 2)
+UCS2LE_CHAR_LEN_TABLE = (2, 2, 2, 2, 2, 2)
-                 'charLenTable': UCS2LECharLenTable,
+UCS2LE_SM_MODEL = {'class_table': UCS2LE_CLS,
-UTF8_cls = (
+UTF8_CLS = (
-    eError,eStart,eError,eError,eError,eError,     12,   10,#00-07
+UTF8_ST = (
-    eError,eError,eError,eError,eError,eError,eError,eError #c8-cf
+    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#10-17
-UTF8CharLenTable = (0, 1, 0, 0, 0, 0, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6)
+UTF8_CHAR_LEN_TABLE = (0, 1, 0, 0, 0, 0, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6)
-               'name': 'UTF-8'}
+UTF8_SM_MODEL = {'class_table': UTF8_CLS,
-#NEGATIVE_CAT = 0
+from .enums import CharacterCategory, ProbingState, SequenceLikelihood
-        self._mModel = model
+    SAMPLE_SIZE = 64
-        self._mReversed = reversed
+        self._reversed = reversed
-        self._mNameProber = nameProber
+        self._name_prober = name_prober
-        CharSetProber.reset(self)
+        super(SingleByteCharSetProber, self).reset()
-        self._mTotalChar = 0
+        self._last_order = 255
-        self._mFreqChar = 0
+        self._freq_char = 0
-            return self._mNameProber.get_charset_name()
+    @property
-            return self._mModel['charsetName']
+            return self._model.get('language')
-                        model = self._mModel['precedenceMatrix'][i]
+    def feed(self, byte_str):
-            self._mLastOrder = order
+                        i = (order * self.SAMPLE_SIZE) + self._last_order
-                    self._mState = constants.eNotMe
+        charset_name = self._model['charset_name']
-        return self.get_state()
+        return self.state
-            r = r * self._mFreqChar / self._mTotalChar
+        if self._total_seqs > 0:
-from .langhungarianmodel import Latin2HungarianModel, Win1250HungarianModel
+# from .langhungarianmodel import Latin2HungarianModel, Win1250HungarianModel
-        self._mProbers = [
+        super(SBCSGroupProber, self).__init__()
-            SingleByteCharSetProber(Win1250HungarianModel),
+            # TODO: Restore Hungarian encodings (iso-8859-2 and windows-1250)
-                               visualHebrewProber])
+        hebrew_prober = HebrewProber()
-from . import constants
+from .mbcssm import SJIS_SM_MODEL
-        self._mContextAnalyzer = SJISContextAnalysis()
+        super(SJISProber, self).__init__()
-        self._mContextAnalyzer.reset()
+        super(SJISProber, self).reset()
-        return self._mContextAnalyzer.get_charset_name()
+    @property
-                self._mState = constants.eNotMe
+    @property
-                self._mState = constants.eFoundIt
+            elif coding_state == MachineState.ITS_ME:
-                charLen = self._mCodingSM.get_current_charlen()
+            elif coding_state == MachineState.START:
-                    self._mDistributionAnalyzer.feed(self._mLastChar, charLen)
+                    self._last_char[1] = byte_str[0]
-                                                     charLen)
+                    self.context_analyzer.feed(byte_str[i + 1 - char_len:i + 3
-        self._mLastChar[0] = aBuf[aLen - 1]
+        self._last_char[0] = byte_str[-1]
-                self._mState = constants.eFoundIt
+        if self.state == ProbingState.DETECTING:
-        return self.get_state()
+        return self.state
-        return max(contxtCf, distribCf)
+        context_conf = self.context_analyzer.get_confidence()
-from .escprober import EscCharSetProber  # ISO-2122, etc.
+import logging
-eHighbyte = 2
+from .enums import InputState, LanguageFilter, ProbingState
-        self._mCharSetProbers = []
+    """
-        self.result = {'encoding': None, 'confidence': 0.0}
+        """
-        for prober in self._mCharSetProbers:
+        self._got_data = False
-    def feed(self, aBuf):
+    def feed(self, byte_str):
-        if not aLen:
+        if not len(byte_str):
-        if not self._mGotData:
+        if not isinstance(byte_str, bytearray):
-            if aBuf[:3] == codecs.BOM_UTF8:
+            if byte_str.startswith(codecs.BOM_UTF8):
-            elif aBuf[:4] == codecs.BOM_UTF32_LE:
+                self.result = {'encoding': "UTF-8-SIG",
-            elif aBuf[:4] == b'\xFE\xFF\x00\x00':
+                self.result = {'encoding': "UTF-32",
-            elif aBuf[:4] == b'\x00\x00\xFF\xFE':
+                self.result = {'encoding': "X-ISO-10646-UCS-4-3412",
-            elif aBuf[:2] == codecs.BOM_LE:
+                self.result = {'encoding': "X-ISO-10646-UCS-4-2143",
-                self.result = {'encoding': "UTF-16BE", 'confidence': 1.0}
+                self.result = {'encoding': "UTF-16",
-            return
+            self._got_data = True
-                               'confidence': self._mEscCharSetProber.get_confidence()}
+        # If we've seen escape sequences, use the EscCharSetProber, which
-                                   'confidence': prober.get_confidence()}
+        # If we've seen high bytes (i.e., those with values greater than 127),
-            return
+            return self.result
-            return self.result
+        if not self._got_data:
-            for prober in self._mCharSetProbers[0].mProbers:
+        # Default to ASCII if it is all we've seen so far
-                                  prober.get_confidence()))
+                prober_confidence = prober.get_confidence()
-from . import constants
+from .enums import ProbingState, MachineState
-from .mbcssm import UTF8SMModel
+from .mbcssm import UTF8_SM_MODEL
-ONE_CHAR_PROB = 0.5
+    ONE_CHAR_PROB = 0.5
-        self._mCodingSM = CodingStateMachine(UTF8SMModel)
+        super(UTF8Prober, self).__init__()
-        self._mNumOfMBChar = 0
+        super(UTF8Prober, self).reset()
-    def get_charset_name(self):
+    @property
-                self._mState = constants.eNotMe
+    @property
-                self._mState = constants.eFoundIt
+            elif coding_state == MachineState.ITS_ME:
-                    self._mNumOfMBChar += 1
+            elif coding_state == MachineState.START:
-                self._mState = constants.eFoundIt
+        if self.state == ProbingState.DETECTING:
-        return self.get_state()
+        return self.state
-                unlike = unlike * ONE_CHAR_PROB
+        if self._num_mb_chars < 6:
-__version__ = '1.20'
+__version__ = '1.21.1'
-        self._container[key.lower()] = (key, val)
+        self._container[key.lower()] = [key, val]
-        new_vals = key, val
+        new_vals = [key, val]
-                self._container[key_lower] = [vals[0], vals[1], val]
+            vals.append(val)
-                return vals[1:]
+            return vals[1:]
-    'HTTPSPoolKey', HTTPPoolKey._fields + SSL_KEYWORDS
+# All known keyword arguments that could be provided to the pool manager, its
-    Create a pool key of type ``key_class`` for a request.
+    Create a pool key out of a request context dictionary.
-
+    :type  key_class: namedtuple
-        It should contain a key for each field in the :class:`HTTPPoolKey`
+    :type  request_context: dict
-        context[key] = request_context.get(key)
+    # Since we mutate the dictionary, make a copy first
-# globally here, or individually on the instance.
+#: A dictionary that maps a scheme to a callable that creates a pool key.
-    'https': functools.partial(_default_key_normalizer, HTTPSPoolKey),
+    'http': functools.partial(_default_key_normalizer, PoolKey),
-    def _new_pool(self, scheme, host, port):
+    def _new_pool(self, scheme, host, port, request_context=None):
-        Create a new :class:`ConnectionPool` based on host, port and scheme.
+        Create a new :class:`ConnectionPool` based on host, port, scheme, and
-        to be overridden for customization.
+        If ``request_context`` is provided, it is provided as keyword arguments
-        kwargs = self.connection_pool_kw
+        if request_context is None:
-                kwargs.pop(kw, None)
+                request_context.pop(kw, None)
-        return pool_cls(host, port, **kwargs)
+        return pool_cls(host, port, **request_context)
-    def connection_from_host(self, host, port=None, scheme='http'):
+    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):
-        ``urllib3.connectionpool.port_by_scheme``.
+        ``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is
-        request_context = self.connection_pool_kw.copy()
+        request_context = self._merge_pool_kwargs(pool_kwargs)
-        return self.connection_from_pool_key(pool_key)
+        return self.connection_from_pool_key(pool_key, request_context=request_context)
-    def connection_from_pool_key(self, pool_key):
+    def connection_from_pool_key(self, pool_key, request_context=None):
-            pool = self._new_pool(pool_key.scheme, pool_key.host, pool_key.port)
+            scheme = request_context['scheme']
-    def connection_from_url(self, url):
+    def connection_from_url(self, url, pool_kwargs=None):
-        constructor.
+        Similar to :func:`urllib3.connectionpool.connection_from_url`.
-        return self.connection_from_host(u.host, port=u.port, scheme=u.scheme)
+        return self.connection_from_host(u.host, port=u.port, scheme=u.scheme,
-    def connection_from_host(self, host, port=None, scheme='http'):
+    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):
-                host, port, scheme)
+                host, port, scheme, pool_kwargs=pool_kwargs)
-            self.proxy.host, self.proxy.port, self.proxy.scheme)
+            self.proxy.host, self.proxy.port, self.proxy.scheme, pool_kwargs=pool_kwargs)
-            return self._obj.decompress(data)
+            decompressed = self._obj.decompress(data)
-            raise UnrewindableBodyError("An error occured when rewinding request "
+            raise UnrewindableBodyError("An error occurred when rewinding request "
-    def __init__(self, total=10, connect=None, read=None, redirect=None,
+    def __init__(self, total=10, connect=None, read=None, redirect=None, status=None,
-            connect=self.connect, read=self.read, redirect=self.redirect,
+            connect=self.connect, read=self.read, redirect=self.redirect, status=self.status,
-        retry_counts = (self.total, self.connect, self.read, self.redirect)
+        retry_counts = (self.total, self.connect, self.read, self.redirect, self.status)
-            connect=connect, read=read, redirect=redirect,
+            connect=connect, read=read, redirect=redirect, status=status_count,
-                'read={self.read}, redirect={self.redirect})').format(
+                'read={self.read}, redirect={self.redirect}, status={self.status})').format(
-import time
+_DEFAULT_SELECTOR = None
-    while result is _SYSCALL_SENTINEL:
+# Determine which function to use to wrap system calls because Python 3.5+
-        # Aren't we thankful for Python 3.x rework for exceptions?
+            return func(*args, **kwargs)
-                raise SelectorError(errcode)
+            raise SelectorError(errcode)
-    return result
+                expires = monotonic() + timeout
-    HAS_SELECT = False
+def DefaultSelector():
-        if host:
+        if host and scheme in NORMALIZABLE_SCHEMES:
-    :param timeout: (optional) How long to wait for the server to send data
+    :param timeout: (optional) How many seconds to wait for the server to send data
-    from urllib import quote, unquote, quote_plus, unquote_plus, urlencode, getproxies, proxy_bypass
+    from urllib import (
-    from urllib.request import parse_http_list, getproxies, proxy_bypass
+    from urllib.request import parse_http_list, getproxies, proxy_bypass, proxy_bypass_environment, getproxies_environment
-    proxy_bypass, urlunparse, basestring, integer_types)
+    proxy_bypass, urlunparse, basestring, integer_types, is_py3,
-            ('http://google.com:5000/v1.0/', False),
+    'url, expected, override', (
-def test_should_bypass_proxies_win_registry(url, expected, monkeypatch):
+def test_should_bypass_proxies_win_registry(url, expected, override,
-                return ['192.168.*;127.0.0.1;localhost.localdomain;172.16.1.1']
+                return [override]
-from .structures import CaseInsensitiveDict, TimedCacheManaged
+from .structures import CaseInsensitiveDict
-            bypass = _proxy_bypass_cached(netloc)
+            bypass = proxy_bypass(netloc)
-from requests.structures import CaseInsensitiveDict, LookupDict, TimedCache, TimedCacheManaged
+from requests.structures import CaseInsensitiveDict, LookupDict
-        assert third_result is 3
+import platform
-from datetime import datetime
+from datetime import timedelta
-        start = datetime.utcnow()
+        start = preferred_clock()
-        r.elapsed = datetime.utcnow() - start
+        elapsed = preferred_clock() - start
-                    select_proxy, to_native_string)
+                    select_proxy)
-from io import BytesIO, UnsupportedOperation
+from io import UnsupportedOperation
-    cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,
+    cookielib, urlunparse, urlsplit, urlencode, str, bytes,
-from .structures import CaseInsensitiveDict, TimedCache, TimedCacheManaged
+from .cookies import cookiejar_from_dict
-from .compat import cookielib, OrderedDict, urljoin, urlparse
+from .compat import cookielib, is_py3, OrderedDict, urljoin, urlparse
-            return resp.headers['location']
+            location = resp.headers['location']
-    expected_path_py3 = b'%C3%85%C2%A1'
+    expected_path = b'%C5%A1'
-            assert redirect_request[0].startswith(b'GET /' + expected_path + b' HTTP/1.1')
+        assert redirect_request[0].startswith(b'GET /' + expected_path + b' HTTP/1.1')
-                url = '%s:%s' % (parsed_rurl.scheme, url)
+                url = '%s:%s' % (to_native_string(parsed_rurl.scheme), url)
-import os
+from requests.compat import quote, is_py3
-    """This function allows you to check if on IP belongs to a network subnet
+    """This function allows you to check if an IP belongs to a network subnet
-    """Sends a GET request.
+    r"""Sends a GET request.
-    """Sends a OPTIONS request.
+    r"""Sends a OPTIONS request.
-    """Sends a HEAD request.
+    r"""Sends a HEAD request.
-    """Sends a POST request.
+    r"""Sends a POST request.
-    """Sends a PUT request.
+    r"""Sends a PUT request.
-    """Sends a PATCH request.
+    r"""Sends a PATCH request.
-    """Sends a DELETE request.
+    r"""Sends a DELETE request.
-        """Returns the json-encoded content of a response, if any.
+        r"""Returns the json-encoded content of a response, if any.
-        """Sends a GET request. Returns :class:`Response` object.
+        r"""Sends a GET request. Returns :class:`Response` object.
-        """Sends a OPTIONS request. Returns :class:`Response` object.
+        r"""Sends a OPTIONS request. Returns :class:`Response` object.
-        """Sends a HEAD request. Returns :class:`Response` object.
+        r"""Sends a HEAD request. Returns :class:`Response` object.
-        """Sends a POST request. Returns :class:`Response` object.
+        r"""Sends a POST request. Returns :class:`Response` object.
-        """Sends a PUT request. Returns :class:`Response` object.
+        r"""Sends a PUT request. Returns :class:`Response` object.
-        """Sends a PATCH request. Returns :class:`Response` object.
+        r"""Sends a PATCH request. Returns :class:`Response` object.
-        """Sends a DELETE request. Returns :class:`Response` object.
+        r"""Sends a DELETE request. Returns :class:`Response` object.
-from requests.packages.urllib3.util import Timeout
+from requests.packages.urllib3.util import Timeout as Urllib3Timeout
-            Timeout(connect=None, read=None)
+            Urllib3Timeout(connect=None, read=None)
-            Timeout(connect=None, read=0.1)
+            Urllib3Timeout(connect=None, read=0.1)
-            Timeout(connect=0.1, read=None)
+            Urllib3Timeout(connect=0.1, read=None)
-            Timeout(connect=0.1, read=0.1)
+            Urllib3Timeout(connect=0.1, read=0.1)
-    def test_none_timeout(self, httpbin):
+    @pytest.mark.parametrize(
-                         timeout=Timeout(connect=None, read=None))
+        r = requests.get(httpbin('get'), timeout=timeout)
-        from requests.packages.urllib3.util import Timeout
+    @pytest.mark.parametrize(
-                         timeout=Timeout(connect=None, read=0.1))
+            requests.get(httpbin('delay/10'), timeout=timeout)
-        from requests.packages.urllib3.util import Timeout
+    @pytest.mark.parametrize(
-                         timeout=Timeout(connect=0.1, read=None))
+            requests.get(TARPIT, timeout=timeout)
-        from requests.packages.urllib3.util import Timeout
+    @pytest.mark.parametrize(
-                         timeout=Timeout(connect=0.1, read=0.1))
+            requests.get(TARPIT, timeout=timeout)
-        #: SSL client certificate default.
+        #: SSL client certificate default, if String, path to ssl client
-        elif timeout is not None:
+        else:
-                    **kwargs
+                    timeout=timeout
-        elif isinstance(timeout, tuple):
+        if isinstance(timeout, tuple):
-        :type timeout: float or tuple
+        :type timeout: float or tuple or urllib3 Timeout object
-        if isinstance(timeout, tuple):
+        
-        else:
+        elif timeout is not None:
-                    timeout=timeout
+                    **kwargs
-        :param verify: (optional) Whether to verify SSL certificates.
+        :param verify: (optional) Either a boolean, in which case it controls whether we verify
-            or it could be a path to a ca bundle
+        :param verify: Either a boolean, in which case it controls whether we verify
-                raise IOError("Could not find a suitable SSL CA certificate bundle, "
+                raise IOError("Could not find a suitable TLS CA certificate bundle, "
-                raise IOError("Could not find the SSL certificate file, "
+                raise IOError("Could not find the TLS certificate file, "
-                raise IOError("Could not find the SSL key file, "
+                raise IOError("Could not find the TLS key file, "
-        :param verify: (optional) Whether to verify SSL certificates.
+        :param verify: (optional) Either a boolean, in which case it controls whether
-    :param verify: (optional) whether the SSL cert will be verified. A CA_BUNDLE path can also be provided. Defaults to ``True``.
+    :param verify: (optional) Either a boolean, in which case it controls whether we verify
-            A CA_BUNDLE path can also be provided. Defaults to ``True``.
+        :param verify: (optional) Either a boolean, in which case it controls whether we verify
-    def test_invalid_ca_certificate_path(self):
+    def test_invalid_ca_certificate_path(self, httpbin_secure):
-        assert str(e.value) == 'Could not find a suitable SSL CA certificate bundle, invalid path: {0}'.format(INVALID_PATH)
+            requests.get(httpbin_secure(), verify=INVALID_PATH)
-    def test_invalid_ssl_certificate_files(self):
+    def test_invalid_ssl_certificate_files(self, httpbin_secure):
-        assert str(e.value) == 'Could not find the SSL certificate file, invalid path: {0}'.format(INVALID_PATH)
+            requests.get(httpbin_secure(), cert=INVALID_PATH)
-        assert str(e.value) == 'Could not find the SSL key file, invalid path: {0}'.format(INVALID_PATH)
+            requests.get(httpbin_secure(), cert=('.', INVALID_PATH))
-            else:
+            if not os.path.isdir(cert_loc):
-                conn.cert_file, conn.key_file = cert
+                conn.cert_file = cert[0]
-        :param verify: Whether we should actually verify the certificate.
+        :param verify: Whether we should actually verify the certificate
-                raise Exception("Could not find a suitable SSL CA certificate bundle.")
+            if not cert_loc or not os.path.exists(cert_loc):
-            else:
+            if os.path.isdir(cert_loc):
-                conn.key_file = cert[1]
+                conn.cert_file, conn.key_file = cert
-copyright = u'2017. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'MMXVII. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-    :param data: (optional) Dictionary or list of tuples ``[(key, value)]`` (will be form-encoded), bytes, or file-like object to send in the body of the :class:`Request`. The list of tuple version is to allow duplication of fields.
+    :param data: (optional) Dictionary or list of tuples ``[(key, value)]`` (will be form-encoded), bytes, or file-like object to send in the body of the :class:`Request`.
-    :param data: (optional) Dictionary (will be form-encoded), bytes, or file-like object to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary or list of tuples ``[(key, value)]`` (will be form-encoded), bytes, or file-like object to send in the body of the :class:`Request`. The list of tuple version is to allow duplication of fields.
-        return map(lambda kv: (kv[0], kv[1][1]), self._dict.items()).__iter__()
+        return ((key, value[1]) for key, value in self._dict.items())
-        return self._dict.__delitem__(item)
+        del self._dict[item]
-            raise KeyError
+            raise KeyError(key)
-        return self._dict.__setitem__(key, (now, value))
+        self._dict[key] = (now, value)
-    :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary (will be form-encoded), bytes, or file-like object to send in the body of the :class:`Request`.
-    :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary (will be form-encoded), bytes, or file-like object to send in the body of the :class:`Request`.
-    :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary (will be form-encoded), bytes, or file-like object to send in the body of the :class:`Request`.
-    :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary (will be form-encoded), bytes, or file-like object to send in the body of the :class:`Request`.
-            raise UnrewindableBodyError("An error occured when rewinding request "
+            raise UnrewindableBodyError("An error occurred when rewinding request "
-        assert 'error occured when rewinding request body' in str(e)
+        assert 'error occurred when rewinding request body' in str(e)
-from .structures import CaseInsensitiveDict
+from .structures import CaseInsensitiveDict, TimedCache, TimedCacheManaged
-            bypass = proxy_bypass(netloc)
+            bypass = _proxy_bypass_cached(netloc)
-from requests.structures import CaseInsensitiveDict, LookupDict
+from requests.structures import CaseInsensitiveDict, LookupDict, TimedCache, TimedCacheManaged
-        """Returns true if :attr:`status_code` is 'OK'."""
+        """Returns True if :attr:`status_code` is less than 400.
-        """Returns true if :attr:`status_code` is 'OK'."""
+        """Returns True if :attr:`status_code` is less than 400.
-        """Returns true if :attr:`status_code` is 'OK'."""
+        """Returns True if :attr:`status_code` is less than 400.
-                o.seek(current_position or 0)
+                try:
-            def seek(self, pos):
+            def seek(self, pos, whence=0):
-        while resp.is_redirect:
+        url = self.get_redirect_target(resp)
-                resp.history = new_hist
+            # Update history and keep track of redirects.
-            if i >= self.max_redirects:
+            if len(resp.history) >= self.max_redirects:
-            i += 1
+            # extract redirect url, if any, for the next loop
-        new_proxies = proxies.copy() if proxies is not None else {}
+        new_proxies = proxies.copy()
-            environ_proxies = get_environ_proxies(url)
+        bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)
-            env_proxies = get_environ_proxies(url) or {}
+            no_proxy = proxies.get('no_proxy') if proxies is not None else None
-def should_bypass_proxies(url):
+@contextlib.contextmanager
-    no_proxy = get_proxy('no_proxy')
+    no_proxy_arg = no_proxy
-        bypass = False
+    with set_environ('no_proxy', no_proxy_arg):
-def get_environ_proxies(url):
+def get_environ_proxies(url, no_proxy):
-    if should_bypass_proxies(url):
+    if should_bypass_proxies(url, no_proxy=no_proxy):
-        assert get_environ_proxies(url) == {}
+        assert get_environ_proxies(url, no_proxy=None) == {}
-        assert get_environ_proxies(url) != {}
+        assert get_environ_proxies(url, no_proxy=None) != {}
-    assert should_bypass_proxies(url) == expected
+    assert should_bypass_proxies(url, no_proxy=None) == expected
-        if not if not title.startswith(('\\', '/')):
+        if not title.startswith(('\\', '/')):
-        if not title.startswith('\\') and not title.strartswith('/'):
+        if not if not title.startswith(('\\', '/')):
-        if not title.startswith('\\'):
+        if not title.startswith('\\') and not title.strartswith('/'):
-copyright = u'2016. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'2017. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-__build__ = 0x021205
+__version__ = '2.13.0'
-uts46data = (
+
-__version__ = '1.19.1'
+__version__ = '1.20'
-RECENT_DATE = datetime.date(2014, 1, 1)
+# When updating RECENT_DATE, move it to
-from .packages.six.moves.queue import LifoQueue, Empty, Full
+from .packages.six.moves import queue
-    QueueCls = LifoQueue
+    QueueCls = queue.LifoQueue
-        self.host = host.strip('[]')
+        self.host = _ipv6_host(host).lower()
-    :param \**conn_kw:
+    :param \\**conn_kw:
-        except Empty:
+        except queue.Empty:
-        except Full:
+        except queue.Full:
-        except Empty:
+        except queue.Empty:
-                **response_kw):
+                body_pos=None, **response_kw):
-        :param \**response_kw:
+        :param int body_pos:
-        except Empty:
+        except queue.Empty:
-                                release_conn=release_conn, **response_kw)
+                                release_conn=release_conn, body_pos=body_pos,
-                release_conn=release_conn, **response_kw)
+                release_conn=release_conn, body_pos=body_pos,
-                release_conn=release_conn, **response_kw)
+                release_conn=release_conn,
-    :param \**kw:
+    :param \\**kw:
-import select
+    _validate_dependencies_met()
-                [self.socket], [], [], self.socket.gettimeout())
+            rd = util.wait_for_read(self.socket, self.socket.gettimeout())
-                [self.socket], [], [], self.socket.gettimeout())
+            rd = util.wait_for_read(self.socket, self.socket.gettimeout())
-                if not wlist:
+                wr = util.wait_for_write(self.socket, self.socket.gettimeout())
-                rd, _, _ = select.select([sock], [], [], sock.gettimeout())
+                rd = util.wait_for_read(sock, sock.gettimeout())
-    :param \**connection_pool_kw:
+    :param \\**connection_pool_kw:
-        select = False
+from .wait import wait_for_read
-            return False
+    if not HAS_SELECT:
-            return True
+    try:
-from ..packages.six import b
+from ..packages.six import b, integer_types
-        """ Is this method/status code retryable? (Based on method/codes whitelists)
+    def _is_method_retryable(self, method):
-            if read is False:
+            if read is False or not self._is_method_retryable(method):
-    return time.time()
+# Use time.monotonic if available.
-        with open('requirements.txt') as f:
+        with open('Pipfile') as f:
-        with open('requirements.txt') as f:
+        with open('Pipfile') as f:
-        with open('requirements.txt') as f:
+        with open('Pipfile') as f:
-__build__ = 0x021204
+__version__ = '2.12.5'
-from .packages import idna
+    @staticmethod
-            if not unicode_is_ascii(host) or host.startswith(u'*'):
+        # In general, we want to try IDNA encoding the hostname if the string contains
-    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection.
+    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
-    cookiejar_from_dict, morsel_to_cookie, merge_cookies)
+    cookiejar_from_dict, morsel_to_cookie)
-from requests.cookies import RequestsCookieJar, cookiejar_from_dict
+from requests.cookies import RequestsCookieJar
-test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov']
+test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov', 'pytest-mock']
-        data = '\ufeff{}'.encode(encoding)
+        data = u'\ufeff{}'.encode(encoding)
-    if sample in (codecs.BOM_UTF32_LE, codecs.BOM32_BE):
+    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):
-            "https://urllib3.readthedocs.io/en/latest/contrib.html.",
+            "https://urllib3.readthedocs.io/en/latest/reference/urllib3.contrib.html.",
-            "3.0.0. Please convert the object you've passed in ({!r}) to "
+            "3.0.0. Please convert the object you've passed in ({0!r}) to "
-            "3.0.0. Please convert the object you've passed in ({!r}) to "
+            "3.0.0. Please convert the object you've passed in ({0!r}) to "
-__build__ = 0x021203
+__version__ = '2.12.4'
-from tests.testserver.server import Server
+from tests.testserver.server import Server, consume_socket_content
-            (42, 42)
+            (42, 42),
-from .compat import urlparse, str
+from .compat import urlparse, str, basestring
-    
+
-        and Transfer-Encoding header
+        and Transfer-Encoding header.
-        and Transfer-Encoding header"""
+        and Transfer-Encoding header.
-__build__ = 0x021202
+__version__ = '2.12.3'
-        if ':' in url and not url.lower().startswith(('http://', 'https://')):
+        # `data` etc to work around exceptions from `url_parse`, which
-__build__ = 0x021201
+__version__ = '2.12.2'
-            if not self.status_code:
+            if self.status_code == 0 or self.raw is None:
-            if self.status_code == 0:
+            if not self.status_code:
-    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin, username, password):
+    def test_set_basicauth(self, httpbin, username, password):
-        if ':' in url and not url.lower().startswith('http'):
+        # `data`, `http+unix` etc to work around exceptions from `url_parse`,
-from ._internal_utils import to_native_string
+from ._internal_utils import to_native_string, unicode_is_ascii
-        # Only want to apply IDNA to the hostname
+        # In general, we want to try IDNA encoding every hostname, as that
-            raise InvalidURL('URL has an invalid label.')
+            if not unicode_is_ascii(host) or host.startswith(u'*'):
-from .compat import is_py2, builtin_str
+from .compat import is_py2, builtin_str, str
-    builtin_str, OrderedDict, bytes)
+    builtin_str, OrderedDict)
-        url = httpbin('basic-auth', httpbin_username, httpbin_password)
+        url = httpbin('get')
-    builtin_str, OrderedDict)
+    builtin_str, OrderedDict, bytes)
-        url = httpbin('get')
+        
-    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin, username, password, auth_str):
+    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin, username, password):
-        r = Request('GET', url, auth=auth)
+
-        assert p['Authorization'] == _basic_auth_str(username, password)
+        assert p.headers['Authorization'] == _basic_auth_str(username, password)
-        ))    
+        ))
-            (u'Ð¸Ð¼Ñ'.encode('utf-8'), u'Ð¿Ð°ÑÐ¾Ð»Ñ'.encode('utf-8'), 'Basic 0LjQvNGPOtC/0LDRgNC+0LvRjA=='),
+        'username, password', (
-        assert p['Authorization'] == auth_str
+        assert p['Authorization'] == _basic_auth_str(username, password)
-        s = _basic_auth_str("test", "test")
+    @pytest.mark.parametrize(
-        assert s == "Basic dGVzdDp0ZXN0"
+        assert s == auth_str
-            (u'Ð¸Ð¼Ñ'.encode('utf-8'), u'Ð¿Ð°ÑÐ¾Ð»Ñ'.encode('utf-8')),
+        'username, password, auth_str', (
-    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin, username, password):
+    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin, username, password, auth_str):
-        url = httpbin('basic-auth', username, password)
+        url = httpbin('get')
-            ('Ð¸Ð¼Ñ'.encode('utf-8'), 'Ð¿Ð°ÑÐ¾Ð»Ñ'.encode('utf-8')),
+            (u'Ð¸Ð¼Ñ'.encode('utf-8'), u'Ð¿Ð°ÑÐ¾Ð»Ñ'.encode('utf-8')),
-        url = httpbin('basic-auth', 'user', 'pass')
+    @pytest.mark.parametrize(
-from .compat import urlparse, str, bytes
+from .compat import urlparse, str
-        username = username.decode('latin1')
+    if isinstance(username, str):
-        password = password.decode('latin1')
+    if isinstance(password, str):
-        b64encode(('%s:%s' % (username, password)).encode('latin1')).strip()
+        b64encode(b':'.join((username, password))).strip()
-        url = url.strip()
+        # Remove leading whitespaces from url
-        request = requests.Request('GET', ' http://example.com ').prepare()
+        request = requests.Request('GET', ' http://example.com').prepare()
-__build__ = 0x021200
+__version__ = '2.12.1'
-__version__ = '1.19'
+__version__ = '1.19.1'
-from urlparse import urljoin
+from ..packages.six.moves.urllib.parse import urljoin
-        'security': ['pyOpenSSL>=0.13', 'ndg-httpsclient', 'pyasn1'],
+        'security': ['pyOpenSSL>=0.14', 'cryptography>=1.3.4', 'idna>=2.0.0'],
-    :param allow_redirects: (optional) Boolean. Set to True if POST/PUT/DELETE redirect following is allowed.
+    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection.
-        r = requests.Request(url=url)
+        r = requests.Request('GET', url=url)
-        r = requests.Request(url=url)
+        r = requests.Request('GET', url=url)
-__build__ = 0x021101
+__version__ = '2.12.0'
-            ('foo', 'must be an int or float'),
+            ('foo', 'must be an int, float or None'),
-__version__ = '1.16'
+__version__ = '1.19'
-    from httplib import HTTPException  # noqa: unused in this module
+from .packages.six.moves.http_client import HTTPConnection as _HTTPConnection
-    ssl_wrap_socket,
+    create_urllib3_context,
-        self.putrequest(method, url, skip_accept_encoding=skip_accept_encoding)
+        skip_host = 'host' in headers
-                 strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT, **kw):
+                 strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
-        self.sock = ssl.wrap_socket(conn, self.key_file, self.cert_file)
+
-            cert_reqs = 'CERT_REQUIRED'
+        """
-                                    ssl_version=resolved_ssl_version)
+        if self.ssl_context is None:
-        elif resolved_cert_reqs != ssl.CERT_NONE \
+        elif context.verify_mode != ssl.CERT_NONE \
-                            self.assert_fingerprint is not None)
+        self.is_verified = (
-
+from .packages.six.moves.queue import LifoQueue, Empty, Full
-                 self.num_connections, self.host)
+        log.debug("Starting new HTTP connection (%d): %s",
-            log.info("Resetting dropped connection: %s", self.host)
+            log.debug("Resetting dropped connection: %s", self.host)
-                  httplib_response.status, httplib_response.length)
+        log.debug("%s://%s:%s \"%s %s %s\" %s %s", self.scheme, self.host, self.port,
-            log.info("Redirecting %s -> %s", url, redirect_location)
+            retries.sleep_for_retry(response)
-        if retries.is_forced_retry(method, status_code=response.status):
+        has_retry_after = bool(response.getheader('Retry-After'))
-            log.info("Forced retry: %s", url)
+            retries.sleep(response)
-                 self.num_connections, self.host)
+        log.debug("Starting new HTTPS connection (%d): %s",
-                'https://urllib3.readthedocs.io/en/latest/security.html'),
+                'https://urllib3.readthedocs.io/en/latest/advanced-usage.html'
-        https://cloud.google.com/appengine/docs/python/urlfetch
+    the App Engine documentation `here
-    Notably it will raise an AppEnginePlatformError if:
+    Notably it will raise an :class:`AppEnginePlatformError` if:
-        * If you attempt to use this on GAEv2 (Managed VMs), as full socket
+        * If you attempt to use this on App Engine Flexible, as full socket
-    def __init__(self, headers=None, retries=None, validate_certificate=True):
+    def __init__(self, headers=None, retries=None, validate_certificate=True,
-                    retries.total),
+                follow_redirects=self.urlfetch_retries and follow_redirects,
-            raise MaxRetryError(self, url, "too many redirects")
+            response, retries=retries, **response_kw)
-        if retries.is_forced_retry(method, status_code=http_response.status):
+        has_retry_after = bool(http_response.getheader('Retry-After'))
-            retries.sleep()
+            log.debug("Retry: %s", url)
-            return 5  # 5s is the default timeout for URLFetch.
+            return None  # Defer to URLFetch's default.
-            if timeout._read is not timeout._connect:
+            if timeout._read is not None or timeout._connect is not None:
-                    "reverting to total timeout.", AppEnginePlatformWarning)
+                    "reverting to total or default URLFetch timeout.",
-from urllib3 import HTTPSConnectionPool
+from .. import HTTPSConnectionPool
-'''SSL with SNI_-support for Python 2. Follow these instructions if you would
+"""
-* pyasn1 (tested with 0.1.6)
+* pyOpenSSL (tested with 16.0.0)
-    pip install pyopenssl ndg-httpsclient pyasn1
+    pip install pyopenssl cryptography idna
-'''
+"""
-
+import idna
-from pyasn1.type import univ, constraint
+from cryptography import x509
-    from urllib3.packages.backports.makefile import backport_makefile
+    from ..packages.backports.makefile import backport_makefile
-HAS_SNI = SUBJ_ALT_NAME_SUPPORT
+# SNI always works.
-_openssl_verify = {
+_stdlib_to_openssl_verify = {
-DEFAULT_SSL_CIPHER_LIST = util.ssl_.DEFAULT_CIPHERS.encode('ascii')
+_openssl_to_stdlib_verify = dict(
-orig_connection_ssl_wrap_socket = connection.ssl_wrap_socket
+orig_util_SSLContext = util.ssl_.SSLContext
-    connection.ssl_wrap_socket = ssl_wrap_socket
+    util.ssl_.SSLContext = PyOpenSSLContext
-    connection.ssl_wrap_socket = orig_connection_ssl_wrap_socket
+    util.ssl_.SSLContext = orig_util_SSLContext
-    return dns_name
+    """
-            ]
+            'subjectAltName': get_subj_alt_name(x509)
-    return err_no == 0
+class PyOpenSSLContext(object):
-    return WrappedSocket(cnx, sock)
+def _verify_callback(cnx, x509, err_no, err_depth, return_code):
-This contrib module contains provisional support for SOCKS proxies from within
+This module contains provisional support for SOCKS proxies from within
-  IPv6 addresses. Any such connection attempt will fail.
+  IPv6 addresses. Any such connection attempt will fail. You must use a domain
-            if value:
+            if value is not None:
-    Our embarassingly-simple replacement for mimetools.choose_boundary.
+    Our embarrassingly-simple replacement for mimetools.choose_boundary.
-    # Python 3.2+
+    # Our match_hostname function is the same as 3.5's, so we only want to
-__version__ = '3.4.0.2'
+def _to_unicode(obj):
-        raise ValueError("empty or no certificate")
+        raise ValueError("empty or no certificate, match_hostname needs a "
-            if _dnsname_match(value, hostname):
+            if host_ip is None and _dnsname_match(value, hostname):
-
+from .packages.six.moves.urllib.parse import urljoin
-                'ssl_version', 'ca_cert_dir')
+                'ssl_version', 'ca_cert_dir', 'ssl_context')
-    from urllib import urlencode
+from .packages.six.moves.urllib.parse import urlencode
-    ProtocolError, DecodeError, ReadTimeoutError, ResponseNotChunked
+    BodyNotHttplibCompatible, ProtocolError, DecodeError, ReadTimeoutError,
-                 original_response=None, pool=None, connection=None):
+                 original_response=None, pool=None, connection=None,
-        Set-up the _decoder attribute if necessar.
+        Set-up the _decoder attribute if necessary.
-        if self.chunked:
+        if self.chunked and self.supports_chunked_reads():
-            return self._fp.isclosed()
+    def supports_chunked_reads(self):
-                 _observed_errors=0):
+                 history=None, respect_retry_after_header=True):
-        self._observed_errors = _observed_errors  # TODO: use .history instead?
+        self.history = history or tuple()
-            _observed_errors=self._observed_errors,
+            history=self.history,
-        if self._observed_errors <= 1:
+        # We want to consider only the last consecutive errors sequence (Ignore redirects).
-        backoff_value = self.backoff_factor * (2 ** (self._observed_errors - 1))
+        backoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))
-        """ Sleep between retry attempts using an exponential backoff.
+    def parse_retry_after(self, retry_after):
-        """
+        if seconds < 0:
-    def is_forced_retry(self, method, status_code):
+    def is_retry(self, method, status_code, has_retry_after=False):
-        return self.status_forcelist and status_code in self.status_forcelist
+        if self.status_forcelist and status_code in self.status_forcelist:
-        _observed_errors = self._observed_errors
+        status = None
-            _observed_errors += 1
+            redirect_location = response.get_redirect_location()
-            _observed_errors += 1
+                status = response.status
-            _observed_errors=_observed_errors)
+            history=history)
-# - use 3DES as fallback which is secure but slow,
+# - prefer any AES-GCM and ChaCha20 over any AES-CBC for better performance and
-)
+DEFAULT_CIPHERS = ':'.join([
-                '#insecureplatformwarning.',
+                'https://urllib3.readthedocs.io/en/latest/advanced-usage.html'
-        '#snimissingwarning.',
+        'https://urllib3.readthedocs.io/en/latest/advanced-usage.html'
-            is a numeric value less than zero.
+        :raises ValueError: If it is a numeric value less than or equal to
-                             "int or float." % (name, value))
+                             "int, float or None." % (name, value))
-            if value < 0:
+            if value <= 0:
-                                 "than 0." % (name, value))
+                                 "than or equal to 0." % (name, value))
-                             "int or float." % (name, value))
+                             "int, float or None." % (name, value))
-    :func:`parse_url`.
+    :func:`parse_url`. Both the scheme and host are normalized as they are
-    slots = ()
+    __slots__ = ()
-            # If given, ports must be integers.
+            # If given, ports must be integers. No whitespace, no plus or
-            port = int(port)
+            try:
-    Deprecated. Use :func:`.parse_url` instead.
+    Deprecated. Use :func:`parse_url` instead.
-from .compat import urlparse, str
+from .compat import urlparse, str, bytes
-    def test_prepared_request_is_pickleable(self):
+    def test_prepared_request_is_pickleable(self, httpbin):
-        r = pickle.dumps(p)
+        # Verify PreparedRequest can be pickled and unpickled
-        # Verify we can use the unpickled request.
+        # Verify unpickled PreparedRequest sends properly
-        assert r.status_code == 200
+        resp = s.send(r)
-        r = requests.Request('POST', httpbin('post'), data=data, files=files)
+    def test_prepared_request_with_file_is_pickleable(self, httpbin):
-        r = pickle.dumps(p)
+        # Verify PreparedRequest can be pickled and unpickled
-        # Verify we can use the unpickled request.
+        # Verify unpickled PreparedRequest sends properly
-            print(r.url)
+        resp = s.send(r)
-        r = requests.Request('POST', httpbin('post'), hooks=dict(response=print_url))
+    def test_prepared_request_with_hook_is_pickleable(self, httpbin):
-        r = pickle.loads(r)
+        # Verify PreparedRequest can be pickled
-        # Verify we can use the unpickled request.
+        # Verify unpickled PreparedRequest sends properly
-        assert r.status_code == 200
+        resp = s.send(r)
-        r = requests.post(httpbin('redirect-to'), data='test', params={'url': url, 'status_code': 307})
+        r = requests.post(httpbin('redirect-to'), data='test', params={'url': 'post', 'status_code': 307})
-        r = requests.post(httpbin('redirect-to'), data=io.BytesIO(b'test'), params={'url': url, 'status_code': 307})
+        byte_str = b'test'
-    get_auth_from_url
+    get_auth_from_url, rewind_body
-                     getproxies, proxy_bypass, urlunparse, basestring)
+from .compat import (
-from .exceptions import InvalidURL, InvalidHeader, FileModeWarning
+from .exceptions import (
-    ProxyError, InvalidHeader)
+    ProxyError, InvalidHeader, UnrewindableBodyError)
-        if username and password:
+        if username:
-    urldefragauth)
+    urldefragauth, add_dict_to_cookiejar)
-    return cj
+    return cookiejar_from_dict(cookie_dict, cj)
-            not isinstance(data, (basestring, list, tuple, dict))
+            not isinstance(data, (basestring, list, tuple, collections.Mapping))
-        new_content = sock.recv(chunks)
+    while True:
-from idna.core import encode, decode, alabel, ulabel, IDNAError
+from .core import encode, decode, alabel, ulabel, IDNAError
-from idna.codec import *
+from .core import *
-            total_length = o.tell()
+                # seek to end of file
-            o.seek(current_position or 0)
+                # seek back to current position to support
-            host = idna.encode(host).decode('utf-8')
+            host = idna.encode(host, uts46=True).decode('utf-8')
-            (u'http://straÃe.de/straÃe', u'http://xn--strae-oqa.de/stra%C3%9Fe'),
+            (
-        except UnicodeError:
+            host = idna.encode(host).decode('utf-8')
-                    self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()
+            if self._content_consumed:
-            except AttributeError:
+            if self.status_code == 0:
-    def test_request_with_bytestring_host(self):
+    def test_request_with_bytestring_host(self, httpbin):
-            'http://httpbin.org/cookies/set?cookie=value',
+            httpbin('cookies/set?cookie=value'),
-from .utils import parse_dict_header, to_native_string
+from ._internal_utils import to_native_string
-    check_header_validity)
+    iter_slices, guess_json_utf, super_len, check_header_validity)
-from .utils import to_key_val_list, default_headers, to_native_string
+from ._internal_utils import to_native_string
-# noinspection PyUnresolvedReferences
+# to_native_string is unused here, but imported here for backwards compatibility
-from . import utils
+from ._internal_utils import to_native_string
-        host = utils.to_native_string(self._r.headers['Host'], encoding='utf-8')
+        host = to_native_string(self._r.headers['Host'], encoding='utf-8')
-                     basestring)
+from .compat import (quote, urlparse, bytes, str, OrderedDict, unquote,
-
+
-        host = self._r.headers['Host']
+        host = utils.to_native_string(self._r.headers['Host'], encoding='utf-8')
-
+
-        elif (self.method not in ('GET', 'HEAD')) and (self.headers.get('Content-Length') is None):
+        """Prepare Content-Length header based on request method and body"""
-            prepared_request._cookies.update(self.cookies)
+            merge_cookies(prepared_request._cookies, self.cookies)
-from requests.cookies import cookiejar_from_dict, morsel_to_cookie
+from requests.cookies import (
-        r.reason = reason
+        reason = u'Komponenttia ei lÃ¶ydy'
-        assert reason.decode('latin-1') in str(e)
+        assert reason in e.value.args[0]
-        r.reason = reason.encode('latin-1')
+        reason = b'Komponenttia ei l\xf6ydy'
-        assert reason in str(e)
+        assert reason.decode('latin-1') in str(e)
-        'socks': ['PySocks>=1.5.6'],
+        'socks': ['PySocks>=1.5.6, !=1.5.7'],
-            reason = self.reason.decode('utf-8', 'ignore')
+            try:
-        #: SSL certificate default.
+        #: SSL client certificate default.
-        if total_length is None and hasattr(o, 'tell'):
+        if hasattr(o, 'seek') and total_length is None:
-        o.seek(current_position or 0)
+            # seek back to current position to support
-            current_position = total_length
+            if total_length is not None:
-        o.seek(current_position)
+        o.seek(current_position or 0)
-    total_length = 0
+    total_length = None
-
+    if hasattr(o, 'seek') and total_length is None:
-            proxy = environ_proxies.get('all', environ_proxies.get(scheme))
+            proxy = environ_proxies.get(scheme, environ_proxies.get('all'))
-        return proxies.get('all', proxies.get(urlparts.scheme))
+        return proxies.get(urlparts.scheme, proxies.get('all'))
-        
+        ('https://', 'socks5://http.proxy', mixed_proxies),
-        'all',
+        'all://' + urlparts.hostname,
-__build__ = 0x021100
+__version__ = '2.11.1'
-        return self.raw.release_conn()
+        release_conn = getattr(self.raw, 'release_conn', None)
-        resp = ses.send(prep)
+
-        resp.headers['location'] = 'get'
+        resp.headers['location'] = httpbin('get')
-
+                # https://github.com/kennethreitz/requests/issues/3490
-        raise UnicodeError("Unable to decode contents with encoding %s." % encoding)
+    if r.encoding is None:
-
+        :rtype: requests.packages.urllib3.ProxyManager
-        """Takes the given response and tries digest-auth, if needed."""
+        """
-    """Produce an appropriate Cookie header string to be sent with `request`, or None."""
+    """
-        """Send a given PreparedRequest."""
+        """
-        """Check the environment and merge it with some settings."""
+        """
-        """Returns the appropriate connection adapter for the given URL."""
+        """
-    """Returns a :class:`Session` for context-management."""
+    """
-    """Very simple check of the cidr format in no_proxy variable"""
+    """
-    """Returns whether we should bypass proxies or not."""
+    """
-    """Return a dict of environment proxies."""
+    """
-    """Return a string representing the default user agent."""
+    """
-    """Given a url remove the fragment and the authentication part"""
+    """
-__build__ = 0x021000
+__version__ = '2.11.0'
-__version__ = '1.15.1'
+__version__ = '1.16'
-    def close():
+    def close(self):
-                httplib_response = conn.getresponse()
+            except TypeError:  # Python 2.6 and older, Python 3
-                                                 **response_kw)
+            response = self.ResponseCls.from_httplib(httplib_response,
-                release_conn = True
+                release_this_conn = True
-            if release_conn:
+            if release_this_conn:
-                'https://urllib3.readthedocs.org/en/latest/security.html'),
+                'https://urllib3.readthedocs.io/en/latest/security.html'),
-            "https://urllib3.readthedocs.org/en/latest/contrib.html.",
+            "https://urllib3.readthedocs.io/en/latest/contrib.html.",
-        'https://urllib3.readthedocs.org/en/latest/contrib.html#socks-proxies'
+        'https://urllib3.readthedocs.io/en/latest/contrib.html#socks-proxies'
-
+# Copyright (c) 2010-2015 Benjamin Peterson
-__version__ = "1.2.0"  # Revision 41c74fef2ded
+__version__ = "1.10.0"
-# True if we are running on Python 3.
+# Useful for very coarse version differentiation.
-            del X
+        del X
-        delattr(tp, self.name)
+        setattr(obj, self.name, result)  # Invokes __set__.
-class _MovedItems(types.ModuleType):
+    __path__ = []  # mark as package
-    MovedAttribute("reload_module", "__builtin__", "imp", "reload"),
+    MovedAttribute("getcwd", "os", "os", "getcwdu", "getcwd"),
-
+    MovedAttribute("zip_longest", "itertools", "itertools", "izip_longest", "zip_longest"),
-    MovedModule("winreg", "_winreg"),
+    MovedModule("xmlrpc_client", "xmlrpclib", "xmlrpc.client"),
-moves = sys.modules[__name__ + ".moves"] = _MovedItems("moves")
+_MovedItems._moved_attributes = _moved_attributes
-    _iteritems = "items"
+    _func_globals = "__globals__"
-    _iteritems = "iteritems"
+    _func_globals = "func_globals"
-    Iterator = object
+    create_bound_method = types.MethodType
-        return any("__call__" in klass.__dict__ for klass in type(obj).__mro__)
+    def create_unbound_method(func, cls):
-    return iter(getattr(d, _iterkeys)())
+    def iteritems(d, **kw):
-    return iter(getattr(d, _itervalues)())
+    def iterlists(d, **kw):
-    return iter(getattr(d, _iteritems)())
+    viewkeys = operator.methodcaller("viewkeys")
-        int2byte = operator.methodcaller("to_bytes", 1, "big")
+    unichr = chr
-        return unicode(s, "unicode_escape")
+        return unicode(s.replace(r'\\', r'\\\\'), "unicode_escape")
-    exec_ = getattr(builtins, "exec")
+def assertCountEqual(self, *args, **kwargs):
-    def exec_(code, globs=None, locs=None):
+    def exec_(_code_, _globs_=None, _locs_=None):
-        if globs is None:
+        if _globs_ is None:
-                locs = frame.f_locals
+            _globs_ = frame.f_globals
-
+        elif _locs_ is None:
-        """The new-style print function."""
+        """The new-style print function for Python 2.4 and 2.5."""
-def with_metaclass(meta, base=object):
+def with_metaclass(meta, *bases):
-    return meta("NewBase", (base,), {})
+    # This requires a bit of explanation: the basic idea is to make a dummy
-        # Locally set the pool classes so other PoolManagers can override them.
+        # Locally set the pool classes and keys so other PoolManagers can
-        pool_key = (scheme, host, port)
+        request_context = self.connection_pool_kw.copy()
-            pool = self._new_pool(scheme, host, port)
+            pool = self._new_pool(pool_key.scheme, pool_key.host, pool_key.port)
-    for res in socket.getaddrinfo(host, port, 0, socket.SOCK_STREAM):
+
-            # This is the only addition urllib3 makes to this function.
+
-        indempotent (multiple requests with the same parameters end with the
+        idempotent (multiple requests with the same parameters end with the
-        A set of HTTP status codes that we should force a retry on.
+        A set of integer HTTP status codes that we should force a retry on.
-        A backoff factor to apply between attempts. urllib3 will sleep for::
+        A backoff factor to apply between attempts after the second try
-        for [0.1s, 0.2s, 0.4s, ...] between retries. It will never be longer
+        for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer
-                'https://urllib3.readthedocs.org/en/latest/security.html'
+                'https://urllib3.readthedocs.io/en/latest/security.html'
-        'https://urllib3.readthedocs.org/en/latest/security.html'
+        'https://urllib3.readthedocs.io/en/latest/security.html'
-            return self.raw.close()
+            self.raw.close()
-        chunks are recieved. If stream=False, data is returned as
+        chunks are received. If stream=False, data is returned as
-        question = b"sucess?"
+        question = b"success?"
-    Use .get and .set and include domain and path args in order to be more specific."""
+    Use .get and .set and include domain and path args in order to be more specific.
-        .. warning:: operation is O(n), not O(1)."""
+        .. warning:: operation is O(n), not O(1).
-        multiple domains."""
+        multiple domains.
-        from the jar. See itervalues() and iteritems()."""
+        from the jar.
-        jar. See values() and items()."""
+        jar.
-        from the jar. See iterkeys() and iteritems()."""
+        from the jar.
-        jar. See keys() and items()."""
+        jar.
-        from the jar. See iterkeys() and itervalues()."""
+        from the jar.
-        pairs."""
+        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
-        Returns False otherwise."""
+        Returns False otherwise.
-        requirements."""
+        requirements.
-
+        .. warning:: operation is O(n), not O(1).
-
+        case, use the more explicit set() method instead.
-        ``remove_cookie_by_name()``."""
+        ``remove_cookie_by_name()``.
-        conflicting cookies."""
+        """Requests uses this method internally to get cookie values.
-        and optionally domain and path."""
+        used elsewhere in Requests.
-    request."""
+    request.
-        """
+        """Initialize RequestException with `request` and `response` objects."""
-    """
+    """A file was opened in text mode, but Requests determined its binary length."""
-
+        header is removed beforehand.
-    explicit setting on that request, and the setting in the session. If a
+    """Determines appropriate setting for a given request, taking into account
-    Properly merges both requests and session hooks.
+    """Properly merges both requests and session hooks.
-        When being redirected we may want to strip authentication from the
+        """When being redirected we may want to strip authentication from the
-        This method re-evaluates the proxy configuration by considering the
+        """This method re-evaluates the proxy configuration by considering the
-
+        Adapters are sorted in descending order by key length.
-    A case-insensitive ``dict``-like object.
+    """A case-insensitive ``dict``-like object.
-    This function allows you to check if on IP belongs to a network subnet
+    """This function allows you to check if on IP belongs to a network subnet
-    Converts mask from /xx format to xxx.xxx.xxx.xxx
+    """Converts mask from /xx format to xxx.xxx.xxx.xxx
-    """
+    """Returns whether we should bypass proxies or not."""
-    Does not replace a present scheme with the one provided as an argument."""
+    Does not replace a present scheme with the one provided as an argument.
-    username,password."""
+    username,password.
-    This assumes ASCII unless told otherwise.
+    """Given a string object, regardless of type, returns a representation of
-    """Verifies that header value is a string which doesn't contain 
+    """Verifies that header value is a string which doesn't contain
-    """
+    """Given a url remove the fragment and the authentication part"""
-        When called with decode_unicode, Response.iter_content should always
+        """When called with decode_unicode, Response.iter_content should always
-        """
+        """Ensure that header updates are done case-insensitively."""
-        """ Check that you can set None as a valid timeout value.
+        """Check that you can set None as a valid timeout value.
-        """
+        """CaseInsensitiveDict instance with "Accept" header."""
-        """
+        """LookupDict instance with "bad_gateway" attribute."""
-        """
+        """If tell() raises errors, assume the cursor is at position zero."""
-    in no_proxy variable."""
+    in no_proxy variable.
-    """
+    """See: https://github.com/kennethreitz/requests/issues/2356"""
-    Tests for function should_bypass_proxies to check if proxy can be bypassed or not
+    """Tests for function should_bypass_proxies to check if proxy
-    iter_slices, guess_json_utf, super_len, to_native_string, 
+    iter_slices, guess_json_utf, super_len, to_native_string,
-    codes.permanent_redirect, # 308
+    codes.moved,               # 301
-            #Â authentication headers.
+            # authentication headers.
-          'resume_incomplete', 'resume',), # These 2 to be removed in 3.0
+          'resume_incomplete', 'resume',),  # These 2 to be removed in 3.0
-    if slice_length is None or slice_length <= 0: 
+    if slice_length is None or slice_length <= 0:
-        raise InvalidHeader("Header value %s must be of type str or bytes, " 
+        raise InvalidHeader("Header value %s must be of type str or bytes, "
-        close_server.set() # release server block
+        close_server.set()  # release server block
-                data={'some': 'data'}, files={'some': f})
+            post2 = requests.post(url, data={'some': 'data'}, files={'some': f})
-                         * 10**6) / 10**6)
+        total_seconds = ((td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6)
-        assert not r.ok # old behaviour - crashes here
+        assert not r.ok  # old behaviour - crashes here
-        headers_dict = {'bar': {'foo':'bar'}}
+        headers_dict = {'bar': {'foo': 'bar'}}
-            assert text == question 
+            assert text == question
-        
+
-            "HTTP/1.1 200 OK\r\n" + 
+            "HTTP/1.1 200 OK\r\n" +
-            
+            assert r.headers['Content-Length'] == '6'
-            block_server.set() # release server block
+            block_server.set()  # release server block
-        
+
-            
+
-            sock = socket.socket() 
+            sock = socket.socket()
-            
+
-~~~~~~~~
+requests.certs
-pythoncompat
+requests.compat
-# coding: utf-8
+# -*- coding: utf-8 -*-
-# coding: utf-8
+# -*- coding: utf-8 -*-
-# coding: utf-8
+# -*- coding: utf-8 -*-
-# coding: utf-8
+# -*- coding: utf-8 -*-
-# coding: utf-8
+# -*- coding: utf-8 -*-
-# coding: utf-8
+# -*- coding: utf-8 -*-
-    return characters. This prevents unintended header injection.
+    """Verifies that header value is a string which doesn't contain 
-        raise InvalidHeader("Invalid return character or leading space in header: %s" % name)
+    try:
-    def test_header_validation(self,httpbin):
+    def test_header_validation(self, httpbin):
-                      'bar': '1',
+                      'bar': u'fbbq'.encode('utf8'),
-                      'qux': str.encode(u'fbbq')}
+                      'qux': '1'}
-            http_error_msg = '%s Client Error: %s for url: %s' % (self.status_code, self.reason, self.url)
+            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)
-            http_error_msg = '%s Server Error: %s for url: %s' % (self.status_code, self.reason, self.url)
+            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)
-
+    if length is None or (length <= 0 and len(value) > 0):
-    """ The URL provided was somehow invalid. """
+    """The URL provided was somehow invalid."""
-    iter_slices, guess_json_utf, super_len, to_native_string)
+    iter_slices, guess_json_utf, super_len, to_native_string, 
-            self.headers = CaseInsensitiveDict()
+            for header in headers.items():
-from .exceptions import InvalidURL, FileModeWarning
+from .exceptions import InvalidURL, InvalidHeader, FileModeWarning
-    ProxyError)
+    ProxyError, InvalidHeader)
-        elif not isinstance(chunk_size, int):
+        elif chunk_size is not None and not isinstance(chunk_size, int):
-        """Ensure that chunk_size is passed as an integer, otherwise
+    def test_response_chunk_size_type(self):
-        return
+    if encoding is None:
-    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')
+        # check for encoding value of None
-    def send(self):
+    def send(self, request, stream=False, timeout=None, verify=True,
-            sock = self._create_socket_and_bind()
+            self.server_sock = self._create_socket_and_bind()
-            self.port = sock.getsockname()[1]
+            self.port = self.server_sock.getsockname()[1]
-            self._handle_requests(sock)
+            self._handle_requests()
-            sock.close()
+            self._close_server_sock_ignore_errors()
-    def _handle_requests(self, server_sock):
+    def _close_server_sock_ignore_errors(self):
-            sock = server_sock.accept()[0]
+            sock = self._accept_connection()
-    data = (i for i in [b'a', b'b', b'c'])
+    data = iter([b'a', b'b', b'c'])
-
+
-    requote_uri, select_proxy, super_len,
+    requote_uri, select_proxy, should_bypass_proxies, super_len,
-        proxy = proxies.get(urlparts.scheme)
+        return proxies.get('all', proxies.get(urlparts.scheme))
-    data = (i for i in [b'a', b'b', b'c']) 
+    data = (i for i in [b'a', b'b', b'c'])
-
+http_proxies = {'http': 'http://http.proxy',
-        ('file:///etc/motd', None),
+    'url, expected, proxies', (
-def test_select_proxies(url, expected):
+def test_select_proxies(url, expected, proxies):
-    def __init__(self, handler, host='localhost', port=0, requests_to_handle=1, wait_to_close_event=None):
+    def __init__(self, handler=None, host='localhost', port=0, requests_to_handle=1, wait_to_close_event=None):
-        self.handler = handler
+        self.handler = handler or consume_socket_content
-	"""
+        """
-            proxy = environ_proxies.get(scheme)
+            proxy = environ_proxies.get('all', environ_proxies.get(scheme))
-                new_proxies.setdefault(scheme, environ_proxies[scheme])
+                new_proxies.setdefault(scheme, proxy)
-        if not self.encoding and len(self.content) > 3:
+        if not self.encoding and self.content and len(self.content) > 3:
-        json='body'
+        json=body
-            # returns just that, but Python 3 returns a Unicode string.
+            # urllib3 requires a bytes-like body. Python 2's json.dumps
-            body = complexjson.dumps(json).encode('utf-8')
+            content_type = 'application/json'
-            body = complexjson.dumps(json)
+            # When urllib3 uses pyOpenSSL, it can only resume large uploads
-__version__ = 'dev'
+__version__ = '1.15.1'
-warnings.simplefilter('default', exceptions.SubjectAltNameWarning)
+warnings.simplefilter('default', exceptions.SubjectAltNameWarning, append=True)
-warnings.simplefilter('default', exceptions.SNIMissingWarning)
+warnings.simplefilter('default', exceptions.SNIMissingWarning, append=True)
-        self._container = {}
+        self._container = OrderedDict()
-from .packages.ssl_match_hostname import match_hostname
+from .packages.ssl_match_hostname import match_hostname, CertificateError
-            match_hostname(cert, asserted_hostname)
+            _match_hostname(cert, self.assert_hostname or hostname)
-        self.host = host
+        # httplib doesn't like it when we include brackets in ipv6 addresses
-    def _make_request(self, conn, method, url, timeout=_Default,
+    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,
-        conn.request(method, url, **httplib_request_kw)
+        if chunked:
-                pool_timeout=None, release_conn=None, **response_kw):
+                pool_timeout=None, release_conn=None, chunked=False,
-                                                  body=body, headers=headers)
+                                                  body=body, headers=headers,
-            # the request doesn't need to know about the connection. Otherwise
+            # the response doesn't need to know about the connection. Otherwise
-            response_conn = not release_conn and conn
+            response_conn = conn if not release_conn else None
-            #     ``response.read()``)
+            # Everything went great!
-            release_conn = True
+            clean_exit = False
-            release_conn = True
+            clean_exit = False
-            release_conn = True
+            clean_exit = False
-            retries = retries.increment(method, url, response=response, _pool=self)
+            try:
-        if sys.version_info <= (2, 6, 4) and not self.proxy_headers:   # Python 2.6.4 and older
+        if sys.version_info <= (2, 6, 4) and not self.proxy_headers:  # Python 2.6.4 and older
-                'https://urllib3.readthedocs.io/en/latest/security.html'),
+                'https://urllib3.readthedocs.org/en/latest/security.html'),
-            "https://urllib3.readthedocs.io/en/latest/contrib.html.",
+            "https://urllib3.readthedocs.org/en/latest/contrib.html.",
-from socket import _fileobject, timeout, error as SocketError
+from socket import timeout, error as SocketError
-DEFAULT_SSL_CIPHER_LIST = util.ssl_.DEFAULT_CIPHERS
+DEFAULT_SSL_CIPHER_LIST = util.ssl_.DEFAULT_CIPHERS.encode('ascii')
-        if ext_name != 'subjectAltName':
+        if ext_name != b'subjectAltName':
-        return _fileobject(self, mode, bufsize, close=True)
+    # Copy-pasted from Python 3.5 source code
-                raise SocketError(e)
+                raise SocketError(str(e))
-    # Disable TLS compression to migitate CRIME attack (issue #309)
+    # Disable TLS compression to mitigate CRIME attack (issue #309)
-        except UnicodeEncodeError:
+        except (UnicodeEncodeError, UnicodeDecodeError):
-    if not six.PY3:  # Python 2:
+    if not six.PY3 and isinstance(value, six.text_type):  # Python 2:
-            raise
+            # If no exception is thrown, we should avoid cleaning up
-                 backoff_factor=0, raise_on_redirect=True, _observed_errors=0):
+                 backoff_factor=0, raise_on_redirect=True, raise_on_status=True,
-                'https://urllib3.readthedocs.io/en/latest/security.html'
+                'certain SSL connections to fail. You can upgrade to a newer '
-        'https://urllib3.readthedocs.io/en/latest/security.html'
+        'certificate, which can cause validation failures. You can upgrade to '
-:copyright: (c) 2015 by Kenneth Reitz.
+:copyright: (c) 2016 by Kenneth Reitz.
-__build__ = 0x020902
+__version__ = '2.10.0'
-__build__ = 0x020901
+__version__ = '2.9.2'
-intersphinx_mapping = {'urllib3': ('http://urllib3.readthedocs.org/en/latest', None)}
+intersphinx_mapping = {'urllib3': ('http://urllib3.readthedocs.io/en/latest', None)}
-                'https://urllib3.readthedocs.org/en/latest/security.html'),
+                'https://urllib3.readthedocs.io/en/latest/security.html'),
-            "https://urllib3.readthedocs.org/en/latest/contrib.html.",
+            "https://urllib3.readthedocs.io/en/latest/contrib.html.",
-                'https://urllib3.readthedocs.org/en/latest/security.html'
+                'https://urllib3.readthedocs.io/en/latest/security.html'
-        'https://urllib3.readthedocs.org/en/latest/security.html'
+        'https://urllib3.readthedocs.io/en/latest/security.html'
-    proxy = proxies.get(urlparts.scheme+'://'+urlparts.hostname)
+    if urlparts.hostname is None:
-        if not isinstance(request, PreparedRequest):
+        if isinstance(request, Request):
-        req = requests.Request('GET', httpbin('get'), headers = headers)
+        req = requests.Request('GET', httpbin('get'), headers=headers)
-        items = prep.headers.items()
+        items = list(prep.headers.items())
-        connections.
+        Currently, this closes the PoolManager and any active ProxyManager,
-        self._store = collections.OrderedDict()
+        self._store = OrderedDict()
-        ses.headers = collections.OrderedDict()
+        ses.headers = OrderedDict()
-        headers = collections.OrderedDict([('Third', '3'), ('Fourth', '4')])
+        headers = OrderedDict([('Third', '3'), ('Fourth', '4')])
-        self._store = dict()
+        self._store = collections.OrderedDict()
-import threading 
+import threading
-        content += new_content 
+        content += new_content
-        more_to_read = select.select([sock], [], [], timeout)[0] 
+        more_to_read = select.select([sock], [], [], timeout)[0]
- 
+
-            "Content-Length: 0\r\n\r\n", 
+            "Content-Length: 0\r\n\r\n",
-        
+
-      
+        self.start()
-    
+                # avoid server from waiting for event timeouts
-        """
+        :rtype: requests.Response
-        class BufferedStream(object):
+        class TestStream(object):
-                    self.data = buffer(data)
+                self.data = data.encode()
-                    ret = buffer(self.data, self.index, size)
+                    ret = self.data[self.index:self.index + size]
-                    ret = buffer(self.data, self.index)
+                    ret = self.data[self.index:]
-        test = BufferedStream('test')
+        test = TestStream('test')
-        test = BufferedStream('test')
+        test = TestStream('test')
-            body.seek(0, 0)
+            end_pos = body.tell()
-    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': ('filename', fileobj)}``) for multipart encoding upload.
+    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
-        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
+        tuples. Order is retained if data is a list of tuples but arbitrary
-            prepared_request.method = method
+            self.rebuild_method(prepared_request, resp)
-    MissingSchema, ReadTimeout, Timeout, RetryError, TooManyRedirects)
+    MissingSchema, ReadTimeout, Timeout, RetryError, TooManyRedirects,
-    FileModeWarning,
+    FileModeWarning, ConnectTimeout, ReadTimeout
-from testserver.server import Server
+from tests.testserver.server import Server
-from testserver.server import Server
+from tests.testserver.server import Server
-        second_request = "put your hand down in the floor"
+        first_request = b'put your hands up in the air'
-            sock1.sendall(first_request.encode())
+            sock1.sendall(first_request)
-            sock2.sendall(second_request.encode())
+            sock2.sendall(second_request)
-            sock.sendall(b"hehehe, not received")
+            sock.sendall(b'hehehe, not received')
-        assert server.handler_results[0] == ''
+        assert server.handler_results[0] == b''
-        data = "bananadine"
+        data = b'bananadine'
-            sock.sendall(data.encode())
+            sock.sendall(data)
-    content = ""
+    content = b''
-            current_position = 0
+            # is actually a special file descriptor like stdin. In this
-        assert super_len(BoomFile()) == 5
+        assert super_len(BoomFile()) == 0
-        current_position = o.tell()
+        try:
-
+    @pytest.mark.parametrize('error', [IOError, OSError])
-    def test_cookie_duplicte_names_raises_cookie_conflict_error(self):
+    def test_cookie_duplicate_names_raises_cookie_conflict_error(self):
-
+
-from .compat import StringIO, u
+from .compat import StringIO, u
-    assert r.request.headers['Transfer-Encoding'] == 'chunked'
+
-from testserver.server import Server
+
-            assert r.text == 'roflol'
+            assert r.text == u'roflol'
-            assert r.text == ''
+            assert r.text == u''
-        assert server.handler_results[0] == ""
+        assert server.handler_results[0] == ''
-            sock.send(answer)
+            sock.sendall(answer)
-            sock.send(question)
+            sock.sendall(question)
-            sock.send(b'send something')
+            sock.sendall(b'send something')
-            sock.send(b'still alive')
+            sock.sendall(b'still alive')
-            sock1.send(first_request.encode())
+            sock1.sendall(first_request.encode())
-            sock2.send(second_request.encode())
+            sock2.sendall(second_request.encode())
-            sock.send(b"hehehe, not received")
+            sock.sendall(b"hehehe, not received")
-            sock.send(data.encode())
+            sock.sendall(data.encode())
-        # stop reading if no new data is received for a while 
+        # stop reading if no new data is received for a while
-    """ Dummy server using for unit testing """
+    """Dummy server using for unit testing"""
-        threading.Thread.__init__(self)
+        super(Server, self).__init__()
-        return server
+        return Server(text_response_handler, **kwargs)
-        server = cls.text_response_server(
+        return cls.text_response_server(
-            "Content-Length: 0\r\n\r\n", **kwargs
+            "Content-Length: 0\r\n\r\n", 
-    unittest.main()
+import threading
-            url = 'http://{}:{}/'.format(host, port)
+            url = 'http://{0}:{1}/'.format(host, port)
-            r = requests.get('http://{}:{}'.format(host, port))
+            r = requests.get('http://{0}:{1}'.format(host, port))
-            r = requests.get('http://{}:{}'.format(host, port))
+            r = requests.get('http://{0}:{1}'.format(host, port))
-            server_url = 'http://{}:{}'.format(host, port)
+            server_url = 'http://{0}:{1}'.format(host, port)
-    
+#!/usr/bin/python
-        new_content = sock.recv(chunks).decode("utf-8")
+        new_content = sock.recv(chunks)
-            sock.send(text.encode())
+            sock.send(text.encode('utf-8'))
-            self._handle_requests_and_close_server(sock)
+            self._handle_requests(sock)
-    def _handle_requests_and_close_server(self, server_sock):
+    def _handle_requests(self, server_sock):
-       self.ready_event.wait()
+       self.ready_event.wait(self.WAIT_EVENT_TIMEOUT)
-            self.stop_event.wait()
+            self.stop_event.wait(self.WAIT_EVENT_TIMEOUT)
-                # in the main thread
+                # avoid server from waiting for event timeouts 
-        """ can safely send generators """
+        """can safely send generators"""
-
+        assert r.status_code == 200
-def consume_socket_content(sock, chunks=65536, timeout=0.5):
+def consume_socket_content(sock, timeout=0.5):
-            more_to_read = False # empty recv means the socket disconnected
+        if not new_content:
-            more_to_read = select.select([sock], [], [], timeout)[0] 
+        content += new_content 
-import sys
+
-    replace_chars = " '\""
+    replace_chars = ' \'"'
-    for val in re.split(", *<", value):
+    for val in re.split(', *<', value):
-            url, params = val.split(";", 1)
+            url, params = val.split(';', 1)
-        link = {}
+        link = {'url': url.strip('<> \'"')}
-        for param in params.split(";"):
+        for param in params.split(';'):
-                key, value = param.split("=")
+                key, value = param.split('=')
-    Does not replace a present scheme with the one provided as an argument.'''
+    """Given a URL that may or may not have a scheme, prepend the given scheme.
-import os
+from requests.structures import CaseInsensitiveDict
-    select_proxy, super_len)
+    get_auth_from_url, get_encoding_from_headers,
-        del os.environ[request.param]
+    @pytest.fixture(autouse=True, params=['no_proxy', 'NO_PROXY'])
-# sphinx-quickstart on Sun Feb 13 23:54:25 2011.
+# sphinx-quickstart on Fri Feb 19 00:05:47 2016.
-# This file is execfile()d with the current directory set to its containing dir.
+# This file is execfile()d with the current directory set to its
-import sys, os
+import sys
-# -- General configuration -----------------------------------------------------
+# -- General configuration ------------------------------------------------
-# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
+# Add any Sphinx extension module names here, as strings. They can be
-    'alabaster'
+    'sphinx.ext.todo',
-# The suffix of source filenames.
+# The suffix(es) of source filenames.
-release = version
+release = __version__
-#language = None
+#
-# The reST default role (used for this markup: `text`) to use for all documents.
+# The reST default role (used for this markup: `text`) to use for all
-#add_function_parentheses = True
+add_function_parentheses = False
-#add_module_names = True
+add_module_names = True
-# -- Options for HTML output ---------------------------------------------------
+# If true, `todo` and `todoList` produce output, else they produce nothing.
-html_theme = 'default'
+html_theme = 'alabaster'
-  'github_banner': True
+    'show_powered_by': False,
-
+# Add any extra paths that contain custom files (such as robots.txt or
-#html_use_smartypants = True
+html_use_smartypants = False
-    'index':    ['sidebarintro.html', 'sourcelink.html', 'searchbox.html'],
+    'index':    ['sidebarintro.html', 'sourcelink.html', 'searchbox.html',
-                 'sourcelink.html', 'searchbox.html']
+                 'sourcelink.html', 'searchbox.html', 'hacks.html']
-#html_show_copyright = True
+html_show_copyright = True
-#latex_paper_size = 'letter'
+latex_elements = {
-#latex_font_size = '10pt'
+#'pointsize': '10pt',
-# (source start file, target name, title, author, documentclass [howto/manual]).
+# (source start file, target name, title,
-   u'Kenneth Reitz', 'manual'),
+    (master_doc, 'Requests.tex', u'Requests Documentation',
-# -- Options for manual page output --------------------------------------------
+# -- Options for manual page output ---------------------------------------
-     [u'Kenneth Reitz'], 1)
+    (master_doc, 'requests', u'Requests Documentation',
-# -- Options for Texinfo output ------------------------------------------------
+
-   'Requests', 'One line description of project.', 'Miscellaneous'),
+    (master_doc, 'Requests', u'Requests Documentation',
-texinfo_appendices = []
+#texinfo_appendices = []
-html_theme = 'alabaster'
+# If false, no module index is generated.
-__copyright__ = 'Copyright 2015 Kenneth Reitz'
+__copyright__ = 'Copyright 2016 Kenneth Reitz'
-
+        # Resolve URL in redirect cache, if available.
-TARPIT = "http://10.255.255.1"
+TARPIT = 'http://10.255.255.1'
-        (
+    @pytest.mark.parametrize(
-    )
+        ))
-        (
+    @pytest.mark.parametrize(
-    )
+        ))
-        }
+        heads = {key: 'Mozilla/5.0 (github.com/kennethreitz/requests)'}
-    )
+        ))
-        (
+        'url, params', (
-    )
+        ))
-    )
+        ))
-                                             open(filename, 'rb'))})
+        r = requests.Request(
-        req = requests.Request(u("POST"), httpbin('post'), files=files)
+        req = requests.Request(u('POST'), httpbin('post'), files=files)
-        assert prep.method == "POST"
+        assert prep.method == 'POST'
-                             'text/py-content-type')})
+            files={
-    )
+        ))
-    )
+        ))
-    )
+        ))
-)
+    ))
-)
+    ))
-            ),
+            pytest.mark.skipif('cStringIO is None')((cStringIO, 'Test')),
-        """ Ensures that we properly deal with different kinds of IO streams. """
+        """Ensures that we properly deal with different kinds of IO streams."""
-        in no_proxy variable."""
+    in no_proxy variable."""
-    )
+        ))
-    )
+        ))
-    )
+        ))
-    )
+        ))
-    )
+        ))
-)
+    ))
-)
+    ))
-)
+    ))
-)
+    ))
-    Morsel, cookielib, getproxies, str, urljoin, urlparse, is_py3,
+    Morsel, cookielib, getproxies, str, urlparse,
-
+from .compat import StringIO, u
-        (
+    @pytest.mark.parametrize(
-        requests.get(httpsbin_url('status', '301'), verify=httpbin_ca_bundle)
+    def test_pyopenssl_redirect(self, httpbin_secure, httpbin_ca_bundle):
-        files = {'file': open('test_requests.py', 'rb')}
+        files = {'file': open(__file__, 'rb')}
-        files = {'file': open('test_requests.py', 'rb')}
+        files = {'file': open(__file__, 'rb')}
-        # Test bytes:
+    @pytest.mark.parametrize('files', ('foo', b'foo', bytearray(b'foo')))
-        files = {'b': bytearray(b'foo')}
+        files = {'b': files}
-        (
+    @pytest.mark.parametrize(
-        (
+    @pytest.mark.parametrize(
-
+    @pytest.mark.parametrize(
-        assert 'must be an int or float' in str(e)
+            requests.get(httpbin('get'), timeout=timeout)
-class TestRedirects:
+def test_requests_are_updated_each_time(httpbin):
-    return [
+@pytest.mark.parametrize(
-def test_data_argument_accepts_tuples(list_of_tuples):
+    )
-        data='foo=bar',
+        data=data,
-        cookies={'foo': 'bar'}
+    assert p.body == urlencode(data)
-def test_prepare_unicode_url():
+)
-    assert_copy(p, p.copy())
+    if kwargs:
-        requests.Request('GET', httpbin(), hooks={'response': hook})
+        s = requests.Session()
-    )
+    builtin_str, OrderedDict)
-                                 ReadTimeout, Timeout, RetryError, TooManyRedirects)
+from requests.exceptions import (
-        'exception, url',
+    @pytest.mark.parametrize('exception, url',
-        'url, expected',
+    @pytest.mark.parametrize('url, expected',
-        """
+        """Show that even with redirects, Response.history is always a list."""
-        'url, exception',
+    @pytest.mark.parametrize('url, exception',
-        'cid',
+    @pytest.mark.parametrize('cid',
-        'value, exception',
+    @pytest.mark.parametrize('value, exception',
-        ]
+    ]
-    Ensure that the data argument will accept tuples of strings
+    """Ensure that the data argument will accept tuples of strings
-    test_requirements.append('pytest-cov')
+test_requirements = ['pytest>=2.8.0', 'pytest-httpbin==0.0.7', 'pytest-cov']
-        'Programming Language :: Python :: Implementation :: Jython',
+        'Programming Language :: Python :: Implementation :: PyPy'
-version = ''
+        'Programming Language :: Python :: 2.6',
-        pass
+class TestRequests:
-            requests.get('http://')
+    @pytest.mark.parametrize(
-        assert 'Content-Length' not in head_req.headers
+    @pytest.mark.parametrize('method', ('GET', 'HEAD'))
-        assert request.url == "http://example.com/path?key=value&a=b#fragment"
+    @pytest.mark.parametrize(
-    def test_mixed_case_scheme_acceptable(self, httpbin):
+    @pytest.mark.parametrize('scheme', ('http://', 'HTTP://', 'hTTp://', 'HttP://'))
-            assert r.status_code == 200, 'failed for scheme {0}'.format(scheme)
+        url = scheme + parts.netloc + parts.path
-        assert heads['User-agent'] in r.text
+    @pytest.mark.parametrize('key', ('User-agent', 'user-agent'))
-            'user-agent': 'Mozilla/5.0 (github.com/kennethreitz/requests)'
+            key: 'Mozilla/5.0 (github.com/kennethreitz/requests)'
-        assert heads['user-agent'] in r.text
+        assert heads[key] in r.text
-            requests.get("http://fe80::5054:ff:fe5a:fc0")
+    @pytest.mark.parametrize(
-        post1 = requests.post(url).raise_for_status()
+        requests.post(url).raise_for_status()
-        post1 = requests.post(url).raise_for_status()
+        requests.post(url).raise_for_status()
-        requests.get(httpbin('Ã¸'), params={'foo': 'foo'})
+    @pytest.mark.parametrize(
-
+    @pytest.mark.parametrize(
-            data={'stuff': 'elixr'.encode('utf-8')},
+            data=data,
-            i = i + 1
+            i += 1
-class TestContentEncodingDetection(unittest.TestCase):
+class TestContentEncodingDetection:
-        content = '<?xml version="1.0" encoding="UTF-8"?>'
+    @pytest.mark.parametrize(
-class TestCaseInsensitiveDict(unittest.TestCase):
+class TestCaseInsensitiveDict:
-        cid = CaseInsensitiveDict(FOO='foo', BAr='bar')
+    @pytest.mark.parametrize(
-class UtilsTestCase(unittest.TestCase):
+class TestUtils:
-        RFC 3986 are correclty extracted."""
+        RFC 3986 are correctly extracted."""
-class TestMorselToCookieExpires(unittest.TestCase):
+class TestMorselToCookieExpires:
-    def test_expires_invalid_int(self):
+    @pytest.mark.parametrize(
-        with pytest.raises(ValueError):
+        morsel['expires'] = value
-class TestMorselToCookieMaxAge(unittest.TestCase):
+class TestMorselToCookieMaxAge:
-            assert False, "The recv() request should time out."
+            pytest.fail('The recv() request should time out.')
-            assert False, "The connect() request should time out."
+            pytest.fail('The connect() request should time out.')
-            assert False, "The connect() request should time out."
+            pytest.fail('The connect() request should time out.')
-        ]
+        ])
-        ]
+        ])
-        return self.username == other.username and self.password == other.password
+        return all([
-            self.num_401_calls == other.num_401_calls
+        return all([
-    :param int max_retries: The maximum number of retries each connection
+    :param max_retries: The maximum number of retries each connection
-            requests.get(httpbin('redirect', '50'))
+            requests.get(httpbin('relative-redirect', '50'))
-            assert e.request.url == e.response.url
+            url = httpbin('relative-redirect', '20')
-            s.get(httpbin('redirect', '50'))
+            s.get(httpbin('relative-redirect', '50'))
-            assert e.request.url == e.response.url
+            url = httpbin('relative-redirect', '45')
-            pytest.fail('Expected redirect to raise TooManyRedirects but it did not')
+            pytest.fail('Expected custom max number of redirects to be respected but was not')
-            pytest.fail()
+            pytest.fail('Expected redirect to raise TooManyRedirects but it did not')
-            pytest.fail()
+            pytest.fail('Expected redirect to raise TooManyRedirects but it did not')
-                )
+                raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)
-from requests.models import PreparedRequest, DEFAULT_REDIRECT_LIMIT
+from requests.models import PreparedRequest
-            assert len(e.response.history) == DEFAULT_REDIRECT_LIMIT
+            assert '/relative-redirect/20' in e.request.url
-            assert False
+            pytest.fail()
-            assert e.request is not None
+            assert '/relative-redirect/45' in e.request.url
-            assert False
+            pytest.fail()
-    from distutils.core import setup
+from setuptools import setup
-        except TooManyRedirects, e:
+        except TooManyRedirects as e:
-        except TooManyRedirects, e:
+        except TooManyRedirects as e:
-                raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects)
+                raise TooManyRedirects(
-from requests.models import PreparedRequest
+                                 ReadTimeout, Timeout, RetryError, TooManyRedirects)
-  'show_powered_by': False
+  'show_powered_by': False,
-copyright = u'2015. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'2016. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-        proxy_scheme = ''
+
-            proxy_scheme = urlparse(proxy).scheme
+            proxy_scheme = urlparse(proxy).scheme.lower()
-        elif proxy and scheme != 'https':
+        url = request.path_url
-                    select_proxy)
+                    select_proxy, to_native_string)
-                    **proxy_kwargs)
+        if proxy in self.proxy_manager:
-        return self.proxy_manager[proxy]
+        return manager
-        proxy_scheme = urlparse(proxy).scheme
+        if proxy:
-                         ProxyError, RetryError)
+                         ProxyError, RetryError, InvalidSchema)
-                **proxy_kwargs)
+            if proxy.lower().startswith('socks'):
-        if proxy and scheme != 'https':
+        proxy_scheme = urlparse(proxy).scheme
-__version__ = '1.14'
+__version__ = 'dev'
-    from urllib3.exceptions import DependencyWarning
+    from ..exceptions import DependencyWarning
-from urllib3.connection import (
+from ..connection import (
-from urllib3.connectionpool import (
+from ..connectionpool import (
-from urllib3.util.url import parse_url
+from ..exceptions import ConnectTimeoutError, NewConnectionError
-__version__ = '1.13.1'
+__version__ = '1.14'
-    logger.debug('Added a stderr logging handler to logger: %s' % __name__)
+    logger.debug('Added a stderr logging handler to logger: %s', __name__)
-                 (self.num_connections, self.host))
+        log.info("Starting new HTTP connection (%d): %s",
-            log.info("Resetting dropped connection: %s" % self.host)
+            log.info("Resetting dropped connection: %s", self.host)
-                "Connection pool is full, discarding connection: %s" %
+                "Connection pool is full, discarding connection: %s",
-                                          httplib_response.length))
+        log.debug("\"%s %s %s\" %s %s", method, url, http_version,
-                        "broken by '%r': %s" % (retries, err, url))
+                        "broken by '%r': %s", retries, err, url)
-            log.info("Redirecting %s -> %s" % (url, redirect_location))
+            log.info("Redirecting %s -> %s", url, redirect_location)
-            log.info("Forced retry: %s" % url)
+            log.info("Forced retry: %s", url)
-                 % (self.num_connections, self.host))
+        log.info("Starting new HTTPS connection (%d): %s",
-            log.info("Forced retry: %s" % url)
+            log.info("Forced retry: %s", url)
-            if timeout.read is not timeout.connect:
+            if timeout._read is not timeout._connect:
-                  (self.num_connections, self.host, self.authurl))
+        log.debug('Starting NTLM HTTPS connection no. %d: https://%s%s',
-        log.debug('Request headers: %s' % headers)
+        log.debug('Request headers: %s', headers)
-        log.debug('Response data: %s [...]' % res.read(100))
+        log.debug('Response status: %s %s', res.status, res.reason)
-        log.debug('Request headers: %s' % headers)
+        log.debug('Request headers: %s', headers)
-        log.debug('Response data: %s [...]' % res.read()[:100])
+        log.debug('Response status: %s %s', res.status, res.reason)
-
+pool_classes_by_scheme = {
-        pool_cls = pool_classes_by_scheme[scheme]
+        pool_cls = self.pool_classes_by_scheme[scheme]
-        log.info("Redirecting %s -> %s" % (url, redirect_location))
+        log.info("Redirecting %s -> %s", url, redirect_location)
-    Checks, wether a the request of a response has been a HEAD-request.
+    Checks whether the request of a response has been a HEAD-request.
-        log.debug("Converted retries value: %r -> %r" % (retries, new_retries))
+        log.debug("Converted retries value: %r -> %r", retries, new_retries)
-        log.debug("Incremented Retry for (url='%s'): %r" % (url, new_retry))
+        log.debug("Incremented Retry for (url='%s'): %r", url, new_retry)
-        def wrap_socket(self, socket, server_hostname=None):
+        def wrap_socket(self, socket, server_hostname=None, server_side=False):
-__build__ = 0x020900
+__version__ = '2.9.1'
-        # Strip port numbers from netloc
+        # Strip port numbers from netloc. This weird `if...encode`` dance is
-            host = ri.netloc.split(b':')[0]
+            splitstr = splitstr.decode('ascii')
-__version__ = '1.13'
+__version__ = '1.13.1'
-            match_hostname(cert, self.assert_hostname or hostname)
+
-        host = ri.netloc.split(':')[0]
+        if isinstance(url, str):
-            return to_native_string(data)
+            return data
-__build__ = 0x020801
+__version__ = '2.9.0'
-
+from __future__ import absolute_import
-import warnings
+# SNIMissingWarnings should go off only once.
-    if not PY3: # Python 2
+    if not PY3:  # Python 2
-                            "arguments ({} given)".format(len(args)))
+                            "arguments ({0} given)".format(len(args)))
-    def from_httplib(cls, message): # Python 2
+    def from_httplib(cls, message):  # Python 2
-    from http.client import HTTPConnection as _HTTPConnection, HTTPException
+    from http.client import HTTPConnection as _HTTPConnection
-
+    from httplib import HTTPConnection as _HTTPConnection
-    HTTPSConnection = DummyConnection
+class DummyConnection(object):
-        self.ca_cert_dir = ca_cert_dir
+        self.ca_certs = ca_certs and os.path.expanduser(ca_certs)
-                            or self.assert_fingerprint is not None)
+        self.is_verified = (resolved_cert_reqs == ssl.CERT_REQUIRED or
-    import Queue as _  # Platform-specific: Windows
+    # Queue is imported for side effects on MS Windows
-    HTTPException, BaseSSLError, ConnectionError
+    HTTPException, BaseSSLError,
-## Pool objects
+# Pool objects
-        self.host = host.strip('[]')
+        self.host = host
-                    release_conn=release_conn, **response_kw)
+            return self.urlopen(
-                    release_conn=release_conn, **response_kw)
+            return self.urlopen(
-        if is_prod_appengine_v2():
+        if is_prod_appengine_mvms():
-            if 'too large' in e.message:
+            if 'too large' in str(e):
-            if 'Too many redirects' in e.message:
+            if 'Too many redirects' in str(e):
-        if is_prod_appengine_v1():
+        if is_prod_appengine():
-            if not timeout.read is timeout.connect:
+            if timeout.read is not timeout.connect:
-            is_prod_appengine_v2())
+            is_prod_appengine() or
-    return is_appengine() and not is_prod_appengine_v2()
+    return is_appengine() and not is_prod_appengine_mvms()
-def is_prod_appengine_v1():
+def is_prod_appengine():
-            not is_prod_appengine_v2())
+            not is_prod_appengine_mvms())
-def is_prod_appengine_v2():
+def is_prod_appengine_mvms():
-from socket import _fileobject, timeout
+from socket import _fileobject, timeout, error as SocketError
-                       + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,
+    ssl.CERT_REQUIRED:
-### Note: This is a slightly bug-fixed version of same from ndg-httpsclient.
+# Note: This is a slightly bug-fixed version of same from ndg-httpsclient.
-### Note: This is a slightly bug-fixed version of same from ndg-httpsclient.
+# Note: This is a slightly bug-fixed version of same from ndg-httpsclient.
-                raise
+                raise SocketError(e)
-            sent = self._send_until_done(data[total_sent:total_sent+SSL_WRITE_BLOCKSIZE])
+            sent = self._send_until_done(data[total_sent:total_sent + SSL_WRITE_BLOCKSIZE])
-            return self.connection.close()
+            try:
-## Base Exceptions
+
-## Leaf Exceptions
+# Leaf Exceptions
-                'ssl_version')
+                'ssl_version', 'ca_cert_dir')
-                raise TypeError('request got values for both \'fields\' and \'body\', can only specify one.')
+                raise TypeError(
-        if not self.chunked and preload_content and not self._body:
+        # If requested, preload the body.
-            data += buf + self._decoder.flush()
+        if flush_decoder and decode_content:
-            except HTTPException as e:
+            except (HTTPException, SocketError) as e:
-            if PY3: # Python 3
+            if PY3:  # Python 3
-            else: # Python 2
+            else:  # Python 2
-            raise ResponseNotChunked("Response is not chunked. "
+            raise ResponseNotChunked(
-                                   flush_decoder=True)
+                decoded = self._decode(chunk, decode_content=decode_content,
-        raise TypeError('expected httplib.Message, got {}.'.format(
+        raise TypeError('expected httplib.Message, got {0}.'.format(
-        self._observed_errors = _observed_errors # TODO: use .history instead?
+        self._observed_errors = _observed_errors  # TODO: use .history instead?
-    def increment(self, method=None, url=None, response=None, error=None, _pool=None, _stacktrace=None):
+    def increment(self, method=None, url=None, response=None, error=None,
-
+from __future__ import absolute_import
-from ..exceptions import SSLError, InsecurePlatformWarning
+from ..exceptions import SSLError, InsecurePlatformWarning, SNIMissingWarning
-import warnings
+
-    if cert_digest != fingerprint_bytes:
+    if not _const_compare_digest(cert_digest, fingerprint_bytes):
-            self._read is not self.DEFAULT_TIMEOUT):
+                self.total is not self.DEFAULT_TIMEOUT and
-    return s[:min_idx], s[min_idx+1:], min_delim
+    return s[:min_idx], s[min_idx + 1:], min_delim
-        verify=True,
+        stream=None,
-    :param verify: (optional) if ``True``, the SSL cert will be verified. A CA_BUNDLE path can also be provided.
+    :param verify: (optional) whether the SSL cert will be verified. A CA_BUNDLE path can also be provided. Defaults to ``True``.
-        verify=None,
+        stream=False,
-        :param verify: (optional) if ``True``, the SSL cert will be verified.
+        :param verify: (optional) whether the SSL cert will be verified.
-            A CA_BUNDLE path can also be provided.
+            A CA_BUNDLE path can also be provided. Defaults to ``True``.
-            assert r.headers['Content-Length'] == '6'
+            assert r.headers['Content-Length'] == '6' 
-            pass
+def consume_socket_content(sock, chunks=65536, timeout=0.5):
-    def text_response_server(cls, text, **kwargs):
+    def text_response_server(cls, text, request_timeout=0.5, **kwargs):
-            self.handler(sock)
+            handler_result = self.handler(sock)
-            )
+    def text_response_server(cls, text, **kwargs):
-        server = Server(basic_response_handler, **kwargs)
+    @classmethod
-        if qop is None:
+        if not qop:
-#html_theme_options = {}
+html_theme_options = {
-html_theme = 'kr'
+html_theme_path =[alabaster.get_path()]
-            sock, _ = server_sock.accept()
+        def handler(sock):
-import threading, socket
+import threading 
-    def __init__(self, handler, host='localhost', port=0):
+    def __init__(self, handler, host='localhost', port=0, requests_to_handle=1, wait_to_close_event=None):
-            sock, _ = server_sock.accept()
+    def basic_response_server(cls, **kwargs):
-        server = Server(basic_response_handler, host=host, port=port)
+        server = Server(basic_response_handler, **kwargs)
-            
+            self._handle_requests_and_close_server(sock)
-        # We're dealing with an instane of RequestsCookieJar
+        # We're dealing with an instance of RequestsCookieJar
-        #: We're unable to blindy call unicode/str functions
+        #: We're unable to blindly call unicode/str functions
-        """True if this Response one of the permanant versions of redirect"""
+        """True if this Response one of the permanent versions of redirect"""
-        #: Trust environement settings for proxy configuration, default
+        #: Trust environment settings for proxy configuration, default
-        """Returns the appropriate connnection adapter for the given URL."""
+        """Returns the appropriate connection adapter for the given URL."""
-    def test_session_hooks_are_overriden_by_request_hooks(self, httpbin):
+    def test_session_hooks_are_overridden_by_request_hooks(self, httpbin):
-        sock.close()
+    def test_server_closes(self):
-            self.stop_event.set()
+            self.stop_event.set()
-        sock.close()
+        return sock
-    """ Basic socket server used for unit testing """
+    """ Dummy server using for unit testing """
-    def __init__(self, handler, host='localhost', port=8021):
+    def __init__(self, handler, host='localhost', port=0):
-from dummyserver.server import Server
+from testserver.server import Server
-class TestDummyServer(unittest.TestCase):
+class TestTestServer(unittest.TestCase):
-    """ Dummy server using for unit testing """
+    """ Basic socket server used for unit testing """
-        answer = "yeah, success"
+        question = b"sucess?"
-"""
+    """ Dummy server using for unit testing """
-        # because self.poolmanager uses a lambda function, which isn't pickleable.
+        # self.poolmanager uses a lambda function, which isn't pickleable.
-            if length is not None:
+            if length:
-                            self.headers['Transfer-Encoding'] = 'chunked'
+                        if hasattr(data, 'fileno') and length == 0:
-        'security': ['pyOpenSSL', 'ndg-httpsclient', 'pyasn1'],
+        'security': ['pyOpenSSL>=0.13', 'ndg-httpsclient', 'pyasn1'],
-        return len(o)
+        total_length = len(o)
-        return o.len
+    elif hasattr(o, 'getvalue'):
-    if hasattr(o, 'fileno'):
+    elif hasattr(o, 'fileno'):
-            filesize = os.fstat(fileno).st_size
+            total_length = os.fstat(fileno).st_size
-            return filesize
+    if hasattr(o, 'tell'):
-        return len(o.getvalue())
+    return max(0, total_length - current_position)
-        if domain and domain != cookie.domain:
+        if domain is not None and domain != cookie.domain:
-        if path and path != cookie.path:
+        if path is not None and path != cookie.path:
-                clearables.append((cookie.domain, cookie.path, cookie.name))
+        if domain and domain != cookie.domain:
-                    clearables.append((cookie.domain, cookie.path, cookie.name))
+        if cookie.name != name:
-    return response
+    # By using the 'with' statement we are sure the session is closed, thus we
-                        r = conn.getresponse(buffering=True)
+                        r = low_conn.getresponse(buffering=True)
-                        r = conn.getresponse()
+                        r = low_conn.getresponse()
-            requests.get("http://httpbin.org:1", timeout=1)
+            requests.get("http://localhost:1", timeout=1)
-        assert not response._content_consumed is False
+        assert response._content_consumed is False
-        assert u"HTTPConnectionPool(host='httpbin.org', port=80): Pool is closed." in str(e)
+        assert u"Pool is closed." in str(e)
-        self.assertTrue(response.raw.closed)
+        assert not response._content_consumed is False
-    def test_no_content_length(self):
+    def test_no_content_length(self, httpbin):
-    def test_override_content_length(self):
+    def test_override_content_length(self, httpbin):
-    def test_mixed_case_scheme_acceptable(self):
+    def test_mixed_case_scheme_acceptable(self, httpbin):
-    def test_HTTP_200_OK_GET_ALTERNATIVE(self):
+    def test_HTTP_200_OK_GET_ALTERNATIVE(self, httpbin):
-    def test_HTTP_302_ALLOW_REDIRECT_GET(self):
+    def test_HTTP_302_ALLOW_REDIRECT_GET(self, httpbin):
-    def test_HTTP_200_OK_GET_WITH_PARAMS(self):
+    def test_HTTP_200_OK_GET_WITH_PARAMS(self, httpbin):
-    def test_HTTP_200_OK_GET_WITH_MIXED_PARAMS(self):
+    def test_HTTP_200_OK_GET_WITH_MIXED_PARAMS(self, httpbin):
-    def test_set_cookie_on_301(self):
+    def test_set_cookie_on_301(self, httpbin):
-    def test_cookie_sent_on_redirect(self):
+    def test_cookie_sent_on_redirect(self, httpbin):
-    def test_cookie_removed_on_expire(self):
+    def test_cookie_removed_on_expire(self, httpbin):
-    def test_cookie_quote_wrapped(self):
+    def test_cookie_quote_wrapped(self, httpbin):
-    def test_cookie_persists_via_api(self):
+    def test_cookie_persists_via_api(self, httpbin):
-    def test_request_cookie_overrides_session_cookie(self):
+    def test_request_cookie_overrides_session_cookie(self, httpbin):
-    def test_request_cookies_not_persisted(self):
+    def test_request_cookies_not_persisted(self, httpbin):
-    def test_generic_cookiejar_works(self):
+    def test_generic_cookiejar_works(self, httpbin):
-    def test_param_cookiejar_works(self):
+    def test_param_cookiejar_works(self, httpbin):
-    def test_requests_in_history_are_not_overridden(self):
+    def test_requests_in_history_are_not_overridden(self, httpbin):
-    def test_history_is_always_a_list(self):
+    def test_history_is_always_a_list(self, httpbin):
-    def test_headers_on_session_with_None_are_not_sent(self):
+    def test_headers_on_session_with_None_are_not_sent(self, httpbin):
-    def test_user_agent_transfers(self):
+    def test_user_agent_transfers(self, httpbin):
-    def test_HTTP_200_OK_HEAD(self):
+    def test_HTTP_200_OK_HEAD(self, httpbin):
-    def test_HTTP_200_OK_PUT(self):
+    def test_HTTP_200_OK_PUT(self, httpbin):
-    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self):
+    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self, httpbin):
-    def test_basicauth_with_netrc(self):
+    def test_basicauth_with_netrc(self, httpbin):
-    def test_DIGEST_HTTP_200_OK_GET(self):
+    def test_DIGEST_HTTP_200_OK_GET(self, httpbin):
-    def test_DIGEST_AUTH_RETURNS_COOKIE(self):
+    def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):
-    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self):
+    def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):
-    def test_DIGEST_STREAM(self):
+    def test_DIGEST_STREAM(self, httpbin):
-    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self):
+    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self, httpbin):
-    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self):
+    def test_DIGESTAUTH_QUOTES_QOP_VALUE(self, httpbin):
-    def test_DIGESTAUTH_THREADED(self):
+    def test_DIGESTAUTH_THREADED(self, httpbin):
-    def test_POSTBIN_GET_POST_FILES(self):
+    def test_POSTBIN_GET_POST_FILES(self, httpbin):
-    def test_POSTBIN_GET_POST_FILES_WITH_DATA(self):
+    def test_POSTBIN_GET_POST_FILES_WITH_DATA(self, httpbin):
-    def test_conflicting_post_params(self):
+    def test_conflicting_post_params(self, httpbin):
-    def test_request_ok_set(self):
+    def test_request_ok_set(self, httpbin):
-    def test_status_raising(self):
+    def test_status_raising(self, httpbin):
-    def test_decompress_gzip(self):
+    def test_decompress_gzip(self, httpbin):
-    def test_unicode_get(self):
+    def test_unicode_get(self, httpbin):
-    def test_unicode_header_name(self):
+    def test_unicode_header_name(self, httpbin):
-        requests.get('https://httpbin.org/status/301')
+    def test_pyopenssl_redirect(self, httpsbin_url, httpbin_ca_bundle):
-    def test_urlencoded_get_query_multivalued_param(self):
+    def test_urlencoded_get_query_multivalued_param(self, httpbin):
-    def test_different_encodings_dont_break_post(self):
+    def test_different_encodings_dont_break_post(self, httpbin):
-    def test_unicode_multipart_post(self):
+    def test_unicode_multipart_post(self, httpbin):
-    def test_unicode_multipart_post_fieldnames(self):
+    def test_unicode_multipart_post_fieldnames(self, httpbin):
-    def test_unicode_method_name(self):
+    def test_unicode_method_name(self, httpbin):
-    def test_unicode_method_name_with_request_object(self):
+    def test_unicode_method_name_with_request_object(self, httpbin):
-    def test_custom_content_type(self):
+    def test_custom_content_type(self, httpbin):
-    def test_hook_receives_request_arguments(self):
+    def test_hook_receives_request_arguments(self, httpbin):
-        requests.Request('GET', HTTPBIN, hooks={'response': hook})
+        requests.Request('GET', httpbin(), hooks={'response': hook})
-    def test_session_hooks_are_used_with_no_request_hooks(self):
+    def test_session_hooks_are_used_with_no_request_hooks(self, httpbin):
-        r = requests.Request('GET', HTTPBIN)
+        r = requests.Request('GET', httpbin())
-    def test_session_hooks_are_overriden_by_request_hooks(self):
+    def test_session_hooks_are_overriden_by_request_hooks(self, httpbin):
-        r = requests.Request('GET', HTTPBIN, hooks={'response': [hook1]})
+        r = requests.Request('GET', httpbin(), hooks={'response': [hook1]})
-    def test_prepared_request_hook(self):
+    def test_prepared_request_hook(self, httpbin):
-        req = requests.Request('GET', HTTPBIN, hooks={'response': hook})
+        req = requests.Request('GET', httpbin(), hooks={'response': hook})
-    def test_prepared_from_session(self):
+    def test_prepared_from_session(self, httpbin):
-    def test_time_elapsed_blank(self):
+    def test_time_elapsed_blank(self, httpbin):
-    def test_request_and_response_are_pickleable(self):
+    def test_request_and_response_are_pickleable(self, httpbin):
-        r = requests.Request(url=HTTPBIN)
+    def test_cannot_send_unprepared_requests(self, httpbin):
-    def test_session_pickling(self):
+    def test_session_pickling(self, httpbin):
-    def test_fixes_1329(self):
+    def test_fixes_1329(self, httpbin):
-    def test_uppercase_scheme_redirect(self):
+    def test_uppercase_scheme_redirect(self, httpbin):
-    def test_header_remove_is_case_insensitive(self):
+    def test_header_remove_is_case_insensitive(self, httpbin):
-    def test_params_are_merged_case_sensitive(self):
+    def test_params_are_merged_case_sensitive(self, httpbin):
-    def test_header_keys_are_native(self):
+    def test_header_keys_are_native(self, httpbin):
-    def test_can_send_nonstring_objects_with_files(self):
+    def test_can_send_nonstring_objects_with_files(self, httpbin):
-    def test_can_send_bytes_bytearray_objects_with_files(self):
+    def test_can_send_bytes_bytearray_objects_with_files(self, httpbin):
-    def test_can_send_file_object_with_non_string_filename(self):
+    def test_can_send_file_object_with_non_string_filename(self, httpbin):
-    def test_autoset_header_values_are_native(self):
+    def test_autoset_header_values_are_native(self, httpbin):
-    def test_auth_is_stripped_on_redirect_off_host(self):
+    def test_auth_is_stripped_on_redirect_off_host(self, httpbin):
-    def test_auth_is_retained_for_redirect_on_host(self):
+    def test_auth_is_retained_for_redirect_on_host(self, httpbin):
-    def test_manual_redirect_with_partial_body_read(self):
+    def test_manual_redirect_with_partial_body_read(self, httpbin):
-    def test_redirect_with_wrong_gzipped_header(self):
+    def test_redirect_with_wrong_gzipped_header(self, httpbin):
-    def test_requests_history_is_saved(self):
+    def test_requests_history_is_saved(self, httpbin):
-    def test_json_param_post_content_type_works(self):
+    def test_json_param_post_content_type_works(self, httpbin):
-        r = requests.Request(method='POST', url='http://httpbin.org/post',
+    def test_json_param_post_should_not_override_data_param(self, httpbin):
-    def test_response_iter_lines(self):
+    def test_response_iter_lines(self, httpbin):
-    def test_unconsumed_session_response_closes_connection(self):
+    def test_unconsumed_session_response_closes_connection(self, httpbin):
-    def test_response_iter_lines_reentrant(self):
+    def test_response_iter_lines_reentrant(self, httpbin):
-    def test_stream_timeout(self):
+    def test_stream_timeout(self, httpbin):
-    def test_invalid_timeout(self):
+    def test_invalid_timeout(self, httpbin):
-    def test_none_timeout(self):
+    def test_none_timeout(self, httpbin):
-    def test_read_timeout(self):
+    def test_read_timeout(self, httpbin):
-    def test_encoded_methods(self):
+    def test_encoded_methods(self, httpbin):
-    def test_requests_are_updated_each_time(self):
+    def test_requests_are_updated_each_time(self, httpbin):
-def test_urllib3_retries():
+def test_urllib3_retries(httpbin):
-def test_urllib3_pool_connection_closed():
+def test_urllib3_pool_connection_closed(httpbin):
-        requests.sessions.get_netrc_auth = get_netrc_auth_mock
+        old_auth = requests.sessions.get_netrc_auth
-        assert r.status_code == 401
+        try:
-                   'https://', 'HTTPS://', 'hTTps://', 'HttPs://']
+        schemes = ['http://', 'HTTP://', 'hTTp://', 'HttP://']
-class RequestsTestCase(unittest.TestCase):
+class TestRequests(object):
-HTTPBIN = HTTPBIN.rstrip('/') + '/'
+@pytest.fixture
-    return urljoin(HTTPBIN, '/'.join(suffix))
+    return inner
-            conn.ca_certs = cert_loc
+
-        'Programming Language :: Python :: 3.4'
+        'Programming Language :: Python :: 3.4',
-    TooManyRedirects, HTTPError, ConnectionError
+    TooManyRedirects, HTTPError, ConnectionError,
-from .exceptions import InvalidURL
+from .exceptions import InvalidURL, FileModeWarning
-            return os.fstat(fileno).st_size
+            filesize = os.fstat(fileno).st_size
-            return data
+            return to_native_string(data)
-                    r = low_conn.getresponse()
+                    # Receive the response from the server
-      200
+      <Response [200]>
-      200
+      <Response [200]>
-__build__ = 0x020800
+__version__ = '2.8.1'
-            self.method = self.method.upper()
+            self.method = to_native_string(self.method.upper())
-
+    def test_unicode_method_name_with_request_object(self):
-        if data == {} and json is not None:
+        if not data and json is not None:
-                raise ConnectTimeout(e, request=request)
+                # TODO: Remove this in 3.0.0: see #2811
-__build__ = 0x020700
+__version__ = '2.8.0'
-__version__ = 'dev'
+__version__ = '1.12'
-class HTTPHeaderDict(dict):
+class HTTPHeaderDict(MutableMapping):
-        dict.__init__(self)
+        super(HTTPHeaderDict, self).__init__()
-        return _dict_setitem(self, key.lower(), (key, val))
+        self._container[key.lower()] = (key, val)
-        val = _dict_getitem(self, key.lower())
+        val = self._container[key.lower()]
-        return _dict_delitem(self, key.lower())
+        del self._container[key.lower()]
-        return _dict_contains(self, key.lower())
+        return key.lower() in self._container
-        return dict((k1, self[k1]) for k1 in self) == dict((k2, other[k2]) for k2 in other)
+        return (dict((k.lower(), v) for k, v in self.itermerged()) ==
-    
+    def __len__(self):
-        vals = _dict_setdefault(self, key_lower, new_vals)
+        vals = self._container.setdefault(key_lower, new_vals)
-                _dict_setitem(self, key_lower, [vals[0], vals[1], val])
+                self._container[key_lower] = [vals[0], vals[1], val]
-        
+
-            vals = _dict_getitem(self, key.lower())
+            vals = self._container[key.lower()]
-            val = _dict_getitem(other, key)
+            val = other.getlist(key)
-            _dict_setitem(self, key, val)
+            self._container[key.lower()] = [key] + val
-            vals = _dict_getitem(self, key)
+            vals = self._container[key.lower()]
-            val = _dict_getitem(self, key)
+            val = self._container[key.lower()]
-        # efficiently. This function re-reads raw lines from the message 
+        # efficiently. This function re-reads raw lines from the message
-         
+
-    
+
-from socket import timeout as SocketTimeout
+from socket import error as SocketError, timeout as SocketTimeout
-    SystemTimeWarning,
+    SystemTimeWarning,
-        except SocketTimeout:
+        except SocketTimeout as e:
-                 assert_hostname=None, assert_fingerprint=None):
+                 assert_hostname=None, assert_fingerprint=None,
-        if ca_certs and cert_reqs is None:
+        if (ca_certs or ca_cert_dir) and cert_reqs is None:
- 
+
-        except (TimeoutError, HTTPException, SocketError, ConnectionError) as e:
+        except (TimeoutError, HTTPException, SocketError, ProtocolError) as e:
-            if isinstance(e, SocketError) and self.proxy:
+            if isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
-    into an SSL socket.
+    The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
-                 **conn_kw):
+                 ca_cert_dir=None, **conn_kw):
-                    ssl_version=None):
+                    ssl_version=None, ca_cert_dir=None):
-    if ca_certs:
+    if ca_certs or ca_cert_dir:
-            ctx.load_verify_locations(ca_certs, None)
+            ctx.load_verify_locations(ca_certs, ca_cert_dir)
-    import httplib
+from .packages.six.moves import http_client as httplib
-            err = _
+        except socket.error as e:
-        raise socket.error("getaddrinfo returns an empty list")
+
-    import httplib
+from ..packages.six.moves import http_client as httplib
-            self.ca_certs = location
+        def load_verify_locations(self, cafile=None, capath=None):
-                    ssl_version=None, ciphers=None, ssl_context=None):
+                    ssl_version=None, ciphers=None, ssl_context=None,
-    meaning as they do when using :func:`ssl.wrap_socket`.
+    All arguments except for server_hostname, ssl_context, and ca_cert_dir have
-    if ca_certs:
+    if ca_certs or ca_cert_dir:
-            context.load_verify_locations(ca_certs)
+            context.load_verify_locations(ca_certs, ca_cert_dir)
-                     '%s/%s' % (p_system, p_release)])
+    return '%s/%s' % (name, __version__)
-        return self.status_code < 400
+        try:
-        return True
+        """True if the status code does *not* indicate an error, i.e. status code < 400."""
-        #: Should we trust the environment?
+        #: Trust environement settings for proxy configuration, default
-    :param json: json for the body to attach to the request (if data is not specified).
+    :param json: json for the body to attach to the request (if files or data is not specified).
-    return hook_data
+    return hook_data
-
+from collections import defaultdict
-    return hooks
+    return dict((event, []) for event in HOOKS)
-
+    hooks = hooks.get(key)
-    return hook_data
+    return hook_data
-for (code, titles) in list(_codes.items()):
+for code, titles in _codes.items():
-                             data={'stuff'.encode('utf-8'): 'elixr'},
+                             data={'stuff': 'elixr'},
-        if not data and json is not None:
+        if data == {} and json is not None:
-                             json={'music'.encode('utf-8'): 'flute'})
+                             json={'music': 'flute'})
-        if json is not None:
+        if not data and json is not None:
-                if data and json is None:
+                if data:
-        scheme = urlparse(request.url.lower()).scheme
+        scheme = urlparse(request.url).scheme
-    urlparts = urlparse(url.lower())
+    urlparts = urlparse(url)
-        if proxy and not request.url.lower().startswith('https'):
+        scheme = urlparse(request.url.lower()).scheme
-        :param proxies: A dictionary of schemes to proxy URLs.
+        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
-    """Select a proxy, if applicable."""
+    """Select a proxy for the url, if applicable.
-                    prepend_scheme_if_needed, get_auth_from_url, urldefragauth)
+                    prepend_scheme_if_needed, get_auth_from_url, urldefragauth,
-            proxy = proxies.get(urlparts.scheme)
+        proxy = select_proxy(url, proxies)
-        if proxy and urlparts.scheme != 'https':
+        proxy = select_proxy(request.url, proxies)
-        #: :class:`Request <Request>`.
+        #: Dictionary mapping protocol or protocol and host to the URL of the proxy
-            the proxy.
+        :param proxies: (optional) Dictionary mapping protocol or protocol and
-        proxy = proxies.get(scheme)
+        urlparts = urlparse(request.url.lower())
-        if proxy and scheme != 'https':
+        if proxy and urlparts.scheme != 'https':
-        proxy = proxies.get(u.scheme+'://'+u.hostname, proxies.get(u.scheme))
+        urlparts = urlparse(url.lower())
-    Morsel, cookielib, getproxies, str, urljoin, urlparse, is_py3, builtin_str)
+    Morsel, cookielib, getproxies, str, urljoin, urlparse, is_py3,
-        param_ordered_dict = collections.OrderedDict((('z', 1), ('a', 1), ('k', 1), ('d', 1)))
+        param_ordered_dict = OrderedDict((('z', 1), ('a', 1), ('k', 1), ('d', 1)))
-            :class:`Request`.
+        :param data: (optional) Dictionary, bytes, or file-like object to send
-        proxy = proxies.get(urlparse(url.lower()).scheme)
+        u = urlparse(url.lower())
-            del merged_setting[k]
+    # Remove keys that are set to None. Extract keys first to avoid altering
-            timeout <user/advanced.html#timeouts>`_) tuple.
+            data before giving up, as a float, or a :ref:`(connect timeout,
-        <user/advanced.html#timeouts>`_) tuple.
+        before giving up, as a float, or a :ref:`(connect timeout, read
-            timeout <user/advanced.html#timeouts>`_) tuple.
+            data before giving up, as a float, or a :ref:`(connect timeout,
-        no_proxy = no_proxy.replace(' ', '').split(',')
+        no_proxy = (
-    for (k, v) in request_setting.items():
+    for (k, v) in merged_setting.items():
-
+    def test_params_original_order_is_preserved_by_default(self):
-        assert u"HTTPConnectionPool(host='httpbin.org', port=80): Pool is closed." in str(e.message)
+        assert u"HTTPConnectionPool(host='httpbin.org', port=80): Pool is closed." in str(e)
-__version__ = '1.10.4'
+__version__ = 'dev'
-    SecurityWarning,
+    SubjectAltNameWarning,
-                    SecurityWarning
+                    'Certificate for {0} has no `subjectAltName`, falling back to check for a '
-from .util.url import get_host
+from .util.url import get_host, Url
-        in multithreaded situations. If ``block`` is set to false, more
+        in multithreaded situations. If ``block`` is set to False, more
-
+ 
-                conn = None
+            conn = conn and conn.close()
-                conn = None
+            conn = conn and conn.close()
-                conn = None
+            # Discard the connection for these exceptions. It will be
-            data = data[sent:]
+        if has_memoryview and not isinstance(data, memoryview):
-            return self.connection.shutdown()
+            return self.connection.close()
-            raise ssl.SSLError('bad handshake', e)
+            raise ssl.SSLError('bad handshake: %r' % e)
-from .exceptions import LocationValueError, MaxRetryError
+from .exceptions import LocationValueError, MaxRetryError, ProxySchemeUnknown
-            'Not supported proxy scheme %s' % proxy.scheme
+        if proxy.scheme not in ("http", "https"):
-    def request_encode_url(self, method, url, fields=None, **urlopen_kw):
+    def request_encode_url(self, method, url, fields=None, headers=None,
-        return self.urlopen(method, url, **urlopen_kw)
+
-from .util.response import is_fp_closed
+from .util.response import is_fp_closed, is_response_to_head
-                    data = self._fp.read()
+        data = None
-                raise ProtocolError('Connection broken: %r' % e, e)
+        if data:
-            return data
+        return data
-                self.release_conn()
+
-            # FIXME: Can we do this somehow without accessing private httplib _method?
+        # Don't bother reading the body of a HEAD request.
-        self.release_conn()
+        with self._error_catcher():
-        than :attr:`Retry.MAX_BACKOFF`.
+        than :attr:`Retry.BACKOFF_MAX`.
-        raise SSLError('Fingerprint is of invalid length.')
+    digest_length = len(fingerprint)
-    if not cert_digest == fingerprint_bytes:
+    if cert_digest != fingerprint_bytes:
-                               hexlify(cert_digest)))
+                       .format(fingerprint, hexlify(cert_digest)))
-        assert cid == cid.copy()
+        cid_copy = cid.copy()
-        assert cid.__eq__(object()) == NotImplemented
+        assert cid != object()
-                low_conn = conn._get_conn(timeout=timeout)
+                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
-def get_netrc_auth(url, ignore_errors=True):
+def get_netrc_auth(url, raise_errors=False):
-            if not ignore_errors:
+            # we'll just skip netrc auth unless explicitly asked to raise errors.
-def get_netrc_auth(url):
+def get_netrc_auth(url, ignore_errors=True):
-            pass
+            if not ignore_errors:
-            http_error_msg = '%s Client Error: %s' % (self.status_code, self.reason)
+            http_error_msg = '%s Client Error: %s for url: %s' % (self.status_code, self.reason, self.url)
-            http_error_msg = '%s Server Error: %s' % (self.status_code, self.reason)
+            http_error_msg = '%s Server Error: %s for url: %s' % (self.status_code, self.reason, self.url)
-        self.assertTrue(response.raw.closed, True)
+        self.assertFalse(response._content_consumed)
-            expires = time.time() + float(morsel['max-age'])
+            expires = int(time.time() + int(morsel['max-age']))
-            pass
+            raise TypeError('max-age: %s must be integer' % morsel['max-age'])
-            time.strptime(morsel['expires'], time_template)) - time.timezone
+        expires = int(time.mktime(
-                    return json.loads(self.content.decode(encoding), **kwargs)
+                    return complexjson.loads(
-        return json.loads(self.text, **kwargs)
+        return complexjson.loads(self.text, **kwargs)
-    is_py2, chardet, json, builtin_str, basestring)
+    is_py2, chardet, builtin_str, basestring)
-            body = json.dumps(json)
+            body = complexjson.dumps(json)
-        expires = time.time() + float(morsel['max-age'])
+        try:
-                    return json.loads(self.content.decode(encoding), **kwargs)
+                    return complexjson.loads(
-        return json.loads(self.text, **kwargs)
+        return complexjson.loads(self.text, **kwargs)
-    is_py2, chardet, json, builtin_str, basestring)
+    is_py2, chardet, builtin_str, basestring)
-            body = json.dumps(json)
+            body = complexjson.dumps(json)
-        expires = time.time() + morsel['max-age']
+        expires = time.time() + float(morsel['max-age'])
-            r.raw.release_conn()
+            r.close()
-                # Special case for urllib3.
+            # Special case for urllib3.
-            except AttributeError:
+            else:
-                              filename=fn, headers=fh)
+            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)
-        json=None):
+    def __init__(self, method=None, url=None, headers=None, files=None,
-                json=None):
+        data=None, params=None, auth=None, cookies=None, hooks=None, json=None):
-                                    to_native_string(url, 'utf8')))
+            error = ("Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?")
-        'request',
+        '_content', 'status_code', 'headers', 'url', 'history',
-            body = json_dumps(json)
+            body = json.dumps(json)
-requests HTTP library
+Requests HTTP library
-__build__ = 0x020602
+__version__ = '2.7.0'
-__version__ = '1.10.3'
+__version__ = '1.10.4'
-warnings.simplefilter('always', exceptions.SecurityWarning)
+warnings.simplefilter('always', exceptions.SecurityWarning, append=True)
-warnings.simplefilter('default', exceptions.InsecurePlatformWarning)
+warnings.simplefilter('default', exceptions.InsecurePlatformWarning,
-        if tr_enc.lower() == "chunked":
+        tr_enc = self.headers.get('transfer-encoding', '').lower()
-                self._body = self.read(decode_content=decode_content)
+        if not self.chunked and preload_content and not self._body:
-                self._decoder = _get_decoder(content_encoding)
+        if self._decoder is None and content_encoding in self.CONTENT_DECODERS:
-                yield self._decode(line, decode_content, True)
+            for line in self.read_chunked(amt, decode_content=decode_content):
-        #        a better structured logic.
+    def _update_chunk_length(self):
-                self.chunk_left = None
+            self._update_chunk_length()
-
+        if path and not path.startswith('/'):
-def get(url, **kwargs):
+def get(url, params=None, **kwargs):
-    return request('get', url, **kwargs)
+    return request('get', url, params=params, **kwargs)
-from . import urllib3
+try:
-__build__ = 0x020601
+__version__ = '2.6.2'
-                self._decoder = _get_decoder(content_encoding)
+        self._init_decoder()
-                data += buf + self._decoder.flush()
+            data = self._decode(data, decode_content, flush_decoder)
-                yield line
+                yield self._decode(line, decode_content, True)
-sys.meta_path.insert(0, VendorAlias(["urllib3", "chardet"]))
+from . import urllib3
-__version__ = '1.10.2'
+__version__ = '1.10.3'
-__build__ = 0x020600
+__version__ = '2.6.1'
-# Set security warning to always go off by default.
+# SecurityWarning's always go off by default.
-    def extend(*args, **kwargs):
+    def extend(self, *args, **kwargs):
-            raise TypeError("update() takes at most 2 positional "
+        if len(args) > 1:
-        other = args[1] if len(args) >= 2 else ()
+        other = args[0] if len(args) >= 1 else ()
-        if isinstance(other, Mapping):
+        if isinstance(other, HTTPHeaderDict):
-    def from_httplib(cls, message, duplicates=('set-cookie',)): # Python 2
+    def from_httplib(cls, message): # Python 2
-            return ret
+        # python2.7 does not expose a proper API for exporting multiheaders
-    "!aNULL:!MD5:!DSS"
+DEFAULT_SSL_CIPHER_LIST = util.ssl_.DEFAULT_CIPHERS
-            select.select([sock], [], [])
+            rd, _, _ = select.select([sock], [], [], sock.gettimeout())
-from .exceptions import ProtocolError, DecodeError, ReadTimeoutError
+from .exceptions import (
-            self._body = self.read(decode_content=decode_content)
+        # Are we using the chunked-style of transfer encoding?
-            data = self.read(amt=amt, decode_content=decode_content)
+        if self.chunked:
-                yield data
+                if data:
-import ssl
+    import ssl
-    )
+# A secure default.
-        supports_set_ciphers = sys.version_info >= (2, 7)
+        supports_set_ciphers = ((2, 7) <= sys.version_info < (3,) or
-def create_urllib3_context(ssl_version=None, cert_reqs=ssl.CERT_REQUIRED,
+def create_urllib3_context(ssl_version=None, cert_reqs=None,
-        context.set_ciphers(ciphers or _DEFAULT_CIPHERS)
+        context.set_ciphers(ciphers or DEFAULT_CIPHERS)
-                                .format(to_native_string(url, 'utf8')))
+                                "Perhaps you meant http://{0}?".format(
-                                "Perhaps you meant http://{0}?".format(to_native_string(url,encoding='utf8')))
+                                "Perhaps you meant http://{0}?"
-                                "Perhaps you meant http://{0}?".format(url.encode('utf8')))
+                                "Perhaps you meant http://{0}?".format(to_native_string(url,encoding='utf8')))
-                                "Perhaps you meant http://{0}?".format(url))
+                                "Perhaps you meant http://{0}?".format(url.encode('utf8')))
-        """Prepares the given HTTP cookie data."""
+        """Prepares the given HTTP cookie data.
-                self.set_cookie(cookie)
+                self.set_cookie(copy.copy(cookie))
-from .cookies import cookiejar_from_dict, get_cookie_header
+from .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar
-        p._cookies = self._cookies.copy() if self._cookies is not None else None
+        p._cookies = _copy_cookie_jar(self._cookies)
-__build__ = 0x020503
+__build__ = 0x020600
-sys.meta_path.append(VendorAlias(["urllib3", "chardet"]))
+sys.meta_path.insert(0, VendorAlias(["urllib3", "chardet"]))
-        self.tl = threading.local()
+        self._thread_local = threading.local()
-            self.tl.num_401_calls = None
+        if not hasattr(self._thread_local, 'init'):
-        opaque = self.tl.chal.get('opaque')
+        realm = self._thread_local.chal['realm']
-            self.tl.nonce_count += 1
+        if nonce == self._thread_local.last_nonce:
-        s = str(self.tl.nonce_count).encode('utf-8')
+            self._thread_local.nonce_count = 1
-        self.tl.last_nonce = nonce
+        self._thread_local.last_nonce = nonce
-            self.tl.num_401_calls = 1
+            self._thread_local.num_401_calls = 1
-        if self.tl.pos is not None:
+        if self._thread_local.pos is not None:
-        num_401_calls = self.tl.num_401_calls
+            r.request.body.seek(self._thread_local.pos)
-        if 'digest' in s_auth.lower() and num_401_calls < 2:
+        if 'digest' in s_auth.lower() and self._thread_local.num_401_calls < 2:
-            self.tl.num_401_calls += 1
+            self._thread_local.num_401_calls += 1
-            self.tl.chal = parse_dict_header(pat.sub('', s_auth, count=1))
+            self._thread_local.chal = parse_dict_header(pat.sub('', s_auth, count=1))
-        self.tl.num_401_calls = 1
+        self._thread_local.num_401_calls = 1
-        if self.tl.last_nonce:
+        if self._thread_local.last_nonce:
-            self.tl.pos = r.body.tell()
+            self._thread_local.pos = r.body.tell()
-            self.tl.pos = None
+            self._thread_local.pos = None
-        self.tl.num_401_calls = 1
+        self._thread_local.num_401_calls = 1
-        self.tl.num_401_calls = None
+        # Ensure state is initialized just once per-thread
-            self.init_per_thread_state()
+        # Initialize per-thread state, if needed
-        self.num_401_calls = threading.local()
+        # Keep state in per-thread local storage
-        opaque = self.chal.get('opaque')
+        realm = self.tl.chal['realm']
-            self.nonce_count += 1
+        if nonce == self.tl.last_nonce:
-        s = str(self.nonce_count).encode('utf-8')
+            self.tl.nonce_count = 1
-        self.last_nonce = nonce
+        self.tl.last_nonce = nonce
-            self.num_401_calls.value = 1
+            self.tl.num_401_calls = 1
-        if self.pos is not None:
+        if self.tl.pos is not None:
-        num_401_calls = self.num_401_calls.value
+            r.request.body.seek(self.tl.pos)
-            self.num_401_calls.value += 1
+            self.tl.num_401_calls += 1
-            self.chal = parse_dict_header(pat.sub('', s_auth, count=1))
+            self.tl.chal = parse_dict_header(pat.sub('', s_auth, count=1))
-        self.num_401_calls.value = 1
+        self.tl.num_401_calls = 1
-        if self.last_nonce:
+        if self.tl.last_nonce:
-            self.pos = r.body.tell()
+            self.tl.pos = r.body.tell()
-            self.pos = None
+            self.tl.pos = None
-        self.num_401_calls.value = 1
+        self.tl.num_401_calls = 1
-        num_401_calls = getattr(self.num_401_calls, 'value', 1)
+        num_401_calls = self.num_401_calls.value
-        self.num_401_calls = 1
+        self.num_401_calls = threading.local()
-            self.num_401_calls = 1
+            self.num_401_calls.value = 1
-        num_401_calls = getattr(self, 'num_401_calls', 1)
+        num_401_calls = getattr(self.num_401_calls, 'value', 1)
-            self.num_401_calls += 1
+            self.num_401_calls.value += 1
-        self.num_401_calls = 1
+        self.num_401_calls.value = 1
-                          verify=True, cert=None, proxies=None):
+                          verify=True, cert=None, proxies=None, **adapter_kwargs):
-            proxies=proxies)
+        gen = self.resolve_redirects(r, request, **kwargs)
-                         fd.read()).group(1)
+    version = re.search(r'^__version__\s*=\s*[\'"]([^\'"]*)[\'"]',
-            break
+    version = re.search(r'__version__\s*=\s*[\'"]([^\'"]*)[\'"]',
-
+        if 'timed out' in str(err) or 'did not complete (read)' in str(err):  # Python 2.6
-            raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
+        # Wrapped in a try/catch because python 2.7 throws TypeError,
-        #: and the arrival of the response (as a timedelta)
+        #: and the arrival of the response (as a timedelta).
-__version__ = '2.5.3'
+__version__ = '2.6.0'
-    Returns :class:`Response <Response>` object.
+    :return: :class:`Response <Response>` object
-    """Sends a GET request. Returns :class:`Response` object.
+    """Sends a GET request.
-    """Sends a OPTIONS request. Returns :class:`Response` object.
+    """Sends a OPTIONS request.
-    """Sends a HEAD request. Returns :class:`Response` object.
+    """Sends a HEAD request.
-    """Sends a POST request. Returns :class:`Response` object.
+    """Sends a POST request.
-    """Sends a PUT request. Returns :class:`Response` object.
+    """Sends a PUT request.
-    """Sends a PATCH request. Returns :class:`Response` object.
+    """Sends a PATCH request.
-    """Sends a DELETE request. Returns :class:`Response` object.
+    """Sends a DELETE request.
-            extract_cookies_to_jar(prepared_request._cookies, prepared_request, resp.raw)
+            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)
-
+version = ''
-    version=requests.__version__,
+    version=version,
-from .packages.urllib3 import Retry
+from .packages.urllib3.util.retry import Retry
-__version__ = 'dev'
+__version__ = '1.10.2'
-            self.extend(headers)
+            if isinstance(headers, HTTPHeaderDict):
-                    _dict_setitem(self, key_lower, new_vals)
+                # Need to convert the tuple to list for further extension
-            val = _dict_getitem(self, key)
+    def _copy_from(self, other):
-            _dict_setitem(clone, key, val)
+            _dict_setitem(self, key, val)
-from ..exceptions import SSLError
+from ..exceptions import SSLError, InsecurePlatformWarning
-            rf = RequestField(name=k, data=fp.read(),
+            if isinstance(fp, (str, bytes, bytearray)):
-        data = {'a': 0.0}
+        data = {'a': 'this is a string'}
-            if isinstance(fp, bytes):
+            if isinstance(fp, (bytes, bytearray)):
-        self._package_name = package_name
+    def __init__(self, package_names):
-        self._vendor_pkg = self._vendor_name + "." + self._package_name
+        self._vendor_pkg = self._vendor_name + "."
-sys.meta_path.extend([VendorAlias("urllib3"), VendorAlias("chardet")])
+sys.meta_path.append(VendorAlias(["urllib3", "chardet"]))
-    def __init__(self):
+    def __init__(self, package_name):
-        self._vendor_pkg = self._vendor_name + "."
+        self._vendor_pkg = self._vendor_name + "." + self._package_name
-sys.meta_path.append(VendorAlias())
+sys.meta_path.extend([VendorAlias("urllib3"), VendorAlias("chardet")])
-__build__ = 0x020502
+__version__ = '2.5.3'
-__build__ = 0x020501
+__version__ = '2.5.2'
-from .packages.six import iterkeys, itervalues
+from .packages.six import iterkeys, itervalues, PY3
-class HTTPHeaderDict(MutableMapping):
+_dict_setitem = dict.__setitem__
-        self.update(headers, **kwargs)
+        dict.__init__(self)
-    def add(self, key, value):
+    def __contains__(self, key):
-        self._data.setdefault(key.lower(), []).append((key, value))
+        key_lower = key.lower()
-        return len(self._data)
+        try:
-            yield headers[0][0]
+    # Backwards compatibility for httplib
-        return '%s(%r)' % (self.__class__.__name__, dict(self.items()))
+        return "%s(%s)" % (type(self).__name__, dict(self.itermerged()))
-            super(HTTPHeaderDict, self).update(*args, **kwds)
+    def copy(self):
-                                        _pool=self, _stacktrace=stacktrace)
+            retries = retries.increment(method, url, error=e, _pool=self,
-from .exceptions import LocationValueError
+from .exceptions import LocationValueError, MaxRetryError
-        kw['retries'] = retries.increment(method, redirect_location)
+        try:
-from .packages.six import string_types as basestring, binary_type
+from .packages.six import string_types as basestring, binary_type, PY3
-            self.headers.update(headers)
+        if isinstance(headers, HTTPHeaderDict):
-            headers.add('set-cookie', cookie)
+        headers = r.msg
-        return ResponseCls(body=r,
+        resp = ResponseCls(body=r,
-        'DH+RC4:RSA+RC4:!aNULL:!eNULL:!MD5'
+        'DH+HIGH:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+HIGH:RSA+3DES:!aNULL:'
-except ImportError: # Platform-specific: No threads available
+except ImportError:  # Platform-specific: No threads available
-try: # Python 2.7+
+try:  # Python 2.7+
-        return self[key].split(', ') if key in self else []
+        return [v for k, v in self._data.get(key.lower(), [])]
-            try:  # Python 2.7+, use buffering of HTTP responses
+            try:  # Python 2.7, use buffering of HTTP responses
-
+        if not data:
-        return zlib.decompressobj(16 + zlib.MAX_WBITS)
+        return GzipDecoder()
-                if not 'read operation timed out' in str(e):  # Defensive:
+                if 'read operation timed out' not in str(e):  # Defensive:
-            headers.add(k, v)
+            if k.lower() != 'set-cookie':
-from hashlib import md5, sha1
+from hashlib import md5, sha1, sha256
-        20: sha1
+        20: sha1,
-        context.check_hostname = (context.verify_mode == ssl.CERT_REQUIRED)
+        # We do our own verification, including fingerprints and alternative
-            requests.get("http://httpbin.org:1")
+            requests.get("http://httpbin.org:1", timeout=1)
-    def test_connection_error(self):
+    def test_connection_error_invalid_domain(self):
-            requests.get("http://fooobarbangbazbing.httpbin.org")
+            requests.get("http://doesnotexist.google.com")
-        path = p_parsed.path
+        #: path is request-uri defined in RFC 2616 which should not be empty
-                     builtin_str, getproxies, proxy_bypass, urlunparse)
+                     builtin_str, getproxies, proxy_bypass, urlunparse,
-    if name and isinstance(name, builtin_str) and name[0] != '<' and name[-1] != '>':
+    if (name and isinstance(name, basestring) and name[0] != '<' and
-        noncebit = "%s:%s:%s:%s:%s" % (nonce, ncvalue, cnonce, qop, HA2)
+            noncebit = "%s:%s:%s:%s:%s" % (
-    return quote(unquote_unreserved(uri), safe="!#$%&'()*+,/:;=?@[]~")
+    safe_with_percent = "!#$%&'()*+,/:;=?@[]~"
-# Set security warning to only go off once by default.
+# Set security warning to always go off by default.
-                                                  timeout=timeout,
+                                                  timeout=timeout_obj,
-                set_tunnel = conn._set_tunnel
+        return conn
-                set_tunnel(self.host, self.port, self.proxy_headers)
+    def _prepare_proxy(self, conn):
-            conn.connect()
+        if sys.version_info <= (2, 6, 4) and not self.proxy_headers:   # Python 2.6.4 and older
-        return conn
+        conn.connect()
-        """ Is this method/response retryable? (Based on method/codes whitelists)
+        """ Is this method/status code retryable? (Based on method/codes whitelists)
-copyright = u'2014. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'2015. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-:copyright: (c) 2014 by Kenneth Reitz.
+:copyright: (c) 2015 by Kenneth Reitz.
-__copyright__ = 'Copyright 2014 Kenneth Reitz'
+__copyright__ = 'Copyright 2015 Kenneth Reitz'
-    compatibility with external client code. All `requests` code should work
+    compatibility with external client code. All requests code should work
-        not O(1)."""
+        use the more explicit get() method instead.
-        optionally domain and path."""
+        """Both ``__get_item__`` and ``get`` call this function: it's never
-    """Compatibility class; is a cookielib.CookieJar, but exposes a dict interface.
+    """Compatibility class; is a cookielib.CookieJar, but exposes a dict
-    Caution: dictionary operations that are normally O(1) may be O(n).
+    Requests does not use the dict interface internally; it's just for
-    """
+    .. warning:: dictionary operations that are normally O(1) may be O(n).
-        multiple domains. Caution: operation is O(n), not O(1)."""
+        multiple domains.
-        See itervalues() and iteritems()."""
+        """Dict-like iterkeys() that returns an iterator of names of cookies
-        See values() and items()."""
+        """Dict-like keys() that returns a list of names of cookies from the
-        See iterkeys() and iteritems()."""
+        """Dict-like itervalues() that returns an iterator of values of cookies
-        See keys() and items()."""
+        """Dict-like values() that returns a list of values of cookies from the
-        See iterkeys() and itervalues()."""
+        """Dict-like iteritems() that returns an iterator of name-value tuples
-        and get a vanilla python dict of key value pairs."""
+        """Dict-like items() that returns a list of name-value tuples from the
-        Python dict of name-value pairs of cookies that meet the requirements."""
+        """Takes as an argument an optional domain and path and returns a plain
-        explicit get() method instead. Caution: operation is O(n), not O(1)."""
+        """Dict-like __getitem__() for compatibility with client code. Throws
-        explicit set() method instead."""
+        """Dict-like __setitem__ for compatibility with client code. Throws
-        """Deletes a cookie given a name. Wraps cookielib.CookieJar's remove_cookie_by_name()."""
+        """Deletes a cookie given a name. Wraps ``cookielib.CookieJar``'s
-        if there are conflicting cookies."""
+        """Requests uses this method internally to get cookie values. Takes as
-        multiple cookies that match name and optionally domain and path."""
+        """__get_item__ and get call _find_no_duplicates -- never used in
-    
+
-__build__ = 0x020500
+__version__ = '2.5.1'
-            setattr(self, 'num_401_calls', 1)
+            self.num_401_calls = 1
-            setattr(self, 'num_401_calls', num_401_calls + 1)
+            self.num_401_calls += 1
-        setattr(self, 'num_401_calls', num_401_calls + 1)
+        self.num_401_calls = 1
-            raise InvalidURL(e.message)
+            raise InvalidURL(*e.args)
-    StreamConsumedError)
+    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,
-        except RequestException:
+        except HTTPError:
-##        assert r.status_code == 200
+    def test_session_pickling(self):
-    # simplejson does not support Python 3.2, it thows a SyntaxError
+    # simplejson does not support Python 3.2, it throws a SyntaxError
-depend on something external.
+Copyright (c) Donald Stufft, pip, and individual contributors
-updated to versions from upstream.
+Permission is hereby granted, free of charge, to any person obtaining
-                # pip._vendor.six.moves will fail.
+                # requests.packages.urllib3.poolmanager will fail.
-    if name and name[0] != '<' and name[-1] != '>':
+    if name and isinstance(name, builtin_str) and name[0] != '<' and name[-1] != '>':
-from . import urllib3
+import sys
-__build__ = 0x020403
+__version__ = '2.5.0'
-        req = requests.Request('GET', 'http://httpbin.org/get')
+        req = requests.Request('GET', httpbin('get'))
-        r = requests.get('https://httpbin.org/redirect/5')
+        r = requests.get(httpbin('redirect/5'))
-            i=i+1
+            i = i + 1
-            requests.get('https://httpbin.org/delay/10', timeout=2.0)
+            requests.get(httpbin('delay/10'), timeout=2.0)
-        prep = requests.Request('POST', 'http://httpbin.org/post').prepare()
+        prep = requests.Request('POST', httpbin('post')).prepare()
-    s.mount('https://', HTTPAdapter(max_retries=Retry(
+    s.mount('http://', HTTPAdapter(max_retries=Retry(
-        s.get('https://httpbin.org/status/500')
+        s.get(httpbin('status/500'))
-__version__ = "2.2.1"
+__version__ = "2.3.0"
-from sys import argv, stdin
+from chardet import __version__
-    """Return a string describing the probable encoding of a file."""
+def description_of(lines, name='stdin'):
-    for line in file:
+    for line in lines:
-                                              result['confidence'])
+        return '{0}: {1} with confidence {2}'.format(name, result['encoding'],
-        return '%s: no result' % name
+        return '{0}: no result'.format(name)
-                print(description_of(f, path))
+def main(argv=None):
-                          - (self._mFreqCounter[1] * 20.0 / total))
+            confidence = ((self._mFreqCounter[3] - self._mFreqCounter[1] * 20.0)
-        confidence = confidence * 0.5
+        confidence = confidence * 0.73
-    3,3,3,3,3,3,3,3,  # 80 - 87
+    3,3,3,3,3,2,2,3,  # 80 - 87
-)
+    3,3,3,3,3,3,3,3,  # f0 - f7
-        return "SHIFT_JIS"
+        return self._mContextAnalyzer.get_charset_name()
-            if aBuf[:3] == codecs.BOM:
+            if aBuf[:3] == codecs.BOM_UTF8:
-                self.result = {'encoding': "UTF-8", 'confidence': 1.0}
+                self.result = {'encoding': "UTF-8-SIG", 'confidence': 1.0}
-warnings.simplefilter('module', exceptions.SecurityWarning)
+warnings.simplefilter('always', exceptions.SecurityWarning)
-from .packages.six import itervalues
+from .packages.six import iterkeys, itervalues
-            values = list(self._container.values())
+            values = list(itervalues(self._container))
-            return self._container.keys()
+            return list(iterkeys(self._container))
-from .util import connection
+from .util import connection
-                           self.assert_hostname or hostname)
+            cert = self.sock.getpeercert()
-    HTTPException, BaseSSLError,
+    HTTPException, BaseSSLError, ConnectionError
-        self._validate_conn(conn)
+        try:
-
+        except (SocketTimeout, BaseSSLError, SocketError) as e:
-            release_conn = True
+            # Close the connection. If a connection is reused on which there
-        except (TimeoutError, HTTPException, SocketError) as e:
+        except (TimeoutError, HTTPException, SocketError, ConnectionError) as e:
-                '(This warning will only appear once by default.)'),
+                'https://urllib3.readthedocs.org/en/latest/security.html'),
-encryption in Python 2 (see `CRIME attack`_).
+compression in Python 2 (see `CRIME attack`_).
-    ssl.PROTOCOL_SSLv3: OpenSSL.SSL.SSLv3_METHOD,
+
-        return self.connection.sendall(data)
+        while len(data):
-            message += " (Caused by redirect)"
+        message = "Max retries exceeded with url: %s (Caused by %r)" % (
-        headers_.update(headers)
+        extra_kw = {'headers': {}}
-                            **urlopen_kw)
+        return self.urlopen(method, url, **extra_kw)
-    ReadTimeoutError,
+    ProtocolError,
-        assume that the server did not process any of it.
+        """ Errors that occur after the request has been started, so we should
-        """
+        """ Are we out of retries? """
-            # FIXME: Nothing changed, scenario doesn't make sense.
+            # Incrementing because of a server error like a 500 in
-            raise MaxRetryError(_pool, url, error)
+            raise MaxRetryError(_pool, url, error or ResponseError(cause))
-    HAS_SNI = False
+SSLContext = None
-    import ssl
+try:  # Test for SSL features
-    from ssl import SSLContext  # Modern SSL?
+try:
-            except Exception as e:  # Reraise as SSLError
+def create_urllib3_context(ssl_version=None, cert_reqs=ssl.CERT_REQUIRED,
-                           ssl_version=ssl_version)
+            raise
-        Url(scheme='http', host='google.com', port=None, path='/', ...)
+        Url(scheme='http', host='google.com', port=None, path='/mail/', ...)
-            if not urlparse(url).netloc:
+            if not parsed.netloc:
-        'max_redirects', 'redirect_cache'
+        'max_redirects',
-        self.redirect_cache = RecentlyUsedContainer(1000)
+        self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
-        return dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
+        state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
-            raise ConnectionError(e.message)
+            raise InvalidURL(e.message)
-        with pytest.raises(ConnectionError):
+        """Inputing a URL that cannot be parsed should raise an InvalidURL error"""
-    DecodeError, ReadTimeoutError, ProtocolError)
+    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)
-        scheme, auth, host, port, path, query, fragment = parse_url(url)
+        try:
-        assert r.status_code == 200
+##    def test_session_pickling(self):
-        connections.
+        connections. If you need granular control over the conditions under
-                         ProxyError)
+                         ProxyError, RetryError)
-DEFAULT_RETRIES = object()
+DEFAULT_RETRIES = 0
-        if max_retries is DEFAULT_RETRIES:
+        if max_retries == DEFAULT_RETRIES:
-                                 ReadTimeout, Timeout)
+                                 ReadTimeout, Timeout, RetryError)
-from .packages.six import itervalues
+from .packages.six import iterkeys, itervalues
-            values = list(self._container.values())
+            values = list(itervalues(self._container))
-            return self._container.keys()
+            return list(iterkeys(self._container))
-from .util import connection
+from .util import connection
-    HTTPException, BaseSSLError,
+    HTTPException, BaseSSLError, ConnectionError
-        except (TimeoutError, HTTPException, SocketError) as e:
+        except (TimeoutError, HTTPException, SocketError, ConnectionError) as e:
-encryption in Python 2 (see `CRIME attack`_).
+compression in Python 2 (see `CRIME attack`_).
-        return self.connection.sendall(data)
+        while len(data):
-            message += " (Caused by redirect)"
+        message = "Max retries exceeded with url: %s (Caused by %r)" % (
-    ReadTimeoutError,
+    ProtocolError,
-        assume that the server did not process any of it.
+        """ Errors that occur after the request has been started, so we should
-        """
+        """ Are we out of retries? """
-            # FIXME: Nothing changed, scenario doesn't make sense.
+            # Incrementing because of a server error like a 500 in
-            raise MaxRetryError(_pool, url, error)
+            raise MaxRetryError(_pool, url, error or ResponseError(cause))
-        Url(scheme='http', host='google.com', port=None, path='/', ...)
+        Url(scheme='http', host='google.com', port=None, path='/mail/', ...)
-DEFAULT_RETRIES = 0
+DEFAULT_RETRIES = object()
-        self.max_retries = max_retries
+        if max_retries is DEFAULT_RETRIES:
-                    retries=Retry(self.max_retries, read=False),
+                    retries=self.max_retries,
-            pass
+            # In the case of HTTPDigestAuth being reused and the body of
-        elif self.method not in ('GET', 'HEAD'):
+        elif (self.method not in ('GET', 'HEAD')) and (self.headers.get('Content-Length') is None):
-    return session.request(method=method, url=url, **kwargs)
+    response = session.request(method=method, url=url, **kwargs)
-                                       block=block, **pool_kwargs)
+                                       block=block, strict=True, **pool_kwargs)
-from .compat import cookielib, OrderedDict, urljoin, urlparse, builtin_str
+from .compat import cookielib, OrderedDict, urljoin, urlparse
-        method = builtin_str(method)
+        method = to_native_string(method)
-        timeouts, never to requests where the server returns a response.
+        should attempt. Note, this applies only to failed DNS lookups, socket
-        self.redirect_cache = {}
+        # Only store 1000 redirects to prevent using infinite memory
-        url=u('http://www.example.com/Ã¼niÃ§Ã¸âÃ©')
+        url=u('http://www.example.com/Ã¼niÃ§Ã¸âÃ©'),
-    ChunkedEncodingError, ContentDecodingError, ConnectionError,
+    HTTPError, RequestException, MissingSchema, InvalidURL, 
-        self.prepare_hooks(hooks if hooks is not None else [])
+        self.prepare_hooks(hooks)
-    ChunkedEncodingError, ContentDecodingError, ConnectionError, 
+    HTTPError, RequestException, MissingSchema, InvalidURL,
-        self.prepare_hooks(hooks)
+        self.prepare_hooks(hooks if hooks is not None else [])
-    ChunkedEncodingError, ContentDecodingError, ConnectionError,
+    HTTPError, RequestException, MissingSchema, InvalidURL, 
-                self.register_hook(event, hooks[event])
+        for event in hooks:
-    ChunkedEncodingError, ContentDecodingError, ConnectionError, 
+    HTTPError, RequestException, MissingSchema, InvalidURL,
-            self.register_hook(event, hooks[event])
+        if hooks is not None:
-    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, newline=None):
+    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):
-                lines = chunk.split(newline)
+            if delimiter:
-                codes.permanent_redirect):
+        if r.is_redirect:
-    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None):
+    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, newline=None):
-            lines = chunk.splitlines()
+
-    for val in re.split(",\ *<", value):
+    for val in re.split(", *<", value):
-    for val in re.split(",\ *<",value):
+    for val in re.split(",\ *<", value):
-    for val in value.split(","):
+    for val in re.split(",\ *<",value):
-    def handle_302(self, r, **kwargs):
+    def handle_redirect(self, r, **kwargs):
-        return r
+        if r.status_code in (
-        setattr(self, 'num_401_calls', 1)
+        setattr(self, 'num_401_calls', num_401_calls + 1)
-        r.register_hook('response', self.handle_302)
+        r.register_hook('response', self.handle_redirect)
-__build__ = 0x020402
+__version__ = '2.4.3'
-        hooks=None):
+        hooks=None,
-        cert=None):
+        cert=None,
-        try:
+        if isinstance(url, bytes):
-        except AttributeError:
+        else:
-   >>> r = requests.get('http://python.org')
+   >>> r = requests.get('https://www.python.org')
-   >>> r = requests.post("http://httpbin.org/post", data=payload)
+   >>> r = requests.post('http://httpbin.org/post', data=payload)
-__build__ = 0x020401
+__version__ = '2.4.2'
-    3. fall back and replace all unicode characters
+    2. fall back and replace all unicode characters
-        'trust_env', 'max_redirects', 'redirect_cache']
+        'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',
-    :param json: json for the body to attach the request.
+    :param data: the body to attach to the request. If a dictionary is provided, form-encoding will take place.
-                data=None, json=None, params=None, auth=None, cookies=None, hooks=None):
+                data=None, params=None, auth=None, cookies=None, hooks=None,
-    def prepare_body(self, data, files, _json=None):
+    def prepare_body(self, data, files, json=None):
-        if _json is not None:
+        if json is not None:
-            data = json.dumps(_json)
+            body = json_dumps(json)
-                if data and _json is None:
+                if data and json is None:
-            if (content_type) and (not 'content-type' in self.headers):
+            if content_type and ('content-type' not in self.headers):
-            json = json or {},
+            json = json,
-            pass
+            url = url.decode('utf8')
-from .compat import urlparse, basestring, urldefrag
+from .compat import urlparse, basestring
-                    prepend_scheme_if_needed, get_auth_from_url)
+                    prepend_scheme_if_needed, get_auth_from_url, urldefragauth)
-            url, _ = urldefrag(request.url)
+            url = urldefragauth(request.url)
-            request.url = self.redirect_cache.get(request.url)
+            checked_urls.add(request.url)
-class StreamConsumedError(RequestException):
+class StreamConsumedError(RequestException, TypeError):
-    ChunkedEncodingError, ContentDecodingError, ConnectionError)
+    HTTPError, RequestException, MissingSchema, InvalidURL, 
-                        'The content for this response was already consumed')
+            raise StreamConsumedError()
-            reused_chunks = iter_slices(self._content, chunk_size)
+        # simulate reading small chunks of the content
-        reused_chunks = iter_slices(self._content, chunk_size)
+        if self._content_consumed and isinstance(self._content, bool):
-        # Don't do any URL preparation for oddball schemes
+        # Don't do any URL preparation for non-HTTP schemes like `mailto`,
-    def test_oddball_schemes_dont_check_URLs(self):
+    def test_nonhttp_schemes_dont_check_URLs(self):
-                                 ReadTimeout, ConnectionError, Timeout)
+from requests.exceptions import (ConnectionError, ConnectTimeout,
-__build__ = 0x020400
+__version__ = '2.4.1'
-            if resp.is_permanent_redirect:
+            # Cache the url, unless it redirects to itself.
-requires = ['certifi']
+requires = []
-        'betterssl': ['pyOpenSSL', 'ndg-httpsclient', 'pyasn1'],
+        'security': ['pyOpenSSL', 'ndg-httpsclient', 'pyasn1'],
-            raise ConnectionError(e, request=request)
+        except (ProtocolError, socket.error) as err:
-with open('README.rst') as f:
+with open('README.rst', 'r', 'utf-8') as f:
-with open('HISTORY.rst') as f:
+with open('HISTORY.rst', 'r', 'utf-8') as f:
-        'Connection': 'keep-alive'
+        'Connection': 'keep-alive',
-        :type timeout: float or tuple (connect timeout, read timeout), eg (3.1, 20)
+        :param timeout: (optional) How long to wait for the server to send
-    :param files: (optional) Dictionary of 'name': file-like-objects (or {'name': ('filename', fileobj)}) for multipart encoding upload.
+    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': ('filename', fileobj)}``) for multipart encoding upload.
-    :param timeout: (optional) Float describing the timeout of the request in seconds.
+    :param timeout: (optional) How long to wait for the server to send data
-    :exc:`ReadTimeout` errors.
+    Catching this error will catch both
-    """The request timed out while trying to connect to the server.
+    """The request timed out while trying to connect to the remote server.
-    Requests that produce this error are safe to retry
+    Requests that produced this error are safe to retry.
-        :param files: (optional) Dictionary of 'filename': file-like-objects
+        :param files: (optional) Dictionary of ``'filename': file-like-objects``
-        :param allow_redirects: (optional) Boolean. Set to True by default.
+        :param timeout: (optional) How long to wait for the server to send
-        #assert {'life': 42} == r.json()['json']
+        assert {'life': 42} == r.json()['json']
-                if data and not _json:
+                if data and _json is None:
-                            content_type = 'application/x-www-form-urlencoded'
+                    if isinstance(data, basestring) or hasattr(data, 'read'):
-        self.prepare_body(data, files)
+        self.prepare_body(data, files, json)
-                if data:
+                if data and not _json:
-        assert 'application/json' in r.headers['Content-Type']
+        assert 'application/json' in r.request.headers['Content-Type']
-def post(url, data=None, **kwargs):
+def post(url, data=None, json=None, **kwargs):
-    return request('post', url, data=data, **kwargs)
+    return request('post', url, data=data, json=json, **kwargs)
-                data=None, params=None, auth=None, cookies=None, hooks=None):
+                data=None, json=None, params=None, auth=None, cookies=None, hooks=None):
-    def prepare_body(self, data, files):
+    def prepare_body(self, data, files, _json=None):
-                        content_type = 'application/x-www-form-urlencoded'
+                    if not _json:
-    def post(self, url, data=None, **kwargs):
+    def post(self, url, data=None, json=None, **kwargs):
-        return self.request('POST', url, data=data, **kwargs)
+        return self.request('POST', url, data=data, json=json, **kwargs)
-        'Accept': '*/*'
+        'Accept': '*/*',
-__build__ = 0x020300
+__version__ = '2.4.0'
-        """Checks the environment and merges it with some settings."""
+        """Check the environment and merge it with some settings."""
-            # Look for configuration.
+            # Look for requests environment configuration and be compatible
-                verify = os.environ.get('CURL_CA_BUNDLE')
+                verify = (os.environ.get('REQUESTS_CA_BUNDLE') or
-        cert = merge_setting(cert, self.cert)
+        settings = self.merge_environment_settings(
-            'proxies': proxies,
+        send_kwargs.update(settings)
-warnings.simplefilter('module', exceptions.InsecureRequestWarning)
+warnings.simplefilter('module', exceptions.SecurityWarning)
-                               self.assert_hostname or hostname)
+        if self.assert_fingerprint:
-        self.is_verified = resolved_cert_reqs == ssl.CERT_REQUIRED
+        self.is_verified = (resolved_cert_reqs == ssl.CERT_REQUIRED
-        if not conn.sock:
+        if not getattr(conn, 'sock', None):  # AppEngine might not have  `.sock`
-from ndg.httpsclient.subj_alt_name import SubjectAltName as BaseSubjectAltName
+try:
-    '''API-compatibility wrapper for Python OpenSSL's Connection-class.'''
+    '''API-compatibility wrapper for Python OpenSSL's Connection-class.
-        return _fileobject(self, mode, bufsize)
+        self._makefile_refs += 1
-                raise timeout()
+                raise timeout('The read operation timed out')
-        return self.connection.shutdown()
+        if self._makefile_refs < 1:
-    "Raised when the maximum number of retries is exceeded."
+    """Raised when the maximum number of retries is exceeded.
-class InsecureRequestWarning(HTTPWarning):
+class SecurityWarning(HTTPWarning):
-    loaded and decoded on-demand when the ``data`` property is accessed.
+    loaded and decoded on-demand when the ``data`` property is accessed.  This
-        # on exhaustion (e.g. HTTPResponse)
+
-    return obj.closed
+    raise ValueError("Unable to determine whether fp is closed.")
-        A set of HTTP status codes that we should force a retry on. 
+        A set of HTTP status codes that we should force a retry on.
-        assert isinstance(e, Timeout)
+            assert isinstance(e, ConnectionError)
-                                 ReadTimeout)
+                                 ReadTimeout, ConnectionError, Timeout)
-        except ConnectTimeout:
+        except ConnectTimeout as e:
-    """ The request timed out while trying to connect to the server.
+class ConnectTimeout(ConnectionError, Timeout):
-    operations are given keys that have equal ``.lower()`` s, the
+    operations are given keys that have equal ``.lower()``s, the
-from .compat import urlparse, basestring, urldefrag, unquote
+from .compat import urlparse, basestring, urldefrag
-from .packages.urllib3.exceptions import SSLError as _SSLError
+from .packages.urllib3.exceptions import ConnectTimeoutError
-from .exceptions import ConnectionError, Timeout, SSLError, ProxyError
+from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,
-        timeout = TimeoutSauce(connect=timeout, read=timeout)
+        if isinstance(timeout, tuple):
-                raise Timeout(e, request=request)
+            elif isinstance(e, ReadTimeoutError):
-    """The request timed out."""
+    """The request timed out.
-    testing is case insensitive:
+    testing is case insensitive::
-    operations are given keys that have equal ``.lower()``s, the
+    operations are given keys that have equal ``.lower()`` s, the
-from requests.exceptions import InvalidURL, MissingSchema, ConnectionError
+from requests.exceptions import (InvalidURL, MissingSchema, ConnectTimeout,
-            requests.get('https://httpbin.org/delay/10', timeout=5.0)
+            requests.get('https://httpbin.org/delay/10', timeout=2.0)
-        hist = [] #keep track of history
+        hist = [] # keep track of history
-                #update history and keep track of redirects
+                # Update history and keep track of redirects.
-                #create deep copy of the history and keep track of redirects
+                #update history and keep track of redirects
-        count = 0
+        total = r.history[-1].history
-            count = count + 1
+            assert item.history == total[0:i]
-from .packages.urllib3.exceptions import DecodeError
+from .packages.urllib3.exceptions import (
-    is_py2, chardet, json, builtin_str, basestring, IncompleteRead)
+    is_py2, chardet, json, builtin_str, basestring)
-                except IncompleteRead as e:
+                except ProtocolError as e:
-                except socket.error as e:
+                except ReadTimeoutError as e:
-        setattr(r, 'raw', RawMock())
+        r.raw = RawMock()
-    ChunkedEncodingError, ContentDecodingError)
+    ChunkedEncodingError, ContentDecodingError, ConnectionError)
-from requests.exceptions import InvalidURL, MissingSchema
+from requests.exceptions import InvalidURL, MissingSchema, ConnectionError
-                    retries=self.max_retries,
+                    retries=Retry(self.max_retries, read=False),
-from .util import make_headers, get_host, Timeout
+from .util.request import make_headers
-    logger.debug('Added an stderr logging handler to logger: %s' % __name__)
+    logger.debug('Added a stderr logging handler to logger: %s' % __name__)
-    RFC 2616. Iteration provides the first case-sensitive key seen for each
+    RFC 7230. Iteration provides the first case-sensitive key seen for each
-try: # Python 3
+try:  # Python 3
-    ssl = None
+
-    assert_fingerprint,
+
-    tcp_nodelay = 1
+    #: Disable Nagle's algorithm by default.
-            kw.pop('source_address', None)
+        if sys.version_info < (2, 7):  # Python 2.6
-        _HTTPConnection.__init__(self, *args, **kw)  
+        _HTTPConnection.__init__(self, *args, **kw)
-        :return: a new socket connection
+        :return: New socket connection.
-            extra_args.append(self.source_address)
+        extra_kw = {}
-            socket.IPPROTO_TCP, socket.TCP_NODELAY, self.tcp_nodelay)
+        if self.socket_options:
-                        self.tcp_nodelay)
+        conn = self._new_conn()
-            self.sock = sock
+            self.sock = conn
-        self.sock = ssl_wrap_socket(sock, self.key_file, self.cert_file,
+        self.sock = ssl_wrap_socket(conn, self.key_file, self.cert_file,
-import sys
+import sys
-try: # Python 3
+try:  # Python 3
-    ConnectTimeoutError,
+    ProtocolError,
-    LocationParseError,
+    LocationValueError,
-    ProxyError,
+    InsecureRequestWarning,
-)
+
-## Pool objects
+## Pool objects
-            raise LocationParseError(host)
+        if not host:
-        self.host = host
+        self.host = host.strip('[]')
-                 headers=None, _proxy=None, _proxy_headers=None, **conn_kw):
+                 headers=None, retries=None,
-        # can only be set to a Timeout object
+        if retries is None:
-            conn_kw.pop('source_address', None)
+        if self.proxy:
-        except AttributeError: # self.pool is None
+        except AttributeError:  # self.pool is None
-            return # Everything is dandy, done.
+            return  # Everything is dandy, done.
-                (self.host, timeout_obj.connect_timeout))
+        # Trigger any extra validation we need to do.
-        if hasattr(conn, 'sock'):
+        if getattr(conn, 'sock', None):
-                    "Read timed out. (read timeout=%s)" % read_timeout)
+                    self, url, "Read timed out. (read timeout=%s)" % read_timeout)
-            else: # None or a value
+            else:  # None or a value
-            try: # Python 2.7+, use buffering of HTTP responses
+            try:  # Python 2.7+, use buffering of HTTP responses
-            except TypeError: # Python 2.6 and older
+            except TypeError:  # Python 2.6 and older
-                raise ReadTimeoutError(self, url, "Read timed out.")
+                raise ReadTimeoutError(
-        except SocketError as e: # Platform-specific: Python 2
+        except SocketError as e:  # Platform-specific: Python 2
-                    "Read timed out. (read timeout=%s)" % read_timeout)
+                    self, url, "Read timed out. (read timeout=%s)" % read_timeout)
-            pass # Done.
+            pass  # Done.
-    def urlopen(self, method, url, body=None, headers=None, retries=3,
+    def urlopen(self, method, url, body=None, headers=None, retries=None,
-            immediately.
+            Configure the number of retries to allow before raising a
-            raise MaxRetryError(self, url)
+        if not isinstance(retries, Retry):
-            raise HostChangedError(self, url, retries - 1)
+            raise HostChangedError(self, url, retries)
-            # Request a connection from the queue
+            # Request a connection from the queue.
-            # Make the request on the httplib connection object
+            # Make the request on the httplib connection object.
-                    raise ProxyError('Cannot connect to proxy.', e)
+            stacktrace = sys.exc_info()[2]
-                raise MaxRetryError(self, url, e)
+            retries = retries.increment(method, url, error=e,
-            log.warning("Retrying (%d attempts remain) after connection "
+            log.warning("Retrying (%r) after connection "
-            return self.urlopen(method, url, body, headers, retries - 1,
+            return self.urlopen(method, url, body, headers, retries,
-        if redirect_location and retries is not False:
+        if redirect_location:
-                                release_conn=release_conn, **response_kw)
+                    retries=retries, redirect=redirect,
-                 block=False, headers=None,
+                 strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1,
-                                    block, headers, _proxy, _proxy_headers, **conn_kw)
+                                    block, headers, retries, _proxy, _proxy_headers,
-            set_tunnel(self.host, self.port, self.proxy_headers)
+
-            conn.tcp_nodelay = 0
+                                  strict=self.strict, **self.conn_kw)
-    Example: ::
+    Example::
-    def __init__(self, connection, socket):
+    def __init__(self, connection, socket, suppress_ragged_eofs=True):
-        return fileobject(self.connection, mode, bufsize)
+        return _fileobject(self, mode, bufsize)
-
+class HTTPWarning(Warning):
-    "Raised when a normal connection fails."
+class DecodeError(HTTPError):
-    "Raised when automatic decoding based on Content-Type fails."
+class ProtocolError(HTTPError):
-            message += " (Caused by %s: %s)" % (type(reason), reason)
+            message += " (Caused by %r)" % reason
-class LocationParseError(ValueError, HTTPError):
+class LocationValueError(ValueError, HTTPError):
-        tuple where the MIME type is optional. For example: ::
+        Supports constructing :class:`~urllib3.fields.RequestField` from
-            `k1="v1"; k2="v2"; ...`.
+            A sequence of (k, v) typles or a :class:`dict` of (k, v) to format
-    def make_multipart(self, content_disposition=None, content_type=None, content_location=None):
+    def make_multipart(self, content_disposition=None, content_type=None,
-        self.headers['Content-Disposition'] += '; '.join(['', self._render_parts((('name', self._name), ('filename', self._filename)))])
+        self.headers['Content-Disposition'] += '; '.join([
-        yield RequestField.from_tuples(*field)
+        if isinstance(field, RequestField):
-
+from .exceptions import LocationValueError
-from .util import parse_url
+from .util.url import parse_url
-    Example: ::
+    Example::
-        scheme = scheme or 'http'
+        if not host:
-
+
-        # RFC 2616, Section 10.3.4
+        # RFC 7231, Section 6.4.4
-        kw['retries'] = kw.get('retries', 3) - 1  # Persist retries countdown
+        retries = kw.get('retries')
-            'Not supported proxy scheme %s' % self.proxy.scheme
+
-                                                                self.headers))
+            headers = kw.get('headers', self.headers)
-        return super(ProxyManager, self).urlopen(method, url, redirect, **kw)
+        return super(ProxyManager, self).urlopen(method, url, redirect=redirect, **kw)
-    in the URL (such as GET, HEAD, DELETE).
+    :meth:`.request_encode_url` is for sending requests whose fields are
-                **kw): # Abstract
+                **kw):  # Abstract
-        to drop down to more specific methods when necessary, such as
+        effort. It can be used in most situations, while still having the
-                                            **urlopen_kw)
+                                           headers=headers,
-                                             **urlopen_kw)
+                                            headers=headers,
-        payload with the appropriate content type. Otherwise
+        :meth:`urllib3.filepost.encode_multipart_formdata` is used to encode
-        such as with OAuth.
+        safe to use it in other times too. However, it may break request
-        the MIME type is optional. For example: ::
+        the MIME type is optional. For example::
-        overwritten because it depends on the dynamic random boundary string
+        Note that if ``headers`` are supplied, the 'Content-Type' header will
-                                    boundary=multipart_boundary)
+            body, content_type = encode_multipart_formdata(
-                                    'application/x-www-form-urlencoded')
+                                  'application/x-www-form-urlencoded')
-import logging
+from socket import timeout as SocketTimeout
-from .exceptions import DecodeError
+from .exceptions import ProtocolError, DecodeError, ReadTimeoutError
-
+from .connection import HTTPException, BaseSSLError
-        self._body = body if body and isinstance(body, basestring) else None
+        self._body = None
-        # Section 3.5
+        # Note: content-encoding value should be case-insensitive, per RFC 7230
-                    self._fp.close()
+            try:
-                    e)
+                    "failed to decode it." % content_encoding, e)
-            raise IOError("The file-like object  this HTTPResponse is wrapped "
+            raise IOError("The file-like object this HTTPResponse is wrapped "
-
+# For backwards compatibility, provide imports that used to be here.
-from socket import error as SocketError
+import socket
-        return False
+        return True
-        except SocketError:
+        except socket.error:
-
+from ..packages.six import b
-                 basic_auth=None, proxy_basic_auth=None):
+                 basic_auth=None, proxy_basic_auth=None, disable_cache=None):
-    Example: ::
+    :param disable_cache:
-            b64encode(six.b(basic_auth)).decode('utf-8')
+            b64encode(b(basic_auth)).decode('utf-8')
-    return headers
+            b64encode(b(proxy_basic_auth)).decode('utf-8')
-    if rest or digest_length not in hashfunc_map:
+    if odd or digest_length not in hashfunc_map:
-    Retrieve the current time, this function is mocked out in unit testing.
+    Retrieve the current time. This function is mocked out in unit testing.
-# by httplib to define the default timeout
+class Timeout(object):
-    Utility object for storing timeout values.
+        timeout = Timeout(connect=2.0, read=7.0)
-    Example usage:
+        no_timeout = Timeout(connect=None, read=None)
-        pool.request(...) # Etc, etc
+    :param total:
-        `total`.
+        an HTTP response.
-        take several minutes to complete.
+        of 20 seconds will not trigger, even though the request will take
-        """ Check that a timeout attribute is valid
+        """ Check that a timeout attribute is valid.
-            is a numeric value less than zero
+        :param name: The name of the timeout attribute to validate. This is
-        except TypeError: # Python 3
+        except TypeError:  # Python 3
-        to this function.
+        object that sets the individual timeouts to the ``timeout`` value
-        :param timeout: The legacy timeout value
+        :param timeout: The legacy timeout value.
-        :return: a Timeout object
+        :return: Timeout object
-        :return: the elapsed time
+        :return: Elapsed time.
-        :return: the connect timeout
+        :return: Connect timeout.
-        :return: the value to use for the read timeout
+        :return: Value to use for the read timeout.
-            # in case the connect timeout has not yet been established.
+            # In case the connect timeout has not yet been established.
-class Url(namedtuple('Url', ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment'])):
+url_attrs = ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment']
-        return super(Url, cls).__new__(cls, scheme, auth, host, port, path, query, fragment)
+    def __new__(cls, scheme=None, auth=None, host=None, port=None, path=None,
-    Example: ::
+    Example::
-    Example: ::
+    Example::
-requires = []
+requires = ['certifi']
-    return os.path.join(os.path.dirname(__file__), 'cacert.pem')
+try:
-            if verify is True or (verify is None and verify is not False):
+            if verify is True or verify is None:
-            if verify is True or (verify is None and verify is not False):
+            if verify is True or verify is None:
-            if not verify and verify is not False:
+            if verify is True or (verify is None and verify is not False):
-            if not verify and verify is not False:
+            if verify is True or (verify is None and verify is not False):
-        'trust_env', 'max_redirects']
+        'trust_env', 'max_redirects', 'redirect_cache']
-    308: ('permanent_redirect',),
+    308: ('permanent_redirect',
-    codes.resume, # 308
+    codes.moved,              # 301
-            if resp.status_code not in (codes.temporary, codes.resume):
+            if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):
-    308: ('resume_incomplete', 'resume'),
+    308: ('permanent_redirect',),
-                url, data={'some': 'data'}, files={'some': f})
+            post2 = requests.post(url,
-            httpbin('post'),
+        r = requests.post(httpbin('post'),
-            httpbin('post'),
+        r = requests.post(httpbin('post'),
-            httpbin('post'),
+        r = requests.post(httpbin('post'),
-            httpbin('post'),
+        r = requests.post(httpbin('post'),
-            httpbin('post'),
+        r = requests.post(httpbin('post'),
-from requests.models import PreparedRequest, Response
+from requests.models import PreparedRequest
-from requests.models import PreparedRequest, urlencode
+from requests.models import urlencode
-        r = s.get(url)
+        s.get(url)
-        cookiejar_from_dict({'foo' : 'bar'}, cj)
+        cookiejar_from_dict({'foo': 'bar'}, cj)
-            requests.post(url, files = ['bad file data'])
+            requests.post(url, files=['bad file data'])
-            post2 = requests.post(url, data={'some': 'data'}, files={'some': f})
+            post2 = requests.post(
-            requests.post(url, files = ['bad file data'])
+            requests.post(url, files=['bad file data'])
-        requests.put(httpbin('put'), headers={str('Content-Type'): 'application/octet-stream'}, data='\xff') # compat.str is unicode.
+        requests.put(
-                          files={'file': ('test_requests.py', open(__file__, 'rb'))})
+        r = requests.post(
-                          files={'file': ('test_requests.py', open(__file__, 'rb'))})
+        r = requests.post(
-                          files={'file': ('test_requests.py', open(__file__, 'rb'))})
+        r = requests.post(
-                          files={'file': ('test_requests.py', open(__file__, 'rb'))})
+        r = requests.post(
-                          files={'file': ('test_requests.py', open(__file__, 'rb'))})
+        r = requests.post(
-        r = requests.request(method=u('POST'), url=httpbin('post'), files=files)
+        r = requests.request(
-                                           'text/py-content-type')})
+        r = requests.post(
-        assert resp.json()['headers']['Dummy-Auth-Test'] == 'dummy-auth-test-ok'
+        assert resp.json()['headers'][
-        cid = CaseInsensitiveDict({'Foo': 'foo','BAr': 'bar'})
+        cid = CaseInsensitiveDict({'Foo': 'foo', 'BAr': 'bar'})
-        cid = CaseInsensitiveDict({'Foo': 'foo','BAr': 'bar'})
+        cid = CaseInsensitiveDict({'Foo': 'foo', 'BAr': 'bar'})
-        assert super_len(StringIO.StringIO('with so much drama in the LBC')) == 29
+        assert super_len(
-        assert super_len(BytesIO(b"it's kinda hard bein' snoop d-o-double-g")) == 40
+        assert super_len(
-            assert super_len(cStringIO.StringIO('but some how, some way...')) == 25
+            assert super_len(
-        """ Ensures that IP addresses are correctly matches with ranges in no_proxy variable """
+        """Ensures that IP addresses are correctly matches with ranges
-        """ Ensures that IP addresses are correctly matches with ranges in no_proxy variable """
+        """Ensures that IP addresses are correctly matches with ranges
-        assert get_environ_proxies('http://localhost.localdomain:5000/v1.0/') == {}
+        assert get_environ_proxies(
-        """ Ensures that username and password in well-encoded URI as per RFC 3986 are correclty extracted """
+        """Ensures that username and password in well-encoded URI as per
-        url = "http://" + quote(percent_encoding_test_chars, '') + ':' + quote(percent_encoding_test_chars, '') + '@' + url_address
+        url = "http://" + quote(
-            r = requests.get('https://httpbin.org/delay/10', timeout=5.0)
+            requests.get('https://httpbin.org/delay/10', timeout=5.0)
-            ]
+        (('a', 'b'), ('c', 'd')),
-                                            **proxy_kwargs)
+                proxy,
-    ).strip()
+    authstr = 'Basic ' + to_native_string(
-    return to_native_string(authstr, encoding='latin1')
+    return authstr
-from .utils import parse_dict_header
+from .utils import parse_dict_header, to_native_string
-    return 'Basic ' + b64encode(('%s:%s' % (username, password)).encode('latin1')).strip().decode('latin1')
+    authstr = 'Basic ' + b64encode(
-from requests.auth import HTTPDigestAuth
+from requests.auth import HTTPDigestAuth, _basic_auth_str
-    Morsel, cookielib, getproxies, str, urljoin, urlparse, is_py3)
+    Morsel, cookielib, getproxies, str, urljoin, urlparse, is_py3, builtin_str)
-            # Facilitate non-RFC2616-compliant 'location' headers
+            # Facilitate relative 'location' headers, as allowed by RFC 7231.
-            # http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.4
+            # http://tools.ietf.org/html/rfc7231#section-6.4.4
-        p._cookies = self._cookies.copy()
+        p.headers = self.headers.copy() if self.headers is not None else None
-                    if isinstance(data, basestring) or isinstance(data, builtin_str) or hasattr(data, 'read'):
+                    if isinstance(data, basestring) or hasattr(data, 'read'):
-                    if isinstance(data, str) or isinstance(data, builtin_str) or hasattr(data, 'read'):
+                    if isinstance(data, basestring) or isinstance(data, builtin_str) or hasattr(data, 'read'):
-    Morsel, cookielib, getproxies, str, urljoin, urlparse)
+    Morsel, cookielib, getproxies, str, urljoin, urlparse, is_py3)
-            pytest.raises(ValueError, "requests.post(url, data=u'[{\"some\": \"data\"}]', files={'some': f})")
+            pytest.raises(ValueError, "requests.post(url, data=u('[{\"some\": \"data\"}]'), files={'some': f})")
-                          data={'stuff': u'Ã«lÃ¯xr'},
+                          data={'stuff': u('Ã«lÃ¯xr')},
-                          data={'stuff': u'Ã«lÃ¯xr'.encode('utf-8')},
+                          data={'stuff': u('Ã«lÃ¯xr').encode('utf-8')},
-        r = requests.request(method=u'POST', url=httpbin('post'), files=files)
+        r = requests.request(method=u('POST'), url=httpbin('post'), files=files)
-        headers = {u'unicode': 'blah', 'byte'.encode('ascii'): 'blah'}
+        headers = {u('unicode'): 'blah', 'byte'.encode('ascii'): 'blah'}
-except ImportError:
+except (ImportError, SyntaxError):
-        from user code, and is only exposed for use when subclassing the
+    def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):
-                                       block=block)
+                                       block=block, **pool_kwargs)
-        subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
+    def proxy_manager_for(self, proxy, **proxy_kwargs):
-                                            block=self._pool_block)
+                                            block=self._pool_block,
-            conn = self.proxy_manager[proxy].connection_from_url(url)
+            proxy_manager = self.proxy_manager_for(proxy)
-__build__ = 0x020201
+__version__ = '2.3.0'
-        
+
-        return r
+        return self.build_response(request, resp)
-from .exceptions import TooManyRedirects, InvalidSchema
+from .exceptions import (
-            resp.content  # Consume socket so it can be released
+            try:
-__version__ = '1.8.2'
+__version__ = 'dev'
-        if self._tunnel_host:
+        # the _tunnel_host attribute was added in python 2.6.3 (via
-        # not have them.
+        hostname = self.host
-                                    server_hostname=self.host,
+                                    server_hostname=hostname,
-                               self.assert_hostname or self.host)
+                               self.assert_hostname or hostname)
-        The filename to guess the "Content-Type" of using :mod:`mimetimes`.
+        The filename to guess the "Content-Type" of using :mod:`mimetypes`.
-__build__ = 0x020300
+__version__ = '2.2.1'
-    'requests.packages.urllib3.packages.ssl_match_hostname'
+    'requests.packages.urllib3.util',
-        back to the pool.
+        """Releases the connection back to the pool. Once this method has been
-        new_proxies = {}
+        scheme = urlparse(url).scheme
-        if not should_bypass_proxies(url):
+        if self.trust_env and not should_bypass_proxies(url):
-__version__ = '1.8'
+__version__ = '1.8.2'
-        if sys.version_info < (2, 7):  # Python 2.6 and earlier
+        if sys.version_info < (2, 7):  # Python 2.6 and older
-        _HTTPConnection.__init__(self, *args, **kw)
+        # Pre-set source_address in case we have an older Python like 2.6.
-        """ Establish a socket connection and set nodelay settings on it
+        """ Establish a socket connection and set nodelay settings on it.
-                        self.tcp_nodelay)
+            (self.host, self.port), self.timeout, *extra_args)
-                 source_address=None):
+                 strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT, **kw):
-                                source_address=source_address)
+        HTTPConnection.__init__(self, host, port, strict=strict,
-            )
+                address=(self.host, self.port), timeout=self.timeout,
-    assert_fingerprint,
+        if host is None:
-                 headers=None, _proxy=None, _proxy_headers=None):
+                 headers=None, _proxy=None, _proxy_headers=None, **conn_kw):
-                                  strict=self.strict)
+                                  strict=self.strict, **self.conn_kw)
-                 assert_hostname=None, assert_fingerprint=None):
+                 assert_hostname=None, assert_fingerprint=None,
-                                    block, headers, _proxy, _proxy_headers)
+                                    block, headers, _proxy, _proxy_headers, **conn_kw)
-'''SSL with SNI_-support for Python 2.
+'''SSL with SNI_-support for Python 2. Follow these instructions if you would
-your application begins using ``urllib3``, like this::
+You can install them with the following command:
-                           ssl_version=ssl_version)
+# urllib3/util/__init__.py
-        # e.g. BytesIO, cStringIO.StringI
+        # e.g. BytesIO, cStringIO.StringIO
-__version__ = 'dev'
+__version__ = '1.8'
-from collections import MutableMapping
+from collections import Mapping, MutableMapping
-__all__ = ['RecentlyUsedContainer']
+__all__ = ['RecentlyUsedContainer', 'HTTPHeaderDict']
-            )
+        extra_args = []
-            HTTPConnection.__init__(self, host, port, strict, timeout)
+
-                                  **extra_params)
+                                  strict=self.strict)
-                        % self.host)
+            log.warning(
-            303, 307, 308). Each redirect counts as a retry.
+            303, 307, 308). Each redirect counts as a retry. Disabling retries
-        if retries < 0:
+        if retries < 0 and retries is not False:
-            # Timed out by queue
+            # Timed out by queue.
-        except BaseSSLError as e:
+        except (BaseSSLError, CertificateError) as e:
-            raise SSLError(e)
+        except (TimeoutError, HTTPException, SocketError) as e:
-            err = e
+            if not retries:
-                raise
+                # Wrap unexpected exceptions with the most appropriate
-            err = e
+                if retries is False:
-                    raise MaxRetryError(self, url, e)
+            # Keep track of the error for the retry warning.
-                     "broken by '%r': %s" % (retries, err, url))
+            log.warning("Retrying (%d attempts remain) after connection "
-        if redirect_location:
+        if redirect_location and retries is not False:
-    !MD5 !EXP !PSK !SRP !DSS'``
+    Default: ``ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:
-from socket import _fileobject
+from socket import _fileobject, timeout
-        'EECDH RC4 !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS'
+# A secure default.
-                        continue
+                    self._wait_for_sock()
-        from _implementation import CertificateError, match_hostname
+        from ._implementation import CertificateError, match_hostname
-        self.headers = headers or {}
+
-        headers = {}
+        headers = HTTPHeaderDict()
-            headers[k] = v
+            headers.add(k, v)
-            not isinstance(data, dict)
+            not isinstance(data, (basestring, list, tuple, dict))
-        'proxies': None,
+        'proxies': {},
-        return '%s' % (dict(self.items()))
+        return str(dict(self.items()))
-        return '%s' % (dict(self.items())
+        return '%s' % (dict(self.items()))
-            try:
+            proxy = environ_proxies.get(scheme)
-            pass
+            username, password = None, None
-                prepared_request,
+                req,
-            r.history = tuple(history)
+    def test_history_is_always_a_list(self):
-        # a new one (potentially re-adding the one we just removed).
+from .auth import _basic_auth_str
-from .utils import requote_uri, get_environ_proxies, get_netrc_auth
+from .utils import (
-                prepared_request.prepare_auth(new_auth)
+            self.rebuild_auth(prepared_request, resp)
-
+def should_bypass_proxies(url):
-                        return {}
+                        return True
-                    return {}
+                    return True
-        return {}
+        return True
-    return getproxies()
+    return False
-        'Accept-Encoding': ', '.join(('gzip', 'deflate', 'compress')),
+        'Accept-Encoding': ', '.join(('gzip', 'deflate')),
-        gen = generate()
+        # simulate reading small chunks of the content
-            gen = stream_decode_response_unicode(gen, self)
+            chunks = stream_decode_response_unicode(chunks, self)
-        return gen
+        return chunks
-            timeout = TimeoutSauce(connect=timeout, read=timeout)
+        timeout = TimeoutSauce(connect=timeout, read=timeout)
-            proxy = prepend_scheme_if_needed(proxy, urlparse(url.lower()).scheme)
+            proxy = prepend_scheme_if_needed(proxy, 'http')
-                    except_on_missing_scheme, get_auth_from_url)
+                    prepend_scheme_if_needed, get_auth_from_url)
-            except_on_missing_scheme(proxy)
+            proxy = prepend_scheme_if_needed(proxy, urlparse(url.lower()).scheme)
-                     builtin_str, getproxies, proxy_bypass)
+                     builtin_str, getproxies, proxy_bypass, urlunparse)
-from .exceptions import MissingSchema, InvalidURL
+from .exceptions import InvalidURL
-    scheme, netloc, path, params, query, fragment = urlparse(url)
+def prepend_scheme_if_needed(url, new_scheme):
-        raise MissingSchema('Proxy URLs must have explicit schemes.')
+    return urlunparse((scheme, netloc, path, params, query, fragment))
-    :param timeout: (optional) Float describing the timeout of the request.
+    :param timeout: (optional) Float describing the timeout of the request in seconds.
-            request.
+            request in seconds.
-__build__ = 0x020201
+__version__ = '2.3.0'
-
+from .status_codes import codes
-from .models import Request, PreparedRequest
+from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT
-DEFAULT_REDIRECT_LIMIT = 30
+
-        while ('location' in resp.headers and resp.status_code in REDIRECT_STATI):
+        while resp.is_redirect:
-        #: Integer Code of responded HTTP Status.
+        #: Integer Code of responded HTTP Status, e.g. 404 or 200.
-        (Thanks, Ian!)."""
+        """The apparent encoding, provided by the chardet library"""
-            # decoding fails, fall back to `self.text` (using charade to make
+            # decoding fails, fall back to `self.text` (using chardet to make
-            # decoding fails, fall back to `self.text` (using chardet to make
+            # decoding fails, fall back to `self.text` (using charade to make
-                return json.loads(self.content.decode(encoding), **kwargs)
+                try:
-                                                 decode_content=True):
+                    for chunk in self.raw.stream(chunk_size, decode_content=True):
-                                       decode_unicode=decode_unicode):
+        for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):
-    codes.temporary_moved, # 307
+    codes.moved,  # 301
-        # hooks
+        # Set up variables needed for resolve_redirects and dispatching of hooks
-                                     proxies=proxies)
+        gen = self.resolve_redirects(r, request,
-                                   prepared_request, resp.raw)
+            extract_cookies_to_jar(prepared_request._cookies, prepared_request, resp.raw)
-            redirect_parsed = urlparse(url)
+            if 'Authorization' in headers:
-                del headers['Authorization']
+                if (original_parsed.hostname != redirect_parsed.hostname):
-            # does.
+            # .netrc might have more auth for us.
-            new_auth = get_netrc_auth(url)
+            new_auth = get_netrc_auth(url) if self.trust_env else None
-                    pass
+            if (original_parsed.hostname != redirect_parsed.hostname and
-    license=license,
+    license='Apache 2.0',
-        if response and not self.request and hasattr(response, 'request'):
+        if (response is not None and not self.request and
-        self.response = kwargs.pop('response', None)
+        response = kwargs.pop('response', None)
-        if self.response and not self.request:
+        if response and not self.request and hasattr(response, 'request'):
-            raise ConnectionError(sockerr)
+            raise ConnectionError(sockerr, request=request)
-            raise ConnectionError(e)
+            raise ConnectionError(e, request=request)
-                raise SSLError(e)
+                raise SSLError(e, request=request)
-                raise Timeout(e)
+                raise Timeout(e, request=request)
-from .utils import to_key_val_list, default_headers
+from .utils import to_key_val_list, default_headers, to_native_string
-            prepared_request.url = url
+            prepared_request.url = to_native_string(url)
-        The encoding of the response content is determined based soley on HTTP
+        The encoding of the response content is determined based solely on HTTP
-__build__ = 0x020200
+__version__ = '2.2.1'
-    from http.client import HTTPConnection, HTTPException
+    from http.client import HTTPConnection as _HTTPConnection, HTTPException
-    from httplib import HTTPConnection, HTTPException
+    from httplib import HTTPConnection as _HTTPConnection, HTTPException
-        from http.client import HTTPSConnection
+        from http.client import HTTPSConnection as _HTTPSConnection
-        from httplib import HTTPSConnection
+        from httplib import HTTPSConnection as _HTTPSConnection
-                    (self.host, self.timeout))
+            raise ConnectTimeoutError(
-        Return a fresh :class:`httplib.HTTPConnection`.
+        Return a fresh :class:`HTTPConnection`.
-        return self.ConnectionCls(host=self.host, port=self.port,
+        conn = self.ConnectionCls(host=self.host, port=self.port,
-        Perform a request on a given httplib connection object taken from our
+        Perform a request on a given urllib connection object taken from our
-                raise MaxRetryError(self, url, e)
+                if isinstance(e, SocketError) and self.proxy is not None:
-    instead of :class:`httplib.HTTPSConnection`.
+    instead of :class:`.HTTPSConnection`.
-'''SSL with SNI-support for Python 2.
+'''SSL with SNI_-support for Python 2.
-from ndg.httpsclient.subj_alt_name import SubjectAltName
+from ndg.httpsclient.subj_alt_name import SubjectAltName as BaseSubjectAltName
-    Iterate over fields.
+    .. deprecated:: 1.6
-    .. deprecated ::
+    Iterate over fields.
-      `~urllib3.fields.RequestField` objects, instead.
+    The addition of :class:`~urllib3.fields.RequestField` makes this function
-# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2014 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-    :param poxy_url:
+    :param proxy_url:
-        return (parsed.username, parsed.password)
+        username = ""
-        url = 'http://user%user:pass@complex.url.com/path?query=yes'
+        url = 'http://user%25user:pass@complex.url.com/path?query=yes'
-            time.strptime(morsel['expires'], time_template)) - time.timezone
+        expires = calendar.timegm(time.strptime(morsel['expires'],
-        parsed = urlparse(url)
+    parsed = urlparse(url)
-    else:
+    try:
-            return (unquote(parsed.username), unquote(parsed.password))
+            auth = (unquote(parsed.username), unquote(parsed.password))
-            pass
+            auth = ('', '')
-    return ('', '')
+    return auth
-        except AttributeError:
+        except (AttributeError, TypeError):
-        return ('', '')
+
-    
+
-__build__ = 0x020100
+__version__ = '2.2.0'
-class ContentDecodingError(RequestException):
+class ContentDecodingError(RequestException, BaseHTTPError):
-        if self._tunnel_host:
+        # the _tunnel_host attribute was added in python 2.6.3 (via
-            # Use explicit default port for comparison when none is given.
+        elif not self.port and port == port_by_scheme.get(scheme):
-            if os.path.exists(loc) and not netrc_path:
+            if os.path.exists(loc):
-            return netrc_path
+            return
-        for loc in locations:
+        for f in NETRC_FILES:
-    if proxy_bypass(netloc):
+    # The proxy_bypass function is incredibly buggy on OS X in early versions
-copyright = u'2013. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'2014. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-:copyright: (c) 2013 by Kenneth Reitz.
+:copyright: (c) 2014 by Kenneth Reitz.
-__copyright__ = 'Copyright 2013 Kenneth Reitz'
+__copyright__ = 'Copyright 2014 Kenneth Reitz'
-    :param max_retries: The maximum number of retries each connection should attempt.
+    :param int max_retries: The maximum number of retries each connection
-      >>> a = requests.adapters.HTTPAdapter()
+      >>> a = requests.adapters.HTTPAdapter(max_retries=3)
-        #: Requires that ``stream=True` on the request.
+        #: Use of ``raw`` requires that ``stream=True`` be set on the request.
-        session's settings.
+            session's settings.
-extensions = ['sphinx.ext.autodoc']
+extensions = [
-                                                proxy_headers=proxy_headers)
+                                                proxy_headers=proxy_headers,
-    ChunkedEncodingError)
+    ChunkedEncodingError, ContentDecodingError)
-    def test_cookie_as_dict(self):
+    def test_cookie_as_dict_keeps_len(self):
-        assert d3['some_cookie'] == 'some_value'
+        assert d3['some_cookie1'] == 'some_value1'
-    'requests.packages.charade',
+    'requests.packages.chardet',
-from .packages import charade as chardet
+from .packages import chardet
-        ``charade``.
+        ``chardet``.
-        
+######################## BEGIN LICENSE BLOCK ########################
-        return "Big5"
+######################## BEGIN LICENSE BLOCK ########################
-            return -1
+######################## BEGIN LICENSE BLOCK ########################
-#            return self._mBestGuessProber.get_confidence()
+######################## BEGIN LICENSE BLOCK ########################
-        return self._mModel['name']
+######################## BEGIN LICENSE BLOCK ########################
-SHORTCUT_THRESHOLD = 0.95
+######################## BEGIN LICENSE BLOCK ########################
-        return "CP949"
+######################## BEGIN LICENSE BLOCK ########################
-        return self.get_state()
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-        return max(contxtCf, distribCf)
+######################## BEGIN LICENSE BLOCK ########################
-        return "EUC-KR"
+######################## BEGIN LICENSE BLOCK ########################
-        return "EUC-TW"
+######################## BEGIN LICENSE BLOCK ########################
-        return "GB2312"
+######################## BEGIN LICENSE BLOCK ########################
-        return eDetecting
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-        return confidence
+######################## BEGIN LICENSE BLOCK ########################
-        return self._mDistributionAnalyzer.get_confidence()
+######################## BEGIN LICENSE BLOCK ########################
-        self.reset()
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-        return r
+######################## BEGIN LICENSE BLOCK ########################
-        self.reset()
+######################## BEGIN LICENSE BLOCK ########################
-        return max(contxtCf, distribCf)
+######################## BEGIN LICENSE BLOCK ########################
-                                  prober.get_confidence()))
+######################## BEGIN LICENSE BLOCK ########################
-            return unlike
+######################## BEGIN LICENSE BLOCK ########################
-from .compat import cookielib, urlparse, urlunparse, Morsel, is_py3
+from .compat import cookielib, urlparse, urlunparse, Morsel
-            return list(self.iterkeys())
+        return list(self.iterkeys())
-            return list(self.itervalues())
+        return list(self.itervalues())
-            return list(self.iteritems())
+        return list(self.iteritems())
-from .compat import cookielib, urlparse, urlunparse, Morsel
+from .compat import cookielib, urlparse, urlunparse, Morsel, is_py3
-        keys = []
+        if is_py3:
-        return keys
+            yield cookie.value
-        values = []
+        if is_py3:
-        return values
+            yield cookie.name, cookie.value
-        return items
+        if is_py3:
-
+        # Can't handle by adding 'proxy_manager' to self.__attrs__ because
-        self.assertEquals(cookie.expires, 1)
+        assert cookie.expires == 1
-        self.assertRaises(TypeError, morsel_to_cookie, (morsel))
+        with pytest.raises(TypeError):
-        self.assertRaises(ValueError, morsel_to_cookie, (morsel))
+        with pytest.raises(ValueError):
-        self.assertEquals(cookie.expires, None)
+        assert cookie.expires is None
-        self.assertTrue(isinstance(cookie.expires, int))
+        assert isinstance(cookie.expires, int)
-        self.assertRaises(TypeError, morsel_to_cookie, (morsel))
+        with pytest.raises(TypeError):
-        expires = time.mktime(time.strptime(morsel['expires'], time_template))
+        expires = time.mktime(
-        self.assertEquals(cookie.expires, 18001)
+        self.assertEquals(cookie.expires, 1)
-        self.assertIsInstance(cookie.expires, int)
+        self.assertTrue(isinstance(cookie.expires, int))
-        expires = time.time() + morsel["max-age"]
+    if morsel['max-age']:
-        discard=False,
+        time_template = '%a, %d-%b-%Y %H:%M:%S GMT'
-    return c
+        rfc2109=False,
-
+
-        if type(expires) == type(""):
+        try:
-import unittest
+import unittest
-from requests.cookies import cookiejar_from_dict
+from requests.auth import HTTPDigestAuth
-__build__ = 0x020001
+__version__ = '2.1.0'
-def default_user_agent(name=u"python-requests"):
+def default_user_agent(name="python-requests"):
-                     u'%s/%s' % (p_system, p_release)])
+    return " ".join(['%s/%s' % (name, __version__),
-    if '/' in string_network:
+def is_valid_cidr(string_network):
-                if is_ipv4_network(proxy_ip):
+                if is_valid_cidr(proxy_ip):
-        assert is_ipv4_network('192.168.1.0/24')
+    def test_is_valid_cidr(self):
-    This function allows you to check if on IP belongs to a Network subnet
+    This function allows you to check if on IP belongs to a network subnet
-    except BaseException:
+    except socket.error:
-        except OSError:
+        except socket.error:
-def default_user_agent():
+def default_user_agent(name=u"python-requests"):
-                     '%s/%s' % (p_system, p_release)])
+    return " ".join([u'%s/%s' % (name, __version__),
-    Example: if mask is /24 function returns 255.255.255.0
+    Example: if mask is 24 function returns 255.255.255.0
-            prep.prepare_cookies(prep.cookies)
+            extract_cookies_to_jar(prep._cookies, r.request, r.raw)
-        self.cookies = None
+        # The `CookieJar` used to create the Cookie header will be stored here
-        p.cookies = self.cookies.copy()
+        p._cookies = self._cookies.copy()
-            self.cookies = cookies
+            self._cookies = cookies
-            self.cookies = cookiejar_from_dict(cookies)
+            self._cookies = cookiejar_from_dict(cookies)
-        cookie_header = get_cookie_header(self.cookies, self)
+        cookie_header = get_cookie_header(self._cookies, self)
-            prepared_request.prepare_cookies(prepared_request.cookies)
+            extract_cookies_to_jar(prepared_request._cookies,
-            prep.prepare_cookies(r.cookies)
+            extract_cookies_to_jar(prep.cookies, r.request, r.raw)
-            cookies = cookies
+            self.cookies = cookies
-            cookies = cookiejar_from_dict(cookies)
+            self.cookies = cookiejar_from_dict(cookies)
-                self.headers['Cookie'] = cookie_header
+        cookie_header = get_cookie_header(self.cookies, self)
-            prepared_request.prepare_cookies(self.cookies)
+            extract_cookies_to_jar(prepared_request.cookies, prepared_request, resp.raw)
-        r = s.get(httpbin('redirect/1'), cookies={'foo':'bar'})
+        r = s.get(httpbin('redirect/1'), cookies={'foo': 'bar'})
-    '''This function allows you to check if on IP belogs to a Network'''
+def address_in_network(ip, net):
-        assert get_environ_proxies('http://www.requests.com:5000/v1.0/') != {}
+        assert get_environ_proxies('http://www.requests.com:5000/v1.0/') != {}
-import netaddr
+import socket
-        if ip:
+        ip = netloc.split(':')[0]
-                    return {}
+                if is_ipv4_network(proxy_ip):
-        os.environ['no_proxy'] = "127.0.0.1,localhost.localdomain,192.168.0.0/24,172.16.1.1"
+        os.environ['no_proxy'] = "192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1"
-        assert get_environ_proxies('http://192.168.1.1:5000/') == {'no': os.environ['no_proxy']}
+        assert get_environ_proxies('http://172.16.1.1:5000/') == {}
-                return {}
+        ip = None
-                     is_py2, is_py3, builtin_str, getproxies, proxy_bypass)
+from .compat import (quote, urlparse, bytes, str, OrderedDict, unquote, is_py2,
-        
+
-            base += ', qop=auth, nc=%s, cnonce="%s"' % (ncvalue, cnonce)
+            base += ', qop="auth", nc=%s, cnonce="%s"' % (ncvalue, cnonce)
-            base += ', qop=auth, nc=%s, cnonce="%s"' % (ncvalue, cnonce)
+            base += ', qop="auth", nc=%s, cnonce="%s"' % (ncvalue, cnonce)
-from threading import RLock
+try:
-from .compat import cookielib, OrderedDict, urljoin, urlparse, urlunparse, builtin_str
+from .compat import cookielib, OrderedDict, urljoin, urlparse, builtin_str
-        except CookieJarError:
+            cookiejar.update(cookies)
-            if hasattr(cookiejar, 'update'):
+            try:
-            else:
+            except AttributeError:
-            cookies, cookiejar=merged_cookie, overwrite=False)
+        cookiejar = cookiejar_from_dict(
-        merged_cookie.update(cookies)
+        try:
-    return merged_cookie
+    return cookiejar
-        assert s.cookies['foo'] == 'bar'
+        assert s.cookies is cj
-            cookies, cookiejar=cookiejar, overwrite=False)
+        merged_cookie = cookiejar_from_dict(
-        cookiejar.update(cookies)
+        merged_cookie.update(cookies)
-    return cookiejar
+    return merged_cookie
-        merged_cookies.update(cookies)
+        merged_cookies = merge_cookies(
-        assert s.cookies is cj
+        assert isinstance(s.cookies, cookielib.CookieJar)
-                cookies, cookiejar=cookiejar, overwrite=False))
+        cookiejar = cookiejar_from_dict(
-from .cookies import cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar
+from .compat import cookielib, OrderedDict, urljoin, urlparse, urlunparse, builtin_str
-            self.cookies.update(cookies)
+        self.cookies = merge_cookies(self.cookies, cookies)
-        self.cookies = cookiejar_from_dict(cookies, cookiejar=self.cookies, overwrite=False)
+        if isinstance(cookies, dict):
-                    method not in ('GET', 'HEAD')):
+            if resp.status_code == codes.found and method != 'HEAD':
-            if (resp.status_code == codes.moved) and (method == 'POST'):
+            if resp.status_code == codes.moved and method == 'POST':
-            if (resp.status_code in (codes.moved, codes.found) and
+            # First, turn 302s into GETs.
-from .compat import urlparse, basestring, urldefrag, unquote, urlunparse
+from .compat import urlparse, basestring, urldefrag, unquote
-            url = urlunparse(parsed)
+            url = parsed.geturl()
-from .compat import cookielib, OrderedDict, urljoin, urlparse, urlunparse, builtin_str
+from .compat import cookielib, OrderedDict, urljoin, urlparse, builtin_str
-            url = urlunparse(parsed)
+            url = parsed.geturl()
-from .compat import urlparse, basestring, urldefrag, unquote
+from .compat import urlparse, basestring, urldefrag, unquote, urlunparse
-            conn = self.poolmanager.connection_from_url(url.lower())
+            # Only scheme should be lower case
-        scheme = urlparse(request.url).scheme.lower()
+        scheme = urlparse(request.url).scheme
-            parsed = (parsed.scheme.lower(), parsed.netloc, parsed.path,
+            parsed = (parsed.scheme, parsed.netloc, parsed.path,
-        if cookie.value.startswith('"') and cookie.value.endswith('"'):
+        if hasattr(cookie.value, 'startswith') and cookie.value.startswith('"') and cookie.value.endswith('"'):
-    
+
-from .. import connectionpool
+from .. import connection
-orig_connectionpool_ssl_wrap_socket = connectionpool.ssl_wrap_socket
+orig_connection_ssl_wrap_socket = connection.ssl_wrap_socket
-    connectionpool.ssl_wrap_socket = ssl_wrap_socket
+    connection.ssl_wrap_socket = ssl_wrap_socket
-    connectionpool.ssl_wrap_socket = orig_connectionpool_ssl_wrap_socket
+    connection.ssl_wrap_socket = orig_connection_ssl_wrap_socket
-            "subjectAltName fields were found")
+try:
-            # constructor's proxy_headers instead.
+            # For proxied HTTPS requests, httplib sets the necessary headers
-            kw['headers'].update(self.proxy_headers)
+        self._fp_bytes_read = 0
-                 basic_auth=None):
+                 basic_auth=None, proxy_basic_auth=None):
-from .compat import builtin_str
+
-    return session.request(method=builtin_str(method), url=url, **kwargs)
+    return session.request(method=method, url=url, **kwargs)
-from .compat import cookielib, OrderedDict, urljoin, urlparse, urlunparse
+from .compat import cookielib, OrderedDict, urljoin, urlparse, urlunparse, builtin_str
-
+from .compat import builtin_str
-    return session.request(method=method, url=url, **kwargs)
+    return session.request(method=builtin_str(method), url=url, **kwargs)
-        :param vert: (optional) Any user-provided SSL certificate to be trusted.
+        :param cert: (optional) Any user-provided SSL certificate to be trusted.
-        if Response.encoding is None, encoding will be guessed using
+        If Response.encoding is None, encoding will be guessed using
-        will be guessed.
+        if Response.encoding is None, encoding will be guessed using
-
+        # Don't do any URL preparation for oddball schemes
-from netrc import netrc, NetrcParseError
+        from netrc import netrc, NetrcParseError
-                     open('HISTORY.rst').read(),
+    long_description=readme + '\n\n' + history,
-    license=open('LICENSE').read(),
+    license=license,
-        self.assertRaises(InvalidURL, requests.get, 'http://')
+        with pytest.raises(MissingSchema):
-        self.assertTrue('Content-Length' not in get_req.headers)
+        assert 'Content-Length' not in get_req.headers
-        self.assertTrue('Content-Length' not in head_req.headers)
+        assert 'Content-Length' not in head_req.headers
-        self.assertEqual(request.path_url, "/get/test%20case")
+        assert request.path_url == '/get/test%20case'
-            "http://example.com/path?a=b#fragment")
+        assert request.url == "http://example.com/path?a=b#fragment"
-            "http://example.com/path?key=value&a=b#fragment")
+        assert request.url == "http://example.com/path?key=value&a=b#fragment"
-                             "failed for scheme %s" % scheme)
+            assert r.status_code == 200, 'failed for scheme {0}'.format(scheme)
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert heads['User-agent'] in r.text
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertTrue(s.cookies['foo'] == 'bar')
+        assert s.cookies['foo'] == 'bar'
-        self.assertTrue("Cookie" in r.json()["headers"])
+        assert 'Cookie' in r.json()['headers']
-        self.assertTrue(s.cookies['foo'] == 'bar')
+        assert s.cookies['foo'] == 'bar'
-        self.assertTrue(s.cookies['foo'] == '"bar:baz"')
+        assert s.cookies['foo'] == '"bar:baz"'
-        self.assertTrue('foo' in r.history[0].request.headers['Cookie'])
+        assert 'foo' in r.request.headers['Cookie']
-        self.assertEquals(urls, req_urls)
+        assert urls == req_urls
-        self.assertTrue(heads['User-agent'] in r.text)
+        assert heads['User-agent'] in r.text
-        self.assertTrue(heads['user-agent'] in r.text)
+        assert heads['user-agent'] in r.text
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 401)
+        assert r.status_code == 401
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 401)
+        assert r.status_code == 401
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 401)
+        assert r.status_code == 401
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 401)
+        assert r.status_code == 401
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertNotEqual(r.raw.read(), b'')
+        assert r.raw.read() != b''
-
+        assert r.raw.read() == b''
-        self.assertEqual(r.status_code, 401)
+        assert r.status_code == 401
-        self.assertEqual(r.status_code, 401)
+        assert r.status_code == 401
-        self.assertEqual(r.status_code, 401)
+        assert r.status_code == 401
-        self.assertEqual(post1.status_code, 200)
+        assert post1.status_code == 200
-        self.assertEqual(post2.status_code, 200)
+        assert post2.status_code == 200
-        self.assertEqual(post4.status_code, 200)
+        assert post4.status_code == 200
-            pass
+        with pytest.raises(ValueError):
-        self.assertEqual(post1.status_code, 200)
+        assert post1.status_code == 200
-        self.assertEqual(post2.status_code, 200)
+        assert post2.status_code == 200
-        self.assertEqual(post4.status_code, 200)
+        assert post4.status_code == 200
-            pass
+        with pytest.raises(ValueError):
-        self.assertEqual(r.ok, False)
+        assert not r.ok
-        self.assertRaises(requests.exceptions.HTTPError, r.raise_for_status)
+        with pytest.raises(requests.exceptions.HTTPError):
-        self.assertFalse(r.ok)
+        assert not r.ok
-        self.assertEqual(r.url, httpbin('get?test=foo&test=baz'))
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        self.assertFalse(b'name="b\'stuff\'"' in prep.body)
+        assert b'name="stuff"' in prep.body
-        self.assertTrue(b"text/py-content-type" in r.request.body)
+        assert r.status_code == 200
-        self.assertTrue(hasattr(resp, 'hook_working'))
+        assert hasattr(resp, 'hook_working')
-        self.assertEqual(req.auth, None)
+        assert not req.auth
-        self.assertTrue(resp.json()['headers']['Dummy-Auth-Test'], 'dummy-auth-test-ok')
+        assert resp.json()['headers']['Dummy-Auth-Test'] == 'dummy-auth-test-ok'
-        self.assertEqual(r.links['next']['rel'], 'next')
+        assert r.links['next']['rel'] == 'next'
-        self.assertTrue('some_cookie' in jar)
+        assert len(jar) == 1
-        self.assertEqual(cookie._rest['HttpOnly'], rest['HttpOnly'])
+        assert cookie.secure == secure
-        self.assertTrue(total_seconds > 0.0)
+        assert total_seconds > 0.0
-        self.assertTrue(next(iter(r)))
+        assert next(iter(r))
-                         requests.utils.get_auth_from_url(url))
+        assert ('user', 'pass') == requests.utils.get_auth_from_url(url)
-        self.assertRaises(ValueError, requests.Session().send, r)
+        with pytest.raises(ValueError):
-        self.assertEqual(error.response, None)
+        assert not error.response
-        self.assertEqual(error.response, response)
+        assert error.response == response
-        self.assertEqual(error.response, response)
+        assert str(error) == 'message'
-        self.assertEqual(r.status_code, 200)
+        assert r.status_code == 200
-        )
+        assert headers['accept'] == 'application/json'
-        self.assertEqual(r.url.lower(), url.lower())
+        assert r.status_code == 200
-        self.assertEqual(order, list(s.adapters))
+        assert order == list(s.adapters)
-        self.assertEqual(order, list(s.adapters))
+        assert order == list(s.adapters)
-        self.assertEqual(order, list(s.adapters))
+        assert order == list(s.adapters)
-        self.assertTrue('https://' in s2.adapters)
+        assert 'http://' in s2.adapters
-        self.assertEqual(r.url, url)
+        assert r.url == url
-        self.assertTrue('byte' in p.headers.keys())
+        assert 'unicode' in p.headers.keys()
-        self.assertTrue('multipart/form-data' in p.headers['Content-Type'])
+        assert 'multipart/form-data' in p.headers['Content-Type']
-
+        assert p.headers['Content-Length'] == length
-        self.assertEqual(len(encodings), 0)
+        assert not len(encodings)
-        self.assertEqual(encodings[0], 'UTF-8')
+        assert len(encodings) == 1
-        self.assertEqual(encodings[0], 'UTF-8')
+        assert len(encodings) == 1
-        self.assertEqual(encodings[0], 'UTF-8')
+        assert len(encodings) == 1
-        self.assertEqual(encodings[0], 'UTF-8')
+        assert len(encodings) == 1
-        self.assertEqual(encodings, ['HTML5', 'HTML4', 'XML'])
+        assert encodings == ['HTML5', 'HTML4', 'XML']
-        self.assertTrue('bar' in cid)
+        assert len(cid) == 2
-        self.assertTrue('bar' in cid)
+        assert len(cid) == 2
-        self.assertTrue('bar' in cid)
+        assert len(cid) == 2
-        self.assertEqual(list(cid), ['Accept'])
+        assert cid['aCCEPT'] == 'application/json'
-        self.assertEqual(len(cid), 2)
+        assert len(cid) == 2
-        self.assertEqual(cid['SPAM'], 'blueval')
+        assert cid['spam'] == 'blueval'
-        self.assertEqual(list(cid.keys()), ['SPAM'])
+        assert cid['spam'] == 'blueval'
-        self.assertEqual(len(cid), 0)
+        assert 'spam' not in cid
-        self.assertFalse('notspam' in cid)
+        assert 'Spam' in cid
-        self.assertEqual(cid.get('notspam', 'default'), 'default')
+        assert cid.get('spam') == 'blueval'
-        self.assertEqual(cid['spam'], 'notblueval')
+        assert cid['spam'] == 'notblueval'
-        self.assertEqual(cid['bar'], 'anotherbar')
+        assert len(cid) == 2
-        self.assertEquals(cid['bar'], 'bar')
+        assert cid['bar'] == 'bar'
-        self.assertEqual(frozenset(iter(cid)), keys)
+        assert frozenset(iter(cid)) == keys
-        self.assertEqual(cid, othercid)
+        assert cid == othercid
-        self.assertEqual(cid, {'spam': 'blueval', 'eggs': 'redval'})
+        assert cid != othercid
-        )
+        assert cid.setdefault('spam', 'notblueval') == 'blueval'
-        self.assertEqual(keyset, lowerkeyset)
+        assert keyset == lowerkeyset
-        self.assertEqual(frozenset(cid), keyset)
+        assert frozenset(i[0] for i in cid.items()) == keyset
-        self.assertEqual(frozenset(cid), keyset)
+        assert frozenset(i[0] for i in cid.items()) == keyset
-        self.assertEqual(super_len(StringIO.StringIO('with so much drama in the LBC')), 29)
+        assert super_len(StringIO.StringIO()) == 0
-        self.assertEqual(super_len(BytesIO(b"it's kinda hard bein' snoop d-o-double-g")), 40)
+        assert super_len(BytesIO()) == 0
-            self.assertEqual(super_len(cStringIO.StringIO('but some how, some way...')), 25)
+            assert super_len(cStringIO.StringIO('but some how, some way...')) == 25
-        if _algorithm == 'MD5':
+        if _algorithm == 'MD5' or _algorithm == 'MD5-SESS':
-        # XXX MD5-sess
+
-            respdig = KD(hash_utf8(A1), "%s:%s" % (nonce, hash_utf8(A2)))
+            respdig = KD(HA1, "%s:%s" % (nonce, HA2))
-            respdig = KD(hash_utf8(A1), noncebit)
+            respdig = KD(HA1, noncebit)
-            return (self._mTotalRel - self._mRelSample[0]) / self._mTotalRel
+            return float(self._mTotalRel - self._mRelSample[0]) / self._mTotalRel
-            confidence = ((self._mFreqCounter[3] / total)
+            confidence = ((float(self._mFreqCounter[3]) / total)
-            elif aBuf[:4] == codecs.BOM_UTF32_LE:
+            elif aBuf[:4] in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):
-                self.result = {'encoding': "UTF-32BE", 'confidence': 1.0}
+                self.result = {'encoding': "UTF-32", 'confidence': 1.0}
-            elif aBuf[:2] == codecs.BOM_LE:
+            elif aBuf[:2] == codecs.BOM_LE or aBuf[:2] == codecs.BOM_BE:
-                self.result = {'encoding': "UTF-16BE", 'confidence': 1.0}
+                self.result = {'encoding': "UTF-16", 'confidence': 1.0}
-
+    TimeoutError,
-from .packages.ssl_match_hostname import CertificateError, match_hostname
+from .packages.ssl_match_hostname import CertificateError
-    ssl_wrap_socket,
+
-    'https': HTTPS_PORT,
+    'http': 80,
-
+    ConnectionCls = HTTPConnection
-
+        return self.ConnectionCls(host=self.host, port=self.port,
-            # request.py. It also calls makefile (recv) on the socket
+            # urllib3.request. It also calls makefile (recv) on the socket.
-        log.debug("Setting read timeout to %s" % read_timeout)
+
-            read_timeout is not Timeout.DEFAULT_TIMEOUT:
+        if hasattr(conn, 'sock'):
-            conn.sock.settimeout(read_timeout)
+            if read_timeout is Timeout.DEFAULT_TIMEOUT:
-            raise
+            raise
-            raise ReadTimeoutError(self, url, "Read timed out.")
+            raise EmptyPoolError(self, "No pool connections are available.")
-                raise ReadTimeoutError(self, url, "Read timed out.")
+        except TimeoutError as e:
-    def _prepare_conn(self, connection):
+    def _prepare_conn(self, conn):
-            connection.ssl_version = self.ssl_version
+        if isinstance(conn, VerifiedHTTPSConnection):
-                set_tunnel = connection.set_tunnel
+                set_tunnel = conn.set_tunnel
-                set_tunnel = connection._set_tunnel
+                set_tunnel = conn._set_tunnel
-            connection.connect()
+            conn.connect()
-        return connection
+        return conn
-        return self._prepare_conn(connection)
+        conn = self.ConnectionCls(host=actual_host, port=actual_port,
-        return. This combines the connect and read timeouts into one. In the
+        This combines the connect and read timeouts into one; the read timeout
-        time out. This case is admittedly rare.
+        read operations on the socket connecting the client and the server,
-    def __init__(self, connect=_Default, read=_Default, total=None):
+    def __init__(self, total=None, connect=_Default, read=_Default):
-        auth, url = url.split('@', 1)
+        # Last '@' denotes end of auth part
-        port = int(port)
+        if port:
-__build__ = 0x020000
+__version__ = '2.0.1'
-        """Prepares the the entire request with the given parameters."""
+        """Prepares the entire request with the given parameters."""
-        while (('location' in resp.headers and resp.status_code in REDIRECT_STATI)):
+        while ('location' in resp.headers and resp.status_code in REDIRECT_STATI):
-                                "Perhaps you meant http://%s?" % (url, url))
+            raise MissingSchema("Invalid URL {0!r}: No schema supplied. "
-            raise MissingSchema("Invalid URL %r: No schema supplied" % url)
+            raise MissingSchema("Invalid URL %r: No schema supplied. "
-                self.headers['Content-Length'] = str(length)
+                self.headers['Content-Length'] = builtin_str(length)
-            self.headers['Content-Length'] = str(body.tell())
+            self.headers['Content-Length'] = builtin_str(body.tell())
-                self.headers['Content-Length'] = str(l)
+                self.headers['Content-Length'] = builtin_str(l)
-        2-tuples. Order is retained if data is a list of 2-tuples but abritrary
+        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
-                    resp = HTTPResponse.from_httplib(r,
+                    resp = HTTPResponse.from_httplib(
-                )
+                try:
-            rf = RequestField(name=k, data=fp.read(), 
+            rf = RequestField(name=k, data=fp.read(),
-        return json.loads(self.text or self.content, **kwargs)
+        return json.loads(self.text, **kwargs)
-        # If they did set it, retrieve it and reconstruct the expected doain
+        # If they did set it, retrieve it and reconstruct the expected domain
-        return os.fstat(o.fileno()).st_size
+        try:
-from .compat import cookielib, urlparse, Morsel
+from .compat import cookielib, urlparse, urlunparse, Morsel
-        return self._r.url
+        if not self._r.headers.get('Host'):
-    return ret
+    return merge_setting(request_hooks, session_hooks, dict_class)
-            hooks=merge_setting(request.hooks, self.hooks),
+            hooks=merge_hooks(request.hooks, self.hooks),
-    class BaseSSLError(Exception):
+    class BaseSSLError(BaseException):
-   >>> print (r.text)
+   >>> print(r.text)
-                while 1:
+                while True:
-   >>> print r.text
+   >>> print (r.text)
-    class BaseSSLError(BaseException):
+    class BaseSSLError(Exception):
-from .exceptions import ConnectionError, Timeout, SSLError
+from .exceptions import ConnectionError, Timeout, SSLError, ProxyError
-                else:
+                elif len(v) == 3:
-            new_fields.append((k, new_v))
+            rf = RequestField(name=k, data=fp.read(), 
-def cookiejar_from_dict(cookie_dict, cookiejar=None):
+def cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True):
-    """Merges cookie_dict with session CookieJar.
+            if overwrite or (name not in names_from_jar):
-                cookiejar.set_cookie(create_cookie(k, cookie_dict[k]))
+    return cookiejar
-from .cookies import cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_session_cookies
+from .cookies import cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar
-        merge_session_cookies(self.cookies, cookies)
+        self.cookies = cookiejar_from_dict(cookies, cookiejar=self.cookies, overwrite=False)
-from .compat import cookielib, OrderedDict, urljoin, urlparse
+from .compat import cookielib, OrderedDict, urljoin, urlparse, urlunparse
-                url = '%s://%s' % (scheme.lower(), uri)
+            parsed = urlparse(url)
-        used. Otherwise, we should only use the path portion of the URL.
+        If the message is being sent through a HTTP proxy, the full URL has to
-        proxy = proxies.get(urlparse(request.url).scheme)
+        scheme = urlparse(request.url).scheme.lower()
-        if proxy:
+        if proxy and scheme != 'https':
-from .cookies import cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar
+from .cookies import cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_session_cookies
-
+        # Add param cookies to session cookies
-        if _algorithm == 'MD5' or _algorithm == 'MD5-SESS':
+        if _algorithm == 'MD5':
-
+        # XXX MD5-sess
-            respdig = KD(HA1, "%s:%s" % (nonce, HA2))
+            respdig = KD(hash_utf8(A1), "%s:%s" % (nonce, hash_utf8(A2)))
-            respdig = KD(HA1, noncebit)
+            if nonce == self.last_nonce:
-        p.headers = self.headers
+        p.headers = self.headers.copy()
-        if _algorithm == 'MD5':
+        if _algorithm == 'MD5' or _algorithm == 'MD5-SESS':
-        # XXX MD5-sess
+
-            respdig = KD(hash_utf8(A1), "%s:%s" % (nonce, hash_utf8(A2)))
+            respdig = KD(HA1, "%s:%s" % (nonce, HA2))
-            respdig = KD(hash_utf8(A1), noncebit)
+            respdig = KD(HA1, noncebit)
-from .packages.urllib3.util import Timeout
+from .packages.urllib3.util import Timeout as TimeoutSauce
-            timeout = Timeout(connect=timeout)
+            timeout = TimeoutSauce(connect=timeout)
-            timeout = Timeout(connect=timeout, read=timeout)
+            timeout = TimeoutSauce(connect=timeout, read=timeout)
-__build__ = 0x010203
+__version__ = '2.0.0'
-from .util import make_headers, get_host
+from .util import make_headers, get_host, Timeout
-import socket
+import logging
-from .util import resolve_cert_reqs, resolve_ssl_version, assert_fingerprint
+import socket
-from .util import get_host, is_connection_dropped, ssl_wrap_socket
+    ConnectTimeoutError,
-    TimeoutError,
+    ReadTimeoutError,
-from .packages.ssl_match_hostname import match_hostname, CertificateError
+from .packages.ssl_match_hostname import CertificateError, match_hostname
-
+from .request import RequestMethods
-        sock = socket.create_connection((self.host, self.port), self.timeout)
+        try:
-        a float. None disables timeout.
+        Socket timeout in seconds for each individual connection. This can
-                 block=False, headers=None, _proxy=None, _proxy_headers=None):
+    def __init__(self, host, port=None, strict=False,
-                              strict=self.strict)
+        extra_params = {}
-        conn.close()
+        if conn:
-        conn.request(method, url, **httplib_request_kw)
+        timeout_obj = self._get_timeout(timeout)
-            sock.settimeout(timeout)
+        try:
-            303, 307). Each redirect counts as a retry.
+            303, 307, 308). Each redirect counts as a retry.
-            It may be a float (in seconds).
+            If specified, overrides the default timeout for this one
-        except Empty as e:
+        except Empty:
-                               pool_timeout)
+            raise ReadTimeoutError(
-        except SocketTimeout as e:
+        except SocketTimeout:
-                               timeout)
+            raise ReadTimeoutError(self, url, "Read timed out.")
-                                    strict, timeout, maxsize,
+        HTTPConnectionPool.__init__(self, host, port, strict, timeout, maxsize,
-                                      strict=self.strict)
+                                      timeout=self.timeout.connect_timeout,
-                                                   SUBJ_ALT_NAME_SUPPORT)
+from ndg.httpsclient.ssl_peer_verification import SUBJ_ALT_NAME_SUPPORT
-        return _fileobject(self.connection, mode, bufsize)
+        return fileobject(self.connection, mode, bufsize)
-            raise ssl.SSLError('')
+            return x509
-        raise ssl.SSLError('bad handshake', e)
+    while True:
-    "Raised when a socket timeout occurs."
+class TimeoutStateError(HTTPError):
-    return mimetypes.guess_type(filename)[0] or 'application/octet-stream'
+def iter_field_objects(fields):
-        Field names and filenames must be unicode.
+        Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).
-    for fieldname, value in iter_fields(fields):
+    for field in iter_field_objects(fields):
-            body.write(b'\r\n')
+        writer(body).write(field.render_headers())
-def _dnsname_to_pat(dn):
+def _dnsname_match(dn, hostname, max_wildcards=1):
-    return re.compile(r'\A' + r'\.'.join(pats) + r'\Z', re.IGNORECASE)
+    if not dn:
-    are mostly followed, but IP addresses are not accepted for *hostname*.
+    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
-            if _dnsname_to_pat(value).match(hostname):
+            if _dnsname_match(value, hostname):
-                    if _dnsname_to_pat(value).match(hostname):
+                    if _dnsname_match(value, hostname):
-        if self.status in [301, 302, 303, 307]:
+        if self.status in self.REDIRECT_STATUSES:
-from binascii import hexlify, unhexlify
+from socket import error as SocketError, _GLOBAL_DEFAULT_TIMEOUT
-from .exceptions import LocationParseError, SSLError
+from .exceptions import LocationParseError, SSLError, TimeoutStateError
-        if qop == 'auth':
+        if qop is None:
-        params=dict(),
+        data=None,
-        :class:`HTTPAdapter <reqeusts.adapters.HTTPAdapter>`.
+        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
-    Provides cookie persistience, connection-pooling, and configuration.
+    Provides cookie persistence, connection-pooling, and configuration.
-        for _, v in self.adapters.items():
+        for v in self.adapters.values():
-    return charset_re.findall(content)
+    return (charset_re.findall(content) +
-    from requests.packages.urllib3.contrib import pyopenssl
+    from .packages.urllib3.contrib import pyopenssl
-        no_proxy = no_proxy.split(',')
+        no_proxy = no_proxy.replace(' ', '').split(',')
-class RequestException(RuntimeError):
+class RequestException(IOError):
-                self.proxy_manager[proxy] = proxy_from_url(proxy)
+                self.proxy_manager[proxy] = proxy_from_url(
-        Proxy-Authorization header.
+        """Add any headers needed by the connection. As of v2.0 this does
-        proxies = kwargs.get('proxies', {})
+        pass
-            proxies = {}
+    def proxy_headers(self, proxy):
-        proxy = proxies.get(urlparse(request.url).scheme)
+        This should not be called from user code, and is only exposed for use
-                                                                     password)
+            headers['Proxy-Authorization'] = _basic_auth_str(username,
-        self.add_headers(request, proxies=proxies)
+        self.add_headers(request)
-                pass
+            pytest.raises(ValueError, "requests.post(url, data='[{\"some\": \"data\"}]', files={'some': f})")
-            return None
+        if (not files):
-from io import BytesIO
+from io import BytesIO, UnsupportedOperation
-        except (TypeError, AttributeError):
+        except (TypeError, AttributeError, UnsupportedOperation):
-            conn = proxy_from_url(proxy).connection_from_url(url)
+            if not proxy in self.proxy_manager:
-from .packages.urllib3.poolmanager import PoolManager, ProxyManager
+from .packages.urllib3.poolmanager import PoolManager, proxy_from_url
-            conn = ProxyManager(self.poolmanager.connection_from_url(proxy))
+            conn = proxy_from_url(proxy).connection_from_url(url)
-                 block=False, headers=None):
+                 block=False, headers=None, _proxy=None, _proxy_headers=None):
-                                    block, headers)
+                                    block, headers, _proxy, _proxy_headers)
-                                   strict=self.strict)
+        connection = connection_class(host=actual_host, port=actual_port,
-        return connection
+        return self._prepare_conn(connection)
-from .connectionpool import connection_from_url, port_by_scheme
+from .connectionpool import port_by_scheme
-          self.pools[pool_key] = pool
+            # If the scheme, host, or port doesn't match existing open
-        response = conn.urlopen(method, u.request_uri, **kw)
+        if self.proxy is not None and u.scheme == "http":
-class ProxyManager(RequestMethods):
+class ProxyManager(PoolManager):
-    class will automatically set the 'Host' header if it is not provided.
+    Behaves just like :class:`PoolManager`, but sends all requests through
-        self.proxy_pool = proxy_pool
+    def __init__(self, proxy_url, num_pools=10, headers=None,
-    def urlopen(self, method, url, **kw):
+    def urlopen(self, method, url, redirect=True, **kw):
-        return self.proxy_pool.urlopen(method, url, **kw)
+        u = parse_url(url)
-    return ProxyManager(proxy_pool)
+def proxy_from_url(url, **kw):
-            if flush_decoder and self._decoder:
+            if flush_decoder and decode_content and self._decoder:
-from .exceptions import MissingSchema
+from .exceptions import MissingSchema, InvalidURL
-            c = chr(int(h, 16))
+            try:
-
+        p.prepare(
-        object from those of the :class:`Session`.
+    def prepare_request(self, request):
-        :param request: mutable :class:`Request` instance.
+        :param request: :class:`Request` instance to prepare with this
-        return req.prepare()
+        # Set environment's basic authentication if not explicitly set.
-        prep = req.prepare()
+        prep = self.prepare_request(req)
-        if getattr(request, 'prepare', None):
+        if not isinstance(request, PreparedRequest):
-
+    def test_prepared_from_session(self):
-            hooks = self.hooks,
+
-        req = self.update_request(request.copy())
+        req = request.copy()
-        prep = self.prepare_request(req)
+        self.update_request(req)
-
+    @property
-            return (None, None)
+        if (not files) or isinstance(data, basestring):
-            return None
+            return (None, None)
-            self.headers = CaseInsensitiveDict(headers)
+            self.headers = CaseInsensitiveDict((to_native_string(name), value) for name, value in headers.items())
-            headers['accept'.encode('ascii')],
+            headers['accept'],
-            headers['Accept'.encode('ascii')],
+            headers['Accept'],
-            headers['ACCEPT'.encode('ascii')],
+            headers['ACCEPT'],
-    iter_slices, guess_json_utf, super_len)
+    iter_slices, guess_json_utf, super_len, to_native_string)
-            headers = dict((name.encode('ascii'), value) for name, value in headers.items())
+            headers = dict((to_native_string(name), value) for name, value in headers.items())
-from .compat import getproxies, proxy_bypass
+from .compat import (quote, urlparse, bytes, str, OrderedDict, urlunparse,
-    
+
-        
+
-                
+
-    
+
-    
+
-        
+
-        
+
-    BaseSSLError = None
+
-        disables timeout.
+        Socket timeout in seconds for each individual connection, can be
-            headers_['Host'] = host
+        netloc = parse_url(url).netloc
-                                  "failed to decode it." % content_encoding)
+            except (IOError, zlib.error) as e:
-from .exceptions import HTTPError, RequestException, MissingSchema, InvalidURL
+from .exceptions import (
-    is_py2, chardet, json, builtin_str, basestring)
+    is_py2, chardet, json, builtin_str, basestring, IncompleteRead)
-                    yield chunk
+                try:
-                    prepend_scheme_if_needed, get_auth_from_url)
+                    except_on_missing_scheme, get_auth_from_url)
-            proxy = prepend_scheme_if_needed(proxy, urlparse(url.lower()).scheme)
+            except_on_missing_scheme(proxy)
-    
+
-        
+
-                
+
-    
+
-        netloc, path = path, netloc
+def except_on_missing_scheme(url):
-    return urlunparse((scheme, netloc, path, params, query, fragment))
+    if not scheme:
-            prep.hooks = r.request.hooks
+            prep = r.request.copy()
-            prepared_request.hooks = req.hooks
+            prepared_request = req.copy()
-        s.auth = auth
+        s.auth = HTTPDigestAuth('user', 'pass')
-            _r = r.connection.send(prepared_request, **kwargs)
+            prep = PreparedRequest()
-            _r.request = prepared_request
+            _r.request = prep
-
+        from .models import PreparedRequest
-            _r = r.connection.send(r.request, **kwargs)
+            _r = r.connection.send(prepared_request, **kwargs)
-        #: session. By default is a
+        #: session. By default it is a
-        #: may be any other ``CookieJar``.
+        #: may be any other ``cookielib.CookieJar`` compatible object.
-        # Set up a CookieJar to be used by default
+        #: A CookieJar containing all currently outstanding cookies set on this
-        r = requests.get(httpbin('redirect-to'), params={'url': 'HTTP://example.com/'})
+        parts = urlparse(httpbin('html'))
-from requests.compat import str, cookielib, getproxies, urljoin
+from requests.compat import str, cookielib, getproxies, urljoin, urlparse
-        self.assertEqual(r.status_code,200)
+        parts = urlparse(httpbin('get'))
-        s.proxies = proxies
+        s.proxies = getproxies()
-from requests.compat import str, cookielib, getproxies
+from requests.compat import str, cookielib, getproxies, urljoin
-    return urlparse.urljoin(HTTPBIN, '/'.join(suffix))
+    return urljoin(HTTPBIN, '/'.join(suffix))
-    return HTTPBIN + '/'.join(suffix)
+    return urlparse.urljoin(HTTPBIN, '/'.join(suffix))
-        This shoudl not be called from user code, and is only exposed for use
+        This should not be called from user code, and is only exposed for use
-from requests.compat import str, cookielib
+from requests.compat import str, cookielib, getproxies
-    cookielib, urlparse, urlunparse, urlsplit, urlencode, str, bytes, StringIO,
+    cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,
-         return CaseInsensitiveDict(self._store.values())
+        return CaseInsensitiveDict(self._store.values())
-    cookielib, urlparse, urlunparse, urlsplit, urlencode, str, bytes, StringIO,
+    cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,
-from threading import Lock
+from threading import RLock
-        self._lock = Lock()
+        self.lock = RLock()
-        with self._lock:
+        with self.lock:
-        with self._lock:
+        with self.lock:
-        with self._lock:
+        with self.lock:
-        with self._lock:
+        with self.lock:
-        with self._lock:
+        with self.lock:
-        with self._lock:
+        with self.lock:
-        self.pools[pool_key] = pool
+        with self.pools.lock:
-    # Additionally, this imeplementations does silly things to be optimal
+    # Additionally, this implementations does silly things to be optimal
-        host, url = url[1:].split(']', 1)
+        host, url = url.split(']', 1)
-    208: ('im_used',),
+    226: ('im_used',),
-                    chunk = self.raw.read(chunk_size, decode_content=True)
+                    chunk = self.raw.read(chunk_size)
-            cookie.value = cookie.value.strip('\\"')
+            cookie.value = cookie.value.replace('\\"', '')
-        self.assertTrue(s.cookies['foo'] == 'bar:baz')
+        self.assertTrue(s.cookies['foo'] == '"bar:baz"')
-            if not auth:
+            # Set environment's basic authentication if not explicitly set.
-    rv = decoder.decode('', final=True)
+    rv = decoder.decode(b'', final=True)
-                yield chunk
+            try:
-
+def is_fp_closed(obj):
-        prepared_request.url = req.url
+            prepared_request = PreparedRequest()
-            method = prepared_request.method
+            method = req.method
-                    prepared_request.method != 'HEAD'):
+                    method != 'HEAD'):
-                    prepared_request.method not in ('GET', 'HEAD')):
+                    method not in ('GET', 'HEAD')):
-<<<<<<< HEAD
+<<<<<<< HEAD
-
+    
-            else:
+            elif self.assert_hostname is not False:
-        user is the Windows user, probably in the DOMAIN\username format.
+        user is the Windows user, probably in the DOMAIN\\username format.
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-    encoded in the *body* of the request using multipart or www-orm-urlencoded
+    encoded in the *body* of the request using multipart or www-form-urlencoded
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-class HTTPResponse(object):
+class HTTPResponse(io.IOBase):
-        expires=morsel['max-age'] or morsel['expires'],
+        expires=expires,
-    from urllib import quote, unquote, quote_plus, unquote_plus, urlencode
+    from urllib import quote, unquote, quote_plus, unquote_plus, urlencode, getproxies, proxy_bypass
-    from urllib.request import parse_http_list
+    from urllib.request import parse_http_list, getproxies, proxy_bypass
-
+    netloc = urlparse(url).netloc
-
+        
-
+    # anywhere that no_proxy applies to, and the system settings don't require
-
+        self.assertEqual(r.status_code, 200)
-            url = '%s://%s' % (scheme.lower(), uri)
+            if '://' in url:
-__build__ = 0x010202
+__version__ = '1.2.3'
-        proxy = proxies.get(urlparse(url).scheme)
+        proxy = proxies.get(urlparse(url.lower()).scheme)
-            proxy = prepend_scheme_if_needed(proxy, urlparse(url).scheme)
+            proxy = prepend_scheme_if_needed(proxy, urlparse(url.lower()).scheme)
-            conn = self.poolmanager.connection_from_url(url)
+            conn = self.poolmanager.connection_from_url(url.lower())
-        r = requests.Request('GET', 'HTTP://httbin.org/get')
+        r = requests.Request('GET', 'http://httpbin.org/get')
-        r = requests.Request('GET', 'hTTp://httbin.org/get')
+        s = requests.Session()
-        r = requests.Request('GET', 'HttP://httbin.org/get')
+        r = requests.Request('GET', 'https://httpbin.org/get')
-        r = requests.Request('GET', 'HTTPS://httbin.org/get')
+        r = requests.Request('GET', 'HTTPS://httpbin.org/get')
-        r = requests.Request('GET', 'hTTps://httbin.org/get')
+        r = requests.Request('GET', 'hTTps://httpbin.org/get')
-        r = requests.Request('GET', 'HttPs://httbin.org/get')
+        r = requests.Request('GET', 'HttPs://httpbin.org/get')
-        if url.lower.startswith('https') and verify:
+        if url.lower().startswith('https') and verify:
-            if url.lower.startswith(prefix):
+            if url.lower().startswith(prefix):
-        if url.startswith('https') and verify:
+        if url.lower.startswith('https') and verify:
-            if url.startswith(prefix):
+            if url.lower.startswith(prefix):
-            length = False
+            length = None
-            if length:
+            if length is not None:
-__build__ = 0x010201
+__version__ = '1.2.2'
-    setup_requires=['sphinx'],
+        filename = os.path.splitext(__file__)[0] + '.py'
-                                             open(__file__, 'rb'))})
+                                             open(filename, 'rb'))})
-            self.chal = parse_dict_header(pat.sub('', s_auth))
+            self.chal = parse_dict_header(pat.sub('', s_auth, count=1))
-            raise InvalidURL("Invalid URL %t: No host supplied" % url)
+            raise InvalidURL("Invalid URL %r: No host supplied" % url)
-        self.assertRaises(ValueError, requests.get, 'hiwpefhipowhefopw')
+        self.assertRaises(MissingSchema, requests.get, 'hiwpefhipowhefopw')
-                        (field.encode('utf-8') if isinstance(field, str) else field,
+                        (field.decode('utf-8') if isinstance(field, bytes) else field,
-from .utils import from_key_val_list, default_headers
+from .utils import to_key_val_list, default_headers
-    If a local key in the dictionary is set to None, it will be removed.
+def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
-        return local_kwarg
+    if session_setting is None:
-    local_kwarg = from_key_val_list(local_kwarg)
+    if request_setting is None:
-        return new_key
+    # Bypass if not a dictionary (e.g. verify)
-        kwargs[get_original_key(original_keys, key)] = value
+    merged_setting = dict_class(to_key_val_list(session_setting))
-    for (k, v) in local_kwarg.items():
+    for (k, v) in request_setting.items():
-            del kwargs[k]
+            del merged_setting[k]
-    return kwargs
+    return merged_setting
-        cert = merge_kwargs(cert, self.cert)
+        params = merge_setting(params, self.params)
-    if isinstance(value, dict):
+    if isinstance(value, collections.Mapping):
-__build__ = 0x010200
+__version__ = '1.2.1'
-        scheme, netloc, path, _params, query, fragment = urlparse(url)
+        scheme, auth, host, port, path, query, fragment = parse_url(url)
-            raise InvalidURL("Invalid URL %t: No netloc supplied" % url)
+        if not host:
-            netloc = netloc.encode('idna').decode('utf-8')
+            host = host.encode('idna').decode('utf-8')
-        url = requote_uri(urlunparse([scheme, netloc, path, _params, query, fragment]))
+        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))
-                # Compliant with RFC3986, we percent encode the url.
+            else:
-from .compat import cookielib
+from .compat import cookielib, OrderedDict, urljoin, urlparse
-        self.mount('http://', HTTPAdapter())
+        self.adapters = OrderedDict()
-        """Registers a connection adapter to a prefix."""
+        """Registers a connection adapter to a prefix.
-    __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize']
+    __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',
-        self.init_poolmanager(self._pool_connections, self._pool_maxsize)
+        self.init_poolmanager(self._pool_connections, self._pool_maxsize,
-                 max_retries=DEFAULT_RETRIES):
+                 pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,
-                 pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES):
+                 pool_maxsize=DEFAULT_POOLSIZE, pool_block=DEFAULT_POOLBLOCK,
-        self.init_poolmanager(pool_connections, pool_maxsize)
+        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)
-    def init_poolmanager(self, connections, maxsize):
+    def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK):
-        self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize)
+        self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,
-        header = self.headers['link']
+        header = self.headers.get('link')
-        'Programming Language :: Python :: 3.2',
+
-    """Case-insensitive Dictionary
+class CaseInsensitiveDict(collections.MutableMapping):
-    value of a ``'Content-Encoding'`` response header."""
+    value of a ``'Content-Encoding'`` response header, regardless
-        return self._lower_keys
+    If the constructor, ``.update``, or equality comparison
-            self._lower_keys.clear()
+    """
-        self._clear_lower_keys()
+        # Use the lowercased key for lookups, but store the actual
-        self._lower_keys.clear()
+    def __getitem__(self, key):
-        return key.lower() in self.lower_keys
+    def __delitem__(self, key):
-            return dict.__getitem__(self, self.lower_keys[key.lower()])
+    def __iter__(self):
-            return self[key]
+    def __len__(self):
-            return default
+            return NotImplemented
-    return {
+    return CaseInsensitiveDict({
-    }
+    })
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-            raise TimeoutError(self, "Request timed out. (pool_timeout=%s)" %
+            raise TimeoutError(self, url,
-            raise TimeoutError(self, "Request timed out. (timeout=%s)" %
+            raise TimeoutError(self, url,
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-        return self.__class__, (None, self.url)
+        return self.__class__, (None, None)
-class MaxRetryError(PoolError):
+class MaxRetryError(RequestError):
-        self.url = url
+        RequestError.__init__(self, pool, url, message)
-class HostChangedError(PoolError):
+class HostChangedError(RequestError):
-        self.url = url
+        RequestError.__init__(self, pool, url, message)
-class TimeoutError(PoolError):
+class TimeoutError(RequestError):
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-from .cookies import cookiejar_from_dict, extract_cookies_to_jar
+from .cookies import cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar
-            merged_cookies.set_cookie(cookie)
+        merged_cookies = RequestsCookieJar()
-from requests.compat import str
+from requests.compat import str, cookielib
-        merged_cookies.update(cookies)
+        merged_cookies = copy(self.cookies)
-        #: Maximum number of redirects to follow.
+        #: Maximum number of redirects allowed. If the request exceeds this
-                    prepared_request.method == 'POST'):
+                    prepared_request.method not in ('GET', 'HEAD')):
-        self.max_retries = DEFAULT_RETRIES
+    def __init__(self, pool_connections=DEFAULT_POOLSIZE,
-    stream_untransfer, guess_filename, get_auth_from_url, requote_uri,
+    guess_filename, get_auth_from_url, requote_uri,
-                chunk = self.raw.read(chunk_size)
+                chunk = self.raw.read(chunk_size, decode_content=True)
-        gen = stream_untransfer(generate(), self)
+        gen = generate()
-    content_type = b('multipart/form-data; boundary=%s' % boundary)
+    content_type = str('multipart/form-data; boundary=%s' % boundary)
-import gzip
+
-from .packages.six import string_types as basestring
+from .packages.six import string_types as basestring, binary_type
-    return gzipper.read()
+class DeflateDecoder(object):
-        return zlib.decompress(data, -zlib.MAX_WBITS)
+    def decompress(self, data):
-    }
+    CONTENT_DECODERS = ['gzip', 'deflate']
-        self._decode_content = decode_content
+        self._decoder = None
-            sense to cache partial content as the full response.
+            How much of the content to read. If specified, caching is skipped
-            'content-encoding' header. (Overridden if ``amt`` is set.)
+            'content-encoding' header.
-        decoder = self.CONTENT_DECODERS.get(content_encoding)
+        if self._decoder is None:
-            decode_content = self._decode_content
+            decode_content = self.decode_content
-                return data
+                    flush_decoder = True
-                    data = decoder(data)
+                if decode_content and self._decoder:
-    """Built-In HTTP Adapter for Urllib3."""
+    """The built-in HTTP Adapter for urllib3.
-        """Returns a connection for the given URL."""
+        """Returns a urllib3 connection for the given URL. This should not be
-        """Dispose of any internal state.
+        """Disposes of any internal state.
-        used. Otherwise, we should only use the path portion of the URL."""
+        used. Otherwise, we should only use the path portion of the URL.
-        Proxy-Authorization header."""
+        Proxy-Authorization header.
-        """Sends PreparedRequest object. Returns Response object."""
+        """Sends PreparedRequest object. Returns Response object.
-        if not (scheme and netloc):
+        if not scheme:
-        self.assertNotIn('foo', s.cookies)
+        assert 'foo' not in s.cookies
-from .cookies import cookiejar_from_dict
+from .cookies import cookiejar_from_dict, extract_cookies_to_jar
-            prepared_request.prepare_cookies(cookiejar)
+            prepared_request.prepare_cookies(self.cookies)
-            cookiejar.update(resp.cookies)
+            extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)
-        resp.cookies.update(cookiejar)
+        resp.cookies = self.cookies.copy()
-
+        # Persist cookies
-                new_fields.append((field, str(val)))
+            if isinstance(val, basestring) or not hasattr(val, '__iter__'):
-            content. Defaults to ``True``.
+        :param stream: (optional) whether to immediately download the response
-        return_response=True):
+        cert=None):
-        cert=None):
+        cert=None,
-                    new_fields.append((field, builtin_str(v)))
+                    new_fields.append((field, str(v)))
-                new_fields.append((field, builtin_str(val)))
+                new_fields.append((field, str(val)))
-    """Attaches HTTP Proxy Authenetication to a given Request object."""
+    """Attaches HTTP Proxy Authentication to a given Request object."""
-        2-tuples. Order is retained if data is a list of 2-tuples but abritrary
+        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
-                if self.status_code is 0:
+                if self.status_code == 0:
-__build__ = 0x010100
+__version__ = '1.2.0'
-        kwargs.setdefault('proxies', self.proxies
+        kwargs.setdefault('proxies', self.proxies)
-        kwargs.setdefault('proxies', {})
+        kwargs.setdefault('stream', self.stream)
-        'trust_env']
+        'trust_env', 'max_redirects']
-from .util import resolve_cert_reqs, resolve_ssl_version
+from .util import resolve_cert_reqs, resolve_ssl_version, assert_fingerprint
-                 cert_reqs=None, ca_certs=None):
+                 cert_reqs=None, ca_certs=None,
-
+            if self.assert_fingerprint:
-    :meth:`urllib3.util.ssl_wrap_socket` to upgrade the connection socket into an SSL socket.
+    :class:`.VerifiedHTTPSConnection` uses one of ``assert_fingerprint``,
-                 cert_reqs=None, ca_certs=None, ssl_version=None):
+                 key_file=None, cert_file=None, cert_reqs=None,
-        if not ssl: # Platform-specific: Python compiled without +ssl
+        if not ssl:  # Platform-specific: Python compiled without +ssl
-                            cert_reqs=self.cert_reqs, ca_certs=self.ca_certs)
+                            cert_reqs=self.cert_reqs, ca_certs=self.ca_certs,
-        return pool_cls(host, port, **self.connection_pool_kw)
+        kwargs = self.connection_pool_kw
-    from ssl import wrap_socket, CERT_NONE, SSLError, PROTOCOL_SSLv23
+    from ssl import wrap_socket, CERT_NONE, PROTOCOL_SSLv23
-from .exceptions import LocationParseError
+from .exceptions import LocationParseError, SSLError
-def is_connection_dropped(conn):
+def is_connection_dropped(conn):  # Platform-specific
-    if not poll: # Platform-specific
+    if not poll:
-                self.headers['Content-Length'] = super_len(l)
+                self.headers['Content-Length'] = str(l)
-        # Guard against that specific failure case.
+        # Set defaults that the hooks can utilize to ensure they always have
-            if resp.status_code is not codes.temporary:
+            # https://github.com/kennethreitz/requests/issues/1084
-            length = str(super_len(data))
+            length = super_len(data)
-                self.headers['Content-Length'] = length
+                self.headers['Content-Length'] = str(length)
-            self.headers['Content-Length'] = str(len(body))
+            l = super_len(body)
-            'req': req,
+        kwargs.setdefault('stream', False)
-        stream = kwargs.get('stream', False)
+        stream = kwargs.get('stream')
-        def hook(resp):
+        def hook(resp, **kwargs):
-        length of each item returned as decoding can take place.
+        """Iterates over the response data.  When stream=True is set on the
-        responses.
+        """Iterates over the response data, one line at a time.  When
-            self.chal = parse_dict_header(re.sub(r'digest ', '', s_auth, flags=re.IGNORECASE))
+            pat = re.compile(r'digest ', flags=re.IGNORECASE)
-        # If no Auth is explicitly provided, extract it from the URL.
+        # If no Auth is explicitly provided, extract it from the URL first.
-    def prepare_auth(self, auth):
+    def prepare_auth(self, auth, url=''):
-__version__ = "1.0.1"
+__version__ = "1.0.3"
-        if self._mTotalChars <= 0:
+        if self._mTotalChars <= 0 or self._mFreqChars <= MINIMUM_DATA_THRESHOLD:
-    if isinstance(a, str):
+    if sys.version_info < (3, 0) and isinstance(a, base_str):
-    elif isinstance(a, int):
+    else:
-
+from .cp949prober import CP949Prober
-            if aBuf[:3] == '\xEF\xBB\xBF':
+            if aBuf[:3] == codecs.BOM:
-            elif aBuf[:4] == '\xFF\xFE\x00\x00':
+            elif aBuf[:4] == codecs.BOM_UTF32_LE:
-            elif aBuf[:4] == '\x00\x00\xFE\xFF':
+            elif aBuf[:4] == codecs.BOM_UTF32_BE:
-            elif aBuf[:4] == '\xFE\xFF\x00\x00':
+            elif aBuf[:4] == b'\xFE\xFF\x00\x00':
-            elif aBuf[:4] == '\x00\x00\xFF\xFE':
+            elif aBuf[:4] == b'\x00\x00\xFF\xFE':
-            elif aBuf[:2] == '\xFF\xFE':
+            elif aBuf[:2] == codecs.BOM_LE:
-            elif aBuf[:2] == '\xFE\xFF':
+            elif aBuf[:2] == codecs.BOM_BE:
-        return None
+        return ('', '')
-        return ('', '')
+        return None
-        p.prepare_auth(self.auth)
+
-    stream_untransfer, guess_filename, requote_uri,
+    stream_untransfer, guess_filename, get_auth_from_url, requote_uri,
-                          verify=True, cert=None, proxies=None, cookies=None):
+                          verify=True, cert=None, proxies=None):
-        cookiejar.update(cookies)
+        cookiejar.update(self.cookies)
-                                     proxies=proxies, cookies=cookies)
+                                     proxies=proxies)
-                          verify=True, cert=None, proxies=None):
+                          verify=True, cert=None, proxies=None, cookies=None):
-        cookiejar = resp.cookies
+
-                                     proxies=proxies)
+                                     proxies=proxies, cookies=cookies)
-            self.init_poolmanager(self._pool_connections, self._pool_maxsize)
+        self.init_poolmanager(self._pool_connections, self._pool_maxsize)
-        'params', 'verify', 'cert', 'prefetch', 'adapters']
+        'params', 'verify', 'cert', 'prefetch', 'adapters', 'stream',
-        'params', 'verify', 'cert', 'prefetch']
+        'headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks',
-            self.chal = parse_dict_header(s_auth.replace('Digest ', ''))
+            self.chal = parse_dict_header(re.sub(r'digest ', '', s_auth, flags=re.IGNORECASE))
-
+    __attrs__ = [
-            return {}
+        return dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
-
+        self.max_retries = DEFAULT_RETRIES
-    def send(self, request, stream=False, timeout=None, max_retries=DEFAULT_RETRIES, verify=True, cert=None, proxies=None):
+    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
-                    retries=max_retries,
+                    retries=self.max_retries,
-                          max_retries=0, verify=True, cert=None, proxies=None):
+                          verify=True, cert=None, proxies=None):
-                                     verify=verify, cert=cert,
+                                     timeout=timeout, verify=verify, cert=cert,
-    response = None
+
-            raise http_error
+            raise HTTPError(http_error_msg, response=self)
-        
+
-        """Raises stored :class:`HTTPError` or :class:`URLError`, if one occurred."""
+        """Raises stored :class:`HTTPError`, if one occurred."""
-        return dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
+        if hasattr(self, '__attrs__'):
-    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
+    def send(self, request, stream=False, timeout=None, max_retries=DEFAULT_RETRIES, verify=True, cert=None, proxies=None):
-                    retries=self.max_retries,
+                    retries=max_retries,
-                          verify=True, cert=None, proxies=None):
+                          max_retries=0, verify=True, cert=None, proxies=None):
-                                     timeout=timeout, verify=verify, cert=cert,
+                                     timeout=timeout, max_retries=max_retries,
-                raise e
+                raise
-from .compat import urlparse, basestring, urldefrag
+from .compat import urlparse, basestring, urldefrag, unquote
-        Host: header if a proxy is being used."""
+        """Add any headers needed by the connection. Currently this adds a
-                raise
+                raise e
-                raise Timeout('Request timed out.')
+                raise
-        raise NotImplementedError
+        """Return a copy of this RequestsCookieJar."""
-            cookies.set_cookie(cookie)
+        # Merge with session cookies
-            self.cookies.set_cookie(cookie)
+        self.cookies.update(resp.cookies)
-        cj.set_cookie(cookie)
+    cj.update(cj2)
-        self.assertNotEqual(str(r.raw.read()), str(''))
+        self.assertNotEqual(r.raw.read(), b'')
-        self.assertEqual(str(r.raw.read()), str(''))
+        self.assertEqual(r.raw.read(), b'')
-        self.assertNotEqual(r.raw.read(), '')
+        self.assertNotEqual(str(r.raw.read()), str(''))
-        self.assertEqual(r.raw.read(), '')
+        self.assertEqual(str(r.raw.read()), str(''))
-    def handle_401(self, r):
+    def handle_401(self, r, **kwargs):
-            _r = r.connection.send(r.request)
+            _r = r.connection.send(r.request, **kwargs)
-def dispatch_hook(key, hooks, hook_data):
+def dispatch_hook(key, hooks, hook_data, **kwargs):
-            _hook_data = hook(hook_data)
+            _hook_data = hook(hook_data, **kwargs)
-        r = dispatch_hook('response', hooks, r)
+        r = dispatch_hook('response', hooks, r, **kwargs)
-                headers = dict((builtin_str(name), value) for name, value in headers.items())
+            headers = dict((name.encode('ascii'), value) for name, value in headers.items())
-from requests.compat import is_py2, str
+from requests.compat import str
-            requests.put(httpbin('put'), headers={unicode('Content-Type'): 'application/octet-stream'}, data='\xff')
+        requests.put(httpbin('put'), headers={str('Content-Type'): 'application/octet-stream'}, data='\xff') # compat.str is unicode.
-REDIRECT_STATI = (codes.moved, codes.found, codes.other, codes.temporary_moved)
+REDIRECT_STATI = (
-from requests.compat import str
+from requests.compat import is_py2, str
-                del prepared_request.headers['Cookie']
+                del headers['Cookie']
-                prepared_request.headers['Cookie'] = response.headers.get('Set-Cookie')
+            prepared_request.prepare_cookies(cookiejar)
-        url = httpbin('cookies/set/foo/bar')
+        s = requests.session()
-    will make requests to any url through the defined proxy.
+    will make requests to any url through the defined proxy. The ProxyManager
-    def _set_proxy_headers(self, headers=None):
+    def _set_proxy_headers(self, url, headers=None):
-        kw['headers'] = self._set_proxy_headers(kw.get('headers'))
+        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))
-            prepared_request.body = None
+            if resp.status_code is not codes.temporary:
-from .models import Request
+from .models import Request, PreparedRequest
-                          timeout=None, verify=True, cert=None, proxies=None):
+    def resolve_redirects(self, resp, req, stream=False, timeout=None,
-                pass
+            for h in ('Cookie', 'Content-Length'):
-                          verify=True, cert=None, proxies=None):
+    def resolve_redirects(self, resp, prepared_request, stream=False,
-            method = req.method
+            method = prepared_request.method
-            if resp.status_code == codes.see_other and req.method != 'HEAD':
+            if (resp.status_code == codes.see_other and
-            if resp.status_code in (codes.moved, codes.found) and req.method == 'POST':
+            if (resp.status_code in (codes.moved, codes.found) and
-            headers = req.headers
+            headers = prepared_request.headers
-                allow_redirects=False,
+            resp = self.send(
-                hooks=req.hooks,
+                allow_redirects=False,
-                                     verify=verify, cert=cert, proxies=proxies)
+        gen = self.resolve_redirects(r, request, stream=stream,
-                    prepend_scheme_if_needed)
+                    prepend_scheme_if_needed, get_auth_from_url)
-            if resp.status_code is codes.see_other and req.method != 'HEAD':
+            if resp.status_code == codes.see_other and req.method != 'HEAD':
-        return name
+        return os.path.basename(name)
-            req = kwargs.pop('req')
+        allow_redirects = kwargs.pop('allow_redirects', True)
-    def resolve_redirects(self, resp, req, stream=False, timeout=None, verify=True, cert=None, proxies=None):
+    def resolve_redirects(self, resp, req, stream=False, timeout=None,
-        resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
+        send_kwargs = {
-
+        # Set up variables needed for resolve_redirects and dispatching of
-        self.assertTrue(r.elapsed.total_seconds() > 0.0)
+        td = r.elapsed
-        self.assertTrue(iter(r).next())
+        self.assertTrue(next(iter(r)))
-        """Returns the current object."""
+        """Allows you to use a response as an iterator."""
-        r.elapsed = finish - start
+from datetime import datetime
-import time
+import datetime
-        start = time.time()
+        start = datetime.datetime.utcnow()
-            finish = time.time()
+            finish = datetime.datetime.utcnow()
-        r.time_taken = finish - start
+        r.elapsed = finish - start
-        self.time_taken = 0.0
+        #: The amount of time elapsed between sending the request
-    def test_time_taken_blank(self):
+    def test_time_elapsed_blank(self):
-        self.assertTrue(r.time_taken > 0.0)
+        self.assertTrue(r.elapsed.total_seconds() > 0.0)
-           'response="%s"' % (self.username, realm, nonce, path, respdig)
+               'response="%s"' % (self.username, realm, nonce, path, respdig)
-        num_401_calls =  getattr(self, 'num_401_calls', 1)
+        num_401_calls = getattr(self, 'num_401_calls', 1)
-            
+
-        setattr(self, 'num_401_calls', 1)  
+        setattr(self, 'num_401_calls', 1)
-
+
-            decode_unicode=decode_unicode):
+        for chunk in self.iter_content(chunk_size=chunk_size,
-                    hooks=req.hooks,
+                url=url,
-
+
-                                                sys.pypy_version_info.major,
+        _implementation_version = '%s.%s.%s' % (sys.pypy_version_info.major,
-                                            )
+                                                sys.pypy_version_info.micro)
-        ])
+    return " ".join(['python-requests/%s' % __version__,
-                key,value = param.split("=")
+                key, value = param.split("=")
-                'Mozilla/5.0 (github.com/kennethreitz/requests)'
+            'User-agent': 'Mozilla/5.0 (github.com/kennethreitz/requests)'
-                'Mozilla/5.0 (github.com/kennethreitz/requests)'
+            'user-agent': 'Mozilla/5.0 (github.com/kennethreitz/requests)'
-        r = requests.head(url=url)
+        r = requests.Response()
-        elif self.method in ('POST', 'PUT', 'PATCH'):
+        elif self.method not in ('GET', 'HEAD'):
-        self.assertTrue('Content-Length' not in req.headers)
+        get_req = requests.Request('GET', httpbin('get')).prepare()
-        elif self.method in ('POST', 'PUT'):
+        elif self.method in ('POST', 'PUT', 'PATCH'):
-        self.assertNotIn('Content-Length', req.headers)
+        self.assertTrue('Content-Length' not in req.headers)
-        self.headers['Content-Length'] = '0'
+        elif self.method in ('POST', 'PUT'):
-        self.assertIn('some_cookie', jar)
+        self.assertTrue('some_cookie' in jar)
-
+    def test_links(self):
-        """Returns the json-encoded content of a response, if any."""
+    def json(self, **kwargs):
-        return json.loads(self.text or self.content)
+                return json.loads(self.content.decode(encoding), **kwargs)
-        num_401_calls = getattr(r.request, 'num_401_calls', 1)  
+
-
+            
-            r.request.num_401_calls = num_401_calls + 1
+        setattr(self, 'num_401_calls', 1)  
-from .hooks import default_hooks, HOOKS
+from .hooks import default_hooks
-
+        hooks = request.hooks
-                )
+                    proxies=proxies,
-            self.hooks[event].extend(hooks[event])
+        for event in hooks:
-from .hooks import default_hooks
+from .hooks import default_hooks, dispatch_hook
-        }
+                 cert_reqs=None, ca_certs=None):
-        self.cert_reqs = ssl_req_scheme.get(cert_reqs) or ssl.CERT_NONE
+        self.cert_reqs = cert_reqs
-                                    cert_reqs=self.cert_reqs,
+                                    cert_reqs=resolved_cert_reqs,
-                                    ssl_version=self.ssl_version)
+                                    ssl_version=resolved_ssl_version)
-        if self.ca_certs:
+        if resolved_cert_reqs != ssl.CERT_NONE:
-                 cert_reqs='CERT_NONE', ca_certs=None, ssl_version=None):
+                 cert_reqs=None, ca_certs=None, ssl_version=None):
-            connection.ssl_version = self.ssl_version
+        connection.ssl_version = self.ssl_version
-
+        pool = self._new_pool(scheme, host, port)
-                return self._fp.read(amt)
+                data = self._fp.read(amt)
-    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=CERT_NONE,
+    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,
-                        ssl_version=PROTOCOL_SSLv23):
+                        ssl_version=None):
-                # FIXME: This block needs a test.
+            # Py32 raises IOError
-    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=CERT_NONE,
+    def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,
-                        ssl_version=PROTOCOL_SSLv23):
+                        ssl_version=None):
-        if not scheme:
+        if not (scheme and netloc):
-        opaque = self.chal.get('opaque', None)
+        algorithm = self.chal.get('algorithm')
-        algorithm = algorithm.upper()
+        if algorithm is None:
-        if algorithm == 'MD5':
+        if _algorithm == 'MD5':
-        elif algorithm == 'SHA':
+        elif _algorithm == 'SHA':
-            base += ', algorithm="%s"' % algorithm
+        # If auth hooks are present, they aren't passed to `dispatch_hook`
-        num_401_calls = r.request.hooks['response'].count(self.handle_401)
+        num_401_calls = getattr(r.request, 'num_401_calls', 1)  
-ITER_CHUNK_SIZE = 10 * 1024
+ITER_CHUNK_SIZE = 512
-            
+
-        self.response = dispatch_hook('response', hooks, resp)
+        resp = dispatch_hook('response', hooks, resp)
-            
+
-            length = super_len(data)
+            length = str(super_len(data))
-
+    def test_content_length_is_string_for_file_objects(self):
-from .packages.urllib3.poolmanager import PoolManager, proxy_from_url
+from .packages.urllib3.poolmanager import PoolManager, ProxyManager
-            conn = proxy_from_url(proxy)
+            conn = ProxyManager(self.poolmanager.connection_from_url(proxy))
-
+    # vendored bundle inside Requests
-# otherwise, try and use the OS bundle
+            not isinstance(data, list),
-from .hooks import default_hooks
+from .hooks import default_hooks, HOOKS
-from .hooks import dispatch_hook, default_hooks
+from .hooks import default_hooks
-
+    def test_prepared_request_hook(self):
-                self.headers['Content-Length'] = str(len(body))
+            self.prepare_content_length(body)
-	'requests.packages.charade',
+    'requests.packages.charade',
-copyright = u'2012. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'2013. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-:copyright: (c) 2012 by Kenneth Reitz.
+:copyright: (c) 2013 by Kenneth Reitz.
-__build__ = 0x01004
+__version__ = '1.1.0'
-__copyright__ = 'Copyright 2012 Kenneth Reitz'
+__copyright__ = 'Copyright 2013 Kenneth Reitz'
-                    params=req.params,
+from .packages.urllib3.response import HTTPResponse
-
+        chunked = not (request.body is None or 'Content-Length' in request.headers)
-            )
+            else:
-    iter_slices, guess_json_utf)
+    iter_slices, guess_json_utf, super_len)
-            raise NotImplementedError('Generator bodies are not supported yet.')
+        # Check if file, fo, generator, iterator.
-            if data:
+        is_stream = all([
-            self.headers['Content-Type'] = content_type
+        try:
-        kwargs[get_original_key(kwargs.keys(), key)] = value
+        kwargs[get_original_key(original_keys, key)] = value
-        self.assertEqual(r.status_code, 200)
+    # def test_HTTP_302_ALLOW_REDIRECT_POST(self):
-    # Update new values.
+    # Update new values in a case-insensitive way
-    kwargs.update(local_kwarg)
+    for key, value in local_kwarg.items():
-        self.assertTrue("text/py-content-type" in r.request.body)
+        self.assertTrue(b"text/py-content-type" in r.request.body)
-                fn, fp = v
+                if len(v) == 2:
-            new_fields.append((k, (fn, fp.read())))
+            
-from .utils import DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers
+from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,
-from .compat import quote, urlparse, bytes, str, OrderedDict
+from .compat import quote, urlparse, bytes, str, OrderedDict, urlunparse
-    is_py2, chardet, json, builtin_str, basestring, urldefrag)
+    is_py2, chardet, json, builtin_str, basestring)
-from .compat import urlparse, basestring
+from .compat import urlparse, basestring, urldefrag
-                url=request.path_url,
+                url=url,
-    is_py2, chardet, json, builtin_str, basestring)
+    is_py2, chardet, json, builtin_str, basestring, urldefrag)
-~~~~~~~~~~
+certs.py
-This module returns the installation location of cacert.pem.
+This module returns the preferred default CA certificate bundle.
-import os
+import os.path
-
+    pass
-
+    """Return the preferred certificate bundle."""
-        return os.path.join(f, 'cacert.pem')
+
-
+DEFAULT_CA_BUNDLE_PATH = certs.where()
-        """The apparent encoding, provided by the lovely Charade library."""
+        """The apparent encoding, provided by the lovely Charade library
-    of this class.
+    """The :class:`Response <Response>` object, which contains a
-    Generated from a :class:`Request <Request>` object or manually.
+    Generated from either a :class:`Request <Request>` object or manually.
-    """A Requests session."""
+    """A Requests session.
-        #: Authentication tuple or object to attach to
+        #: Default Authentication tuple or object to attach to
-        #: Stream response content.
+        #: Stream response content default.
-        #: SSL Verification.
+        #: SSL Verification default.
-        #: SSL certificate.
+        #: SSL certificate default.
-        #: Should we trust the environment
+        #: Should we trust the environment?
-        # self.proxies = proxies
+        #: HTTP verb to send to the server.
-        self.proxies = None
+        #: dictionary of callback hooks, for internal usage.
-        """Constructs a PreparedRequest for transmission and returns it."""
+        """Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it."""
-    """The :class:`PreparedRequest <PreparedRequest>` object."""
+    """The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
-__build__ = 0x01003
+__version__ = '1.0.4'
-    """A user-created :class:`Request <Request>` object."""
+    """A user-created :class:`Request <Request>` object.
-            if resp.status_code is codes.see_other:
+            if resp.status_code is codes.see_other and req.method != 'HEAD':
-        req.method = method
+        req.method = method.upper()
-        # Note that prepare_auth most be last to enable authentication schemes
+        # Note that prepare_auth must be last to enable authentication schemes
-        :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
+        :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
-        :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
+        :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
-        :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
+        :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
-    :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
-    :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
-    :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
-    :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
+    :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
-from .compat import urlparse
+from .compat import urlparse, basestring
-            if isinstance(cert, basestring):
+            if not isinstance(cert, basestring):
-            if len(cert) == 2:
+            if isinstance(cert, basestring):
-        p.prepare_auth(self.auth)
+        p.prepare_auth(self.auth)
-        raise InvalidSchema('No connection adapters were found for \'%s\'' % url)
+        raise InvalidSchema("No connection adapters were found for '%s'" % url)
-def session(**kwargs):
+def session():
-    return Session(**kwargs)
+    return Session()
-__build__ = 0x01002
+__version__ = '1.0.3'
-        return r
+        return r
-from .hooks import dispatch_hook, default_hooks
+from .hooks import default_hooks
-from .cookies import cookiejar_from_dict, extract_cookies_to_jar, get_cookie_header
+from .auth import HTTPBasicAuth
-    URLRequired, SSLError, MissingSchema, InvalidSchema, InvalidURL)
+from .exceptions import HTTPError, RequestException, MissingSchema, InvalidURL
-    guess_json_utf)
+    stream_untransfer, guess_filename, requote_uri,
-    StringIO, is_py2, is_py3, chardet, json, builtin_str, urldefrag, basestring)
+    cookielib, urlparse, urlunparse, urlsplit, urlencode, str, bytes, StringIO,
-from .compat import quote, quote_plus, urlparse, basestring, bytes, str, OrderedDict
+from .compat import quote, urlparse, bytes, str, OrderedDict
-
+        # Persist cookies.
-    StringIO, is_py2, chardet, json, builtin_str, urldefrag, basestring)
+    StringIO, is_py2, is_py3, chardet, json, builtin_str, urldefrag, basestring)
-        self.method = method.upper()
+        self.method = method
-    unittest.main()
+    unittest.main()
-__build__ = 0x01001
+__version__ = '1.0.2'
-from .packages.urllib3.poolmanager import PoolManager, ProxyManager
+from .packages.urllib3.poolmanager import PoolManager, proxy_from_url
-            conn = ProxyManager(self.poolmanager.proxy_from_url(proxy))
+            conn = proxy_from_url(proxy)
-__build__ = 0x01000
+__version__ = '1.0.1'
-from .packages.urllib3.poolmanager import PoolManager
+from .packages.urllib3.poolmanager import PoolManager, ProxyManager
-            conn = self.poolmanager.ProxyManager(self.poolmanager.proxy_from_url(proxy))
+            conn = ProxyManager(self.poolmanager.proxy_from_url(proxy))
-            if i > self.max_redirects:
+            if i >= self.max_redirects:
-
+import os
-                cert_loc = self.verify
+                cert_loc = verify
-        'Programming Language :: Python :: 3.0',
+        # 'Programming Language :: Python :: 3.0',
-__build__ = 0x00000
+__build__ = 0x01000
-        """Constructs a PreparedRequest and returns it."""
+        """Constructs a PreparedRequest for transmission and returns it."""
-            return None
+                return json.loads(self.content.decode(encoding))
-    def resolve_redirects(self, resp, req, stream=False, timeout=None, verify=True, cert=None):
+    def resolve_redirects(self, resp, req, stream=False, timeout=None, verify=True, cert=None, proxies=None):
-                    cert=cert
+                    cert=cert,
-        gen = self.resolve_redirects(resp, req, stream, timeout, verify, cert)
+        gen = self.resolve_redirects(resp, req, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
-        with open(__file__) as f:
+        with open('requirements.txt') as f:
-        with open(__file__) as f:
+        with open('requirements.txt') as f:
-        files = to_key_val_list(files)
+        fields = to_key_val_list(data or {})
-httpbin = os.environ.get('HTTPBIN_URL', 'http://httpbin.org/')
+HTTPBIN = os.environ.get('HTTPBIN_URL', 'http://httpbin.org/')
-            conn = poolmanager.proxy_from_url(proxy)
+            conn = self.poolmanager.ProxyManager(self.poolmanager.proxy_from_url(proxy))
-from .utils import requote_uri
+from .utils import requote_uri, get_environ_proxies, get_netrc_auth
-        resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert)
+        resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
-from .cookies import cookiejar_from_dict, remove_cookie_by_name
+from .cookies import cookiejar_from_dict
-from .utils import header_expand, from_key_val_list, default_headers
+from .utils import from_key_val_list, default_headers
-    Stream decodes an iterator over compressed data
+    """Stream decodes an iterator over compressed data
-from .exceptions import TooManyRedirects
+from .exceptions import TooManyRedirects, InvalidSchema
-        adapter = HTTPAdapter()
+        adapter = self.get_adapter(url=request.url)
-    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None, proxies=None):
+    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
-        if prefetch:
+        if not stream:
-    :param prefetch: (optional) if ``True``, the response content will be immediately downloaded.
+    :param stream: (optional) if ``False``, the response content will be immediately downloaded.
-        #: Requires that ``prefetch=False` on the request.
+        #: Requires that ``stream=True` on the request.
-                encoding = chardet.detect(self.content)['encoding']
+            encoding = self.apparent_encoding
-    def resolve_redirects(self, resp, req, prefetch=True, timeout=None, verify=True, cert=None):
+    def resolve_redirects(self, resp, req, stream=False, timeout=None, verify=True, cert=None):
-                    prefetch=prefetch,
+                    stream=stream,
-        self.prefetch = True
+        #: Stream response content.
-        prefetch=None,
+        stream=None,
-        prefetch = merge_kwargs(prefetch, self.prefetch)
+        stream = merge_kwargs(stream, self.stream)
-        resp = self.send(prep, prefetch=prefetch, timeout=timeout, verify=verify, cert=cert)
+        resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert)
-        gen = self.resolve_redirects(resp, req, prefetch, timeout, verify, cert)
+        gen = self.resolve_redirects(resp, req, stream, timeout, verify, cert)
-
+        """Returns a connection for the given URL."""
-    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None):
+    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None, proxies=None):
-        conn = self.poolmanager.connection_from_url(request.url)
+        conn = self.get_connection(request.url, proxies)
-
+ITER_CHUNK_SIZE = 10 * 1024
-        if isinstance(data, types.GeneratorType)
+        if isinstance(data, type(_ for _ in [])):
-    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=None):
+    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None):
-
+from types import GeneratorType
-        # if a generator is provided, error out.
+
-            #     pass
+            headers = req.headers
-            return self.get_host()
+        return self.get_host()
-        return bool(self._r.response.history)
+        return True
-                raise TooManyRedirects()
+                raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects)
-        cookies=None or {},
+        cookies=None,
-        return_response=True,
+        cookies = cookies or {}
-        # passed-in cookies must become a CookieJar:
+        # Bootstrap CookieJar.
-        # merge the session's cookies into the passed-in cookies:
+
-
+        # Merge all the kwargs.
-
+        auth = merge_kwargs(auth, self.auth)
-        # req.proxies = proxies
+        # Prepare the Request.
-
+        # Send the request.
-    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None):
+    def send(self, request, **kwargs):
-        r = adapter.send(request, prefetch, timeout, verify, cert)
+        r = adapter.send(request, **kwargs)
-        scheme, netloc, path, params, query, fragment = urlparse(url)
+        scheme, netloc, path, _params, query, fragment = urlparse(url)
-                params = params.encode('utf-8')
+            if isinstance(_params, str):
-        url = requote_uri(urlunparse([scheme, netloc, path, params, query, fragment]))
+        url = requote_uri(urlunparse([scheme, netloc, path, _params, query, fragment]))
-        cookies=None,
+        cookies=None or {},
-from .hooks import dispatch_hook, HOOKS
+from .hooks import dispatch_hook, default_hooks
-class SessionMixin(object):
+class SessionRedirectMixin(object):
-class Session(SessionMixin):
+class Session(SessionRedirectMixin):
-        cert=None):
+    def __init__(self):
-        self.headers = from_key_val_list(headers or [])
+        self.headers = default_headers()
-        self.timeout = timeout
+        self.auth = None
-        self.proxies = from_key_val_list(proxies or [])
+        self.proxies = {}
-        self.hooks = from_key_val_list(hooks or {})
+        self.hooks = default_hooks()
-        self.params = from_key_val_list(params or [])
+        self.params = {}
-        self.prefetch = prefetch
+        self.prefetch = True
-        self.verify = verify
+        self.verify = True
-        self.cert = cert
+        self.cert = None
-            self.cookies = cookiejar_from_dict(cookies)
+        self.cookies = cookiejar_from_dict({})
-        req.proxies = proxies
+        # req.proxies = proxies
-        resp = self.send(prep, prefetch, timeout, verify, cert)
+        resp = self.send(prep, prefetch=prefetch, timeout=timeout, verify=verify, cert=cert)
-    # @staticmethod
+
-    def build_response(req, resp):
+    # @staticmethod
-            _r = r.request.response
+            _r = r.connection.send(r.request)
-        print hook
+
-from .hooks import dispatch_hook
+from .hooks import dispatch_hook, HOOKS
-        elif (decoded_body is not None and 
+        elif (decoded_body is not None and
-        return r
+        return r
-HOOKS = ('response')
+HOOKS = ['response']
-# import collections
+import collections
-from .hooks import dispatch_hook, HOOKS
+from .hooks import dispatch_hook, default_hooks
-class RequestMixin(object):
+class RequestEncodingMixin(object):
-class Request(object):
+class RequestHooksMixin(object):
-        cert=None):
+        hooks=None):
-        self.proxies = proxies
+        # self.allow_redirects = allow_redirects
-class PreparedRequest(RequestMixin):
+class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
-        self.hooks = None
+        self.hooks = default_hooks()
-from socket import timeout as SocketTimeout
+from socket import error as SocketError, timeout as SocketTimeout
-from .util import get_host, is_connection_dropped
+from .util import get_host, is_connection_dropped, ssl_wrap_socket
-        self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,
+        self.sock = ssl_wrap_socket(sock, self.key_file, self.cert_file,
-                                    ca_certs=self.ca_certs)
+                                    ca_certs=self.ca_certs,
-        super(HTTPConnectionPool, self).__init__(host, port)
+        ConnectionPool.__init__(self, host, port)
-        return HTTPConnection(host=self.host, port=self.port)
+        return HTTPConnection(host=self.host,
-        except HTTPException as e:
+        except (HTTPException, SocketError) as e:
-    instead of :class:httplib.HTTPSConnection`.
+    instead of :class:`httplib.HTTPSConnection`.
-    The ``key_file``, ``cert_file``, ``cert_reqs``, and ``ca_certs`` parameters
+    The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``, and ``ssl_version``
-    :meth:`ssl.wrap_socket` to upgrade the connection socket into an SSL socket.
+    :meth:`urllib3.util.ssl_wrap_socket` to upgrade the connection socket into an SSL socket.
-                 cert_reqs='CERT_NONE', ca_certs=None):
+                 cert_reqs='CERT_NONE', ca_certs=None, ssl_version=None):
-                                                  block, headers)
+        HTTPConnectionPool.__init__(self, host, port,
-            return HTTPSConnection(host=self.host, port=self.port)
+            return HTTPSConnection(host=self.host,
-        connection = VerifiedHTTPSConnection(host=self.host, port=self.port)
+        connection = VerifiedHTTPSConnection(host=self.host,
-    def __init__(self, pool, url):
+    def __init__(self, pool, url, reason=None):
-        PoolError.__init__(self, pool, message)
+        if reason:
-        super(LocationParseError, self).__init__(self, message)
+        HTTPError.__init__(self, message)
-    Encode a dictionary of ``fields`` using the multipart/form-data mime format.
+    Encode a dictionary of ``fields`` using the multipart/form-data MIME format.
-        is treated as the filename of the form-data section.
+        Dictionary of fields or list of (key, value) or (key, value, MIME type)
-            filename, data = value
+            if len(value) == 3:
-                       (get_content_type(filename))))
+                       (content_type,)))
-            body.write(b'Content-Type: text/plain\r\n\r\n')
+            body.write(b'\r\n')
-__version__ = "1.1.0"
+__version__ = "1.2.0"  # Revision 41c74fef2ded
-        # 32-bit
+    if sys.platform.startswith("java"):
-    del X
+        # It's possible to have sizeof(long) != sizeof(Py_ssize_t).
-moves = sys.modules["six.moves"] = _MovedItems("moves")
+moves = sys.modules[__name__ + ".moves"] = _MovedItems("moves")
-    advance_iterator = next
+    Iterator = object
-        return it.next()
+        def next(self):
-    return getattr(d, _iterkeys)()
+    return iter(getattr(d, _iterkeys)())
-    return getattr(d, _itervalues)()
+    return iter(getattr(d, _itervalues)())
-    return getattr(d, _iteritems)()
+    return iter(getattr(d, _iteritems)())
-        used pool.
+        Number of connection pools to cache before discarding the least
-        >>> r = manager.urlopen("http://yahoo.com/")
+        >>> r = manager.request('GET', 'http://google.com/')
-    def __init__(self, num_pools=10, **connection_pool_kw):
+    def __init__(self, num_pools=10, headers=None, **connection_pool_kw):
-        kw['retries'] = kw.get('retries', 3) - 1 # Persist retries countdown
+        kw['retries'] = kw.get('retries', 3) - 1  # Persist retries countdown
-        headers['Proxy-Connection'] = 'Keep-Alive'
+        headers_ = {'Accept': '*/*'}
-        return headers
+        return headers_
-
+    def __init__(self, headers=None):
-        key/filetuple. A filetuple is a (filename, data) tuple. For example: ::
+        key/filetuple. A filetuple is a (filename, data, MIME type) tuple where
-                'nonamefile': ('contents of nonamefile field'),
+                'typedfile': ('bazfile.bin', open('bazfile').read(),
-        headers.update({'Content-Type': content_type})
+        if headers is None:
-        return self.urlopen(method, url, body=body, headers=headers,
+        return self.urlopen(method, url, body=body, headers=headers_,
-        content_encoding = self.headers.get('content-encoding')
+        # Note: content-encoding value should be case-insensitive, per RFC 2616
-except ImportError: # `poll` doesn't exist on OSX and other platforms
+except ImportError:  # `poll` doesn't exist on OSX and other platforms
-    except ImportError: # `select` doesn't exist on AppEngine.
+    except ImportError:  # `select` doesn't exist on AppEngine.
-        >>> prase_url('google.com:80')
+        >>> parse_url('google.com:80')
-        >>> prase_url('/foo?bar')
+        >>> parse_url('/foo?bar')
-# 
+#
-# 
+#
-__version__ = "1.0.0"
+__version__ = "1.0.1"
-HOOKS = ('pre_prepare', 'post_prepare', 'pre_request', 'pre_send', 'post_request', 'response')
+HOOKS = ('response')
-
+HOOKS = ('pre_prepare', 'post_prepare', 'pre_request', 'pre_send', 'post_request', 'response')
-import collections
+# import os
-from datetime import datetime
+# from datetime import datetime
-from .packages.urllib3 import connectionpool, poolmanager
+# from .packages.urllib3.exceptions import MaxRetryError, LocationParseError
-URLRequired, SSLError, MissingSchema, InvalidSchema, InvalidURL)
+from .exceptions import ConnectionError, Timeout, SSLError
-
+        url = requote_uri(urlunparse([scheme, netloc, path, params, query, fragment]))
-
+    session = sessions.Session()
-        'params', 'config', 'verify', 'cert', 'prefetch']
+        'params', 'verify', 'cert', 'prefetch']
-from .packages.urllib3.exceptions import MaxRetryError, LocationParseError
+from .packages.urllib3.exceptions import MaxRetryError
-from .packages.urllib3.filepost import encode_multipart_formdata
+from .packages.urllib3 import poolmanager
-        # extract_cookies_to_jar(self.cookies, self, resp)
+        extract_cookies_to_jar(response.cookies, req, resp)
-        self.config = {}
+        self.cookies = cookiejar_from_dict({})
-from .utils import DEFAULT_CA_BUNDLE_PATH
+from .utils import DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers
-        pool_maxsize=DEFAULT_POOLSIZE):
+    def __init__(self, pool_connections=DEFAULT_POOLSIZE, pool_maxsize=DEFAULT_POOLSIZE):
-        # response.encoding = get_encoding_from_headers(response.headers)
+        response.encoding = get_encoding_from_headers(response.headers)
-
+            yield resp
-
+        i = 0
-                # raise TooManyRedirects()
+            if i > self.max_redirects:
-
+            method = req.method
-                              requote_uri(url))
+                # Compliant with RFC3986, we percent encode the url.
-                method = req.method
+            i += 1
-from .defaults import SCHEMAS
+
-    #     raise NotImplementedError
+    def send(self):
-from .utils import header_expand, from_key_val_list
+from .utils import header_expand, from_key_val_list, default_headers
-
+DEFAULT_REDIRECT_LIMIT = 30
-            self.config.setdefault(k, deepcopy(v))
+        #: Maximum number of redirects to follow.
-        
+
-        req.allow_redirects = allow_redirects
+        # req.allow_redirects = allow_redirects
-        resp = self.send(prep)
+        resp = self.send(prep, prefetch, timeout, verify, cert)
-        # Redirect generator.
+        # Redirect resolving generator.
-            resp.history = history
+            resp.history = tuple(history)
-            gen = self.resolve_redirects(resp, req, prefetch, timeout, verify, cert)
+        # Redirect generator.
-            history = [r for r in gen]
+        history = [r for r in gen] if allow_redirects else []
-            print history
+        if history:
-
+from .compat import urlparse, urljoin
-class Session(object):
+
-        return self.send(prep)
+        resp = self.send(prep)
-        return self.request('get', url, **kwargs)
+        return self.request('GET', url, **kwargs)
-        return self.request('options', url, **kwargs)
+        return self.request('OPTIONS', url, **kwargs)
-        return self.request('head', url, **kwargs)
+        return self.request('HEAD', url, **kwargs)
-        return self.request('post', url, data=data, **kwargs)
+        return self.request('POST', url, data=data, **kwargs)
-        return self.request('put', url, data=data, **kwargs)
+        return self.request('PUT', url, data=data, **kwargs)
-        return self.request('patch', url,  data=data, **kwargs)
+        return self.request('PATCH', url,  data=data, **kwargs)
-        return self.request('delete', url, **kwargs)
+        return self.request('DELETE', url, **kwargs)
-    def send(self, request):
+    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None):
-        r = adapter.send(request)
+        r = adapter.send(request, prefetch, timeout, verify, cert)
-        return urlparse(self._r.full_url).netloc
+        return urlparse(self._r.url).netloc
-        return self._r.full_url
+        return self._r.url
-
+        """Prepares the given HTTP auth data."""
-    """A user-created Request object."""
+    """A user-created :class:`Request <Request>` object."""
-    """
+    """The :class:`PreparedRequest <PreparedRequest>` object."""
-        # self.cert = cert
+
-__build__ = 0x001402
+__version__ = '1.0.0'
-from .models import Request, Response
+from .models import Request, Response, PreparedRequest
-        self.body = None
+# class BaseResponse(object):
-class Response(BaseResponse):
+class Response(object):
-
+                try:
-            return None
+                return json.loads(self.content.decode(encoding))
-            self.headers = CaseInsensitiveDict(self.headers)
+            self.headers = CaseInsensitiveDict(headers)
-from adapters import HTTPAdapter
+from .adapters import HTTPAdapter
-            session.close()
+
-zz
+from .structures import CaseInsensitiveDict
-        self.timeout = timeout
+        # self.timeout = timeout
-        self.poolmanager.clear()
+        pass
-        return request.send()
+        adapter = HTTPAdapter()
-        # l = MultiDict()
+
-from .structures import CaseInsensitiveDict
+zz
-
+from .models import Response
-        raise NotImplementedError
+    # def send(self):
-        if url.startswith('https') and self.verify:
+    def cert_verify(self, conn, url, verify, cert):
-            if self.verify is not True:
+            if verify is not True:
-                conn.key_file = self.cert[1]
+        if cert:
-                conn.cert_file = self.cert
+                conn.cert_file = cert
-    def send(self, request, timeout, verify, cert):
+    def send(self, request, prefetch=True, timeout=None, verify=True, cert=None):
-        self.cert_verify(conn, verify, cert)
+        conn = self.poolmanager.connection_from_url(request.url)
-                response.status_code = getattr(resp, 'status', None)
+                # response.status_code = getattr(resp, 'status', None)
-                response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))
+                # response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))
-                response.encoding = get_encoding_from_headers(response.headers)
+                # response.encoding = get_encoding_from_headers(response.headers)
-
+        # TODO: session level shit
-                    self.headers['Cookie'] = cookie_header
+            # if 'cookie' not in self.headers:
-                    raise Timeout('Request timed out.')
+            # try:
-        self.type = urlparse(self._r.full_url).scheme
+        self.type = urlparse(self._r.url).scheme
-defaults['verbose'] = None
+# Consumed at the session level, not connection.
-defaults['support_http0.9'] = True
+# defaults['support_http0.9'] = True
-        #: CookieJar to attach to :class:`Request <Request>`.
+
-            self.cookies = cookies
+            cookies = cookies
-            self.cookies = cookiejar_from_dict(cookies)
+            cookies = cookiejar_from_dict(cookies)
-                    prefetch=self.prefetch,
+                    prefetch=self.prefetch
-        if url.startswith('https') and self.verify:
+        # if url.startswith('https') and self.verify:
-            cert_loc = None
+        #     cert_loc = None
-                cert_loc = self.verify
+        #     # Allow self-specified cert location.
-                cert_loc = os.environ.get('REQUESTS_CA_BUNDLE')
+        #     # Look for configuration.
-                cert_loc = os.environ.get('CURL_CA_BUNDLE')
+        #     # Curl compatibility.
-                cert_loc = DEFAULT_CA_BUNDLE_PATH
+        #     if not cert_loc:
-                raise Exception("Could not find a suitable SSL CA certificate bundle.")
+        #     if not cert_loc:
-            conn.ca_certs = None
+        #     conn.cert_reqs = 'CERT_REQUIRED'
-                conn.cert_file = self.cert
+        # if self.cert:
-class Response(object):
+class Response(BaseResponse):
-        self.request = None
+        # self.request = None
-    def raise_for_status(self, allow_redirects=True):
+    def raise_for_status(self):
-        elif 400 <= self.status_code < 500:
+        if 400 <= self.status_code < 500:
-            (body, content_type) = self._encode_files(files)
+            (body, content_type) = self._encode_files(files, data)
-        p.prepare_url(self.url)
+        p.prepare_url(self.url, self.params)
-        self.data = None
+        self.body = None
-
+        """Prepares the given HTTP method."""
-        """Request URL."""
+    def prepare_url(self, url, params):
-        enc_params = self._encode_params(self.params)
+        enc_params = self._encode_params(params)
-        """change to list"""
+        """Prepares the given HTTP headers."""
-    def prepare_data(self, headers, files):
+    def prepare_body(self, data, files):
-        pass
+        # Nottin' on you.
-        pass
+        if auth:
-        content_type = None
+        # if self.auth:
-            if self.data:
+        #     # Allow auth to make its changes.
-                    content_type = 'application/x-www-form-urlencoded'
+        #     # Update self to reflect the auth changes.
-            self.headers['Content-Length'] = str(len(body))
+        # # Nottin' on you.
-            self.headers['Content-Type'] = content_type
+        # # Multi-part file uploads.
-        s.send(r)
+        r = s.send(r)
-            self.url = url
+        # URL
-            self.cookies = cookiejar_from_dict(cookies)
+        # #: CookieJar to attach to :class:`Request <Request>`.
-            headers = CaseInsensitiveDict()
+        # if headers:
-            return data
+    def send(self, request):
-defaults['store_cookies'] = True
+import logging
-            ))
+        log.info('Sending %s: %s' % (self, url))
-                    extract_cookies_to_jar(self.cookies, self, resp)
+                # Add new cookies from the server.
-        for _ in xrange(self.request_count):
+        for _ in range(self.request_count):
-    from ._oauth import (Client, SIGNATURE_HMAC, SIGNATURE_TYPE_AUTH_HEADER, extract_params)
+    from oauthlib.common import extract_params
-            while (('location' in r.headers) and
+            while (('location' in r.headers and r.status_code in REDIRECT_STATI) and
-:license: ISC, see LICENSE for more details.
+:license: Apache 2.0, see LICENSE for more details.
-__license__ = 'ISC'
+__license__ = 'Apache 2.0'
-:license: ISC, see LICENSE for more details.
+:license: Apache2, see LICENSE for more details.
-        'License :: OSI Approved :: ISC License (ISCL)',
+        'License :: OSI Approved :: Apache Software License',
-        session = sessions.session()
+        session = sessions.session(config=kwargs.get('config', None))
-            maxsize=self.config.get('pool_maxsize')
+            maxsize=self.config.get('pool_maxsize'),
-    return u.result
+######################## BEGIN LICENSE BLOCK ########################
-# 
+#
-# 
+#
-# 
+#
-# 
+#
-# by Taiwan's Mandarin Promotion Council 
+# by Taiwan's Mandarin Promotion Council
-# 
+#
-# 
+#
-# 
+#
-Big5CharToFreqOrder = ( \
+Big5CharToFreqOrder = (
-        return "Big5"
+######################## BEGIN LICENSE BLOCK ########################
-            return -1
+######################## BEGIN LICENSE BLOCK ########################
-#            return self._mBestGuessProber.get_confidence()
+######################## BEGIN LICENSE BLOCK ########################
-        return self._mModel['name']
+######################## BEGIN LICENSE BLOCK ########################
-    if isinstance(a, str) and version_info < (3, 0):
+    if isinstance(a, str):
-    elif isinstance(a, int) and version_info >= (3, 0):
+    elif isinstance(a, int):
-SHORTCUT_THRESHOLD = 0.95
+######################## BEGIN LICENSE BLOCK ########################
-        return self.get_state()
+######################## BEGIN LICENSE BLOCK ########################
-                    'name': "ISO-2022-KR"}
+######################## BEGIN LICENSE BLOCK ########################
-        return max(contxtCf, distribCf)
+######################## BEGIN LICENSE BLOCK ########################
-        return "EUC-KR"
+######################## BEGIN LICENSE BLOCK ########################
-# 
+#
-# 
+#
-# by Taiwan's Mandarin Promotion Council 
+# Converted from big5 work
-# 
+#
-# Char to FreqOrder table , 
+# Char to FreqOrder table ,
-EUCTWCharToFreqOrder = ( \
+EUCTWCharToFreqOrder = (
-        return "EUC-TW"
+######################## BEGIN LICENSE BLOCK ########################
-# 
+#
-# 
+#
-# 
+#
-GB2312CharToFreqOrder = ( \
+GB2312CharToFreqOrder = (
-        return "GB2312"
+######################## BEGIN LICENSE BLOCK ########################
-        return constants.eDetecting
+######################## BEGIN LICENSE BLOCK ########################
-# 
+#
-# 
+#
-# They are sorted in order. 
+# They are sorted in order.
-# Typical Distribution Ratio, 25% of IDR 
+#
-# Char to FreqOrder table , 
+# Char to FreqOrder table ,
-JISCharToFreqOrder = ( \
+JISCharToFreqOrder = (
-        return -1, charLen
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-# flake8: noqa
+######################## BEGIN LICENSE BLOCK ########################
-        return confidence
+######################## BEGIN LICENSE BLOCK ########################
-        return self._mDistributionAnalyzer.get_confidence()
+######################## BEGIN LICENSE BLOCK ########################
-        self.reset()
+######################## BEGIN LICENSE BLOCK ########################
-               'name': 'UTF-8'}
+######################## BEGIN LICENSE BLOCK ########################
-        return r
+######################## BEGIN LICENSE BLOCK ########################
-        self.reset()
+######################## BEGIN LICENSE BLOCK ########################
-        return max(contxtCf, distribCf)
+######################## BEGIN LICENSE BLOCK ########################
-                                  prober.get_confidence()))
+######################## BEGIN LICENSE BLOCK ########################
-            return unlike
+######################## BEGIN LICENSE BLOCK ########################
-            conn = poolmanager.proxy_from_url(proxy)
+            conn = poolmanager.ProxyManager(self.get_connection_for_url(proxy))
-                raise InvalidURL(e)
+            conn = self.get_connection_for_url(url)
-        aBuf = re.sub(b'([\x00-\x7F])+', ' ', aBuf)
+        aBuf = re.sub(b'([\x00-\x7F])+', b' ', aBuf)
-        aBuf = re.sub(b'([A-Za-z])+', ' ', aBuf)
+        aBuf = re.sub(b'([A-Za-z])+', b' ', aBuf)
-from sys import verion_info
+from sys import version_info
-    if isinstance(a, 'str') and version_info < (3, 0):
+    if isinstance(a, str) and version_info < (3, 0):
-                        self._mDone = constants.True
+                        self._mDone = True
-                    self._mSeqCounters[self.mModel['precedenceMatrix'][i]] += 1
+                    model = self._mModel['precedenceMatrix'][i]
-# 
+#
-# 
+#
-from hebrewprober import HebrewProber
+from .charsetgroupprober import CharSetGroupProber
-        self._mProbers = [ \
+        self._mProbers = [
-            ]
+        ]
-        visualHebrewProber = SingleByteCharSetProber(Win1255HebrewModel, constants.True, hebrewProber)
+        logicalHebrewProber = SingleByteCharSetProber(Win1255HebrewModel,
-        self._mProbers.extend([hebrewProber, logicalHebrewProber, visualHebrewProber])
+        self._mProbers.extend([hebrewProber, logicalHebrewProber,
-    'requests.packages.chardet'
+    'requests.packages.charade'
-    return u.result
+######################## BEGIN LICENSE BLOCK ########################
-        return "Big5"
+######################## BEGIN LICENSE BLOCK ########################
-            return -1
+######################## BEGIN LICENSE BLOCK ########################
-#            return self._mBestGuessProber.get_confidence()
+######################## BEGIN LICENSE BLOCK ########################
-class CharSetProber:
+class CharSetProber(object):
-        aBuf = re.sub(b'([\x00-\x7F])+', b' ', aBuf)
+        aBuf = re.sub('([\x00-\x7F])+', ' ', aBuf)
-        aBuf = re.sub(b'([A-Za-z])+', b' ', aBuf)
+        aBuf = re.sub('([A-Za-z])+', ' ', aBuf)
-        return self._mModel['name']
+######################## BEGIN LICENSE BLOCK ########################
-                    'name': "ISO-2022-KR"}
+######################## BEGIN LICENSE BLOCK ########################
-        return max(contxtCf, distribCf)
+######################## BEGIN LICENSE BLOCK ########################
-        return "EUC-KR"
+######################## BEGIN LICENSE BLOCK ########################
-        return "EUC-TW"
+######################## BEGIN LICENSE BLOCK ########################
-        return "GB2312"
+######################## BEGIN LICENSE BLOCK ########################
-        return constants.eDetecting
+######################## BEGIN LICENSE BLOCK ########################
-        return -1, charLen
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-        return confidence
+######################## BEGIN LICENSE BLOCK ########################
-        return self._mDistributionAnalyzer.get_confidence()
+######################## BEGIN LICENSE BLOCK ########################
-               'name': 'UTF-8'}
+######################## BEGIN LICENSE BLOCK ########################
-        return r
+######################## BEGIN LICENSE BLOCK ########################
-        return max(contxtCf, distribCf)
+######################## BEGIN LICENSE BLOCK ########################
-print(count, 'tests')
+import sys, glob
-                                  prober.get_confidence()))
+######################## BEGIN LICENSE BLOCK ########################
-            return unlike
+######################## BEGIN LICENSE BLOCK ########################
-    from .packages import chardet2 as chardet
+    from .packages import chardet
-    'requests.packages.chardet'
+    'requests.packages.chardet',
-# 
+#
-# 
+#
-# 
+#
-# 
+#
-# 2 : normal 
+# 0 : illegal
-  
+
-        # lower the confidence of latin1 so that other more accurate detector 
+        # lower the confidence of latin1 so that other more accurate detector
-# 
+#
-# 
+#
- 
+
-                        files = None
+                # Do what the browsers do, despite standards...
-    return u.result
+######################## BEGIN LICENSE BLOCK ########################
-        return "Big5"
+######################## BEGIN LICENSE BLOCK ########################
-            return -1
+######################## BEGIN LICENSE BLOCK ########################
-#            return self._mBestGuessProber.get_confidence()
+######################## BEGIN LICENSE BLOCK ########################
-import constants, re
+from . import constants
-        aBuf = re.sub(r'([\x00-\x7F])+', ' ', aBuf)
+        aBuf = re.sub(b'([\x00-\x7F])+', b' ', aBuf)
-        aBuf = re.sub(r'([A-Za-z])+', ' ', aBuf)
+        aBuf = re.sub(b'([A-Za-z])+', b' ', aBuf)
-        return self._mModel['name']
+######################## BEGIN LICENSE BLOCK ########################
-    True = __builtin__.True
+######################## BEGIN LICENSE BLOCK ########################
-        return self.get_state()
+######################## BEGIN LICENSE BLOCK ########################
-                    'name': "ISO-2022-KR"}
+######################## BEGIN LICENSE BLOCK ########################
-        return max(contxtCf, distribCf)
+######################## BEGIN LICENSE BLOCK ########################
-        return "EUC-KR"
+######################## BEGIN LICENSE BLOCK ########################
-        return "EUC-TW"
+######################## BEGIN LICENSE BLOCK ########################
-        return "GB2312"
+######################## BEGIN LICENSE BLOCK ########################
-        return constants.eDetecting
+######################## BEGIN LICENSE BLOCK ########################
-        return -1, charLen
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-}
+######################## BEGIN LICENSE BLOCK ########################
-        return confidence
+######################## BEGIN LICENSE BLOCK ########################
-        return self._mDistributionAnalyzer.get_confidence()
+######################## BEGIN LICENSE BLOCK ########################
-        self.reset()
+######################## BEGIN LICENSE BLOCK ########################
-               'name': 'UTF-8'}
+######################## BEGIN LICENSE BLOCK ########################
-        return r
+######################## BEGIN LICENSE BLOCK ########################
-        self.reset()
+######################## BEGIN LICENSE BLOCK ########################
-        return max(contxtCf, distribCf)
+######################## BEGIN LICENSE BLOCK ########################
-                                  prober.get_confidence()))
+######################## BEGIN LICENSE BLOCK ########################
-            return unlike
+######################## BEGIN LICENSE BLOCK ########################
-from requests.compat import is_py3
+    'requests.packages.chardet'
-from requests.compat import is_py2
+from requests.compat import is_py3
-else:
+if is_py3:
-        elif r.data:
+        else:
-        if isinstance(body, file):
+        if hasattr(body, 'seek') and hasattr(body, 'tell'):
-        if body is not None:
+        if isinstance(body, file):
-                unicode(r.full_url), unicode(r.method), r.data, r.headers)
+            r.url, r.headers, _ = self.client.sign(unicode(r.full_url),
-        if callable(hook):
+        if isinstance(hook, collections.Callable):
-            self.hooks[event].extend(h for h in hook if callable(h))
+            self.hooks[event].extend(h for h in hook if isinstance(h, collections.Callable))
-                self.assertTrue(callable(h))
+                self.assertTrue(isinstance(h, collections.Callable))
-    """New implementation of safe_mode. We catch all exceptions at the API level
+    """New implementation of safe_mode. We catch all exceptions at the Session level
-    wraps request() in api.py.
+    wraps Session._send_request() in sessions.py.
-    def wrapped(method, url, **kwargs):
+    def wrapped(*args, **kwargs):
-                return function(method, url, **kwargs)
+                return function(*args, **kwargs)
-        return function(method, url, **kwargs)
+        return function(*args, **kwargs)
-        r.send(prefetch=prefetch)
+        return self._send_request(r, **args)
-                    parts[i] = '%' + parts[i]
+    parts = uri.split('%')
-        return uri
+        else:
-    CERTIFI_BUNDLE_PATH = certs.where()
+    path = certs.where()
-    CERTIFI_BUNDLE_PATH = certs.where()
+    path = certs.where()
-            self.proxies = get_environ_proxies()
+            self.proxies = get_environ_proxies(self.url)
-def get_environ_proxies():
+def get_environ_proxies(url):
-        'no'
+        'socks'
-class GuessJSONUTFTests(unittest.TestCase):
+class UtilityTests(unittest.TestCase):
-        return urlparse(self._r.full_url).scheme
+        return self.type
-        #: Dictionary or byte of querystring data to attach to the
+        #: Dictionary of querystring data to attach to the
-            '%s/%s' % (platform.system(), platform.release()),
+            '%s/%s' % (p_system, p_release),
-    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/'),
+    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/', 'â'),
-    500: ('internal_server_error', 'server_error', '/o\\'),
+    500: ('internal_server_error', 'server_error', '/o\\', 'â'),
-    StringIO, is_py2, chardet, json, builtin_str, urldefrag)
+    StringIO, is_py2, chardet, json, builtin_str, urldefrag, basestring)
-                for v in isinstance(vs, list) and vs or [vs]:
+                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):
-__build__ = 0x001401
+__version__ = '0.14.2'
-    from urlparse import urlparse, urlunparse, urljoin, urlsplit
+    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urldefrag
-    from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus
+    from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus, urldefrag
-    StringIO, is_py2, chardet, json, builtin_str)
+    StringIO, is_py2, chardet, json, builtin_str, urldefrag)
-            return self.full_url
+            url_base, frag = urldefrag(self.full_url)
-            if res is not None and res != 'utf-8':
+            if res is not None:
-
+                # something in this encoding. However, UTF-8 is a lot
-    chr = lambda c: bytes([c])
+    byteschr = lambda c: bytes([c])
-                [chr(random.randrange(256)) for _ in range(4)])
+                [byteschr(random.randrange(256)) for _ in range(4)])
-    """Smoke test for https functionality."""
+    """Tests for the JSON UTF encoding guessing code."""
-    to_key_val_list, DEFAULT_CA_BUNDLE_PATH, parse_header_links, iter_slices)
+    to_key_val_list, DEFAULT_CA_BUNDLE_PATH, parse_header_links, iter_slices,
-    from urllib import quote, unquote, urlencode
+    from urllib import quote, unquote, quote_plus, unquote_plus, urlencode
-    from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote
+    from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus
-from .compat import quote, urlparse, basestring, bytes, str, OrderedDict
+from .compat import quote, quote_plus, urlparse, basestring, bytes, str, OrderedDict
-    sys.path.insert(0, path)
+    from .packages import oauthlib
-    if 'gzip' in resp.headers.get('content-encoding', ''):
+    ce = resp.headers.get('content-encoding', '').lower()
-    elif 'deflate' in resp.headers.get('content-encoding', ''):
+    elif 'deflate' in ce:
-        assert heads['User-agent'] in r.text
+        self.assertTrue(heads['User-agent'] in r.text)
-            assert isinstance(response.url, str)
+            self.assertTrue(isinstance(response.url, str))
-            assert rbody.get('form') in (None, {})
+            self.assertTrue(rbody.get('form') in (None, {}))
-            assert rbody.get('form') in (None, {})
+            self.assertTrue(rbody.get('form') in (None, {}))
-            assert rbody.get('form') in (None, {})
+            self.assertTrue(rbody.get('form') in (None, {}))
-        assert heads['User-agent'] in r1.text
+        self.assertTrue(heads['User-agent'] in r1.text)
-        assert heads['User-agent'] in r2.text
+        self.assertTrue(heads['User-agent'] in r2.text)
-        assert new_heads['User-agent'] in r3.text
+        self.assertTrue(new_heads['User-agent'] in r3.text)
-            assert 'foo' in response.text
+            self.assertTrue('foo' in response.text)
-            assert 'bar' in response.text
+            for text in ('foo', 'bar'):
-                assert callable(h) is True
+                self.assertTrue(callable(h))
-        assert 'k' in c
+        self.assertTrue('k' in c)
-        assert 'k' in c
+        self.assertTrue('k' in c)
-        assert params['a'] in r1.text
+        self.assertTrue(params['a'] in r1.text)
-        assert params2['b'] in r2.text
+        for param in (params['a'], params2['b']):
-        assert params3['c'] in r3.text
+        self.assertFalse(params['a'] in r3.text)
-        assert 'k' in s.cookies
+        self.assertTrue('k' in c)
-        assert 'k' in c
+        self.assertTrue('k' in c)
-        assert 'k' in c
+        self.assertTrue('k' in c)
-        assert not ds2.prefetch
+        self.assertTrue(ds1.prefetch)
-            assert False
+            self.fail()
-        assert r.content is None
+        self.assertTrue(r.content is None)
-        assert r1.text
+        self.assertFalse(r1._content)
-        assert r2.text
+        self.assertTrue(r2._content)
-        assert r._content_consumed
+        self.assertTrue(r._content_consumed)
-        assert (1 + 1) == 2
+        self.assertEqual(2, 1 + 1)
-        assert r.ok
+        self.assertTrue(r.ok)
-        assert r.ok
+        self.assertTrue(r.ok)
-        assert r.ok
+        self.assertTrue(r.ok)
-        assert r3.url == 'http://httpbin.org/cookies'
+        self.assertEqual(r3.url, 'http://httpbin.org/cookies')
-html_theme = 'kr'
+html_theme = 'kr'
-                             data={'some': 'data'})
+                post1 = post(url, data={'some': 'data'}, files={'some': f})
-                        files=[('some', f)])
+                post3 = post(url, data=[('some', 'data')], files=[('some', f)])
-                             data={'some': 'ä¸­æ'})
+                post1 = post(url, data={'some': 'ä¸­æ'}, files={'some': f})
-                        files=[('some', f)])
+                post3 = post(url, data=[('some', 'íêµ­ì')], files=[('some', f)])
-        elif decoded_body != None and contenttype in (CONTENT_TYPE_FORM_URLENCODED, ''):
+        elif decoded_body is not None and contenttype in (CONTENT_TYPE_FORM_URLENCODED, ''):
-    basestring = (str,bytes)
+    basestring = (str, bytes)
-            if (domain == None or cookie.domain == domain) and (path == None
+            if (domain is None or cookie.domain == domain) and (path is None
-                        if toReturn != None:  # if there are multiple cookies that meet passed in criteria
+                        if toReturn is not None:  # if there are multiple cookies that meet passed in criteria
-        )
+        rfc2109=False,)
-        )
+        rfc2109=False,)
-        for proxy_type,uri_ref in list(self.proxies.items()):
+        for proxy_type, uri_ref in list(self.proxies.items()):
-        yield string[pos:pos+slice_length]
+        yield string[pos:pos + slice_length]
-import gc, os, subprocess, requests, sys
+import gc
-import sys, os, unittest
+import os
-        result = requests.get(self.smoke_url, verify=False, proxies = proxy)
+        proxy = {"https": ""}
-        result = requests.get(self.smoke_url, proxies = proxy)
+        proxy = {"http": ""}
-        assert r.content == None
+        assert r.content is None
-import sys, os
+import os
-import json
+import os
-        else:
+        if callable(hook):
-__build__ = 0x001400
+__version__ = '0.14.1'
-            return self.is_unverifiable()
+    @property
-                cookie_dict[cookie.name] = cookie.value
+    for cookie in cj:
-        except LookupError:
+        except (LookupError, TypeError):
-        except TypeError:
+        except TypeError:
-                    new_fields.append((field, str(v)))
+                    new_fields.append((field, builtin_str(v)))
-                new_fields.append((field, str(val)))
+                new_fields.append((field, builtin_str(val)))
-        else:
+        if callable(hook):
-__build__ = 0x001400
+__version__ = '0.14.1'
-            return self.is_unverifiable()
+    @property
-                cookie_dict[cookie.name] = cookie.value
+    for cookie in cj:
-        except LookupError:
+        except (LookupError, TypeError):
-        except TypeError:
+        except TypeError:
-
+        self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,
-    'Accept-Encoding': ', '.join(('identity', 'deflate', 'compress', 'gzip')),
+    'Accept-Encoding': ', '.join(('gzip', 'deflate', 'compress')),
-        self.hooks[event].append(hook)
+        if isinstance(hook, (list, tuple, set)):
-        for proxy_type,uri_ref in self.proxies.items():
+        for proxy_type,uri_ref in list(self.proxies.items()):
-                response.headers = CaseInsensitiveDict(getattr(resp, 'headers', None))
+                response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))
-os.environ['PYTHONDONTWRITEBYTECODE'] = bytecode
+del os.environ['PYTHONDONTWRITEBYTECODE']
-:param store_cookies: If false, the received cookies as part of the HTTP response would be ignored.
+:store_cookies: If false, the received cookies as part of the HTTP response would be ignored.
-        # been read.
+        # prefetch should persist across the redirect;
-        # content should not have been prefetched, and iter_lines should succeed
+        # content should not have been prefetched
-    StringIO, is_py2, chardet, json, builtin_str, numeric_types)
+    StringIO, is_py2, chardet, json, builtin_str)
-from .utils import header_expand, to_key_val_list
+from .utils import header_expand, from_key_val_list
-    if not hasattr(kwargs, 'items'):
+    if not hasattr(default_kwarg, 'items'):
-    local_kwarg = to_key_val_list(local_kwarg)
+    default_kwarg = from_key_val_list(default_kwarg)
-    kwargs = kwargs.copy()
+    kwargs = default_kwarg.copy()
-    for (k, v) in local_kwarg:
+    for (k, v) in local_kwarg.items():
-        self.headers = headers or {}
+        self.headers = from_key_val_list(headers or [])
-        self.config = config or {}
+        self.proxies = from_key_val_list(proxies or [])
-        params = [] if params is None else params
+        params = {} if params is None else params
-            for k, v in list(headers.items()) or {}:
+            for k, v in list(headers.items() or {}):
-            headers=headers,
+            params=from_key_val_list(params),
-            hooks=hooks,
+            hooks=from_key_val_list(hooks),
-            config=config,
+            proxies=from_key_val_list(proxies),
-from .compat import quote, urlparse, basestring, bytes, str
+from .compat import quote, urlparse, basestring, bytes, str, OrderedDict
-    [('key', 'val')]
+    dictionary. If it can be, return a list of tuples, e.g.,
-                '2-tuples.')
+    if isinstance(value, (str, bytes, bool, int)):
-    if isinstance(value, dict) or hasattr(value, 'items'):
+    if isinstance(value, dict):
-    
+
-            
+
-     // ...snip... //
+     ...
-     // ...snip... //
+     ...
-is at <http://requests.rtfd.org/>.
+is at <http://python-requests.org>.
-__build__ = 0x001309
+__version__ = '0.14.0'
-    to_key_val_list, DEFAULT_CA_BUNDLE_PATH, parse_header_links)
+    to_key_val_list, DEFAULT_CA_BUNDLE_PATH, parse_header_links, iter_slices)
-            )
+            # simulate reading small chunks of the content
-        _cond = True
+        _oauth_signed = True
-        if _cond:
+            _oauth_signed = False
-            r.headers['Content-Type'] = CONTENT_TYPE_FORM_URLENCODED
+            if not contenttype:
-        # a mimetype of multipart/form-encoded and if this is not the case
+        # a mimetype of multipart/form-data and if this is not the case
-            r.headers['Content-Type'] = CONTENT_TYPE_MULTI_PART
+CONTENT_TYPE_MULTI_PART = 'multipart/form-data'
-        contenttype = r.headers.get('Content-Type', None)
+        # split(";") because Content-Type may be "multipart/form-data; boundary=xxxxx"
-
+        # extract_params can only check the present r.data and does not know
-~~~~~~~~
+requests HTTP library
-        logging.debug("Collected params: {0}".format(collected_params))
+        logger.debug("Collected params: {0}".format(collected_params))
-        logging.debug("Normalized URI: {0}".format(normalized_uri))
+        logger.debug("Normalized params: {0}".format(normalized_params))
-        logging.debug("Base signing string: {0}".format(base_string))
+        logger.debug("Base signing string: {0}".format(base_string))
-        logging.debug("Signature: {0}".format(sig))
+        logger.debug("Signature: {0}".format(sig))
-    from .packages import chardet
+    try:
-__build__ = 0x001308
+__version__ = '0.13.9'
-            and decoded_body != None:
+
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-        
+
-    
+
-    
+
-    
+
-            # Consume content and release the original connection 
+            # Consume content and release the original connection
-            r.headers['Authorization'] = self.build_digest_header(r.method, r.url)    
+            r.headers['Authorization'] = self.build_digest_header(r.method, r.url)
-                         v.encode('utf-8') if isinstance(v, str) else v))
+                    if v is not None:
-    if not hasattr(default_kwarg, 'items'):
+    if not hasattr(kwargs, 'items'):
-    kwargs = default_kwarg.copy()
+    kwargs = kwargs.copy()
-__build__ = 0x001307
+__version__ = '0.13.8'
-from .structures import CaseInsensitiveDict, MultiDict
+from .structures import CaseInsensitiveDict
-from .structures import CaseInsensitiveDict
+from .structures import CaseInsensitiveDict, MultiDict
-    to_key_val_list, DEFAULT_CA_BUNDLE_PATH)
+    to_key_val_list, DEFAULT_CA_BUNDLE_PATH, parse_header_links)
-        """Returns the json-encoded content of a request, if any."""
+        """Returns the json-encoded content of a response, if any."""
-        if contenttype == None and decoded_body != None:
+        if (contenttype is None or contenttype.lower() == "application/x-www-form-urlencoded")\
-                                    ca_certs=self.ca_certs)
+        try:
-                    new_fields.append((k, str(v)))
+                    new_fields.append((field, str(v)))
-__build__ = 0x001306
+__version__ = '0.13.7'
-                    cookie_attr, expected_value)
+            message = 'Failed comparison for %s: %s != %s' % (attr, cookie_attr, expected_value)
-                headers=heads)
+        r = get(httpbin('get') + '?test=true', params={'q': 'test'}, headers=heads)
-                session=s)
+        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)
-                session=s)
+        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)
-        """
+        """Test the max_redirects config variable, normally and under safe_mode."""
-                unsafe_callable)
+            requests.get(httpbin('redirect', '3'), config=dict(max_redirects=2))
-                config=dict(safe_mode=True, max_redirects=2))
+        response = requests.get(httpbin('redirect', '3'), config=dict(safe_mode=True, max_redirects=2))
-                requests.exceptions.TooManyRedirects))
+        self.assertTrue(isinstance(response.error, requests.exceptions.TooManyRedirects))
-        """
+        """Test that we send 'Connection: close' when keep_alive is disabled."""
-        self.assertTrue('preview' not in json.loads(r2.text)['cookies'])
+        self.assertTrue('preview' not in json.loads(r3.text)['cookies'])
-        self.headers = to_key_val_list(headers or [])
+        #self.headers = to_key_val_list(headers or [])
-        headers = [] if headers is None else headers
+        headers = {} if headers is None else headers
-            headers = expanded
+            #e = [(k, header_expand(v)) for k, v in to_key_val_list(headers)]
-            self.fail()
+            self.fail('Not able to have none in header values')
-            fields.append((k, (fn, fp.read())))
+            new_fields.append((k, (fn, fp.read())))
-        self.assertEqual(t.get('form'), {'field': 'a, b'})
+            self.assertEqual(len(r.history), 1)
-                base += ', qop=auth, nc=%s, cnonce="%s"' % (ncvalue, cnonce)
+            self.chal = parse_dict_header(s_auth.replace('Digest ', ''))
-            r.request.headers['Authorization'] = 'Digest %s' % (base)
+            r.request.headers['Authorization'] = self.build_digest_header(r.request.method, r.request.url)
-
+
-    """There are two cookies that meet the criteria specified in the cookie jar. 
+    """There are two cookies that meet the criteria specified in the cookie jar.
-    
+
-        return False # there is only one domain in jar
+        return False  # there is only one domain in jar
-            if (domain == None or cookie.domain == domain) and (path == None 
+            if (domain == None or cookie.domain == domain) and (path == None
-        """Requests uses this method internally to get cookie values. Takes as args name 
+        """Requests uses this method internally to get cookie values. Takes as args name
-        Throws KeyError if cookie is not found and CookieConflictError if there are 
+        """__get_item__ and get call _find_no_duplicates -- never used in Requests internally.
-                        if toReturn != None: # if there are multiple cookies that meet passed in criteria
+                        if toReturn != None:  # if there are multiple cookies that meet passed in criteria
-                        toReturn = cookie.value # we will eventually return this as long as no cookie conflict
+                        toReturn = cookie.value  # we will eventually return this as long as no cookie conflict
-        no_proxy = filter(lambda x:x.strip(), self.proxies.get('no', '').split(','))
+        no_proxy = filter(lambda x: x.strip(), self.proxies.get('no', '').split(','))
-    
+
-        if (kwargs.get('config') and kwargs.get('config').get('safe_mode')) or (kwargs.get('session') 
+        if (kwargs.get('config') and kwargs.get('config').get('safe_mode')) or (kwargs.get('session')
-                r.status_code = 0 # with this status_code, content returns None
+                r.raw = HTTPResponse()  # otherwise, tests fail
-            setattr(codes, title.upper(), code)
+            setattr(codes, title.upper(), code)
-        config = {'store_cookies' : False}
+        config = {'store_cookies': False}
-        cookies = requests.get(httpbin('cookies', 'set', 'key', 'value'), config = config).cookies
+        cookies = requests.get(httpbin('cookies', 'set', 'key', 'value'), config=config).cookies
-                                                cookies = {"key_2" : "value_2"}).cookies
+        cookies_2 = requests.get(httpbin('cookies', 'set', 'key', 'value'), config=config,\
-        s.get(httpbin('cookies', 'set', 'key', 'value'), config = config)
+        s.get(httpbin('cookies', 'set', 'key', 'value'), config=config)
-        
+
-        
+        self.assertEqual(r.cookies.items(), [('myname', 'myvalue')])
-        self.assertEqual(dictOfCookies, {'myname':'myvalue'})
+        self.assertEqual(dictOfCookies, {'myname': 'myvalue'})
-            post2 = post(url, files={'fname.txt': 'fdata', 'fname2.txt':'more fdata'})
+            post2 = post(url, files={'fname.txt': 'fdata', 'fname2.txt': 'more fdata'})
-            post3 = post(url, files={'fname.txt': 'fdata', 'fname2.txt':open(__file__,'rb')})
+            post3 = post(url, files={'fname.txt': 'fdata', 'fname2.txt': open(__file__, 'rb')})
-
+
-                    hook_data = _hook_data
+            _hook_data = hook(hook_data)
-        if proxy and not any(map(_p.netloc.endswith, no_proxy)):
+        if proxy and not any(map(_p.hostname.endswith, no_proxy)):
-        netloc = netloc.encode('idna').decode('utf-8')
+        try:
-        files = [
+        fields = [
-        r = post(httpbin('post'), data=data, files=files)
+        r = post(httpbin('post'), data=fields, files=fields)
-        self.assertEqual(body.count('__value__'), 4)
+        file_field = (b'Content-Disposition: form-data;'
-            if isinstance(fp, (bytes, str)):
+            if isinstance(fp, str):
-        with the same name."""
+        with the same name.
-            fields = dict(self.data)
+        def tuples(obj):
-        for (k, v) in list(files.items()):
+        for k, v in tuples(files):
-        return (body, content_type)
+            fields.append((k, (fn, fp.read())))
-        files = {'file': 'Garbled data'}
+        files = {'field': 'Garbled data'}
-        self.assertEqual(t.get('form'), {'field': 'a, b'})
+        self.assertEqual(t.get('form'), {'field': ['a', 'b']})
-        self.assertIn('preview', s.cookies)
+        self.assertTrue('preview' in s.cookies)
-        self.assertNotIn('preview', json.loads(r2.text)['cookies'])
+        self.assertTrue('preview' not in json.loads(r2.text)['cookies'])
-        self.assertNotIn('preview', json.loads(r2.text)['cookies'])
+        self.assertTrue('preview' not in json.loads(r2.text)['cookies'])
-        self.url = url
+        #: Accept objects that have string representations.
-        self.assertTrue(first_line.strip().startswith('{'))
+        self.assertTrue(first_line.strip().decode('utf-8').startswith('{'))
-        self.assertTrue(first_line.strip().startswith('{'))
+        self.assertTrue(first_line.strip().decode('utf-8').startswith('{'))
-                    cert=self.cert
+                    cert=self.cert,
-    def send(self, anyway=False, prefetch=True):
+    def send(self, anyway=False, prefetch=None):
-            if prefetch or self.prefetch:
+            if prefetch is None:
-    StringIO, is_py2, chardet, json, builtin_str)
+    StringIO, is_py2, chardet, json, builtin_str, numeric_types)
-            if isinstance(fields[field], float):
+            if isinstance(fields[field], numeric_types):
-__build__ = 0x001305
+__version__ = '0.13.6'
-
+    # if this session was passed in, leave it open (and retain pooled connections);
-        prefetch=False,
+        prefetch=True,
-    def send(self, anyway=False, prefetch=False):
+    def send(self, anyway=False, prefetch=True):
-        prefetch=False,
+        prefetch=True,
-        pass
+        self.close()
-        prefetch=False,
+        prefetch=None,
-        :param prefetch: (optional) if ``True``, the response content will be immediately downloaded.
+        :param prefetch: (optional) whether to immediately download the response content. Defaults to ``True``.
-        prefetch = self.prefetch or prefetch
+        prefetch = prefetch if prefetch is not None else self.prefetch
-        assert ds2.prefetch
+        ds2 = pickle.loads(pickle.dumps(requests.session(prefetch=False)))
-        r = get(httpbin('get'))
+        r = get(httpbin('get'), prefetch=False)
-    DEFAULT_CA_BUNDLE_PATH)
+    to_key_val_list, DEFAULT_CA_BUNDLE_PATH)
-            for k, vs in params:
+            for k, vs in to_key_val_list(data):
-            files = files.items()
+        fields = to_key_val_list(self.data)
-from .utils import header_expand
+from .utils import header_expand, to_key_val_list
-        local_kwarg = list(local_kwarg.items())
+    local_kwarg = to_key_val_list(local_kwarg)
-        self.headers = headers or {}
+        self.headers = to_key_val_list(headers or [])
-        self.proxies = proxies or {}
+        self.proxies = to_key_val_list(proxies or [])
-        self.params = params or {}
+        self.params = to_key_val_list(params or [])
-        params = {} if params is None else params
+        data = [] if data is None else data
-                headers[k] = header_expand(v)
+            expanded = []
-            proxies=proxies,
+            proxies=to_key_val_list(proxies),
-from __builtin__ import str as builtin_str
+    StringIO, is_py2, chardet, json, builtin_str)
-                if isinstance(self.data, str) or hasattr(self.data, 'read'):
+                if isinstance(self.data, str) or isinstance(self.data, builtin_str) or hasattr(self.data, 'read'):
-        data = "test string data"
+        data = 'test string data'
-        self.assertEqual(t.get('headers').get('Content-Type'), 'text/plain')
+        self.assertEqual(t.get('headers').get('Content-Type'), '')
-        self.assertEqual(t.get('headers').get('Content-Type'), 'text/plain')
+        self.assertEqual(t.get('headers').get('Content-Type'), '')
-    for (k, v) in list(local_kwarg.items()):
+    for (k, v) in local_kwarg:
-
+    def test_params_accepts_kv_list(self):
-        raise http_error
+        if http_error_msg:
-            fields = list(dict(self.data).items())
+            fields = list(self.data)
-            fields = self.data.items()
+            fields = list(self.data.items())
-            fields = dict(self.data).items()
+            fields = list(dict(self.data).items())
-            message = 'Failed comparison for %s: %s != %s' % (attr, cookie_attr, expected_value)
+            message = 'Failed comparison for %s: %s != %s' % (attr,
-        r = get(httpbin('get') + '?test=true', params={'q': 'test'}, headers=heads)
+        r = get(httpbin('get') + '?test=true', params={'q': 'test'},
-        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)
+        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True,
-        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)
+        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True,
-        """Test the max_redirects config variable, normally and under safe_mode."""
+        """Test the max_redirects config variable, normally and under
-        self.assertRaises(requests.exceptions.TooManyRedirects, unsafe_callable)
+            requests.get(httpbin('redirect', '3'),
-        response = requests.get(httpbin('redirect', '3'), config=dict(safe_mode=True, max_redirects=2))
+        response = requests.get(httpbin('redirect', '3'),
-        self.assertTrue(isinstance(response.error, requests.exceptions.TooManyRedirects))
+        self.assertTrue(isinstance(response.error,
-        """Test that we send 'Connection: close' when keep_alive is disabled."""
+        """Test that we send 'Connection: close' when keep_alive is
-            post3 = post(url, data='[{"some": "json"}]')
+            post4 = post(url, data='[{"some": "json"}]')
-            post2 = post(url, files={'fname.txt': 'fdata', 'fname2.txt':'more fdata'})
+            post2 = post(url, files={'fname.txt': 'fdata',
-            post3 = post(url, files={'fname.txt': 'fdata', 'fname2.txt':open(__file__,'rb')})
+            post3 = post(url, files={'fname.txt': 'fdata',
-            self.assertTrue(rbody['files'].get('fname.txt'), None)
+            self.assertTrue(rbody['files'].get('fname.txt', None))
-    Requests. Recommended interface is with the Requests functions.
+    """The :class:`Request <Request>` object. It carries out all functionality
-        if isinstance(data, str):
+        if isinstance(data, (str, bytes)):
-                raise ValueError('Unable to encode lists with elements that are not 2-tuples.')
+                raise ValueError('Unable to encode lists with elements that '
-            fields = self.data.copy()
+            fields = self.data.items()
-            fields = dict(self.data)
+            fields = dict(self.data).items()
-        for (k, v) in list(files.items()):
+        for (k, v) in files:
-                
+            fields.append((k, (fn, fp.read())))
-            raise http_error
+        if 300 <= self.status_code < 400 and not allow_redirects:
-            except (RequestException, ConnectionError, HTTPError, socket.timeout) as e:
+            except (RequestException, ConnectionError, HTTPError,
-
+        # Use .netrc auth if none was provided.
-__build__ = 0x001304
+__version__ = '0.13.5'
-__build__ = 0x001302
+__version__ = '0.13.4'
-        assert r.content == None
+    # def test_invalid_content(self):
-    def test_safe_mode(self):
+    # def test_safe_mode(self):
-        safe = requests.session(config=dict(safe_mode=True))
+    #     safe = requests.session(config=dict(safe_mode=True))
-        assert isinstance(r.error, requests.exceptions.ConnectionError)
+    #     # Safe mode creates empty responses for failed requests.
-        assert isinstance(r.error, requests.exceptions.ConnectionError)
+    #     r = get('http://0.0.0.0:789/', session=safe)
-        assert isinstance(r.error, requests.exceptions.Timeout)
+    #     # When not in safe mode, should raise Timeout exception
-	
+
-from collections import deque
+from collections import MutableMapping
-from threading import RLock
+try: # Python 2.7+
-__all__ = ['RecentlyUsedContainer']
+__all__ = ['RecentlyUsedContainer']
-        self.is_valid = is_valid
+_Null = object()
-    away the least-recently-used keys beyond ``maxsize``.
+class RecentlyUsedContainer(MutableMapping):
-            old_entry.is_valid = False
+    :param maxsize:
-            num -= 1
+    :param dispose_func:
-        self.access_log_lock.release()
+    ContainerCls = OrderedDict
-        self.access_log_lock.release()
+    def __init__(self, maxsize=10, dispose_func=None):
-        return r
+        self._container = self.ContainerCls()
-        item = dict.get(self, key)
+        # Re-insert the item, moving it to the end of the eviction line.
-            raise KeyError(key)
+    def __delitem__(self, key):
-        self._push_entry(key)
+        if self.dispose_func:
-            self._prune_invalidated_entries()
+    def __len__(self):
-        return item
+    def __iter__(self):
-        self._push_entry(key)
+    def clear(self):
-        self._prune_entries(len(self) - self._maxsize)
+        if self.dispose_func:
-            return default
+    def keys(self):
-from socket import error as SocketError, timeout as SocketTimeout
+from socket import timeout as SocketTimeout
-try:   # Python 3
+try: # Python 3
-try:   # Python 3
+try: # Python 3
-try:   # Compiled with SSL?
+try: # Compiled with SSL?
-    try:   # Python 3
+    try: # Python 3
-except (ImportError, AttributeError):
+except (ImportError, AttributeError): # Platform-specific: No SSL.
-                conn.close()
+        except AttributeError: # self.pool is None
-        should be increased.
+        If the pool is already full, the connection is closed and discarded
-
+    def close(self):
-                (scheme, host, port) == (self.scheme, self.host, self.port))
+        return (scheme, host, port) == (self.scheme, self.host, self.port)
-        except (HTTPException, SocketError) as e:
+        except HTTPException as e:
-                # Put the connection back to be reused
+            if release_conn:
-                                redirect, assert_same_host)  # Try again
+                                redirect, assert_same_host,
-                                retries - 1, redirect, assert_same_host)
+                                retries - 1, redirect, assert_same_host,
-from .exceptions import HostChangedError
+from .connectionpool import connection_from_url, port_by_scheme
-        self.pools = RecentlyUsedContainer(num_pools)
+        self.pools = RecentlyUsedContainer(num_pools,
-    def connection_from_host(self, host, port=80, scheme='http'):
+    def connection_from_host(self, host, port=None, scheme='http'):
-        connection pools in our container most effectively.
+        If ``port`` isn't given, it will be derived from the ``scheme`` using
-        return self.connection_from_host(host, port=port, scheme=scheme)
+        u = parse_url(url)
-    def urlopen(self, method, url, **kw):
+    def urlopen(self, method, url, redirect=True, **kw):
-        Same as :meth:`urllib3.connectionpool.HTTPConnectionPool.urlopen`.
+        Same as :meth:`urllib3.connectionpool.HTTPConnectionPool.urlopen`
-        ``url`` must be absolute, such that an appropriate
+        The given ``url`` parameter must be absolute, such that an appropriate
-            return conn.urlopen(method, url, **kw)
+        u = parse_url(url)
-            return self.urlopen(method, e.url, **kw)
+        log.info("Redirecting %s -> %s" % (url, redirect_location))
-from .exceptions import HTTPError
+from .exceptions import DecodeError
-                                "failed to decode it." % content_encoding)
+            except (IOError, zlib.error):
-                 basic_auth=None):
+class Url(namedtuple('Url', ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment'])):
-        {'accept-encoding': 'gzip,deflate'}
+    Datastructure for representing an HTTP URL. Used as a return value for
-        headers['accept-encoding'] = accept_encoding
+    slots = ()
-        headers['user-agent'] = user_agent
+    def __new__(cls, scheme=None, auth=None, host=None, port=None, path=None, query=None, fragment=None):
-        headers['connection'] = 'keep-alive'
+    @property
-            b64encode(six.b(basic_auth)).decode('utf-8')
+    @property
-    return headers
+        if self.query is not None:
-    delimiter. Return two split parts.
+    delimiter. Return two split parts and the matched delimiter.
-        if not min_idx:
+        if min_idx is None or idx < min_idx:
-            min_idx = min(idx, min_idx)
+            min_delim = d
-        return s, ''
+    if min_idx is None or min_idx < 0:
-    return s[:min_idx], s[min_idx+1:]
+    return s[:min_idx], s[min_idx+1:], min_delim
-def get_host(url):
+def parse_url(url):
-    Given a url, return its scheme, host and port (None if it's not there).
+    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is
-    For example: ::
+    Partly backwards-compatible with :mod:`urlparse`.
-        ('http', 'google.com', 80)
+    Example: ::
-    scheme = 'http'
+    scheme = None
-    url, _path = split_first(url, ['/', '?', '#'])
+    url, path_, delim = split_first(url, ['/', '?', '#'])
-        _auth, url = url.split('@', 1)
+        auth, url = url.split('@', 1)
-    elif not host:
+    elif not host and url:
-    return scheme, host, port
+    if not path:
-        ``HTTPConnection`` object.
+        :class:`httplib.HTTPConnection` object.
-        return select([sock], [], [], 0.0)[0]
+        try:
-    except AttributeError:
+    except (ImportError, AttributeError):
-while allowing upstream changes.
+This module contains the path hack necessary for oauthlib to be vendored into
-    path = os.path.abspath('/'.join(__file__.split('/')[:-1]+['packages']))
+    directory = os.path.dirname(__file__)
-    from oauthlib.oauth1.rfc5849 import (Client, SIGNATURE_HMAC, SIGNATURE_TYPE_AUTH_HEADER)
+    from oauthlib.oauth1.rfc5849 import (Client, SIGNATURE_HMAC, SIGNATURE_TYPE_AUTH_HEADER)
-            http_error = HTTPError('%s Redirection: %s' % (self.status_code, self.content))
+            http_error = HTTPError('%s Redirection: %s' % (self.status_code, self.reason))
-            http_error = HTTPError('%s Client Error: %s' % (self.status_code, self.content))
+            http_error = HTTPError('%s Client Error: %s' % (self.status_code, self.reason))
-            http_error = HTTPError('%s Server Error: %s' % (self.status_code, self.content))
+            http_error = HTTPError('%s Server Error: %s' % (self.status_code, self.reason))
-            http_error = HTTPError('%s Redirection' % self.status_code)
+            http_error = HTTPError('%s Redirection: %s' % (self.status_code, self.content))
-            http_error = HTTPError('%s Client Error' % self.status_code)
+            http_error = HTTPError('%s Client Error: %s' % (self.status_code, self.content))
-            http_error = HTTPError('%s Server Error' % self.status_code)
+            http_error = HTTPError('%s Server Error: %s' % (self.status_code, self.content))
-
+        num_401_calls = r.request.hooks['response'].count(self.handle_401)
-        if 'digest' in s_auth.lower():
+        if 'digest' in s_auth.lower() and num_401_calls < 2:
-        #: up here.
+        #: up here. The list is sorted from the oldest to the most recent request.
-                if self.verify and isinstance(e, _SSLError):
+                if isinstance(e, _SSLError):
-                raise Timeout('Request timed out.')
+                else:
-                url = '%s&%s' % (url, enc_params)
+            if query:
-                url = '%s?%s' % (url, enc_params)
+                query = enc_params
-from . import __version__
+from .utils import default_user_agent
-        ]),
+    'User-Agent': default_user_agent(),
-    StringIO, is_py2, chardet)
+    StringIO, is_py2, chardet, json)
-import json
+try:
-    'Accept-Encoding': ', '.join(('identity', 'deflate', 'compress', 'gzip')),
+    'User-Agent': " ".join([
-import requests.compat import is_py2
+from requests.compat import is_py2
-    'requests.packages.chardet2',
+if is_py2:
-__build__ = 0x001301
+__version__ = '0.13.2'
-    setup
+    'requests.packages.oauthlib',
-    license=open("LICENSE").read(),
+    license=open('LICENSE').read(),
-    SIGNATURE_HMAC; SIGNATURE_TYPE_AUTH_HEADER
+    from ._oauth import (Client, SIGNATURE_HMAC, SIGNATURE_TYPE_AUTH_HEADER, extract_params)
-        decoded_body = extract_params(r.data)     
+        decoded_body = extract_params(r.data)
-            # if files are present the request will not have 
+            # of r.files, thus an extra check is performed. We know that
-                # to preserve body. 
+                # to preserve body.
-            if u_header in r.headers:               
+            if u_header in r.headers:
-    'requests.packages.urllib3.packages.ssl_match_hostname',
+    'requests.packages.urllib3.packages.ssl_match_hostname'
-from requests.compat import is_py3
+from requests.compat import is_py2
-requires = ['certifi>=0.0.7']
+requires = []
-    chardet_package = 'chardet>=1.0.0'
+if is_py2:
-    package_data={'': ['LICENSE', 'NOTICE']},
+    package_data={'': ['LICENSE', 'NOTICE'], 'requests': ['*.pem']},
-    chardet = None
+    StringIO, is_py2, chardet)
-    CERTIFI_BUNDLE_PATH = certifi.where()
+    from . import certs
-        if self.cert and self.verify:
+        if self.cert:
-try:
+try:  # Python 2.7+
-        http_version = getattr(conn, '_http_vsn_str', 'HTTP/?'),
+        http_version = getattr(conn, '_http_vsn_str', 'HTTP/?')
-            each redirect counts as a retry.
+            If True, automatically handle redirects (status codes 301, 302,
-    port = None
+    # While this code has overlap with stdlib's urlparse, it is much
-    # http://tools.ietf.org/html/rfc3986#section-3.2
+    # (http://tools.ietf.org/html/rfc3986#section-3.2)
-        url, port = url.split(':', 1)
+        _host, port = url.split(':', 1)
-    return scheme, url, port
+    elif not host:
-            post6 = post(url, files={'fname.txt': '\xe9'})
+            # Dirty hack to tide us over until 3.3.
-                    unicode(r.url), unicode(r.method), None, r.headers)
+                    unicode(r.full_url), unicode(r.method), None, r.headers)
-                    unicode(r.url), unicode(r.method), r.data, r.headers)
+                    unicode(r.full_url), unicode(r.method), r.data, r.headers)
-        httplib_response = conn.getresponse()
+        try: # Python 2.7+, use buffering of HTTP responses
-
+from uuid import uuid4
-    return "%s.%.3f.%d" % (_prefix, time.time(), _get_next_counter())
+def split_first(s, delims):
-        url, _path = url.split('/', 1)
+
-    if not sock: #Platform-specific: AppEngine
+    if not sock: # Platform-specific: AppEngine
-        if not select: #Platform-specific: AppEngine
+        if not select: # Platform-specific: AppEngine
-            return r
+        return r
-        testfile = tempfile.NamedTemporaryFile()
+        testfile = tempfile.NamedTemporaryFile(delete=False)
-            r = post(service('post'), data=open(testfile.name, "rb"),
+            data = open(testfile.name, "rb")
-            return urlparse(r).netloc
+            return urlparse(r.url).netloc
-        filecontent = "fooaowpeufbarasjhf"
+        filecontent = b"fooaowpeufbarasjhf"
-            self.assertEqual(rbody.get('data'), filecontent)
+            self.assertEqual(rbody.get('data'), filecontent.decode('ascii'))
-__build__ = 0x001300
+__version__ = '0.13.1'
-            return u''
+            return str('')
-        #: Dictionary or byte of request body data to attach to the
+        #: Dictionary, bytes or file stream of request body data to attach to the
-                if isinstance(self.data, str):
+                if isinstance(self.data, str) or hasattr(self.data, 'read'):
-    requires.append('certifi>=0.0.7')
+# certifi is a Python package containing a CA certificate bundle for SSL verification.
-requires = ['certifi>=0.0.7']
+requires = []
-                hook_data = hook(hook_data) or hook_data
+                _hook_data = hook(hook_data)
-__build__ = 0x001201
+__version__ = '0.13.0'
-            if len(h) == 2:
+            if len(h) == 2 and h.isalnum():
-    '''
+    """Un-escape any percent-escape sequences in a URI that are unreserved
-    except:
+    except ValueError:
-        #: Encoding to decode with when accessing r.content.
+        #: Encoding to decode with when accessing r.text.
-        no_proxy = filter(string.strip, self.proxies.get('no', '').split(','))
+        no_proxy = filter(lambda x:x.strip(), self.proxies.get('no', '').split(','))
-        if proxy:
+        if proxy and not any(map(_p.netloc.endswith, no_proxy)):
-                parts[i] = c + parts[i][2:]
+    '''
-    return ''.join(parts)
+        return ''.join(parts)
-        self.assertIsNone(cookies.get("key"))
+        self.assertTrue(cookies.get("key") is None)
-    :param config: (optional) A configuration dictionary.
+    :param config: (optional) A configuration dictionary. See ``request.defaults`` for allowed keys and their default values.
-                if self.store_cookies:
+                if self.config.get('store_cookies'):
-        :param config: (optional) A configuration dictionary.
+        :param config: (optional) A configuration dictionary. See ``request.defaults`` for allowed keys and their default values.
-            store_cookies=store_cookies,
+        config = {'store_cookies' : False}
-        self.assertEqual(cookies.get("key"), None)
+        cookies = requests.get(httpbin('cookies', 'set', 'key', 'value'), config = config).cookies
-        cookies_2 = requests.get(httpbin('cookies', 'set', 'key', 'value'), store_cookies = False,\
+        cookies_2 = requests.get(httpbin('cookies', 'set', 'key', 'value'), config = config,\
-        s.get(httpbin('cookies', 'set', 'key', 'value'), store_cookies = False)
+        s.get(httpbin('cookies', 'set', 'key', 'value'), config = config)
-            return self._find(name, domain, path)
+            return self._find_no_duplicates(name, domain, path)
-    def keys():
+    def keys(self):
-    def values():
+    def values(self):
-            values.append(cookie.values)
+            values.append(cookie.value)
-    def items():
+    def items(self):
-            items.append((cookies.name, cookie.values))
+            items.append((cookie.name, cookie.value))
-        return self._find(name)
+        return self._find_no_duplicates(name)
-        that match name and optionally domain and path."""
+        """Requests uses this method internally to get cookie values. Takes as args name 
-    # TODO docstrings
+        """Unlike a normal CookieJar, this class is pickleable."""
-        if there are multiple domains or paths in the jar. In that case, use the more
+        if there are more than one cookie with name. In that case, use the more
-        if there are multiple domains or paths in the jar. In that case, use the more
+        if there is already a cookie of that name in the jar. In that case, use the more
-        if cookie is not found."""
+        if cookie is not found and CookieConflictError if there are multiple cookies
-                        return cookie.value
+                        if toReturn != None: # if there are multiple cookies that meet passed in criteria
-        """Returns True if there are multiple domains or paths in the jar.
+    def _multipleDomains(self):
-        return False # there is only one domains and one path in jar
+        return False # there is only one domain in jar
-        """This is not currently implemented. Calling copy() will throw an exception."""
+        """This is not implemented. Calling this will throw an exception."""
-    def get_dict(self, domain, path):
+    def get_dict(self, domain=None, path=None):
-            # TODO double check this logic
+        """Dict-like __getitem__() for compatibility with client code. Throws exception
-        # consider testing for multiple domains
+        """Deletes a cookie given a name. Wraps cookielib.CookieJar's remove_cookie_by_name()."""
-        """We're probably better off forbidding this."""
+        """This is not currently implemented. Calling copy() will throw an exception."""
-        self.assertIsNone(cookies.get("key"))
+        self.assertEqual(cookies.get("key"), None)
-                extract_cookies_to_jar(self.cookies, self, resp)
+                # Add new cookies from the server. Don't if configured not to
-        """Sends the request. Returns True of successful, False if not.
+        """Sends the request. Returns True if successful, False if not.
-        dict.__delitem__(self, key)
+        dict.__delitem__(self, self.lower_keys.get(key.lower(), key))
-from .utils import randombytes, parse_dict_header
+from .utils import parse_dict_header
-                s += randombytes(8)
+                s += os.urandom(8)
-from .compat import basestring, bytes, str
+from .compat import quote, urlparse, basestring, bytes, str
-                del r.headers[u'Authorization']
+            u_header = unicode('Authorization')
-                print r.headers
+        """Add OAuth parameters to the request.
-        decoded_body = extract_params(r.data)
+        # extract_params will not give params unless the body is a properly
-        return r
+            # extract_params can only check the present r.data and does not know
-            self.config.setdefault(k, v)
+            self.config.setdefault(k, deepcopy(v))
-    
+
-    """ The URL provided was somehow invalid. """
+    """ The URL provided was somehow invalid. """
-        """Sends the request. Returns True of successful, False if not.
+        """Sends the request. Returns True if successful, False if not.
-    def get(self, name, domain=None, path=None, default=None):
+    def get(self, name, default=None, domain=None, path=None):
-from .exceptions import RequestException, ConnectionError, HTTPError
+from .exceptions import RequestException, ConnectionError, HTTPError
-            except (RequestException, ConnectionError, HTTPError) as e:
+            except (RequestException, ConnectionError, HTTPError, socket.timeout) as e:
-        jar.extract_cookies(res, req)
+    req = MockRequest(request)
-                        self.session.cookies.set_cookie(cookie)
+                for cookie in self.cookies:
-                    raise
+                # Send the request.
-                    raise
+            self._build_response(r)
-
+import requests
-__version__ = '0.12.01'
+__version__ = '0.12.1'
-__build__ = 0x001200
+__version__ = '0.12.01'
-                    files=self.files,
+                    files=files,
-                raise ValueError("Can't detect page encoding.")
+    @property
-            post4 = post(url, files={'fname.txt': u'fdata'})
+            post4 = post(url, files={'fname.txt': 'fdata'})
-            post6 = post(url, files={'fname.txt': u'\xe9'})
+            post6 = post(url, files={'fname.txt': '\xe9'})
-            if isinstance(fp, bytes):
+            if isinstance(fp, (bytes, str)):
-    is_py2)
+    StringIO, is_py2)
-            self.assertEqual(getattr(cookie, attr), expected_value, message)
+            cookie_attr = getattr(cookie, attr)
-    stream_decode_response_unicode, get_netrc_auth,
+    stream_decode_response_unicode, get_netrc_auth, get_environ_proxies,
-                self.proxies['https'] = os.environ['HTTPS_PROXY']
+            self.proxies = get_environ_proxies()
-            requests.get("http://httpbin.org/redirect/3", config=dict(max_redirects=2))
+            requests.get(httpbin('redirect', '3'), config=dict(max_redirects=2))
-        response = requests.get("http://httpbin.org/redirect/3", config=dict(safe_mode=True, max_redirects=2))
+        response = requests.get(httpbin('redirect', '3'), config=dict(safe_mode=True, max_redirects=2))
-from .compat import urlparse, str, is_py2
+from .compat import urlparse, str
-            self.cookies.set_cookie(cookie)
+        # (in safe mode, cookies may be None if the request didn't succeed)
-        self.assertGreaterEqual(len(c), 1)
+        self.assertTrue(len(c) >= 1)
-        self.assertGreaterEqual(len(s.cookies), 1)
+        self.assertTrue(len(s.cookies) >= 1)
-        self.assertIs(r.cookies, r2.cookies)
+        self.assertTrue(r.cookies is r2.cookies)
-        self.assertNotIn('Cookie', page['headers'])
+        self.assertTrue('Cookie' not in page['headers'])
-        self.assertGreaterEqual(num_github_cookies, 1)
+        self.assertTrue(num_github_cookies >= 1)
-        self.assertGreater(num_total_cookies, num_github_cookies)
+        self.assertTrue(num_total_cookies >= 2)
-    pass
+    chardet = None
-        # Fallback to auto-detected encoding if chardet is available.
+        # Fallback to auto-detected encoding.
-            encoding = self._detected_encoding()
+            if chardet is not None:
-__build__ = 0x001103
+__version__ = '0.12.0'
-HOOKS = ('args', 'pre_request', 'post_request', 'response')
+HOOKS = ('args', 'pre_request', 'pre_send', 'post_request', 'response')
-
+CONTENT_CHUNK_SIZE = 10 * 1024
-                    self._content = bytes().join(self.iter_content()) or bytes()
+                    self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()
-        self.files, self._enc_files = self._encode_files(files)
+        self.data = data
-            return data, data
+            return data
-            return data, data
+            return data
-            return result, urlencode(result, doseq=True)
+            return urlencode(result, doseq=True)
-            return data, data
+            return data
-            return None, None
+            return None
-        return files, (body, content_type)
+        return (body, content_type)
-        if self._enc_params:
+        enc_params = self._encode_params(self.params)
-                url = '%s&%s' % (url, self._enc_params)
+                url = '%s&%s' % (url, enc_params)
-                url = '%s?%s' % (url, self._enc_params)
+                url = '%s?%s' % (url, enc_params)
-            (body, content_type) = self._enc_files
+            (body, content_type) = self._encode_files(self.files)
-                body = self._enc_data
+                body = self._encode_params(self.data)
-            self.proxies['https'] = os.environ['HTTPS_PROXY']
+            if 'HTTP_PROXY' in os.environ:
-    def _encode_files(self,files):
+    def _encode_files(self, files):
-    def deregister_hook(self,event,hook):
+    def deregister_hook(self, event, hook):
-            if lines[-1][-1] == chunk[-1]:
+            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:
-        self._text = None
+
-            return 'utf-8'
+            pass
-import os
+"""
-from requests.compat import is_py3, is_py2
+from requests.compat import is_py3
-required = ['certifi>=0.0.7']
+# certifi is a Python package containing a CA certificate bundle for SSL verification.
-    required.append('chardet2')
+    chardet_package = 'chardet2'
-    packages.append('requests.packages.oreos')
+    chardet_package = 'chardet>=1.0.0'
-    install_requires=required,
+    install_requires=requires,
-
+        if self._text is not None:
-            pass
+            return 'utf-8'
-            cookiejar.set_cookie(create_cookie(name, value))
+        for name in cookie_dict:
-        for attr, expected_value in kwargs.iteritems():
+        for attr, expected_value in kwargs.items():
-
+    def test_cookies_on_redirects(self):
-                self.headers['Cookie'] = get_cookie_header(self.cookies, self)
+                cookie_header = get_cookie_header(self.cookies, self)
-    jar.extract_cookies(res, req)
+    """Extract the cookies from the response into a CookieJar.
-        return urlparse.urlparse(self._r.full_url).scheme
+        return urlparse(self._r.full_url).scheme
-        return urlparse.urlparse(self._r.full_url).netloc
+        return urlparse(self._r.full_url).netloc
-            return urlparse.urlparse(r).netloc
+            return urlparse(r).netloc
-    from .packages.oreos.monkeys import SimpleCookie
+    from Cookie import Morsel
-    from http.cookies import SimpleCookie
+    from http.cookies import Morsel
-from .packages.oreos.cookiejar import CookieJar
+from .cookies import cookiejar_from_dict, extract_cookies_to_jar, get_cookie_header
-    dict_from_string, stream_decode_response_unicode, get_netrc_auth,
+    stream_decode_response_unicode, get_netrc_auth,
-    SimpleCookie, is_py2)
+    cookielib, urlparse, urlunparse, urljoin, urlsplit, urlencode, str, bytes,
-        if isinstance(cookies, CookieJar):
+        if isinstance(cookies, cookielib.CookieJar):
-                self.cookies.update(cookies)
+            self.cookies = cookiejar_from_dict(cookies)
-                
+
-                self.cookies.extract_cookies(response, self)
+                extract_cookies_to_jar(self.cookies, self, resp)
-                    self.headers['Cookie'] = cookie_header
+                self.headers['Cookie'] = get_cookie_header(self.cookies, self)
-        self.cookies = {}
+        #: A CookieJar of Cookies the server sent back.
-    return c
+from .compat import cookielib
-        if isinstance(cookies, CookieJar):
+        if isinstance(cookies, cookielib.CookieJar):
-                self.cookies.update(cookies)
+            self.cookies = cookiejar_from_dict(cookies)
-        self.cookies.update(r.response.cookies)
+        for cookie in r.response.cookies:
-from .compat import quote, cookielib, SimpleCookie, is_py2, urlparse
+from .compat import quote, is_py2, urlparse
-        # add cookie to cookiejar
+    cj2 = cookiejar_from_dict(cookie_dict)
-
+#!/usr/bin/env python
-import sys
+class TestBaseMixin(object):
-class RequestsTestSuite(TestSetup, unittest.TestCase):
+class RequestsTestSuite(TestSetup, TestBaseMixin, unittest.TestCase):
-        assert c == _c
+        self.assertEqual(c, _c)
-        assert c == _c
+        self.assertEqual(c, _c)
-        assert c == _c
+        self.assertEqual(c, _c)
-        assert c == _c
+        self.assertEqual(c, _c)
-        self.assertEqual(s.cookies, ds.cookies)
+        # Cookie doesn't have a good __eq__, so verify manually:
-        self.cookies = dict(cookies or [])
+        if isinstance(cookies, CookieJar):
-
+                
-                    cookies = dict_from_string(cookie_header)
+                self.cookies.extract_cookies(response, self)
-                response.cookies = cookies
+                response.cookies = self.cookies
-                    cookie_header = c.output(header='', sep='; ').strip()
+            # Skip if 'cookie' header is explicitly set.
-            r = self._r.history[0]
+        if self._r.response.history:
-        return bool(self.history)
+        return bool(self._r.response.history)
-class CookieJar(cookielib.LWPCookieJar, collections.MutableMapping):
+class CookieJar(cookielib.CookieJar, collections.MutableMapping):
-
+from .packages.oreos.cookiejar import CookieJar
-            self.cookies.update(cookies)
+        if isinstance(cookies, CookieJar):
-        cookies = {} if cookies is None else cookies
+import urlparse
-            self._build_response(r)
+            # build_response can throw TooManyRedirects
-__build__ = 0x001102
+__version__ = '0.11.3'
-required = ['certifi>=0.0.7','oauthlib']
+required = ['certifi>=0.0.7']
-if is_py2:
+try:
-else:
+except (ImportError, SyntaxError):
-from oauthlib.common import extract_params
+    from oauthlib.common import extract_params
-                                     SIGNATURE_HMAC, SIGNATURE_TYPE_AUTH_HEADER)
+
-from .compat import urlparse, str
+from .compat import urlparse, str, is_py2
-            self.__dict__.update(r.__dict__)
+        # Multi-part file uploads.
-    SIGNATURE_TYPE_BODY)
+from oauthlib.oauth1.rfc5849 import (Client,
-        r.headers = headers
+        contenttype = r.headers.get('Content-Type', None)
-                         v.encode('utf-8') if isinstance(v, types.StringType) else v))
+                        (k.encode('utf-8') if isinstance(k, str) else k,
-        full_url, new_body, headers = self.client.sign(r.url, unicode(r.method), body, r.headers)
+        full_url, headers, new_body = self.client.sign(r.url, unicode(r.method), body, r.headers)
-            r.headers['Content-Type'] != 'application/x-www-form-urlencoded'):
+            (contenttype and contenttype != 'application/x-www-form-urlencoded')):
-            if isinstance(str, body):
+            if isinstance(body, str):
-
+        # Multi-part file uploads.
-        version of that.
+        Will successfully encode parameters when passed as a dict or a list of
-        if hasattr(data, 'items'):
+            params = list(data.items() if isinstance(data, dict) else data)
-            for k, vs in list(data.items()):
+            for k, vs in params:
-                                   v.encode('utf-8') if isinstance(v, str) else v))
+                    result.append(
-
+class OAuth1(AuthBase):
-required = ['certifi>=0.0.7',]
+required = ['certifi>=0.0.7','oauthlib']
-        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
+        :param auth: (optional) Auth tuple or callable to enable Basic/Digest/Custom HTTP Auth.
-__build__ = 0x001101
+__version__ = '0.11.2'
-_unreserved_set = frozenset(
+UNRESERVED_SET = frozenset(
-    return s
+    parts = uri.split('%')
-        self.assertEqual(response.url, httpbin('get/?' + query_unreserved))
+    # def test_session_with_escaped_url(self):
-    dict_from_string, stream_decode_response_unicode, get_netrc_auth, CA_BUNDLE_PATH)
+    dict_from_string, stream_decode_response_unicode, get_netrc_auth,
-                cert_loc = CA_BUNDLE_PATH
+                cert_loc = DEFAULT_CA_BUNDLE_PATH
-                cert_loc = __import__('certifi').where()
+                raise Exception("Could not find a suitable SSL CA certificate bundle.")
-        # Red Hat, CentOS, Fedora and friends:
+        # Red Hat, CentOS, Fedora and friends (provided by the ca-certificates package):
-        # Ubuntu and friends:
+        # Ubuntu, Debian, and friends (provided by the ca-certificates package):
-def get_ca_bundle_path():
+def get_os_ca_bundle_path():
-CA_BUNDLE_PATH = get_ca_bundle_path()
+# if certifi is installed, use its CA bundle;
-    dict_from_string, stream_decode_response_unicode, get_netrc_auth)
+    dict_from_string, stream_decode_response_unicode, get_netrc_auth, CA_BUNDLE_PATH)
-                
+
-            # Curl compatiblity.
+            # Curl compatibility.
-            if prefetch:
+            if prefetch or self.prefetch:
-        'params', 'config', 'verify', 'cert']
+        'params', 'config', 'verify', 'cert', 'prefetch']
-    """See defaults.py for valid schemas."""
+    """See defaults.py for valid schemas."""
-from .packages.urllib3.exceptions import MaxRetryError
+from .packages.urllib3.exceptions import MaxRetryError, LocationParseError
-    URLRequired, SSLError, MissingSchema, InvalidSchema)
+    URLRequired, SSLError, MissingSchema, InvalidSchema, InvalidURL)
-
+            try:
-        self.files = files
+        self.files = None
-                # TODO: Conflict?
+            (body, content_type) = self._enc_files
-        self._content_consumed = True        
+        self._content_consumed = True
-        return self.hooks[event].append(hook)
+        self.hooks[event].append(hook)
-UNRESERVED_SET = frozenset(
+_unreserved_set = frozenset(
-    return ''.join(parts)
+    res = uri.split('%')
-    #     self.assertEqual(response.url, httpbin('get/?' + query_unreserved))
+    def test_session_with_escaped_url(self):
-                def h(x):
+                def md5_utf8(x):
-                H = h
+                hash_utf8 = md5_utf8
-                def h(x):
+                def sha_utf8(x):
-                H = h
+                hash_utf8 = sha_utf8
-            KD = lambda s, d: H("%s:%s" % (s, d))
+            KD = lambda s, d: hash_utf8("%s:%s" % (s, d))
-            if H is None:
+            if hash_utf8 is None:
-                respdig = KD(H(A1), noncebit)
+                noncebit = "%s:%s:%s:%s:%s" % (nonce, ncvalue, cnonce, qop, hash_utf8(A2))
-                respdig = KD(H(A1), "%s:%s" % (nonce, H(A2)))
+                respdig = KD(hash_utf8(A1), "%s:%s" % (nonce, hash_utf8(A2)))
-    def iter_content(self, chunk_size=10 * 1024, decode_unicode=False):
+    def iter_content(self, chunk_size=1, decode_unicode=False):
-        #: :class:`Request <Request>`.
+        #: :class:`Request <Request>`. The dictionary values can be lists for representing
-    def test_no_conent(self):
+    def test_no_content(self):
-        self._content = None
+        self._content = False
-        if self._content is None:
+        if self._content is False:
-        self._content_consumed = True
+        self._content_consumed = True        
-    os.system('python test_requests.py')
+    os.system('python tests/test_requests.py')
-__version__ = '1.3'
+__version__ = 'dev'
-                   httplib_response.status, httplib_response.length))
+        # AppEngine doesn't have a version attr.
-        r = get(httpbin('/get'))
+        r = get(httpbin('get'))
-        r = get(httpbin('/get'))
+        r = get(httpbin('get'))
-        r = head(httpbin('/get'))
+        r = head(httpbin('get'))
-        r = get(httpbin('/get'), session=s)
+        r = get(httpbin('get'), session=s)
-    netrc_path = None
+    try:
-            netrc_path = loc
+        for loc in locations:
-        return netrc_path
+        # Abort early if there isn't one.
-    ri = urlparse(url)
+        ri = urlparse(url)
-    host = ri.netloc.split(':')[0]
+        # Strip port numbers from netloc
-        # we'll just skip netrc auth
+        try:
-    license=open("LICENSE").read(
+    license=open("LICENSE").read(),
-    license='ISC',
+    license=open("LICENSE").read(
-__build__ = 0x001100
+__version__ = '0.11.1'
-        allow_redirects=False,
+        allow_redirects=True,
-        :param allow_redirects: (optional) Boolean. Set to True if POST/PUT/DELETE redirect following is allowed.
+        :param allow_redirects: (optional) Boolean. Set to True by default.
-    except (NetrcParseError, IOError):
+    except (NetrcParseError, IOError, AttributeError):
-__version__ = '1.2.2'
+__version__ = '1.3'
-    TimeoutError)
+    connection_from_url
-from .filepost import encode_multipart_formdata
+from .util import make_headers, get_host
-except ImportError:
+except (ImportError, AttributeError):
-from .packages.ssl_match_hostname import match_hostname, CertificateError
+from .util import get_host, is_connection_dropped
-    LocationParseError,
+
-            if conn and conn.sock and is_connection_dropped(conn):
+            if conn and is_connection_dropped(conn):
-        conn.sock.settimeout(timeout)
+
-           by :class:`.RequestMethods`, such as :meth:`.request`.
+           by :class:`.RequestMethods`, such as :meth:`request`.
-            return True
+def iter_fields(fields):
-        form-data section.
+        Dictionary of fields or list of (key, value) field tuples.  The key is
-    for fieldname, value in six.iteritems(fields):
+    for fieldname, value in iter_fields(fields):
-        >>> manager = PoolManager()
+        >>> manager = PoolManager(num_pools=2)
-        >>> len(r.pools)
+        >>> len(manager.pools)
-                **kw):
+                **kw): # Abstract
-                                        **urlopen_kw)
+        # Normalize headers between different versions of Python
-                           headers=dict((k.lower(), v) for k,v in r.getheaders()),
+                           headers=headers,
-    URLRequired, SSLError)
+    URLRequired, SSLError, MissingSchema, InvalidSchema)
-            raise ValueError("Invalid URL %r: No schema supplied" % url)
+            raise MissingSchema("Invalid URL %r: No schema supplied" % url)
-            raise ValueError("Invalid scheme %r" % scheme)
+            raise InvalidSchema("Invalid scheme %r" % scheme)
-        gen = stream_untransfer(gen, self)
+        gen = stream_untransfer(generate(), self)
-        except HTTPError:
+        except RequestException:
-        :param **kwargs: Optional arguments that ``request`` takes.
+        :param \*\*kwargs: Optional arguments that ``request`` takes.
-        :param **kwargs: Optional arguments that ``request`` takes.
+        :param \*\*kwargs: Optional arguments that ``request`` takes.
-        :param **kwargs: Optional arguments that ``request`` takes.
+        :param \*\*kwargs: Optional arguments that ``request`` takes.
-        :param **kwargs: Optional arguments that ``request`` takes.
+        :param \*\*kwargs: Optional arguments that ``request`` takes.
-        :param **kwargs: Optional arguments that ``request`` takes.
+        :param \*\*kwargs: Optional arguments that ``request`` takes.
-        :param **kwargs: Optional arguments that ``request`` takes.
+        :param \*\*kwargs: Optional arguments that ``request`` takes.
-        :param **kwargs: Optional arguments that ``request`` takes.
+        :param \*\*kwargs: Optional arguments that ``request`` takes.
-    :param **kwargs: Optional arguments that ``request`` takes.
+    :param \*\*kwargs: Optional arguments that ``request`` takes.
-    :param **kwargs: Optional arguments that ``request`` takes.
+    :param \*\*kwargs: Optional arguments that ``request`` takes.
-    :param **kwargs: Optional arguments that ``request`` takes.
+    :param \*\*kwargs: Optional arguments that ``request`` takes.
-    :param **kwargs: Optional arguments that ``request`` takes.
+    :param \*\*kwargs: Optional arguments that ``request`` takes.
-    :param **kwargs: Optional arguments that ``request`` takes.
+    :param \*\*kwargs: Optional arguments that ``request`` takes.
-    :param **kwargs: Optional arguments that ``request`` takes.
+    :param \*\*kwargs: Optional arguments that ``request`` takes.
-    :param **kwargs: Optional arguments that ``request`` takes.
+    :param \*\*kwargs: Optional arguments that ``request`` takes.
-curious_george.patch_all(thread=False)
+curious_george.patch_all(thread=False, select=False)
-                      "!#$%&'*+-.^_`|~_" + _RFC2965Forbidden )
+                      "!#$%&'*+-.^_`|~_@" + _RFC2965Forbidden )
-__build__ = 0x001008
+__version__ = '0.11.0'
-            if type(self.cert) is tuple:
+        if self.cert and self.verify:
-    :param cert_file: (optional) ssl client cert file.
+    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
-        cert_file=None):
+        cert=None):
-        self.cert_file = cert_file
+        self.cert = cert
-                    session=self.session
+                    session=self.session,
-            conn.cert_file = self.cert_file
+        if self.cert:
-        'params', 'config', 'verify']
+        'params', 'config', 'verify', 'cert']
-        cert_file=None):
+        cert=None):
-        self.cert_file = cert_file
+        self.cert = cert
-        cert_file=None):
+        cert=None):
-            cert_file=cert_file,
+            cert=cert,
-        session=None):
+        session=None,
-        verify=True):
+        verify=True,
-        verify=None):
+        verify=None,
-from .compat import urlparse, str, bytes
+from .compat import urlparse, str
-
+
-import traceback
+def dict_to_sequence(d):
-            # try blindly encoding
+            # A LookupError is raised if the encoding was not found which could
-    c.load(s)
+    try:
-        cookies.update({k: v.value})
+        for k, v in list(c.items()):
-            raise HTTPError('%s Redirection' % self.status_code)
+            http_error = HTTPError('%s Redirection' % self.status_code)
-            raise HTTPError('%s Client Error' % self.status_code)
+            http_error = HTTPError('%s Client Error' % self.status_code)
-            raise HTTPError('%s Server Error' % self.status_code)
+            http_error = HTTPError('%s Server Error' % self.status_code)
-                    url = urljoin(r.url, url)
+                    url = urljoin(r.url,
-                if pending_bytes == '':
+                if not len(pending_bytes):
-        utf8_string = (u'SmÃ¶rgÃ¥s').encode('utf-8')
+        '''We need to be careful how we build the utf-8 string since
-        url = u'http://blip.fm/~1abvfu'
+        url = 'http://blip.fm/~1abvfu'
-    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=True):
+    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=None):
-                pass
+            encoding = self._detected_encoding()
-    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=None):
+    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=True):
-            if lines[-1].endswith(chunk[-1]):
+            if lines[-1][-1] == chunk[-1]:
-    def iter_lines(self, decode_unicode=None):
+    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=None):
-        for chunk in self.iter_content(chunk_size=10 * 1024, decode_unicode=decode_unicode):
+        for chunk in self.iter_content(
-        if not self.proxies:
+        if not self.proxies and self.config.get('trust_env'):
-        if not self.auth:
+        if not self.auth and self.config.get('trust_env'):
-            if not cert_loc:
+            if not cert_loc and self.config.get('trust_env'):
-            if not cert_loc:
+            if not cert_loc and self.config.get('trust_env'):
-__build__ = 0x001007
+__version__ = '0.10.8'
-
+
-                        url = url.decode('utf-8', 'ignore')
+                if pending_bytes == '':
-
+    def test_chunked_head_redirect(self):
-print r.text
+:encode_uri: If true, URIs will automatically be percent-encoded.
-        if self.config.get('encode_uri'):
+        if self.config.get('encode_uri', True):
-        assert request.path_url == "/get/test%20case"
+        self.assertEqual(request.path_url, "/get/test%20case")
-__build__ = 0x001006
+__version__ = '0.10.7'
-defaults['encode_urls'] = True
+defaults['encode_uri'] = True
-        if self.config.get('encode_urls'):
+        if self.config.get('encode_uri'):
-        url = requote_uri(url)
+        if self.config.get('encode_urls'):
-
+
-    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=None):
+    def iter_lines(self, decode_unicode=None):
-        for chunk in self.iter_content(chunk_size, decode_unicode=decode_unicode):
+        for chunk in self.iter_content(chunk_size=10 * 1024, decode_unicode=decode_unicode):
-            lines = chunk.splitlines(True)
+            lines = chunk.splitlines()
-                    pending = None
+            # An incomplete line.
-        # Yield the last line
+            for line in lines:
-            yield pending.rstrip()
+            yield pending
-        # a newline.
+        # Tests that trailing whitespaces within lines do not get stripped.
-            '''Untent his person and share the air with us?'''
+            '''Agamemnon  \n'''
-        self.assertEqual(lines, quote)
+        lines = list(r.iter_lines())
-        """Sends the request. Returns True of successful, false if not.
+        """Sends the request. Returns True of successful, False if not.
-            prefetch=prefetch,
+        prefetch=False,
-__build__ = 0x001005
+__version__ = '0.10.6'
-__version__ = '1.1'
+__version__ = '1.2.2'
-    from http.client import HTTPConnection, HTTPSConnection, HTTPException
+    from http.client import HTTPConnection, HTTPException
-    from httplib import HTTPConnection, HTTPSConnection, HTTPException
+    from httplib import HTTPConnection, HTTPException
-    from queue import Queue, Empty, Full
+    from queue import LifoQueue, Empty, Full
-    from Queue import Queue, Empty, Full
+    from Queue import LifoQueue, Empty, Full
-    BaseSSLError = None
+    pass
-from .exceptions import (SSLError,
+from .exceptions import (
-    EmptyPoolError,
+    QueueCls = LifoQueue
-        self.port = port
+        super(HTTPConnectionPool, self).__init__(host, port)
-        self.pool = Queue(maxsize)
+        self.pool = self.QueueCls(maxsize)
-        if not ssl:
+        if not ssl: # Platform-specific: Python compiled without +ssl
-            basic_auth.encode('base64').strip()
+            b64encode(six.b(basic_auth)).decode('utf-8')
-    if not poll:
+    if not poll: # Platform-specific
-                           "Max retries exceeded with url: %s" % url)
+        message = "Max retries exceeded with url: %s" % url
-                           "Tried to open a foreign host with url: %s" % url)
+        message = "Tried to open a foreign host with url: %s" % url
-    basestring = (str, bytes)
+from .packages.six import string_types as basestring
-__build__ = 0x001004
+__version__ = '0.10.5'
-                # print repr(self._content)
+                if self.status_code is 0:
-    'map',
+    'map', 'imap',
-    return [r.response for r in requests]
+    return [r.response for r in requests]
-if (sys.platform == 'win32') and ('HTTPBIN_URL' not in os.environ):
+if 'HTTPBIN_URL' not in os.environ:
-HTTPBIN_URL = os.environ.get('HTTPBIN_URL', 'http://0.0.0.0:%s/' % (PORT))
+HTTPBIN_URL = os.environ.get('HTTPBIN_URL')
-                self._content = bytes().join(self.iter_content()) or None
+                self._content = bytes().join(self.iter_content()) or bytes()
-    except NetrcParseError, IOError:
+    except (NetrcParseError, IOError):
-from .compat import basestring, bytes
+from .compat import basestring, bytes, str
-        return unicode(r.content, encoding, errors='replace')
+        return str(r.content, encoding, errors='replace')
-        return str(r.content, encoding, errors='replace')
+        return unicode(r.content, encoding, errors='replace')
-_RFC2965Forbidden = "[]:{}"
+_RFC2965Forbidden = "[]:{}="
-    except NetrcParseError:
+    except NetrcParseError, IOError:
-__build__ = 0x001003
+__version__ = '0.10.4'
-    elif isinstance(headers, unicode):
+    elif isinstance(headers, str):
-        return (_netrc[0 if _netrc[0] else 1], _netrc[2])
+        if _netrc:
-    dict_from_string, stream_decode_response_unicode)
+    dict_from_string, stream_decode_response_unicode, get_netrc_auth)
-from .compat import quote, cookielib, SimpleCookie, is_py2
+from .compat import quote, cookielib, SimpleCookie, is_py2, urlparse
-    for (k,v) in list(local_kwarg.items()):
+    for (k, v) in list(local_kwarg.items()):
-    kwargs.setdefault('allow_redirects', True)
+    kwargs.setdefault('allow_redirects', False)
-        kwargs.setdefault('allow_redirects', True)
+        kwargs.setdefault('allow_redirects', False)
-__build__ = 0x001002
+__version__ = '0.10.3'
-    def raise_for_status(self):
+    def raise_for_status(self, allow_redirects=True):
-        if (self.status_code >= 300) and (self.status_code < 400) and not self.rquest.allow_redirects:
+        if (self.status_code >= 300) and (self.status_code < 400) and not allow_redirects:
-        if (self.status_code >= 300) and (self.status_code < 400):
+        if (self.status_code >= 300) and (self.status_code < 400) and not self.rquest.allow_redirects:
-import sys, os
+import sys
-from requests.compat import str, bytes, StringIO
+from requests.compat import str, StringIO
-
+
-        r = get(httpbin('user-agent'), headers=heads);
+        r = get(httpbin('user-agent'), headers=heads)
-        r = get(httpbin('user-agent'), headers=heads);
+        r = get(httpbin('user-agent'), headers=heads)
-            self.assertEqual(rbody.get('form'), {}) # No form supplied
+            self.assertEqual(rbody.get('form'), {})  # No form supplied
-            r = get(service('get'), params=dict(test=['foo','baz']))
+            r = get(service('get'), params=dict(test=['foo', 'baz']))
-            r = post(service('post'), params=dict(test=['foo','baz']))
+            r = post(service('post'), params=dict(test=['foo', 'baz']))
-            self.assertEqual(rbody.get('form'), {}) # No form supplied
+            self.assertEqual(rbody.get('form'), {})  # No form supplied
-                data=dict(test2="foobar",test3=['foo','baz']))
+                params=dict(test=['foo', 'baz']),
-            self.assertEqual(rbody.get('form'), dict(test2='foobar',test3=['foo','baz']))
+            self.assertEqual(rbody.get('form'), dict(test2='foobar', test3=['foo', 'baz']))
-            )
+            response = get(url=url, hooks={'args': add_foo_header})
-                hooks = {
+            response = get(url=url,
-        r = requests.get(httpbin('post'), auth=('a', 'b'), data='\xff')
+        requests.get(httpbin('post'), auth=('a', 'b'), data='\xff')
-        # If we pass a legitimate URL with a scheme not supported 
+
-
+    elif headers is None:
-    dict_from_string, supported_schemes, stream_decode_response_unicode)
+    dict_from_string, stream_decode_response_unicode)
-        if not scheme in supported_schemes():
+        if not scheme in SCHEMAS:
-from .compat import quote, unquote, cookielib, SimpleCookie, is_py2
+from .compat import quote, cookielib, SimpleCookie, is_py2
-    for k,v in list(c.items()):
+    for k, v in list(c.items()):
-            if not len(headers) == i+1:
+            if not len(headers) == i + 1:
-
+
-from .compat import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, str, bytes, SimpleCookie, is_py3, is_py2
+    dict_from_string, supported_schemes, stream_decode_response_unicode)
-                    session = self.session
+                    proxies=self.proxies,
-                    pending_bytes-=len(chunk)
+                    pending_bytes -= len(chunk)
-                fp.read(2) # throw away crlf
+                fp.read(2)  # throw away crlf
-                    pending_bytes-=len(chunk)
+                    pending_bytes -= len(chunk)
-                fp.read(2) # throw away crlf
+                fp.read(2)  # throw away crlf
-            with open('test_requests.py') as f:
+            with open(__file__) as f:
-            with open('test_requests.py') as f:
+            with open(__file__) as f:
-            with open('test_requests.py') as f:
+            with open(__file__) as f:
-                    headers = {'User-Agent': 'requests-tests'})
+                    headers={'User-Agent': 'requests-tests'})
-        'params', 'config']
+        'params', 'config', 'verify']
-        )
+        self.init_poolmanager()
-
+    def __getstate__(self):
-    def test_useful_exception_for_invalid_schema(self):
+    def test_useful_exception_for_invalid_scheme(self):
-        # If we pass a legitimate URL with a schema not supported 
+        # If we pass a legitimate URL with a scheme not supported 
-    dict_from_string)
+    dict_from_string, supported_schemes)
-              requests.exceptions.URLRequired,
+        # If we pass a legitimate URL with a schema not supported 
-          self.fail()
+              'ftp://ftp.kernel.org/pub/')
-os.environ['HTTPBIN_URL'] = 'http://httpbin.org/'
+if (sys.platform == 'win32') and ('HTTPBIN_URL' not in os.environ):
-    os.environ['HTTPBIN_URL'] = 'http://httpbin.org/'
+os.environ['HTTPBIN_URL'] = 'http://httpbin.org/'
-
+        if isinstance(data, bytes):
-from .compat import basestring
+from .compat import basestring, bytes
-        buf = dec.decompress('')
+        buf = dec.decompress(bytes())
-            response.url = self.full_url.decode('utf-8')
+            if isinstance(self.full_url, bytes):
-                self._content = bytes('').join(self.iter_content()) or None
+                self._content = bytes().join(self.iter_content()) or None
-    
+
-    
+
-    
+
-    
+
-        async.delete 
+
-        
+
-       
+
-from __future__ import with_statement
+# Path hack.
-        self.assertEqual(response.url, httpbin('get/?' + query_unreserved))
+    # def test_unicode_headers(self):
-            post2 = post(url, files={'some': open('test_requests.py')})
+            with open('test_requests.py') as f:
-                         data={'some': 'data'})
+            with open('test_requests.py') as f:
-                headers = {'User-Agent': 'requests-tests'})
+            with open('test_requests.py') as f:
-    stream_decompress, guess_filename, requote_uri, dict_from_string)
+    get_encoding_from_headers, stream_untransfer, guess_filename, requote_uri,
-            gen = stream_decompress(gen, mode='deflate')
+        gen = stream_untransfer(gen, self)
-                self._content = self.raw.read()
+                self._content = bytes('').join(self.iter_content()) or None
-                        decode_content=True,
+                        decode_content=False,
-
+    def test_upload_binary_data(self):
-    return 'Basic ' + b64encode(("%s:%s" % (username, password)).encode('utf-8')).strip().decode('utf-8')
+    return 'Basic ' + b64encode(('%s:%s' % (username, password)).encode('latin1')).strip().decode('latin1')
-class RequestException(Exception):
+class RequestException(RuntimeError):
-            response.url = self.full_url
+            response.url = self.full_url.decode('utf-8')
-        url = (urlunparse([ scheme, netloc, path, params, query, fragment ]))
+        url = (urlunparse([scheme, netloc, path, params, query, fragment]))
-    stream_decompress, guess_filename, requote_path, dict_from_string)
+    stream_decompress, guess_filename, requote_uri, dict_from_string)
-        url = requote_path(url)
+        url = requote_uri(url)
-    """Re-quote the given URL path component.
+def requote_uri(uri):
-    This function passes the given path through an unquote/quote cycle to
+    This function passes the given URI through an unquote/quote cycle to
-    return quote(unquote_unreserved(path), safe="!#$%&'()*+,/:;=?@[]~")
+    return quote(unquote_unreserved(uri), safe="!#$%&'()*+,/:;=?@[]~")
-        path = requote_path(path)
+            if isinstance(params, str):
-                return '%s&%s' % (url, self._enc_params)
+                url = '%s&%s' % (url, self._enc_params)
-            return url
+                url = '%s?%s' % (url, self._enc_params)
-#       _RFC2068Forbidden is the list of forbidden chars we accept anyway
+#       _RFC2965Forbidden is the list of forbidden chars we accept anyway
-_RFC2068Forbidden = "[]:{}"
+_RFC2965Forbidden = "[]:{}"
-                      "!#$%&'*+-.^_`|~_" + _RFC2068Forbidden )
+                      "!#$%&'*+-.^_`|~_" + _RFC2965Forbidden )
-                      "!#$%&'*+-.^_`|~_" + "[]:{}")
+                      "!#$%&'*+-.^_`|~_" + _RFC2068Forbidden )
-                      "!#$%&'*+-.^_`|~[]_:{}" )
+                      "!#$%&'*+-.^_`|~_" + "[]:{}")
-             for part in parts)
+    return quote(unquote_unreserved(path), safe="!#$%&'()*+,/:;=?@[]~")
-    parts = (quote(unquote(part), safe="") for part in parts)
+    # Unquote only the unreserved characters
-        request = requests.Request("http://0.0.0.0/get/~test")
+        request = requests.Request("http://0.0.0.0/get/test case")
-        assert request.path_url == "/get/%7Etest"
+        assert request.path_url == "/get/test%20case"
-            path = requote_path(path)
+        path = requote_path(path)
-    return b"/".join(parts)
+    parts = path.split("/")
-_LegalChars       = string.ascii_letters + string.digits + "!#$%&'*+-.^_`|~[]_"
+_LegalChars       = ( string.ascii_letters + string.digits + 
-
+    elif isinstance(headers, unicode):
-    
+
-
+    def test_unicode_headers(self):
-~~~~~~~~~~~~~~~
+oreos.structures
-    elif isinstance(headers, str):
+    elif isinstance(headers, basestring):
-        except KeyError, e:
+        except KeyError as e:
-        except KeyError, e:
+        except KeyError as e:
-        except KeyError, e:
+        except KeyError as e:
-__version__ = '0.10.3'
+__version__ = '0.10.2'
-__version__ = '0.10.2'
+__version__ = '0.10.3'
-__build__ = 0x001001
+__version__ = '0.10.2'
-            content = str(self.content, encoding)
+            content = str(self.content, encoding, errors='replace')
-
+        if not path:
-    """Sends the request object using the specified pool. If a pool isn't 
+def send(r, pool=None, prefetch=False):
-        return pool.spawn(r.send)
+        return pool.spawn(r.send, prefetch=prefetch)
-    return gevent.spawn(r.send)
+    return gevent.spawn(r.send, prefetch=prefetch)
-    jobs = [send(r, pool) for r in requests]
+    jobs = [send(r, pool, prefetch=prefetch) for r in requests]
-
+                # Release the connection back into the pool.
-            
+
-        cookies = self.cookies
+
-                    cookies=cookies,
+                    cookies=self.cookies,
-            ):
+            while (('location' in r.headers) and
-from requests.compat import is_py3
+from requests.compat import is_py3, is_py2
-    ],
+    packages=packages,
-    str = unicode
+    str = unicode
-        path = quote(path.encode('utf-8'))
+        if is_py3:
-class RequestsTestSuite(unittest.TestCase):
+class TestSetup(object):
-        self.assertRaises(ValueError, requests.get, 'hiwpefhipowhefopw')
+        self.assertRaises(ValueError, get, 'hiwpefhipowhefopw')
-        r = requests.get(httpbin('/get'))
+        r = get(httpbin('/get'))
-        r = requests.get(httpbin('/get'))
+        r = get(httpbin('/get'))
-        r = requests.get(httpbin('redirect', '1'))
+        r = get(httpbin('redirect', '1'))
-        r = requests.get(httpbin('redirect', '1'), allow_redirects=False)
+        r = get(httpbin('redirect', '1'), allow_redirects=False)
-        r = requests.get(httpbin('user-agent'), headers=heads)
+        r = get(httpbin('user-agent'), headers=heads)
-        r = requests.get(httpbin('get') + '?test=true', params={'q': 'test'}, headers=heads)
+        r = get(httpbin('get') + '?test=true', params={'q': 'test'}, headers=heads)
-        r = requests.get(httpbin('user-agent'), headers=heads);
+        r = get(httpbin('user-agent'), headers=heads);
-        r = requests.get(httpbin('user-agent'), headers=heads);
+        r = get(httpbin('user-agent'), headers=heads);
-        r = requests.head(httpbin('/get'))
+        r = head(httpbin('/get'))
-        r = requests.put(httpbin('put'))
+        r = put(httpbin('put'))
-            r = requests.get(url, auth=auth)
+            r = get(url, auth=auth)
-            r = requests.get(url)
+            r = get(url)
-            r = s.get(url)
+            r = get(url, session=s)
-            r = requests.get(url, auth=auth)
+            r = get(url, auth=auth)
-            r = requests.get(url, auth=auth)
+            r = get(url, auth=auth)
-            r = requests.get(url)
+            r = get(url)
-            r = s.get(url)
+            r = get(url, session=s)
-            r = requests.get(url, auth=auth)
+            r = get(url, auth=auth)
-            r = requests.get(url)
+            r = get(url)
-            r = s.get(url)
+            r = get(url, session=s)
-            post = requests.post(url).raise_for_status()
+            post1 = post(url).raise_for_status()
-            self.assertEqual(post.status_code, 200)
+            post1 = post(url, data={'some': 'data'})
-            post2 = requests.post(url, files={'some': open('test_requests.py')})
+            post2 = post(url, files={'some': open('test_requests.py')})
-            post3 = requests.post(url, data='[{"some": "json"}]')
+            post3 = post(url, data='[{"some": "json"}]')
-                data={'some': 'data'})
+            post1 = post(url,
-            self.assertEqual(post.status_code, 200)
+            self.assertEqual(post1.status_code, 200)
-            post2 = requests.post(url,
+            post2 = post(url,
-            r = requests.get(service('status', '500'))
+            r = get(service('status', '500'))
-            r = requests.get(service('/get'))
+            r = get(service('/get'))
-            r = requests.get(service('status', '404'))
+            r = get(service('status', '404'))
-        r = requests.get(httpbin('status', '404'))
+        r = get(httpbin('status', '404'))
-        r = requests.get(httpbin('status', '200'))
+        r = get(httpbin('status', '200'))
-        self.assertRaises(HTTPError, requests.get, *args, **kwargs)
+        self.assertRaises(HTTPError, get, *args, **kwargs)
-        r = requests.get(httpbin('status', '200'))
+        r = get(httpbin('status', '200'))
-        r = requests.get(httpbin('gzip'))
+        r = get(httpbin('gzip'))
-            response = requests.get(url)
+            response = get(url)
-            requests.get(service('Ã¸'), params={'foo': 'foo'})
+            get(url, params={'foo': 'fÃ¸Ã¸'})
-            r = requests.get(service('basic-auth', 'user', 'pass'), auth=http_auth)
+            r = get(service('basic-auth', 'user', 'pass'), auth=http_auth)
-            r = requests.post(service('post'), data=dict(test='fooaowpeuf'))
+            r = post(service('post'), data=dict(test='fooaowpeuf'))
-            r = requests.post(service('post'), data='fooaowpeuf')
+            r = post(service('post'), data='fooaowpeuf')
-            r = requests.post(service('post'), params=dict(test='fooaowpeuf'))
+            r = post(service('post'), params=dict(test='fooaowpeuf'))
-            r = requests.post(
+            r = post(
-            r = requests.post(service('post'), data="foobar")
+            r = post(service('post'), data="foobar")
-    #     r = requests.get(u'http://â¡.ws/httpbin')
+    #     r = get(u'http://â¡.ws/httpbin')
-            r = requests.get(service('get'), params=dict(test=['foo','baz']))
+            r = get(service('get'), params=dict(test=['foo','baz']))
-            r = requests.post(service('post'), params=dict(test=['foo','baz']))
+            r = post(service('post'), params=dict(test=['foo','baz']))
-            r = requests.post(
+            r = post(
-            r = requests.get(service('redirect', '3'), allow_redirects=False)
+            r = get(service('redirect', '3'), allow_redirects=False)
-            r = requests.head(service('redirect', '3'), allow_redirects=False)
+            r = head(service('redirect', '3'), allow_redirects=False)
-            r = requests.get(service('redirect', '3'))
+            r = get(service('redirect', '3'))
-            r = requests.get(service('relative-redirect', '3'))
+            r = get(service('relative-redirect', '3'))
-        r = s.get(httpbin('/get'))
+        r = get(httpbin('/get'), session=s)
-        r1 = s.get(httpbin('user-agent'))
+        r1 = get(httpbin('user-agent'), session=s)
-        r2 = s.get(httpbin('user-agent'))
+        r2 = get(httpbin('user-agent'), session=s)
-        r3 = s.get(httpbin('user-agent'), headers=new_heads)
+        r3 = get(httpbin('user-agent'), headers=new_heads, session=s)
-            response = requests.get(
+            response = get(
-            response = requests.get(
+            response = get(
-        r = s.get(httpbin('cookies'))
+        r = get(httpbin('cookies'), cookies=_c, session=s)
-        r = s.get(httpbin('cookies'), cookies={})
+        r = get(httpbin('cookies'), cookies={}, session=s)
-        r = s.get(httpbin('cookies'), cookies={'bessie': None})
+        r = get(httpbin('cookies'), cookies={'bessie': None}, session=s)
-        r = s.get(httpbin('cookies'))
+        r = get(httpbin('cookies'), session=s)
-        r = s.get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True)
+        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)
-        r = s.get(httpbin('cookies'))
+        r = get(httpbin('cookies'), session=s)
-        r1 = s.get(httpbin('get'))
+        r1 = get(httpbin('get'), session=s)
-        r2 = s.get(httpbin('get'), params=params2)
+        r2 = get(httpbin('get'), params=params2, session=s)
-        r3 = s.get(httpbin('get'), params=params3)
+        r3 = get(httpbin('get'), params=params3, session=s)
-            r = requests.get(hah, allow_redirects=False)
+            r = get(hah, allow_redirects=False)
-        r = requests.get(hah, allow_redirects=False, config=config)
+        r = get(hah, allow_redirects=False, config=config)
-        r1 = requests.get(httpbin('get'), prefetch=False)
+        r1 = get(httpbin('get'), prefetch=False)
-        r2 = requests.get(httpbin('get'), prefetch=True)
+        r2 = get(httpbin('get'), prefetch=True)
-            r = requests.get(httpbin('stream', str(i)), prefetch=False)
+            r = get(httpbin('stream', str(i)), prefetch=False)
-        r = requests.get(httpbin('get'))
+        r = get(httpbin('get'))
-        r = safe.get('http://_/')
+        r = get('http://_/', session=safe)
-        r = safe.get('http://_/')
+        r = get('http://_/', session=safe)
-            requests.get,
+            get,
-        r = requests.get(httpbin('stream', '1000'), timeout=0.0001,
+        r = get(httpbin('stream', '1000'), timeout=0.0001,
-
+            
-__build__ = 0x001000
+__version__ = '0.10.1'
-        self.assertIsNone(r.content)
+        assert r.content is None
-            r = requests.get(httpbin('stream', '1000'), timeout=0.0001)
+        self.assertRaises(
-         assert isinstancer.error, requests.exceptions.ConnectionError)
+        assert isinstance(r.error, requests.exceptions.ConnectionError)
-         assert isinstance(r.error, requests.exceptions.Timeout)
+        assert isinstance(r.error, requests.exceptions.Timeout)
-            self.assertIsInstance(response.url, str)
+            assert isinstance(response.url, str)
-        self.assertIsInstance(r.error, requests.exceptions.ConnectionError)
+        assert isinstance(r.error, requests.exceptions.ConnectionError)
-        self.assertIsInstance(r.error, requests.exceptions.ConnectionError)
+         assert isinstancer.error, requests.exceptions.ConnectionError)
-        self.assertIsInstance(r.error, requests.exceptions.Timeout)
+         assert isinstance(r.error, requests.exceptions.Timeout)
-import unittest2 as unittest
+import unittest
-import unittest
+import unittest2 as unittest
-required = ['certifi>=0.0.4',]
+required = ['certifi>=0.0.7',]
-]
+required = ['certifi>=0.0.4',]
-    required.append('simplejson')
+        'requests.packages.urllib3.packages.mimetools_choose_boundary',
-        # 'Programming Language :: Python :: 3.1',
+        'Programming Language :: Python :: 3.0',
-
+from .compat import urlparse, str, bytes
-    from urllib import quote, unquote
+    from urllib import quote, unquote, urlencode
-from .compat import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote
+from .compat import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, str, bytes, SimpleCookie, is_py3, is_py2
-        #     path = path.encode('utf-8')
+        if is_py2:
-        # path = requote_path(path)
+            path = requote_path(path)
-                    from http.cookies import SimpleCookie
+    def __nonzero__(self):
-
+        if not content:
-from .compat import quote, unquote, cookielib, SimpleCookie
+from .compat import quote, unquote, cookielib, SimpleCookie, is_py2
-    L = [chr(random.randrange(0, 256)).encode('utf-8') for i in range(n)]
+    if is_py2:
-
+import json
-    import json
+
-            self.assertEqual(rbody.get('form'), {})
+
-            self.assertEqual(rbody.get('form'), {})
+            assert rbody.get('form') in (None, {})
-        r.raw = io.StringIO(quote)
+        r.raw = StringIO(quote)
-from .compat import quote, unquote, cookielib
+from .compat import quote, unquote, cookielib, SimpleCookie
-from select import poll, POLLIN
+from httplib import (HTTPConnection, HTTPSConnection, HTTPException,
-    from http.client import HTTP_PORT, HTTPS_PORT
+    from httplib import HTTPConnection, HTTPSConnection, HTTPException
-    from queue import Queue, Empty, Full
+    from Queue import Queue, Empty, Full
-        for _ in range(maxsize):
+        for _ in xrange(maxsize):
-    # poll-based replacement to select([conn.sock], [], [], 0.0)[0]:
+    if not poll:
-    from http.client import HTTPSConnection
+    from httplib import HTTPSConnection
-
+from __future__ import absolute_import
-    text_type = str
+    string_types = basestring,
-        return unbound.__func__
+        return unbound.im_func
-        return next(it)
+        return it.next()
-        return str(s, "unicode_escape")
+        return unicode(s, "unicode_escape")
-    StringIO = BytesIO = io.StringIO
+    import StringIO
-            if not isinstance(data, str):
+            if not isinstance(data, basestring):
-            if isinstance(sep, str):
+            if isinstance(sep, unicode):
-            if isinstance(end, str):
+            if isinstance(end, unicode):
-                if isinstance(arg, str):
+                if isinstance(arg, unicode):
-            space = str(" ")
+            newline = unicode("\n")
-    from urllib.parse import urlencode
+    from urllib import urlencode
-
+try:
-        self._body = body if body and isinstance(body, str) else None
+        self._body = body if body and isinstance(body, basestring) else None
-    from urlparse import urlparse, urlunparse, urljoin, urlsplit, quote, unquote
+    from urllib import quote, unquote
-# from .packages import oreos
+
-
+# ---------
-from urllib.request import parse_http_list as _parse_list_header
+from .compat import parse_http_list as _parse_list_header
-                H = lambda x: hashlib.md5(x).hexdigest()
+                def h(x):
-                H = lambda x: hashlib.sha1(x).hexdigest()
+                def h(x):
-from urlparse import urlparse
+# from urlparse import urlparse
-    return 'Basic %s' % b64encode('%s:%s' % (username, password))
+
-        self.password = str(password)
+        self.username = username
-                )
+                s = str(nonce_count).encode('utf-8')
-import urllib
+import urllib.request, urllib.parse, urllib.error
-from urlparse import urlparse, urlunparse, urljoin, urlsplit
+# from urlparse import urlparse, urlunparse, urljoin, urlsplit
-from .packages import oreos
+# from .packages import oreos
-    stream_decompress, guess_filename, requote_path)
+    stream_decompress, guess_filename, requote_path, dict_from_string)
-        for (k, v) in hooks.items():
+        for (k, v) in list(hooks.items()):
-        for (k, v) in self.config.get('base_headers', {}).items():
+        for (k, v) in list(self.config.get('base_headers', {}).items()):
-                    cookies = oreos.dict_from_string(cookie_header)
+                    cookies = dict_from_string(cookie_header)
-            response.url = self.full_url.decode('utf-8')
+            response.url = self.full_url
-        if hasattr(data, '__iter__'):
+        if hasattr(data, '__iter__') and not isinstance(data, str):
-            for k, vs in data.items():
+            for k, vs in list(data.items()):
-            return result, urllib.urlencode(result, doseq=True)
+                    result.append((k.encode('utf-8') if isinstance(k, str) else k,
-        scheme, netloc, path, params, query, fragment = urlparse(self.url)
+        scheme, netloc, path, params, query, fragment = urlparse(url)
-            raise ValueError("Invalid URL %r: No schema supplied" %self.url)
+            raise ValueError("Invalid URL %r: No schema supplied" % url)
-        netloc = netloc.encode('idna')
+        netloc = netloc.encode('idna').decode('utf-8')
-            path = path.encode('utf-8')
+        # if isinstance(path, str):
-        path = requote_path(path)
+        # path = requote_path(path)
-        url = str(urlunparse([ scheme, netloc, path, params, query, fragment ]))
+        # print([ scheme, netloc, path, params, query, fragment ])
-            if not isinstance(self.data, basestring):
+            if not isinstance(self.data, str):
-                for (k, v) in self.files.items():
+                for (k, v) in list(self.files.items()):
-                if isinstance(self.data, basestring):
+                if isinstance(self.data, str):
-                    for (k, v) in self.cookies.items():
+                    # c = oreos.monkeys.SimpleCookie()
-                except MaxRetryError, e:
+                except MaxRetryError as e:
-                except (_SSLError, _HTTPError), e:
+                except (_SSLError, _HTTPError) as e:
-            except RequestException, e:
+            except RequestException as e:
-    def __nonzero__(self):
+    def __bool__(self):
-        except UnicodeError, TypeError:
+            content = str(self.content, encoding)
-            except UnicodeError, TypeError:
+                content = str(content, encoding, errors='replace')
-_idmap = ''.join(chr(x) for x in xrange(256))
+_idmap = ''.join(chr(x) for x in range(256))
-    from httplib import HTTP_PORT, HTTPS_PORT
+    from http.client import HTTPConnection, HTTPSConnection, HTTPException
-    from Queue import Queue, Empty, Full
+    from queue import Queue, Empty, Full
-from urllib3.packages import six
+from .packages.ssl_match_hostname import match_hostname, CertificateError
-        for _ in xrange(maxsize):
+        for _ in range(maxsize):
-    from httplib import HTTPSConnection
+    from http.client import HTTPSConnection
-from __future__ import absolute_import
+
-    text_type = unicode
+    string_types = str,
-        return unbound.im_func
+        return unbound.__func__
-        return it.next()
+        return next(it)
-        return unicode(s, "unicode_escape")
+        return str(s, "unicode_escape")
-    StringIO = BytesIO = StringIO.StringIO
+    import io
-            if not isinstance(data, basestring):
+            if not isinstance(data, str):
-            if isinstance(sep, unicode):
+            if isinstance(sep, str):
-            if isinstance(end, unicode):
+            if isinstance(end, str):
-                if isinstance(arg, unicode):
+                if isinstance(arg, str):
-            space = unicode(" ")
+            newline = str("\n")
-    from urllib import urlencode
+    from urllib.parse import urlencode
-        self._body = body if body and isinstance(body, basestring) else None
+        self._body = body if body and isinstance(body, str) else None
-    if isinstance(local_kwarg, basestring):
+    if isinstance(local_kwarg, str):
-    for (k,v) in local_kwarg.items():
+    for (k,v) in list(local_kwarg.items()):
-        for (k, v) in defaults.items():
+        for (k, v) in list(defaults.items()):
-        for key, cb in self.hooks.iteritems():
+        for key, cb in list(self.hooks.items()):
-            for k, v in headers.items() or {}:
+            for k, v in list(headers.items()) or {}:
-for (code, titles) in _codes.items():
+for (code, titles) in list(_codes.items()):
-            self._lower_keys = dict((k.lower(), k) for k in self.iterkeys())
+            self._lower_keys = dict((k.lower(), k) for k in list(self.keys()))
-        return self.__dict__.get(key, default)
+        return self.__dict__.get(key, default)
-import cookielib
+# import cookielib
-import urllib
+import urllib.request, urllib.parse, urllib.error
-from urllib2 import parse_http_list as _parse_list_header
+from urllib.parse import quote, unquote
-        headers = headers.items()
+        headers = list(headers.items())
-    elif isinstance(headers, basestring):
+    elif isinstance(headers, str):
-        for (p_k, p_v) in params.items():
+        for (p_k, p_v) in list(params.items()):
-        return "".join(L)
+    L = [chr(random.randrange(0, 256)).encode('utf-8') for i in range(n)]
-            for cookie in cookies.values():
+    for _, cookies in list(cj._cookies.items()):
-    for k, v in cookie_dict.items():
+    for k, v in list(cookie_dict.items()):
-            return unicode(content, encoding)
+            return str(content, encoding)
-            return unicode(r.content, encoding)
+            return str(r.content, encoding)
-        return unicode(r.content, encoding, errors='replace')
+        return str(r.content, encoding, errors='replace')
-    return "/".join(parts)
+    parts = path.split(b"/")
-import StringIO
+
-import envoy
+# import envoy
-            time.sleep(1)
+            # c = envoy.connect('httpbin %s' % (PORT))
-        assert heads['User-agent'] in r.content
+        assert heads['User-agent'] in r.text
-        self.assertTrue(heads['User-agent'] in r.content)
+        self.assertTrue(heads['User-agent'] in r.text)
-        self.assertTrue(heads['user-agent'] in r.content)
+        self.assertTrue(heads['user-agent'] in r.text)
-            self.assertIsInstance(response.url, unicode)
+            self.assertIsInstance(response.url, str)
-            requests.get(url, params={u'fÃ¸Ã¸': u'fÃ¸Ã¸'})
+            requests.get(url, params={'foo': 'fÃ¸Ã¸'})
-            requests.get(service('Ã¸'), params={'foo': u'foo'})
+            requests.get(url, params={'foo': 'foo'})
-            self.assertEquals(r.status_code, 401)
+            self.assertEqual(r.status_code, 401)
-            self.assertEquals(r.url, service('post'))
+            self.assertEqual(r.status_code, 200)
-            rbody = json.loads(r.content)
+            rbody = json.loads(r.text)
-            self.assertEquals(rbody.get('data'), '')
+            self.assertEqual(rbody.get('form'), dict(test='fooaowpeuf'))
-            self.assertEquals(r.url, service('post'))
+            self.assertEqual(r.status_code, 200)
-            rbody = json.loads(r.content)
+            rbody = json.loads(r.text)
-            self.assertEquals(rbody.get('data'), 'fooaowpeuf')
+            self.assertEqual(rbody.get('form'), {})
-            self.assertEquals(r.url, service('post?test=fooaowpeuf'))
+            self.assertEqual(r.status_code, 200)
-            self.assertEquals(rbody.get('data'), '')
+            rbody = json.loads(r.text)
-            self.assertEquals(r.url, service('post?test=fooaowpeuf'))
+            self.assertEqual(r.status_code, 200)
-            self.assertEquals(rbody.get('data'), '')
+            rbody = json.loads(r.text)
-            self.assertEquals(r.headers['content-type'], 'application/json')
+            self.assertEqual(r.status_code, 200)
-            rbody = json.loads(r.content)
+            rbody = json.loads(r.text)
-            self.assertEquals(rbody.get('data'), 'foobar')
+            self.assertEqual(rbody.get('form'), {})
-            self.assertEquals(r.url, service('get?test=foo&test=baz'))
+            self.assertEqual(r.status_code, 200)
-            self.assertEquals(r.url, service('post?test=foo&test=baz'))
+            self.assertEqual(r.status_code, 200)
-            self.assertEquals(rbody.get('data'), '')
+            rbody = json.loads(r.text)
-            self.assertEquals(rbody.get('data'), '')
+            self.assertEqual(r.status_code, 200)
-            self.assertEquals(len(r.history), 0)
+            self.assertEqual(r.status_code, 302)
-            self.assertEquals(len(r.history), 0)
+            self.assertEqual(r.status_code, 302)
-            self.assertEquals(len(r.history), 3)
+            self.assertEqual(r.status_code, 200)
-            self.assertEquals(len(r.history), 3)
+            self.assertEqual(r.status_code, 200)
-        assert heads['User-agent'] in r1.content
+        assert heads['User-agent'] in r1.text
-        assert heads['User-agent'] in r2.content
+        assert heads['User-agent'] in r2.text
-        assert new_heads['User-agent'] in r3.content
+        assert new_heads['User-agent'] in r3.text
-            assert 'foo' in response.content
+            assert 'foo' in response.text
-            assert 'bar' in response.content
+            assert 'foo' in response.text
-        c = json.loads(r.content).get('cookies')
+        c = json.loads(r.text).get('cookies')
-        c = json.loads(r.content).get('cookies')
+        c = json.loads(r.text).get('cookies')
-        c = json.loads(r.content).get('cookies')
+        c = json.loads(r.text).get('cookies')
-        c = json.loads(r.content).get('cookies')
+        c = json.loads(r.text).get('cookies')
-        c = json.loads(r.content).get('cookies')
+        c = json.loads(r.text).get('cookies')
-        c = json.loads(r.content).get('cookies')
+        c = json.loads(r.text).get('cookies')
-        assert params['a'] in r1.content
+        assert params['a'] in r1.text
-        assert params2['b'] in r2.content
+        assert params['a'] in r2.text
-        assert params3['c'] in r3.content
+        assert not params['a'] in r3.text
-        assert r1.content
+        assert r1.text
-        r.raw = StringIO.StringIO(quote)
+        r.raw = io.StringIO(quote)
-        self.assertEquals(list(r.iter_lines()), [])
+        self.assertEqual(list(r.iter_lines()), [])
-        self.assertEquals(list(r.iter_content()), [])
+        self.assertEqual(list(r.iter_content()), [])
-# HTTPBIN_URL = 'http://127.0.0.1:8000/'
+HTTPBIN_URL = os.environ.get('HTTPBIN_URL', 'http://0.0.0.0:%s/' % (PORT))
-            _httpbin = True
+        if (not 'HTTPBIN_URL' in os.environ) and not _httpbin:
-        pass
+            _httpbin = True
-
+from select import poll, POLLIN
-try:
+try:   # Compiled with SSL?
-    SSLError,
+from .exceptions import (SSLError,
-xrange = six.moves.xrange
+from urllib3.packages.ssl_match_hostname import match_hostname, CertificateError
-    pass
+
-                # Either data is buffered (bad), or the connection is dropped.
+            if conn and conn.sock and is_connection_dropped(conn):
-                raise EmptyPoolError("Pool reached maximum size and no more "
+                raise EmptyPoolError(self,
-        conncetion pool.
+        connection pool.
-                get_host(url) == (self.scheme, self.host, self.port))
+                (scheme, host, port) == (self.scheme, self.host, self.port))
-            raise MaxRetryError(url)
+            raise MaxRetryError(self, url)
-            raise HostChangedError(host, url, retries - 1)
+            raise HostChangedError(self, url, retries - 1)
-            raise TimeoutError("Request timed out. (pool_timeout=%s)" %
+            raise TimeoutError(self, "Request timed out. (pool_timeout=%s)" %
-            raise TimeoutError("Request timed out. (timeout=%s)" %
+            raise TimeoutError(self, "Request timed out. (timeout=%s)" %
-## Exceptions
+## Base Exceptions
-class SSLError(Exception):
+class PoolError(HTTPError):
-        self.url = url
+## Leaf Exceptions
-    pass
+        self.url = url
-class HostChangedError(HTTPError):
+class HostChangedError(PoolError):
-            (original_host, new_url))
+    def __init__(self, pool, url, retries=3):
-        self.new_url = new_url
+        self.url = url
-class EmptyPoolError(HTTPError):
+class TimeoutError(PoolError):
-    from email.generator import _make_boundary as choose_boundary
+    from .packages.mimetools_choose_boundary import choose_boundary
-from .six import b
+from .packages import six
-from .connectionpool import get_host, connection_from_url
+from .connectionpool import get_host, connection_from_url, port_by_scheme
-            return self.urlopen(method, e.new_url, **kw)
+            return self.urlopen(method, e.url, **kw)
-        self._body = None
+        self._body = body if body and isinstance(body, basestring) else None
-        if preload_content:
+        if preload_content and not self._body:
-        data = self._fp and self._fp.read(amt)
+        if self._fp is None:
-                return data
+            if amt is None:
-                data = decoder(data)
+                if decode_content and decoder:
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-__version__ = '1.0.2'
+__version__ = '1.1'
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-from Queue import Queue, Empty, Full
+try:   # Python 3
-        except (Empty), e:
+        except Empty as e:
-        except (SocketTimeout), e:
+        except SocketTimeout as e:
-        except (BaseSSLError), e:
+        except BaseSSLError as e:
-        except (CertificateError), e:
+        except CertificateError as e:
-        except (HTTPException, SocketError), e:
+        except (HTTPException, SocketError) as e:
-                     "broken by '%r': %s" % (retries, e, url))
+                     "broken by '%r': %s" % (retries, err, url))
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-import httplib
+try:
-        conn = httplib.HTTPSConnection(host=self.host, port=self.port)
+        conn = HTTPSConnection(host=self.host, port=self.port)
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-    from cStringIO import StringIO
+    from mimetools import choose_boundary
-    from StringIO import StringIO # pylint: disable-msg=W0404
+    # I don't like using an undocumented function, but I don't yet know what it does
-    body = StringIO()
+    body = BytesIO()
-        boundary = mimetools.choose_boundary()
+        boundary = choose_boundary()
-        body.write('--%s\r\n' % (boundary))
+    for fieldname, value in six.iteritems(fields):
-                       (get_content_type(filename)))
+            body.write(b('Content-Type: %s\r\n\r\n' %
-            body.write('Content-Type: text/plain\r\n\r\n')
+            body.write(b'Content-Type: text/plain\r\n\r\n')
-        if isinstance(data, unicode):
+        if isinstance(data, six.text_type):
-        body.write('\r\n')
+        body.write(b'\r\n')
-    body.write('--%s--\r\n' % (boundary))
+    body.write(b('--%s--\r\n' % (boundary)))
-    content_type = 'multipart/form-data; boundary=%s' % boundary
+    content_type = b('multipart/form-data; boundary=%s' % boundary)
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-        except HostChangedError, e:
+        except HostChangedError as e:
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-from urllib import urlencode
+try:
-# Copyright 2008-2011 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
+# Copyright 2008-2012 Andrey Petrov and contributors (see CONTRIBUTORS.txt)
-    from StringIO import StringIO # pylint: disable-msg=W0404
+from io import BytesIO
-    gzipper = gzip.GzipFile(fileobj=StringIO(data))
+    gzipper = gzip.GzipFile(fileobj=BytesIO(data))
-                           headers=dict(r.getheaders()),
+                           # In Python 3, the header keys are returned capitalised
-                           strict=r.strict,
+                           strict=strict,
-        #XXX: why rstrip by default
+        #TODO: why rstrip by default
-            if not content:
+        if not content:
-            pass
+            except UnicodeError, TypeError:
-            content = unicode(content, encoding, errors='replace')
+            if not content:
-        """Content of the response, in unicode."""
+        """Content of the response, in unicode.
-                pass
+        # Fallback to auto-detected encoding if chardet is available.
-            except TypeError:
+                detected = chardet.detect(self.content) or {}
-    'certifi>=0.0.4'
+    'certifi>=0.0.4',
-__build__ = 0x000903
+__build__ = 0x001000
-__version__ = '0.9.3'
+__version__ = '0.10.0'
-        content = u''
+        content = None
-        r.hooks['response'] = self.handle_401
+        r.register_hook('response', self.handle_401)
-from .hooks import dispatch_hook
+from .hooks import dispatch_hook, HOOKS
-        self.hooks = hooks
+        self.hooks = {}
-            
+
-        
+
-            return hooks.get(key).__call__(hook_data) or hook_data
+        hooks = hooks.get(key)
-            traceback.print_exc()
+        if hasattr(hooks, '__call__'):
-:decode_unicode: Decode unicode responses automatically?
+:max_redirects: Maximum number of redirects allowed within a request.s
-    def _build_response(self, resp, is_error=False):
+    def _build_response(self, resp):
-            pass
+        if self.encoding:
-            pass
+            # Try to fall back:
-            
+
-    def iter_content(self, chunk_size=10 * 1024, decode_unicode=None):
+    def iter_content(self, chunk_size=10 * 1024, decode_unicode=False):
-        
+
-        """
+        """Content of the response, in bytes."""
-        content = self._content
+        self._content_consumed = True
-            # Try charset from content-type
+    @property
-                    pass
+        # Try charset from content-type
-                pass
+        content = u''
-    
+    pool = Pool(size) if size else None
-            response.url = self.full_url
+            response.url = self.full_url.decode('utf-8')
-__build__ = 0x000902
+__version__ = '0.9.3'
-
+        s.get('https://kennethreitz.com', verify=False)
-        print pool.full()
+
-    """Sends a given Request object."""
+def send(r, pool=None):
-        r._pools = pools
+    if pool != None:
-    return r.response
+    return gevent.spawn(r.send)
-        pool.join()
+        jobs = [pool.spawn(r.send) for r in requests]
-        gevent.joinall(jobs)
+        jobs = [gevent.spawn(r.send) for r in requests]
-
+    return [r.response for r in requests]
-                fp.read(2) #throw away crlf
+            if resp.chunk_left is not None:
-                #XXX correct line size
+                #XXX correct line size? (httplib has 64kb, seems insane)
-        verify=None):
+        verify=None,
-        self.session = None
+        self.session = session
-                    verify = self.verify
+                    verify = self.verify,
-            yield fp.read(resp.chunk_left)
+            if resp.chunk_left:
-                    break
+                pending_bytes = fp.readline(40).strip()
-        if getattr(self.raw._original_response, 'chunked', False):
+        if getattr(getattr(self.raw, '_original_response', None), 'chunked', False):
-            len_lines = len([l for l in r.iter_lines()])
+            lines = list(r.iter_lines())
-        gen = generate()
+
-                yield pending.rstrip()
+            # lines may be empty for the last chunk of a chunked response
-
+        #XXX: why rstrip by default
-__build__ = 0x000901
+__version__ = '0.9.2'
-            path = p_parsed.path + p_parsed.query
+            path = p_parsed.path
-import warnings
+import traceback
-            warnings.warn(str(why))
+        except Exception:
-    s = kwargs.get('session') or sessions.session()
+    s = kwargs.pop('session') if 'session' in kwargs else sessions.session()
-            raise MaxRetryError("Max retries exceeded for url: %s" % url)
+            raise MaxRetryError(url)
-                                   "open a foreign host: %s" % (host, url))
+            raise HostChangedError(host, url, retries - 1)
-            
+
-                                assert_same_host)
+        # Handle redirect?
-    pass
+    def __init__(self, url):
-    pass
+    def __init__(self, original_host, new_url, retries=3):
-)
+from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool
-
+log = logging.getLogger(__name__)
-        return conn.urlopen(method, url, assert_same_host=False, **kw)
+        try:
-                             cache_content=True)
+            return self.read(cache_content=True)
-    def read(self, amt=None, decode_content=True, cache_content=False):
+    def read(self, amt=None, decode_content=None, cache_content=False):
-    def from_httplib(r, **response_kw):
+    @classmethod
-                            **response_kw)
+        return ResponseCls(body=r,
-            raise ValueError("Invalid URL %r: No schema supplied" %r self.url)
+            raise ValueError("Invalid URL %r: No schema supplied" %self.url)
-            raise ValueError()
+            raise ValueError("Invalid URL %r: No schema supplied" %r self.url)
-__build__ = 0x000900
+__version__ = '0.9.1'
-:eager_mode: If true, Requests will raise errors immediately.
+:danger_mode: If true, Requests will raise errors immediately.
-defaults['eager_mode'] = False
+defaults['danger_mode'] = False
-            if self.config.get('eager_mode'):
+            if self.config.get('danger_mode'):
-        config = {'eager_mode': True}
+        config = {'danger_mode': True}
-            lines = chunk.splitlines()
+            lines = chunk.splitlines(True)
-                yield line
+                yield line.rstrip()
-            yield pending
+            yield pending.rstrip()
-    def iter_lines(self, newlines=None, decode_unicode=None):
+    def iter_lines(self, chunk_size=10 * 1024, decode_unicode=None):
-            yield ''.join(chunk)
+        pending = None
-copyright = u'2011. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
+copyright = u'2012. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-:copyright: (c) 2011 by Kenneth Reitz.
+:copyright: (c) 2012 by Kenneth Reitz.
-__copyright__ = 'Copyright 2011 Kenneth Reitz'
+__copyright__ = 'Copyright 2012 Kenneth Reitz'
-:copyright: (c) 2011 by Kenneth Reitz.
+:copyright: (c) 2012 by Kenneth Reitz.
-    stream_decode_gzip, stream_decode_deflate, guess_filename, requote_path)
+    get_encoding_from_headers, stream_decode_response_unicode,
-                        decode_content=False,
+                        decode_content=True,
-            gen = stream_decode_gzip(gen)
+            gen = stream_decompress(gen, mode='gzip')
-            gen = stream_decode_deflate(gen)
+            gen = stream_decompress(gen, mode='deflate')
-        pass
+def stream_decompress(iterator, mode='gzip'):
-    """Stream decodes a deflate-encoded iterator"""
+    if mode not in ['gzip', 'deflate']:
-        dec = zlib.decompressobj(-zlib.MAX_WBITS)
+    except zlib.error:
-        pass
+
-    decode_gzip, stream_decode_gzip, guess_filename, requote_path)
+    get_encoding_from_headers, stream_decode_response_unicode, decode_gzip,
-                chunk = []
+        chunk = []
-                        break
+        for c in self.iter_content(1, decode_unicode=decode_unicode):
-            gen = stream_decode_response_unicode(gen, self)
+            if c in newlines:
-        return gen
+        # Yield the remainder, in case the response
-        self.assertRaises(requests.exceptions.SSLError, requests.get, 'https://kennethreitz.com', verify=True)
+        self.assertRaises(requests.exceptions.SSLError, requests.get, 'https://kennethreitz.com')
-        s = requests.session(verify=True)
+        s = requests.session()
-__build__ = 0x000809
+__version__ = '0.9.0'
-        verify=None):
+        verify=True):
-__build__ = 0x000808
+__version__ = '0.8.9'
-    'certifi>=0.0.2'
+    'certifi>=0.0.4'
-    'certifi>=0.0.1'
+    'certifi>=0.0.2'
-        :param prefetch: (optional) if ``True``, the SSL cert will be verified. A CA_BUNDLE path can also be provided.
+        :param verify: (optional) if ``True``, the SSL cert will be verified. A CA_BUNDLE path can also be provided.
-__build__ = 0x000807
+__version__ = '0.8.8'
-        verify = verify or self.verify
+
-        config=None):
+        config=None,
-        prefetch=False):
+        prefetch=False,
-    URLRequired)
+    URLRequired, SSLError)
-        _poolmanager=None):
+        _poolmanager=None,
-                    # In safe mode, catch the exception and attach it to 
+                    # In safe mode, catch the exception and attach it to
-    s = session or sessions.session()
+    s = kwargs.get('session') or sessions.session()
-    config=None):
+def request(method, url, **kwargs):
-    )
+    return s.request(method=method, url=url, **kwargs)
-required = []
+required = [
-
+        if self.ca_certs:
-__build__ = 0x000806
+__version__ = '0.8.7'
-    Timeout, URLRequired, TooManyRedirects, HTTPError, ConnectionError)
+    ConnectionError, HTTPError, RequestException, Timeout, TooManyRedirects,
-                if not self.config.get('safe_mode', False):
+                # The inner try .. except re-raises certain exceptions as
-                if not self.config.get('safe_mode', False):
+                except (_SSLError, _HTTPError), e:
-                    yield chunk
+            while 1:
-    def test_null_response(self):
+    def test_safe_mode(self):
-        # Safe mode creates empty responses for failed requests.
+        safe = requests.session(config=dict(safe_mode=True))
-        r = requests.get('http://_/', config=dict(safe_mode=True))
+        r = safe.get('http://_/')
-        r = requests.get('http://_/', config=dict(safe_mode=True))
+        r = safe.get('http://_/')
-    def test_timeout(self):
+        self.assertIsInstance(r.error, requests.exceptions.ConnectionError)
-                yield chunk
+            # self.raw can be None if we're in safe_mode and the request failed
-            chunk = []
+            if self.raw is not None:
-                    break
+                while 1:
-                    chunk.append(c)
+                    if c in newlines:
-                yield ''.join(chunk)
+                # Yield the remainder, in case the response
-            while True:
+            while 1:
-            while 1:
+            while True:
-
+                else:
-            while True:
+            while 1:
-
+            # If the request fails but exceptions are suppressed,
-            while 1:
+            while True:
-            while True:
+            while 1:
-            while 1:
+            while True:
-            A2 = "%s:%s" % (r.request.method, path)
+            A1 = '%s:%s:%s' % (self.username, realm, self.password)
-__build__ = 0x000805
+__version__ = '0.8.6'
-        r.headers['Authorization'] = ('Basic %s' % auth_s)
+        r.headers['Authorization'] = _basic_auth_str(self.username, self.password)
-        r.headers['Proxy-Authorization'] = ('Basic %s' % auth_s)
+        r.headers['Proxy-Authorization'] = _basic_auth_str(self.username, self.password)
-            the connection back into the pool. If None, it takes the value of
+            back into the pool once a response is received (but will release if
-                               self.timeout)
+        except (Empty), e:
-    if '//' in url:
+    if '://' in url:
-			    self.__dict__.update(r.__dict__)
+                auth, url = _proxy.netloc.split('@', 1)
-from .auth import HTTPBasicAuth
+from .auth import HTTPBasicAuth, HTTPProxyAuth
-__build__ = 0x000804
+__version__ = '0.8.5'
-
+    def iter_lines(self, newlines=None, decode_unicode=None):
-            self.assertEquals(rbody.get('form'), dict(test2='foobar',test3='foo'))
+            self.assertEquals(rbody.get('form'), dict(test2='foobar',test3=['foo','baz']))
-__build__ = 0x000803
+__version__ = '0.8.4'
-    os.system("python setup.py sdist upload")
+if sys.argv[-1] == 'publish':
-    os.system("python test_requests.py")
+if sys.argv[-1] == 'test':
-    packages= [
+    packages=[
-                    preload_content=prefetch,
+                    preload_content=False,
-                self.response._content_consumed = True
+                # Save the response.
-    :param auth: (optional) Auth typle to enable Basic/Digest/Custom HTTP Auth.
+    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
-:max_redirects: Maximum njumber of redirects allowed within a request.
+:max_redirects: Maximum number of redirects allowed within a request.
-    """An HTTP error occured."""
+    """An HTTP error occurred."""
-    """A Connection error occured."""
+    """A Connection error occurred."""
-                # Fallback to None if there's no staus_code, for whatever reason.
+                # Fallback to None if there's no status_code, for whatever reason.
-            # Save original resopnse for later.
+            # Save original response for later.
-        :param auth: (optional) Auth typle to enable Basic/Digest/Custom HTTP Auth.
+        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
-This module provides utlity functions that are used within Requests
+This module provides utility functions that are used within Requests
-    ensure that it is fully and consistenty quoted.
+    ensure that it is fully and consistently quoted.
-            time.sleep(.01)
+            time.sleep(1)
-            time.sleep(1)
+            time.sleep(.01)
-__build__ = 0x000802
+__version__ = '0.8.3'
-from .sessions import session
+from . import sessions
-    use_session=None,
+    session=None,
-    :param use_session: (optional) A :class:`Session` object to be used for the request.
+    :param session: (optional) A :class:`Session` object to be used for the request.
-    s = use_session or session()
+    s = session or sessions.session()
-    s = session()
+    s = use_session or session()
-                datetime.now().isoformat(), self.method, self.url
+                datetime.now().isoformat(), self.method, url
-
+from .auth import HTTPBasicAuth
-        #: Authentication tuple to attach to :class:`Request <Request>`.
+        #: Authentication tuple or object to attach to :class:`Request <Request>`.
-
+            if isinstance(self.auth, tuple) and len(self.auth) == 2:
-        'requests.packages.urllib3'
+        'requests.packages.urllib3',
-    if encoding is None:
+
-    decoder = codecs.getincrementaldecoder(encoding)(errors='replace')
+    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')
-    get_unicode_from_response, stream_decode_response_unicode,
+    get_encoding_from_headers, stream_decode_response_unicode,
-                               'already consumed')
+        if self._content is None:
-            return None
+                self._content = self.raw.read()
-                self._content = decode_gzip(self._content)
+                content = decode_gzip(self._content)
-            self._content = get_unicode_from_response(self)
+
-        return self._content
+        return content
-                    c = SimpleCookie()
+                    c = oreos.monkeys.SimpleCookie()
-    cookies = MultiDict()
+    cookies = dict()
-        cookies.add(k, v.value)
+        cookies.update({k: v.value})
-from .core import *
+from .core import dict_from_string
-__build__ = 0x000801
+__version__ = '0.8.2'
-                        cookies.update({k: v.value})
+                    cookies = oreos.dict_from_string(cookie_header)
-
+# -*- coding: utf-8 -*-
-    :param files: (optional) Dictionary of 'filename': file-like-objects for multipart encoding upload.
+    :param files: (optional) Dictionary of 'name': file-like-objects (or {'name': ('filename', fileobj)}) for multipart encoding upload.
-                    url = urljoin(r.url, requote_path(url))
+                    url = urljoin(r.url, url)
-    Arguments should be considered non-positional.
+class AuthBase(object):
-    password = str(password)
+    def __call__(self, r):
-    return r
+class HTTPBasicAuth(AuthBase):
-    """
+class HTTPDigestAuth(AuthBase):
-    def handle_401(r):
+    def handle_401(self, r):
-            A1 = "%s:%s:%s" % (username, realm, password)
+            A1 = "%s:%s:%s" % (self.username, realm, self.password)
-                   'response="%s"' % (username, realm, nonce, path, respdig)
+                   'response="%s"' % (self.username, realm, nonce, path, respdig)
-
+    def __call__(self, r):
-        self.auth = auth_dispatch(auth)
+        self.auth = auth
-                    auth=self._auth,
+                    auth=self.auth,
-            r = auth_func(self, *auth_args)
+            r = self.auth(self)
-            auth = ('user', 'pass')
+            auth = HTTPBasicAuth('user', 'pass')
-            auth = ('digest', 'user', 'pass')
+            auth = HTTPDigestAuth('user', 'pass')
-        http_auth = ('user', 'BADpass')
+        http_auth = HTTPBasicAuth('user', 'BADpass')
-    decode_gzip, stream_decode_gzip, guess_filename)
+    decode_gzip, stream_decode_gzip, guess_filename, requote_path)
-                    url = urljoin(r.url, urllib.quote(urllib.unquote(url)))
+                    url = urljoin(r.url, requote_path(url))
-        path = urllib.quote(urllib.unquote(path))
+        path = requote_path(path)
-                    cookie_header = c.output(header='').strip()
+                    cookie_header = c.output(header='', sep='; ').strip()
-                    fields.update({k: (guess_filename(k) or k, v.read())})
+                    # support for explicit filename
-            raise TimeoutError("Request timed out after %f seconds" %
+            raise TimeoutError("Request timed out after %s seconds" %
-__build__ = 0x000800
+__version__ = '0.8.1'
-from urlparse import urlparse, urlunparse, urljoin
+from urlparse import urlparse, urlunparse, urljoin, urlsplit
-            response.url = self._build_url()
+            response.url = self.full_url
-    def _build_url(self):
+    @property
-        self.url = str(urlunparse([ scheme, netloc, path, params, query, fragment ]))
+
-                return '%s&%s' % (self.url, self._enc_params)
+            if urlparse(url).query:
-                return '%s?%s' % (self.url, self._enc_params)
+                return '%s?%s' % (url, self._enc_params)
-            return self.url
+            return url
-        url = self._build_url()
+        url = self.full_url
-                    url=url,
+                    url=self.path_url,
-                    _poolmanager=self._poolmanager
+                    _poolmanager=self._poolmanager,
-            conn = poolmanager.proxy_from_url(url)
+            conn = poolmanager.proxy_from_url(proxy)
-    from .__collections import MutableMapping
+from threading import RLock
-class RecentlyUsedContainer(MutableMapping):
+class RecentlyUsedContainer(dict):
-            self._container.pop(p.key, None)
+            dict.pop(self, p.key, None)
-        item = self._container.get(key)
+        item = dict.get(self, key)
-        self._container[key] = item
+        dict.__setitem__(self, key, item)
-        self._prune_entries(len(self._container) - self._maxsize)
+        self._prune_entries(len(self) - self._maxsize)
-        return self._container.__contains__(key)
+        self.access_lookup.pop(key, None)
-            raise TimeoutError("Request timed out after %s seconds" %
+            raise TimeoutError("Request timed out after %f seconds" %
-    decode_gzip, stream_decode_gzip)
+    decode_gzip, stream_decode_gzip, guess_filename)
-                    fields.update({k: (k, v.read())})
+                    fields.update({k: (guess_filename(k) or k, v.read())})
-        'requests.packages.poster'
+        'requests.packages.urllib3'
-from .__collections import MutableMapping
+try:
-from Cookie import SimpleCookie
+from Cookie import SimpleCookie
-    stream_decode_response_unicode, decode_gzip, stream_decode_gzip)
+    get_unicode_from_response, stream_decode_response_unicode,
-                    c.load(self.cookies)
+                    for (k, v) in self.cookies.items():
-
+
-            self.assertAlmostEquals(rbody.get('form'), {})
+            self.assertEquals(rbody.get('form'), {})
-from collections import deque, MutableMapping
+from collections import deque
-        config, prefetch
+        method=method,
-
+
-
+        #: Session.
-                    # params=self.params,
+                    params=self.session.params,
-    return request('GET', url, **kwargs)
+    return request('get', url, **kwargs)
-    return request('OPTIONS', url, **kwargs)
+    return request('options', url, **kwargs)
-    return request('HEAD', url, **kwargs)
+    return request('head', url, **kwargs)
-        # Expand header values
+        # Expand header values.
-        return self.request('GET', url, **kwargs)
+        return self.request('get', url, **kwargs)
-        return self.request('OPTIONS', url, **kwargs)
+        return self.request('options', url, **kwargs)
-        return self.request('HEAD', url, **kwargs)
+        return self.request('head', url, **kwargs)
-def post(url, data='', **kwargs):
+def post(url, data=None, **kwargs):
-def put(url, data='', **kwargs):
+def put(url, data=None, **kwargs):
-def patch(url, data='', **kwargs):
+def patch(url, data=None, **kwargs):
-
+
-                content_type = 'application/x-www-form-urlencoded'
+                if isinstance(self.data, basestring):
-            raise TimeoutError("Request timed out after %f seconds" %
+            raise TimeoutError("Request timed out after %s seconds" %
-defaults['pool_maxsize'] = 1
+defaults['pool_maxsize'] = 10
-        keep_alive=True):
+        config=None):
-            cookies = {}
+        # Default empty dicts for dict params.
-    def post(self, url, data='', **kwargs):
+    def post(self, url, data=None, **kwargs):
-    def put(self, url, data='', **kwargs):
+    def put(self, url, data=None, **kwargs):
-    def patch(self, url, data='', **kwargs):
+    def patch(self, url, data=None, **kwargs):
-        return self.request('patch', url,  data='', **kwargs)
+        return self.request('patch', url,  data=data, **kwargs)
-            self.assertEquals(rbody.get('form'), None)
+            self.assertAlmostEquals(rbody.get('form'), {})
-            self.assertEquals(rbody.get('form'), None)
+            self.assertEquals(rbody.get('form'), {})
-                    retries=self.config.get('max_retries', 0)
+                    retries=self.config.get('max_retries', 0),
-from . import poster
+from . import urllib3
-__version__ = '1.0.1'
+__version__ = '1.0.2'
-from collections import MutableMapping, deque
+from collections import deque, MutableMapping
-
+        self.access_log_lock = RLock()
-        # Invalidate old entry if it exists
+    def _invalidate_entry(self, key):
-        new_entry = AccessEntry(key)
+        return old_entry
-            del self.access_lookup[p.key]
+            self._container.pop(p.key, None)
-        return [e.key for e in self.access_log if e.is_valid]
+        "Return ordered access keys for inspection. Used for testing."
-            return
+            raise KeyError(key)
-        del self._access_lookup[key]
+        del self.access_lookup[key]
-class ProxyManager(object):
+class ProxyManager(RequestMethods):
-    return opener
+            # If prefetch is True, mark content as consumed.
-from .packages.urllib3 import connectionpool
+from .packages.urllib3 import connectionpool, poolmanager
-            conn = connectionpool.proxy_from_url()
+            conn = poolmanager.proxy_from_url(url)
-        config
+        config, prefetch
-        config=None):
+        config=None,
-        r.send()
+        r.send(prefetch=prefetch)
-    def send(self, anyway=False):
+    def send(self, anyway=False, prefetch=False):
-            conn = self._poolmanager.connection_from_url(url)
+        _p = urlparse(url)
-            conn = connectionpool.connection_from_url(url)
+            # Check to see if keep_alive is allowed.
-                    preload_content=False,
+                    preload_content=prefetch,
-from .sessions import session
+from .sessions import session, Session
-- :decode_unicode: - whether or not to accept unicode?
+Configurations:
-defaults['proxies'] = {}
+
-defaults['timeout_fallback'] = True
+
-
+        # Test session-level cookies.
-
+        cookies = self.cookies
-                    headers=self.headers,
+                    headers=headers,
-                    cookies=self.cookies,
+                    cookies=cookies,
-
+        # Check to see if keep_alive is allowed.
-# defaults['keep_alive'] = True
+defaults['keep_alive'] = True
-        conn = self._poolmanager.connection_from_url(url)
+        if self.config.get('keep_alive'):
-                # Create the connection.
+                # Send the request.
-    TooManyRedirects, HTTPError
+    RequestException, Timeout, URLRequired,
-        self.config = None
+        self.config = {}
-        self.cookies = None
+        self.cookies = {}
-        self.headers = headers
+        self.headers = dict(headers or [])
-        self.proxies = proxies
+        self.proxies = dict(proxies or [])
-        self.cookies = cookies
+        self.cookies = dict(cookies or [])
-        self.config = config
+        self.config = dict(config or [])
-            response.status_code = getattr(resp, 'status', None)
+            if resp:
-            response.headers = CaseInsensitiveDict(getattr(resp, 'headers', None))
+                # Make headers case-insensitive.
-            cookies = self.cookies or dict()
+                # Start off with our local cookies.
-                cookie_header = response.headers['set-cookie']
+                # Add new cookies from the server.
-                c.load(cookie_header)
+                    c = SimpleCookie()
-                    cookies.update({k: v.value})
+                    for k,v in c.items():
-            response.cookies = cookies
+                # Save cookies in Response.
-
+                if not self.config.get('safe_mode', False):
-    def test_nonurlencoded_post_query_and_data(self):
+    def test_nonurlencoded_postdata(self):
-                params='fooaowpeuf', data="foobar")
+            r = requests.post(service('post'), data="foobar")
-            self.assertEquals(r.url, service('post?fooaowpeuf'))
+
-        print r.url
+        # print r.headers
-        r = requests.get('http://somedomainthatclearlydoesntexistg.com', allow_redirects=False)
+        try:
-    """The authentication credentials provided were invalid."""
+class ConnectionError(RequestException):
-
+from .packages.urllib3.exceptions import MaxRetryError
-            )
+            try:
-        import requests
+    def test_session_persistent_cookies(self):
-        r = requests.get('http://somedomainthatclearlydoesntexistg.com')
+        # WARNING: if you're using a terrible DNS provider (comcast),
-from .api import request, get, head, post, patch, put, delete
+from .api import request, get, options, head, post, patch, put, delete
-__all__ = ('request', 'get', 'head', 'post', 'patch', 'put', 'delete')
+__all__ = ('request', 'get', 'options', 'head', 'post', 'patch', 'put', 'delete')
-    'get', 'head', 'post', 'put', 'patch', 'delete', 'request'
+    'get', 'options', 'head', 'post', 'put', 'patch', 'delete', 'request'
-    return Session(**kwargs)
+    return Session(**kwargs)
-__build__ = 0x000705
+__version__ = '0.7.6'
-            path = urlparse(r.request.url).path
+            p_parsed = urlparse(r.request.url)
-def map(requests, prefetch=True):
+def map(requests, prefetch=True, size=None):
-    gevent.joinall(jobs)
+    if size:
-__build__ = 0x000704
+__version__ = '0.7.5'
-        self._content = self.raw.read()
+        try:
-                    auth=self.auth,
+                    auth=self._auth,
-            self.auth = auth_args
+            self.auth = auth_args
-from .monkeys import HTTPRedirectHandler
+from .exceptions import Timeout, URLRequired, TooManyRedirects, HTTPError
-from .utils import add_dict_to_cookiejar, cookiejar_from_dict, header_expand
+from .utils import header_expand
-        self.cookies = cookielib.FileCookieJar()
+        self.cookies = {}
-from urllib2 import HTTPError
+from requests import HTTPError
-            print r.status_code
+            # print r.status_code
-        self.assertRaises(requests.HTTPError, r.raise_for_status)
+        self.assertRaises(HTTPError, r.raise_for_status)
-__build__ = 0x000703
+__version__ = '0.7.4'
-        args = dispatch_hook('args', hooks, args)
+        args = dispatch_hook('args', args['hooks'], args)
-        new_kwargs['return_response'] = False
+
-
+        if hasattr(data, '__iter__'):
-                fields = self.data.copy()
+
-                        c.load(self.cookies)
+            if self.cookies:
-                        cookie_header = c.output(header='').strip()
+                # Skip if 'cookie' header is explicitly set.
-                        self.headers['Cookie'] = cookie_header
+                    # Simple cookie with our dict.
-                )
+                    # Turn it into a header.
-                # resp = {}
+                    # Attach Cookie header to request.
-        # self.sent = self.response.ok
+            self._build_response(r)
-
+        return self.ok
-            return True
+        return True
-                               'already consumed')
+            raise RuntimeError(
-from .exceptions import Timeout, URLRequired, TooManyRedirects, RequestException
+from .exceptions import Timeout, URLRequired, TooManyRedirects, RequestException, HTTPError
-        self.response.ok = True
+
-        return not self.error
+        try:
-__build__ = 0x000702
+__version__ = '0.8.0'
-    TooManyRedirects
+    TooManyRedirects, HTTPError
-            raise RequestException('%s Redirection' % self.status_code)
+            raise HTTPError('%s Redirection' % self.status_code)
-            raise RequestException('%s Client Error' % self.status_code)
+            raise HTTPError('%s Client Error' % self.status_code)
-            raise RequestException('%s Server Error' % self.status_code)
+            raise HTTPError('%s Server Error' % self.status_code)
-import urllib2
+from Cookie import SimpleCookie
-        config=None):
+        config=None,
-        """Creates appropriate opener object for urllib2."""
+    # def _get_opener(self):
-        _handlers = []
+    #     _handlers = []
-            _handlers.append(urllib2.HTTPCookieProcessor(self.cookies))
+    #     if self.cookies is not None:
-            _handlers.append(urllib2.ProxyHandler(self.proxies))
+    #     if self.proxies:
-        _handlers.append(HTTPRedirectHandler)
+    #     _handlers.append(HTTPRedirectHandler)
-            return urllib2.urlopen
+    #     if not _handlers:
-            _handlers.extend(get_handlers())
+    #     if self.data or self.files:
-        opener = urllib2.build_opener(*_handlers)
+    #     opener = urllib2.build_opener(*_handlers)
-                opener.addheaders.remove((key, val))
+    #     if self.headers:
-        return opener.open
+    #     return opener.open
-                response.raw = resp
+            # Fallback to None if there's no staus_code, for whatever reason.
-                    response.cookies = dict_from_cookiejar(self.cookies)
+            # Make headers case-insensitive.
-                pass
+            # Add new cookies from the server.
-            response.url = getattr(resp, 'url', None)
+            response.url = self._build_url()
-                r.raw.close()
+                # r.raw.close()
-                    config=self.config
+                    config=self.config,
-        # Attach uploaded files.
+        # Nottin' on you.
-            register_openers()
+            if not isinstance(self.data, basestring):
-                self.files.update(self.data)
+        # TODO: Setup cookies.
-            data, headers = multipart_encode(self.files)
+        # Add content-type if it wasn't explicitly provided.
-                req.add_header(k, v)
+        conn = self._poolmanager.connection_from_url(url)
-                try:
+                if self.cookies:
-                    resp = opener(req, timeout=self.timeout)
+                    # Skip if 'cookie' header is explicitly set.
-                        raise
+                        # Simple cookie with our dict.
-                        socket.setdefaulttimeout(self.timeout)
+                        # Turn it into a header.
-                    resp = opener(req)
+                        # Attach Cookie header to request.
-                        socket.setdefaulttimeout(old_timeout)
+                # Create the connection.
-                    self.cookies.extract_cookies(resp, req)
+                # resp = {}
-                self._build_response(why, is_error=True)
+            except ArithmeticError:
-                self._build_response(resp)
+                self._build_response(r)
-        self.response = dispatch_hook('response', self.hooks, self.response)
+            # Response manipulation hook.
-        self.__dict__.update(r.__dict__)
+            # Post-request hook.
-        return self.sent
+            return self.sent
-            config=config
+            config=config,
-# defaults['max_connections'] = 10
+defaults['pool_connections'] = 10
-from .models import HTTPError, Request, Response
+from .models import Request, Response
-from urllib2 import HTTPError
+from .auth import dispatch as auth_dispatch
-from .utils import (dict_from_cookiejar, get_unicode_from_response, stream_decode_response_unicode, decode_gzip, stream_decode_gzip)
+from .utils import (
-    __attrs__ = ['headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks', 'params', 'config']
+    __attrs__ = [
-        config=None):
+        config=None,
-__build__ = 0x000702
+__version__ = '0.7.3'
-from .exceptions import Timeout, URLRequired, TooManyRedirects
+from .exceptions import Timeout, URLRequired, TooManyRedirects, RequestException
-~~~~~~~~~~~~~~~
+~~~~~~~~~~~~~~~~
-__build__ = 0x000701
+__version__ = '0.7.2'
-    return request('patch', url,  data='', **kwargs)
+    return request('patch', url,  data=data, **kwargs)
-__build__ = 0x000700
+__version__ = '0.7.1'
-        :param auth: (optional) AuthObject to enable Basic HTTP Auth.
+        :param auth: (optional) Auth typle to enable Basic/Digest/Custom HTTP Auth.
-    HTTPDigestAuthHandler, HTTPRedirectHandler)
+from .monkeys import HTTPRedirectHandler
-    def http_error_301(self, req, fp, code, msg, headers):
+    def _pass(self, req, fp, code, msg, headers):
-    http_error_302 = http_error_303 = http_error_307 = http_error_301
+    http_error_302 = _pass
-            raise
+        # Arguments manipulation hook.
-    def test_AUTH_HTTP_200_OK_GET(self):
+    def test_BASICAUTH_HTTP_200_OK_GET(self):
-    'Accept-Encoding': ', '.join([ 'identity', 'deflate', 'compress', 'gzip' ]),
+    'Accept-Encoding': ', '.join(('identity', 'deflate', 'compress', 'gzip')),
-    r.headers
+    def handle_401(r):
-def _patched(f):
+def patched(f):
-def _send(r, pools=None):
+def send(r, pools=None):
-request = _patched(api.request)
+get = patched(api.get)
-    jobs = [gevent.spawn(_send, r) for r in requests]
+    jobs = [gevent.spawn(send, r) for r in requests]
-    assert len(t) <= 2
+    assert len(t) >= 2
-    return (t[0], t[1:])
+    return (t[0], tuple(t[1:]))
-
+from .auth import dispatch as auth_dispatch
-        self.auth = auth
+        #: Authentication tuple to attach to :class:`Request <Request>`.
-    r.headers
+    r.headers
-        # if isinstance(auth, (list, tuple)):
+        if isinstance(auth, (list, tuple)):
-        # if self.auth:
+
-
+            self.assertEqual(r.status_code, 401)
-from base64 import base64
+from base64 import b64encode
-    auth_s = base64('%s:%s' % (username, password))
+    auth_s = b64encode('%s:%s' % (username, password))
-from base64 import encodestring as base64
+from base64 import base64
-    auth_s = base64('%s:%s' % (username, password)).replace('\n', '')
+    auth_s = base64('%s:%s' % (username, password))
-            auth = auth_manager.get_auth(self.url)
+        # if isinstance(auth, (list, tuple)):
-                urllib2.AbstractDigestAuthHandler)):
+        # if self.auth:
-                    self.auth.password)
+                # auth_manager.add_password(
-                auth_manager.add_auth(self.url, self.auth)
+                # self.auth.handler = self.auth.handler(auth_manager)
-            _handlers.append(self.auth.handler)
+            # _handlers.append(self.auth.handler)
-
+# -*- coding: utf-8 -*-
-    'User-Agent': 'python-requests/{0}'.format(__version__),
+    'User-Agent': 'python-requests/%s' % __version__,
-__build__ = 0x000607
+__version__ = '0.7.0'
-
+        # Attach uploaded files.
-            req = _Request(url, data=datagen, headers=headers, method=self.method)
+            data, headers = multipart_encode(self.files)
-            req = _Request(url, data=self._enc_data, method=self.method)
+            data = self._enc_data
-                    self.files.update(self.data)
+        if self.files:
-                req = _Request(url, data=datagen, headers=headers, method=self.method)
+            if self.data:
-        self._checks()
+        # Some people...
-# }
+# defaults['max_connections'] = 10
-    timeout=None, allow_redirects=False, proxies=None, hooks=None, return_response=True):
+    params=None,
-        timeout, allow_redirects, proxies, hooks, return_response
+        timeout, allow_redirects, proxies, hooks, return_response,
-from .utils import dict_from_cookiejar, get_unicode_from_response, stream_decode_response_unicode, decode_gzip, stream_decode_gzip
+from .utils import (dict_from_cookiejar, get_unicode_from_response, stream_decode_response_unicode, decode_gzip, stream_decode_gzip)
-        allow_redirects=False, proxies=None, hooks=None):
+        url=None,
-            settings.base_headers.update({'Accept-Encoding': 'gzip'})
+        if self.config.get('accept_gzip'):
-        for (k, v) in settings.base_headers.items():
+        for (k, v) in self.config.get('base_headers', {}).items():
-                if not len(history) < settings.max_redirects:
+                if not len(history) < self.config.get('max_redirects'):
-                    redirect=True
+                    url=url,
-            settings.verbose.write('%s   %s   %s\n' % (
+        if self.config.get('verbose'):
-                    if settings.timeout_fallback:
+                    if self.config.get('timeout_fallback'):
-                    if settings.timeout_fallback:
+                    if self.config.get('timeout_fallback'):
-            decode_unicode = settings.decode_unicode
+            decode_unicode = self.config.get('decode_unicode')
-        if settings.decode_unicode:
+        if self.config.get('decode_unicode'):
-from . import config
+from .defaults import defaults
-    __attrs__ = ['headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks', 'params']
+    __attrs__ = ['headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks', 'params', 'config']
-        params=None):
+        params=None,
-        timeout=None, allow_redirects=False, proxies=None, hooks=None, return_response=True):
+        params=None,
-            proxies = proxies or config.settings.proxies,
+            method=method,
-settings.timeout_fallback = True
+# -*- coding: utf-8 -*-
-	self.assertEqual(r.status_code, 200)
+        r = requests.get(httpbin('redirect', '1'))
-	self.assertEqual(r.status_code, 302)
+        r = requests.get(httpbin('redirect', '1'), allow_redirects=False)
-~~~~~~~~~~~~~~~
+~~~~~~~~~~~~~~~~~~~
-    def patch(url, data='', **kwargs):
+    def patch(self, url, data='', **kwargs):
-from .exceptions import RequestException, AuthenticationError, Timeout, URLRequired, InvalidMethod, TooManyRedirects
+from .exceptions import Timeout, URLRequired, TooManyRedirects
-        params=dict(), auth=None, cookiejar=None, timeout=None, redirect=False,
+        params=dict(), auth=None, cookies=None, timeout=None, redirect=False,
-        self.cookiejar = cookiejar
+        self.cookies = cookies
-            _handlers.append(urllib2.HTTPCookieProcessor(self.cookiejar))
+        if self.cookies is not None:
-                    response.cookies = dict_from_cookiejar(self.cookiejar)
+                if self.cookies:
-                    self.data, self.params, self.auth, self.cookiejar,
+                    self.data, self.params, self.auth, self.cookies,
-                    self.cookiejar.extract_cookies(resp, req)
+                if self.cookies is not None:
-
+from .sessions import session
-        proxies = proxies or config.settings.proxies,
+    s = session()
-
+from . import config
-        self._map_api_methods()
+        # self._map_api_methods()
-        (from __attrs__) that have been set, combining them with **kwargs.
+    def request(self, method, url,
-            def wrapper_func(*args, **kwargs):
+        method = str(method).upper()
-                _kwargs = {}
+        # Expand header values
-                    )
+        args = dict(
-                    r_val = kwargs.get(attr)
+        for attr in self.__attrs__:
-                    new_attr = merge_kwargs(r_val, s_val)
+            args[attr] = merge_kwargs(local_val, session_val)
-                        _kwargs[attr] = new_attr
+        # Arguments manipulation hook.
-                        _kwargs[k] = v
+        r = Request(**args)
-                return func(*args, **_kwargs)
+        # Pre-request hook.
-            return wrapper_func
+        # Don't send if asked nicely.
-                api.__all__)
+        kwargs.setdefault('allow_redirects', True)
-            self.httpbin = envoy.connect('gunicorn httpbin:app --bind=0.0.0.0:%s' % (PORT))
+            c = envoy.connect('gunicorn httpbin:app --bind=0.0.0.0:%s' % (PORT))
-__build__ = 0x000606
+__version__ = '0.6.7'
-    InvalidMethod, TooManyRedirects
+    TooManyRedirects
-    
+
-
+import requests
-PORT = os.environ.get('HTTPBIN_PORT', '7045')
+# TODO: Detect an open port.
-        s = Session()
+        s = requests.session()
-        s = Session()
+        s = requests.session()
-        s = Session()
+        s = requests.session()
-    return request('patch', url, **kwargs)
+    return request('patch', url,  data='', **kwargs)
-~~~~~~~~~~~~~
+#   __
-This module implements the main Requests system.
+"""
-from core import __version__
+"""
-import config
+from . import config
-import utils
+from . import utils
-This module impliments the Requests API.
+This module implements the Requests API.
-    """There was an ambiguous exception that occured while handling your
+    """There was an ambiguous exception that occurred while handling your
-    """Dipatches a hook dictionary on a given peice of data."""
+    """Dispatches a hook dictionary on a given piece of data."""
-        #: Float describ the timeout of the request.
+        #: Float describes the timeout of the request.
-        #: Dictonary of HTTP Headers to attach to the :class:`Request <Request>`.
+        #: Dictionary of HTTP Headers to attach to the :class:`Request <Request>`.
-                        # restore gobal timeout
+                        # restore global timeout
-        #: True if no :attr:`error` occured.
+        #: True if no :attr:`error` occurred.
-        #: Resulting :class:`HTTPError` of request, if one occured.
+        #: Resulting :class:`HTTPError` of request, if one occurred.
-        """Raises stored :class:`HTTPError` or :class:`URLError`, if one occured."""
+        """Raises stored :class:`HTTPError` or :class:`URLError`, if one occurred."""
-    """Returns a :class:`Session` for context-managment."""
+    """Returns a :class:`Session` for context-management."""
-    415: ('unspported_media_type', 'unspported_media', 'media_type'),
+    415: ('unsupported_media_type', 'unsupported_media', 'media_type'),
-    424: ('failed_depdendency', 'depdendency'),
+    424: ('failed_dependency', 'dependency'),
-Datastructures that power Requests.
+Data structures that power Requests.
-    # Remove trailing seperators.
+    # Remove trailing separators.
-    :param r: Reponse object to get unicode content from.
+    :param r: Response object to get unicode content from.
-__build__ = 0x000605
+__version__ = '0.6.6'
-    __attrs__ = ['headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks']
+    __attrs__ = ['headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks', 'params']
-        hooks=None):
+        hooks=None,
-__build__ = 0x000604
+__version__ = '0.6.5'
-        r2 = s.get(httpbin('user-agent'))
+        r2 = s.get(httpbin('user-agent'))
-    def __init__(self, **kwargs):
+    def __init__(self,
-                kwargs = dict(inst_attrs.items() + kwargs.items())
+
-                        inst_attrs['cookies'], kwargs['cookies']
+                        self.cookies, kwargs['cookies']
-                    kwargs['headers'].update(inst_attrs['headers'])
+                for attr in self.__attrs__:
-        with requests.settings(timeout=0.0000001):
+        with requests.settings(timeout=0.0000000001):
-HTTPBIN_URL = 'http://0.0.0.0:7045/'
+HTTPBIN_URL = 'http://0.0.0.0:%s/' % (PORT)
-            self.httpbin = envoy.connect('gunicorn httpbin:app --bind=0.0.0.0:7045')
+            self.httpbin = envoy.connect('gunicorn httpbin:app --bind=0.0.0.0:%s' % (PORT))
-import unittest
+import time
-HTTPBIN_URL = 'http://127.0.0.1:44444/'
+HTTPBIN_URL = 'http://0.0.0.0:7045/'
-            # print '!'/
+            self.httpbin = envoy.connect('gunicorn httpbin:app --bind=0.0.0.0:7045')
-            import time
+            _httpbin = True
-        assert 'httpbin' in r.url
+    # def test_idna(self):
-# HTTPSBIN_URL = 'https://httpbin-staging.ep.io/'
+HTTPBIN_URL = 'http://127.0.0.1:44444/'
-
+SERVICES = (httpbin, )
-        pass
+
-        pass
+        # self.httpbin.kill()
-        r = requests.get(httpbin('/'))
+        r = requests.get(httpbin('/get'))
-        r = requests.head(httpsbin('/'))
+        r = requests.head(httpbin('/get'))
-            r = requests.get(service('/'))
+            r = requests.get(service('/get'))
-            url = service('/')
+            url = service('/get')
-        r = s.get(httpsbin('/'))
+        r = s.get(httpbin('/get'))
-        return f(*args, return_response=False, **kwargs)
+        new_kwargs = dict(kwargs)
-__build__ = 0x000603
+__version__ = '0.6.4'
-                response.fo = resp
+                response.raw = resp
-                r.fo.close()
+                r.raw.close()
-        self.fo = None
+        self.raw = None
-                chunk = self.fo.read(chunk_size)
+                chunk = self.raw.read(chunk_size)
-        self._content = self.fo.read()
+        self._content = self.raw.read()
-    return request('GET', url, **kwargs)
+
-__build__ = 0x000601
+__version__ = '0.6.3'
-def map(requests):
+def map(requests, prefetch=True):
-    :param keep_alive: If True, HTTP Keep-Alive will be used.
+    :param prefetch: If False, the content will not be downloaded immediately.
-HTTPBIN_URL = 'http://httpbin.org/'
+HTTPBIN_URL = 'http://httpbin.ep.io/'
-        allow_redirects=False, proxies=None):
+        allow_redirects=False, proxies=None, hooks=None):
-def map(requests, keep_alive=False):
+def map(requests):
-    jobs = [gevent.spawn(_send, r, pools=pools) for r in requests]
+    jobs = [gevent.spawn(_send, r) for r in requests]
-    timeout=None, allow_redirects=False, proxies=None, hooks=None):
+    timeout=None, allow_redirects=False, proxies=None, hooks=None, return_response=True):
-        return f(*args, _return_request=True, **kwargs)
+        return f(*args, return_response=False, **kwargs)
-    ~~~~~~~~~~~~~~
+requests.async
-    :license: ISC, see LICENSE for more details.
+This module contains an asynchronous replica of ``requests.api``, powered
-from __future__ import absolute_import
+from . import api
-from urllib2 import HTTPError
+__all__ = (
-    pass
+def _patched(f):
-        pass
+    return [r.response for r in requests]
-defaults['accept_gzip'] = True
+defaults['base_headers'] = {
-from .hooks import dispatch_hooks
+from .hooks import dispatch_hook
-    args = dispatch_hooks('args', hooks, args)
+    args = dispatch_hook('args', hooks, args)
-    r = dispatch_hooks('pre_request', hooks, r)
+    r = dispatch_hook('pre_request', hooks, r)
-    r = dispatch_hooks('post_request', hooks, r)
+    r = dispatch_hook('post_request', hooks, r)
-    r.response = dispatch_hooks('response', hooks, r.response)
+    r.response = dispatch_hook('response', hooks, r.response)
-def dispatch_hooks(key, hooks, hook_data):
+def dispatch_hook(key, hooks, hook_data):
-from hooks import setup_hooks, dispatch_hooks
+from .hooks import dispatch_hooks
-    # cookies = cookiejar_from_dict(cookies if cookies is not None else dict())
+    if cookies is None:
-    args = dispatch_hooks(hooks['args'], args)
+    args = dispatch_hooks('args', hooks, args)
-    r = dispatch_hooks(hooks['pre_request'], r)
+    r = dispatch_hooks('pre_request', hooks, r)
-    r = dispatch_hooks(hooks['post_request'], r)
+    r = dispatch_hooks('post_request', hooks, r)
-    r.response = dispatch_hooks(hooks['response'], r.response)
+    r.response = dispatch_hooks('response', hooks, r.response)
-from cgi import parse_header
+import collections
-    """
+def dispatch_hooks(key, hooks, hook_data):
-    dispatching = dict([(k, v[:]) for k, v in default.items()])
+    hooks = (hooks or {}).get(key, [])
-
+            hook_data = hook(hook_data) or hook_data
-    return r
+    return hook_data
-            self._content = self.fo.read()
+        if self._content is not None:
-                pass
+        # Read the contents.
-
+    # cookies = cookiejar_from_dict(cookies if cookies is not None else dict())
-    
+
-        #: CookieJar to attach to :class:`Request <Request>`.
+        #: CookieDict to attach to :class:`Request <Request>`.
-__version__ = '0.6.2 (dev)'
+__version__ = '0.7.0 (dev)'
-        self.response.request.response = ref(self.response)()
+        self.response.request = self
-                    do_block = True
+                    do_block = False
-            a MaxRetryError exception.
+            Number of retries to allow before raising a MaxRetryError exception.
-                                                 connection=conn,
+                                                 connection=response_conn,
-__version__ = "$Rev$"
+__author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'
-from .poolmanager import PoolManager
+from .poolmanager import PoolManager, ProxyManager, proxy_from_url
-        return len(self.access_log)
+        return self._container.__len__()
-from .filepost import encode_multipart_formdata
+from .request import RequestMethods
-    EmptyPoolError)
+    EmptyPoolError,
-        self.ca_certs = None
+    cert_reqs = None
-class HTTPConnectionPool(ConnectionPool):
+class HTTPConnectionPool(ConnectionPool, RequestMethods):
-    host
+    :param host:
-        httplib.HTTPConnection()
+        :class:`httplib.HTTPConnection`.
-    port
+    :param port:
-        into httplib.HTTPConnection()
+        into :class:`httplib.HTTPConnection`.
-    strict
+    :param strict:
-        httplib.HTTPConnection()
+        :class:`httplib.HTTPConnection`.
-    timeout
+    :param timeout:
-    maxsize
+    :param maxsize:
-    block
+    :param block:
-    headers
+    :param headers:
-        Return a fresh HTTPConnection.
+        Return a fresh :class:`httplib.HTTPConnection`.
-        Otherwise, a fresh connection is returned.
+
-
+        """
-        Get a connection from the pool and perform an HTTP request.
+        Get a connection from the pool and perform an HTTP request. This is the
-        method
+           More commonly, it's appropriate to use a convenience method provided
-        body
+        :param body:
-        headers
+        :param headers:
-        retries
+        :param retries:
-        redirect
+        :param redirect:
-            If True, will make sure that the host of the pool requests is
+        :param assert_same_host:
-        timeout
+        :param timeout:
-        pool_timeout
+        :param pool_timeout:
-        release_conn
+        :param release_conn:
-        ``HTTPResponse.from_httplib(r, **response_kw)``
+        :param \**response_kw:
-    Same as HTTPConnectionPool, but HTTPS.
+    Same as :class:`.HTTPConnectionPool`, but HTTPS.
-                 cert_reqs=ssl.CERT_REQUIRED, ca_certs=None):
+                 cert_reqs='CERT_NONE', ca_certs=None):
-        Return a fresh HTTPSConnection.
+        Return a fresh :class:`httplib.HTTPSConnection`.
-        If true, adds 'connection: keep-alive' header.
+    :param keep_alive:
-    accept_encoding
+    :param accept_encoding:
-        True translates to 'gzip,deflate'.
+        ``True`` translates to 'gzip,deflate'.
-    user_agent
+    :param user_agent:
-    basic_auth
+    :param basic_auth:
-    http, google.com, 80
+    For example: ::
-    Given a url, return an HTTP(S)ConnectionPool instance of its host.
+    Given a url, return an :class:`.ConnectionPool` instance of its host.
-    before creating an HTTP(S)ConnectionPool instance.
+    Example: ::
-    HTTP(S)ConnectionPool. (e.g. timeout, maxsize, block)
+        >>> conn = connection_from_url('http://google.com/')
-from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, get_host
+from .connectionpool import (
-class PoolManager(object):
+class PoolManager(RequestMethods):
-    num_pools
+    :param num_pools:
-    Additional parameters are used to create fresh ConnectionPool instances.
+    :param \**connection_pool_kw:
-        Get a ConnectionPool based on the host, port, and scheme.
+        Get a :class:`ConnectionPool` based on the host, port, and scheme.
-        keywords are taken from the PoolManager constructor.
+        Similar to :func:`urllib3.connectionpool.connection_from_url` but
-        r = self.connection_from_host(host, port=port, scheme=scheme)
+        return self.connection_from_host(host, port=port, scheme=scheme)
-        return r
+    def urlopen(self, method, url, **kw):
-        return conn.urlopen(method, url, **kw)
+        kw['assert_same_host'] = False
-    preload_content
+    :param preload_content:
-    decode_content
+    :param decode_content:
-    original_response
+    :param original_response:
-        Similar to ``httplib.HTTPResponse.read(amt=None)``.
+        Similar to :meth:`httplib.HTTPResponse.read`, but with two additional
-        amt
+        :param amt:
-        decode_content
+        :param decode_content:
-        cache_content
+        :param cache_content:
-        urllib3.HTTPResponse object.
+        Given an :class:`httplib.HTTPResponse` instance ``r``, return a
-        self.response.request = self
+        self.response.request = ref(self)()
-        """Sends the shit."""
+        """Sends the HTTP Request. Populates `Request.response`.
-__build__ = 0x000601
+__version__ = '0.6.2'
-        print r.__dict__
+
-                (self.allow_redirects))
+                ((r.status_code is codes.see_other) or (self.allow_redirects))
-                url = get_clean_url(r.headers['location'], parent_url=self.url)
+                url = cleanup_url(r.headers['location'], parent_url=self.url)
-def get_clean_url(url, parent_url=None):
+def cleanup_url(url, parent_url=None):
-    url = get_clean_url(url)
+    url = cleanup_url(url)
-        return self.connection_from_host(host, port=port, scheme=scheme)
+        r = self.connection_from_host(host, port=port, scheme=scheme)
-    'https': 433,
+    'https': 443,
-        HTTPSConnection.__init__()
+    def __init__(self, **kwargs):
-        conn = self._get_conn(timeout=pool_timeout)
+        conn = None
-            # response.release_conn() is called (implicitly by response.read())
+            if release_conn:
-            if release_conn:
+            if conn and release_conn:
-                                        # tracks release state.
+                self._put_conn(conn)
-                 cert_reqs='CERT_NONE', ca_certs=None):
+                 cert_reqs=ssl.CERT_REQUIRED, ca_certs=None):
-        return  self.connection_from_host(host, port=port, scheme=scheme)
+        return self.connection_from_host(host, port=port, scheme=scheme)
-    'map', 'get', 'head', 'post', 'put', 'patch', 'delete', 'request'
+    'map',
-
+    :param keep_alive: If True, HTTP Keep-Alive will be used.
-    """Patches a given api function to not send."""
+    """Patches a given API function to not send."""
-    """Dispatcher."""
+    """Sends a given Request object."""
-    """Sends the requests... Asynchronously."""
+    """Concurrently converts a list of Requests to Responses.
-reqeusts.async
+requests.async
-This module contains an asyncronous replica of ``requests.api``, powered
+This module contains an asynchronous replica of ``requests.api``, powered
-    
+
-        'requests.packages.poster'
+        'requests.packages.urllib3'
-        allow_redirects=False, proxies=None, config=None, _pools=None):
+        allow_redirects=False, proxies=None, config=None, hooks=None,
-                self.cookies.update(r.cookies)
+
-                if self.config.get('keepalive') and pools:
+                if self.config.get('keep_alive') and pools:
-    config=None, _pools=None):
+    config=None, _pools=None, _return_request=False):
-                if self.config.get('keepalive'):
+                if self.config.get('keep_alive'):
-                self.cookies.update(r.cookies)
+                self.cookies.update(r.cookies or {})
-defaults['keepalive'] = True
+defaults['keep_alive'] = True
-This module impliments the Requests API.
+This module implements the Requests API.
-from urlparse import urlparse, urlunparse, urljoin
+from urlparse import urlparse
-from .utils import dict_from_cookiejar, get_unicode_from_response, stream_decode_response_unicode, decode_gzip, stream_decode_gzip
+from .utils import get_clean_url, dict_from_cookiejar, get_unicode_from_response, stream_decode_response_unicode, decode_gzip, stream_decode_gzip
-                    url = urljoin(r.url, str(urlunparse(parsed_url)))
+                url = get_clean_url(r.headers['location'], parent_url=r.url)
-         ))
+        self.url = get_clean_url(self.url)
-        self.cookies = cookies
+        self.cookies = cookies or {}
-                    # Merge local and session dictionaries.
+                    # Cookies persist.
-                return func(*args, **_kwargs)
+                r = func(*args, **_kwargs)
-    cookies = cookiejar_from_dict(cookies)
+    # cookies = cookiejar_from_dict(cookies)
-                # if self.cookiejar is not None:
+                if self.cookies is not None:
-def dict_from_cookiejar(cj):
+def dict_from_cookiejar(cookies):
-    for _, cookies in cj._cookies.items():
+    for _, cookies in cookies.items():
-                    fields.update({k: (None, v.read()))
+                    fields.update({k: (k, v.read())})
-                body = urlencode(self.data)
+                body = encode_params(self.data)
-                    body=self.data,
+                    body=body,
-# print dir(urllib3)
+from .packages.urllib3.filepost import encode_multipart_formdata
-        # Setup Files.
+        body = None
-            pass
+            if not isinstance(self.data, basestring):
-            pass
+        if self.data and (not body):
-                        maxsize=1)
+                        maxsize=1,
-                    connection = pools.connection_from_url(url, timeout=self.timeout)
+                    connection = pools.connection_from_url(url)
-                    )
+                        maxsize=1)
-    r.send(pools=_pools)
+    r.send()
-        allow_redirects=False, proxies=None, config=None):
+        allow_redirects=False, proxies=None, config=None, _pools=None):
-        self.headers = headers
+        self.headers = headers or {}
-        self.files = files
+        self.files = files or {}
-                if len(history) >= settings.max_redirects:
+                if len(history) >= self.config.get('max_redirects'):
-    def send(self, pools=None, anyway=False):
+    def send(self, anyway=False):
-                    connection = urllib3.connection_from_url(url, timeout=self.timeout)
+                if not self._pools:
-                    connection = pools.connection_from_url(url)
+                    # Create a connection.
-                    # preload_content=False
+                # Set the pools manager for redirections, if allowed.
-            num_pools=self.config.get('max_connections')
+        self.__pools = PoolManager(
-                    _kwargs['_pools'] = self.__pool
+                    _kwargs['_pools'] = self.__pools
-                self._put_conn(conn)
+                response.release_conn() # Equivalent to self._put_conn(conn) but
-                    preload_content=do_block
+                    preload_content=do_block,
-
+_Default = object()
-    def _make_request(self, conn, method, url, **httplib_request_kw):
+    def _make_request(self, conn, method, url, timeout=_Default,
-        conn.sock.settimeout(self.timeout)
+        conn.sock.settimeout(timeout)
-                release_conn=None, **response_kw):
+                redirect=True, assert_same_host=True, timeout=_Default,
-    def connection_from_url(self, url):
+    def connection_from_host(self, host, port=80, scheme='http'):
-        keywords are taken from the PoolManager constructor.
+        Get a ConnectionPool based on the host, port, and scheme.
-        scheme, host, port = get_host(url)
+        pool_key = (scheme, host, port)
-
+    def connection_from_url(self, url):
-        "Same as HTTP(S)ConnectionPool.urlopen"
+        "Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute."
-                response.raw = resp
+            # Make headers case-insensitive.
-                pass
+            # Save original resopnse for later.
-                    connection = pools.connection_from_url(url, timeout=self.timeout)
+                    connection = pools.connection_from_url(url)
-        if settings.decode_unicode:
+        if self.config.get('decode_unicode'):
-                    _kwargs['_pool'] = self.__pool
+                    _kwargs['_pools'] = self.__pool
-    config=None, _connection=None):
+    config=None, _pools=None):
-    :param _connection: (optional) An HTTP Connection to re-use.
+    :param _pools: (optional) An HTTP PoolManager to use.
-    r.send(connection=_connection)
+    r.send(pools=_pools)
-    def send(self, connection=None, anyway=False):
+    def send(self, pools=None, anyway=False):
-                if not connection:
+                if not pools:
-        # Map and wrap requests.api methods
+        # Map and wrap requests.api methods.
-    If a key in the dictionary is set to None, i
+    If a local key in the dictionary is set to None, it will be removed.
-                for (k, v) in kwargs:
+                for (k, v) in kwargs.items():
-                kwargs = dict(inst_attrs.items() + kwargs.items())
+                # Argument collector.
-                #     )
+                # Merge local and session arguments.
-                    kwargs['headers'].update(inst_attrs['headers'])
+                    # Merge local and session dictionaries.
-                return func(*args, **kwargs)
+                    # Skip attributes that were set to None.
-import config
+from ._config import get_config
-    _connection=None):
+    config=None, _connection=None):
-        timeout=timeout or config.settings.timeout,
+        timeout=timeout or config.get('timeout'),
-        proxies=proxies or config.settings.proxies,
+        proxies=proxies or config.get('proxies'),
-from .config import get_config
+from ._config import get_config
-            settings.base_headers.update({'Accept-Encoding': 'gzip'})
+        if self.config.get('accept_gzip'):
-        for (k, v) in settings.base_headers.items():
+        for (k, v) in self.config.get('base_headers').items():
-from .config import get_config
+from ._config import get_config
-def merge_kwargs(local_kwargs, default_kwargs):
+def merge_kwargs(local_kwarg, default_kwarg):
-        return local_kwargs
+    if not hasattr(local_kwarg, 'items'):
-    kwargs.update(local_kwargs)
+    # print colored.red(default_kwarg)
-    for (k,v) in local_kwargs.items():
+    for (k,v) in local_kwarg.items():
-    def get(url, **kwargs):
+    def get(self, url, **kwargs):
-This module provides the Requests settings feature set.
+This module provides the Requests configuration defaults.
-    """Merge two given configurations."""
+def get_config(config=None, default_config=None):
-        default_config = config.copy()
+        default_config = defaults.copy()
-config['decode_unicode'] = True
+defaults = dict()
-from .config import settings
+from .config import get_config
-        allow_redirects=False, proxies=None):
+        allow_redirects=False, proxies=None, config=None):
-    def __init__(self, **kwargs):
+    def __init__(self,
-        self.config = kwargs.get('config') or dict()
+        # self.cookies = cookielib.FileCookieJar()
-                kwargs.iterkeys(), kwargs.itervalues())
+        # map(lambda k, v: (k in self.__attrs__) and setattr(self, k, v),
-                    )
+                # if isinstance(kwargs.get('cookies', None), dict):
-
+def merge_configs(config, default_config=None):
-class Settings(object):
+    # Use the module-level defaults, if none is given.
-        super(Settings, self).__init__()
+    d = default_config.copy()
-        return object.__getattribute__(self, key)
+    return d
-settings = Settings()
+config['base_headers'] = {'User-Agent': 'python-requests.org'}
-settings.timeout_fallback = True
+                # print r.headers['location']
-                    self.data, self.params, self.auth, self.cookies,
+                    url=url,
-    __attrs__ = ['headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks']
+    __attrs__ = [
-                        if k in self.__attrs__)
+                inst_attrs = dict((k, v) for k, v in self.__dict__.iteritems() if k in self.__attrs__)
-                api.__all__)
+        map(lambda fn: setattr(self, fn, pass_args(getattr(api, fn))), api.__all__)
-from .models import Request, Response, AuthObject
+from .models import Request, Response
-        # self.auth = auth
+        self.auth = auth
-                r.raw.close()
+                # r.raw.close()
-                    self.data, self.params, self.auth, self.cookiejar,
+                    self.data, self.params, self.auth, self.cookies,
-                    # block=do_block
+                    # preload_content=False
-        self._content = self.raw.read()
+        # self.raw.read() or
-from urlparse import urlparse, urlunparse, urljoin
+from urlparse import urlparse, urlunparse
-                               v.encode('utf-8') if isinstance(v, unicode) else v)
+                result.append(
-            auth = auth_manager.get_auth(self.url)
+        # if isinstance(auth, (list, tuple)):
-        self.auth = auth
+        # self.auth = auth
-                response.raw = resp._raw
+                response.raw = resp
-                    preload_content=do_block
+                    # preload_content=True
-        gen = generate()
+        gen = generate
-        self._content = self.raw.read() or self._response.data
+
-    """Build the actual URL to use."""
+def build_url(url, query_params):
-    # International Domain Name
+    scheme, netloc, path, params, query, fragment = urlparse(url)
-        path = path.encode('utf-8')
+       path = path.encode('utf-8')
-     ))
+     [scheme, netloc, path, params, query, fragment]
-            return '%s?%s' % (url, params)
+    query_params = encode_params(query_params)
-        return url
+       return url
-        cookiejar=cookies,
+        cookies=cookies,
-        params=dict(), auth=None, cookiejar=None, timeout=None, redirect=False,
+        params=dict(), auth=None, cookies=None, timeout=None, redirect=False,
-        self.cookiejar = cookiejar
+        self.cookies = cookies
-        # req = _Request(url, data=self._enc_data, method=self.method)
+        elif self.cookies:
-from models import HTTPError, Request, Response
+from models import Request, Response
-from .utils import dict_from_cookiejar, get_unicode_from_response, stream_decode_response_unicode, decode_gzip, stream_decode_gzip
+from .utils import *
-        self.params, self._enc_params = self._encode_params(params)
+        self.data = data
-        url = self._build_url()
+        url = build_url(self.url, self.params)
-                        timeout=self.timeout)
+                    connection = urllib3.connection_from_url(url, timeout=self.timeout)
-                    block=do_block
+                    preload_content=do_block
-        self.response.status_code will contain the HTTPError code.
+    # def old_send(self, anyway=False):
-        Once a request is successfully sent, `sent` will equal True.
+    #     Once a request is successfully sent, `sent` will equal True.
-        """
+    #     :param anyway: If True, request will be sent, even if it has
-        self._checks()
+    #     self._checks()
-            ))
+    #     # Logging
-        else:
+    #     url = self._build_url()
-                register_openers()
+    #         if self.files:
-                    self.files.update(self.data)
+    #             if self.data:
-                req = _Request(url, data=datagen, headers=headers, method=self.method)
+    #             datagen, headers = multipart_encode(self.files)
-                req = _Request(url, data=self._enc_data, method=self.method)
+    #         else:
-                req.add_header(k, v)
+    #     if self.headers:
-        if not self.sent or anyway:
+    #     if not self.sent or anyway:
-                try:
+    #         try:
-                    resp = opener(req, timeout=self.timeout)
+    #                 resp = opener(req, timeout=self.timeout)
-                        raise
+    #             except TypeError, err:
-                        socket.setdefaulttimeout(self.timeout)
+    #                 if settings.timeout_fallback:
-                    resp = opener(req)
+    #                 resp = opener(req)
-                        socket.setdefaulttimeout(old_timeout)
+    #                 if settings.timeout_fallback:
-                    self.cookiejar.extract_cookies(resp, req)
+    #             if self.cookiejar is not None:
-                        why = Timeout(why)
+    #         except (urllib2.HTTPError, urllib2.URLError), why:
-                self._build_response(why, is_error=True)
+    #             self._build_response(why, is_error=True)
-                self.response.ok = True
+    #         else:
-        self.sent = self.response.ok
+    #     self.sent = self.response.ok
-        return self.sent
+    #     return self.sent
-                **response_kw):
+                release_conn=None, **response_kw):
-            conn = self._get_conn(timeout=pool_timeout)
+        # Request a connection from the queue
-
+            # Connection broken, discard. It will be replaced next _get_conn().
-                 strict=0, preload_content=False, decode_content=True,
+                 strict=0, preload_content=True, decode_content=True,
-    get_host,
+__author__ = "Andrey Petrov (andrey.petrov@shazow.net)"
-from connectionpool import (
+
-__version__ = "$Rev$"
+from .poolmanager import PoolManager
-except ImportError, e:
+except ImportError:
-from filepost import encode_multipart_formdata
+from .filepost import encode_multipart_formdata
-## Connection objects
+## Connection objects (extension of httplib)
-                 ca_certs=None):
+    def __init__(self):
-class HTTPConnectionPool(object):
+class ConnectionPool(object):
-        [self.pool.put(None) for i in xrange(maxsize)]
+        for _ in xrange(maxsize):
-                            "connection, resetting: %s" % self.host)
+                log.info("Resetting dropped connection: %s" % self.host)
-        except Empty, e:
+        except Empty:
-        except Full, e:
+        except Full:
-                redirect=True, assert_same_host=True, block=True):
+                redirect=True, assert_same_host=True, pool_timeout=None,
-        if headers == None:
+        if headers is None:
-            conn = self._get_conn()
+            conn = self._get_conn(timeout=pool_timeout)
-                       httplib_response.status, httplib_response.length))
+            # Make the request on the httplib connection object
-            response = HTTPResponse.from_httplib(httplib_response, block=block)
+            # Import httplib's response into our own wrapper object
-            self._put_conn(conn)
+            # The connection will be put back into the pool when
-                redirect=True):
+                redirect=True, **response_kw):
-                            redirect=redirect)
+                            redirect=redirect, **response_kw)
-                 redirect=True, encode_multipart=True):
+                 redirect=True, encode_multipart=True, multipart_boundary=None,
-            body, content_type = encode_multipart_formdata(fields or {})
+            body, content_type = encode_multipart_formdata(fields or {},
-                            retries=retries, redirect=redirect)
+                            retries=retries, redirect=redirect, **response_kw)
-        self.headers = headers or {}
+    def __init__(self, host, port=None,
-        url, path = url.split('/', 1)
+        url, _path = url.split('/', 1)
-    from StringIO import StringIO
+except ImportError:
-def encode_multipart_formdata(fields):
+def encode_multipart_formdata(fields, boundary=None):
-    BOUNDARY = mimetools.choose_boundary()
+    if boundary is None:
-        body.write('--%s\r\n' % (BOUNDARY))
+        body.write('--%s\r\n' % (boundary))
-    body.write('--%s--\r\n' % (BOUNDARY))
+    body.write('--%s--\r\n' % (boundary))
-    content_type = 'multipart/form-data; boundary=%s' % BOUNDARY
+    content_type = 'multipart/form-data; boundary=%s' % boundary
-                    response.cookies = dict_from_cookiejar(self.cookiejar)
+                    # response.cookies = dict_from_cookiejar(self.cookiejar)
-                    response.cookies = dict_from_cookiejar(self.cookiejar)
+                    # response.cookies = dict_from_cookiejar(self.cookiejar)
-from models import HTTPError, Request, Response
+from config import settings
-        proxies = proxies or config.settings.proxies,
+        method=method,
-import utils
+import utils
-    
+
-            return result, urllib.urlencode(result, doseq=True)
+                                   v.encode('utf-8') if isinstance(v, unicode) else v)
-
+
-        self.url = str(urlunparse([ scheme, netloc, path, params, query, fragment ]))
+
-            for k,v in self.headers.iteritems():
+            for k, v in self.headers.iteritems():
-    of this class.
+    """The core :class:`Response <Response>` object.
-    See AutoAuth for more details.
+    """The :class:`AuthObject` is a simple HTTP Authentication token.
-import urllib2
+import urllib2
-    def __init__(self,  *args, **kwargs):
+    def __init__(self, *args, **kwargs):
-            raise
+            raise
-    return Session(**kwargs)
+    return Session(**kwargs)
-            setattr(codes, title.upper(), code)
+            setattr(codes, title.upper(), code)
-        return self.__dict__.get(key, default)
+        return self.__dict__.get(key, default)
-            if not len(headers) == i+1:
+        if not len(headers) == i + 1:
-    return zlib.decompress(content, 16+zlib.MAX_WBITS)
+    return zlib.decompress(content, 16 + zlib.MAX_WBITS)
-       auth = '-u "%s:%s" ' % (request.auth.username, request.auth.password)
+
-        proxies = proxies or config.settings.proxies,
+        method=method,
-import utils
+import utils
-    
+
-            return result, urllib.urlencode(result, doseq=True)
+                                   v.encode('utf-8') if isinstance(v, unicode) else v)
-
+
-        self.url = str(urlunparse([ scheme, netloc, path, params, query, fragment ]))
+
-            for k,v in self.headers.iteritems():
+            for k, v in self.headers.iteritems():
-    of this class.
+    """The core :class:`Response <Response>` object.
-    See AutoAuth for more details.
+    """The :class:`AuthObject` is a simple HTTP Authentication token.
-import urllib2
+import urllib2
-    def __init__(self,  *args, **kwargs):
+    def __init__(self, *args, **kwargs):
-            raise
+            raise
-    return Session(**kwargs)
+    return Session(**kwargs)
-            setattr(codes, title.upper(), code)
+            setattr(codes, title.upper(), code)
-        return self.__dict__.get(key, default)
+        return self.__dict__.get(key, default)
-            if not len(headers) == i+1:
+        if not len(headers) == i + 1:
-    return zlib.decompress(content, 16+zlib.MAX_WBITS)
+    return zlib.decompress(content, 16 + zlib.MAX_WBITS)
-       auth = '-u "%s:%s" ' % (request.auth.username, request.auth.password)
+
-    if encoding is None:
+    try:
-    decoder = codecs.getincrementaldecoder(encoding)(errors='replace')
+        except LookupError:
-
+        # elif self.cookies:
-
+        # Create the lone response object.
-                if not len(history) < settings.max_redirects:
+                # Woah, this is getting crazy.
-                    # Part of a connection pool, so no streaming. Sorry!
+                    # Part of a connection pool, so no fancy stuff. Sorry!
-        scheme, netloc, path, params, query, fragment = urlparse(self.url)
+        (scheme, netloc, path, params, query, fragment) = urlparse(self.url)
-        self.url = str(urlunparse([ scheme, netloc, path, params, query, fragment ]))
+        # Turn it back into a bytestring.
-                # req = _Request(url, data=self._enc_data, method=self.method)
+        elif self.data:
-from .exceptions import RequestException, AuthenticationError, Timeout, URLRequired, TooManyRedirects
+from .exceptions import RequestException, Timeout, URLRequired, TooManyRedirects
-    def send(self, anyway=False):
+    def send(self, connection=None, anyway=False):
-        if not self.sent or anyway:
+        if (anyway) or (not self.sent):
-                r = pool.urlopen(
+                r = connection.urlopen(
-                    block=True
+                    block=do_block
-                               'already consumed')
+            raise RuntimeError(
-        self._content = self.raw.read()
+        # print self.raw.__dict__
-        """Raises stored :class:`HTTPError` or :class:`URLError`, if one occured."""
+        """Raises stored :class:`HTTPError` or :class:`URLError`,
-        'proxy_digest': urllib2.ProxyDigestAuthHandler
+        # 'basic': HTTPBasicAuthHandler,
-    timeout=None, allow_redirects=False, proxies=None, hooks=None):
+    timeout=None, allow_redirects=False, proxies=None, hooks=None,
-        proxies = proxies or config.settings.proxies,
+        proxies = proxies or config.settings.proxies
-    r.send()
+    r.send(connection=_connection)
-        kwargs["allow_redirects"] = True
+    if 'allow_redirects' not in kwargs:
-        kwargs["allow_redirects"] = True
+    if 'allow_redirects' not in kwargs:
-print dir(urllib3)
+# print dir(urllib3)
-                # response.fo = resp
+                response.raw = resp._raw
-
+
-                # r.fo.close()
+                r.raw.close()
-                    assert_same_host=False
+                    assert_same_host=False,
-                r.socket = pool._get_conn().sock
+                # r.socket = pool._get_conn().sock
-        self.url = None
+        self.raw = None
-                chunk = self.fo.read(chunk_size)
+                chunk = self.raw.read(chunk_size)
-        self._content = self.fo.read()
+        self._content = self.raw.read()
-    def from_httplib(r):
+    def from_httplib(r, block=True):
-        return HTTPResponse(data=data,
+
-                redirect=True, assert_same_host=True):
+                redirect=True, assert_same_host=True, block=True):
-            response = HTTPResponse.from_httplib(httplib_response)
+            response = HTTPResponse.from_httplib(httplib_response, block=block)
-from .packages.poster.streaminghttp import register_openers, get_handlers
+# from .packages.poster.encode import multipart_encode
-            response.status_code = getattr(resp, 'code', None)
+            response.status_code = getattr(resp, 'status', None)
-                response.fo = resp
+                response.headers = CaseInsensitiveDict(getattr(resp, 'headers', None))
-                    response.cookies = dict_from_cookiejar(self.cookiejar)
+                # if self.cookiejar:
-                r.fo.close()
+                # r.fo.close()
-    
+
-from .exceptions import RequestException, AuthenticationError, Timeout, URLRequired, InvalidMethod, TooManyRedirects
+from .exceptions import RequestException, AuthenticationError, Timeout, URLRequired, TooManyRedirects
-from . import poster
+from . import urllib3
-    return opener
+"""
-                    parsed_url[2] = urllib.quote(urllib.unquote(parsed_url[2]))
+                    parsed_url[2] = urllib.quote(parsed_url[2], safe="%/:=&?~#+!$,;'@()*[]")
-        path = urllib.quote(urllib.unquote(path))
+        path = urllib.quote(path, safe="%/:=&?~#+!$,;'@()*[]")
-from .utils import dict_from_cookiejar, get_unicode_from_response, decode_gzip
+from .utils import dict_from_cookiejar, get_unicode_from_response, stream_decode_response_unicode, decode_gzip, stream_decode_gzip
-from urlparse import urlparse
+
-    return request('patch', url, **kwargs)
+    return request('patch', url, data=data, **kwargs)
-__build__ = 0x000601
+__version__ = '0.6.2 (dev)'
-       curl_str = 'curl -L -X POST -H "Accept-Encoding:gzip" -H "User-Agent:python-requests.org" -d "some=data" "http://httpbin.org/post"' 
+       curl_str = 'curl -L -X POST -H "Accept-Encoding:gzip" -H "User-Agent:python-requests.org" -d "some=data" "http://httpbin.org/post"'
-       curl_str = 'curl -L -X POST -H "Accept-Encoding:gzip" -H "User-Agent:python-requests.org" -F "some=@test_requests.py" "https://httpbin.ep.io/post"' 
+       curl_str = 'curl -L -X POST -H "Accept-Encoding:gzip" -H "User-Agent:python-requests.org" -F "some=@test_requests.py" "https://httpbin.ep.io/post"'
-       curl_str = 'curl -L -X POST -H "Accept-Encoding:gzip" -H "User-Agent:python-requests.org" -d \'[{"some": "json"}]\' "http://httpbin.org/post"' 
+       curl_str = 'curl -L -X POST -H "Accept-Encoding:gzip" -H "User-Agent:python-requests.org" -d \'[{"some": "json"}]\' "http://httpbin.org/post"'
-    os.system("python setup.py sdist upload")
+if 'publish' in sys.argv:
-    os.system("python test_requests.py")
+if 'test' in sys.argv:
-       #self.assertEqual(curl_from_request(post3.request), curl_str)
+       curl_str = 'curl -L -X POST -H "Accept-Encoding:gzip" -H "User-Agent:python-requests.org" -d \'[{"some": "json"}]\' "http://httpbin.org/post"' 
-
+import codecs
-from .utils import dict_from_cookiejar, get_unicode_from_response, decode_gzip
+from .utils import dict_from_cookiejar, get_unicode_from_response, stream_decode_response_unicode, decode_gzip, stream_decode_gzip
-    return zlib.decompress(content, 16+zlib.MAX_WBITS)
+    return zlib.decompress(content, 16 + zlib.MAX_WBITS)
-                (r.status_code is codes.see_other) or
+                ((r.status_code is codes.see_other) or
-                    url = urljoin(r.url, urllib.quote(urllib.unquote(url)))
+                parsed_url = urlparse(url)
-        return
+
-    """Creates a curl command from the request."""
+    """Returns a curl command from the request.
-    #: -L/--location - if there is a redirect, redo request on the new place
+    #: -L/--location - if there is a redirect, redo request on the new place.
-        #: -I/--head - fetch headers only
+        #: -I/--head - fetch headers only.
-        #: -X/--request - specify request method
+        #: -X/--request - specify request method.
-    #: -H/--header - Extra header to use when getting a web page
+    #: -H/--header - Extra header to use when getting a web page.
-        #: ContentType multipart/form-data is used
+        #: request.files is updated with request.data if both exist, so only iterate request.files.
-        #: content-type application/x-www-form-urlencoded is used here
+        #: content-type application/x-www-form-urlencoded is used here.
-
+    elif isinstance(headers, basestring):
-from .utils import cookiejar_from_dict
+from .utils import cookiejar_from_dict, header_expand
-
+    # Remove trailing seperators.
-def header_expand(header_dict):
+def header_expand(headers):
-        # Accept: text/x-dvi; q=.8; mxb=100000; mxt=5.0, text/x-c
+        # Accept: text/x-dvi; q=.8; mxb=100000; mxt=5.0, text/x-c
-    for i, (value, params) in enumerate(header_dict.items()):
+    if isinstance(headers, dict):
-        for p_k, p_v in params.items():
+        for (p_k, p_v) in params.items():
-            _params.append('{k}={v}'.format(k=p_k, v=p_v))
+        collector.append(value)
-            collector.append('; ')
+
-            if not len(header_dict) == i+1:
+            if not len(headers) == i+1:
-    #: data previously received from the server in a "Set-Cookie:" line. 
+    #: data previously received from the server in a "Set-Cookie:" line.
-        cookies = cookies.join(['-b "%s=%s" ' % (k.name, k.value) for k in request.cookiejar]) 
+        cookies = cookies.join(['-b "%s=%s" ' % (k.name, k.value) for k in request.cookiejar])
-    #TODO - Cookies
+    method = ''
-    return curl + auth + method + header + form + '"' + request._build_url() + '"'
+    return curl + auth + method + header + cookies + form + '"' + request._build_url() + '"'
-from functools import wraps
+import bz2
-decoders = {
+content_decoders = {
-    'identity': lambda r: r.content,
+    'identity': lambda content: content,
-    'deflate': lambda r: zlib.decompress(r.content),
+    'deflate': lambda content: zlib.decompress(content),
-    'gzip': lambda r: zlib.decompress(r.content, 16+zlib.MAX_WBITS),
+    'gzip': lambda content: zlib.decompress(content, 16+zlib.MAX_WBITS),
-decoders['compress'] = decoders['deflate']
+content_decoders['compress'] = content_decoders['deflate']
-    content_type, params = parse_header(r.headers.get('content-type'))
+def decode_unicode(r):
-    r._content = decoders.get(encoding)(r)
+def decode_encoding(r):
-    hooks = setup_hooks(hooks or dict())
+    cookies = cookiejar_from_dict(cookies if cookies is not None else dict())
-    args = dispatch_hooks(hooks.get('args', []), args)
+    args = dispatch_hooks(hooks['args'], args)
-    r = dispatch_hooks(hooks.get('pre_request', []), r)
+    r = dispatch_hooks(hooks['pre_request'], r)
-    r = dispatch_hooks(hooks.get('post_request', []), hooks, r)
+    r = dispatch_hooks(hooks['post_request'], r)
-    r.response = dispatch_hooks(hooks.get('response', []), r.response)
+    r.response = dispatch_hooks(hooks['response'], r.response)
-    dispatching = dict([(k, v[:]) for k, v in config.settings.default_hooks])
+    default = config.settings.default_hooks
-from response import unicode_response, decode_response
+from . import args
-    """Setup hooks as a dictionary. Each value is a set of hooks."""
+def setup_hooks(supplied):
-    for key, values in hooks.items():
+    :param supplied: a dictionary of hooks. Each value can either be a callable
-        hooks[key] = set(hook_list) 
+        dispatching[hooks].extends(hook_list)
-    return hooks
+    return dispatching
-def dispatch_hooks(hooks, hook_data):
+def dispatch_hooks(hooks, data):
-    :type hook_data: object
+    :param data: the object on witch the hooks should be applied
-            hook_data = hook(hook_data)
+            # hook must be a callable.
-    return hook_data
+
-settings.base_headers = {'User-Agent': 'python-requests.org'}
+settings.base_headers = {
-settings.decode_response = True
+settings.decode_unicode = False
-    #TODO - Files
+    #: Basic Auth only for now
-    data = ''
+    form = ''
-            data = '-d %s ' % (request._enc_data)
+        #: request.files is updated with request.data if both exist.
-    return curl + auth + method + header + data + '"' + request._build_url() + '"'
+    return curl + auth + method + header + form + '"' + request._build_url() + '"'
-    return curl + auth + method + header + data + '"' + request._build_url() + '"' 
+def curl_from_request(request):
-    """Creates a curl command from the request."""
+def curl_from_request(request): 
-    #TODO - Cookies
+    #TODO - Files 
-    curl = 'curl -L '
+    #: -L/--location - if there is a redirect, redo request on the new place 
-    if request.auth is not None:
+    auth = '' 
-    return curl + auth + method + header + data + '"' + request._build_url() + '"'
+    if request.method.upper() == 'HEAD': 
-    #TODO - OAuth/Other Auths
+    #TODO - OAuth
-    #TODO - Cookies?
+    #TODO - OAuth/Other Auths
-    curl_cmd = 'curl -L '
+    curl = 'curl -L '
-        header = header.join(['-H "' + key + ':' + value + '" ' for key, value in request.headers.iteritems()])
+    #: -u/--user - Specify the user name and password to use for server auth. 
-        method_opt = '-I '
+        method = '-I '
-        method_opt = '-X %s ' % request.method.upper()
+        method = '-X %s ' % request.method.upper()
-            data = data.join(['-d %s=%s ' % (k, v) for (k, v) in request.data])
+            data = data.join(['-d "%s=%s" ' % (k, v) for (k, v) in request.data])
-    return curl_cmd + method_opt + data + header + '"' + request._build_url() + '"'
+    return curl + auth + method + header + data + '"' + request._build_url() + '"'
-            data = data.join(['-d ' + key + '=' + value + ' ' for key, value in request.data])
+            data = data.join(['-d %s=%s ' % (k, v) for (k, v) in request.data])
-            data = '-d ' + request._enc_data + ' '
+            data = '-d %s ' % (request._enc_data)
-    return zlib.decompress(content, 16+zlib.MAX_WBITS)
+    return zlib.decompress(content, 16+zlib.MAX_WBITS)
-
+        return content
-            else:
+            elif self._enc_data is not None:
-        success = False
+
-            #: post chunk 'name=daniel&skill=lousy'
+            #: -d/--data - send specified data in post request.
-        return curl_cmd
+        return curl_cmd + method_opt + data + header + '"' + self._build_url() + '"'
-        #TODO - Files...How do I do files???
+        #TODO - Auth with User names and accounts
-        curl_cmd = 'curl --location '
+        #: -L/--location - if there is a redirect, redo request on the new place
-        #: --header - Extra header to use when getting a web page
+        #: -H/--header - Extra header to use when getting a web page
-            header = header.join(['--header "' + key + ':' + value + '" ' for key, value in self.headers.iteritems()])
+            header = header.join(['-H "' + key + ':' + value + '" ' for key, value in self.headers.iteritems()])
-            method_opt = '--head '
+            #: -I/--head - fetch headers only
-            method_opt = '--request %s ' % self.method.upper()
+            #: -X/--request - specify request method
-                data = data.join(['--data ' + key + '=' + value + ' ' for key, value in self.data])
+                data = data.join(['-d ' + key + '=' + value + ' ' for key, value in self.data])
-                data = '--data ' + self._enc_data + ' '
+                data = '-d ' + self._enc_data + ' '
-    'identity': lambda r: r,
+    'identity': lambda r: r.content,
-    r.content = unicode(r.content, charset) if charset else unicode(r.content)
+    r._content = unicode(r.content, charset) if charset else unicode(r.content)
-    return decoders.get(encoding)(r)
+    r._content = decoders.get(encoding)(r)
-from .hooks import dispatch_hooks
+from hooks import setup_hooks, dispatch_hooks
-        cookies = {}
+    cookies = cookiejar_from_dict(cookies or dict())
-    cookies = cookiejar_from_dict(cookies)
+    hooks = setup_hooks(hooks or dict())
-    args = dispatch_hooks('args', hooks, args)
+    args = dispatch_hooks(hooks.get('args', []), args)
-    r = dispatch_hooks('pre_request', hooks, r)
+    r = dispatch_hooks(hooks.get('pre_request', []), r)
-    r = dispatch_hooks('post_request', hooks, r)
+    r = dispatch_hooks(hooks.get('post_request', []), hooks, r)
-    r.response = dispatch_hooks('response', hooks, r.response)
+    r.response = dispatch_hooks(hooks.get('response', []), r.response)
-settings.decode_unicode = True
+# settings.decode_unicode = True
-def dispatch_hooks(key, hooks, hook_data):
+def setup_hooks(hooks):
-    for hook in dispatching:
+    for hook in hooks:
-            self._content = get_unicode_from_response(self)
+        if self._content is None:
-from .hooks import dispatch_hook
+from .hooks import dispatch_hooks
-    args = dispatch_hook('args', hooks, args)
+    args = dispatch_hooks('args', hooks, args)
-    r = dispatch_hook('pre_request', hooks, r)
+    r = dispatch_hooks('pre_request', hooks, r)
-    r = dispatch_hook('post_request', hooks, r)
+    r = dispatch_hooks('post_request', hooks, r)
-    r.response = dispatch_hook('response', hooks, r.response)
+    r.response = dispatch_hooks('response', hooks, r.response)
-    if key in hooks:
+from collections import Iterable
-
+            # hook must be a callable
-
+
-        self.content = None
+
-        (if available)."""
+        (if available).
-        
+
-        """
+    @property
-                return self._content
+        # Read the contents.
-            self._content = self.fo.read()
+        # Decode GZip'd content.
-                    pass
+        # Decode unicode content.
-                self._content = get_unicode_from_response(self)
+        return self._content
-            raise AttributeError
+    @content.setter
-    method = method.upper()
+    method = str(method).upper()
-        #: The Request that created the Response.
+        #: The :class:`Request <Request>` that created the Response.
-    Returns :class:`Response <models.Response>` object.
+    """Constructs and sends a :class:`Request <Request>`.
-    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
+    :param **kwargs: Optional arguments that ``request`` takes.
-    return request('GET', url, **kwargs)
+    return request('get', url, **kwargs)
-    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
+    :param **kwargs: Optional arguments that ``request`` takes.
-    return request('HEAD', url, **kwargs)
+    return request('head', url, **kwargs)
-    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
+    :param **kwargs: Optional arguments that ``request`` takes.
-    return request('POST', url, data=data, **kwargs)
+    return request('post', url, data=data, **kwargs)
-    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
+    :param **kwargs: Optional arguments that ``request`` takes.
-    return request('PUT', url, data=data, **kwargs)
+    return request('put', url, data=data, **kwargs)
-    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
+    :param **kwargs: Optional arguments that ``request`` takes.
-    return request('PATCH', url, **kwargs)
+    return request('patch', url, **kwargs)
-    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
+    :param **kwargs: Optional arguments that ``request`` takes.
-    return request('DELETE', url, **kwargs)
+    return request('delete', url, **kwargs)
-from models import HTTPError
+from models import HTTPError, Request, Response
-from config import settings
+from config import settings
-    """The :class:`Request <models.Request>` object. It carries out all functionality of
+    """The :class:`Request <Request>` object. It carries out all functionality of
-        #: Dictonary of HTTP Headers to attach to the :class:`Request <models.Request>`.
+        #: Dictonary of HTTP Headers to attach to the :class:`Request <Request>`.
-        #: :class:`Request <models.Request>`.
+        #: :class:`Request <Request>`.
-        #: :class:`Request <models.Request>`.
+        #: :class:`Request <Request>`.
-        #: True if :class:`Request <models.Request>` is part of a redirect chain (disables history
+        #: True if :class:`Request <Request>` is part of a redirect chain (disables history
-        #: :class:`Response <models.Response>` instance, containing
+        #: :class:`Response <Response>` instance, containing
-        #: :class:`AuthObject` to attach to :class:`Request <models.Request>`.
+        #: :class:`AuthObject` to attach to :class:`Request <Request>`.
-        #: CookieJar to attach to :class:`Request <models.Request>`.
+        #: CookieJar to attach to :class:`Request <Request>`.
-        """Build internal :class:`Response <models.Response>` object
+        """Build internal :class:`Response <Response>` object
-    :class:`response <models.Response>` attribute, which is an instance
+    """The core :class:`Response <Response>` object. All
-        #: A list of :class:`Response <models.Response>` objects from
+        #: A list of :class:`Response <Response>` objects from
-    2. every encodings from <meta ... charset=XXX>
+
-        #: response data will be automatically deflated.
+
-        #: Raw content of the response, in bytes.
+        #: Content of the response, in bytes or unicode (if available).
-        self._content = None
+        self.content = None
-        #: HTTP Method to use. Available: GET, HEAD, PUT, POST, DELETE.
+        #: HTTP Method to use.
-
+
-    """Returns a key/value dictionary from a CookieJar."""
+def dict_from_cookiejar(cj):
-    for _, cookies in cookiejar._cookies.items():
+    for _, cookies in cj._cookies.items():
-    """Returns a CookieJar from a key/value dictionary."""
+    """Returns a CookieJar from a key/value dictionary.
-    """Returns a CookieJar from a key/value dictionary."""
+    """Returns a CookieJar from a key/value dictionary.
-    """Returns encodings from given content string."""
+    """Returns encodings from given content string.
-    """Returns encodings from given HTTP Header Dict."""
+    """Returns encodings from given HTTP Header Dict.
-    """Return gzip-decoded string."""
+    """Return gzip-decoded string.
-                r.close()
+                r.fo.close()
-            self._content = self.read()
+            self._content = self.fo.read()
-settings.allow_unicode = True
+settings.decode_unicode = True
-            if settings.allow_unicode:
+            if settings.decode_unicode:
-from .utils import dict_from_cookiejar, get_unicode_from_response
+from .utils import dict_from_cookiejar, get_unicode_from_response, decode_gzip
-                    self._content = zlib.decompress(self._content, 16+zlib.MAX_WBITS)
+                    self._content = decode_gzip(self._content)
-            if self.headers.get('content-encoding', '') == 'gzip':
+            if 'gzip' in self.headers.get('content-encoding', ''):
-            try:
+            if settings.allow_unicode:
-    unittest.main()
+
-from .exceptions import RequestException, AuthenticationError, Timeout, URLRequired, InvalidMethod, TooManyRedirects
+from .utils import dict_from_cookiejar, get_unicode_from_response
-            if not isinstance(self.auth.handler, (urllib2.AbstractBasicAuthHandler, urllib2.AbstractDigestAuthHandler)):
+            if not isinstance(self.auth.handler,
-                auth_manager.add_password(self.auth.realm, self.url, self.auth.username, self.auth.password)
+                auth_manager.add_password(
-        """Build internal :class:`Response <models.Response>` object from given response."""
+        """Build internal :class:`Response <models.Response>` object
-                response._resp = resp
+                response.fo = resp
-        """Read and returns the full stream when accessing to :attr: `content`"""
+        """Read and returns the full stream when accessing to
-            self._resp.fp._sock.recv = None
+        if self.fo.fp is not None and hasattr(self.fo.fp, '_sock'):
-import re
+
-from .exceptions import RequestException, AuthenticationError, Timeout, URLRequired, InvalidMethod, TooManyRedirects
+from .utils import dict_from_cookiejar, get_unicode_from_response
-        """Read and returns the full stream when accessing to :attr: `content`"""
+        """Read and returns the full stream when accessing to
-    
+            # Decode unicode content.
-        return unicode(content, encoding, errors="replace")
+
-__build__ = 0x000600
+__version__ = '0.6.1'
-REDIRECT_STATI = (301, 302, 303, 307)
+REDIRECT_STATI = (codes.moved, codes.found, codes.other, codes.temporary_moved)
-                (r.status_code is 303) or
+                (r.status_code is codes.see_other) or
-                if not len(history) < 30:
+                if not len(history) < settings.max_redirects:
-                if r.status_code is 303:
+                if r.status_code is codes.see_other:
-    302: ('see_other', 'other'),
+    303: ('see_other', 'other'),
-
+        else:
-                self.tried_encodings.append(encoding)
+                tried_encodings.append(encoding)
-            if encoding in self.tried_encodings:
+            if encoding in tried_encodings:
-                self.tried_encodings.append(encoding)
+                tried_encodings.append(encoding)
-
+                # Handle redirection without scheme (see: RFC 1808 Section 4)
-                url = urljoin(r.url, urllib.quote(urllib.unquote(url)))
+                if not urlparse(url).netloc:
-    301: ('moved_permanently', 'moved'),
+    301: ('moved_permanently', 'moved', '\\o-'),
-    404: ('not_found',),
+    404: ('not_found', '-o-'),
-    500: ('internal_server_error', 'server_error'),
+    500: ('internal_server_error', 'server_error', '/o\\'),
-    r = Request(hooks=hooks, **args)
+    r = Request(**args)
-    :param cookies: (optional) CookieJar object to send with the :class:`Request`.
+    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
-    :param cookies: (optional) CookieJar object to send with the :class:`Request`.
+    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
-    :param cookies: (optional) CookieJar object to send with the :class:`Request`.
+    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
-    :param cookies: (optional) CookieJar object to send with the :class:`Request`.
+    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
-    :param cookies: (optional) CookieJar object to send with the :class:`Request`.
+    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
-    :param cookies: (optional) CookieJar object to send with the :class:`Request`.
+    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
-    :param cookies: (optional) CookieJar object to send with the :class:`Request`.
+    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
-        allow_redirects=False, proxies=None, hooks=None):
+        allow_redirects=False, proxies=None):
-
+        #: A dictionary of Cookies the server sent back.
-    __attrs__ = ('timeout', 'verbose')
+    __attrs__ = []
-import Cookie
+                # print cookie
-def cookiejar_from_dict(cookie_dict, domain=None):
+def cookiejar_from_dict(cookie_dict):
-        ck.domain = domain
+        cookie = cookielib.Cookie(
-        cj.set_cookie(ck)
+        cj.set_cookie(cookie)
-    """Returns a CookieJar from a key/value dictoinary."""
+    """Returns a CookieJar from a key/value dictionary."""
-__build__ = 0x000501
+__version__ = '0.6.0'
-    """Returns a key/value dictoinary from a CookieJar."""
+    """Returns a key/value dictionary from a CookieJar."""
-            return self._content
+            return self.unicode_content(self._content)
-
+
-
+    # Arguments manipulation hook.
-
+        self.__dict__.update(
-    """"""
+    """Dipatches a hook dictionary on a given peice of data."""
-``pre-request``:
+``pre_request``:
-``post-request``:
+``post_request``:
-        allow_redirects=False, proxies=None):
+        allow_redirects=False, proxies=None, hooks=None):
-                    if not "timeout" in str(err):
+                    if not 'timeout' in str(err):
-        proxies = proxies or config.settings.proxies
+        proxies = proxies or config.settings.proxies,
-    r = Request(**args)
+    r = Request(hooks=hooks, **args)
-html_show_sourcelink = True
+html_show_sourcelink = False
-        """Build the actual URL to use"""
+        """Build the actual URL to use."""
-        # (Use socket.setdefaulttimeout() as fallback)
+        #  (Use socket.setdefaulttimeout() as fallback)
-    """Constructs and sends a :class:`Request <models.Request>`. Returns :class:`Response <models.Response>` object.
+    """Constructs and sends a :class:`Request <models.Request>`.
-        #: Float describ the timeout of the request. (Use socket.setdefaulttimeout() as fallback)
+        #: Float describ the timeout of the request.
-                    
+
-                        
+
-                    
+
-from requests.session import Session
+from requests.sessions import Session
-    def test_AUTH_HTTPS_200_OK_GET(self):
+    def test_AUTH_HTTP_200_OK_GET(self):
-            r = requests.get(url, auth=auth)
+            r = requests.get(url, auth=auth)
-
+
-        r1 = s.get(httpbin('user-agent')
+        r1 = s.get(httpbin('user-agent'))
-        r2 = s.get(httpbin('user-agent')
+        r2 = s.get(httpbin('user-agent'))
-        
+        self.assertEqual(r2.status_code, 200)
-from models import HTTPError, auth_manager
+from models import HTTPError
-from .models import Request, Response, AuthManager, AuthObject, auth_manager
+from .models import Request, Response, AuthObject
-    timeout=None, allow_redirects=False, proxies=None):
+    timeout=None, allow_redirects=False, proxies=None, hooks=None):
-    r = Request(
+    args = dict(
-        auth = auth or auth_manager.get_auth(url),
+        auth = auth,
-settings.timeout_fallback = True # Use socket.setdefaulttimeout() as fallback?
+
-import requests.api
+from . import api
-    __attrs__ = ['headers', 'cookies', 'auth', 'timeout', 'proxies']
+    __attrs__ = ['headers', 'cookies', 'auth', 'timeout', 'proxies', 'hooks']
-                requests.api.__all__)
+        map(lambda fn: setattr(self, fn, pass_args(getattr(api, fn))),
-        return '<requests-client at %s>' % (id(self))
+        return '<requests-client at 0x%x>' % (id(self))
-        (from __attrs__) that have been set, combining them with **kwargs """
+        """Reads each available method from requests.api and decorates
-        
+
-                inst_attrs = dict((k, v) for k, v in self.__dict__.iteritems() 
+                inst_attrs = dict((k, v) for k, v in self.__dict__.iteritems()
-                # Combine instance-local values with kwargs values, with 
+                # Combine instance-local values with kwargs values, with
-                requests.api.__all__) 
+                requests.api.__all__)
-        #TODO - Query string...
+        #: --header - Extra header to use when getting a web page
-        curl_cmd = curl_cmd + method_opt + data + self.url
+        #: Params handled in _build_url
-    301: ('moved_pemanently', 'moved'),
+    301: ('moved_permanently', 'moved'),
-    500: ('iternal_server_error', 'server_error'),
+    500: ('internal_server_error', 'server_error'),
-        #socket.setdefaulttimeout(timeout)
+        #: Float describ the timeout of the request. (Use socket.setdefaulttimeout() as fallback)
-                    socket.setdefaulttimeout(self.timeout)
+                    
-                    socket.setdefaulttimeout(old_timeout)
+                    
-        socket.setdefaulttimeout(timeout)
+        #socket.setdefaulttimeout(timeout)
-                resp = opener(req)
+                try:
-            req.headers.update(self.headers)
+            for k,v in self.headers.iteritems():
-        self.content = None
+
-
+        #: The Request that created the Response.
-    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', r'\o/'),
+    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/'),
-        if not title.startswith(r'\'):
+        if not title.startswith('\\'):
-    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\o/'),
+    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', r'\o/'),
-        setattr(codes, title.upper(), code)
+        if not title.startswith(r'\'):
-        else:
+        self.request = None
-    proxies=None):
+def get(url, **kwargs):
-        timeout=timeout, proxies=proxies)
+    return request('GET', url, **kwargs)
-    proxies=None):
+def head(url, **kwargs):
-        timeout=timeout, proxies=proxies)
+    return request('HEAD', url, **kwargs)
-    allow_redirects=False, params=None, proxies=None):
+def post(url, data='', **kwargs):
-        allow_redirects=allow_redirects, proxies=proxies)
+    return request('POST', url, data=data, **kwargs)
-        timeout=None, allow_redirects=False, params=None, proxies=None):
+def put(url, data='', **kwargs):
-        allow_redirects=allow_redirects, proxies=proxies)
+    return request('PUT', url, data=data, **kwargs)
-        timeout=None, allow_redirects=False, params=None, proxies=None):
+def patch(url, data='', **kwargs):
-        allow_redirects=allow_redirects, proxies=proxies)
+    return request('PATCH', url, **kwargs)
-    allow_redirects=False, proxies=None):
+def delete(url, **kwargs):
-        timeout=timeout, allow_redirects=allow_redirects, proxies=proxies)
+    return request('DELETE', url, **kwargs)
-    def _build_response(self, resp):
+    def _build_response(self, resp, is_error=False):
-                    self.response.error = why
+                self._build_response(why, is_error=True)
-        self.assertEqual(r.status_code, 200)
+        for service in SERVICES:
-        self.assertEqual(r.status_code, 200)
+            auth = ('user', 'pass')
-        requests.auth_manager.empty()
+            r = requests.get(url)
-        self.assertEqual(post.status_code, 200)
+        for service in SERVICES:
-        self.assertEqual(post2.status_code, 200)
+            post = requests.post(url, data={'some': 'data'})
-        self.assertEqual(post3.status_code, 200)
+            post2 = requests.post(url, files={'some': open('test_requests.py')})
-        self.assertEqual(post.status_code, 200)
+        for service in SERVICES:
-        url = httpbin('post')
+        for service in SERVICES:
-            headers = {'User-Agent': 'requests-tests'})
+            post2 = requests.post(url,
-        self.assertEqual(post2.status_code, 200)
+            self.assertEqual(post2.status_code, 200)
-        self.assertEqual(bool(r), True)
+        for service in SERVICES:
-        self.assertEqual(r.ok, False)
+
-        url = httpbin('/')
+        for service in SERVICES:
-        requests.get(httpbin('Ã¸'), params={'foo': u'foo'})
+            url = service('/')
-        self.assertEquals(r.status_code, 401)
+        for service in SERVICES:
-        self.assertEquals(rbody.get('data'), '')
+
-        self.assertEquals(rbody.get('data'), 'fooaowpeuf')
+
-        self.assertEquals(rbody.get('data'), '')
+
-        self.assertEquals(rbody.get('data'), '')
+
-        self.assertEquals(rbody.get('data'), '')
+
-        self.assertEquals(rbody.get('data'), 'foobar')
+
-        self.assertEquals(r.url, httpbin('get?test=foo&test=baz'))
+
-        self.assertEquals(rbody.get('data'), '')
+
-        self.assertEquals(rbody.get('data'), '')
+
-        self.assertEquals(len(r.history), 3)
+        for service in SERVICES:
-from .exceptions import RequestException, AuthenticationError, Timeout, URLRequired, InvalidMethod
+from .exceptions import RequestException, AuthenticationError, Timeout, URLRequired, InvalidMethod, TooManyRedirects
-from urlparse import urlparse, urlunparse
+from urlparse import urlparse, urlunparse, urljoin
-                    url = '%s://%s/%s' % (parent_url_components.scheme, parent_url_components.netloc, urllib.quote(urllib.unquote(url)))
+                    url = urljoin(r.url, urllib.quote(urllib.unquote(url)))
-                response.close = resp.close
+                response._resp = resp
-        self.url = urlunparse(parsed_url)
+        scheme, netloc, path, params, query, fragment = urlparse(self.url)
-        proxies = proxies
+        proxies = proxies or config.settings.proxies
-settings.accept_gzip = True
+settings.accept_gzip = True
-                    url = '%s://%s/%s' % (parent_url_components.scheme, parent_url_components.netloc, url)
+                    url = '%s://%s/%s' % (parent_url_components.scheme, parent_url_components.netloc, urllib.quote(urllib.unquote(url)))
-        # Support for unicode domain names.
+        # Support for unicode domain names and paths.
-                url = urljoin(self.url, url)
+                url = urljoin(r.url, url)
-from urlparse import urlparse, urlunparse
+from urlparse import urlparse, urlunparse, urljoin
-                    url = '%s://%s/%s' % (parent_url_components.scheme, parent_url_components.netloc, url)
+                url = urljoin(self.url, url)
-__build__ = 0x000500
+__version__ = '0.5.1'
-        assert 'tinyarrows.com' in r.url
+        assert 'httpbin' in r.url
-settings.base_headers = {'User-Agent': 'python-requests.org'}
+settings.base_headers = {'User-Agent': 'python-requests.org'}
-            headers.update(self.headers)
+
-        if self.redirect:
+        if r.status_code in REDIRECT_STATI and not self.redirect:
-    import simplejson as json
+    import json
-        self.assertEqual(r.url, HTTPBIN_URL)
+        assert 'tinyarrows.com' in r.url
-settings = Settings()
+settings = Settings()
-from .monkeys import Request as _Request, HTTPBasicAuthHandler, HTTPDigestAuthHandler, HTTPRedirectHandler
+from .monkeys import Request as _Request, HTTPBasicAuthHandler, HTTPForcedBasicAuthHandler, HTTPDigestAuthHandler, HTTPRedirectHandler
-    def __init__(self, username, password, handler='basic', realm=None):
+    def __init__(self, username, password, handler='forced_basic', realm=None):
-            self.handler = self._handlers.get(handler.lower(), HTTPBasicAuthHandler)
+            self.handler = self._handlers.get(handler.lower(), HTTPForcedBasicAuthHandler)
-
+import re
-class HTTPRedirectHandler(urllib2.HTTPRedirectHandler):
+class HTTPRedirectHandler(urllib2.HTTPRedirectHandler):
-            self.handler = self._handlers.get(handler.lower(), urllib2.HTTPBasicAuthHandler)
+            self.handler = self._handlers.get(handler.lower(), HTTPBasicAuthHandler)
-        dict.__delitem__(self, key, value)
+        dict.__delitem__(self, key)
-    """Case-insensitive Dictionary for :class:`Response <models.Response>` Headers.
+    """Case-insensitive Dictionary
-        return map(str.lower, self.keys())
+    @property
-        return key.lower() in self._lower_keys()
+    def __setitem__(self, key, value):
-            return self.items()[self._lower_keys().index(key.lower())][1]
+            return dict.__getitem__(self, self.lower_keys[key.lower()])
-import omnijson as json
+try:
-        of that.
+        returns a list of tuples containing the encoded parameters, and a urlencoded
-                     = v.encode('utf-8') if isinstance(v, unicode) else v
+            result = []
-                response.content = resp.read()
+                response.read = resp.read
-        self.content = None
+        self._content = None
-            return result, urllib.urlencode(result)
+            return result, urllib.urlencode(result, doseq=True)
-from urlparse import urlparse
+from urlparse import urlparse, urlunparse
-        """Raises stored :class:`HTTPError`, if one occured."""
+        """Raises stored :class:`HTTPError` or :class:`URLError`, if one occured."""
-    description='Awesome Python HTTP Library that\'s actually usable.',
+    description='Python HTTP for Humans.',
-            except urllib2.HTTPError, why:
+            except (urllib2.HTTPError, urllib2.URLError), why:
-                raise Timeout if isinstance(error.reason, socket.timeout) else error
+
-            self.assertRaises(requests.Timeout, requests.get, httpbin(''))
+            self.assertRaises(requests.Timeout, test)
-__build__ = 0x000401
+__version__ = '0.5.0'
-import requests
+from datetime import datetime
-                # Facilitate for non-RFC2616-compliant 'location' headers
+                # Facilitate non-RFC2616-compliant 'location' headers
-                    redirect=False
+                    redirect=True
-    __attrs__ = ('timeout',)
+    __attrs__ = ('timeout', 'verbose')
-__all__ = ('request', 'get', 'head', 'post', 'put', 'delete')
+__all__ = ('request', 'get', 'head', 'post', 'patch', 'put', 'delete')
-def get(url, params=None, headers=None, cookies=None, auth=None, timeout=None, proxies=None):
+
-                   proxies=proxies)
+    return request('GET', url,
-def head(url, params=None, headers=None, cookies=None, auth=None, timeout=None, proxies=None):
+def head(url,
-                   proxies=proxies)
+    return request('HEAD', url,
-                   allow_redirects=allow_redirects, proxies=proxies)
+    return request('POST', url,
-                   allow_redirects=allow_redirects, proxies=proxies)
+    return request('PUT', url,
-                    timeout=timeout, allow_redirects=allow_redirects, proxies=proxies)
+    return request('DELETE', url,
-    _METHODS = ('GET', 'HEAD', 'PUT', 'POST', 'DELETE')
+    _METHODS = ('GET', 'HEAD', 'PUT', 'POST', 'DELETE', 'PATCH')
-                 proxies=None):
+    def __init__(self,
-        self.assertEqual(post.status_code, 200)
+        self.assertEqual(post3.status_code, 200)
-    import json
+
-from distutils.core import setup
+try:
-            timeout=None, allow_redirects=False):
+            timeout=None, allow_redirects=False, proxies=None):
-        allow_redirects = allow_redirects
+        allow_redirects = allow_redirects,
-def get(url, params=None, headers=None, cookies=None, auth=None, timeout=None):
+def get(url, params=None, headers=None, cookies=None, auth=None, timeout=None, proxies=None):
-    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
+    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout,
-def head(url, params=None, headers=None, cookies=None, auth=None, timeout=None):
+def head(url, params=None, headers=None, cookies=None, auth=None, timeout=None, proxies=None):
-    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
+    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout,
-         timeout=None, allow_redirects=False, params=None):
+         timeout=None, allow_redirects=False, params=None, proxies=None):
-                   allow_redirects=allow_redirects)
+                   allow_redirects=allow_redirects, proxies=proxies)
-        timeout=None, allow_redirects=False, params=None):
+        timeout=None, allow_redirects=False, params=None, proxies=None):
-                   allow_redirects=allow_redirects)
+                   allow_redirects=allow_redirects, proxies=proxies)
-def delete(url, params=None, headers=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
+def delete(url, params=None, headers=None, cookies=None, auth=None, timeout=None, allow_redirects=False,
-                    timeout=timeout, allow_redirects=allow_redirects)
+                    timeout=timeout, allow_redirects=allow_redirects, proxies=proxies)
-                 timeout=None, redirect=False, allow_redirects=False):
+                 timeout=None, redirect=False, allow_redirects=False,
-        data = params or data,
+        data = data,
-def post(url, data='', headers=None, files=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
+def post(url, data='', headers=None, files=None, cookies=None, auth=None,
-                   timeout=timeout, allow_redirects=allow_redirects)
+    return request('POST', url, params=params, data=data, headers=headers,
-def put(url, data='', headers=None, files=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
+def put(url, data='', headers=None, files=None, cookies=None, auth=None,
-                   timeout=timeout, allow_redirects=allow_redirects)
+    return request('PUT', url, params=params, data=data, headers=headers,
-                 redirect=False, allow_redirects=False):
+                 data=dict(), params=dict(), auth=None, cookiejar=None,
-        self.data = dict()
+        #: Dictionary or byte of request body data to attach to the
-                    self.data, self.auth, self.cookiejar, redirect=False
+                    self.data, self.params, self.auth, self.cookiejar,
-        """Build URLs."""
+    def _build_url(self):
-                return '%s?%s' % (url, data)
+        if self._enc_params:
-                return url
+                return '%s?%s' % (self.url, self._enc_params)
-            req = _Request(self._build_url(self.url, self._enc_data), method=self.method)
+            req = _Request(url, method=self.method)
-                req = _Request(self.url, data=datagen, headers=headers, method=self.method)
+                req = _Request(url, data=datagen, headers=headers, method=self.method)
-                req = _Request(self.url, data=self._enc_data, method=self.method)
+                req = _Request(url, data=self._enc_data, method=self.method)
-    :param data: (optional) Bytes/Dictionary of PUT/POST Data to send with the :class:`Request`.
+    :param params: (optional) Dictionary or bytes to be sent in the query string for the :class:`Request`.
-    :param params: (optional) Dictionary of GET Parameters to send with the :class:`Request`.
+    :param params: (optional) Dictionary of parameters, or bytes, to be sent in the query string for the :class:`Request`.
-    :param params: (optional) Dictionary of GET Parameters to send with the :class:`Request`.
+    :param params: (optional) Dictionary of parameters, or bytes, to be sent in the query string for the :class:`Request`.
-    :param data: (optional) Dictionary or bytes of POST data to send with the :class:`Request`.
+    :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
-    :param headers: (optional) Dictionary or bytes of HTTP Headers to sent with the :class:`Request`.
+    :param data: (optional) Dictionary or bytes to send in the body of the :class:`Request`.
-    :param params: (optional) Dictionary of DELETE Parameters to send with the :class:`Request`.
+    :param params: (optional) Dictionary of parameters, or bytes, to be sent in the query string for the :class:`Request`.
-
+        self.data, self._enc_data = self._encode_params(data)
-    return HTTPBIN_URL + '/'.join(suffix)
+    return HTTPSBIN_URL + '/'.join(suffix)
-    :param data: (optional) Dictionary of POST data to send with the :class:`Request`.
+    :param data: (optional) Dictionary or bytes of POST data to send with the :class:`Request`.
-    :param headers: (optional) Dictionary of HTTP Headers to sent with the :class:`Request`.
+    :param data: (optional) Bytes of PUT Data to send with the :class:`Request`.
-
+        url = httpbin('cookies', 'set', 'requests_cookie', 'awesome')
-        r = requests.get('http://httpbin.org/')
+        r = requests.get(httpbin('/'))
-        r = requests.get('https://github.com/')
+        r = requests.get(httpsbin('/'))
-        r = requests.get('http://httpbin.org/user-agent', headers=heads)
+        r = requests.get(httpbin('user-agent'), headers=heads)
-        r = requests.get('http://httpbin.org/get?test=true', params={'q': 'test'}, headers=heads)
+        r = requests.get(httpbin('get') + '?test=true', params={'q': 'test'}, headers=heads)
-        r = requests.get('http://httpbin.org/user-agent', headers=heads);
+        r = requests.get(httpbin('user-agent'), headers=heads);
-        r = requests.get('http://httpbin.org/user-agent', headers=heads);
+        r = requests.get(httpbin('user-agent'), headers=heads);
-        r = requests.head('http://httpbin.org')
+        r = requests.head(httpbin('/'))
-        r = requests.head('https://github.com')
+        r = requests.head(httpsbin('/'))
-        url = 'https://convore.com/api/account/verify.json'
+        auth = ('user', 'pass')
-        self.assertEqual(bin.status_code, 302)
+        url = httpbin('post')
-        self.assertEqual(post.status_code, 201)
+        post = requests.post(url, data={'some': 'data'})
-        self.assertEqual(post2.status_code, 201)
+        post2 = requests.post(url, files={'some': open('test_requests.py')})
-        self.assertEqual(post.status_code, 201)
+        post3 = requests.post(url, data='[{"some": "json"}]')
-        self.assertEqual(post2.status_code, 201)
+        url = httpbin('post')
-        post_url = bin.headers['location']
+        url = httpbin('post')
-        headers = {'User-Agent': 'requests-tests'})
+        post2 = requests.post(url, files={'some': open('test_requests.py')},
-        self.assertEqual(post2.status_code, 201)
+        self.assertEqual(post2.status_code, 200)
-        r = requests.get('http://google.com/some-404-url')
+        r = requests.get(httpbin('status', '500'))
-        r = requests.get('http://google.com/')
+        r = requests.get(httpbin('/'))
-        r = requests.get('http://google.com/some-404-url')
+        r = requests.get(httpbin('status', '404'))
-        r = requests.get('http://google.com/some-404-url')
+        r = requests.get(httpbin('status', '404'))
-        r = requests.get('http://google.com/')
+        r = requests.get(httpbin('status', '200'))
-        r = requests.get('http://api.stackoverflow.com/1.1/users/495995/top-answer-tags')
+        r = requests.get(httpbin('gzip'))
-        requests.auth_manager.add_auth('convore.com', conv_auth)
+        http_auth = ('user', 'pass')
-        r = requests.get('https://convore.com/api/account/verify.json')
+        r = requests.get(httpbin('basic-auth', 'user', 'pass'))
-        requests.get('http://google.com/Ã¸', params={'foo': u'foo'})
+        url = httpbin('/')
-        conv_auth = ('requeststest', 'bad_password')
+        http_auth = ('user', 'BADpass')
-        r = requests.get('https://convore.com/api/account/verify.json', auth=conv_auth)
+        r = requests.get(httpbin('basic-auth', 'user', 'pass'), auth=http_auth)
-            self.assertRaises(requests.Timeout, requests.get, 'http://google.com')
+            self.assertRaises(requests.Timeout, requests.get, httpbin(''))
-            requests.get('http://google.com')
+        with requests.settings(timeout=100):
-        requests.post('http://google.com', data='foo')
+        r = requests.post(httpbin('post'), data='fooaowpeuf')
-                 redirect=True, allow_redirects=False):
+                 redirect=False, allow_redirects=False):
-        r = requests.get('https://httpbin.org/')
+        r = requests.get('https://github.com/')
-        r = requests.get('http://whatsmyua.com', headers=heads);
+        r = requests.get('http://httpbin.org/user-agent', headers=heads);
-        r = requests.get('http://whatsmyua.com', headers=heads);
+        r = requests.get('http://httpbin.org/user-agent', headers=heads);
-        r = requests.head('http://google.com')
+        r = requests.head('http://httpbin.org')
-        r = requests.head('https://google.com')
+        r = requests.head('https://github.com')
-        r = requests.get('http://google.com')
+        r = requests.get('http://httpbin.org/')
-        r = requests.get('https://google.com')
+        r = requests.get('https://httpbin.org/')
-        r = requests.get('http://www.google.com/search', params={'q': 'test'}, headers=heads)
+        r = requests.get('http://httpbin.org/user-agent', headers=heads)
-        r = requests.get('http://google.com/search?test=true', params={'q': 'test'}, headers=heads)
+        r = requests.get('http://httpbin.org/get?test=true', params={'q': 'test'}, headers=heads)
-        requests.get('http://google.com', cookies=jar)
+        data = {'cn': 'requests_cookie', 'cv': 'awesome'}
-        with requests.settings(timeout=0.0001):
+        with requests.settings(timeout=0.0000001):
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-        
+
-def post(url, data=None, headers=None, files=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
+def post(url, data='', headers=None, files=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
-def put(url, data=None, headers=None, files=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
+def put(url, data='', headers=None, files=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
-class CaseInsensitiveDict(DictMixin):
+class CaseInsensitiveDict(dict):
-        return map(str.lower, self.data.keys())
+        return map(str.lower, self.keys())
-        if key.lower() in self:
+        # We allow fall-through here, so values default to None
-def get(url, params={}, headers={}, cookies=None, auth=None, **kwargs):
+def get(url, params=None, headers=None, cookies=None, auth=None, timeout=None):
-    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth, **kwargs)
+    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
-def head(url, params={}, headers={}, cookies=None, auth=None, **kwargs):
+def head(url, params=None, headers=None, cookies=None, auth=None, timeout=None):
-    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth, **kwargs)
+    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
-def post(url, data={}, headers={}, files=None, cookies=None, auth=None, **kwargs):
+def post(url, data=None, headers=None, files=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
-    return request('POST', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth, **kwargs)
+    return request('POST', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth,
-def put(url, data='', headers={}, files={}, cookies=None, auth=None, **kwargs):
+def put(url, data=None, headers=None, files=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
-    return request('PUT', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth, **kwargs)
+    return request('PUT', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth,
-def delete(url, params={}, headers={}, cookies=None, auth=None, **kwargs):
+def delete(url, params=None, headers=None, cookies=None, auth=None, timeout=None, allow_redirects=False):
-    return request('DELETE', url, params=params, headers=headers, cookies=cookies, auth=auth, **kwargs)
+    return request('DELETE', url, params=params, headers=headers, cookies=cookies, auth=auth,
-            timeout=config.settings.timeout, allow_redirects=False):
+            timeout=None, allow_redirects=False):
-        timeout = timeout,
+        timeout = timeout or config.settings.timeout,
-def request(method, url, **kwargs):
+def request(method, url, params=None, data=None, headers=None, cookies=None, files=None, auth=None,
-        allow_redirects=kwargs.pop('allow_redirects', None)
+
-__build__ = 0x000400
+__version__ = '0.4.1'
-        allow_redirects=kwargs.pop('allow_redirects', None)
+    r = Request(method=method, url=url, data=data, headers=kwargs.pop('headers', dict()),
-from settings import Settings as settings
+from config import settings
-
+
-        return object.__getattribute__(self, key)
+
-
+    def __getattribute__(self, key):
-import settings
+import config
-        timeout=kwargs.pop('timeout', settings.timeout),
+        timeout=kwargs.pop('timeout', config.settings.timeout),
-
+# -*- coding: utf-8 -*-
-                 'Mozilla/5.0 (github.com/kennethreitz/requests)'}
+        heads = {
-    
+        cookiejar=kwargs.pop('cookies', None),
-                timeout=kwargs.pop('timeout', requests.timeout))
+                timeout=kwargs.pop('timeout', requests.timeout),
-                 data=dict(), auth=None, cookiejar=None, timeout=None, redirect=True):
+                 data=dict(), auth=None, cookiejar=None, timeout=None,
-        
+        #: Set to True if full redirects are allowed (e.g. re-POST-ing of data at new ``Location``)
-            while 'location' in r.headers:
+            while (
-                    url, self.headers, self.files, self.method,
+                    url, self.headers, self.files, method,
-        self.assertEqual(bin.status_code, 200)
+        self.assertEqual(bin.status_code, 302)
-        post = requests.post(bin.url, data={'some': 'data'})
+        post_url = bin.headers['location']
-        post2 = requests.post(bin.url, files={'some': open('test_requests.py')})
+        post2 = requests.post(post_url, files={'some': open('test_requests.py')})
-        post3 = requests.post(bin.url, data='[{"some": "json"}]')
+        post3 = requests.post(post_url, data='[{"some": "json"}]')
-        self.assertEqual(bin.status_code, 200)
+        post_url = bin.headers['location']
-        post2 = requests.post(bin.url, files={'some': open('test_requests.py')}, data={'some': 'data'})
+        post2 = requests.post(post_url, files={'some': open('test_requests.py')}, data={'some': 'data'})
-        self.assertEqual(bin.status_code, 200)
+        self.assertEqual(bin.status_code, 302)
-        headers={'User-Agent': 'requests-tests'})
+        post2 = requests.post(post_url, files={'some': open('test_requests.py')},
-        
+
-            
+
-            
+
-        
+
-from settings import settings
+from settings import Settings as settings
-import requests
+import settings
-                timeout=kwargs.pop('timeout', requests.timeout))
+                timeout=kwargs.pop('timeout', settings.timeout))
-from settings import *
+from settings import settings
-
+from settings import *
-requests.models
+requests.exceptions
-            self.assertRaises(urllib2.URLError, requests.get, 'http://google.com')
+        with requests.settings(timeout=0.0001):
-    """An inappropriate method was attempted."""
+            except urllib2.URLError, error:
-    """Sends a Constructs and sends a :class:`Request <models.Request>`. Returns :class:`Response <models.Response>` object.
+    """Constructs and sends a :class:`Request <models.Request>`. Returns :class:`Response <models.Response>` object.
-requests.system
+requests.models
-        # self.data = {}
+        
-            self._enc_data = data
+            self._enc_data = self.data = data
-        self.module.timeout = timeout
+    def __init__(self, **settings):
-            setattr(self.module, key, self.cache[key])
+        self._restore_settings()
-    url='https://github.com/kennethreitz/requests',
+    url='http://python-requests.org',
-copyright = u'2011. A <a href="http://kennethreitz.com">Kenneth Reitz</a> Project'
+copyright = u'2011. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project'
-    """Sends a `method` request. Returns :class:`Response` object.
+    """Sends a Constructs and sends a :class:`Request <models.Request>`. Returns :class:`Response <models.Response>` object.
-    """The :class:`Request` object. It carries out all functionality of
+    """The :class:`Request <models.Request>` object. It carries out all functionality of
-
+        #: :class:`Response <models.Response>` instance, containing
-        """Build internal Response object from given response."""
+        """Build internal :class:`Response <models.Response>` object from given response."""
-    this class.
+    """The core :class:`Response <models.Response>` object. All
-        """Returns true if status_code is 'OK'."""
+        """Returns true if :attr:`status_code` is 'OK'."""
-        """Raises stored HTTPError if one exists."""
+        """Raises stored :class:`HTTPError`, if one occured."""
-    """Authentication Manager."""
+    """Requests Authentication Manager."""
-    """docstring for CaseInsensitiveDict"""
+    """Case-insensitive Dictionary for :class:`Response <models.Response>` Headers.
-copyright = u'2011. A Kenneth Reitz Project'
+copyright = u'2011. A <a href="http://kennethreitz.com">Kenneth Reitz</a> Project'
-#html_sidebars = {}
+# Custom sidebar templates, maps document names to template names.
-copyright = u'2011, Kenneth Reitz'
+copyright = u'2011. A Kenneth Reitz Project'
-#html_show_sourcelink = True
+html_show_sourcelink = True
-#html_show_sphinx = True
+html_show_sphinx = False
-#sys.path.insert(0, os.path.abspath('.'))
+sys.path.insert(0, os.path.abspath('..'))
-version = '0.3.3'
+version = __version__
-pygments_style = 'sphinx'
+pygments_style = 'flask_theme_support.FlaskyStyle'
-__build__ = 0x000304
+__version__ = '0.4.0'
-                self.response.error = why
+                if not self.redirect:
-from .api import *
+
-from .monkeys import Request as _Request, HTTPBasicAuthHandler, HTTPDigestAuthHandler
+from .monkeys import Request as _Request, HTTPBasicAuthHandler, HTTPDigestAuthHandler, HTTPRedirectHandler
-                 data=dict(), auth=None, cookiejar=None, timeout=None):
+                 data=dict(), auth=None, cookiejar=None, timeout=None, redirect=True):
-        self.data = {}
+        self.data = dict()
-        _handlers.extend(get_handlers())
+        if self.data or self.files:
-        self.response.status_code = getattr(resp, 'code', None)
+        def build(resp):
-            pass
+            response = Response()
-            except zlib.error:
+                response.headers = CaseInsensitiveDict(getattr(resp.info(), 'dict', None))
-        self.response.url = getattr(resp, 'url', None)
+            if response.headers['content-encoding'] == 'gzip':
-# -*- coding: utf-8 -*-
+#-*- coding: utf-8 -*-
-    # from mercurial
+
-                        self, auth_header, host, req, headers)
+            self, auth_header, host, req, headers
-    def __init__(self):
+    def __init__(self, *args, **kwargs):
-        self.data = dict()
+        self.data = dict(*args, **kwargs)
-
+from .structures import CaseInsensitiveDict
-            self.response.headers = getattr(resp.info(), 'dict', None)
+            self.response.headers = CaseInsensitiveDict(getattr(resp.info(), 'dict', None))
-        except AttributeError, why:
+        except AttributeError:
-        if self.response.headers.get('content-encoding', None) == 'gzip':
+        if self.response.headers['content-encoding'] == 'gzip':
-        self.headers = dict()
+        self.headers = CaseInsensitiveDict()
-        return key.lower() in self._lower_keys
+        return key.lower() in self._lower_keys()
-        raise KeyError
+            return self.items()[self._lower_keys().index(key.lower())][1]
-]
+# -*- coding: utf-8 -*-
-# from: werkzeug
+"""
-    """
+Datastructures that power Requests.
-        found:
+"""
-        -1
+from UserDict import DictMixin
-        return rv
+class CaseInsensitiveDict(DictMixin):
-            dict.__init__(self, tmp)
+    def __repr__(self):
-        dict.setdefault(self, key, []).append(value)
+        return self.data.copy()
-        with the callable defined there.
+    def __setstate__(self, d):
-        return result
+    @property
-        ['1', '2']
+    def __contains__(self, key):
-        return dict.itervalues(self)
+    def __getitem__(self, key):
-        return self.__class__(self)
+        if key.lower() in self:
-        `False` all values will be returned as lists.
+        raise KeyError
-            MultiDict.add(self, key, value)
+    def __setitem__(self, key, value):
-        False
+    def __delitem__(self, key):
-            raise self.KeyError(str(e))
+    def __keys__(self):
-        return dict.pop(self, key, [])
+    def __iter__(self):
-        return '%s(%r)' % (self.__class__.__name__, self.items(multi=True))
+    def iteritems(self):
-__build__ = 0x000303
+__version__ = '0.3.4'
-from .monkeys import _Request, _HTTPBasicAuthHandler, _HTTPDigestAuthHandler
+from .monkeys import Request as _Request, HTTPBasicAuthHandler, HTTPDigestAuthHandler
-        'digest': _HTTPDigestAuthHandler,
+        'basic': HTTPBasicAuthHandler,
-Monkey patches to urllib2 and the like.
+Urllib2 Monkey patches.
-class _Request(urllib2.Request):
+class Request(urllib2.Request):
-class _HTTPBasicAuthHandler(urllib2.HTTPBasicAuthHandler):
+class HTTPBasicAuthHandler(urllib2.HTTPBasicAuthHandler):
-class _HTTPDigestAuthHandler(urllib2.HTTPDigestAuthHandler):
+class HTTPDigestAuthHandler(urllib2.HTTPDigestAuthHandler):
-    ~~~~~~~~~~~~~
+requests.core
-    This module implements the main Requests system.
+This module implements the main Requests system.
-from .packages.poster.streaminghttp import register_openers, get_handlers
+:copyright: (c) 2011 by Kenneth Reitz.
-    """An inappropriate method was attempted."""
+from .models import HTTPError, auth_manager
-        print r.__dict__
+class _HTTPBasicAuthHandler(urllib2.HTTPBasicAuthHandler):
-        self.response.content = resp.read()
+
-        'basic': urllib2.HTTPBasicAuthHandler,
+        'basic': _HTTPBasicAuthHandler,
-
+        # self.data = {}
-            # url encode data if it's a dict
+
-            self._enc_data = self.data
+            self._enc_data = data
-        # url encode data if it's a dict
+            for (k, v) in data.items():
-        
+
-                v.encode('utf-8') if v.__class__ is unicode else v
+                k.encode('utf-8') if isinstance(k, unicode) else k:
-        self.data = data
+        
-
+        requests.get('http://google.com', params={u'fÃ¸Ã¸': u'fÃ¸Ã¸'})
-version = '0.3.2'
+version = '0.3.3'
-__build__ = 0x000302
+__version__ = '0.3.3'
-    
+
-        
+
-            self._enc_data = urllib.urlencode(data)
+            self._enc_data = urllib.urlencode(self.data)
-            self._enc_data = data
+            self._enc_data = self.data
-    def _build_url(url, data):
+    def _build_url(url, data=None):
-extensions = ['sphinx.ext.autodoc', 'sphinx.ext.todo', 'sphinx.ext.coverage', 'sphinx.ext.pngmath', 'sphinx.ext.jsmath', 'sphinx.ext.viewcode']
+extensions = ['sphinx.ext.autodoc']
-
+    :param timeout: (optional) Float describing the timeout of the request.
-
+    
-                timeout=kwargs.pop('timeout', None))
+                timeout=kwargs.pop('timeout', requests.timeout))
-def get(url, params={}, headers={}, cookies=None, auth=None, timeout=None):
+def get(url, params={}, headers={}, cookies=None, auth=None, **kwargs):
-    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
+    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth, **kwargs)
-def head(url, params={}, headers={}, cookies=None, auth=None, timeout=None):
+def head(url, params={}, headers={}, cookies=None, auth=None, **kwargs):
-    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
+    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth, **kwargs)
-def post(url, data={}, headers={}, files=None, cookies=None, auth=None, timeout=None):
+def post(url, data={}, headers={}, files=None, cookies=None, auth=None, **kwargs):
-    return request('POST', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth, timeout=timeout)
+    return request('POST', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth, **kwargs)
-def put(url, data='', headers={}, files={}, cookies=None, auth=None, timeout=None):
+def put(url, data='', headers={}, files={}, cookies=None, auth=None, **kwargs):
-    return request('PUT', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth, timeout=timeout)
+    return request('PUT', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth, **kwargs)
-def delete(url, params={}, headers={}, cookies=None, auth=None, timeout=None):
+def delete(url, params={}, headers={}, cookies=None, auth=None, **kwargs):
-    return request('DELETE', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
+    return request('DELETE', url, params=params, headers=headers, cookies=cookies, auth=auth, **kwargs)
-                 data=dict(), auth=None, cookiejar=None):
+                 data=dict(), auth=None, cookiejar=None, timeout=None):
-                auth=kwargs.pop('auth', auth_manager.get_auth(url)))
+                auth=kwargs.pop('auth', auth_manager.get_auth(url)),
-def get(url, params={}, headers={}, cookies=None, auth=None):
+def get(url, params={}, headers={}, cookies=None, auth=None, timeout=None):
-    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth)
+    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
-def head(url, params={}, headers={}, cookies=None, auth=None):
+def head(url, params={}, headers={}, cookies=None, auth=None, timeout=None):
-    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth)
+    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
-def post(url, data={}, headers={}, files=None, cookies=None, auth=None):
+def post(url, data={}, headers={}, files=None, cookies=None, auth=None, timeout=None):
-    return request('POST', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth)
+    return request('POST', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth, timeout=timeout)
-def put(url, data='', headers={}, files={}, cookies=None, auth=None):
+def put(url, data='', headers={}, files={}, cookies=None, auth=None, timeout=None):
-    return request('PUT', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth)
+    return request('PUT', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth, timeout=timeout)
-def delete(url, params={}, headers={}, cookies=None, auth=None):
+def delete(url, params={}, headers={}, cookies=None, auth=None, timeout=None):
-    return request('DELETE', url, params=params, headers=headers, cookies=cookies, auth=auth)
+    return request('DELETE', url, params=params, headers=headers, cookies=cookies, auth=auth, timeout=timeout)
-    
+
-    
+
-# if python > 2.6, require simplejson
+if sys.version_info[:2] < (2,6):
-version = '0.2.0'
+version = '0.3.2'
-release = '0.2.0'
+release = version
-__build__ = 0x000301
+__version__ = '0.3.2'
-        print bin.url
+    def test_autoauth(self):
-        return self._auth.get(uri, None)
+        (in_domain, in_path) = self.reduce_uri(uri, False)
-        
+
-        
+
-        
+
-        
+
-  
+
-    
+
-    
+
-    
+
-    
+
-        
+
-        self.response.url = getattr(resp, 'url', None)
+        if self.response.headers.get('content-encoding', None) == 'gzip':
-    'auth_manager', 'AuthObject','RequestException', 'AuthenticationError', 
+    'Request', 'Response', 'request', 'get', 'head', 'post', 'put', 'delete',
-        
+
-        
+
-        
+
-                    
+
-                
+
-                    
+
-    def read(self):
+    def read(self, *args):
-    
+
-    def read(self):
+    def read(self, *args):
-    
+
-        
+
-            
+
-        
+
-    
+
-    
+
-__build__ = 0x000300
+__version__ = '0.3.1'
-        return self.content
+        return self.response.read()
-
+    def read(self):
-        else:
+        if not _handlers:
-
+
-        if self.cookiejar:
+        if self.cookiejar is not None:
-                if self.cookiejar:
+                if self.cookiejar is not None:
-        if self.cookiejar != None:
+        if self.cookiejar:
-                if self.cookiejar != None:
+                if self.cookiejar:
-                cookiejar=kwargs.pop('cookiejar', None), files=kwargs.pop('files', None),
+                cookiejar=kwargs.pop('cookies', None), files=kwargs.pop('files', None),
-    return request('GET', url, params=params, headers=headers, cookiejar=cookies, auth=auth)
+    return request('GET', url, params=params, headers=headers, cookies=cookies, auth=auth)
-    return request('HEAD', url, params=params, headers=headers, cookiejar=cookies, auth=auth)
+    return request('HEAD', url, params=params, headers=headers, cookies=cookies, auth=auth)
-    return request('POST', url, data=data, headers=headers, files=files, cookiejar=cookies, auth=auth)
+    return request('POST', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth)
-    return request('PUT', url, data=data, headers=headers, files=files, cookiejar=cookies, auth=auth)
+    return request('PUT', url, data=data, headers=headers, files=files, cookies=cookies, auth=auth)
-    return request('DELETE', url, params=params, headers=headers, cookiejar=cookies, auth=auth)
+    return request('DELETE', url, params=params, headers=headers, cookies=cookies, auth=auth)
-            req.headers = self.headers
+            req.headers.update(self.headers)
-                resp =  opener(req)
+                resp = opener(req)
-                cookiejar=kwargs.pop('cookies', None), files=kwargs.pop('files', None),
+                cookiejar=kwargs.pop('cookiejar', None), files=kwargs.pop('files', None),
-        # TODO: postbin w/ params
+
-        print bin.url
+        
-        
+
-        
+        self.assertEqual(bin.status_code, 200)
-        bin = requests.get('http://www.postbin.org/')
+        bin = requests.post('http://www.postbin.org/')
-    
+
-        # self.assertEqual(post2.status_code, 200)
+        self.assertEqual(post2.status_code, 201)
-            self.data = urllib.urlencode(data)
+            self._enc_data = urllib.urlencode(data)
-            self.data = data
+            self._enc_data = data
-            req = _Request(self._build_url(self.url, self.data), method=self.method)
+            req = _Request(self._build_url(self.url, self._enc_data), method=self.method)
-#                self.files
+
-                    req.data = self.data
+                req = _Request(self.url, data=self._enc_data, method=self.method)
-                req.data = self.data
+                if self.data:
-    data = kwargs.get('data', None) or kwargs.get('params', None)
+    data = kwargs.pop('data', dict()) or kwargs.pop('params', dict())
-                auth=kwargs.get('auth', auth_manager.get_auth(url)))
+    r = Request(method=method, url=url, data=data, headers=kwargs.pop('headers', {}),
-        self.assertEqual(bin.status_code, 200)
+        h = {'Content-type': 'application/x-www-form-urlencoded'}
-        self.assertEqual(post.status_code, 200)
+        # post = requests.post(bin.url, data={'some': 'data'})
-        self.assertEqual(post2.status_code, 200)
+        # post2 = requests.post(bin.url, files={'some': open('test_requests.py')})
-        # post2 = requests.post(bin.url, files={'some': open('test_requests.py')}, data={'some': 'data'})
+        post2 = requests.post(bin.url, files={'some': open('test_requests.py')}, data={'some': 'data'})
-
+    
-
+    
-
+    
-
+    
-
+    
-
+    
-                 unverifiable=False, method=None):
+    def __init__(self, url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None):
-        if isinstance(data, dict):
+        if hasattr(data, 'items'):
-            req = _Request(("%s?%s" % (self.url, self.data)), method=self.method)
+            req = _Request(self._build_url(self.url, self.data), method=self.method)
-    data = kwargs.pop('data', {}) or kwargs.pop('params', {})
+    data = kwargs.get('data', None) or kwargs.get('params', None)
-                auth=kwargs.pop('auth', auth_manager.get_auth(url)))
+    r = Request(method=method, url=url, data=data, headers=kwargs.get('headers', {}),
-
+    
-        
+
-__build__ = 0x000205
+__version__ = '0.3.0'
-    ~~~~~~~~~~~~~
+    requests.async
-    This module implements the main Requests system.
+    This module implements the main Requests system, after monkey-patching
-__copyright__ = 'Copyright 2011 Kenneth Reitz'
+
-           'RequestException', 'AuthenticationError', 'URLRequired', 'InvalidMethod', 'HTTPError']
+
-__author__ = 'Kenneth Reitz, Dj Gilcrease'
+__author__ = 'Kenneth Reitz'
-            _handlers += get_handlers()
+            _handlers.extend(get_handlers())
-from .packages.poster.streaminghttp import register_openers
+from .packages.poster.streaminghttp import register_openers, get_handlers
-    opener = urllib2.build_opener(*handlers)
+    opener = urllib2.build_opener(*get_handlers())
-        self.response.headers = resp.info().dict
+        self.response.status_code = getattr(resp, 'code', None)
-def put(url, data=b'', headers={}, files={}, cookies=None, auth=None):
+def put(url, data='', headers={}, files={}, cookies=None, auth=None):
-__copyright__ = 'Copyright 2011 Dj Gilcrease'
+__copyright__ = 'Copyright 2011 Kenneth Reitz'
-        self.handler = self._handlers.get(handler.lower(), urllib2.HTTPBasicAuthHandler)
+        if isinstance(handler, basestring):
-__all__ = ['Request', 'Response', 'request', 'get', 'head', 'post', 'put', 'delete', 'add_autoauth', 'AUTOAUTHS',
+__all__ = ['Request', 'Response', 'request', 'get', 'head', 'post', 'put', 'delete', 'auth_manager', 'AuthObject',
-__all__ = ['Request', 'Response', 'request', 'get', 'head', 'post', 'put', 'delete', 'add_autoauth', 'AUTOAUTHS',
+__all__ = ['Request', 'Response', 'request', 'get', 'head', 'post', 'put', 'delete', 'auth_manager', 'AuthObject',
-__author__ = 'Kenneth Reitz'
+__author__ = 'Kenneth Reitz, Dj Gilcrease'
-
+        if isinstance(auth, (list, tuple)):
-                auth_handler = urllib2.HTTPBasicAuthHandler(authr)
+        if self.auth:
-                _handlers.append(cookie_handler)
+            _handlers.append(self.auth.handler)
-        self.response.headers = resp.info().dict
+        self.response.headers = resp.info().dict or resp.headers
-                self.response.cached = False
+
-                auth=_detect_auth(url, kwargs.pop('auth', None)))
+                auth=kwargs.pop('auth', auth_manager.get_auth(url)))
-                    auth=_detect_auth(url, auth))
+    return request('GET', url, params=params, headers=headers, cookiejar=cookies, auth=auth)
-                    auth=_detect_auth(url, auth))
+    return request('HEAD', url, params=params, headers=headers, cookiejar=cookies, auth=auth)
-                    auth=_detect_auth(url, auth))
+    return request('POST', url, data=data, headers=headers, files=files, cookiejar=cookies, auth=auth)
-                    auth=_detect_auth(url, auth))
+    return request('PUT', url, data=data, headers=headers, files=files, cookiejar=cookies, auth=auth)
-
+    return request('DELETE', url, params=params, headers=headers, cookiejar=cookies, auth=auth)
-        requests.AUTOAUTHS = []
+        requests.auth_manager.empty()
-__build__ = 0x000204
+__version__ = '0.2.5'
-
+__all__ = ['Request', 'Response', 'request', 'get', 'head', 'post', 'put', 'delete', 'add_autoauth', 'AUTOAUTHS',
-    
+
-    
+
-    
+
-                 params=dict(), data=dict(), auth=None, cookiejar=None):
+                 data=dict(), auth=None, cookiejar=None):
-        self.data = data
+
-        
+
-        
+
-    
+
-        
+
-    
+
-                authr.add_password(None, self.url, self.auth.username, self.auth.password)
+                authr.add_password(None, self.url, self.auth[0], self.auth[1])
-        
+
-    
+
-                    params = self.params
+            req = _Request(("%s?%s" % (self.url, self.data)), method=self.method)
-                req = _Request(("%s?%s" % (self.url, params)), method=self.method)
+            if self.data:
-                    req.headers = self.headers
+        if self.headers:
-        
+
-        
+
-        
+        self.cached = False
-        
+
-        
+
-    :param password: Password for given username.
+def request(method, url, **kwargs):
-        self.password = password
+    data = kwargs.pop('data', {}) or kwargs.pop('params', {})
-    return r.response
+
-    return r.response
+
-    :param data: (optional) Dictionary of POST Data to send with the :class:`Request`.
+    :param data: (optional) Dictionary of POST data to send with the :class:`Request`.
-def put(url, data='', headers={}, files={}, cookies=None, auth=None):
+
-    :param data: (optional) Bytes of PUT Data to send with the :class:`Request`.
+    :param params: (optional) Bytes of PUT Data to send with the :class:`Request`.
-    return r.response
+    return request('PUT', url, data=data, headers=headers, files=files, cookiejar=cookies,
-    :param params: (optional) Dictionary of GET Parameters to send with the :class:`Request`.
+    :param params: (optional) Dictionary of DELETE Parameters to send with the :class:`Request`.
-    return r.response
+
-    
+
-    
+
-    
+
-        if autoauth_url in url: 
+        if autoauth_url in url:
-            
+
-    
+
-    
+
-    
+
-        
+
-        auth = requests.AuthObject('requeststest', 'requeststest')
+        auth = ('requeststest', 'requeststest')
-        bin = requests.post('http://www.postbin.org/')
+        bin = requests.get('http://www.postbin.org/')
-        self.assertEqual(post.status_code, 201)
+        self.assertEqual(post.status_code, 200)
-
+        self.assertEqual(post2.status_code, 200)
-    
+
-
+from core import __version__
-        # 'Development Status :: 5 - Production/Stable',
+        'Development Status :: 5 - Production/Stable',
-        # 'Programming Language :: Python :: 2.5',
+        'Programming Language :: Python :: 2.5',
-    version='0.2.3',
+    version=requests.__version__,
-__build__ = 0x000203
+__version__ = '0.2.4'
-from .core import *
+import packages
-
+        requests.add_autoauth(url, auth)
-        post2 = requests.post(bin.url, files={'some': StringIO('data')})
+        post2 = requests.post(bin.url, files={'some': open('test_requests.py')})
-from core import *
+from __future__ import absolute_import
-    from StringIO import StringIO
+if sys.version_info >= (3,0):
-from cStringIO import StringIO
+
-from .core import *
+import packages
-                except urllib2.HTTPError as why:
+                except urllib2.HTTPError, why:
-                except urllib2.HTTPError as why:
+                except urllib2.HTTPError, why:
-                except urllib2.HTTPError as why:
+                except urllib2.HTTPError, why:
-	eventlet.monkey_patch()
+    import eventlet
-	pass
+    pass
-		pass
+    try:
-	"""Hidden wrapper around the urllib2.Request object. Allows for manual
+    """Hidden wrapper around the urllib2.Request object. Allows for manual
-		self.method = method
+    
-			return self.method
+    def get_method(self):
-		return urllib2.Request.get_method(self)
+        return urllib2.Request.get_method(self)
-	"""The :class:`Request` object. It carries out all functionality of
+    """The :class:`Request` object. It carries out all functionality of
-		"""Sends the request. Returns True of successful, false if not.
+    
-		self._checks()
+        self._checks()
-		success = False
+        success = False
-			if (not self.sent) or anyway:
+        if self.method in ('GET', 'HEAD', 'DELETE'):
-					params = self.params
+                # url encode GET params if it's a dict
-				req = _Request(("%s?%s" % (self.url, params)), method=self.method)
+                req = _Request(("%s?%s" % (self.url, params)), method=self.method)
-					req.headers = self.headers
+                if self.headers:
-				opener = self._get_opener()
+                opener = self._get_opener()
-					self.response.ok = True
+                try:
-					self.response.error = why
+                except urllib2.HTTPError as why:
-			if (not self.sent) or anyway:
+        elif self.method == 'PUT':
-					req = _Request(self.url, data=datagen, headers=headers, method='PUT')
+                if self.files:
-						req.headers.update(self.headers)
+                    if self.headers:
-				else:
+                else:
-					req = _Request(self.url, method='PUT')
+                    req = _Request(self.url, method='PUT')
-						req.headers = self.headers
+                    if self.headers:
-					req.data = self.data
+                    req.data = self.data
-					resp =  opener(req)
+                try:
-					self.response.ok = True
+                    self._build_response(resp)
-					self.response.error = why
+                except urllib2.HTTPError as why:
-			if (not self.sent) or anyway:
+        elif self.method == 'POST':
-					req = _Request(self.url, data=datagen, headers=headers, method='POST')
+                if self.files:
-					req.headers = self.headers
+                    if self.headers:
-						req.data = self.data
+                    # url encode form data if it's a dict
-					resp =  opener(req)
+                try:
-					self.response.ok = True
+                    self._build_response(resp)
-		
+                except urllib2.HTTPError as why:
-	"""The :class:`Request` object. All :class:`Request` objects contain a
+    """The :class:`Request` object. All :class:`Request` objects contain a
-	
+    def __init__(self):
-	"""The :class:`AuthObject` is a simple HTTP Authentication token. When
+    """The :class:`AuthObject` is a simple HTTP Authentication token. When
-		self.password = password
+    
-	"""Sends a GET request. Returns :class:`Response` object.
+    """Sends a GET request. Returns :class:`Response` object.
-	return r.response
+    
-	"""Sends a HEAD request. Returns :class:`Response` object.
+    """Sends a HEAD request. Returns :class:`Response` object.
-	return r.response
+    r = Request(method='HEAD', url=url, params=params, headers=headers,
-	"""Sends a POST request. Returns :class:`Response` object.
+    """Sends a POST request. Returns :class:`Response` object.
-	
+    
-	"""Sends a PUT request. Returns :class:`Response` object.
+    """Sends a PUT request. Returns :class:`Response` object.
-	return r.response
+    r = Request(method='PUT', url=url, data=data, headers=headers, files=files,
-	
+    
-	"""Sends a DELETE request. Returns :class:`Response` object.
+    """Sends a DELETE request. Returns :class:`Response` object.
-	return r.response
+    
-	"""Registers given AuthObject to given URL domain. for auto-activation.
+    """Registers given AuthObject to given URL domain. for auto-activation.
-	AUTOAUTHS.append((url, authobject))
+    global AUTOAUTHS
-	"""Returns registered AuthObject for given url if available, defaulting to
+    """Returns registered AuthObject for given url if available, defaulting to
-	return _get_autoauth(url) if not auth else auth
+    return _get_autoauth(url) if not auth else auth
-	
+    
-	return None
+    """Returns registered AuthObject for given url if available."""
-	"""There was an ambiguous exception that occured while handling your
+    """There was an ambiguous exception that occured while handling your
-	
+    """The authentication credentials provided were invalid."""
-	
+    """A valid URL is required to make a request."""
-	"""An inappropriate method was attempted."""
+    """An inappropriate method was attempted."""
-	
+    
-	sys.exit()
+    os.system("python setup.py sdist upload")
-	
+    os.system("python test_requests.py")
-		'Programming Language :: Python',
+    name='requests',
-	),
+        'Programming Language :: Python :: 2.7',
-		pass
+    """Requests test cases."""
-		self.assertRaises(ValueError, requests.get, 'hiwpefhipowhefopw')
+    def tearDown(self):
-		self.assertEqual(r.status_code, 200)
+    def test_HTTP_200_OK_GET(self):
-		self.assertEqual(r.status_code, 200)
+    def test_HTTPS_200_OK_GET(self):
-		self.assertEqual(r.status_code, 200)
+    def test_HTTP_200_OK_HEAD(self):
-		self.assertEqual(r.status_code, 200)
+    def test_HTTPS_200_OK_HEAD(self):
-		r = requests.get(url, auth=auth)
+    def test_AUTH_HTTPS_200_OK_GET(self):
-		self.assertEqual(r.status_code, 200)
+        self.assertEqual(r.status_code, 200)
-	def test_POSTBIN_GET_POST_FILES(self):
+    def test_POSTBIN_GET_POST_FILES(self):
-		self.assertEqual(bin.status_code, 200)
+        bin = requests.post('http://www.postbin.org/')
-		self.assertEqual(post.status_code, 201)
+        post = requests.post(bin.url, data={'some': 'data'})
-		self.assertEqual(post2.status_code, 201)
+        post2 = requests.post(bin.url, files={'some': StringIO('data')})
-		self.assertEqual(bool(r), True)
+    def test_nonzero_evaluation(self):
-		self.assertEqual(r.ok, False)
+    def test_request_ok_set(self):
-		self.assertRaises(requests.HTTPError, r.raise_for_status)
+    def test_status_raising(self):
-		r.raise_for_status()
+        r = requests.get('http://google.com/')
-	unittest.main()
+    unittest.main()
-		urllib2.Request.__init__( self, url, data, headers, origin_req_host, unverifiable)
+	def __init__(self, url, data=None, headers={}, origin_req_host=None,
-	def __init__(self, url=None, headers=dict(), files=None, method=None, params=dict(), data=dict(), auth=None, cookiejar=None):
+	def __init__(self, url=None, headers=dict(), files=None, method=None,
-	r = Request(method='GET', url=url, params=params, headers=headers, cookiejar=cookies, auth=_detect_auth(url, auth))
+	r = Request(method='GET', url=url, params=params, headers=headers,
-	r = Request(method='HEAD', url=url, params=params, headers=headers, cookiejar=cookies, auth=_detect_auth(url, auth))
+	r = Request(method='HEAD', url=url, params=params, headers=headers,
-	r = Request(method='POST', url=url, data=data, headers=headers, files=files, cookiejar=cookies, auth=_detect_auth(url, auth))
+	r = Request(method='POST', url=url, data=data, headers=headers,
-	r = Request(method='PUT', url=url, data=data, headers=headers, files=files, cookiejar=cookies, auth=_detect_auth(url, auth))	
+	r = Request(method='PUT', url=url, data=data, headers=headers, files=files,
-	r = Request(method='DELETE', url=url, params=params, headers=headers, cookiejar=cookies, auth=_detect_auth(url, auth))
+	r = Request(method='DELETE', url=url, params=params, headers=headers,
-	"""There was an ambiguous exception that occured while handling your request."""
+	"""There was an ambiguous exception that occured while handling your
-
+
-		self.data = {}
+	def __init__(self, url=None, headers=dict(), files=None, method=None, params=dict(), data=dict(), auth=None, cookiejar=None):
-		self.cookiejar = None
+		self.auth = auth
-	
+	r = Request(method='GET', url=url, params=params, headers=headers, cookiejar=cookies, auth=_detect_auth(url, auth))
-	
+	r = Request(method='HEAD', url=url, params=params, headers=headers, cookiejar=cookies, auth=_detect_auth(url, auth))
-	
+	r = Request(method='POST', url=url, data=data, headers=headers, files=files, cookiejar=cookies, auth=_detect_auth(url, auth))
-	
+
-	
+	r = Request(method='DELETE', url=url, params=params, headers=headers, cookiejar=cookies, auth=_detect_auth(url, auth))
-
+from __future__ import absolute_import
-	version='0.2.2',
+	version='0.2.3',
-__build__ = 0x000202
+__version__ = '0.2.3'
-
+	def test_nonzero_evaluation(self):
-	def raise_for_response(self):
+	def raise_for_status(self):
-		self.error = False
+		self.error = None
-					success = True
+					self.response.ok = True
-					success = False
+					self.response.error = why
-					success = True
+					self.response.ok = True
-					success = False
+					self.response.error = why
-					success = True
+					self.response.ok = True
-
+					self.response.error = why
-		self.sent = True if success else False
+		self.sent = self.response.ok
-		return success
+		return self.sent
-__build__ = 0x000201
+__version__ = '0.2.2'
-	version='0.2.1',
+	version='0.2.2',
-    :param headers: (optional) Dictionary of HTTP Headers to sent with the :class:`Request`.
+    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
-		"""Deterministic checks for consistiency."""
+		"""Deterministic checks for consistency."""
-def get(url, params={}, headers={}, auth=None):
+def get(url, params={}, headers={}, cookies=None, auth=None):
-def head(url, params={}, headers={}, auth=None):
+def head(url, params={}, headers={}, cookies=None, auth=None):
-def post(url, data={}, headers={}, files=None, auth=None):
+def post(url, data={}, headers={}, files=None, cookies=None, auth=None):
-def put(url, data='', headers={}, files={}, auth=None):
+def put(url, data='', headers={}, files={}, cookies=None, auth=None):
-def delete(url, params={}, headers={}, auth=None):
+def delete(url, params={}, headers={}, cookies=None, auth=None):
-#
+
-			authr = urllib2.HTTPPasswordMgrWithDefaultRealm()
+		if self.auth or self.cookiejar:
-			auth_handler = urllib2.HTTPBasicAuthHandler(authr)
+			if self.auth:
-			_handlers.append(auth_handler)
+				authr = urllib2.HTTPPasswordMgrWithDefaultRealm()
-			_handlers.append(cookie_handler)
+				authr.add_password(None, self.url, self.auth.username, self.auth.password)
-		return opener.open
+				_handlers.append(auth_handler)
-	
+#
-			# create a password manager
+			
-#			return opener.open
+		
-#			return urllib2.urlopen
+		
-		
+
-			opener = urllib2.build_opener(handler)
+			auth_handler = urllib2.HTTPBasicAuthHandler(authr)
-			return urllib2.urlopen
+#			return opener.open
-try:
+if not 'eventlet' in locals():
-	from eventlet.green import urllib2
+	from gevent import monkey 
-	import urllib2
+	pass
-import urllib2
+try:
-					sself._build_response(why)
+					self._build_response(why)
-	
+
-		"""Sends the request. Returns True of successfull, false if not.
+		"""Sends the request. Returns True of successful, false if not.
-
+					self._build_response(resp)
-					self.response.status_code = why.code
+					self._build_response(why)
-
+					self._build_response(resp)
-					self.response.status_code = why.code
+					self._build_response(why)
-
+					self._build_response(resp)
-					self.response.status_code = why.code
+					sself._build_response(why)
-
+	
-	publish()
+	os.system("python setup.py sdist upload")
-	description='Python HTTP Library that\'s actually usable.',
+	description='Awesome Python HTTP Library that\'s actually usable.',
-__build__ = 0x000200
+__version__ = '0.2.1'
-	version='0.2.0',
+	version='0.2.1',
-		self.multipart_files = None
+		self.files = None
-				if self.multipart_files:
+				if self.files:
-					datagen, headers = multipart_encode(self.multipart_files)
+					datagen, headers = multipart_encode(self.files)
-				if self.multipart_files:
+				if self.files:
-					datagen, headers = multipart_encode(self.multipart_files)
+					datagen, headers = multipart_encode(self.files)
-def post(url, data={}, headers={}, multipart_files=None, auth=None):
+def post(url, data={}, headers={}, files=None, auth=None):
-    :param multipart_files: (optional) Dictoinary of 'filename': file-like-objects for multipart encoding upload.
+    :param files: (optional) Dictionary of 'filename': file-like-objects for multipart encoding upload.
-		r.multipart_files = multipart_files
+	if files:
-def put(url, data='', headers={}, multipart_files={}, auth=None):
+def put(url, data='', headers={}, files={}, auth=None):
-    :param multipart_files: (optional) Dictoinary of 'filename': file-like-objects for multipart encoding upload.
+    :param files: (optional) Dictionary of 'filename': file-like-objects for multipart encoding upload.
-	
+	r.files = files
-					if self.method.lower() == 'get':
+					if self.method == 'GET':
-				req = _Request(self.url, method='PUT')
+				if self.multipart_files:
-					req.headers = self.headers
+					if self.headers:
-				req.data = self.data
+				else:
-from .core import *
+from . import packages
-import poster
+from . import poster
-import encode
+from . import streaminghttp
-				except urllib2.HTTPError, why:
+				except urllib2.HTTPError as why:
-				except urllib2.HTTPError, why:
+				except urllib2.HTTPError as why:
-				except(urllib2.HTTPError, why):
+				except urllib2.HTTPError as why:
-		
+
-		return repr
+		return '<Request [%s]>' % (self.method)
-				except urllib2.HTTPError, why:
+				except(urllib2.HTTPError, why):
-		return repr
+		return '<Response [%s]>' % (self.status_code)
-from poster.streaminghttp import register_openers
+from .packages.poster.encode import multipart_encode
-				req = _Request(self.url, method='POST')
+				if self.multipart_files:
-				if self.headers:
+					if self.headers:
-					req.data = self.data
+
-def post(url, data={}, headers={}, multipart_files={}, auth=None):
+def post(url, data={}, headers={}, multipart_files=None, auth=None):
-
+	
-import poster.encode
+import streaminghttp
-def post(url, data={}, headers={}, auth=None):
+def post(url, data={}, headers={}, multipart_files={}, auth=None):
-def put(url, data='', headers={}, auth=None):
+def put(url, data='', headers={}, multipart_files={}, auth=None):
-		'License :: OSI Approved :: MIT License',
+		'License :: OSI Approved :: ISC License (ISCL)',
-    """Hidden wrapper around the urllib2.Request object. Allows for manual
+	"""Hidden wrapper around the urllib2.Request object. Allows for manual
-    """The :class:`Request` object. It carries out all functionality of
+	"""The :class:`Request` object. It carries out all functionality of
-	    """Deterministic checks for consistiency."""
+		"""Deterministic checks for consistiency."""
-	    """Creates appropriate opener object for urllib2."""
+		"""Creates appropriate opener object for urllib2."""
-	    """Sends the request. Returns True of successfull, false if not.
+		"""Sends the request. Returns True of successfull, false if not.
-    """The :class:`Request` object. All :class:`Request` objects contain a
+	"""The :class:`Request` object. All :class:`Request` objects contain a
-    """The :class:`AuthObject` is a simple HTTP Authentication token. When
+	"""The :class:`AuthObject` is a simple HTTP Authentication token. When
-    """Sends a GET request. Returns :class:`Response` object.
+	"""Sends a GET request. Returns :class:`Response` object.
-    """Sends a HEAD request. Returns :class:`Response` object.
+	"""Sends a HEAD request. Returns :class:`Response` object.
-    """Sends a POST request. Returns :class:`Response` object.
+	"""Sends a POST request. Returns :class:`Response` object.
-    """Sends a PUT request. Returns :class:`Response` object.
+	"""Sends a PUT request. Returns :class:`Response` object.
-    """Sends a DELETE request. Returns :class:`Response` object.
+	"""Sends a DELETE request. Returns :class:`Response` object.
-    """Registers given AuthObject to given URL domain. for auto-activation.
+	"""Registers given AuthObject to given URL domain. for auto-activation.
-    """Returns registered AuthObject for given url if available, defaulting to
+	"""Returns registered AuthObject for given url if available, defaulting to
-    """Returns registered AuthObject for given url if available."""
+	"""Returns registered AuthObject for given url if available."""
-    """There was an ambiguous exception that occured while handling your request."""
+	"""There was an ambiguous exception that occured while handling your request."""
-    """The authentication credentials provided were invalid."""
+	"""The authentication credentials provided were invalid."""
-    """A valid URL is required to make a request."""
+	"""A valid URL is required to make a request."""
-    """An inappropriate method was attempted."""
+	"""An inappropriate method was attempted."""
-	"""
+    """Hidden wrapper around the urllib2.Request object. Allows for manual
-	   	self.method = method
+	def __init__(self, url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None):
-	"""
+    """The :class:`Request` object. It carries out all functionality of
-		"""Deterministic checks for consistiency."""
+	    """Deterministic checks for consistiency."""
-		"""
+	    """Creates appropriate opener object for urllib2."""
-		    self.response.status_code will contain the HTTPError code.
+	    """Sends the request. Returns True of successfull, false if not.
-		
+
-	"""
+    """The :class:`Request` object. All :class:`Request` objects contain a
-	:param username: Username to authenticate with.
+    """The :class:`AuthObject` is a simple HTTP Authentication token. When
-	"""
+    """
-	"""Sends a GET request. Returns :class:`Response` object.
+    """Sends a GET request. Returns :class:`Response` object.
-	"""
+    :param url: URL for the new :class:`Request` object.
-	"""Sends a HEAD request. Returns :class:`Response` object.
+    """Sends a HEAD request. Returns :class:`Response` object.
-	"""
+    :param url: URL for the new :class:`Request` object.
-	"""Sends a POST request. Returns :class:`Response` object.
+    """Sends a POST request. Returns :class:`Response` object.
-	"""
+    :param url: URL for the new :class:`Request` object.
-	"""Sends a PUT request. Returns :class:`Response` object.
+    """Sends a PUT request. Returns :class:`Response` object.
-	"""
+    :param url: URL for the new :class:`Request` object.
-	"""Sends a DELETE request. Returns :class:`Response` object.
+    """Sends a DELETE request. Returns :class:`Response` object.
-	"""
+    :param url: URL for the new :class:`Request` object.
-	"""
+    """Registers given AuthObject to given URL domain. for auto-activation.
-	given AuthObject."""
+    """Returns registered AuthObject for given url if available, defaulting to
-	"""
+    """Returns registered AuthObject for given url if available."""
-	"""There was an ambiguous exception that occured while handling your request."""
+    """There was an ambiguous exception that occured while handling your request."""
-	"""The authentication credentials provided were invalid."""
+    """The authentication credentials provided were invalid."""
-	"""A valid URL is required to make a request."""
+    """A valid URL is required to make a request."""
-	"""An inappropriate method was attempted."""
+    """An inappropriate method was attempted."""
-from core import *
+from .core import *
-print requests.get('http://kennethreitz.com').headers
+class RequestsTestSuite(unittest.TestCase):
-r = requests.Request()
+	def tearDown(self):
-	version='0.0.1',
+	version='0.2.0',
-       self.method = method
+	"""Hidden wrapper around the urllib2.Request object. Allows for manual
-            return self.method
+	def get_method(self):
-        return urllib2.Request.get_method(self)
+		return urllib2.Request.get_method(self)
-	"""The :class:`Request` object. It's awesome.
+	"""The :class:`Request` object. It carries out all functionality of
-		"""Sends the request. 
+		"""Sends the request. Returns True of successfull, false if not.
-		   :param anyway: If True, request will be sent, even if it has already been sent.
+		    :param anyway: If True, request will be sent, even if it has
-	"""The :class:`Request` object. It's awesome.
+	"""The :class:`Request` object. All :class:`Request` objects contain a
-	"""The :class:`AuthObject` is a simple HTTP Authentication token.
+	"""The :class:`AuthObject` is a simple HTTP Authentication token. When
-	 """
+	"""
-__build__ = 0x000001
+__version__ = '0.2.0'
-	for (authauth_url, auth) in AUTOAUTHS:
+	for (autoauth_url, auth) in AUTOAUTHS:
-		pass
+		"""Deterministic checks for consistiency."""
-	
+		if not self.url:
-						params = self.params
+				# url encode GET params if it's a dict
-					req = _Request(("%s?%s" % (self.url, params)), method=self.method)
+					params = self.params
-						req.headers = self.headers
+				req = _Request(("%s?%s" % (self.url, params)), method=self.method)
-					resp = opener(req)
+				if self.headers:
-					try:
+				req = _Request(self.url, method='PUT')
-						req = _Request(self.url, method='PUT')
+				if self.headers:
-							req.headers = self.headers
+				req.data = self.data
-						req.data = self.data
+					self.response.status_code = resp.code
-						resp =  opener(req)
+					success = True
-						self.response.content = resp.read()
+				except urllib2.HTTPError, why:
-					req = _Request(self.url, method='POST')
+				req = _Request(self.url, method='POST')
-						req.headers = self.headers
+				if self.headers:
-						req.data = self.data
+				# url encode form data if it's a dict
-					
+
-					raise RequestException
+				except urllib2.HTTPError, why:
-	
+
-		
+
-	_METHODS = ('get', 'head', 'put', 'post', 'delete')
+	_METHODS = ('GET', 'HEAD', 'PUT', 'POST', 'DELETE')
-			if not value.lower() in self._METHODS:
+			if not value in self._METHODS:
-		if self.method.lower() in ('get', 'head', 'delete'):
+		if self.method in ('GET', 'HEAD', 'DELETE'):
-						req = _Request(("%s?%s" % (self.url, params)), method='DELETE')
+					req = _Request(("%s?%s" % (self.url, params)), method=self.method)
-		elif self.method.lower() == 'put':
+		elif self.method == 'PUT':
-		elif self.method.lower() == 'post':
+		elif self.method == 'POST':
-				except Exception:
+				except RequestException:
-						raise RequestException
+					except urllib2.HTTPError:
-	
+
-		if self.method.lower() in ('get', 'head'):
+		if self.method.lower() in ('get', 'head', 'delete'):
-					else:
+					elif self.method.lower() == 'head':
-				except RequestException:
+				except Exception:
-#						req.get_method = lambda : 'PUT'
+						req = _Request(self.url, method='PUT')
-						req.headers = self.headers
+						if self.headers:
-					resp = opener(req)
+						req.data = self.data
-					if self.method.lower() == 'get':
+						opener = self._get_opener()
-					success = True
+						success = True
-					req = urllib2.Request(self.url)
+					req = _Request(self.url, method='POST')
-						r.headers = self.headers
+						req.headers = self.headers
-						resp =  urllib2.urlopen(req)
+					opener = self._get_opener()
-
+					if self.method.lower() == 'get':
-					pass
+
-				except Exception:
+
-	
+
-	# return response object
+	r.data = data
-		if self.method.lower() == 'get':
+		if self.method.lower() in ('get', 'head'):
-					self.response.content = resp.read()
+					if self.method.lower() == 'get':
-def head(url, data={}, headers={}, auth=None):
+def head(url, params={}, headers={}, auth=None):
-	r.data = data
+	r.params = params
-		
+	
-						req.params = urllib.urlencode(self.params)
+					# url encode GET params if it's a dict
-					if self.auth:
+						params = self.params
-						password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
+					req = urllib2.Request("%s?%s" % (self.url, params))
-						opener = urllib2.build_opener(handler)
+					if self.headers:
-						resp =  urllib2.urlopen(req)
+					opener = self._get_opener()
-				except Exception:
+				except RequestException:
-					pass
+					req = urllib2.Request(self.url)
-		self.data = None
+		self.data = {}
-					success = True
+					pass
-					pass
+
-def head(url, params={}, headers={}, auth=None):
+def head(url, data={}, headers={}, auth=None):
-	
+	r.data = data
-def post(url, params={}, headers={}, auth=None):
+def post(url, data={}, headers={}, auth=None):
-	
+
-	# return response object
+	r.data = data
-		
+	
-				success = True
+				try:
-				pass
+				try:
-				pass
+				try:
-				pass
+				try:
-				pass
+				try:
-		#set self.response
+		else:
-			self.sent = True
+		
-		"""Sends the request. """
+	def send(self, anyway=False):
-		# return True / False
+		if success:
-import unittest
+import unittest
-AUTHOAUTHS = []
+AUTOAUTHS = []
-		self.response = None
+		self.response = Response()
-			if not val.lower() in _METHODS:
+	def __setattr__(self, name, value):
-	r.method = 'GET'
+	
-	pass
+	r = Request()
-	pass
+	r = Request()
-	pass
+	r = Request()
-	pass
+	r = Request()
-__title__ = 'convore'
+__title__ = 'requests'
-	_METHODS = ('get', 'put', 'post', 'delete')
+	_METHODS = ('get', 'head', 'put', 'post', 'delete')
-	
+
-	pass
+	"""Sends a GET request. Returns :class:`Response` object.
-	AUTHOAUTHS.append((url, authobject))
+	global AUTOAUTHS
-		set self.response()
+		"""Sends the request. """
-	"""An innappropriate method was attempted."""
+class InvalidMethod(RequestException):
-	pass
+	_METHODS = ('get', 'put', 'post', 'delete')
-def get():
+def get(url, params={}, headers={}, auth=None):
-def post():
+def head(url, params={}, headers={}, auth=None):
-def put():
+def put(url, data='', headers={}, auth=None):
-def delete():
+def delete(url, params={}, headers={}, auth=None):
-# -*- coding: utf-8 -*-
+# -*- coding: utf-8 -*-
