-                stream.wait_for_handshake(self.handshake_done)
+                with ignore_deprecation():
-                stream.wait_for_handshake(self.handshake_done)
+                with ignore_deprecation():
-                stream.wait_for_handshake(self.handshake_done)
+                with ignore_deprecation():
-                self.stream.wait_for_handshake(self.handshake2_done)
+                with ignore_deprecation():
-        super(SSLIOStream, self).connect(address, callback=lambda: None)
+        # Ignore the result of connect(). If it fails,
-from tornado.test.util import unittest, skipOnTravis
+from tornado.test.util import unittest, skipOnTravis, ignore_deprecation
-            stream.connect(('127.0.0.1', self.get_http_port()), self.stop)
+            with ignore_deprecation():
-        self.wait()
+        self.io_loop.run_sync(lambda: self.stream.connect(('127.0.0.1', self.get_http_port())))
-        self.wait()
+        self.io_loop.run_sync(lambda: self.stream.connect(self.sockfile))
-                       callback=connected_callback)
+        with ignore_deprecation():
-            stream.connect(("127.0.0.1", port), connect_callback)
+            with ignore_deprecation():
-                stream.connect(('localhost', 80), callback=self.stop)
+                with ignore_deprecation():
-        `StreamClosedError` when the stream is closed.
+        This mostly is not necessary for applications that use the
-                stream.write(b"""\
+                yield stream.write(b"""\
-""".replace(b"\n", b"\r\n"), callback=stream.close)
+""".replace(b"\n", b"\r\n"))
-                stream.write(b"""\
+                yield stream.write(b"""\
-""".replace(b"\n", b"\r\n"), callback=stream.close)
+""".replace(b"\n", b"\r\n"))
-                     callback=write_callback)
+        with ignore_deprecation():
-            self.respond_200)
+        with ignore_deprecation():
-            self.request.connection.stream.close)
+        with ignore_deprecation():
-        self._receive_frame()
+        IOLoop.current().add_callback(self._receive_frame_loop)
-    def _receive_frame(self):
+    @gen.coroutine
-                self.stream.read_bytes(2, self._on_frame_start)
+            while not self.client_terminated:
-        self._final_frame = header & self.FIN
+    def _read_bytes(self, n):
-        if self._decompressor is not None and self._frame_opcode != 0:
+        opcode = header & self.OPCODE_MASK
-        if self._frame_opcode_is_control and payloadlen >= 126:
+        is_masked = bool(mask_payloadlen & 0x80)
-        new_len = self._frame_length
+        if payloadlen < 126:
-        except StreamClosedError:
+            return
-        handled_future = None
+        # Read the payload, unmasking if necessary.
-        if self._frame_opcode_is_control:
+        # Decide what to do with this frame.
-            if not self._final_frame:
+            if not is_final_frame:
-        elif self._frame_opcode == 0:  # continuation frame
+        elif opcode == 0:  # continuation frame
-            if self._final_frame:
+            if is_final_frame:
-                self._fragmented_message_opcode = self._frame_opcode
+            if not is_final_frame:
-        if self._final_frame:
+        if is_final_frame:
-                self._receive_frame()
+            if handled_future is not None:
-        self.protocol._receive_frame()
+        IOLoop.current().add_callback(self.protocol._receive_frame_loop)
-           in Tornado 6.0. Use the returned `.Future` instead.
+           The ``callback`` and ``streaming_callback`` arguments are
-        self._streaming_callback = stack_context.wrap(streaming_callback)
+        if streaming_callback is not None:
-           in Tornado 6.0. Use the returned `.Future` instead.
+           The ``callback`` and ``streaming_callback`` arguments are
-        self._streaming_callback = stack_context.wrap(streaming_callback)
+        if streaming_callback is not None:
-            fut = rs.read_bytes(6, streaming_callback=streaming_callback)
+            with ignore_deprecation():
-        rs.read_until_close(streaming_callback=streaming_fut.set_result)
+        with ignore_deprecation():
-                yield rs.read_until_close(streaming_callback=chunks.append)
+                with ignore_deprecation():
-        logging.debug("handle_read")
+        data = yield stream.read_until(b"\n")
-            self.stream.write(b"error\talready capitalized\n")
+            stream.write(b"error\talready capitalized\n")
-        self.stream.close()
+            stream.write(utf8("ok\t%s" % data.upper()))
-            def write_response(stream, request_data):
+            @gen.coroutine
-            def write_response(stream, request_data):
+            @gen.coroutine
-from tornado import netutil
+from tornado import gen, netutil
-        data = self.wait()
+        yield stream.connect(("127.0.0.1", self.get_http_port()))
-        first_line = self.wait()
+        first_line = yield stream.read_until(b"\r\n")
-        header_data = self.wait()
+        header_data = yield stream.read_until(b"\r\n\r\n")
-        body = self.wait()
+        body = yield stream.read_bytes(int(headers["Content-Length"]))
-            self.wait()
+            yield self.stream.read_until_close()
-        response = self.wait()
+        response = yield self.stream.read_until(b"\r\n")
-        body = self.wait()
+        header_data = yield self.stream.read_until(b"\r\n\r\n")
-            response = self.wait()
+            response = yield self.stream.read_until_close()
-        self.wait()
+        yield self.stream.connect(('127.0.0.1', self.get_http_port()))
-        first_line = self.wait()
+        first_line = yield self.stream.read_until(b'\r\n')
-        header_bytes = self.wait()
+        header_bytes = yield self.stream.read_until(b'\r\n\r\n')
-        return headers
+        raise gen.Return(headers)
-        body = self.wait()
+        self.headers = yield self.read_headers()
-        self.connect()
+        yield self.connect()
-        self.read_response()
+        yield self.read_response()
-        self.read_response()
+        yield self.read_response()
-        self.connect()
+        yield self.connect()
-        data = self.wait()
+        yield self.read_response()
-        self.connect()
+        yield self.connect()
-        data = self.wait()
+        yield self.read_response()
-        self.connect()
+        yield self.connect()
-        self.read_response()
+        yield self.read_response()
-        self.read_response()
+        yield self.read_response()
-        self.connect()
+        yield self.connect()
-        self.read_response()
+        yield self.read_response()
-        self.read_response()
+        yield self.read_response()
-        self.connect()
+        yield self.connect()
-        self.read_response()
+        yield self.read_response()
-        self.connect()
+        yield self.connect()
-        self.read_response()
+        yield self.read_response()
-        self.connect()
+        yield self.connect()
-        self.wait()
+        yield self.read_headers()
-        self.connect()
+        yield self.connect()
-        self.read_headers()
+        yield self.read_headers()
-        self.connect()
+        yield self.connect()
-        self.read_response()
+        yield self.read_response()
-        self.read_response()
+        yield self.read_response()
-        self.wait()
+        yield stream.connect(('127.0.0.1', self.get_http_port()))
-        return stream
+        raise gen.Return(stream)
-        self.wait()
+        stream = yield self.connect()
-        stream.set_close_callback(lambda: self.stop("closed"))
+        stream = yield self.connect()
-            data = self.wait()
+            yield stream.read_until(b"\r\n\r\n")
-        self.assertEqual(data, "closed")
+        yield event.wait()
-from tornado.test.util import unittest, skipIfNonUnix, refusing_port, skipPypy3V58
+from tornado.test.util import (unittest, skipIfNonUnix, refusing_port, skipPypy3V58,
-        self.wait()
+        yield stream.connect(('127.0.0.1', self.get_http_port()))
-        data = self.wait()
+        data = yield stream.read_until_close()
-        self.wait()
+        yield self.stream.connect(("127.0.0.1", self.get_http_port()))
-        data = self.wait()
+        data = yield self.stream.read_bytes(9)
-        data = self.wait()
+        data = yield self.stream.read_bytes(0)
-        data = self.wait()
+        data = yield self.stream.read_bytes(3)
-            self.stop()
+            cond.notify()
-            self.stop()
+            cond.notify()
-            self.wait(lambda: connected[0] and written[0])
+            while not (connected[0] and written[0]):
-        data = self.wait()
+        data = yield stream.read_until_close()
-        self.wait()
+        rs, ws = yield self.make_iostream_pair()
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-                self.stop()
+                cond.notify()
-                          streaming_callback=streaming_callback)
+                cond.notify()
-            self.wait(condition=lambda: chunks)
+            while not chunks:
-            self.wait(condition=lambda: final_called)
+            while not final_called:
-            data = self.wait()
+            data = yield rs.read_bytes(2)
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-        data = self.wait()
+        data = yield rs.read_until(b"\r\n")
-        data = self.wait()
+        streaming_fut = Future()
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-                self.stop()
+                cond.notify()
-                                streaming_callback=streaming_callback)
+                cond.notify()
-            self.wait()
+            while len(chunks) != 1:
-            self.wait(condition=lambda: closed[0])
+            while not closed[0]:
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            self.io_loop.run_sync(f)
+            yield [rs_task(), ws_task()]
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            rs.set_close_callback(self.stop)
+            event = Event()
-                rs.read_bytes(1, callback2)
+                with ignore_deprecation():
-            self.wait()  # stopped by close_callback
+            with ignore_deprecation():
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-        def f(self):
+        try:
-            f(self)
+    @gen_test
-        rs, ws = self.make_iostream_pair(read_chunk_size=256)
+        rs, ws = yield self.make_iostream_pair(read_chunk_size=256)
-            data = self.wait()
+            data = yield rs.read_bytes(256)
-            data = self.wait()
+            yield gen.sleep(0.01)
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            data = self.wait()
+            data = yield rs.read_bytes(1)
-            data = self.wait()
+            data = yield rs.read_until_close()
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            data = self.wait()
+            data = yield rs.read_bytes(1)
-            self.assertEqual(b'', data)
+            final_future = Future()
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            data = self.wait()
+            data = yield rs.read_until(b"\r\n")
-        rs.set_close_callback(self.stop)
+        rs, ws = yield self.make_iostream_pair()
-            res = self.wait()
+            res = yield rs.read_until(b"\r\n")
-            rs.read_until(b"\r\n", lambda x: x)
+            with ignore_deprecation():
-            self.assertTrue(res is None)
+            yield event.wait()
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            self.stop()
+            cond.notify()
-            self.assertEqual(self.wait().result(), b'a')
+            res = yield rs.read_bytes(1)
-            self.wait()
+            yield cond.wait()
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            rs.read_bytes(4, self.stop)
+            fut = rs.read_bytes(4)
-            data = self.wait()
+            data = yield fut
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            rs.read_bytes(50, self.stop, partial=True)
+            fut = rs.read_bytes(50, partial=True)
-            data = self.wait()
+            data = yield fut
-            rs.read_bytes(3, self.stop, partial=True)
+            fut = rs.read_bytes(3, partial=True)
-            data = self.wait()
+            data = yield fut
-            data = self.wait()
+            data = yield rs.read_bytes(0, partial=True)
-        rs.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = yield self.make_iostream_pair()
-            rs.read_until(b"def", self.stop, max_bytes=50)
+            fut = rs.read_until(b"def", max_bytes=50)
-            data = self.wait()
+            data = yield fut
-            rs.read_until(b"def", self.stop, max_bytes=6)
+            fut = rs.read_until(b"def", max_bytes=6)
-            data = self.wait()
+            data = yield fut
-                rs.read_until(b"def", self.stop, max_bytes=5)
+                fut = rs.read_until(b"def", max_bytes=5)
-            self.assertEqual(data, "closed")
+                yield closed.wait()
-        rs.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = yield self.make_iostream_pair()
-            self.assertEqual(data, "closed")
+                with ignore_deprecation():
-        rs.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = yield self.make_iostream_pair()
-            self.assertEqual(data, "closed")
+                rs.read_until(b"def", max_bytes=5)
-        rs.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = yield self.make_iostream_pair()
-            rs.read_until_regex(b"def", self.stop, max_bytes=50)
+            fut = rs.read_until_regex(b"def", max_bytes=50)
-            data = self.wait()
+            data = yield fut
-            rs.read_until_regex(b"def", self.stop, max_bytes=6)
+            fut = rs.read_until_regex(b"def", max_bytes=6)
-            data = self.wait()
+            data = yield fut
-                rs.read_until_regex(b"def", self.stop, max_bytes=5)
+                rs.read_until_regex(b"def", max_bytes=5)
-            self.assertEqual(data, "closed")
+                yield closed.wait()
-        rs.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = yield self.make_iostream_pair()
-            self.assertEqual(data, "closed")
+                rs.read_until_regex(b"def", max_bytes=5)
-        rs.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = yield self.make_iostream_pair()
-            self.assertEqual(data, "closed")
+                rs.read_until_regex(b"def", max_bytes=5)
-        rs, ws = self.make_iostream_pair(max_buffer_size=10 * 1024)
+        rs, ws = yield self.make_iostream_pair(max_buffer_size=10 * 1024)
-                data = self.wait()
+                data = yield rs.read_bytes(1024)
-        rs, ws = self.make_iostream_pair(max_buffer_size=10 * 1024)
+        rs, ws = yield self.make_iostream_pair(max_buffer_size=10 * 1024)
-                data = self.wait()
+                data = yield rs.read_until(b"\n", max_bytes=4096)
-        rs, ws = self.make_iostream_pair(max_buffer_size=5 * MB)
+        rs, ws = yield self.make_iostream_pair(max_buffer_size=5 * MB)
-            self.wait()
+            yield rs.read_bytes(MB)
-                self.wait()
+                yield rs.read_bytes(MB)
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            rs.read_into(buf, callback=self.stop)
+            fut = rs.read_into(buf)
-            sleep_some()
+            yield gen.sleep(0.05)
-            data = self.wait()
+            data = yield fut
-            sleep_some()
+            fut = rs.read_into(buf)
-            data = self.wait()
+            data = yield fut
-            data = self.wait()
+            data = yield rs.read_into(buf)
-            data = self.wait()
+            data = yield rs.read_bytes(7)
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-            rs.read_into(buf, callback=self.stop, partial=True)
+            fut = rs.read_into(buf, partial=True)
-            data = self.wait()
+            data = yield fut
-            data = self.wait()
+            data = yield rs.read_into(buf, partial=True)
-            data = self.wait()
+            data = yield rs.read_into(buf, partial=True)
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-        def main():
+        try:
-            self.io_loop.run_sync(main)
+    @gen.coroutine
-        streams = [None, None]
+        server_stream_fut = Future()
-            self.stop()
+            server_stream_fut.set_result(self._make_server_iostream(connection, **kwargs))
-        self.wait(condition=lambda: all(streams))
+        connect_fut = client_stream.connect(('127.0.0.1', port))
-        return streams
+        raise gen.Return((server_stream, client_stream))
-        server, client = self.make_iostream_pair()
+        server, client = yield self.make_iostream_pair()
-            server.set_close_callback(self.stop)
+            closed = Event()
-                    server.read_bytes(1, callback=lambda data: 1 / 0)
+                    with ignore_deprecation():
-                self.wait()
+                yield closed.wait()
-        server, client = self.make_iostream_pair()
+        server, client = yield self.make_iostream_pair()
-                    client.read_until_close(self.stop)
+                    with ignore_deprecation():
-        server, client = self.make_iostream_pair()
+        server, client = yield self.make_iostream_pair()
-                server.read_bytes(1, lambda data: None)
+                server.read_bytes(1)
-        server.set_close_callback(self.stop)
+        server, client = yield self.make_iostream_pair()
-            server.read_bytes(1, lambda data: None)
+            with ignore_deprecation():
-                self.wait()
+                yield closed.wait()
-        server, client = self.make_iostream_pair(max_buffer_size=total_bytes)
+        server, client = yield self.make_iostream_pair(max_buffer_size=total_bytes)
-            self.io_loop.run_sync(main)
+            yield [produce() for i in range(nproducers)] + [consume()]
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-        data = self.wait()
+        data = yield rs.read_until(b' ')
-        data = self.wait()
+        data = yield rs.read_bytes(3)
-        data = self.wait()
+        data = yield rs.read_until_close()
-        rs, ws = self.make_iostream_pair()
+        rs, ws = yield self.make_iostream_pair()
-        data = self.wait()
+        data = yield rs.read_bytes(NUM_BYTES)
-        self.wait()
+        yield subproc.stdout.read_until(b'>>> ')
-        data = self.wait()
+        data = yield subproc.stdout.read_until(b'\n')
-        self.wait()
+        yield subproc.stdout.read_until(b">>> ")
-        data = self.wait()
+        data = yield subproc.stdout.read_until_close()
-        self.wait()
+        yield subproc.stdout.read_until(b'>>> ')
-        data = self.wait()
+        data = yield subproc.stdout.read_until_close()
-        data = self.wait()
+        data = yield subproc.stderr.read_until(b'\n')
-            self.stream.read_bytes(2, self._on_frame_start)
+            with ignore_deprecation():
-                self.stream.read_bytes(8, self._on_frame_length_64)
+            with ignore_deprecation():
-            self._on_masked_frame_data if masked else self._on_frame_data)
+        with ignore_deprecation():
-                self.stream.read_bytes(4, self._on_masking_key)
+                with ignore_deprecation():
-                self.stream.read_bytes(4, self._on_masking_key)
+                with ignore_deprecation():
-           variable ``PYTHONASYNCIODEBUG=1`` instead.
+           variable ``PYTHONASYNCIODEBUG=1`` instead. This method will be
-           variable ``PYTHONASYNCIODEBUG=1`` instead.
+           variable ``PYTHONASYNCIODEBUG=1`` instead. This method will be
-           the ``version`` attribute directly.
+
-           to write the response.
+           to write the response. This method will be removed in Tornado 6.0.
-           to write the response.
+           to write the response. This method will be removed in Tornado 6.0.
-            request.finish()
+            request.connection.write(utf8("HTTP/1.1 200 OK\r\n"
-        self.request.finish()
+        self.request.connection.finish()
-            Use `.HTTPMessageDelegate.on_connection_close` instead.
+        Note that this callback is slightly different from
-from tornado.escape import to_unicode
+from tornado.escape import to_unicode, utf8
-        self.write("ok")
+        self.stream = self.request.connection.detach()
-    def xtest_multiple_content_length_accepted(self):
+    def test_multiple_content_length_accepted(self):
-        self.assertEqual(response.code, 599)
+        with ExpectLog(gen_log, ".*Multiple unequal Content-Lengths"):
-    def __init__(self, callback, callback_time):
+    def __init__(self, callback, callback_time, jitter=0):
-import collections
+from tornado.queues import Queue
-        self.read_queue = collections.deque()
+        self.read_queue = Queue(1)
-            self.read_future = future
+
-            self.read_queue.append(message)
+            return self.read_queue.put(message)
-        addrinfo = yield Resolver().resolve('localhost', 80)
+        addrinfo = self.io_loop.run_sync(lambda: Resolver().resolve('localhost', 80))
-            result, error = callback_args.args
+            fut = Future()
-            request, 599, error=HTTPError(599, error_message),
+            request, 599, error=HTTPTimeoutError(error_message),
-        Raise a timeout HTTPError when a timeout occurs.
+        Raise a `HTTPTimeoutError` when a timeout occurs.
-            raise HTTPError(599, error_message)
+            raise HTTPTimeoutError(error_message)
-                    value = HTTPError(599, "Stream closed")
+                    value = HTTPStreamClosedError("Stream closed")
-            except HTTPError:
+                raise HTTPStreamClosedError(message)
-from tornado.httpclient import AsyncHTTPClient, HTTPError
+from tornado.httpclient import AsyncHTTPClient
-from tornado.simple_httpclient import SimpleAsyncHTTPClient
+from tornado.simple_httpclient import SimpleAsyncHTTPClient, HTTPStreamClosedError
-                self.assertEqual(str(response.error), "HTTP 599: Timeout while connecting")
+                self.assertEqual(str(response.error), "Timeout while connecting")
-        self.assertEqual(str(response.error), "HTTP 599: Timeout during request")
+        self.assertEqual(str(response.error), "Timeout during request")
-                self.assertEqual(str(response.error), "HTTP 599: Timeout in request queue")
+                self.assertEqual(str(response.error), "Timeout in request queue")
-            with self.assertRaises(HTTPError):
+            with self.assertRaises(HTTPStreamClosedError):
-            with self.assertRaises(HTTPError):
+            with self.assertRaises(HTTPStreamClosedError):
-class HTTPError(Exception):
+class HTTPClientError(Exception):
-        super(HTTPError, self).__init__(code, message, response)
+        super(HTTPClientError, self).__init__(code, message, response)
-from tornado import gen, httpclient
+from tornado import gen
-                with self.assertRaises(httpclient.HTTPError):
+                with self.assertRaises(HTTPClientError):
-                with self.assertRaises(httpclient.HTTPError):
+                with self.assertRaises(HTTPClientError):
-from tornado.httpclient import HTTPRequest
+from tornado.httpclient import HTTPRequest, HTTPClientError
-from tornado.test.util import unittest
+from tornado.test.util import unittest, ignore_deprecation
-            response = self.fetch(u'/ã¦ãã³ã¼ã')
+            with ignore_deprecation():
-                response.rethrow()
+                self.fetch("/auth", auth_username="Aladdin",
-                resp.rethrow()
+                self.fetch('/all_methods', method=method, raise_error=True)
-                resp.rethrow()
+                self.fetch('/all_methods', method=method, body=b'asdf', raise_error=True)
-                resp.rethrow()
+                self.fetch('/all_methods', method=method, body=b'asdf',
-        self.assertEqual(response.code, 599)
+                with self.assertRaises((IOError, HTTPError)):
-            self.assertEqual(response.code, 599)
+            with self.assertRaises((IOError, HTTPError)):
-        self.assertIn(response.code, (431, 599))
+            try:
-        self.assertIn(response.code, [400, 599])
+        self.assertEqual(response.code, 400)
-        self.assertIn(response.code, [400, 599])
+        self.assertEqual(response.code, 400)
-from tornado.httpclient import AsyncHTTPClient
+from tornado.httpclient import AsyncHTTPClient, HTTPError
-from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port, skipBefore35, exec_test, ignore_deprecation
+from tornado.testing import (AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase,
-        self.assertEqual(response.code, 599)
+        with ignore_deprecation():
-        self.assertEqual(response.code, 599)
+        with self.assertRaises(Exception):
-            response = self.fetch("http://127.0.0.1:%d/" % port)
+            with ignore_deprecation():
-        self.assertRaises(ssl.SSLError, resp.rethrow)
+            with self.assertRaises(ssl.SSLError):
-        self.assertRaises(ssl.SSLError, resp.rethrow)
+            with self.assertRaises(ssl.SSLError):
-            self.assertIsInstance(response.error, ssl.SSLError)
+            with self.assertRaises(ssl.SSLError):
-            response = self.fetch("/?error=1")
+            with ignore_deprecation():
-        self.assertEqual(response.code, 599)
+        with self.assertRaises(TypeError):
-        self.assertEqual(response.code, 599)
+            with self.assertRaises(UnsatisfiableReadError):
-        self.assertEqual(response.code, 599)
+            with self.assertRaises(HTTPError):
-        self.assertEqual(response.code, 599)
+            with self.assertRaises(HTTPError):
-from tornado.test.util import unittest, skipBefore35, exec_test
+from tornado.test.util import unittest, skipBefore35, exec_test, ignore_deprecation
-        response = self.fetch(path, request_timeout=0.1)
+        with ignore_deprecation():
-        response = self.fetch(path, request_timeout=0.1)
+        with ignore_deprecation():
-from tornado import gen
+from tornado import gen, httpclient
-        self.assertEqual(response.code, 599)
+                with self.assertRaises(httpclient.HTTPError):
-        self.assertEqual(response.code, 599)
+                with self.assertRaises(httpclient.HTTPError):
-        response = self.fetch('/')
+        with ignore_deprecation():
-    from tornado.httpclient import AsyncHTTPClient, HTTPError, HTTPResponse
+    from tornado.httpclient import AsyncHTTPClient
-    def fetch(self, path, **kwargs):
+    def fetch(self, path, raise_error=False, **kwargs):
-        ``raise_error=True`` option were used).
+        If ``raise_error`` is True, a `tornado.httpclient.HTTPError` will
-           errors that would be raised due to non-200 response codes.
+           errors other than `tornado.httpclient.HTTPError` will be
-            return HTTPResponse(None, 599, error=e, effective_url='unknown')
+        return self.io_loop.run_sync(
-from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port, skipBefore35, exec_test
+from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port, skipBefore35, exec_test, ignore_deprecation
-            self.assertEqual(str(response.error), "HTTP 599: Timeout while connecting")
+            with ignore_deprecation():
-            fut1.result()
+        with ignore_deprecation():
-    from tornado.httpclient import AsyncHTTPClient
+    from tornado.httpclient import AsyncHTTPClient, HTTPError, HTTPResponse
-        return self.io_loop.run_sync(lambda: self.http_client.fetch(url, raise_error=False, **kwargs))
+        try:
-            method="POST", body=urllib_parse.urlencode(args))
+        fut = http_client.fetch(url, method="POST", body=urllib_parse.urlencode(args))
-        if response.error or b"is_valid:true" not in response.body:
+    def _on_authentication_verified(self, future, response_fut):
-                                                 response.body)))
+                "Error response %s" % e))
-            http_client.fetch(
+            fut = http_client.fetch(
-                    callback))
+                                              extra_params=extra_params))
-                self._oauth_request_token_url(),
+            fut = http_client.fetch(self._oauth_request_token_url())
-                          functools.partial(self._on_access_token, callback))
+        fut = http_client.fetch(self._oauth_access_token_url(token))
-            raise Exception("Could not get request token: %s" % response.error)
+                          response_fut):
-        if response.error:
+    def _on_access_token(self, future, response_fut):
-                       callback=callback)
+            fut = http.fetch(url, method="POST", body=urllib_parse.urlencode(post_args))
-                                           (response.error, response.request.url)))
+            fut = http.fetch(url)
-        http_callback = functools.partial(self._on_twitter_request, callback)
+        http_callback = functools.partial(self._on_twitter_request, callback, url)
-                       callback=http_callback)
+            fut = http.fetch(url, method="POST", body=urllib_parse.urlencode(post_args))
-            http.fetch(url, callback=http_callback)
+            fut = http.fetch(url)
-        if response.error:
+    def _on_twitter_request(self, future, url, response_fut):
-                                                   response.request.url)))
+                "Error response %s fetching %s" % (e, url)))
-                   body=body)
+        fut = http.fetch(self._OAUTH_ACCESS_TOKEN_URL,
-    def _on_access_token(self, future, response):
+    def _on_access_token(self, future, response_fut):
-            future.set_exception(AuthError('Google auth error: %s' % str(response)))
+        try:
-                                     client_secret, callback, fields))
+        fut = http.fetch(self._oauth_request_token_url(**args))
-            future.set_exception(AuthError('Facebook auth error: %s' % str(response)))
+                         future, fields, response_fut):
-            self.client.fetch(new_request, final_callback)
+            fut = self.client.fetch(new_request, raise_error=False)
-from tornado.test.util import unittest, skipOnTravis
+from tornado.test.util import unittest, skipOnTravis, ignore_deprecation
-            resp = self.wait()
+            resp = self.fetch("http://127.0.0.1:%d/" % port)
-        response = self.wait()
+        response = self.fetch(url)
-            response = self.wait()
+            response = yield client.fetch(self.get_url('/user_agent'))
-            resp = self.wait()
+            resp = self.fetch("http://127.0.0.1:%d/" % port)
-                                   lambda response: 1 / 0)
+            with ignore_deprecation():
-                self.http_client.fetch(
+                response = self.fetch(
-            response = self.wait()
+            response = self.fetch(
-from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, ExpectLog, gen_test
-                             lambda response, i=i: (seen.append(i), self.stop()))
+                client.fetch(self.get_url("/trigger")).add_done_callback(
-            response = self.wait()
+            response = yield client.fetch(self.get_url('/countdown/3'),
-            response = self.wait()
+            response = yield client.fetch(self.get_url('/hello'),
-        response = self.wait()
+        response = self.fetch(url, allow_ipv6=False)
-        response = self.wait()
+        response = self.fetch(url)
-        response = self.wait()
+        response = self.fetch(url)
-            response = self.wait()
+            response = self.fetch("http://127.0.0.1:%d/" % port)
-                         request_timeout=10)
+            fut1 = client.fetch(self.get_url('/trigger'),
-            response = self.wait()
+            fut2 = client.fetch(self.get_url('/hello'),
-        response = self.wait()
+        response = self.fetch(
-        response = self.wait()
+        response = self.fetch('http://foo.example.com:8000/hello')
-from tornado.test.util import unittest
+from tornado.test.util import unittest, ignore_deprecation
-            self.wait()
+            with ignore_deprecation():
-        response = self.wait()
+        response = self.fetch(self.get_url('/relative'),
-        response = self.wait()
+        response = self.fetch(self.get_url('/absolute'),
-            self.http_client.fetch(path, self.stop, **kwargs)
+            url = path
-        return self.wait()
+            url = self.get_url(path)
-            callback_time_sec = self.callback_time / 1000.0
+            # The period should be measured from the start of one call
-        returns the times at which each call would be made.
+        Pass a list of call durations in seconds (negative values
-
+            self._update_next(self.io_loop.time())
-    that are running an IOLoop will want to use `AsyncHTTPClient` instead.
+    This interface is provided to make it easier to share code between
-    _ioloop_for_asyncio = weakref.WeakKeyDictionary()
+    _ioloop_for_asyncio = dict()
-        self.io_loop.close(all_fds=True)
+        if not isinstance(self.io_loop, _NON_OWNED_IOLOOPS):
-        the singleton `.IOLoop.instance()`).
+        """Returns the `.IOLoop` to use for this test.
-
+
-            resolved = yield gen.Task(deferred.addBoth)
+            fut = Future()
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-        yield gen.Task(stream.connect, ('127.0.0.1', self.port))
+        yield stream.connect(('127.0.0.1', self.port))
-        data = yield gen.Task(stream.read_until, b'\n')
+        data = yield stream.read_until(b'\n')
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-            return 42
+        async def f2():
-        result = yield namespace['f']()
+        result = yield namespace['f2']()
-            await gen.Task(self.io_loop.add_callback)
+        async def f2():
-            yield gen.Task(self.io_loop.add_callback)
+        def f3():
-        results = yield [namespace['f1'](), f2()]
+        results = yield [namespace['f2'](), f3()]
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-        response = yield gen.Task(client.fetch, self.get_argument('url'))
+        with ignore_deprecation():
-            self.finish('ok')
+        with ignore_deprecation():
-        yield gen.Task(IOLoop.current().add_callback)
+        yield gen.moment
-        yield gen.Task(IOLoop.current().add_callback)
+        yield gen.moment
-        yield gen.Task(IOLoop.current().add_callback)
+        yield gen.moment
-        yield gen.Task(IOLoop.current().add_callback)
+        yield gen.moment
-            await gen.Task(IOLoop.current().add_callback)
+            import asyncio
-            start_line, headers, response = yield gen.Task(read_stream_body, stream)
+            fut = Future()
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-            yield gen.Task(self.io_loop.add_timeout, self.io_loop.time() + 1)
+            yield gen.sleep(1)
-            await gen.Task(self.io_loop.add_callback)
+        async def f2():
-        self.io_loop.run_sync(namespace['f'])
+        self.io_loop.run_sync(namespace['f2'])
-        yield gen.Task(IOLoop.current().add_callback)
+        yield gen.moment
-            await gen.Task(IOLoop.current().add_callback)
+            import asyncio
-            await gen.Task(IOLoop.current().add_callback)
+            import asyncio
-        yield gen.Task(self.io_loop.add_callback)
+        yield gen.moment
-            yield gen.Task(self.io_loop.add_timeout, self.io_loop.time() + 1)
+            yield gen.sleep(1)
-                "gen.Task(self.io_loop.add_timeout, self.io_loop.time() + 1)",
+                "gen.sleep(1)",
-            yield gen.Task(self.io_loop.add_timeout, time() + 0.1)
+            yield gen.sleep(0.1)
-            yield gen.Task(self.io_loop.add_timeout, time() + 0.25)
+            yield gen.sleep(0.25)
-            yield gen.Task(self.io_loop.add_timeout, time() + 1)
+            yield gen.sleep(1)
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-            yield gen.Task(self.io_loop.add_callback)
+            yield gen.moment
-from tornado.test.util import unittest, skipBefore35, exec_test
+from tornado.test.util import unittest, skipBefore35, exec_test, ignore_deprecation
-        yield gen.Task(self.flush)  # empty flush
+        with ignore_deprecation():
-        data = yield gen.Task(stream.read_until_close)
+        data = yield stream.read_until_close()
-        data = yield gen.Task(stream.read_until_close)
+        data = yield stream.read_until_close()
-        data = yield gen.Task(stream.read_until_close)
+        data = yield stream.read_until_close()
-        yield gen.Task(IOLoop.current().add_callback)
+        yield gen.moment
-            yield gen.Task(IOLoop.current().add_callback)
+            yield gen.moment
-                    yield gen.Task(IOLoop.current().add_callback)
+                    yield gen.moment
-                    await gen.Task(IOLoop.current().add_callback)
+                    import asyncio
-       Use `Futures <.Future>` instead.
+       Use `Futures <.Future>` instead. This class and all its subclasses
-       Use `Futures <.Future>` instead.
+       Use `Futures <.Future>` instead. This class will be removed in 6.0.
-       Use `Futures <.Future>` instead.
+       Use `Futures <.Future>` instead. This class will be removed in 6.0.
-       Use `Futures <.Future>` instead.
+       Use `Futures <.Future>` instead. This class will be removed in 6.0.
-       Use `multi` instead.
+       Use `multi` instead. This class will be removed in 6.0.
-        results = yield [namespace['f1'](), gen.Wait('cb')]
+            results = yield [namespace['f1'](), gen.Wait('cb')]
-                raise KeyError()
+        with ignore_deprecation():
-        self.finished = True
+            future = f2()
-                raise gen.Return(42)
+        with ignore_deprecation():
-        self.finished = True
+            result = yield f2()
-            self.finish("3")
+            # The outer ignore_deprecation applies at definition time.
-        yield gen.Wait("k1")
+        yield gen.moment
-        yield gen.Wait("k2")
+        yield gen.moment
-        yield gen.Wait("k1")
+        yield gen.moment
-        yield gen.Wait("k1")
+        yield gen.moment
-        yield gen.Wait("k2")
+        yield gen.moment
-        yield gen.Wait("k1")
+        yield gen.moment
-from tornado.test.util import unittest, ignore_deprecation
+from tornado.test.util import unittest
-                    yield gen.Wait('a')
+        @gen.engine
-                self.wait()
+        @gen.engine
-def coroutine(func, replace_callback=True):
+def coroutine(func):
-                                    callback=self._on_connect)
+            fut = self.tcp_client.connect(host, port, af=af,
-    def _on_connect(self, stream):
+    def _on_connect(self, stream_fut):
-        f2(callback=(yield gen.Callback('cb')))
+        with ignore_deprecation():
-        result = yield gen.Task(f)
+        with ignore_deprecation():
-        addrinfo = self.wait()
+        addrinfo = yield Resolver().resolve('localhost', 80)
-            self.authorize_redirect()
+    with ignore_deprecation():
-            self.finish(response)
+    with ignore_deprecation():
-
+    def test_future_traceback_legacy(self):
-        def f(callback):
+        @gen.coroutine
-    def capitalize(self, request_data, callback):
+    @gen.coroutine
-        callback(self.process_response(data))
+        raise gen.Return(self.process_response(data))
-        @gen.engine
+        @gen.coroutine
-        self.wait()
+        self.io_loop.run_sync(f)
-        @gen.engine
+        @gen.coroutine
-        self.wait()
+        self.io_loop.run_sync(f)
-from tornado.test.util import unittest, skipOnTravis, skipBefore33, skipBefore35, skipNotCPython, exec_test  # noqa: E501
+from tornado.test.util import unittest, skipOnTravis, skipBefore33, skipBefore35, skipNotCPython, exec_test, ignore_deprecation  # noqa: E501
-        self.finish("3")
+    with ignore_deprecation():
-    @gen.engine
+    @gen.coroutine
-        raise Exception("oops")
+    with ignore_deprecation():
-    @gen.engine
+    @gen.coroutine
-from tornado.test.util import unittest
+from tornado.test.util import unittest, ignore_deprecation
-                yield gen.Wait('a')
+        with ignore_deprecation():
-            self.wait()
+        with ignore_deprecation():
-    @gen.engine
+    @gen.coroutine
-        or::
+      taking the link as an argument and returning the extra text
-            linkify(text, extra_params=extra_params_cb)
+          def extra_params_cb(url):
-        this is False, urls such as www.facebook.com will also be linkified.
+      this is False, urls such as www.facebook.com will also be linkified.
-        ``javascript``.
+      linkified, e.g. ``linkify(text, permitted_protocols=["http", "ftp",
-from tornado.test.util import unittest, skipIfNoNetwork
+from tornado.test.util import unittest, skipIfNoNetwork, ignore_deprecation
-        self.resolver.resolve('localhost', 80, callback=self.stop)
+        with ignore_deprecation():
-            self.resolver.resolve('an invalid domain', 80, callback=self.stop)
+            with ignore_deprecation():
-        result = self.wait()
+        result = yield self.resolver.resolve('google.com', 80, socket.AF_INET)
-        result = self.wait()
+        result = yield self.resolver.resolve('google.com', 80, socket.AF_INET6)
-        callback via this method.
+        registered a callback URI with the third-party service. For
-        should not write any other response after it returns.
+        or ``yield`` (This is different from other ``auth*_redirect``
-        ..testcode::
+        .. testcode::
-        self._oauth_get_user_future(access_token).add_done_callback(
+        fut = self._oauth_get_user_future(access_token)
-    def _oauth_get_user(self, access_token, callback):
+    @gen.coroutine
-        callback(dict(email='foo@example.com'))
+        return dict(email='foo@example.com')
-            headers={'Cookie': '_oauth_request_token=enhjdg==|MTIzNA=='})
+        with ignore_deprecation():
-            headers={'Cookie': '_oauth_request_token=enhjdg==|MTIzNA=='})
+        with ignore_deprecation():
-        response from being closed prematurely.
+        This method is asynchronous and must be called with ``await``
-from tornado.test.util import unittest, skipBefore35, exec_test
+from tornado.test.util import unittest, skipBefore35, exec_test, ignore_deprecation
-        future = self.sync_future(callback=self.stop)
+        with ignore_deprecation():
-        future = self.sync_future(self.stop)
+        with ignore_deprecation():
-        self.sync_future(callback=lambda future: 1 / 0)
+        with ignore_deprecation():
-        future = self.no_result_future(self.stop)
+        with ignore_deprecation():
-        future = self.no_result_future(callback=lambda: self.stop())
+        with ignore_deprecation():
-        self.client.capitalize("hello", callback=self.stop)
+        with ignore_deprecation():
-        self.client.capitalize("HELLO", callback=self.stop)
+        with ignore_deprecation():
-        or `.return_future` to make it asynchronous (the
+        or use ``async def`` to make it asynchronous (the
-        self.facebook_request(
+        user = yield self.facebook_request(
-    def _on_get_user_info(self, future, session, fields, user):
+
-class OpenIdClientLoginHandler(RequestHandler, OpenIdMixin):
+class OpenIdClientLoginHandlerLegacy(RequestHandler, OpenIdMixin):
-            return
+            with warnings.catch_warnings():
-class OAuth1ClientLoginHandler(RequestHandler, OAuthMixin):
+class OAuth1ClientLoginHandlerLegacy(RequestHandler, OAuthMixin):
-                self.on_user, http_client=self.settings['http_client'])
+            with warnings.catch_warnings():
-class TwitterClientLoginHandler(TwitterClientHandler):
+class TwitterClientLoginHandlerLegacy(TwitterClientHandler):
-class TwitterClientShowUserHandler(TwitterClientHandler):
+class TwitterClientShowUserHandlerLegacy(TwitterClientHandler):
-                                  access_token=dict(key='hjkl', secret='vbnm'))
+        with warnings.catch_warnings():
-            response = self.fetch('/twitter/client/show_user?name=error')
+        response = self.fetch('/twitter/client/show_user?name=error')
-from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError, WebSocketClosedError
+from tornado.websocket import (
-here:
+MacOS users should run:
-                f = None # noqa
+                f = None  # noqa
-        import tornado.ioloop, tornado.gen, tornado.util
+        import tornado.ioloop
-version = "5.0"
+version = "5.0.1"
-version_info = (5, 0, 0, 0)
+version = "5.0.1"
-                                          data[eol:100])
+        headers = httputil.HTTPHeaders.parse(data[eol:])
-            name, value = line.split(":", 1)
+            try:
-        with ExpectLog(gen_log, '.*Malformed HTTP headers'):
+        with ExpectLog(gen_log, '.*Malformed HTTP message.*no colon in header line'):
-            future = getattr(self, executor).submit(fn, self, *args, **kwargs)
+            async_future = Future()
-            return future
+                    async_future, lambda future: callback(future.result()))
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipBefore35, exec_test
-        """Send ping frame to the remote end."""
+    def ping(self, data=b''):
-        data_len = len(data)
+    def ping(self, data=b''):
-    _wrap_awaitable = asyncio.ensure_future
+    try:
-            except RuntimeError:
+            except (RuntimeError, AssertionError):
-        except RuntimeError:
+        except (RuntimeError, AssertionError):
-            except RuntimeError:
+            except (RuntimeError, AssertionError):
-        except RuntimeError:
+        except (RuntimeError, AssertionError):
-        self.assertRaises(RuntimeError,
+        self.assertRaises((RuntimeError, AssertionError),
-    _wrap_awaitable = asyncio.ensure_future
+    try:
-            except RuntimeError:
+            except (RuntimeError, AssertionError):
-        except RuntimeError:
+        except (RuntimeError, AssertionError):
-            except RuntimeError:
+            except (RuntimeError, AssertionError):
-        except RuntimeError:
+        except (RuntimeError, AssertionError):
-        self.assertRaises(RuntimeError,
+        self.assertRaises((RuntimeError, AssertionError),
-version = "5.0"
+version = "5.1.dev1"
-version_info = (5, 0, 0, 0)
+version = "5.1.dev1"
-version = "5.0b1"
+version = "5.0"
-version_info = (5, 0, 0, -98)
+version = "5.0"
-"""Utilities for working with threads and ``Futures``.
+"""Utilities for working with ``Future`` objects.
-`concurrent.futures` package.
+Python 3.2 in the `concurrent.futures` package, and also adopted (in a
-    `.IOLoop.run_in_executor`.
+    `.IOLoop.run_in_executor`. In general, using ``run_in_executor``
-is technically asynchronous, but it is written as a single generator
+"""``tornado.gen`` implements generator-based coroutines.
-"""Asynchronous queues for coroutines.
+"""Asynchronous queues for coroutines. These classes are very similar
-not thread-safe.  In particular, methods such as
+not thread-safe. In particular, methods such as
-`~RequestHandler.flush()` must only be called from the main thread.  If
+`~RequestHandler.flush()` must only be called from the main thread. If
-request.
+request, or to limit your use of other threads to
-# Author: Jacob Kristhammar, 2010
+        This property is of type `bytes`, but it contains only ASCII
-           `clear_instance()` is an alias for `clear_instance()`.
+           `clear_instance()` is an alias for `clear_current()`.
-        :arg string method: HTTP method, e.g. "GET" or "POST"
+        :arg str url: URL to fetch
-        :arg string auth_mode: Authentication mode; default is "basic".
+        :arg str auth_username: Username for HTTP authentication
-        :arg string user_agent: String to send as ``User-Agent`` header
+        :arg str user_agent: String to send as ``User-Agent`` header
-        :arg string network_interface: Network interface to use for request.
+        :arg str network_interface: Network interface to use for request.
-        :arg callable streaming_callback: If set, ``streaming_callback`` will
+        :arg collections.abc.Callable streaming_callback: If set, ``streaming_callback`` will
-        :arg callable header_callback: If set, ``header_callback`` will
+        :arg collections.abc.Callable header_callback: If set, ``header_callback`` will
-        :arg callable prepare_curl_callback: If set, will be called with
+        :arg collections.abc.Callable prepare_curl_callback: If set, will be called with
-        :arg string proxy_host: HTTP proxy hostname.  To use proxies,
+        :arg str proxy_host: HTTP proxy hostname.  To use proxies,
-        :arg string proxy_auth_mode: HTTP proxy Authentication mode;
+        :arg str proxy_username: HTTP proxy username
-        :arg string ca_certs: filename of CA certificates in PEM format,
+        :arg str ca_certs: filename of CA certificates in PEM format,
-        :arg string client_key: Filename for client SSL key, if any.  See
+        :arg str client_key: Filename for client SSL key, if any.  See
-        :arg string client_cert: Filename for client SSL certificate, if any.
+        :arg str client_cert: Filename for client SSL certificate, if any.
-        :arg string fmt: Log message format.
+        :arg str fmt: Log message format.
-        :arg string datefmt: Datetime format.
+        :arg str datefmt: Datetime format.
-        :arg string reason: Human-readable reason phrase describing the status
+        :arg str reason: Human-readable reason phrase describing the status
-    :arg string log_message: Message to be written to the log for this error
+    :arg str log_message: Message to be written to the log for this error
-    :arg string reason: Keyword-only argument.  The HTTP "reason" phrase
+    :arg str reason: Keyword-only argument.  The HTTP "reason" phrase
-        subprotocols = [s.strip() for s in subprotocols.split(',')]
+        subprotocols = [s.strip() for s in self.request.headers.get_list("Sec-WebSocket-Protocol")]
-        debug_msg = native_str(debug_msg)
+            debug_msg = native_str(debug_msg)
-            return True
+        # If client sent If-None-Match, use it, ignore If-Modified-Since
-          position if unnamed. Named and unnamed capturing groups may
+          position if unnamed. Named and unnamed capturing groups
-    assert all(is_future(i) for i in children)
+    assert all(is_future(i) or isinstance(i, _NullFuture) for i in children)
-            yield gen.multi([gen.moment, gen.moment])
+            result = yield gen.multi([gen.moment, gen.moment])
-        loop.run_sync(wait_a_moment)
+        result = loop.run_sync(wait_a_moment)
-version = "5.0a1"
+version = "5.0b1"
-version_info = (5, 0, 0, -99)
+version = "5.0b1"
-            # Delay the shutdown of the IOLoop by one iteration because
+            # Delay the shutdown of the IOLoop by several iterations because
-            self.server_ioloop.add_callback(self.server_ioloop.stop)
+            @gen.coroutine
-            "4.4.4.4")
+        resp = self.fetch("/", headers=valid_ipv4_list)
-            request.finish()
+            request.connection.write_headers(
-            self.assertFalse(IOLoop.initialized())
+import weakref
-
+    # In Python 2, _current.instance points to the current IOLoop.
-        return IOLoop.current(instance=False) is not None
+        if asyncio is None:
-           an alias for this method)
+           an alias for this method). ``instance=False`` is deprecated,
-            if current is None:
+        if asyncio is None:
-                raise RuntimeError("new IOLoop did not become current")
+                if IOLoop._current.instance is not current:
-        old = getattr(IOLoop._current, "instance", None)
+        old = IOLoop.current(instance=False)
-        IOLoop._current.instance = None
+        if asyncio is None:
-            if IOLoop.current(instance=False) is not None:
+            current = IOLoop.current(instance=False)
-        old_current = IOLoop.current(instance=False)
+        try:
-            self.make_current()
+            asyncio.set_event_loop(self.asyncio_loop)
-                old_current.make_current()
+            asyncio.set_event_loop(old_loop)
-            super(AsyncIOLoop, self).make_current()
+@unittest.skipIf(asyncio is not None,
-            ensure_future = asyncio.async
+            # async is a reserved word in Python 3.7
-        self._callbacks = None
+        if self._callbacks:
-        self._future = Future()
+        self._value = False
-        return self._future.done()
+        return self._value
-            self._future.set_result(None)
+        if not self._value:
-            self._future = Future()
+        self._value = False
-            return self._future
+            return fut
-            return gen.with_timeout(timeout, self._future)
+            timeout_fut = gen.with_timeout(timeout, fut, quiet_exceptions=(CancelledError,))
-from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError
+from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError, WebSocketClosedError
-        except StreamClosedError:
+            yield self.write_message(message, isinstance(message, bytes))
-        with self.assertRaises(StreamClosedError):
+        with self.assertRaises(WebSocketClosedError):
-        return self._write_frame(True, opcode, message, flags=flags)
+        # For historical reasons, write methods in Tornado operate in a semi-synchronous
-        return self.protocol.write_message(message, binary)
+        """Sends a message to the WebSocket server.
-from tornado.util import ObjectDict, unicode_type, PY3
+from tornado.test.util import unittest
-
+    @unittest.skipIf(asyncio is None, "asyncio module not present")
-                future.set_result(self._consume(size))
+
-            self._run_callback(callback, self._consume(size))
+            self._run_callback(callback, result)
-                    buf = bytearray(self.read_chunk_size)
+                    if self._user_read_buffer:
-            self._read_buffer += memoryview(buf)[:bytes_read]
+            if not self._user_read_buffer:
-    def read_from_fd(self):
+    def read_from_fd(self, buf):
-        ``self.read_chunk_size`` bytes at a time.
+        Reads up to ``len(buf)`` bytes, storing them in the buffer.
-                    # be available on self.error for apps that care).
+        try:
-        self._read_buffer_size += len(chunk)
+                    raise
-        return len(chunk)
+        return bytes_read
-    def read_from_fd(self):
+    def read_from_fd(self, buf):
-            chunk = self.socket.recv(self.read_chunk_size)
+            return self.socket.recv_into(buf)
-        return chunk
+        finally:
-            return None
+    def read_from_fd(self, buf):
-            if e.args[0] in _ERRNO_WOULDBLOCK:
+            if self._ssl_accepting:
-        return chunk
+            try:
-    def read_from_fd(self):
+    def read_from_fd(self, buf):
-            chunk = self._fio.read(self.read_chunk_size)
+            return self._fio.readinto(buf)
-        return chunk
+        finally:
-# can test the regular and error cases in the same class.
+# could test the regular and error cases in the same class. However,
-                          _ResolverErrorTestMixin):
+class TwistedResolverTest(AsyncTestCase, _ResolverTestMixin):
-      attribute of the resulting Subprocess a `.PipeIOStream`.
+      attribute of the resulting Subprocess a `.PipeIOStream`. If this option
-        return result
+def test_runner_factory(stderr):
-    kwargs['testRunner'] = TornadoTextTestRunner
+    kwargs['testRunner'] = test_runner_factory(orig_stderr)
-        if (log_counter.info_count > 1 or
+        # logged anything at info level or above.
-            logging.error("logged %d infos, %d warnings, and %d errors",
+                log_counter.error_count > 0 or
-                          log_counter.error_count)
+                          log_counter.error_count, sys.stderr.byte_count)
-from tornado.log import gen_log, app_log
+from tornado.log import app_log
-        raise
+    # In order to be able to run tests by their fully-qualified name
-        os.close(self.fd)
+        self._fio.close()
-            chunk = os.read(self.fd, self.read_chunk_size)
+            chunk = self._fio.read(self.read_chunk_size)
-            elif errno_from_exception(e) == errno.EBADF:
+            if errno_from_exception(e) == errno.EBADF:
-        raise NotImplementedError()
+class TestReadWriteMixin(object):
-        client.close()
+        raise NotImplementedError
-        server.write(b'', callback=self.stop)
+        rs, ws = self.make_iostream_pair()
-            client.close()
+        ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            client.write(b"1234")
+            rs.read_bytes(6, callback=final_callback,
-            client.write(b"5678")
+            ws.write(b"5678")
-            server.read_bytes(2, callback=self.stop)
+            rs.read_bytes(2, callback=self.stop)
-            client.close()
+            rs.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            server.write(b"1234")
+            rs.read_until_close(callback=close_callback,
-            server.write(b"5678", self.stop)
+            ws.write(b"5678", self.stop)
-            server.close()
+            ws.close()
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-                yield client.read_until_close(streaming_callback=chunks.append)
+            def rs_task():
-                yield server.write(b"1234")
+            def ws_task():
-                server.close()
+                yield ws.write(b"5678")
-                yield [client_task(), server_task()]
+                yield [rs_task(), ws_task()]
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            server.write(b"12")
+            rs.set_close_callback(self.stop)
-                server.close()
+                rs.read_bytes(1, callback2)
-            client.read_bytes(1, callback1)
+            rs.read_bytes(1, callback1)
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            server.write(b"12")
+            ws.write(b"12")
-            chunks.append((yield client.read_bytes(1)))
+            chunks.append((yield rs.read_bytes(1)))
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair(read_chunk_size=256)
+        rs, ws = self.make_iostream_pair(read_chunk_size=256)
-            client.read_bytes(256, self.stop)
+            ws.write(b"A" * 512)
-            # Allow the close to propagate to the client side of the
+            ws.close()
-            client.read_bytes(256, self.stop)
+            rs.read_bytes(256, self.stop)
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            server.close()
+            ws.write(b"1234")
-            client.read_bytes(1, self.stop)
+            rs.read_bytes(1, self.stop)
-            client.read_until_close(self.stop)
+            rs.read_until_close(self.stop)
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            client.read_bytes(1, self.stop)
+            ws.write(b"1234")
-                                    streaming_callback=streaming_data.append)
+            rs.read_until_close(self.stop,
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            if (isinstance(server, SSLIOStream) and
+            if (isinstance(rs, SSLIOStream) and
-            server.read_until(b"\r\n", self.stop)
+                ws.write(b"A" * 1024)
-            client.close()
+            ws.close()
-        client.set_close_callback(self.stop)
+        rs, ws = self.make_iostream_pair()
-            client.read_until(b"\r\n", self.stop)
+            ws.write(OK)
-            client.read_until(b"\r\n", lambda x: x)
+            ws.close()
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-        server.set_close_callback(close_callback)
+        rs.set_close_callback(close_callback)
-            future = server.read_bytes(1)
+            ws.write(b'a')
-            client.close()
+            ws.close()
-            client.close()
+            rs.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            server.write(memoryview(b"hello"))
+            rs.read_bytes(4, self.stop)
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair()
+        rs, ws = self.make_iostream_pair()
-            server.write(b"hello")
+            rs.read_bytes(50, self.stop, partial=True)
-            server.write(b"world")
+            rs.read_bytes(3, self.stop, partial=True)
-            client.read_bytes(0, self.stop, partial=True)
+            rs.read_bytes(0, self.stop, partial=True)
-            client.close()
+            ws.close()
-        client.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = self.make_iostream_pair()
-            server.write(b"abcdef")
+            rs.read_until(b"def", self.stop, max_bytes=50)
-            server.write(b"abcdef")
+            rs.read_until(b"def", self.stop, max_bytes=6)
-                server.write(b"123456")
+                rs.read_until(b"def", self.stop, max_bytes=5)
-            client.close()
+            ws.close()
-        client.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = self.make_iostream_pair()
-            # server writes first so client reads are satisfied
+            # ws writes first so rs reads are satisfied
-            server.write(b"123456")
+            ws.write(b"123456")
-                client.read_until(b"def", self.stop, max_bytes=5)
+                rs.read_until(b"def", self.stop, max_bytes=5)
-            client.close()
+            ws.close()
-        client.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = self.make_iostream_pair()
-            server.write(b"abcdef")
+            ws.write(b"abcdef")
-                client.read_until(b"def", self.stop, max_bytes=5)
+                rs.read_until(b"def", self.stop, max_bytes=5)
-            client.close()
+            ws.close()
-        client.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = self.make_iostream_pair()
-            server.write(b"abcdef")
+            rs.read_until_regex(b"def", self.stop, max_bytes=50)
-            server.write(b"abcdef")
+            rs.read_until_regex(b"def", self.stop, max_bytes=6)
-                server.write(b"123456")
+                rs.read_until_regex(b"def", self.stop, max_bytes=5)
-            client.close()
+            ws.close()
-        client.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = self.make_iostream_pair()
-            # server writes first so client reads are satisfied
+            # ws writes first so rs reads are satisfied
-            server.write(b"123456")
+            ws.write(b"123456")
-                client.read_until_regex(b"def", self.stop, max_bytes=5)
+                rs.read_until_regex(b"def", self.stop, max_bytes=5)
-            client.close()
+            ws.close()
-        client.set_close_callback(lambda: self.stop("closed"))
+        rs, ws = self.make_iostream_pair()
-            server.write(b"abcdef")
+            ws.write(b"abcdef")
-                client.read_until_regex(b"def", self.stop, max_bytes=5)
+                rs.read_until_regex(b"def", self.stop, max_bytes=5)
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair(max_buffer_size=10 * 1024)
+        rs, ws = self.make_iostream_pair(max_buffer_size=10 * 1024)
-            server.write(b"a" * 1024 * 100)
+            ws.write(b"a" * 1024 * 100)
-                client.read_bytes(1024, self.stop)
+                rs.read_bytes(1024, self.stop)
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair(max_buffer_size=10 * 1024)
+        rs, ws = self.make_iostream_pair(max_buffer_size=10 * 1024)
-            server.write((b"a" * 1023 + b"\n") * 100)
+            ws.write((b"a" * 1023 + b"\n") * 100)
-                client.read_until(b"\n", self.stop, max_bytes=4096)
+                rs.read_until(b"\n", self.stop, max_bytes=4096)
-            client.close()
+            ws.close()
-        server, client = self.make_iostream_pair(max_buffer_size=5 * MB)
+        rs, ws = self.make_iostream_pair(max_buffer_size=5 * MB)
-            server.read_bytes(MB, self.stop)
+            # Client writes more than the rs will accept.
-            # The client's writes have been blocked; the server can
+            # The ws's writes have been blocked; the rs can
-                server.read_bytes(MB, self.stop)
+                rs.read_bytes(MB, self.stop)
-    def test_pipe_iostream(self):
+class TestPipeIOStream(TestReadWriteMixin, AsyncTestCase):
-        ws = PipeIOStream(w)
+        return PipeIOStream(r, **kwargs), PipeIOStream(w, **kwargs)
-        ws = PipeIOStream(w)
+        rs, ws = self.make_iostream_pair()
-    before the deadline.
+    The method returns False if there's no notification before the deadline.
-        IOLoop._current.instance = self
+        old_current = IOLoop.current(instance=False)
-            IOLoop._current.instance = old_current
+            if old_current is None:
-            self.old_asyncio = None
+        if not self.is_current:
-        asyncio.set_event_loop(self.old_asyncio)
+        if self.is_current:
-        old = IOLoop._current.instance
+        old = getattr(IOLoop._current, "instance", None)
-                    _futures_to_runners[future] = Runner(result, future, yielded)
+                    # Provide strong references to Runner objects as long
-    @skipOnTravis
+    def is_pypy3(self):
-        # Create the weakref
+        # Github issue 1769: Runner objects can get GCed unexpectedly
-    def initialize(self, asyncio_loop, close_loop=False, **kwargs):
+    def initialize(self, asyncio_loop, **kwargs):
-            self.asyncio_loop.close()
+        self.asyncio_loop.close()
-                                                close_loop=False, **kwargs)
+        super(AsyncIOMainLoop, self).initialize(asyncio.get_event_loop(), **kwargs)
-            super(AsyncIOLoop, self).initialize(loop, close_loop=True, **kwargs)
+            super(AsyncIOLoop, self).initialize(loop, **kwargs)
-define("put", type=bool, help="Use PUT instead of POST", group="file uploader")
+if __name__ == "__main__":
-    sys.exit(1)
+    # Tornado configures logging from command line opts and returns remaining args.
-ioloop.IOLoop.current().run_sync(lambda: method(filenames))
+    method = put if options.put else post
-#!/usr/bin/env python
+#!/usr/bin/env python
-
+#!/usr/bin/env python
-# coding: utf-8
+# -*- coding: utf-8 -*-
-#!/usr/bin/env python
+#
-import tornado.escape
+import tornado.escape
-
+
-
+
-
+
-    >>> async def f():  # doctest: +SKIP
+    >>> async def f2():  # doctest: +SKIP
-    'table': [dict(a=1,b=2,c=3,d=4,e=5,f=6,g=7,h=8,i=9,j=10) for x in range(1000)]
+    'table': [dict(a=1, b=2, c=3, d=4, e=5,
-            if res != (0,0):
+            if res != (0, 0):
-    @unittest.skipIf((3,) < sys.version_info < (3,6),
+    @unittest.skipIf((3,) < sys.version_info < (3, 6),
-        l = len(data)
+        data_len = len(data)
-            frame += struct.pack("!BH", 126 | mask_bit, l)
+        if data_len < 126:
-            frame += struct.pack("!BQ", 127 | mask_bit, l)
+            frame += struct.pack("!BQ", 127 | mask_bit, data_len)
-version = "4.5.2"
+version = "4.5.3"
-version_info = (4, 5, 2, 0)
+version = "4.5.3"
-from tornado.test.util import unittest, skipIfNonUnix, refusing_port
+from tornado.test.util import unittest, skipIfNonUnix, refusing_port, skipPypy3V58
-            server_hostname=b'127.0.0.1')
+            server_hostname='127.0.0.1')
-            raise
+        [sock] = bind_sockets(None, '::1', family=socket.AF_INET6)
-
+def _detect_ipv6():
-        host_re = re.compile(b"^localhost:[0-9]+$")
+        host_re = re.compile(b"^127.0.0.1:[0-9]+$")
-            'http://example.com/login\?next=http%3A%2F%2Flocalhost%3A[0-9]+%2Fabsolute',
+            'http://example.com/login\?next=http%3A%2F%2F127.0.0.1%3A[0-9]+%2Fabsolute',
-        return '%s://localhost:%s%s' % (self.get_protocol(),
+        return '%s://127.0.0.1:%s%s' % (self.get_protocol(),
-                    raise HTTPInputError("improperly terminated chunked request")
+                    raise httputil.HTTPInputError("improperly terminated chunked request")
-        self.stream.write(b'POST / HTTP/1.0\r\nConnection: keep-alive\r\n'
+        self.stream.write(b'POST / HTTP/1.0\r\n'
-                          b'\r\n0\r\n')
+                          b'\r\n'
-        stream.write(b"0\r\n")
+        stream.write(b"0\r\n\r\n")
-                    del mem, mem2
+                num_bytes = self.write_to_fd(
-            del mem, mem2
+        b = (memoryview(self._read_buffer)
-        return self.socket.send(data)
+        try:
-        return os.write(self.fd, data)
+        try:
-                    memoryview(self._write_buffer)[start:start + size])
+                mem = memoryview(self._write_buffer)
-             ).tobytes()
+        mem = memoryview(self._read_buffer)
-            if self._status_code in (204, 304):
+            if (self._status_code in (204, 304) or
-                  (self._status_code < 100 or self._status_code >= 200)):
+            elif "Content-Length" not in self._headers:
-                # headers.
+                # 1xx, 204 and 304 responses have no body (not even a zero-length
-            elif "Content-Length" not in self._headers:
+            elif ("Content-Length" not in self._headers and
-        if name in self._options:
+        normalized = self._normalize_name(name)
-                        (name, self._options[name].file_name))
+                        (normalized, self._options[normalized].file_name))
-from tornado.test.util import unittest
+from tornado.test.util import unittest, subTest
-from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, AuthError, GoogleOAuth2Mixin, FacebookGraphMixin
+
-                ('/twitter/client/show_user_future', TwitterClientShowUserFutureHandler, dict(test=self)),
+                ('/twitter/client/login_gen_engine',
-                (r'/twitter/api/account/verify_credentials\.json', TwitterServerVerifyCredentialsHandler),
+                (r'/twitter/api/account/verify_credentials\.json',
-        response = self.fetch('/openid/client/login?openid.mode=blah&openid.ns.ax=http://openid.net/srv/ax/1.0&openid.ax.type.email=http://axschema.org/contact/email&openid.ax.value.email=foo@example.com')
+        response = self.fetch('/openid/client/login?openid.mode=blah'
-from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode, json_decode, json_encode, squeeze, recursive_unicode
+from tornado.escape import (
-     u'hello <a href="http://world.com/with?param=true&amp;stuff=yes">http://world.com/with?param=true&amp;stuff=yes</a>'),
+     u'hello <a href="http://world.com/with?param=true&amp;stuff=yes">http://world.com/with?param=true&amp;stuff=yes</a>'),  # noqa: E501
-     u'<a href="http://url.com/w">http://url.com/w</a>(aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'),
+     u'<a href="http://url.com/w">http://url.com/w</a>(aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'),  # noqa: E501
-     u'<a href="http://url.com/withmany">http://url.com/withmany</a>.......................................'),
+     u'<a href="http://url.com/withmany">http://url.com/withmany</a>.......................................'),  # noqa: E501
-     u'<a href="http://url.com/withmany">http://url.com/withmany</a>((((((((((((((((((((((((((((((((((a)'),
+     u'<a href="http://url.com/withmany">http://url.com/withmany</a>((((((((((((((((((((((((((((((((((a)'),  # noqa: E501
-     u'<a href="http://foo.com/blah_(blah)_(wikipedia)_blah">http://foo.com/blah_(blah)_(wikipedia)_blah</a>'),
+     u'<a href="http://foo.com/blah_(blah)_(wikipedia)_blah">http://foo.com/blah_(blah)_(wikipedia)_blah</a>'),  # noqa: E501
-     u'(Something like <a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>)'),
+     u'(Something like <a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>)'),  # noqa: E501
-     u'<a href="http://userid:password@example.com:8080">http://userid:password@example.com:8080</a>'),
+     u'<a href="http://userid:password@example.com:8080">http://userid:password@example.com:8080</a>'),  # noqa: E501
-     u'<a href="message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e">message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e</a>'),
+     u'<a href="message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e">'
-     u'A <a href="http://reallylong.com/link/that/exceedsthelenglimit.html" title="http://reallylong.com/link/that/exceedsthelenglimit.html">http://reallylong.com/link...</a>'),
+     u'A <a href="http://reallylong.com/link/that/exceedsthelenglimit.html"'
-     u'A <a href="http://reallylongdomainnamethatwillbetoolong.com/hi" title="http://reallylongdomainnamethatwillbetoolong.com/hi">http://reallylongdomainnametha...</a>!'),
+     u'A <a href="http://reallylongdomainnamethatwillbetoolong.com/hi"'
-     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>'),
+     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>'),  # noqa: E501
-     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a> and <a href="http://www.internal-link.com/blogs" class="internal">www.internal-link.com/blogs</a> extra'),
+     {"extra_params": lambda href: 'class="internal"' if href.startswith("http://www.internal-link.com") else 'rel="nofollow" class="external"'},  # noqa: E501
-     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>'),
+     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>'),  # noqa: E501
-        self.assertEqual(squeeze(u'sequences     of    whitespace   chars'), u'sequences of whitespace chars')
+        self.assertEqual(squeeze(u'sequences     of    whitespace   chars'),
-from tornado.test.util import unittest, skipOnTravis, skipBefore33, skipBefore35, skipNotCPython, exec_test
+from tornado.test.util import unittest, skipOnTravis, skipBefore33, skipBefore35, skipNotCPython, exec_test  # noqa: E501
-from tornado.httputil import HTTPHeaders, HTTPMessageDelegate, HTTPServerConnectionDelegate, ResponseStartLine
+from tornado.httputil import HTTPHeaders, HTTPMessageDelegate, HTTPServerConnectionDelegate, ResponseStartLine  # noqa: E501
-from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, ExpectLog, gen_test
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, ExpectLog, gen_test  # noqa: E501
-from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp, HTTPServerRequest, parse_request_start_line, parse_cookie, qs_to_qsl, PY3
+
-        self.assertEqual(parse_cookie('chips=ahoy; vienna=finger'), {'chips': 'ahoy', 'vienna': 'finger'})
+        self.assertEqual(parse_cookie('chips=ahoy; vienna=finger'),
-        self.assertEqual(parse_cookie('a=b; c=[; d=r; f=h'), {'a': 'b', 'c': '[', 'd': 'r', 'f': 'h'})
+        self.assertEqual(parse_cookie('a=b; c=[; d=r; f=h'),
-        self.assertEqual(parse_cookie('a=b; Domain=example.com'), {'a': 'b', 'Domain': 'example.com'})
+        self.assertEqual(parse_cookie('a=b; Domain=example.com'),
-        self.assertIn('django_language', parse_cookie('abc=def; unnamed; django_language=en').keys())
+        self.assertIn('django_language',
-        self.assertEqual(parse_cookie('a   b,c<>@:/[]?{}=d  "  =e,f g'), {'a   b,c<>@:/[]?{}': 'd  "  =e,f g'})
+        self.assertEqual(parse_cookie('a   b,c<>@:/[]?{}=d  "  =e,f g'),
-        self.assertEqual(parse_cookie('saint=AndrÃ© Bessette'), {'saint': native_str('AndrÃ© Bessette')})
+        self.assertEqual(parse_cookie('saint=AndrÃ© Bessette'),
-from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, bind_unused_port, ExpectLog, gen_test
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, bind_unused_port, ExpectLog, gen_test  # noqa: E501
-        self.assertEqual(locale.format_date(datetime.datetime.utcnow() - datetime.timedelta(seconds=2), full_format=False),
+        now = datetime.datetime.utcnow()
-        self.assertEqual(locale.format_date(datetime.datetime.utcnow() - datetime.timedelta(minutes=2), full_format=False),
+        self.assertEqual(locale.format_date(now - datetime.timedelta(minutes=2), full_format=False),
-        self.assertEqual(locale.format_date(datetime.datetime.utcnow() - datetime.timedelta(hours=2), full_format=False),
+        self.assertEqual(locale.format_date(now - datetime.timedelta(hours=2), full_format=False),
-                         'yesterday')
+        self.assertEqual(locale.format_date(now - datetime.timedelta(days=1),
-    LINE_RE = re.compile(b"(?s)\x01\\[E [0-9]{6} [0-9]{2}:[0-9]{2}:[0-9]{2} log_test:[0-9]+\\]\x02 (.*)")
+    LINE_RE = re.compile(
-from tornado.netutil import BlockingResolver, OverrideResolver, ThreadedResolver, is_valid_ip, bind_sockets
+from tornado.netutil import (
-from tornado.httputil import HTTPHeaders, HTTPMessageDelegate, HTTPServerConnectionDelegate, ResponseStartLine
+from tornado.httputil import HTTPHeaders, HTTPMessageDelegate, HTTPServerConnectionDelegate, ResponseStartLine  # noqa: E501
-                    ResponseStartLine("HTTP/1.1", 200, "OK"), HTTPHeaders({"Content-Length": "2"}), b"OK"
+                    ResponseStartLine("HTTP/1.1", 200, "OK"),
-                (PathMatches("/first_handler"), "tornado.test.routing_test.SecondHandler", {}, "second_handler")
+                (PathMatches("/first_handler"),
-from tornado.test.httpclient_test import ChunkHandler, CountdownHandler, HelloWorldHandler, RedirectHandler
+from tornado.test.httpclient_test import ChunkHandler, CountdownHandler, HelloWorldHandler, RedirectHandler  # noqa: E501
-        }, namespace={"_tt_modules": ObjectDict(Template=lambda path, **kwargs: loader.load(path).generate(**kwargs))})
+        }, namespace={"_tt_modules": ObjectDict(Template=load_generate)})
-from tornado.util import raise_exc_info, Configurable, exec_in, ArgReplacer, timedelta_to_seconds, import_object, re_unescape, is_finalizing, PY3
+from tornado.util import (
-from tornado.escape import json_decode, utf8, to_unicode, recursive_unicode, native_str, to_basestring
+from tornado.escape import json_decode, utf8, to_unicode, recursive_unicode, native_str, to_basestring  # noqa: E501
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish, removeslash, addslash, RedirectHandler as WebRedirectHandler, get_signature_key_version, GZipContentEncoding
+from tornado.web import (
-{{ set_resources(embedded_css=".entry { margin-bottom: 1em; }", embedded_javascript="js_embed()", css_files=["/base.css", "/foo.css"], javascript_files="/common.js", html_head="<meta>", html_body='<script src="/analytics.js"/>') }}
+{{ set_resources(embedded_css=".entry { margin-bottom: 1em; }",
-            url("//web_redirect_double_slash", WebRedirectHandler, {"url": '/web_redirect_newpath'}),
+            url("/web_redirect", WebRedirectHandler,
-</body></html>""")
+</body></html>""")  # noqa: E501
-    description="Tornado is a Python web framework and asynchronous networking library, originally developed at FriendFeed.",
+    description=("Tornado is a Python web framework and asynchronous networking library,"
-        cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split("|")]
+        cookie_key, cookie_secret = [
-        """
+        """  # noqa: E501
-                   method="POST", headers={'Content-Type': 'application/x-www-form-urlencoded'}, body=body)
+                   method="POST",
-          fields are copied from the Facebook graph API `user object <https://developers.facebook.com/docs/graph-api/reference/user>`_
+          fields are copied from the Facebook graph API
-_URL_RE = re.compile(to_unicode(r"""\b((?:([\w-]+):(/{1,3})|www[.])(?:(?:(?:[^\s&()]|&amp;|&quot;)*(?:[^!"#$%&'()*+,.:;<=>?@\[\]^`{|}~\s]))|(?:\((?:[^\s&()]|&amp;|&quot;)*\)))+)"""))
+_URL_RE = re.compile(to_unicode(
-from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info, future_add_done_callback
+from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info, future_add_done_callback  # noqa: E501
-from tornado.util import PY3, Configurable, errno_from_exception, timedelta_to_seconds, TimeoutError, unicode_type, import_object
+from tornado.util import (
-    _ERRNO_CONNRESET += (errno.WSAECONNRESET, errno.WSAECONNABORTED, errno.WSAETIMEDOUT)  # type: ignore
+    _ERRNO_CONNRESET += (errno.WSAECONNRESET, errno.WSAECONNABORTED, errno.WSAETIMEDOUT)  # type: ignore # noqa: E501
-    DEFAULT_FORMAT = '%(color)s[%(levelname)1.1s %(asctime)s %(module)s:%(lineno)d]%(end_color)s %(message)s'
+    DEFAULT_FORMAT = \
-from twisted.internet.interfaces import IReactorFDSet, IDelayedCall, IReactorTime, IReadDescriptor, IWriteDescriptor  # type: ignore
+from twisted.internet.interfaces import IReactorFDSet, IDelayedCall, IReactorTime, IReadDescriptor, IWriteDescriptor  # type: ignore # noqa: E501
-SetHandleInformation.argtypes = (ctypes.wintypes.HANDLE, ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)
+SetHandleInformation.argtypes = (ctypes.wintypes.HANDLE, ctypes.wintypes.DWORD, ctypes.wintypes.DWORD)  # noqa: E501
-        `~.httputil.HTTPServerConnectionDelegate` or an old-style callable, accepting a request argument.
+        `~.httputil.HTTPServerConnectionDelegate` or an old-style callable,
-            directives.
+        :arg tornado.template.BaseLoader loader: the `~tornado.template.BaseLoader` responsible
-                self.__timeout = self.io_loop.add_timeout(self.io_loop.time() + timeout, timeout_func)
+                self.__timeout = self.io_loop.add_timeout(self.io_loop.time() + timeout,
-        # openssl req -new -keyout tornado/test/test.key -out tornado/test/test.crt -nodes -days 3650 -x509
+        # openssl req -new -keyout tornado/test/test.key \
-                message += ". Lists not accepted for security reasons; see http://www.tornadoweb.org/en/stable/web.html#tornado.web.RequestHandler.write"
+                message += ". Lists not accepted for security reasons; see " + \
-    """
+    """  # noqa: E501
-        # type: (int, httputil.HTTPHeaders, bytes, bool) -> typing.Tuple[int, httputil.HTTPHeaders, bytes]
+        # type: (int, httputil.HTTPHeaders, bytes, bool) -> typing.Tuple[int, httputil.HTTPHeaders, bytes] # noqa: E501
-        # type: (int, httputil.HTTPHeaders, bytes, bool) -> typing.Tuple[int, httputil.HTTPHeaders, bytes]
+        # type: (int, httputil.HTTPHeaders, bytes, bool) -> typing.Tuple[int, httputil.HTTPHeaders, bytes] # noqa: E501
-        return zlib.compressobj(self._compression_level, zlib.DEFLATED, -self._max_wbits, self._mem_level)
+        return zlib.compressobj(self._compression_level,
-           stmt.children[0].type == token.STRING
+    return isinstance(stmt, pytree.Node) and stmt.children[0].type == token.STRING
-            ('/', EchoHandler),
+        ('/', EchoHandler),
-            lambda future: io_loop.remove_timeout(timeout_handle))
+        future_add_done_callback(
-                            yielded.get_result())
+                        future_set_result_unless_cancelled(self.future, yielded.get_result())
-                self._disconnect_on_finish):
+            if (self._request_start_line.version == 'HTTP/1.1' and self._disconnect_on_finish):
-                 'keep-alive')):
+                    self._request_headers.get('Connection', '').lower() == 'keep-alive'):
-                           lambda future: self.add_callback(callback, future))
+        future_add_done_callback(
-                                                     addrs, af, addr))
+        future_add_done_callback(
-            log_counter.error_count > 0):
+                log_counter.warning_count > 0 or
-                (self._status_code >= 100 and self._status_code < 200)):
+                    (self._status_code >= 100 and self._status_code < 200)):
-        if isinstance(value, (unicode, bytes)):
+        if isinstance(value, (unicode_type, bytes)):
-        elif isinstance(value, int) or isinstance(value, long):
+        elif isinstance(value, (int, long)):
-    print "Content-Type: text/plain\r\n\r\n",
+    print("Content-Type: text/plain\r\n\r\n", end="")
-    except SystemExit, e:
+    except SystemExit as e:
-            print "PASS"
+            print("PASS")
-from __future__ import with_statement
+from __future__ import absolute_import, division, print_function
-        print resp.read()
+        print(resp.read())
-            print "%s already exists, skipping" % exe
+            print("%s already exists, skipping" % exe)
-        print "Installing %s" % url
+        print("Installing %s" % url)
-        warnings.filterwarnings("ignore", category=ResourceWarning,
+        warnings.filterwarnings("ignore", category=ResourceWarning,  # noqa: F821
-                except ValueError as exc:
+                except ValueError:
-        if user: user.administrator = users.is_current_user_admin()
+        if user:
-        if not entry: raise tornado.web.HTTPError(404)
+        if not entry:
-            if not slug: slug = "entry"
+            if not slug:
-        if not user_id: return None
+        if not user_id:
-        if not entry: raise tornado.web.HTTPError(404)
+        if not entry:
-            if not entry: raise tornado.web.HTTPError(404)
+            if not entry:
-            if not slug: slug = "entry"
+            if not slug:
-                if not e: break
+                if not e:
-        if not user_json: return None
+        if not user_json:
-    print('%0.3f ms per iteration' % (results*1000))
+    print('%0.3f ms per iteration' % (results * 1000))
-        tree.insert_child(pos+1, Newline())  # terminates the import stmt
+        tree.insert_child(pos + 1, Newline())  # terminates the import stmt
-        node.replace(String('u'+arg.value, prefix=node.prefix))
+        node.replace(String('u' + arg.value, prefix=node.prefix))
-    ext_modules=Cython.Build.cythonize('cythonapp.pyx')
+    ext_modules = Cython.Build.cythonize('cythonapp.pyx')
-
+
-        ]
+    ]
-            ],
+        ],
-        )
+    )
-            }
+        }
-    ]
+]
-    ]
+]
-    ]
+]
-    ]
+]
-    }
+}
-        }[options.family]
+    }[options.family]
-            ]
+        ]
-            ]
+        ]
-            ]
+        ]
-            ])
+    ])
-    ]
+]
-        },
+        ],
-        ],
+    ],
-            ]
+        ]
-            ]
+        ]
-            
+
-    """Generator converting a result of ``parse_qs`` back to name-value pairs. 
+    """Generator converting a result of ``parse_qs`` back to name-value pairs.
-    import typing
+    import typing  # noqa: F401
-from tornado.testing import AsyncHTTPTestCase, ExpectLog
+from tornado.testing import AsyncHTTPTestCase
-from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port, unittest, skipBefore35, exec_test
+from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port, skipBefore35, exec_test
-from tornado.test.util import skipIfNoIPv6, unittest, refusing_port, skipIfNonUnix, skipOnTravis
+from tornado.test.util import skipIfNoIPv6, unittest, refusing_port, skipIfNonUnix
-
+    @skipOnTravis
-            functools.partial(stack_context.wrap(callback), *args, **kwargs))
+        try:
-            raise unittest.SkipTest("AsyncIOMainLoop shutdown not thread safe")
+        # add_callback should not fail if it races with another thread
-                break
+            other_ioloop.add_callback(lambda: None)
-
+This module is inspired by Google's `gflags
-either::
+either `parse_command_line` or `parse_config_file`::
-    tornado.options.parse_config_file("/etc/server.conf")
+    import myapp.db, myapp.server
-.. note:
+    if __name__ == '__main__':
-    myotheroption = "myothervalue"
+.. note::
-`define()` below.
+   When using multiple ``parse_*`` functions, pass ``final=False`` to all
-        comma-separated values, and the option value is always a list.
+        ``type`` can be any of `str`, `int`, `float`, `bool`,
-        turns into ``range(x, y)`` - very useful for long integer ranges.
+        If ``multiple`` is True, the option value is a list of ``type``
-        config file with `parse_config_file`.
+        Command line option names must be unique globally.
-        """Parses and loads the Python config file at the given path.
+        """Parses and loads the config file at the given path.
-    from tornado.platform.asyncio import AsyncIOLoop, to_asyncio_future
+    from tornado.platform.asyncio import AsyncIOLoop, to_asyncio_future, AnyThreadEventLoopPolicy
-                    raise HTTPInputError("improperly terminated chunked request")
+                    raise httputil.HTTPInputError("improperly terminated chunked request")
-        except AttributeError:
+        except AttributeError as err:
-version = "5.0.dev1"
+version = "5.0a1"
-version_info = (5, 0, 0, -100)
+version = "5.0a1"
-    host-port-family triplets.
+    The mapping can be in three formats::
-Config files are just Python files. Global names become options, e.g.::
+Command line formats are what you would expect (``--myoption=myvalue``
-<datetime.timedelta>`, ints, and floats (just pass a ``type`` kwarg to
+<datetime.timedelta>`, bools, ints, and floats (just pass a ``type`` kwarg to
-        If ``type`` is given (one of str, float, int, datetime, or timedelta)
+        If ``type`` is given (one of str, float, int, bool, datetime, or timedelta)
-    The mapping can contain either host strings or host-port pairs.
+    The mapping can contain either host strings or host-port pairs or
-        if (host, port) in self.mapping:
+    def resolve(self, host, port, family=socket.AF_UNSPEC, *args, **kwargs):
-        return self.resolver.resolve(host, port, *args, **kwargs)
+        return self.resolver.resolve(host, port, family, *args, **kwargs)
-from tornado.netutil import BlockingResolver, ThreadedResolver, is_valid_ip, bind_sockets
+from tornado.netutil import BlockingResolver, OverrideResolver, ThreadedResolver, is_valid_ip, bind_sockets
-        self.stream.write(b'POST / HTTP/1.0\r\nConnection: keep-alive\r\n'
+        self.stream.write(b'POST / HTTP/1.0\r\n'
-                          b'\r\n0\r\n')
+                          b'\r\n'
-        stream.write(b"0\r\n")
+        stream.write(b"0\r\n\r\n")
-    * `tornado.netutil.ThreadedResolver`
+    * `tornado.netutil.DefaultExecutorResolver`
-        return BlockingResolver
+        return DefaultExecutorResolver
-        return results
+        return _resolve_addr(host, port, family)
-    `~tornado.netutil.ThreadedResolver`.  Specifically, it returns at
+    `~tornado.netutil.DefaultExecutorResolver`.  Specifically, it returns at
-_null_future.set_result(None)
+class _NullFuture(object):
-moment = Future()
+    It's not actually a `Future` to avoid depending on a particular event loop.
-    if yielded is None:
+    if yielded is None or yielded is moment:
-            return gen._null_future
+            future.set_result(None)
-                                        lambda f: f.result())
+                IOLoop.current().add_future(gen.convert_yielded(future),
-from tornado.test.util import skipBefore35, exec_test
+from tornado.test.util import skipBefore35, skipIfNonUnix, exec_test, unittest
-    'python': ('https://docs.python.org/3.5/', None),
+    'python': ('https://docs.python.org/3.6/', None),
-    with `Future.result()` as an argument.  If the function fails, the
+    with ``Future.result()`` as an argument.  If the function fails, the
-    Accepts both Tornado/asyncio `Future` objects and `concurrent.futures.Future`.
+    .. versionchanged:: 5.0
-    This may differ from the behavior of `.Future.add_done_callback`,
+    This may differ from the behavior of ``Future.add_done_callback``,
-yielding this object returns its `~.Future.result`.
+yielding this object returns its ``Future.result``.
-    """Generator rewinding a result of ``parse_qs`` back to name-value pairs. 
+    """Generator converting a result of ``parse_qs`` back to name-value pairs. 
-`IOLoop.add_timeout` is a non-blocking alternative to `time.sleep`.
+On Python 3, `.IOLoop` is a wrapper around the `asyncio` event loop.
-    either ``epoll`` or ``kqueue``.
+    On Python 3, `IOLoop` is a wrapper around the `asyncio` event
-        Use `functools.partial` to pass keyword arguments to `func`.
+        Use `functools.partial` to pass keyword arguments to ``func``.
-        """Sets the default executor to use with :meth:`run_in_executor`."""
+        """Sets the default executor to use with :meth:`run_in_executor`.
-loops.
+.. deprecated:: 5.0
-    ``asyncio.get_event_loop()``).  Recommended usage::
+    ``asyncio.get_event_loop()``).
-        asyncio.get_event_loop().run_forever()
+    .. deprecated:: 5.0
-    installing alternative IOLoops.
+       Now used automatically when appropriate; it is no longer necessary
-        IOLoop.current().start()
+    ``asyncio`` default event loop.
-            it must be present in `httplib.responses <http.client.responses>`.
+        :arg int status_code: Response status code.
-            `httplib.responses <http.client.responses>`.
+            `http.client.responses` or "Unknown".
-        super(BaseAsyncIOLoop, self).initialize(**kwargs)
+        super(BaseAsyncIOLoop, self).initialize(**kwargs)
-            asyncio.set_event_loop(old_asyncio)
+    def make_current(self):
-else:
+# Convert Awaitables into Futures.
-            timeout_handle = self.add_timeout(self.time() + timeout, self.stop)
+            def timeout_callback():
-        if not future_cell[0].done():
+        if future_cell[0].cancelled() or not future_cell[0].done():
-            self.io_loop.add_callback(self.stop)
+            # Stop the IOLoop two iterations after raising an exception
-                # exception, which is better than nothing.
+                # If the underlying generator is still running, we can throw the
-        import tornado.ioloop
+        import tornado.ioloop
-            sock.bind(("", port))
+            sock.bind(("", 8888))
-from tornado.concurrent import Future, return_future, chain_future, future_set_exc_info
+from tornado.concurrent import (Future, return_future, chain_future,
-        future.set_result(user)
+        future_set_result_unless_cancelled(future, user)
-        future.set_result(user)
+        future_set_result_unless_cancelled(future, user)
-        future.set_result(escape.json_decode(response.body))
+        future_set_result_unless_cancelled(future, escape.json_decode(response.body))
-        future.set_result(escape.json_decode(response.body))
+        future_set_result_unless_cancelled(future, escape.json_decode(response.body))
-        future.set_result(args)
+        future_set_result_unless_cancelled(future, args)
-            future.set_result(None)
+            future_set_result_unless_cancelled(future, None)
-        future.set_result(fieldmap)
+        future_set_result_unless_cancelled(future, fieldmap)
-            future.set_result(fn(*args, **kwargs))
+            future_set_result_unless_cancelled(future, fn(*args, **kwargs))
-            lambda value=_NO_RESULT: future.set_result(value),
+            lambda value=_NO_RESULT: future_set_result_unless_cancelled(future, value),
-from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info, future_add_done_callback
+from tornado.concurrent import (Future, is_future, chain_future, future_set_exc_info,
-                    future.set_result(_value_from_stopiteration(e))
+                    future_set_result_unless_cancelled(future, _value_from_stopiteration(e))
-        future.set_result(result)
+        future_set_result_unless_cancelled(future, result)
-        future.set_result(result)
+        future_set_result_unless_cancelled(future, result)
-        future.set_result({} if keys is not None else [])
+        future_set_result_unless_cancelled(future,
-                    future.set_result(dict(zip(keys, result_list)))
+                    future_set_result_unless_cancelled(future,
-                    future.set_result(result_list)
+                    future_set_result_unless_cancelled(future, result_list)
-    IOLoop.current().call_later(duration, lambda: f.set_result(None))
+    IOLoop.current().call_later(duration,
-                self.future.set_result(self.yield_point.get_result())
+                future_set_result_unless_cancelled(self.future,
-                    self.result_future.set_result(_value_from_stopiteration(e))
+                    future_set_result_unless_cancelled(self.result_future,
-                        self.future.set_result(
+                        future_set_result_unless_cancelled(self.future,
-from tornado.concurrent import Future, future_add_done_callback
+from tornado.concurrent import (Future, future_add_done_callback,
-            self._finish_future.set_result(None)
+            future_set_result_unless_cancelled(self._finish_future, None)
-            self._finish_future.set_result(None)
+            future_set_result_unless_cancelled(self._finish_future, None)
-            self._finish_future.set_result(None)
+            future_set_result_unless_cancelled(self._finish_future, None)
-            future.set_result(None)
+            future_set_result_unless_cancelled(future, None)
-            self._finish_future.set_result(None)
+            future_set_result_unless_cancelled(self._finish_future, None)
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_set_result_unless_cancelled
-                future.set_result(response)
+                future_set_result_unless_cancelled(future, response)
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_set_result_unless_cancelled
-                    waiter.set_result(False)
+                    future_set_result_unless_cancelled(waiter, False)
-            waiter.set_result(True)
+            future_set_result_unless_cancelled(waiter, True)
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_set_result_unless_cancelled
-                future.set_result(ret)
+                future_set_result_unless_cancelled(future, ret)
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_set_result_unless_cancelled
-            getter.set_result(self._get())
+            future_set_result_unless_cancelled(getter, self._get())
-            putter.set_result(None)
+            future_set_result_unless_cancelled(putter, None)
-from tornado.concurrent import Future, return_future, ReturnValueIgnoredError, run_on_executor
+from tornado.concurrent import (Future, return_future, ReturnValueIgnoredError,
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_set_result_unless_cancelled
-                self._prepared_future.set_result(None)
+                future_set_result_unless_cancelled(self._prepared_future, None)
-            self.request.body.set_result(None)
+            future_set_result_unless_cancelled(self.request.body, None)
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_set_result_unless_cancelled
-        self.connect_future.set_result(self)
+        future_set_result_unless_cancelled(self.connect_future, self)
-            future.set_result(self.read_queue.popleft())
+            future_set_result_unless_cancelled(future, self.read_queue.popleft())
-            self.read_future.set_result(message)
+            future_set_result_unless_cancelled(self.read_future, message)
-        self._write_buffer_size = 0
+        self._write_buffer = _StreamBuffer()
-                    self._write_buffer_size + len(data) > self.max_write_buffer_size):
+                    len(self._write_buffer) + len(data) > self.max_write_buffer_size):
-            self._write_buffer_size += len(data)
+            self._write_buffer.append(data)
-            if self._write_buffer_size:
+            if self._write_buffer:
-        return self._write_buffer_size > 0
+        return bool(self._write_buffer)
-            assert self._write_buffer_size >= 0
+        while True:
-                    memoryview(self._write_buffer)[start:start + size])
+
-                    self._write_buffer_pos = 0
+                self._write_buffer.advance(num_bytes)
-        if not self._write_buffer_size:
+        if not len(self._write_buffer):
-from tornado.iostream import IOStream, SSLIOStream, PipeIOStream, StreamClosedError
+from tornado.iostream import IOStream, SSLIOStream, PipeIOStream, StreamClosedError, _StreamBuffer
-    gc.collect()
+
-            return future
+            try:
-        future = Future()
+        future = _create_future()
-                        yielded = Future()
+                        yielded = _create_future()
-    future = Future()
+    future = _create_future()
-    future = Future()
+    future = _create_future()
-        fut = Future()
+        fut = _create_future()
-    result = Future()
+    result = _create_future()
-    f = Future()
+    f = _create_future()
-            response = self.fetch("/404")
+        response = self.fetch("/404")
-from tornado.testing import AsyncHTTPTestCase
+from tornado.testing import AsyncHTTPTestCase, ExpectLog
-    faster for use with single-threaded event loops).
+    `tornado.concurrent.Future` is an alias for `asyncio.Future` when
-    Python 2 futures backport this information is discarded.
+    In addition to ``exception`` and ``set_exception``, Tornado's
-       This name, which was deprecated since version 4.0, has been removed.
+
-            fn(self)
+            from tornado.ioloop import IOLoop
-                                  cb, self)
+            loop.add_callback(cb, self)
-        result.set_exception(TimeoutError("Timeout"))
+        if not result.done():
-   ``yield None`` is now equivalent to ``yield gen.moment``.
+   ``yield None`` (or ``yield`` with no argument) is now equivalent to
-        if not self.future.done() or self.future is moment:
+        if self.future is moment:
-        tornado
+                future.exception()
-                waiter.set_result(False)
+                if not waiter.done():
-                    waiter.set_exception(gen.TimeoutError())
+                    if not waiter.done():
-    return tf
+    return asyncio_future
-    convert_yielded.register(asyncio.Future, to_tornado_future)  # type: ignore
+    .. deprecated:: 5.0
-            future.set_exception(gen.TimeoutError())
+            if not future.done():
-        with self.assertRaises(RuntimeError):
+        # Futures (which our Future is since 5.0).
-                native_coroutine_without_adapter())
+                native_coroutine_without_adapter()),
-from tornado.testing import AsyncHTTPTestCase
+from tornado.testing import AsyncHTTPTestCase, gen_test
-            self.stop()
+            error_event.set()
-            request = HTTPRequest(self.get_url('/'),
+            request = HTTPRequest(self.get_url('/custom_reason'),
-        self.wait()
+        yield [error_event.wait(), self.http_client.fetch(request)]
-                yield gen.moment
+                yield stream.read_bytes(len(b'hello'))
-    future_add_done_callback(a, copy)
+    if isinstance(a, Future):
-                                   executor.submit(lambda: None))
+                                   executor.submit(lambda: time.sleep(0.01)))
-        raise e
+import asyncio
-from tornado.util import PY3, Configurable, errno_from_exception, timedelta_to_seconds, TimeoutError
+from tornado.util import PY3, Configurable, errno_from_exception, timedelta_to_seconds, TimeoutError, unicode_type, import_object
-            future.add_done_callback(wrap(run_callback))
+            future_add_done_callback(future, wrap(run_callback))
-    a.add_done_callback(copy)
+    future_add_done_callback(a, copy)
-from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info
+from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info, future_add_done_callback
-        future.add_done_callback(stack_context.wrap(final_callback))
+        future_add_done_callback(future, stack_context.wrap(final_callback))
-            future.add_done_callback(self._done_callback)
+            future_add_done_callback(future, self._done_callback)
-            f.add_done_callback(callback)
+            future_add_done_callback(f, callback)
-        future.add_done_callback(error_callback)
+        future_add_done_callback(future, error_callback)
-        future.add_done_callback(
+        future_add_done_callback(future,
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_add_done_callback
-            self._pending_write.add_done_callback(self._finish_request)
+            future_add_done_callback(self._pending_write, self._finish_request)
-from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info
+from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info, future_add_done_callback
-            lambda future: self.add_callback(callback, future))
+        future_add_done_callback(future,
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_add_done_callback
-                                                   addrs, af, addr))
+        future_add_done_callback(future, functools.partial(self.on_connect_done,
-from tornado.concurrent import TracebackFuture, return_future, chain_future, future_set_exc_info
+from tornado.concurrent import Future, return_future, chain_future, future_set_exc_info
-        future = TracebackFuture()
+        future = Future()
-    ``TracebackFuture``, which is now a deprecated alias for this class.
+
-        future = TracebackFuture()
+        future = Future()
-        future = TracebackFuture()
+        future = Future()
-from tornado.concurrent import Future, TracebackFuture, is_future, chain_future, future_set_exc_info
+from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info
-        future = TracebackFuture()
+        future = Future()
-                        yielded = TracebackFuture()
+                        yielded = Future()
-        self._running_future = TracebackFuture()
+        self._running_future = Future()
-    `.TracebackFuture`)
+    `.Future`)
-            self.future = TracebackFuture()
+            self.future = Future()
-from tornado.concurrent import TracebackFuture
+from tornado.concurrent import Future
-        future = TracebackFuture()
+        future = Future()
-from tornado.concurrent import TracebackFuture, is_future, chain_future, future_set_exc_info
+from tornado.concurrent import Future, is_future, chain_future, future_set_exc_info
-                future_cell[0] = TracebackFuture()
+                future_cell[0] = Future()
-                    future_cell[0] = TracebackFuture()
+                    future_cell[0] = Future()
-        t_future = TracebackFuture()
+        t_future = Future()
-from tornado.concurrent import TracebackFuture
+from tornado.concurrent import Future
-            future = TracebackFuture()
+            future = Future()
-            self._read_future = TracebackFuture()
+            self._read_future = Future()
-            future = self._connect_future = TracebackFuture()
+            future = self._connect_future = Future()
-        future = TracebackFuture()
+        future = Future()
-            future = self._ssl_connect_future = TracebackFuture()
+            future = self._ssl_connect_future = Future()
-from tornado.concurrent import TracebackFuture
+from tornado.concurrent import Future
-        self.connect_future = TracebackFuture()
+        self.connect_future = Future()
-        future = TracebackFuture()
+        future = Future()
-from tornado.concurrent import TracebackFuture, return_future, chain_future
+from tornado.concurrent import TracebackFuture, return_future, chain_future, future_set_exc_info
-                future.set_exc_info((typ, value, tb))
+                future_set_exc_info(future, (typ, value, tb))
-            future.set_exc_info(sys.exc_info())
+            future_set_exc_info(future, sys.exc_info())
-            future.set_exc_info((typ, value, tb))
+            future_set_exc_info(future, (typ, value, tb))
-                isinstance(b, TracebackFuture) and
+        if (hasattr(a, 'exc_info') and
-            b.set_exc_info(a.exc_info())
+            future_set_exc_info(b, a.exc_info())
-from tornado.concurrent import Future, TracebackFuture, is_future, chain_future
+from tornado.concurrent import Future, TracebackFuture, is_future, chain_future, future_set_exc_info
-            future.set_exc_info(sys.exc_info())
+            future_set_exc_info(future, sys.exc_info())
-                    future.set_exc_info(sys.exc_info())
+                    future_set_exc_info(future, sys.exc_info())
-        future.set_exc_info((typ, value, tb))
+        future_set_exc_info(future, (typ, value, tb))
-                        future.set_exc_info(sys.exc_info())
+                        future_set_exc_info(future, sys.exc_info())
-                self.future.set_exc_info(sys.exc_info())
+                future_set_exc_info(self.future, sys.exc_info())
-                    self.result_future.set_exc_info(sys.exc_info())
+                    future_set_exc_info(self.result_future, sys.exc_info())
-                    self.future.set_exc_info(sys.exc_info())
+                    self.future = Future()
-                self.future.set_exc_info(sys.exc_info())
+                self.future = Future()
-            self.future.set_exc_info((typ, value, tb))
+            self.future = Future()
-from tornado.concurrent import TracebackFuture, is_future, chain_future
+from tornado.concurrent import TracebackFuture, is_future, chain_future, future_set_exc_info
-                future_cell[0].set_exc_info(sys.exc_info())
+                future_set_exc_info(future_cell[0], sys.exc_info())
-from tornado.concurrent import Future
+from tornado.concurrent import Future, future_set_exc_info
-                f.set_exc_info(sys.exc_info())
+                future_set_exc_info(f, sys.exc_info())
-            raise
+        [sock] = bind_sockets(None, '::1', family=socket.AF_INET6)
-
+def _detect_ipv6():
-        host_re = re.compile(b"^localhost:[0-9]+$")
+        host_re = re.compile(b"^127.0.0.1:[0-9]+$")
-            'http://example.com/login\?next=http%3A%2F%2Flocalhost%3A[0-9]+%2Fabsolute',
+            'http://example.com/login\?next=http%3A%2F%2F127.0.0.1%3A[0-9]+%2Fabsolute',
-        return '%s://localhost:%s%s' % (self.get_protocol(),
+        return '%s://127.0.0.1:%s%s' % (self.get_protocol(),
-            else response.body.decode()
+            else response.body.decode(errors='ignore')
-        self.io_loop = IOLoop.current()
+        # Looking up the IOLoop here allows to first instantiate the
-from tornado.concurrent import TracebackFuture, is_future
+from tornado.concurrent import TracebackFuture, is_future, chain_future
-        return executor.submit(func, *args)
+        c_future = executor.submit(func, *args)
-        def callback(self_event, other_event):
+        def sync_func(self_event, other_event):
-            self.assertTrue(other_event.is_set())
+            other_event.wait()
-            IOLoop.current().run_in_executor(None, callback, event2, event1)
+            IOLoop.current().run_in_executor(None, sync_func, event1, event2),
-        def callback(self_event, other_event):
+        def sync_func(self_event, other_event):
-            self.assertTrue(other_event.is_set())
+        # Go through an async wrapper to ensure that the result of
-                self.assertEqual([event1, event2], res)
+            async def async_wrapper(self_event, other_event):
-        IOLoop.current().run_sync(namespace['main'])
+        res = yield [
-        class MyExecutor(futures.Executor):
+        count = [0]
-                return Future()
+                count[0] += 1
-        def future_func():
+        def sync_func():
-        executor = MyExecutor()
+        executor = MyExecutor(1)
-        loop.add_timeout(0.01, lambda: self.assertFalse(event.is_set()))
+        yield loop.run_in_executor(None, sync_func)
-        # This constant wasn't added until python 3.3.
+        # This constant depends on openssl version 1.0.
-                ssl_options["keyfile"] = self.request.client_key
+            ssl_ctx = ssl.create_default_context(
-            return ssl_options
+                ssl_ctx.load_cert_chain(self.request.client_cert,
-    from tornado.testing import unittest
+# Delegate the choice of unittest or unittest2 to tornado.testing.
-        install_requires.append('certifi')
+# Verify that the SSL module has all the modern upgrades. Check for several
-from tornado.netutil import ssl_wrap_socket, ssl_match_hostname, SSLCertificateError, _client_ssl_defaults, _server_ssl_defaults
+from tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults
-        except SSLCertificateError as e:
+            ssl.match_hostname(peercert, self._server_hostname)
-    _server_ssl_defaults = {}
+if ssl is not None:
-            isinstance(ssl_options, ssl.SSLContext)):
+    if isinstance(ssl_options, ssl.SSLContext):
-            return context.wrap_socket(socket, **kwargs)
+    if ssl.HAS_SNI:
-        return ssl.wrap_socket(socket, **dict(context, **kwargs))  # type: ignore
+        return context.wrap_socket(socket, **kwargs)
-        return self.socket.send(data)
+        try:
-        return os.write(self.fd, data)
+        try:
-from tornado.testing import AsyncTestCase, bind_unused_port, ExpectLog
+from tornado.testing import AsyncTestCase, bind_unused_port, ExpectLog, gen_test
-                self._write_buffer_size += len(data)
+            self._write_buffer += data
-                elif _WINDOWS:
+                if _WINDOWS:
-
+    def test_missing_websocket_key(self):
-        except Exception:
+        except Exception as e:
-        yield write(b'\r\n')
+        buf = (
-              (filename_bytes, filename_bytes))
+        yield write(b'--%s\r\n' % (boundary_bytes,))
-        write(b'\r\n')
+        yield write(b'Content-Type: %s\r\n' % (mtype.encode(),))
-                write(chunk)
+                yield write(chunk)
-                yield gen.moment
+        yield write(b'\r\n')
-    write(b'--%s--\r\n' % (boundary_bytes,))
+    yield write(b'--%s--\r\n' % (boundary_bytes,))
-            write(chunk)
+            yield write(chunk)
-    (r'c:\python33\python.exe', 'http://www.python.org/ftp/python/3.3.0/python-3.3.0.msi'),
+    (r'c:\python36\python.exe', 'http://www.python.org/ftp/python/3.6.0/python-3.6.0.msi'),
-        raise Return(self)
+        return self
-it possible to combine the two libraries on the same event loop.
+in Python 3.4. This makes it possible to combine the two libraries on
-from tornado.test.util import unittest, skipIfNonUnix, refusing_port
+from tornado.test.util import unittest, skipIfNonUnix, refusing_port, skipPypy3V58
-            server_hostname=b'127.0.0.1')
+            server_hostname='127.0.0.1')
-                            message=".*legacy __aiter__ protocol")
+# Used for tests affected by
-    start(io_loop)
+    io_loop.add_callback(start)
-version = "4.5.1"
+version = "4.5.2"
-version_info = (4, 5, 1, 0)
+version = "4.5.2"
-    _OAUTH_ACCESS_TOKEN_URL = "https://accounts.google.com/o/oauth2/token"
+    _OAUTH_AUTHORIZE_URL = "https://accounts.google.com/o/oauth2/v2/auth"
-            self.__class__.__name__, args, dict(self.headers))
+        return "%s(%s)" % (self.__class__.__name__, args)
-       HTTPServer(applicaton, ssl_options=ssl_ctx)
+       HTTPServer(application, ssl_options=ssl_ctx)
-            # byte strings whereever possible).
+            # byte strings wherever possible).
-            # the client finishes with the response (this is noticable
+            # the client finishes with the response (this is noticeable
-        # re-arised in wait().
+        # re-raised in wait().
-from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp, HTTPServerRequest, parse_request_start_line, parse_cookie
+from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp, HTTPServerRequest, parse_request_start_line, parse_cookie, qs_to_qsl, PY3
-        self.redirect(self._url.format(*args), permanent=self._permanent)
+        to_url = self._url.format(*args)
-    def start(self, timeout=_INITIAL_CONNECT_TIMEOUT):
+    def start(self, timeout=_INITIAL_CONNECT_TIMEOUT, connect_timeout=None):
-        self.set_timout(timeout)
+        self.set_timeout(timeout)
-        future = self.connect(af, addr)
+        stream, future = self.connect(af, addr)
-        self.clear_timeout()
+        self.clear_timeouts()
-    def set_timout(self, timeout):
+    def set_timeout(self, timeout):
-        self.try_connect(iter(self.secondary_addrs))
+        if not self.future.done():
-                max_buffer_size=None, source_ip=None, source_port=None):
+                max_buffer_size=None, source_ip=None, source_port=None,
-        addrinfo = yield self.resolver.resolve(host, port, af)
+        if timeout is not None:
-        af, addr, stream = yield connector.start()
+        af, addr, stream = yield connector.start(connect_timeout=timeout)
-                                            server_hostname=host)
+            if timeout is not None:
-            return stream.connect(addr)
+            return stream, stream.connect(addr)
-from tornado.test.util import skipIfNoIPv6, unittest, refusing_port, skipIfNonUnix
+from tornado.test.util import skipIfNoIPv6, unittest, refusing_port, skipIfNonUnix, skipOnTravis
-        return future
+        return stream, future
-            self.streams[addr] = ConnectorTest.FakeStream()
+            self.streams.pop(addr)
-        future = conn.start(3600)
+        future = conn.start(3600, connect_timeout=self.io_loop.time() + 3600)
-            if self._status_code in (204, 304):
+            if (self._status_code in (204, 304) or
-                  (self._status_code < 100 or self._status_code >= 200)):
+            elif "Content-Length" not in self._headers:
-                # headers.
+                # 1xx, 204 and 304 responses have no body (not even a zero-length
-            elif "Content-Length" not in self._headers:
+            elif ("Content-Length" not in self._headers and
-        sys.argv = ['-m', spec.name] + sys.argv[1:]
+        argv = ['-m', spec.name] + sys.argv[1:]
-        subprocess.Popen([sys.executable] + sys.argv)
+        subprocess.Popen([sys.executable] + argv)
-            os.execv(sys.executable, [sys.executable] + sys.argv)
+            os.execv(sys.executable, [sys.executable] + argv)
-                      [sys.executable] + sys.argv)
+            os.spawnv(os.P_NOWAIT, sys.executable, [sys.executable] + argv)
-                response = yield gen.Task(self.fetch('/'))
+                response = yield self.http_client.fetch(self.get_url('/'))
-                response = yield gen.Task(self.fetch('/'))
+                response = yield self.http_client.fetch(self.get_url('/'))
-    removed = []
+    removed = [False]
-            if removed:
+            if removed[0]:
-        removed.append(True)
+        removed[0] = True
-        self.assertEqual('Bad Request', start_line.reason)
+        with ExpectLog(gen_log, '.*Malformed HTTP request line'):
-        self.warning_count = self.error_count = 0
+        self.info_count = self.warning_count = self.error_count = 0
-                          log_counter.warning_count, log_counter.error_count)
+        # The tests should run clean; consider it a failure if they
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase
-class DefaultHTTPTest(AsyncHTTPTestCase, LogTrapTestCase, TestMixin):
+class DefaultHTTPTest(AsyncHTTPTestCase, TestMixin):
-class GzipHTTPTest(AsyncHTTPTestCase, LogTrapTestCase, TestMixin):
+class GzipHTTPTest(AsyncHTTPTestCase, TestMixin):
-from tornado.testing import AsyncTestCase, ExpectLog, LogTrapTestCase, bind_unused_port, gen_test
+from tornado.testing import AsyncTestCase, ExpectLog, bind_unused_port, gen_test
-        logging.info("handle_stream")
+        logging.debug("handle_stream")
-        logging.info("handle_read")
+        logging.debug("handle_read")
-        logging.info("capitalize")
+        logging.debug("capitalize")
-        logging.info("handle_connect")
+        logging.debug("handle_connect")
-        logging.info("handle_read")
+        logging.debug("handle_read")
-        logging.info("capitalize")
+        logging.debug("capitalize")
-        logging.info("handle_connect")
+        logging.debug("handle_connect")
-        logging.info("handle_read")
+        logging.debug("handle_read")
-        logging.info('capitalize')
+        logging.debug('capitalize')
-        logging.info('connecting')
+        logging.debug('connecting')
-        logging.info('reading')
+        logging.debug('reading')
-        logging.info('returning')
+        logging.debug('returning')
-class ManualClientTest(ClientTestMixin, AsyncTestCase, LogTrapTestCase):
+class ManualClientTest(ClientTestMixin, AsyncTestCase):
-class DecoratorClientTest(ClientTestMixin, AsyncTestCase, LogTrapTestCase):
+class DecoratorClientTest(ClientTestMixin, AsyncTestCase):
-class GeneratorClientTest(ClientTestMixin, AsyncTestCase, LogTrapTestCase):
+class GeneratorClientTest(ClientTestMixin, AsyncTestCase):
-* `ExpectLog` and `LogTrapTestCase`: Make test logs less spammy.
+* `ExpectLog`: Make test logs less spammy.
-    # won't work, but e.g. LogTrapTestCase and main() will.
+    # won't work, but e.g. main() will.
-from tornado.util import PY3, raise_exc_info
+from tornado.util import PY3, raise_exc_info, TimeoutError
-    relative to `.IOLoop.time`)
+    Raises `tornado.util.TimeoutError` if the input future does not
-from tornado.util import PY3, Configurable, errno_from_exception, timedelta_to_seconds
+from tornado.util import PY3, Configurable, errno_from_exception, timedelta_to_seconds, TimeoutError
-        a `TimeoutError` is raised.
+        a `tornado.util.TimeoutError` is raised.
-    The method raises `tornado.gen.TimeoutError` if there's no notification
+    The method raises `tornado.util.TimeoutError` if there's no notification
-        Returns a Future, which raises `tornado.gen.TimeoutError` after a
+        Returns a Future, which raises `tornado.util.TimeoutError` after a
-        Returns a Future, which raises `tornado.gen.TimeoutError` after a
+        Returns a Future, which raises `tornado.util.TimeoutError` after a
-        Returns a Future, which raises `tornado.gen.TimeoutError` after a
+        Returns a Future, which raises `tornado.util.TimeoutError` after a
-        `tornado.gen.TimeoutError` after a timeout.
+        `tornado.util.TimeoutError` after a timeout.
-        Returns a Future, which raises `tornado.gen.TimeoutError` after a
+        Returns a Future, which raises `tornado.util.TimeoutError` after a
-        out = p.communicate()[0].decode()
+        p = Popen(
-# (http://bugs.python.org/issue14208).
+# We address the former problem by reconstructing the original command
-                                    os.environ.get("PYTHONPATH", ""))
+    # sys.path fixes: see comments at top of file.  If __main__.__spec__
-        import tornado.autoreload
+    'tornado.test.autoreload_test',
-from tornado.iostream import IOStream, StreamClosedError
+from tornado.iostream import IOStream
-        # AsyncTestCase.tearDown() would re-raise the EBADF encountered in the IO loop
+        try:
-    IOLoop.current().add_handler(sock, accept_handler, IOLoop.READ)
+
-        self._sockets = {}  # fd -> socket object
+        self._sockets = {}   # fd -> socket object
-            add_accept_handler(sock, self._handle_connection)
+            self._handlers[sock.fileno()] = add_accept_handler(
-            self.io_loop.remove_handler(fd)
+            # Unregister socket from IOLoop
-from tornado.iostream import IOStream
+from tornado.iostream import IOStream, StreamClosedError
-        self.no_keep_alive = no_keep_alive
+            # If connection to a 1.1 client will be closed, inform client
-        For backwards compatibility is is allowed but deprecated to
+        For backwards compatibility it is allowed but deprecated to
-            current = IOLoop()
+            current = None
-                                                  'AsyncIOMainLoop'):
+        if IOLoop.configured_class().__name__ == 'TwistedIOLoop':
-                'AsyncIOMainLoop')
+                'Sync HTTPClient not compatible with TwistedIOLoop')
-        self.assertEqual(results, [1, 2, 3, 4])
+        # The asyncio event loop does not guarantee the order of these
-        self.assertEqual(is_poll, 'True')
+        if asyncio is not None:
-        self.assertEqual(cls, 'AsyncIOLoop')
+        self.assertEqual(cls, 'AsyncIOMainLoop')
-                                "TwistedIOLoop or AsyncIOMainLoop")
+    if IOLoop.configured_class().__name__.endswith('TwistedIOLoop'):
-        # and have no way to get it back into a sane state after the fork.
+        # This test doesn't work on twisted because we use the global
-    headers and body."""
+    start_line, headers and body."""
-            callback((self.headers, b''.join(chunks)))
+            callback((self.start_line, self.headers, b''.join(chunks)))
-            headers, body = self.wait()
+            start_line, headers, body = self.wait()
-    def test_malformed_first_line(self):
+    def test_malformed_first_line_response(self):
-        headers, response = self.wait()
+        start_line, headers, response = self.wait()
-        headers, response = self.wait()
+        start_line, headers, response = self.wait()
-        self.assertEqual(response, b"")
+        self.assertEqual(response, b"HTTP/1.1 400 Bad Request\r\n\r\n")
-        self.assertEqual(response.code, 599)
+        self.assertEqual(response.code, 400)
-        self.assertEqual(response.code, 599)
+        # this test is flaky on windows; accept 400 (expected) or 599
-        self.assertEqual(response.code, 599)
+        self.assertEqual(response.code, 400)
-        self.assertEqual(response.code, 599)
+        # this test is flaky on windows; accept 400 (expected) or 599
-            headers, response = yield gen.Task(read_stream_body, stream)
+            start_line, headers, response = yield gen.Task(read_stream_body, stream)
-            self.assertEqual(data, b'')
+            self.assertEqual(data, b'HTTP/1.1 400 Bad Request\r\n\r\n')
-        to get the current thread's `IOLoop`.
+        """Deprecated alias for `IOLoop.current()`.
-        return IOLoop._instance
+        return IOLoop.current()
-        return hasattr(IOLoop, "_instance")
+        """Returns true if there is a current IOLoop.
-        """Installs this `IOLoop` object as the singleton instance.
+        """Deprecated alias for `make_current()`.
-        a custom subclass of `IOLoop`.
+           Previously, this method would set this `IOLoop` as the
-        `IOLoop` (e.g., :class:`tornado.httpclient.AsyncHTTPClient`).
+        .. deprecated:: 5.0
-        IOLoop._instance = self
+        self.make_current()
-        """Clear the global `IOLoop` instance.
+        """Deprecated alias for `clear_current()`.
-            del IOLoop._instance
+        IOLoop.clear_current()
-        one.
+        no current `IOLoop` and ``instance`` is true, creates one.
-            return IOLoop.instance()
+            current = IOLoop()
-            self.io_loop.close(all_fds=True)
+        # Try to clean up any file descriptors left open in the ioloop.
-            self.http_client.close()
+        self.http_client.close()
-        return SelectIOLoop
+        return PollIOLoop
-from tornado.ioloop import IOLoop
+from tornado.ioloop import IOLoop, PollIOLoop
-        """Layers a TwistedIOLoop on top of a TornadoReactor on a SelectIOLoop.
+        """Layers a TwistedIOLoop on top of a TornadoReactor on a PollIOLoop.
-            self.real_io_loop = SelectIOLoop(make_current=False)  # type: ignore
+            self.real_io_loop = PollIOLoop(make_current=False)  # type: ignore
-        if cls.__impl_class is None:
+        # Manually mangle the private name to see whether this base
-    pass keyword arguments to the decorator::
+    The executor to be used is determined by the ``executor``
-                getattr(self, io_loop).add_future(
+                from tornado.ioloop import IOLoop
-                self.io_loop = io_loop
+            def __init__(self):
-        o = Object(io_loop=self.io_loop)
+        o = Object()
-                self.io_loop = io_loop
+            def __init__(self):
-        o = Object(io_loop=self.io_loop)
+        o = Object()
-                self.io_loop = io_loop
+            def __init__(self):
-        o = Object(io_loop=self.io_loop)
+        o = Object()
-def start(io_loop=None, check_time=500):
+def start(check_time=500):
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-    io_loop = io_loop or ioloop.IOLoop.current()
+    io_loop = ioloop.IOLoop.current()
-    scheduler = ioloop.PeriodicCallback(callback, check_time, io_loop=io_loop)
+    scheduler = ioloop.PeriodicCallback(callback, check_time)
-        super(CurlAsyncHTTPClient, self).initialize(io_loop, defaults=defaults)
+    def initialize(self, max_clients=10, defaults=None):
-            self._handle_force_timeout, 1000, io_loop=io_loop)
+            self._handle_force_timeout, 1000)
-    def __init__(self, future, io_loop=None):
+    def __init__(self, future):
-           The ``io_loop`` argument is deprecated.
+        .. versionchanged:: 5.0
-        self.io_loop = io_loop or IOLoop.current()
+        self.io_loop = IOLoop.current()
-def with_timeout(timeout, future, io_loop=None, quiet_exceptions=()):
+def with_timeout(timeout, future, quiet_exceptions=()):
-        io_loop = IOLoop.current()
+    io_loop = IOLoop.current()
-                                body_future, self.stream.io_loop,
+                                body_future,
-from tornado import httputil, stack_context
+from tornado import gen, httputil, stack_context
-        self._async_client = async_client_class(self._io_loop, **kwargs)
+        # Create the client while our IOLoop is "current", without
-    constructor can be set with the static method `configure()`
+    (one per `.IOLoop`). The keyword argument ``force_instance=True``
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-        io_loop = io_loop or IOLoop.current()
+    def __new__(cls, force_instance=False, **kwargs):
-                                                       **kwargs)
+        instance = super(AsyncHTTPClient, cls).__new__(cls, **kwargs)
-        self.io_loop = io_loop
+    def initialize(self, defaults=None):
-    def initialize(self, request_callback, no_keep_alive=False, io_loop=None,
+    def initialize(self, request_callback, no_keep_alive=False,
-        TCPServer.__init__(self, io_loop=io_loop, ssl_options=ssl_options,
+        TCPServer.__init__(self, ssl_options=ssl_options,
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-    def __init__(self, callback, callback_time, io_loop=None):
+    def __init__(self, callback, callback_time):
-        self.io_loop = io_loop or IOLoop.current()
+        self.io_loop = IOLoop.current()
-    def __init__(self, io_loop=None, max_buffer_size=None,
+    def __init__(self, max_buffer_size=None,
-                      Deprecated since Tornado 4.1.
+        .. versionchanged:: 5.0
-        self.io_loop = io_loop or ioloop.IOLoop.current()
+        self.io_loop = ioloop.IOLoop.current()
-                                 io_loop=self.io_loop)
+        ssl_stream = SSLIOStream(socket, ssl_options=ssl_options)
-def add_accept_handler(sock, callback, io_loop=None):
+def add_accept_handler(sock, callback):
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-    io_loop.add_handler(sock, accept_handler, IOLoop.READ)
+    IOLoop.current().add_handler(sock, accept_handler, IOLoop.READ)
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-        self.io_loop = io_loop or IOLoop.current()
+    def initialize(self, executor=None, close_executor=True):
-        super(BlockingResolver, self).initialize(io_loop=io_loop)
+    def initialize(self):
-    def initialize(self, io_loop=None, num_threads=10):
+    def initialize(self, num_threads=10):
-            io_loop=io_loop, executor=threadpool, close_executor=False)
+            executor=threadpool, close_executor=False)
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-        self.io_loop = io_loop or IOLoop.current()
+    def initialize(self):
-    ``tornado.platform.twisted.TornadoReactor(io_loop)``.  However, if
+    ``tornado.platform.twisted.TornadoReactor()``.  However, if
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-        self._io_loop = io_loop
+    def __init__(self):
-        super(_TestReactor, self).__init__(IOLoop())
+        IOLoop(make_current=True)
-def install(io_loop=None):
+def install():
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-    reactor = TornadoReactor(io_loop)
+    reactor = TornadoReactor()
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-        self.io_loop = io_loop or IOLoop.current()
+    def initialize(self):
-        self.reactor = tornado.platform.twisted.TornadoReactor(io_loop)
+        self.reactor = tornado.platform.twisted.TornadoReactor()
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-        self.io_loop = kwargs.pop('io_loop', None) or ioloop.IOLoop.current()
+        self.io_loop = ioloop.IOLoop.current()
-            self.stdin = PipeIOStream(in_w, io_loop=self.io_loop)
+            self.stdin = PipeIOStream(in_w)
-            self.stdout = PipeIOStream(out_r, io_loop=self.io_loop)
+            self.stdout = PipeIOStream(out_r)
-            self.stderr = PipeIOStream(err_r, io_loop=self.io_loop)
+            self.stderr = PipeIOStream(err_r)
-        Subprocess.initialize(self.io_loop)
+        Subprocess.initialize()
-    def initialize(cls, io_loop=None):
+    def initialize(cls):
-           The ``io_loop`` argument is deprecated.
+        .. versionchanged:: 5.0
-            io_loop = ioloop.IOLoop.current()
+        io_loop = ioloop.IOLoop.current()
-    def initialize(self, io_loop, max_clients=10,
+    def initialize(self, max_clients=10,
-                                                      defaults=defaults)
+        super(SimpleAsyncHTTPClient, self).initialize(defaults=defaults)
-            self.resolver = Resolver(io_loop=io_loop)
+            self.resolver = Resolver()
-        self.tcp_client = TCPClient(resolver=self.resolver, io_loop=io_loop)
+        self.tcp_client = TCPClient(resolver=self.resolver)
-            self.io_loop, self, request, release_callback,
+            self, request, release_callback,
-    def __init__(self, io_loop, client, request, release_callback,
+    def __init__(self, client, request, release_callback,
-        self.io_loop = io_loop
+        self.io_loop = IOLoop.current()
-        self.io_loop = io_loop
+    def __init__(self, addrinfo, connect):
-       The ``io_loop`` argument is deprecated.
+    .. versionchanged:: 5.0
-        self.io_loop = io_loop or IOLoop.current()
+    def __init__(self, resolver=None):
-            self.resolver = Resolver(io_loop=io_loop)
+            self.resolver = Resolver()
-            addrinfo, self.io_loop,
+            addrinfo,
-                              io_loop=self.io_loop,
+
-    def __init__(self, io_loop=None, ssl_options=None, max_buffer_size=None,
+    def __init__(self, ssl_options=None, max_buffer_size=None,
-        self.io_loop = io_loop
+        self.io_loop = IOLoop.current()
-                               io_loop=self.io_loop)
+            add_accept_handler(sock, self._handle_connection)
-                stream = SSLIOStream(connection, io_loop=self.io_loop,
+                stream = SSLIOStream(connection,
-                stream = IOStream(connection, io_loop=self.io_loop,
+                stream = IOStream(connection,
-    def __init__(self, port, io_loop):
+    def __init__(self, port):
-        self.stream = IOStream(socket.socket(), io_loop=self.io_loop)
+        self.stream = IOStream(socket.socket())
-        self.stream = IOStream(socket.socket(), io_loop=self.io_loop)
+        self.stream = IOStream(socket.socket())
-        stream = IOStream(socket.socket(), io_loop=self.io_loop)
+        stream = IOStream(socket.socket())
-        self.server = CapServer(io_loop=self.io_loop)
+        self.server = CapServer()
-        self.client = self.client_class(io_loop=self.io_loop, port=port)
+        self.client = self.client_class(port=port)
-                                     defaults=dict(allow_ipv6=False))
+        client = CurlAsyncHTTPClient(defaults=dict(allow_ipv6=False))
-        return CurlAsyncHTTPClient(self.io_loop, force_instance=True,
+        return CurlAsyncHTTPClient(force_instance=True,
-        client = AsyncHTTPClient(io_loop=io_loop)
+        client = AsyncHTTPClient()
-                                        future, io_loop=self.io_loop)
+                                        future)
-                                   future, io_loop=self.io_loop)
+                                   future)
-                                        future, io_loop=self.io_loop)
+                                        future)
-                stream = IOStream(conn, io_loop=self.io_loop)
+                stream = IOStream(conn)
-            netutil.add_accept_handler(sock, accept_callback, self.io_loop)
+            netutil.add_accept_handler(sock, accept_callback)
-        client = self.http_client.__class__(self.io_loop, force_instance=True,
+        client = self.http_client.__class__(force_instance=True,
-                stream = IOStream(conn, io_loop=self.io_loop)
+                stream = IOStream(conn)
-            netutil.add_accept_handler(sock, accept_callback, self.io_loop)
+            netutil.add_accept_handler(sock, accept_callback)
-        self.server.add_socket(sock)
+        @gen.coroutine
-        stream = IOStream(socket.socket(), io_loop=self.io_loop)
+        stream = IOStream(socket.socket())
-        self.server = HTTPServer(app, io_loop=self.io_loop)
+        self.server = HTTPServer(app)
-        self.stream = IOStream(socket.socket(socket.AF_UNIX), io_loop=self.io_loop)
+        self.stream = IOStream(socket.socket(socket.AF_UNIX))
-        self.stream = IOStream(socket.socket(), io_loop=self.io_loop)
+        self.stream = IOStream(socket.socket())
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop)
+        return SimpleAsyncHTTPClient()
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop)
+        return SimpleAsyncHTTPClient()
-                                   io_loop=self.io_loop)
+        netutil.add_accept_handler(listener, accept_callback)
-        stream = IOStream(socket.socket(), self.io_loop)
+        stream = IOStream(socket.socket())
-        stream = IOStream(s, io_loop=self.io_loop)
+        stream = IOStream(s)
-        return IOStream(socket.socket(), io_loop=self.io_loop)
+        return IOStream(socket.socket())
-        return SSLIOStream(socket.socket(), io_loop=self.io_loop,
+        return SSLIOStream(socket.socket(),
-        return SSLIOStream(connection, io_loop=self.io_loop, **kwargs)
+        return SSLIOStream(connection, **kwargs)
-        return SSLIOStream(connection, io_loop=self.io_loop,
+        return SSLIOStream(connection,
-        return SSLIOStream(connection, io_loop=self.io_loop, **kwargs)
+        return SSLIOStream(connection, **kwargs)
-                           ssl_options=context, **kwargs)
+        return SSLIOStream(connection, ssl_options=context, **kwargs)
-        ws = PipeIOStream(w, io_loop=self.io_loop)
+        rs = PipeIOStream(r)
-        ws = PipeIOStream(w, io_loop=self.io_loop)
+        rs = PipeIOStream(r)
-        self.resolver = BlockingResolver(io_loop=self.io_loop)
+        self.resolver = BlockingResolver()
-        self.resolver = BlockingResolver(io_loop=self.io_loop)
+        self.resolver = BlockingResolver()
-        self.resolver = ThreadedResolver(io_loop=self.io_loop)
+        self.resolver = ThreadedResolver()
-        self.resolver = BlockingResolver(io_loop=self.io_loop)
+        self.resolver = BlockingResolver()
-        self.resolver = CaresResolver(io_loop=self.io_loop)
+        self.resolver = CaresResolver()
-        self.resolver = TwistedResolver(io_loop=self.io_loop)
+        self.resolver = TwistedResolver()
-                             io_loop=self.io_loop)
+                             stdout=Subprocess.STREAM, stderr=subprocess.STDOUT)
-                             io_loop=self.io_loop)
+                             stdout=Subprocess.STREAM, stderr=subprocess.STDOUT)
-                             io_loop=self.io_loop)
+                             stderr=Subprocess.STREAM)
-        Subprocess.initialize(io_loop=self.io_loop)
+        Subprocess.initialize()
-                             io_loop=self.io_loop)
+        subproc = Subprocess([sys.executable, '-c', 'pass'])
-        Subprocess.initialize(io_loop=self.io_loop)
+        Subprocess.initialize()
-                             io_loop=self.io_loop)
+                             stdout=Subprocess.STREAM)
-                                       force_instance=True)
+        client = SimpleAsyncHTTPClient(force_instance=True)
-                        SimpleAsyncHTTPClient(self.io_loop))
+        self.assertTrue(SimpleAsyncHTTPClient() is
-                                              force_instance=True))
+        self.assertTrue(SimpleAsyncHTTPClient() is not
-                            SimpleAsyncHTTPClient(io_loop2))
+            client1 = self.io_loop.run_sync(gen.coroutine(SimpleAsyncHTTPClient))
-                                     **kwargs)
+        return SimpleAsyncHTTPClient(force_instance=True, **kwargs)
-        return SimpleAsyncHTTPClient(self.io_loop, force_instance=True,
+        return SimpleAsyncHTTPClient(force_instance=True,
-                self.io_loop, force_instance=True)) as client:
+        with closing(AsyncHTTPClient(force_instance=True)) as client:
-                self.io_loop, max_clients=11, force_instance=True)) as client:
+                max_clients=11, force_instance=True)) as client:
-                self.io_loop, force_instance=True)) as client:
+        with closing(AsyncHTTPClient(force_instance=True)) as client:
-                self.io_loop, max_clients=13, force_instance=True)) as client:
+                max_clients=13, force_instance=True)) as client:
-                self.io_loop, max_clients=14, force_instance=True)) as client:
+                max_clients=14, force_instance=True)) as client:
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop, max_header_size=1024)
+        return SimpleAsyncHTTPClient(max_header_size=1024)
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop, max_body_size=1024 * 64)
+        return SimpleAsyncHTTPClient(max_body_size=1024 * 64)
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop, max_body_size=1024 * 100, max_buffer_size=1024 * 64)
+        return SimpleAsyncHTTPClient(max_body_size=1024 * 100, max_buffer_size=1024 * 64)
-    def __init__(self, app, request, io_loop):
+    def __init__(self, app, request):
-        self.io_loop.add_callback(self.part2)
+        IOLoop.current().add_callback(self.part2)
-        self.io_loop.add_callback(self.part3)
+        IOLoop.current().add_callback(self.part3)
-                             dict(io_loop=self.io_loop))])
+        return Application([('/', TestRequestHandler)])
-        conn = _Connector(addrinfo, self.io_loop, self.create_stream)
+        conn = _Connector(addrinfo, self.create_stream)
-        self._reactor = TornadoReactor(self._io_loop)
+        self._io_loop = IOLoop(make_current=True)
-        self.reactor = TornadoReactor(self.io_loop)
+        self.reactor = TornadoReactor()
-        server = HTTPServer(app, io_loop=self.io_loop)
+        server = HTTPServer(app)
-        client = AsyncHTTPClient(self.io_loop)
+        client = AsyncHTTPClient()
-            reactor = TornadoReactor(io_loop=self.real_io_loop)
+            reactor = self.real_io_loop.run_sync(gen.coroutine(TornadoReactor))
-        self.stream = IOStream(s, io_loop=self.io_loop)
+        self.stream = IOStream(s)
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop)
+        return SimpleAsyncHTTPClient()
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop)
+        return SimpleAsyncHTTPClient()
-        stream = IOStream(s, io_loop=self.io_loop)
+        stream = IOStream(s)
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop)
+        return SimpleAsyncHTTPClient()
-            io_loop=self.io_loop, callback=self.stop)
+            callback=self.stop)
-                                     io_loop=self.io_loop)
+        ws = yield websocket_connect(HTTPRequest(url, headers=headers))
-                                     io_loop=self.io_loop)
+        ws = yield websocket_connect(HTTPRequest(url, headers=headers))
-                                    io_loop=self.io_loop)
+            yield websocket_connect(HTTPRequest(url, headers=headers))
-                                    io_loop=self.io_loop)
+            yield websocket_connect(HTTPRequest(url, headers=headers))
-                                    io_loop=self.io_loop)
+            yield websocket_connect(HTTPRequest(url, headers=headers))
-    HTTP clients/servers, etc.  If the code being tested requires a
+    as ``self.io_loop``.  If the code being tested requires a
-                client = AsyncHTTPClient(self.io_loop)
+                client = AsyncHTTPClient()
-                client = AsyncHTTPClient(self.io_loop)
+                client = AsyncHTTPClient()
-                client = AsyncHTTPClient(self.io_loop)
+                client = AsyncHTTPClient()
-        return AsyncHTTPClient(io_loop=self.io_loop)
+        return AsyncHTTPClient()
-                          **self.get_httpserver_options())
+        return HTTPServer(self._app, **self.get_httpserver_options())
-        return AsyncHTTPClient(io_loop=self.io_loop, force_instance=True,
+        return AsyncHTTPClient(force_instance=True,
-    def __init__(self, io_loop, request, on_message_callback=None,
+    def __init__(self, request, on_message_callback=None,
-        self.tcp_client = TCPClient(io_loop=io_loop)
+        self.tcp_client = TCPClient()
-            io_loop, None, request, lambda: None, self._on_http_response,
+            None, request, lambda: None, self._on_http_response,
-def websocket_connect(url, io_loop=None, callback=None, connect_timeout=None,
+def websocket_connect(url, callback=None, connect_timeout=None,
-       The ``io_loop`` argument is deprecated.
+
-    conn = WebSocketClientConnection(io_loop, request,
+    conn = WebSocketClientConnection(request,
-        io_loop.add_future(conn.connect_future, callback)
+        IOLoop.current().add_future(conn.connect_future, callback)
-from tornado.testing import AsyncTestCase, gen_test, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, bind_unused_port, gen_test, ExpectLog
-        if name in self._options:
+        normalized = self._normalize_name(name)
-                        (name, self._options[name].file_name))
+                        (normalized, self._options[normalized].file_name))
-from tornado.test.util import unittest
+from tornado.test.util import unittest, subTest
-        self.write_message(message, isinstance(message, bytes))
+        try:
-            self._abort()
+        return self.stream.write(frame)
-            self._write_frame(True, 0xA, data)
+            try:
-                self._write_frame(True, 0x8, close_data)
+                try:
-        """Gets the value of the cookie with the given name, else default."""
+        """Returns the value of the request cookie with the given name.
-        """Sets the given cookie name/value with the given options.
+        """Sets an outgoing cookie name/value with the given options.
-        Additional keyword arguments are set on the Cookie.Morsel
+        Additional keyword arguments are set on the cookies.Morsel
-        See https://docs.python.org/2/library/cookie.html#Cookie.Morsel
+        See https://docs.python.org/3/library/http.cookies.html#http.cookies.Morsel
-version = "4.5.1"
+version = "5.0.dev1"
-version_info = (4, 5, 1, 0)
+version = "5.0.dev1"
-        with self.assertRaises(WindowsError) as cm:
+        with self.assertRaises(WindowsError):
-            self.close(exc_info=True)
+            self.close(exc_info=e)
-            self.close(exc_info=True)
+            self.close(exc_info=e)
-                if any(exc_info):
+                if isinstance(exc_info, tuple):
-            self.close(exc_info=True)
+            self.close(exc_info=e)
-            self.close(exc_info=True)
+            self.close(exc_info=e)
-            except Exception:
+            except Exception as e:
-                self.close(exc_info=True)
+                self.close(exc_info=e)
-            self.close(exc_info=True)
+            self.close(exc_info=e)
-                    self.close(exc_info=True)
+                    self.close(exc_info=e)
-                self.close(exc_info=True)
+                self.close(exc_info=e)
-                    self.close(exc_info=True)
+                    self.close(exc_info=e)
-                self.close(exc_info=True)
+                self.close(exc_info=e)
-                return self.close(exc_info=True)
+                return self.close(exc_info=err)
-                return self.close(exc_info=True)
+                return self.close(exc_info=err)
-                return self.close(exc_info=True)
+                return self.close(exc_info=err)
-            return self.close(exc_info=True)
+            return self.close(exc_info=err)
-                self.close(exc_info=True)
+                self.close(exc_info=e)
-version = "4.5"
+version = "4.5.1"
-version_info = (4, 5, 0, 0)
+version = "4.5.1"
-            try:
+    try:
-    return color
+                    return True
-            elif sys.stderr is getattr(colorama, 'wrapped_stderr', object()):
+            else:
-                raise RuntimeError("No supported color terminal library")
+    if args is None:
-version = "4.5b2"
+version = "4.5"
-version_info = (4, 5, 0, -98)
+version = "4.5"
-        ])
+            ('/render', RenderMessageHandler,
-version = "4.5b1"
+version = "4.5b2"
-version_info = (4, 5, 0, -99)
+version = "4.5b2"
-                f = None
+                # Break a reference cycle to speed GC.
-        if compression_options is None or not 'compression_level' in compression_options:
+        if compression_options is None or 'compression_level' not in compression_options:
-        if compression_options is None or not 'mem_level' in compression_options:
+        if compression_options is None or 'mem_level' not in compression_options:
-        extension_header = ''
+
-            curl.setopt(pycurl.REDIR_PROTOCOLS, pycurl.PROTO_HTTP|pycurl.PROTO_HTTPS)
+        if hasattr(pycurl, 'PROTOCOLS'):  # PROTOCOLS first appeared in pycurl 7.19.5 (2014-07-12)
-            res.append(str[k+1])
+            res.append(str[k + 1])
-            res.append(chr(int(str[j+1:j+4], 8)))
+            res.append(chr(int(str[j + 1:j + 4], 8)))
-                       ).tobytes()
+             [self._read_buffer_pos:self._read_buffer_pos + loc]
-    import asyncio # type: ignore
+    import asyncio  # type: ignore
-            1/0
+            1 / 0
-
+
-        #TODO: Add wbits option.
+        # TODO: Add wbits option.
-        if new_len > (self.handler.max_message_size or 10*1024*1024):
+        if new_len > (self.handler.max_message_size or 10 * 1024 * 1024):
-                self.periodic_ping, self.ping_interval*1000)
+                self.periodic_ping, self.ping_interval * 1000)
-        if (since_last_ping < 2*self.ping_interval and
+        if (since_last_ping < 2 * self.ping_interval and
-            "expires": args.get("expires")
+            "expires_in": args.get("expires_in")
-        fieldmap.update({"access_token": session["access_token"], "session_expires": session.get("expires")})
+        # session_expires is converted to str for compatibility with
-        self.write(dict(access_token="asdf"))
+        self.write(dict(access_token="asdf", expires_in=3600))
-        """Convenience method to synchronously fetch a url.
+        """Convenience method to synchronously fetch a URL.
-        self.http_client.fetch(self.get_url(path), self.stop, **kwargs)
+        if path.lower().startswith(('http://', 'https://')):
-       Added ``websocket_ping_interval`` and ``websocket_ping_timeout``.
+       Added ``websocket_ping_interval``, ``websocket_ping_timeout``, and
-                                           self._on_frame_data)
+                    self._read_frame_data(False)
-                self.stream.read_bytes(self._frame_length, self._on_frame_data)
+                self._read_frame_data(False)
-                self.stream.read_bytes(self._frame_length, self._on_frame_data)
+                self._read_frame_data(False)
-                                   self._on_masked_frame_data)
+            self._read_frame_data(True)
-                 compression_options=None, ping_interval=None, ping_timeout=None):
+                 compression_options=None, ping_interval=None, ping_timeout=None,
-                      ping_interval=None, ping_timeout=None):
+                      ping_interval=None, ping_timeout=None,
-                                     ping_timeout=ping_timeout)
+                                     ping_timeout=ping_timeout,
-            data = yield self.server.streams[0].read_bytes(5)
+            data = yield server_stream.read_bytes(5)
-version = "4.4.2"
+version = "4.4.3"
-version_info = (4, 4, 2, 0)
+version = "4.4.3"
-        args = urlparse.parse_qs(escape.native_str(response.body))
+        args = escape.json_decode(response.body)
-            "access_token": args["access_token"][-1],
+            "access_token": args.get("access_token"),
-        self.write('access_token=asdf')
+        self.write(dict(access_token="asdf"))
-        args = urlparse.parse_qs(escape.native_str(response.body))
+        args = escape.json_decode(response.body)
-            "access_token": args["access_token"][-1],
+            "access_token": args.get("access_token"),
-        self.write('access_token=asdf')
+        self.write(dict(access_token="asdf"))
-        self.assertEqual(response.code, 500)
+        response = self.fetch("/?code=682")
-                raise ValueError("unknown status code %d" % status_code)
+            self._reason = httputil.responses.get(status_code, "Unknown")
-                self.send_error(e.status_code, exc_info=sys.exc_info())
+            self.send_error(e.status_code, exc_info=sys.exc_info())
-version = "4.5.dev1"
+version = "4.5b1"
-version_info = (4, 5, 0, -100)
+version = "4.5b1"
-        resolved, the previous future will be orphaned and will never resolve.
+        completed.
-"""Basic routing implementation.
+"""Flexible routing implementation.
-Tornado routes HTTP requests to appropriate handlers using `Router` class implementations.
+Tornado routes HTTP requests to appropriate handlers using `Router`
-as a ``request_callback`` for `~.httpserver.HTTPServer` constructor.
+`Router` interface extends `~.httputil.HTTPServerConnectionDelegate`
-`~.httputil.HTTPMessageDelegate` instance to handle the request:
+`Router` subclass must implement a ``find_handler`` method to provide
-we can see that routing is possible even without instantiating an `~.web.Application`.
+The main responsibility of `Router` implementation is to provide a
-`~.httputil.HTTPMessageDelegate` for a given request and `~.web.RequestHandler`.
+For routing to `~.web.RequestHandler` implementations we need an
-by HTTP method:
+Here is a simple example of how we can we route to
-`~.web.Application` is itself an implementation of `ReversibleRouter` class.
+`ReversibleRouter` interface adds the ability to distinguish between
-interfaces and can be used for creating rule-based routing configurations.
+`RuleRouter` and `ReversibleRuleRouter` are implementations of
-one of the following.
+Rules are instances of `Rule` class. They contain a `Matcher`, which
-        Set ws_ping_interval = 0 to disable pings.
+        Set websocket_ping_interval = 0 to disable pings.
-        ``compression_level`` specifies the compression level. 
+        ``compression_level`` specifies the compression level.
-         These parameters are documented in details here: https://docs.python.org/3.6/library/zlib.html#zlib.compressobj
+
-        ret = self.wait()
+        try:
-        self._write_future = None
+        self._write_futures = collections.deque()
-            future = self._write_future = TracebackFuture()
+            future = TracebackFuture()
-                self._write_future = None
+            futures += [future for _, future in self._write_futures]
-                self._write_callback or self._write_future or
+                self._write_callback or self._write_futures or
-
+                result = gen.convert_yielded(result)
-                gen.convert_yielded(handled_future).add_done_callback(
+                handled_future.add_done_callback(
-    this must first initialize colorama with a call to :func:`colorama.init`.
+    this must first initialize colorama with a call to ``colorama.init``.
-            self._compressor = self._create_compressor(self._compression_level, self._mem_level)
+            self._compressor = self._create_compressor()
-        return zlib.compressobj(compression_level, zlib.DEFLATED, -self._max_wbits, mem_level)
+    def _create_compressor(self):
-        compressor = self._compressor or self._create_compressor(self._compression_level, self._mem_level)
+        compressor = self._compressor or self._create_compressor()
-    def __init__(self, persistent, max_wbits):
+    def __init__(self, persistent, max_wbits, compression_options=None):
-            **self._get_compressor_options(other_side, agreed_parameters))
+            **self._get_compressor_options(other_side, agreed_parameters, compression_options))
-    def _get_compressor_options(self, side, agreed_parameters, compression_options):
+    def _get_compressor_options(self, side, agreed_parameters, compression_options=None):
-    def _get_compressor_options(self, side, agreed_parameters):
+    def _get_compressor_options(self, side, agreed_parameters, compression_options):
-            **self._get_compressor_options(side, agreed_parameters), compression_options=compression_options)
+            **self._get_compressor_options(side, agreed_parameters, compression_options))
-        but no such options are currently implemented.
+        control the following compression options:
-    def __init__(self, persistent, max_wbits):
+    def __init__(self, persistent, max_wbits, compression_options=None):
-            self._compressor = self._create_compressor()
+            self._compressor = self._create_compressor(self._compression_level, self._mem_level)
-                                zlib.DEFLATED, -self._max_wbits)
+    def _create_compressor(self, compression_level, mem_level):
-        compressor = self._compressor or self._create_compressor()
+        compressor = self._compressor or self._create_compressor(self._compression_level, self._mem_level)
-                self._create_compressors('server', ext[1])
+                self._create_compressors('server', ext[1], self._compression_options)
-    def _create_compressors(self, side, agreed_parameters):
+    def _create_compressors(self, side, agreed_parameters, compression_options=None):
-            **self._get_compressor_options(side, agreed_parameters))
+            **self._get_compressor_options(side, agreed_parameters), compression_options=compression_options)
-                          Name("with_statement", prefix=" ")])
+                          Name("print_function", prefix=" ")])
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import absolute_import, division, print_function
-    Three steps are required to have you app translated:
+    Three steps are required to have your app translated:
-                 datefmt=DEFAULT_DATE_FORMAT, colors=DEFAULT_COLORS):
+    def __init__(self, fmt=DEFAULT_FORMAT, datefmt=DEFAULT_DATE_FORMAT,
-    colorama.init()
+
-            elif colorama is not None:
+            elif sys.stderr is getattr(colorama, 'wrapped_stderr', object()):
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipBefore35, exec_test
-from tornado import httpclient, httputil
+from tornado import gen, httpclient, httputil
-        On error, aborts the websocket connection and returns False.
+        If the callback is a coroutine, returns its Future. On error, aborts the
-            callback(*args, **kwargs)
+            result = callback(*args, **kwargs)
-            self._handle_message(opcode, data)
+            handled_future = self._handle_message(opcode, data)
-            self._receive_frame()
+            if handled_future:
-            self._run_callback(self.handler.on_message, decoded)
+            return self._run_callback(self.handler.on_message, decoded)
-            self._run_callback(self.handler.on_message, data)
+            return self._run_callback(self.handler.on_message, data)
-            self._run_callback(self.handler.on_pong, data)
+            return self._run_callback(self.handler.on_pong, data)
-                          self.request.path, exc_info=True)
+                          getattr(self.request, 'path', None), exc_info=True)
-            body_timeout=body_timeout)
+            body_timeout=body_timeout,
-    def ws_connect(self, path, compression_options=None):
+    def ws_connect(self, path, **kwargs):
-            compression_options=compression_options)
+            **kwargs)
-        return self.settings.get('websocket_ping_interval', 0)
+        return self.settings.get('websocket_ping_interval', None)
-        )
+        return self.settings.get('websocket_ping_timeout', None)
-        if self.handler.ping_interval > 0:
+        if self.ping_interval > 0:
-                self.periodic_ping, self.handler.ping_interval*1000)
+                self.periodic_ping, self.ping_interval*1000)
-                since_last_pong > self.handler.ping_timeout):
+        if (since_last_ping < 2*self.ping_interval and
-                 compression_options=None):
+                 compression_options=None, ping_interval=None, ping_timeout=None):
-                      on_message_callback=None, compression_options=None):
+                      on_message_callback=None, compression_options=None,
-                                     compression_options=compression_options)
+                                     compression_options=compression_options,
-        self.last_pong = IOLoop.current().time()
+        """Invoked when the response to a ping frame is received."""
-        self._run_callback(self.handler.start_pinging)
+        self.start_pinging()
-    parsing and log formatting.
+    parsing and log formatting. It is *not* necessary to use this
-        self.addCleanup(lambda: os.kill(subproc.pid, signal.SIGTERM))
+        self.addCleanup(lambda: (subproc.proc.terminate(), subproc.proc.wait()))
-        self.addCleanup(lambda: os.kill(subproc.pid, signal.SIGTERM))
+        self.addCleanup(lambda: (subproc.proc.terminate(), subproc.proc.wait()))
-        self.addCleanup(lambda: os.kill(subproc.pid, signal.SIGTERM))
+        self.addCleanup(lambda: (subproc.proc.terminate(), subproc.proc.wait()))
-            # Fail loudly if unable to use the IP/port.
+            try:
-           particular, if your authenticatino is cookie-based, you
+           particular, if your authentication is cookie-based, you
-        x = yield asyncio.async(
+        # Without 'yield from', we must wrap coroutines in ensure_future,
-                self.code in (301, 302, 303, 307))
+                self.code in (301, 302, 303, 307, 308))
-            # start_line may be a request or reponse start line; only
+            # start_line may be a request or response start line; only
-from tornado.test.util import skipIfNoIPv6, unittest, refusing_port
+from tornado.test.util import skipIfNoIPv6, unittest, refusing_port, skipIfNonUnix
-
+"""Asynchronous queues for coroutines.
-    def do_test_connect(self, family, host):
+    def do_test_connect(self, family, host, source_ip=None, source_port=None):
-        stream = yield self.client.connect(host, port)
+        stream = yield self.client.connect(host, port,
-                max_buffer_size=None, source_ip=None):
+                max_buffer_size=None, source_ip=None, source_port=None):
-        Using the `source_ip` kwarg, one can specify the source
+        Using the ``source_ip`` kwarg, one can specify the source
-                              source_ip=source_ip)
+                              source_ip=source_ip, source_port=source_port)
-    def _create_stream(self, max_buffer_size, af, addr, source_ip=None):
+    def _create_stream(self, max_buffer_size, af, addr, source_ip=None,
-            # so the port argument is set to 0.
+        source_port_bind = source_port if isinstance(source_port, int) else 0
-            stream = IOStream(socket.socket(af),
+            stream = IOStream(socket_obj,
-    def __init__(self, addrinfo, io_loop, connect, source_ip=None):
+    def __init__(self, addrinfo, io_loop, connect):
-        future = self.connect(af, addr, source_ip=self.source_ip)
+        future = self.connect(af, addr)
-            return stream.connect(addr, source_ip=source_ip)
+            return stream.connect(addr)
-                source_ip=None):
+    def connect(self, address, callback=None, server_hostname=None):
-        # source_ip not used here
+    def connect(self, address, callback=None, server_hostname=None):
-            of Tornado as this depneds very much on the platform.
+        Using the `source_ip` kwarg, one can specify the source
-            source_ip=source_ip)
+            functools.partial(self._create_stream, max_buffer_size,
-            raise_exc_info(self._exc_info)
+            try:
-                self.future, lambda f: self.run())
+                self.future, inner)
-    raise exc_info[1].with_traceback(exc_info[2])
+    try:
-                        exc_info = None
+                        try:
-    def connect(self, address, callback=None, server_hostname=None):
+    def connect(self, address, callback=None, server_hostname=None,
-    def connect(self, address, callback=None, server_hostname=None):
+    def connect(self, address, callback=None, server_hostname=None,
-    def __init__(self, addrinfo, io_loop, connect):
+    def __init__(self, addrinfo, io_loop, connect, source_ip=None):
-        future = self.connect(af, addr)
+        future = self.connect(af, addr, source_ip=self.source_ip)
-                max_buffer_size=None):
+                max_buffer_size=None, source_ip=None):
-            functools.partial(self._create_stream, max_buffer_size))
+            functools.partial(self._create_stream, max_buffer_size),
-    def _create_stream(self, max_buffer_size, af, addr):
+    def _create_stream(self, max_buffer_size, af, addr, source_ip=None):
-                            max_buffer_size=max_buffer_size)
+                              io_loop=self.io_loop,
-            return stream.connect(addr)
+            return stream.connect(addr, source_ip=source_ip)
-        'https://pypi.python.org/packages/source/t/tornado/tornado-%s.tar.g%%s' % version,
+        'https://pypi.org/packages/source/t/tornado/tornado-%s.tar.g%%s' % version,
-            for fd, handler in self._handlers.values():
+            for fd, handler in list(self._handlers.values()):
-    `set_default_headers` or `prepare`.
+    `~tornado.web.RequestHandler.set_default_headers` or
-import string
+        self.set_header("X-Extra-Response-Header", "Extra-Response-Value")
-                                 'X-Test-Random': random_str}))
+                        headers={'X-Test-Hello': 'hello'}))
-    `set_default_headers`.
+    `set_default_headers` or `prepare`.
-
+import functools
-            pass
+        methods_to_test = [
-        super(WebSocketHandler, self).__init__(application, request, **kwargs)
+        # disable non-WS methods
-            _wrap_method(getattr(WebSocketHandler, method)))
+def _raise_not_supported_for_websockets(*args, **kwargs):
-            self.set_status(426)
+            self.set_status(426, "Upgrade Required")
-        )
+    def set_default_headers(self):
-    `upgrade_response_headers`.
+    `set_default_headers`.
-        super(WebSocketHandler, self).__init__(application, request, **kwargs)
+        super(WebSocketHandler, self).__init__(application, request, **kwargs)
-                self.stream.close()
+            self.set_status(426)
-           upgrade response.
+    def set_default_headers(self):
-        return ""
+        pass
-                                      % selected)
+                self.handler.set_header("Sec-WebSocket-Protocol", selected)
-                                        'permessage-deflate', ext[1]))
+                self.handler.set_header("Sec-WebSocket-Extensions",
-                      self.handler.upgrade_response_headers())))
+        self.handler.clear_header("Content-Type")
-            "%s%s"
+            "%s%s%s"
-                      subprotocol_header, extension_header)))
+                      subprotocol_header, extension_header,
-`~.httputil.HTTPServerConnectionDelegate`):
+`Router` interface extends `~.httputil.HTTPServerConnectionDelegate` to provide additional
-            return HTTPMessageDelegateImplementation()
+            # some routing logic providing a suitable HTTPMessageDelegate instance
-`~.httputil.HTTPMessageDelegate` that will be used to process the request.
+The main responsibility of `Router` implementation is to provide a mapping from a request
-routing configurations. For example, `RuleRouter` can be used to route between applications:
+`RuleRouter` and `ReversibleRuleRouter` are implementations of `Router` and `ReversibleRouter`
-.. code-block:: python
+Rules are instances of `Rule` class. They contain a `Matcher`, which provides the logic for
-    ])
+1) An instance of `~.httputil.HTTPServerConnectionDelegate`:
-    ])
+.. code-block:: python
-        Rule(PathMatches("/app2.*"), app2)
+        Rule(PathMatches("/handler"), ConnectionDelegate()),
-    server = HTTPServer(router)
+    class ConnectionDelegate(HTTPServerConnectionDelegate):
-rule targets:
+2) A callable accepting a single argument of `~.httputil.HTTPServerRequest` type:
-        Rule(PathMatches("/delegate"), HTTPServerConnectionDelegateImpl())
+        Rule(PathMatches("/callable"), request_callable)
-    server = HTTPServer(router)
+    def request_callable(request):
-You can use nested routers as targets as well:
+3) Another `Router` instance:
-And of course a nested `RuleRouter` would be a valid thing:
+Of course a nested `RuleRouter` or a `~.web.Application` is allowed:
-and others).
+In the example below `RuleRouter` is used to route between applications:
-backwards compatibility.
+    app1 = Application([
-        """Constructs a router with an ordered list of rules::
+        """Constructs a router from an ordered list of rules::
-                Rule(PathMatches("/handler"), SomeHandler),
+                Rule(PathMatches("/handler"), Target),
-                (PathMatches("/handler"), SomeHandler),
+                (PathMatches("/handler"), Target),
-                ("/handler", SomeHandler),
+                ("/handler", Target),
-            `~.httputil.HTTPServerConnectionDelegate` subclass or even a nested `Router`).
+            `~.httputil.HTTPServerConnectionDelegate` subclass or even a nested `Router`,
-    """Specifies mappings between URLs and handlers."""
+    """Specifies mappings between URLs and handlers.
-from tornado.routing import HostMatches, PathMatches, ReversibleRouter, Rule, RuleRouter
+from tornado.routing import HostMatches, PathMatches, ReversibleRouter, Router, Rule, RuleRouter
-from tornado.web import Application, RequestHandler
+from tornado.web import Application, HTTPError, RequestHandler
-def get_named_handler(handler_name):
+class BasicRouter(Router):
-SecondHandler = get_named_handler("second_handler")
+FirstHandler = _get_named_handler("first_handler")
-    """Routing implementation used by `Application`.
+    """Routing implementation used internally by `Application`.
-    Provides a binding between `Application` and `RequestHandler` implementations.
+    Provides a binding between `Application` and `RequestHandler`.
-        the list of routes.
+        * it allows to use a list/tuple of rules as `~.routing.Rule` target.
-    except ValueError:
+    except (AttributeError, ValueError):
-
+from tornado.util import errno_from_exception
-                        detail[0] != errno.WSAEADDRINUSE):
+                        errno_from_exception(detail) != errno.WSAEADDRINUSE):
-                self.io_loop.add_future(future, lambda f: f.result())
+                self.io_loop.add_future(gen.convert_yielded(future),
-                 start_line=None):
+                 start_line=None, server_connection=None):
-Subclasses of `~.httputil.HTTPMessageDelegate` and old-style callables can also be used as
+Implementations of `~.httputil.HTTPServerConnectionDelegate` and old-style callables can also be used as
-        Rule(PathMatches("/delegate"), HTTPMessageDelegateSubclass)
+        Rule(PathMatches("/delegate"), HTTPServerConnectionDelegateImpl())
-basic routing logic defining whether this rule is a match for a particular request.
+`~.httputil.HTTPServerConnectionDelegate` implementation, a callable or a nested `Router`) and
-        return _RoutingDelegate(self, request_conn)
+        return _RoutingDelegate(self, server_conn, request_conn)
-        self.connection = request_conn
+    def __init__(self, router, server_conn, request_conn):
-            headers=headers)
+            connection=self.request_conn,
-            return target(request.connection)
+        elif isinstance(target, httputil.HTTPServerConnectionDelegate):
-            `~.httputil.HTTPMessageDelegate` subclass or even a nested `Router`).
+            `~.httputil.HTTPServerConnectionDelegate` subclass or even a nested `Router`).
-from tornado.httputil import HTTPHeaders, HTTPMessageDelegate, ResponseStartLine
+from tornado.httputil import HTTPHeaders, HTTPMessageDelegate, HTTPServerConnectionDelegate, ResponseStartLine
-        self.connection = connection
+class ConnectionDelegate(HTTPServerConnectionDelegate):
-        self.connection.finish()
+        class MessageDelegate(HTTPMessageDelegate):
-            ("/message_delegate", MessageDelegate)
+            ("/connection_delegate", ConnectionDelegate())
-        response = self.fetch("/message_delegate")
+        response = self.fetch("/connection_delegate")
-    from urllib.parse import urlencode
+    from urllib.parse import urlencode, urlparse, urlunparse, parse_qsl
-    return url + urlencode(args)
+    parsed_url = urlparse(url)
-        self.assertEqual(url, "https://localhost/path?x&y=y&z=z")
+        self.assertEqual(url, "https://localhost/path?x=&y=y&z=z")
-        self.assertEqual(url, "https://localhost/path?x&y=y&z=z")
+        self.assertEqual(url, "https://localhost/path?x=&y=y&z=z")
-class ApplicationRouter(ReversibleRuleRouter):
+class _ApplicationRouter(ReversibleRuleRouter):
-        super(ApplicationRouter, self).__init__(rules)
+        super(_ApplicationRouter, self).__init__(rules)
-        rule = super(ApplicationRouter, self).process_rule(rule)
+        rule = super(_ApplicationRouter, self).process_rule(rule)
-            rule.target = ApplicationRouter(self.application, rule.target)
+            rule.target = _ApplicationRouter(self.application, rule.target)
-        return super(ApplicationRouter, self).get_target_delegate(target, request, **target_params)
+        return super(_ApplicationRouter, self).get_target_delegate(target, request, **target_params)
-    (fully-qualified) name.
+    The constructor for this class takes in a list of `~.routing.Rule`
-    only tuples of two or three elements were allowed).
+    In addition to this you can use nested `~.routing.Router` instances,
-    constructor and `~RequestHandler.initialize` method.  This pattern
+    When we receive requests, we iterate over the list in order and
-        self.default_router.add_rules([
+        self.wildcard_router = _ApplicationRouter(self, handlers)
-        rule = Rule(host_matcher, ApplicationRouter(self, host_handlers))
+        rule = Rule(host_matcher, _ApplicationRouter(self, host_handlers))
-    def find_handler(self, request):
+    def find_handler(self, request, **kwargs):
-from tornado.util import ObjectDict, unicode_type
+from tornado.test.util import unittest, is_coverage_running
-    @functools.wraps(func)
+    @functools.wraps(wrapped)
-            return bool(L)
+            # Not referencing any globals here
-from tornado.util import raise_exc_info, ArgReplacer
+from tornado.util import raise_exc_info, ArgReplacer, is_finalizing
-        if self.formatted_tb:
+    def __del__(self, is_finalizing=is_finalizing):
-            if not self._log_traceback:
+        def __del__(self, is_finalizing=is_finalizing):
-from tornado.testing import AsyncTestCase, LogTrapTestCase, bind_unused_port, gen_test
+from tornado.testing import AsyncTestCase, ExpectLog, LogTrapTestCase, bind_unused_port, gen_test
-from tornado.util import raise_exc_info, Configurable, exec_in, ArgReplacer, timedelta_to_seconds, import_object, re_unescape, PY3
+from tornado.util import raise_exc_info, Configurable, exec_in, ArgReplacer, timedelta_to_seconds, import_object, re_unescape, is_finalizing, PY3
-"""Basic implementation of rule-based routing.
+"""Basic routing implementation.
-    """
+    """Abstract router interface."""
-        Router implementations may pass additional kwargs to extend the routing logic.
+        """Must be implemented to return an appropriate instance of `~.httputil.HTTPMessageDelegate`
-        self.named_rules = {}
+        self.named_rules = {}  # type: typing.Dict[str]
-    """
+    """Represents a matcher for request features."""
-        ``None`` must be returned to indicate that there is no match."""
+        """Matches current instance against the request.
-        """Reconstruct URL from matcher instance"""
+        """Reconstructs full url from matcher instance and additional arguments."""
-            self.regex = re.compile(pattern)
+    """Matches requests with paths specified by ``path_pattern`` regex."""
-            self.regex = pattern
+            self.regex = path_pattern
-        * ``handler``: `RequestHandler` subclass to be invoked.
+        * ``handler``: `~.web.RequestHandler` subclass to be invoked.
-          `Application.reverse_url`.
+          `~.web.Application.reverse_url`.
-        self.assertEqual(response.code, 301)
+        response = self.fetch("/foo", headers={"X-Real-Ip": "127.0.0.1"})
-from tornado.httputil import split_host_and_port
+from tornado.routing import (AnyMatches, DefaultHostMatches, HostMatches,
-class Application(httputil.HTTPServerConnectionDelegate):
+class ApplicationRouter(ReversibleRuleRouter):
-    def __init__(self, handlers=None, default_host="", transforms=None,
+    def __init__(self, handlers=None, default_host=None, transforms=None,
-            self.add_handlers(".*$", handlers)
+        self.wildcard_router = ApplicationRouter(self, handlers)
-                self.named_handlers[spec.name] = spec
+        host_matcher = HostMatches(host_pattern)
-        dispatcher.set_request(request)
+        dispatcher = self.find_handler(request)
-            return self.named_handlers[name].reverse(*args)
+        reversed_url = self.default_router.reverse_url(name, *args)
-    def __init__(self, application, connection):
+class _HandlerDelegate(httputil.HTTPMessageDelegate):
-        self.request = None
+        self.connection = request.connection
-        self.path_kwargs = {}
+        self.stream_request_body = _has_stream_request_body(self.handler_class)
-        pass
+        """
-        self.redirect(self._url, permanent=self._permanent)
+    def get(self, *args):
-        except (IOError, socket.error):
+        except (IOError, socket.error, ValueError):
-        except IOError:
+        except (IOError, ValueError):
-        self._waker.mark_closing()
+import time
-        self.closing = True
+        try_close(self.writer)
-from tornado.platform import interface
+from tornado.platform import common, interface
-        self.closing = True
+        common.try_close(self.writer)
-                for i in range(n):
+                for i in range(ncallbacks):
-        self._callback_lock = threading.Lock()
+        self._callbacks = collections.deque()
-            self._closing = True
+        self._waker.mark_closing()
-                    self._run_callback(callback)
+                # Prevent IO event starvation by delaying new callbacks
-                callbacks = callback = due_timeouts = timeout = None
+                due_timeouts = timeout = None
-                    self._waker.wake()
+            # This will write one byte but Waker.consume() reads many
-                stack_context.wrap(callback), *args, **kwargs))
+            # If we're on the IOLoop's thread, we don't need to wake anyone.
-            self._write_buffer_size += len(data)
+            if self._write_buffer_frozen:
-                    self._write_buffer_frozen = size
+                    self._got_empty_write(size)
-                self._write_buffer_frozen = False
+                if self._write_buffer_frozen:
-                    self._write_buffer_frozen = size
+                    self._got_empty_write(size)
-                if _WINDOWS:
+                if self._write_buffer_frozen:
-                    stop = start + 128 * 1024
+                    size = 128 * 1024
-                    stop = None
+                    size = self._write_buffer_size
-                    memoryview(self._write_buffer)[start:stop])
+                    memoryview(self._write_buffer)[start:start + size])
-                    self._write_buffer_frozen = True
+                    self._write_buffer_frozen = size
-                    self._write_buffer_frozen = True
+                    self._write_buffer_frozen = size
-                    self._write_buffer = self._write_buffer[self._write_buffer_pos:]
+                    del self._write_buffer[:self._write_buffer_pos]
-            self._read_buffer = self._read_buffer[self._read_buffer_pos:]
+            del self._read_buffer[:self._read_buffer_pos]
-        assert isinstance(data, bytes)
+    def test_write_memoryview(self):
-        self._write_buffer = collections.deque()
+        self._read_buffer = bytearray()
-                self._write_buffer.append(data[i:i + WRITE_BUFFER_CHUNK_SIZE])
+            self._write_buffer += data
-            if self._write_buffer:
+            if self._write_buffer_size:
-        return bool(self._write_buffer)
+        return self._write_buffer_size > 0
-        self._read_buffer.append(chunk)
+        self._read_buffer += chunk
-                    _double_prefix(self._read_buffer)
+                loc = self._read_buffer.find(self._read_delimiter,
-                                      len(self._read_buffer[0]))
+                                      self._read_buffer_size)
-                                      len(self._read_buffer[0]))
+                m = self._read_regex.search(self._read_buffer,
-        while self._write_buffer:
+        while self._write_buffer_size:
-                if not self._write_buffer_frozen:
+                start = self._write_buffer_pos
-                num_bytes = self.write_to_fd(self._write_buffer[0])
+                    stop = start + 128 * 1024
-                self._write_buffer.popleft()
+                self._write_buffer_pos += num_bytes
-        if not self._write_buffer:
+        if not self._write_buffer_size:
-        _merge_prefix(self._read_buffer, loc)
+        assert loc <= self._read_buffer_size
-        return self._read_buffer.popleft()
+        # Amortized O(1) shrink
-        return _ServerRequestAdapter(self, server_conn, request_conn)
+        if isinstance(self.request_callback, httputil.HTTPServerConnectionDelegate):
-        self.server = server
+class _ProxyAdapter(httputil.HTTPMessageDelegate):
-            self._chunks = []
+        self.delegate = delegate
-            return self.delegate.headers_received(start_line, headers)
+        self.connection.context._apply_xheaders(headers)
-            return self.delegate.data_received(chunk)
+        return self.delegate.data_received(chunk)
-            self.delegate.finish()
+        self.delegate.finish()
-            self.delegate.on_connection_close()
+        self.delegate.on_connection_close()
-
+        self.connection.context._unapply_xheaders()
-                   max_body_size=None, max_buffer_size=None):
+                   max_body_size=None, max_buffer_size=None,
-                                      self.protocol)
+                                      self.protocol,
-    def __init__(self, stream, address, protocol):
+    def __init__(self, stream, address, protocol, trusted_downstream=None):
-        ip = ip.split(',')[-1].strip()
+        # Skip trusted downstream hosts in X-Forwarded-For list
-        return dict(xheaders=True)
+        return dict(xheaders=True, trusted_downstream=['5.5.5.5'])
-        :arg float request_timeout: Timeout for entire request in seconds
+        :arg float connect_timeout: Timeout for initial connection in seconds,
-        :arg int max_redirects: Limit for ``follow_redirects``
+           or return the 3xx response? Default True.
-           argument?
+           argument? Default is False.
-           certificate?
+           certificate? Default is True.
-version = "4.4.1"
+version = "4.4.2"
-version_info = (4, 4, 1, 0)
+version = "4.4.2"
-                        native_str(self.headers["Cookie"]))
+                    parsed = parse_cookie(self.headers["Cookie"])
-                    self._cookies = {}
+                    pass
-from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp, HTTPServerRequest, parse_request_start_line
+from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp, HTTPServerRequest, parse_request_start_line, parse_cookie
-                # ('foo=a\\073b', 'a;b'),  # even encoded, ";" is a delimiter
+                ('foo="a;b"', '"a'),  # even quoted, ";" is a delimiter
-   Use the `~asyncio.SelectorEventLoop` instead.
+   Tornado requires the `~asyncio.AbstractEventLoop.add_reader` family of
-                    self.add_future(ret, lambda f: f.result())
+                    self.add_future(ret, self._discard_future_result)
-        return stream.connect(addr)
+        try:
-  with additional support for testing asynchronous (`.IOLoop` based) code.
+  with additional support for testing asynchronous (`.IOLoop`-based) code.
-    reason to return a value from a test.
+    reason to return a value from a test).
-        :param required: If true, an exeption will be raised if the end of
+        :param required: If true, an exception will be raised if the end of
-7.21.1, and the minimum version of pycurl is 7.18.2.  It is highly
+7.22.0, and the minimum version of pycurl is 7.18.2.  It is highly
-        color = True
+    if hasattr(sys.stderr, 'isatty') and sys.stderr.isatty():
-            self._normal = '\033[0m'
+        if color and _stderr_supports_color():
-            self.io_loop.add_timeout(datetime.timedelta(seconds=0.01),
+            self.io_loop.add_timeout(datetime.timedelta(seconds=0.05),
-            self.io_loop.add_timeout(datetime.timedelta(seconds=0.01),
+            self.io_loop.add_timeout(datetime.timedelta(seconds=0.05),
-                print("Error:", response.error)
+                print("Error: %s" % response.error)
-                 client_key=None, client_cert=None, body_producer=None,
+                 proxy_password=None, proxy_auth_mode=None,
-           with ``curl_httpclient``.
+           ``proxy_host`` and ``proxy_port`` must be set; ``proxy_username``,
-                    'proxy_username', 'proxy_password'):
+                    'proxy_username', 'proxy_password',
-            print response.body
+            print(response.body)
-                print "Error:", response.error
+                print("Error:", response.error)
-                print response.body
+                print(response.body)
-    print user_locale.translate("Sign out")
+    print(user_locale.translate("Sign out"))
-    print message % {"list": user_locale.list(people)}
+    print(message % {"list": user_locale.list(people)})
-    print t.generate(myvalue="XXX")
+    print(t.generate(myvalue="XXX"))
-    print loader.load("test.html").generate(myvalue="XXX")
+    print(loader.load("test.html").generate(myvalue="XXX"))
-        if color and _stderr_supports_color() and not colorama:
+        if color and _stderr_supports_color() and curses is not None:
-        elif colorama:
+        elif colorama is not None:
-                self._colors[levelno] = '\033[3{}m'.format(code)
+                self._colors[levelno] = '\033[2;3%dm' % code
-        # import tornado.curl_httpclient  # depends on pycurl
+        import tornado.tcpclient
-    ``resuse_port`` option sets ``SO_REUSEPORT`` option for every socket
+    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket
-        The user object may any type of the application's choosing.
+        The user object may be any type of the application's choosing.
-    """None-safe wrapper around url_unescape to handle unamteched optional
+    """None-safe wrapper around url_unescape to handle unmatched optional
-                    Runner(result, future, yielded)
+                    _futures_to_runners[future] = Runner(result, future, yielded)
-
+class RunnerGCTest(AsyncTestCase):
-    method.
+    method. For example, a simple echo server could be defined like this::
-   Use the `~asyncio.SelectorEventLoop` instead.
+   Tornado requires the `~asyncio.AbstractEventLoop.add_reader` family of
-        if color and _stderr_supports_color():
+        if color and _stderr_supports_color() and not colorama:
-        See http://docs.python.org/library/cookie.html#morsel-objects
+        See https://docs.python.org/2/library/cookie.html#Cookie.Morsel
-        config_path = os.path.join(os.path.dirname(__file__),
+        config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
-    * body: response body as string (created on demand from ``self.buffer``)
+    * body: response body as bytes (created on demand from ``self.buffer``)
-version = "4.4.1"
+version = "4.5.dev1"
-version_info = (4, 4, 1, 0)
+version = "4.5.dev1"
-version = "4.4"
+version = "4.4.1"
-version_info = (4, 4, 0, 0)
+version = "4.4.1"
-        if headers.get("Transfer-Encoding") == "chunked":
+        if headers.get("Transfer-Encoding", "").lower() == "chunked":
-                    raise ValueError(exc.args[0] + '; invalid url: %r' % pattern)
+                    # If we can't unescape part of it, we can't
-            "Cannot reverse url regex " + self.regex.pattern
+        if self._path is None:
-    pass
+    if isinstance(code, basestring_type):
-    exec code in glob, loc
+        if hasattr(pycurl,'PROTOCOLS'): # PROTOCOLS first appeared in pycurl 7.19.5 (2014-07-12)
-version = "4.4b1"
+version = "4.4"
-version_info = (4, 4, 0, -99)
+version = "4.4"
-        self.assertEqual(response.code, 599)
+        with ExpectLog(gen_log, ".*Response with code 204 should not have body"):
-    IOLoop.instance().add_callback_from_signal(IOLoop.instance().stop)
+    IOLoop.current().add_callback_from_signal(IOLoop.current().stop)
-    assert not IOLoop.initialized()
+    io_loop.start()
-version = "4.4.dev1"
+version = "4.4b1"
-version_info = (4, 4, 0, -100)
+version = "4.4b1"
-    'python': ('https://docs.python.org/3.4/', None),
+    'python': ('https://docs.python.org/3.5/', None),
-    """Wraps a `.Future` in a timeout.
+    """Wraps a `.Future` (or other yieldable object) in a timeout.
-    Currently only supports Futures, not other `YieldPoint` classes.
+    Does not support `YieldPoint` subclasses.
-    def bind(self, port, address=None, family=socket.AF_UNSPEC, backlog=128, reuse_port=False):
+    def bind(self, port, address=None, family=socket.AF_UNSPEC, backlog=128,
-        `socket.listen <socket.socket.listen>`.
+        `socket.listen <socket.socket.listen>`. The ``reuse_port`` argument
-                self.skipTest("requires HTTP/1.x")
+        response = self.fetch("/?error=1")
-        self.request.finish()
+        self.set_status(204)
-        # A test without a content-length header is included below
+        # Tests with a content-length header are included below
-
+
-        # no content length and does not close the connection.
+        # (which would otherwise mean read-until-close).  We simulate here a
-        # Tests of a 204 response with a Content-Length header are included
+        # Tests of a 204 response with no Content-Length header are included
-            b"HTTP/1.1 204 No content\r\n\r\n")
+        stream.write(b"HTTP/1.1 204 No content\r\n")
-        return "\n%s\n" % ("\n".join(lines))
+            lines.append("%s: %s\n" % (name, value))
-            sockets = bind_sockets(port, 'localhost', reuse_port=True)
+            sockets = bind_sockets(port, '127.0.0.1', reuse_port=True)
-    # TODO: allow yield points in addition to futures?
+    # TODO: allow YieldPoints in addition to other yieldables?
-                                (error, pycares.errno.strerror(error), host))
+                raise IOError('C-Ares returned error %s: %s while resolving %s' %
-                                (family, address_family))
+                raise IOError('Requested socket family %d but got %d' %
-                resolved.raiseException()
+                try:
-        with self.assertRaises(Exception):
+        with self.assertRaises(IOError):
-                self._next_timeout += (math.floor((current_time - self._next_timeout) / callback_time_sec) + 1) * callback_time_sec
+                self._next_timeout += (math.floor((current_time - self._next_timeout) /
-                start_line.code != 304 and
+                start_line.code not in (204, 304) and
-        self.set_status(204)
+            headers['Content-Length'] = "5"
-        # add a zero content-length anyway.
+        # 204 status shouldn't have a content-length
-        self.assertEqual(response.headers["Content-length"], "0")
+        self.assertNotIn("Content-Length", response.headers)
-                assert not self._write_buffer, "Cannot send body with 304"
+            if self._status_code in (204, 304):
-    (e.g., :class:`tornado.httpclient.AsyncHTTPClient`).
+    See also :meth:`tornado.ioloop.IOLoop.install` for general notes on
-    __slots__ = ['deadline', 'callback', 'tiebreaker']
+    __slots__ = ['deadline', 'callback', 'tdeadline']
-        self.tiebreaker = next(io_loop._timeout_counter)
+        self.tdeadline = (deadline, next(io_loop._timeout_counter))
-                (other.deadline, other.tiebreaker))
+        return self.tdeadline < other.tdeadline
-                (other.deadline, other.tiebreaker))
+        return self.tdeadline <= other.tdeadline
-            self.io_loop.add_timeout(datetime.timedelta(seconds=0.01), self.stop)
+            self.stream.read_until_close(self.stop)
-        raise ctypes.GetLastError()
+        raise ctypes.WinError()
-            self.io_loop.call_later(0.03, self.stop)
+            self.io_loop.call_later(0.1, self.stop)
-            content_length = int(headers["Content-Length"])
+
-    if isinstance(yielded, (list, dict)):
+    if yielded is None:
-    if sys.version_info < (3, 2):
+    if sys.version_info < (2, 7, 9):
-class ObjectDict(dict):
+try:
-        # On python 2 a byte string is required.
+    if not isinstance(name, str):
-        return e.errno
+        return e.errno  # type: ignore
-    __impl_kwargs = None  # type: dict
+    __impl_kwargs = None  # type: Dict[str, Any]
-        if isinstance(impl, (unicode_type, bytes)):
+        if isinstance(impl, (str, unicode_type)):
-                code = func.func_code
+                code = func.func_code  # type: ignore
-    unmasked = array.array("B", data)
+    mask_arr = array.array("B", mask)
-    if hasattr(unmasked, 'tobytes'):
+        unmasked_arr[i] = unmasked_arr[i] ^ mask_arr[i % 4]
-        return unmasked.tobytes()
+        return unmasked_arr.tobytes()
-        return unmasked.tostring()
+        return unmasked_arr.tostring()
-            "__loader__": ObjectDict(get_source=lambda name: self.code),  # type: ignore
+            "__loader__": ObjectDict(get_source=lambda name: self.code),
-        }, namespace={"_tt_modules": ObjectDict({"Template": lambda path, **kwargs: loader.load(path).generate(**kwargs)})})
+        }, namespace={"_tt_modules": ObjectDict(Template=lambda path, **kwargs: loader.load(path).generate(**kwargs))})
-            self.application = ObjectDict(settings=dict(cookie_secret=cookie_secret))  # type: ignore
+            self.application = ObjectDict(settings=dict(cookie_secret=cookie_secret))
-            self.application = ObjectDict(settings=dict(cookie_secret=cookie_secret,  # type: ignore
+            self.application = ObjectDict(settings=dict(cookie_secret=cookie_secret,
-from tornado.util import GzipDecompressor
+from tornado.util import GzipDecompressor, PY3
-        lines.extend([utf8(n) + b": " + utf8(v) for n, v in headers.get_all()])
+        # TODO: headers are supposed to be of type str, but we still have some
-        self._as_list = {}
+        self._dict = {}  # type: typing.Dict[str, str]
-                self.set_header('Vary', self.get_argument('vary'))
+            for v in self.get_arguments('vary'):
-        response = self.fetch('/')
+    def assert_compressed(self, response):
-            'gzip')
+        self.assert_compressed(response)
-
+        self.assert_compressed(response)
-unicode_type = type(u'')
+    unicode_type = str
-    # The name basestring doesn't exist in py3 so silence flake8.
+    # The names unicode and basestring don't exist in py3 so silence flake8.
-    _INVALID_HEADER_CHAR_RE = re.compile(br"[\x00-\x1f]")
+    _INVALID_HEADER_CHAR_RE = re.compile(r"[\x00-\x1f]")
-            value = value.encode('utf-8')
+        # type: (_HeaderTypes) -> str
-        return value
+        if RequestHandler._INVALID_HEADER_CHAR_RE.search(retval):
-            headers['Vary'] += b', Accept-Encoding'
+            headers['Vary'] += ', Accept-Encoding'
-            headers['Vary'] = b'Accept-Encoding'
+            headers['Vary'] = 'Accept-Encoding'
-    used).
+    `tornado.options.parse_command_line` or `tornado.options.parse_config_file`
-        from inspect import isawaitable  # py35+
+        # py35+
-        try:
+        if PY3:
-        except TypeError:
+        else:
-    import curses
+    import curses  # type: ignore
-    import asyncio
+    import asyncio # type: ignore
-    iscoroutinefunction = inspect.iscoroutinefunction
+    iscoroutine = inspect.iscoroutine  # type: ignore
-        import unittest2 as unittest
+        import unittest2 as unittest  # type: ignore
-        import unittest
+        import unittest  # type: ignore
-import pkgutil
+import pkgutil  # type: ignore
-_io_loops = weakref.WeakKeyDictionary()
+_io_loops = weakref.WeakKeyDictionary()  # type: ignore
-import pycurl
+import pycurl  # type: ignore
-        from functools import singledispatch  # py34+
+        # py34+
-        from collections.abc import Generator as GeneratorType  # py35+
+        # py35+
-        from backports_abc import Generator as GeneratorType
+        from backports_abc import Generator as GeneratorType  # type: ignore
-    def isawaitable(x):
+    def isawaitable(x):  # type: ignore
-    def _get_body(self):
+    @property
-    class SSLError(Exception):
+    class _SSLError(Exception):
-
+    # Hack around a mypy limitation. We can't simply put "type: ignore"
-            files.setdefault(name, []).append(HTTPFile(
+            files.setdefault(name, []).append(HTTPFile(  # type: ignore
-    _ERRNO_WOULDBLOCK += (errno.WSAEWOULDBLOCK,)
+    _ERRNO_WOULDBLOCK += (errno.WSAEWOULDBLOCK,)  # type: ignore
-    _ERRNO_CONNRESET += (errno.WSAECONNRESET, errno.WSAECONNABORTED, errno.WSAETIMEDOUT)
+    _ERRNO_CONNRESET += (errno.WSAECONNRESET, errno.WSAECONNABORTED, errno.WSAETIMEDOUT)  # type: ignore
-    _ERRNO_CONNRESET += (errno.EPROTOTYPE,)
+    _ERRNO_CONNRESET += (errno.EPROTOTYPE,)  # type: ignore
-    _ERRNO_INPROGRESS += (errno.WSAEINPROGRESS,)
+    _ERRNO_INPROGRESS += (errno.WSAEINPROGRESS,)  # type: ignore
-_translations = {}
+_translations = {}  # type: dict
-    ssl_match_hostname = SSLCertificateError = None
+    ssl_match_hostname = SSLCertificateError = None  # type: ignore
-    SSLCertificateError = backports.ssl_match_hostname.CertificateError
+    SSLCertificateError = backports.ssl_match_hostname.CertificateError  # type: ignore
-    _ERRNO_WOULDBLOCK += (errno.WSAEWOULDBLOCK,)
+    _ERRNO_WOULDBLOCK += (errno.WSAEWOULDBLOCK,)  # type: ignore
-    _threadpool_pid = None
+    _threadpool = None  # type: ignore
-        return ssl.wrap_socket(socket, **dict(context, **kwargs))
+        return ssl.wrap_socket(socket, **dict(context, **kwargs))  # type: ignore
-        import trollius as asyncio
+        import trollius as asyncio  # type: ignore
-    convert_yielded.register(asyncio.Future, to_tornado_future)
+    convert_yielded.register(asyncio.Future, to_tornado_future)  # type: ignore
-import pycares
+import pycares  # type: ignore
-from zope.interface import implementer
+import twisted.internet.abstract  # type: ignore
-    from twisted.internet.main import installReactor
+    from twisted.internet.main import installReactor  # type: ignore
-            import twisted.internet.reactor
+            import twisted.internet.reactor  # type: ignore
-    @gen.convert_yielded.register(Deferred)
+    @gen.convert_yielded.register(Deferred)  # type: ignore
-import ctypes.wintypes
+import ctypes  # type: ignore
-    _waiting = {}
+    _waiting = {}  # type: ignore
-from tornado.util import ObjectDict, exec_in, unicode_type
+from tornado.util import ObjectDict, exec_in, unicode_type, PY3
-    from io import StringIO  # py3
+if PY3:
-            "__loader__": ObjectDict(get_source=lambda name: self.code),
+            "__loader__": ObjectDict(get_source=lambda name: self.code),  # type: ignore
-        super(ClientTestMixin, self).setUp()
+        super(ClientTestMixin, self).setUp()  # type: ignore
-        super(ClientTestMixin, self).tearDown()
+        super(ClientTestMixin, self).tearDown()  # type: ignore
-    import pycurl
+    import pycurl  # type: ignore
-        return dict(ssl_version=self.get_ssl_version(),
+        return dict(ssl_version=self.get_ssl_version(),  # type: ignore
-            import pycurl
+            import pycurl  # type: ignore
-    from unittest import mock  # python 3.3
+    from unittest import mock  # type: ignore
-        import mock  # third-party mock package
+        import mock  # type: ignore
-                        side_effect=socket.gaierror('boom')):
+                        side_effect=socket.gaierror(errno.EIO, 'boom')):
-    import pycares
+    import pycares  # type: ignore
-    import twisted.names
+    import twisted  # type: ignore
-    raise socket.gaierror("mock: lookup failed")
+    raise socket.gaierror(errno.EIO, "mock: lookup failed")
-    from unittest import mock  # python 3.3
+    # py33+
-        import mock  # third-party mock package
+        import mock  # type: ignore
-    from twisted.python import log
+    from twisted.internet.defer import Deferred, inlineCallbacks, returnValue  # type: ignore
-    from zope.interface import implementer
+    from zope.interface import implementer  # type: ignore
-    from twisted.web.server import Site
+    from twisted.web.client import Agent, readBody  # type: ignore
-        return "Reader"
+if have_twisted:
-        self._fd.close()
+        def logPrefix(self):
-        return self._fd.fileno()
+        def close(self):
-        self.close()
+        def fileno(self):
-        self.close()
+        def readConnectionLost(self, reason):
-    Reader = implementer(IReadDescriptor)(Reader)
+        def connectionLost(self, reason):
-        self._callback = callback
+    @implementer(IWriteDescriptor)
-        return "Writer"
+        def logPrefix(self):
-        self._fd.close()
+        def close(self):
-        return self._fd.fileno()
+        def fileno(self):
-        self.close()
+        def connectionLost(self, reason):
-    Writer = implementer(IWriteDescriptor)(Writer)
+        def doWrite(self):
-        for test_func in blacklist:
+        for test_func in blacklist:  # type: ignore
-            class TornadoTest(test_class):
+            class TornadoTest(test_class):  # type: ignore
-                    super(TornadoTest, self).setUp()
+                    super(TornadoTest, self).setUp()  # type: ignore
-                    super(TornadoTest, self).tearDown()
+                    super(TornadoTest, self).tearDown()  # type: ignore
-                    for w in super(TornadoTest, self).flushWarnings(
+                    for w in super(TornadoTest, self).flushWarnings(  # type: ignore
-        from twisted.logger import globalLogBeginner
+        from twisted.logger import globalLogBeginner  # type: ignore
-            self.real_io_loop = SelectIOLoop(make_current=False)
+            self.real_io_loop = SelectIOLoop(make_current=False)  # type: ignore
-    import unittest2 as unittest
+    import unittest2 as unittest  # type: ignore
-    global_namespace = dict(caller_globals, **caller_locals)
+    global_namespace = dict(caller_globals, **caller_locals)  # type: ignore
-from tornado.util import raise_exc_info, Configurable, exec_in, ArgReplacer, timedelta_to_seconds, import_object, re_unescape
+from tornado.util import raise_exc_info, Configurable, exec_in, ArgReplacer, timedelta_to_seconds, import_object, re_unescape, PY3
-    from io import StringIO  # py3
+if PY3:
-            self.application = ObjectDict(settings=dict(cookie_secret=cookie_secret))
+            self.application = ObjectDict(settings=dict(cookie_secret=cookie_secret))  # type: ignore
-            self.application = ObjectDict(settings=dict(cookie_secret=cookie_secret,
+            self.application = ObjectDict(settings=dict(cookie_secret=cookie_secret,  # type: ignore
-                              headers=dict({"X-Xsrftoken": self.xsrf_token},
+                              headers=dict({"X-Xsrftoken": self.xsrf_token},  # type: ignore
-        class WSGIApplicationWrappedTest(cls):
+        class WSGIApplicationWrappedTest(cls):  # type: ignore
-        class WSGIAdapterWrappedTest(cls):
+        class WSGIAdapterWrappedTest(cls):  # type: ignore
-    Subprocess = None
+    AsyncHTTPClient = None  # type: ignore
-    from collections.abc import Generator as GeneratorType  # py35+
+    from collections.abc import Generator as GeneratorType  # type: ignore
-    from types import GeneratorType
+    from types import GeneratorType  # type: ignore
-        super(AsyncTestCase, self).__init__(methodName, **kwargs)
+    def __init__(self, methodName='runTest'):
-gen_test.__test__ = False
+gen_test.__test__ = False  # type: ignore
-    _template_loaders = {}  # {path: template.BaseLoader}
+    _template_loaders = {}  # type: typing.Dict[str, template.BaseLoader]
-    _ARG_DEFAULT = []
+    _ARG_DEFAULT = object()
-    _static_hashes = {}
+    _static_hashes = {}  # type: typing.Dict
-            user["name"] = u(" ").join(name_parts)
+            user["name"] = u" ".join(name_parts)
-                and a.exc_info() is not None):
+        if (isinstance(a, TracebackFuture) and
-                 == 'keep-alive')):
+                (self._request_headers.get('Connection', '').lower() ==
-              or getattr(start_line, 'method', None) in ("HEAD", "GET")):
+        elif ("Content-Length" in headers or
-                            and self._cancellations > (len(self._timeouts) >> 1)):
+                    if (self._cancellations > 512 and
-
+__all__ = ['Condition', 'Event', 'Semaphore', 'BoundedSemaphore', 'Lock']
-   tornado.options.parse_config_file, the only options that are set are 
+   When using tornado.options.parse_command_line or
-
+__all__ = ['Queue', 'PriorityQueue', 'LifoQueue', 'QueueFull', 'QueueEmpty']
-from tornado.util import PY3
+from tornado.escape import utf8
-relpath = lambda *a: os.path.join(os.path.dirname(__file__), *a)
+
-            response = self.fetch(url)
+        for u in ['/', '/?finish_value=1']:
-
+# This is kind of hacky, but run some of the HTTPServer and web tests
-            val = lambda x: x[2:] if x.startswith(b'W/') else x
+            def val(x):
-                digestmod=hashlib.sha256).hexdigest(),
+                                     msg=session["access_token"].encode('utf8'),
-                                              u'secret': u'vbnm'},
+                                            u'screen_name': u'foo',
-                       "with both Transfer-Encoding and Content-Length")):
+                                 "with both Transfer-Encoding and Content-Length")):
-                                  reuse_port=reuse_port)[0]
+                                reuse_port=reuse_port)[0]
-    import urllib as urllib_parse  # py2
+from tornado.util import unicode_type, ArgReplacer, PY3
-from tornado.util import ObjectDict
+from tornado.util import ObjectDict, PY3
-    import http.cookies as Cookie  # py3
+if PY3:
-from tornado.util import errno_from_exception
+from tornado.util import errno_from_exception, PY3
-
+if PY3:
-    import urllib.parse as urlparse  # py3
+if PY3:
-from tornado.util import basestring_type
+from tornado.util import basestring_type, PY3
-    from io import StringIO  # python 3
+if PY3:
-    import _thread as thread  # py3
+if PY3:
-from tornado.util import ObjectDict, unicode_type, timedelta_to_seconds
+from tornado.util import ObjectDict, unicode_type, timedelta_to_seconds, PY3
-try:
+if PY3:
-except ImportError:
+else:
-from tornado.util import raise_exc_info, basestring_type
+from tornado.util import raise_exc_info, basestring_type, PY3
-    from io import StringIO  # py3
+if PY3:
-if sys.version_info >= (3,):
+if PY3:
-                          unicode_type, _websocket_mask, re_unescape)
+                          unicode_type, _websocket_mask, re_unescape, PY3)
-    from urllib.parse import urlencode  # py3
+if PY3:
-from tornado.util import _websocket_mask
+from tornado.util import _websocket_mask, PY3
-try:
+if PY3:
-except ImportError:
+    xrange = range
-from tornado.util import unicode_type
+from tornado.util import unicode_type, PY3
-try:
+if PY3:
-except ImportError:
+else:
-        config = {}
+        config = {'__file__': os.path.abspath(path)}
-        self.assertEquals(options.port, 443)
+        options.define("my_path")
-                # this IOLoop that update self._events
+                # this IOLoop that modify self._events
-        def handle_request(response):
+        def handle_response(response):
-        http_client.fetch("http://www.google.com/", handle_request)
+        http_client.fetch("http://www.google.com/", handle_response)
-                raise ValueError("unknown status code %d", status_code)
+                raise ValueError("unknown status code %d" % status_code)
-                                extra_params={"scope": "read_stream"})
+                                extra_params={"scope": "user_posts"})
-                digestmod=hashlib.sha256).hexdigest()
+                digestmod=hashlib.sha256).hexdigest(),
-                          return json.loads(user_cookie)
+                  if user_cookie:
-                         for p in paths)
+            js = self.render_linked_js(js_files)
-                b'\n'.join(js_embed) + b'\n//]]>\n</script>'
+            js = self.render_embed_js(js_embed)
-                          for p in paths)
+            css = self.render_linked_css(css_files)
-                b'\n</style>'
+            css = self.render_embed_css(css_embed)
-from tornado.ioloop import IOLoop
+from tornado.ioloop import IOLoop, PeriodicCallback
-        pass
+        """Invoked when the response to a ping frame is received.
-              or start_line.method in ("HEAD", "GET")):
+              or getattr(start_line, 'method', None) in ("HEAD", "GET")):
-        header_line = native_str(header_line)
+        header_line = native_str(header_line.decode('latin1'))
-from tornado.escape import utf8
+from tornado.escape import utf8, native_str
-and ``{%!`` if you need to include a literal ``{{`` or ``{%`` in the output.
+template directives use ``{% %}``.
-    '''
+    """Unescape a string escaped by `re.escape`.
-                pieces.append(re_unescape(fragment))
+                pieces.append(unescaped_fragment)
-    def test_str(self):
+    def test_plain_error(self):
-    def __init__(self, message, filename, lineno):
+    def __init__(self, message, filename=None, lineno=0):
-          methods as arguments.
+        * ``pattern``: Regular expression to be matched. Any capturing
-                         "application/json", "application/xhtml+xml"])
+                         "application/json", "application/xhtml+xml",
-    FUTURES = Future
+    FUTURES = Future  # type: typing.Union[type, typing.Tuple[type, ...]]
-    import urllib as urllib_parse  # py2
+from tornado.util import PY3, unicode_type, basestring_type
-except NameError:
+if PY3:
-if sys.version_info[0] < 3:
+if not PY3:
-from tornado.util import raise_exc_info
+from tornado.util import PY3, raise_exc_info
-except ImportError:
+if PY3:
-from tornado.util import Configurable, errno_from_exception, timedelta_to_seconds
+from tornado.util import PY3, Configurable, errno_from_exception, timedelta_to_seconds
-from tornado.platform.auto import set_close_exec, Waker
+if PY3:
-        from tornado.options import options
+        import tornado.options
-        from tornado.options import options
+        import tornado.options
-from tornado.util import Configurable, errno_from_exception
+from tornado.util import PY3, Configurable, errno_from_exception
-    xrange = range  # py3
+if PY3:
-    xrange = range  # py3
+if PY3:
-    from inspect import getargspec  # py2
+if PY3:
-bytes_type = bytes
+# Stubs to make mypy happy (and later for actual type-checking).
-if sys.version_info > (3,):
+if PY3:
-    __impl_kwargs = None
+    __impl_class = None  # type: type
-            '\x00\x01\\000',
+
-# re.escape('\x00') is a special case
+_alphanum = frozenset(
-    return ''.join(parts)
+    return _re_unescape_pattern.sub(_re_unescape_replacement, s)
-RedHat, CentOS, and Fedora users should issue the following command:
+RedHat and CentOS users should issue the following command:
-from tornado.util import raise_exc_info, Configurable, exec_in, ArgReplacer, timedelta_to_seconds, import_object
+from tornado.util import raise_exc_info, Configurable, exec_in, ArgReplacer, timedelta_to_seconds, import_object, re_unescape
-                          unicode_type, _websocket_mask)
+                          unicode_type, _websocket_mask, re_unescape)
-          
+
-                pieces.append(fragment)
+                pieces.append(re_unescape(fragment))
-                setattr(request, k, v)
+            if kwargs:
-from tornado.netutil import Resolver, bind_sockets, BlockingResolver
+from tornado.netutil import Resolver, bind_sockets
-            timeout_min, timeout_max = 0.4, 0.6
+        timeout_min, timeout_max = 0.099, 1.0
-        class TimeoutResolver(BlockingResolver):
+        class TimeoutResolver(Resolver):
-                return Future()
+                return Future()  # never completes
-                stack_context.wrap(functools.partial(self._on_timeout, "while interacting")))
+                stack_context.wrap(functools.partial(self._on_timeout, "during request")))
-import time
+from tornado.concurrent import Future
-from tornado.simple_httpclient import SimpleAsyncHTTPClient, _HTTPConnection
+from tornado.simple_httpclient import SimpleAsyncHTTPClient
-        timeout_min, timeout_max = 0.099, 0.5
+        timeout = 0.1
-                self.client.close()
+            timeout = 0.5
-                return super(TimeoutResolver, self).resolve(*args, **kwargs)
+                return Future()
-        with patching(self.create_client(resolver=TimeoutResolver())) as client:
+        with closing(self.create_client(resolver=TimeoutResolver())) as client:
-                         connect_timeout=connect_timeout)
+                         connect_timeout=timeout)
-        self.assertEqual(str(response.error), "HTTP 599: Timeout while interacting")
+        self.assertEqual(str(response.error), "HTTP 599: Timeout during request")
-                functools.partial(self._on_timeout, key))
+                functools.partial(self._on_timeout, key, "in request queue"))
-    def _on_timeout(self, key):
+    def _on_timeout(self, key, info=None):
-            request, 599, error=HTTPError(599, "Timeout"),
+            request, 599, error=HTTPError(599, error_message),
-                    stack_context.wrap(self._on_timeout))
+                    stack_context.wrap(functools.partial(self._on_timeout, "while connecting")))
-    def _on_timeout(self):
+    def _on_timeout(self, info=None):
-            raise HTTPError(599, "Timeout")
+            raise HTTPError(599, error_message)
-                stack_context.wrap(self._on_timeout))
+                stack_context.wrap(functools.partial(self._on_timeout, "while interacting")))
-from tornado.simple_httpclient import SimpleAsyncHTTPClient
+from tornado.netutil import Resolver, bind_sockets, BlockingResolver
-        self.assertEqual(str(response.error), "HTTP 599: Timeout")
+        self.assertEqual(str(response.error), "HTTP 599: Timeout while interacting")
-            self.assertEqual(str(response.error), "HTTP 599: Timeout")
+            self.assertEqual(str(response.error), "HTTP 599: Timeout in request queue")
-        tornado.web.Application.__init__(self, handlers, **settings)
+        super(Application, self).__init__(handlers, **settings)
-        globalLogBeginner.beginLoggingTo([])
+        globalLogBeginner.beginLoggingTo([], redirectStandardIO=False)
-   means to offer overriding settings for different environments.
+   When using tornado.options.parse_command_line or 
-   or tornado.options.define. torndo.options.parse_config_file is used mainly as a 
+   When using tornado.options.parse_config_file, the only options that are set
-                                            **kwargs)
+        super(WebSocketHandler, self).__init__(application, request, **kwargs)
-    def bind(self, port, address=None, family=socket.AF_UNSPEC, backlog=128):
+    def bind(self, port, address=None, family=socket.AF_UNSPEC, backlog=128, reuse_port=False):
-                               backlog=backlog)
+                               backlog=backlog, reuse_port=reuse_port)
-
+        """Hook for subclass initialization. Called for each request.
-    .. versionchanged:: 3.5
+    .. versionchanged:: 4.3
-        returned regardless of the response code.
+        `HTTPResponse`. By default, the ``Future`` will raise an
-                                               defaults=dict(allow_ipv6=False))
+        self.http_client = self.create_client()
-    from time import monotonic as monotonic_time
+    # monotonic can provide a monotonic function in versions of python before
-    monotonic_time = None
+    try:
-from tornado.util import u, unicode_type, ArgReplacer
+from tornado.util import unicode_type, ArgReplacer
-from tornado.util import unicode_type, basestring_type, u
+from tornado.util import unicode_type, basestring_type
-from tornado.util import u, Configurable, errno_from_exception
+from tornado.util import Configurable, errno_from_exception
-u('foo').encode('idna')
+u'foo'.encode('idna')
-from tornado.util import u, unicode_type
+from tornado.util import unicode_type
-            (u('\u00e9').encode('latin1'), '%E9'),
+            (u'\u00e9'.encode('utf8'), '%C3%A9'),
-                u("\u00e1").encode("utf-8"),
+                u"\u00e1".encode("utf-8"),
-                u('Content-Disposition: form-data; name="files"; filename="\u00f3"').encode("utf8"),
+                u'Content-Disposition: form-data; name="files"; filename="\u00f3"'.encode("utf8"),
-                u("\u00fa").encode("utf-8"),
+                u"\u00fa".encode("utf-8"),
-from tornado.util import u, unicode_type
+from tornado.util import unicode_type
-from tornado.util import u, basestring_type
+from tornado.util import basestring_type
-            self.logger.error(u("\u00e9").encode("utf8"))
+            self.logger.error(u"\u00e9".encode("utf8"))
-from tornado.util import u, ObjectDict, unicode_type
+from tornado.util import ObjectDict, unicode_type
-from tornado.util import raise_exc_info, Configurable, u, exec_in, ArgReplacer, timedelta_to_seconds, import_object
+from tornado.util import raise_exc_info, Configurable, exec_in, ArgReplacer, timedelta_to_seconds, import_object
-from tornado.util import u, ObjectDict, unicode_type, timedelta_to_seconds
+from tornado.util import ObjectDict, unicode_type, timedelta_to_seconds
-        self.assertEqual(response.body, u("foo bar\u00e9").encode("utf-8"))
+        self.assertEqual(response.body, u"foo bar\u00e9".encode("utf-8"))
-    "zh_TW": {"name_en": u("Chinese (Traditional)"), "name": u("ä¸­æ(ç¹é«)")},
+    "af_ZA": {"name_en": u"Afrikaans", "name": u"Afrikaans"},
-        args["openid.mode"] = u("check_authentication")
+        args["openid.mode"] = u"check_authentication"
-                    self.get_argument(name) == u("http://openid.net/srv/ax/1.0"):
+                    self.get_argument(name) == u"http://openid.net/srv/ax/1.0":
-                return u("")
+                return u""
-            return self.get_argument(ax_name, u(""))
+                return u""
-        return u('<a href="%s"%s>%s</a>') % (href, params, url)
+        return u'<a href="%s"%s>%s</a>' % (href, params, url)
-        self.name = LOCALE_NAMES.get(code, {}).get("name", u("Unknown"))
+        self.name = LOCALE_NAMES.get(code, {}).get("name", u"Unknown")
-                (u('\u4e0a\u5348'), u('\u4e0b\u5348'))[local_date.hour >= 12],
+                (u'\u4e0a\u5348', u'\u4e0b\u5348')[local_date.hour >= 12],
-        comma = u(' \u0648 ') if self.code.startswith("fa") else u(", ")
+        comma = u' \u0648 ' if self.code.startswith("fa") else u", "
-                          u('username'): u('foo')})
+                         {u'access_token': {u'key': u'hjkl',
-            u('access_token'): u('fake-access-token'),
+            u'name': u'Foo',
-     u('hello <a href="http://world.com/">http://world.com/</a>!')),
+     u'hello <a href="http://world.com/">http://world.com/</a>!'),
-     u('hello <a href="http://world.com/with?param=true&amp;stuff=yes">http://world.com/with?param=true&amp;stuff=yes</a>')),
+     u'hello <a href="http://world.com/with?param=true&amp;stuff=yes">http://world.com/with?param=true&amp;stuff=yes</a>'),
-     u('<a href="http://url.com/w">http://url.com/w</a>(aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')),
+     u'<a href="http://url.com/w">http://url.com/w</a>(aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'),
-     u('<a href="http://url.com/withmany">http://url.com/withmany</a>.......................................')),
+     u'<a href="http://url.com/withmany">http://url.com/withmany</a>.......................................'),
-     u('<a href="http://url.com/withmany">http://url.com/withmany</a>((((((((((((((((((((((((((((((((((a)')),
+     u'<a href="http://url.com/withmany">http://url.com/withmany</a>((((((((((((((((((((((((((((((((((a)'),
-     u('<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>')),
+     u'<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>'),
-     u('<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>')),
+     u'<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>'),
-     u('(Something like <a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>)')),
+     u'(Something like <a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>)'),
-     u('<a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>')),
+     u'<a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>'),
-     u('<a href="http://foo.com/blah_(blah)_(wikipedia)_blah">http://foo.com/blah_(blah)_(wikipedia)_blah</a>')),
+     u'<a href="http://foo.com/blah_(blah)_(wikipedia)_blah">http://foo.com/blah_(blah)_(wikipedia)_blah</a>'),
-     u('(Something like <a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>)')),
+     u'(Something like <a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>)'),
-     u('<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>.')),
+     u'<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>.'),
-     u('<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>.')),
+     u'<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>.'),
-     u('&lt;<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>&gt;')),
+     u'&lt;<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>&gt;'),
-     u('&lt;<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>&gt;')),
+     u'&lt;<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>&gt;'),
-     u('<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>,')),
+     u'<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>,'),
-     u('<a href="http://www.example.com/wpstyle/?p=364">http://www.example.com/wpstyle/?p=364</a>.')),
+     u'<a href="http://www.example.com/wpstyle/?p=364">http://www.example.com/wpstyle/?p=364</a>.'),
-     u('<a href="rdar://1234">rdar://1234</a>')),
+     u'<a href="rdar://1234">rdar://1234</a>'),
-     u('<a href="rdar:/1234">rdar:/1234</a>')),
+     u'<a href="rdar:/1234">rdar:/1234</a>'),
-     u('<a href="http://userid:password@example.com:8080">http://userid:password@example.com:8080</a>')),
+     u'<a href="http://userid:password@example.com:8080">http://userid:password@example.com:8080</a>'),
-     u('<a href="http://userid@example.com">http://userid@example.com</a>')),
+     u'<a href="http://userid@example.com">http://userid@example.com</a>'),
-     u('<a href="http://userid@example.com:8080">http://userid@example.com:8080</a>')),
+     u'<a href="http://userid@example.com:8080">http://userid@example.com:8080</a>'),
-     u('<a href="http://userid:password@example.com">http://userid:password@example.com</a>')),
+     u'<a href="http://userid:password@example.com">http://userid:password@example.com</a>'),
-     u('<a href="message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e">message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e</a>')),
+     u'<a href="message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e">message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e</a>'),
-     u('<a href="http://\u27a1.ws/\u4a39">http://\u27a1.ws/\u4a39</a>')),
+    (u"http://\u27a1.ws/\u4a39", {},
-     u('&lt;tag&gt;<a href="http://example.com">http://example.com</a>&lt;/tag&gt;')),
+     u'&lt;tag&gt;<a href="http://example.com">http://example.com</a>&lt;/tag&gt;'),
-     u('Just a <a href="http://www.example.com">www.example.com</a> link.')),
+     u'Just a <a href="http://www.example.com">www.example.com</a> link.'),
-     u('Just a www.example.com link.')),
+     u'Just a www.example.com link.'),
-     u('A <a href="http://reallylong.com/link/that/exceedsthelenglimit.html" title="http://reallylong.com/link/that/exceedsthelenglimit.html">http://reallylong.com/link...</a>')),
+     u'A <a href="http://reallylong.com/link/that/exceedsthelenglimit.html" title="http://reallylong.com/link/that/exceedsthelenglimit.html">http://reallylong.com/link...</a>'),
-     u('A <a href="http://reallylongdomainnamethatwillbetoolong.com/hi" title="http://reallylongdomainnamethatwillbetoolong.com/hi">http://reallylongdomainnametha...</a>!')),
+     u'A <a href="http://reallylongdomainnamethatwillbetoolong.com/hi" title="http://reallylongdomainnamethatwillbetoolong.com/hi">http://reallylongdomainnametha...</a>!'),
-     u('A file:///passwords.txt and <a href="http://web.com">http://web.com</a> link')),
+     u'A file:///passwords.txt and <a href="http://web.com">http://web.com</a> link'),
-     u('A <a href="file:///passwords.txt">file:///passwords.txt</a> and http://web.com link')),
+     u'A <a href="file:///passwords.txt">file:///passwords.txt</a> and http://web.com link'),
-     u('<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>')),
+     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>'),
-     u('<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a> and <a href="http://www.internal-link.com/blogs" class="internal">www.internal-link.com/blogs</a> extra')),
+     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a> and <a href="http://www.internal-link.com/blogs" class="internal">www.internal-link.com/blogs</a> extra'),
-     u('<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>')),
+     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>'),
-            (u("<foo>"), u("&lt;foo&gt;")),
+            (u"<foo>", u"&lt;foo&gt;"),
-            (u("<\u00e9>"), u("&lt;\u00e9&gt;")),
+            (u"<\u00e9>", u"&lt;\u00e9&gt;"),
-            ('foo&#xabc;bar', u('foo\u0abcbar')),
+            ('foo&#xabc;bar', u'foo\u0abcbar'),
-            (u('\u00e9'), '%C3%A9'),
+            (u'\u00e9', '%C3%A9'),
-            ('%C3%A9', utf8(u('\u00e9')), None),
+            ('%C3%A9', u'\u00e9', 'utf8'),
-        self.assertEqual(type(xhtml_escape(u("foo"))), unicode_type)
+        self.assertEqual(type(xhtml_escape(u"foo")), unicode_type)
-        self.assertEqual(json_decode(u('"foo"')), u("foo"))
+        self.assertEqual(json_decode(b'"foo"'), u"foo")
-        self.assertEqual(json_decode(utf8(u('"\u00e9"'))), u("\u00e9"))
+        self.assertEqual(json_decode(utf8(u'"\u00e9"')), u"\u00e9")
-        self.assertEqual(json_decode(json_encode(u("\u00e9"))), u("\u00e9"))
+        self.assertEqual(json_decode(json_encode(u"\u00e9")), u"\u00e9")
-            self.assertEqual(json_decode(json_encode(utf8(u("\u00e9")))), u("\u00e9"))
+            self.assertEqual(json_decode(json_encode(utf8(u"\u00e9"))), u"\u00e9")
-        self.assertEqual(squeeze(u('sequences     of    whitespace   chars')), u('sequences of whitespace chars'))
+        self.assertEqual(squeeze(u'sequences     of    whitespace   chars'), u'sequences of whitespace chars')
-        self.assertEqual(recursive_unicode(tests['bytes']), u("foo"))
+        self.assertEqual(recursive_unicode(tests['dict']), {u"foo": u"bar"})
-        unicode_body = u("\xe9")
+        unicode_body = u"\xe9"
-                              user_agent=u("foo"))
+                              user_agent=u"foo")
-        for value in [u("MyUserAgent"), b"MyUserAgent"]:
+        for value in [u"MyUserAgent", b"MyUserAgent"]:
-        self.assertEqual(u("\u00fa"), data["filebody"])
+        self.assertEqual(u"\u00e9", data["header"])
-        self.assertEqual(data, {u("foo"): [u("\u00e9")]})
+        self.assertEqual(data, {u"foo": [u"\u00e9"]})
-        self.assertEqual(data, {u("foo"): [u(""), u("")]})
+        self.assertEqual(data, {u"foo": [u"", u""]})
-        self.assertEqual(data, {u("foo"): [u("")], u("bar"): [u("")]})
+        self.assertEqual(data, {u"foo": [u""], u"bar": [u""]})
-        self.assertEqual(json_decode(response), {u('foo'): [u('bar')]})
+        self.assertEqual(json_decode(response), {u'foo': [u'bar']})
-        self.assertEquals(json_decode(response.body), {u('foo'): [u('bar')]})
+        self.assertEquals(json_decode(response.body), {u'foo': [u'bar']})
-        self.assertEquals(json_decode(response.body), {u('foo'): [u('bar')]})
+        self.assertEquals(json_decode(response.body), {u'foo': [u'bar']})
-            u('\u2029'),  # PARAGRAPH SEPARATOR
+            u'\u001b',  # VERTICAL TAB
-        self.assertEqual(locale.translate("school"), u("\u00e9cole"))
+        self.assertEqual(locale.translate("school"), u"\u00e9cole")
-                self.assertEqual(locale.translate("school"), u("\u00e9cole"))
+                self.assertEqual(locale.translate("school"), u"\u00e9cole")
-        self.assertEqual(locale.pgettext("stick", "club", "clubs", 2), u("les b\xe2tons"))
+        self.assertEqual(locale.translate("school"), u"\u00e9cole")
-        self.assertEqual(name, u('Espa\u00f1ol'))
+        self.assertEqual(name, u'Espa\u00f1ol')
-            logging.ERROR: u("\u0001"),
+            logging.ERROR: u"\u0001",
-        self.formatter._normal = u("\u0002")
+        self.formatter._normal = u"\u0002"
-            self.assertEqual(self.get_output(), utf8(u("\u00e9")))
+            self.assertEqual(self.get_output(), utf8(u"\u00e9"))
-            self.assertEqual(self.get_output(), utf8(repr(utf8(u("\u00e9")))))
+            self.assertEqual(self.get_output(), utf8(repr(utf8(u"\u00e9"))))
-        self.assertEqual(self.get_output(), utf8(u("\u00e9")))
+        self.logger.error(u"\u00e9")
-IOLoop.current().run_sync(lambda: resolver.resolve(u('localhost'), 80))
+IOLoop.current().run_sync(lambda: resolver.resolve(u'localhost', 80))
-        self.assertEqual(template.generate(), utf8(u("\u00e9")))
+        template = Template(utf8(u"\u00e9"))
-            template = Template(utf8(u('{{ "\u00e9" }}')))
+            template = Template(utf8(u'{{ "\u00e9" }}'))
-        self.assertEqual(template.generate(), utf8(u("\u00e9")))
+            template = Template(utf8(u'{{ u"\u00e9" }}'))
-        self.assertEqual(template.generate(upper=upper), utf8(u("FOO \u00c9")))
+        template = Template(utf8(u"{% apply upper %}foo \u00e9{% end %}"))
-        self.assertEqual(template.generate(upper=upper), utf8(u("FOO \u00c9")))
+        template = Template(utf8(u"{% apply upper %}foo \u00e9{% end %}"))
-        self.assertEqual(loader.load(u("t\u00e9st.html")).generate(), b"hello")
+        loader = DictLoader({u"t\u00e9st.html": "hello"})
-        self.assertEqual(to_unicode(result).strip(), u("H\u00e9llo"))
+        self.assertEqual(to_unicode(result).strip(), u"H\u00e9llo")
-        self.assertEqual(utf8(u('\u00e9')), b'\xc3\xa9')
+        self.assertEqual(utf8(u'\u00e9'), b'\xc3\xa9')
-        self.assertIs(import_object(u('tornado.escape.utf8')), utf8)
+        self.assertIs(import_object(u'tornado.escape.utf8'), utf8)
-        self.assertIs(import_object(u('tornado.escape')), tornado.escape)
+        self.assertIs(import_object(u'tornado.escape'), tornado.escape)
-                self.set_cookie("unicode", u("qwer"))
+                self.set_cookie("unicode", u"qwer")
-                                path=u("/foo"))
+                self.set_cookie("unicode_args", "blah", domain=u"foo.com",
-                          u("args"): {u("arg"): [u("\u00e9")]}})
+                         {u"path": u"/group/%C3%A9",
-                                    u('query'): [u('unicode'), u('\u00e9')],
+            self.assertEqual(data, {u'path': [u'unicode', u'\u00e9'],
-                                u('query'): [u('bytes'), u('c3a9')],
+        self.assertEqual(data, {u'path': [u'bytes', u'c3a9'],
-                                    u('query'): [u('unicode'), u('1 + 1')],
+            self.assertEqual(data, {u'path': [u'unicode', u'1 + 1'],
-        self.assertEqual(self.app.reverse_url('decode_arg', u('\u00e9')),
+        self.assertEqual(self.app.reverse_url('decode_arg', u'\u00e9'),
-                         {u("path"): u("foo")})
+                         {u"path": u"foo"})
-                         {u("path"): None})
+                         {u"path": None})
-                (u("/unicode/(?P<path>.*)"), EchoHandler)]
+                (u"/unicode/(?P<path>.*)", EchoHandler)]
-        ws.write_message(u('hello \u00e9'))
+        ws.write_message(u'hello \u00e9')
-        self.assertEqual(response, u('hello \u00e9'))
+        self.assertEqual(response, u'hello \u00e9')
-_literal_re = re.compile(r"[uU][rR]?[\'\"]")
+from lib2to3.fixer_util import String
-    PATTERN = """STRING"""
+    PATTERN = """
-            node.replace(Call(Name(u'u', prefix=node.prefix), [new]))
+        arg = results["arg"]
-version = "4.3"
+version = "4.4.dev1"
-version_info = (4, 3, 0, 0)
+version = "4.4.dev1"
-version = "4.3b2"
+version = "4.3"
-version_info = (4, 3, 0, -98)
+version = "4.3"
-                                  reuse_port=reuse_port)
+    sock = netutil.bind_sockets(None, '127.0.0.1', family=socket.AF_INET,
-        return self._options[name].value()
+        return self.__getattr__(name)
-            lines.append(utf8('HTTP/1.1 %s %s' % (start_line[1], start_line[2])))
+            lines.append(utf8('HTTP/1.1 %d %s' % (start_line[1], start_line[2])))
-        with ExpectLog(gen_log, "Unsatisfiable read"):
+        with ExpectLog(gen_log, "Unsatisfiable read", required=False):
-        self.assertEqual(response.code, 599)
+        # 431 is "Request Header Fields Too Large", defined in RFC
-_literal_re = re.compile(ur"[uU][rR]?[\'\"]")
+_literal_re = re.compile(r"[uU][rR]?[\'\"]")
-
+from __future__ import absolute_import, division, print_function, with_statement
-                        print_function, with_statement)
+from __future__ import absolute_import, division, print_function, with_statement
-        server = app.listen(0)
+        server = app.listen(0, address='127.0.0.1')
-version = "4.3b1"
+version = "4.3b2"
-version_info = (4, 3, 0, -99)
+version = "4.3b2"
-        self.assertIn('HttpOnly;', response.headers['Set-Cookie'])
+        self.assertIn('httponly;', response.headers['Set-Cookie'].lower())
-from tornado.testing import AsyncHTTPTestCase, ExpectLog, gen_test
+from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, ExpectLog, gen_test
-                                expires_days=expires_days)
+                                expires_days=expires_days,
-        response = self.get_and_head('/root_static' + path)
+        path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
-'https://pypi.python.org/packages/source/t/tornado/tornado-%s.tar.g%%s' % version,
+        'https://pypi.python.org/packages/source/t/tornado/tornado-%s.tar.g%%s' % version,
-version = "4.3.dev1"
+version = "4.3b1"
-version_info = (4, 3, 0, -100)
+version = "4.3b1"
-        from singledispatch import singledispatch  # backport
+        from functools import singledispatch  # py34+
-
+        from singledispatch import singledispatch  # backport
-        from backports_abc import Generator as GeneratorType
+        from collections.abc import Generator as GeneratorType  # py35+
-        from types import GeneratorType
+        from backports_abc import Generator as GeneratorType
-        from backports_abc import isawaitable
+        from inspect import isawaitable  # py35+
-            return False
+        from backports_abc import isawaitable
-CalledProcessError = subprocess.CalledProcessError
+try:
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipOnAppEngine
-
+from tornado.test.util import unittest, skipBefore35, exec_test
-                            "tornado.testing.gen_test")
+        if isinstance(result, GeneratorType) or iscoroutine(result):
-            if isinstance(result, GeneratorType):
+            if isinstance(result, GeneratorType) or iscoroutine(result):
-        coro = gen.coroutine(pre_coroutine)
+        if iscoroutinefunction(f):
-                # will be replaced by the point where the test is stopped.
+                # Throw it back into the generator or coroutine so the stack
-    """Convert a `tornado.concurrent.Future` to an `asyncio.Future`.
+    """Convert a Tornado yieldable object to an `asyncio.Future`.
-from tornado.test.util import unittest, skipBefore33, exec_test
+from tornado.test.util import unittest, skipBefore33, skipBefore35, exec_test
-    from tornado.platform.asyncio import asyncio, AsyncIOLoop
+    from tornado.platform.asyncio import asyncio
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipBefore33, exec_test
-                     'PEP 380 not available')
+    @skipBefore33
-        exec(textwrap.dedent("""
+        namespace = exec_test(globals(), locals(), """
-        result = yield local_namespace['f']()
+        """)
-    @gen.engine
+    @gen.engine
-from tornado.concurrent import Future, is_future
+from tornado.concurrent import Future
-    .. versionadded:: 3.1
+    .. versionchanged:: 3.1
-            if is_future(result):
+            if result is not None:
-from tornado.concurrent import is_future
+from tornado import gen
-            if is_future(fut):
+            if fut is not None:
-from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port, unittest
+from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port, unittest, skipBefore35, exec_test
-            if ret is not None and is_future(ret):
+            if ret is not None:
-                self.add_future(ret, lambda f: f.result())
+                try:
-        caller.
+        The function must return either a yieldable object or
-from tornado.test.util import unittest, skipIfNonUnix, skipOnTravis
+from tornado.test.util import unittest, skipIfNonUnix, skipOnTravis, skipBefore35, exec_test
-        self.assertEqual(self.io_loop.run_sync(lambda: 42), 42)
+        with self.assertRaises(gen.BadYieldError):
-    def test_async_await_mixed_multi(self):
+    def test_async_await_mixed_multi_native_future(self):
-                    yield gen.maybe_future(delegate.data_received(body))
+                    ret = delegate.data_received(body)
-                        yield gen.maybe_future(delegate.data_received(chunk))
+                        ret = delegate.data_received(chunk)
-                        self._delegate.data_received(decompressed))
+                    ret = self._delegate.data_received(decompressed)
-            yield gen.maybe_future(self._delegate.data_received(chunk))
+            ret = self._delegate.data_received(chunk)
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipBefore35, exec_test
-                yield gen.Task(IOLoop.current().add_callback)
+# Each method in this handler returns a yieldable object and yields to the
-                    yield gen.Task(IOLoop.current().add_callback)
+    @gen.coroutine
-                self.write(dict(methods=self.methods))
+    @gen.coroutine
-        return [('/', FlowControlHandler, dict(test=self))]
+class BaseStreamingRequestFlowControlTest(object):
-        return dict(chunk_size=10)
+        return dict(chunk_size=10, decompress_request=True)
-    def test_flow_control(self):
+    def get_http_client(self):
-        self.io_loop.add_timeout(self.io_loop.time() + 0.01, self.stop)
+        self.io_loop.add_timeout(self.io_loop.time() + 0.00, self.stop)
-            self.real_io_loop = SelectIOLoop()
+            self.real_io_loop = SelectIOLoop(make_current=False)
-            self.reactor.callWhenRunning(self.reactor.crash)
+            def f():
-            # Fail in case POST or PUT method has no body, unless the user has
+        body_expected = request.method in ("POST", "PATCH", "PUT")
-            elif not request.allow_nonstandard_methods:
+            if ((body_expected and not body_present) or
-                request_buffer = BytesIO()
+                    'Body must %sbe None for method %s (unless '
-            self.assertEqual(response.body, utf8(method))
+        # These methods require a body.
-            if request.body is None:
+        if request.method in ("POST", "PUT") or request.body:
-            request_buffer = BytesIO(utf8(request.body))
+                    'Body must not be None for method %s (unless '
-                curl.setopt(pycurl.POSTFIELDSIZE, len(request.body))
+                curl.setopt(pycurl.POSTFIELDSIZE, len(request.body or ''))
-                curl.setopt(pycurl.INFILESIZE, len(request.body))
+                curl.setopt(pycurl.INFILESIZE, len(request.body or ''))
-        from collections import Generator as GeneratorType  # py2 with backports_abc
+        from backports_abc import Generator as GeneratorType
-        return False
+    try:
-                err.args[0] in (errno.EBADF, errno.ENOTCONN)):
+                    err.args[0] in (errno.EBADF, errno.ENOTCONN)):
-                    extra_params={"scope": "read_stream,offline_access"})
+            yield self.authorize_redirect(
-                })
+            'name': 'Foo',
-                                quiet_exceptions=RuntimeError)
+            yield gen.Multi([self.async_exception(RuntimeError("error 1")),
-                    quiet_exceptions=RuntimeError)
+            yield gen.multi_future(
-                          })
+        })
-                          })
+        })
-                               b"hello")
+                         b"hello")
-                self.write("a"*1024*64)
+                self.write("a" * 1024 * 64)
-                self.write("a"*1024*100)
+                self.write("a" * 1024 * 100)
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop, max_body_size=1024*64)
+        return SimpleAsyncHTTPClient(io_loop=self.io_loop, max_body_size=1024 * 64)
-        self.assertEqual(response.body, b'a'*1024*64)
+        self.assertEqual(response.body, b'a' * 1024 * 64)
-                self.write("a"*1024*100)
+                self.write("a" * 1024 * 100)
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop, max_body_size=1024*100, max_buffer_size=1024*64)
+        return SimpleAsyncHTTPClient(io_loop=self.io_loop, max_body_size=1024 * 100, max_buffer_size=1024 * 64)
-        self.assertEqual(response.body, b'a'*1024*100)
+        self.assertEqual(response.body, b'a' * 1024 * 100)
-                1/0
+                1 / 0
-            })
+        })
-            }
+        }
-            1/0
+            1 / 0
-            1/0
+            1 / 0
-from tornado.concurrent import TracebackFuture, return_future
+from tornado.concurrent import TracebackFuture, return_future, chain_future
-        args = escape.parse_qs_bytes(escape.native_str(response.body))
+        args = urlparse.parse_qs(escape.native_str(response.body))
-                                   post_args, **args)
+        # Thanks to the _auth_return_future decorator, our "callback"
-from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, AuthError, GoogleOAuth2Mixin
+from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, AuthError, GoogleOAuth2Mixin, FacebookGraphMixin
-            twitter_consumer_secret='test_twitter_consumer_secret')
+            twitter_consumer_secret='test_twitter_consumer_secret',
-    from urlparse import urljoin, urlparse, urlunparse
+    from urlparse import urljoin, urldefrag
-    from urllib.parse import urljoin, urlparse, urlunparse
+    from urllib.parse import urljoin, urldefrag
-    return urlunparse((scheme, netloc, url, params, query, ''))
+    pure_url, frag = urldefrag(url)
-        ws.write_message('hello')
+        yield ws.write_message('hello')
-        self.ws_connection.write_message(message, binary=binary)
+        return self.ws_connection.write_message(message, binary=binary)
-            self.stream.write(frame)
+            return self.stream.write(frame)
-        self._write_frame(True, opcode, message, flags=flags)
+        return self._write_frame(True, opcode, message, flags=flags)
-        self.protocol.write_message(message, binary)
+        return self.protocol.write_message(message, binary)
-            raise Finish()
+            if self.get_argument('finish_value', ''):
-        self.assertEqual(b'authentication required', response.body)
+        for url in ['/', '/?finish_value=1']:
-                self.finish()
+                self.finish(*e.args)
-    methods (including `RequestHandler.write_error`) will not be called.
+    When `Finish` is raised in a `RequestHandler`, the request will
-        message = message or httputil.responses.get(code, "Unknown")
+        self.message = message or httputil.responses.get(code, "Unknown")
-        Exception.__init__(self, "HTTP %d: %s" % (self.code, message))
+        super(HTTPError, self).__init__(code, message, response)
-    def __init__(self, status_code, log_message=None, *args, **kwargs):
+    def __init__(self, status_code=500, log_message=None, *args, **kwargs):
-                # be available on self.error for apps that care).
+        while True:
-            raise
+                raise
-                    raise RuntimeError("IOLoop is closing")
+                    return
-                raise RuntimeError("IOLoop is closing")
+                return
-                ('/override_static_url/(.*)', OverrideStaticUrlHandler)]
+                ('/override_static_url/(.*)', OverrideStaticUrlHandler),
-        root = os.path.abspath(root) + os.path.sep
+        root = os.path.abspath(root)
-        self.name = name
+        self.name = escape.native_str(name)
-This is a work in progress and interfaces are subject to change.
+.. versionadded:: 3.2
-unfinished callbacks on the event loop that fail when it resumes)
+This module integrates Tornado with the ``asyncio`` module introduced
-    """Convert an ``asyncio.Future`` to a `tornado.concurrent.Future`."""
+    """Convert an `asyncio.Future` to a `tornado.concurrent.Future`.
-    """Convert a `tornado.concurrent.Future` to an ``asyncio.Future``."""
+    """Convert a `tornado.concurrent.Future` to an `asyncio.Future`.
-    using the implementation in `PosixReactorBase`.
+    `TornadoReactor` implements the Twisted reactor interface on top of
-        """Remove a Selectable for notification of data available to write."""
+        # Since this class is intended to be used in applications
-    `TwistedIOLoops` in the same process, you must pass a unique reactor
+    ``TwistedIOLoops`` in the same process, you must pass a unique reactor
-                    # wake is harmless).  Waking up a polling IOLoop is 
+                    # If we're not in the IOLoop's thread, and we added the
-            # but either way will work.
+            # since we don't need to wake anyone, just add the
-                    stack_context.wrap(callback), *args, **kwargs))
+            self.add_callback(callback, *args, **kwargs)
-from tornado.escape import utf8, to_unicode
+from tornado.escape import utf8
-
+from tornado.escape import to_unicode
-from tornado.test.httpclient_test import ChunkHandler, CountdownHandler, HelloWorldHandler
+from tornado.simple_httpclient import SimpleAsyncHTTPClient
-        method is not overridden, this method always returns None.
+        This is set in one of two ways:
-        and cache the result after that.
+        * A subclass may override `get_current_user()`, which will be called
-        """Override to determine the current user from, e.g., a cookie."""
+        """Override to determine the current user from, e.g., a cookie.
-        self.headers = headers
+        self.headers = headers
-                self.code in (301, 302, 303, 307)):
+        if self._should_follow_redirect():
-from tornado.escape import utf8
+from tornado.escape import utf8, to_unicode
-            # quiet as well.
+            # to cause do_handshake to raise EBADF and ENOTCONN, so make
-            if self._is_connreset(err) or err.args[0] == errno.EBADF:
+            if (self._is_connreset(err) or
-        conn = yield websocket_connection(loop)
+        conn = yield websocket_connect(url)
-    arguments to the `URLSpec` constructor.  (Prior to Tornado 3.2, this
+    arguments to the `URLSpec` constructor.  (Prior to Tornado 3.2,
-import urlparse
+try:
-                for new_url in get_links(response.body)]
+
-    return urlparse.urlunparse((scheme, netloc, url, params, query, ''))
+    scheme, netloc, url, params, query, fragment = urlparse(url)
-    class URLSeeker(HTMLParser.HTMLParser):
+    class URLSeeker(HTMLParser):
-            HTMLParser.HTMLParser.__init__(self)
+            HTMLParser.__init__(self)
-class Multi(YieldPoint):
+def _contains_yieldpoint(children):
-    a list of ``YieldPoints`` or a mixture of ``YieldPoints`` and ``Futures``.
+    ``children`` may either be a list or a dict whose values are
-    the logging of multiple exceptions.
+class MultiYieldPoint(YieldPoint):
-    does not require the creation of a stack context.
+    This function is similar to `multi`, but does not support
-       Added support for other yieldable objects.
+    .. deprecated:: 4.3
-            yielded = Multi(yielded)
+        # other lists are handled in convert_yielded.
-    # via Multi().
+    # Lists and dicts containing YieldPoints were handled earlier.
-        return multi_future(yielded)
+        return multi(yielded)
-        for abbrev in abbrevs)
+    _TIMEDELTA_ABBREV_DICT = {
-    def test_arg_replacer(self):
+    def test_arg_replacer_function(self):
-                # Inline the portion of getargspec that we need here.
+                # by inspect.getargspec, but the inspect module only
-            self.arg_pos = getargspec(func).args.index(self.name)
+            self.arg_pos = self._getargnames(func).index(name)
-    from types import GeneratorType
+    try:
-            result = getattr(e, 'value', None)
+            result = _value_from_stopiteration(e)
-                    future.set_result(getattr(e, 'value', None))
+                    future.set_result(_value_from_stopiteration(e))
-                    self.result_future.set_result(getattr(e, 'value', None))
+                    self.result_future.set_result(_value_from_stopiteration(e))
-        raise NotImplementedError()
+        if hasattr(x, '__await__'):
-class HTTPHeaders(dict):
+class HTTPHeaders(collections.MutableMapping):
-        dict.__init__(self)
+        self._dict = {}
-                             native_str(value))
+            self._dict[norm_name] = (native_str(self[norm_name]) + ',' +
-                             self[self._last_key] + new_part)
+            self._dict[self._last_key] += new_part
-    # dict implementation overrides
+    # MutableMapping abstract method implementations.
-        dict.__setitem__(self, norm_name, value)
+        self._dict[norm_name] = value
-        return dict.__getitem__(self, _normalized_headers[name])
+        return self._dict[_normalized_headers[name]]
-        dict.__delitem__(self, norm_name)
+        del self._dict[norm_name]
-        return dict.get(self, _normalized_headers[name], default)
+    def __len__(self):
-            self[k] = v
+    def __iter__(self):
-        # default implementation returns dict(self), not the subclass
+        # defined in dict but not in MutableMapping.
-
+    def test_setdefault(self):
-                 backlog=_DEFAULT_BACKLOG, flags=None):
+                 backlog=_DEFAULT_BACKLOG, flags=None, reuse_port=False):
-from tornado.testing import AsyncTestCase, gen_test
+from tornado.testing import AsyncTestCase, gen_test, bind_unused_port
-def bind_unused_port():
+def bind_unused_port(reuse_port=False):
-    [sock] = netutil.bind_sockets(None, 'localhost', family=socket.AF_INET)
+    [sock] = netutil.bind_sockets(None, 'localhost', family=socket.AF_INET,
-                raise ValueError(error_message)
+            error_message = 'The value of log_rotate_mode option should be ' +\
-        if options.log_rotate_mode == 'size':
+        rotate_mode = options.log_rotate_mode
-        elif options.log_rotate_mode == 'time':
+        elif rotate_mode == 'time':
-            channel = logging.NullHandler()
+            if not isinstance(rotate_mode, str):
-        if options.rotating_mode == 'sized':
+        if options.log_rotate_mode == 'size':
-        elif options.rotating_mode == 'timed':
+        elif options.log_rotate_mode == 'time':
-                interval=options.log_file_rotating_interval,
+                when=options.log_rotate_when,
-    options.define("log_file_rotating_when", type=str, default='midnight',
+    options.define("log_rotate_when", type=str, default='midnight',
-    options.define("log_file_rotating_interval", type=int, default=1,
+    options.define("log_rotate_interval", type=int, default=1,
-                   help="The mode of rotating files(timed or sized)")
+    options.define("log_rotate_mode", type=str, default='size',
-            self.options.log_file_rotating_interval = 1
+            self.options.log_rotate_mode = 'time'
-            self.logger.error('hello2 from TimedRotatingFileHandler')
+            self.logger.error('hello')
-            with open(new_file) as f:
+            self.assertEqual(1, len(filenames))
-                    r'^\[E [^]]*\] hello2 from TimedRotatingFileHandler$')
+                    r'^\[E [^]]*\] hello$')
-            backupCount=options.log_file_num_backups)
+        if options.rotating_mode == 'sized':
-    def isawaitable(x): return False
+    def isawaitable(x):
-                          count)
+                              "%s%s%s" % (context, CONTEXT_SEPARATOR, plural_message),
-                                  **self.path_kwargs)
+        self.handler._execute(transforms, *self.path_args,
-            raise RuntimeError("IOLoop is closing")
+                if self._closing:
-                    # avoid it when we can.
+                    # If we're not in the IOLoop's thread, and we added the 
-            list_empty = not self._callbacks
+        if thread.get_ident() != self._thread_ident:
-    ('documentation', 'tornado.tex', 'Tornado Documentation', 'Facebook', 'manual', False),
+    ('index', 'tornado.tex', 'Tornado Documentation', 'The Tornado Authors', 'manual', False),
-            self.assertEqual(resp.headers['X-XSS-Protection'], b"1; mode=block")
+            self.assertEqual(resp.headers['X-XSS-Protection'], "1; mode=block")
-        if self._decompressor is not None:
+        if self._decompressor is not None and self._frame_opcode != 0:
-        header_line = header_line.strip()
+        # whitespace at the start should be preserved to allow multi-line headers
-            future.add_done_callback(lambda f: f.exception())
+            if future is not None:
-from tornado.util import u
+# NOTE: This file is supposed to contain unicode strings, which is
-    "zh_TW": {"name_en": u"Chinese (Traditional)", "name": u"ä¸­æ(ç¹é«)"},
+    "af_ZA": {"name_en": u("Afrikaans"), "name": u("Afrikaans")},
-    "bn_IN": {"name_en": u"Bengali", "name": u"\u09ac\u09be\u0982\u09b2\u09be"},
+    "am_ET": {"name_en": u"Amharic", "name": u'á áá­á'},
-    "cs_CZ": {"name_en": u"Czech", "name": u"\u010ce\u0161tina"},
+    "ca_ES": {"name_en": u"Catalan", "name": u"CatalÃ "},
-    "el_GR": {"name_en": u"Greek", "name": u"\u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac"},
+    "el_GR": {"name_en": u"Greek", "name": u"ÎÎ»Î»Î·Î½Î¹ÎºÎ¬"},
-    "es_LA": {"name_en": u"Spanish", "name": u"Espa\xf1ol"},
+    "es_ES": {"name_en": u"Spanish (Spain)", "name": u"EspaÃ±ol (EspaÃ±a)"},
-    "fa_IR": {"name_en": u"Persian", "name": u"\u0641\u0627\u0631\u0633\u06cc"},
+    "fa_IR": {"name_en": u"Persian", "name": u"ÙØ§Ø±Ø³Û"},
-    "fr_FR": {"name_en": u"French", "name": u"Fran\xe7ais"},
+    "fr_CA": {"name_en": u"French (Canada)", "name": u"FranÃ§ais (Canada)"},
-    "hi_IN": {"name_en": u"Hindi", "name": u"\u0939\u093f\u0928\u094d\u0926\u0940"},
+    "he_IL": {"name_en": u"Hebrew", "name": u"×¢××¨××ª"},
-    "is_IS": {"name_en": u"Icelandic", "name": u"\xcdslenska"},
+    "is_IS": {"name_en": u"Icelandic", "name": u"Ãslenska"},
-    "ml_IN": {"name_en": u"Malayalam", "name": u"\u0d2e\u0d32\u0d2f\u0d3e\u0d33\u0d02"},
+    "ja_JP": {"name_en": u"Japanese", "name": u"æ¥æ¬èª"},
-    "nb_NO": {"name_en": u"Norwegian (bokmal)", "name": u"Norsk (bokm\xe5l)"},
+    "nb_NO": {"name_en": u"Norwegian (bokmal)", "name": u"Norsk (bokmÃ¥l)"},
-    "pa_IN": {"name_en": u"Punjabi", "name": u"\u0a2a\u0a70\u0a1c\u0a3e\u0a2c\u0a40"},
+    "pa_IN": {"name_en": u"Punjabi", "name": u"à¨ªà©°à¨à¨¾à¨¬à©"},
-    "sl_SI": {"name_en": u"Slovenian", "name": u"Sloven\u0161\u010dina"},
+    "pt_BR": {"name_en": u"Portuguese (Brazil)", "name": u"PortuguÃªs (Brasil)"},
-    "sr_RS": {"name_en": u"Serbian", "name": u"\u0421\u0440\u043f\u0441\u043a\u0438"},
+    "sr_RS": {"name_en": u"Serbian", "name": u"Ð¡ÑÐ¿ÑÐºÐ¸"},
-    "th_TH": {"name_en": u"Thai", "name": u"\u0e20\u0e32\u0e29\u0e32\u0e44\u0e17\u0e22"},
+    "ta_IN": {"name_en": u"Tamil", "name": u"à®¤à®®à®¿à®´à¯"},
-    "zh_TW": {"name_en": u"Chinese (Traditional)", "name": u"\u4e2d\u6587(\u7e41\u9ad4)"},
+    "tr_TR": {"name_en": u"Turkish", "name": u"TÃ¼rkÃ§e"},
-}
+                def flushWarnings(self, *args, **kwargs):
-    Note that in this case there is no `acquire`:
+    In Python 3.5, `Lock` also supports the async context manager
-            raise globals()['StopAsyncIteration']()
+            raise getattr(builtins, 'StopAsyncIteration')()
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipBefore35, exec_test
-        
+
-        
+
-        
+
-    
+
-    
+
-from tornado.test.util import unittest, skipOnTravis
+from tornado.test.util import unittest, skipOnTravis, skipBefore33, skipBefore35, skipNotCPython, exec_test
-        exec(textwrap.dedent("""
+        namespace = exec_test(globals(), locals(), """
-        result = yield local_namespace['f']()
+        """)
-        exec(textwrap.dedent("""
+        namespace = exec_test(globals(), locals(), """
-        result = yield local_namespace['f']()
+        """)
-        exec(textwrap.dedent("""
+        namespace = exec_test(globals(), locals(), """
-        result = yield local_namespace['f']()
+        """)
-        exec(textwrap.dedent("""
+        namespace = exec_test(globals(), locals(), """
-        """), global_namespace, local_namespace)
+        """)
-        results = yield [local_namespace['f1'](), f2()]
+        results = yield [namespace['f1'](), f2()]
-skipBefore35 = unittest.skipIf(sys.version_info < (3, 5), 'PEP 492 (async/await) not available')
+from tornado.test.util import unittest, skipBefore35, exec_test
-        exec(textwrap.dedent("""
+        namespace = exec_test(globals(), locals(), """
-        yield local_namespace['f']()
+        """)
-        exec(textwrap.dedent("""
+        namespace = exec_test(globals(), locals(), """
-        futures = [local_namespace['f'](i) for i in range(N)]
+        """)
-    `acquire` supports the context manager protocol:
+    `acquire` supports the context manager protocol in all Python versions:
-    of the first one to fail.
+    Takes a list of ``Futures`` or other yieldable objects (with the
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish, removeslash, addslash, RedirectHandler as WebRedirectHandler, get_signature_key_version
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish, removeslash, addslash, RedirectHandler as WebRedirectHandler, get_signature_key_version, GZipContentEncoding
-            self.write('hello world')
+            # Must write at least MIN_LENGTH bytes to activate compression.
-    MIN_LENGTH = 5
+    # Python's GzipFile defaults to level 9, while most other gzip
-            self._gzip_file = gzip.GzipFile(mode="w", fileobj=self._gzip_value)
+            self._gzip_file = gzip.GzipFile(mode="w", fileobj=self._gzip_value,
-        return zlib.compressobj(-1, zlib.DEFLATED, -self._max_wbits)
+        return zlib.compressobj(tornado.web.GZipContentEncoding.GZIP_LEVEL,
-        condition = locks.Condition()
+        from tornado import gen
-        io_loop.run_sync(runner)
+        IOLoop.current().run_sync(runner)
-        io_loop = ioloop.IOLoop.current()
+        io_loop = IOLoop.current()
-        event = locks.Event()
+        from tornado import gen
-        io_loop.run_sync(runner)
+        IOLoop.current().run_sync(runner)
-        
+
-       from tornado import gen, ioloop
+       from tornado import gen
-       ioloop.IOLoop.current().add_callback(simulator, list(futures_q))
+       IOLoop.current().add_callback(simulator, list(futures_q))
-        sem = locks.Semaphore(2)
+        from tornado import gen
-        io_loop.run_sync(runner)
+        IOLoop.current().run_sync(runner)
-        q = queues.Queue(maxsize=2)
+        from tornado import gen
-            consumer()           # Start consumer.
+            # Start consumer without waiting (since it never finishes).
-        io_loop.run_sync(main)
+        IOLoop.current().run_sync(main)
-        Put 2
+        Put 2
-        q = queues.PriorityQueue()
+        from tornado.queues import PriorityQueue
-        q = queues.LifoQueue()
+        from tornado.queues import LifoQueue
-        return mime_type
+        # per RFC 6713, use the appropriate type for a gzip compressed file
-        self.asyncio_loop.run_forever()
+        old_current = IOLoop.current(instance=False)
-                                            close_loop=True, **kwargs)
+        loop = asyncio.new_event_loop()
-        self.reactor.callWhenRunning(self.make_current)
+            self.make_current()
-        self.assertIsNone(IOLoop.current(instance=False))
+        # Starting the IOLoop makes it current, and stopping the loop
-        self.reactor.run()
+        old_current = IOLoop.current(instance=False)
-                RequestHandler._INVALID_HEADER_CHAR_RE.search(value)):
+        # additional headers or split the request.
-            if IOLoop.current(instance=False) is None:
+            if IOLoop.current(instance=False) is not None:
-        self.io_loop = IOLoop()
+        self.io_loop = None
-        self.io_loop.close()
+        if self.io_loop is not None:
-    def test_current(self):
+    def test_default_current(self):
-        self.protocol = protocol
+import time
-copyright = "2011, Facebook"
+copyright = "2009-%s, The Tornado Authors" % time.strftime("%Y")
-version = "4.2"
+version = "4.2.1"
-version_info = (4, 2, 0, 0)
+version = "4.2.1"
-        # it needs to be temporarily added back for requests to root/
+        # os.path.abspath strips a trailing /.
-                          "comment", "autoescape", "raw", "module"):
+                          "comment", "autoescape", "whitespace", "raw",
-            "bar.txt": "\t\tbar",
+            "foo.html": "\t\tfoo\n\n",
-        self.assertEqual(loader.load("bar.txt").generate(), b"\t\tbar")
+        self.assertEqual(loader.load("foo.html").generate(), b"\t\tfoo\n\n")
-        self.assertEqual(loader.load("bar.txt").generate(), b" bar")
+        self.assertEqual(loader.load("foo.html").generate(), b" foo\n")
-                 compress_whitespace=None, autoescape=_UNSET):
+                 compress_whitespace=_UNSET, autoescape=_UNSET,
-                name.endswith(".js")
+
-                                 compress_whitespace)
+                                 whitespace)
-        in the template namespace, such as "xhtml_escape".
+    def __init__(self, autoescape=_DEFAULT_AUTOESCAPE, namespace=None,
-    def __init__(self, value, line, compress_whitespace):
+    def __init__(self, value, line, whitespace):
-        self.compress_whitespace = compress_whitespace
+        self.whitespace = whitespace
-            value = re.sub(r"(\s*\n\s*)", "\n", value)
+        # Compress whitespace if requested, with a crude heuristic to avoid
-    def __init__(self, name, text, compress_whitespace):
+    def __init__(self, name, text, whitespace):
-        self.compress_whitespace = compress_whitespace
+        self.whitespace = whitespace
-                                         reader.compress_whitespace))
+                                         reader.whitespace))
-                                     reader.compress_whitespace))
+                                     reader.whitespace))
-                                     reader.compress_whitespace))
+                                     reader.whitespace))
-        application setting is supplied, uses that instead.
+        ``autoescape`` and ``template_whitespace`` application
-        reader = _TemplateReader(name, escape.native_str(template_string))
+        reader = _TemplateReader(name, escape.native_str(template_string),
-        self.code = self._generate_python(loader, compress_whitespace)
+        self.code = self._generate_python(loader)
-    def _generate_python(self, loader, compress_whitespace):
+    def _generate_python(self, loader):
-                                 compress_whitespace)
+            writer = _CodeWriter(buffer, named_blocks, loader,
-    def __init__(self, value, line):
+    def __init__(self, value, line, compress_whitespace):
-        if writer.compress_whitespace and "<pre>" not in value:
+        if self.compress_whitespace and "<pre>" not in value:
-                 compress_whitespace):
+    def __init__(self, file, named_blocks, loader, current_template):
-    def __init__(self, name, text):
+    def __init__(self, name, text, compress_whitespace):
-                body.chunks.append(_Text(reader.consume(), reader.line))
+                body.chunks.append(_Text(reader.consume(), reader.line,
-            body.chunks.append(_Text(cons, reader.line))
+            body.chunks.append(_Text(cons, reader.line,
-            body.chunks.append(_Text(start_brace, line))
+            body.chunks.append(_Text(start_brace, line,
-    def test_minimize_whitespace(self):
+    def test_manual_minimize_whitespace(self):
-def load_translations(directory):
+def load_translations(directory, encoding=None):
-            f = open(full_path, "r", encoding="utf-8")
+            f = open(full_path, "r", encoding=encoding)
-            f = open(full_path, "r")
+            # python 2: csv can only handle byte strings (in ascii-compatible
-from tornado.escape import utf8
+from tornado.escape import utf8, to_unicode
-        with self.assertRaises(ssl.SSLError):
+        with self.assertRaises(Exception):
-    pass
+    def __init__(self, real_error=None):
-                    future.set_exception(self.error or StreamClosedError())
+                future.set_exception(StreamClosedError(real_error=self.error))
-            gen_log.warning("error on read", exc_info=True)
+        except Exception as e:
-            raise StreamClosedError("Stream is closed")
+            raise StreamClosedError(real_error=self.error)
-            gen_log.warning("Invalid SSL certificate", exc_info=True)
+        except SSLCertificateError as e:
-                value = HTTPError(599, "Stream closed")
+                if value.real_error is None:
-        with self.assertRaises((ssl.SSLError, socket.error)):
+        with self.assertRaises(ssl.SSLError):
-
+    def test_pickle_roundtrip(self):
-        return iter(self._options)
+        return (opt.name for opt in self._options.values())
-        return self._options[item].value()
+    def __getitem__(self, name):
-        return [(name, opt.value()) for name, opt in self._options.items()]
+        return [(opt.name, opt.value()) for name, opt in self._options.items()]
-            (name, opt.value()) for name, opt in self._options.items()
+            (opt.name, opt.value()) for name, opt in self._options.items()
-            (name, opt.value()) for name, opt in self._options.items())
+            (opt.name, opt.value()) for name, opt in self._options.items())
-                                      callback=callback)
+        normalized = self._normalize_name(name)
-            name = name.replace('-', '_')
+            name = self._normalize_name(name)
-                self._options[name].set(config[name])
+            normalized = self._normalize_name(name)
-                prefix = option.name
+                # Always print names with dashes in a CLI context.
-        # Test that IOStream sets its exc_info on getaddrinfo error
+        # Test that IOStream sets its exc_info on getaddrinfo error.
-            self.assertTrue(isinstance(stream.error, socket.gaierror), stream.error)
+        with mock.patch('socket.socket.connect',
-    pass
+    """Raised for template syntax errors.
-                                     in_block)
+                    reader.raise_parse_error(
-                raise ParseError("Missing end expression #} on line %d" % line)
+                reader.raise_parse_error("Missing end comment #}")
-                raise ParseError("Missing end expression }} on line %d" % line)
+                reader.raise_parse_error("Missing end expression }}")
-                raise ParseError("Empty expression on line %d" % line)
+                reader.raise_parse_error("Empty expression")
-            raise ParseError("Missing end block %%} on line %d" % line)
+            reader.raise_parse_error("Missing end block %}")
-            raise ParseError("Empty block tag ({%% %%}) on line %d" % line)
+            reader.raise_parse_error("Empty block tag ({% %})")
-                                 (operator, allowed_parents))
+                reader.raise_parse_error("%s outside %s block" %
-                raise ParseError("%s block cannot be attached to %s block" % (operator, in_block))
+                reader.raise_parse_error(
-                raise ParseError("Extra {%% end %%} block on line %d" % line)
+                reader.raise_parse_error("Extra {% end %} block")
-                    raise ParseError("extends missing file path on line %d" % line)
+                    reader.raise_parse_error("extends missing file path")
-                    raise ParseError("import missing statement on line %d" % line)
+                    reader.raise_parse_error("import missing statement")
-                    raise ParseError("include missing file path on line %d" % line)
+                    reader.raise_parse_error("include missing file path")
-                    raise ParseError("set missing statement on line %d" % line)
+                    reader.raise_parse_error("set missing statement")
-                    raise ParseError("apply missing method name on line %d" % line)
+                    reader.raise_parse_error("apply missing method name")
-                    raise ParseError("block missing name on line %d" % line)
+                    reader.raise_parse_error("block missing name")
-                raise ParseError("%s outside %s block" % (operator, set(["for", "while"])))
+                reader.raise_parse_error("%s outside %s block" %
-            raise ParseError("unknown operator: %r" % operator)
+            reader.raise_parse_error("unknown operator: %r" % operator)
-                        # Save the user with e.g. set_secure_cookie
+                        user = yield self.oauth2_request(
-            # return the user as json
+            user = yield self.oauth2_request(
-                u'email': u'foo@example.com'
+                'name': 'Foo',
-        callback = functools.partial(self._on_facebook_request, callback)
+        callback = functools.partial(self._on_oauth2_request, callback)
-                        user = yield self.get_authenticated_user(
+                        access = yield self.get_authenticated_user(
-                                                     code)
+            access = yield self.get_authenticated_user(self._OAUTH_REDIRECT_URI,
-            u('expires_in'): u('never-expires'),
+            u('name'): u('Foo'),
-module.
+Python 3.2 in the `concurrent.futures` package. This package defines
-        """Handles the login for the Google user, returning a user object.
+        """Handles the login for the Google user, returning an access token.
-
+        This method is a wrapper around `OAuth2Mixin.oauth2_request`;
-        return httpclient.AsyncHTTPClient()
+        return self.oauth2_request(url, callback, access_token,
-from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, AuthError
+from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, AuthError, GoogleOAuth2Mixin
-    files that are too large to fit comfortably in memory.
+    HTML5 audio or video).
-                # module) will see the right things.
+                # If __package__ is defined, imports may be incorrectly
-    Example::
+    Example, assuming the "Hello, world" example from the user guide is in
-        class MyHTTPTest(AsyncHTTPTestCase):
+        class TestHelloApp(AsyncHTTPTestCase):
-                return Application([('/', MyHandler)...])
+                return hello.make_app()
-                # test contents of response
+                response = self.fetch('/')
-import weakref
+try:
-            if isinstance(result, types.GeneratorType):
+            if isinstance(result, GeneratorType):
-skipBefore33 = unittest.skipIf(sys.version_info < (3, 3), 'PEP 380 not available')
+skipBefore33 = unittest.skipIf(sys.version_info < (3, 3), 'PEP 380 (yield from) not available')
-        if isinstance(result, types.GeneratorType):
+        if isinstance(result, GeneratorType):
-            if isinstance(result, types.GeneratorType):
+            if isinstance(result, GeneratorType):
-                raise TypeError("Expected None, got %r" % result)
+                result = yield result
-                raise TypeError("Expected None, got %r" % result)
+                result = yield result
-        self.assertTrue(set_cookies[1].startswith('foo=;'))
+        # Python 3.5 sends 'baz="";'; older versions use 'baz=;'
-import inspect
+# inspect.getargspec() raises DeprecationWarnings in Python 3.5.
-            self.arg_pos = inspect.getargspec(func).args.index(self.name)
+            self.arg_pos = getargspec(func).args.index(self.name)
-version = "4.2"
+version = "4.3.dev1"
-version_info = (4, 2, 0, 0)
+version = "4.3.dev1"
-version = "4.2b1"
+version = "4.2"
-version_info = (4, 2, 0, -99)
+version = "4.2"
-            "deprecated interface ony supported in HTTP/1.x"
+            "deprecated interface only supported in HTTP/1.x"
-version = "4.2.dev1"
+version = "4.2b1"
-version_info = (4, 2, 0, -100)
+version = "4.2b1"
-    """Subclass this class and define `get()` or `post()` to make a handler.
+    """Base class for HTTP request handlers.
-    `RequestHandler` subclass.
+    Subclasses must define at least one of the methods defined in the
-                self._done_callback, self_ref))
+            future.add_done_callback(self._done_callback)
-                self._finished.append(done)
+    def _done_callback(self, done):
-        yield self.close_future
+        code, reason = yield self.close_future
-            self.close()
+            # Echo the received close code, if any (RFC 6455 section 5.5.1).
-            return unichr(int(m.group(2)))
+            if m.group(2)[:1].lower() == 'x':
-              print("Result {} recieved from {} at {}".format(
+              print("Result {} received from {} at {}".format(
-    "multi_future",
+
-        force_instance=True may be used to suppress this behavior.
+        ``force_instance=True`` may be used to suppress this behavior.
-        client is reused.
+        ``max_clients`` is the number of concurrent requests that can be
-        hostname_mapping is a dictionary mapping hostnames to IP addresses.
+        ``hostname_mapping`` is a dictionary mapping hostnames to IP addresses.
-        settings like /etc/hosts is not possible or desirable (e.g. in
+        settings like ``/etc/hosts`` is not possible or desirable (e.g. in
-        defaults to 100mb.
+        ``max_buffer_size`` (default 100MB) is the number of bytes
-    yields a list of `Futures`. However, calling it directly
+    yields a list of ``Futures``. However, calling it directly
-                                           key_version=1)
+                                           key_version=0)
-        new_key_versions.pop(1)
+        new_key_versions.pop(0)
-                                     "key", value, clock=self.present)
+                                     "key", value, clock=self.present,
-                                     "key", value, clock=self.present)
+                                     "key", value, clock=self.present,
-    def test_key_version_retreival(self):
+    def test_key_version_retrieval(self):
-            format_field(str(key_version)),
+            format_field(str(key_version or 0)),
-            self.server_ioloop.stop()
+            # Delay the shutdown of the IOLoop by one iteration because
-    def acquire(self, deadline=None):
+    def acquire(self, timeout=None):
-        return self._block.acquire(deadline)
+        return self._block.acquire(timeout)
-            yield lock.acquire(deadline=timedelta(seconds=0.01))
+            yield lock.acquire(timeout=timedelta(seconds=0.01))
-        yield condition.wait(deadline=io_loop.time() + 1)
+        yield condition.wait(timeout=io_loop.time() + 1)
-    ...or a `datetime.timedelta` for a deadline relative to the current time::
+    ...or a `datetime.timedelta` for a timeout relative to the current time::
-        yield condition.wait(deadline=datetime.timedelta(seconds=1))
+        yield condition.wait(timeout=datetime.timedelta(seconds=1))
-    ``executor`` and ``io_loop``.
+    The `.IOLoop` and executor to be used are determined by the ``io_loop``
-                                    lambda future: callback(future.result()))
+                getattr(self, io_loop).add_future(
-    if len(args) == 1 and callable(args[0]):
+    if args and kwargs:
-        self.assertEqual(anwser, 42)
+        answer = yield o.f()
-        self.assertEqual(anwser, 42)
+        answer = yield o.f()
-        self.assertEqual(anwser, 42)
+        answer = yield o.f()
-        self.assertEqual(anwser, 42)
+        answer = yield o.f()
-        self.assertEqual(anwser, 42)
+        answer = yield o.f()
-                    self._multi.add_handle(curl)
+                    try:
-    def wait_for_exit(self):
+    def wait_for_exit(self, raise_error=True):
-        self.set_exit_callback(future.set_result)
+
-                pass
+            except ValueError:
-    def initialize(self, asyncio_loop, close_loop=False):
+    def initialize(self, asyncio_loop, close_loop=False, **kwargs):
-    def initialize(self):
+    def initialize(self, **kwargs):
-                                                close_loop=False)
+                                                close_loop=False, **kwargs)
-    def initialize(self):
+    def initialize(self, **kwargs):
-                                            close_loop=True)
+                                            close_loop=True, **kwargs)
-    def initialize(self, reactor=None):
+    def initialize(self, reactor=None, **kwargs):
-                yield gen.moment
+                yield gen.sleep(0.01)
-        def initialize(self):
+        def initialize(self, **kwargs):
-            super(LayeredTwistedIOLoop, self).initialize(reactor=reactor)
+            super(LayeredTwistedIOLoop, self).initialize(reactor=reactor, **kwargs)
-
+"""A trivial web-spider that crawls all the pages in http://tornadoweb.org.
-        self.assertEqual(response.body, "a"*1024*64)
+        self.assertEqual(response.body, b'a'*1024*64)
-        self.assertEqual(response.body, "a"*1024*100)
+        self.assertEqual(response.body, b'a'*1024*100)
-                   resolver=None, defaults=None, max_header_size=None):
+                   resolver=None, defaults=None, max_header_size=None,
-            self.max_header_size)
+            self.max_header_size, self.max_body_size)
-                 max_header_size):
+                 max_header_size, max_body_size):
-            104857600, self.tcp_client, 65536)
+            104857600, self.tcp_client, 65536, 104857600)
-    """A `.Queue` that retrieves the most recently put items first."""
+    """A `.Queue` that retrieves the most recently put items first.
-        f.add_done_callback(callback)
+        if f not in listening:
-
+        super(Application, self).__init__(handlers, **settings)
-from tornado.concurrent import Future, return_future, ReturnValueIgnoredError
+from tornado.concurrent import Future, return_future, ReturnValueIgnoredError, run_on_executor
-    for module in sys.modules.values():
+    for module in list(sys.modules.values()):
-def run_on_executor(fn):
+def run_on_executor(*args, **kwargs):
-            self.io_loop.add_future(future,
+    def run_on_executor_decorator(fn):
-    return wrapper
+            return future
-                app_log.exception('exception calling callback %r for %r',
+                app_log.exception('Exception in callback %r for %r',
-from tornado.httputil import HTTPHeaders
+from tornado.httputil import HTTPHeaders, ResponseStartLine
-    @gen.coroutine
+    @asynchronous
-        stream.close()
+        if self.request.version.startswith('HTTP/1'):
-        self.assertEquals(b"hello", response.body)
+        if response.body == b"HTTP/1 required":
-        request.connection.stream.write(
+        stream = request.connection.detach()
-                    yield gen.Task(IOLoop.current().add_callback)
+                # Note that asynchronous prepare() does not block data_received,
-        with ExpectLog(app_log, "Uncaught exception"):
+        with ExpectLog(app_log, "(Uncaught exception|Exception in callback)"):
-        with ExpectLog(app_log, "Uncaught exception"):
+        with ExpectLog(app_log, "(Uncaught exception|Exception in callback)"):
-            self.write('hello')
+            if self.request.version.startswith('HTTP/1'):
-        IOLoop.instance().stop()
+        IOLoop.current().stop()
-    IOLoop.instance().start()
+    IOLoop.current().start()
-    
+    IOLoop.current().start()
-    tornado.ioloop.IOLoop.instance().start()
+    tornado.ioloop.IOLoop.current().start()
-    tornado.ioloop.IOLoop.instance().start()
+    tornado.ioloop.IOLoop.current().start()
-    tornado.ioloop.IOLoop.instance().start()
+    tornado.ioloop.IOLoop.current().start()
-    tornado.ioloop.IOLoop.instance().start()
+    tornado.ioloop.IOLoop.current().start()
-    ioloop.IOLoop.instance().start()
+    ioloop.IOLoop.current().start()
-    IOLoop.instance().start()
+    IOLoop.current().start()
-    tornado.ioloop.IOLoop.instance().start()
+    tornado.ioloop.IOLoop.current().start()
-        self._io_loop = IOLoop()
+        self._io_loop = IOLoop(make_current=False)
-            IOLoop.instance().start()
+            IOLoop.current().start()
-            IOLoop.instance().start()
+            IOLoop.current().start()
-            IOLoop.instance().start()
+            IOLoop.current().start()
-            io_loop = tornado.ioloop.IOLoop.instance()
+            io_loop = tornado.ioloop.IOLoop.current()
-        another thread.  To get the current thread's `IOLoop`, use `current()`.
+        another thread.  In most other cases, it is better to use `current()`
-        if IOLoop.current(instance=False) is None:
+    def initialize(self, make_current=None):
-                IOLoop.instance().run_sync(main)
+                IOLoop.current().run_sync(main)
-        super(PollIOLoop, self).initialize()
+    def initialize(self, impl, time_func=None, **kwargs):
-            tornado.ioloop.IOLoop.instance().stop()
+            tornado.ioloop.IOLoop.current().stop()
-            tornado.ioloop.IOLoop.instance().start()
+            tornado.ioloop.IOLoop.current().start()
-When the app is ready to start, call `IOLoop.instance().start()`
+When the app is ready to start, call `IOLoop.current().start()`
-            IOLoop.instance().start()
+            IOLoop.current().start()
-            IOLoop.instance().start()
+            IOLoop.current().start()
-            IOLoop.instance().start()
+            IOLoop.current().start()
-                    IOLoop.instance().start()
+                    IOLoop.current().start()
-        tornado.ioloop.IOLoop.instance().start()
+        tornado.ioloop.IOLoop.current().start()
-        ioloop.IOLoop.instance().start()
+        ioloop.IOLoop.current().start()
-        ``IOLoop.instance().start()`` to start the server.
+        ``IOLoop.current().start()`` to start the server.
-        tornado.ioloop.IOLoop.instance().start()
+        tornado.ioloop.IOLoop.current().start()
-       (which is raised) will be logged.
+       (which is raised) will be logged. Added the ``quiet_exceptions``
-    def __init__(self, children):
+    def __init__(self, children, quiet_exceptions=()):
-            except Exception:
+            except Exception as e:
-                                  exc_info=True)
+                    if not isinstance(e, self.quiet_exceptions):
-def multi_future(children):
+def multi_future(children, quiet_exceptions=()):
-    require the creation of a stack context.
+    It is not normally necessary to call `multi_future` explcitly,
-       raised) will be logged.
+       raised) will be logged. Added the ``quiet_exceptions``
-                except Exception:
+                except Exception as e:
-                                      exc_info=True)
+                        if not isinstance(e, quiet_exceptions):
-        return
+        # Exception logging may be explicitly quieted.
-            self.result = self.future.result()
+            self.result_fn = self.future.result
-            return self.result
+            return self.result_fn()
-        result = (i.get_result() for i in self.children)
+        result_list = []
-            return dict(zip(self.keys, result))
+            return dict(zip(self.keys, result_list))
-            return list(result)
+            return list(result_list)
-            else:
+            result_list = []
-from tornado.concurrent import TracebackFuture, chain_future, return_future
+from tornado.concurrent import TracebackFuture, return_future
-    or `GoogleMixin` for an OAuth/OpenID hybrid.
+    See `TwitterMixin` below for an example implementation.
-    See `FacebookGraphMixin` below for an example implementation.
+    See `FacebookGraphMixin` or `GoogleOAuth2Mixin` below for example
-from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, GoogleMixin, AuthError
+from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, AuthError
-        self.assertEqual(parsed["email"], "foo@example.com")
+import bcrypt
-import tornado.auth
+import tornado.escape
-    @tornado.web.asynchronous
+class AuthCreateHandler(BaseHandler):
-        self.authenticate_redirect()
+        self.render("create_author.html")
-            raise tornado.web.HTTPError(500, "Google auth failed")
+
-                             user["email"])
+                             self.get_argument("email"))
-                return
+            self.render("login.html", error="email not found")
-        self.redirect(self.get_argument("next", "/"))
+            self.render("login.html", error="incorrect password")
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish, removeslash, addslash, RedirectHandler as WebRedirectHandler
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish, removeslash, addslash, RedirectHandler as WebRedirectHandler, get_signature_key_version
-    def __init__(self):
+    def __init__(self, cookie_secret='0123456789', key_version=None):
-        self.application = ObjectDict(settings=dict(cookie_secret='0123456789'))
+        if key_version is None:
-May be overrided by passing a ``min_version`` keyword argument.
+May be overridden by passing a ``min_version`` keyword argument.
-                                   name, value, version=version)
+        secret = self.application.settings["cookie_secret"]
-def create_signed_value(secret, name, value, version=None, clock=None):
+def create_signed_value(secret, name, value, version=None, clock=None,
-        #       key rotation features)
+        # - key version (integer, default is 0)
-            b"2|1:0",
+            b"2",
-    # Figure out what version this is.  Version 1 did not include an
+def _get_version(value):
-    value = utf8(value)
+    return version
-def _decode_signed_value_v2(secret, name, value, max_age_days, clock):
+def _decode_fields_v2(value):
-        value_field, rest = _consume_field(rest)
+        key_version, timestamp, name_field, value_field, passed_sig = _decode_fields_v2(value)
-    passed_sig = rest
+
-    @tornado.web.authenticated
+class MainHandler(tornado.web.RequestHandler):
-    @tornado.web.authenticated
+class MessageNewHandler(tornado.web.RequestHandler):
-    @tornado.web.authenticated
+class MessageUpdatesHandler(tornado.web.RequestHandler):
-            future.set_result(self._consume(size))
+            if self._read_future is not None:
-            assert self._read_future is None
+            assert (self._read_future is None) or streaming
-from tornado.testing import bind_unused_port, ExpectLog, AsyncTestCase
+from tornado.testing import bind_unused_port, ExpectLog, AsyncTestCase, gen_test
-                               "@asynchronous decorator.")
+            raise RuntimeError("Cannot write() after finish()")
-                "write() only accepts bytes, unicode, and dict objects")
+            message = "write() only accepts bytes, unicode, and dict objects"
-                               "@asynchronous decorator.")
+            raise RuntimeError("finish() called twice")
-    first).
+    This decorator is for callback-style asynchronous methods; for
-__all__ = ['Queue', 'QueueFull', 'QueueEmpty']
+__all__ = ['Queue', 'PriorityQueue', 'LifoQueue', 'QueueFull', 'QueueEmpty']
-            self._put(item)
+            self.__put_internal(item)
-            self._put(item)
+            self.__put_internal(item)
-            self._put(item)
+            self.__put_internal(item)
-        self._queue.append(item)
+        self._put(item)
-        q = queues.Queue()
+        q = self.queue_class()
-        q = queues.Queue()
+        q = self.queue_class()
-        q = queues.Queue()
+        q = self.queue_class()
-        q = queues.Queue()
+        q = self.queue_class()
-        q = queues.Queue()
+        q = self.queue_class()
-        """Block until all items in the queue are processed. Returns a Future.
+        """Block until all items in the queue are processed.
-
+           Added ``instance`` argument to control the fallback to
-Example usage for Google OpenID::
+Example usage for Google OAuth::
-elif 'APPENGINE_RUNTIME' in os.environ:
+if 'APPENGINE_RUNTIME' in os.environ:
-            self.io_loop.add_timeout(timeout, on_timeout)
+            io_loop = ioloop.IOLoop.current()
-                ioloop.IOLoop.current().add_timeout(timeout, on_timeout)
+                io_loop = ioloop.IOLoop.current()
-        self.assertFalse((yield c.wait(timedelta(seconds=0.01))))
+        wait = c.wait(timedelta(seconds=0.01))
-        yield c.wait(timedelta(seconds=1))
+        wait = c.wait(timedelta(seconds=0.02))
-            yield sem.acquire(timedelta(seconds=0.01))
+            yield acquire
-                ioloop.IOLoop.current().add_timeout(timeout, on_timeout)
+            _set_timeout(future, timeout)
-                ioloop.IOLoop.current().add_timeout(timeout, on_timeout)
+            _set_timeout(future, timeout)
-        elif self.full():
+        try:
-            future = Future()
+        future = Future()
-            return future
+        return future
-                partial(future.set_result, self._get()))
+            future.set_result(self._get())
-        # item, but it's worthwhile testing the degenerate case.
+        # items.
-        producer()
+        yield producer()
-            if header_line.startswith('HTTP/'):
+            if header_line.startswith('HTTP/1.1 101'):
-                headers[k] = v.strip()
+                headers[k.lower()] = v.strip()
-            self.assertEqual(headers['Content-Type'], 'text/html; charset=UTF-8')
+            self.assertEqual(headers['content-type'], 'text/html; charset=UTF-8')
-        self.assertRegexpMatches(first_line[0], 'HTTP/[0-9]\\.[0-9] 200 OK\r\n')
+        self.assertEqual(len(first_line), 1, first_line)
-            if header_line.startswith('Content-Type:'):
+            if header_line.lower().startswith('content-type:'):
-        self.assertRegexpMatches(first_line[0], 'HTTP/1.[01] 200 OK\r\n')
+        self.assertRegexpMatches(first_line[0], 'HTTP/[0-9]\\.[0-9] 200 OK\r\n')
-        status_code = int(data["status"].split()[0])
+        status_code, reason = data["status"].split(' ', 1)
-        parts = [escape.utf8("HTTP/1.1 " + data["status"] + "\r\n")]
+        start_line = httputil.ResponseStartLine("HTTP/1.1", status_code, reason)
-        request.finish()
+            header_obj.add(key, value)
-    if not hasattr(ssl, 'create_default_context'):
+    if ssl is None or hasattr(ssl, 'create_default_context'):
-else:
+elif ssl:
-    # the javscript.  Some json libraries do this escaping by default,
+    # the javascript.  Some json libraries do this escaping by default,
-                                                     utf8(url)))
+        self.set_header("Location", utf8(url))
-            self.connection.finish()
+        self.connection.finish()
-                                     defaults=dict(validate_cert=False))
+        return AsyncHTTPClient(io_loop=self.io_loop, force_instance=True,
-                        self.max_header_size)
+        self._connection_class()(
-            self._sockaddr)
+        self.connection = self._create_connection(stream)
-class HTTPServer(TCPServer, httputil.HTTPServerConnectionDelegate):
+class HTTPServer(TCPServer, Configurable,
-                 max_body_size=None, max_buffer_size=None):
+    def __init__(self, *args, **kwargs):
-                          "certfile": "/__mising__.crt",
+        self.assertRaises((ValueError, IOError),
-                          "keyfile": "/__missing__.key"
+        self.assertRaises((ValueError, IOError),
-                   "keyfile": existing_certificate
+                   "keyfile": existing_key,
-    def initialize(self, a=None):
+    def initialize(self, pos_arg=None, a=None):
-    def initialize(self, b=None):
+    def initialize(self, pos_arg=None, b=None):
-        obj = TestConfigurable(a=4)
+        obj = TestConfigurable(42, a=4)
-        obj = TestConfigurable(b=6)
+        obj = TestConfigurable(42, b=6)
-    def __new__(cls, **kwargs):
+    def __new__(cls, *args, **kwargs):
-        args = {}
+        init_kwargs = {}
-                args.update(base.__impl_kwargs)
+                init_kwargs.update(base.__impl_kwargs)
-        args.update(kwargs)
+        init_kwargs.update(kwargs)
-        instance.initialize(**args)
+        instance.initialize(*args, **init_kwargs)
-            " (" + self.request.remote_ip + ")"
+        return "%s %s (%s)" % (self.request.method, self.request.uri,
-                           "Cannot send error response after headers written"):
+                           "(Cannot send error response after headers written"
-                           "Cannot send error response after headers written"):
+                           "(Cannot send error response after headers written"
-                self.finish()
+                # If we get an error between writing headers and finishing,
-            self._handle_request_exception(e)
+            try:
-        self.log_exception(*sys.exc_info())
+        try:
-        # trapped in the Future it returns (which we are ignoring here).
+        # trapped in the Future it returns (which we are ignoring here,
-        f.add_done_callback(lambda f: f.exception())
+@wsgi_safe
-        """Override to handle a new `.IOStream` from an incoming connection."""
+        """Override to handle a new `.IOStream` from an incoming connection.
-            self.handle_stream(stream, address)
+            future = self.handle_stream(stream, address)
-                self._run_callback(callback)
+            self._run_ssl_connect_callback()
-        return super(SSLIOStream, self).connect(address, callback=None)
+        # Pass a dummy callback to super.connect(), which is slightly
-
+
-        computed_etag = self._headers.get("Etag")
+        computed_etag = utf8(self._headers.get("Etag", ""))
-            r'\*|(?:W/)?"[^"]*"',
+            br'\*|(?:W/)?"[^"]*"',
-        if etags[0] == '*':
+        if etags[0] == b'*':
-            val = lambda x: x[2:] if x.startswith('W/') else x
+            val = lambda x: x[2:] if x.startswith(b'W/') else x
-
+    def test_strong_etag_match(self):
-        etag = self._headers.get("Etag")
+        computed_etag = self._headers.get("Etag")
-            r'(?:W/)?"[^"]*"',
+            r'\*|(?:W/)?"[^"]*"',
-        return bool(etag and match)
+        if not computed_etag or not etags:
-        match = (inm[0] == '"*"') or (etag in tags)
+        # Find all weak and strong etag values from If-None-Match header
-        # For the case of weak validator, strip inm entities with `W\"`.
+        # For the case of weak validator, lstrip inm entities with `W/`.
-        return bool(etag and inm and inm.find(etag) >= 0)
+        # Split If-None-Match with `,` because RFC 2616 allows multiple etag
-                        errno_from_exception(self.error) in _ERRNO_CONNRESET):
+                if self._is_connreset(self.error):
-            if e.args[0] in _ERRNO_CONNRESET:
+            if self._is_connreset(e):
-                    if e.args[0] not in _ERRNO_CONNRESET:
+                    if not self._is_connreset(e):
-                if e.errno not in (errno.EINVAL, errno.ECONNRESET):
+                if e.errno != errno.EINVAL and not self._is_connreset(e):
-                    err.args[0] == errno.EBADF):
+            if self._is_connreset(err) or err.args[0] == errno.EBADF:
-        response.rethrow()
+# os.execv is broken on Windows and can't properly parse command line
-    add_reload_hook(functools.partial(io_loop.close, all_fds=True))
+    if _has_execv:
-        # fixes that behavior.
+    if not _has_execv:
-            sys.exit(0)
+            # At this point the IOLoop has been closed and finally
-    'python': ('http://python.readthedocs.org/en/latest/', None),
+    'python': ('https://docs.python.org/3.4/', None),
-    'python': ('http://python.readthedocs.org/en/latest/', None),
+    'python': ('https://docs.python.org/3.4/', None),
-class Condition(object):
+class _TimeoutGarbageCollector(object):
-class Semaphore(object):
+class Semaphore(_TimeoutGarbageCollector):
-        self._waiters = collections.deque()
+        waiter = Future()
-            future.set_result(_ReleasingContextManager(self))
+            waiter.set_result(_ReleasingContextManager(self))
-        return future
+                def on_timeout():
-            raise
+        heapq.heappush(self._timeouts, timeout)
-        for waiter in self._waiters:
+        while self._waiters:
-    def test_acquire_contended(self):
+    def test_acquire_fifo(self):
-        def f():
+        def f(idx):
-                pass
+                history.append(idx)
-        futures = [f() for _ in range(N)]
+        futures = [f(i) for i in range(N)]
-    def test_acquire_fifo(self):
+    def test_acquire_contended(self):
-        def f(idx):
+        def f():
-                history.append(idx)
+                pass
-        futures = [f(i) for i in range(N)]
+        futures = [f() for _ in range(N)]
-    def __str__(self):
+    def __repr__(self):
-    def __str__(self):
+    def __repr__(self):
-    def test_str(self):
+    def test_repr(self):
-        self.assertNotIn('waiters', str(c))
+        self.assertIn('Condition', repr(c))
-        self.assertIn('waiters', str(c))
+        self.assertIn('waiters', repr(c))
-    def test_str(self):
+    def test_repr(self):
-    def test_str(self):
+    def test_repr(self):
-        self.assertIn('unlocked,value:1', str(sem))
+        self.assertIn('Semaphore', repr(sem))
-        self.assertNotIn('waiters', str(sem))
+        self.assertIn('locked', repr(sem))
-        self.assertIn('waiters', str(sem))
+        self.assertIn('waiters', repr(sem))
-__all__ = ['Condition', 'Event', 'Semaphore', 'BoundedSemaphore']
+__all__ = ['Condition', 'Event', 'Semaphore', 'BoundedSemaphore', 'Lock']
-__all__ = ['Condition', 'Event', 'Semaphore']
+__all__ = ['Condition', 'Event', 'Semaphore', 'BoundedSemaphore']
-                future = gen.with_timeout(timeout, waiter, self.io_loop,
+                future = gen.with_timeout(timeout, waiter,
-    ...        assert semaphore.locked()
+    ...        # Do something holding the semaphore.
-      it without fear of interruption from another thread.
+    ...    # Now the semaphore is released.
-        extra = 'locked' if self.locked() else 'unlocked,value:{0}'.format(
+        extra = 'locked' if self._value == 0 else 'unlocked,value:{0}'.format(
-        """Increment `.counter` and wake one waiter."""
+        """Increment the counter and wake one waiter."""
-        """Decrement `.counter`. Returns a Future.
+        """Decrement the counter. Returns a Future.
-        self.assertTrue(sem.locked())
+        self.assertFalse(f1.done())
-        self.assertEqual(3, sem.counter)
+
-        self.assertFalse(sem.locked())
+        # Semaphore was released and can be acquired again.
-        self.assertFalse(sem.locked())
+        # Semaphore was released and can be acquired again.
-    """A Future that can be used with the "with" statement.
+class _ReleasingContextManager(object):
-        with (yield future):
+        with (yield semaphore.acquire()):
-    Lock.acquire and Semaphore.acquire.
+        # Now semaphore.release() has been called.
-        self.exit_callback = exit_callback
+    def __init__(self, obj):
-            raise self.exception()
+    def __enter__(self):
-        return f()
+    def __exit__(self, exc_type, exc_val, exc_tb):
-                waiter.set_result(None)
+
-            future = gen._null_future
+            future = Future()
-        return _ContextManagerFuture(future, self.release)
+        return future
-        gen_log.warning('pgettext is not supported by CSVLocale')
+        if self.translations:
-        """Allows to set context for translation, accept plural forms.
+        """Allows to set context for translation, accepts plural forms.
-        Usage example:
+        Usage example::
-        Plural message example:
+        Plural message example::
-        of `load_gettext_translations` sequence:
+        To generate POT file with context, add following options to step 1
-        heapq.heappush(self._timeouts, timeout)
+        try:
-            
+
-from tornado.ioloop import IOLoop, TimeoutError
+from tornado.ioloop import IOLoop, TimeoutError, PollIOLoop, PeriodicCallback
-        Returns a Future, which raises `.TimeoutError` after a timeout.
+        Returns a Future, which raises `tornado.gen.TimeoutError` after a
-__all__ = ['Condition', 'Event']
+__all__ = ['Condition', 'Event', 'Semaphore']
-class TestEvent(AsyncTestCase):
+class EventTest(AsyncTestCase):
-        timeout.
+        Returns a Future, which raises `.TimeoutError` after a timeout.
-                    'Body must %sbe None for method %s (unelss '
+                    'Body must %sbe None for method %s (unless '
-        self.assertEqual(headers[3], 'd=1; Path=/')
+        # The secure and httponly headers are capitalized in py35 and
-import unittest
+from tornado.test.util import unittest
-        self._future = Future()
+        if self._future.done():
-    os.environ.get('TORNADO_EXTENSION') != '0'):
+        os.environ.get('TORNADO_EXTENSION') != '0'):
-    install_requires = ['certifi']
+    install_requires = []
-    package_data = {
+    packages=["tornado", "tornado.test", "tornado.platform"],
-import certifi
+    import certifi
-            else:
+            elif not hasattr(ssl, 'create_default_context'):
-
+    """Add logging-related flags to ``options``.
-    options.add_parse_callback(enable_pretty_logging)
+    options.add_parse_callback(lambda: enable_pretty_logging(options))
-from __future__ import absolute_import, division, print_function, with_statement
+# Licensed under the Apache License, Version 2.0 (the "License"); you may
-from tornado.testing import AsyncTestCase, gen_test, unittest
+from tornado.gen import TimeoutError
-    'tornado.test.event_test',
+    'tornado.test.locks_test',
-from tornado import ioloop
+from tornado import gen, ioloop
-        self._flag = False
+        self._future = Future()
-            self.__class__.__name__, 'set' if self._flag else 'clear')
+            self.__class__.__name__, 'set' if self.is_set() else 'clear')
-        return self._flag
+        return self._future.done()
-        self._condition.notify_all()
+        if not self._future.done():
-        self._flag = False
+        self._future = Future()
-    def wait(self, deadline=None):
+    def wait(self, timeout=None):
-        or ``False`` after a timeout.
+        Returns a Future, which raises :exc:`~tornado.gen.TimeoutError` after a
-            return _true_future
+        if timeout is None:
-            return self._condition.wait(deadline)
+            return gen.with_timeout(timeout, self._future)
-    def _test_event(self, n):
+    def test_event(self):
-        futures = [e.wait() for _ in range(n)]
+        future_0 = e.wait()
-        self.assertTrue(all(results))
+        future_2 = e.wait()
-        yield self._test_event(200)
+        self.assertTrue(future_0.done())
-        self.assertEqual(False, result)
+        with self.assertRaises(TimeoutError):
-        self.assertTrue(result)
+        yield e.wait(timedelta(seconds=1))
-    def test_event_nowait(self):
+    def test_event_set_multiple(self):
-        self.assertTrue(e.wait().result())
+        e.set()
-__all__ = ['Condition']
+__all__ = ['Condition', 'Event']
-from tornado import concurrent, gen, ioloop
+from tornado import ioloop
-        :arg SSLContext ssl_options: `ssl.SSLContext` object for use in
+        :arg ssl.SSLContext ssl_options: `ssl.SSLContext` object for use in
-        .. verisonadded:: 4.2
+        .. versionadded:: 4.2
-        with ExpectLog(gen_log, "SSL Error|Uncaught exception"):
+        with ExpectLog(gen_log, "SSL Error|Uncaught exception",
-from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port
+from tornado.test.util import skipOnTravis, skipIfNoIPv6, refusing_port, unittest
-from tornado.netutil import ssl_wrap_socket, ssl_match_hostname, SSLCertificateError
+from tornado.netutil import ssl_wrap_socket, ssl_match_hostname, SSLCertificateError, _client_ssl_defaults, _server_ssl_defaults
-
+import certifi
-from tornado.netutil import Resolver, OverrideResolver
+from tornado.netutil import Resolver, OverrideResolver, _client_ssl_defaults
-           ``simple_httpclient`` and true in ``curl_httpclient``
+        :arg bool allow_ipv6: Use IPv6 when available?  Default is true.
-                 expect_100_continue=False, decompress_response=None):
+                 expect_100_continue=False, decompress_response=None,
-           ``simple_httpclient`` and true in ``curl_httpclient``
+        :arg SSLContext ssl_options: `ssl.SSLContext` object for use in
-#######################################################
+if hasattr(ssl, 'SSLContext'):
-        Python 2.7.9+).
+        In SSL mode, the ``server_hostname`` parameter will be used
-        configured in the ``ssl_options``).
+        `ssl.wrap_socket` function.  The ``server_hostname`` argument
-            ssl_options = {}
+            if server_side:
-        self._ssl_options = kwargs.pop('ssl_options', {})
+        self._ssl_options = kwargs.pop('ssl_options', _client_ssl_defaults)
-        return SSLIOStream(socket.socket(), io_loop=self.io_loop)
+        return SSLIOStream(socket.socket(), io_loop=self.io_loop,
-        return SSLIOStream(connection, io_loop=self.io_loop, **kwargs)
+        return SSLIOStream(connection, io_loop=self.io_loop,
-        client_future = self.client_start_tls()
+        client_future = self.client_start_tls(dict(cert_reqs=ssl.CERT_NONE))
-            dict(cert_reqs=ssl.CERT_REQUIRED, ca_certs=certifi.where()))
+        # Certificates are verified with the default configuration.
-       })
+    To make this server serve SSL traffic, send the ``ssl_options`` keyword
-                    ca_certs="cacert.crt"))
+        To use client certificates, the HTTPServer's
-        Python 3.2+).
+        Python 2.7.9+).
-        (as configured in the ``ssl_options``).
+        The ``ssl_options`` argument may be either an `ssl.SSLContext`
-        object.
+        """The ``ssl_options`` keyword argument may either be an
-    `ssl.wrap_socket`.  In Python 3.2+, `ssl.SSLContext` objects can
+    `ssl.wrap_socket`.  In Python 2.7.9+, `ssl.SSLContext` objects can
-    as appropriate).
+    ``ssl_options`` may be either an `ssl.SSLContext` object or a
-       })
+    To make this server serve SSL traffic, send the ``ssl_options`` keyword
-            self._on_close_called
+            self._on_close_called = True
-            self.io_loop.call_later(0.01, self.stop)
+            self.io_loop.call_later(0.03, self.stop)
-                        yielded = self.gen.throw(*sys.exc_info())
+                        exc_info = sys.exc_info()
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import (absolute_import, division,
-from tornado.util import import_object, ObjectDict, raise_exc_info, unicode_type, _websocket_mask
+from tornado.util import (import_object, ObjectDict, raise_exc_info,
-        return self._get_argument(name, default, self.request.body_arguments, strip)
+        return self._get_argument(name, default, self.request.body_arguments,
-        return self._get_argument(name, default, self.request.query_arguments, strip)
+        return self._get_argument(name, default,
-        """An alias for `self.request.cookies <.httputil.HTTPServerRequest.cookies>`."""
+        """An alias for
-            raise TypeError("write() only accepts bytes, unicode, and dict objects")
+            raise TypeError(
-                        self._status_code, self._headers, chunk, include_footers)
+                        self._status_code, self._headers,
-            gen_log.debug("Uncaught exception in _decode_xsrf_token", exc_info=True)
+            gen_log.debug("Uncaught exception in _decode_xsrf_token",
-            connection=self.connection, start_line=start_line, headers=headers))
+            connection=self.connection, start_line=start_line,
-            self.handler_kwargs = dict(url="%s://%s/" % (self.request.protocol, app.default_host))
+            self.handler_kwargs = dict(url="%s://%s/"
-        f = self.handler._execute(transforms, *self.path_args, **self.path_kwargs)
+        f = self.handler._execute(transforms, *self.path_args,
-        cache_time = self.get_cache_time(self.path, self.modified, content_type)
+        cache_time = self.get_cache_time(self.path, self.modified,
-        modified = datetime.datetime.utcfromtimestamp(stat_result[stat.ST_MTIME])
+        modified = datetime.datetime.utcfromtimestamp(
-        """Override to return a JavaScript string to be embedded in the page."""
+        """Override to return a JavaScript string
-        """Override to return a CSS string that will be embedded in the page."""
+        """Override to return a CSS string
-        # - key version (currently 0; reserved for future key rotation features)
+        # - key version (currently 0; reserved for future
-# A leading version number in decimal with no leading zeros, followed by a pipe.
+# A leading version number in decimal
-def decode_signed_value(secret, name, value, max_age_days=31, clock=None, min_version=None):
+def decode_signed_value(secret, name, value, max_age_days=31,
-        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)
+        return _decode_signed_value_v1(secret, name, value,
-        return _decode_signed_value_v2(secret, name, value, max_age_days, clock)
+        return _decode_signed_value_v2(secret, name, value,
-        gen_log.warning("Cookie timestamp in future; possible tampering %r", value)
+        gen_log.warning("Cookie timestamp in future; possible tampering %r",
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import (absolute_import, division,
-            self.finish("Can \"Upgrade\" only to \"WebSocket\".")
+            log_msg = "Can \"Upgrade\" only to \"WebSocket\"."
-        # Connection header should be upgrade. Some proxy servers/load balancers
+        # Connection header should be upgrade.
-        connection = map(lambda s: s.strip().lower(), headers.get("Connection", "").split(","))
+        connection = map(lambda s: s.strip().lower(),
-            self.finish("\"Connection\" must be \"Upgrade\".")
+            log_msg = "\"Connection\" must be \"Upgrade\"."
-            self.finish("Cross origin websockets not allowed")
+            log_msg = "Cross origin websockets not allowed"
-            gen_log.debug("Malformed WebSocket request received", exc_info=True)
+            gen_log.debug("Malformed WebSocket request received",
-                subprotocol_header = "Sec-WebSocket-Protocol: %s\r\n" % selected
+                subprotocol_header = ("Sec-WebSocket-Protocol: %s\r\n"
-                    self.stream.read_bytes(self._frame_length, self._on_frame_data)
+                    self.stream.read_bytes(self._frame_length,
-            self.stream.read_bytes(self._frame_length, self._on_masked_frame_data)
+            self.stream.read_bytes(self._frame_length,
-from __future__ import absolute_import, division, print_function, with_statement
+from __future__ import (absolute_import, division,
-        # Connection header should be upgrade. Some proxy servers/load balancers
+        # Connection header should be upgrade.
-        connection = map(lambda s: s.strip().lower(), headers.get("Connection", "").split(","))
+        connection = map(lambda s: s.strip().lower(),
-            gen_log.debug("Malformed WebSocket request received", exc_info=True)
+            gen_log.debug("Malformed WebSocket request received",
-                subprotocol_header = "Sec-WebSocket-Protocol: %s\r\n" % selected
+                subprotocol_header = ("Sec-WebSocket-Protocol: %s\r\n"
-                    self.stream.read_bytes(self._frame_length, self._on_frame_data)
+                    self.stream.read_bytes(self._frame_length,
-            self.stream.read_bytes(self._frame_length, self._on_masked_frame_data)
+            self.stream.read_bytes(self._frame_length,
-                self._next_timeout += self.callback_time / 1000.0
+            
-Example usage for Google OpenID::
+Example usage for Google OpenID:
-    to authenticate the user with Twitter and get access to their stream::
+    to authenticate the user with Twitter and get access to their stream:
-        usage::
+        usage:
-    to authenticate the user with FriendFeed and get access to their feed::
+    to authenticate the user with FriendFeed and get access to their feed:
-        Example usage::
+        Example usage:
-    Example usage::
+    Example usage:
-        Example usage::
+        Example usage:
-    to authenticate the user with Facebook::
+    to authenticate the user with Facebook:
-        Here is an example for the stream.get() method::
+        Here is an example for the stream.get() method:
-        Example usage::
+        Example usage:
-            class FacebookGraphLoginHandler(LoginHandler, tornado.auth.FacebookGraphMixin):
+            class FacebookGraphLoginHandler(tornado.web.RequestHandler,
-        Example usage::
+        Example usage:
-    Usage::
+    Usage:
-For example, the following asynchronous handler::
+For example, the following asynchronous handler:
-could be written with ``gen`` as::
+.. testoutput::
-be returned when they are all finished::
+be returned when they are all finished:
-    ::
+    errors, you can use ``WaitIterator``::
-              print "Error {} from {}".format(e, wait_iterator.current_future)
+              print("Error {} from {}".format(e, wait_iterator.current_future))
-              print "Result {} recieved from {} at {}".format(
+              print("Result {} recieved from {} at {}".format(
-                  wait_iterator.current_index)
+                  wait_iterator.current_index))
-    Example usage for a simple TCP server::
+    Example usage for a simple TCP server:
-        import ioloop
+        import tornado.ioloop
-                except socket.error, e:
+                except socket.error as e:
-        sock.listen(128)
+        if __name__ == '__main__':
-        io_loop.start()
+    .. testoutput::
-    A very simple (and broken) HTTP client using this class::
+    A very simple (and broken) HTTP client using this class:
-            print data
+            print(data)
-        tornado.ioloop.IOLoop.instance().start()
+        if __name__ == '__main__':
-Here is a simple "Hello, world" example app::
+Here is a simple "Hello, world" example app:
-    finished when the ``get()`` or ``post()`` method returns. Example::
+    finished when the ``get()`` or ``post()`` method returns. Example:
-           @web.asynchronous
+    .. testcode::
-    back to the client::
+    back to the client:
-      class EchoWebSocket(websocket.WebSocketHandler):
+    .. testcode::
-              print "WebSocket opened"
+              print("WebSocket opened")
-              print "WebSocket closed"
+              print("WebSocket closed")
-                request.streaming_callback, chunk)
+            def write_function(chunk):
-            if not name in self._options:
+            if name not in self._options:
-from tornado.web import Application, RequestHandler, URLSpec
+from tornado.web import Application, RequestHandler
-        #'twisted.internet.test.test_process.PTYProcessTestsBuilder': [
+        # 'twisted.internet.test.test_process.PTYProcessTestsBuilder': [
-        #'twisted.internet.test.test_tls.SSLClientTestsMixin': [],
+        # 'twisted.internet.test.test_tls.SSLClientTestsMixin': [],
-    import tornado.websocket
+    import tornado.websocket  # noqa
-if type('') is not type(b''):
+if not isinstance(b'', type('')):
-    basestring_type = basestring
+    # These names don't exist in py3, so use noqa comments to disable
-                                       client_secret, callback, fields))
+                                     client_secret, callback, fields))
-                        headers, request.header_callback))
+                                      headers, request.header_callback))
-                          request.auth_username)
+                           request.auth_username)
-            any(isinstance(f, YieldPoint) for f in yielded)):
+                any(isinstance(f, YieldPoint) for f in yielded)):
-            any(isinstance(f, YieldPoint) for f in yielded.values())):
+              any(isinstance(f, YieldPoint) for f in yielded.values())):
-                        'Transfer-Encoding' in headers):
+                            'Transfer-Encoding' in headers):
-                err.args[0] == errno.EBADF):
+                    err.args[0] == errno.EBADF):
-            #self.read_fds.add(fd)
+            # self.read_fds.add(fd)
-                (body_present and not body_expected)):
+                    (body_present and not body_expected)):
-    
+        self.assertEqual(squeeze(u('sequences     of    whitespace   chars')), u('sequences of whitespace chars'))
-                self.assertTrue(dg.current_future==f1 and dr==24,
+                self.assertTrue(dg.current_future == f1 and dr == 24,
-                self.assertTrue(dg.current_future==f2 and dr==42,
+                self.assertTrue(dg.current_future == f2 and dr == 42,
-            self.io_loop.add_callback(self.finish_coroutines, iteration+1, futures)
+            self.io_loop.add_callback(self.finish_coroutines, iteration + 1, futures)
-    #def test_post_307(self):
+    # def test_post_307(self):
-            {'If-Modified-Since': format_timestamp(http_date)})
+        self.assertEqual(request.headers,
-            ]
+            u('\u001b'),  # VERTICAL TAB
-                         ])
+                          ])
-            self.io_loop.add_callback(lambda: 1/0)
+            self.io_loop.add_callback(lambda: 1 / 0)
-                1/0
+                1 / 0
-        self.io_loop.add_callback(lambda: 1/0)
+        self.io_loop.add_callback(lambda: 1 / 0)
-        self.io_loop.spawn_callback(lambda: 1/0)
+        self.io_loop.spawn_callback(lambda: 1 / 0)
-        self.assertEqual(locale.format_date(datetime.datetime.utcnow() - datetime.timedelta(seconds=2), full_format=False), 
+        self.assertEqual(locale.format_date(datetime.datetime.utcnow() - datetime.timedelta(seconds=2), full_format=False),
-    
+
-            response  = self.fetch(
+            response = self.fetch(
-        1/0
+        1 / 0
-            io_loop=self.io_loop)
+                                     io_loop=self.io_loop)
-            io_loop=self.io_loop)
+                                     io_loop=self.io_loop)
-    os.environ.get('TORNADO_EXTENSION') == '0'):
+        os.environ.get('TORNADO_EXTENSION') == '0'):
-    from urllib.parse import urlparse # py2
+    from urllib.parse import urlparse  # py2
-    from urlparse import urlparse # py3
+    from urlparse import urlparse  # py3
-                self._compression_options is not None):
+                    self._compression_options is not None):
-                    ext[1]['client_max_window_bits'] is None):
+                        ext[1]['client_max_window_bits'] is None):
-                self._compression_options is not None):
+                    self._compression_options is not None):
-from tornado.util import raise_exc_info, Configurable, u, exec_in, ArgReplacer, timedelta_to_seconds
+from tornado.util import raise_exc_info, Configurable, u, exec_in, ArgReplacer, timedelta_to_seconds, import_object
-version = "4.1"
+version = "4.2.dev1"
-version_info = (4, 1, 0, 0)
+version = "4.2.dev1"
-version = "4.1b2"
+version = "4.1"
-version_info = (4, 1, 0, -98)
+version = "4.1"
-    print 'engine: %0.3f ms per iteration' % (results * 1000)
+    print('engine: %0.3f ms per iteration' % (results * 1000))
-    print 'coroutine: %0.3f ms per iteration' % (results * 1000)
+    print('coroutine: %0.3f ms per iteration' % (results * 1000))
-        print cmd
+        print(cmd)
-        print tmpl.code
+        print(tmpl.code)
-    print '%0.3f ms per iteration' % (results*1000)
+    print('%0.3f ms per iteration' % (results*1000))
-    
+
-version = "4.1b1"
+version = "4.1b2"
-version_info = (4, 1, 0, -99)
+version = "4.1b2"
-        """Overridden in subclasses to return this module's output."""
+        """Override in subclasses to return this module's output."""
-        """Returns a JavaScript string that will be embedded in the page."""
+        """Override to return a JavaScript string to be embedded in the page."""
-        """Returns a list of JavaScript files required by this module."""
+        """Override to return a list of JavaScript files needed by this module.
-        """Returns a CSS string that will be embedded in the page."""
+        """Override to return a CSS string that will be embedded in the page."""
-        """Returns a list of CSS files required by this module."""
+        """Override to returns a list of CSS files required by this module.
-        """Returns a CSS string that will be put in the <head/> element"""
+        """Override to return an HTML string that will be put in the <head/>
-        """Returns an HTML string that will be put in the <body/> element"""
+        """Override to return an HTML string that will be put at the end of
-                                        future)
+                                        future, io_loop=self.io_loop)
-            yield gen.with_timeout(datetime.timedelta(seconds=3600), future)
+            yield gen.with_timeout(datetime.timedelta(seconds=3600),
-                                        future)
+                                        future, io_loop=self.io_loop)
-                                self.socket.fileno(), e)
+                if future is None:
-    have_twisted_web = True
+    # As of Twisted 15.0.0, twisted.web is present but fails our
-        d = client.request('GET', url)
+        d = client.request(b'GET', utf8(url))
-            self.stop_loop()
+        def shutdown(failure):
-            response = yield client.request('GET', url)
+            response = yield client.request(b'GET', utf8(url))
-            body[0] = yield readBody(response)
+            with warnings.catch_warnings():
-    def npgettext(self, context, singular, plural, number):
+    def pgettext(self, context, message, plural_message=None, count=None):
-    def pgettext(self, context, message):
+    def pgettext(self, context, message, plural_message=None, count=None):
-        return self.translate(singular, plural, number)
+        return self.translate(message, plural_message, count)
-        """Allows to set context for translation.
+    def pgettext(self, context, message, plural_message=None, count=None):
-        return result
+        Plural message example:
-            npgettext("stick", "club", "clubs", len(clubs))
+            pgettext("organization", "club", "clubs", len(clubs))
-            xgettext [basic options] --keyword=npgettext:1c,2,3
+            xgettext [basic options] --keyword=pgettext:1c,2 --keyword=pgettext:1c,2,3
-        return result
+        if plural_message is not None:
-# 1) xgettext --language=Python --keyword=_:1,2 --keyword=pgettext:1c,2 --keyword=npgettext:1c,2,3 extract_me.py -o tornado_test.po
+# 1) xgettext --language=Python --keyword=_:1,2 --keyword=pgettext:1c,2 --keyword=pgettext:1c,2,3 extract_me.py -o tornado_test.po
-npgettext("stick", "club", "clubs", 1)
+pgettext("organization", "club", "clubs", 1)
-        self.assertEqual(locale.npgettext("stick", "club", "clubs", 2), u("les b\xe2tons"))
+        self.assertEqual(locale.pgettext("organization", "club", "clubs", 1), u("le club"))
-# 2) Edit tornado_test.po, setting CHARSET and setting msgstr
+# 1) xgettext --language=Python --keyword=_:1,2 --keyword=pgettext:1c,2 --keyword=npgettext:1c,2,3 extract_me.py -o tornado_test.po
-        return 'http://localhost:%d%s' % (self.port, path)
+        return 'http://127.0.0.1:%d%s' % (self.port, path)
-        stream.connect(("localhost", self.get_http_port()), callback=self.stop)
+        stream.connect(("127.0.0.1", self.get_http_port()), callback=self.stop)
-        self.stream.connect(('localhost', self.get_http_port()), self.stop)
+        self.stream.connect(('127.0.0.1', self.get_http_port()), self.stop)
-        self.stream.connect(('localhost', self.get_http_port()), self.stop)
+        self.stream.connect(('127.0.0.1', self.get_http_port()), self.stop)
-        stream.connect(('localhost', self.get_http_port()), self.stop)
+        stream.connect(('127.0.0.1', self.get_http_port()), self.stop)
-        stream.connect(('localhost', self.get_http_port()), callback=self.stop)
+        stream.connect(('127.0.0.1', self.get_http_port()), callback=self.stop)
-        self.stream.connect(("localhost", self.get_http_port()),
+        self.stream.connect(("127.0.0.1", self.get_http_port()),
-        stream.connect(("localhost", self.get_http_port()),
+        stream.connect(("127.0.0.1", self.get_http_port()),
-            ("localhost", self.get_http_port()))
+            ("127.0.0.1", self.get_http_port()))
-        yield stream.connect(("localhost", self.get_http_port()))
+        yield stream.connect(("127.0.0.1", self.get_http_port()))
-        yield stream.connect(("localhost", self.get_http_port()))
+        yield stream.connect(("127.0.0.1", self.get_http_port()))
-            self.http_client.fetch("http://localhost:%d/" % port, self.stop)
+            self.http_client.fetch("http://127.0.0.1:%d/" % port, self.stop)
-            'http://localhost:%d' % self.twisted_port, self.run_ioloop)
+            'http://127.0.0.1:%d' % self.twisted_port, self.run_ioloop)
-            'http://localhost:%d' % self.twisted_port, self.run_reactor)
+            'http://127.0.0.1:%d' % self.twisted_port, self.run_reactor)
-            'http://localhost:%d' % self.tornado_port, self.run_ioloop)
+            'http://127.0.0.1:%d' % self.tornado_port, self.run_ioloop)
-            'http://localhost:%d' % self.tornado_port, self.run_reactor)
+            'http://127.0.0.1:%d' % self.tornado_port, self.run_reactor)
-            'http://localhost:%d' % self.tornado_port, self.run_ioloop)
+            'http://127.0.0.1:%d' % self.tornado_port, self.run_ioloop)
-        s.connect(("localhost", self.get_http_port()))
+        s.connect(("127.0.0.1", self.get_http_port()))
-        s.connect(("localhost", self.get_http_port()))
+        s.connect(("127.0.0.1", self.get_http_port()))
-            'ws://localhost:%d%s' % (self.get_http_port(), path),
+            'ws://127.0.0.1:%d%s' % (self.get_http_port(), path),
-            'ws://localhost:%d/echo' % self.get_http_port(),
+            'ws://127.0.0.1:%d/echo' % self.get_http_port(),
-                    'ws://localhost:%d/' % port,
+                    'ws://127.0.0.1:%d/' % port,
-            'ws://localhost:%d/echo' % self.get_http_port())
+            'ws://127.0.0.1:%d/echo' % self.get_http_port())
-            HTTPRequest('ws://localhost:%d/header' % self.get_http_port(),
+            HTTPRequest('ws://127.0.0.1:%d/header' % self.get_http_port(),
-        headers = {'Origin': 'http://localhost:%d' % port}
+        url = 'ws://127.0.0.1:%d/echo' % port
-        headers = {'Origin': 'http://localhost:%d/something' % port}
+        url = 'ws://127.0.0.1:%d/echo' % port
-        headers = {'Origin': 'localhost:%d' % port}
+        url = 'ws://127.0.0.1:%d/echo' % port
-        # Host is localhost, which should not be accessible from some other
+        url = 'ws://127.0.0.1:%d/echo' % port
-version = "4.1.dev1"
+version = "4.1b1"
-version_info = (4, 1, 0, -100)
+version = "4.1b1"
-       Added ``compression_options``. The ``io_loop`` argument is deprecated.
+       Added ``compression_options`` and ``on_message_callback``.
-from tornado.log import gen_log
+curl_log = logging.getLogger('tornado.curl_httpclient')
-        if gen_log.isEnabledFor(logging.DEBUG):
+        if curl_log.isEnabledFor(logging.DEBUG):
-            gen_log.debug("%s %s (username: %r)", request.method, request.url,
+            curl_log.debug("%s %s (username: %r)", request.method, request.url,
-            gen_log.debug("%s %s", request.method, request.url)
+            curl_log.debug("%s %s", request.method, request.url)
-            gen_log.debug('%s', debug_msg.strip())
+            curl_log.debug('%s', debug_msg.strip())
-                gen_log.debug('%s %s', debug_types[debug_type], line)
+                curl_log.debug('%s %s', debug_types[debug_type], line)
-            gen_log.debug('%s %r', debug_types[debug_type], debug_msg)
+            curl_log.debug('%s %r', debug_types[debug_type], debug_msg)
-        return tf
+    convert_yielded.register(asyncio.Future, to_tornado_future)
-    from twisted.internet.defer import Deferred
+    from twisted.internet.defer import Deferred, inlineCallbacks, returnValue
-    from twisted.web.client import Agent
+    from twisted.web.client import Agent, readBody
-                yielded = Multi(yielded)
+        # Lists containing YieldPoints require stack contexts;
-                "yielded unknown object %r" % (yielded,)))
+            try:
-    """Provides an iterator to yield the results of futures as they finish
+    """Provides an iterator to yield the results of futures as they finish.
-      for future in wait_iterator:
+      while not wait_iterator.done():
-              result = yield future
+              result = yield wait_iterator.next()
-              print "Error {} from {}".format(e, wait_iterator.current_future())
+              print "Error {} from {}".format(e, wait_iterator.current_future)
-                  result, wait_iterator.current_future(), wait_iterator.current_index())
+                  result, wait_iterator.current_future,
-    from the input list.
+    current result, you can use the attributes
-                self._futures.append(v)
+            self._unfinished = dict((f, k) for (k, f) in kwargs.items())
-        self._current_future = None
+            self._unfinished = dict((f, i) for (i, f) in enumerate(args))
-                        self._done_callback, self_ref))
+        self._finished = collections.deque()
-        return self
+        self_ref = weakref.ref(self)
-        return self.next()
+    def done(self):
-            raise StopIteration
+        """Returns a `.Future` that will yield the next available result.
-            pass
+        if self._finished:
-                self._queue.append(done)
+                self._finished.append(done)
-        self._futures[index] = None
+        chain_future(done, self._running_future)
-            index = self._keys[index]
+        self.current_future = done
-            self.assertTrue(True, 'empty generator iterated')
+        self.assertTrue(g.done(), 'empty generator iterated')
-        try:
+        with self.assertRaises(ValueError):
-        self.assertEqual(g.current_future(), None, "bad nil current future")
+        self.assertEqual(g.current_index, None, "bad nil current index")
-            r = yield f
+        while not g.done():
-                    "WaitIterator status incorrect")
+                self.assertEqual(g.current_index, 0)
-                    "WaitIterator status incorrect")
+                self.assertEqual(g.current_index, 1)
-                    "WaitIterator status incorrect")
+                self.assertEqual(g.current_index, 2)
-        self.assertEqual(g.current_future(), None, "bad nil current future")
+        self.assertEqual(g.current_index, None, "bad nil current index")
-                self.assertTrue(dg.current_future()==f1 and dr==24,
+        while not dg.done():
-                self.assertTrue(dg.current_future()==f2 and dr==42,
+            elif dg.current_index == "f2":
-                    dg.current_index()))
+                self.fail("got bad WaitIterator index {}".format(
-        self.assertEqual(dg.current_future(), None, "bad nil current future")
+        self.assertEqual(dg.current_index, None, "bad nil current index")
-        for f in g:
+        while not g.done():
-                r = yield f
+                r = yield g.next()
-                                 'exception future invalid')
+                self.assertIs(g.current_future, futures[0],
-                    self.assertEqual(g.current_index(), 2, 'wrong index')
+                    self.assertEqual(g.current_index, 2, 'wrong index')
-                    self.assertEqual(g.current_index(), 1, 'wrong index')
+                    self.assertEqual(g.current_index, 1, 'wrong index')
-                    self.assertEqual(g.current_index(), 3, 'wrong index')
+                    self.assertEqual(g.current_index, 3, 'wrong index')
-            
+
-        
+
-    
+
-            
+
-        
+
-        
+
-        
+
-                        
+
-            futures[0].set_exception(ZeroDivisionError)
+            futures[0].set_exception(ZeroDivisionError())
-        
+
-    """Begins watching source files for changes using the given `.IOLoop`. """
+    """Begins watching source files for changes.
-    def current():
+    def current(instance=True):
-                    self.io_loop = io_loop or IOLoop.current()
+        If an `IOLoop` is currently running or has been marked as
-        if current is None:
+        if current is None and instance:
-        pass
+        if IOLoop.current(instance=False) is None:
-    """Install this package as the default Twisted reactor."""
+    """Install this package as the default Twisted reactor.
-       Added ``compression_options``.
+       Added ``compression_options``. The ``io_loop`` argument is deprecated.
-            gen_log.warning("Invalid multipart/form-data")
+        try:
-        with self.assertRaises(ssl.SSLError):
+        with self.assertRaises((ssl.SSLError, socket.error)):
-        with self.assertRaises(ssl.SSLError):
+        with self.assertRaises((ssl.SSLError, socket.error)):
-        super(LogCounter, self).__init__(*args, **kwargs)
+        # Can't use super() because logging.Filter is an old-style class in py26
-        self.server_start_tls(_server_ssl_options())
+        server_future = self.server_start_tls(_server_ssl_options())
-    tornado.testing.main(**kwargs)
+    try:
-            raise_exc_info(exc_info)
+            future.result()
-def with_timeout(timeout, future, io_loop=None):
+def with_timeout(timeout, future, io_loop=None, quiet_exceptions=()):
-        future.add_done_callback(lambda f: f.exception())
+        # In case the wrapped future goes on to fail, log it.
-                        io_loop=self.stream.io_loop)
+                        io_loop=self.stream.io_loop,
-                                body_future, self.stream.io_loop)
+                                body_future, self.stream.io_loop,
-        future.exception()
+        exc = future.exception()
-        # call add_future.
+        # call add_future (because of the requirement to remain compatible
-        f.add_done_callback(lambda f: f.exception()) # XXX
+        f.add_done_callback(lambda f: f.exception())
-                self, compression_options=self.get_compression_options())
+        self.ws_connection = self.get_websocket_protocol()
-
+    def get_websocket_protocol(self):
-            compression_options=self.compression_options)
+        self.protocol = self.get_websocket_protocol()
-                try:
+
-                return version, token, timestamp
+
-            return (version, token, timestamp)
+                version = 1
-        return _ServerRequestAdapter(self, request_conn)
+        return _ServerRequestAdapter(self, server_conn, request_conn)
-    def __init__(self, server, connection):
+    def __init__(self, server, server_conn, request_conn):
-        self.connection = connection
+        self.connection = request_conn
-            self.delegate = server.request_callback.start_request(connection)
+            self.delegate = server.request_callback.start_request(
-                return StreamingChunkSizeTest.MessageDelegate(connection)
+            def start_request(self, server_conn, request_conn):
-    def start_request(self, connection):
+    def start_request(self, server_conn, request_conn):
-        return _RequestDispatcher(self, connection)
+        return _RequestDispatcher(self, request_conn)
-        lines = [utf8("%s %s %s" % start_line)]
+        The ``version`` field of ``start_line`` is ignored.
-    if not version.startswith("HTTP/"):
+    if not re.match(r"^HTTP/1\.[0-9]$", version):
-    match = re.match("(HTTP/1.[01]) ([0-9]+) ([^\r]*)", line)
+    match = re.match("(HTTP/1.[0-9]) ([0-9]+) ([^\r]*)", line)
-                                               req_path, 'HTTP/1.1')
+                                               req_path, '')
-        self.assertEqual(response, b"HTTP/1.0 200 OK\r\n")
+        self.assertEqual(response, b"HTTP/1.1 200 OK\r\n")
-        self.assertTrue(first_line.startswith(self.http_version + b' 200'), first_line)
+        self.assertTrue(first_line.startswith(b'HTTP/1.1 200'), first_line)
-        self.assertTrue(data.startswith(b"HTTP/1.0 200"))
+        self.assertTrue(data.startswith(b"HTTP/1.1 200"))
-        self.assertEqual(data, b"HTTP/1.0 ")
+        self.assertEqual(data, b"HTTP/1.1 ")
-        self.assertEqual(first_line, b"HTTP/1.0 200 OK\r\n")
+        self.assertEqual(first_line, b"HTTP/1.1 200 OK\r\n")
-            start_line = httputil.ResponseStartLine(self.request.version,
+            start_line = httputil.ResponseStartLine('',
-        start_line = data[:eol]
+        # RFC 7230 section allows for both CRLF and bare LF.
-    def raw_fetch(self, headers, body):
+    def raw_fetch(self, headers, body, newline=b"\r\n"):
-                b"\r\n" + body)
+                newline.join(headers +
-            u'\u2029', # PARAGRAPH SEPARATOR
+            u('\u001b'), # VERTICAL TAB
-        for line in headers.splitlines():
+        for line in _CRLF_RE.split(headers):
-from tornado.escape import utf8
+from tornado.escape import utf8, native_str
-from tornado.test.util import unittest, skipIfNonUnix
+from tornado.test.util import unittest, skipIfNonUnix, refusing_port
-        server_socket.close()
+        cleanup_func, port = refusing_port()
-from tornado.test.util import skipOnTravis, skipIfNoIPv6
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, ExpectLog
-        server_socket.close()
+        cleanup_func, port = refusing_port()
-from tornado.test.util import skipIfNoIPv6, unittest
+from tornado.testing import AsyncTestCase, gen_test
-        sock.close()
+        cleanup_func, port = refusing_port()
-                _, mask, masked_token, timestamp = cookie.split("|")
+                try:
-                    "Sec-WebSocket-Version: 8\r\n\r\n"))
+                    "Sec-WebSocket-Version: 7, 8, 13\r\n\r\n"))
-        self.read_chunk_size = None
+        self.read_chunk_size = read_chunk_size
-            self.ws_connection = WebSocketProtocol13(
+        protocol_subclass = self.get_websocket_protocol_subclass(
-        self.body = body or ""
+        self.body = body or b""
-            body = ""
+            body = b""
-    def client_start_tls(self, ssl_options=None):
+    def client_start_tls(self, ssl_options=None, server_hostname=None):
-        return client_stream.start_tls(False, ssl_options)
+        return client_stream.start_tls(False, ssl_options, server_hostname)
-            if isinstance(result, Future):
+            if is_future(result):
-    ``prepare``: The first call to ``data_recieved`` may occur at any point
+    ``prepare``: The first call to ``data_received`` may occur at any point
-                host = netloc
+            host, port = httputil.split_host_and_port(netloc)
-            host = host.rsplit(':', 1)[0]
+        host = split_host_and_port(request.host.lower())[0]
-        response = self.fetch('/trigger?wake=false', request_timeout=0.1)
+        timeout = 0.1
-        self.assertTrue(0.099 < response.request_time < 0.15, response.request_time)
+        self.assertTrue(timeout_min < response.request_time < timeout_max,
-_PY34 = sys.version_info >= (3, 4)
+# Can the garbage collector handle cycles that include __del__ methods?
-    __slots__ = ('loop', 'source_traceback', 'exc', 'tb')
+    __slots__ = ('exc_info', 'formatted_tb')
-        self.tb = None
+    def __init__(self, exc_info):
-                                                          exc)
+        exc_info = self.exc_info
-        self.tb = None
+        self.exc_info = None
-            app_log.error(msg)
+        if self.formatted_tb:
-        
+
-        
+
-        """
+    def _clear_tb_log(self):
-            return self._exception
+        self._clear_tb_log()
-        self._set_done()
+        self.set_exc_info(
-        self.set_exception(exc_info[1])
+        self._log_traceback = True
-        
+
-    # cycle are never destroyed. It's not more the case on Python 3.4 thanks to
+    # cycle are never destroyed. It's no longer the case on Python 3.4 thanks to
-    if _PY34:
+    if _GC_CYCLE_FINALIZERS:
-            
+
-        lambda: result.set_exception(TimeoutError("Timeout")))
+        timeout, timeout_callback)
-        self._try_inline_read()
+        try:
-        self._try_inline_read()
+        try:
-            lambda: future.set_exception(ZeroDivisionError))
+            lambda: future.set_exception(ZeroDivisionError()))
-            stream.connect(('an invalid domain', 54321))
+            stream.connect(('an invalid domain', 54321), callback=self.stop)
-        self.server_start_tls(_server_ssl_options())
+        server_future = self.server_start_tls(_server_ssl_options())
-        self.handler._execute(transforms, *self.path_args, **self.path_kwargs)
+        f = self.handler._execute(transforms, *self.path_args, **self.path_kwargs)
-        socket = ssl_wrap_socket(socket, ssl_options, server_side=server_side,
+        socket = ssl_wrap_socket(socket, ssl_options,
-import platform
+import sys
-        if (platform.system() == 'Darwin' and address == 'localhost' and
+        if (sys.platform == 'darwin' and address == 'localhost' and
-            self.handler_kwargs = dict(url="http://" + app.default_host + "/")
+            self.handler_kwargs = dict(url="%s://%s/" % (self.request.protocol, app.default_host))
-        host = request.host.lower().split(':')[0]
+        host = request.host.lower()
-        If an error occurs during the fetch, we raise an `HTTPError`.
+        If an error occurs during the fetch, we raise an `HTTPError` unless
-    def fetch(self, request, callback=None, **kwargs):
+    def fetch(self, request, callback=None, raise_error=True, **kwargs):
-        the request returned a non-200 response code.
+        `HTTPResponse`.  By default, the ``Future`` will raise an `HTTPError`
-            if response.error:
+            if raise_error and response.error:
-            self.read_fds.add(fd)
+            #self.read_fds.add(fd)
-            # Always read when there is not a write
+        if events & IOLoop.READ:
-    def open(self):
+    def open(self, *args, **kwargs):
-    """Provides an iterator to yield the result of futures as they finish
+    """Provides an iterator to yield the results of futures as they finish
-    lost.
+    raise that exception and all the results will be lost.
-                "You must provide a list of futures or key/values, not both")
+                "You must provide args or kwargs, not both")
-            self._futures = kwargs.values()
+            self._keys, self._futures = list(), list()
-                future.add_done_callback(self._done_callback)
+                self_ref = weakref.ref(self)
-        result
+        """Returns a `.Future` that will yield the next available
-        keyword will be returned.
+        """Returns the index of the current `.Future` from the
-        """Returns the most recently completed `.Future` object"""
+        """Returns the current `.Future` object."""
-            self._queue.append(done)
+
-            pass
+class WaitIterator(object):
-    their response.
+    A server is defined by a subclass of `.HTTPServerConnectionDelegate`,
-                raise StreamBufferFullError("Reached maximum read buffer size")
+                raise StreamBufferFullError("Reached maximum write buffer size")
-            stream.connect(("localhost", port), connect_callback)
+            stream.connect(("127.0.0.1", port), connect_callback)
-               {"Content-Length": str(len(message))})
+               httputil.HTTPHeaders({"Content-Length": str(len(message))}))
-        self.logger.error(u("\u00e9").encode("utf8"))
+        with ignore_bytes_warning():
-            self.stream.close()
+            if not self.stream.closed():
-        self.stream.write(frame)
+        try:
-            self._abort()
+        self._write_frame(True, opcode, message, flags=flags)
-                yield self.flush()
+                try:
-                        [native_str("%s: %s" % i) for i in request.headers.items()])
+        curl.setopt(pycurl.HTTPHEADER,
-from tornado.httputil import format_timestamp
+from tornado.httputil import format_timestamp, HTTPHeaders
-                raise AssertionError('Body must be empty for GET request')
+                raise ValueError('Body must be None for GET request')
-                    'Body must not be empty for "%s" request'
+                raise ValueError(
-                        % self.request.method)
+            # Some HTTP methods nearly always have bodies while others
-    def test_body(self):
+    def test_body_sanity_checks(self):
-        with self.assertRaises(AssertionError) as context:
+        with self.assertRaises(ValueError) as context:
-        self.assertTrue('must be empty' in str(context.exception))
+        self.assertTrue('must be None' in str(context.exception))
-        with self.assertRaises(AssertionError) as context:
+        with self.assertRaises(ValueError) as context:
-        self.assertTrue('must not be empty' in str(context.exception))
+        self.assertTrue('must not be None' in str(context.exception))
-    """Concatenate url and argument dictionary regardless of whether
+    """Concatenate url and arguments regardless of whether
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish, removeslash, addslash
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish, removeslash, addslash, RedirectHandler as WebRedirectHandler
-                            headers, native_str(line)))
+        curl.setopt(pycurl.HEADERFUNCTION,
-            write_function = request.streaming_callback
+            write_function = lambda chunk: self.io_loop.add_callback(
-    def _curl_header_callback(self, headers, header_line):
+    def _curl_header_callback(self, headers, header_callback, header_line):
-        self._curls = [_curl_create() for i in range(max_clients)]
+        self._curls = [self._curl_create() for i in range(max_clients)]
-                                        curl.info["headers"])
+                    self._curl_setup_request(curl, request, curl.info["buffer"],
-
+import datetime
-from tornado.util import u, ObjectDict, unicode_type
+from tornado.util import u, ObjectDict, unicode_type, timedelta_to_seconds
-        self.assertTrue(re.match('foo=bar; expires=(.+); Path=/', header))
+        match = re.match("foo=bar; expires=(?P<expires>.+); Path=/", header)
-        self.assertTrue(expires - header_expires < datetime.timedelta(seconds=10))
+        header_expires = datetime.datetime(
-from tornado.log import gen_log, app_log
+from tornado.log import gen_log
-from tornado.log import gen_log, app_log
+from tornado.log import gen_log
-from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp, HTTPServerRequest
+from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp, HTTPServerRequest, parse_request_start_line
-from tornado.util import raise_exc_info, Configurable, u, exec_in, ArgReplacer
+from tornado.util import raise_exc_info, Configurable, u, exec_in, ArgReplacer, timedelta_to_seconds
-            print "Error:", e
+            # HTTPError is raised for non-200 responses; the response
-from tornado.testing import AsyncTestCase, gen_test
+from tornado.log import app_log
-from tornado.log import gen_log
+from tornado.log import gen_log, app_log
-        self.__failure = (typ, value, tb)
+        if self.__failure is None:
-        future.add_done_callback(final_callback)
+        # The engine interface doesn't give us any way to return
-
+    
-    # ignore errors on remove_handler to accomodate this behavior, but
+    # ignore errors on remove_handler to accommodate this behavior, but
-            # Start a read that will be fullfilled asynchronously.
+            # Start a read that will be fulfilled asynchronously.
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish, removeslash, addslash
-            cb(self)
+            try:
-from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode, json_decode, json_encode, squeeze
+from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode, json_decode, json_encode, squeeze, recursive_unicode
-        
+    
-from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode, json_decode, json_encode
+from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode, json_decode, json_encode, squeeze
-        some sevices (including Friendfeed), you must use a
+        some services (including Friendfeed), you must use a
-        `make_current` explictly before starting the `IOLoop`,
+        `make_current` explicitly before starting the `IOLoop`,
-            # estabilsh a real pending callback via
+            # establish a real pending callback via
-    Since it is intented to be used in applications where the top-level
+    Since it is intended to be used in applications where the top-level
-    # Multiprocessing is not availble on Google App Engine.
+    # Multiprocessing is not available on Google App Engine.
-        # Any exception thrown here *or in callback and its desendents*
+        # Any exception thrown here *or in callback and its descendants*
-Most applications shouln't have to work with `StackContext` directly.
+Most applications shouldn't have to work with `StackContext` directly.
-        # information here and re-use it on sbusequent connections to
+        # information here and re-use it on subsequent connections to
-    the errno out of the args but if someone instatiates an Exception
+    the errno out of the args but if someone instantiates an Exception
-        # initialize vs __init__ chosen for compatiblity with AsyncHTTPClient
+        # initialize vs __init__ chosen for compatibility with AsyncHTTPClient
-version = "4.0.2.dev1"
+version = "4.0.2"
-version_info = (4, 0, 2, -100)
+version = "4.0.2"
-            future = self._connect_future = TracebackFuture()
+                return future
-def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=128, flags=None):
+def bind_sockets(port, address=None, family=socket.AF_UNSPEC,
-    def bind_unix_socket(file, mode=0o600, backlog=128):
+    def bind_unix_socket(file, mode=0o600, backlog=_DEFAULT_BACKLOG):
-        while True:
+        # More connections may come in while we're handling callbacks;
-                return future
+                try:
-            future = self._connect_future = TracebackFuture()
+                return future
-def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=128, flags=None):
+def bind_sockets(port, address=None, family=socket.AF_UNSPEC,
-    def bind_unix_socket(file, mode=0o600, backlog=128):
+    def bind_unix_socket(file, mode=0o600, backlog=_DEFAULT_BACKLOG):
-        while True:
+        # More connections may come in while we're handling callbacks;
-                return future
+                try:
-        if isinstance(value, (unicode, bytes_type)):
+        if isinstance(value, (unicode, bytes)):
-        self.write_message(message, binary=isinstance(message, bytes_type))
+        self.write_message(message, binary=isinstance(message, bytes))
-from tornado.util import bytes_type, u, unicode_type, ArgReplacer
+from tornado.util import u, unicode_type, ArgReplacer
-            if isinstance(extended_permissions, (unicode_type, bytes_type)):
+            if isinstance(extended_permissions, (unicode_type, bytes)):
-    if bytes_type is str:  # py2
+    if bytes is str:  # py2
-from tornado.util import bytes_type, unicode_type, basestring_type, u
+from tornado.util import unicode_type, basestring_type, u
-_UTF8_TYPES = (bytes_type, type(None))
+_UTF8_TYPES = (bytes, type(None))
-    if not isinstance(value, bytes_type):
+    if not isinstance(value, bytes):
-    if not isinstance(value, bytes_type):
+    if not isinstance(value, bytes):
-    elif isinstance(obj, bytes_type):
+    elif isinstance(obj, bytes):
-from tornado.util import ObjectDict, bytes_type
+from tornado.util import ObjectDict
-        assert isinstance(chunk, bytes_type)
+        assert isinstance(chunk, bytes)
-from tornado.util import bytes_type, errno_from_exception
+from tornado.util import errno_from_exception
-        assert isinstance(data, bytes_type)
+        assert isinstance(data, bytes)
-from tornado.util import bytes_type, ObjectDict, exec_in, unicode_type
+from tornado.util import ObjectDict, exec_in, unicode_type
-            "_tt_string_types": (unicode_type, bytes_type),
+            "_tt_string_types": (unicode_type, bytes),
-from tornado.util import u, unicode_type, bytes_type
+from tornado.util import u, unicode_type
-        if bytes_type is str:
+        if bytes is str:
-from tornado.util import u, bytes_type
+from tornado.util import u
-        self.assertEqual(type(response.body), bytes_type)
+        self.assertEqual(type(response.body), bytes)
-from tornado.util import u, bytes_type
+from tornado.util import u
-        self.check_type('arg_value', list(self.request.arguments.values())[0][0], bytes_type)
+        self.check_type('arg_value', list(self.request.arguments.values())[0][0], bytes)
-        self.check_type('body', self.request.body, bytes_type)
+        self.check_type('body', self.request.body, bytes)
-        if str is bytes_type:
+        if str is bytes:
-from tornado.util import u, bytes_type, basestring_type
+from tornado.util import u, basestring_type
-        if issubclass(bytes_type, basestring_type):
+        if issubclass(bytes, basestring_type):
-from tornado.util import u, bytes_type, ObjectDict, unicode_type
+from tornado.util import u, ObjectDict, unicode_type
-            self.assertEqual(type(s), bytes_type)
+            self.assertEqual(type(s), bytes)
-from tornado.util import u, bytes_type, ObjectDict, unicode_type
+from tornado.util import u, ObjectDict, unicode_type
-                if type(value) != bytes_type:
+                if type(value) != bytes:
-        self.check_type('get_secure_cookie', self.get_secure_cookie('asdf'), bytes_type)
+        self.check_type('get_secure_cookie', self.get_secure_cookie('asdf'), bytes)
-        self.check_type('xsrf_token', self.xsrf_token, bytes_type)
+        self.check_type('xsrf_token', self.xsrf_token, bytes)
-        if type(value) != bytes_type:
+        if type(value) != bytes:
-            if type(s) == bytes_type:
+            if type(s) == bytes:
-        if isinstance(impl, (unicode_type, bytes_type)):
+        if isinstance(impl, (unicode_type, bytes)):
-from tornado.util import bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type, _websocket_mask
+from tornado.util import import_object, ObjectDict, raise_exc_info, unicode_type, _websocket_mask
-        if isinstance(value, bytes_type):
+        if isinstance(value, bytes):
-        if not isinstance(chunk, (bytes_type, unicode_type, dict)):
+        if not isinstance(chunk, (bytes, unicode_type, dict)):
-                if isinstance(file_part, (unicode_type, bytes_type)):
+                if isinstance(file_part, (unicode_type, bytes)):
-                if isinstance(file_part, (unicode_type, bytes_type)):
+                if isinstance(file_part, (unicode_type, bytes)):
-            if isinstance(content, bytes_type):
+            if isinstance(content, bytes):
-        if isinstance(data, bytes_type):
+        if isinstance(data, bytes):
-            if isinstance(f, (unicode_type, bytes_type)):
+            if isinstance(f, (unicode_type, bytes)):
-            if isinstance(f, (unicode_type, bytes_type)):
+            if isinstance(f, (unicode_type, bytes)):
-            if not isinstance(a, (unicode_type, bytes_type)):
+            if not isinstance(a, (unicode_type, bytes)):
-from tornado.util import bytes_type, _websocket_mask
+from tornado.util import _websocket_mask
-        assert isinstance(message, bytes_type)
+        assert isinstance(message, bytes)
-        assert isinstance(data, bytes_type)
+        assert isinstance(data, bytes)
-from tornado.util import bytes_type, unicode_type
+from tornado.util import unicode_type
-        assert isinstance(s, bytes_type)
+        assert isinstance(s, bytes)
-        assert isinstance(s, bytes_type)
+        assert isinstance(s, bytes)
-        return dict(gzip=True)
+        return dict(
-                headers["Content-Length"] = str(len(chunk))
+                # The original content length is no longer correct.
-        result = self.orig_method()
+    def __call__(self, *args, **kwargs):
-                            # the timeout was cancelled
+                            # The timeout was cancelled.  Note that the
-                            del timeout
+                            due_timeouts.append(heapq.heappop(self._timeouts))
-                callbacks = callback = None
+                callbacks = callback = due_timeouts = timeout = None
-version = "4.0.1"
+version = "4.0.2.dev1"
-version_info = (4, 0, 1, -100)
+version = "4.0.2.dev1"
-       default="32fc6114554e3c53d5952594510021e2")
+define("facebook_api_key", help="your Facebook application API key", type=str)
-        # SIGCHILD processing in response to its own wakeup fd being
+        # SIGCHLD processing in response to its own wakeup fd being
-        This method uses a ``SIGCHILD`` handler, which is a global setting
+        This method uses a ``SIGCHLD`` handler, which is a global setting
-        """Initializes the ``SIGCHILD`` handler.
+        """Initializes the ``SIGCHLD`` handler.
-        """Removes the ``SIGCHILD`` handler."""
+        """Removes the ``SIGCHLD`` handler."""
-        return dict(gzip=True)
+        return dict(
-                headers["Content-Length"] = str(len(chunk))
+                # The original content length is no longer correct.
-        result = self.orig_method()
+    def __call__(self, *args, **kwargs):
-                            # the timeout was cancelled
+                            # The timeout was cancelled.  Note that the
-                            del timeout
+                            due_timeouts.append(heapq.heappop(self._timeouts))
-                callbacks = callback = None
+                callbacks = callback = due_timeouts = timeout = None
-class SetCurrentUserTest(SimpleHandlerTestCase):
+class SetLazyPropertiesTest(SimpleHandlerTestCase):
-            self.write('Hello %s' % self.current_user)
+            self.write('Hello %s (%s)' % (self.current_user, self.locale.code))
-    def test_set_current_user(self):
+    def test_set_properties(self):
-        self.assertEqual(response.body, b'Hello Ben')
+        self.assertEqual(response.body, b'Hello Ben (en_US)')
-        """The local for the current session.
+        """The locale for the current session.
-version = "4.0.1b1"
+version = "4.0.1"
-version = "4.0.1b1"
+version = "4.0.1"
-        Resolver().resolve('localhost', 0, callback=self.stop)
+        # The port used here doesn't matter, but some systems require it
-version = "4.0"
+version = "4.0.1b1"
-version_info = (4, 0, 0, 0)
+version = "4.0.1b1"
-                body_future = self._read_body(headers, delegate)
+                body_future = self._read_body(
-            content_length = int(content_length)
+    def _read_body(self, code, headers, delegate):
-        self.stream.set_close_callback(self._on_close)
+        self.stream.set_close_callback(self.on_connection_close)
-    def _on_close(self):
+    def on_connection_close(self):
-            raise HTTPError(599, message)
+            try:
-
+        #
-        with ExpectLog(app_log, "Uncaught exception"):
+        with ExpectLog(gen_log, "Malformed HTTP message"):
-    def _on_close(self):
+    def on_connection_close(self):
-        super(WebSocketClientConnection, self)._on_close()
+        super(WebSocketClientConnection, self).on_connection_close()
-        self.stream.set_close_callback(self._on_close)
+        self.stream.set_close_callback(self.on_connection_close)
-        self.resolver.close()
+        self.tcp_client.close()
-                callback(*args)
+                return callback(*args)
-            self._maybe_add_error_listener()
+            finally:
-            self.callback()
+            return self.callback()
-        self._schedule_next()
+        finally:
-        self.call_at(self.time() + delay, callback, *args, **kwargs)
+        return self.call_at(self.time() + delay, callback, *args, **kwargs)
-        self.add_timeout(when, callback, *args, **kwargs)
+        return self.add_timeout(when, callback, *args, **kwargs)
-        except build_errors:
+        except Exception:
-        except build_errors:
+        except Exception:
-                body_future = self._read_body(headers, delegate)
+                body_future = self._read_body(
-            content_length = int(content_length)
+    def _read_body(self, code, headers, delegate):
-        self.stream.set_close_callback(self._on_close)
+        self.stream.set_close_callback(self.on_connection_close)
-    def _on_close(self):
+    def on_connection_close(self):
-            raise HTTPError(599, message)
+            try:
-
+        #
-        with ExpectLog(app_log, "Uncaught exception"):
+        with ExpectLog(gen_log, "Malformed HTTP message"):
-    def _on_close(self):
+    def on_connection_close(self):
-        super(WebSocketClientConnection, self)._on_close()
+        super(WebSocketClientConnection, self).on_connection_close()
-        self.stream.set_close_callback(self._on_close)
+        self.stream.set_close_callback(self.on_connection_close)
-        self.resolver.close()
+        self.tcp_client.close()
-                callback(*args)
+                return callback(*args)
-            self._maybe_add_error_listener()
+            finally:
-            self.callback()
+            return self.callback()
-        self._schedule_next()
+        finally:
-        self.io_loop.run_sync(self.http_server.close_all_connections)
+        self.io_loop.run_sync(self.http_server.close_all_connections,
-for method in ["write", "redirect", "set_header", "send_error", "set_cookie",
+for method in ["write", "redirect", "set_header", "set_cookie",
-    def __init__(self, persistent):
+    def __init__(self, persistent, max_wbits):
-        return zlib.compressobj(-1, zlib.DEFLATED, -zlib.MAX_WBITS)
+        return zlib.compressobj(-1, zlib.DEFLATED, -self._max_wbits)
-    def __init__(self, persistent):
+    def __init__(self, persistent, max_wbits):
-        return zlib.decompressobj(-zlib.MAX_WBITS)
+        return zlib.decompressobj(-self._max_wbits)
-                self._create_compressors('server', {})
+                # TODO: negotiate parameters if compression_options
-        # TODO: support the max_wbits parameters.
+        # TODO: handle invalid parameters gracefully
-            persistent=(side + '_no_context_takeover') not in agreed_parameters)
+            **self._get_compressor_options(side, agreed_parameters))
-                        not in agreed_parameters))
+            **self._get_compressor_options(other_side, agreed_parameters))
-            request.headers['Sec-WebSocket-Extensions'] = 'permessage-deflate'
+            # Always offer to let the server set our max_wbits (and even though
-        test_ws = yield websocket_connect(url, None)
+        test_ws = yield websocket_connect(url, None, compression_options={})
-    def initialize(self, close_future):
+    def initialize(self, close_future, compression_options=None):
-class WebSocketTest(AsyncHTTPTestCase):
+class WebSocketBaseTestCase(AsyncHTTPTestCase):
-            io_loop=self.io_loop)
+        ws = yield self.ws_connect('/echo')
-        yield self.close_future
+        yield self.close(ws)
-            'ws://localhost:%d/echo' % self.get_http_port())
+        ws = yield self.ws_connect('/echo')
-        yield self.close_future
+        yield self.close(ws)
-            'ws://localhost:%d/echo' % self.get_http_port())
+        ws = yield self.ws_connect('/echo')
-        yield self.close_future
+        yield self.close(ws)
-            'ws://localhost:%d/error_in_on_message' % self.get_http_port())
+        ws = yield self.ws_connect('/error_in_on_message')
-        yield self.close_future
+        yield self.close(ws)
-                io_loop=self.io_loop)
+            yield self.ws_connect('/notfound')
-                io_loop=self.io_loop)
+            yield self.ws_connect('/non_ws')
-        yield self.close_future
+        yield self.close(ws)
-            'ws://localhost:%d/close_reason' % self.get_http_port())
+        ws = yield self.ws_connect('/close_reason')
-            'ws://localhost:%d/echo' % self.get_http_port())
+        ws = yield self.ws_connect('/echo')
-        yield self.close_future
+        yield self.close(ws)
-        yield self.close_future
+        yield self.close(ws)
-            self.ws_connection = WebSocketProtocol13(self)
+            self.ws_connection = WebSocketProtocol13(
-    def __init__(self, handler, mask_outgoing=False):
+    # Bit masks for the first byte of a frame.
-            "\r\n" % (self._challenge_response(), subprotocol_header)))
+            "%s%s"
-    def _write_frame(self, fin, opcode, data):
+    def _parse_extensions_header(self, headers):
-            finbit = 0x80
+            finbit = self.FIN
-        frame = struct.pack("B", finbit | opcode)
+        frame = struct.pack("B", finbit | opcode | flags)
-            self._write_frame(True, opcode, message)
+            self._write_frame(True, opcode, message, flags=flags)
-        self._frame_opcode = header & 0xf
+        self._final_frame = header & self.FIN
-    def __init__(self, io_loop, request):
+    def __init__(self, io_loop, request, compression_options=None):
-        self.protocol = WebSocketProtocol13(self, mask_outgoing=True)
+        self.protocol = WebSocketProtocol13(
-def websocket_connect(url, io_loop=None, callback=None, connect_timeout=None):
+def websocket_connect(url, io_loop=None, callback=None, connect_timeout=None,
-    conn = WebSocketClientConnection(io_loop, request)
+    conn = WebSocketClientConnection(io_loop, request, compression_options)
-            if err.args[0] in _ERRNO_CONNRESET:
+            # Some port scans (e.g. nmap in -sT mode) have been known
-                result_future.set_result(callback(self.cache[-new_count:]))
+                result_future.set_result(self.cache[-new_count:])
-        """
+        "Return the request payload - so we can check it is being kept"
-
+        # The lstrip removes newlines that some implementations sometimes
-        client.close()
+        try:
-        data = native_str(data.decode('latin1'))
+        data = native_str(data.decode('latin1')).lstrip("\r\n")
-        body = "some patch data"
+        body = b"some patch data"
-        self.assertEqual(response.body, body)
+class PatchHandler(RequestHandler):
-                self.contact_list[contact_name][attribute] = value
+        self.write(self.request.body)
-        self.assertEqual(computed_body, expected_body)
+	body = "some patch data"
-
+
-        self.skipOnCares()
+def _failing_getaddrinfo(*args):
-class TwistedResolverTest(AsyncTestCase, _ResolverTestMixin):
+class TwistedResolverTest(AsyncTestCase, _ResolverTestMixin,
-        self.assertEqual(response.body, b"Post arg1: foo, arg2: bar")
+    # This test causes odd failures with the combination of
-        self.call_at(self.time() + delay, callback, *args, **kwargs)
+        return self.call_at(self.time() + delay, callback, *args, **kwargs)
-        self.add_timeout(when, callback, *args, **kwargs)
+        return self.add_timeout(when, callback, *args, **kwargs)
-        self.remote_ip = getattr(context, 'remote_ip')
+        self.remote_ip = getattr(context, 'remote_ip', None)
-from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp
+from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp, HTTPServerRequest
-        except build_errors:
+        except Exception:
-        except build_errors:
+        except Exception:
-from tornado.escape import _unicode
+from tornado.escape import _unicode, native_str
-                exec_in(f.read(), config, config)
+        with open(path, 'rb') as f:
-version = "4.0"
+version = "4.1.dev1"
-version_info = (4, 0, 0, 0)
+version = "4.1.dev1"
-version = "4.0b3"
+version = "4.0"
-version_info = (4, 0, 0, -97)
+version = "4.0"
-
+from io import BytesIO
-    from cStringIO import StringIO as BytesIO  # python 2
+from io import BytesIO
-    from cStringIO import StringIO as BytesIO  # python 2
+from io import BytesIO
-    from cStringIO import StringIO as BytesIO  # python 2
+from io import BytesIO
-You can also yield a list or dict of ``Futures`` and/or ``Tasks``, which will be
+You can also yield a list or dict of ``Futures``, which will be
-    subclassed to provide additional yielding behavior.
+    .. deprecated:: 4.0
-    """Returns the argument passed to the result of a previous `Callback`."""
+    """Returns the argument passed to the result of a previous `Callback`.
-    """Runs a single asynchronous operation.
+    """Adapts a callback-based asynchronous function for use in coroutines.
-    )
+
-    old_value = os.environ.get('name')
+    old_value = os.environ.get(name)
-        reason = None
+        reason = kwargs.get('reason')
-    This is called automaticaly by `tornado.options.parse_command_line`
+    This is called automatically by `tornado.options.parse_command_line`
-version = "4.0b2"
+version = "4.0b3"
-version_info = (4, 0, 0, -98)
+version = "4.0b3"
-            except TypeError:
+            except (binascii.Error, TypeError):
-                raise HTTPError(400, "XSRF cookie is not a hexadecimal")
+                token = utf8(cookie)
-
+    def test_xsrf_success_short_token(self):
-        elif len(cookie) == 32:
+        else:
-            token = binascii.a2b_hex(utf8(cookie))
+            try:
-        * ``handler_class``: `RequestHandler` subclass to be invoked.
+        * ``handler``: `RequestHandler` subclass to be invoked.
-from tornado.log import gen_log
+from tornado.log import gen_log, app_log
-    def wait_for_messages(self, callback, cursor=None):
+    def wait_for_messages(self, cursor=None):
-        self.waiters.add(callback)
+                result_future.set_result(callback(self.cache[-new_count:]))
-        self.waiters.remove(callback)
+    def cancel_wait(self, future):
-                logging.error("Error in waiter callback", exc_info=True)
+        for future in self.waiters:
-    @tornado.web.asynchronous
+    @gen.coroutine
-        # Closed client connection
+        # Save the future returned by wait_for_messages so we can cancel
-        self.finish(dict(messages=messages))
+        self.write(dict(messages=messages))
-        global_message_buffer.cancel_wait(self.on_new_messages)
+        global_message_buffer.cancel_wait(self.future)
-started guide.
+See the :doc:`guide` for additional information.
-            self._run_callback(self.handler.on_message, decoded)
+            self._run_callback(self.handler.on_message, data)
-    if request.method in ("POST", "PUT"):
+    if request.method == "GET":
-            raise AssertionError('Body must be empty for GET request')
+import json
-from tornado.web import Application, RequestHandler
+from tornado.web import Application, RequestHandler, URLSpec
-version = "4.0b1"
+version = "4.0b2"
-version_info = (4, 0, 0, -99)
+version = "4.0b2"
-    if request.use_gzip:
+    if request.decompress_response:
-                 body_timeout=None, use_gzip=False):
+                 body_timeout=None, decompress=False):
-        :arg bool use_gzip: if true, decode incoming ``Content-Encoding: gzip``
+        :arg bool decompress: if true, decode incoming
-        self.use_gzip = use_gzip
+        self.decompress = decompress
-        if self.params.use_gzip:
+        if self.params.decompress:
-        use_gzip=True,
+        decompress_response=True,
-                 expect_100_continue=False):
+                 expect_100_continue=False, decompress_response=None):
-        :arg bool use_gzip: Request gzip encoding from the server
+        :arg bool decompress_response: Request a compressed response from
-        self.use_gzip = use_gzip
+        if decompress_response is not None:
-       Added ``gzip``, ``chunk_size``, ``max_header_size``,
+       Added ``decompress_request``, ``chunk_size``, ``max_header_size``,
-                 xheaders=False, ssl_options=None, protocol=None, gzip=False,
+                 xheaders=False, ssl_options=None, protocol=None,
-            use_gzip=gzip,
+            decompress=decompress_request,
-        if self.request.use_gzip:
+        if self.request.decompress_response:
-                use_gzip=self.request.use_gzip),
+                decompress=self.request.decompress_response),
-        return dict(gzip=True)
+        return dict(decompress_request=True)
-        return dict(chunk_size=self.CHUNK_SIZE, gzip=True)
+        return dict(chunk_size=self.CHUNK_SIZE, decompress_request=True)
-            if settings.get("gzip"):
+            if settings.get("compress_response") or settings.get("gzip"):
-    def parse_config_file(self, path, final=True, encoding=None):
+    def parse_config_file(self, path, final=True):
-            with open(path, encoding=encoding) as f:
+            with open(path, encoding="utf-8") as f:
-
+        options.parse_config_file(os.path.join(os.path.dirname(__file__),
-    def parse_config_file(self, path, final=True):
+    def parse_config_file(self, path, final=True, encoding=None):
-            exec_in(f.read(), config, config)
+        try:
-                                               "options_test.cfg"))
+        options.define("username", default='foo')
-            if (errno_from_exception(e) != errno.EINPROGRESS and
+            if (errno_from_exception(e) not in _ERRNO_INPROGRESS and
-            self.assertEqual(stream.error.args[0], errno.ECONNREFUSED)
+            self.assertTrue(stream.error.args[0] in _ERRNO_CONNREFUSED)
-                            response.error)
+            contains_errno = str(errno.ECONNREFUSED) in str(response.error)
-version = "4.0.dev1"
+version = "4.0b1"
-version_info = (4, 0, 0, -100)
+version = "4.0b1"
-    supporting registration-free authentication.
+    .. deprecated:: 4.0
-    Future-based interface seen on other classes in this module.
+    .. deprecated:: 1.1
-    to find an unused port.
+    .. deprecated::
-   documentation for caveats).
+WebSockets are supported in the current versions of all major browsers,
-from tornado.util import bytes_type, unicode_type, _websocket_mask
+from tornado.util import bytes_type, _websocket_mask
-    new Transform.
+    Applications are not expected to create their own OutputTransforms
-            return 'got expected exception'
+    def write_error(self, status_code, **kwargs):
-            return 'unexpected failure'
+            self.write('unexpected failure')
-            return
+        """
-                ret, num_handles = self._socket_action(fd, action)
+                ret, num_handles = self._multi.socket_action(fd, action)
-                    ret, num_handles = self._socket_action(
+                    ret, num_handles = self._multi.socket_action(
-various problems with request timeouts (for more information, see
+Note that if you are using ``curl_httpclient``, it is highly
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body, Finish
-from tornado.util import errno_from_exception
+from tornado.util import Configurable, errno_from_exception, timedelta_to_seconds
-    def add_timeout(self, deadline, callback):
+    def add_timeout(self, deadline, callback, *args, **kwargs):
-        current time.
+        current time.  Since Tornado 4.0, `call_later` is a more
-        raise NotImplementedError()
+        if isinstance(deadline, numbers.Real):
-        
+
-        timeout = _Timeout(deadline, stack_context.wrap(callback), self)
+    def call_at(self, deadline, callback, *args, **kwargs):
-        else:
+        if not isinstance(deadline, numbers.Real):
-from tornado.ioloop import IOLoop, _Timeout
+from tornado.ioloop import IOLoop
-                                            stack_context.wrap(callback))
+    def call_at(self, when, callback, *args, **kwargs):
-    long = int  # py3
+from tornado.util import timedelta_to_seconds
-        if isinstance(deadline, (int, long, float)):
+    def add_timeout(self, deadline, callback, *args, **kwargs):
-            delay = tornado.ioloop._Timeout.timedelta_to_seconds(deadline)
+            delay = timedelta_to_seconds(deadline)
-        return self.reactor.callLater(delay, self._run_callback, wrap(callback))
+        return self.reactor.callLater(
-        handle = self.io_loop.add_timeout(self.io_loop.time(), self.stop())
+        handle = self.io_loop.add_timeout(self.io_loop.time(), self.stop)
-            return cls._async_clients()[io_loop]
+        if force_instance:
-            cls._async_clients()[io_loop] = instance
+        # Make sure the instance knows which cache to remove itself from.
-            del self._async_clients()[self.io_loop]
+        if self._instance_cache is not None:
-        except httputil.HTTPInputException:
+        except httputil.HTTPInputError:
-        except httputil.HTTPInputException as e:
+        except httputil.HTTPInputError as e:
-                raise httputil.HTTPOutputException(
+                raise httputil.HTTPOutputError(
-            raise httputil.HTTPOutputException(
+            raise httputil.HTTPOutputError(
-                                              data[eol:100])
+            raise httputil.HTTPInputError("Malformed HTTP headers: %r" %
-                raise httputil.HTTPInputException("Content-Length too long")
+                raise httputil.HTTPInputError("Content-Length too long")
-                raise httputil.HTTPInputException("chunked body too large")
+                raise httputil.HTTPInputError("chunked body too large")
-class HTTPInputException(Exception):
+class HTTPInputError(Exception):
-class HTTPOutputException(Exception):
+class HTTPOutputError(Exception):
-        raise HTTPInputException("Malformed HTTP request line")
+        raise HTTPInputError("Malformed HTTP request line")
-        raise HTTPInputException(
+        raise HTTPInputError(
-        raise HTTPInputException("Error parsing response start line")
+        raise HTTPInputError("Error parsing response start line")
-                self._error = httputil.HTTPOutputException(
+                self._error = httputil.HTTPOutputError(
-            self._error = httputil.HTTPOutputException(
+            self._error = httputil.HTTPOutputError(
-            self.stream.close()
+            self.set_status(400)
-            self.stream.close()
+            self.set_status(400)
-            self.stream.close()
+            self.set_status(403)
-
+def _wrap_method(method):
-    setattr(WebSocketHandler, method, WebSocketHandler._not_supported)
+    setattr(WebSocketHandler, method,
-        after a successful connection will be the stream itself).
+        same format as for `socket.connect <socket.socket.connect>` for
-        self._closed = True
+        self._closed = False
-    its constructor can be set with the static method `configure()`
+    can be used to suppress this singleton behavior.  Unless
-                callbacks = callback = None
+                # Add any timeouts that have come due to the callback list.
-                            self._run_callback(timeout.callback)
+                            callbacks.append(timeout.callback)
-                            poll_timeout = min(seconds, poll_timeout)
+                for callback in callbacks:
-            self.get_authenticated_user(self.async_callback(self._on_auth))
+            self.get_authenticated_user(self._on_auth)
-        """Wrap callbacks with this if they are used on asynchronous requests.
+    def _run_callback(self, callback, *args, **kwargs):
-        is uncaught.
+        On error, aborts the websocket connection and returns False.
-        return wrapper
+        try:
-        self.async_callback(self.handler.open)(*self.handler.open_args, **self.handler.open_kwargs)
+        self._run_callback(self.handler.open, *self.handler.open_args,
-                frame[:-1].decode("utf-8", "replace"))
+            self._run_callback(self.handler.on_message,
-        self.async_callback(self.handler.open)(*self.handler.open_args, **self.handler.open_kwargs)
+        self._run_callback(self.handler.open, *self.handler.open_args,
-            self.async_callback(self.handler.on_message)(decoded)
+            self._run_callback(self.handler.on_message, decoded)
-            self.async_callback(self.handler.on_message)(data)
+            self._run_callback(self.handler.on_message, decoded)
-            self.async_callback(self.handler.on_pong)(data)
+            self._run_callback(self.handler.on_pong, data)
-_ERRNO_CONNRESET = (errno.ECONNRESET, errno.ECONNABORTED, errno.EPIPE)
+_ERRNO_CONNRESET = (errno.ECONNRESET, errno.ECONNABORTED, errno.EPIPE,
-            callback()
+            ret = callback()
-                self._run_callback, stack_context.wrap(callback), *args)
+        self.asyncio_loop.call_soon_threadsafe(
-                                    wrap(callback), *args, **kwargs)
+        self.reactor.callFromThread(
-from tornado.testing import AsyncTestCase, bind_unused_port
+from tornado.testing import AsyncTestCase, bind_unused_port, ExpectLog
-version = "3.3.dev1"
+version = "4.0.dev1"
-version_info = (3, 3, 0, -100)
+version = "4.0.dev1"
-.. versionchanged:: 3.3
+.. versionchanged:: 4.0
-    .. versionchanged:: 3.3
+    .. versionchanged:: 4.0
-        .. versionadded:: 3.3
+        .. versionadded:: 4.0
-        .. versionadded:: 3.3
+        .. versionadded:: 4.0
-    .. versionchanged:: 3.3
+    .. versionchanged:: 4.0
-    .. versionadded:: 3.3
+    .. versionadded:: 4.0
-    .. versionadded:: 3.3
+    .. versionadded:: 4.0
-.. versionadded:: 3.3
+.. versionadded:: 4.0
-.. versionadded:: 3.3
+.. versionadded:: 4.0
-        .. deprecated:: 3.3
+        .. deprecated:: 4.0
-           encoding on requests.  New in Tornado 3.3
+           encoding on requests.  New in Tornado 4.0
-        .. versionadded:: 3.3
+        .. versionadded:: 4.0
-.. versionchanged:: 3.3
+.. versionchanged:: 4.0
-    .. versionchanged:: 3.3
+    .. versionchanged:: 4.0
-    .. versionchanged:: 3.3
+    .. versionchanged:: 4.0
-        .. deprecated:: 3.3
+        .. deprecated:: 4.0
-        .. deprecated:: 3.3
+        .. deprecated:: 4.0
-        .. deprecated:: 3.3
+        .. deprecated:: 4.0
-    .. versionadded:: 3.3
+    .. versionadded:: 4.0
-    .. versionadded:: 3.3
+    .. versionadded:: 4.0
-    .. versionadded:: 3.3
+    .. versionadded:: 4.0
-    .. versionadded:: 3.3
+    .. versionadded:: 4.0
-    .. versionadded:: 3.3
+    .. versionadded:: 4.0
-        .. versionadded:: 3.3
+        .. versionadded:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionadded:: 3.3
+        .. versionadded:: 4.0
-        .. versionadded:: 3.3
+        .. versionadded:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionadded:: 3.3
+        .. versionadded:: 4.0
-    .. versionchanged:: 3.3
+    .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-    .. versionchanged:: 3.3
+    .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-        .. versionadded:: 3.3
+        .. versionadded:: 4.0
-        .. versionchanged:: 3.3
+        .. versionchanged:: 4.0
-    .. deprecated: 3.3::
+    .. deprecated:: 4.0
-    .. versionadded:: 3.3
+    .. versionadded:: 4.0
-        except DistutilsPlatformError:
+        except build_errors:
-        else:
+        try:
-                                                  "extension."))
+                                                  "The output above "
-version = "3.2.1"
+version = "3.2.2"
-version_info = (3, 2, 1, 0)
+version = "3.2.2"
-
+        self._timeout_counter = itertools.count()
-    __slots__ = ['deadline', 'callback']
+    __slots__ = ['deadline', 'callback', 'tiebreaker']
-                (other.deadline, id(other)))
+        return ((self.deadline, self.tiebreaker) <
-                (other.deadline, id(other)))
+        return ((self.deadline, self.tiebreaker) <=
-from tornado.netutil import Resolver
+from tornado.netutil import Resolver, bind_sockets
-            self.http_server.listen(self.get_http_port(), address='::1')
+            [sock] = bind_sockets(None, '::1', family=socket.AF_INET6)
-        url = self.get_url("/hello").replace("localhost", "[::1]")
+        url = '%s://[::1]:%d/hello' % (self.get_protocol(), port)
-                yield header_future
+            with _ExceptionLoggingContext(app_log):
-                delegate.finish()
+                with _ExceptionLoggingContext(app_log):
-                delegate.on_connection_close()
+                with _ExceptionLoggingContext(app_log):
-                yield gen.maybe_future(delegate.data_received(body))
+                with _ExceptionLoggingContext(app_log):
-                        delegate.data_received(chunk))
+                    with _ExceptionLoggingContext(app_log):
-            delegate.data_received(body)
+            with _ExceptionLoggingContext(app_log):
-                    app_log.error("Uncaught exception", exc_info=True)
+                    gen_log.error("Uncaught exception", exc_info=True)
-            with ExpectLog(app_log, 'Uncaught exception', required=False):
+            with ExpectLog(gen_log, 'Uncaught exception', required=False):
-from tornado.log import gen_log
+from tornado.log import gen_log, app_log
-        response = self.fetch("/no_content?error=1")
+        with ExpectLog(app_log, "Uncaught exception"):
-        f(*args, **kwargs)
+        def handle_exception(typ, value, tb):
-        http_client.fetch(url, self.async_callback(
+        http_client.fetch(url, functools.partial(
-                self.async_callback(
+                functools.partial(
-                self.async_callback(
+                functools.partial(
-                          self.async_callback(self._on_access_token, callback))
+                          functools.partial(self._on_access_token, callback))
-            self.async_callback(self._on_oauth_get_user, access_token, future))
+            functools.partial(self._on_oauth_get_user, access_token, future))
-                   self.async_callback(
+                   functools.partial(
-        http_callback = self.async_callback(self._on_twitter_request, callback)
+        http_callback = functools.partial(self._on_twitter_request, callback)
-        callback = self.async_callback(self._on_friendfeed_request, callback)
+        callback = functools.partial(self._on_friendfeed_request, callback)
-                       self.async_callback(self._on_access_token, callback))
+                       functools.partial(self._on_access_token, callback))
-                   self.async_callback(self._on_access_token, callback),
+                   functools.partial(self._on_access_token, callback),
-                    self.get_authenticated_user(self.async_callback(self._on_auth))
+                    self.get_authenticated_user(self._on_auth)
-            callback=self.async_callback(
+            callback=functools.partial(
-                        callback=self.async_callback(self._on_stream),
+                        callback=self._on_stream,
-        http.fetch(url, callback=self.async_callback(
+        http.fetch(url, callback=functools.partial(
-                   self.async_callback(self._on_access_token, redirect_uri, client_id,
+                   functools.partial(self._on_access_token, redirect_uri, client_id,
-            callback=self.async_callback(
+            callback=functools.partial(
-        callback = self.async_callback(self._on_facebook_request, callback)
+        callback = functools.partial(self._on_facebook_request, callback)
-                             tornado.auth.GoogleMixin):
+    class GoogleOAuth2LoginHandler(tornado.web.RequestHandler,
-                # Save the user with e.g. set_secure_cookie()
+            if self.get_argument('code', False):
-                yield self.authenticate_redirect()
+                yield self.authorize_redirect(
-            class GoogleOAuth2LoginHandler(LoginHandler,
+            class GoogleOAuth2LoginHandler(tornado.web.RequestHandler,
-    def get_token(self, old_token=None):
+    def get_token(self, old_token=None, version=None):
-        response = self.fetch("/", headers=headers)
+        response = self.fetch(
-            if version is None or version != 2:
+            output_version = self.settings.get("xsrf_cookie_version", 2)
-            token = binascii.a2b_hex(cookie)
+            token = binascii.a2b_hex(utf8(cookie))
-            self.assertEqual(token, self.xsrf_token)
+            # Tokens are encoded uniquely each time
-from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError, _websocket_mask_python
+from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError
-from tornado.util import bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type
+from tornado.util import bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type, _websocket_mask
-                token = binascii.b2a_hex(os.urandom(16))
+            version, token, timestamp = self._get_raw_xsrf_token()
-            self._xsrf_token = token
+                self.set_cookie("_xsrf", self._xsrf_token,
-        if not _time_independent_equals(utf8(self.xsrf_token), utf8(token)):
+        _, token, _ = self._decode_xsrf_token(token)
-    xrange = range  # py3
+from tornado.util import bytes_type, unicode_type, _websocket_mask
-        _websocket_mask = _websocket_mask_python
+
-                token = binascii.b2a_hex(uuid.uuid4().bytes)
+                token = binascii.b2a_hex(os.urandom(16))
-        if self.xsrf_token != token:
+        if not _time_independent_equals(utf8(self.xsrf_token), utf8(token)):
-import asyncio
+try:
-import asyncio
+try:
-    def test_check_origin_valid(self):
+    def test_check_origin_valid_no_path(self):
-    def test_check_origin_with_path(self):
+    def test_check_origin_valid_with_path(self):
-    def test_check_origin_valid2(self):
+    def test_check_origin_invalid_partial_url(self):
-        yield self.close_future
+        with self.assertRaises(HTTPError) as cm:
-    def test_check_origin_invalid2(self):
+    def test_check_origin_invalid_subdomains(self):
-                   'Host': 'subtenant2.somewhereelse.com'}
+        # Subdomains should be disallowed by default.  If we could pass a
-        # came from a browser and that it can be passed on.
+        # did not come from a browser and that it can be passed on.
-        provided.
+
-        """
+        browsers, since WebSockets are allowed to bypass the usual same-origin
-            origin = "//" + origin
+        .. versionadded:: 3.3
-    """Exception raised by `IOStream.write` method when write buffer is full.
+class StreamBufferFullError(Exception):
-                raise StreamBufferFullError
+                raise StreamBufferFullError("Reached maximum read buffer size")
-            raise IOError("Reached maximum read buffer size")
+            raise StreamBufferFullError("Reached maximum read buffer size")
-            self._write_future.set_exception(iostream.StreamClosedError())
+            future = self._write_future = Future()
-                self._write_future = Future()
+                future = self._write_future = Future()
-        return self._write_future
+        return future
-        self.get(path, include_body=False)
+        return self.get(path, include_body=False)
-            start = end = size = None
+            start = end = None
-        or on ``HEAD`` requests.
+        This method may be overridden by subclasses.
-        response2 = self.fetch("/static/robots.txt", headers={
+        response1 = self.get_and_head("/static/robots.txt")
-        response2 = self.fetch("/static/robots.txt", headers={
+        response1 = self.get_and_head("/static/robots.txt")
-        response = self.fetch("/static/robots.txt", headers={
+        response = self.get_and_head("/static/robots.txt", headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt')
+        response = self.get_and_head('/static/robots.txt')
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/robots.txt', headers={
+        response = self.get_and_head('/static/robots.txt', headers={
-        response = self.fetch('/static/blarg')
+        response = self.get_and_head('/static/blarg')
-            if include_body:
+            start = end = size = None
-        if not include_body:
+        else:
-        be called if a partial result is requested from `get_content`
+        be called if a partial result is requested from `get_content`,
-                self.arguments.setdefault(k, []).extend(v)
+        parse_body_arguments(
-"""A special object which may be yielded to allow the IOLoop to run for
+    """A special object which may be yielded to allow the IOLoop to run for
-
+
-                        max_bytes=self.params.max_header_size)
+                b"\r?\n\r?\n",
-                    self._request_start_line.method == 'HEAD'):
+                        self._request_start_line.method == 'HEAD'):
-                    not self._write_finished):
+                        not self._write_finished):
-                not self.stream.closed()):
+                    self.stream is not None and
-            not self.stream.closed()):
+                self._expected_content_remaining != 0 and
-                self.error = HTTPError(self.code, message=self.reason, 
+                self.error = HTTPError(self.code, message=self.reason,
-            address is not None):
+                address is not None):
-    class SSLError(Exception): pass
+    class SSLError(Exception):
-                                   self.max_buffer_size//2)
+                                   self.max_buffer_size // 2)
-                    errno_from_exception(self.error) in _ERRNO_CONNRESET):
+                        errno_from_exception(self.error) in _ERRNO_CONNRESET):
-                    self._read_buffer_size >= target_bytes):
+                        self._read_buffer_size >= target_bytes):
-            size > self._read_max_bytes):
+                size > self._read_max_bytes):
-            self._read_buffer or self._write_buffer):
+                self._write_callback or self._write_future or
-        logging.ERROR:      1,  # Red
+        logging.DEBUG: 4,  # Blue
-            af == socket.AF_INET6 and sockaddr[3] != 0):
+                af == socket.AF_INET6 and sockaddr[3] != 0):
-    def set_close_exec(fd): pass
+    def set_close_exec(fd):
-                    self.request.body_producer is None):
+                        self.request.body_producer is None):
-                    self.request.body_producer is not None):
+                        self.request.body_producer is not None):
-                   (('?' + self.parsed.query) if self.parsed.query else ''))
+                    (('?' + self.parsed.query) if self.parsed.query else ''))
-
+
-                                (operator, allowed_parents))
+                                 (operator, allowed_parents))
-                                         future)
+                                        future)
-         # in fetch_chunk_sizes are as specific as we can get.
+        self.fetch_chunk_sizes(body=self.compress(self.BODY),
-        response = self.fetch('/buffered', method='PUT', body=b'a'*4096)
+        response = self.fetch('/buffered', method='PUT', body=b'a' * 4096)
-        response = self.fetch('/streaming', method='PUT', body=b'a'*4096)
+        response = self.fetch('/streaming', method='PUT', body=b'a' * 4096)
-            response = self.fetch('/buffered', method='PUT', body=b'a'*10240)
+            response = self.fetch('/buffered', method='PUT', body=b'a' * 10240)
-                                  body_producer=lambda write: write(b'a'*10240))
+                                  body_producer=lambda write: write(b'a' * 10240))
-            response = self.fetch('/streaming', method='PUT', body=b'a'*10240)
+            response = self.fetch('/streaming', method='PUT', body=b'a' * 10240)
-                                  body_producer=lambda write: write(b'a'*10240))
+                                  body_producer=lambda write: write(b'a' * 10240))
-                              body=b'a'*10240)
+                              body=b'a' * 10240)
-                              body_producer=lambda write: write(b'a'*10240))
+                              body_producer=lambda write: write(b'a' * 10240))
-            stream.write(b'a'*10240)
+            stream.write(b'a' * 10240)
-                         })
+                             })
-                              'foo', '12345678', timestamp),
+                                 'foo', '12345678', timestamp),
-                              'foo', '1234', b'5678' + timestamp),
+                                 'foo', '1234', b'5678' + timestamp),
-                not self._prepared_future.done()):
+                    not self._prepared_future.done()):
-                                     **self.handler_kwargs)
+                                          **self.handler_kwargs)
-def decode_signed_value(secret, name, value, max_age_days=31, clock=None,min_version=None):
+
-        if rest[n:n+1] != b'|':
+        if rest[n:n + 1] != b'|':
-        rest = rest[n+1:]
+        rest = rest[n + 1:]
-    os.environ.get('TORNADO_EXTENSION') == '0'):
+        os.environ.get('TORNADO_EXTENSION') == '0'):
-            self._expected_content_remaining != 0):
+                self._expected_content_remaining != 0):
-from tornado.iostream import IOStream, SSLIOStream, StreamClosedError
+from tornado.iostream import StreamClosedError
-from tornado.iostream import IOStream, SSLIOStream
+from tornado.iostream import IOStream
-            response = self.fetch(url)
+        for req_url in urls:
-            response = self.fetch(url)
+        for req_url in urls:
-            raise
+        sockets = bind_sockets(None, 'localhost', family)
-    Takes a list of ``Tasks`` or other ``YieldPoints`` and returns a list of
+    Takes a list of ``YieldPoints`` or ``Futures`` and returns a list of
-    a list of ``YieldPoints``.
+    a list of ``YieldPoints`` or a mixture of ``YieldPoints`` and ``Futures``.
-            yielded = Multi(yielded)
+        if isinstance(yielded, list):
-    def test_multi_delayed(self):
+    # The following tests explicitly run with both gen.Multi
-            responses = yield [
+            responses = yield gen.Multi([
-            ]
+            ])
-    def test_multi_dict_delayed(self):
+    def test_multi_yieldpoint_dict_delayed(self):
-            responses = yield dict(
+            responses = yield gen.Multi(dict(
-            )
+            ))
-                              host, ssl_options, max_buffer_size))
+            functools.partial(self._create_stream, max_buffer_size))
-        return stream.connect(addr, server_hostname=host)
+    def _create_stream(self, max_buffer_size, af, addr):
-from tornado.ioloop import IOLoop
+import certifi
-                                     **ssl_options)
+                                     **_server_ssl_options())
-            print(socket.getaddrinfo('localhost', 0))
+            print(socket.getaddrinfo('localhost', 0, socket.AF_UNSPEC, socket.SOCK_STREAM, 0, socket.AI_PASSIVE))
-        sockets = bind_sockets(None, 'localhost', family)
+        try:
-                reason=info['headers'].get("x-http-reason", None),
+                reason=info['headers'].get("X-Http-Reason", None),
-        except AssertionError:
+            header_line = "X-Http-Reason: %s" % reason
-    assert match
+    if not match:
-                reason=info['headers'].get("reason", None),
+                reason=info['headers'].get("x-http-reason", None),
-            header_line = "Reason: %s" % reason
+            header_line = "X-HTTP-Reason: %s" % reason
-            pass
+            return
-class Task(YieldPoint):
+def Task(func, *args, **kwargs):
-        return self.runner.pop_result(self.key)
+    .. versionchanged:: 3.3
-        return stack_context.wrap(inner)
+        return stack_context.wrap(_argument_adapter(
-        # yield point.
+        # YieldPoint (i.e. not a Future).
-            yield gen.Task(self.io_loop.add_callback)
+            (yield gen.Callback(1))()
-            yield gen.Task(self.io_loop.add_callback)
+            (yield gen.Callback(1))()
-from tornado.test.util import unittest, skipOnTravis
+from tornado.test.util import unittest
-        with self.assertRaises(IOError) as cm:
+        with self.assertRaises(IOError):
-                       for sockaddr in socket.getaddrinfo('localhost', 0))
+        Resolver().resolve('localhost', 0, callback=self.stop)
-                future.set_exception(self.error or StreamClosedError())
+                if (isinstance(self.error, (socket.error, IOError)) and
-                            self.socket.fileno(), errno.errorcode[err])
+            if self._connect_future is None:
-                # so restrict to ipv4 by default.
+            if request.allow_ipv6 is False:
-        self.http_client.fetch(url, self.stop)
+        # ipv6 is currently enabled by default but can be disabled
-        self.http_client.fetch(url, self.stop, allow_ipv6=True)
+        self.http_client.fetch(url, self.stop)
-from tornado.testing import AsyncTestCase, bind_unused_port, gen_test, ExpectLog
+from tornado.testing import AsyncTestCase, bind_unused_port, gen_test
-            self.do_test_connect(socket.AF_INET, 'localhost')
+        self.do_test_connect(socket.AF_INET, 'localhost')
-            self.do_test_connect(socket.AF_INET6, 'localhost')
+        self.do_test_connect(socket.AF_INET6, 'localhost')
-                yield self.client.connect('127.0.0.1', port)
+        with self.assertRaises(IOError):
-        this method returns a `.Future`.
+        it will be called with no arguments when the connection is
-            future.set_result(None)
+            future.set_result(self)
-        yield stream.connect(addr, server_hostname=host)
+        connector = _Connector(
-    def _create_stream(self, af, ssl_options, max_buffer_size):
+    def _create_stream(self, host, ssl_options, max_buffer_size, af, addr):
-                            max_buffer_size=max_buffer_size)
+            stream = IOStream(socket.socket(af),
-                               max_buffer_size=max_buffer_size)
+            stream = SSLIOStream(socket.socket(af),
-        yield stream.connect(("localhost", self.get_http_port()))
+        connect_result = yield stream.connect(
-from tornado.test.util import unittest, skipOnTravis
+from tornado.test.util import skipOnTravis, skipIfNoIPv6
-    @unittest.skipIf(not socket.has_ipv6, 'ipv6 support not present')
+    @skipIfNoIPv6
-from tornado.tcpclient import TCPClient
+from tornado.netutil import bind_sockets, Resolver
-    def __init__(self):
+    def __init__(self, family):
-        self.add_socket(socket)
+        sockets = bind_sockets(None, 'localhost', family)
-        self.port = self.server.port
+        self.server = None
-        self.server.stop()
+        self.stop_server()
-        stream = yield self.client.connect('127.0.0.1', self.port)
+    def do_test_connect(self, family, host):
-        self.assertTrue(all(s.getsockname()[1] == port for s in sockets[1:]))
+        try:
-                except iostream.StreamClosedError:
+                except (iostream.StreamClosedError,
-                future.set_exception(StreamClosedError())
+                future.set_exception(self.error or StreamClosedError())
-                    self._handle_connect()
+from tornado.tcpclient import TCPClient
-                        final_callback, self.max_buffer_size, self.resolver,
+                        final_callback, self.max_buffer_size, self.tcp_client,
-                 final_callback, max_buffer_size, resolver,
+                 final_callback, max_buffer_size, tcp_client,
-        self.resolver = resolver
+        self.tcp_client = tcp_client
-            self.resolver.resolve(host, port, af, callback=self._on_resolve)
+            self.tcp_client.connect(host, port, af=af,
-        if self.parsed.scheme == "https":
+    def _get_ssl_options(self, scheme):
-                            max_buffer_size=self.max_buffer_size)
+            return ssl_options
-    def _on_connect(self):
+    def _on_connect(self, stream):
-from tornado.log import gen_log
+from tornado.log import gen_log, app_log
-            response = self.wait()
+            # TODO: this should go to gen_log, not app_log.  See TODO
-from tornado.netutil import Resolver
+from tornado.tcpclient import TCPClient
-        self.resolver = Resolver(io_loop=io_loop)
+        self.tcp_client = TCPClient(io_loop=io_loop)
-            104857600, self.resolver, 65536)
+            104857600, self.tcp_client, 65536)
-# in to modules that are supposed to work on app engine.
+# Most of our tests depend on IOLoop, which is not usable on app engine.
-    #'tornado.iostream.doctests',
+    'tornado.iostream.doctests',
-    #'tornado.test.import_test',
+    'tornado.test.import_test',
-import ssl
+try:
-import ssl
+try:
-import multiprocessing
+    import multiprocessing
-import ssl
+    import ssl
-import ssl
+try:
-    <https://github.com/tornadoweb/tornado/tree/master/demos/appengine>`_
+    <https://github.com/tornadoweb/tornado/tree/stable/demos/appengine>`_
-            result = f(self)
+        def pre_coroutine(self, *args, **kwargs):
-        def post_coroutine(self):
+        def post_coroutine(self, *args, **kwargs):
-                    functools.partial(coro, self), timeout=timeout)
+                    functools.partial(coro, self, *args, **kwargs),
-            header_line = "Reason: %s" % m.group(1)
+        try:
-# Please see https://github.com/facebook/tornado/pull/706
+# Please see https://github.com/tornadoweb/tornado/pull/706
-                # https://github.com/facebook/tornado/pull/750
+                # https://github.com/tornadoweb/tornado/pull/750
-    <https://github.com/facebook/tornado/tree/master/demos/appengine>`_
+    <https://github.com/tornadoweb/tornado/tree/master/demos/appengine>`_
-                # for unbounded delimited reads.
+                # this loop.  We can't just call read_from_buffer here
-            self._read_to_buffer_loop()
+            pos = self._read_to_buffer_loop()
-        if self._read_from_buffer():
+        if pos is not None:
-        if self._read_from_buffer():
+        self._run_streaming_callback()
-            self._read_to_buffer_loop()
+            pos = self._read_to_buffer_loop()
-        if self._read_from_buffer():
+        if pos is not None:
-        """
+    def _run_streaming_callback(self):
-            return True
+            return num_bytes
-                        return True
+                        return loc + delimiter_len
-                        return True
+                        return m.end()
-        return False
+        return None
-            yield self._finish_future
+            # If we're waiting for the application to produce an asynchronous
-        self.stream.close()
+        if self.stream is not None:
-            elif self._read_buffer_size == 0:
+            elif (self._read_buffer_size == 0 and
-        self.assertEqual(server._state, IOLoop.READ | IOLoop.ERROR)
+        self.stream.set_close_callback(self.on_connection_close)
-            if not self.future.done():
+            if not self.future.done() or self.future is moment:
-        return
+        m = re.search("HTTP\/\S*\s*\d+\s*(.*?)\s*$", header_line)
-                self.error = HTTPError(self.code, response=self)
+                self.error = HTTPError(self.code, message=self.reason, 
-            self.stream.write(data, self._on_write_complete)
+            self._pending_write = self.stream.write(data)
-            self._write_future = Future()
+            future = self._write_future = Future()
-        return self._write_future
+                future = self._write_future = Future()
-                self.stream.write(b"0\r\n\r\n", self._on_write_complete)
+                self._pending_write = self.stream.write(b"0\r\n\r\n")
-            self._finish_request()
+        if self._pending_write is None:
-    def _on_write_complete(self):
+    def _on_write_complete(self, future):
-            callback()
+            self.stream.io_loop.add_callback(callback)
-    def _finish_request(self):
+    def _finish_request(self, future):
-            pass
+
-        elif origin and not self.check_origin(origin):
+        # according to check_origin. When the origin is None, we assume it
-
+        # Due to how stdlib's urlparse is implemented, urls without a //
-        if not self.check_origin(origin):
+        elif origin and not self.check_origin(origin):
-        '''Currently a failing test'''
+    def test_check_origin_valid2(self):
-        headers = {'Origin': 'http://somewhereelse.com'}
+        headers = {'Origin': 'localhost:%d' % port}
-        self.assertEqual(response, None)
+        self.assertEqual(response, 'hello')
-    def check_origin(self, allowed_origins=None):
+    def check_origin(self, origin):
-        since WebSockets don't have CORS headers.
+        By default, this checks to see that the host matches the origin
-        >>> self.check_origins(allowed_origins=['localhost'])
+        >>> self.check_origin(origin='localhost')
-        if(origin_header is None or host is None):
+        # When origin is None, assume it didn't come from a browser and we can
-            return True
+        host = self.request.headers.get("Host")
-        self.assertEqual(response, 'hello')
+        self.assertEqual(response, None)
-
+        since WebSockets don't have CORS headers.
-        if origin in allowed_origins:
+        if allowed_origins and origin in allowed_origins:
-        elif not self.same_origin():
+        if not self.check_origin():
-        return origin == host
+    def check_origin(self, allowed_origins=None):
-        origin_header = self.request.headers.get("Origin")
+
-        self.assertIs(fds[1], server_sock.fileno())
+        self.assertEqual(fds[1], server_sock.fileno())
-                # EWOULDBLOCK and EAGAIN indicate we have accepted every
+                # _ERRNO_WOULDBLOCK indicate we have accepted every
-                if errno_from_exception(e) in (errno.EWOULDBLOCK, errno.EAGAIN):
+                if errno_from_exception(e) in _ERRNO_WOULDBLOCK:
-version = "3.2"
+version = "3.2.1"
-version_info = (3, 2, 0, 0)
+version = "3.2.1"
-        version = 2
+        version = DEFAULT_SIGNED_VALUE_VERSION
-        min_version = 1
+        min_version = DEFAULT_SIGNED_VALUE_MIN_VERSION
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value, ErrorHandler, UIModule, MissingArgumentError
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature_v1, create_signed_value, decode_signed_value, ErrorHandler, UIModule, MissingArgumentError
-class SecureCookieTest(unittest.TestCase):
+# See SignedValueTest below for more.
-        self.assertEqual(handler.get_secure_cookie('foo'), b'bar')
+        handler.set_secure_cookie('foo', b'bar', version=1)
-        handler.set_secure_cookie('foo', binascii.a2b_hex(b'd76df8e7aefc'))
+        handler.set_secure_cookie('foo', binascii.a2b_hex(b'd76df8e7aefc'),
-            _create_signature(handler.application.settings["cookie_secret"],
+            _create_signature_v1(handler.application.settings["cookie_secret"],
-            _create_signature(handler.application.settings["cookie_secret"],
+            _create_signature_v1(handler.application.settings["cookie_secret"],
-            self.assertTrue(handler.get_secure_cookie('foo') is None)
+            self.assertTrue(
-        self.assertEqual(handler.get_secure_cookie('foo'), b'\xe9')
+        handler.set_secure_cookie('foo', b'\xe9', version=1)
-def create_signed_value(secret, name, value, version=None):
+def create_signed_value(secret, name, value, version=None, clock=None):
-        version = 1
+        version = 2
-        signature = _create_signature(secret, name, value, timestamp)
+        signature = _create_signature_v1(secret, name, value, timestamp)
-_signed_value_version_re = re.compile(r"^([1-9][0-9]*)\|(.*)$")
+_signed_value_version_re = re.compile(br"^([1-9][0-9]*)\|(.*)$")
-def decode_signed_value(secret, name, value, max_age_days=31, min_version=None):
+def decode_signed_value(secret, name, value, max_age_days=31, clock=None,min_version=None):
-    if min_version > 1:
+    if min_version > 2:
-                         (version, min_version))
+        return None
-        return _decode_signed_value_v1(secret, name, value, max_age_days)
+        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)
-        raise ValueError("Unsupported signed value version %r" % value)
+        return None
-def _decode_signed_value_v1(secret, name, value, max_age_days):
+def _decode_signed_value_v1(secret, name, value, max_age_days, clock):
-    signature = _create_signature(secret, name, parts[0], parts[1])
+    signature = _create_signature_v1(secret, name, parts[0], parts[1])
-    if timestamp < time.time() - max_age_days * 86400:
+    if timestamp < clock() - max_age_days * 86400:
-    if timestamp > time.time() + 31 * 86400:
+    if timestamp > clock() + 31 * 86400:
-def _create_signature(secret, *parts):
+def _decode_signed_value_v2(secret, name, value, max_age_days, clock):
-    def set_secure_cookie(self, name, value, expires_days=30, **kwargs):
+    def set_secure_cookie(self, name, value, expires_days=30, version=None,
-        self.set_cookie(name, self.create_signed_value(name, value),
+        self.set_cookie(name, self.create_signed_value(name, value,
-    def create_signed_value(self, name, value):
+    def create_signed_value(self, name, value, version=None):
-                                   name, value)
+                                   name, value, version=version)
-    def get_secure_cookie(self, name, value=None, max_age_days=31):
+    def get_secure_cookie(self, name, value=None, max_age_days=31,
-                                   name, value, max_age_days=max_age_days)
+                                   name, value, max_age_days=max_age_days,
-    return value
+def create_signed_value(secret, name, value, version=None):
-def decode_signed_value(secret, name, value, max_age_days=31):
+def decode_signed_value(secret, name, value, max_age_days=31, min_version=None):
-    build_errors = (CCompilerError, DistutilsExecError, DistutilsPlatformError)
+    build_errors = (CCompilerError, DistutilsExecError, DistutilsPlatformError,
-                message = str(self.stream.error)
+                raise self.stream.error
-        with self.assertRaises(HTTPError) as cm:
+        with self.assertRaises(IOError) as cm:
-        with self.assertRaises(HTTPError) as cm:
+        with self.assertRaises(IOError) as cm:
-        self.assertAlmostEqual(time.time(), self.stop_time, places=2)
+        delta = time.time() - self.stop_time
-        kwargs['install_requires'] = ['backports.ssl_match_hostname']
+        install_requires.append('backports.ssl_match_hostname')
-_DEFAULT_CA_CERTS = os.path.dirname(__file__) + '/ca-certificates.crt'
+try:
-                ssl_options["ca_certs"] = _DEFAULT_CA_CERTS
+                ssl_options["ca_certs"] = _default_ca_certs()
-from tornado.simple_httpclient import SimpleAsyncHTTPClient, _DEFAULT_CA_CERTS
+from tornado.simple_httpclient import SimpleAsyncHTTPClient, _default_ca_certs
-        open(_DEFAULT_CA_CERTS).close()
+        open(_default_ca_certs()).close()
-                      has_body=True):
+    def write_headers(self, start_line, headers, chunk=None, callback=None):
-                has_body and
+                start_line.method in ('POST', 'PUT', 'PATCH') and
-                      has_body=True):
+    def write_headers(self, start_line, headers, chunk=None, callback=None):
-                      self.request.body_producer is not None))
+        self.connection.write_headers(start_line, self.request.headers)
-                      has_body=True):
+    def write_headers(self, start_line, headers, chunk=None, callback=None):
-        """Implements `.HTTPConnection.write`."""
+        """Implements `.HTTPConnection.write`.
-class HTTP1Connection(object):
+class HTTP1Connection(httputil.HTTPConnection):
-            that no further writes will be coming.
+        :arg bool has_body: may be false to indicate that this message
-class _WSGIConnection(object):
+class _WSGIConnection(httputil.HTTPConnection):
-    def write_headers(self, start_line, headers, chunk=None, callback=None):
+    def write_headers(self, start_line, headers, chunk=None, callback=None,
-    def __init__(self, no_keep_alive=False, protocol=None, chunk_size=None,
+    def __init__(self, no_keep_alive=False, chunk_size=None,
-        self.protocol = protocol
+        self.protocol = protocol
-                                      self.conn_params.protocol)
+                                      self.protocol)
-                no_keep_alive=True, protocol=self.parsed.scheme,
+                no_keep_alive=True,
-    """Handles a connection to an HTTP client, executing HTTP requests.
+    """Implements the HTTP/1.x protocol.
-    until the HTTP conection is closed.
+    This class can be on its own for clients, or via `HTTP1ServerConnection`
-        recommended approach prior to Tornado 3.0).
+        .. deprecated:: 3.3
-        """Writes a chunk of output to the stream."""
+        """Implements `.HTTPConnection.write`."""
-        """Finishes the request."""
+        """Implements `.HTTPConnection.finish`."""
-           TODO: document the interface.
+           It is called with one argument, a ``write`` function, and should
-           encoding on requests.
+           encoding on requests.  New in Tornado 3.3
-    requested::
+    A server is defined by either a request callback that takes a
-           request.finish()
+           request.connection.write_headers(
-    of HTTP responses are required.
+    Applications should use the methods of `.HTTPConnection` to write
-    constructor.
+    requests ``Connection: keep-alive``).
-        """Returns True if this request supports HTTP/1.1 semantics"""
+        """Returns True if this request supports HTTP/1.1 semantics.
-        """Writes the given chunk to the response stream."""
+        """Writes the given chunk to the response stream.
-        """Finishes this HTTP request on the open connection."""
+        """Finishes this HTTP request on the open connection.
-    """Exception class for errors in HTTP output."""
+    """Exception class for errors in HTTP output.
-        """Clear the global `IOLoop` instance."""
+        """Clear the global `IOLoop` instance.
-    therefore faster for use with single-threaded event loops.
+    A ``Future`` encapsulates the result of an asynchronous
-        `~concurrent.futures.Future.set_exception`.
+        """Sets the exception information of a ``Future.``
-    non-blocking and asynchronous).
+    All of the methods take an optional ``callback`` argument and return a
-        """Run ``callback`` when we read the given regex pattern.
+        """Asynchronously read until we have matched the given regex.
-        matched the regex and anything that came before it) as an argument.
+        The result includes the data that matches the regex and anything
-        """Run ``callback`` when we read the given delimiter.
+        """Asynchronously read until we have found the given delimiter.
-        as an argument.
+        .. versionchanged:: 3.3
-        """Run callback when we read the given number of bytes.
+        """Asynchronously read a number of bytes.
-        the data as an argument.
+        of data as they become available, and the final result will be empty.
-        """Reads all data from the socket until it is closed.
+        """Asynchronously reads all data from the socket until it is closed.
-        a ``streaming_callback`` is not used.
+        of data as they become available, and the final result will be empty.
-        """Write the given data to this stream.
+        """Asynchronously write the given data to this stream.
-        """Call the given callback when the stream is closed."""
+        """Call the given callback when the stream is closed.
-        it will be called when the connection is completed.
+        it will be called when the connection is completed; if not
-            self._write_callback = stack_context.wrap(callback)
+        if self.stream.closed():
-            self._write_callback = stack_context.wrap(callback)
+        if self.stream.closed():
-        yield gen.Task(write, b'1234')
+        yield write(b'1234')
-        yield gen.Task(write, b'5678')
+        yield write(b'5678')
-        # was any output.
+        # was any output.  The gen.Task and direct yield forms are
-        yield gen.Task(self.flush)  # empty flush
+        yield self.flush()  # flushes the "o"
-                                                  chunk, callback=callback)
+            return self.request.connection.write_headers(
-                self.request.connection.write(chunk, callback=callback)
+                return self.request.connection.write(chunk, callback=callback)
-                if headers.get("Expect") == "100-continue":
+                if (headers.get("Expect") == "100-continue" and
-                 client_key=None, client_cert=None, body_producer=None):
+                 client_key=None, client_cert=None, body_producer=None,
-                    self._read_response()
+                    if start_read:
-        self._read_response()
+        if start_read:
-from tornado.web import RequestHandler, Application, asynchronous, url
+from tornado.web import RequestHandler, Application, asynchronous, url, stream_request_body
-            lambda f: f.result())
+        self.stream.io_loop.add_future(self._serving_future,
-                return
+        try:
-        return _ServerRequestAdapter(self, connection)
+    def start_request(self, server_conn, request_conn):
-    def start_request(self, connection):
+    def start_request(self, server_conn, request_conn):
-                ('/early_return', EarlyReturnHandler)]
+                ('/early_return', EarlyReturnHandler),
-        pass
+        if _has_stream_request_body(self.__class__):
-                yield self.request.body
+                try:
-    """Reads an HTTP response from `stream` and runs callback with its body."""
+    """Reads an HTTP response from `stream` and runs callback with its
-            callback(b''.join(chunks))
+            callback((self.headers, b''.join(chunks)))
-            return self.wait()
+            headers, body = self.wait()
-        response = self.wait()
+        headers, response = self.wait()
-        self.stream.read_bytes(int(headers['Content-Length']), self.stop)
+        self.headers = self.read_headers()
-            response = yield gen.Task(read_stream_body, stream)
+            headers, response = yield gen.Task(read_stream_body, stream)
-            "gzip" in request.headers.get("Accept-Encoding", "")
+        self._gzipping = "gzip" in request.headers.get("Accept-Encoding", "")
-    def __init__(self, stream, address, is_client, params=None):
+    def __init__(self, stream, is_client, params=None, context=None):
-        self.address = address
+        self.context = context
-                                         self.address)
+                            gen_log.info("Timeout reading body from %s",
-                         self.address, e)
+            gen_log.info("Malformed HTTP message from %s: %s",
-    def __init__(self, stream, address, params=None):
+    def __init__(self, stream, params=None, context=None):
-        self.address = address
+        self.context = context
-                                   self.params)
+            conn = HTTP1Connection(self.stream, False,
-            params=self.conn_params)
+            stream, self.conn_params, context)
-            self._chunks = None
+class _HTTPRequestContext(object):
-            self._chunks = []
+            self.address_family = None
-        self._orig_protocol = self.connection.protocol
+    def __str__(self):
-        ip = headers.get("X-Forwarded-For", self.connection.remote_ip)
+        ip = headers.get("X-Forwarded-For", self.remote_ip)
-            self.connection.remote_ip = ip
+            self.remote_ip = ip
-                                    self.connection.protocol))
+                                    self.protocol))
-            self.connection.protocol = proto_header
+            self.protocol = proto_header
-        self.connection.protocol = self._orig_protocol
+        self.remote_ip = self._orig_remote_ip
-            self._apply_xheaders(headers)
+            self.connection.context._apply_xheaders(headers)
-            self._unapply_xheaders()
+            self.connection.context._unapply_xheaders()
-                 files=None, connection=None, start_line=None):
+                 body=None, host=None, files=None, connection=None,
-        self.protocol = protocol or getattr(connection, 'protocol', "http")
+        context = getattr(connection, 'context', None)
-            self.stream, self._sockaddr, True,
+            self.stream, True,
-                use_gzip=self.request.use_gzip))
+                use_gzip=self.request.use_gzip),
-    conn = HTTP1Connection(stream, None, is_client=True)
+    conn = HTTP1Connection(stream, True)
-    def __init__(self, method, start_response):
+    def __init__(self, method, start_response, context):
-        connection = _WSGIConnection(method, start_response)
+        connection = _WSGIConnection(method, start_response,
-            headers=headers, body=body, remote_ip=remote_ip, protocol=protocol,
+            method, uri, "HTTP/1.1", headers=headers, body=body,
-    def __init__(self, stream, address, is_client, params=None, method=None):
+    def __init__(self, stream, address, is_client, params=None):
-        self._method = method
+        # _write_finished is set to True when finish() has been called,
-        self._clear_request_state()
+        self._clear_callbacks()
-        self._finish_future = None
+        # Save the start lines after we read or write them; they
-        self._chunking = None
+        self._response_start_line = None
-            self._finish_future = Future()
+                self._response_start_line = start_line
-            self._request_start_line = start_line
+                self._request_start_line = start_line
-                start_line, headers)
+            header_future = delegate.headers_received(start_line, headers)
-                if self._method == 'HEAD':
+                if (self._request_start_line is not None and
-            if not self._request_finished or self.is_client:
+            self._read_finished = True
-        """Clears the per-request state.
+    def _clear_callbacks(self):
-        facilitate garbage collection in cpython).
+        This allows the request handler to be garbage collected more
-        if self._finish_future is not None and not self._finish_future.done():
+        if not self._finish_future.done():
-        self._clear_request_state()
+        self._clear_callbacks()
-        self._clear_request_state()
+        self._clear_callbacks()
-            self._chunking = (
+            self._chunking_output = (
-            self._chunking = (
+            self._response_start_line = start_line
-        if self._chunking:
+        if self._chunking_output:
-        if self._chunking and chunk:
+        if self._chunking_output and chunk:
-        if self._chunking:
+        if self._chunking_output:
-        self._request_finished = True
+        self._write_finished = True
-        if self._reading:
+        if not self._read_finished:
-        if self._request_finished and not self.stream.writing():
+        if self._write_finished and not self.stream.writing():
-        if self._disconnect_on_finish:
+        self._clear_callbacks()
-        if self._finish_future is not None and not self._finish_future.done():
+        if not self._finish_future.done():
-            if not self._request_finished or self.is_client:
+            if not self._write_finished or self.is_client:
-                if not self._request_finished or self.is_client:
+                if not self._write_finished or self.is_client:
-        if not self._request_finished or self.is_client:
+        if not self._write_finished or self.is_client:
-                                   params=self.params)
+            conn = HTTP1Connection(self.stream, self.address, False,
-            params=HTTP1ConnectionParameters(
+            self.stream, self._sockaddr, True,
-            method=self.request.method)
+                use_gzip=self.request.use_gzip))
-                 max_body_size=None, body_timeout=None):
+    def __init__(self, stream, address, is_client, params=None, method=None):
-        self.no_keep_alive = no_keep_alive
+        if stream.socket is not None:
-            self.protocol = protocol
+        if self.params.protocol:
-        self._default_body_timeout = body_timeout
+        self._max_body_size = (self.params.max_body_size or
-            lambda f: f.result())
+    def read_response(self, delegate):
-        self._body_timeout = self._default_body_timeout
+    def _read_message(self, delegate):
-            if self._header_timeout is None:
+                        max_bytes=self.params.max_header_size)
-                        self.stream.io_loop.time() + self._header_timeout,
+                        self.stream.io_loop.time() + self.params.header_timeout,
-            header_future = self.message_delegate.headers_received(
+            header_future = delegate.headers_received(
-                if method == 'HEAD':
+                if self._method == 'HEAD':
-                                             method=method)
+                    yield self._read_message(delegate)
-                body_future = self._read_body(headers)
+                body_future = self._read_body(headers, delegate)
-            self.message_delegate.finish()
+            if not self._request_finished or self.is_client:
-        # input body.
+        # divert any remaining data away from the delegate and
-        if self.no_keep_alive:
+        if self.params.no_keep_alive:
-        if self._finish_future is not None:
+        if self._finish_future is not None and not self._finish_future.done():
-    def _read_body(self, headers):
+    def _read_body(self, headers, delegate):
-            return self._read_fixed_body(content_length)
+            return self._read_fixed_body(content_length, delegate)
-            return self._read_chunked_body()
+            return self._read_chunked_body(delegate)
-            return self._read_body_until_close()
+            return self._read_body_until_close(delegate)
-    def _read_fixed_body(self, content_length):
+    def _read_fixed_body(self, content_length, delegate):
-                min(self._chunk_size, content_length), partial=True)
+                min(self.params.chunk_size, content_length), partial=True)
-            yield gen.maybe_future(self.message_delegate.data_received(body))
+            if not self._request_finished or self.is_client:
-    def _read_chunked_body(self):
+    def _read_chunked_body(self, delegate):
-                    min(bytes_to_read, self._chunk_size), partial=True)
+                    min(bytes_to_read, self.params.chunk_size), partial=True)
-                    self.message_delegate.data_received(chunk))
+                if not self._request_finished or self.is_client:
-    def _read_body_until_close(self):
+    def _read_body_until_close(self, delegate):
-        self.message_delegate.data_received(body)
+        if not self._request_finished or self.is_client:
-from tornado.http1connection import HTTP1Connection
+from tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters
-        self.max_body_size = max_body_size
+        self.conn_params = HTTP1ConnectionParameters(
-        conn.start_serving(self, gzip=self.gzip)
+        conn = HTTP1ServerConnection(
-from tornado.http1connection import HTTP1Connection
+from tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters
-            max_header_size=self.max_header_size)
+            params=HTTP1ConnectionParameters(
-                                          use_gzip=self.request.use_gzip),
+            self.connection.read_response(self),
-    conn.read_response(Delegate(), method='GET')
+    conn.read_response(Delegate())
-                           max_buffer_size=max_buffer_size)
+                           max_buffer_size=max_buffer_size,
-                 read_chunk_size=4096):
+                 read_chunk_size=None):
-        self.read_chunk_size = read_chunk_size
+        # A chunk size that is too close to max_buffer_size can cause
-        if self._read_buffer_size >= self.max_buffer_size:
+        if self._read_buffer_size > self.max_buffer_size:
-    def __init__(self, io_loop=None, ssl_options=None, max_buffer_size=None):
+    def __init__(self, io_loop=None, ssl_options=None, max_buffer_size=None,
-                stream = SSLIOStream(connection, io_loop=self.io_loop, max_buffer_size=self.max_buffer_size)
+                stream = SSLIOStream(connection, io_loop=self.io_loop,
-                stream = IOStream(connection, io_loop=self.io_loop, max_buffer_size=self.max_buffer_size)
+                stream = IOStream(connection, io_loop=self.io_loop,
-                 max_body_size=None, **kwargs):
+                 max_body_size=None, max_buffer_size=None):
-                           **kwargs)
+                           max_buffer_size=max_buffer_size)
-                 max_header_size=None, header_timeout=None):
+                 max_header_size=None, header_timeout=None,
-                    yield body_future
+                    if self._body_timeout is None:
-            if content_length > self.stream.max_buffer_size:
+            if content_length > self._max_body_size:
-                 idle_connection_timeout=None, **kwargs):
+                 idle_connection_timeout=None, body_timeout=None,
-            header_timeout=self.idle_connection_timeout)
+            header_timeout=self.idle_connection_timeout,
-from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, ExpectLog, gen_test
-from tornado.web import Application, RequestHandler, asynchronous
+from tornado.web import Application, RequestHandler, asynchronous, stream_request_body
-    # on the input future, so cancelling it might disrupt other callers.
+    # It's tempting to optimize this by cancelling the input future on timeout
-                        lambda future: io_loop.remove_timeout(timeout_handle))
+    if isinstance(future, Future):
-                        datetime.timedelta(seconds=self._header_timeout),
+                        self.stream.io_loop.time() + self._header_timeout,
-            self.deadline = io_loop.time() + _Timeout.timedelta_to_seconds(deadline)
+            now = io_loop.time()
-    IOLoop.instance().add_callback(IOLoop.instance().stop)
+    IOLoop.instance().add_callback_from_signal(IOLoop.instance().stop)
-            self._expected_content_remaining != 0):
+            self._expected_content_remaining != 0 and
-            chunk_len = yield self.stream.read_until(b"\r\n")
+            chunk_len = yield self.stream.read_until(b"\r\n", max_bytes=64)
-            if state == self.io_loop.ERROR:
+            if state == self.io_loop.ERROR and self._read_buffer_size == 0:
-        self._maybe_add_error_listener()
+        # We couldn't satisfy the read inline, so either close the stream
-        if self._state is None and self._pending_callbacks == 0:
+        # This method is part of an optimization: to detect a connection that
-            else:
+            elif self._read_buffer_size == 0:
-            self.wait()
+            # Read one byte to make sure the client has received the data.
-            self.assertEqual(data, b"1234")
+            self.assertEqual(data, b"234")
-            self.wait()
+            client.read_bytes(1, self.stop)
-            self.assertEqual(b''.join(streaming_data), b"1234")
+            self.assertEqual(b''.join(streaming_data), b"234")
-            self._run_read_callback(self._consume(self._read_buffer_size))
+                self._run_read_callback(self._read_buffer_size, True)
-                                       self._consume(self._read_buffer_size))
+                    self._run_read_callback(self._read_buffer_size, True)
-                self._run_read_callback(self._consume(self._read_buffer_size))
+                self._run_read_callback(self._read_buffer_size, False)
-        self._streaming_callback = None
+    def _run_read_callback(self, size, streaming):
-            self._run_callback(callback, data)
+            future.set_result(self._consume(size))
-                               self._consume(bytes_to_consume))
+            self._run_read_callback(bytes_to_consume, True)
-            self._run_read_callback(self._consume(num_bytes))
+            self._run_read_callback(num_bytes, False)
-            # consume().
+            # _consume().
-                            self._consume(loc + delimiter_len))
+                        self._run_read_callback(loc + delimiter_len, False)
-                        self._run_read_callback(self._consume(m.end()))
+                        self._run_read_callback(m.end(), False)
-        return self._read_callback is not None
+        return self._read_callback is not None or self._read_future is not None
-                self._pending_callbacks -= 1
+            self._read_to_buffer_loop()
-                self._pending_callbacks -= 1
+            self._read_to_buffer_loop()
-    build_errors = (CCompilerError, DistutilsExecError, DistutilsPlatformError)
+    build_errors = (CCompilerError, DistutilsExecError, DistutilsPlatformError,
-        # Based on Zope async.py: http://svn.zope.org/zc.ngi/trunk/src/zc/ngi/async.py
+        # Based on Zope select_trigger.py:
-        `HTTPResponse`.  The ``Future`` wil raise an `HTTPError` if
+        `HTTPResponse`.  The ``Future`` will raise an `HTTPError` if
-    The result (success or failure) of ``a`` will be copied to ``b``.
+    The result (success or failure) of ``a`` will be copied to ``b``, unless
-from tornado.concurrent import Future, TracebackFuture, is_future
+from tornado.concurrent import Future, TracebackFuture, is_future, chain_future
-                 max_header_size=None):
+                 max_header_size=None, header_timeout=None):
-                max_bytes=self._max_header_size)
+            header_future = self.stream.read_until_regex(
-                 chunk_size=None, max_header_size=None, **kwargs):
+                 chunk_size=None, max_header_size=None,
-                               max_header_size=self.max_header_size)
+        conn = HTTP1Connection(
-from tornado.concurrent import return_future
+from tornado.concurrent import return_future, Future
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipOnTravis
-                 no_keep_alive=False, protocol=None, chunk_size=None):
+                 no_keep_alive=False, protocol=None, chunk_size=None,
-            header_data = yield self.stream.read_until_regex(b"\r?\n\r?\n")
+            header_data = yield self.stream.read_until_regex(
-                 chunk_size=None, **kwargs):
+                 chunk_size=None, max_header_size=None, **kwargs):
-                               chunk_size=self.chunk_size)
+                               chunk_size=self.chunk_size,
-                   resolver=None, defaults=None):
+                   resolver=None, defaults=None, max_header_size=None):
-                        final_callback, self.max_buffer_size, self.resolver)
+                        final_callback, self.max_buffer_size, self.resolver,
-                 final_callback, max_buffer_size, resolver):
+                 final_callback, max_buffer_size, resolver,
-            no_keep_alive=True, protocol=self.parsed.scheme)
+            no_keep_alive=True, protocol=self.parsed.scheme,
-            104857600, self.resolver)
+            104857600, self.resolver, 65536)
-    def read_until_regex(self, regex, callback=None):
+    def read_until_regex(self, regex, callback=None, max_bytes=None):
-        self._try_inline_read()
+        self._read_max_bytes = max_bytes
-    def read_until(self, delimiter, callback=None):
+    def read_until(self, delimiter, callback=None, max_bytes=None):
-        self._try_inline_read()
+        self._read_max_bytes = max_bytes
-from tornado.log import gen_log
+from tornado.log import gen_log, app_log
-        self._version = None
+        self._request_start_line = None
-            self._version = start_line.version
+            # write_header().
-        except httputil.HTTPMessageException as e:
+        except httputil.HTTPInputException as e:
-                self._version == 'HTTP/1.1' and
+                # TODO: should this use
-                                                data[eol:100])
+            raise httputil.HTTPInputException("Malformed HTTP headers: %r" %
-                raise httputil.HTTPMessageException("Content-Length too long")
+                raise httputil.HTTPInputException("Content-Length too long")
-    """Exception class for malformed HTTP requests or responses."""
+class HTTPInputException(Exception):
-        raise HTTPMessageException("Malformed HTTP request line")
+        raise HTTPInputException("Malformed HTTP request line")
-        raise HTTPMessageException(
+        raise HTTPInputException(
-            self.set_header("Content-Length", "7")
+            self.set_header("Content-Length", "5")
-    def test_multiple_content_length_accepted(self):
+    def xtest_multiple_content_length_accepted(self):
-    def __init__(self, start_response):
+    def __init__(self, method, start_response):
-        connection = _WSGIConnection(start_response)
+        connection = _WSGIConnection(method, start_response)
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        self.assertIn(self.expected_frame, tb)
+            self.fail("didn't get expected exception")
-            for i in range(1000):
+        for i in range(1000):
-        with self.assertRaises(ParseError):
+        try:
-        with self.assertRaises(ParseError):
+        try:
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        self.assertTrue("# test.html:2" in exc_stack)
+            self.fail("did not get expected exception")
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        self.assertTrue("# test.html:2" in exc_stack)
+            self.fail("did not get expected exception")
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        self.assertTrue('# sub.html:1' in exc_stack)
+            self.fail("did not get expected exception")
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        self.assertTrue("# sub.html:1 (via base.html:1)" in exc_stack)
+            self.fail("did not get expected exception")
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        exc_stack = traceback.format_exc()
+            self.fail("did not get expected exception")
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        self.assertTrue("# sub.html:4 (via base.html:1)" in exc_stack)
+            self.fail("did not get expected exception")
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        self.assertTrue("# c.html:1 (via b.html:1, a.html:1)" in exc_stack)
+            self.fail("did not get expected exception")
-        with self.assertRaises(ZeroDivisionError):
+        try:
-        with self.assertRaises(ioloop.TimeoutError):
+        try:
-            exc_stack)
+            self.fail("did not get expected exception")
-        with self.assertRaises(TwoArgException) as context:
+        try:
-        self.assertIs(context.exception, exc_info[1])
+            self.fail("didn't get expected exception")
-            self.message_delegate.headers_received(start_line, headers)
+            header_future = self.message_delegate.headers_received(
-            self.delegate.headers_received(start_line, headers)
+            return self.delegate.headers_received(start_line, headers)
-            self.delegate.data_received(chunk)
+            return self.delegate.data_received(chunk)
-            self.execute()
+            return self.execute()
-            self.handler.data_received(data)
+            return self.handler.data_received(data)
-                 no_keep_alive=False, protocol=None):
+                 no_keep_alive=False, protocol=None, chunk_size=None):
-                request_delegate = _GzipMessageDelegate(request_delegate)
+                request_delegate = _GzipMessageDelegate(request_delegate,
-            delegate = _GzipMessageDelegate(delegate)
+            delegate = _GzipMessageDelegate(delegate, self._chunk_size)
-        self.message_delegate.data_received(body)
+        while content_length > 0:
-            self.message_delegate.data_received(chunk[:-2])
+            crlf = yield self.stream.read_bytes(2)
-    def __init__(self, delegate):
+    def __init__(self, delegate, chunk_size):
-        return self._delegate.data_received(chunk)
+            compressed_data = chunk
-                 **kwargs):
+                 chunk_size=None, **kwargs):
-                               protocol=self.protocol)
+                               protocol=self.protocol,
-from tornado.escape import json_decode, utf8, _unicode, recursive_unicode, native_str
+from tornado.escape import json_decode, json_encode, utf8, _unicode, recursive_unicode, native_str
-from tornado.httputil import HTTPHeaders, HTTPMessageDelegate
+from tornado.httputil import HTTPHeaders, HTTPMessageDelegate, HTTPServerConnectionDelegate, ResponseStartLine
-    The interface is like that of `zlib.decompressobj` (without the
+    The interface is like that of `zlib.decompressobj` (without some of the
-    def decompress(self, value):
+    def decompress(self, value, max_length=None):
-        return self.decompressobj.decompress(value)
+        return self.decompressobj.unconsumed_tail
-    def read_bytes(self, num_bytes, callback=None, streaming_callback=None):
+    def read_bytes(self, num_bytes, callback=None, streaming_callback=None,
-            num_bytes = self._read_bytes
+        if (self._read_bytes is not None and
-    def __init__(self, stream, address, no_keep_alive=False, protocol=None):
+    def __init__(self, stream, address, is_client,
-                ret = yield self._read_message(request_delegate, False)
+                ret = yield self._read_message(request_delegate)
-        return self._read_message(delegate, True, method=method)
+        return self._read_message(delegate, method=method)
-    def _read_message(self, delegate, is_client, method=None):
+    def _read_message(self, delegate, method=None):
-            if is_client:
+            if self.is_client:
-            if is_client:
+            if self.is_client:
-                                             is_client, method=method)
+                                             method=method)
-                body_future = self._read_body(is_client, headers)
+                body_future = self._read_body(headers)
-            'Transfer-Encoding' not in headers)
+    def write_headers(self, start_line, headers, chunk=None, callback=None,
-        self._finish_future.set_result(None)
+        if self._finish_future is not None:
-    def _read_body(self, is_client, headers):
+    def _read_body(self, headers):
-        if is_client:
+        if self.is_client:
-                 client_key=None, client_cert=None):
+                 client_key=None, client_cert=None, body_producer=None):
-        :arg body: HTTP body to pass on the request
+        :arg body: HTTP request body as a string (byte or unicode; if unicode
-        conn = HTTP1Connection(stream, address=address,
+        conn = HTTP1Connection(stream, address=address, is_client=False,
-                if self.request.body is None:
+                if (self.request.body is None and
-                if self.request.body is not None:
+                if (self.request.body is not None or
-            self.stream, self._sockaddr,
+            self.stream, self._sockaddr, is_client=True,
-        self.connection.write_headers(start_line, self.request.headers)
+        self.connection.write_headers(
-    conn = HTTP1Connection(stream, None)
+    conn = HTTP1Connection(stream, None, is_client=True)
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipIfNoNetwork
-        try:
+        with self.assertRaises(ZeroDivisionError):
-            tb = traceback.extract_tb(sys.exc_info()[2])
+        tb = traceback.extract_tb(sys.exc_info()[2])
-        try:
+        with self.assertRaises(HTTPError) as context:
-        self.assertEqual(got_exception.response.code, 404)
+        self.assertEqual(context.exception.code, 404)
-            try:
+        with self.assertRaisesRegexp(RuntimeError, "\AIOLoop is closing\Z"):
-        try:
+        with self.assertRaises(ParseError):
-        try:
+        with self.assertRaises(ParseError):
-        try:
+        with self.assertRaises(ZeroDivisionError):
-            exc_stack = traceback.format_exc()
+        exc_stack = traceback.format_exc()
-        try:
+        with self.assertRaises(ZeroDivisionError):
-            exc_stack = traceback.format_exc()
+        exc_stack = traceback.format_exc()
-        try:
+        with self.assertRaises(ZeroDivisionError):
-            exc_stack = traceback.format_exc()
+        exc_stack = traceback.format_exc()
-        try:
+        with self.assertRaises(ZeroDivisionError):
-            exc_stack = traceback.format_exc()
+        exc_stack = traceback.format_exc()
-        try:
+        with self.assertRaises(ZeroDivisionError):
-            exc_stack = traceback.format_exc()
+        exc_stack = traceback.format_exc()
-        try:
+        with self.assertRaises(ZeroDivisionError):
-            exc_stack = traceback.format_exc()
+        exc_stack = traceback.format_exc()
-        try:
+        with self.assertRaises(ZeroDivisionError):
-            exc_stack = traceback.format_exc()
+        exc_stack = traceback.format_exc()
-        try:
+        with self.assertRaises(ZeroDivisionError):
-        try:
+        with self.assertRaises(ioloop.TimeoutError):
-            exc_stack = traceback.format_exc()
+        exc_stack = traceback.format_exc()
-        try:
+        with self.assertRaises(TwoArgException) as context:
-        self.assertIs(got_exception, exc_info[1])
+        self.assertIs(context.exception, exc_info[1])
-            self.assertIn(self.expected_frame, tb)
+        self.assertIn(self.expected_frame, tb)
-            self.assertEqual(e.response.code, 404)
+            got_exception = e
-                self.assertEqual("IOLoop is closing", str(e))
+                got_exception = e
-            self.assertTrue("# test.html:2" in traceback.format_exc())
+            exc_stack = traceback.format_exc()
-            self.assertTrue("# test.html:2" in traceback.format_exc())
+            exc_stack = traceback.format_exc()
-            self.assertTrue('# sub.html:1' in exc_stack)
+        self.assertTrue('# base.html:1' in exc_stack)
-                            traceback.format_exc())
+            exc_stack = traceback.format_exc()
-                            traceback.format_exc())
+            exc_stack = traceback.format_exc()
-                            traceback.format_exc())
+            exc_stack = traceback.format_exc()
-                traceback.format_exc())
+            exc_stack = traceback.format_exc()
-            self.assertIs(e, exc_info[1])
+            got_exception = e
-            delegate.headers_received(start_line, headers)
+            self.message_delegate.headers_received(start_line, headers)
-                    yield self._read_message(delegate, is_client, method=method)
+                    # TODO: client delegates will get headers_received twice
-                body_future = self._read_body(is_client, headers, delegate)
+                body_future = self._read_body(is_client, headers)
-            delegate.finish()
+            self._reading = False
-    def _read_body(self, is_client, headers, delegate):
+    def _read_body(self, is_client, headers):
-            return self._read_fixed_body(content_length, delegate)
+            return self._read_fixed_body(content_length)
-            return self._read_chunked_body(delegate)
+            return self._read_chunked_body()
-            return self._read_body_until_close(delegate)
+            return self._read_body_until_close()
-    def _read_fixed_body(self, content_length, delegate):
+    def _read_fixed_body(self, content_length):
-        delegate.data_received(body)
+        self.message_delegate.data_received(body)
-    def _read_chunked_body(self, delegate):
+    def _read_chunked_body(self):
-            delegate.data_received(chunk[:-2])
+            self.message_delegate.data_received(chunk[:-2])
-    def _read_body_until_close(self, delegate):
+    def _read_body_until_close(self):
-        delegate.data_received(body)
+        self.message_delegate.data_received(body)
-        return [('/', StreamingBodyHandler, dict(test=self))]
+        @stream_request_body
-        self.finished = Future()
+        return [('/stream_body', StreamingBodyHandler, dict(test=self)),
-        stream.write(b"Connection: close\r\n")
+        stream.write(b"GET " + url + b" HTTP/1.1\r\n")
-from tornado.testing import AsyncHTTPTestCase, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, ExpectLog, gen_test
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value, ErrorHandler, UIModule, MissingArgumentError
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value, ErrorHandler, UIModule, MissingArgumentError, stream_request_body
-        self.chunks.append(data)
+        if self.stream_request_body:
-        self.execute()
+        if self.stream_request_body:
-        handler = self.handler_class(self.application, self.request,
+        self.handler = self.handler_class(self.application, self.request,
-
+        self.handler._execute(transforms, *self.path_args, **self.path_kwargs)
-``{% try %}...{% except %}...{% finally %}...{% else %}...{% end %}``
+``{% try %}...{% except %}...{% else %}...{% finally %}...{% end %}``
-                runner.run()
+                # Inline the first iteration of Runner.run.  This lets us
-    def __init__(self, gen, result_future):
+    def __init__(self, gen, result_future, first_yielded):
-                        "yielded unknown object %r" % (yielded,)))
+                if not self.handle_yield(yielded):
-from tornado.concurrent import Future
+from tornado.concurrent import Future, is_future
-            result = yield gen.maybe_future(self.prepare())
+            result = self.prepare()
-                method(*self.path_args, **self.path_kwargs))
+            result = method(*self.path_args, **self.path_kwargs)
-            self._handle_request_exception(e)
+            result = yield gen.maybe_future(self.prepare())
-            self.finish()
+            result = yield gen.maybe_future(
-from tornado.websocket import WebSocketConnect
+from tornado.websocket import websocket_connect
-    control_ws = yield WebSocketConnect(url, None)
+    control_ws = yield websocket_connect(url, None)
-        test_ws = yield WebSocketConnect(url, None)
+        test_ws = yield websocket_connect(url, None)
-    update_ws = yield WebSocketConnect(url, None)
+    update_ws = yield websocket_connect(url, None)
-                return
+            delegate.headers_received(start_line, headers)
-    def _execute(self, transforms, *args, **kwargs):
+    @tornado.web.asynchronous
-            return
+        self.stream = self.request.connection.detach()
-    def write_headers(self, start_line, headers):
+    def write_headers(self, start_line, headers, chunk=None, callback=None):
-            self.stream.write(b"\r\n".join(lines) + b"\r\n\r\n")
+            self._write_callback = stack_context.wrap(callback)
-        """Writes a chunk of output to the stream."""
+    def _format_chunk(self, chunk):
-            chunk = utf8("%x" % len(chunk)) + b"\r\n" + chunk + b"\r\n"
+            return utf8("%x" % len(chunk)) + b"\r\n" + chunk + b"\r\n"
-            self.stream.write(chunk, self._on_write_complete)
+            self.stream.write(self._format_chunk(chunk),
-            self.request.connection.write_headers(start_line, self._headers)
+            self.request.connection.write_headers(start_line, self._headers,
-        self.request.write(chunk, callback=callback)
+            # Ignore the chunk and only write the headers for HEAD requests
-    def write_headers(self, start_line, headers):
+    def write_headers(self, start_line, headers, chunk=None, callback=None):
-    interface expected by our clients.
+    """Adapts the `HTTPMessageDelegate` interface to the interface expected
-            remote_ip = self.connection.address[0]
+        self.request = None
-            remote_ip = '0.0.0.0'
+            self.delegate = None
-        # xheaders can override the defaults
+    def headers_received(self, start_line, headers):
-            headers=headers, remote_ip=remote_ip, protocol=protocol)
+            self._apply_xheaders(headers)
-        self._chunks.append(chunk)
+        if self.delegate is None:
-        self.server.request_callback(self.request)
+        if self.delegate is None:
-    def __init__(self, method, uri, version="HTTP/1.0", headers=None,
+    def __init__(self, method=None, uri=None, version="HTTP/1.0", headers=None,
-                 files=None, connection=None):
+                 files=None, connection=None, start_line=None):
-        self.protocol = protocol or "http"
+        self.remote_ip = remote_ip or getattr(connection, 'remote_ip')
-class Application(object):
+class Application(httputil.HTTPServerConnectionDelegate):
-                handler = handler_class(self, request, **handler_args)
+    def start_request(self, connection):
-        return handler
+    def __call__(self, request):
-        self.request.body = chunk
+        self._chunks.append(chunk)
-foo=bar
+4
-        return self._adapter.__call__(environ, start_response)
+        return WSGIAdapter(self)(environ, start_response)
-        self.write(b"\r\n".join(lines) + b"\r\n\r\n")
+        if not self.stream.closed():
-            raise httputil.HTTPMessageException("Malformed HTTP headers")
+            raise httputil.HTTPMessageException("Malformed HTTP headers: %r" %
-    ChunkedTransferEncoding example below if you want to implement a
+    GZipContentEncoding example below if you want to implement a
-
+            if is_client:
-                code = httputil.parse_response_start_line(start_line).code
+                code = start_line.code
-        if start_line.endswith("HTTP/1.1"):
+        if start_line.version == "HTTP/1.1":
-              or start_line.startswith(("HEAD ", "GET "))):
+              or start_line.method in ("HEAD", "GET")):
-            connection=self.connection, method=method, uri=uri, version=version,
+            connection=self.connection, method=start_line.method,
-        self.reason = reason
+        self.code = first_line.code
-            self.request.header_callback(first_line + '\r\n')
+            # Reassemble the start line.
-        if code != 101:
+        if start_line.code != 101:
-application = tornado.wsgi.WSGIApplication([
+application = tornado.web.Application([
-
+        self.request._parse_body()
-from tornado.wsgi import WSGIApplication, WSGIContainer
+from tornado.web import RequestHandler, Application
-def wrap_web_tests():
+def wrap_web_tests_application():
-        class WSGIWrappedTest(cls):
+        class WSGIApplicationWrappedTest(cls):
-        result["WSGIWrapped_" + cls.__name__] = WSGIWrappedTest
+        result["WSGIApplication_" + cls.__name__] = WSGIApplicationWrappedTest
-globals().update(wrap_web_tests())
+globals().update(wrap_web_tests_application())
-                self.on_connection_close)
+        self.request.connection.set_close_callback(self.on_connection_close)
-            self._log()
+        self.flush(include_footers=True)
-                 wsgi=False, **settings):
+                 **settings):
-        if self.settings.get('autoreload') and not wsgi:
+        if self.settings.get('autoreload'):
-  HTTP server, such as Google App Engine.  See the `WSGIApplication` class
+* `WSGIAdapter` converts a `tornado.web.Application` to the WSGI application
-from tornado.escape import native_str, parse_qs_bytes
+from tornado.escape import native_str
-    handlers running in a `WSGIApplication`, we throw an exception.
+    .. deprecated: 3.3::
-            application = tornado.wsgi.WSGIApplication([
+            application = tornado.web.Application([
-            server = wsgiref.simple_server.make_server('', 8888, application)
+            wsgi_app = tornado.wsgi.WSGIAdapter(application)
-    `tornado.websocket` modules.
+    In WSGI mode asynchronous methods are not supported.  This means
-                                 wsgi=True, **settings)
+    def __init__(self, application):
-        self.headers = httputil.HTTPHeaders()
+        method = environ["REQUEST_METHOD"]
-            self.headers["Content-Type"] = environ["CONTENT_TYPE"]
+            headers["Content-Type"] = environ["CONTENT_TYPE"]
-            self.headers["Content-Length"] = environ["CONTENT_LENGTH"]
+            headers["Content-Length"] = environ["CONTENT_LENGTH"]
-                int(self.headers["Content-Length"]))
+                headers[key[5:].replace("_", "-")] = environ[key]
-        self.remote_ip = environ.get("REMOTE_ADDR", "")
+            body = ""
-            self.host = environ["HTTP_HOST"]
+            host = environ["HTTP_HOST"]
-            return self._finish_time - self._start_time
+            host = environ["SERVER_NAME"]
-from tornado.escape import native_str
+from tornado.escape import native_str, utf8
-        self.stream.write(request_str)
+        start_line = httputil.RequestStartLine(self.request.method,
-            headers = self._generate_headers()
+            # Finalize the cookie headers (which have been stored in a side
-        self.request.write(headers + chunk, callback=callback)
+        self.request.write(chunk, callback=callback)
-        http://haacked.com/archive/2008/11/20/anatomy-of-a-subtle-json-vulnerability.aspx
+        http://haacked.com/archive/2009/06/25/json-hijacking.aspx/ and
-else:
+if sys.version_info < (2, 7):
-except ImportError:
+if sys.version_info >= (3,):
-                ssl_options["ciphers"] = "DEFAULT:!SSLv2"
+                # In addition to disabling SSLv2, we also exclude certain
-from tornado.escape import utf8
+from tornado.escape import utf8, native_str
-            print(response.body)
+            print(native_str(response.body))
-        self._streaming_callback = stack_context.wrap(streaming_callback)
+    import twisted.names
-
+class StreamBufferFullError(IOError):
-                 read_chunk_size=4096):
+                 read_chunk_size=4096, max_write_buffer_size=None):
-from tornado.log import app_log, gen_log
+from tornado.log import gen_log
-            return b''.join(chunks)
+            read_stream_body(stream, self.stop)
-    def start_serving(self, delegate):
+    def start_serving(self, delegate, gzip=False):
-                                       lambda f: f.result())
+        self.stream.io_loop.add_future(
-    def _server_request_loop(self, delegate):
+    def _server_request_loop(self, delegate, gzip=False):
-                 xheaders=False, ssl_options=None, protocol=None, **kwargs):
+                 xheaders=False, ssl_options=None, protocol=None, gzip=False,
-        conn.start_serving(self)
+        conn.start_serving(self, gzip=self.gzip)
-                self.request.body_arguments, self.request.files)
+                self.request.body_arguments, self.request.files,
-def parse_body_arguments(content_type, body, arguments, files):
+def parse_body_arguments(content_type, body, arguments, files, headers=None):
-from tornado.log import gen_log
+from tornado.log import app_log, gen_log
-        self.assertEqual(response.headers['Content-Encoding'], 'gzip')
+        # simple_httpclient renames the content-encoding header;
-                                      self.body, self.body_arguments, self.files)
+                                      self.body, self.body_arguments,
-    def read_response(self, delegate, method):
+    def read_response(self, delegate, method, use_gzip=False):
-            self.connection.read_response(self, method=self.request.method),
+            self.connection.read_response(self, method=self.request.method,
-        assert isinstance(delegate, httputil.HTTPConnectionDelegate)
+        assert isinstance(delegate, httputil.HTTPServerConnectionDelegate)
-        self.stream.io_loop.add_future(self._process_requests(delegate),
+        self.stream.io_loop.add_future(self._server_request_loop(delegate),
-    def _process_requests(self, delegate):
+    def _server_request_loop(self, delegate):
-                ret = yield self._process_message(request_delegate, False)
+                ret = yield self._read_message(request_delegate, False)
-        return self._process_message(delegate, True, method=method)
+    def read_response(self, delegate, method):
-        assert isinstance(delegate, httputil.HTTPStreamDelegate)
+    def _read_message(self, delegate, is_client, method=None):
-                    yield self._process_message(delegate, is_client, method=method)
+                    yield self._read_message(delegate, is_client, method=method)
-            gen_log.info("Malformed HTTP request from %r: %s",
+        except httputil.HTTPMessageException as e:
-            raise httputil.BadRequestException("Malformed HTTP headers")
+            raise httputil.HTTPMessageException("Malformed HTTP headers")
-                raise httputil.BadRequestException("Content-Length too long")
+                raise httputil.HTTPMessageException("Content-Length too long")
-from tornado import http1connection, httputil
+from tornado.http1connection import HTTP1Connection
-class HTTPServer(TCPServer, httputil.HTTPConnectionDelegate):
+class HTTPServer(TCPServer, httputil.HTTPServerConnectionDelegate):
-                              self.protocol)
+        conn = HTTP1Connection(stream, address=address,
-        return _ServerRequestProcessor(self, connection)
+        return _ServerRequestAdapter(self, connection)
-class _ServerRequestProcessor(httputil.HTTPStreamDelegate):
+class _ServerRequestAdapter(httputil.HTTPMessageDelegate):
-            raise httputil.BadRequestException("Malformed HTTP request line")
+            raise httputil.HTTPMessageException("Malformed HTTP request line")
-            raise httputil.BadRequestException("Malformed HTTP version in HTTP Request-Line")
+            raise httputil.HTTPMessageException(
-    """Exception class for malformed HTTP requests."""
+class HTTPMessageException(Exception):
-class HTTPConnectionDelegate(object):
+class HTTPServerConnectionDelegate(object):
-class HTTPStreamDelegate(object):
+class HTTPMessageDelegate(object):
-class _HTTPConnection(httputil.HTTPStreamDelegate):
+class _HTTPConnection(httputil.HTTPMessageDelegate):
-        # Ensure that any exception raised in process_response ends up in our
+        # Ensure that any exception raised in read_response ends up in our
-            self.connection.process_response(self, method=self.request.method),
+            self.connection.read_response(self, method=self.request.method),
-from tornado import httpclient, simple_httpclient, netutil
+from tornado import netutil
-from tornado.httputil import HTTPHeaders, HTTPStreamDelegate
+from tornado.httputil import HTTPHeaders, HTTPMessageDelegate
-from tornado.simple_httpclient import SimpleAsyncHTTPClient
+from tornado.netutil import ssl_options_to_context
-            class Delegate(HTTPStreamDelegate):
+            class Delegate(HTTPMessageDelegate):
-            conn.process_response(Delegate(), method='GET')
+            conn.read_response(Delegate(), method='GET')
-        with ExpectLog(gen_log, "Malformed HTTP request from"):
+        with ExpectLog(gen_log, "Malformed HTTP message from"):
-                 protocol=None):
+    def __init__(self, stream, address, no_keep_alive=False, protocol=None):
-        self.delegate = delegate
+
-                                  lambda f: f.result())
+        self.stream.io_loop.add_future(self._process_requests(delegate),
-    def _process_requests(self):
+    def _process_requests(self, delegate):
-                return
+                ret = yield self._process_message(request_delegate, False)
-    def _read_body(self, headers):
+    def _read_body(self, is_client, headers, delegate):
-            return self.stream.read_bytes(content_length)
+            return self._read_fixed_body(content_length, delegate)
-        HTTPConnection(stream, address, self, self.no_keep_alive, self.protocol)
+        conn = HTTPConnection(stream, address, self.no_keep_alive,
-from tornado.escape import utf8, _unicode, native_str
+from tornado.escape import utf8, _unicode
-from tornado.iostream import IOStream, SSLIOStream
+from tornado import httputil
-class _HTTPConnection(object):
+class _HTTPConnection(httputil.HTTPStreamDelegate):
-        self.chunks = None
+        self.chunks = []
-        self.stream.connect(sockaddr, self._on_connect,
+        self._sockaddr = addrinfo[0][1]
-        self.stream.read_until_regex(b"\r?\n\r?\n", self._on_headers)
+        self.connection = HTTP1Connection(
-            return False
+            # pass it along, unless it's just the stream being closed.
-            self.reason = match.group(2)
+    def headers_received(self, first_line, headers):
-            self.request.header_callback(first_line + _)
+            self.request.header_callback(first_line + '\r\n')
-    def _on_body(self, data):
+    def finish(self):
-                                self.code, reason=self.reason,
+                                self.code, reason=getattr(self, 'reason', None),
-        chunk = data[:-2]
+    def data_received(self, chunk):
-        self.stream.read_until(b"\r\n", self._on_chunk_length)
+from tornado.http1connection import HTTP1Connection
-from tornado.httputil import HTTPHeaders
+from tornado.httputil import HTTPHeaders, HTTPStreamDelegate
-                return response
+        with closing(IOStream(socket.socket())) as stream:
-        data = json_decode(response.body)
+        data = json_decode(response)
-        assert code == 101
+    def headers_received(self, start_line, headers):
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipOnTravis
-        return template
+        with open(path, "rb") as f:
-                         len(e.args) == 2 and e.args[0] == errno.EINTR)):
+                    if errno_from_exception(e) == errno.EINTR:
-                        if e.args[0] == errno.EPIPE:
+                        if errno_from_exception(e) == errno.EPIPE:
-from tornado.util import bytes_type
+from tornado.util import bytes_type, errno_from_exception
-                    e.args[0] not in _ERRNO_WOULDBLOCK):
+            if (errno_from_exception(e) != errno.EINPROGRESS and
-            if e.args[0] in _ERRNO_WOULDBLOCK:
+            if errno_from_exception(e) in _ERRNO_WOULDBLOCK:
-            elif e.args[0] == errno.EBADF:
+            elif errno_from_exception(e) == errno.EBADF:
-from tornado.util import u, Configurable
+from tornado.util import u, Configurable, errno_from_exception
-            if e.args[0] == errno.EAFNOSUPPORT:
+            if errno_from_exception(e) == errno.EAFNOSUPPORT:
-            if err.errno != errno.ENOENT:
+            if errno_from_exception(err) != errno.ENOENT:
-                if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
+                if errno_from_exception(e) in (errno.EWOULDBLOCK, errno.EAGAIN):
-                if e.args[0] == errno.ECONNABORTED:
+                if errno_from_exception(e) == errno.ECONNABORTED:
-            if e.errno == errno.EINTR:
+            if errno_from_exception(e) == errno.EINTR:
-            if e.args[0] == errno.ECHILD:
+            if errno_from_exception(e) == errno.ECHILD:
-                if err.args[0] in (errno.ECONNABORTED, errno.EINVAL):
+                if errno_from_exception(err) in (errno.ECONNABORTED, errno.EINVAL):
-                 xheaders=False, protocol=None):
+    def __init__(self, stream, address, delegate, no_keep_alive=False,
-        self.request_callback = request_callback
+        self.delegate = delegate
-        self.xheaders = xheaders
+        self._disconnect_on_finish = False
-                self._request = request
+                self._disconnect_on_finish = not self._can_keep_alive(
-                self.request_callback(request)
+                    request_delegate.data_received((yield body_future))
-            except _BadRequestException as e:
+            except httputil.BadRequestException as e:
-        self._request = None
+    def _can_keep_alive(self, start_line, headers):
-        if disconnect:
+        if self._disconnect_on_finish:
-            raise _BadRequestException("Malformed HTTP headers")
+            raise httputil.BadRequestException("Malformed HTTP headers")
-                raise _BadRequestException("Content-Length too long")
+                raise httputil.BadRequestException("Content-Length too long")
-                self._request.arguments.setdefault(k, []).extend(v)
+import socket
-class HTTPServer(TCPServer):
+class HTTPServer(TCPServer, httputil.HTTPConnectionDelegate):
-                       self.no_keep_alive, self.xheaders, self.protocol)
+        HTTPConnection(stream, address, self, self.no_keep_alive, self.protocol)
-        self.stream.read_until(b"\r\n\r\n", self._header_callback)
+        self._finish_future = None
-        self._header_callback = None
+        # Turn Nagle's algorithm back on, leaving the stream in its
-            self.close()
+            headers = httputil.HTTPHeaders.parse(data[eol:])
-    def _on_headers(self, data):
+    def _make_request(self, start_line, headers):
-        self._request.body = data
+            method, uri, version = start_line.split(" ")
-                self._request.headers.get("Content-Type", ""), data,
+                self._request.headers.get("Content-Type", ""), request.body,
-`tornado.web.RequestHandler.request`.
+.. versionchanged:: 3.3
-    `HTTPRequest.write`. `HTTPRequest.finish` finishes the request (but does
+    `.HTTPServerRequest.write`. `.HTTPServerRequest.finish` finishes the request (but does
-"""HTTP utility code shared by clients and servers."""
+"""HTTP utility code shared by clients and servers.
-        """An alias for `self.request.cookies <.httpserver.HTTPRequest.cookies>`."""
+        """An alias for `self.request.cookies <.httputil.HTTPServerRequest.cookies>`."""
-    `~.httpserver.HTTPRequest`, such as an `Application` or
+    `~.httputil.HTTPServerRequest`, such as an `Application` or
-    """Mimics `tornado.httpserver.HTTPRequest` for WSGI applications."""
+    """Mimics `tornado.httputil.HTTPServerRequest` for WSGI applications."""
-        """Converts a `tornado.httpserver.HTTPRequest` to a WSGI environment.
+        """Converts a `tornado.httputil.HTTPServerRequest` to a WSGI environment.
-        self.protocol = protocol
+        if protocol:
-                headers=headers, remote_ip=remote_ip, protocol=self.protocol)
+                headers=headers, remote_ip=remote_ip, protocol=protocol)
-from tornado import netutil
+try:
-                self.protocol = proto
+        self.protocol = protocol or "http"
-        except ssl.SSLError:
+        except SSLError:
-from tornado import netutil
+from tornado import http1connection, httputil
-            self.__class__.__name__, args, dict(self.headers))
+HTTPRequest = httputil.HTTPServerRequest
-from tornado.util import ObjectDict
+from tornado import netutil
-        unittest.main(defaultTest="all", argv=sys.argv)
+        unittest.main(defaultTest='all', argv=sys.argv[:1])
-from tornado.netutil import BlockingResolver, ThreadedResolver, is_valid_ip
+from tornado.netutil import BlockingResolver, ThreadedResolver, is_valid_ip, bind_sockets
-    if options.logging == 'none':
+    if options.logging is None or options.logging.lower() == 'none':
-        self._value = None
+        self._value = _Option.UNSET
-        return self.default if self._value is None else self._value
+        return self.default if self._value is _Option.UNSET else self._value
-        self.close_future.set_result(None)
+        self.close_future.set_result((self.close_code, self.close_reason))
-from tornado.escape import utf8, native_str
+from tornado.escape import utf8, native_str, to_unicode
-        """Invoked when the WebSocket is closed."""
+        """Invoked when the WebSocket is closed.
-    def close(self):
+    def close(self, code=None, reason=None):
-            self.ws_connection.close()
+            self.ws_connection.close(code, reason)
-    def close(self):
+    def close(self, code=None, reason=None):
-    def close(self):
+    def close(self, code=None, reason=None):
-                self._write_frame(True, 0x8, b"")
+                if code is None and reason is not None:
-    def close(self):
+    def close(self, code=None, reason=None):
-            self.protocol.close()
+            self.protocol.close(code, reason)
-        "text/javascript", "application/json", "application/xhtml+xml"])
+    # Whitelist of compressible mime types (in addition to any types
-            self._gzipping = (ctype in self.CONTENT_TYPES) and \
+            self._gzipping = self._compressible_type(ctype) and \
-from tornado.ioloop import IOLoop
+# _Timeout is used for its timedelta_to_seconds method for py26 compatibility.
-            delay = deadline.total_seconds()
+            delay = _Timeout.timedelta_to_seconds(deadline)
-from tornado.util import bytes_type, ArgReplacer
+from tornado.util import bytes_type
-
+        self._write_future = None
-        self._write_callback = stack_context.wrap(callback)
+        if callback is not None:
-                fut.set_exception(StreamClosedError())
+            futures = []
-                self._read_future.set_exception(StreamClosedError())
+                futures.append(self._read_future)
-            self._read_future.set_result(data)
+            future = self._read_future
-            self._run_callback(callback)
+        if not self._write_buffer:
-        self._connect_callback = stack_context.wrap(callback)
+        if callback is not None:
-    def read_until_regex(self, regex, callback):
+    def read_until_regex(self, regex, callback=None):
-        self._set_read_callback(callback)
+        future = self._set_read_callback(callback)
-    def read_until(self, delimiter, callback):
+    def read_until(self, delimiter, callback=None):
-        self._set_read_callback(callback)
+        future = self._set_read_callback(callback)
-    def read_bytes(self, num_bytes, callback, streaming_callback=None):
+    def read_bytes(self, num_bytes, callback=None, streaming_callback=None):
-        self._set_read_callback(callback)
+        future = self._set_read_callback(callback)
-    def read_until_close(self, callback, streaming_callback=None):
+    def read_until_close(self, callback=None, streaming_callback=None):
-        self._set_read_callback(callback)
+        future = self._set_read_callback(callback)
-            return
+            self._run_read_callback(self._consume(self._read_buffer_size))
-                                   self._consume(self._read_buffer_size))
+                self._run_read_callback(self._consume(self._read_buffer_size))
-        self._read_callback = stack_context.wrap(callback)
+        assert self._read_callback is None, "Already reading"
-            self._run_callback(callback, self._consume(num_bytes))
+            self._run_read_callback(self._consume(num_bytes))
-                                           self._consume(loc + delimiter_len))
+                        self._run_read_callback(
-                        self._run_callback(callback, self._consume(m.end()))
+                        self._run_read_callback(self._consume(m.end()))
-        self.results = {}
+        self.pending_callbacks = None
-        self.exc_info = None
+        if self.pending_callbacks is None:
-        if key not in self.pending_callbacks:
+        if self.pending_callbacks is None or key not in self.pending_callbacks:
-                        self.exc_info = sys.exc_info()
+                future = self.future
-                    if self.exc_info is not None:
+                    try:
-                        yielded = self.gen.throw(*exc_info)
+                        yielded = self.gen.throw(*sys.exc_info())
-                        yielded = self.gen.send(next)
+                        yielded = self.gen.send(value)
-                            self.exc_info = sys.exc_info()
+                            self.future = TracebackFuture()
-                        "yielded unknown object %r" % (yielded,)),)
+                    self.future = TracebackFuture()
-            self.exc_info = (typ, value, tb)
+            self.future = TracebackFuture()
-        if self._exception:
+        if self._result is not None:
-        if self._exception:
+        if self._exception is not None:
-                future.set_exc_info(sys.exc_info())
+        try:
-            future.set_result(result)
+        future.set_result(result)
-                        self.exc_info = sys.exc_info()
+                    def start_yield_point():
-from tornado.stack_context import ExceptionStackContext, wrap
+from tornado import stack_context
-        with ExceptionStackContext(handle_exception) as deactivate:
+        with stack_context.ExceptionStackContext(handle_exception) as deactivate:
-        return wrap(inner)
+        return stack_context.wrap(inner)
-                pass
+            self.callback = yield gen.Callback('a')
-                pass
+            with ExceptionStackContext(lambda t, v, tb: False):
-                    runner = Runner(result, final_callback)
+                    runner = Runner(result, future)
-    ``final_callback`` is run after the generator exits.
+    The results of the generator are stored in ``result_future`` (a
-    def __init__(self, gen, final_callback):
+    def __init__(self, gen, result_future):
-        self.final_callback = final_callback
+        self.result_future = result_future
-                    self.final_callback = None
+                    self.result_future.set_result(getattr(e, 'value', None))
-                    raise
+                    self.result_future.set_exc_info(sys.exc_info())
-            if result is not None:
+        future = func(*args, **kwargs)
-            # no yield, so we're done
+                    (future.result(),))
-def coroutine(func):
+def coroutine(func, replace_callback=True):
-        if 'callback' in kwargs:
+        if replace_callback and 'callback' in kwargs:
-from tornado.concurrent import TracebackFuture, is_future
+from tornado.concurrent import Future, TracebackFuture, is_future
-_null_yield_point = _NullYieldPoint()
+_null_future = Future()
-        self.yield_point = _null_yield_point
+        self.future = _null_future
-        self.run()
+        if self.yield_point is not None and self.yield_point.is_ready():
-                        if not self.yield_point.is_ready():
+                        if not self.future.done():
-                        self.yield_point = None
+                        next = self.future.result()
-                    self.yield_point = _null_yield_point
+                    self.future = _null_future
-                    self.yield_point = _null_yield_point
+                    self.future = _null_future
-                    self.yield_point = yielded
+                    self.future = TracebackFuture()
-                        self.yield_point.start(self)
+                        yielded.start(self)
-class _DummyFuture(object):
+class Future(object):
-    Future = _DummyFuture
+    FUTURES = Future
-    Future = futures.Future
+    FUTURES = (futures.Future, Future)
-from tornado.concurrent import Future, TracebackFuture
+from tornado.concurrent import TracebackFuture, is_future
-            if isinstance(i, Future):
+            if is_future(i):
-                elif isinstance(yielded, Future):
+                elif is_future(yielded):
-from tornado.concurrent import Future, TracebackFuture
+from tornado.concurrent import TracebackFuture, is_future
-                if isinstance(result, Future):
+                if is_future(result):
-        assert isinstance(future, Future)
+        assert is_future(future)
-
+#!/usr/bin/env python
-        with self.assertRaises(ioloop.TimeoutError):
+        # This can't use assertRaises because we need to inspect the
-    from tornado.ioloop import IOLoop
+    from tornado.ioloop import IOLoop, TimeoutError
-
+        # Stack up several decorators to allow us to access the generator
-        return wrapper
+        def pre_coroutine(self):
-        yield self.close_future
+        self.wait()
-        super(AsyncTestCase, self).__init__(*args, **kwargs)
+    def __init__(self, methodName='runTest', **kwargs):
-from tornado.util import bytes_type
+from tornado.util import bytes_type, ArgReplacer
-        super(SSLIOStream, self).connect(address, callback=None)
+        # Note: Since we don't pass our callback argument along to
-from tornado.iostream import IOStream, SSLIOStream, PipeIOStream
+from tornado.iostream import IOStream, SSLIOStream, PipeIOStream, StreamClosedError
-from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, bind_unused_port, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, bind_unused_port, ExpectLog, gen_test
-        self.assertEqual(self.replacer.replace('new', (1, 2), dict()),
+        args = (1, 2)
-        self.assertEqual(self.replacer.replace('new', (1, 2, 'old', 3), dict()),
+        args = (1, 2, 'old', 3)
-                                               dict(y=2, callback='old', z=3)),
+        args = (1,)
-                self._write_buffer.append(data)
+            for i in range(0, len(data), WRITE_BUFFER_CHUNK_SIZE):
-import os
+"""Shim to allow python -m tornado.test.
-if __name__ == '__main__':
+def main():
-"""xAutomatically restart the server when a source file is modified.
+"""Automatically restart the server when a source file is modified.
-    io_loop.add_handler(sock.fileno(), accept_handler, IOLoop.READ)
+    io_loop.add_handler(sock, accept_handler, IOLoop.READ)
-        # Maps fd to handler function (as in IOLoop.add_handler)
+        # Maps fd to (fileobj, handler function) pair (as in IOLoop.add_handler)
-                self.close_fd(fd)
+                self.close_fd(fileobj)
-        self.handlers[fd] = stack_context.wrap(handler)
+        self.handlers[fd] = (fileobj, stack_context.wrap(handler))
-        self.handlers[fd](fd, events)
+        fileobj, handler_func = self.handlers[fd]
-                        self._handlers[fd][1](fd, events)
+                        fd_obj, handler_func = self._handlers[fd]
-            self.handler(self.fd, tornado.ioloop.IOLoop.READ)
+            self.handler(self.fileobj, tornado.ioloop.IOLoop.READ)
-            self.handler(self.fd, tornado.ioloop.IOLoop.WRITE)
+            self.handler(self.fileobj, tornado.ioloop.IOLoop.WRITE)
-            self.handler(self.fd, tornado.ioloop.IOLoop.ERROR)
+            self.handler(self.fileobj, tornado.ioloop.IOLoop.ERROR)
-        """Registers the given handler to receive the given events for fd.
+        """Registers the given handler to receive the given events for ``fd``.
-        """Changes the events we listen for fd."""
+        """Changes the events we listen for ``fd``.
-        """Stop listening for events on fd."""
+        """Stop listening for events on ``fd``.
-        we use `os.close()`.
+        we use `os.close`.
-                    gen_log.debug("error closing fd %s", fd, exc_info=True)
+            for fd, handler in self._handlers.values():
-        self._handlers[fd] = stack_context.wrap(handler)
+        fd, obj = self.split_fd(fd)
-                        self._handlers[fd](fd, events)
+                        self._handlers[fd][1](fd, events)
-            gen_log.warning("Got events for closed stream %d", fd)
+            gen_log.warning("Got events for closed stream %s", fd)
-                        gen_log.warning("Write error on %d: %s",
+                        gen_log.warning("Write error on %s: %s",
-        return self.socket.fileno()
+        return self.socket
-                gen_log.warning("Connect error on fd %d: %s",
+                gen_log.warning("Connect error on fd %s: %s",
-            gen_log.warning("Connect error on fd %d: %s",
+            gen_log.warning("Connect error on fd %s: %s",
-                gen_log.warning("SSL Error on %d %s: %s",
+                gen_log.warning("SSL Error on %s %s: %s",
-                    pass
+                self.close_fd(fd)
-            raise ValueError("fd %d added twice" % fd)
+            raise ValueError("fd %s added twice" % fd)
-            raise IOError("fd %d already registered" % fd)
+            raise IOError("fd %s already registered" % fd)
-            raise IOError("fd %d already registered" % fd)
+            raise IOError("fd %s already registered" % fd)
-    def __init__(self, fd, handler):
+    def __init__(self, fd, fileobj, handler):
-        self.fds[fd] = _FD(fd, wrap(handler))
+            raise ValueError('fd %s added twice' % fd)
-import logging
+import os
-from tornado.ioloop import IOLoop, PollIOLoop, TimeoutError
+from tornado.ioloop import IOLoop, TimeoutError
-if platform.python_implementation() == 'CPython':
+if (platform.python_implementation() == 'CPython' and
-    # it's not guaranteed to remain supported in the future.
+if (os.environ.get('TORNADO_NO_EXTENSION') or
-version = "3.2"
+version = "3.3.dev1"
-version_info = (3, 2, 0, 0)
+version = "3.3.dev1"
-version = "3.2b2"
+version = "3.2"
-version_info = (3, 2, 0, -97)
+version = "3.2"
-            record.color = self._colors.get(record.levelno, '')
+            record.color = self._colors[record.levelno]
-version = "3.2b1"
+version = "3.2b2"
-version_info = (3, 2, 0, -98)
+version = "3.2b2"
-                os.close(fd)
+                try:
-            'test_iterate',  # deliberately not supported
+            # Fails on TwistedIOLoop and AsyncIOLoop.
-    DEFAULT_FORMAT = '%(color)s[%(levelname)1.1s %(asctime)s %(module)s:%(lineno)d]%(normal)s %(message)s'
+    DEFAULT_FORMAT = '%(color)s[%(levelname)1.1s %(asctime)s %(module)s:%(lineno)d]%(end_color)s %(message)s'
-          text between ``%(color)s`` and ``%(normal)s`` will be colored
+          text between ``%(color)s`` and ``%(end_color)s`` will be colored
-           Added ``prefix_fmt`` and ``datefmt`` arguments.
+           Added ``fmt`` and ``datefmt`` arguments.
-        record.normal = self._normal
+        if record.levelno in self._colors:
-    DEFAULT_PREFIX_FORMAT = '[%(levelname)1.1s %(asctime)s %(module)s:%(lineno)d]'
+    DEFAULT_FORMAT = '%(color)s[%(levelname)1.1s %(asctime)s %(module)s:%(lineno)d]%(normal)s %(message)s'
-    def __init__(self, color=True, prefix_fmt=None, datefmt=None):
+    DEFAULT_COLORS = {
-          message text.
+        :arg bool color: Enables color support.
-        if self._color:
+        self._fmt = fmt
-            }
+
-            record.message = record.getMessage()
+            message = record.getMessage()
-        assert isinstance(record.message, basestring_type)  # guaranteed by logging
+
-        formatted = prefix + " " + safe_unicode(record.message)
+
-            # exc_text contains multiple lines.  We need to safe_unicode
+            # exc_text contains multiple lines.  We need to _safe_unicode
-            lines.extend(safe_unicode(ln) for ln in record.exc_text.split('\n'))
+            lines.extend(_safe_unicode(ln) for ln in record.exc_text.split('\n'))
-        self.formatter._color = True
+    def _setup_logging(self):
-
+        self._setup_logging()
-from tornado.ioloop import IOLoop, TimeoutError
+from tornado.ioloop import IOLoop, PollIOLoop, TimeoutError
-            class GoogleOAuth2LoginHandler(LoginHandler, tornado.auth.GoogleOAuth2Mixin):
+            class GoogleOAuth2LoginHandler(LoginHandler,
-                    if self.get_argument("code", False):
+                    if self.get_argument('code', False):
-                            code=self.get_argument("code"))
+                            code=self.get_argument('code'))
-                            scope=['openid', 'email'],
+                            client_id=self.settings['google_oauth']['key'],
-                            extra_params={"approval_prompt": "auto"})
+                            extra_params={'approval_prompt': 'auto'})
-            # far without anything.
+    def _setup_logging(self):
-    @asynchronous
+# Without this line sphinx includes a copy of object.__init__'s docstring
-    """Google authentication using OAuth2."""
+    """Google authentication using OAuth2.
-    """Escapes a string so it is valid within HTML or XML."""
+    """Escapes a string so it is valid within HTML or XML.
-version = "3.2.dev2"
+version = "3.2b1"
-version_info = (3, 2, 0, -99)
+version = "3.2b1"
-                  method="POST", headers={'Content-Type': 'application/x-www-form-urlencoded'}, body=body)
+                   self.async_callback(self._on_access_token, callback),
-                e.args[0] not in _ERRNO_WOULDBLOCK):
+                    e.args[0] not in _ERRNO_WOULDBLOCK):
-                                          stack_context.wrap(callback))
+                                            stack_context.wrap(callback))
-                    *args, **kwargs))
+                self._run_callback, stack_context.wrap(callback),
-                    functools.partial(self._on_timeout, key))
+                self.io_loop.time() + min(request.connect_timeout,
-                request_time=self.io_loop.time() - request.start_time)
+            request, 599, error=HTTPError(599, "Timeout"),
-            b"",
+                b"Content-Disposition: form-data; name=argument",
-
+
-                self.set_header("Content-Range", "bytes */%s" %(size, ))
+                self.set_header("Content-Range", "bytes */%s" % (size, ))
-            subprotocol=subprotocol_header))))
+                version=tornado.version,
-            request.path, encoding=None, plus=False)),
+                request.path, encoding=None, plus=False)),
-        client = CurlAsyncHTTPClient(io_loop=self.io_loop)
+        client = CurlAsyncHTTPClient(io_loop=self.io_loop,
-        self.http_client = CurlAsyncHTTPClient(self.io_loop)
+        self.http_client = CurlAsyncHTTPClient(self.io_loop,
-        defaults = dict(user_agent='TestDefaultUserAgent')
+        defaults = dict(user_agent='TestDefaultUserAgent', allow_ipv6=False)
-           callback=AsyncHTTPClient.configure)
+           callback=lambda s: AsyncHTTPClient.configure(
-            self.resolver.resolve('doesntexist', 80, callback=self.stop)
+            self.resolver.resolve('an invalid domain', 80, callback=self.stop)
-            yield self.resolver.resolve('doesntexist', 80,
+            yield self.resolver.resolve('an invalid domain', 80,
-        curl.setopt(pycurl.HEADERFUNCTION, request.header_callback)
+        curl.setopt(pycurl.HEADERFUNCTION,
-                    lambda line: _curl_header_callback(headers, line))
+                    lambda line: _curl_header_callback(headers,
-            digest = md5('%s:%s:%s' % (h1, nonce, h2)).hexdigest()
+            h1 = md5(utf8('%s:%s:%s' % (username, realm, password))).hexdigest()
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipOnTravis
-Loader is a class that loads templates from a root directory and caches
+`Loader` is a class that loads templates from a root directory and caches
-translated exactly into Python, you can do complex expressions like::
+expressions you can include in your statements. ``if`` and ``for`` blocks get
-functions in to your template just like any other variable::
+easily, like the ``escape()`` function in the examples above. You can pass
-to all templates by default.
+We provide the functions `escape() <.xhtml_escape>`, `.url_escape()`,
-            if twisted.internet.abstract.isIPAddress(resolved):
+            resolved = yield gen.Task(deferred.addBoth)
-            raise HTTPError(400, "Invalid unicode: %r" % value)
+            raise HTTPError(400, "Invalid unicode in %s: %r" %
-        self.assertEqual(response.code, 400)
+        with ExpectLog(gen_log, ".*Invalid unicode.*"):
-            headers = httputil.HTTPHeaders()
+        # Note that some of these attributes go through property setters
-            headers["If-Modified-Since"] = httputil.format_timestamp(
+            self.headers["If-Modified-Since"] = httputil.format_timestamp(
-        self._body = utf8(body)
+        self.body = body
-        self._prepare_curl_callback = stack_context.wrap(prepare_curl_callback)
+        self.streaming_callback = streaming_callback
-        return _unicode(value)
+        try:
-            'import tornado.test.resolve_test']
+            'import tornado.test.resolve_test_helper']
-        while time.time() - start < 20:
+        popen = Popen(command, preexec_fn=lambda: signal.alarm(TIMEOUT))
-IOLoop.current().run_sync(lambda: resolver.resolve(u('tornadoweb.org'), 80))
+IOLoop.current().run_sync(lambda: resolver.resolve(u('localhost'), 80))
-from tornado.util import Configurable
+from tornado.util import u, Configurable
-        self.body = utf8(body)
+        self._headers = headers
-        self.prepare_curl_callback = stack_context.wrap(prepare_curl_callback)
+        self._streaming_callback = stack_context.wrap(streaming_callback)
-        If `on_message_callback` was specified at WebSocket
+        If on_message_callback was specified at WebSocket
-    def __init__(self, io_loop, request):
+    def __init__(self, io_loop, request, on_message_callback=None):
-        if self.read_future is not None:
+        if self._on_message_callback:
-def websocket_connect(url, io_loop=None, callback=None, connect_timeout=None):
+def websocket_connect(url, io_loop=None, callback=None, connect_timeout=None, on_message_callback=None):
-    conn = WebSocketClientConnection(io_loop, request)
+    conn = WebSocketClientConnection(io_loop, request, on_message_callback=on_message_callback)
-                              callback=(yield gen.Callback("key"))
+                              callback=(yield gen.Callback("key")))
-setuptools.setup(
+setup(
-
+        r"""
-          Prefix is a part of the log message, directly preceding the actual message text.
+          Prefix is a part of the log message, directly preceding the actual
-          Used for formatting '(asctime)' placeholder in prefix_fmt.
+          Used for formatting ``(asctime)`` placeholder in ``prefix_fmt``.
-                    raise
+        try:
-                        pass
+                    event_pairs = self._impl.poll(poll_timeout)
-            signal.set_wakeup_fd(old_wakeup_fd)
+
-        self.io_loop.add_future(self.future, runner.result_callback(self.key))
+        if not self.future.done():
-        return self.runner.is_ready(self.key)
+        if self.runner is not None:
-
+        if self.runner is not None:
-        "Expected bytes, unicode, or None; got %r" % type(value)
+    if not isinstance(value, unicode_type):
-        "Expected bytes, unicode, or None; got %r" % type(value)
+    if not isinstance(value, bytes_type):
-        "Expected bytes, unicode, or None; got %r" % type(value)
+    if not isinstance(value, bytes_type):
-    def result(self):
+    def result(self, timeout=None):
-            return super(TracebackFuture, self).result()
+            return super(TracebackFuture, self).result(timeout=timeout)
-        logging.Formatter.__init__(self, *args, **kwargs)
+    DEFAULT_PREFIX_FORMAT = '[%(levelname)1.1s %(asctime)s %(module)s:%(lineno)d]'
-            record.__dict__
+        record.asctime = self.formatTime(record, self.datefmt)
-    keyword arguments to the contructor of the handler. This pattern
+    Each tuple can contain additional elements, which correspond to the
-                    yield gen.Task(self.io_loop.add_callback)
+                    yield gen.Wait('a')
-    """WebSocket client connection."""
+    """WebSocket client connection.
-        uri_arguments = parse_qs_bytes(native_str(body), keep_blank_values=True)
+        try:
-    cythonize = None
+from distutils.core import Extension
-    kwargs['ext_modules'] = cythonize('tornado/speedups.pyx')
+if platform.python_implementation() == 'CPython':
-except ImportError:
+if os.environ.get('TORNADO_NO_EXTENSION'):
-# it's optional so swallow the error if it's not there.
+
-    pass
+    setuptools = None
-    long_description = f.read()
+    kwargs['long_description'] = f.read()
-    extensions = []
+    kwargs['ext_modules'] = cythonize('tornado/speedups.pyx')
-distutils.core.setup(
+setuptools.setup(
-import re
+if hasattr(ssl, 'match_hostname') and hasattr(ssl, 'CertificateError'):  # python 3.2+
-                                      "subjectAltName fields were found")
+            timeout = min(self.request.connect_timeout, self.request.request_timeout)
-                stack_context.wrap(self._on_timeout))
+        if self.final_callback is None:
-                assert self.request.body is not None
+                if self.request.body is None:
-                assert self.request.body is None
+                if self.request.body is not None:
-                spec = URLSpec(pattern, handler, kwargs)
+                assert len(spec) in (2, 3, 4)
-        
+
-        
+
-        """Closes the websocket connection."""
+        """Closes the websocket connection.
-                    request.start_time + min(request.connect_timeout, request.request_timeout),
+                    self.io_loop.time() + min(request.connect_timeout,
-            self.waiting[key] = (request, callback, timeout_handle)
+        else:
-            self.io_loop.remove_timeout(timeout_handle)
+            if timeout_handle is not None:
-                           callback=None):
+                           client_secret=None, extra_params=None,
-    def test_websocket_network_fail(self):
+    def test_websocket_network_timeout(self):
-            # on python 2.6, we set ssl_version to SSLv3.  This is
+            # on python 2.6, we set ssl_version to TLSv1.  This is
-            # but nearly all servers support SSLv3:
+            # compatibility with servers configured for SSLv3 only,
-                ssl_options["ssl_version"] = ssl.PROTOCOL_SSLv3
+                ssl_options["ssl_version"] = ssl.PROTOCOL_TLSv1
-        :arg string network_interface: Network interface to use for request
+        :arg string network_interface: Network interface to use for request.
-           to mix requests with ``ca_certs`` and requests that use the defaults.
+           or None to use defaults.  See note below when used with
-        :arg string client_cert: Filename for client SSL certificate, if any
+        :arg string client_key: Filename for client SSL key, if any.  See
-    def __init__(self, pattern, handler_class, kwargs=None, name=None):
+    def __init__(self, pattern, handler, kwargs=None, name=None):
-        self.handler_class = handler_class
+        
-from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError
+from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError, _websocket_mask_python
-            data = mask + self._apply_mask(mask, data)
+            data = mask + _websocket_mask(mask, data)
-        self._on_frame_data(self._apply_mask(self._frame_mask, data))
+        self._on_frame_data(_websocket_mask(self._frame_mask, data))
-To test: python3.4 -m tornado.test.runtests --ioloop=tornado.platform.asyncio.AsyncIOLoop
+To test:
-        self.asyncio_loop = asyncio.events.new_event_loop()
+class BaseAsyncIOLoop(IOLoop):
-        self.asyncio_loop.close()
+        if self.close_loop:
-        if IOLoop.configured_class().__name__ == 'TwistedIOLoop':
+        if IOLoop.configured_class().__name__ in ('TwistedIOLoop',
-                'Sync HTTPClient not compatible with TwistedIOLoop')
+                'Sync HTTPClient not compatible with TwistedIOLoop or '
-        raise unittest.SkipTest("Process tests not compatible with TwistedIOLoop")
+    if IOLoop.configured_class().__name__.endswith(('TwistedIOLoop',
-class EchoHandler(WebSocketHandler):
+    This allows for deterministic cleanup of the associated socket.
-class HeaderHandler(WebSocketHandler):
+class EchoHandler(TestWebSocketHandler):
-            ('/header', HeaderHandler),
+            ('/header', HeaderHandler, dict(close_future=self.close_future)),
-    if curses and sys.stderr.isatty():
+    if curses and hasattr(sys.stderr, 'isatty') and sys.stderr.isatty():
-        if self.keys:
+        if self.keys is not None:
-started at the same time and run in parallel; a list of results will
+You can also yield a list or dict of ``Futures`` and/or ``Tasks``, which will be
-        return [i.get_result() for i in self.children]
+        result = (i.get_result() for i in self.children)
-                if isinstance(yielded, list):
+                if isinstance(yielded, (list, dict)):
-                if e.errno != errno.EINVAL:
+                if e.errno not in (errno.EINVAL, errno.ECONNRESET):
-keyword argument ``autoreload=False``).
+Most applications should not access this module directly.  Instead,
-        if self.settings.get("debug_traceback") and "exc_info" in kwargs:
+        if self.settings.get("serve_traceback") and "exc_info" in kwargs:
-            self.settings.setdefault('debug_traceback', True)
+            self.settings.setdefault('compiled_template_cache', False)
-        if not self.settings.get("template_cache"):
+        if not self.settings.get("compiled_template_cache", True):
-        self.write(self.get_query_argument("foo", "default"))
+    def prepare(self):
-        self.write(self.get_body_argument("foo", "default"))
+class GetArgumentsHandler(RequestHandler):
-            url("/get_body_argument", GetBodyArgumentHandler),
+            url("/get_arguments", GetArgumentsHandler),
-        # body arguments overwrite query arguments
+        # Test merging of query and body arguments.
-        response = self.fetch("/get_query_argument?foo=bar", method="POST", body=body)
+        response = self.fetch("/get_argument?source=query&foo=bar",
-        response = self.fetch("/get_query_argument?foo=", method="POST", body=body)
+        response = self.fetch("/get_argument?source=query&foo=",
-        response = self.fetch("/get_query_argument", method="POST", body=body)
+        response = self.fetch("/get_argument?source=query",
-        response = self.fetch("/get_body_argument?foo=hello", method="POST", body=body)
+        response = self.fetch("/get_argument?source=body&foo=hello",
-        response = self.fetch("/get_body_argument?foo=hello", method="POST", body=body)
+        response = self.fetch("/get_argument?source=body&foo=hello",
-        response = self.fetch("/get_body_argument?foo=hello", method="POST", body=body)
+        response = self.fetch("/get_argument?source=body&foo=hello",
-            for k, v in self._request.body_arguments.iteritems():
+            for k, v in self._request.body_arguments.items():
-        for k, v in self.body_arguments.iteritems():
+        for k, v in self.body_arguments.items():
-                                      self.body, self.arguments, self.files)
+                                      self.body, self.body_arguments, self.files)
-                self._request.arguments, self._request.body_arguments, self._request.files)
+                self._request.body_arguments, self._request.files)
-def parse_body_arguments(content_type, body, arguments, body_arguments, files):
+def parse_body_arguments(content_type, body, arguments, files):
-                parse_multipart_form_data(utf8(v), body, arguments, body_arguments, files)
+                parse_multipart_form_data(utf8(v), body, arguments, files)
-def parse_multipart_form_data(boundary, data, arguments, body_arguments, files):
+def parse_multipart_form_data(boundary, data, arguments, files):
-        parse_multipart_form_data(b"1234", data, args, body_args, files)
+        parse_multipart_form_data(b"1234", data, args, files)
-        parse_multipart_form_data(b"1234", data, args, body_args, files)
+        parse_multipart_form_data(b"1234", data, args, files)
-            parse_multipart_form_data(b"1234", data, args, body_args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-        parse_multipart_form_data(b'"1234"', data, args, body_args, files)
+        parse_multipart_form_data(b'"1234"', data, args, files)
-            parse_multipart_form_data(b"1234", data, args, body_args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-            parse_multipart_form_data(b"1234", data, args, body_args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-            parse_multipart_form_data(b"1234", data, args, body_args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-            parse_multipart_form_data(b"1234", data, args, body_args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-        parse_multipart_form_data(b"1234", data, args, body_args, files)
+        parse_multipart_form_data(b"1234", data, args, files)
-            for value in self.get_arguments(key, self.request.arguments):
+            for value in self.get_arguments(key):
-        return self._get_argument(name, self.request.arguments, default, strip)
+        return self._get_argument(name, default, self.request.arguments, strip)
-        return self._get_argument(name, self.request.body_arguments, default, strip)
+        return self._get_argument(name, default, self.request.body_arguments, strip)
-        return self._get_argument(name, self.request.query_arguments, default, strip)
+        return self._get_argument(name, default, self.request.query_arguments, strip)
-        """Returns a list of the arguments with the given name.
+    def get_query_arguments(self, name, strip=True):
-                                      self.body, self.arguments, self.body_arguments, self.files)
+                                      self.body, self.arguments, self.files)
-                self._request.arguments, self._request.files)
+                self._request.arguments, self._request.body_arguments, self._request.files)
-def parse_body_arguments(content_type, body, arguments, files):
+def parse_body_arguments(content_type, body, arguments, body_arguments, files):
-                parse_multipart_form_data(utf8(v), body, arguments, files)
+                parse_multipart_form_data(utf8(v), body, arguments, body_arguments, files)
-def parse_multipart_form_data(boundary, data, arguments, files):
+def parse_multipart_form_data(boundary, data, arguments, body_arguments, files):
-        parse_multipart_form_data(b"1234", data, args, files)
+        parse_multipart_form_data(b"1234", data, args, body_args, files)
-        parse_multipart_form_data(b"1234", data, args, files)
+        parse_multipart_form_data(b"1234", data, args, body_args, files)
-            parse_multipart_form_data(b"1234", data, args, files)
+            parse_multipart_form_data(b"1234", data, args, body_args, files)
-        parse_multipart_form_data(b'"1234"', data, args, files)
+        parse_multipart_form_data(b'"1234"', data, args, body_args, files)
-            parse_multipart_form_data(b"1234", data, args, files)
+            parse_multipart_form_data(b"1234", data, args, body_args, files)
-            parse_multipart_form_data(b"1234", data, args, files)
+            parse_multipart_form_data(b"1234", data, args, body_args, files)
-            parse_multipart_form_data(b"1234", data, args, files)
+            parse_multipart_form_data(b"1234", data, args, body_args, files)
-            parse_multipart_form_data(b"1234", data, args, files)
+            parse_multipart_form_data(b"1234", data, args, body_args, files)
-        parse_multipart_form_data(b"1234", data, args, files)
+        parse_multipart_form_data(b"1234", data, args, body_args, files)
-            for value in self.get_arguments(key):
+            for value in self.get_arguments(key, self.request.arguments):
-        args = self.get_arguments(name, strip=strip)
+        return self._get_argument(name, self.request.arguments, default, strip)
-    def get_arguments(self, name, strip=True):
+    def get_arguments(self, name, source, strip=True):
-        for v in self.request.arguments.get(name, []):
+        for v in source.get(name, []):
-                                      self.body, self.arguments, self.files)
+                                      self.body, self.arguments, self.body_arguments, self.files)
-    module (or the debug=True option to `tornado.web.Application`).
+    module (or the ``autoreload=True`` option to `tornado.web.Application`
-        module (or the ``debug=True`` option to `tornado.web.Application`).
+        module (or the ``autoreload=True`` option to `tornado.web.Application`
-        if self.settings.get("debug") and "exc_info" in kwargs:
+        if self.settings.get("debug_traceback") and "exc_info" in kwargs:
-        if self.settings.get("debug") and not wsgi:
+        if self.settings.get('autoreload') and not wsgi:
-        # In debug mode, re-compile templates and reload static files on every
+        # If template cache is disabled (usually in the debug mode),
-        if self.settings.get("debug"):
+        if not self.settings.get("template_cache"):
-        with ExpectLog(gen_log, "Malformed HTTP request from ''"):
+        with ExpectLog(gen_log, "Malformed HTTP request from"):
-                         self.address[0], e)
+            gen_log.info("Malformed HTTP request from %r: %s",
-        stream.read_until(b"\r\n", self.stop)
+        self.stream.write(b"GET /hello HTTP/1.0\r\n\r\n")
-        stream.read_until(b"\r\n\r\n", self.stop)
+        self.stream.read_until(b"\r\n\r\n", self.stop)
-        stream.read_bytes(int(headers["Content-Length"]), self.stop)
+        self.stream.read_bytes(int(headers["Content-Length"]), self.stop)
-        server.stop()
+
-        server.add_socket(sock)
+        self.server = HTTPServer(app, io_loop=self.server_ioloop)
-        self.server_ioloop.add_callback(self.server_ioloop.stop)
+        def stop_server():
-                        SimpleAsyncHTTPClient(io_loop2))
+        with closing(IOLoop()) as io_loop2:
-                yield gen.Task(self.io_loop.add_callback)
+            try:
-                yield gen.Task(self.io_loop.add_callback)
+            try:
-                handler = ErrorHandler(self, request, status_code=404)
+                if self.settings.get('default_handler_class'):
-                self.set_header("Connection", "Keep-Alive")
+                self._headers["Connection"] = "Keep-Alive"
-from tornado.httpclient import HTTPError
+from tornado.httpclient import HTTPError, HTTPRequest
-from tornado import httpclient
+from tornado import httpclient, httputil
-    request = httpclient.HTTPRequest(url, connect_timeout=connect_timeout)
+    if isinstance(url, httpclient.HTTPRequest):
-                           client_secret=None, extra_params=None,
+                           client_secret=None, scope=None,
-            "client_id": client_id
+            "client_id": client_id,
-            '', extra_params)
+    _OAUTH_SETTINGS_KEY = 'google_oauth'
-        """Handles the login for the Facebook user, returning a user object.
+        """Handles the login for the Google user, returning a user object.
-                            redirect_uri='/auth/google',
+                            redirect_uri='http://your.site.com/auth/google',
-                            redirect_uri='/auth/google',
+                            redirect_uri='http://your.site.com/auth/google',
-            "redirect_uri": self.request.protocol + '://' + self.request.host + redirect_uri,
+        body = urllib_parse.urlencode({
-            "client_secret": self.settings['google_consumer_secret'],
+            "client_id": self.settings[self._OAUTH_SETTINGS_KEY]['key'],
-
+        args = escape.json_decode(response.body)
-                    request.start_time + request.async_timeout,
+                    request.start_time + min(request.connect_timeout, request.request_timeout),
-            client.fetch(self.get_url('/hello'), self.stop, async_timeout=3)
+            client.fetch(self.get_url('/hello'), self.stop, connect_timeout=3)
-version = "3.1"
+version = "3.1.1"
-version_info = (3, 1, 0, 0)
+version = "3.1.1"
-            # set on the IOStream (which would otherwise prevent the
+            # set on the HTTPConnection (which would otherwise prevent the
-            self.request.connection.stream.set_close_callback(None)
+            self.request.connection.set_close_callback(None)
-            self.request.protocol + '://' + self.request.host + (redirect_uri or self.request.uri),
+            (redirect_uri or self.request.uri),
-                          scope=['openid', 'email'], response_type="code", overwrites={}):
+                          scope=['openid', 'email'], response_type="code", extra_params={}):
-        extra_params = {
+        extra_params.update({
-        extra_params.update(overwrites)
+        })
-version = "3.2.dev1"
+version = "3.2.dev2"
-version_info = (3, 2, 0, -100)
+version = "3.2.dev2"
-        self.queue.append((request, callback))
+        key = object()
-                key = object()
+                key, request, callback = self.queue.popleft()
-            self._waker.wake()
+            if list_empty and thread.get_ident() != self._thread_ident:
-        self.ws_connection = None
+        if self.ws_connection:
-        on the `AsyncHTTPClient` after ``close()``.
+
-        """Deletes the cookie with the given name."""
+        """Deletes the cookie with the given name.
-        """Deletes all the cookies the user sent with this request."""
+        """Deletes all the cookies the user sent with this request.
-    def clear_all_cookies(self):
+    def clear_all_cookies(self, path="/", domain=None):
-            self.clear_cookie(name)
+            self.clear_cookie(name, path=path, domain=domain)
-        self._add_io_state(self.io_loop.READ | self.io_loop.WRITE)
+        # If the socket is already connected, attempt to start the handshake.
-            # set on the IOStream (which would otherwise prevent the
+            # set on the HTTPConnection (which would otherwise prevent the
-            self.request.connection.stream.set_close_callback(None)
+            self.request.connection.set_close_callback(None)
-            self._run_callback(cb)
+        # If there are pending callbacks, don't run the close callback
-                                      fd, exc_info=True)
+                        self.handle_callback_exception(self._handlers.get(fd))
-                                  fd, exc_info=True)
+                    self.handle_callback_exception(self._handlers.get(fd))
-            app_log.error("Error in periodic callback", exc_info=True)
+            self.io_loop.handle_callback_exception(self.callback)
-            poll_timeout = 3600.0
+            poll_timeout = _POLL_TIMEOUT
-         * access_type = online
+        approval_prompt = auto
-            except socket.error as e:
+            except (socket.error, IOError, OSError) as e:
-        self.current_user = handler.current_user
+    @property
-            if e.args[0] == errno.ECONNRESET:
+            if e.args[0] in _ERRNO_CONNRESET:
-                if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
+                if e.args[0] in _ERRNO_WOULDBLOCK:
-                    if e.args[0] not in (errno.EPIPE, errno.ECONNRESET):
+                    if e.args[0] not in _ERRNO_CONNRESET:
-            if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
+            if e.args[0] in _ERRNO_WOULDBLOCK:
-            if e.args[0] not in (errno.EINPROGRESS, errno.EWOULDBLOCK):
+            if (e.args[0] != errno.EINPROGRESS and
-            if err.args[0] in (errno.ECONNABORTED, errno.ECONNRESET):
+            if err.args[0] in _ERRNO_CONNRESET:
-            if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
+            if e.args[0] in _ERRNO_WOULDBLOCK:
-            if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
+            if e.args[0] in _ERRNO_WOULDBLOCK:
-            del callbacks
+            callbacks = callback = None
-    _OAUTH_AUTHORIZE_URL = "https://graph.facebook.com/oauth/authorize?"
+    _OAUTH_AUTHORIZE_URL = "https://www.facebook.com/dialog/oauth?"
-from tornado.concurrent import Future, chain_future, return_future
+from tornado.concurrent import TracebackFuture, chain_future, return_future
-        future = Future()
+        future = TracebackFuture()
-from tornado.concurrent import Future
+from tornado.concurrent import TracebackFuture
-        future = Future()
+        future = TracebackFuture()
-                    future_cell[0] = Future()
+                    future_cell[0] = TracebackFuture()
-from tornado.concurrent import Future
+from tornado.concurrent import TracebackFuture
-        self.connect_future = Future()
+        self.connect_future = TracebackFuture()
-        future = Future()
+        future = TracebackFuture()
-        self.proc = subprocess.Popen(*args, **kwargs)
+        try:
-_XHTML_ESCAPE_DICT = {'&': '&amp;', '<': '&lt;', '>': '&gt;', '"': '&quot;'}
+_XHTML_ESCAPE_RE = re.compile('[&<>"\']')
-            ("<>&\"", "&lt;&gt;&amp;&quot;"),
+            ("<>&\"'", "&lt;&gt;&amp;&quot;&#39;"),
-                StackContext(functools.partial(self.context, 'c1')),
+                StackContext(functools.partial(self.context, 'c2')),
-        run_with_stack_context(
+        yield run_with_stack_context(
-                        raise ValueError('Expected None, got %r' % result)
+                        raise ValueError('Expected None, got %r' % result.result())
-version = "3.1"
+version = "3.2.dev1"
-version_info = (3, 1, 0, 0)
+version = "3.2.dev1"
-            app_response.close()
+        try:
-version = "3.1b1"
+version = "3.1"
-version_info = (3, 1, 0, -98)
+version = "3.1"
-        via this method.
+        registered a callback URI with the third-party service.  For
-        self.io_loop = kwargs.pop('io_loop', None)
+        self.io_loop = kwargs.pop('io_loop', None) or ioloop.IOLoop.current()
-            in_r, in_w = os.pipe()
+            in_r, in_w = _pipe_cloexec()
-            out_r, out_w = os.pipe()
+            out_r, out_w = _pipe_cloexec()
-            err_r, err_w = os.pipe()
+            err_r, err_w = _pipe_cloexec()
-    ``gen.coroutine``).
+    in either this decorator or `engine`.
-        sock = socket.socket(af, socktype, proto)
+        try:
-        if indent == None:
+        if indent is None:
-            ('/echo', EchoHandler),
+            ('/echo', EchoHandler, dict(close_future=self.close_future)),
-        self._write_frame(True, opcode, message)
+        try:
-        self.stream.read_bytes(2, self._on_frame_start)
+        try:
-            self._frame_length = payloadlen
+        try:
-            self.stream.read_bytes(self._frame_length, self._on_frame_data)
+        except StreamClosedError:
-            self.stream.read_bytes(self._frame_length, self._on_frame_data)
+        try:
-        self.stream.read_bytes(self._frame_length, self._on_masked_frame_data)
+        try:
-version = "3.1.dev2"
+version = "3.1b1"
-version_info = (3, 1, 0, -99)
+version = "3.1b1"
-        @tornado.gen.engine
+        @tornado.gen.coroutine
-            @tornado.gen.engine
+            @tornado.gen.coroutine
-                @tornado.gen.engine
+                @tornado.gen.coroutine
-            @tornado.gen.engine
+            @tornado.gen.coroutine
-                @tornado.gen.engine
+                @tornado.gen.coroutine
-           @tornado.gen.engine
+           @tornado.gen.coroutine
-              @tornado.gen.engine
+              @tornado.gen.coroutine
-                @tornado.gen.engine
+                @tornado.gen.coroutine
-version = "3.0.1"
+version = "3.0.2"
-version_info = (3, 0, 1, 0)
+version = "3.0.2"
-    _OAUTH_AUTHENTICATE_URL = "http://api.twitter.com/oauth/authenticate"
+    _OAUTH_REQUEST_TOKEN_URL = "https://api.twitter.com/oauth/request_token"
-    _TWITTER_BASE_URL = "http://api.twitter.com/1"
+    _TWITTER_BASE_URL = "https://api.twitter.com/1.1"
-        response = self.wait()
+        with ExpectLog(gen_log, ".*", required=False):
-    def initialize(self, io_loop=None, executor=None):
+    """Resolver implementation using a `concurrent.futures.Executor`.
-        self.executor = executor or dummy_executor
+        if executor is not None:
-        self.executor.shutdown()
+        if self.close_executor:
-        from concurrent.futures import ThreadPoolExecutor
+        threadpool = ThreadedResolver._create_threadpool(num_threads)
-            io_loop=io_loop, executor=ThreadPoolExecutor(num_threads))
+            io_loop=io_loop, executor=threadpool, close_executor=False)
-        self.resolver.executor.shutdown()
+        self.resolver.close()
-            "/users/show/" + escape.native_str(access_token["screen_name"]),
+            "/account/verify_credentials",
-    _OAUTH_AUTHENTICATE_URL = "http://api.twitter.com/oauth/authenticate"
+    _OAUTH_REQUEST_TOKEN_URL = "https://api.twitter.com/oauth/request_token"
-    _TWITTER_BASE_URL = "http://api.twitter.com/1"
+    _TWITTER_BASE_URL = "https://api.twitter.com/1.1"
-            raise Exception("Could not get request token")
+            raise Exception("Could not get request token: %s" % response.error)
-                self.authenticate_redirect()
+                yield self.authenticate_redirect()
-                              ax_attrs=["name", "email", "language", "username"]):
+                              ax_attrs=["name", "email", "language", "username"],
-
+    @return_future
-                           http_client=None):
+                           http_client=None, callback=None):
-                    callback_uri))
+                    callback_uri,
-                    callback_uri))
+                    callback_uri,
-    def _on_request_token(self, authorize_url, callback_uri, response):
+    def _on_request_token(self, authorize_url, callback_uri, callback,
-
+    @return_future
-                           client_secret=None, extra_params=None):
+                           client_secret=None, extra_params=None,
-                    self.authorize_redirect()
+                    yield self.authorize_redirect()
-    def authenticate_redirect(self, callback_uri=None):
+    @return_future
-            self._on_request_token, self._OAUTH_AUTHENTICATE_URL, None))
+        http.fetch(self._oauth_request_token_url(callback_uri=callback_uri),
-        """Fetches the given API path, e.g., ``/statuses/user_timeline/btaylor``
+        """Fetches the given API path, e.g., ``statuses/user_timeline/btaylor``
-                        self.authorize_redirect()
+                        yield self.authorize_redirect()
-                    self.authorize_redirect()
+                    yield self.authorize_redirect()
-                        self.authorize_redirect()
+                        yield self.authorize_redirect()
-                   self.authenticate_redirect()
+                   yield self.authenticate_redirect()
-                           ax_attrs=["name", "email", "language", "username"]):
+                           ax_attrs=["name", "email", "language", "username"],
-                self.authenticate_redirect()
+                yield self.authenticate_redirect()
-        """Authenticates/installs this app for the current user."""
+                              extended_permissions=None, callback=None):
-                           cancel_uri=None):
+                           cancel_uri=None, callback=None):
-                                   extended_permissions)
+        return self.authenticate_redirect(callback_uri, cancel_uri,
-                      self.authorize_redirect(
+                      yield self.authorize_redirect(
-                        self.authorize_redirect()
+                        yield self.authorize_redirect()
-        self.authenticate_redirect()
+        res = self.authenticate_redirect()
-        self.authorize_redirect(http_client=self.settings['http_client'])
+        res = self.authorize_redirect(http_client=self.settings['http_client'])
-        self.authorize_redirect()
+        res = self.authorize_redirect()
-        self.authenticate_redirect()
+        res = self.authenticate_redirect()
-    def test_twitter_redirect(self):
+    def base_twitter_redirect(self, url):
-        response = self.fetch('/twitter/client/login', follow_redirects=False)
+        response = self.fetch(url, follow_redirects=False)
-        @tornado.gen.coroutine
+        @tornado.gen.engine
-            @tornado.gen.coroutine
+            @tornado.gen.engine
-                @tornado.gen.coroutine
+                @tornado.gen.engine
-            @tornado.gen.coroutine
+            @tornado.gen.engine
-                @tornado.gen.coroutine
+                @tornado.gen.engine
-           @tornado.gen.coroutine
+           @tornado.gen.engine
-              @tornado.gen.coroutine
+              @tornado.gen.engine
-                @tornado.gen.coroutine
+                @tornado.gen.engine
-            future.set_exception(AuthError("Error response %s fetching %s", 
+            future.set_exception(AuthError("Error response %s fetching %s",
-            response = self.fetch('/trigger?wake=false', request_timeout=0.1)
+        response = self.fetch('/trigger?wake=false', request_timeout=0.1)
-            response = self.wait()
+        self.http_client.fetch(url, self.stop)
-            self.assertEqual(response.code, 599)
+        response = self.fetch("/content_length?value=2,4")
-            self.assertEqual(response.code, 599)
+        response = self.fetch("/no_content?error=1")
-            response = self.wait()
+        self.http_client.fetch("http://localhost:%d/" % port, self.stop)
-                 "body")
+        attrs = ("protocol", "host", "method", "uri", "version", "remote_ip")
-            end = None
+            if end != 0:
-            if start < 0:
+            if (start is not None and start >= size) or end == 0:
-    0-0/4
+    bytes 0-0/4
-    1-2/4
+    bytes 1-2/4
-    0-3/4
+    bytes 0-3/4
-    return "%s-%s/%s" % (start, end, total)
+    return "bytes %s-%s/%s" % (start, end, total)
-                         "0-9/26")
+                         "bytes 0-9/26")
-                         "22-25/26")
+                         "bytes 22-25/26")
-                         "22-25/26")
+                         "bytes 22-25/26")
-       in the ``X-Real-Ip`` header
+       in the ``X-Real-Ip`` or ``X-Forwarded-For`` header.
-        """Closes the `Resolver`, freeing any resources used."""
+        """Closes the `Resolver`, freeing any resources used.
-        """A sequence of (name, value) pairs."""
+        """A sequence of (name, value) pairs.
-        """The set of option-groups created by ``define``."""
+        """The set of option-groups created by ``define``.
-        """The names and values of all options."""
+        """The names and values of all options.
-        argument or globally with the ASYNC_TEST_TIMEOUT environment variable.
+        In the event of a timeout, an exception will be thrown. The
-    overridden globally with the ASYNC_TEST_TIMEOUT environment variable,
+    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,
-    uses the maximum of the two.
+    .. versionadded:: 3.1
-        """Sets the content and caching headers on the response."""
+        """Sets the content and caching headers on the response.
-        """Returns True if the headers indicate that we should return 304."""
+        """Returns True if the headers indicate that we should return 304.
-        """Returns the ``Content-Type`` header to be used for this request."""
+        """Returns the ``Content-Type`` header to be used for this request.
-        class to handle caching of the result.
+        .. versionchanged:: 3.1
-                            "yielded unknown object %r" % (yielded,)),)
+                        "yielded unknown object %r" % (yielded,)),)
-        self.auth_mode = auth_mode        
+        self.auth_mode = auth_mode
-
+
-                    self._read_buffer_size):
+                        self._read_buffer_size):
-            self.socket.family in (socket.AF_INET, socket.AF_INET6)):
+                self.socket.family in (socket.AF_INET, socket.AF_INET6)):
-                                'Not CPython implementation')
+                                 'Not CPython implementation')
-            class Foo(object): pass
+            class Foo(object):
-                ])
+            ('/echo', EchoHandler),
-                remote_protocol=self.request.protocol))
+                            remote_protocol=self.request.protocol))
-        #self.io_loop.add_timeout(self.io_loop.time() + 0.01, self.stop)
+        # self.io_loop.add_timeout(self.io_loop.time() + 0.01, self.stop)
-            reduce(operator.or_, (getattr(gc, v) for v in values))))
+               reduce(operator.or_, (getattr(gc, v) for v in values))))
-
+
-                #('foo=a\\073b', 'a;b'),  # even encoded, ";" is a delimiter
+                # ('foo=a\\073b', 'a;b'),  # even encoded, ";" is a delimiter
-                'If-Modified-Since': 'Fri, 01 Jan 1960 00:00:00 GMT'})
+            'If-Modified-Since': 'Fri, 01 Jan 1960 00:00:00 GMT'})
-                'If-Modified-Since': format_timestamp(stat.st_mtime - 1)})
+            'If-Modified-Since': format_timestamp(stat.st_mtime - 1)})
-                'If-Modified-Since': format_timestamp(stat.st_mtime + 1)})
+            'If-Modified-Since': format_timestamp(stat.st_mtime + 1)})
-                'Range': 'bytes=0-9'})
+            'Range': 'bytes=0-9'})
-                'Range': 'bytes=0-'})
+            'Range': 'bytes=0-'})
-                'Range': 'bytes=22-'})
+            'Range': 'bytes=22-'})
-                'Range': 'bytes=-4'})
+            'Range': 'bytes=-4'})
-                'Range': 'asdf'})
+            'Range': 'asdf'})
-                })
+            'foo.html': '{{ my_ui_method(42) }} {% module MyModule(123) %}',
-            not self.request.connection.no_keep_alive):
+                not self.request.connection.no_keep_alive):
-            RequestHandler._INVALID_HEADER_CHAR_RE.search(value)):
+                RequestHandler._INVALID_HEADER_CHAR_RE.search(value)):
-        return '"%s"' %(version_hash, )
+        return '"%s"' % (version_hash, )
-            self.default_filename is not None):
+                self.default_filename is not None):
-                        "Non-websocket response"))
+                    "Non-websocket response"))
-                    request.path, encoding=None, plus=False)),
+            request.path, encoding=None, plus=False)),
-                raise CertificateError(
+                raise SSLCertificateError(
-        url = "https://graph.facebook.com" + path
+        url = self._FACEBOOK_BASE_URL + path
-                return True
+            if date_tuple is not None:
-                    return (wrap(check_contexts), [c0, c1, c2])
+                partial = functools.partial
-
+        while parent is not None:
-                    fn(*args, **kwargs)
+                    ret = fn(*args, **kwargs)
-        self.io_loop.add_timeout(self.io_loop.time() + 0.01, self.stop)
+        #self.io_loop.add_timeout(self.io_loop.time() + 0.01, self.stop)
-            def validate_absolute_path(self, absolute_path):
+            def validate_absolute_path(self, root, absolute_path):
-        self.root = os.path.abspath(path) + os.path.sep
+        self.root = path
-        self.absolute_path = self.validate_absolute_path(absolute_path)
+        absolute_path = self.get_absolute_path(self.root, self.path)
-        """Returns the absolute location of ``path``.
+    def get_absolute_path(cls, root, path):
-    def validate_absolute_path(self, absolute_path):
+    def validate_absolute_path(self, root, absolute_path):
-        abs_path = cls.get_absolute_path(settings, path)
+        abs_path = cls.get_absolute_path(settings['static_path'], path)
-                self._fds[fd] = ioloop_event
+            # libcurl sometimes closes a socket and then opens a new
-from tornado.web import Application
+from tornado.web import Application, RequestHandler
-        return Application([])
+        return Application([
-    assert isinstance(value, unicode_type)
+    assert isinstance(value, unicode_type), \
-    assert isinstance(value, bytes_type)
+    assert isinstance(value, bytes_type), \
-    assert isinstance(value, bytes_type)
+    assert isinstance(value, bytes_type), \
-    if isinstance(ts, (tuple, time.struct_time)):
+    if isinstance(ts, numbers.Real):
-        ts = time.gmtime(ts)
+        ts = calendar.timegm(ts.utctimetuple())
-    return time.strftime("%a, %d %b %Y %H:%M:%S GMT", ts)
+    return email.utils.formatdate(ts, usegmt=True)
-                                                 "%a, %d %b %Y %H:%M:%S GMT")
+        header_date = datetime.datetime(
-            "Date": httputil.format_timestamp(time.gmtime()),
+            "Date": httputil.format_timestamp(time.time()),
-    def _dnsname_to_pat(dn):
+    def _dnsname_to_pat(dn, max_wildcards=1):
-            # The subject is only checked when subjectAltName is empty
+        if not dnsnames:
-                            self._execute_finish)
+        if not self._finished:
-        may be passed through `static_url` but are not standard.
+        ``make_static_url(cls, settings, path)``; other keyword
-                                    response.error, response.request.url))
+            future.set_exception(AuthError("Error response %s fetching %s" %
-        all options are included.
+    def group_dict(self, group):
-
+relpath = lambda *a: os.path.join(os.path.dirname(__file__), *a)
-                                             'static'))
+        return dict(static_path=relpath('static'))
-                                    'static/robots.txt'))
+        stat = os.stat(relpath('static/robots.txt'))
-                                             'static'),
+        return dict(static_path=relpath('static'),
-        self.assertEqual(response.headers.get("Content-Range"), "0-25/26")
+        self.assertEqual(response.headers.get("Content-Range"), None)
-                            httputil._get_content_range(start, end, size))
+                self.set_header("Content-Range",
-                                             'static'))
+        return dict(static_path=self.static_dir)
-                self.set_status(206)
+                data_sliced = data[request_range]
-                data = data[request_range]
+                data = data_sliced
-    def __init__(self, context_factory, _active=True):
+    def __init__(self, context_factory):
-        self.active = _active
+        self.active = True
-    def __init__(self, exception_handler, _active=True):
+    def __init__(self, exception_handler):
-        self.active = _active
+        self.active = True
-        with ExceptionStackContext(handle_exception):
+        with ExceptionStackContext(handle_exception) as deactivate:
-        with ExceptionStackContext(handle_exception):
+        with ExceptionStackContext(handle_exception) as deactivate:
-    def __init__(self, context_factory):
+    def __init__(self, context_factory, _active=True):
-    def __init__(self, exception_handler):
+    def __init__(self, exception_handler, _active=True):
-    contexts = _state.contexts
+    # TODO: Any other better way to store contexts and update them in wrapped function?
-            # Force local state - switch to new stack chain
+            # Capture old state
-            stack_increase = len(stack_context._state.contexts) - initial_stack_depth
+
-        initial_stack_depth = len(stack_context._state.contexts)
+        initial_stack_depth = _stack_depth()
-from tornado.stack_context import StackContext, wrap, NullContext, StackContextInconsistentError, ExceptionStackContext, run_with_stack_context
+from tornado.stack_context import (StackContext, wrap, NullContext, StackContextInconsistentError,
-            raise Exception("WSGI applications do not support flush()")
+            # WSGI applications cannot usefully support flush, so just make
-    `get_absolute_path`, and `validate_absolute_path`.
+    To replace all interaction with the filesystem (e.g. to serve
-        else:
+        content = self.get_content(self.absolute_path, start, end)
-            self.set_header("Content-Length", len(data))
+            self.set_header("Content-Length", content_length)
-                return file.read()
+                remaining = None
-        return hashlib.md5(data).hexdigest()
+        hasher = hashlib.md5()
-    >>> [0, 1, 2, 3, 4][rh]
+    Returns either ``None`` or tuple ``(start, end)``.
-    slice(6, None, None)
+    (6, None)
-    slice(-6, None, None)
+    (-6, None)
-    slice(None, None, None)
+    (None, None)
-    return slice(start, end)
+    return (start, end)
-def _get_content_range(data, request_range):
+def _get_content_range(start, end, total):
-    >>> print(_get_content_range("abcd", slice(None, 1)))
+    >>> print(_get_content_range(None, 1, 4))
-    >>> print(_get_content_range("abcd", slice(1, 3)))
+    >>> print(_get_content_range(1, 3, 4))
-    >>> print(_get_content_range("abcd", slice(None, None)))
+    >>> print(_get_content_range(None, None, 4))
-    return "%s-%s/%s" %(start, stop, data_len)
+    end = (end or total) - 1
-            def get_content(self, path):
+            def get_content(self, path, start=None, end=None):
-        data = self.get_content(self.absolute_path)
+            start, end = request_range
-            data = data[request_range]
+            self.set_header("Content-Range",
-    def get_content(cls, abspath):
+    def get_content(cls, abspath, start=None, end=None):
-            return file.read()
+            if start is not None:
-        stat_result = os.stat(self.absolute_path)
+        stat_result = self._stat()
-            def make_static_url(cls, settings, path, include_version=True):
+            def make_static_url(cls, settings, path):
-    def static_url(self, path, include_host=None, include_version=True):
+    def static_url(self, path, include_host=None, **kwargs):
-        is set to False, i.e ?v=<signature> is not appended.
+        This method returns a versioned url (by default appending
-        return base + get_url(self.settings, path, include_version)
+        return base + get_url(self.settings, path, **kwargs)
-        a class method rather than an instance method).
+        This method may be overridden in subclasses (but note that it
-        version_hash = self.get_version(self.settings, self.path_args[0])
+        version_hash = self._get_cached_version(self.absolute_path)
-                self.redirect(self.request.path + "/")
+                self.redirect(self.request.path + "/", permanent=True)
-
+
-                    hashes[abs_path] = hashlib.md5(data).hexdigest()
+                    hashes[abs_path] = cls.get_content_version(abs_path)
-                    gen_log.error("Could not open static file %r", path)
+                    gen_log.error("Could not open static file %r", abs_path)
-        root = self.settings["static_path"]
+        root = os.path.abspath(self.settings["static_path"])
-def parse_request_range(range_header):
+def _parse_request_range(range_header):
-        >>> parse_request_range("bytes=1-2,6-10")
+    Returns either ``None`` or an instance of ``slice``:
-    """ Returns a suitable Content-Range header::
+def _get_content_range(data, request_range):
-        0-3/4
+    >>> print(_get_content_range("abcd", slice(None, 1)))
-                return path
+                return 'CustomStaticFileTest:' + path
-                pass
+            def validate_absolute_path(self, absolute_path):
-                if path == 'foo.txt':
+                if path == 'CustomStaticFileTest:foo.txt':
-    To map a path to this handler for a static data directory ``/var/www``,
+    A `StaticFileHandler` is configured automatically if you pass the
-            (r"/static/(.*)", web.StaticFileHandler, {"path": "/var/www"}),
+            (r"/content/(.*)", web.StaticFileHandler, {"path": "/var/www"}),
-    more fine-grained cache control.
+    To maximize the effectiveness of browser caching, this class supports
-        self.validate_absolute_path()
+        absolute_path = self.get_absolute_path(self.settings, self.path)
-            request_range = httputil.parse_request_range(range_header)
+            request_range = httputil._parse_request_range(range_header)
-            content_range = httputil.get_content_range(data, request_range)
+            content_range = httputil._get_content_range(data, request_range)
-        corresponding to the given URL ``path`` can be found.
+    def compute_etag(self):
-        resources outside of the static directory cannot be accessed.
+        This allows efficient ``If-None-Match`` checks against cached
-        return mime_type
+        version_hash = self.get_version(self.settings, self.path_args[0])
-        """
+        """Sets the content and caching headers on the response."""
-        at the given absolute ``path``.
+        at the given absolute path.
-            def parse_url_path(cls, url_path):
+            def parse_url_path(self, url_path):
-            def get_content(self, settings, path):
+            def get_content(self, path):
-            def get_modified_time(self, path):
+            def get_modified_time(self):
-            return
+        # Set up our path instance variables.
-            return
+        self.modified = self.get_modified_time()
-        if self.check_etag_header():
+        if self.should_return_304():
-                self.set_status(416)
+                self.set_status(416)  # Range Not Satisfiable
-                                 %(range_header, )))
+                self.write("The provided Range header is not valid: %r\n"
-        data = self.get_content(self.settings, path)
+        data = self.get_content(self.absolute_path)
-            self.set_status(206)
+            self.set_status(206)  # Partial Content
-
+        return abspath
-        if os.path.isdir(abspath) and self.default_filename is not None:
+        if not (self.absolute_path + os.path.sep).startswith(root):
-        if not os.path.exists(abspath):
+            self.absolute_path = os.path.join(self.absolute_path,
-        return abspath
+        if not os.path.isfile(self.absolute_path):
-        stat_result = os.stat(abspath)
+    def get_modified_time(self):
-        modified = self.get_modified_time(path)
+    def get_content_type(self):
-            self.set_header("Last-Modified", modified)
+        Returns True if the content should be returned, and False
-            self.set_header("Content-Type", mime_type)
+        if self.modified is not None:
-        cache_time = self.get_cache_time(path, modified, mime_type)
+        content_type = self.get_content_type()
-        self.set_extra_headers(path)
+        self.set_extra_headers(self.path)
-        return True
+            if if_since >= self.modified:
-    def get_content(cls, settings, path):
+    def get_content(cls, abspath):
-                    data = cls.get_content(settings, path)
+                    data = cls.get_content(abs_path)
-                cls.get_version(settings, path)
+                version = cls.get_version(settings, path)
-                return '/static/%s.%s.%s' % (before_version, 42, after_version)
+                return '/static/%s.%s.%s' % (before_version, version,
-        body = self.get_content(path)
+        body = self.get_content(self.settings, path)
-                self.set_header("Content-Length", len(data))
+        data = self.get_content(self.settings, path)
-    def get_absolute_path(self, path):
+    @classmethod
-        abspath = os.path.abspath(os.path.join(self.root, path))
+        root = settings["static_path"]
-        if not (abspath + os.path.sep).startswith(self.root):
+        if not (abspath + os.path.sep).startswith(root):
-        self._abspath = abspath
+    def get_modified_time(self, path):
-        modified = datetime.datetime.utcfromtimestamp(stat_result[stat.ST_MTIME])
+        abspath = self.get_absolute_path(self.settings, path)
-        self.set_header("Last-Modified", modified)
+        if modified is not None:
-    def get_content(self, path):
+    @classmethod
-        abspath = self.get_absolute_path(path)
+        abspath = cls.get_absolute_path(settings, path)
-        abs_path = os.path.join(settings["static_path"], path)
+        abs_path = cls.get_absolute_path(settings, path)
-                    f.close()
+                    data = cls.get_content(settings, path)
-from redbot.droid import ResourceExpertDroid
+from redbot.resource import HttpResource
-                raise state.res_error
+        red = self.run_redbot(url, method, body, headers)
-        self.assertEqual(int(state.res_status), expected_status)
+        self.assertEqual(int(red.response.status_code), expected_status)
-        for msg in state.messages:
+        for msg in red.response.notes:
-                                  req_hdrs=headers)
+        red = HttpResource(url, method=method, req_body=body,
-        return red.state
+        return red
-                        self.set_status(304)
+                self.set_etag_header()
-    custom_methods = set(["DELETE"])
+    custom_methods = set(["DELETE", "OPTIONS", "PATCH"])
-def parse_request_range(range_header, ):
+def parse_request_range(range_header):
-                                "Note: multiple ranges are not supported"))
+                                "Note: multiple ranges are not supported."
-        self.assertEqual(response.code, 406)
+        self.assertEqual(response.code, 416)
-                self.set_status(406)
+                # 416: Range Not Satisfiable
-        """A dict of names and values.
+    def groups(self):
-            application = Application(handler, **options.options.as_dict())
+            from tornado.options import define, parse_command_line, options
-        return dict(self.items())
+        return dict(
-        # OptionParsers always define 'help'.
+    def test_group_dict(self):
-        self.assertEqual(expected, options_dict)
+        self.assertEqual(expected, default_group_dict)
-        return self._options[item]
+        return self._options[item].value()
-def parse_request_range(range_header):
+def parse_request_range(range_header, ):
-        end += 1
+        if start is None:
-    )
+    start, stop = request_range.start, request_range.stop
-                              self.robots_txt_hash))
+        self.assertEqual(response.body, (
-                         b'"%s"' %(self.robots_txt_hash, ))
+        self.assertEqual(utf8(response.headers.get("Etag")),
-        self.assertEqual(response.body, b"/static/robots.txt?v=f71d2")
+        self.assertEqual(response.body,
-                         utf8(self.get_url("/") + "static/robots.txt?v=f71d2"))
+                         utf8(self.get_url("/") +
-                return hsh[:5]
+                return hsh
-                if item != None and not isinstance(item, self.type):
+                if item is not None and not isinstance(item, self.type):
-            if value != None and not isinstance(value, self.type):
+            if value is not None and not isinstance(value, self.type):
-                        self._options[name].file_name)
+            raise Error("Option %r already defined in %s" %
-        self.resolver = resolver or Resolver(io_loop=io_loop)
+        if resolver:
-        return response
+        with closing(Resolver(io_loop=self.io_loop)) as resolver:
-        self.assertEqual(len(self.triggers), 0)
+        with closing(self.create_client(max_clients=2)) as client:
-        response.rethrow()
+        with closing(self.create_client(max_clients=1)) as client:
-            104857600, Resolver(io_loop=io_loop))
+            104857600, self.resolver)
-        self._ssl_connect_callback = callback
+        self._ssl_connect_callback = stack_context.wrap(callback)
-from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, bind_unused_port, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, bind_unused_port, ExpectLog
-
+class SimpleHTTPClientTestMixin(object):
-                                       force_instance=True)
+        client = self.create_client(max_clients=2)
-                                       force_instance=True)
+        client = self.create_client(max_clients=1)
-                                                     url))
+                                                     utf8(url)))
-            if self.request.headers.get("Connection") == "Keep-Alive":
+        if (not self.request.supports_http_1_1() and
-from tornado.web import Application, RequestHandler, asynchronous
+from tornado.web import Application, RequestHandler, asynchronous, HTTPError
-    @asynchronous
+class UndecoratedCoroutinesHandler(RequestHandler):
-                    self.finish()
+            self._when_complete(self.prepare(), self._execute_method)
-        See `.IOStream.set_nodelay` for additional details.
+        See `.BaseIOStream.set_nodelay` for additional details.
-                    if e.args[0] != errno.EPIPE:
+                    if e.args[0] not in (errno.EPIPE, errno.ECONNRESET):
-                            return escape.url_unescape(s, encoding=None)
+                            return escape.url_unescape(s, encoding=None,
-            converted_args.append(escape.url_escape(utf8(a)))
+            converted_args.append(escape.url_escape(utf8(a), plus=False))
-            "PATH_INFO": to_wsgi_str(escape.url_unescape(request.path, encoding=None)),
+            "PATH_INFO": to_wsgi_str(escape.url_unescape(
-    return urllib_parse.quote_plus(utf8(value))
+def url_escape(value, plus=True):
-    def url_unescape(value, encoding='utf-8'):
+    def url_unescape(value, encoding='utf-8', plus=True):
-            return urllib_parse.unquote_plus(utf8(value))
+            return unquote(utf8(value))
-            return unicode_type(urllib_parse.unquote_plus(utf8(value)), encoding)
+            return unicode_type(unquote(utf8(value)), encoding)
-    def url_unescape(value, encoding='utf-8'):
+    def url_unescape(value, encoding='utf-8', plus=True):
-            return urllib_parse.unquote_plus(to_basestring(value), encoding=encoding)
+            unquote = (urllib_parse.unquote_plus if plus
-    def test_url_escape(self):
+    def test_url_escape_unicode(self):
-    def test_url_unescape(self):
+    def test_url_unescape_unicode(self):
-                                    self.fileno(), e)
+                    if e.args[0] != errno.EPIPE:
-from tornado.stack_context import StackContext, wrap, NullContext, StackContextInconsistentError, ExceptionStackContext
+from tornado.stack_context import StackContext, wrap, NullContext, StackContextInconsistentError, ExceptionStackContext, run_with_stack_context
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value, ErrorHandler, UIModule
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value, ErrorHandler, UIModule, MissingArgumentError
-        required, and we throw an HTTP 400 exception if it is missing.
+        required, and we raise a `MissingArgumentError` if it is missing.
-                raise HTTPError(400, "Missing argument %s" % name)
+                raise MissingArgumentError(name)
-    the ``path`` argument to the get() method (different than the constructor 
+    the ``path`` argument to the get() method (different than the constructor
-    argument to the handler.
+    The handler constructor requires a ``path`` argument, which specifies the
-        httpclient.close()
+        http_client.close()
-    [sock] = netutil.bind_sockets(0, 'localhost', family=socket.AF_INET)
+    [sock] = netutil.bind_sockets(None, 'localhost', family=socket.AF_INET)
-            application.ui_modules.items())
+        self.ui["_tt_modules"] = _UIModuleNamespace(self,
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value, ErrorHandler
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value, ErrorHandler, UIModule
-        if len(value) > 4000 or re.search(br"[\x00-\x1f]", value):
+        if (len(value) > 4000 or
-        norm_name = HTTPHeaders._normalize_name(name)
+        norm_name = _normalized_headers[name]
-        norm_name = HTTPHeaders._normalize_name(name)
+        norm_name = _normalized_headers[name]
-        norm_name = HTTPHeaders._normalize_name(name)
+        norm_name = _normalized_headers[name]
-        return dict.__getitem__(self, HTTPHeaders._normalize_name(name))
+        return dict.__getitem__(self, _normalized_headers[name])
-        norm_name = HTTPHeaders._normalize_name(name)
+        norm_name = _normalized_headers[name]
-        norm_name = HTTPHeaders._normalize_name(name)
+        norm_name = _normalized_headers[name]
-        return dict.get(self, HTTPHeaders._normalize_name(name), default)
+        return dict.get(self, _normalized_headers[name], default)
-                                   socket.TCP_NODELAY, 1 if value else 0)
+            try:
-                                   socket.TCP_NODELAY, 1)
+                                   socket.TCP_NODELAY, 1 if value else 0)
-        self.stream.write(b"\r\n".join(request_lines) + b"\r\n\r\n")
+        request_str = b"\r\n".join(request_lines) + b"\r\n\r\n"
-            self.stream.write(self.request.body)
+            request_str += self.request.body
-                          self.request, exc_info=True)
+    def log_exception(self, typ, value, tb):
-    the `stop()` and `wait()` methods for this purpose.  The test
+    complete by the time the test method returns.  This means that
-        # This test uses argument passing between self.stop and self.wait.
+        # This test uses coroutine style.
-        class MyTestCase2(AsyncTestCase):
+        class MyTestCase3(AsyncTestCase):
-            self._pending_callbacks -= 1
+            try:
-            def callback(data):
+            def streaming_callback(data):
-                                    streaming_callback=callback)
+            def close_callback(data):
-            server.write(b"5678")
+            self.wait(condition=lambda: len(chunks) == 1)
-            self.assertEqual(chunks, [b"1234", b"5678", b""])
+            self.wait(condition=lambda: closed[0])
-        self._close_callback = None
+        self._clear_request_state()
-        """Clears the per-request callbacks.
+    def _clear_request_state(self):
-        self._clear_callbacks()
+        self._clear_request_state()
-        self._clear_callbacks()
+        self._clear_request_state()
-        if self.no_keep_alive:
+        if self.no_keep_alive or self._request is None:
-        self._clear_callbacks()
+        self._clear_request_state()
-        if type(date) in (int, long, float):
+        if isinstance(date, numbers.Real):
-            "_string_types": (unicode_type, bytes_type),
+            "_tt_utf8": escape.utf8,  # for internal use
-        execute = namespace["_execute"]
+        execute = namespace["_tt_execute"]
-        writer.write_line("def _execute():", self.line)
+        writer.write_line("def _tt_execute():", self.line)
-            writer.write_line("_append = _buffer.append", self.line)
+            writer.write_line("_tt_buffer = []", self.line)
-            writer.write_line("return _utf8('').join(_buffer)", self.line)
+            writer.write_line("return _tt_utf8('').join(_tt_buffer)", self.line)
-        method_name = "apply%d" % writer.apply_counter
+        method_name = "_tt_apply%d" % writer.apply_counter
-            writer.write_line("_append = _buffer.append", self.line)
+            writer.write_line("_tt_buffer = []", self.line)
-        writer.write_line("_append(_utf8(%s(%s())))" % (
+            writer.write_line("return _tt_utf8('').join(_tt_buffer)", self.line)
-        writer.write_line("else: _tmp = _utf8(str(_tmp))", self.line)
+        writer.write_line("_tt_tmp = %s" % self.expression, self.line)
-            writer.write_line("_tmp = _utf8(%s(_tmp))" %
+            writer.write_line("_tt_tmp = _tt_utf8(%s(_tt_tmp))" %
-        writer.write_line("_append(_tmp)", self.line)
+        writer.write_line("_tt_append(_tt_tmp)", self.line)
-        super(_Module, self).__init__("_modules." + expression, line,
+        super(_Module, self).__init__("_tt_modules." + expression, line,
-            writer.write_line('_append(%r)' % escape.utf8(value), self.line)
+            writer.write_line('_tt_append(%r)' % escape.utf8(value), self.line)
-        }, namespace={"_modules": ObjectDict({"Template": lambda path, **kwargs: loader.load(path).generate(**kwargs)})})
+        }, namespace={"_tt_modules": ObjectDict({"Template": lambda path, **kwargs: loader.load(path).generate(**kwargs)})})
-        # UIModules are available as both `modules` and `_modules` in the
+        # UIModules are available as both `modules` and `_tt_modules` in the
-        # The template {% module %} directive looks in `_modules` to avoid
+        # The template {% module %} directive looks in `_tt_modules` to avoid
-        self.ui["modules"] = self.ui["_modules"]
+        self.ui["_tt_modules"] = ObjectDict(
-
+        # On CPython, tasks and their arguments should be released immediately
-            yield Task(self.io_loop.add_callback, arg=Task(None))
+            class Foo(object): pass
-        self.assertEqual(Task.released, 2)
+        self.assertIs(self.arg_ref(), None)
-            yield Task(lambda _arg, callback: callback(), Task(None))
+            yield Task(self.io_loop.add_callback, arg=Task(None))
-                if self.type in (int, long):
+                if issubclass(self.type, numbers.Integral):
-        # Task with arguments on CPython should be relased immediately after
+        # Task with arguments on CPython should be released immediately after
-            relased = 0
+            released = 0
-                type(self).relased += 1
+                type(self).released += 1
-        self.assertEqual(Task.relased, 2)
+        self.assertEqual(Task.released, 2)
-        self.yield_point = _NullYieldPoint()
+        self.yield_point = _null_yield_point
-        addrinfo = socket.getaddrinfo(host, port, family)
+        # On Solaris, getaddrinfo fails if the given port is not found
-                except:
+                except Exception:
-                if err.args[0] == errno.ECONNABORTED:
+                # If the connection is closed immediately after it is created
-        self.max_buffer_size = 104857600 or max_buffer_size
+        self.max_buffer_size = max_buffer_size or 104857600
-    def __init__(self, io_loop=None, max_buffer_size=104857600,
+    def __init__(self, io_loop=None, max_buffer_size=None,
-        self.max_buffer_size = max_buffer_size
+        self.max_buffer_size = 104857600 or max_buffer_size
-    def __init__(self, io_loop=None, ssl_options=None):
+    def __init__(self, io_loop=None, ssl_options=None, max_buffer_size=None):
-                stream = SSLIOStream(connection, io_loop=self.io_loop)
+                stream = SSLIOStream(connection, io_loop=self.io_loop, max_buffer_size=self.max_buffer_size)
-                stream = IOStream(connection, io_loop=self.io_loop)
+                stream = IOStream(connection, io_loop=self.io_loop, max_buffer_size=self.max_buffer_size)
-        callback()
+        if self._close_callback is not None:
-                "X-Real-Ip", self.headers.get("X-Forwarded-For", self.remote_ip))
+                "X-Real-Ip", ip)
-    `~tornado.web.RequestHandler` ``get``/``post``/etc methods,
+    `~tornado.web.RequestHandler` :ref:`HTTP verb methods <verbs>`,
-    `~tornado.web.RequestHandler` ``get``/``post``/etc methods, this
+    `~tornado.web.RequestHandler` :ref:`HTTP verb methods <verbs>` methods, this
-    or for each test with the ``timeout`` keyword argument:
+    or for each test with the ``timeout`` keyword argument::
-        """Called at the beginning of a request before `get`/`post`/etc.
+        """Called at the beginning of a request before  `get`/`post`/etc.
-                    except AttributeError:
+                    close_method = getattr(fd, 'close', None)
-                    os.close(fd)
+                    try:
-        raise ImportError, "No module named %s" % parts[-1], exc_info[2] 
+        raise ImportError("No module named %s" % parts[-1])
-            oauth_version=getattr(self, "_OAUTH_VERSION", "1.0a"),
+            oauth_version="1.0",
-            oauth_version=getattr(self, "_OAUTH_VERSION", "1.0a"),
+            oauth_version="1.0",
-            oauth_version=getattr(self, "_OAUTH_VERSION", "1.0a"),
+            oauth_version="1.0",
-        assert self.get_argument('oauth_version') == '1.0a'
+        assert self.get_argument('oauth_version') == '1.0'
-            headers = httputil.HTTPHeaders.parse(data[eol:])
+            try:
-        stream.connect(('localhost', self.get_http_port()), self.stop)
+
-        stream.close()
+
-        :arg string auth_mode: Authentication mode (basic, digest)
+        :arg string auth_mode: Authentication mode; default is "basic".
-from tornado.testing import AsyncHTTPTestCase, bind_unused_port, gen_test
+from tornado.testing import AsyncHTTPTestCase, bind_unused_port, gen_test, ExpectLog
-        modified = datetime.datetime.fromtimestamp(stat_result[stat.ST_MTIME])
+        modified = datetime.datetime.utcfromtimestamp(stat_result[stat.ST_MTIME])
-            if_since = datetime.datetime.fromtimestamp(time.mktime(date_tuple))
+            if_since = datetime.datetime(*date_tuple[:6])
-        self.__failure = sys.exc_info()
+        self.__failure = (typ, value, tb)
-        if new_timeout != -1:
+        if new_timeout >= 0:
-                    c = stack[n]
+                while last_ctx > 0:
-                for n in xrange(last_ctx - 1, -1, -1):
+                for n in range(last_ctx - 1, -1, -1):
-            if final_contexts != self.new_contexts:
+            if final_contexts is not self.new_contexts:
-            if final_contexts != self.new_contexts:
+            if final_contexts is not self.new_contexts:
-        with ExceptionStackContext(handle_exception) as deactivate:
+        with ExceptionStackContext(handle_exception):
-        with ExceptionStackContext(handle_exception) as deactivate:
+        with ExceptionStackContext(handle_exception):
-        self.contexts = ()
+        self.contexts = (tuple(), None)
-    def __init__(self, context_factory, _active_cell=None):
+    def __init__(self, context_factory):
-        self.active_cell = _active_cell or [True]
+        self.contexts = []
-                               self.active_cell),))
+        self.new_contexts = (self.old_contexts[0] + (self,), self)
-        except Exception:
+            self.enter()
-            return self.context.__exit__(type, value, traceback)
+            self.exit(type, value, traceback)
-            if final_contexts is not self.new_contexts:
+            if final_contexts != self.new_contexts:
-    def __init__(self, exception_handler, _active_cell=None):
+    def __init__(self, exception_handler):
-        self.active_cell = _active_cell or [True]
+
-                               self.active_cell),))
+        self.new_contexts = (self.old_contexts[0], self)
-            if final_contexts is not self.new_contexts:
+
-        _state.contexts = ()
+        _state.contexts = (tuple(), None)
-    if fn is None or fn.__class__ is _StackContextWrapper:
+    # Check if function is already wrapped
-    #@functools.wraps(fn)
+    # Capture current stack head
-            raise_exc_info(exc)
+        try:
-
+@contextlib.contextmanager
-            yield gen.Task(self.io_loop.add_timeout, self.io_loop.time() + 0.1)
+            time = self.io_loop.time
-        with set_environ('TIMEOUT', '0.1'):
+        with set_environ('ASYNC_TEST_TIMEOUT', '0.1'):
-        with set_environ('TIMEOUT', '0.1'):
+        # Uses environment-variable timeout of 0.1, times out.
-    def wait(self, condition=None, timeout=5):
+    def wait(self, condition=None, timeout=None):
-        In the event of a timeout, an exception will be thrown.
+        In the event of a timeout, an exception will be thrown. The default
-    test with the ``timeout`` keyword argument:
+    overridden globally with the ASYNC_TEST_TIMEOUT environment variable,
-        env_timeout = None
+    if timeout is None:
-
+            time = self.io_loop.time
-
+            time = self.io_loop.time
-import functools
+import contextlib
-                yield gen.Task(add_timeout, time() + 0.25)
+        @gen_test(timeout=0.5)
-                functools.partial(test_long_timeout, self))
+        # Uses provided timeout of 0.5 seconds, doesn't time out.
-                yield gen.Task(add_timeout, time() + 1)
+        self.finished = True
-            # Uses environment TIMEOUT of 0.1, times out.
+    def test_no_timeout_environment_variable(self):
-                os.environ['TIMEOUT'] = old_timeout
+        self.finished = True
-def gen_test(timeout=None):
+def gen_test(func=None, timeout=None):
-    test with the ``timeout`` parameter:
+    test with the ``timeout`` keyword argument:
-    if inspect.isfunction(timeout):
+    if func is not None:
-        return wrap(f)
+        return wrap(func)
-
+        # Used like @gen_test(timeout=10)
-version = "3.0.1"
+version = "3.1.dev2"
-version_info = (3, 0, 1, 0)
+version = "3.1.dev2"
-from tornado import gen
+from tornado import gen, ioloop
-def gen_test(f):
+def gen_test(timeout=None):
-    f = gen.coroutine(f)
+    try:
-    return wrapper
+        return wrap
-version = "3.1.dev1"
+version = "3.0.1"
-version_info = (3, 1, 0, -100)
+version = "3.0.1"
-from tornado.websocket import WebSocketHandler, websocket_connect
+from tornado.httpclient import HTTPError
-    
+
-                'ws://localhost:%d/no_websock' % self.get_http_port(),
+    def test_websocket_http_fail(self):
-            self.fail('Should\'ve caught an Exception')
+        self.assertEqual(cm.exception.code, 404)
-            io_loop, None, request, lambda: None, lambda response: None,
+            io_loop, None, request, lambda: None, self._on_http_response,
-        self.connect_future.set_exception(Exception('Could not connect.'))
+    def _on_http_response(self, response):
-def websocket_connect(url, io_loop=None, callback=None):
+def websocket_connect(url, io_loop=None, callback=None, connect_timeout=None):
-    request = httpclient.HTTPRequest(url)
+    request = httpclient.HTTPRequest(url, connect_timeout=connect_timeout)
-        self.request = request
+        if isinstance(request, _RequestProxy):
-                         callback, fields, response):
+                         future, fields, response):
-            callback(None)
+            future.set_exception(AuthError('Facebook auth error: %s' % str(response)))
-                self._on_get_user_info, callback, session, fields),
+                self._on_get_user_info, future, session, fields),
-    def _on_get_user_info(self, callback, session, fields, user):
+    def _on_get_user_info(self, future, session, fields, user):
-            callback(None)
+            future.set_result(None)
-        callback(fieldmap)
+        future.set_result(fieldmap)
-    def _on_facebook_request(self, callback, response):
+    def _on_facebook_request(self, future, response):
-            callback(None)
+            future.set_exception(AuthError("Error response %s fetching %s", 
-        callback(escape.json_decode(response.body))
+
-except ImportError:
+except ImportError:
-                                "%r" % result)
+                                "%r" % (value,))
-                    "@gen.engine functions cannot return values: %r" % result)
+                    "@gen.engine functions cannot return values: %r" %
-            raise KeyReuseError("key %r is already pending" % key)
+            raise KeyReuseError("key %r is already pending" % (key,))
-            raise UnknownKeyError("key %r is not pending" % key)
+            raise UnknownKeyError("key %r is not pending" % (key,))
-                    self.exc_info = (BadYieldError("yielded unknown object %r" % yielded),)
+                    self.exc_info = (BadYieldError(
-if hasattr(ssl, 'match_hostname'):  # python 3.2+
+if hasattr(ssl, 'match_hostname') and hasattr(ssl, 'CertificateError'):  # python 3.2+
-version = "3.0"
+version = "3.1.dev1"
-version_info = (3, 0, 0, 0)
+version = "3.1.dev1"
-version = "3.0b2"
+version = "3.0"
-version_info = (3, 0, 0, -9)
+version = "3.0"
-        'https://github.com/downloads/facebook/tornado/tornado-%s.tar.g%%s' % version,
+'https://pypi.python.org/packages/source/t/tornado/tornado-%s.tar.g%%s' % version,
-    description="Tornado is an open source version of the scalable, non-blocking web server and and tools that power FriendFeed",
+    description="Tornado is a Python web framework and asynchronous networking library, originally developed at FriendFeed.",
-            "templates/utf8.html",
+            "options_test.cfg",
-from tornado.util import basestring_type
+from tornado.util import basestring_type, exec_in
-        execfile(path, config, config)
+        with open(path) as f:
-version = "3.0b1"
+version = "3.0b2"
-version_info = (3, 0, 0, -10)
+version = "3.0b2"
-        self._write_callback = None
+        self._header_callback = None
-            return method(self, *args, **kwargs)
+            result = method(self, *args, **kwargs)
-        curl.setopt(pycurl.HTTPAUTH, pycurl.HTTPAUTH_BASIC)
+
-                 auth_username=None, auth_password=None,
+                 auth_username=None, auth_password=None, auth_mode=None,
-        :arg string auth_password: Password for HTTP "Basic" authentication
+        :arg string auth_username: Username for HTTP authentication
-        chat["html"] = self.render_string("message.html", message=chat)
+        chat["html"] = tornado.escape.to_basestring(
-from tornado.util import bytes_type
+from tornado.util import bytes_type, unicode_type
-        spaces = len(c for c in key if c.isspace())
+        spaces = len([c2 for c2 in key if c2.isspace()])
-        if isinstance(message, unicode):
+        if isinstance(message, unicode_type):
-        request to the service.
+        Should return a `.Future` whose result is a dictionary
-when `concurrent.futures` is not available.
+"""Utilities for working with threads and ``Futures``.
-    with exceptions.
+    """Subclass of `Future` which can store a traceback with
-    `~concurrent.futures.Future`.
+    `Future`.
-    an exception will be raised into the surrounding `.StackContext`.
+    with `Future.result()` as an argument.  If the function fails, the
-yielding this object returns its `~concurrent.futures.Future.result`.
+Most asynchronous functions in Tornado return a `.Future`;
-    argument is not treated specially.
+    return a `.Future` and the ``callback`` argument is not treated
-    decorator itself.
+    Functions with this decorator return a `.Future`.  Additionally,
-        `HTTPError` if the request returned a non-200 response code.
+        This method returns a `.Future` whose result is an
-        re-raised to the caller.
+        If the function returns a `.Future`, the `IOLoop` will run
-        `~concurrent.futures.Future` is finished.
+        `.Future` is finished.
-        `~concurrent.futures.Future`.
+        `.Future`.
-        with the result as an argument when it is complete.
+        Returns a `.Future` whose result is a list of (family,
-version = "2.4.post4"
+version = "3.0b1"
-version_info = (2, 4, 0, 4)
+# or negative for a release candidate or beta (after the base version
-from tornado.options import define, options
+from tornado import gen
-            self.get_authenticated_user(self.async_callback(self._on_auth))
+            user = yield self.get_authenticated_user()
-    tornado.options.parse_command_line()
+    parse_command_line()
-    chosen with the ``Resolver.configure`` class method::
+    chosen with the `Resolver.configure <.Configurable.configure>`
-    * ``tornado.platform.caresresolver.CaresResolver``
+    * `tornado.platform.twisted.TwistedResolver`
-    the default for `tornado.simple_httpclient`, but other libraries
+    the default for ``tornado.simple_httpclient``, but other libraries
-"""Miscellaneous utility functions."""
+"""Miscellaneous utility functions and classes.
-    """Makes a dictionary behave like an object."""
+    """Makes a dictionary behave like an object, with attribute-style access.
-    specialized subclasses.
+    By using the constructor as the factory method, the interface
-    method `initialize` instead of `__init__`.
+    method `initialize` instead of ``__init__``.
-        Configurable classes should use `initialize` instead of `__init__`.
+        Configurable classes should use `initialize` instead of ``__init__``.
-Tornado non-blocking web server and tools.
+"""``tornado.web`` provides a simple web framework with asynchronous
-Here is the canonical "Hello, world" example app::
+Here is a simple "Hello, world" example app::
-and a good getting started guide.
+See the :doc:`Tornado overview <overview>` for more details and a good getting
-back to the main thread before finishing the request.
+In general, methods on `RequestHandler` and elsewhere in Tornado are
-    """Subclass this class and define get() or post() to make a handler.
+    """Subclass this class and define `get()` or `post()` to make a handler.
-    RequestHandler class.
+    should override the class variable ``SUPPORTED_METHODS`` in your
-        """An alias for ``self.application.settings``."""
+        """An alias for `self.application.settings <Application.settings>`."""
-        values extracted from the url and passed to get()/post()/etc.
+        This method is used as a filter for both `get_argument()` and for
-        (if you want to send JSON as a different Content-Type, call
+        the Content-Type of the response to be ``application/json``.
-        as a response, use render() above.
+        We return the generated byte string (in utf8). To generate and
-        Determined by either get_user_locale, which you can override to
+        Determined by either `get_user_locale`, which you can override to
-        database, or get_browser_locale, which uses the Accept-Language
+        database, or `get_browser_locale`, which uses the ``Accept-Language``
-        If None is returned, we fall back to get_browser_locale().
+        If None is returned, we fall back to `get_browser_locale()`.
-        most likely obtained via a call like tornado.locale.get("en")
+        This method should return a `tornado.locale.Locale` object,
-        """Determines the user's locale from Accept-Language header.
+        """Determines the user's locale from ``Accept-Language`` header.
-        overridden, this method always returns None.
+        This is a cached version of `get_current_user`, which you can
-        By default, we use the 'login_url' application setting.
+        By default, we use the ``login_url`` application setting.
-        By default, we use the 'template_path' application setting.
+        By default, we use the ``template_path`` application setting.
-        """Verifies that the '_xsrf' cookie matches the '_xsrf' argument.
+        """Verifies that the ``_xsrf`` cookie matches the ``_xsrf`` argument.
-        To prevent cross-site request forgery, we set an '_xsrf'
+        To prevent cross-site request forgery, we set an ``_xsrf``
-        field with all POST requests. If the two do not match, we
+        field with all ``POST`` requests. If the two do not match, we
-        or in a custom HTTP header named X-XSRFToken or X-CSRFToken
+        The ``_xsrf`` value may be set as either a form field named ``_xsrf``
-        "X-Requested-With: XMLHTTPRequest" was present.  This exception
+        ``X-Requested-With: XMLHTTPRequest`` was present.  This exception
-        """An HTML <input/> element to be included with all POST forms.
+        """An HTML ``<input/>`` element to be included with all POST forms.
-        It defines the _xsrf input value, which we check on all POST
+        It defines the ``_xsrf`` input value, which we check on all POST
-        the 'xsrf_cookies' application setting, you must include this
+        the ``xsrf_cookies`` application setting, you must include this
-        See check_xsrf_cookie() above for more information.
+        In a template, this method should be called with ``{% module
-        This method requires you set the 'static_path' setting in your
+        This method requires you set the ``static_path`` setting in your
-        We append ?v=<signature> to the returned URL, which makes our
+        We append ``?v=<signature>`` to the returned URL, which makes our
-    automatically finished when the get() or post() method returns. ::
+    method returns. It is up to the request handler to call
-    For example, a request to ``'/foo/'`` would redirect to ``'/foo'`` with this
+    For example, a request to ``/foo/`` would redirect to ``/foo`` with this
-    For example, a request to '/foo' would redirect to '/foo/' with this
+    For example, a request to ``/foo`` would redirect to ``/foo/`` with this
-    like r'/foo/?' in conjunction with using the decorator.
+    like ``r'/foo/?'`` in conjunction with using the decorator.
-    The constructor for this class takes in a list of URLSpec objects
+    The constructor for this class takes in a list of `URLSpec` objects
-    below)::
+    Each tuple can contain an optional third element, which should be
-    We support virtual hosts with the add_handlers method, which takes in
+    We support virtual hosts with the `add_handlers` method, which takes in
-    static_handler_class setting.
+    You can serve static files by sending the ``static_path`` setting
-        methods directly.
+        This is a convenience alias for creating an `.HTTPServer`
-        IOLoop.instance().start() to start the server.
+        ``IOLoop.instance().start()`` to start the server.
-        The handler must be added to the application as a named URLSpec.
+        The handler must be added to the application as a named `URLSpec`.
-        Args will be substituted for capturing groups in the URLSpec regex.
+        Args will be substituted for capturing groups in the `URLSpec` regex.
-        'log_function'.
+        ``log_function``.
-    """Generates an error response with status_code for all requests."""
+    """Generates an error response with ``status_code`` for all requests."""
-    You should provide the keyword argument "url" to the handler, e.g.::
+    You should provide the keyword argument ``url`` to the handler, e.g.::
-    To map a path to this handler for a static data directory /var/www,
+    To map a path to this handler for a static data directory ``/var/www``,
-    The local root directory of the content should be passed as the "path"
+    The local root directory of the content should be passed as the ``path``
-    To support aggressive browser caching, if the argument "v" is given
+    To support aggressive browser caching, if the argument ``v`` is given
-    /static/images/myimage.png?v=xxx. Override ``get_cache_time`` method for
+    ``/static/images/myimage.png?v=xxx``. Override `get_cache_time` method for
-        to mark resource as cacheable, only.
+        Return a positive number of seconds to make the result
-        with "v" argument.
+        with ``v`` argument.
-    """A RequestHandler that wraps another HTTP server callback.
+    """A `RequestHandler` that wraps another HTTP server callback.
-    Typical usage::
+    The fallback is a callable object that accepts an
-    """Decorate methods with this to require that the user be logged in."""
+    """Decorate methods with this to require that the user be logged in.
-    """A UI re-usable, modular unit on a page.
+    """A re-usable, modular UI unit on a page.
-        Parameters:
+        """Parameters:
-            arguments.
+        * ``pattern``: Regular expression to be matched.  Any groups
-        handler_class: RequestHandler subclass to be invoked.
+        * ``handler_class``: `RequestHandler` subclass to be invoked.
-            to the handler's constructor.
+        * ``kwargs`` (optional): A dictionary of additional arguments
-            Application.reverse_url.
+        * ``name`` (optional): A name for this handler.  Used by
-"""Server-side implementation of the WebSocket protocol.
+"""Implementation of the WebSocket protocol.
-    open and on_close to handle opened and closed connections.
+    Override `on_message` to handle incoming messages, and use
-    Here is an example Web Socket handler that echos back all received messages
+    Here is an example WebSocket handler that echos back all received messages
-    implement open() method rather than get() or post().
+    WebSockets are not standard HTTP connections. The "handshake" is
-    If you map the handler above to "/websocket" in your application, you can
+    If you map the handler above to ``/websocket`` in your application, you can
-        """Wrap callbacks with this if they are used on asynchronous requests.
+        """Obsolete - catches exceptions from the wrapped function.
-        `tornado.stack_context`)
+        This function is normally unncecessary thanks to
-    WSGIApplication, we throw an exception.
+    `WSGIApplication` is very similar to `tornado.web.Application`,
-    a Tornado app on Google AppEngine.
+    See the `appengine demo
-    do not support flush() or asynchronous methods.
+    WSGI applications use the same `.RequestHandler` class, but not
-        """Parses the given WSGI environ to construct the request."""
+        """Parses the given WSGI environment to construct the request."""
-    Wrap a WSGI function in a WSGIContainer and pass it to HTTPServer to
+    Wrap a WSGI function in a `WSGIContainer` and pass it to `.HTTPServer` to
-    or socket.AF_INET6 to restrict to ipv4 or ipv6 addresses, otherwise
+    available interfaces.  Family may be set to either `socket.AF_INET`
-    ``socket.listen()``.
+    `socket.listen() <socket.socket.listen>`.
-    ``flags`` is a bitmask of AI_* flags to ``getaddrinfo``, like
+    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like
-    """Adds an ``IOLoop`` event handler to accept new connections on ``sock``.
+    """Adds an `.IOLoop` event handler to accept new connections on ``sock``.
-    ``IOLoop`` handlers.
+    `.IOLoop` handlers.
-        argument when it is complete.
+        to pass to `socket.connect <socket.socket.connect>` (i.e. a
-    """Try to Convert an ssl_options dictionary to an SSLContext object.
+    """Try to convert an ``ssl_options`` dictionary to an
-The main() method of your application does not need to be aware of all of
+The ``main()`` method of your application does not need to be aware of all of
-Your main() method can parse the command line or parse a config file with
+Your ``main()`` method can parse the command line or parse a config file with
-Command line formats are what you would expect ("--myoption=myvalue").
+Command line formats are what you would expect (``--myoption=myvalue``).
-for define() below.
+We support `datetimes <datetime.datetime>`, `timedeltas
-        arguments based on the given type. If multiple is True, we accept
+        If ``type`` is given (one of str, float, int, datetime, or timedelta)
-        turns into range(x, y) - very useful for long integer ranges.
+        For multi-value integers, we also accept the syntax ``x:y``, which
-        command line help string. The help message is formatted like::
+        ``help`` and ``metavar`` are used to construct the
-        group is used to group the defined options in logical
+        ``group`` is used to group the defined options in logical
-        config file with parse_config_file.
+        from the command line with `parse_command_line` or parsed from a
-        If a callback is given, it will be run with the new value whenever
+        If a ``callback`` is given, it will be run with the new value whenever
-        """Parses all options given on the command line (defaults to sys.argv).
+        """Parses all options given on the command line (defaults to
-        Note that args[0] is ignored since it is the program name in sys.argv.
+        Note that ``args[0]`` is ignored since it is the program name
-"""Utilities for working with multiple processes."""
+"""Utilities for working with multiple processes, including both forking
-        Note that the IOLoop used for signal handling need not be the
+        The signal handler is run on an `.IOLoop` to avoid locking issues.
-        IOLoops are each running in separate threads).
+        ``IOLoops`` are each running in separate threads).
-"""StackContext allows applications to maintain threadlocal-like state
+"""`StackContext` allows applications to maintain threadlocal-like state
-async_callback wrappers (as in tornado.web.RequestHandler), and to
+``async_callback`` wrappers (as in `tornado.web.RequestHandler`), and to
-itself, IOLoop, thread pools, etc).
+This is slightly magic, but it's an extension of the idea that an
-    The supplied exception_handler function will be called in the
+    The supplied ``exception_handler`` function will be called in the
-    exc_info triple (type, value, traceback) will be passed to the
+    ``exc_info`` triple ``(type, value, traceback)`` will be passed to the
-    """Resets the StackContext.
+    """Resets the `StackContext`.
-    operations.
+    Useful when creating a shared resource on demand (e.g. an
-    """Returns a callable object that will restore the current StackContext
+    """Returns a callable object that will restore the current `StackContext`
-        or ``socket.AF_INET6`` to restrict to ipv4 or ipv6 addresses, otherwise
+        available interfaces.  Family may be set to either `socket.AF_INET`
-        `socket.socket.listen`.
+        `socket.listen <socket.socket.listen>`.
-        """Starts this server in the IOLoop.
+        """Starts this server in the `.IOLoop`.
-        use the filesystem.
+    """Base class for template loaders.
-        autoescape must be either None or a string naming a function
+    You must use a template loader to use template constructs like
-This module contains three parts:
+* `AsyncTestCase` and `AsyncHTTPTestCase`:  Subclasses of unittest.TestCase
-  from tests that pass and only produces output for failing tests.
+* `ExpectLog` and `LogTrapTestCase`: Make test logs less spammy.
-    as self.io_loop.  This IOLoop should be used in the construction of
+    """`~unittest.TestCase` subclass for testing `.IOLoop`-based
-    global IOLoop, subclasses should override get_new_ioloop to return it.
+    global `.IOLoop`, subclasses should override `get_new_ioloop` to return it.
-    wait/stop cycles in the same test.
+    The `.IOLoop`'s ``start`` and ``stop`` methods should not be
-        # application code.
+        # This test uses argument passing between self.stop and self.wait.
-        the singleton).
+        """Creates a new `.IOLoop` for this test.  May be overridden in
-        """Stops the ioloop, causing one pending (or future) call to wait()
+        """Stops the `.IOLoop`, causing one pending (or future) call to `wait()`
-        saved and will be returned by wait().
+        Keyword arguments or a single positional argument passed to `stop()` are
-        """Runs the IOLoop until stop is called or timeout has passed.
+        """Runs the `.IOLoop` until stop is called or timeout has passed.
-        until condition() returns true.
+        If ``condition`` is not None, the `.IOLoop` will be restarted
-    Tests will typically use the provided self.http_client to fetch
+    Subclasses must override `get_app()`, which returns the
-        tornado.web.Application or other HTTPServer callback.
+        `tornado.web.Application` or other `.HTTPServer` callback.
-        body="...", etc).
+        The given path will be appended to the local server's host and
-    ("class MyTestCase(AsyncHTTPTestCase, LogTrapTestCase):")
+    (``class MyTestCase(AsyncHTTPTestCase, LogTrapTestCase):``)
-    by some test runners.
+    This class assumes that only one log handler is configured and
-    be overridden by naming a single test on the command line::
+    ``tornado/test/runtests.py``.  This script should define a method
-* ``curl_httpclient`` is faster
+* ``curl_httpclient`` is faster.
-        except httpclient.HTTPError, e:
+        except httpclient.HTTPError as e:
-        http_client = httpclient.AsyncHTTPClient()
+        http_client = AsyncHTTPClient()
-    its constructor can be set with the static method configure()
+
-        """Destroys this http client, freeing any file descriptors used.
+        """Destroys this HTTP client, freeing any file descriptors used.
-        on the AsyncHTTPClient after close().
+        on the `AsyncHTTPClient` after ``close()``.
-        """Executes a request, calling callback with an `HTTPResponse`.
+        """Executes a request, asynchronously returning an `HTTPResponse`.
-        throw the exception (if any) in the callback.
+        This method returns a `~concurrent.futures.Future` whose
-        """Configures the AsyncHTTPClient subclass to use.
+        """Configures the `AsyncHTTPClient` subclass to use.
-        AsyncHTTPClient() actually creates an instance of a subclass.
+        ``AsyncHTTPClient()`` actually creates an instance of a subclass.
-        SimpleAsyncHTTPClient)
+        fully-qualified name of such a class (or ``None`` to use the default,
-        on the implementation class in use.
+        keyword argument ``max_clients`` determines the maximum number
-        All parameters except ``url`` are optional.
+        r"""All parameters except ``url`` are optional.
-           header
+        :arg if_modified_since: Timestamp for ``If-Modified-Since`` header
-           to mix requests with ca_certs and requests that use the defaults.
+           to mix requests with ``ca_certs`` and requests that use the defaults.
-        server's actual response)
+      (with curl_httpclient, this is a default value rather than the
-    * headers: httputil.HTTPHeaders object
+    * headers: `tornado.httputil.HTTPHeaders` object
-    * buffer: cStringIO object for response body
+    * buffer: ``cStringIO`` object for response body
-    * body: response body as string (created on demand from self.buffer)
+    * body: response body as string (created on demand from ``self.buffer``)
-        a slot under AsyncHTTPClient's max_clients setting.
+      Available data are subject to change, but currently uses timings
-           used when no HTTP response was received, e.g. for a timeout.
+    * ``code`` - HTTP error integer error code, e.g. 404.  Error code 599 is
-    response - HTTPResponse object, if any.
+    * ``response`` - `HTTPResponse` object, if any.
-    and you can look at error.response.headers['Location'] to see the
+    Note that if ``follow_redirects`` is False, redirects become HTTPErrors,
-        import ioloop
+        import tornado.httpserver
-        http_server = httpserver.HTTPServer(handle_request)
+        http_server = tornado.httpserver.HTTPServer(handle_request)
-        ioloop.IOLoop.instance().start()
+        tornado.ioloop.IOLoop.instance().start()
-    To make this server serve SSL traffic, send the ssl_options dictionary
+    To make this server serve SSL traffic, send the ``ssl_options`` dictionary
-    an `ssl.SSLContext` object instead of a dict::
+    including ``certfile`` and ``keyfile``.  (In Python 3.2+ you can pass
-    """A dictionary that maintains Http-Header-Case for all keys.
+    """A dictionary that maintains ``Http-Header-Case`` for all keys.
-    value per key, with multiple values joined by a comma.
+    `add()` and `get_list()`.  The regular dictionary interface
-    attributes are also accessible as dictionary keys.
+    """Represents a file uploaded via a form.
-    that will be updated with the parsed contents.
+    Supports ``application/x-www-form-urlencoded`` and
-    """Parses a multipart/form-data body.
+    """Parses a ``multipart/form-data`` body.
-    The boundary and data parameters are both byte strings.
+    The ``boundary`` and ``data`` parameters are both byte strings.
-    epoll or kqueue.
+    We use ``epoll`` (Linux) or ``kqueue`` (BSD and Mac OS X) if they
-        """Returns a global IOLoop instance.
+        """Returns a global `IOLoop` instance.
-                    self.io_loop = io_loop or IOLoop.instance()
+        Most applications have a single, global `IOLoop` running on the
-        """Installs this IOloop object as the singleton instance.
+        """Installs this `IOLoop` object as the singleton instance.
-        a custom subclass of IOLoop.
+        an `IOLoop` on demand, but you may want to call `install` to use
-        """Closes the IOLoop, freeing any resources used.
+        """Closes the `IOLoop`, freeing any resources used.
-        IOLoop will be closed (not just the ones created by the IOLoop itself).
+        IOLoop will be closed (not just the ones created by the
-        entire lifetime of the process.  In that case closing the IOLoop
+        Many applications will only use a single `IOLoop` that runs for the
-        IOLoops.
+        ``IOLoops``.
-        An IOLoop must be completely stopped before it can be closed.  This
+        An `IOLoop` must be completely stopped before it can be closed.  This
-        """Registers the given handler to receive the given events for fd."""
+        """Registers the given handler to receive the given events for fd.
-        """Sends a signal if the ioloop is blocked for more than s seconds.
+        """Sends a signal if the `IOLoop` is blocked for more than
-        Pass seconds=None to disable.  Requires python 2.6 on a unixy
+        Pass ``seconds=None`` to disable.  Requires Python 2.6 on a unixy
-        too long.
+        The action parameter is a Python signal handler.  Read the
-        Equivalent to set_blocking_signal_threshold(seconds, self.log_stack)
+        """Logs a stack trace if the `IOLoop` is blocked for more than
-        For use with set_blocking_signal_threshold.
+        For use with `set_blocking_signal_threshold`.
-        The loop will run until one of the I/O handlers calls stop(), which
+        The loop will run until one of the callbacks calls `stop()`, which
-        If the event loop is not currently running, the next call to start()
+        If the event loop is not currently running, the next call to `start()`
-        whether that callback was invoked before or after ioloop.start.
+        ``ioloop.start()`` will return after ``async_method`` has run
-        Note that even after `stop` has been called, the IOLoop is not
+        Note that even after `stop` has been called, the `IOLoop` is not
-        be run before the IOLoop shuts down.
+        be run before the `IOLoop` shuts down.
-        """Returns the current time according to the IOLoop's clock.
+        """Returns the current time according to the `IOLoop`'s clock.
-        By default, the IOLoop's time function is `time.time`.  However,
+        By default, the `IOLoop`'s time function is `time.time`.  However,
-        """Calls the given callback at the time deadline from the I/O loop.
+        """Runs the ``callback`` at the time ``deadline`` from the I/O loop.
-        Returns a handle that may be passed to remove_timeout to cancel.
+        Returns an opaque handle that may be passed to
-        deadline relative to the current time.
+        ``deadline`` may be a number denoting a time (on the same
-        IOLoop's thread, and then call `add_timeout` from there.
+        `IOLoop`'s thread, and then call `add_timeout` from there.
-        The argument is a handle as returned by add_timeout.  It is
+        The argument is a handle as returned by `add_timeout`.  It is
-        control from other threads to the IOLoop's thread.
+        except from a signal handler.  Note that this is the **only**
-        stack_context, to avoid picking up the context of the function
+        `.stack_context`, to avoid picking up the context of the function
-        """Schedules a callback on the IOLoop when the given future is finished.
+        """Schedules a callback on the ``IOLoop`` when the given
-        The callback is invoked with one argument, the future.
+        The callback is invoked with one argument, the
-        """This method is called whenever a callback run by the IOLoop
+        """This method is called whenever a callback run by the `IOLoop`
-        in sys.exc_info.
+        in `sys.exc_info`.
-    The callback is called every callback_time milliseconds.
+    The callback is called every ``callback_time`` milliseconds.
-    `start` must be called after the PeriodicCallback is created.
+    `start` must be called after the `PeriodicCallback` is created.
-        should return no more than ``self.read_chunk_size`` bytes at a time.
+        Returns ``None`` if there was nothing to read (the socket
-        This method is called after the IOLoop has signaled an error on the
+        This method is called after the `.IOLoop` has signaled an error on the
-        """Call callback when we read the given regex pattern."""
+        """Run ``callback`` when we read the given regex pattern.
-        """Call callback when we read the given delimiter."""
+        """Run ``callback`` when we read the given delimiter.
-        """Call callback when we read the given number of bytes.
+        """Run callback when we read the given number of bytes.
-        ``callback`` will be empty.
+        ``callback`` will be empty.  Otherwise, the ``callback`` gets
-        ``callback`` will be empty.
+        ``callback`` will be empty.  Otherwise, the ``callback`` gets the
-        If callback is given, we call it when all of the buffered write
+        If ``callback`` is given, we call it when all of the buffered write
-    r"""Socket-based IOStream implementation.
+    r"""Socket-based `IOStream` implementation.
-    connected with IOStream.connect.
+    The ``socket`` parameter may either be connected or unconnected.
-        from tornado import iostream
+        import tornado.ioloop
-            stream.read_until("\r\n\r\n", on_headers)
+            stream.write(b"GET / HTTP/1.0\r\nHost: friendfeed.com\r\n\r\n")
-               parts = line.split(":")
+            for line in data.split(b"\r\n"):
-            stream.read_bytes(int(headers["Content-Length"]), on_body)
+            stream.read_bytes(int(headers[b"Content-Length"]), on_body)
-            ioloop.IOLoop.instance().stop()
+            tornado.ioloop.IOLoop.instance().stop()
-        stream = iostream.IOStream(s)
+        stream = tornado.iostream.IOStream(s)
-        ioloop.IOLoop.instance().start()
+        tornado.ioloop.IOLoop.instance().start()
-        connection is completed.
+        same format as for `socket.connect <socket.socket.connect>`,
-        but is non-portable.
+        Note that it is safe to call `IOStream.write
-    wrapped when IOStream.connect is finished.
+    before constructing the `SSLIOStream`.  Unconnected sockets will be
-        The ``ssl_options`` keyword argument may either be a dictionary
+        """The ``ssl_options`` keyword argument may either be a dictionary
-    """Pipe-based IOStream implementation.
+    """Pipe-based `IOStream` implementation.
-    by `os.pipe`) rather than an open file object.
+    by `os.pipe`) rather than an open file object.  Pipes are generally
-    user_locale = locale.get("es_LA")
+    user_locale = tornado.locale.get("es_LA")
-locale.get() returns the closest matching locale, not necessarily the
+`tornado.locale.get()` returns the closest matching locale, not necessarily the
-additional arguments to translate(), e.g.::
+additional arguments to `~Locale.translate()`, e.g.::
-The first string is chosen if len(people) == 1, otherwise the second
+The first string is chosen if ``len(people) == 1``, otherwise the second
-the locale.translate method will simply return the original string.
+Applications should call one of `load_translations` (which uses a simple
-    By default we return en_US if no translations are found for any of
+    By default we return ``en_US`` if no translations are found for any of
-    set_default_locale() below.
+    `set_default_locale()`.
-    """Sets the default locale, used in get_closest_locale().
+    """Sets the default locale.
-    (e.g., "My name is %(name)s") and their associated translations.
+    (e.g., ``My name is %(name)s``) and their associated translations.
-    e.g. es_GT.csv. The CSV files should have two or three columns: string,
+    The directory should have translation files of the form ``LOCALE.csv``,
-    and plural forms. For example "%(name)s liked this" may have a
+    and plural forms. For example ``%(name)s liked this`` may have a
-    The file is read using the csv module in the default "excel" dialect.
+    The file is read using the `csv` module in the default "excel" dialect.
-    Example translation es_LA.csv::
+    Example translation ``es_LA.csv``::
-    """Loads translations from gettext's locale tree
+    """Loads translations from `gettext`'s locale tree
-    Locale tree is similar to system's /usr/share/locale, like:
+    Locale tree is similar to system's ``/usr/share/locale``, like::
-    {directory}/{lang}/LC_MESSAGES/{domain}.mo
+        {directory}/{lang}/LC_MESSAGES/{domain}.mo
-        xgettext --language=Python --keyword=_:1,2 -d cyclone file1.py file2.html etc
+    1. Generate POT translation file::
-        msgmerge old.po cyclone.po > new.po
+        xgettext --language=Python --keyword=_:1,2 -d mydomain file1.py file2.html etc
-        msgfmt cyclone.po -o {directory}/pt_BR/LC_MESSAGES/cyclone.mo
+    2. Merge against existing POT file::
-        for the given message when count == 1.
+        If ``plural_message`` is given, you must also provide
-        can return an absolute date string with relative=False.
+        can return an absolute date string with ``relative=False``.
-        full_format=True.
+        ``full_format=True``.
-        dow=False.
+        ``dow=False``.
-    """Locale implementation using the gettext module."""
+    """Locale implementation using the `gettext` module."""
-        and should not be trusted outright given that it can be easily forged.
+    * ``filename``
-#
+# -*- coding: utf-8 -*-
-    u("""Loads translations from CSV files in a directory.
+    """Loads translations from CSV files in a directory.
-    Example translation es_LA.csv:
+    Example translation es_LA.csv::
-        "%(name)s liked this","A %(name)s le gust\u00f3 esto","singular"
+        "%(name)s liked this","A %(name)s les gustÃ³ esto","plural"
-    """)
+    """
-`simple_httpclient` and `curl_httpclient`.  Applications may either
+``simple_httpclient`` and ``curl_httpclient``.  Applications may either
-The default implementation is `simple_httpclient`, and this is expected
+The default implementation is ``simple_httpclient``, and this is expected
-to switch to `curl_httpclient` for reasons such as the following:
+to switch to ``curl_httpclient`` for reasons such as the following:
-* `curl_httpclient` has some features not found in `simple_httpclient`,
+* ``curl_httpclient`` has some features not found in ``simple_httpclient``,
-* `curl_httpclient` is more likely to be compatible with sites that are
+* ``curl_httpclient`` is more likely to be compatible with sites that are
-* `simple_httpclient` only supports SSL on Python 2.6 and above.
+* ``simple_httpclient`` only supports SSL on Python 2.6 and above.
-* `curl_httpclient` is faster
+* ``curl_httpclient`` is faster
-* `curl_httpclient` was the default prior to Tornado 2.0.
+* ``curl_httpclient`` was the default prior to Tornado 2.0.
-Note that if you are using `curl_httpclient`, it is highly recommended that
+Note that if you are using ``curl_httpclient``, it is highly recommended that
-        All parameters except `url` are optional.
+        All parameters except ``url`` are optional.
-        :arg int max_redirects: Limit for `follow_redirects`
+        :arg int max_redirects: Limit for ``follow_redirects``
-        :arg callable streaming_callback: If set, `streaming_callback` will
+        :arg callable streaming_callback: If set, ``streaming_callback`` will
-           `~HTTPResponse.body` and `~HTTPResponse.buffer` will be empty in
+           ``HTTPResponse.body`` and ``HTTPResponse.buffer`` will be empty in
-        :arg callable header_callback: If set, `header_callback` will
+        :arg callable header_callback: If set, ``header_callback`` will
-           characters).  `~HTTPResponse.headers` will be empty in the final
+           characters).  ``HTTPResponse.headers`` will be empty in the final
-           `streaming_callback`, because it's the only way to get access to
+           ``streaming_callback``, because it's the only way to get access to
-           `setopt` calls.
+           a ``pycurl.Curl`` object to allow the application to make additional
-           with `curl_httpclient`.
+           ``proxy_host`` and ``proxy_port`` must be set; ``proxy_username`` and
-        :arg bool allow_nonstandard_methods: Allow unknown values for `method`
+        :arg bool allow_nonstandard_methods: Allow unknown values for ``method``
-           don't have to all use the same `ca_certs`, but it's not possible
+           or None to use defaults.  Note that in ``curl_httpclient``, if
-           `simple_httpclient` and true in `curl_httpclient`
+           ``simple_httpclient`` and true in ``curl_httpclient``
-       the server on the default singleton `IOLoop`.
+       When using this interface, an `.IOLoop` must *not* be passed
-       `tornado.netutil.bind_sockets`.
+       The `~.TCPServer.add_sockets` interface is more complicated,
-        directly (which was the recommended approach prior to Tornado 3.0).
+        Use this instead of accessing
-       `HTTPHeader` dictionary-like object for request headers.  Acts like
+       `.HTTPHeaders` dictionary-like object for request headers.  Acts like
-       Client's IP address as a string.  If `HTTPServer.xheaders` is set,
+       Client's IP address as a string.  If ``HTTPServer.xheaders`` is set,
-       The protocol used, either "http" or "https".  If `HTTPServer.xheaders`
+       The protocol used, either "http" or "https".  If ``HTTPServer.xheaders``
-       `RequestHandler.get_argument`, which returns argument values as
+       `.RequestHandler.get_argument`, which returns argument values as
-       names to lists of :class:`HTTPFile`.
+       names to lists of `.HTTPFile`.
-    a time tuple as returned by `time.gmtime()`, or a `datetime.datetime`
+    The argument may be a numeric timestamp as returned by `time.time`,
-        will stop and the exception will be re-raised to the caller.
+        If the function returns a `~concurrent.futures.Future`, the
-        to allow asynchronous calls in a `main()` function::
+        to allow asynchronous calls in a ``main()`` function::
-    When a stream is closed due to an error, the IOStream's `error`
+    When a stream is closed due to an error, the IOStream's ``error``
-        exception from `sys.exc_info()` (or if ``exc_info`` is a tuple,
+        exception from `sys.exc_info` (or if ``exc_info`` is a tuple,
-    can be chosen with the `Resolver.configure` class method::
+    By default, a blocking implementation is used (which simply calls
-    * `tornado.platform.caresresolver.CaresResolver`
+    * ``tornado.platform.twisted.TwistedResolver``
-        it is complete.
+        Returns a `~concurrent.futures.Future` whose result is a list
-    callback will not be run until the next `IOLoop` iteration.
+    The `.IOLoop` will be blocked during the resolution, although the
-    `ssl.wrap_sockets`.  In Python 3.2+, `ssl.SSLContext` objects can
+    `ssl.wrap_socket`.  In Python 3.2+, `ssl.SSLContext` objects can
-    accepts both forms needs to upgrade to the `SSLContext` version
+    `~ssl.SSLContext` equivalent, and may be used when a component which
-    """Returns an `ssl.SSLSocket` wrapping the given socket.
+    """Returns an ``ssl.SSLSocket`` wrapping the given socket.
-    (either the `SSLContext` method or the `ssl` module function
+    `ssl_options_to_context`) or an `ssl.SSLContext` object.
-        option values::
+        """Returns a wrapper around self that is compatible with
-      attribute of the resulting Subprocess a `PipeIOStream`.
+      ``tornado.process.Subprocess.STREAM``, which will make the corresponding
-  `stack_context.wrap()` before any asynchronous operations to capture the
+  `.stack_context.wrap()` before any asynchronous operations to capture the
-       When using this interface, an `IOLoop` must *not* be passed
+       When using this interface, an `.IOLoop` must *not* be passed
-       the server on the default singleton `IOLoop`.
+       the server on the default singleton `.IOLoop`.
-       `bind_sockets`.
+       `~tornado.netutil.bind_sockets`.
-        the `IOLoop`.
+        the `.IOLoop`.
-        those returned by `bind_sockets`.
+        those returned by `~tornado.netutil.bind_sockets`.
-        `socket.listen`.
+        `socket.socket.listen`.
-        """Override to handle a new `IOStream` from an incoming connection."""
+        """Override to handle a new `.IOStream` from an incoming connection."""
-hand, but instead use the `render` and `render_string` methods of
+hand, but instead use the `~.RequestHandler.render` and
-on the ``template_path`` `Application` setting.
+on the ``template_path`` `.Application` setting.
-    autoescaping can also be configured globally, at the `Application`
+    autoescaping can also be configured globally, at the `.Application`
-    ``@gen.coroutine`` cannot be used on tests because the `IOLoop` is not
+    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not
-        """An alias for `self.application.settings`."""
+        """An alias for ``self.application.settings``."""
-            it must be present in `httplib.responses`.
+        :arg int status_code: Response status code. If ``reason`` is ``None``,
-            code. If ``None``, it will be filled in from `httplib.responses`.
+            code. If ``None``, it will be filled in from
-        """Returns a URL path for handler named `name`
+        """Returns a URL path for handler named ``name``
-        `httplib.responses` unless the ``reason`` keyword argument is given.
+        `httplib.responses <http.client.responses>` unless the ``reason``
-    Takes a url and returns a Future whose result is a `WebSocketConnection`.
+    Takes a url and returns a Future whose result is a
-from tornado.options import define, options
+from tornado import gen
-class Application(tornado.web.Application):
+class MessageBuffer(object):
-    cache_size = 200
+        self.waiters = set()
-                callback(recent)
+            new_count = 0
-        cls.waiters.add(callback)
+        self.waiters.add(callback)
-        cls.waiters.remove(callback)
+        self.waiters.remove(callback)
-        for callback in cls.waiters:
+        logging.info("Sending new message to %r listeners", len(self.waiters))
-            cls.cache = cls.cache[-self.cache_size:]
+        self.waiters = set()
-class MessageNewHandler(BaseHandler, MessageMixin):
+
-        message["html"] = self.render_string("message.html", message=message)
+        # to_basestring is necessary for Python 3's json encoder,
-        self.new_messages([message])
+        global_message_buffer.new_messages([message])
-class MessageUpdatesHandler(BaseHandler, MessageMixin):
+class MessageUpdatesHandler(BaseHandler):
-                               cursor=cursor)
+        global_message_buffer.wait_for_messages(self.on_new_messages,
-        self.cancel_wait(self.on_new_messages)
+        global_message_buffer.cancel_wait(self.on_new_messages)
-            self.get_authenticated_user(self.async_callback(self._on_auth))
+            user = yield self.get_authenticated_user()
-    app = Application()
+    parse_command_line()
-        @gen.engine
+        @gen.coroutine
-            response = yield gen.Task(http_client.fetch, "http://example.com")
+            response = yield http_client.fetch("http://example.com")
-argument.  You can also yield a list of ``Tasks``, which will be
+Most asynchronous functions in Tornado return a `~concurrent.futures.Future`;
-                                      gen.Task(http_client.fetch, url2)]
+        response1, response2 = yield [http_client.fetch(url1),
-        @gen.engine
+        @gen.coroutine
-    """Decorator for asynchronous generators.
+    """Callback-oriented decorator for asynchronous generators.
-    don't already take a callback argument.
+    This is an older interface; for new code that does not need to be
-    (prior to Python 3.3 generators were not allowed to also return values.
+    """Decorator for asynchronous generators.
-    into the surrounding `StackContext`.
+    Any generator that yields objects from this module must be wrapped
-    """Base class for objects that may be yielded from the generator."""
+    """Base class for objects that may be yielded from the generator.
-    """Returns the results of multiple previous `Callbacks`.
+    """Returns the results of multiple previous `Callbacks <Callback>`.
-        """Returns the `AsyncHTTPClient` instance to be used for auth requests.
+        """Returns the `.AsyncHTTPClient` instance to be used for auth requests.
-        using ``access_token`` to make a request to the service.
+        Should return a `~concurrent.futures.Future` whose result is a
-        For backwards compatibility, the callback-based `_oauth_get_user`
+        For backwards compatibility, the callback-based ``_oauth_get_user``
-        """Returns the `AsyncHTTPClient` instance to be used for auth requests.
+        """Returns the `.AsyncHTTPClient` instance to be used for auth requests.
-        `get_authenticated_user()` in the handler for your
+        ``get_authenticated_user`` in the handler for your
-    custom Twitter user attributes described at
+    The user object returned by `~OAuthMixin.get_authenticated_user`
-    `~OpenIDMixin.authenticate_redirect`.  If you need to make
+    `~OpenIdMixin.authenticate_redirect`.  If you need to make
-    `~OpenIDMixin.get_authenticated_user()`. We send a dict containing
+    `~OpenIdMixin.get_authenticated_user`. We send a dict containing
-        """Returns the `AsyncHTTPClient` instance to be used for auth requests.
+        """Returns the `.AsyncHTTPClient` instance to be used for auth requests.
-        """Returns the `AsyncHTTPClient` instance to be used for auth requests.
+        """Returns the `.AsyncHTTPClient` instance to be used for auth requests.
-"""Automatically restart the server when a source file is modified.
+"""xAutomatically restart the server when a source file is modified.
-and Google App Engine.  It also will not work correctly when `HTTPServer`'s
+This module depends on `.IOLoop`, so it will not work in WSGI applications
-    """Begins watching source files for changes using the given `IOLoop`. """
+    """Begins watching source files for changes using the given `.IOLoop`. """
-    hook to close them.
+    ``tornado.platform.auto.set_close_exec``) instead
-    """Subclass of `Future` which can store a traceback with exceptions.
+    """Subclass of `~concurrent.futures.Future` which can store a traceback
-        """Traceback-aware replacement for `Future.set_exception`."""
+        """Traceback-aware replacement for
-    """Decorator to make a function that returns via callback return a `Future`.
+    """Decorator to make a function that returns via callback return a
-    captured by the `stack_context` and passed along to the `Future`).
+    captured by the `.StackContext` and passed along to the ``Future``).
-    the surrounding `StackContext`.
+    with `Future.result() <concurrent.futures.Future.result>` as an
-    If no callback is given, the caller should use the `Future` to
+    If no callback is given, the caller should use the ``Future`` to
-    `gen.engine` function, or passing it to `IOLoop.add_future`).
+    `.gen.engine` function, or passing it to `.IOLoop.add_future`).
-"""A module to automatically restart the server when a module is modified.
+"""Automatically restart the server when a source file is modified.
-Most applications should not call this module directly.  Instead, pass the
+Most applications should not access this module directly.  Instead, pass the
-and static resources.
+and static resources.  Note that restarting is a destructive operation
-and Google AppEngine.  It also will not work correctly when HTTPServer's
+This module can also be used as a command-line wrapper around scripts
-    """
+    """Begins watching source files for changes using the given `IOLoop`. """
-"""Blocking and non-blocking HTTP client implementations using pycurl."""
+"""Non-blocking HTTP client implementation using pycurl."""
-    """Escapes a string so it is valid within XML or XHTML."""
+    """Escapes a string so it is valid within HTML or XML."""
-    """Returns a valid URL-encoded version of the given value."""
+    """Returns a URL-encoded version of the given value."""
-    shorten: Long urls will be shortened for display.
+    * ``shorten``: Long urls will be shortened for display.
-    extra_params: Extra text to include in the link tag, or a callable
+    * ``extra_params``: Extra text to include in the link tag, or a callable
-        False, urls such as www.facebook.com will also be linkified.
+    * ``require_protocol``: Only linkify urls which include a protocol. If
-        It is very unsafe to include protocols such as "javascript".
+    * ``permitted_protocols``: List (or set) of protocols which should be
-    class GoogleHandler(tornado.web.RequestHandler, tornado.auth.GoogleMixin):
+    class GoogleLoginHandler(tornado.web.RequestHandler,
-            # Save the user with, e.g., set_secure_cookie()
+                user = yield self.get_authenticated_user()
-                # Save the user using, e.g., set_secure_cookie()
+                    user = yield self.get_authenticated_user()
-                    self.twitter_request(
+                    new_entry = yield self.twitter_request(
-                def _on_post(self, new_entry):
+                        access_token=self.current_user["access_token"])
-                                tornado.auth.FriendFeedMixin):
+        class FriendFeedLoginHandler(tornado.web.RequestHandler,
-                # Save the user using, e.g., set_secure_cookie()
+                    user = yield self.get_authenticated_user()
-                    self.friendfeed_request(
+                    new_entry = yield self.friendfeed_request(
-                        callback=self.async_callback(self._on_post))
+                        access_token=self.current_user["access_token"])
-        class GoogleHandler(tornado.web.RequestHandler, tornado.auth.GoogleMixin):
+        class GoogleLoginHandler(tornado.web.RequestHandler,
-
+                   user = yield self.get_authenticated_user()
-
+                      user = yield self.get_authenticated_user(
-                    self.facebook_request(
+                    new_entry = yield self.facebook_request(
-                        callback=self.async_callback(self._on_post))
+                        access_token=self.current_user["access_token"])
-"""Implementations of various third-party authentication schemes.
+"""This module contains implementations of various third-party
-the third party service.
+All the classes in this file are class mixins designed to be used with
-    See GoogleMixin below for example implementations.
+    See `GoogleMixin` below for a customized example (which also
-        """Returns the authentication URL for this service.
+        """Redirects to the authentication URL for this service.
-        callback URI.
+        callback URI with additional parameters including ``openid.mode``.
-        methods.
+        redirect from the `authenticate_redirect()` method (which is
-        """Returns the AsyncHTTPClient instance to be used for auth requests.
+        """Returns the `AsyncHTTPClient` instance to be used for auth requests.
-        May be overridden by subclasses to use an http client other than
+        May be overridden by subclasses to use an HTTP client other than
-    """Abstract implementation of OAuth.
+    """Abstract implementation of OAuth 1.0 and 1.0a.
-    See TwitterMixin and FriendFeedMixin below for example implementations.
+    Subclasses must also override the `_oauth_get_user_future` and
-        process.
+        The ``callback_uri`` may be omitted if you have previously
-        subsequently used (and cleared) in get_authenticated_user for
+        This method sets a cookie called ``_oauth_request_token`` which is
-
+        """Gets the OAuth authorized user and access token.
-        """Returns the AsyncHTTPClient instance to be used for auth requests.
+        """Returns the `AsyncHTTPClient` instance to be used for auth requests.
-        May be overridden by subclasses to use an http client other than
+        May be overridden by subclasses to use an HTTP client other than
-    """Abstract implementation of OAuth v 2."""
+    """Abstract implementation of OAuth 2.0.
-        process.
+        Some providers require that you register a redirect URL with
-    you registered as your application's Callback URL.
+    Twitter at http://twitter.com/apps. Then copy your Consumer Key
-    When your application is set up, you can use this Mixin like this
+    When your application is set up, you can use this mixin like this
-                             tornado.auth.TwitterMixin):
+        class TwitterLoginHandler(tornado.web.RequestHandler,
-    with twitter_request().
+    The user object returned by `get_authenticated_user()` includes the
-        """Just like authorize_redirect(), but auto-redirects if authorized.
+        """Just like `~OAuthMixin.authorize_redirect`, but
-        """Fetches the given API path, e.g., "/statuses/user_timeline/btaylor"
+        """Fetches the given API path, e.g., ``/statuses/user_timeline/btaylor``
-        ".json" and parse the JSON output).
+        The path should not include the format or API version number.
-        If the request is a POST, post_args should be provided. Query
+        If the request is a POST, ``post_args`` should be provided. Query
-        http://apiwiki.twitter.com/Twitter-API-Documentation.
+        All the Twitter methods are documented at http://dev.twitter.com/
-        this method. Example usage::
+        Many methods require an OAuth access token which you can
-    application's Callback URL.
+    FriendFeed at http://friendfeed.com/api/applications. Then copy
-    When your application is set up, you can use this Mixin like this
+    When your application is set up, you can use this mixin like this
-    'access_token'. You should save the access token with the user;
+    The user object returned by `~OAuthMixin.get_authenticated_user()` includes the
-    friendfeed_request().
+    `friendfeed_request()`.
-        If the request is a POST, post_args should be provided. Query
+        If the request is a POST, ``post_args`` should be provided. Query
-        this method. Example usage::
+        Many methods require an OAuth access token which you can
-    values for the user, including 'email', 'name', and 'locale'.
+    No application registration is necessary to use Google for
-        Some of the available resources are:
+        Some of the available resources which can be used in the ``oauth_scope``
-    'facebook_api_key' and 'facebook_secret'.
+    ``facebook_api_key`` and ``facebook_secret``.
-    When your application is set up, you can use this Mixin like this
+    When your application is set up, you can use this mixin like this
-    like 'session_key'. You should save the session key with the user; it is
+    The user object returned by `get_authenticated_user` includes the
-    facebook_request().
+    `facebook_request`.
-        """Returns the AsyncHTTPClient instance to be used for auth requests.
+        """Returns the `AsyncHTTPClient` instance to be used for auth requests.
-        May be overridden by subclasses to use an http client other than
+        May be overridden by subclasses to use an HTTP client other than
-        If the request is a POST, post_args should be provided. Query
+        If the request is a POST, ``post_args`` should be provided. Query
-        this method. Example usage::
+        Many methods require an OAuth access token which you can
-        """Returns the AsyncHTTPClient instance to be used for auth requests.
+        """Returns the `AsyncHTTPClient` instance to be used for auth requests.
-        May be overridden by subclasses to use an http client other than
+        May be overridden by subclasses to use an HTTP client other than
-from tornado.websocket import WebSocketHandler, WebSocketConnect
+from tornado.websocket import WebSocketHandler, websocket_connect
-        ws = yield WebSocketConnect(
+        ws = yield websocket_connect(
-        WebSocketConnect(
+        websocket_connect(
-class _WebSocketClientConnection(simple_httpclient._HTTPConnection):
+class WebSocketClientConnection(simple_httpclient._HTTPConnection):
-        super(_WebSocketClientConnection, self).__init__(
+        super(WebSocketClientConnection, self).__init__(
-def WebSocketConnect(url, io_loop=None, callback=None):
+def websocket_connect(url, io_loop=None, callback=None):
-    conn = _WebSocketClientConnection(io_loop, request)
+    conn = WebSocketClientConnection(io_loop, request)
-                                self.max_buffer_size, self.resolver)
+                release_callback = functools.partial(self._release_fetch, key)
-        af, sockaddr = addrinfo[0]
+        self.stream = self._create_stream(addrinfo)
-                                      max_buffer_size=self.max_buffer_size)
+            return SSLIOStream(socket.socket(af),
-                            server_hostname=self.parsed_hostname)
+            return IOStream(socket.socket(af),
-            self.stream.close()
+            self._on_end_request()
-                self.remote_ip = remote_ip
+            ip = self.headers.get(
-                self.protocol = "http"
+            proto = self.headers.get(
-            self.write(dict(remote_ip=self.request.remote_ip))
+            self.write(dict(remote_ip=self.request.remote_ip,
-                         "127.0.0.1")
+        self.assertEqual(self.fetch_json("/")["remote_ip"], "127.0.0.1")
-            if isinstance(spec, type(())):
+            if isinstance(spec, (tuple, list)):
-    ('index', 'tornado.tex', 'Tornado Documentation', 'Facebook', 'manual', False),
+    ('documentation', 'tornado.tex', 'Tornado Documentation', 'Facebook', 'manual', False),
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipOnTravis
-from tornado.test.util import unittest, skipIfNonUnix
+from tornado.test.util import unittest, skipIfNonUnix, skipOnTravis
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipOnTravis
-sys.path.insert(0, os.path.abspath("../.."))
+sys.path.insert(0, os.path.abspath(".."))
-html_static_path = [os.path.abspath("../static")]
+html_static_path = ['tornado.css']
-html_style = "sphinx.css"
+html_style = "tornado.css"
-], **settings)
+html_favicon = 'favicon.ico'
-extensions = ["sphinx.ext.autodoc", "sphinx.ext.coverage", "sphinx.ext.viewcode"]
+extensions = [
-        self.assertTrue(0.099 < response.request_time < 0.12, response.request_time)
+        self.assertTrue(0.099 < response.request_time < 0.15, response.request_time)
-            delay = deadline.total_seconds()
+            delay = tornado.ioloop._Timeout.timedelta_to_seconds(deadline)
-    from urllib.parse import parse_qs  # py3
+    from urllib.parse import parse_qs as _parse_qs  # py3
-    from urlparse import parse_qs  # Python 2.6+
+    from urlparse import parse_qs as _parse_qs  # Python 2.6+
-    return json.dumps(recursive_unicode(value)).replace("</", "<\\/")
+    return json.dumps(value).replace("</", "<\\/")
-    parse_qs_bytes = parse_qs
+    parse_qs_bytes = _parse_qs
-                          encoding='latin1', errors='strict')
+        result = _parse_qs(qs, keep_blank_values, strict_parsing,
-from tornado.util import u, unicode_type
+from tornado.util import u, unicode_type, bytes_type
-        # accept bytes as well as long as they are utf8.
+        # json deals with strings, not bytes.  On python 2 byte strings will
-        self.assertRaises(UnicodeDecodeError, json_encode, b"\xe9")
+        if bytes_type is str:
-                base64.b64encode(request_token["secret"]))
+        data = (base64.b64encode(escape.utf8(request_token["key"])) + b"|" +
-        base_args["oauth_signature"] = signature
+        base_args["oauth_signature"] = escape.to_basestring(signature)
-            "/users/show/" + escape.native_str(access_token[b"screen_name"]),
+            "/users/show/" + escape.native_str(access_token["screen_name"]),
-    token = dict(key=p[b"oauth_token"][0], secret=p[b"oauth_token_secret"][0])
+    # I can't find an officially-defined encoding for oauth responses and
-    special = (b"oauth_token", b"oauth_token_secret")
+    special = ("oauth_token", "oauth_token_secret")
-        if access_token != dict(key=b'uiop', secret=b'5678'):
+        if access_token != dict(key='uiop', secret='5678'):
-from tornado.stack_context import ExceptionStackContext
+from tornado.stack_context import ExceptionStackContext, wrap
-        return inner
+        return wrap(inner)
-
+    def function_with_stack_context(self, callback):
-        self._add_io_state(self.io_loop.READ)
+        self._try_inline_read()
-                                                     response.body)))
+                "Invalid OpenID response: %s" % (response.error or
-                    "Missing OAuth request token cookie"))
+                "Missing OAuth request token cookie"))
-                    "Request token does not match cookie"))
+                "Request token does not match cookie"))
-                                                       response.request.url)))
+                "Error response %s fetching %s" % (response.error,
-                                                       response.request.url)))
+                "Error response %s fetching %s" % (response.error,
-            and a.exc_info() is not None):
+                and a.exc_info() is not None):
-                lambda i: i.is_ready(), self.unfinished_children))
+            lambda i: i.is_ready(), self.unfinished_children))
-                self._async_client.fetch, request, **kwargs))
+            self._async_client.fetch, request, **kwargs))
-
+
-
+
-        isinstance(ssl_options, ssl.SSLContext)):
+            isinstance(ssl_options, ssl.SSLContext)):
-
+
-            ]
+        ]
-
+
-            self.io_loop.add_callback(lambda: 1/ 0)
+            self.io_loop.add_callback(lambda: 1 / 0)
-            self.io_loop.add_callback(lambda: 1/ 0)
+            self.io_loop.add_callback(lambda: 1 / 0)
-
+
-                })
+            })
-        return Application([url("/hello", HelloWorldHandler),])
+        return Application([url("/hello", HelloWorldHandler), ])
-                ])
+            ('/echo', EchoHandler),
-            not isinstance(handler, logging.StreamHandler)):
+                not isinstance(handler, logging.StreamHandler)):
-                })
+            "Server": "TornadoServer/%s" % tornado.version,
-                })
+            'Upgrade': 'websocket',
-
+        import tornado.concurrent
-        import tornado.options
+        import tornado.log
-        # import tornado.platform.twisted # depends on twisted
+        import tornado.options
-from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient, main, _RequestProxy
+from tornado.httpclient import HTTPResponse, HTTPError, AsyncHTTPClient, main
-from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient, main, _RequestProxy
+from tornado.httpclient import HTTPResponse, HTTPError, AsyncHTTPClient, main, _RequestProxy
-from tornado.httputil import HTTPHeaders
+from tornado.concurrent import Future
-        spaces = len([c for c in key if c.isspace()])
+        spaces = len(c for c in key if c.isspace())
-        request, simple_httpclient.HTTPRequest._DEFAULTS)
+    request = httpclient.HTTPRequest(url)
-    if type(b'') is type(''):  # py2
+    if bytes_type is str:  # py2
-        future = Future()
+        future = TracebackFuture()
-            future.set_exception(e)
+        except Exception:
-        future = Future()
+        future = TracebackFuture()
-            future.set_exception(value)
+            future.set_exc_info((typ, value, tb))
-        if a.exception() is not None:
+        if (isinstance(a, TracebackFuture) and isinstance(b, TracebackFuture)
-from tornado.concurrent import Future
+from tornado.concurrent import Future, TracebackFuture
-        future = Future()
+        future = TracebackFuture()
-            future.set_exception(value)
+            except Exception:
-            except Exception as e:
+            except Exception:
-                future.set_exception(e)
+                future.set_exc_info(sys.exc_info())
-from tornado.concurrent import Future
+from tornado.concurrent import Future, TracebackFuture
-                future_cell[0].set_exception(e)
+            except Exception:
-            lambda value=None: future.set_result(value),
+            lambda value=_NO_RESULT: future.set_result(value),
-                callback(future.result())
+                result = future.result()
-        self.no_result_future(self.stop)
+        future = self.no_result_future(self.stop)
-                                                  args, kwargs)
+        callback, args, kwargs = replacer.replace(
-version = "2.4.post3"
+version = "2.4.post4"
-version_info = (2, 4, 0, 3)
+version = "2.4.post4"
-            self.io_loop.add_future(future, callback)
+            self.io_loop.add_future(future,
-    to `IOLoop.add_future`).
+    with `Future.result()` as an argument.  If the function fails,
-    same function, provided ``@return_future`` appears first.
+    same function, provided ``@return_future`` appears first.  However,
-            future.add_done_callback(wrap(callback))
+            def run_callback(future):
-    be invoked with the future when it resolves.
+    be invoked with the future's result when it resolves.  If the coroutine
-            IOLoop.current().add_future(future, kwargs.pop('callback'))
+            callback = kwargs.pop('callback')
-        passed, it will be run with the `Future` as an argument when
+        passed, it will be run with the result as an argument when
-        af, sockaddr = future.result()[0]
+    def _on_resolve(self, addrinfo):
-        self.assertIs(future, future2)
+        result = self.wait()
-        self.assertIs(future, future2)
+        result = self.wait()
-            self.future.add_done_callback(callback)
+            self.future.add_done_callback(
-        self.assertEqual(future.result(), "HELLO")
+        result = self.wait()
-        self.assertRaisesRegexp(CapError, "already capitalized", future.result)
+        self.assertRaisesRegexp(CapError, "already capitalized", self.wait)
-        self.assertEqual(future.result(), 42)
+        result = yield gen.Task(f)
-                      future.result())
+        result = self.wait()
-        user_json = self.get_secure_cookie("user")
+        user_json = self.get_secure_cookie("authdemo_user")
-        self.set_secure_cookie("user", tornado.escape.json_encode(user))
+        self.set_secure_cookie("authdemo_user", tornado.escape.json_encode(user))
-        self.clear_cookie("user")
+        self.clear_cookie("authdemo_user")
-        user_id = self.get_secure_cookie("user")
+        user_id = self.get_secure_cookie("blogdemo_user")
-        self.set_secure_cookie("user", str(author_id))
+        self.set_secure_cookie("blogdemo_user", str(author_id))
-        self.clear_cookie("user")
+        self.clear_cookie("blogdemo_user")
-        user_json = self.get_secure_cookie("user")
+        user_json = self.get_secure_cookie("chatdemo_user")
-        self.set_secure_cookie("user", tornado.escape.json_encode(user))
+        self.set_secure_cookie("chatdemo_user", tornado.escape.json_encode(user))
-        self.clear_cookie("user")
+        self.clear_cookie("chatdemo_user")
-        user_json = self.get_secure_cookie("user")
+        user_json = self.get_secure_cookie("fbdemo_user")
-    
+
-        self.set_secure_cookie("user", tornado.escape.json_encode(user))
+        self.set_secure_cookie("fbdemo_user", tornado.escape.json_encode(user))
-        self.clear_cookie("user")
+        self.clear_cookie("fbdemo_user")
-            autoescape=None,
+            debug=True,
-import markdown
+import tornado.escape
-    markdown = db.TextProperty(required=True)
+    body_source = db.TextProperty(required=True)
-            entry.html = markdown.markdown(self.get_argument("markdown"))
+            entry.body_source = self.get_argument("body_source")
-                html=markdown.markdown(self.get_argument("markdown")),
+                body_source=self.get_argument("body_source"),
-    def render_string(self, template_name, **kwargs):
+    def get_template_namespace(self):
-            self, template_name, users=users, **kwargs)
+        ns = super(BaseHandler, self).get_template_namespace()
-    io_loop = io_loop or ioloop.IOLoop.instance()
+    io_loop = io_loop or ioloop.IOLoop.current()
-        io_loop = io_loop or IOLoop.instance()
+        io_loop = io_loop or IOLoop.current()
-            raise ValueError("no current IOLoop")
+            return IOLoop.instance()
-        self.io_loop = io_loop or IOLoop.instance()
+        self.io_loop = io_loop or IOLoop.current()
-        self.io_loop = io_loop or ioloop.IOLoop.instance()
+        self.io_loop = io_loop or ioloop.IOLoop.current()
-        io_loop = IOLoop.instance()
+        io_loop = IOLoop.current()
-        self.io_loop = io_loop or IOLoop.instance()
+        self.io_loop = io_loop or IOLoop.current()
-        self.io_loop = io_loop or IOLoop.instance()
+        self.io_loop = io_loop or IOLoop.current()
-            io_loop = tornado.ioloop.IOLoop.instance()
+            io_loop = tornado.ioloop.IOLoop.current()
-        io_loop = tornado.ioloop.IOLoop.instance()
+        io_loop = tornado.ioloop.IOLoop.current()
-        self.io_loop = io_loop or IOLoop.instance()
+        self.io_loop = io_loop or IOLoop.current()
-            io_loop = ioloop.IOLoop.instance()
+            io_loop = ioloop.IOLoop.current()
-            self.io_loop = IOLoop.instance()
+            self.io_loop = IOLoop.current()
-        return IOStream(connection, io_loop=self.io_loop, **kwargs)
+        return IOStream(connection, **kwargs)
-        return IOStream(connection, io_loop=self.io_loop, **kwargs)
+        return IOStream(connection, **kwargs)
-        io_loop = IOLoop.instance()
+        io_loop = IOLoop.current()
-@gen.engine
+@gen.coroutine
-    IOLoop.instance().start()
+    IOLoop.instance().run_sync(main)
-        self._response = None
+        response = self._io_loop.run_sync(functools.partial(
-        assert IOLoop._current.instance is self
+    @staticmethod
-from tornado.ioloop import IOLoop
+from tornado import gen
-    """Testing equivalent of ``@gen.engine``, to be applied to test methods.
+    """Testing equivalent of ``@gen.coroutine``, to be applied to test methods.
-    ``@gen.engine`` cannot be used on tests because the `IOLoop` is not
+    ``@gen.coroutine`` cannot be used on tests because the `IOLoop` is not
-
+    f = gen.coroutine(f)
-        self.wait()
+    def wrapper(self):
-class DummyFuture(object):
+class _DummyFuture(object):
-    Future = DummyFuture
+    Future = _DummyFuture
-from tornado.concurrent import DummyFuture
+from tornado.concurrent import Future
-        assert isinstance(future, IOLoop._FUTURE_TYPES)
+        assert isinstance(future, Future)
-@unittest.skipIf(twisted.__version__ < "12.1", "old version of twisted")
+@unittest.skipIf(getattr(twisted, '__version__', '0.0') < "12.1", "old version of twisted")
-            addrinfo = yield resolver.getaddrinfo(host, 80, family)
+            addrinfo = yield resolver.resolve(host, 80, family)
-        self._async_client.fetch(request, callback, **kwargs)
+        self._io_loop.add_callback(self._async_client.fetch, request,
-    def resolve(self, host, port, family=0, callback=None):
+    @gen.coroutine
-        callback(addrinfo)
+        raise gen.Return(addrinfo)
-    def resolve(self, host, port, family=0, callback=None):
+    @gen.coroutine
-        self.io_loop.add_callback(callback, result)
+        raise gen.Return(result)
-    def _oauth_get_user_future(self, access_token, callback):
+    @gen.coroutine
-        callback(user)
+        raise gen.Return(user)
-    def _oauth_get_user(self, access_token, callback):
+    @gen.coroutine
-    def _oauth_get_user_future(self, access_token, callback):
+    def _oauth_get_user_future(self, access_token):
-            assert gen is None, gen
+            try:
-                except StopIteration:
+                except (StopIteration, Return) as e:
-                    self.final_callback()
+                    self.final_callback(getattr(e, 'value', None))
-class GenTest(AsyncTestCase):
+
-        self.wait()
+        return self.wait()
-        runner = gen.Runner(result, self.stop)
+        runner = gen.Runner(result, lambda value: self.stop())
-        server.read_until("\r\n", self.stop)
+        client.write(b"abcd\r\nefgh")
-        self.assertEqual(data, "abcd\r\n")
+        self.assertEqual(data, b"abcd\r\n")
-        self.assertEqual(data, "efgh")
+        self.assertEqual(data, b"efgh")
-    def getaddrinfo(self, *args, **kwargs):
+    def resolve(self, host, port, family=socket.AF_UNSPEC, callback=None):
-        keyword-only ``callback`` argument.
+        The ``host`` argument is a string which may be a hostname or a
-        is complete.
+        Returns a `Future` whose result is a list of (family, address)
-        return socket.getaddrinfo(*args, **kwargs)
+    def resolve(self, host, port, family=socket.AF_UNSPEC):
-    def getaddrinfo(self, host, port, *args, **kwargs):
+    def resolve(self, host, port, *args, **kwargs):
-        return self.resolver.getaddrinfo(host, port, *args, **kwargs)
+        return self.resolver.resolve(host, port, *args, **kwargs)
-                    flags=0, callback=None):
+    def resolve(self, host, port, family=0, callback=None):
-            addrinfo.append((address_family, socktype, proto, '', (address, port)))
+            addrinfo.append((address_family, (address, port)))
-                    flags=0, callback=None):
+    def resolve(self, host, port, family=0, callback=None):
-            (resolved_family, socktype, proto, '', (resolved, port)),
+            (resolved_family, (resolved, port)),
-                callback=self._on_resolve)
+            self.resolver.resolve(host, port, af, callback=self._on_resolve)
-        af, socktype, proto, canonname, sockaddr = future.result()[0]
+        af, sockaddr = future.result()[0]
-            self.stream = SSLIOStream(socket.socket(af, socktype, proto),
+            self.stream = SSLIOStream(socket.socket(af),
-            self.stream = IOStream(socket.socket(af, socktype, proto),
+            self.stream = IOStream(socket.socket(af),
-                                  callback=self.stop)
+        self.resolver.resolve('localhost', 80, callback=self.stop)
-            future.result())
+        self.assertIn((socket.AF_INET, ('127.0.0.1', 80)),
-
+        addrinfo = yield self.resolver.resolve('localhost', 80,
-        self.io_loop = io_loop
+    def initialize(self, io_loop=None):
-            if not self._valid_ip(self.remote_ip):
+            if not netutil.is_valid_ip(self.remote_ip):
-        return True
+def is_valid_ip(ip):
-from tornado.netutil import BlockingResolver, ThreadedResolver
+from tornado.netutil import BlockingResolver, ThreadedResolver, is_valid_ip
-        self._io_loop.add_callback(p)
+        with NullContext():
-    because they will all run in the same thread.
+    Uses the global Twisted reactor by default.  To create multiple
-        from twisted.internet import reactor
+    def initialize(self, reactor=None):
-        timeout.cancel()
+        if timeout.active():
-    if IOLoop.configured_class().__name__ == 'TwistedIOLoop':
+    if IOLoop.configured_class().__name__.endswith('TwistedIOLoop'):
-import functools
+import functools
-import tornado
+from tornado.concurrent import return_future
-            future.add_done_callback(wrap(callback))
+
-            future.result()
+        # The callback is not run because the function failed synchronously.
-from tornado.stack_context import ExceptionStackContext
+from tornado.stack_context import ExceptionStackContext, wrap
-            future.add_done_callback(callback)
+            future.add_done_callback(wrap(callback))
-        # an exception when there wasn't a wait() to re-raise it, do so here.
+        # As a last resort, if an exception escaped super.run() and wasn't
-from tornado.httpclient import HTTPRequest, HTTPResponse, _RequestProxy, HTTPError
+from tornado.httpclient import HTTPRequest, HTTPResponse, _RequestProxy, HTTPError, HTTPClient
-                    self.io_loop.remove_timeout(self.__timeout)
+            if self.__timeout is not None:
-    def _on_connect(self):
+    def _remove_timeout(self):
-            self._timeout = None
+        self._remove_timeout()
-from tornado.concurrent import Future, return_future
+from tornado.concurrent import Future, return_future, ReturnValueIgnoredError
-            result = None
+                raise
-'''StackContext allows applications to maintain threadlocal-like state
+"""StackContext allows applications to maintain threadlocal-like state
-'''
+"""
-    '''Establishes the given context as a StackContext that will be transferred.
+    """Establishes the given context as a StackContext that will be transferred.
-    '''
+    """
-    '''Specialization of StackContext for exception handling.
+    """Specialization of StackContext for exception handling.
-    '''
+    """
-    '''Resets the StackContext.
+    """Resets the StackContext.
-    '''
+    """
-    '''Returns a callable object that will restore the current StackContext
+    """Returns a callable object that will restore the current StackContext
-    '''
+    """
-        '''A missing SSL key should cause an immediate exception.'''
+        """A missing SSL key should cause an immediate exception."""
-        '''Creates a new IOLoop for this test.  May be overridden in
+        """Creates a new IOLoop for this test.  May be overridden in
-        '''
+        """
-        '''Stops the ioloop, causing one pending (or future) call to wait()
+        """Stops the ioloop, causing one pending (or future) call to wait()
-        '''
+        """
-    '''A test case that starts up an HTTP server.
+    """A test case that starts up an HTTP server.
-    '''
+    """
-            for value in list:
+        for name, values in self._as_list.items():
-        callback = kwargs.pop("callback")
+        callback = kwargs.pop("callback", None)
-from tornado.testing import AsyncTestCase
+from tornado.testing import AsyncTestCase, gen_test
-class BaseResolver(object):
+class Resolver(Configurable):
-    def __init__(self, io_loop=None, executor=None):
+class ExecutorResolver(Resolver):
-class OverrideResolver(BaseResolver):
+class BlockingResolver(ExecutorResolver):
-    def __init__(self, resolver, mapping):
+    def initialize(self, resolver, mapping):
-            self.resolver = OverrideResolver(self.resolver, hostname_mapping)
+            self.resolver = OverrideResolver(resolver=self.resolver,
-            1024 * 1024, Resolver(self.io_loop))
+            1024 * 1024, Resolver(io_loop=self.io_loop))
-from tornado.netutil import Resolver
+from tornado.netutil import BlockingResolver, ThreadedResolver
-class SyncResolverTest(AsyncTestCase, _ResolverTestMixin):
+class BlockingResolverTest(AsyncTestCase, _ResolverTestMixin):
-        self.resolver = Resolver(self.io_loop)
+        super(BlockingResolverTest, self).setUp()
-        self.resolver = Resolver(self.io_loop, self.executor)
+        self.resolver = ThreadedResolver(io_loop=self.io_loop)
-        self.executor.shutdown()
+        self.resolver.executor.shutdown()
-            104857600, Resolver(io_loop))
+            104857600, Resolver(io_loop=io_loop))
-        self._requests.append((request, stack_context.wrap(callback)))
+        self._requests.append((request, callback))
-    def fetch(self, request, callback, **kwargs):
+    def fetch(self, request, callback=None, **kwargs):
-        self.fetch_impl(request, callback)
+        future = Future()
-from tornado.httpclient import HTTPRequest, HTTPResponse, _RequestProxy
+from tornado.httpclient import HTTPRequest, HTTPResponse, _RequestProxy, HTTPError
-from tornado.testing import AsyncHTTPTestCase, bind_unused_port
+from tornado.testing import AsyncHTTPTestCase, bind_unused_port, gen_test
-                                self.max_buffer_size)
+                                self.max_buffer_size, self.resolver)
-                 final_callback, max_buffer_size):
+                 final_callback, max_buffer_size, resolver):
-            self.client.resolver.getaddrinfo(
+            self.resolver.getaddrinfo(
-from tornado.netutil import ssl_options_to_context
+from tornado.netutil import ssl_options_to_context, Resolver
-            1024 * 1024)
+            1024 * 1024, Resolver(self.io_loop))
-    def __init__(self, io_loop, client, request):
+    def __init__(self, io_loop, request):
-            104857600)
+            io_loop, None, request, lambda: None, lambda response: None,
-    conn = _WebSocketClientConnection(io_loop, client, request)
+    conn = _WebSocketClientConnection(io_loop, request)
-class Resolver(object):
+class BaseResolver(object):
-from tornado.netutil import Resolver
+from tornado.netutil import Resolver, OverrideResolver
-        self.hostname_mapping = hostname_mapping
+        if hostname_mapping is not None:
-            self.io_loop, hostname_mapping={'www.example.com': '127.0.0.1'})
+            self.io_loop,
-            self.defaults.update(defaults)
+    def initialize(self, io_loop, max_clients=10, defaults=None):
-        request = _RequestProxy(request, self.defaults)
+    def fetch_impl(self, request, callback):
-    def initialize(self, io_loop=None, max_clients=10,
+    def initialize(self, io_loop, max_clients=10,
-        self.io_loop = io_loop
+        super(SimpleAsyncHTTPClient, self).initialize(io_loop,
-        request = _RequestProxy(request, self.defaults)
+
-from tornado.concurrent import Future, chain_future
+from tornado.concurrent import Future, chain_future, return_future
-                             self._on_oauth_get_user, access_token, future))
+        self._oauth_get_user_future(access_token).add_done_callback(
-    def _on_oauth_get_user(self, access_token, future, user):
+    def _on_oauth_get_user(self, access_token, future, user_future):
-        self.twitter_request(
+    @return_future
-    def _parse_user_response(self, callback, user):
+            access_token=access_token)
-        self.friendfeed_request(
+        user = yield self.friendfeed_request(
-            callback=callback)
+            include="id,name,description", access_token=access_token)
-        OpenIdMixin.get_authenticated_user(self, callback)
+    def _oauth_get_user_future(self, access_token, callback):
-from tornado.concurrent import Future
+from tornado.concurrent import Future, chain_future
-    def _on_authentication_verified(self, callback, response):
+    def _on_authentication_verified(self, future, response):
-            callback(None)
+            future.set_exception(AuthError(
-        callback(user)
+        future.set_result(user)
-            callback(None)
+            future.set_exception(AuthError(
-            callback(None)
+            future.set_exception(AuthError(
-    def _on_access_token(self, callback, response):
+    def _on_access_token(self, future, response):
-            callback(None)
+            future.set_exception(AuthError("Could not fetch access token"))
-                             self._on_oauth_get_user, access_token, callback))
+                             self._on_oauth_get_user, access_token, future))
-    def _on_oauth_get_user(self, access_token, callback, user):
+    def _on_oauth_get_user(self, access_token, future, user):
-            callback(None)
+            future.set_exception(AuthError("Error getting user"))
-        callback(user)
+        future.set_result(user)
-    def _on_friendfeed_request(self, callback, response):
+    def _on_friendfeed_request(self, future, response):
-            callback(None)
+            future.set_exception(AuthError(
-        callback(escape.json_decode(response.body))
+        future.set_result(escape.json_decode(response.body))
-            OpenIdMixin.get_authenticated_user(self, callback)
+            chain_future(OpenIdMixin.get_authenticated_user(self),
-    of this class.
+    *Deprecated:* New applications should use `FacebookGraphMixin`
-from tornado.util import bytes_type, u, unicode_type
+from tornado.util import bytes_type, u, unicode_type, ArgReplacer
-    def twitter_request(self, path, callback, access_token=None,
+    @_auth_return_future
-        callback = self.async_callback(self._on_twitter_request, callback)
+        http_callback = self.async_callback(self._on_twitter_request, callback)
-                       callback=callback)
+                       callback=http_callback)
-            http.fetch(url, callback=callback)
+            http.fetch(url, callback=http_callback)
-    def _on_twitter_request(self, callback, response):
+    def _on_twitter_request(self, future, response):
-            callback(None)
+            future.set_exception(AuthError(
-        callback(escape.json_decode(response.body))
+        future.set_result(escape.json_decode(response.body))
-from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, GoogleMixin
+from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, GoogleMixin, AuthError
-from tornado.testing import AsyncHTTPTestCase
+from tornado.log import gen_log
-from tornado.web import RequestHandler, Application, asynchronous
+from tornado.web import RequestHandler, Application, asynchronous, HTTPError
-        response = yield gen.Task(self.twitter_request, '/users/show/somebody',
+        response = yield gen.Task(self.twitter_request,
-        response = self.fetch('/twitter/client/show_user')
+        response = self.fetch('/twitter/client/show_user?name=somebody')
-from tornado.util import raise_exc_info
+from tornado.util import raise_exc_info, ArgReplacer
-        callback_pos = None
+    replacer = ArgReplacer(f, 'callback')
-            kwargs['callback'] = future.set_result
+        callback, args, kwargs = replacer.replace(future.set_result,
-from tornado.util import raise_exc_info, Configurable, u, exec_in
+from tornado.util import raise_exc_info, Configurable, u, exec_in, ArgReplacer
-       default=['Tornado=ws://localhost:9000'])
+import logging
-       default=["9.*"])
+from tornado import gen
-   reactor.run()
+    main()
-            self.stream.read_until_regex(b"\r?\n\r?\n", self._on_headers)
+            self._handle_1xx(code)
-        self.headers = HTTPHeaders.parse(header_data)
+    'tornado.test.websocket_test',
-import base64
+from tornado.concurrent import Future, return_future
-    def __init__(self, handler):
+    def __init__(self, handler, mask_outgoing=False):
-            gen_log.debug("Malformed WebSocket request received")
+            gen_log.debug("Malformed WebSocket request received", exc_info=True)
-    def _challenge_response(self):
+    @staticmethod
-            self.request.headers.get("Sec-Websocket-Key")))
+        sha1.update(utf8(key))
-        return tornado.escape.native_str(base64.b64encode(sha1.digest()))
+        return native_str(base64.b64encode(sha1.digest()))
-            frame += struct.pack("B", l)
+            frame += struct.pack("B", l | mask_bit)
-            frame += struct.pack("!BH", 126, l)
+            frame += struct.pack("!BH", 126 | mask_bit, l)
-            frame += struct.pack("!BQ", 127, l)
+            frame += struct.pack("!BQ", 127 | mask_bit, l)
-            return
+        self._masked_frame = bool(payloadlen & 0x80)
-            self.stream.read_bytes(4, self._on_masking_key)
+            if self._masked_frame:
-        self.stream.read_bytes(4, self._on_masking_key)
+        if self._masked_frame:
-        self.stream.read_bytes(4, self._on_masking_key)
+        if self._masked_frame:
-        self.stream.read_bytes(self._frame_length, self._on_frame_data)
+        self._frame_mask = data
-    def _on_frame_data(self, data):
+    def _apply_mask(self, mask, data):
-            unmasked[i] = unmasked[i] ^ self._frame_mask[i % 4]
+            unmasked[i] = unmasked[i] ^ mask[i % 4]
-            self._fragmented_message_buffer += unmasked
+            self._fragmented_message_buffer += data
-                unmasked = self._fragmented_message_buffer
+                data = self._fragmented_message_buffer
-                self._fragmented_message_buffer = unmasked
+                self._fragmented_message_buffer = data
-            self._handle_message(opcode, unmasked.tostring())
+            self._handle_message(opcode, data)
-        for i in range(len(data)):
+        for i in xrange(len(data)):
-            self.stdout = PipeIOStream(err_r, io_loop=self.io_loop)
+            self.stderr = PipeIOStream(err_r, io_loop=self.io_loop)
-        for i in xrange(len(data)):
+        for i in range(len(data)):
-                           ((StackContext, self.context_factory, self.active_cell),))
+        self.new_contexts = (self.old_contexts +
-                             self.active_cell),))
+        self.new_contexts = (self.old_contexts +
-            self.old_contexts = None
+            if final_contexts is not self.new_contexts:
-from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, ExpectLog
+from tornado.stack_context import StackContext, wrap, NullContext, StackContextInconsistentError, ExceptionStackContext
-        The argument is a handle as returned by add_timeout.
+        The argument is a handle as returned by add_timeout.  It is
-    2. `~tornado.tcpserver.TCPServer.bind`/`~tornado.netutil.TCPServer.start`:
+    2. `~tornado.tcpserver.TCPServer.bind`/`~tornado.tcpserver.TCPServer.start`:
-                "exec")
+                "exec", dont_inherit=True)
-from tornado.util import raise_exc_info, Configurable, u
+from tornado.util import raise_exc_info, Configurable, u, exec_in
-#         # After 2to3: raise exc_info[0](exc_info[1]).with_traceback(exc_info[2])
+    if isinstance(code, str):
-version = "2.4.post2"
+version = "2.4.post3"
-version_info = (2, 4, 0, 2)
+version = "2.4.post3"
-        return all(i.is_ready() for i in self.children)
+        finished = list(itertools.takewhile(
-    and the "pretty logging" configured by tornado.options.
+    and the "pretty logging" configured by tornado.options.  It is not
-        assert isinstance(handler, logging.StreamHandler)
+        if (len(logger.handlers) > 1 or
-                         safe_unicode(record.exc_text))
+            # exc_text contains multiple lines.  We need to safe_unicode
-        self.assertRegexpMatches(self.get_output(), br'Exception.*\\xe9')
+        output = self.get_output()
-        """Stop the loop after the current event loop iteration is complete.
+        """Stop the I/O loop.
-            message = repr(record.message)
+        def safe_unicode(s):
-        formatted = prefix + " " + message
+        formatted = prefix + " " + safe_unicode(record.message)
-            formatted = formatted.rstrip() + "\n" + record.exc_text
+            formatted = (formatted.rstrip() + "\n" +
-    LINE_RE = re.compile(b"\x01\\[E [0-9]{6} [0-9]{2}:[0-9]{2}:[0-9]{2} log_test:[0-9]+\\]\x02 (.*)")
+    # Matches the output of a single logging call (which may be multiple lines
-                v = re.sub(r"[\x00-\x08\x0e-\x1f]", " ", v)
+                v = RequestHandler._remove_control_chars_regex.sub(" ", v)
-from tornado.testing import AsyncTestCase, LogTrapTestCase, get_unused_port, gen_test
+from tornado.testing import AsyncTestCase, LogTrapTestCase, bind_unused_port, gen_test
-        self.server.listen(port, address='127.0.0.1')
+        sock, port = bind_unused_port()
-class TwitterClientLoginHandler(RequestHandler, TwitterMixin):
+class TwitterClientHandler(RequestHandler, TwitterMixin):
-        return self.settings['http_client']
+class TwitterClientShowUserHandler(TwitterClientHandler):
-        self.children = children
+        self.children = []
-                    # TODO: lists of futures
+                elif isinstance(yielded, Future):
-from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, ExpectLog, gen_test
-import operator
+
-    def __init__(self, gen, deactivate_stack_context):
+    def __init__(self, gen, final_callback):
-        self.deactivate_stack_context = deactivate_stack_context
+        self.final_callback = final_callback
-                    self.deactivate_stack_context = None
+                    self.final_callback()
-from tornado.testing import AsyncTestCase, LogTrapTestCase, get_unused_port
+from tornado.testing import AsyncTestCase, LogTrapTestCase, get_unused_port, gen_test
-from tornado.testing import AsyncTestCase
+
-def future_wrap(f):
+def return_future(f):
-        kwargs['callback'] = future.set_result
+        if callback_pos is not None and len(args) > callback_pos:
-            f(*args, **kwargs)
+            try:
-from tornado.concurrent import Future, future_wrap
+from tornado.concurrent import Future, return_future
-    @future_wrap
+    @return_future
-    @future_wrap
+    @return_future
-    kwargs = property(operator.itemgetter(1))
+Arguments = collections.namedtuple('Arguments', ['args', 'kwargs'])
-    def bind_unix_socket(file, mode=int('600', 8), backlog=128):
+    def bind_unix_socket(file, mode=0o600, backlog=128):
-                timestamp, localtime=False, usegmt=True)
+            headers["If-Modified-Since"] = httputil.format_timestamp(
-from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders
+from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders, format_timestamp
-                    "%a, %d %b %Y %H:%M:%S GMT"),
+                "Date": httputil.format_timestamp(time.gmtime()),
-            return email.utils.formatdate(t, localtime=False, usegmt=True)
+            return httputil.format_timestamp(value)
-                timestamp, localtime=False, usegmt=True)
+            morsel["expires"] = httputil.format_timestamp(expires)
-            dict.__setitem__(self, norm_name, self[norm_name] + ',' + value)
+            dict.__setitem__(self, norm_name,
-        self.set_header("x-overwrite", 2)
+        self.set_header("X-Overwrite", 2)
-        self.add_header("x-multi", "4")
+        self.add_header("X-Multi", "4")
-        self._list_headers = []
+        self._headers = httputil.HTTPHeaders({
-        self._list_headers.append((name, self._convert_header_value(value)))
+        self._headers.add(name, self._convert_header_value(value))
-                      itertools.chain(self._headers.items(), self._list_headers)])
+        lines.extend([utf8(n) + b": " + utf8(v) for n, v in self._headers.get_all()])
-        headers = list(handler._headers.items()) + handler._list_headers
+        headers = list(handler._headers.get_all())
-    from twisted.web.server import Site
+# The core of Twisted 12.3.0 is available on python 3, but twisted.web is not
-            self.assertEquals(fd.read(1), 'x')
+            self.assertEquals(fd.read(1), b'x')
-                fd.write('x')
+                fd.write(b'x')
-    if not socket.has_ipv6:
+    if not socket.has_ipv6 and family == socket.AF_UNSPEC:
-from tornado.escape import utf8
+from tornado.escape import utf8, native_str
-        self._curls = [_curl_create() for i in xrange(max_clients)]
+        self._curls = [_curl_create() for i in range(max_clients)]
-                        "buffer": cStringIO.StringIO(),
+                        "buffer": BytesIO(),
-    curl.setopt(pycurl.URL, utf8(request.url))
+    curl.setopt(pycurl.URL, native_str(request.url))
-                    [utf8("%s: %s" % i) for i in request.headers.get_all()])
+                    [native_str("%s: %s" % i) for i in request.headers.get_all()])
-                    [utf8("%s: %s" % i) for i in request.headers.items()])
+                    [native_str("%s: %s" % i) for i in request.headers.items()])
-        curl.setopt(pycurl.WRITEFUNCTION, request.streaming_callback)
+        write_function = request.streaming_callback
-        curl.setopt(pycurl.WRITEFUNCTION, buffer.write)
+        write_function = buffer.write
-        curl.setopt(pycurl.USERAGENT, utf8(request.user_agent))
+        curl.setopt(pycurl.USERAGENT, native_str(request.user_agent))
-        request_buffer = cStringIO.StringIO(utf8(request.body))
+        request_buffer = BytesIO(utf8(request.body))
-        curl.setopt(pycurl.USERPWD, utf8(userpwd))
+        curl.setopt(pycurl.USERPWD, native_str(userpwd))
-from tornado.netutil import ssl_wrap_socket
+from tornado.netutil import ssl_wrap_socket, ssl_match_hostname, SSLCertificateError
-    def connect(self, address, callback=None):
+    def connect(self, address, callback=None, server_hostname=None):
-    def connect(self, address, callback=None):
+    def connect(self, address, callback=None, server_hostname=None):
-def ssl_wrap_socket(socket, ssl_options, **kwargs):
+def ssl_wrap_socket(socket, ssl_options, server_hostname=None, **kwargs):
-        return context.wrap_socket(socket, **kwargs)
+        if server_hostname is not None and getattr(ssl, 'HAS_SNI'):
-        self.stream.connect(sockaddr, self._on_connect)
+        # ipv6 addresses are broken (in self.parsed.hostname) until
-    including "certfile" and "keyfile"::
+    including "certfile" and "keyfile".  In Python 3.2+ you can pass
-        it will be used as additional keyword arguments to ssl.wrap_socket.
+        The ``ssl_options`` keyword argument may either be a dictionary
-                                      **self._ssl_options)
+        self.socket = ssl_wrap_socket(self.socket, self._ssl_options,
-from tornado.netutil import bind_sockets, add_accept_handler
+from tornado.netutil import bind_sockets, add_accept_handler, ssl_wrap_socket
-        if self.ssl_options is not None:
+        if self.ssl_options is not None and isinstance(self.ssl_options, dict):
-                connection = ssl.wrap_socket(connection,
+                connection = ssl_wrap_socket(connection,
-                                             **self.ssl_options)
+                                             do_handshake_on_connect=False)
-from tornado.netutil import TCPServer
+from tornado.tcpserver import TCPServer
-    initialization methods are defined on `tornado.netutil.TCPServer`):
+    initialization methods are defined on `tornado.tcpserver.TCPServer`):
-    1. `~tornado.netutil.TCPServer.listen`: simple single-process::
+    1. `~tornado.tcpserver.TCPServer.listen`: simple single-process::
-    2. `~tornado.netutil.TCPServer.bind`/`~tornado.netutil.TCPServer.start`:
+    2. `~tornado.tcpserver.TCPServer.bind`/`~tornado.netutil.TCPServer.start`:
-    3. `~tornado.netutil.TCPServer.add_sockets`: advanced multi-process::
+    3. `~tornado.tcpserver.TCPServer.add_sockets`: advanced multi-process::
-
+#!/usr/bin/env python
-from tornado.netutil import TCPServer
+from tornado.tcpserver import TCPServer
-        object_file = open(path, "r")
+        object_file = open(path, "rb")
-        if events | tornado.ioloop.IOLoop.READ:
+        if events & tornado.ioloop.IOLoop.READ:
-        if events | tornado.ioloop.IOLoop.WRITE:
+        if events & tornado.ioloop.IOLoop.WRITE:
-        if events | tornado.ioloop.IOLoop.READ:
+        if events & tornado.ioloop.IOLoop.READ:
-        if events | tornado.ioloop.IOLoop.WRITE:
+        if events & tornado.ioloop.IOLoop.WRITE:
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipIfNonUnix
-    add_reload_hook(functools.partial(_close_all_fds, io_loop))
+    add_reload_hook(functools.partial(io_loop.close, all_fds=True))
-        for name in self.request.arguments.keys():
+        for name in self.request.arguments:
-        for name, values in self.request.arguments.iteritems():
+        for name, values in self.request.arguments.items():
-                    values[-1] == u("http://specs.openid.net/extensions/oauth/1.0"):
+                    values[-1] == b"http://specs.openid.net/extensions/oauth/1.0":
-                    [utf8("%s: %s" % i) for i in request.headers.iteritems()])
+                    [utf8("%s: %s" % i) for i in request.headers.items()])
-        args = ",".join("%s=%r" % i for i in self.__dict__.iteritems())
+        args = ",".join("%s=%r" % i for i in sorted(self.__dict__.items()))
-from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin
+from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin, GoogleMixin
-from tornado.httpclient import HTTPRequest, _RequestProxy
+from tornado.httpclient import HTTPRequest, HTTPResponse, _RequestProxy
-    for sig, handler in saved.iteritems():
+    for sig, handler in saved.items():
-    for test_name, blacklist in twisted_tests.iteritems():
+    for test_name, blacklist in twisted_tests.items():
-        for name in self.request.cookies.iterkeys():
+        for name in self.request.cookies:
-            self.request.connection.stream.set_close_callback(
+            self.request.connection.set_close_callback(
-wsgi_safe = []
+wsgi_safe_tests = []
-wsgi_safe.append(WSGISafeWebTest)
+@wsgi_safe
-wsgi_safe.append(ErrorResponseTest)
+@wsgi_safe
-wsgi_safe.append(StaticFileTest)
+@wsgi_safe
-wsgi_safe.append(CustomStaticFileTest)
+@wsgi_safe
-wsgi_safe.append(HostMatchingTest)
+@wsgi_safe
-wsgi_safe.append(NamedURLSpecGroupsTest)
+@wsgi_safe
-wsgi_safe.append(ClearHeaderTest)
+@wsgi_safe
-wsgi_safe.append(Header304Test)
+@wsgi_safe
-wsgi_safe.append(StatusReasonTest)
+@wsgi_safe
-wsgi_safe.append(DateHeaderTest)
+@wsgi_safe
-wsgi_safe.append(RaiseWithReasonTest)
+@wsgi_safe
-wsgi_safe.append(ErrorHandlerXSRFTest)
+@wsgi_safe
-                            ('/kw/(?P<path>.*)', self.Handler)])
+    def get_handlers(self):
-    for cls in web_test.wsgi_safe:
+    for cls in web_test.wsgi_safe_tests:
-            if self.stream.socket.family in (socket.AF_INET, socket.AF_INET6):
+            if self.address_family in (socket.AF_INET, socket.AF_INET6):
-            pass
+    try:
-                # so just assume IP in that case.
+            if self.stream.socket.family in (socket.AF_INET, socket.AF_INET6):
-            # on both 2 and 3.
+@implementer(IDelayedCall)
-TornadoDelayedCall = implementer(IDelayedCall)(TornadoDelayedCall)
+@implementer(IReactorTime, IReactorFDSet)
-TornadoReactor = implementer(IReactorTime, IReactorFDSet)(TornadoReactor)
+@implementer(IReadDescriptor, IWriteDescriptor)
-
+@unittest.skipIf(pycurl is None, "pycurl module not present")
-                                                   CurlHTTPClientCommonTestCase)
+@unittest.skipIf(pycurl is None, "pycurl module not present")
-                                             CurlHTTPClientTestCase)
+@skipIfNoSSL
-SSLv23Test = skipIfNoSSL(SSLv23Test)
+@skipIfNoSSL
-SSLv3Test = skipIfNoSSL(skipIfOldSSL(SSLv3Test))
+@skipIfNoSSL
-TLSv1Test = skipIfNoSSL(skipIfOldSSL(TLSv1Test))
+@unittest.skipIf(not hasattr(socket, 'AF_UNIX') or sys.platform == 'cygwin',
-    "unix sockets not supported on this platform")
+@unittest.skipIf(futures is None, "futures module not present")
-                pass
+            # This test fails on pypy with ssl.  I think it's because
-TestIOStreamWebHTTPS = skipIfNoSSL(TestIOStreamWebHTTPS)
+@skipIfNoSSL
-TestIOStreamSSL = skipIfNoSSL(TestIOStreamSSL)
+@skipIfNonUnix
-        return
+@unittest.skipIf(futures is None, "futures module not present")
-    futures is None, "futures module not present")(ThreadedResolverTest)
+@skipIfNonUnix
-ProcessTest = skipIfNonUnix(ProcessTest)
+@skipIfNonUnix
-SubprocessTest = skipIfNonUnix(SubprocessTest)
+@skipIfNoTwisted
-ReactorWhenRunningTest = skipIfNoTwisted(ReactorWhenRunningTest)
+@skipIfNoTwisted
-ReactorCallLaterTest = skipIfNoTwisted(ReactorCallLaterTest)
+@skipIfNoTwisted
-ReactorTwoCallLaterTest = skipIfNoTwisted(ReactorTwoCallLaterTest)
+@skipIfNoTwisted
-ReactorCallFromThreadTest = skipIfNoTwisted(ReactorCallFromThreadTest)
+@skipIfNoTwisted
-ReactorCallInThread = skipIfNoTwisted(ReactorCallInThread)
+@skipIfNoTwisted
-ReactorReaderWriterTest = skipIfNoTwisted(ReactorReaderWriterTest)
+@skipIfNoTwisted
-                "http://specs.openid.net/auth/2.0/identifier_select",
+            "http://specs.openid.net/auth/2.0/identifier_select",
-                "http://specs.openid.net/auth/2.0/identifier_select",
+            "http://specs.openid.net/auth/2.0/identifier_select",
-                        "http://axschema.org/namePerson/first",
+                    "http://axschema.org/namePerson/first",
-                        "http://axschema.org/namePerson",
+                    "http://axschema.org/namePerson",
-                        "http://axschema.org/namePerson/last",
+                    "http://axschema.org/namePerson/last",
-                    "http://specs.openid.net/extensions/oauth/1.0",
+                "http://specs.openid.net/extensions/oauth/1.0",
-               self.get_argument(name) == u("http://openid.net/srv/ax/1.0"):
+                    self.get_argument(name) == u("http://openid.net/srv/ax/1.0"):
-                callback_uri))
+                    callback_uri))
-             self._on_oauth_get_user, access_token, callback))
+                             self._on_oauth_get_user, access_token, callback))
-                                         access_token)
+                                            access_token)
-          "client_id": client_id
+            "redirect_uri": redirect_uri,
-                url_concat(self._OAUTH_AUTHORIZE_URL, args))
+            url_concat(self._OAUTH_AUTHORIZE_URL, args))
-            )
+        )
-                           post_args=None, **args):
+                        post_args=None, **args):
-               values[-1] == u("http://specs.openid.net/extensions/oauth/1.0"):
+                    values[-1] == u("http://specs.openid.net/extensions/oauth/1.0"):
-                              code, callback, extra_fields=None):
+                               code, callback, extra_fields=None):
-          "client_secret": client_secret,
+            "redirect_uri": redirect_uri,
-                                client_secret, callback, fields))
+                   self.async_callback(self._on_access_token, redirect_uri, client_id,
-                        callback, fields, response):
+                         callback, fields, response):
-            )
+        )
-                           post_args=None, **args):
+                         post_args=None, **args):
-        not os.environ.get("PYTHONPATH", "").startswith(path_prefix)):
+            not os.environ.get("PYTHONPATH", "").startswith(path_prefix)):
-            )
+        )
-                    request.proxy_password)
+                                     request.proxy_password)
-                        parts[1][:8].split('?')[0].split('.')[0]
+                    parts[1][:8].split('?')[0].split('.')[0]
-            setattr(cls, attr_name,  weakref.WeakKeyDictionary())
+            setattr(cls, attr_name, weakref.WeakKeyDictionary())
-                socket.AF_INET, socket.AF_INET6):
+                    socket.AF_INET, socket.AF_INET6):
-            isinstance(args[0], HTTPHeaders)):
+                isinstance(args[0], HTTPHeaders)):
-                         ''.join(traceback.format_stack(frame)))
+                        self._blocking_signal_threshold,
-                           "with the setitimer method")
+                          "with the setitimer method")
-                    stack_context.wrap(callback), *args, **kwargs))
+                stack_context.wrap(callback), *args, **kwargs))
-                        stack_context.wrap(callback), *args, **kwargs))
+                    stack_context.wrap(callback), *args, **kwargs))
-            self._pending_callbacks == 0):
+                self._pending_callbacks == 0):
-                 relative:
+                    relative:
-                         _("yesterday at %(time)s")
+                    _("yesterday at %(time)s")
-                         _("%(weekday)s at %(time)s")
+                    _("%(weekday)s at %(time)s")
-                         _("%(month_name)s %(day)s at %(time)s")
+                    _("%(month_name)s %(day)s at %(time)s")
-                     _("%(month_name)s %(day)s, %(year)s at %(time)s")
+                _("%(month_name)s %(day)s, %(year)s at %(time)s")
-                                       "ascii"),
+                                            "ascii"),
-                                      "ascii"),
+                                           "ascii"),
-                                         "ascii"),
+                                              "ascii"),
-                                       "ascii"),
+                                            "ascii"),
-        (options.log_to_stderr is None and not logger.handlers)):
+            (options.log_to_stderr is None and not logger.handlers)):
-           metavar="debug|info|warning|error|none")
+                   help=("Set the Python log level. If 'none', tornado won't touch the "
-                 "no other logging is configured."))
+                   help=("Send log output to stderr (colorized if possible). "
-                 "include the port number)"))
+                   help=("Path prefix for log files. "
-           help="max size of log files before rollover")
+                   help="max size of log files before rollover")
-           help="number of log files to keep")
+                   help="number of log files to keep")
-                    self.ssl_options['certfile'])
+                                 self.ssl_options['certfile'])
-                    self.ssl_options['keyfile'])
+                                 self.ssl_options['keyfile'])
-                                  0, flags)):
+                                      0, flags)):
-                    detail[0] != errno.WSAEADDRINUSE):
+                        detail[0] != errno.WSAEADDRINUSE):
-                    fd, filter=select.KQ_FILTER_WRITE, flags=flags))
+                fd, filter=select.KQ_FILTER_WRITE, flags=flags))
-                    fd, filter=select.KQ_FILTER_READ, flags=flags))
+                fd, filter=select.KQ_FILTER_READ, flags=flags))
-                                         IOLoop.READ)
+                                          IOLoop.READ)
-                                         IOLoop.WRITE)
+                                          IOLoop.WRITE)
-                    len(self.active), len(self.queue)))
+                              len(self.active), len(self.queue)))
-            isinstance(self.stream, SSLIOStream)):
+                isinstance(self.stream, SSLIOStream)):
-            not self.request.allow_nonstandard_methods):
+                not self.request.allow_nonstandard_methods):
-                    self.request.body))
+                self.request.body))
-            "Content-Type" not in self.request.headers):
+                "Content-Type" not in self.request.headers):
-                (('?' + self.parsed.query) if self.parsed.query else ''))
+                   (('?' + self.parsed.query) if self.parsed.query else ''))
-                                ))
+                                            request_time=self.io_loop.time() - self.start_time,
-                content_length not in (None, 0)):
+                    content_length not in (None, 0)):
-            self.headers.get("Content-Encoding") == "gzip"):
+                self.headers.get("Content-Encoding") == "gzip"):
-            self.code in (301, 302, 303, 307)):
+                self.code in (301, 302, 303, 307)):
-                              self._on_chunk_data)
+                                   self._on_chunk_data)
-            % (hostname, ', '.join(map(repr, dnsnames))))
+                               "doesn't match either of %s"
-            % (hostname, dnsnames[0]))
+                               "doesn't match %r"
-            "subjectAltName fields were found")
+                               "subjectAltName fields were found")
-           not name.startswith("/"):
+            not parent_path.startswith("/") and \
-           not name.startswith("/"):
+            not parent_path.startswith("/") and \
-                reader[curly + 1] == '{' and reader[curly + 2] == '{'):
+                    reader[curly + 1] == '{' and reader[curly + 2] == '{'):
-                            (operator, allowed_parents))
+                                (operator, allowed_parents))
-                ],
+            ],
-                                            u('secret'): u('vbnm')},
+                                              u('screen_name'): u('foo'),
-                 yield self.client.capitalize("HELLO")
+                yield self.client.capitalize("HELLO")
-    CurlHTTPClientCommonTestCase)
+                                                   CurlHTTPClientCommonTestCase)
-    CurlHTTPClientTestCase)
+                                             CurlHTTPClientTestCase)
-     {"extra_params": lambda href:'class="internal"' if href.startswith("http://www.internal-link.com") else 'rel="nofollow" class="external"'},
+     {"extra_params": lambda href: 'class="internal"' if href.startswith("http://www.internal-link.com") else 'rel="nofollow" class="external"'},
-     {"extra_params": lambda href:'    rel="nofollow" class="external"  '},
+     {"extra_params": lambda href: '    rel="nofollow" class="external"  '},
-            ]
+        ]
-            ]
+        ]
-            ]
+        ]
-                    self.delay_callback, iterations - 1, callback, arg))
+                self.delay_callback, iterations - 1, callback, arg))
-                ]
+            ]
-                ])
+            ('/sequence', GenSequenceHandler),
-            ], gzip=True)
+        ], gzip=True)
-        })
+                          "certfile": "/__mising__.crt",
-        })
+                          "certfile": existing_certificate,
-        })
+                   "certfile": existing_certificate,
-                           [utf8("Content-Length: %d\r\n" % len(body))]) +
+                         [utf8("Content-Length: %d\r\n" % len(body))]) +
-                    ]))
+            b"POST /multipart HTTP/1.0",
-                                     b"\r\n"]), callback=self.stop)
+                                   b"Content-Length: 1024",
-            ]
+        ]
-                )
+            "https://localhost/path",
-                )
+            "https://localhost/path",
-                )
+            "https://localhost/path?",
-                )
+            "https://localhost/path?x",
-                )
+            "https://localhost/path?x&",
-                )
+            "https://localhost/path?a=1&b=2",
-            )
+        )
-                    platform.python_implementation() == 'PyPy'):
+                        platform.python_implementation() == 'PyPy'):
-            )
+        )
-            }
+        }
-                    #int(fetch("/").body)
+                    # fetch("/?signal=%d" % signal.SIGTERM, fail_ok=True)
-                    ", ".join(sorted(skip_reasons))))
+                "Some tests were skipped because: %s" %
-            ], gzip=True)
+        ], gzip=True)
-            #request is the original request, is a POST still
+            # request is the original request, is a POST still
-                  functools.partial(library_inner_callback, callback))
+                    functools.partial(library_inner_callback, callback))
-                })
+            "index.html": '{% include "header.html" %}\nbody text',
-                "base.html": """\
+            "base.html": """\
-                "page.html": """\
+            "page.html": """\
-                })
+        })
-                })
+            "a/1.html": "{% include '2.html' %}",
-                })
+            "a.html": "{% include 'b.html' %}",
-            }
+        }
-            ] if issubclass(IOLoop.configured_class(), TwistedIOLoop) else [
+        ] if issubclass(IOLoop.configured_class(), TwistedIOLoop) else [
-            ],
+        ],
-            ],
+        ],
-            ],
+        ],
-            ],
+        ],
-            ],
+        ],
-            ],
+        ],
-            ],
+        ],
-        }
+    }
-    #log.startLoggingWithObserver(log.PythonLoggingObserver().emit, setStdout=0)
+    # import sys; log.startLogging(sys.stderr, setStdout=0)
-                to_basestring(timestamp), to_basestring(sig)))
+            to_basestring(timestamp), to_basestring(sig)))
-                "page.html": """\
+            "linkify.html": "{% module linkify(message) %}",
-                "entry.html": """\
+            "entry.html": """\
-                })
+        })
-            ]
+        ]
-                'If-Modified-Since': response1.headers['Last-Modified']})
+            'If-Modified-Since': response1.headers['Last-Modified']})
-                'If-None-Match': response1.headers['Etag']})
+            'If-None-Match': response1.headers['Etag']})
-            [("/foo", HostMatchingTest.Handler, {"reply": "[0]"})])
+                              [("/foo", HostMatchingTest.Handler, {"reply": "[0]"})])
-            [("/bar", HostMatchingTest.Handler, {"reply": "[1]"})])
+                              [("/bar", HostMatchingTest.Handler, {"reply": "[1]"})])
-            [("/baz", HostMatchingTest.Handler, {"reply": "[2]"})])
+                              [("/baz", HostMatchingTest.Handler, {"reply": "[2]"})])
-                'If-None-Match': response1.headers["Etag"]})
+            'If-None-Match': response1.headers["Etag"]})
-                        ])))
+            ("/", HelloHandler),
-            self.io_loop is not IOLoop.instance()):
+                self.io_loop is not IOLoop.instance()):
-                          timeout)
+                            'Async operation timed out after %s seconds' %
-                    condition is None or condition()):
+                        condition is None or condition()):
-            self.http_client.io_loop is not IOLoop.instance()):
+                self.http_client.io_loop is not IOLoop.instance()):
-                keyfile=os.path.join(module_dir, 'test', 'test.key'))
+            certfile=os.path.join(module_dir, 'test', 'test.crt'),
-
+
-                     application.ui_methods.items())
+                             application.ui_methods.items())
-                                 application.ui_modules.items())
+                                         application.ui_modules.items())
-                    self._status_code, self._headers, chunk, include_footers)
+                        self._status_code, self._headers, chunk, include_footers)
-                "Etag" not in self._headers):
+                    "Etag" not in self._headers):
-                    })
+                            "code": status_code,
-               self.application.settings.get("xsrf_cookies"):
+                    self.application.settings.get("xsrf_cookies"):
-            self._stack_context_handle_exception):
+                self._stack_context_handle_exception):
-            if type(spec) is type(()):
+            if isinstance(spec, type(())):
-        if type(methods) is types.ModuleType:
+        if isinstance(methods, types.ModuleType):
-                   and name[0].lower() == name[0]:
+                        and name[0].lower() == name[0]:
-        if type(modules) is types.ModuleType:
+        if isinstance(modules, types.ModuleType):
-                                       datetime.timedelta(seconds=cache_time))
+                            datetime.timedelta(seconds=cache_time))
-                 self.handler_class, self.kwargs, self.name)
+            (self.__class__.__name__, self.regex.pattern,
-        if type(a[0]) is int:  # python3 byte strings
+        if isinstance(a[0], int):  # python3 byte strings
-                    subprotocol=subprotocol_header))))
+            version=tornado.version,
-                    frame[:-1].decode("utf-8", "replace"))
+                frame[:-1].decode("utf-8", "replace"))
-                self.request.headers.get("Sec-Websocket-Key")))
+            self.request.headers.get("Sec-Websocket-Key")))
-        from cgi import parse_qs
+    from urlparse import parse_qs  # Python 2.6+
-            _json_encode = _json_decode
+import json
-    return _json_encode(recursive_unicode(value)).replace("</", "<\\/")
+    return json.dumps(recursive_unicode(value)).replace("</", "<\\/")
-    return _json_decode(to_basestring(value))
+    return json.loads(to_basestring(value))
-import sys
+import ssl
-try:
+import ssl
-import functools
+import multiprocessing
-try:
+import ssl
-import re
+import ssl
-        server = HTTPServer(application, ssl_options={
+        HTTPServer(application, ssl_options={
-
+import ssl
-from tornado.escape import native_str, utf8, parse_qs_bytes
+from tornado.escape import native_str, parse_qs_bytes
-from tornado.util import bytes_type, b, u, unicode_type
+from tornado.util import bytes_type, u, unicode_type
-from tornado.util import b, bytes_type
+from tornado.util import bytes_type
-from tornado.util import b, ObjectDict
+from tornado.util import ObjectDict
-    ... 
+    ...
-from tornado.util import b, bytes_type
+from tornado.util import bytes_type
-from tornado.util import b, GzipDecompressor
+from tornado.util import GzipDecompressor
-from tornado.util import b, u
+from tornado.util import u
-from tornado.util import b, u, unicode_type
+from tornado.util import u, unicode_type
-from tornado.util import b, u, bytes_type
+from tornado.util import u, bytes_type
-                stream.write(b("""\
+                stream.write(b"""\
-""").replace(b"\n", b"\r\n"), callback=stream.close)
+""".replace(b"\n", b"\r\n"), callback=stream.close)
-from tornado.util import b, u, bytes_type
+from tornado.util import u, bytes_type
-        data = b("""\
+        data = b"""\
-        data = b("""\
+        data = b"""\
-        data = b('''\
+        data = b'''\
-        data = b('''\
+        data = b'''\
-        data = b('''\
+        data = b'''\
-        data = b('''\
+        data = b'''\
-Foo--1234--''').replace(b"\n", b"\r\n")
+Foo--1234--'''.replace(b"\n", b"\r\n")
-        data = b("""\
+        data = b"""\
-        data = b("""\
+        data = b"""\
-""").replace(b"\n", b"\r\n")
+""".replace(b"\n", b"\r\n")
-from tornado.util import b, u, unicode_type
+from tornado.util import u, unicode_type
-from tornado.util import b, u, bytes_type, basestring_type
+from tornado.util import u, bytes_type, basestring_type
-from tornado.util import b, u, bytes_type, ObjectDict, unicode_type
+from tornado.util import u, bytes_type, ObjectDict, unicode_type
-                           "default: Bobby <table>s\n"))
+                         b"escaped: Bobby &lt;table&gt;s\n"
-                           "default: Bobby &lt;table&gt;s\n"))
+                         b"escaped: Bobby &lt;table&gt;s\n"
-                           "raw: <>&\""))
+                         b"expr: &lt;&gt;&amp;&quot;\n"
-                         b("""s = "';sys.exit()"\n"""))
+                         b"""s = "';sys.exit()"\n""")
-                         b("""s = "['not a string']"\n"""))
+                         b"""s = "['not a string']"\n""")
-from tornado.util import raise_exc_info, Configurable, u, b
+from tornado.util import raise_exc_info, Configurable, u
-from tornado.util import b, u, bytes_type, ObjectDict, unicode_type
+from tornado.util import u, bytes_type, ObjectDict, unicode_type
-        match = re.match(b(r'12345678\|([0-9]+)\|([0-9a-f]+)'), cookie)
+        match = re.match(br'12345678\|([0-9]+)\|([0-9a-f]+)', cookie)
-                         b("<a href=\"http://example.com\">http://example.com</a>"))
+                         b"<a href=\"http://example.com\">http://example.com</a>")
-        self.assertEqual(response.body, b("""\
+        self.assertEqual(response.body, b"""\
-</body></html>"""))
+</body></html>""")
-from tornado.util import b, u
+from tornado.util import u
-from tornado.util import b, bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type
+from tornado.util import bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type
-        if len(value) > 4000 or re.search(b(r"[\x00-\x1f]"), value):
+        if len(value) > 4000 or re.search(br"[\x00-\x1f]", value):
-        url = re.sub(b(r"[\x00-\x20]+"), "", utf8(url))
+        url = re.sub(br"[\x00-\x20]+", "", utf8(url))
-from tornado.util import bytes_type, b
+from tornado.util import bytes_type
-from tornado.util import b, bytes_type, unicode_type
+from tornado.util import bytes_type, unicode_type
-        if response.error or b("is_valid:true") not in response.body:
+        if response.error or b"is_valid:true" not in response.body:
-        data = (base64.b64encode(request_token["key"]) + b("|") +
+        data = (base64.b64encode(request_token["key"]) + b"|" +
-            "/users/show/" + escape.native_str(access_token[b("screen_name")]),
+            "/users/show/" + escape.native_str(access_token[b"screen_name"]),
-    key = b("&").join(key_elems)
+    key = b"&".join(key_elems)
-    key = b("&").join(key_elems)
+    key = b"&".join(key_elems)
-    token = dict(key=p[b("oauth_token")][0], secret=p[b("oauth_token_secret")][0])
+    token = dict(key=p[b"oauth_token"][0], secret=p[b"oauth_token_secret"][0])
-    special = (b("oauth_token"), b("oauth_token_secret"))
+    special = (b"oauth_token", b"oauth_token_secret")
-        self.stream.read_until(b("\r\n\r\n"), self._header_callback)
+        self.stream.read_until(b"\r\n\r\n", self._header_callback)
-            self.stream.read_until(b("\r\n\r\n"), self._header_callback)
+            self.stream.read_until(b"\r\n\r\n", self._header_callback)
-                    self.stream.write(b("HTTP/1.1 100 (Continue)\r\n\r\n"))
+                    self.stream.write(b"HTTP/1.1 100 (Continue)\r\n\r\n")
-    if boundary.startswith(b('"')) and boundary.endswith(b('"')):
+    if boundary.startswith(b'"') and boundary.endswith(b'"'):
-    final_boundary_index = data.rfind(b("--") + boundary + b("--"))
+    final_boundary_index = data.rfind(b"--" + boundary + b"--")
-    parts = data[:final_boundary_index].split(b("--") + boundary + b("\r\n"))
+    parts = data[:final_boundary_index].split(b"--" + boundary + b"\r\n")
-        eoh = part.find(b("\r\n\r\n"))
+        eoh = part.find(b"\r\n\r\n")
-        if disposition != "form-data" or not part.endswith(b("\r\n")):
+        if disposition != "form-data" or not part.endswith(b"\r\n"):
-            return b("")
+            return b""
-        deque.appendleft(b(""))
+        deque.appendleft(b"")
-            self.writer.send(b("x"))
+            self.writer.send(b"x")
-            self.writer.write(b("x"))
+            self.writer.write(b"x")
-            self.request.headers["Authorization"] = (b("Basic ") +
+            auth = utf8(username) + b":" + utf8(password)
-            if b('\n') in line:
+            line = utf8(k) + b": " + utf8(v)
-        self.stream.write(b("\r\n").join(request_lines) + b("\r\n\r\n"))
+        self.stream.write(b"\r\n".join(request_lines) + b"\r\n\r\n")
-        self.stream.read_until_regex(b("\r?\n\r?\n"), self._on_headers)
+        self.stream.read_until_regex(b"\r?\n\r?\n", self._on_headers)
-            self.stream.read_until_regex(b("\r?\n\r?\n"), self._on_headers)
+            self.stream.read_until_regex(b"\r?\n\r?\n", self._on_headers)
-            self._on_body(b(""))
+            self._on_body(b"")
-            self._on_body(b(""))
+            self._on_body(b"")
-            self.stream.read_until(b("\r\n"), self._on_chunk_length)
+            self.stream.read_until(b"\r\n", self._on_chunk_length)
-            self._on_body(b('').join(self.chunks))
+            self._on_body(b''.join(self.chunks))
-        assert data[-2:] == b("\r\n")
+        assert data[-2:] == b"\r\n"
-        self.stream.read_until(b("\r\n"), self._on_chunk_length)
+        self.stream.read_until(b"\r\n", self._on_chunk_length)
-        if access_token != dict(key=b('uiop'), secret=b('5678')):
+        if access_token != dict(key=b'uiop', secret=b'5678'):
-        self.stream.read_until(b("\n"), self.handle_read)
+        self.stream.read_until(b"\n", self.handle_read)
-            self.stream.write(b("error\talready capitalized\n"))
+            self.stream.write(b"error\talready capitalized\n")
-        self.stream.read_until(b('\n'), callback=self.handle_read)
+        self.stream.read_until(b'\n', callback=self.handle_read)
-        self.stream.read_until(b('\n'), callback=self.handle_read)
+        self.stream.read_until(b'\n', callback=self.handle_read)
-        data = yield gen.Task(stream.read_until, b('\n'))
+        data = yield gen.Task(stream.read_until, b'\n')
-            (b("<foo>"), b("&lt;foo&gt;")),
+            (b"<foo>", b"&lt;foo&gt;"),
-        self.assertEqual(json_decode(b('"foo"')), u("foo"))
+        self.assertEqual(json_decode(b'"foo"'), u("foo"))
-        self.assertRaises(UnicodeDecodeError, json_encode, b("\xe9"))
+        self.assertRaises(UnicodeDecodeError, json_encode, b"\xe9")
-        self.finish(b("got response: ") + response.body)
+        self.finish(b"got response: " + response.body)
-        self.assertEqual(response.body, b("123"))
+        self.assertEqual(response.body, b"123")
-        self.assertEqual(response.body, b("got response: 123"))
+        self.assertEqual(response.body, b"got response: 123")
-        self.assertEqual(response.body, b('ok'))
+        self.assertEqual(response.body, b'ok')
-        self.assertEqual(response.body, b("Hello world!"))
+        self.assertEqual(response.body, b"Hello world!")
-        self.assertEqual(response.body, b("Hello Ben!"))
+        self.assertEqual(response.body, b"Hello Ben!")
-        self.assertEqual(chunks, [b("Hello world!")])
+        self.assertEqual(chunks, [b"Hello world!"])
-        self.assertEqual(response.body, b("Post arg1: foo, arg2: bar"))
+        self.assertEqual(response.body, b"Post arg1: foo, arg2: bar")
-        self.assertEqual(response.body, b("asdfqwer"))
+        self.assertEqual(response.body, b"asdfqwer")
-        self.assertEqual(chunks, [b("asdf"), b("qwer")])
+        self.assertEqual(chunks, [b"asdf", b"qwer"])
-""").replace(b("\n"), b("\r\n")), callback=stream.close)
+""").replace(b"\n", b"\r\n"), callback=stream.close)
-                stream.read_until(b("\r\n\r\n"),
+                stream.read_until(b"\r\n\r\n",
-            self.assertEqual(resp.body, b("12"))
+            self.assertEqual(resp.body, b"12")
-            if chunk == b('qwer'):
+            if chunk == b'qwer':
-        self.assertEqual(chunks, [b('asdf'), b('qwer')])
+        self.assertEqual(chunks, [b'asdf', b'qwer'])
-                         b("Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ=="))
+                         b"Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==")
-        self.assertEqual(b("Zero"), response.body)
+        self.assertEqual(b"Zero", response.body)
-        self.assertEqual(b("Basic ") + base64.b64encode(b("me:secret")),
+        self.assertEqual(b"Basic " + base64.b64encode(b"me:secret"),
-        byte_body = binascii.a2b_hex(b("e9"))
+        byte_body = binascii.a2b_hex(b"e9")
-        self.assertEqual(chunks, [b('asdf'), b('qwer')])
+        self.assertEqual(chunks, [b'asdf', b'qwer'])
-        self.assertEqual(response.body, b('TestDefaultUserAgent'))
+        self.assertEqual(response.body, b'TestDefaultUserAgent')
-        self.assertEqual(response.body, b("Hello world"))
+        self.assertEqual(response.body, b"Hello world")
-        self.assertEqual(response.body, b("Got 5000 bytes in POST"))
+        self.assertEqual(response.body, b"Got 5000 bytes in POST")
-        self.stream.read_until(b("\r\n\r\n"), self._on_headers)
+        self.stream.read_until(b"\r\n\r\n", self._on_headers)
-            b("\r\n").join(headers +
+            b"\r\n".join(headers +
-            b("\r\n") + body)
+            b"\r\n" + body)
-                b("X-Header-encoding-test: \xe9"),
+                b"POST /multipart HTTP/1.0",
-                    b(""),
+                                  b"\r\n".join([
-                    b("--1234567890"),
+                    b"--1234567890",
-                    b(""),
+                    b"",
-                    b(""),
+                    b"--1234567890--",
-                                     b("\r\n")]), callback=self.stop)
+        stream.write(b"\r\n".join([b"POST /hello HTTP/1.1",
-        stream.read_until(b("\r\n\r\n"), self.stop)
+        stream.read_until(b"\r\n\r\n", self.stop)
-        stream.read_until(b("\r\n"), self.stop)
+        self.assertTrue(data.startswith(b"HTTP/1.1 100 "), data)
-        stream.read_until(b("\r\n\r\n"), self.stop)
+        self.assertTrue(first_line.startswith(b"HTTP/1.1 200"), first_line)
-        self.assertEqual(body, b("Got 1024 bytes in POST"))
+        self.assertEqual(body, b"Got 1024 bytes in POST")
-        stream.read_until(b("\r\n"), self.stop)
+        stream.write(b"GET /hello HTTP/1.0\r\n\r\n")
-        stream.read_until(b("\r\n\r\n"), self.stop)
+        self.assertEqual(response, b"HTTP/1.0 200 OK\r\n")
-        self.assertEqual(body, b("Hello world"))
+        self.assertEqual(body, b"Hello world")
-        self.http_version = b('HTTP/1.1')
+        self.http_version = b'HTTP/1.1'
-        self.stream.read_until(b('\r\n'), self.stop)
+        self.stream.read_until(b'\r\n', self.stop)
-        self.stream.read_until(b('\r\n\r\n'), self.stop)
+        self.assertTrue(first_line.startswith(self.http_version + b' 200'), first_line)
-        self.assertEqual(b('Hello world'), body)
+        self.assertEqual(b'Hello world', body)
-        self.stream.write(b('GET / HTTP/1.1\r\n\r\n'))
+        self.stream.write(b'GET / HTTP/1.1\r\n\r\n')
-        self.stream.write(b('GET / HTTP/1.1\r\n\r\n'))
+        self.stream.write(b'GET / HTTP/1.1\r\n\r\n')
-        self.stream.write(b('GET / HTTP/1.1\r\nConnection: close\r\n\r\n'))
+        self.stream.write(b'GET / HTTP/1.1\r\nConnection: close\r\n\r\n')
-        self.http_version = b('HTTP/1.0')
+        self.http_version = b'HTTP/1.0'
-        self.stream.write(b('GET / HTTP/1.0\r\n\r\n'))
+        self.stream.write(b'GET / HTTP/1.0\r\n\r\n')
-        self.http_version = b('HTTP/1.0')
+        self.http_version = b'HTTP/1.0'
-        self.stream.write(b('GET / HTTP/1.0\r\nConnection: keep-alive\r\n\r\n'))
+        self.stream.write(b'GET / HTTP/1.0\r\nConnection: keep-alive\r\n\r\n')
-        self.stream.write(b('GET / HTTP/1.0\r\nConnection: keep-alive\r\n\r\n'))
+        self.stream.write(b'GET / HTTP/1.0\r\nConnection: keep-alive\r\n\r\n')
-        self.stream.write(b('GET / HTTP/1.1\r\n\r\nGET / HTTP/1.1\r\n\r\n'))
+        self.stream.write(b'GET / HTTP/1.1\r\n\r\nGET / HTTP/1.1\r\n\r\n')
-        self.stream.write(b('GET / HTTP/1.1\r\n\r\nGET / HTTP/1.1\r\n\r\n'))
+        self.stream.write(b'GET / HTTP/1.1\r\n\r\nGET / HTTP/1.1\r\n\r\n')
-        self.stream.write(b('GET /large HTTP/1.1\r\n\r\n'))
+        self.stream.write(b'GET /large HTTP/1.1\r\n\r\n')
-        self.stream.write(b('GET /finish_on_close HTTP/1.1\r\n\r\n'))
+        self.stream.write(b'GET /finish_on_close HTTP/1.1\r\n\r\n')
-        parse_multipart_form_data(b("1234"), data, args, files)
+        parse_multipart_form_data(b"1234", data, args, files)
-        self.assertEqual(file["body"], b("Foo"))
+        self.assertEqual(file["body"], b"Foo")
-        parse_multipart_form_data(b("1234"), data, args, files)
+        parse_multipart_form_data(b"1234", data, args, files)
-        self.assertEqual(file["body"], b("Foo"))
+        self.assertEqual(file["body"], b"Foo")
-            parse_multipart_form_data(b("1234"), data, args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-            self.assertEqual(file["body"], b("Foo"))
+            self.assertEqual(file["body"], b"Foo")
-        parse_multipart_form_data(b('"1234"'), data, args, files)
+        parse_multipart_form_data(b'"1234"', data, args, files)
-        self.assertEqual(file["body"], b("Foo"))
+        self.assertEqual(file["body"], b"Foo")
-            parse_multipart_form_data(b("1234"), data, args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-            parse_multipart_form_data(b("1234"), data, args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-Foo--1234--''').replace(b("\n"), b("\r\n"))
+Foo--1234--''').replace(b"\n", b"\r\n")
-            parse_multipart_form_data(b("1234"), data, args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-            parse_multipart_form_data(b("1234"), data, args, files)
+            parse_multipart_form_data(b"1234", data, args, files)
-""").replace(b("\n"), b("\r\n"))
+""").replace(b"\n", b"\r\n")
-        parse_multipart_form_data(b("1234"), data, args, files)
+        parse_multipart_form_data(b"1234", data, args, files)
-        self.assertEqual(file["body"], b("Foo"))
+        self.assertEqual(file["body"], b"Foo")
-        stream.write(b("GET / HTTP/1.0\r\n\r\n"))
+        stream.write(b"GET / HTTP/1.0\r\n\r\n")
-        self.assertTrue(data.endswith(b("Hello")))
+        self.assertTrue(data.startswith(b"HTTP/1.0 200"))
-        self.stream.write(b("GET / HTTP/1.0\r\n\r\n"))
+        self.stream.write(b"GET / HTTP/1.0\r\n\r\n")
-        self.assertEqual(data, b("HTTP/1.0 "))
+        self.assertEqual(data, b"HTTP/1.0 ")
-        self.assertEqual(data, b(""))
+        self.assertEqual(data, b"")
-        self.assertEqual(data, b("200"))
+        self.assertEqual(data, b"200")
-        stream.write(b("GET / HTTP/1.0\r\nConnection: close\r\n\r\n"),
+        stream.write(b"GET / HTTP/1.0\r\nConnection: close\r\n\r\n",
-        self.assertTrue(data.endswith(b("Hello")))
+        self.assertTrue(data.endswith(b"Hello"))
-        server.write(b(''), callback=self.stop)
+        server.write(b'', callback=self.stop)
-                client.write(b("1"))
+                client.write(b"1")
-            client.write(b("1234"))
+            client.write(b"1234")
-            client.write(b("5678"))
+            client.write(b"5678")
-            self.assertEqual(chunks, [b("1234"), b("56")])
+            self.assertEqual(chunks, [b"1234", b"56"])
-            self.assertEqual(data, b("78"))
+            self.assertEqual(data, b"78")
-            server.write(b("1234"))
+            server.write(b"1234")
-            server.write(b("5678"))
+            server.write(b"5678")
-            self.assertEqual(chunks, [b("1234"), b("5678"), b("")])
+            self.assertEqual(chunks, [b"1234", b"5678", b""])
-            server.write(b("12"))
+            server.write(b"12")
-            self.assertEqual(chunks, [b("1"), b("2")])
+            self.assertEqual(chunks, [b"1", b"2"])
-            server.write(b("A") * 512)
+            server.write(b"A" * 512)
-            self.assertEqual(b("A") * 256, data)
+            self.assertEqual(b"A" * 256, data)
-            self.assertEqual(b("A") * 256, data)
+            self.assertEqual(b"A" * 256, data)
-            server.write(b("1234"))
+            server.write(b"1234")
-            self.assertEqual(data, b("1234"))
+            self.assertEqual(data, b"1234")
-            server.write(b("1234"))
+            server.write(b"1234")
-            self.assertEqual(b('').join(streaming_data), b("1234"))
+            self.assertEqual(b'', data)
-            server.read_until(b("\r\n"), self.stop)
+                client.write(b"A" * 1024)
-        OK = b("OK\r\n")
+        OK = b"OK\r\n"
-            client.read_until(b("\r\n"), self.stop)
+            client.read_until(b"\r\n", self.stop)
-            client.read_until(b("\r\n"), lambda x: x)
+            client.read_until(b"\r\n", lambda x: x)
-            client.write(b('a'))
+            client.write(b'a')
-        ws.write(b("lo world"))
+        ws.write(b"hel")
-        rs.read_until(b(' '), callback=self.stop)
+        rs.read_until(b' ', callback=self.stop)
-        self.assertEqual(data, b("hello "))
+        self.assertEqual(data, b"hello ")
-        self.assertEqual(data, b("wor"))
+        self.assertEqual(data, b"wor")
-        self.assertEqual(data, b("ld"))
+        self.assertEqual(data, b"ld")
-        self.assertEqual(utf8(name), b('Espa\xc3\xb1ol'))
+        self.assertEqual(utf8(name), b'Espa\xc3\xb1ol')
-    LINE_RE = re.compile(b("\x01\\[E [0-9]{6} [0-9]{2}:[0-9]{2}:[0-9]{2} log_test:[0-9]+\\]\x02 (.*)"))
+    LINE_RE = re.compile(b"\x01\\[E [0-9]{6} [0-9]{2}:[0-9]{2}:[0-9]{2} log_test:[0-9]+\\]\x02 (.*)")
-        self.assertEqual(self.get_output(), b("foo"))
+        self.assertEqual(self.get_output(), b"foo")
-            self.assertEqual(self.get_output(), utf8(repr(b("\xe9"))))
+            self.logger.error(b"\xe9")
-        subproc.stdout.read_until(b('>>> '), self.stop)
+        subproc.stdout.read_until(b'>>> ', self.stop)
-        subproc.stdout.read_until(b('\n'), self.stop)
+        subproc.stdin.write(b"print('hello')\n")
-        self.assertEqual(data, b("hello\n"))
+        self.assertEqual(data, b"hello\n")
-        subproc.stdout.read_until(b(">>> "), self.stop)
+        subproc.stdout.read_until(b">>> ", self.stop)
-        subproc.stdin.write(b("raise SystemExit\n"))
+        subproc.stdin.write(b"raise SystemExit\n")
-        self.assertEqual(data, b(""))
+        self.assertEqual(data, b"")
-        self.assertNotEqual(response.body, b("asdfqwer"))
+        self.assertNotEqual(response.body, b"asdfqwer")
-        self.assertEqual(f.read(), b("asdfqwer"))
+        self.assertEqual(f.read(), b"asdfqwer")
-        self.assertEqual(response.body, b("Hello world!"))
+        self.assertEqual(response.body, b"Hello world!")
-        self.assertEqual(response.body, b("ok"))
+        self.assertEqual(response.body, b"ok")
-        self.assertEqual(response.body, b("ok"))
+        self.assertEqual(response.body, b"ok")
-        self.assertEqual(response.body, b("ok"))
+        self.assertEqual(response.body, b"ok")
-        host_re = re.compile(b("^localhost:[0-9]+$"))
+        host_re = re.compile(b"^localhost:[0-9]+$")
-            b("HTTP/1.1 100 CONTINUE\r\n\r\n"),
+            b"HTTP/1.1 100 CONTINUE\r\n\r\n",
-            b("HTTP/1.1 200 OK\r\nContent-Length: 1\r\n\r\nA"),
+            b"HTTP/1.1 200 OK\r\nContent-Length: 1\r\n\r\nA",
-        self.assertEqual(res.body, b('A'))
+        self.assertEqual(res.body, b'A')
-        self.assertTrue(b('got expected exception') in self.response.body)
+        self.assertTrue(b'got expected exception' in self.response.body)
-                         b("Hello Ben!"))
+                         b"Hello Ben!")
-                         b("Hello Ben!"))
+                         b"Hello Ben!")
-        self.assertEqual(template.generate(), b("2 + 2 = 4"))
+        self.assertEqual(template.generate(), b"2 + 2 = 4")
-                         b("Hello Ben!"))
+                         b"Hello Ben!")
-                         b("header text\nbody text"))
+                         b"header text\nbody text")
-                         b("<title>page title</title>\n<body>page body</body>\n"))
+                         b"<title>page title</title>\n<body>page body</body>\n")
-                         b("ok"))
+                         b"ok")
-        self.assertEqual(Template("{%!").generate(), b("{%"))
+        self.assertEqual(Template("{{!").generate(), b"{{")
-                         b("expr {{jquery expr}}"))
+                         b"expr {{jquery expr}}")
-        self.assertEqual(loader.load("test.html").generate(), b("6"))
+        self.assertEqual(loader.load("test.html").generate(), b"6")
-        self.assertEqual(template.generate(upper=upper), b("FOO"))
+        self.assertEqual(template.generate(upper=upper), b"FOO")
-        self.assertEqual(template.generate(x=3), b("no"))
+        self.assertEqual(template.generate(x=5), b"yes")
-        self.assertEqual(template.generate(), b(""))
+        self.assertEqual(template.generate(), b"")
-        self.assertEqual(template.generate(x=0), b("\ntry-except\n-finally\n"))
+        self.assertEqual(template.generate(x=1), b"\ntry\n-else\n-finally\n")
-        self.assertEqual(template.generate(), b("foo"))
+        self.assertEqual(template.generate(), b"foo")
-        self.assertEqual(result, b("013456"))
+        result = b''.join(result.split())
-                         b("Bobby &lt;table&gt;s"))
+                         b"Bobby &lt;table&gt;s")
-                         b("Bobby <table>s"))
+                         b"Bobby <table>s")
-                         b("Bobby <table>s"))
+                         b"Bobby <table>s")
-                         b("Bobby &lt;table&gt;s"))
+                         b"Bobby &lt;table&gt;s")
-                         b("Bobby <table>s"))
+                         b"Bobby <table>s")
-                         b("Bobby &lt;table&gt;s"))
+                         b"Bobby &lt;table&gt;s")
-                         b("base: &lt;script&gt;"))
+                         b"base: &lt;script&gt;")
-                         b("base: <script>"))
+                         b"base: <script>")
-                         b("base: <script>"))
+                         b"base: <script>")
-                         b("extended: &lt;script&gt;"))
+                         b"extended: &lt;script&gt;")
-                         b("base: &lt;script&gt;"))
+                         b"base: &lt;script&gt;")
-                         b("extended: <script>"))
+                         b"extended: <script>")
-                         b("s = '<html>'\n"))
+                         b"s = '<html>'\n")
-        self.assertEqual(utf8(u('\u00e9')), b('\xc3\xa9'))
+        self.assertEqual(utf8(u('\u00e9')), b'\xc3\xa9')
-        self.assertEqual(handler.get_secure_cookie('foo'), b('bar'))
+        handler.set_secure_cookie('foo', b'bar')
-        handler.set_secure_cookie('foo', binascii.a2b_hex(b('d76df8e7aefc')))
+        handler.set_secure_cookie('foo', binascii.a2b_hex(b'd76df8e7aefc'))
-                              'foo', '1234', b('5678') + timestamp),
+                              'foo', '1234', b'5678' + timestamp),
-        self.assertEqual(handler.get_secure_cookie('foo'), b('\xe9'))
+        handler.set_secure_cookie('foo', b'\xe9')
-                self.set_cookie("bytes", b("zxcv"))
+                self.set_cookie("bytes", b"zxcv")
-        self.assertEqual(response.body, b("bar"))
+        self.assertEqual(response.body, b"bar")
-        self.assertEqual(response.body, b("bar"))
+        self.assertEqual(response.body, b"bar")
-        self.assertEqual(response.body, b("default"))
+        self.assertEqual(response.body, b"default")
-        self.stream.write(b("GET / HTTP/1.0\r\n\r\n"))
+        self.stream.write(b"GET / HTTP/1.0\r\n\r\n")
-                self.finish(b("ok"))
+                self.finish(b"ok")
-        self.assertEqual(self.app.reverse_url('decode_arg', b('\xe9')),
+        self.assertEqual(self.app.reverse_url('decode_arg', b'\xe9'),
-        self.assertEqual(response.body, b("ok"))
+        self.assertEqual(response.body, b"ok")
-        self.assertEqual(response.body, b("bar"))
+        self.assertEqual(response.body, b"bar")
-        self.assertEqual(response.body, b(""))
+        self.assertEqual(response.body, b"")
-        self.assertEqual(response.body, b("default"))
+        self.assertEqual(response.body, b"default")
-        self.assertEqual(self.fetch("/flow_control").body, b("123"))
+        self.assertEqual(self.fetch("/flow_control").body, b"123")
-        self.assertEqual(response.body, b("ok"))
+        self.assertEqual(response.body, b"ok")
-            self.assertTrue(b("500: Internal Server Error") in response.body)
+            self.assertTrue(b"500: Internal Server Error" in response.body)
-            self.assertTrue(b("503: Service Unavailable") in response.body)
+            self.assertTrue(b"503: Service Unavailable" in response.body)
-            self.assertEqual(b("Exception: ZeroDivisionError"), response.body)
+            self.assertEqual(b"Exception: ZeroDivisionError", response.body)
-            self.assertEqual(b("Status: 503"), response.body)
+            self.assertEqual(b"Status: 503", response.body)
-            self.assertEqual(b("Exception: ZeroDivisionError"), response.body)
+            self.assertEqual(b"Exception: ZeroDivisionError", response.body)
-            self.assertEqual(b("Status: 503"), response.body)
+            self.assertEqual(b"Status: 503", response.body)
-            self.assertEqual(b(""), response.body)
+            self.assertEqual(b"", response.body)
-        self.assertTrue(b("Disallow: /") in response.body)
+        self.assertTrue(b"Disallow: /" in response.body)
-        self.assertTrue(b("Disallow: /") in response.body)
+        self.assertTrue(b"Disallow: /" in response.body)
-        self.assertEqual(response.body, b("/static/robots.txt?v=f71d2"))
+        self.assertEqual(response.body, b"/static/robots.txt?v=f71d2")
-        self.assertEqual(response.body, b("bar"))
+        self.assertEqual(response.body, b"bar")
-            self.assertEqual(response.body, b("/static/foo.42.txt"))
+            self.assertEqual(response.body, b"/static/foo.42.txt")
-        self.assertEqual(response.body, b("wildcard"))
+        self.assertEqual(response.body, b"wildcard")
-        self.assertEqual(response.body, b("[0]"))
+        self.assertEqual(response.body, b"[0]")
-        self.assertEqual(response.body, b("[1]"))
+        self.assertEqual(response.body, b"[1]")
-        self.assertEqual(response.body, b("[2]"))
+        self.assertEqual(response.body, b"[2]")
-        self.assertEqual(response.body, b("foo"))
+        self.assertEqual(response.body, b"foo")
-        self.assertEqual(response.body, b("bar"))
+        self.assertEqual(response.body, b"bar")
-        self.assertIn(b('682: Foo'), response.body)
+        self.assertIn(b'682: Foo', response.body)
-        return [b("Hello world!")]
+        return [b"Hello world!"]
-        self.assertEqual(response.body, b("Hello world!"))
+        self.assertEqual(response.body, b"Hello world!")
-        self.assertEqual(response.body, b("Hello world!"))
+        self.assertEqual(response.body, b"Hello world!")
-            html = html[:sloc] + utf8(js) + b('\n') + html[sloc:]
+            sloc = html.rindex(b'</body>')
-            html = html[:sloc] + js + b('\n') + html[sloc:]
+            js = b'<script type="text/javascript">\n//<![CDATA[\n' + \
-            html = html[:hloc] + utf8(css) + b('\n') + html[hloc:]
+            hloc = html.index(b'</head>')
-            html = html[:hloc] + css + b('\n') + html[hloc:]
+            css = b'<style type="text/css">\n' + b'\n'.join(css_embed) + \
-            html = html[:hloc] + b('').join(html_heads) + b('\n') + html[hloc:]
+            hloc = html.index(b'</head>')
-            html = html[:hloc] + b('').join(html_bodies) + b('\n') + html[hloc:]
+            hloc = html.index(b'</body>')
-        chunk = b("").join(self._write_buffer)
+        chunk = b"".join(self._write_buffer)
-            headers = b("")
+            headers = b""
-        lines.extend([(utf8(n) + b(": ") + utf8(v)) for n, v in
+        lines.extend([(utf8(n) + b": " + utf8(v)) for n, v in
-        return b("\r\n").join(lines) + b("\r\n\r\n")
+        return b"\r\n".join(lines) + b"\r\n\r\n"
-            headers['Vary'] += b(', Accept-Encoding')
+            headers['Vary'] += b', Accept-Encoding'
-            headers['Vary'] = b('Accept-Encoding')
+            headers['Vary'] = b'Accept-Encoding'
-                block = utf8("%x" % len(block)) + b("\r\n") + block + b("\r\n")
+                block = utf8("%x" % len(block)) + b"\r\n" + block + b"\r\n"
-                block += b("0\r\n\r\n")
+                block += b"0\r\n\r\n"
-    value = b("|").join([value, timestamp, signature])
+    value = b"|".join([value, timestamp, signature])
-    parts = utf8(value).split(b("|"))
+    parts = utf8(value).split(b"|")
-    if parts[1].startswith(b("0")):
+    if parts[1].startswith(b"0"):
-            self.stream.read_until(b("\xff"), self._on_end_delimiter)
+            self.stream.read_until(b"\xff", self._on_end_delimiter)
-        self.stream.write(b("\x00") + message + b("\xff"))
+        self.stream.write(b"\x00" + message + b"\xff")
-        sha1.update(b("258EAFA5-E914-47DA-95CA-C5AB0DC85B11"))  # Magic value
+        sha1.update(b"258EAFA5-E914-47DA-95CA-C5AB0DC85B11")  # Magic value
-                self._write_frame(True, 0x8, b(""))
+                self._write_frame(True, 0x8, b"")
-        body = b("").join(response)
+        body = b"".join(response)
-        parts.append(b("\r\n"))
+            parts.append(escape.utf8(key) + b": " + escape.utf8(value) + b"\r\n")
-        request.write(b("").join(parts))
+        request.write(b"".join(parts))
-                pass
+        if hasattr(select, "epoll"):
-"""
+"""EPoll-based IOLoop implementation for Linux systems."""
-
+class EPollIOLoop(PollIOLoop):
-from tornado.util import bytes_type, b, u
+from tornado.util import bytes_type, b, u, unicode_type
-        self.redirect(self._OPENID_ENDPOINT + "?" + urllib.urlencode(args))
+        self.redirect(self._OPENID_ENDPOINT + "?" + urllib_parse.urlencode(args))
-        args = dict((k, v[-1]) for k, v in self.request.arguments.iteritems())
+        args = dict((k, v[-1]) for k, v in self.request.arguments.items())
-            method="POST", body=urllib.urlencode(args))
+            method="POST", body=urllib_parse.urlencode(args))
-        for name in self.request.arguments.iterkeys():
+        for name in self.request.arguments.keys():
-            for name in self.request.arguments.iterkeys():
+            for name in self.request.arguments.keys():
-        return url + "?" + urllib.urlencode(args)
+        return url + "?" + urllib_parse.urlencode(args)
-            self.finish(authorize_url + "?" + urllib.urlencode(args))
+            self.finish(authorize_url + "?" + urllib_parse.urlencode(args))
-        self.redirect(authorize_url + "?" + urllib.urlencode(args))
+        self.redirect(authorize_url + "?" + urllib_parse.urlencode(args))
-        return url + "?" + urllib.urlencode(args)
+        return url + "?" + urllib_parse.urlencode(args)
-            url += "?" + urllib.urlencode(args)
+            url += "?" + urllib_parse.urlencode(args)
-            http.fetch(url, method="POST", body=urllib.urlencode(post_args),
+            http.fetch(url, method="POST", body=urllib_parse.urlencode(post_args),
-            url += "?" + urllib.urlencode(args)
+            url += "?" + urllib_parse.urlencode(args)
-            http.fetch(url, method="POST", body=urllib.urlencode(post_args),
+            http.fetch(url, method="POST", body=urllib_parse.urlencode(post_args),
-        self.redirect(self._OPENID_ENDPOINT + "?" + urllib.urlencode(args))
+        self.redirect(self._OPENID_ENDPOINT + "?" + urllib_parse.urlencode(args))
-            if isinstance(extended_permissions, (unicode, bytes_type)):
+            if isinstance(extended_permissions, (unicode_type, bytes_type)):
-                      urllib.urlencode(args))
+                      urllib_parse.urlencode(args))
-            urllib.urlencode(args)
+            urllib_parse.urlencode(args)
-        if isinstance(body, unicode):
+        if isinstance(body, unicode_type):
-            url += "?" + urllib.urlencode(all_args)
+            url += "?" + urllib_parse.urlencode(all_args)
-            http.fetch(url, method="POST", body=urllib.urlencode(post_args),
+            http.fetch(url, method="POST", body=urllib_parse.urlencode(post_args),
-    key_elems.append(escape.utf8(urllib.quote(token["secret"], safe='~') if token else ""))
+    key_elems = [escape.utf8(urllib_parse.quote(consumer_token["secret"], safe='~'))]
-    if isinstance(val, unicode):
+    if isinstance(val, unicode_type):
-    return urllib.quote(val, safe="~")
+    return urllib_parse.quote(val, safe="~")
-    from urlparse import parse_qs  # Python 2.6+
+    from urllib.parse import parse_qs  # py3
-    from cgi import parse_qs
+    try:
-    return urllib.quote_plus(utf8(value))
+    return urllib_parse.quote_plus(utf8(value))
-            return urllib.unquote_plus(utf8(value))
+            return urllib_parse.unquote_plus(utf8(value))
-            return unicode_type(urllib.unquote_plus(utf8(value)), encoding)
+            return unicode_type(urllib_parse.unquote_plus(utf8(value)), encoding)
-            return urllib.parse.unquote_to_bytes(value)
+            return urllib_parse.unquote_to_bytes(value)
-            return urllib.unquote_plus(to_basestring(value), encoding=encoding)
+            return urllib_parse.unquote_plus(to_basestring(value), encoding=encoding)
-        for k, v in result.iteritems():
+        for k, v in result.items():
-        return dict((recursive_unicode(k), recursive_unicode(v)) for (k, v) in obj.iteritems())
+        return dict((recursive_unicode(k), recursive_unicode(v)) for (k, v) in obj.items())
-    >>> h.keys()
+    >>> list(h.keys())
-        for name, list in self._as_list.iteritems():
+        for name, list in self._as_list.items():
-        >>> sorted(h.iteritems())
+        >>> sorted(h.items())
-        for k, v in dict(*args, **kwargs).iteritems():
+        for k, v in dict(*args, **kwargs).items():
-    return url + urllib.urlencode(args)
+    return url + urlencode(args)
-        for name, values in uri_arguments.iteritems():
+        for name, values in uri_arguments.items():
-    key = parts.next()
+    key = next(parts)
-            for fd in self._handlers.keys()[:]:
+            for fd in self._handlers.keys():
-        assert isinstance(num_bytes, (int, long))
+        assert isinstance(num_bytes, numbers.Integral)
-    _supported_locales = frozenset(_translations.keys() + [_default_locale])
+    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])
-    _supported_locales = frozenset(_translations.keys() + [_default_locale])
+    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])
-    _supported_locales = frozenset(_translations.keys() + [_default_locale])
+    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])
-        for fd, sock in self._sockets.iteritems():
+        for fd, sock in self._sockets.items():
-        for option in self._options.itervalues():
+        for option in self._options.values():
-        for pid in cls._waiting.keys():
+        for pid in list(cls._waiting.keys()):  # make a copy
-from tornado.util import bytes_type, ObjectDict, exec_in
+from tornado.util import bytes_type, ObjectDict, exec_in, unicode_type
-            "_string_types": (unicode, bytes_type),
+            "_string_types": (unicode_type, bytes_type),
-from tornado.util import b, u
+from tornado.util import b, u, unicode_type
-        self.assertEqual(type(xhtml_escape(u("foo"))), unicode)
+        self.assertEqual(type(xhtml_escape(u("foo"))), unicode_type)
-            for i in xrange(10):
+            for i in range(10):
-            for i in xrange(10):
+            for i in range(10):
-        self.check_type('header_value', self.request.headers.values()[0], str)
+        self.check_type('header_key', list(self.request.headers.keys())[0], str)
-        self.check_type('cookie_value', self.request.cookies.values()[0].value, str)
+        self.check_type('cookie_key', list(self.request.cookies.keys())[0], str)
-        self.check_type('arg_value', self.request.arguments.values()[0][0], bytes_type)
+        self.check_type('arg_key', list(self.request.arguments.keys())[0], str)
-                self.write(''.join(chr(i % 256) * 1024 for i in xrange(512)))
+                self.write(''.join(chr(i % 256) * 1024 for i in range(512)))
-            for i in xrange(NUM_KB):
+            for i in range(NUM_KB):
-from tornado.util import b, u
+from tornado.util import b, u, unicode_type
-        self.assertTrue(isinstance(name, unicode))
+        self.assertTrue(isinstance(name, unicode_type))
-from tornado.util import b, u, bytes_type
+from tornado.util import b, u, bytes_type, basestring_type
-        if issubclass(bytes_type, basestring):
+        if issubclass(bytes_type, basestring_type):
-from tornado.util import b, u, bytes_type, ObjectDict
+from tornado.util import b, u, bytes_type, ObjectDict, unicode_type
-        if str is unicode:
+        if str is unicode_type:
-from tornado.util import b, u, bytes_type, ObjectDict
+from tornado.util import b, u, bytes_type, ObjectDict, unicode_type
-                if type(value) != unicode:
+                if type(value) != unicode_type:
-            if type(arg) != unicode:
+            if type(arg) != unicode_type:
-        self.check_type('cookie_value', self.cookies.values()[0].value, str)
+        self.check_type('argument', self.get_argument('foo'), unicode_type)
-        if self.cookies.keys() != ['asdf']:
+        if list(self.cookies.keys()) != ['asdf']:
-        self.check_type('path_component', path_component, unicode)
+        self.check_type('path_component', path_component, unicode_type)
-        self.check_type('path_component', path_component, unicode)
+        self.check_type('path_component', path_component, unicode_type)
-            elif type(s) == unicode:
+            elif type(s) == unicode_type:
-from tornado.util import raise_exc_info
+from tornado.util import raise_exc_info, basestring_type
-        if isinstance(logger, basestring):
+        if isinstance(logger, basestring_type):
-from tornado.util import b, bytes_type, import_object, ObjectDict, raise_exc_info
+from tornado.util import b, bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type
-                     application.ui_methods.iteritems())
+                     application.ui_methods.items())
-                                 application.ui_modules.iteritems())
+                                 application.ui_modules.items())
-        elif isinstance(value, unicode):
+        elif isinstance(value, unicode_type):
-        elif isinstance(value, (int, long)):
+        elif isinstance(value, numbers.Integral):
-            if isinstance(v, unicode):
+            if isinstance(v, unicode_type):
-        for k, v in kwargs.iteritems():
+        for k, v in kwargs.items():
-        for module in getattr(self, "_active_modules", {}).itervalues():
+        for module in getattr(self, "_active_modules", {}).values():
-                if isinstance(file_part, (unicode, bytes_type)):
+                if isinstance(file_part, (unicode_type, bytes_type)):
-                if isinstance(file_part, (unicode, bytes_type)):
+                if isinstance(file_part, (unicode_type, bytes_type)):
-                                    for (k, v) in kwargs.iteritems())
+                                    for (k, v) in kwargs.items())
-                      itertools.chain(self._headers.iteritems(), self._list_headers)])
+                      itertools.chain(self._headers.items(), self._list_headers)])
-            for name, fn in methods.iteritems():
+            for name, fn in methods.items():
-            for name, cls in modules.iteritems():
+            for name, cls in modules.items():
-                                for (k, v) in match.groupdict().iteritems())
+                                for (k, v) in match.groupdict().items())
-                    url += "?" + urllib.urlencode(dict(next=next_url))
+                    url += "?" + urlencode(dict(next=next_url))
-            if isinstance(f, (unicode, bytes_type)):
+            if isinstance(f, (unicode_type, bytes_type)):
-            if isinstance(f, (unicode, bytes_type)):
+            if isinstance(f, (unicode_type, bytes_type)):
-            if not isinstance(a, (unicode, bytes_type)):
+            if not isinstance(a, (unicode_type, bytes_type)):
-        headers = handler._headers.items() + handler._list_headers
+        headers = list(handler._headers.items()) + handler._list_headers
-        self.path += urllib.quote(from_wsgi_str(environ.get("PATH_INFO", "")))
+        self.path = urllib_parse.quote(from_wsgi_str(environ.get("SCRIPT_NAME", "")))
-        for key, value in request.headers.iteritems():
+        for key, value in request.headers.items():
-                exec f.read() in globals(), globals()
+                exec_in(f.read(), globals(), globals())
-        if isinstance(deadline, (int, long, float)):
+        if isinstance(deadline, numbers.Real):
-    exec(code, namespace)
+def exec_in(code, glob, loc=None):
-    exec code in namespace
+def exec_in(code, glob, loc=None):
-import urlparse
+try:
-    bytes = str
+from tornado.util import bytes_type, unicode_type, basestring_type, u
-            return unicode(urllib.unquote_plus(utf8(value)), encoding)
+            return unicode_type(urllib.unquote_plus(utf8(value)), encoding)
-_UTF8_TYPES = (bytes, type(None))
+_UTF8_TYPES = (bytes_type, type(None))
-    assert isinstance(value, unicode)
+    assert isinstance(value, unicode_type)
-_TO_UNICODE_TYPES = (unicode, type(None))
+_TO_UNICODE_TYPES = (unicode_type, type(None))
-    assert isinstance(value, bytes)
+    assert isinstance(value, bytes_type)
-if str is unicode:
+if str is unicode_type:
-_BASESTRING_TYPES = (basestring, type(None))
+_BASESTRING_TYPES = (basestring_type, type(None))
-    assert isinstance(value, bytes)
+    assert isinstance(value, bytes_type)
-    elif isinstance(obj, bytes):
+    elif isinstance(obj, bytes_type):
-    for name, value in htmlentitydefs.name2codepoint.iteritems():
+    for name, value in htmlentitydefs.name2codepoint.items():
-        self.reason = reason or httplib.responses.get(code, "Unknown")
+        self.reason = reason or httputil.responses.get(code, "Unknown")
-        message = message or httplib.responses.get(code, "Unknown")
+        message = message or httputil.responses.get(code, "Unknown")
-import Cookie
+try:
-import thread
+try:
-                fg_color = unicode(fg_color, "ascii")
+                fg_color = unicode_type(fg_color, "ascii")
-                logging.DEBUG: unicode(curses.tparm(fg_color, 4),  # Blue
+                logging.DEBUG: unicode_type(curses.tparm(fg_color, 4),  # Blue
-                logging.INFO: unicode(curses.tparm(fg_color, 2),  # Green
+                logging.INFO: unicode_type(curses.tparm(fg_color, 2),  # Green
-                logging.WARNING: unicode(curses.tparm(fg_color, 3),  # Yellow
+                logging.WARNING: unicode_type(curses.tparm(fg_color, 3),  # Yellow
-                logging.ERROR: unicode(curses.tparm(fg_color, 1),  # Red
+                logging.ERROR: unicode_type(curses.tparm(fg_color, 1),  # Red
-            self._normal = unicode(curses.tigetstr("sgr0"), "ascii")
+            self._normal = unicode_type(curses.tigetstr("sgr0"), "ascii")
-        assert isinstance(record.message, basestring)  # guaranteed by logging
+        assert isinstance(record.message, basestring_type)  # guaranteed by logging
-    def bind_unix_socket(file, mode=0600, backlog=128):
+    def bind_unix_socket(file, mode=int('600', 8), backlog=128):
-        for i in xrange(1, len(args)):
+        for i in range(1, len(args)):
-    def __init__(self, name, default=None, type=basestring, help=None,
+    def __init__(self, name, default=None, type=basestring_type, help=None,
-            basestring: self._parse_string,
+            basestring_type: self._parse_string,
-import urlparse
+try:
-from tornado.util import bytes_type, ObjectDict
+from tornado.util import bytes_type, ObjectDict, exec_in
-        exec self.compiled in namespace
+        exec_in(self.compiled, namespace)
-        buffer = cStringIO.StringIO()
+        buffer = StringIO()
-     {"extra_params": lambda(href):'class="internal"' if href.startswith("http://www.internal-link.com") else 'rel="nofollow" class="external"'},
+     {"extra_params": lambda href:'class="internal"' if href.startswith("http://www.internal-link.com") else 'rel="nofollow" class="external"'},
-     {"extra_params": lambda(href):'    rel="nofollow" class="external"  '},
+     {"extra_params": lambda href:'    rel="nofollow" class="external"  '},
-import thread
+try:
-from cStringIO import StringIO
+try:
-if str is unicode:
+if type('') is not type(b''):
-
+    unicode_type = unicode
-    """Re-raise an exception (with original traceback) from an exc_info tuple.
+    raise exc_info[1].with_traceback(exc_info[2])
-        # After 2to3: raise exc_info[0](exc_info[1]).with_traceback(exc_info[2])
+def exec_in(code, namespace):
-        if isinstance(impl, (unicode, bytes_type)):
+        if isinstance(impl, (unicode_type, bytes_type)):
-import urlparse
+from tornado import httputil
-        self._reason = httplib.responses[200]
+        self._reason = httputil.responses[200]
-                self._reason = httplib.responses[status_code]
+                self._reason = httputil.responses[status_code]
-                locales.sort(key=lambda (l, s): s, reverse=True)
+                locales.sort(key=lambda pair: pair[1], reverse=True)
-            if e.status_code not in httplib.responses and not e.reason:
+            if e.status_code not in httputil.responses and not e.reason:
-            self.reason or httplib.responses.get(self.status_code, 'Unknown'))
+            self.reason or httputil.responses.get(self.status_code, 'Unknown'))
-from tornado.util import b, bytes_type
+from tornado.util import b, bytes_type, unicode_type
-if str is unicode:
+if str is unicode_type:
-       
+
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-        print >>sys.stderr, _USAGE
+        print(_USAGE, file=sys.stderr)
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-            print response.headers
+            print(response.headers)
-            print response.body
+            print(response.body)
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-    ...
+    ...    print('%s: %s' % (k,v))
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-    >>> _merge_prefix(d, 5); print d
+    >>> _merge_prefix(d, 5); print(d)
-    >>> _merge_prefix(d, 7); print d
+    >>> _merge_prefix(d, 7); print(d)
-    >>> _merge_prefix(d, 3); print d
+    >>> _merge_prefix(d, 3); print(d)
-    >>> _merge_prefix(d, 100); print d
+    >>> _merge_prefix(d, 100); print(d)
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-        print >> file, "\nOptions:\n"
+        print("Usage: %s [OPTIONS]" % sys.argv[0], file=file)
-                print >> file, "\n%s options:\n" % os.path.normpath(filename)
+                print("\n%s options:\n" % os.path.normpath(filename), file=file)
-                print >> file, "  --%-30s %s" % (prefix, lines[0])
+                print("  --%-30s %s" % (prefix, lines[0]), file=file)
-        print >> file
+                    print("%-34s %s" % (' ', line), file=file)
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-        print >> self.file, "    " * indent + line + line_comment
+        print("    " * indent + line + line_comment, file=self.file)
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-        print >> sys.stderr, "No tests specified"
+        print("No tests specified", file=sys.stderr)
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-from __future__ import absolute_import, division, with_statement
+from __future__ import absolute_import, division, print_function, with_statement
-    except SystemExit, e:
+    except SystemExit as e:
-    except Exception, e:
+    except Exception as e:
-        except Exception, e:
+        except Exception as e:
-            except pycurl.error, e:
+            except pycurl.error as e:
-                except pycurl.error, e:
+                except pycurl.error as e:
-                except pycurl.error, e:
+                except pycurl.error as e:
-        except HTTPError, e:
+        except HTTPError as e:
-        except _BadRequestException, e:
+        except _BadRequestException as e:
-        except socket.gaierror, e:
+        except socket.gaierror as e:
-            except Exception, e:
+            except Exception as e:
-                except (OSError, IOError), e:
+                except (OSError, IOError) as e:
-        except (socket.error, IOError, OSError), e:
+        except (socket.error, IOError, OSError) as e:
-            except socket.error, e:
+            except socket.error as e:
-        except socket.error, e:
+        except socket.error as e:
-        except socket.error, e:
+        except socket.error as e:
-        except ssl.SSLError, err:
+        except ssl.SSLError as err:
-        except socket.error, err:
+        except socket.error as err:
-        except ssl.SSLError, e:
+        except ssl.SSLError as e:
-        except socket.error, e:
+        except socket.error as e:
-        except (IOError, OSError), e:
+        except (IOError, OSError) as e:
-        except Exception, e:
+        except Exception as e:
-        except Exception, e:
+        except Exception as e:
-            except ssl.SSLError, err:
+            except ssl.SSLError as err:
-            except socket.error, err:
+            except socket.error as err:
-        except OSError, err:
+        except OSError as err:
-            except socket.error, e:
+            except socket.error as e:
-            except socket.error, detail:
+            except socket.error as detail:
-        except OSError, e:
+        except OSError as e:
-        except OSError, e:
+        except OSError as e:
-        except CapError, e:
+        except CapError as e:
-            except RuntimeError, e:
+            except RuntimeError as e:
-            except SystemExit, e:
+            except SystemExit as e:
-                        except HTTPError, e:
+                        except HTTPError as e:
-        except socket.gaierror, e:
+        except socket.gaierror as e:
-        except TwoArgException, e:
+        except TwoArgException as e:
-        except ValueError, e:
+        except ValueError as e:
-    except SystemExit, e:
+    except SystemExit as e:
-            except Exception, e:
+            except Exception as e:
-        except Exception, e:
+        except Exception as e:
-from tornado.util import bytes_type, b
+from tornado.util import bytes_type, b, u
-        args["openid.mode"] = u"check_authentication"
+        args["openid.mode"] = u("check_authentication")
-               self.get_argument(name) == u"http://openid.net/srv/ax/1.0":
+               self.get_argument(name) == u("http://openid.net/srv/ax/1.0"):
-                return u""
+                return u("")
-            return self.get_argument(ax_name, u"")
+                return u("")
-            user["name"] = u" ".join(name_parts)
+            user["name"] = u(" ").join(name_parts)
-               values[-1] == u"http://specs.openid.net/extensions/oauth/1.0":
+               values[-1] == u("http://specs.openid.net/extensions/oauth/1.0"):
-_URL_RE = re.compile(ur"""\b((?:([\w-]+):(/{1,3})|www[.])(?:(?:(?:[^\s&()]|&amp;|&quot;)*(?:[^!"#$%&'()*+,.:;<=>?@\[\]^`{|}~\s]))|(?:\((?:[^\s&()]|&amp;|&quot;)*\)))+)""")
+# Use to_unicode instead of tornado.util.u - we don't want backslashes getting
-        return u'<a href="%s"%s>%s</a>' % (href, params, url)
+        return u('<a href="%s"%s>%s</a>') % (href, params, url)
-    u"""Loads translations from CSV files in a directory.
+    u("""Loads translations from CSV files in a directory.
-    """
+    """)
-        self.name = LOCALE_NAMES.get(code, {}).get("name", u"Unknown")
+        self.name = LOCALE_NAMES.get(code, {}).get("name", u("Unknown"))
-                (u'\u4e0a\u5348', u'\u4e0b\u5348')[local_date.hour >= 12],
+                (u('\u4e0a\u5348'), u('\u4e0b\u5348'))[local_date.hour >= 12],
-        comma = u' \u0648 ' if self.code.startswith("fa") else u", "
+        comma = u(' \u0648 ') if self.code.startswith("fa") else u(", ")
-    "zh_TW": {"name_en": u"Chinese (Traditional)", "name": u"\u4e2d\u6587(\u7e41\u9ad4)"},
+    "af_ZA": {"name_en": u("Afrikaans"), "name": u("Afrikaans")},
-from tornado.util import b
+from tornado.util import b, u
-                          u'username': u'foo'})
+                         {u('access_token'): {u('key'): u('hjkl'),
-from tornado.util import b
+from tornado.util import b, u
-     u'hello <a href="http://world.com/">http://world.com/</a>!'),
+     u('hello <a href="http://world.com/">http://world.com/</a>!')),
-     u'hello <a href="http://world.com/with?param=true&amp;stuff=yes">http://world.com/with?param=true&amp;stuff=yes</a>'),
+     u('hello <a href="http://world.com/with?param=true&amp;stuff=yes">http://world.com/with?param=true&amp;stuff=yes</a>')),
-     u'<a href="http://url.com/w">http://url.com/w</a>(aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'),
+     u('<a href="http://url.com/w">http://url.com/w</a>(aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')),
-     u'<a href="http://url.com/withmany">http://url.com/withmany</a>.......................................'),
+     u('<a href="http://url.com/withmany">http://url.com/withmany</a>.......................................')),
-     u'<a href="http://url.com/withmany">http://url.com/withmany</a>((((((((((((((((((((((((((((((((((a)'),
+     u('<a href="http://url.com/withmany">http://url.com/withmany</a>((((((((((((((((((((((((((((((((((a)')),
-     u'<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>'),
+     u('<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>')),
-     u'<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>'),
+     u('<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>')),
-     u'(Something like <a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>)'),
+     u('(Something like <a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>)')),
-     u'<a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>'),
+     u('<a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>')),
-     u'<a href="http://foo.com/blah_(blah)_(wikipedia)_blah">http://foo.com/blah_(blah)_(wikipedia)_blah</a>'),
+     u('<a href="http://foo.com/blah_(blah)_(wikipedia)_blah">http://foo.com/blah_(blah)_(wikipedia)_blah</a>')),
-     u'(Something like <a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>)'),
+     u('(Something like <a href="http://foo.com/blah_blah_(wikipedia)">http://foo.com/blah_blah_(wikipedia)</a>)')),
-     u'<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>.'),
+     u('<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>.')),
-     u'<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>.'),
+     u('<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>.')),
-     u'&lt;<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>&gt;'),
+     u('&lt;<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>&gt;')),
-     u'&lt;<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>&gt;'),
+     u('&lt;<a href="http://foo.com/blah_blah/">http://foo.com/blah_blah/</a>&gt;')),
-     u'<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>,'),
+     u('<a href="http://foo.com/blah_blah">http://foo.com/blah_blah</a>,')),
-     u'<a href="http://www.example.com/wpstyle/?p=364">http://www.example.com/wpstyle/?p=364</a>.'),
+     u('<a href="http://www.example.com/wpstyle/?p=364">http://www.example.com/wpstyle/?p=364</a>.')),
-     u'<a href="rdar://1234">rdar://1234</a>'),
+     u('<a href="rdar://1234">rdar://1234</a>')),
-     u'<a href="rdar:/1234">rdar:/1234</a>'),
+     u('<a href="rdar:/1234">rdar:/1234</a>')),
-     u'<a href="http://userid:password@example.com:8080">http://userid:password@example.com:8080</a>'),
+     u('<a href="http://userid:password@example.com:8080">http://userid:password@example.com:8080</a>')),
-     u'<a href="http://userid@example.com">http://userid@example.com</a>'),
+     u('<a href="http://userid@example.com">http://userid@example.com</a>')),
-     u'<a href="http://userid@example.com:8080">http://userid@example.com:8080</a>'),
+     u('<a href="http://userid@example.com:8080">http://userid@example.com:8080</a>')),
-     u'<a href="http://userid:password@example.com">http://userid:password@example.com</a>'),
+     u('<a href="http://userid:password@example.com">http://userid:password@example.com</a>')),
-     u'<a href="message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e">message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e</a>'),
+     u('<a href="message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e">message://%3c330e7f8409726r6a4ba78dkf1fd71420c1bf6ff@mail.gmail.com%3e</a>')),
-     u'<a href="http://\u27a1.ws/\u4a39">http://\u27a1.ws/\u4a39</a>'),
+    (u("http://\u27a1.ws/\u4a39"), {},
-     u'&lt;tag&gt;<a href="http://example.com">http://example.com</a>&lt;/tag&gt;'),
+     u('&lt;tag&gt;<a href="http://example.com">http://example.com</a>&lt;/tag&gt;')),
-     u'Just a <a href="http://www.example.com">www.example.com</a> link.'),
+     u('Just a <a href="http://www.example.com">www.example.com</a> link.')),
-     u'Just a www.example.com link.'),
+     u('Just a www.example.com link.')),
-     u'A <a href="http://reallylong.com/link/that/exceedsthelenglimit.html" title="http://reallylong.com/link/that/exceedsthelenglimit.html">http://reallylong.com/link...</a>'),
+     u('A <a href="http://reallylong.com/link/that/exceedsthelenglimit.html" title="http://reallylong.com/link/that/exceedsthelenglimit.html">http://reallylong.com/link...</a>')),
-     u'A <a href="http://reallylongdomainnamethatwillbetoolong.com/hi" title="http://reallylongdomainnamethatwillbetoolong.com/hi">http://reallylongdomainnametha...</a>!'),
+     u('A <a href="http://reallylongdomainnamethatwillbetoolong.com/hi" title="http://reallylongdomainnamethatwillbetoolong.com/hi">http://reallylongdomainnametha...</a>!')),
-     u'A file:///passwords.txt and <a href="http://web.com">http://web.com</a> link'),
+     u('A file:///passwords.txt and <a href="http://web.com">http://web.com</a> link')),
-     u'A <a href="file:///passwords.txt">file:///passwords.txt</a> and http://web.com link'),
+     u('A <a href="file:///passwords.txt">file:///passwords.txt</a> and http://web.com link')),
-     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>'),
+     u('<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>')),
-     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a> and <a href="http://www.internal-link.com/blogs" class="internal">www.internal-link.com/blogs</a> extra'),
+     u('<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a> and <a href="http://www.internal-link.com/blogs" class="internal">www.internal-link.com/blogs</a> extra')),
-     u'<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>'),
+     u('<a href="http://www.external-link.com" rel="nofollow" class="external">www.external-link.com</a>')),
-            (u"<foo>", u"&lt;foo&gt;"),
+            (u("<foo>"), u("&lt;foo&gt;")),
-            (u'\u00e9'.encode('latin1'), '%E9'),
+            (u('\u00e9').encode('utf8'), '%C3%A9'),
-            (u'\u00e9', '%C3%A9'),
+            (u('\u00e9'), '%C3%A9'),
-            ('%C3%A9', utf8(u'\u00e9'), None),
+            ('%C3%A9', u('\u00e9'), 'utf8'),
-        self.assertEqual(type(xhtml_escape(u"foo")), unicode)
+        self.assertEqual(type(xhtml_escape(u("foo"))), unicode)
-        self.assertEqual(json_decode(u'"foo"'), u"foo")
+        self.assertEqual(json_decode(b('"foo"')), u("foo"))
-        self.assertEqual(json_decode(utf8(u'"\u00e9"')), u"\u00e9")
+        self.assertEqual(json_decode(utf8(u('"\u00e9"'))), u("\u00e9"))
-        self.assertEqual(json_decode(json_encode(utf8(u"\u00e9"))), u"\u00e9")
+        self.assertEqual(json_decode(json_encode(u("\u00e9"))), u("\u00e9"))
-from tornado.util import b, bytes_type
+from tornado.util import b, u, bytes_type
-        unicode_body = u"\xe9"
+        unicode_body = u("\xe9")
-                              user_agent=u"foo")
+                              user_agent=u("foo"))
-from tornado.util import b, bytes_type
+from tornado.util import b, u, bytes_type
-                    u"\u00e1".encode("utf-8"),
+                    u("\u00e1").encode("utf-8"),
-                    u'Content-Disposition: form-data; name="files"; filename="\u00f3"'.encode("utf8"),
+                    u('Content-Disposition: form-data; name="files"; filename="\u00f3"').encode("utf8"),
-                    u"\u00fa".encode("utf-8"),
+                    u("\u00fa").encode("utf-8"),
-        self.assertEqual(u"\u00fa", data["filebody"])
+        self.assertEqual(u("\u00e9"), data["header"])
-        self.assertEqual(data, {u"foo": [u"\u00e9"]})
+        self.assertEqual(data, {u("foo"): [u("\u00e9")]})
-        self.assertEqual(data, {u"foo": [u"", u""]})
+        self.assertEqual(data, {u("foo"): [u(""), u("")]})
-from tornado.util import b
+from tornado.util import b, u
-        self.assertEqual(locale.translate("school"), u"\u00e9cole")
+        self.assertEqual(locale.translate("school"), u("\u00e9cole"))
-        self.assertEqual(locale.translate("school"), u"\u00e9cole")
+        self.assertEqual(locale.translate("school"), u("\u00e9cole"))
-        self.assertEqual(name, u'Espa\u00f1ol')
+        self.assertEqual(name, u('Espa\u00f1ol'))
-from tornado.util import b, bytes_type
+from tornado.util import b, u, bytes_type
-            logging.ERROR: u"\u0001",
+            logging.ERROR: u("\u0001"),
-        self.formatter._normal = u"\u0002"
+        self.formatter._normal = u("\u0002")
-        self.logger.error(u"\u00e9".encode("utf8"))
+        self.logger.error(u("\u00e9").encode("utf8"))
-            self.assertEqual(self.get_output(), utf8(u"\u00e9"))
+            self.assertEqual(self.get_output(), utf8(u("\u00e9")))
-            self.assertEqual(self.get_output(), utf8(repr(utf8(u"\u00e9"))))
+            self.assertEqual(self.get_output(), utf8(repr(utf8(u("\u00e9")))))
-        self.assertEqual(self.get_output(), utf8(u"\u00e9"))
+        self.logger.error(u("\u00e9"))
-from tornado.util import b, bytes_type, ObjectDict
+from tornado.util import b, u, bytes_type, ObjectDict
-        self.assertEqual(template.generate(), utf8(u"\u00e9"))
+        template = Template(utf8(u("\u00e9")))
-            template = Template(utf8(u'{{ "\u00e9" }}'))
+            template = Template(utf8(u('{{ "\u00e9" }}')))
-        self.assertEqual(template.generate(), utf8(u"\u00e9"))
+            template = Template(utf8(u('{{ u"\u00e9" }}')))
-        self.assertEqual(template.generate(upper=upper), utf8(u"FOO \u00c9"))
+        template = Template(utf8(u("{% apply upper %}foo \u00e9{% end %}")))
-        self.assertEqual(template.generate(upper=upper), utf8(u"FOO \u00c9"))
+        template = Template(utf8(u("{% apply upper %}foo \u00e9{% end %}")))
-        self.assertEqual(to_unicode(result).strip(), u"H\u00e9llo")
+        self.assertEqual(to_unicode(result).strip(), u("H\u00e9llo"))
-from tornado.util import b, bytes_type, ObjectDict
+from tornado.util import b, u, bytes_type, ObjectDict
-                self.set_cookie("unicode", u"qwer")
+                self.set_cookie("unicode", u("qwer"))
-                                path=u"/foo")
+                self.set_cookie("unicode_args", "blah", domain=u("foo.com"),
-                          u"args": {u"arg": [u"\u00e9"]}})
+                         {u("path"): u("/group/%C3%A9"),
-                                    u'query': [u'unicode', u'\u00e9'],
+            self.assertEqual(data, {u('path'): [u('unicode'), u('\u00e9')],
-                                u'query': [u'bytes', u'c3a9'],
+        self.assertEqual(data, {u('path'): [u('bytes'), u('c3a9')],
-        self.assertEqual(self.app.reverse_url('decode_arg', u'\u00e9'),
+        self.assertEqual(self.app.reverse_url('decode_arg', u('\u00e9')),
-                         {u"path": u"foo"})
+                         {u("path"): u("foo")})
-                         {u"path": None})
+                         {u("path"): None})
-                (u"/unicode/(?P<path>.*)", EchoHandler)]
+                (u("/unicode/(?P<path>.*)"), EchoHandler)]
-from tornado.util import b
+from tornado.util import b, u
-        self.assertEqual(response.body, u"foo bar\u00e9".encode("utf-8"))
+        self.assertEqual(response.body, u("foo bar\u00e9").encode("utf-8"))
-from tornado.util import raise_exc_info, Configurable
+from tornado.escape import utf8
-    epoll or queue.
+    epoll or kqueue.
-def enable_pretty_logging(options=None):
+def enable_pretty_logging(options=None, logger=None):
-    root_logger.setLevel(getattr(logging, options.logging.upper()))
+    if logger is None:
-        root_logger.addHandler(channel)
+        logger.addHandler(channel)
-        (options.log_to_stderr is None and not root_logger.handlers)):
+        (options.log_to_stderr is None and not logger.handlers)):
-        root_logger.addHandler(channel)
+        logger.addHandler(channel)
-from tornado.log import LogFormatter
+from tornado.log import LogFormatter, define_logging_options, enable_pretty_logging
-        exception from ``sys.exc_info()``.
+        If ``exc_info`` is true, set the ``error`` attribute to the current
-                self.error = sys.exc_info()[1]
+            if exc_info:
-        """Close this stream."""
+    def close(self, exc_info=False):
-            if any(sys.exc_info()):
+            if exc_info and any(sys.exc_info()):
-            self.close()
+            self.close(exc_info=True)
-                self.close()
+                self.close(exc_info=True)
-            self.close()
+            self.close(exc_info=True)
-                self.close()
+                self.close(exc_info=True)
-            self.close()
+            self.close(exc_info=True)
-                    self.close()
+                    self.close(exc_info=True)
-                self.close()
+                self.close(exc_info=True)
-                return self.close()
+                return self.close(exc_info=True)
-                return self.close()
+                return self.close(exc_info=True)
-                return self.close()
+                return self.close(exc_info=True)
-                self.close()
+                self.close(exc_info=True)
-from tornado.log import gen_log
+from tornado.log import gen_log, app_log
-        with stack_context.StackContext(self.cleanup):
+        with stack_context.ExceptionStackContext(self._handle_exception):
-                raise
+    def _handle_exception(self, typ, value, tb):
-from tornado.stack_context import StackContext
+from tornado.stack_context import ExceptionStackContext
-            self.stop()
+    def _handle_exception(self, typ, value, tb):
-        with StackContext(self._stack_context):
+        with ExceptionStackContext(self._handle_exception):
-            final_callback(response)
+            self.io_loop.add_callback(final_callback, response)
-from tornado.stack_context import ExceptionStackContext
+from tornado.stack_context import ExceptionStackContext, NullContext
-        return self.reactor.callLater(delay, wrap(callback))
+        return self.reactor.callLater(delay, self._run_callback, wrap(callback))
-                                                      *args, **kwargs))
+        self.reactor.callFromThread(self._run_callback,
-from tornado.stack_context import ExceptionStackContext, StackContext, wrap
+from tornado.stack_context import ExceptionStackContext, StackContext, wrap, NullContext
-                functools.partial(callback, future)))
+            lambda future: self.add_callback(callback, future))
-            functools.partial(subproc._set_returncode, status))
+            subproc._set_returncode, status)
-    def add_callback(self, callback):
+    def add_callback(self, callback, *args, **kwargs):
-    def add_callback_from_signal(self, callback):
+    def add_callback_from_signal(self, callback, *args, **kwargs):
-    def add_callback(self, callback):
+    def add_callback(self, callback, *args, **kwargs):
-            self._callbacks.append(stack_context.wrap(callback))
+            self._callbacks.append(functools.partial(
-    def add_callback_from_signal(self, callback):
+    def add_callback_from_signal(self, callback, *args, **kwargs):
-                self.add_callback(callback)
+                self.add_callback(callback, *args, **kwargs)
-                self._callbacks.append(stack_context.wrap(callback))
+                self._callbacks.append(functools.partial(
-        self.reactor.callFromThread(wrap(callback))
+    def add_callback(self, callback, *args, **kwargs):
-        self.add_callback(callback)
+    def add_callback_from_signal(self, callback, *args, **kwargs):
-from tornado.stack_context import ExceptionStackContext
+from tornado.stack_context import ExceptionStackContext, StackContext, wrap
-                self.stream.close()
+            if self.final_callback:
-            del self._fds[fd]
+            if fd in self._fds:
-            else:
+            else:
-        except (OSError, IOError):
+        except Exception:
-                getattr(self, self.request.method.lower())(*args, **kwargs)
+                getattr(self, self.request.method.lower())(
-                  expected_status=200, allowed_warnings=None):
+                  expected_status=200, allowed_warnings=None,
-        allowed_warnings += (rs.FRESHNESS_HEURISTIC,)
+        allowed_warnings = (allowed_warnings or []) + self.get_allowed_warnings()
-                errors.append(msg)
+                if not isinstance(msg, tuple(allowed_errors)):
-                if not isinstance(msg, allowed_warnings):
+                if not isinstance(msg, tuple(allowed_warnings)):
-    version the client is using.
+    `HTTPServer` is a very basic connection handler.  It parses the request
-        """Creates an `HTTPRequest`.
+        r"""Creates an `HTTPRequest`.
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value, ErrorHandler
-    load balancer.
+    If ``xheaders`` is ``True``, we support the
-                 xheaders=False, ssl_options=None, **kwargs):
+                 xheaders=False, ssl_options=None, protocol=None, **kwargs):
-                       self.no_keep_alive, self.xheaders)
+                       self.no_keep_alive, self.xheaders, self.protocol)
-                 xheaders=False):
+                 xheaders=False, protocol=None):
-                headers=headers, remote_ip=remote_ip)
+                headers=headers, remote_ip=remote_ip, protocol=self.protocol)
-            # content-length headers
+        if self.request.method == "HEAD" or self.code == 304:
-        if 100 <= self.code < 200 or self.code in (204, 304):
+        if 100 <= self.code < 200 or self.code == 204:
-version = "2.4.post1"
+version = "2.4.post2"
-version_info = (2, 4, 0, 1)
+version = "2.4.post2"
-version = "2.4"
+version = "2.4.1"
-version_info = (2, 4, 0, 0)
+version = "2.4.1"
-            self._run_callback(callback, self._consume(self._read_buffer_size))
+            if self._streaming_callback is not None:
-            http_client = httpclient.AsyncHTTPClient()
+            http_client = self.get_auth_http_client()
-            http_client = httpclient.AsyncHTTPClient()
+            http_client = self.get_auth_http_client()
-            http_client = httpclient.AsyncHTTPClient()
+            http_client = self.get_auth_http_client()
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-            url = "http://api.twitter.com/1" + path + ".json"
+            url = self._TWITTER_BASE_URL + path + ".json"
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-            "/users/show/" + access_token["screen_name"],
+            "/users/show/" + escape.native_str(access_token[b("screen_name")]),
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-            http = httpclient.AsyncHTTPClient()
+            http = self.get_auth_http_client()
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin
+from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin
-            http_client=self.http_client)
+            http_client=self.http_client,
-            self.http_client.fetch(self.get_url("/"), self.stop,
+            self.http_client.fetch(self.get_url("/").replace('https:', 'http:'),
-        return SimpleAsyncHTTPClient(io_loop=self.io_loop, force_instance=True)
+        return SimpleAsyncHTTPClient(io_loop=self.io_loop, force_instance=True,
-                            self.fileno(), e)
+    def test_inline_read_error(self):
-from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient, main
+from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient, main, _RequestProxy
-    def initialize(self, io_loop=None, max_clients=10):
+    def initialize(self, io_loop=None, max_clients=10, defaults=None):
-from tornado.util import import_object, Configurable
+from tornado.util import Configurable
-                 max_redirects=5, user_agent=None, use_gzip=True,
+                 connect_timeout=None, request_timeout=None,
-                 validate_cert=True, ca_certs=None,
+                 proxy_password=None, allow_nonstandard_methods=None,
-from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient, main
+from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient, main, _RequestProxy
-                   resolver=None):
+                   resolver=None, defaults=None):
-            new_request = copy.copy(self.request)
+            assert isinstance(self.request, _RequestProxy)
-            new_request.max_redirects -= 1
+            new_request.max_redirects = self.request.max_redirects - 1
-                                        1024 * 1024)
+        conn = RawRequestHTTPConnection(
-    replace tornado.httpclient.AsyncHTTPClient.
+    specification, but it does enough to work with major web service APIs.
-    main()
+class HostMatchingTest(WebTestCase):
-        used.
+        Host patterns are processed sequentially in the order they were
-                self.handlers.append((re.compile(host_pattern), handlers))
+        handlers = []
-                return handlers
+                matches.extend(handlers)
-        if "X-Real-Ip" not in request.headers:
+        if not matches and "X-Real-Ip" not in request.headers:
-        return None
+                    matches.extend(handlers)
-from tornado import httputil
+from tornado import httputil, stack_context
-from tornado.util import import_object, bytes_type, Configurable
+from tornado.util import import_object, Configurable
-           `~HTTPResponse.headers` will be empty in the final response.
+           be run with each header line as it is received (including the
-        self.prepare_curl_callback = prepare_curl_callback
+        self.streaming_callback = stack_context.wrap(streaming_callback)
-    def test_static_304(self):
+    def test_static_304_if_modified_since(self):
-            self.set_header("Etag", '"%s"' % hasher.hexdigest())
+                    self.deactivate_stack_context = None
-            http_client = httpclient.AsyncHTTPClient()
+            http_client = self.get_auth_http_client()
-            http_client = httpclient.AsyncHTTPClient()
+            http_client = self.get_auth_http_client()
-            http_client = httpclient.AsyncHTTPClient()
+            http_client = self.get_auth_http_client()
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-            url = "http://api.twitter.com/1" + path + ".json"
+            url = self._TWITTER_BASE_URL + path + ".json"
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-            "/users/show/" + access_token["screen_name"],
+            "/users/show/" + escape.native_str(access_token[b("screen_name")]),
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-            http = httpclient.AsyncHTTPClient()
+            http = self.get_auth_http_client()
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-        http = httpclient.AsyncHTTPClient()
+        http = self.get_auth_http_client()
-from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin
+from tornado.auth import OpenIdMixin, OAuthMixin, OAuth2Mixin, TwitterMixin
-            http_client=self.http_client)
+            http_client=self.http_client,
-            self._run_callback(callback, self._consume(self._read_buffer_size))
+            if self._streaming_callback is not None:
-        added in a single add_handlers call.
+        used.
-            self.handlers.append((re.compile(host_pattern), handlers))
+
-            if self.code == 303:
+            # Client SHOULD make a GET request after a 303.
-class SeeOther303PostHandler(RequestHandler):
+class SeeOtherPostHandler(RequestHandler):
-        self.set_status(303)
+        redirect_code = int(self.request.body)
-class SeeOther303GetHandler(RequestHandler):
+class SeeOtherGetHandler(RequestHandler):
-            url("/303_get", SeeOther303GetHandler),
+            url("/see_other_post", SeeOtherPostHandler),
-        self.assertEqual("POST", response.request.method)
+    def test_see_other_redirect(self):
-        self.http_client.close()
+        if (not IOLoop.initialized() or
-            raise ValueError("Periodic callback cannot have a period of 0ms")
+        if callback_time <= 0:
-        uri_arguments = parse_qs_bytes(native_str(body))
+        uri_arguments = parse_qs_bytes(native_str(body), keep_blank_values=True)
-            values = [v for v in values if v]
+    def post(self):
-            lambda sig, frame: io_loop.add_callback(cls._cleanup))
+            lambda sig, frame: io_loop.add_callback_from_signal(cls._cleanup))
-        self.handler(self.fd, tornado.ioloop.IOLoop.READ)
+        if not self.lost:
-        self.handler(self.fd, tornado.ioloop.IOLoop.WRITE)
+        if not self.lost:
-        self.handler(self.fd, tornado.ioloop.IOLoop.ERROR)
+        if not self.lost:
-        self.skip_if_twisted()
+        # Twisted's SIGCHLD handler and Subprocess's conflict with each other.
-        self.skip_if_twisted()
+        skip_if_twisted()
-"""A Twisted reactor built on the Tornado IOLoop.
+"""Bridges between the Twisted reactor and Tornado IOLoop.
-the beginning of the application::
+Twisted in a Tornado application.  It can be used in two modes,
-Twisted and Tornado code in the same process.
+instead of `reactor.run()`.
-This module has been tested with Twisted versions 11.0.0, 11.1.0, and 12.0.0
+Tornado on Twisted
-    IReactorFDSet, IDelayedCall, IReactorTime
+    IReactorFDSet, IDelayedCall, IReactorTime, IReadDescriptor, IWriteDescriptor
-from tornado.stack_context import NullContext
+from tornado.stack_context import NullContext, wrap
-    from tornado.platform.twisted import TornadoReactor
+    from tornado.platform.twisted import TornadoReactor, TwistedIOLoop
-        raise Exception("twisted signal handlers already installed")
+        if not issubclass(IOLoop.configured_class(), TwistedIOLoop):
-            impl = base.__impl_class
+            impl = cls.configured_class()
-
+    @classmethod
-        self._impl.close()
+        raise NotImplementedError()
-        self._impl.register(fd, events | self.ERROR)
+        raise NotImplementedError()
-        self._impl.modify(fd, events | self.ERROR)
+        raise NotImplementedError()
-            gen_log.debug("Error deleting fd from IOLoop", exc_info=True)
+        raise NotImplementedError()
-                          action if action is not None else signal.SIG_DFL)
+        raise NotImplementedError()
-from tornado.ioloop import IOLoop
+from tornado.ioloop import PollIOLoop
-    class EPollIOLoop(IOLoop):
+    class EPollIOLoop(PollIOLoop):
-    class EPollIOLoop(IOLoop):
+    class EPollIOLoop(PollIOLoop):
-from tornado.ioloop import IOLoop
+from tornado.ioloop import IOLoop, PollIOLoop
-class KQueueIOLoop(IOLoop):
+class KQueueIOLoop(PollIOLoop):
-from tornado.ioloop import IOLoop
+from tornado.ioloop import IOLoop, PollIOLoop
-class SelectIOLoop(IOLoop):
+class SelectIOLoop(PollIOLoop):
-        elif hasattr(select, "kqueue"):
+        if hasattr(select, "epoll") or sys.platform.startswith('linux'):
-                return SelectIOLoop
+        from tornado.platform.select import SelectIOLoop
-        super(EPollIOLoop, self).initialize(impl=select.epoll(), **kwargs)
+#!/usr/bin/env python
-        self.wait(timeout=0.1)
+        self.wait(timeout=0.15)
-                while True:
+                while not self.closed():
-            while True:
+            while not self.closed():
-                self._check_closed()
+import weakref
-
+    def test_empty_request(self):
-        writer.write_line("_append(%s(%s()))" % (
+        writer.write_line("_append(_utf8(%s(%s())))" % (
-        self.stream.read_until(b("\r\n\r\n"), self._header_callback)
+        try:
-            raise IOError("Stream is closed")
+            raise StreamClosedError("Stream is closed")
-from tornado.web import Application, RequestHandler
+from tornado.web import Application, RequestHandler, asynchronous
-            time.time() + msecs / 1000.0, self._handle_timeout)
+            self.io_loop.time() + msecs / 1000.0, self._handle_timeout)
-    def initialize(self, impl):
+    def initialize(self, impl, time_func=None):
-                now = time.time()
+                now = self.time()
-        relative to the current time.
+        ``deadline`` may be a number denoting a time relative to
-        timeout = _Timeout(deadline, stack_context.wrap(callback))
+        timeout = _Timeout(deadline, stack_context.wrap(callback), self)
-    def __init__(self, deadline, callback):
+    def __init__(self, deadline, callback, io_loop):
-            self.deadline = time.time() + _Timeout.timedelta_to_seconds(deadline)
+            self.deadline = io_loop.time() + _Timeout.timedelta_to_seconds(deadline)
-        self._next_timeout = time.time()
+        self._next_timeout = self.io_loop.time()
-            current_time = time.time()
+            current_time = self.io_loop.time()
-        return time.time()
+        return self._io_loop.time()
-        self.start_time = time.time()
+        self.start_time = io_loop.time()
-                                request_time=time.time() - self.start_time,
+                                request_time=self.io_loop.time() - self.start_time,
-                                request_time=time.time() - self.start_time,
+                                request_time=self.io_loop.time() - self.start_time,
-        self.io_loop.add_timeout(time.time(), schedule_callback)
+        self.io_loop.add_timeout(self.io_loop.time(), schedule_callback)
-            self.io_loop.add_timeout(time.time() + 0.01, self.stop)
+            self.io_loop.add_timeout(self.io_loop.time() + 0.01, self.stop)
-from tornado.options import define
+from tornado.options import define, options, add_parse_callback
-           callback=IOLoop.configure)
+    define('ioloop', type=str, default=None)
-        self.io_loop.add_timeout(time.time() + 0.01, self.stop)
+        self.io_loop.add_timeout(self.io_loop.time() + 0.01, self.stop)
-        self.io_loop.add_timeout(time.time() + 0.03, self.stop)
+        self.io_loop.add_timeout(self.io_loop.time() + 0.03, self.stop)
-                self.__timeout = self.io_loop.add_timeout(time.time() + timeout, timeout_func)
+                self.__timeout = self.io_loop.add_timeout(self.io_loop.time() + timeout, timeout_func)
-                time.time() + 5, self._abort)
+                self.stream.io_loop.time() + 5, self._abort)
-        return IOLoop
+        if hasattr(select, "epoll"):
-        self._impl = impl or _poll()
+    def initialize(self, impl):
-        epoll.epoll_ctl(self._epoll_fd, self._EPOLL_CTL_ADD, fd, events)
+        self.epoll.epoll_ctl(self._epoll_fd, self._EPOLL_CTL_ADD, fd, events)
-        epoll.epoll_ctl(self._epoll_fd, self._EPOLL_CTL_MOD, fd, events)
+        self.epoll.epoll_ctl(self._epoll_fd, self._EPOLL_CTL_MOD, fd, events)
-        epoll.epoll_ctl(self._epoll_fd, self._EPOLL_CTL_DEL, fd, 0)
+        self.epoll.epoll_ctl(self._epoll_fd, self._EPOLL_CTL_DEL, fd, 0)
-        return epoll.epoll_wait(self._epoll_fd, int(timeout * 1000))
+        return self.epoll.epoll_wait(self._epoll_fd, int(timeout * 1000))
-        _poll = _Select
+
-        tornado.autoreload.wait()
+        raise
-from tornado.util import import_object, bytes_type
+from tornado.util import import_object, bytes_type, Configurable
-class AsyncHTTPClient(object):
+class AsyncHTTPClient(Configurable):
-    _impl_kwargs = None
+    @classmethod
-        return cls._async_client_dict
+        attr_name = '_async_client_dict_' + cls.__name__
-            return instance
+        if io_loop in cls._async_clients() and not force_instance:
-    def configure(impl, **kwargs):
+    @classmethod
-        AsyncHTTPClient._impl_kwargs = saved[1]
+        super(AsyncHTTPClient, cls).configure(impl, **kwargs)
-class IOLoop(object):
+class IOLoop(Configurable):
-    def __init__(self, impl=None):
+    def initialize(self, impl=None):
-from tornado.util import raise_exc_info
+from tornado.util import raise_exc_info, Configurable
-                **kwargs):
+    def __new__(cls, io_loop=None, force_instance=False, **kwargs):
-class OptionParser(dict):
+class OptionParser(object):
-        super(OptionParser, self).__init__()
+        # we have to use self.__dict__ because we override setattr.
-            return self[name].value()
+        if isinstance(self._options.get(name), _Option):
-            return self[name].set(value)
+        if isinstance(self._options.get(name), _Option):
-        if name in self:
+        if name in self._options:
-                        self[name].file_name)
+                        self._options[name].file_name)
-                             callback=callback)
+        self._options[name] = _Option(name, file_name=file_name,
-            if not name in self:
+            if not name in self._options:
-            option = self[name]
+            option = self._options[name]
-                self[name].set(config[name])
+            if name in self._options:
-        for option in self.itervalues():
+        for option in self._options.itervalues():
-Each module defines its own options, e.g.::
+Each module defines its own options which are added to the global
-or parse a config file with::
+when the modules are loaded.  However, all modules that define options
-    tornado.options.parse_config_file("/etc/server.conf")
+    # or
-"""Global options dictionary.
+"""Global options object.
-Supports both attribute-style and dict-style access.
+All defined options are available as attributes on this object.
-    and file-based options::
+    """Defines an option in the global namespace.
-    by later flags.
+    See `OptionParser.define`.
-    Note that args[0] is ignored since it is the program name in sys.argv.
+    """Parses global options from the command line.
-    from multiple sources.
+    See `OptionParser.parse_command_line`.
-    """Parses and loads the Python config file at the given path.
+    """Parses global options from a config file.
-    from multiple sources.
+    See `OptionParser.parse_config_file`.
-    """Prints all the command line options to stdout."""
+    """Prints all the command line options to stderr (or another file).
-    """Adds a parse callback, to be invoked when option parsing is done."""
+    """Adds a parse callback, to be invoked when option parsing is done.
-class _Options(dict):
+class OptionParser(dict):
-        super(_Options, self).__init__()
+        super(OptionParser, self).__init__()
-                print_help()
+                self.print_help()
-options = _Options()
+options = OptionParser()
-def print_help(file=sys.stdout):
+def print_help(file=None):
-from tornado.options import _Options
+from tornado.options import OptionParser, Error
-        options = _Options()
+        options = OptionParser()
-        options = _Options()
+        options = OptionParser()
-        options = _Options()
+        options = OptionParser()
-               multiple=False, group=None):
+               multiple=False, group=None, callback=None):
-                             multiple=multiple, group_name=group_name)
+                             multiple=multiple, group_name=group_name,
-        """Prints all the command line options to stdout."""
+    def print_help(self, file=None):
-                 multiple=False, file_name=None, group_name=None):
+    def __init__(self, name, default=None, type=basestring, help=None,
-           multiple=False, group=None):
+           multiple=False, group=None, callback=None):
-                          metavar=metavar, multiple=multiple, group=group)
+                          metavar=metavar, multiple=multiple, group=group,
-define("help", type=bool, help="show this help information")
+import sys
-        self.assertEqual(self.options.port, 443)
+        options = _Options()
-        self.options.add_parse_callback(callback)
+        options.add_parse_callback(callback)
-        self.options.parse_command_line(["main.py"], final=False)
+        options.parse_command_line(["main.py"], final=False)
-        self.options.parse_command_line(["main.py"])
+        options.parse_command_line(["main.py"])
-        self.options.parse_command_line(["main.py"])
+        options.parse_command_line(["main.py"])
-from tornado.log import LogFormatter
+from tornado.log import define_logging_options
-    def parse_command_line(self, args=None):
+    def parse_command_line(self, args=None, final=True):
-            enable_pretty_logging()
+        if final:
-    def parse_config_file(self, path):
+    def parse_config_file(self, path, final=True):
-def parse_command_line(args=None):
+def parse_command_line(args=None, final=True):
-    return options.parse_command_line(args)
+    return options.parse_command_line(args, final=final)
-    return options.parse_config_file(path)
+    If ``final`` is ``False``, parse callbacks will not be run.
-
+def add_parse_callback(callback):
-       help="number of log files to keep")
+define_logging_options(options)
-        define("logging", default="none")
+
-        self.__port = None
+        sock, port = bind_unused_port()
-        self.resolver = Resolver(self.io_loop, ThreadPoolExecutor(2))
+        self.executor = ThreadPoolExecutor(2)
-                             if active_cell[0]])
+        if _state.contexts:
-                            if active_cell[0]]
+            new_contexts = []
-from tornado.stack_context import StackContext, NullContext
+from tornado.stack_context import StackContext
-                    self.io_loop.start()
+                self.io_loop.start()
-        if contexts is _state.contexts or not contexts:
+        if contexts is _state.contexts:
-        return _StackContextWrapper(fn)
+    return _StackContextWrapper(wrapped, fn, _state.contexts)
-from tornado.stack_context import StackContext, wrap
+from tornado.stack_context import StackContext, wrap, NullContext
-        from that IOLoop's thread.  add_callback() may be used to transfer
+        It is safe to call this method from any thread at any time,
-        subproc.io_loop.add_callback(
+        subproc.io_loop.add_callback_from_signal(
-    return result == 0
+if hasattr(hmac, 'compare_digest'):  # python 3.3
-    def __init__(self, request, code, reason=None, headers=None, buffer=None,
+    def __init__(self, request, code, headers=None, buffer=None,
-                 time_info=None):
+                 time_info=None, reason=None):
-        self.reason = reason
+        self.reason = reason or httplib.responses.get(code, "Unknown")
-        self._reason = None
+        self._reason = httplib.responses[200]
-        self._reason = escape.native_str(reason)
+        if reason is not None:
-                    "message": self._reason or httplib.responses[status_code],
+                    "message": self._reason,
-            self.reason or httplib.responses[self.status_code])
+            self.reason or httplib.responses.get(self.status_code, 'Unknown'))
-            reason = httplib.responses[handler._status_code]
+
-        self.set_status(status_code)
+
-                    "message": httplib.responses[status_code],
+                    "message": self._reason or httplib.responses[status_code],
-            if e.status_code not in httplib.responses:
+            if e.status_code not in httplib.responses and not e.reason:
-    def __init__(self, status_code, log_message=None, *args):
+    """An exception that will turn into an HTTP error response.
-            self.status_code, httplib.responses[self.status_code])
+            self.status_code,
-
+
-        assert reason is not None or status_code in httplib.responses
+        if reason is None and status_code not in httplib.responses:
-        self._reason = reason
+        self._reason = escape.native_str(reason)
-            pass
+            self.async_callback(self.handler.on_pong)(data)
-        if hasattr(signal, 'set_wakeup_fd'):  # requires python 2.6+, unix
+        if hasattr(signal, 'set_wakeup_fd') and os.name == 'posix':
-        """Returns a file descriptor for this waker.
+        """Returns the read file descriptor for this waker.
-        self.returncode = ret
+    def _set_returncode(self, status):
-            callback(ret)
+            callback(self.returncode)
-        self.assertEqual(os.WTERMSIG(ret), signal.SIGTERM)
+        self.assertEqual(ret, -signal.SIGTERM)
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipIfNonUnix
-from tornado.test.util import unittest
+from tornado.test.util import unittest, skipIfNonUnix
-                              "non-unix platform")(ProcessTest)
+ProcessTest = skipIfNonUnix(ProcessTest)
-        io_loop = kwargs.pop('io_loop', None)
+        self.io_loop = kwargs.pop('io_loop', None)
-            self.stdin = PipeIOStream(in_w, io_loop=io_loop)
+            self.stdin = PipeIOStream(in_w, io_loop=self.io_loop)
-            self.stdout = PipeIOStream(out_r, io_loop=io_loop)
+            self.stdout = PipeIOStream(out_r, io_loop=self.io_loop)
-            self.stdout = PipeIOStream(err_r, io_loop=io_loop)
+            self.stdout = PipeIOStream(err_r, io_loop=self.io_loop)
-        except socket.error, e:
+        except (socket.error, IOError, OSError), e:
-from tornado.process import fork_processes, task_id
+from tornado.process import fork_processes, task_id, Subprocess
-from tornado.testing import bind_unused_port, ExpectLog
+from tornado.testing import bind_unused_port, ExpectLog, AsyncTestCase
-from tornado.iostream import IOStream, SSLIOStream
+from tornado.iostream import IOStream, SSLIOStream, PipeIOStream
-"""A utility class to write to and read from a non-blocking socket."""
+"""Utility classes to write to and read from non-blocking files and sockets.
-    r"""A utility class to write to and read from a non-blocking socket.
+class BaseIOStream(object):
-
+    Subclasses must implement `fileno`, `close_fd`, `write_to_fd`,
-    def __init__(self, socket, io_loop=None, max_buffer_size=104857600,
+    def __init__(self, io_loop=None, max_buffer_size=104857600,
-        self.socket.setblocking(False)
+        self._closed = False
-        """Connects the socket to a remote address without blocking.
+    def fileno(self):
-        connection is completed.
+    def close_fd(self):
-        but is non-portable.
+        ``close_fd`` is called by `BaseIOStream` and should not be called
-        self._add_io_state(self.io_loop.WRITE)
+        raise NotImplementedError()
-        if self.socket is not None:
+        if not self.closed():
-                self.io_loop.remove_handler(self.socket.fileno())
+                self.io_loop.remove_handler(self.fileno())
-            self.socket = None
+            self.close_fd()
-        if (self.socket is None and self._close_callback and
+        if (self.closed() and self._close_callback and
-        return self.socket is None
+        return self._closed
-        if not self.socket:
+        if self.closed():
-            if not self.socket:
+            if self.closed():
-            if not self.socket:
+            if self.closed():
-                self.error = socket.error(errno, os.strerror(errno))
+                self.error = self.get_fd_error()
-                self.io_loop.update_handler(self.socket.fileno(), self._state)
+                self.io_loop.update_handler(self.fileno(), self._state)
-            chunk = self._read_from_socket()
+            chunk = self.read_from_fd()
-                            self.socket.fileno(), e)
+                            self.fileno(), e)
-                num_bytes = self.socket.send(self._write_buffer[0])
+                num_bytes = self.write_to_fd(self._write_buffer[0])
-                                    self.socket.fileno(), e)
+                                    self.fileno(), e)
-        if not self.socket:
+        if self.closed():
-            if self.socket is None:
+            if self.closed():
-        if self.socket is None:
+        if self.closed():
-                    self.socket.fileno(), self._handle_events, self._state)
+                    self.fileno(), self._handle_events, self._state)
-            self.io_loop.update_handler(self.socket.fileno(), self._state)
+            self.io_loop.update_handler(self.fileno(), self._state)
-    def _read_from_socket(self):
+    def read_from_fd(self):
-        self.db = tornado.database.Connection(
+        self.db = torndb.Connection(
-    
+
-    
+
-        methods like ``sys.exc_info()`` or ``traceback.format_exc``.
+        If this error was caused by an uncaught exception (including
-from tornado.testing import AsyncHTTPTestCase, get_unused_port
+from tornado.testing import AsyncHTTPTestCase, bind_unused_port
-        (sock,) = netutil.bind_sockets(port, address="127.0.0.1")
+        sock, port = bind_unused_port()
-from tornado.testing import AsyncTestCase, get_unused_port
+from tornado.testing import AsyncTestCase, bind_unused_port
-                              family=socket.AF_INET)
+        sock, port = bind_unused_port()
-from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, get_unused_port, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, bind_unused_port, ExpectLog
-                                          family=socket.AF_INET)
+        listener, port = bind_unused_port()
-        port = get_unused_port()
+        server_socket, port = bind_unused_port()
-from tornado.testing import get_unused_port, ExpectLog
+from tornado.testing import bind_unused_port, ExpectLog
-            port = get_unused_port()
+            sock, port = bind_unused_port()
-                    sock.close()
+                sock.close()
-                    server.add_sockets(sockets)
+                    server.add_sockets([sock])
-                        sock.close()
+                    sock.close()
-from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, get_unused_port, ExpectLog
+from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, bind_unused_port, ExpectLog
-        port = get_unused_port()
+        server_socket, port = bind_unused_port()
-from tornado.testing import get_unused_port
+from tornado.testing import bind_unused_port
-        self.reactor.listenTCP(self.twisted_port, site, interface='127.0.0.1')
+        port = self.reactor.listenTCP(0, site, interface='127.0.0.1')
-        app.listen(self.tornado_port, address='127.0.0.1', io_loop=self.io_loop)
+        server = HTTPServer(app, io_loop=self.io_loop)
-    """Returns a (hopefully) unused port number."""
+    """Returns a (hopefully) unused port number.
-        self.http_server.listen(self.get_http_port(), address="127.0.0.1")
+        sock, port = bind_unused_port()
-            self.__port = get_unused_port()
+wsgi_safe = []
-class SimpleHandlerTestCase(AsyncHTTPTestCase):
+class WebTestCase(AsyncHTTPTestCase):
-                           log_function=lambda x: None)
+    def get_handlers(self):
-    def get_app(self):
+class CookieTest(WebTestCase):
-                ("/set", SetCookieHandler),
+        return [("/set", SetCookieHandler),
-                ])
+                ]
-                             dict(login_url='http://example.com/login'))])
+class AuthRedirectTest(WebTestCase):
-        return Application([('/', ConnectionCloseHandler, dict(test=self))])
+class ConnectionCloseTest(WebTestCase):
-                ("/group/(.*)", EchoHandler),
+class RequestEncodingTest(WebTestCase):
-                ])
+                ]
-class WSGISafeWebTest(AsyncHTTPTestCase):
+class WSGISafeWebTest(WebTestCase):
-
+wsgi_safe.append(WSGISafeWebTest)
-        return Application(urls)
+class NonWSGIWebTests(WebTestCase):
-    def get_app(self):
+class ErrorResponseTest(WebTestCase):
-                url("/default", DefaultHandler),
+        return [url("/default", DefaultHandler),
-                ])
+                ]
-    def get_app(self):
+class StaticFileTest(WebTestCase):
-                           static_path=os.path.join(os.path.dirname(__file__), 'static'))
+        return [('/static_url/(.*)', StaticUrlHandler),
-    def get_app(self):
+class CustomStaticFileTest(WebTestCase):
-                           static_handler_class=MyStaticFileHandler)
+        self.static_handler_class = MyStaticFileHandler
-        with ExpectLog(gen_log, "Could not open static file"):
+        with ExpectLog(gen_log, "Could not open static file", required=False):
-    def get_app(self):
+class NamedURLSpecGroupsTest(WebTestCase):
-                            (u"/unicode/(?P<path>.*)", EchoHandler)])
+        return [("/str/(?P<path>.*)", EchoHandler),
-
+wsgi_safe.append(ClearHeaderTest)
-        return WSGIContainer(validator(self.app))
+def wrap_web_tests():
-            headers.append(("Content-Type", "text/html; charset=UTF-8"))
+        if status_code != 304:
-                    self.arguments[name] = values
+            self.arguments = parse_qs_bytes(native_str(self.query),
-# in the future)
+# Logger objects for internal tornado use
-    def __init__(self, color=None, *args, **kwargs):
+    """Log formatter used in Tornado.
-        if color:
+        self._color = color and _stderr_supports_color()
-        self.logger = logger  # may be either a Logger or a Handler
+        self.logger = logger
-from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, LogTrapTestCase
+from tornado.log import app_log
-class GenWebTest(AsyncHTTPTestCase, LogTrapTestCase):
+class GenWebTest(AsyncHTTPTestCase):
-        response = self.fetch('/exception')
+        with ExpectLog(app_log, "Uncaught exception GET /exception"):
-from tornado.ioloop import IOLoop
+from tornado.log import gen_log
-from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, ExpectLog
-class BaseSSLTest(AsyncHTTPSTestCase, LogTrapTestCase):
+class BaseSSLTest(AsyncHTTPSTestCase):
-        response = self.wait()
+        with ExpectLog(gen_log, '(SSL Error|uncaught exception)'):
-from tornado.testing import LogTrapTestCase
+from tornado.log import gen_log
-class MultipartFormDataTest(LogTrapTestCase):
+class MultipartFormDataTest(unittest.TestCase):
-            logging.info("trying filename %r", filename)
+            logging.debug("trying filename %r", filename)
-        parse_multipart_form_data(b("1234"), data, args, files)
+        with ExpectLog(gen_log, "multipart/form-data missing headers"):
-        parse_multipart_form_data(b("1234"), data, args, files)
+        with ExpectLog(gen_log, "Invalid multipart/form-data"):
-        parse_multipart_form_data(b("1234"), data, args, files)
+        with ExpectLog(gen_log, "Invalid multipart/form-data"):
-        parse_multipart_form_data(b("1234"), data, args, files)
+        with ExpectLog(gen_log, "multipart/form-data value missing name"):
-from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, LogTrapTestCase, get_unused_port
+from tornado.log import gen_log
-            logging.info((connected, written))
+            logging.debug((connected, written))
-        self.wait()
+        # log messages vary by platform and ioloop implementation
-        self.assertTrue(isinstance(stream.error, socket.gaierror), stream.error)
+        with ExpectLog(gen_log, "Connect error"):
-                          LogTrapTestCase):
+class TestIOStreamWebHTTP(TestIOStreamWebMixin, AsyncHTTPTestCase):
-                           LogTrapTestCase):
+class TestIOStreamWebHTTPS(TestIOStreamWebMixin, AsyncHTTPSTestCase):
-class TestIOStream(TestIOStreamMixin, AsyncTestCase, LogTrapTestCase):
+class TestIOStream(TestIOStreamMixin, AsyncTestCase):
-class TestIOStreamSSL(TestIOStreamMixin, AsyncTestCase, LogTrapTestCase):
+class TestIOStreamSSL(TestIOStreamMixin, AsyncTestCase):
-from tornado.testing import LogTrapTestCase, get_unused_port
+from tornado.testing import get_unused_port, ExpectLog
-class ProcessTest(LogTrapTestCase):
+class ProcessTest(unittest.TestCase):
-        port = get_unused_port()
+        with ExpectLog(gen_log, "(Starting .* processes|child .* exited|uncaught exception)"):
-                self.assertEqual(id, task_id())
+            def get_url(path):
-                client = HTTPClient(SimpleAsyncHTTPClient)
+                return
-                            raise
+                    def fetch(url, fail_ok=False):
-                fetch("/?exit=3", fail_ok=True)
+                    # Make two processes exit abnormally
-                int(fetch("/").body)
+                    # They've been restarted, so a new fetch will work
-                #int(fetch("/").body)
+                    # Now the same with signals
-                self.assertNotEqual(pid, pid2)
+                    # Now kill them normally so they won't be restarted
-                fetch("/?exit=0", fail_ok=True)
+                    # Kill the last one so we shut down cleanly
-            raise
+                    os._exit(0)
-from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, LogTrapTestCase, get_unused_port
+from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, get_unused_port, ExpectLog
-        logging.info("queuing trigger")
+        logging.debug("queuing trigger")
-class SimpleHTTPClientTestCase(AsyncHTTPTestCase, LogTrapTestCase):
+class SimpleHTTPClientTestCase(AsyncHTTPTestCase):
-        response = self.fetch('/trigger?wake=false', request_timeout=0.1)
+        with ExpectLog(gen_log, "uncaught exception"):
-        response = self.wait()
+        with ExpectLog(gen_log, "uncaught exception"):
-        self.assertEqual(response.code, 599)
+        with ExpectLog(gen_log, "uncaught exception"):
-        self.assertEqual(response.code, 599)
+        with ExpectLog(gen_log, "uncaught exception"):
-        response = self.wait()
+        with ExpectLog(gen_log, ".*"):
-from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, ExpectLog
-        logging.info('in get()')
+        logging.debug('in get()')
-        logging.info('in part2()')
+        logging.debug('in part2()')
-        logging.info('in part3()')
+        logging.debug('in part3()')
-class HTTPStackContextTest(AsyncHTTPTestCase, LogTrapTestCase):
+class HTTPStackContextTest(AsyncHTTPTestCase):
-        self.wait()
+        with ExpectLog(app_log, "Uncaught exception GET /"):
-class StackContextTest(AsyncTestCase, LogTrapTestCase):
+class StackContextTest(AsyncTestCase):
-from tornado.testing import LogTrapTestCase
+from tornado.testing import ExpectLog
-class StackTraceTest(LogTrapTestCase):
+class StackTraceTest(unittest.TestCase):
-from tornado.testing import LogTrapTestCase, AsyncHTTPTestCase
+from tornado.testing import AsyncHTTPTestCase, ExpectLog
-class SecureCookieTest(LogTrapTestCase):
+class SecureCookieTest(unittest.TestCase):
-        self.assertTrue(handler.get_secure_cookie('foo') is None)
+        with ExpectLog(gen_log, "Cookie timestamp in future"):
-class CookieTest(AsyncHTTPTestCase, LogTrapTestCase):
+class CookieTest(AsyncHTTPTestCase):
-            logging.info("trying %r", header)
+            logging.debug("trying %r", header)
-class ConnectionCloseTest(AsyncHTTPTestCase, LogTrapTestCase):
+class ConnectionCloseTest(AsyncHTTPTestCase):
-        logging.info('handler waiting')
+        logging.debug('handler waiting')
-        logging.info('connection closed')
+        logging.debug('connection closed')
-class ErrorResponseTest(AsyncHTTPTestCase, LogTrapTestCase):
+class ErrorResponseTest(AsyncHTTPTestCase):
-        self.assertTrue(b("500: Internal Server Error") in response.body)
+        with ExpectLog(app_log, "Uncaught exception"):
-        self.assertTrue(b("503: Service Unavailable") in response.body)
+            response = self.fetch("/default?status=503")
-        self.assertEqual(b("Exception: ZeroDivisionError"), response.body)
+        with ExpectLog(app_log, "Uncaught exception"):
-        self.assertEqual(b("Status: 503"), response.body)
+            response = self.fetch("/write_error?status=503")
-        self.assertEqual(b("Exception: ZeroDivisionError"), response.body)
+        with ExpectLog(app_log, "Uncaught exception"):
-        self.assertEqual(b("Status: 503"), response.body)
+            response = self.fetch("/get_error_html?status=503")
-        self.assertEqual(b(""), response.body)
+        with ExpectLog(app_log, "Uncaught exception"):
-class CustomStaticFileTest(AsyncHTTPTestCase, LogTrapTestCase):
+class CustomStaticFileTest(AsyncHTTPTestCase):
-        self.assertEqual(response.body, b("/static/foo.42.txt"))
+        with ExpectLog(gen_log, "Could not open static file"):
-            raise
+        return execute()
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase
-class AuthTest(AsyncHTTPTestCase, LogTrapTestCase):
+class AuthTest(AsyncHTTPTestCase):
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase, get_unused_port
+from tornado.testing import AsyncHTTPTestCase, get_unused_port
-class HTTPClientCommonTestCase(AsyncHTTPTestCase, LogTrapTestCase):
+class HTTPClientCommonTestCase(AsyncHTTPTestCase):
-class HandlerBaseTestCase(AsyncHTTPTestCase, LogTrapTestCase):
+class HandlerBaseTestCase(AsyncHTTPTestCase):
-class HTTPConnectionTest(AsyncHTTPTestCase, LogTrapTestCase):
+class HTTPConnectionTest(AsyncHTTPTestCase):
-class HTTPServerTest(AsyncHTTPTestCase, LogTrapTestCase):
+class HTTPServerTest(AsyncHTTPTestCase):
-class UnixSocketTest(AsyncTestCase, LogTrapTestCase):
+class UnixSocketTest(AsyncTestCase):
-from tornado.testing import AsyncTestCase, LogTrapTestCase, get_unused_port
+from tornado.testing import AsyncTestCase, get_unused_port
-class TestIOLoop(AsyncTestCase, LogTrapTestCase):
+class TestIOLoop(AsyncTestCase):
-class CreateAsyncHTTPClientTestCase(AsyncTestCase, LogTrapTestCase):
+class CreateAsyncHTTPClientTestCase(AsyncTestCase):
-class HTTP100ContinueTestCase(AsyncHTTPTestCase, LogTrapTestCase):
+class HTTP100ContinueTestCase(AsyncHTTPTestCase):
-class TemplateTest(LogTrapTestCase):
+class TemplateTest(unittest.TestCase):
-class AutoEscapeTest(LogTrapTestCase):
+class AutoEscapeTest(unittest.TestCase):
-class TemplateLoaderTest(LogTrapTestCase):
+class TemplateLoaderTest(unittest.TestCase):
-from tornado.testing import AsyncTestCase, LogTrapTestCase
+from tornado.testing import AsyncTestCase
-class AsyncTestCaseTest(AsyncTestCase, LogTrapTestCase):
+class AsyncTestCaseTest(AsyncTestCase):
-class AuthRedirectTest(AsyncHTTPTestCase, LogTrapTestCase):
+class AuthRedirectTest(AsyncHTTPTestCase):
-class RequestEncodingTest(AsyncHTTPTestCase, LogTrapTestCase):
+class RequestEncodingTest(AsyncHTTPTestCase):
-class WSGISafeWebTest(AsyncHTTPTestCase, LogTrapTestCase):
+class WSGISafeWebTest(AsyncHTTPTestCase):
-class NonWSGIWebTests(AsyncHTTPTestCase, LogTrapTestCase):
+class NonWSGIWebTests(AsyncHTTPTestCase):
-class StaticFileTest(AsyncHTTPTestCase, LogTrapTestCase):
+class StaticFileTest(AsyncHTTPTestCase):
-class NamedURLSpecGroupsTest(AsyncHTTPTestCase, LogTrapTestCase):
+class NamedURLSpecGroupsTest(AsyncHTTPTestCase):
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase
-class WSGIContainerTest(AsyncHTTPTestCase, LogTrapTestCase):
+class WSGIContainerTest(AsyncHTTPTestCase):
-class WSGIApplicationTest(AsyncHTTPTestCase, LogTrapTestCase):
+class WSGIApplicationTest(AsyncHTTPTestCase):
-    curses = None
+from tornado.log import LogFormatter
-        channel.setFormatter(_LogFormatter(color=False))
+        channel.setFormatter(LogFormatter(color=False))
-        channel.setFormatter(_LogFormatter(color=color))
+        channel.setFormatter(LogFormatter())
-
+#!/usr/bin/env python
-from tornado.options import _Options, _LogFormatter
+from tornado.options import _Options
-        self.assertEqual(self.get_output(), utf8(u"\u00e9"))
+    'tornado.test.log_test',
-import logging
+from tornado.log import gen_log
-            logging.warning("Invalid OpenID response: %s", response.error or
+            gen_log.warning("Invalid OpenID response: %s", response.error or
-            logging.warning("Missing OAuth request token cookie")
+            gen_log.warning("Missing OAuth request token cookie")
-            logging.warning("Request token does not match cookie")
+            gen_log.info((cookie_key, request_key, request_cookie))
-            logging.warning("Could not fetch access token")
+            gen_log.warning("Could not fetch access token")
-            logging.warning("Error response %s fetching %s", response.error,
+            gen_log.warning("Error response %s fetching %s", response.error,
-            logging.warning("Error response %s fetching %s", response.error,
+            gen_log.warning("Error response %s fetching %s", response.error,
-            logging.warning("HTTP error from Facebook: %s", response.error)
+            gen_log.warning("HTTP error from Facebook: %s", response.error)
-            logging.warning("Invalid JSON from Facebook: %r", response.body)
+            gen_log.warning("Invalid JSON from Facebook: %r", response.body)
-            logging.warning("Facebook error: %d: %r", json["error_code"],
+            gen_log.warning("Facebook error: %d: %r", json["error_code"],
-            logging.warning('Facebook auth error: %s' % str(response))
+            gen_log.warning('Facebook auth error: %s' % str(response))
-            logging.warning("Error response %s fetching %s", response.error,
+            gen_log.warning("Error response %s fetching %s", response.error,
-import logging
+from tornado.log import gen_log
-        logging.info("%s modified; restarting server", path)
+        gen_log.info("%s modified; restarting server", path)
-        logging.info("Script exited with status %s", e.code)
+        gen_log.info("Script exited with status %s", e.code)
-        logging.warning("Script exited with uncaught exception", exc_info=True)
+        gen_log.warning("Script exited with uncaught exception", exc_info=True)
-        logging.info("Script exited normally")
+        gen_log.info("Script exited normally")
-            logging.warning("socket_action method missing from pycurl; "
+            gen_log.warning("socket_action method missing from pycurl; "
-    if logging.getLogger().isEnabledFor(logging.DEBUG):
+    if gen_log.isEnabledFor(logging.DEBUG):
-        logging.debug("%s %s (username: %r)", request.method, request.url,
+        gen_log.debug("%s %s (username: %r)", request.method, request.url,
-        logging.debug("%s %s", request.method, request.url)
+        gen_log.debug("%s %s", request.method, request.url)
-        logging.debug('%s', debug_msg.strip())
+        gen_log.debug('%s', debug_msg.strip())
-            logging.debug('%s %s', debug_types[debug_type], line)
+            gen_log.debug('%s %s', debug_types[debug_type], line)
-        logging.debug('%s %r', debug_types[debug_type], debug_msg)
+        gen_log.debug('%s %r', debug_types[debug_type], debug_msg)
-import logging
+from tornado.log import gen_log
-            logging.error("Cannot connect to MySQL on %s", self.host,
+            gen_log.error("Cannot connect to MySQL on %s", self.host,
-            logging.error("Error connecting to MySQL on %s", self.host)
+            gen_log.error("Error connecting to MySQL on %s", self.host)
-import logging
+from tornado.log import gen_log
-            logging.info("Malformed HTTP request from %s: %s",
+            gen_log.info("Malformed HTTP request from %s: %s",
-import logging
+from tornado.log import gen_log
-            logging.warning("Invalid multipart/form-data")
+            gen_log.warning("Invalid multipart/form-data")
-        logging.warning("Invalid multipart/form-data: no final boundary")
+        gen_log.warning("Invalid multipart/form-data: no final boundary")
-            logging.warning("multipart/form-data missing headers")
+            gen_log.warning("multipart/form-data missing headers")
-            logging.warning("Invalid multipart/form-data")
+            gen_log.warning("Invalid multipart/form-data")
-            logging.warning("multipart/form-data value missing name")
+            gen_log.warning("multipart/form-data value missing name")
-import logging
+from tornado.log import app_log, gen_log
-                    logging.debug("error closing fd %s", fd, exc_info=True)
+                    gen_log.debug("error closing fd %s", fd, exc_info=True)
-            logging.debug("Error deleting fd from IOLoop", exc_info=True)
+            gen_log.debug("Error deleting fd from IOLoop", exc_info=True)
-                       "with the setitimer method")
+            gen_log.error("set_blocking_signal_threshold requires a signal module "
-                        ''.join(traceback.format_stack(frame)))
+        gen_log.warning('IOLoop blocked for %f seconds in\n%s',
-                        logging.error("Exception in I/O handler for fd %s",
+                        app_log.error("Exception in I/O handler for fd %s",
-                    logging.error("Exception in I/O handler for fd %s",
+                    app_log.error("Exception in I/O handler for fd %s",
-        logging.error("Exception in callback %r", callback, exc_info=True)
+        app_log.error("Exception in callback %r", callback, exc_info=True)
-            logging.error("Error in periodic callback", exc_info=True)
+            app_log.error("Error in periodic callback", exc_info=True)
-            logging.warning("epoll module not found; using select()")
+            gen_log.warning("epoll module not found; using select()")
-import logging
+from tornado.log import gen_log, app_log
-                logging.warning("Connect error on fd %d: %s",
+                gen_log.warning("Connect error on fd %d: %s",
-            logging.warning("Got events for closed stream %d", fd)
+            gen_log.warning("Got events for closed stream %d", fd)
-            logging.error("Uncaught exception, closing connection.",
+            gen_log.error("Uncaught exception, closing connection.",
-                logging.error("Uncaught exception, closing connection.",
+                app_log.error("Uncaught exception, closing connection.",
-            logging.warning("error on read", exc_info=True)
+            gen_log.warning("error on read", exc_info=True)
-            logging.warning("Read error on %d: %s",
+            gen_log.warning("Read error on %d: %s",
-            logging.error("Reached maximum read buffer size")
+            gen_log.error("Reached maximum read buffer size")
-            logging.warning("Connect error on fd %d: %s",
+            gen_log.warning("Connect error on fd %d: %s",
-                    logging.warning("Write error on %d: %s",
+                    gen_log.warning("Write error on %d: %s",
-                logging.warning("SSL Error on %d %s: %s",
+                gen_log.warning("SSL Error on %d %s: %s",
-import logging
+from tornado.log import gen_log
-            logging.error("Unrecognized locale %r (path: %s)", locale,
+            gen_log.error("Unrecognized locale %r (path: %s)", locale,
-                logging.error("Unrecognized plural indicator %r in %s line %d",
+                gen_log.error("Unrecognized plural indicator %r in %s line %d",
-    logging.debug("Supported locales: %s", sorted(_supported_locales))
+    gen_log.debug("Supported locales: %s", sorted(_supported_locales))
-            logging.error("Cannot load translation for '%s': %s", lang, str(e))
+            gen_log.error("Cannot load translation for '%s': %s", lang, str(e))
-    logging.debug("Supported locales: %s", sorted(_supported_locales))
+    gen_log.debug("Supported locales: %s", sorted(_supported_locales))
-import logging
+from tornado.log import app_log
-            logging.error("Error in connection callback", exc_info=True)
+            app_log.error("Error in connection callback", exc_info=True)
-import logging
+from tornado.log import app_log
-            logging.error("_called caught exception", exc_info=True)
+            app_log.error("_called caught exception", exc_info=True)
-import logging
+from tornado.log import gen_log
-    logging.error("Could not detect number of processors; assuming 1")
+    gen_log.error("Could not detect number of processors; assuming 1")
-    logging.info("Starting %d processes", num_processes)
+    gen_log.info("Starting %d processes", num_processes)
-            logging.warning("child %d (pid %d) killed by signal %d, restarting",
+            gen_log.warning("child %d (pid %d) killed by signal %d, restarting",
-            logging.warning("child %d (pid %d) exited with status %d, restarting",
+            gen_log.warning("child %d (pid %d) exited with status %d, restarting",
-            logging.info("child %d (pid %d) exited normally", id, pid)
+            gen_log.info("child %d (pid %d) exited normally", id, pid)
-            logging.debug("max_clients limit reached, request queued. "
+            gen_log.debug("max_clients limit reached, request queued. "
-            logging.warning("uncaught exception", exc_info=True)
+            gen_log.warning("uncaught exception", exc_info=True)
-import logging
+from tornado.log import app_log
-            logging.error("%s code:\n%s", self.name, formatted_code)
+            app_log.error("%s code:\n%s", self.name, formatted_code)
-            logging.error("%s code:\n%s", self.name, formatted_code)
+            app_log.error("%s code:\n%s", self.name, formatted_code)
-            logging.info("RUNNING TEST: " + str(self))
+            gen_log.info("RUNNING TEST: " + str(self))
-            logging.info('PASS')
+            gen_log.info('PASS')
-            logging.error('FAIL')
+            gen_log.error('FAIL')
-import logging
+from tornado.log import access_log, app_log, gen_log
-            logging.error("Cannot send error response after headers written")
+            gen_log.error("Cannot send error response after headers written")
-            logging.error("Uncaught exception in write_error", exc_info=True)
+            app_log.error("Uncaught exception in write_error", exc_info=True)
-                    logging.error("Exception after headers written",
+                    app_log.error("Exception after headers written",
-                logging.warning(format, *args)
+                gen_log.warning(format, *args)
-                logging.error("Bad HTTP status code: %d", e.status_code)
+                gen_log.error("Bad HTTP status code: %d", e.status_code)
-            logging.error("Uncaught exception %s\n%r", self._request_summary(),
+            app_log.error("Uncaught exception %s\n%r", self._request_summary(),
-                    logging.warning(
+                    app_log.warning(
-            log_method = logging.info
+            log_method = access_log.info
-            log_method = logging.warning
+            log_method = access_log.warning
-            log_method = logging.error
+            log_method = access_log.error
-                    logging.error("Could not open static file %r", path)
+                    gen_log.error("Could not open static file %r", path)
-        logging.warning("Invalid cookie signature %r", value)
+        gen_log.warning("Invalid cookie signature %r", value)
-        logging.warning("Expired cookie %r", value)
+        gen_log.warning("Expired cookie %r", value)
-        logging.warning("Cookie timestamp in future; possible tampering %r", value)
+        gen_log.warning("Cookie timestamp in future; possible tampering %r", value)
-        logging.warning("Tampered cookie %r", value)
+        gen_log.warning("Tampered cookie %r", value)
-import logging
+from tornado.log import gen_log, app_log
-                logging.error("Uncaught exception in %s",
+                app_log.error("Uncaught exception in %s",
-            logging.debug("Malformed WebSocket request received")
+            gen_log.debug("Malformed WebSocket request received")
-            logging.debug("Malformed key data in WebSocket request")
+            gen_log.debug("Malformed key data in WebSocket request")
-            logging.debug("Malformed WebSocket request received")
+            gen_log.debug("Malformed WebSocket request received")
-import logging
+from tornado.log import access_log
-            log_method = logging.info
+            log_method = access_log.info
-            log_method = logging.warning
+            log_method = access_log.warning
-            log_method = logging.error
+            log_method = access_log.error
-version = "2.4"
+version = "2.4.post1"
-version_info = (2, 4, 0, 0)
+version = "2.4.post1"
-    ``flags`` is a bitmask of AI_* flags to ``getaddrinfo``.
+    ``flags`` is a bitmask of AI_* flags to ``getaddrinfo``, like
-def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=128):
+def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=128, flags=None):
-        flags |= socket.AI_ADDRCONFIG
+    if flags is None:
-version = "2.3.post1"
+version = "2.4"
-version_info = (2, 3, 0, 1)
+version = "2.4"
-        self.io_loop = io_loop or IOLoop.instance()
+        self.io_loop = io_loop or IOLoop.current()
-                                           io_loop=self.io_loop)
+            result = yield self.client.capitalize("hello")
-                                       io_loop=self.io_loop)
+                 yield self.client.capitalize("HELLO")
-        self._exc_info = exc_info
+    def __init__(self):
-        return False
+        return not self._done
-        return True
+        return self._done
-            raise_exc_info(self._exc_info)
+        self._check_done()
-            return self._exc_info[1]
+        self._check_done()
-        fn(self)
+        if self._done:
-            return DummyFuture(result=None, exc_info=sys.exc_info())
+            future.set_result(fn(*args, **kwargs))
-            cookie_secret="32oETzKXQAGaYdkL5gEmGeJJFuYh7EQnp2XdTP1o/Vo=",
+            cookie_secret="__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__",
-            cookie_secret="11oETzKXQAGaYdkL5gEmGeJJFuYh7EQnp2XdTP1o/Vo=",
+            cookie_secret="__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__",
-            cookie_secret="43oETzKXQAGaYdkL5gEmGeJJFuYh7EQnp2XdTP1o/Vo=",
+            cookie_secret="__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__",
-            cookie_secret="12oETzKXQAGaYdkL5gEmGeJJFuYh7EQnp2XdTP1o/Vo=",
+            cookie_secret="__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__",
-            cookie_secret="43oETzKXQAGaYdkL5gEmGeJJFuYh7EQnp2XdTP1o/Vo=",
+            cookie_secret="__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__",
-                   hostname_mapping=None, max_buffer_size=104857600):
+                   hostname_mapping=None, max_buffer_size=104857600,
-            if ssl is None and parsed.scheme == "https":
+            self.parsed = urlparse.urlsplit(_unicode(self.request.url))
-            if parsed.scheme not in ("http", "https"):
+            if self.parsed.scheme not in ("http", "https"):
-            netloc = parsed.netloc
+            netloc = self.parsed.netloc
-                port = 443 if parsed.scheme == "https" else 80
+                port = 443 if self.parsed.scheme == "https" else 80
-            parsed_hostname = host  # save final parsed host for _on_connect
+            self.parsed_hostname = host  # save final host for _on_connect
-                                          max_buffer_size=max_buffer_size)
+            self.client.resolver.getaddrinfo(
-                                                  parsed_hostname))
+                # This is really only necessary for pre-1.0 versions
-    def _on_connect(self, parsed, parsed_hostname):
+    def _on_connect(self):
-                           # parsed.hostname) until 2.7, here is
+                           # self.parsed.hostname) until 2.7, here is
-                           parsed_hostname)
+                           self.parsed_hostname)
-                self.request.headers["Host"] = parsed.netloc.rpartition('@')[-1]
+            if '@' in self.parsed.netloc:
-                self.request.headers["Host"] = parsed.netloc
+                self.request.headers["Host"] = self.parsed.netloc
-            username, password = parsed.username, parsed.password
+        if self.parsed.username is not None:
-                (('?' + parsed.query) if parsed.query else ''))
+        req_path = ((self.parsed.path or '/') +
-    def _on_connect(self, parsed, parsed_hostname):
+    def _on_connect(self):
-        assert isinstance(future, futures.Future)
+        assert isinstance(future, IOLoop._FUTURE_TYPES)
-    futures is None, "futures module is not present")(TestIOLoopFutures)
+    futures is None, "futures module not present")(TestIOLoopFutures)
-from tornado.test.httpclient_test import HTTPClientCommonTestCase
+from tornado.test import httpclient_test
-class CurlHTTPClientCommonTestCase(HTTPClientCommonTestCase):
+class CurlHTTPClientCommonTestCase(httpclient_test.HTTPClientCommonTestCase):
-    del CurlHTTPClientCommonTestCase
+CurlHTTPClientCommonTestCase = unittest.skipIf(pycurl is None,
-
+SSLv3Test = skipIfNoSSL(skipIfOldSSL(SSLv3Test))
-    del UnixSocketTest
+UnixSocketTest = unittest.skipIf(
-                    return
+                    raise unittest.SkipTest(
-    del TestIOStreamSSL
+TestIOStreamSSL = skipIfNoSSL(TestIOStreamSSL)
-    del ProcessTest
+ProcessTest = unittest.skipIf(os.name != 'posix' or sys.platform == 'cygwin',
-from tornado.test.httpclient_test import HTTPClientCommonTestCase, ChunkHandler, CountdownHandler, HelloWorldHandler
+from tornado.test.httpclient_test import ChunkHandler, CountdownHandler, HelloWorldHandler
-class SimpleHTTPClientCommonTestCase(HTTPClientCommonTestCase):
+class SimpleHTTPClientCommonTestCase(httpclient_test.HTTPClientCommonTestCase):
-
+    @unittest.skipIf(not socket.has_ipv6, 'ipv6 support not present')
-            return
+skipIfNoTwisted = unittest.skipUnless(have_twisted,
-
+ReactorWhenRunningTest = skipIfNoTwisted(ReactorWhenRunningTest)
-else:
+if have_twisted:
-from tornado.test.web_test import WSGISafeWebTest
+from tornado.test import httpserver_test
-class WSGIConnectionTest(HTTPConnectionTest):
+class WSGIConnectionTest(httpserver_test.HTTPConnectionTest):
-class WSGIWebTest(WSGISafeWebTest):
+class WSGIWebTest(web_test.WSGISafeWebTest):
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-import unittest
+from tornado.test.util import unittest
-            self.assertTrue(e is exc_info[1])
+            self.assertIs(e, exc_info[1])
-import unittest
+
-from autobahn.fuzzing import FuzzingClientFactory
+from autobahntestsuite.fuzzing import FuzzingClientFactory
-        self.http_client.fetch("http://localhost:1/", self.stop)
+        port = get_unused_port()
-        self.assertTrue("Connection refused" in str(response.error))
+
-       dictionary, so handlers can access it.
+    """Parses a form request body.
-            'test_shebang',
+                def setUp(self):
-            fields="uid,first_name,last_name,name,locale,pic_square," \
+            fields="uid,first_name,last_name,name,locale,pic_square,"
-        fire_shutdown = functools.partial(self.fireSystemEvent,"shutdown")
+        fire_shutdown = functools.partial(self.fireSystemEvent, "shutdown")
-        
+
-        return dict(ssl_version = self.get_ssl_version(),
+        return dict(ssl_version=self.get_ssl_version(),
-    def _make_client_iostream(self, connection ,**kwargs):
+    def _make_client_iostream(self, connection, **kwargs):
-    if sys.version_info >= (3,2):
+    if sys.version_info >= (3, 2):
-            self.set_header("Expires", datetime.datetime.utcnow() + \
+            self.set_header("Expires", datetime.datetime.utcnow() +
-        
+
-        args = dict(
+        namespace = self.get_template_namespace()
-        return t.generate(**args)
+        namespace.update(self.ui)
-    
+
-        self.redirect("/")
+        self.write('You are now logged out. '
-        self.assertIn("Connection refused", str(response.error))
+        self.assertTrue("Connection refused" in str(response.error))
-            self.stream.close()
+            self.close()
-            self.stream.close()
+            self.close()
-        self._maybe_add_error_listener()
+        if not self._connecting:
-            super(SSLIOStream, self)._handle_connect()
+            if self._ssl_connect_callback is not None:
-        # available, etc).
+        super(SSLIOStream, self)._handle_connect()
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase, get_unused_port
+from tornado.iostream import IOStream, SSLIOStream
-class TestIOStream(AsyncHTTPTestCase, LogTrapTestCase):
+class TestIOStreamWebMixin(object):
-        streams = [None, None]
+    def test_connection_closed(self):
-            self.stop()
+    def test_read_until_close(self):
-        return streams
+        stream.read_until_close(self.stop)
-        self.stream = IOStream(s, io_loop=self.io_loop)
+        self.stream = self._make_client_iostream()
-        s.close()
+        self.stream.close()
-
+            try:
-    def get_ssl_certificate(self):
+    def get_ssl_certificate(self, binary_form=False):
-        the standard library for more details.
+        By default, the return value is a dictionary (or None, if no
-            return self.connection.stream.socket.getpeercert()
+            return self.connection.stream.socket.getpeercert(
-                self.arguments[name] = values
+        self.arguments = parse_qs_bytes(self.query, keep_blank_values=True)
-class HTTP100ContinueTestCase(AsyncTestCase, LogTrapTestCase):
+class HTTP100ContinueTestCase(AsyncHTTPTestCase, LogTrapTestCase):
-        self.request.connection.stream.write(b("HTTP/1.1 100 CONTINUE\r\n\r\n"), self.respond_200)
+        self.request.connection.stream.write(
-        self.request.connection.stream.write(b("HTTP/1.1 200 OK\r\nContent-Length: 1\r\n\r\nA"))
+        self.request.connection.stream.write(
-        res = self.wait()
+        res = self.fetch('/')
-        self.assertEqual(res.body, 'A')
+        self.assertEqual(res.body, b('A'))
-        self.request.connection.stream.write("HTTP/1.1 100 CONTINUE\r\n\r\n", self.respond_200)
+        self.request.connection.stream.write(b("HTTP/1.1 100 CONTINUE\r\n\r\n"), self.respond_200)
-        self.request.connection.stream.write("HTTP/1.1 200 OK\r\nContent-Length: 1\r\n\r\nA")
+        self.request.connection.stream.write(b("HTTP/1.1 200 OK\r\nContent-Length: 1\r\n\r\nA"))
-        self.assertEquals(res.body, 'A')
+        self.assertEqual(res.body, 'A')
-        else:
+        if 100 <= code < 200:
-class SaveAsyncHTTPClientConfigurationTestCase(AsyncTestCase, LogTrapTestCase):
+class CreateAsyncHTTPClientTestCase(AsyncTestCase, LogTrapTestCase):
-        super(SaveAsyncHTTPClientConfigurationTestCase, self).setUp()
+        super(CreateAsyncHTTPClientTestCase, self).setUp()
-        super(SaveAsyncHTTPClientConfigurationTestCase, self).tearDown()
+        super(CreateAsyncHTTPClientTestCase, self).tearDown()
-class HTTP100ContinueTestCase(SaveAsyncHTTPClientConfigurationTestCase):
+class HTTP100ContinueTestCase(AsyncTestCase, LogTrapTestCase):
-            oauth_consumer_key=consumer_token["key"],
+            oauth_consumer_key=escape.to_basestring(consumer_token["key"]),
-            oauth_nonce=binascii.b2a_hex(uuid.uuid4().bytes),
+            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),
-            self.finish(authorize_url + "?" + urllib.urlencode(args)) 
+            self.finish(authorize_url + "?" + urllib.urlencode(args))
-            oauth_token=request_token["key"],
+            oauth_consumer_key=escape.to_basestring(consumer_token["key"]),
-            oauth_nonce=binascii.b2a_hex(uuid.uuid4().bytes),
+            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),
-            oauth_token=access_token["key"],
+            oauth_consumer_key=escape.to_basestring(consumer_token["key"]),
-            oauth_nonce=binascii.b2a_hex(uuid.uuid4().bytes),
+            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),
-        # strings (but byte strings will be repr'd automatically.
+        # strings (but byte strings will be repr'd automatically).
-        self.assertEqual(self.get_output(), utf8(repr(b("\xe9"))))
+        with ignore_bytes_warning():
-    tornado.testing.main()
+    kwargs = {}
-from tornado.escape import json_decode, utf8, to_unicode, recursive_unicode, native_str
+from tornado.escape import json_decode, utf8, to_unicode, recursive_unicode, native_str, to_basestring
-        handler._cookies['foo'] = utf8('1234|5678%s|%s' % (timestamp, sig))
+        handler._cookies['foo'] = utf8('1234|5678%s|%s' % (
-                   max_simultaneous_connections=None):
+    def initialize(self, io_loop=None, max_clients=10):
-                       for i in xrange(max_clients)]
+        self._curls = [_curl_create() for i in xrange(max_clients)]
-def _curl_create(max_simultaneous_connections=None):
+def _curl_create():
-        and will be ignored when an existing client is reused.
+        max_clients is the number of concurrent requests that can be
-    ('index', 'tornado', 'Tornado Documentation', 'Facebook', 'manual', False),
+    ('index', 'tornado.tex', 'Tornado Documentation', 'Facebook', 'manual', False),
-    
+
-    ('index', 'tornado', 'Tornado Documentation', 'Facebook', 'manual', False),
+    ('index', 'tornado.tex', 'Tornado Documentation', 'Facebook', 'manual', False),
-    
+
-        self.fireSystemEvent("shutdown")
+        fire_shutdown = functools.partial(self.fireSystemEvent,"shutdown")
-        self._io_loop.stop()
+        self.fireSystemEvent("shutdown")
-            raise HTTPError(599, "Connection closed")
+            message = "Connection closed"
-        self.code = int(match.group(1))
+        code = int(match.group(1))
-from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, LogTrapTestCase, get_unused_port
-class CreateAsyncHTTPClientTestCase(AsyncTestCase, LogTrapTestCase):
+class SaveAsyncHTTPClientConfigurationTestCase(AsyncTestCase, LogTrapTestCase):
-        super(CreateAsyncHTTPClientTestCase, self).setUp()
+        super(SaveAsyncHTTPClientConfigurationTestCase, self).setUp()
-        super(CreateAsyncHTTPClientTestCase, self).tearDown()
+        super(SaveAsyncHTTPClientConfigurationTestCase, self).tearDown()
-            server.write(OK, server.close)
+            server.write(OK)
-            if callback_uri:
+            if callback_uri == "oob":
-        if callback_uri:
+        if callback_uri == "oob":
-        self._add_io_state(self.io_loop.READ)
+        self._maybe_add_error_listener()
-                    peer = 'not connected'
+                    peer = '(not connected)'
-                logging.warning("SSL Error on %d: %s", self.socket.fileno(), err)
+                try:
-        for full argument list.
+    Additional keyword arguments passed through to ``unittest.main()``.
-def main():
+def main(**kwargs):
-            unittest.main(module=None, argv=argv)
+            unittest.main(module=None, argv=argv, **kwargs)
-            unittest.main(defaultTest="all", argv=argv)
+            unittest.main(defaultTest="all", argv=argv, **kwargs)
-    * body: respose body as string (created on demand from self.buffer)
+    * body: response body as string (created on demand from self.buffer)
-    def __init__(self, request, code, headers=None, buffer=None,
+    def __init__(self, request, code, reason=None, headers=None, buffer=None,
-        match = re.match("HTTP/1.[01] ([0-9]+)", first_line)
+        match = re.match("HTTP/1.[01] ([0-9]+) ([^\r]*)", first_line)
-                                self.code, headers=self.headers,
+                                self.code, reason=self.reason,
-        assert status_code in httplib.responses
+    def set_status(self, status_code, reason=None):
-                      " " + httplib.responses[self._status_code])]
+                      " " + reason)]
-            httplib.responses[handler._status_code]
+        reason = handler._reason
-import unittest
+import socket
-from tornado.testing import AsyncTestCase, LogTrapTestCase
+from tornado.ioloop import IOLoop
-from zope.interface import implements
+from zope.interface import implementer
-
+# Fake class decorator for python 2.5 compatibility
-
+TornadoReactor = implementer(IReactorTime, IReactorFDSet)(TornadoReactor)
-    from zope.interface import implements
+    from zope.interface import implementer
-        pass
+    have_twisted = False
-
+class Reader(object):
-
+class Writer(object):
-
+if have_twisted:
-if twisted is None:
+if not have_twisted:
-        else:
+        if os.name != 'nt':
-            if err.args[0] == errno.ECONNABORTED:
+            if err.args[0] in (errno.ECONNABORTED, errno.ECONNRESET):
-        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
+        if os.name == 'nt':
-        formatted = prefix + " " + record.message
+
-from tornado.options import _Options
+from tornado.escape import utf8
-    def wrapped(callback, contexts, *args, **kwargs):
+    def wrapped(*args, **kwargs):
-    Same as the python ``for`` statement.
+    Same as the python ``for`` statement.  ``{% break %}`` and
-    Same as the python ``while`` statement.
+    Same as the python ``while`` statement.  ``{% break %}`` and
-def _parse(reader, template, in_block=None):
+def _parse(reader, template, in_block=None, in_loop=None):
-            block_body = _parse(reader, template, operator)
+            if operator in ("for", "while"):
-        tornado/test/runtests.py
+        python -m tornado.test.runtests
-        tornado/test/runtests.py tornado.test.stack_context_test
+        python -m tornado.test.runtests tornado.test.stack_context_test
-            self.assertEquals(fd.read(), 'x')
+            self.assertEquals(fd.read(1), 'x')
-class WebTest(AsyncHTTPTestCase, LogTrapTestCase):
+# This test is shared with wsgi_test.py
-        return self.app
+        return urls
-
+class NonWSGIWebTests(AsyncHTTPTestCase, LogTrapTestCase):
-from tornado.util import b
+from tornado.util import b, bytes_type
-        self.path += urllib.quote(environ.get("PATH_INFO", ""))
+        self.path = urllib.quote(from_wsgi_str(environ.get("SCRIPT_NAME", "")))
-            "PATH_INFO": urllib.unquote(request.path),
+            "PATH_INFO": to_wsgi_str(escape.url_unescape(request.path, encoding=None)),
-        headers = handler._headers.items()
+        headers = handler._headers.items() + handler._list_headers
-       Additonal keyword arguments passed to the constructor are saved in the
+       Additional keyword arguments passed to the constructor are saved in the
-                         "templates/utf8.html", "csv_translations/fr_FR.csv"],
+        # data files need to be listed both here (which determines what gets
-    logging.info("Supported locales: %s", sorted(_supported_locales))
+    logging.debug("Supported locales: %s", sorted(_supported_locales))
-            return self.translations.ungettext(message, plural_message, count)
+            return self.ngettext(message, plural_message, count)
-            return self.translations.ugettext(message)
+            return self.gettext(message)
-                         "templates/utf8.html"],
+                         "templates/utf8.html", "csv_translations/fr_FR.csv"],
-        f = open(os.path.join(directory, path), "r")
+        full_path = os.path.join(directory, path)
-    logging.info("Supported locales: %s", sorted(_supported_locales))
+    logging.debug("Supported locales: %s", sorted(_supported_locales))
-        self.assertTrue(0.099 < response.request_time < 0.11, response.request_time)
+        self.assertTrue(0.099 < response.request_time < 0.12, response.request_time)
-        stream.connect(('adomainthatdoesntexist.asdf', 54321))
+        # To reliably generate a gaierror we use a malformed domain name
-            assert content_length in (None, 0)
+            if ("Transfer-Encoding" in self.headers or
-        assert user is not None
+        if user is None:
-        assert self.get_argument('openid.mode') == 'check_authentication'
+        if self.get_argument('openid.mode') != 'check_authentication':
-        assert user is not None
+        if user is None:
-        assert access_token == dict(key=b('uiop'), secret=b('5678')), access_token
+        if access_token != dict(key=b('uiop'), secret=b('5678')):
-            assert res is None
+            self.assertTrue(res is None)
-        assert self.request.protocol == self.expected_protocol
+        if self.request.protocol != self.expected_protocol:
-                assert not data
+                self.assertFalse(data)
-            assert id is not None
+            self.assertTrue(id is not None)
-        assert self.request.body == b("blah")
+        if self.request.body != b("blah"):
-        assert not self.request.body
+        if self.request.body:
-    assert "twisted" not in repr(saved), repr(saved)
+    if "twisted" in repr(saved):
-        assert match
+        self.assertTrue(match)
-        assert handler.get_secure_cookie('foo') is None
+        self.assertTrue(handler.get_secure_cookie('foo') is None)
-            assert type(key) == str, repr(key)
+            if type(key) != str:
-                assert type(value) == bytes_type, repr(value)
+                if type(value) != bytes_type:
-                assert type(value) == unicode, repr(value)
+                if type(value) != unicode:
-            assert type(arg) == unicode, repr(arg)
+            if type(arg) != unicode:
-        assert self.cookies.keys() == ['asdf']
+        if self.cookies.keys() != ['asdf']:
-        assert type(value) == bytes_type, repr(value)
+        if type(value) != bytes_type:
-            self.finish(b("ok"))
+            if "Unsafe header value" in str(e):
-        assert b("Disallow: /") in response.body
+        self.assertTrue(b("Disallow: /") in response.body)
-        assert b("Disallow: /") in response.body
+        self.assertTrue(b("Disallow: /") in response.body)
-                assert path == "foo.txt"
+                if path != "foo.txt":
-from tornado.testing import AsyncHTTPTestCase, AsyncSSLTestCase, AsyncTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase, AsyncHTTPSTestCase, AsyncTestCase, LogTrapTestCase
-class BaseSSLTest(AsyncSSLTestCase, LogTrapTestCase):
+class BaseSSLTest(AsyncHTTPSTestCase, LogTrapTestCase):
-        return ssl.PROTOCOL_SSLv2
+    def get_ssl_options(self):
-        raise NotImplementedError()
+class AsyncHTTPSTestCase(AsyncHTTPTestCase):
-                ssl_version=self.get_ssl_version())
+                keyfile=os.path.join(module_dir, 'test', 'test.key'))
-            data = self._decompressor(data)
+            data = (self._decompressor.decompress(data) +
-            self._decompressor = None
+            if self._decompressor is not None:
-            chunk = self._decompressor(chunk)
+            chunk = self._decompressor.decompress(chunk)
-    def __call__(self, value):
+    def decompress(self, value):
-            row = [c.decode("utf-8").strip() for c in row]
+            row = [escape.to_unicode(c).strip() for c in row]
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase, AsyncTestCase
+from tornado.testing import AsyncHTTPTestCase, AsyncSSLTestCase, AsyncTestCase, LogTrapTestCase
-
+class BaseSSLTest(AsyncSSLTestCase, LogTrapTestCase):
-            self.assertEqual(response.code, 599)
+
-elif getattr(ssl, 'OPENSSL_VERSION_INFO', (0, 0)) < (1, 0):
+if getattr(ssl, 'OPENSSL_VERSION_INFO', (0, 0)) < (1, 0):
-        self.http_client = AsyncHTTPClient(io_loop=self.io_loop)
+        self.http_client = self.get_http_client()
-                                      **self.get_httpserver_options())
+        self.http_server = self.get_http_server()
-        keyword arguments for HTTPServer.
+        keyword arguments for the server.
-        """Returns the port used by the HTTPServer.
+        """Returns the port used by the server.
-        return 'http://localhost:%s%s' % (self.get_http_port(), path)
+        return '%s://localhost:%s%s' % (self.get_protocol(),
-from tornado.escape import utf8, native_str, parse_qs_bytes
+from tornado.escape import native_str, parse_qs_bytes
-                    logging.warning("Invalid multipart/form-data")
+            httputil.parse_body_arguments(
-                logging.warning("Invalid multipart/form-data")
+        httputil.parse_body_arguments(self.headers.get("Content-Type", ""),
-from tornado.util import b
+from tornado.util import b, GzipDecompressor
-            self._decompressor = zlib.decompressobj(16 + zlib.MAX_WBITS)
+            self._decompressor = GzipDecompressor()
-            data = self._decompressor.decompress(data)
+            data = self._decompressor(data)
-            chunk = self._decompressor.decompress(chunk)
+            chunk = self._decompressor(chunk)
-     dict(url="http://github.com/downloads/facebook/tornado/tornado-0.1.tar.gz")),
+     dict(url="https://github.com/downloads/facebook/tornado/tornado-0.1.tar.gz")),
-     dict(url="http://github.com/downloads/facebook/tornado/tornado-0.2.tar.gz")),
+     dict(url="https://github.com/downloads/facebook/tornado/tornado-0.2.tar.gz")),
-        signal.alarm(5)
+        signal.alarm(5)  # master process
-version = "2.3"
+version = "2.3.post1"
-version_info = (2, 3, 0, 0)
+version = "2.3.post1"
-                    self._on_timeout)
+                    stack_context.wrap(self._on_timeout))
-        self.stream.close()
+        if self.final_callback is not None:
-                self._on_timeout)
+                stack_context.wrap(self._on_timeout))
-                error=HTTPError(599, "Connection closed")))
+        if self.final_callback is not None:
-version = "2.3.rc1"
+version = "2.3"
-version_info = (2, 3, 0, -1)
+version = "2.3"
-        self._read_callback = callback
+        self._read_callback = stack_context.wrap(callback)
-version = "2.2.post1"
+version = "2.3.rc1"
-version_info = (2, 2, 0, 1)
+version = "2.3.rc1"
-        self.assertEqual(stream.error.args[0], errno.ECONNREFUSED)
+        if sys.platform != 'cygwin':
-                version_hash = cls.get_version(settings, path)
+                cls.get_version(settings, path)
-import cgi
+from __future__ import absolute_import, division, with_statement
-            
+
-        
+
-                self.add(k,v)
+            for k, v in args[0].get_all():
-                    self._write_buffer.append(data[i:i+WRITE_BUFFER_CHUNK_SIZE])
+                    self._write_buffer.append(data[i:i + WRITE_BUFFER_CHUNK_SIZE])
-
+
-
+
-
+
-        self.wait(timeout = 0.02)
+        self.wait(timeout=0.02)
-        self.wait(timeout = 0.1)
+        self.wait(timeout=0.1)
-                self.set_cookie("c", "d" ,domain="example.com")
+                self.set_cookie("c", "d", domain="example.com")
-        
+
-            
+
-        
+
-                    self.redirect(uri, permanent = True)
+                    self.redirect(uri, permanent=True)
-                self.redirect(uri, permanent = True)
+                self.redirect(uri, permanent=True)
-                raise "did not get expected exception"
+                raise Exception("did not get expected exception")
-                raise "did not get expected exception"
+                raise Exception("did not get expected exception")
-            raise "did not get expected exception"
+            raise Exception("did not get expected exception")
-            address = ('0.0.0.0', 0)
+
-                headers=headers, remote_ip=self.address[0])
+                headers=headers, remote_ip=remote_ip)
-                    self._write_buffer.append(data[i:i+128*1024])
+            # Break up large contiguous strings before inserting them in the
-            self._write_buffer.append(data)
+            if len(data) > 128*1024:
-        if hasattr(self.request, "connection"):
+        if getattr(self.request, "connection", None):
-    parts = data[:-footer_length].split(b("--") + boundary + b("\r\n"))
+    final_boundary_index = data.rfind(b("--") + boundary + b("--"))
-        with ExceptionStackContext(handle_exception):
+        with ExceptionStackContext(handle_exception) as deactivate:
-                runner = Runner(gen)
+                runner = Runner(gen, deactivate)
-    def __init__(self, gen):
+    def __init__(self, gen, deactivate_stack_context):
-    def __init__(self, context_factory):
+    def __init__(self, context_factory, _active_cell=None):
-        # _state.contexts is a tuple of (class, arg) pairs
+        # _state.contexts is a tuple of (class, arg, active_cell) tuples
-                           ((StackContext, self.context_factory),))
+                           ((StackContext, self.context_factory, self.active_cell),))
-    def __init__(self, exception_handler):
+    def __init__(self, exception_handler, _active_cell=None):
-                           ((ExceptionStackContext, self.exception_handler),))
+                           ((ExceptionStackContext, self.exception_handler,
-            new_contexts = [cls(arg) for (cls, arg) in contexts]
+            new_contexts = [cls(arg, active_cell)
-                            [cls(arg) for (cls, arg) in contexts])
+                            [cls(arg, active_cell)
-                            for (cls, arg) in contexts[len(_state.contexts):]]
+            new_contexts = [cls(arg, active_cell)
-             linkify(text, extra_params=extra_params_cb)
+        e.g. ``linkify(text, extra_params='rel="nofollow" class="external"')``,
-            if "Content-Length" not in self._headers:
+            if self._status_code == 304:
-        if self._chunking:
+        # 304 responses have no body (not even a zero-length body), and so
-                    self._headers, chunk, include_footers)
+                self._status_code, self._headers, chunk = \
-        return headers, chunk
+    def transform_first_chunk(self, status_code, headers, chunk, finishing):
-    def transform_first_chunk(self, headers, chunk, finishing):
+    def transform_first_chunk(self, status_code, headers, chunk, finishing):
-        return headers, chunk
+        return status_code, headers, chunk
-    def transform_first_chunk(self, headers, chunk, finishing):
+    def transform_first_chunk(self, status_code, headers, chunk, finishing):
-        return headers, chunk
+        return status_code, headers, chunk
-This module has been tested with Twisted versions 11.0.0 and 11.1.0.
+This module has been tested with Twisted versions 11.0.0, 11.1.0, and 12.0.0
-    # dependencies do (last match wins).
+    # Tornado generally shouldn't use anything deprecated, but some of
-    from tornado.platform.windows import set_close_exec, Waker
+    from tornado.platform.common import Waker
-        self.writer.close()
+from tornado.util import raise_exc_info
-            raise exc[0], exc[1], exc[2]
+            raise_exc_info(exc)
-                raise failure[0], failure[1], failure[2]
+            raise_exc_info(failure)
-from tornado.util import b, bytes_type, import_object, ObjectDict
+from tornado.util import b, bytes_type, import_object, ObjectDict, raise_exc_info
-                    raise exc_info[0], exc_info[1], exc_info[2]
+                    raise_exc_info(exc_info)
-            raise type, value, traceback
+            raise_exc_info((type, value, traceback))
-        arguments = parse_qs_bytes(query)
+        self.path, sep, self.query = uri.partition('?')
-            url("/decode_arg/(.*)", DecodeArgHandler),
+            url("/decode_arg/(.*)", DecodeArgHandler, name='decode_arg'),
-                           cookie_secret=self.COOKIE_SECRET)
+        self.app = Application(urls,
-        The handler must be added to the application as a named URLSpec
+        The handler must be added to the application as a named URLSpec.
-        return self._path % tuple([str(a) for a in args])
+        converted_args = []
-    print >> file
+class Error(Exception):
-        return cls._instance
+    """A collection of options, a dictionary with object-like access.
-    pass
+
-def enable_pretty_logging():
+def define(name, default=None, type=None, help=None, metavar=None,
-
+import unittest
-        self.assertEqual(response.body, "ok")
+        self.assertEqual(response.body, b("ok"))
-    def __new__(cls, io_loop=None, max_clients=10, force_instance=False,
+    def __new__(cls, io_loop=None, max_clients=None, force_instance=False,
-            instance.initialize(io_loop, max_clients, **args)
+            if max_clients is not None:
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, LogTrapTestCase
-        watch(pkgutil.get_loader(module).get_filename())
+        loader = pkgutil.get_loader(module)
-from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature
+from tornado.web import RequestHandler, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature, create_signed_value
-                           autoescape="xhtml_escape")
+                           autoescape="xhtml_escape",
-                              headers={"Cookie": "cook=ie"})
+                              headers={"Cookie": "asdf=" + cookie_value})
-                              headers={"Cookie": "cook=ie"},
+                              headers={"Cookie": "asdf=" + cookie_value},
-        """Returns the given signed cookie if it validates, or None."""
+        """Returns the given signed cookie if it validates, or None.
-    def get(self, path):
+    def get(self, *path_args):
-        self.write(dict(path=path,
+        for arg in path_args:
-        return Application([("/(.*)", EchoHandler)])
+        return Application([
-    def test_question_mark(self):
+    def fetch_json(self, path):
-                         dict(path='?', args={'?': ['?']}))
+        self.assertEqual(self.fetch_json('/group/%3F'),
-    def test_path_encoding(self):
+    def test_group_encoding(self):
-                         {u"path": u"\u00e9",
+        self.assertEqual(self.fetch_json('/group/%C3%A9?arg=%C3%A9'),
-            for cookie in cookie_dict.values():
+        if hasattr(handler, "_new_cookie"):
-    extra_params: Extra text to include in the link tag,
+    extra_params: Extra text to include in the link tag, or a callable
-    if extra_params:
+    if extra_params and not callable(extra_params):
-        params = extra_params
+        if callable(extra_params):
-        if self._request.method in ("POST", "PUT"):
+        if self._request.method in ("POST", "PATCH", "PUT"):
-    _SUPPORTED_METHODS = set(["GET", "HEAD", "POST", "PUT", "DELETE"])
+    _SUPPORTED_METHODS = set(["GET", "HEAD", "POST", "PATCH", "PUT", "DELETE"])
-            if self.request.method in ("POST", "PUT"):
+            if self.request.method in ("POST", "PATCH", "PUT"):
-    SUPPORTED_METHODS = ("GET", "HEAD", "POST", "DELETE", "PUT", "OPTIONS")
+    SUPPORTED_METHODS = ("GET", "HEAD", "POST", "DELETE", "PATCH", "PUT",
-            if len(prefix) > 30:
+            if len(prefix) > 30 or len(lines) == 0:
-    """Our global program options, an dictionary with object-like access."""
+    """Our global program options, a dictionary with object-like access."""
-    def __init__(self, name, default=None, type=str, help=None, metavar=None,
+    def __init__(self, name, default=None, type=basestring, help=None, metavar=None,
-            str: self._parse_string,
+            basestring: self._parse_string,
-                            (self.name, self.type.__name__))
+                raise Error("Option %r is required to be a %s (%s given)" %
-version = "2.2"
+version = "2.2.1"
-version_info = (2, 2, 0, 0)
+version = "2.2.1"
-        if len(value) > 4000 or re.match(b(r"[\x00-\x1f]"), value):
+        if len(value) > 4000 or re.search(b(r"[\x00-\x1f]"), value):
-                               curses.tigetstr("setf") or "", "ascii")
+            # The curses module has some str/bytes confusion in
-            IOLoop._instance = IOLoop()
+            with IOLoop._instance_lock:
-            self._check_closed()
+        try:
-            self.request.write(headers + chunk, callback=callback)
+        self.request.write(headers + chunk, callback=callback)
-        "tornado.test": ["README", "test.crt", "test.key", "static/robots.txt"],
+        "tornado.test": ["README", "test.crt", "test.key", "static/robots.txt",
-        f = open(path, "r")
+        f = open(path, "rb")
-from tornado.template import Template, DictLoader, ParseError
+from tornado.escape import utf8, native_str, to_unicode
-        self.wait(timeout = 0.01)
+        self.io_loop.add_timeout(time.time() + 0.01, self.stop)
-                          'Async operation timed out after %d seconds' %
+                          'Async operation timed out after %s seconds' %
-``{% try %}...{% except %}...{% finally %}...{% end %}``
+``{% try %}...{% except %}...{% finally %}...{% else %}...{% end %}``
-            "else": set(["if", "for", "while"]),
+            "else": set(["if", "for", "while", "try"]),
-    print >> file, "Options:"
+    print >> file, "\nOptions:\n"
-            print >> file, filename
+            print >> file, "\n%s options:\n" % os.path.normpath(filename)
-            print >> file, "  --%-30s %s" % (prefix, option.help or "")
+            description = option.help or ""
-import MySQLdb.cursors
+try:
-CONVERSIONS = copy.copy(MySQLdb.converters.conversions)
+    field_types = [FIELD_TYPE.BLOB, FIELD_TYPE.STRING, FIELD_TYPE.VAR_STRING]
-    field_types.append(FIELD_TYPE.VARCHAR)
+    for field_type in field_types:
-OperationalError = MySQLdb.OperationalError
+    # Alias some common MySQL exceptions
-                self._value = []
+            self._value = []
-        if not self.set_headers(abspath, path):
+        if not self.set_headers(path):
-        body = self.get_content(abspath)
+        body = self.get_content(path)
-    def set_headers(self, abspath, path):
+    def set_headers(self, path):
-    def get_content(self, abspath):
+    def get_content(self, path):
-        at the given ``abspath``.
+        at the given absolute ``path``.
-                self._run_callback(cb)
+        self._maybe_run_close_callback()
-        while True:
+        try:
-                    return
+                # Pretend to have a pending callback so that an EOF in
-            self._check_closed()
+            self._check_closed()
-                    self._run_callback(cb)
+                self._maybe_run_close_callback()
-        signal.alarm(5)  # master process
+        signal.alarm(5)
-        IOLoop will be closed (not just the ones created by the IOLoop itself.
+        IOLoop will be closed (not just the ones created by the IOLoop itself).
-            arguments = cgi.parse_qs(self.query)
+            arguments = parse_qs_bytes(native_str(self.query))
-            ],
+        # Process tests appear to work on OSX 10.7, but not 10.6
-            all_args.update(post_args or {})
+            
-from tornado.escape import native_str, utf8
+from tornado.escape import native_str, utf8, parse_qs_bytes
-            for name, values in cgi.parse_qs(self.body).iteritems():
+            for name, values in parse_qs_bytes(native_str(self.body)).iteritems():
-                bytes_to_consume = min(self._read_bytes, self._read_buffer_size)
+        if self._streaming_callback is not None and self._read_buffer_size:
-                return True
+            self._run_callback(self._streaming_callback,
-                return True
+                while True:
-                                   self._consume(self._read_buffer_size))
+                while True:
-            self.set_header("Content-Length", len(body))
+        return abspath
-        if not self.set_headers(abspath, path)
+        if not self.set_headers(abspath, path):
-                return
+                return False
-                self.set_header("Content-Length", len(data))
+            return file.read()
-                    self.redirect(uri)
+                    self.redirect(uri, permanent = True)
-                self.redirect(uri)
+                self.redirect(uri, permanent = True)
-        os.environ["PYTHONPATH"] = path_prefix + os.environ.get("PYTHONPATH", "")
+    # sys.path fixes: see comments at top of file.  If sys.path[0] is an empty
-        del sys.path[0]
+    # See also the other __main__ block at the top of the file, which modifies
-    def __init__(self, request, code, headers={}, buffer=None,
+    def __init__(self, request, code, headers=None, buffer=None,
-                 time_info={}):
+                 time_info=None):
-        self.headers = headers
+        if headers is not None:
-        self.time_info = time_info
+        self.time_info = time_info or {}
-    def __init__(self, pattern, handler_class, kwargs={}, name=None):
+    def __init__(self, pattern, handler_class, kwargs=None, name=None):
-        self.kwargs = kwargs
+        self.kwargs = kwargs or {}
-        self.update(*args, **kwargs)
+        if (len(args) == 1 and len(kwargs) == 0 and
-            request.headers = HTTPHeaders(request.headers)
+        # We're going to modify this (to add Host, Accept-Encoding, etc),
-                raise self.__failure[0], self.__failure[1], self.__failure[2]
+        self.__rethrow()
-    _SUPPORTED_METHODS = set(["GET", "HEAD", "POST", "PUT", "DELETE"])
+    _SUPPORTED_METHODS = set(["GET", "HEAD", "POST", "PUT", "DELETE", "OPTIONS"])
-        'twisted.internet.test.test_tcp.TCPPortTestsBuilder': [],
+        'twisted.internet.test.test_tcp.TCPClientTestsBuilder': [
-            self.request.headers["Host"] = parsed.netloc
+            if '@' in parsed.netloc:
-            new_request = copy.deepcopy(self.request)
+            new_request = copy.copy(self.request)
-            new_request = copy.copy(self.request)
+            new_request = copy.deepcopy(self.request)
-            reverse_url=self.application.reverse_url
+            reverse_url=self.reverse_url
-def get_supported_locales(cls):
+def get_supported_locales():
-        assert not self._read_callback, "Already reading"
+        self._set_read_callback(callback)
-        self._read_until(callback)
+        self._try_inline_read()
-        assert not self._read_callback, "Already reading"
+        self._set_read_callback(callback)
-        self._read_until(callback)
+        self._try_inline_read()
-        assert not self._read_callback, "Already reading"
+        self._set_read_callback(callback)
-        self._read_until(callback)
+        self._try_inline_read()
-        assert not self._read_callback, "Already reading"
+        self._set_read_callback(callback)
-        unless stream has already been read or closed.
+    def _set_read_callback(self, callback):
-        self._read_callback = stack_context.wrap(callback)
+            parsed_hostname = host  # save final parsed host for _on_connect
-                                functools.partial(self._on_connect, parsed))
+                                functools.partial(self._on_connect, parsed,
-    def _on_connect(self, parsed):
+    def _on_connect(self, parsed, parsed_hostname):
-                           parsed._hostname)
+                           # ipv6 addresses are broken (in
-    def _on_connect(self, parsed):
+    def _on_connect(self, parsed, parsed_hostname):
-                         ["str=asdf; Path=/",
+        self.assertEqual(sorted(response.headers.get_list("Set-Cookie")),
-                          "bytes=zxcv; Path=/"])
+                          ])
-        headers = response.headers.get_list("Set-Cookie")
+        headers = sorted(response.headers.get_list("Set-Cookie"))
-        self.assertTrue(headers[1] in ('semicolon="a;b"; Path=/',
+        self.assertTrue(headers[2] in ('semicolon="a;b"; Path=/',
-        self.assertEqual(headers[2], 'quote="a\\"b"; Path=/')
+                        headers[2])
-        new_cookie[name] = value
+        if not hasattr(self, "_new_cookie"):
-            new_cookie[name]["domain"] = domain
+            morsel["domain"] = domain
-            new_cookie[name]["expires"] = email.utils.formatdate(
+            morsel["expires"] = email.utils.formatdate(
-            new_cookie[name]["path"] = path
+            morsel["path"] = path
-            new_cookie[name][k] = v
+            morsel[k] = v
-            for cookie in cookie_dict.values():
+        if hasattr(self, "_new_cookie"):
-                self.io_loop.add_timeout(time.time() + timeout, timeout_func)
+                if self.__timeout is not None:
-          args["oauth_verifier"] = request_token["verifier"]
+            args["oauth_verifier"] = request_token["verifier"]
-      """Handles the login for the Facebook user, returning a user object.
+        """Handles the login for the Facebook user, returning a user object.
-      Example usage::
+        """
-      if extra_fields:
+        fields = set(['id', 'name', 'first_name', 'last_name',
-                              client_secret, callback, fields))
+        http.fetch(self._oauth_request_token_url(**args),
-          )
+        if response.error:
-       self.assertEqual("POST", response.request.method)
+        response = self.fetch("/303_post", method="POST", body="blah")
-                              ax_attrs=["name","email","language","username"]):
+                              ax_attrs=["name", "email", "language", "username"]):
-        if http_client is None: http_client = httpclient.AsyncHTTPClient()
+        if http_client is None:
-            if not ax_ns: return u""
+            if not ax_ns:
-            if not ax_name: return u""
+            if not ax_name:
-        if username: user["username"] = username
+        if email:
-    def _oauth_request_token_url(self, callback_uri= None, extra_params=None):
+    def _oauth_request_token_url(self, callback_uri=None, extra_params=None):
-            if extra_params: args.update(extra_params)
+            if extra_params:
-          args["oauth_verifier"]=request_token["verifier"]
+          args["oauth_verifier"] = request_token["verifier"]
-                           client_secret=None, extra_params=None ):
+                           client_secret=None, extra_params=None):
-        if extra_params: args.update(extra_params)
+        if extra_params:
-    def _oauth_request_token_url(self, redirect_uri= None, client_id = None,
+    def _oauth_request_token_url(self, redirect_uri=None, client_id=None,
-        if extra_params: args.update(extra_params)
+        if extra_params:
-    def authenticate_redirect(self, callback_uri = None):
+    def authenticate_redirect(self, callback_uri=None):
-        http.fetch(self._oauth_request_token_url(callback_uri = callback_uri), self.async_callback(
+        http.fetch(self._oauth_request_token_url(callback_uri=callback_uri), self.async_callback(
-        if args: url += "?" + urllib.urlencode(args)
+        if args:
-        if args: url += "?" + urllib.urlencode(args)
+        if args:
-                           ax_attrs=["name","email","language","username"]):
+                           ax_attrs=["name", "email", "language", "username"]):
-        if isinstance(body, unicode): body = body.encode("utf-8")
+        if isinstance(body, unicode):
-      if extra_fields: fields.update(extra_fields)
+      if extra_fields:
-        if all_args: url += "?" + urllib.urlencode(all_args)
+        if all_args:
-    base_string =  "&".join(_oauth_escape(e) for e in base_elems)
+    base_string = "&".join(_oauth_escape(e) for e in base_elems)
-    base_string =  "&".join(_oauth_escape(e) for e in base_elems)
+    base_string = "&".join(_oauth_escape(e) for e in base_elems)
-
+
-        if not isinstance(module, types.ModuleType): continue
+        if not isinstance(module, types.ModuleType):
-        if not path: continue
+        if not path:
-    
+
-    
+
-            time.time() + msecs/1000.0, self._handle_timeout)
+            time.time() + msecs / 1000.0, self._handle_timeout)
-        if events & ioloop.IOLoop.WRITE: action |= pycurl.CSELECT_OUT
+        if events & ioloop.IOLoop.READ:
-        request_buffer =  cStringIO.StringIO(utf8(request.body))
+        request_buffer = cStringIO.StringIO(utf8(request.body))
-                 max_idle_time=7*3600):
+                 max_idle_time=7 * 3600):
-except Exception: bytes = str
+try:
-        for k,v in result.iteritems():
+        for k, v in result.iteritems():
-        
+
-        return dict((recursive_unicode(k), recursive_unicode(v)) for (k,v) in obj.iteritems())
+        return dict((recursive_unicode(k), recursive_unicode(v)) for (k, v) in obj.iteritems())
-# I originally used the regex from 
+# I originally used the regex from
-class BadYieldError(Exception): pass
+
-        
+
-        
+
-        
+
-            
+
-    
+
-        
+
-    
+
-    
+
-        
+
-    def __new__(cls, io_loop=None, max_clients=10, force_instance=False, 
+    def __new__(cls, io_loop=None, max_clients=10, force_instance=False,
-           `~HTTPResponse.body` and `~HTTPResponse.buffer` will be empty in 
+           be run with each chunk of data as it is received, and
-           be run with each header line as it is received, and 
+           be run with each header line as it is received, and
-           `proxy_pass` are optional.  Proxies are currently only support 
+        :arg string proxy_host: HTTP proxy hostname.  To use proxies,
-        :arg bool allow_nonstandard_methods: Allow unknown values for `method` 
+        :arg bool allow_nonstandard_methods: Allow unknown values for `method`
-        :arg bool allow_ipv6: Use IPv6 when available?  Default is false in 
+        :arg bool allow_ipv6: Use IPv6 when available?  Default is false in
-    import ssl # Python 2.6+
+    import ssl  # Python 2.6+
-    2. `~tornado.netutil.TCPServer.bind`/`~tornado.netutil.TCPServer.start`: 
+    2. `~tornado.netutil.TCPServer.bind`/`~tornado.netutil.TCPServer.start`:
-            callback()            
+            callback()
-       `RequestHandler.get_argument`, which returns argument values as 
+       are byte strings.  Note that this is different from
-            elif connection and isinstance(connection.stream, 
+            elif connection and isinstance(connection.stream,
-            if values: self.arguments[name] = values
+            if values:
-
+
-    if not args: return url
+    if not args:
-        if not part: continue
+        if not part:
-            value = p[i+1:].strip()
+            value = p[i + 1:].strip()
-        return (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / float(10**6)
+        return (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10 ** 6) / float(10 ** 6)
-        if not self._running: return
+        if not self._running:
-        if events & IOLoop.WRITE: self.write_fds.add(fd)
+        if events & IOLoop.READ:
-    import ssl # Python 2.6+
+    import ssl  # Python 2.6+
-    non-blocking and asynchronous). 
+    non-blocking and asynchronous).
-        
+
-
+
-        if not path.endswith(".csv"): continue
+        if not path.endswith(".csv"):
-            if not row or len(row) < 2: continue
+            if not row or len(row) < 2:
-        if os.path.isfile(os.path.join(directory, lang)): continue
+        if lang.startswith('.'):
-            os.stat(os.path.join(directory, lang, "LC_MESSAGES", domain+".mo"))
+            os.stat(os.path.join(directory, lang, "LC_MESSAGES", domain + ".mo"))
-            if not code: continue
+            if not code:
-                             seconds) % { "seconds": seconds }
+                             seconds) % {"seconds": seconds}
-                             minutes) % { "minutes": minutes }
+                             minutes) % {"minutes": minutes}
-                         hours) % { "hours": hours }
+                         hours) % {"hours": hours}
-        if len(parts) == 1: return parts[0]
+        if len(parts) == 0:
-    import ssl # Python 2.6+
+    import ssl  # Python 2.6+
-    The ``backlog`` argument has the same meaning as for 
+    The ``backlog`` argument has the same meaning as for
-        Returns a socket object (not a list of socket objects like 
+        Returns a socket object (not a list of socket objects like
-    if file_name == options_file: file_name = ""
+    if file_name == options_file:
-    if args is None: args = sys.argv
+    if args is None:
-            remaining = args[i+1:]
+            remaining = args[i + 1:]
-        if filename: print >> file, filename
+        if filename:
-                    self._value.extend(range(lo, hi+1))
+                    self._value.extend(range(lo, hi + 1))
-    
+
-                logging.DEBUG: unicode(curses.tparm(fg_color, 4), # Blue
+                logging.DEBUG: unicode(curses.tparm(fg_color, 4),  # Blue
-                logging.INFO: unicode(curses.tparm(fg_color, 2), # Green
+                logging.INFO: unicode(curses.tparm(fg_color, 2),  # Green
-                logging.WARNING: unicode(curses.tparm(fg_color, 3), # Yellow
+                logging.WARNING: unicode(curses.tparm(fg_color, 3),  # Yellow
-                logging.ERROR: unicode(curses.tparm(fg_color, 1), # Red
+                logging.ERROR: unicode(curses.tparm(fg_color, 1),  # Red
-        
+
-    
+
-    
+
-                if not result: break;
+                if not result:
-        self._fds = {} # a map of fd to a (reader, writer) tuple
+        self._fds = {}  # a map of fd to a (reader, writer) tuple
-                if not result: break
+                if not result:
-    import multiprocessing # Python 2.6+
+    import multiprocessing  # Python 2.6+
-        if id is not None: return id
+        if id is not None:
-        if new_id is not None: return new_id
+        if new_id is not None:
-    import ssl # python 2.6+
+    import ssl  # python 2.6+
-                if sys.version_info >= (2,7):
+                if sys.version_info >= (2, 7):
-            self._decompressor = zlib.decompressobj(16+zlib.MAX_WBITS)
+            self._decompressor = zlib.decompressobj(16 + zlib.MAX_WBITS)
-            buffer = BytesIO(data) # TODO: don't require one big string?
+            buffer = BytesIO(data)  # TODO: don't require one big string?
-                            [cls(arg) for (cls,arg) in contexts])
+                            [cls(arg) for (cls, arg) in contexts])
-    
+
-                "%s.generated.py" % self.name.replace('.','_'),
+                "%s.generated.py" % self.name.replace('.', '_'),
-
+
-        print >> self.file, "    "*indent + line + line_comment
+        print >> self.file, "    " * indent + line + line_comment
-            if stop is not None: stop += self.pos
+            if start is None:
-                if fn == "None": fn = None
+                if fn == "None":
-        import urllib; urllib.urlencode(params)
+        import urllib
-            headers={'Cookie':'_oauth_request_token=enhjdg==|MTIzNA=='})
+            headers={'Cookie': '_oauth_request_token=enhjdg==|MTIzNA=='})
-            headers={'Cookie':'_oauth_request_token=enhjdg==|MTIzNA=='})
+            headers={'Cookie': '_oauth_request_token=enhjdg==|MTIzNA=='})
-    ("rdar://1234", 
+    ("rdar://1234",
-    ("rdar:/1234", 
+    ("rdar:/1234",
-    ("Just a www.example.com link.", 
+    ("Just a www.example.com link.",
-            1/0
+            1 / 0
-            1/0
+            1 / 0
-            1/0
+            1 / 0
-            self.io_loop.add_callback(lambda: 1/0)
+            self.io_loop.add_callback(lambda: 1 / 0)
-            io_loop.add_callback(lambda: 1/0)
+            io_loop.add_callback(lambda: 1 / 0)
-        
+
-        return Application([('/', HelloWorldRequestHandler, 
+        return Application([('/', HelloWorldRequestHandler,
-                              body='A'*5000)
+                              body='A' * 5000)
-    def get_ssl_version(self): return ssl.PROTOCOL_SSLv23
+    def get_ssl_version(self):
-    def get_ssl_version(self): return ssl.PROTOCOL_SSLv3
+    def get_ssl_version(self):
-    def get_ssl_version(self): return ssl.PROTOCOL_TLSv1
+    def get_ssl_version(self):
-        def get_ssl_version(self): return ssl.PROTOCOL_SSLv2
+        def get_ssl_version(self):
-elif getattr(ssl, 'OPENSSL_VERSION_INFO', (0,0)) < (1,0):
+elif getattr(ssl, 'OPENSSL_VERSION_INFO', (0, 0)) < (1, 0):
-                                        1024*1024)
+                                        1024 * 1024)
-            self.errors[name] = "expected %s, got %s" % (expected_type, 
+            self.errors[name] = "expected %s, got %s" % (expected_type,
-                [('y','y'), ('z','z')],
+                [('y', 'y'), ('z', 'z')],
-                [('y','/y'), ('z','z')],
+                [('y', '/y'), ('z', 'z')],
-                [('y','y'), ('z','z')],
+                [('y', 'y'), ('z', 'z')],
-                [('y','y'), ('z','z')],
+                [('y', 'y'), ('z', 'z')],
-                [('y','y'), ('z','z')],
+                [('y', 'y'), ('z', 'z')],
-                [('y','y'), ('z','z')],
+                [('y', 'y'), ('z', 'z')],
-        
+
-        
+
-        self.assertEqual(server._state, IOLoop.READ|IOLoop.ERROR)
+        self.assertEqual(server._state, IOLoop.READ | IOLoop.ERROR)
-        
+
-            for sock in sockets: sock.close()
+            for sock in sockets:
-                for sock in sockets: sock.close()
+                for sock in sockets:
-            
+
-        loader = DictLoader({"test.html": "{{ inc(5) }}"}, namespace={"inc": lambda x: x+1})
+        loader = DictLoader({"test.html": "{{ inc(5) }}"}, namespace={"inc": lambda x: x + 1})
-        def upper(s): return s.upper()
+        def upper(s):
-    
+
-        
+
-        
+
-        def render(name): return loader.load(name).generate(name="<script>")
+
-        def render(name): return loader.load(name).generate(name='<>&"')
+
-        loader = DictLoader({"foo.py": 
+        loader = DictLoader({"foo.py":
-            return loader.load(template).generate(py_escape=py_escape, 
+            return loader.load(template).generate(py_escape=py_escape,
-        self.io_loop.add_callback(lambda: 1/0)
+        self.io_loop.add_callback(lambda: 1 / 0)
-    def implements(f): pass
+
-    def logPrefix(self): return "Reader"
+    def logPrefix(self):
-    def logPrefix(self): return "Writer"
+    def logPrefix(self):
-
+
-                         {u"path":u"\u00e9",
+                         {u"path": u"\u00e9",
-        self.render("page.html", entries=[1,2])
+        self.render("page.html", entries=[1, 2])
-                1/0
+                1 / 0
-                    1/0
+                    1 / 0
-                    1/0
+                    1 / 0
-                1/0
+                1 / 0
-
+
-        # and its case-normalization is not generally necessary for 
+        # and its case-normalization is not generally necessary for
-
+
-            if k == 'max_age': k = 'max-age'
+            if k == 'max_age':
-        if value is None: value = self.get_cookie(name)
+        if value is None:
-            if embed_part: js_embed.append(utf8(embed_part))
+            if embed_part:
-            if embed_part: css_embed.append(utf8(embed_part))
+            if embed_part:
-            if head_part: html_heads.append(utf8(head_part))
+            if head_part:
-            if body_part: html_bodies.append(utf8(body_part))
+            if body_part:
-        
+
-            if headers: self.request.write(headers, callback=callback)
+            if headers:
-        if chunk is not None: self.write(chunk)
+        if chunk is not None:
-            self.finish("<html><title>%(code)d: %(message)s</title>" 
+            self.finish("<html><title>%(code)d: %(message)s</title>"
-                              for (k,v) in kwargs.iteritems())
+                              for (k, v) in kwargs.iteritems())
-        lines.extend([(utf8(n) + b(": ") + utf8(v)) for n, v in 
+        lines.extend([(utf8(n) + b(": ") + utf8(v)) for n, v in
-                    if self.request.query: uri += "?" + self.request.query
+                    if self.request.query:
-                if self.request.query: uri += "?" + self.request.query
+                if self.request.query:
-        if handlers: self.add_handlers(".*$", handlers)
+        if handlers:
-            for m in methods: self._load_ui_methods(m)
+            for m in methods:
-            for m in modules: self._load_ui_modules(m)
+            for m in modules:
-                            if s is None: return s
+                            if s is None:
-    CACHE_MAX_AGE = 86400*365*10 #10 years
+    CACHE_MAX_AGE = 86400 * 365 * 10  # 10 years
-        
+
-        "text/plain", "text/html", "text/css", "text/xml", "application/javascript", 
+        "text/plain", "text/html", "text/css", "text/xml", "application/javascript",
-    per instantiation of the template, so they must not depend on 
+    per instantiation of the template, so they must not depend on
-        for x, y in zip(a,b):
+        for x, y in zip(a, b):
-    if not value: return None
+    if not value:
-    if len(parts) != 3: return None
+    if len(parts) != 3:
-    for part in parts: hash.update(utf8(part))
+    for part in parts:
-        
+
-        sha1.update(b("258EAFA5-E914-47DA-95CA-C5AB0DC85B11")) # Magic value
+        sha1.update(b("258EAFA5-E914-47DA-95CA-C5AB0DC85B11"))  # Magic value
-        self.stream.read_bytes(4, self._on_masking_key);
+        self._frame_length = struct.unpack("!H", data)[0]
-        self.stream.read_bytes(4, self._on_masking_key);
+        self._frame_length = struct.unpack("!Q", data)[0]
-        if self.client_terminated: return
+        if self.client_terminated:
-* `WSGIApplication` is a version of `tornado.web.Application` that can run 
+* `WSGIApplication` is a version of `tornado.web.Application` that can run
-    do not support flush() or asynchronous methods. 
+    do not support flush() or asynchronous methods.
-                       [(native_str(k), native_str(v)) for (k,v) in headers])
+                       [(native_str(k), native_str(v)) for (k, v) in headers])
-                if values: self.arguments[name] = values
+                if values:
-                boundary = content_type.split('boundary=',1)[1]
+                boundary = content_type.split('boundary=', 1)[1]
-        if not data: raise Exception("WSGI app did not call start_response")
+        if not data:
-        header_set = set(k.lower() for (k,v) in headers)
+        header_set = set(k.lower() for (k, v) in headers)
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-from __future__ import absolute_import, with_statement
+from __future__ import absolute_import, division, with_statement
-        import epoll
+        from tornado import epoll
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement, absolute_import
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-from __future__ import with_statement
+from __future__ import absolute_import, with_statement
-    def __init__(self, async_client_class=None):
+    def __init__(self, async_client_class=None, **kwargs):
-        self._async_client = async_client_class(self._io_loop)
+        self._async_client = async_client_class(self._io_loop, **kwargs)
-        raise ValueError("Client certificate not supported with curl_httpclient")
+    if request.client_cert is not None:
-                                (k, unquote(v))
+                                (str(k), unquote(v))
-        
+        self._read_until(callback)
-        self._add_io_state(self.io_loop.READ)
+        self._read_until(callback)
-        self._add_io_state(self.io_loop.READ)
+        self._read_until(callback)
-                self.write(self.static_url(path))
+                with_v = int(self.get_argument('include_version', 1))
-        class AbsoluteStaticUrlHandler(RequestHandler):
+        class AbsoluteStaticUrlHandler(StaticUrlHandler):
-                self.write(self.static_url(path))
+    def test_relative_version_exclusion(self):
-            def make_static_url(cls, settings, path):
+            def make_static_url(cls, settings, path, include_version=True):
-    def static_url(self, path, include_host=None):
+    def static_url(self, path, include_host=None, include_version=True):
-        file.
+        file. This behavior can be avoided in case the ``include_version``
-            "static_handler_class", StaticFileHandler)
+        get_url = self.settings.get("static_handler_class",
-        return base + static_handler_class.make_static_url(self.settings, path)
+
-    def make_static_url(cls, settings, path):
+    def make_static_url(cls, settings, path, include_version=True):
-        static_url_prefix = settings.get('static_url_prefix', '/static/')
+        url = settings.get('static_url_prefix', '/static/') + path
-        return static_url_prefix + path
+        if not version_hash:
-    doctest.testmod()
+    # The -W command-line option does not work in a virtualenv with
-                                  b("\r\n")]), callback=self.stop)
+                                     b("Content-Length: 1024"),
-        self.wake_callback()
+        if self.get_argument("wake", "true") == "true":
-        response = self.fetch('/hang', request_timeout=0.1)
+        response = self.fetch('/trigger?wake=false', request_timeout=0.1)
-                               curses.tigetstr("setf") or "", "ascii")
+            # The curses module has some str/bytes confusion in
-version = "2.2"
+version = "2.2.post1"
-version_info = (2, 2, 0, 0)
+version = "2.2.post1"
-version = "2.1.1git"
+version = "2.2"
-version_info = (2, 1, 1, 1)
+version = "2.2"
-                           parsed.hostname)
+                           # ipv6 addresses are broken until 2.7, here is
-    True
+    >>> import_object('missing_module')
-            return None
+        return __import__(name, None, None)
-            password = self.request.auth_password
+            password = self.request.auth_password or ''
-    ``gen.engine`` on functions that don't already take a callback argument.
+    ``get``/``post``/etc methods, this means that both the
-        curl.setopt(pycurl.USERPWD, userpwd.encode('ascii'))
+        curl.setopt(pycurl.USERPWD, utf8(userpwd))
-                response = self.fetch('/')
+                # The server simply closes the connection when it gets
-        """Invoked when a new WebSocket is opened."""
+    def open(self):
-        is uncaught.
+        is uncaught.  (Note that this is usually unnecessary thanks to
-        or absolute URL.
+        By default this method returns URLs relative to the current
-        to the static URL - allowing aggressive caching.
+        """Generate the version string to be used in static URLs.
-        ``settings`` is the `Application.settings` dictionary and ```path``
+        ``settings`` is the `Application.settings` dictionary and ``path``
-    def parse_url_path(cls, url_path):
+    def parse_url_path(self, url_path):
-            file.close()
+        with open(abspath, "rb") as file:
-        userpwd = "%s:%s" % (request.auth_username, request.auth_password)
+    if request.auth_username is not None:
-        curl.setopt(pycurl.USERPWD, userpwd)
+        curl.setopt(pycurl.USERPWD, userpwd.encode('ascii'))
-            self.ws_connection.client_terminated = True
+            self.ws_connection.on_connection_close()
-
+        self.server_terminated = False
-        self.stream.close()
+        self.server_terminated = True
-            tornado.ioloop.IOLoop.instance().remove_timeout(self._waiting)
+        if not self.server_terminated:
-                                time.time() + 5, self._abort)
+        elif self._waiting is None:
-        self._started_closing_handshake = False
+        self._waiting = None
-            self.stream.close()
+            self.close()
-        self._waiting = tornado.ioloop.IOLoop.instance().add_timeout(time.time() + 5, self._abort)
+        if not self.server_terminated:
-       default=[])
+       default=["9.*"])
-    app.listen(options.port, address='localhost')
+    app.listen(options.port, address='127.0.0.1')
-        logging.info('starting websocket')
+            self._waiting = None
-        else:
+        elif not self.stream.closed():
-        """Invoked when a new WebSocket requests specific subprotocols."""
+    def select_subprotocol(self, subprotocols):
-            subprotocol = ''
+        # draft76 only allows a single subprotocol
-                    subprotocol=subprotocol))))
+                    subprotocol=subprotocol_header))))
-        subprotocols = self.request.headers.get("Sec-WebSocket-Protocol", None)
+        subprotocol_header = ''
-            subprotocol = ''
+            selected = self.handler.select_subprotocol(subprotocols)
-            "\r\n" % (self._challenge_response(), subprotocol)))
+            "\r\n" % (self._challenge_response(), subprotocol_header)))
-        scheme = "wss" if self.request.protocol == "https" else "ws"
+        scheme = self.handler.get_websocket_scheme()
-    are not reused, and callers cannot select the network interface to be 
+    are not reused, and callers cannot select the network interface to be
-            self._run_callback(HTTPResponse(self.request, 599, error=e, 
+            self._run_callback(HTTPResponse(self.request, 599, error=e,
-                    raise ValueError("Multiple unequal Content-Lengths: %r" % 
+                    raise ValueError("Multiple unequal Content-Lengths: %r" %
-            self.code in (301, 302, 303)):
+            self.code in (301, 302, 303, 307)):
-                    "Content-Encoding", "Transfer-Encoding"]:
+                for h in ["Content-Length", "Content-Type",
-class SeeOther303GetHandler(RequestHandler):    
+class SeeOther303GetHandler(RequestHandler):
-        
+
-       response = self.fetch("/303_post", method="POST", body="")
+       response = self.fetch("/303_post", method="POST", body="blah")
-        
+
-        """Called before the actual handler method.
+        """Called at the beginning of a request before `get`/`post`/etc.
-        all of your requests.
+        Override this method to perform common initialization regardless
-        long-lived connections.
+        Override this to clean up resources associated with
-A twisted-style reactor for the Tornado IOLoop.
+# Note:  This module's docs are not currently extracted automatically,
-To use it, add the following to your twisted application:
+before closing the `IOLoop`.
-from twisted.internet import reactor
+This module has been tested with Twisted versions 11.0.0 and 11.1.0.
-from twisted.python import failure
+from twisted.python import failure, log
-    """
+    """DelayedCall object for Tornado."""
-    Twisted style reactor for Tornado.
+    """Twisted reactor built on the Tornado IOLoop.
-        self._writers = {}
+        self._readers = {}  # map of reader objects to fd
-        self._closed = False
+        # IOLoop.start() bypasses some of the reactor initialization.
-        """
+        """See `twisted.internet.interfaces.IReactorThreads.callFromThread`"""
-	        writer.connectionLost(failure.Failure(error.ConnectionLost()))
+        if reader:
-        """
+        """Add a FileDescriptor for notification of data available to read."""
-        self._readers[reader] = True
+        self._readers[reader] = fd
-        """
+        """Add a FileDescriptor for notification of data available to write."""
-        self._writers[writer] = True
+        self._writers[writer] = fd
-        fd = reader.fileno()
+        """Remove a Selectable for notification of data available to read."""
-            if self._closed: return
+            fd = self._readers.pop(reader)
-        fd = writer.fileno()
+        """Remove a Selectable for notification of data available to write."""
-            if self._closed: return
+            fd = self._writers.pop(writer)
-        self._closed = True
+        self._io_loop.stop()
-        self._closed = True
+        self._io_loop.stop()
-        self._running = True
+        if self._stopped:
-    with the twisted reactor test builder.
+    with the Twisted reactor test builder.
-    """
+    """Install this package as the default Twisted reactor."""
-class ReactorWhenRunningTest(unittest.TestCase):
+class ReactorTestCase(unittest.TestCase):
-        self._reactor = TornadoReactor(IOLoop())
+        self._io_loop = IOLoop()
-
+class ReactorCallLaterTest(ReactorTestCase):
-
+class ReactorTwoCallLaterTest(ReactorTestCase):
-class ReactorCallFromThreadTest(unittest.TestCase):
+class ReactorCallFromThreadTest(ReactorTestCase):
-        self._reactor = TornadoReactor(IOLoop())
+        super(ReactorCallFromThreadTest, self).setUp()
-class ReactorCallInThread(unittest.TestCase):
+class ReactorCallInThread(ReactorTestCase):
-        self._reactor = TornadoReactor(IOLoop())
+        super(ReactorCallInThread, self).setUp()
-class ReactorReaderWriterTest(unittest.TestCase):
+class ReactorReaderWriterTest(ReactorTestCase):
-        self._reactor = TornadoReactor(IOLoop())
+        super(ReactorReaderWriterTest, self).setUp()
-    for test_name in twisted_tests:
+    # available in Twisted 11.0.0 and 11.1.0 (and a blacklist of
-            test = import_object(test_name)
+            test_class = import_object(test_name)
-        globals().update(TornadoTest.makeTestCaseClasses())
+        for test_func in blacklist:
-    curl.setopt(pycurl.TIMEOUT, int(request.request_timeout))
+    curl.setopt(pycurl.CONNECTTIMEOUT_MS, int(1000 * request.connect_timeout))
-version_info = (2, 1, 1)
+version_info = (2, 1, 1, 1)
-                disconnect = connection_header != "Keep-Alive"
+                disconnect = connection_header != "keep-alive"
-        self.assertEqual(response.code, 599)
+if hasattr(ssl, 'PROTOCOL_SSLv2'):
-                                  0, flags):
+    for res in set(socket.getaddrinfo(address, port, family, socket.SOCK_STREAM,
-                                    follow_redirects=options.follow_redirects
+                                    follow_redirects=options.follow_redirects,
-class SSLTest(AsyncHTTPTestCase, LogTrapTestCase):
+class BaseSSLTest(AsyncHTTPTestCase, LogTrapTestCase):
-        super(SSLTest, self).setUp()
+        super(BaseSSLTest, self).setUp()
-                keyfile=os.path.join(test_dir, 'test.key')))
+                keyfile=os.path.join(test_dir, 'test.key'),
-    del SSLTest
+    del BaseSSLTest
-    curl.setopt(pycurl.URL, request.url)
+    curl.setopt(pycurl.URL, utf8(request.url))
-    def __init__(self):
+    def __init__(self, async_client_class=None):
-        self._async_client = AsyncHTTPClient(self._io_loop)
+        if async_client_class is None:
-        conn = RawRequestHTTPConnection(self.io_loop, self.http_client,
+        client = SimpleAsyncHTTPClient(self.io_loop)
-                client = HTTPClient()
+                # Always use SimpleAsyncHTTPClient here; the curl
-   Wikipedia.
+   The WebSocket protocol was recently finalized as `RFC 6455
-    are also supported.
+    JavaScript interface.  The protocol is specified at
-            self.ws_connection = WebSocketProtocol8(self)
+            self.ws_connection = WebSocketProtocol13(self)
-        """Sends the given message to the client of this Web Socket."""
+        """Sends the given message to the client of this Web Socket.
-    """Implementation of the WebSocket protocol, version 8 (draft version 10).
+class WebSocketProtocol13(WebSocketProtocol):
-    http://tools.ietf.org/html/draft-ietf-hybi-thewebsocketprotocol-10
+    This class supports versions 7 and 8 of the protocol in addition to the
-        elif self.request.headers.get("Sec-WebSocket-Version"):
+        elif (self.allow_draft76() and
-        This method must be overloaded
+        This method must be overridden.
-        self.write_message(message)
+        self.write_message(message, binary=isinstance(message, bytes_type))
-    def write_message(self, message):
+    def write_message(self, message, binary=False):
-        self.ws_connection.write_message(message)
+        if isinstance(message, dict):
-    def write_message(self, message):
+    def write_message(self, message, binary=False):
-            message = tornado.escape.json_encode(message)
+        if binary:
-    def write_message(self, message):
+    def write_message(self, message, binary=False):
-        else:
+        if binary:
-    return getattr(obj, parts[-1])
+    def safe_import(*args, **kwargs):
-                    self._cookies = None
+                    self._cookies = {}
-                                    follow_redirects=options.follow_redirects)
+                                    follow_redirects=options.follow_redirects
-            buffer = BytesIO(data) # TODO: don't require one big string?
+        if self._decompressor:
-            # back in the master process; everything worked!
+        try:
-            if not self.__valid_ip(self.remote_ip):
+            if not self._valid_ip(self.remote_ip):
-    def __valid_ip(self, ip):
+    def _valid_ip(self, ip):
-            except socket.error:
+            res = socket.getaddrinfo(ip, 0, socket.AF_UNSPEC,
-
+            raise
-        # no yield, so we're done
+        runner = None
-                    if self.pending_callbacks:
+                    if self.pending_callbacks and not self.had_exception:
-                    self.yield_point.start(self)
+                    try:
-            poll_timeout = 0.2
+            poll_timeout = 3600.0
-        """Sends a redirect to the given (optionally relative) URL."""
+    def redirect(self, url, permanent=False, status=None):
-        self.set_status(301 if permanent else 302)
+        if status is None:
-            loc = self._read_buffer[0].find(self._read_delimiter)
+            # Multi-byte delimiters (e.g. '\r\n') may straddle two
-        self._frame_mask = bytearray(data)
+        self._frame_mask = array.array("B", data)
-        unmasked = bytearray(data)
+        unmasked = array.array("B", data)
-            self._handle_message(opcode, bytes_type(unmasked))
+            self._handle_message(opcode, unmasked.tostring())
-            if self._frame_opcode_is_control:
+        if self._frame_opcode_is_control:
-                self._fragmented_message_buffer += unmasked
+                # can't start new message until the old one is finished
-                    return
+        if self._final_frame:
-    def write_message(self, message, binary=False):
+    def write_message(self, message):
-        if not binary:
+            message = message.encode("utf-8")
-            if self._fragmented_message_buffer:
+            if self._frame_opcode_is_control:
-        
+
-            self.async_callback(self.handler.on_message)(data.decode("utf-8", "replace"))
+            try:
-            if e.errno == socket.EAI_ADDRFAMILY:
+            if e.args[0] == socket.EAI_ADDRFAMILY:
-    # Set the request method through curl's retarded interface which makes
+    # Set the request method through curl's irritating interface which makes
-        # for a simpler, more synchronous style
+        # for a simpler, more synchronous style.
-       is seet, will pass along the protocol used by a load balancer if
+       is set, will pass along the protocol used by a load balancer if
-            import autoreload
+            from tornado import autoreload
-import logging
+import sys
-if __name__ == '__main__':
+def main():
-        tornado.testing.main()
+        unittest.main(defaultTest="all", argv=sys.argv)
-                             "--port=%d" % port
+                             os.path.dirname(os.path.abspath(__file__)),
-    time.sleep(3)
+            
-        proc.wait()
+        # dev_appserver sometimes ignores SIGTERM (especially on 2.5),
-        if (not all(map(lambda f: self.request.headers.get(f), fields))):
+        if not all(map(lambda f: self.request.headers.get(f), fields)):
-        if self.request.headers.get("Connection", "").lower().find('upgrade') == -1:
+        headers = self.request.headers
-           not all(map(lambda f: self.request.headers.get(f), fields)):
+        if not all(map(lambda f: self.request.headers.get(f), fields)):
-            not all(map(lambda f: self.request.headers.get(f), fields))):
+        if (not all(map(lambda f: self.request.headers.get(f), fields))):
-        # Websocket requires GET method
+        # Websocket only supports GET method
-        if self.request.headers.get("Connection", "").lower() != 'upgrade':
+        if self.request.headers.get("Connection", "").lower().find('upgrade') == -1:
-    and 
+    and
-            
+
-            
+
-    
+
-        
+
-        
+
-        
+
-        
+
-from tornado.util import bytes_type
+from tornado.util import bytes_type, ObjectDict
-        reader = _TemplateReader(name, escape.native_str(self.template_string))
+        reader = _TemplateReader(name, escape.native_str(template_string))
-                                                  loader, compress_whitespace)
+        self.code = self._generate_python(loader, compress_whitespace)
-                                    "<template %s>" % self.name, "exec")
+            # Under python2.5, the fake filename used here must match
-            raise exc_type, exc_value, exc_traceback
+            formatted_code = _format_code(self.code).rstrip()
-            return buffer.getvalue(), writer.line_numbers
+            return buffer.getvalue()
-        self.include_stack.append((self.current_template, line+1))
+        self.include_stack.append((self.current_template, line))
-        self._current_line += 1
+        line_comment = '  # %s:%d' % (self.current_template.name, line_number)
-        self.line = 0
+        self.line = 1
-from tornado.util import b, bytes_type, ObjectDict, LogCaptureHandler
+from tornado.testing import LogTrapTestCase
-class TemplateTest(LogTrapTestCase, LogCaptureTestCase):
+class TemplateTest(LogTrapTestCase):
-            self.assertInLog(handler, lambda record: self.assertEqual(record.args[2:], _error_log(loader, "test.html", 2)))
+        try:
-            self.assertInLog(handler, lambda record: self.assertEqual(record.args[2:], _error_log(loader, "test.html", 2)))
+        try:
-                                    _error_log(loader, "sub.html", 1)))
+        try:
-                                _error_log(loader, "sub.html", 1)))
+        try:
-                                _error_log(loader, "base.html", 1)))
+        try:
-                                _error_log(loader, "sub.html", 4)))
+        try:
-
+                path = self.parse_url_path(path)
-                return "/static/%s?v=42" % path
+                version_hash = cls.get_version(settings, path)
-        response = self.fetch("/static/foo.txt")
+        response = self.fetch("/static/foo.42.txt")
-        self.assertEqual(response.body, b("/static/foo.txt?v=42"))
+        self.assertEqual(response.body, b("/static/foo.42.txt"))
-        return hsh
+            hsh = hashes.get(abs_path)
-            return static_url_prefix + path
+            hsh = hashes.get(abs_path)[:5]
-                            ('/abs_static_url/(.*)', AbsoluteStaticUrlHandler)],
+                            ('/abs_static_url/(.*)', AbsoluteStaticUrlHandler),
-    def static_url(self, path):
+    def static_url(self, path, include_host=None):
-        path names.
+        path names. However, in case the "include_host" argument to this
-        if getattr(self, "include_host", False):
+
-       metavar="info|warning|error|none")
+       metavar="debug|info|warning|error|none")
-                    logging.debug("error closing fd %d", fd, exc_info=True)
+                    logging.debug("error closing fd %s", fd, exc_info=True)
-                        logging.error("Exception in I/O handler for fd %d",
+                        logging.error("Exception in I/O handler for fd %s",
-                    logging.error("Exception in I/O handler for fd %d",
+                    logging.error("Exception in I/O handler for fd %s",
-                        poll_timeout = min(milliseconds, poll_timeout)
+                        seconds = self._timeouts[0].deadline - now
-        seed(int(time.time() * 1000) ^ os.getpid())
+        seed = int(time.time() * 1000) ^ os.getpid()
-from tornado.httpserver import HTTPServer
+try:
-
+import threading
-        self.templates = {}
+        with self.lock:
-        return self.templates[name]
+        with self.lock:
-        t = RequestHandler._templates[template_path].load(template_name)
+        with RequestHandler._template_loader_lock:
-                for loader in RequestHandler._templates.values():
+            with RequestHandler._template_loader_lock:
-            RequestHandler._static_hashes = {}
+            StaticFileHandler.reset()
-                hashes[abs_path] = None
+        with cls._lock:
-            return static_url_prefix + path + "?v=" + hashes[abs_path][:5]
+        if hsh:
-            def handle_fetch(self, response)
+            def handle_fetch(self, response):
-extensions = ["sphinx.ext.autodoc", "sphinx_coverage", "sphinx.ext.viewcode"]
+extensions = ["sphinx.ext.autodoc", "sphinx.ext.coverage", "sphinx.ext.viewcode"]
-                self.write(self.get_cookie("foo"))
+                self.write(self.get_cookie("foo", "default"))
-        if name in self.request.cookies:
+        if self.request.cookies is not None and name in self.request.cookies:
-            self.io_loop.add_timeout(self._next_timeout, self._run)
+            self._timeout = self.io_loop.add_timeout(self._next_timeout, self._run)
-        if events | IOLoop.READ and reader:
+        if events & IOLoop.READ and reader:
-        if events | IOLoop.WRITE and writer:
+        if events & IOLoop.WRITE and writer:
-        self._write_buffer.append(data)
+        if data:
-                for h in ["Content-Length", "Content-Type"]:
+                for h in ["Content-Length", "Content-Type", 
-class PRGPostHandler(RequestHandler):
+class SeeOther303PostHandler(RequestHandler):
-        self.set_header("Location", "/prg_get")
+        self.set_header("Location", "/303_get")
-class PRGGetHandler(RequestHandler):    
+class SeeOther303GetHandler(RequestHandler):    
-            url("/prg_get", PRGGetHandler),
+            url("/303_post", SeeOther303PostHandler),
-       response = self.fetch("/prg_post", method="POST", body="")
+       response = self.fetch("/303_post", method="POST", body="")
-       self.assertTrue(response.effective_url.endswith("/prg_get"))
+       self.assertTrue(response.request.url.endswith("/303_post"))
-                                   self._on_body)
+        elif content_length is not None:
-   <http://en.wikipedia.org/wiki/WebSockets#Browser_support>`_ on Wikipedia.
+   The WebSocket protocol is still in development.  This module
-    The older protocol version specified at
+    and 
-    is also supported.
+    are also supported.
-            self.request.headers.get("Sec-WebSocket-Version") == "7"):
+        # The difference between version 8 and 13 is that in 8 the
-    def authenticate_redirect(self):
+    def authenticate_redirect(self, callback_uri = None):
-        http.fetch(self._oauth_request_token_url(), self.async_callback(
+        http.fetch(self._oauth_request_token_url(callback_uri = callback_uri), self.async_callback(
-version = "2.1.1"
+version = "2.1.1git"
-version = "2.1.1"
+version = "2.1.1git"
-version = "2.1git"
+version = "2.1.1"
-version_info = (2, 1, 0)
+version = "2.1.1"
-            while self._next_timeout < current_time:
+            while self._next_timeout <= current_time:
-   See this `browser compatibility table 
+   implements the "hixie-76" and "hybi-10" versions of the protocol.
-            
+
-            
+
-            "Sec-WebSocket-Location: %(scheme)s://%(host)s%(uri)s\r\n\r\n" % (dict(
+            "Sec-WebSocket-Location: %(scheme)s://%(host)s%(uri)s\r\n"
-                    uri=self.request.uri))))
+                    uri=self.request.uri,
-    
+
-            "Sec-WebSocket-Accept: %s\r\n\r\n" % self._challenge_response()))
+            "Sec-WebSocket-Accept: %s\r\n"
-        
+
-        
+
-        
+
-        
+
-            # In non-blocking mode connect() always raises an exception
+            # In non-blocking mode we expect connect() to raise an
-                raise
+                logging.warning("Connect error on fd %d: %s",
-                # ipv6 is not configured on this system, so skip this test
+                # python supports ipv6, but it's not configured on the network
-        assert isinstance(num_bytes, int)
+        assert isinstance(num_bytes, (int, long))
-            self.code in (301, 302)):
+            self.code in (301, 302, 303)):
-        if self._request_finished:
+        # _on_write_complete is enqueued on the IOLoop whenever the
-    ERROR = _EPOLLERR | _EPOLLHUP | _EPOLLRDHUP
+    ERROR = _EPOLLERR | _EPOLLHUP
-                self._add_io_state(0)
+                self._add_io_state(ioloop.IOLoop.READ)
-    def make_iostream_pair(self):
+    def make_iostream_pair(self, **kwargs):
-            streams[0] = IOStream(connection, io_loop=self.io_loop)
+            streams[0] = IOStream(connection, io_loop=self.io_loop, **kwargs)
-        client_stream = IOStream(socket.socket(), io_loop=self.io_loop)
+        client_stream = IOStream(socket.socket(), io_loop=self.io_loop,
-version = "2.1"
+version = "2.1git"
-version = "2.1"
+version = "2.1git"
-                    match = re.match(r"\<template ([^\>]+)\>", filename)
+            exc_type, exc_value, exc_traceback = sys.exc_info()
-                            error_msg += "%s:%i:%s\n"
+                        code_msg = "%s code:\n%s\n\n" + code_msg
-            raise
+                            include_trace_msg += "%s:%i:%s\n"
-from tornado.util import b, bytes_type, ObjectDict
+from tornado.testing import LogCaptureTestCase, LogTrapTestCase
-class TemplateTest(LogTrapTestCase, LogTestCase):
+class TemplateTest(LogTrapTestCase, LogCaptureTestCase):
-        with LogHandler() as handler:
+        with LogCaptureHandler() as handler:
-            self.assertInLog(handler, lambda record: self.assertEqual(record.args[1:], ("test.html", 2, "two{{1/0}}")))
+            self.assertInLog(handler, lambda record: self.assertEqual(record.args[2:], _error_log(loader, "test.html", 2)))
-        with LogHandler() as handler:
+        with LogCaptureHandler() as handler:
-            self.assertInLog(handler, lambda record: self.assertEqual(record.args[1:], ("test.html", 2, "two{%if 1/0%}")))
+            self.assertInLog(handler, lambda record: self.assertEqual(record.args[2:], _error_log(loader, "test.html", 2)))
-        with LogHandler() as handler:
+        with LogCaptureHandler() as handler:
-                                 "sub.html", 1, "{{1/0}}")))
+            self.assertInLog(handler, lambda record: self.assertEqual(record.args[0], "base.html") and
-        with LogHandler() as handler:
+        with LogCaptureHandler() as handler:
-                                 "sub.html", 1, "{{1/0}}")))
+            self.assertInLog(handler, lambda record: self.assertEqual(record.args[2:],
-        with LogHandler() as handler:
+        with LogCaptureHandler() as handler:
-                                ("base.html", 1, "{{1/0}}")))
+            self.assertInLog(handler, lambda record: self.assertEqual(record.args[2:],
-        with LogHandler() as handler:
+        with LogCaptureHandler() as handler:
-                                 "sub.html", 4, "{{1/0}}")))
+            self.assertInLog(handler, lambda record: self.assertEqual(record.args[2:],
-class LogTestCase(unittest.TestCase):
+class LogCaptureTestCase(unittest.TestCase):
-
+from logging.handlers import MemoryHandler
-version = "2.0git"
+version = "2.1"
-version_info = (2, 0, 0)
+version = "2.1"
-        if l <= 126:
+        if l < 126:
-    """
+    r"""A non-blocking, single-threaded HTTP server.
-
+
-                 **kwargs):
+    def __init__(self, request_callback, no_keep_alive=False, io_loop=None,
-        TCPServer.__init__(self, **kwargs)
+        TCPServer.__init__(self, io_loop=io_loop, ssl_options=ssl_options,
-    connections.
+    r"""A non-blocking, single-threaded TCP server.
-       TCPServer(applicaton, ssl_options={
+       TCPServer(ssl_options={
-            server = TCPServer(app)
+            server = TCPServer()
-            server = TCPServer(app)
+            server = TCPServer()
-            server = TCPServer(app)
+            server = TCPServer()
-            if reader[curly + 1] not in ("{", "%"):
+            if reader[curly + 1] not in ("{", "%", "#"):
-    def test_comment(self):
+    def test_comment_directive(self):
-        self.code = self._generate_python(loader, compress_whitespace)
+        reader = _TemplateReader(name, escape.native_str(self.template_string))
-                                    "exec")
+                                    "<template %s>" % self.name, "exec")
-            logging.error("%s code:\n%s", self.name, formatted_code)
+            error_msg = "\n%s\n\n"
-            writer = _CodeWriter(buffer, named_blocks, loader, self,
+            writer = _CodeWriter(buffer, named_blocks, loader, ancestors[0].template,
-            return buffer.getvalue()
+            return buffer.getvalue(), writer.line_numbers
-    def __init__(self, body):
+    def __init__(self, template, body):
-        writer.write_line("def _execute():")
+        writer.write_line("def _execute():", self.line)
-            writer.write_line("_append = _buffer.append")
+            writer.write_line("_buffer = []", self.line)
-            writer.write_line("return _utf8('').join(_buffer)")
+            writer.write_line("return _utf8('').join(_buffer)", self.line)
-    def __init__(self, name, body, template):
+    def __init__(self, name, body, template, line):
-        writer.current_template = old
+        with writer.include(block.template, self.line):
-    def __init__(self, name, reader):
+    def __init__(self, name, reader, line):
-        writer.current_template = old
+        with writer.include(included, self.line):
-    def __init__(self, method, body=None):
+    def __init__(self, method, line, body=None):
-        writer.write_line("def %s():" % method_name)
+        writer.write_line("def %s():" % method_name, self.line)
-            writer.write_line("_append = _buffer.append")
+            writer.write_line("_buffer = []", self.line)
-            writer.write_line("return _utf8('').join(_buffer)")
+            writer.write_line("return _utf8('').join(_buffer)", self.line)
-            self.method, method_name))
+            self.method, method_name), self.line)
-    def __init__(self, statement, body=None):
+    def __init__(self, statement, line, body=None):
-        writer.write_line("%s:" % self.statement)
+        writer.write_line("%s:" % self.statement, self.line)
-    def __init__(self, statement):
+    def __init__(self, statement, line):
-        writer.write_line("%s:" % self.statement, writer.indent_size() - 1)
+        writer.write_line("%s:" % self.statement, self.line, writer.indent_size() - 1)
-    def __init__(self, statement):
+    def __init__(self, statement, line):
-        writer.write_line(self.statement)
+        writer.write_line(self.statement, self.line)
-    def __init__(self, expression, raw=False):
+    def __init__(self, expression, line, raw=False):
-        writer.write_line("_tmp = %s" % self.expression)
+        writer.write_line("_tmp = %s" % self.expression, self.line)
-        writer.write_line("else: _tmp = _utf8(str(_tmp))")
+                          " _tmp = _utf8(_tmp)", self.line)
-        writer.write_line("_append(_tmp)")
+                              writer.current_template.autoescape, self.line)
-        super(_Module, self).__init__("_modules." + expression,
+    def __init__(self, expression, line):
-    def __init__(self, value):
+    def __init__(self, value, line):
-            writer.write_line('_append(%r)' % escape.utf8(value))
+            writer.write_line('_append(%r)' % escape.utf8(value), self.line)
-        return self
+    def indent(self):
-        self._indent -= 1
+        class IncludeTemplate(object):
-    def write_line(self, line, indent=None):
+            def __exit__(_, *args):
-        print >> self.file, line
+        print >> self.file, "    "*indent + line
-                body.chunks.append(_Text(reader.consume()))
+                body.chunks.append(_Text(reader.consume(), reader.line))
-            body.chunks.append(_Text(reader.consume(curly)))
+            cons = reader.consume(curly)
-            body.chunks.append(_Text(start_brace))
+            body.chunks.append(_Text(start_brace, line))
-            body.chunks.append(_Expression(contents))
+            body.chunks.append(_Expression(contents, line))
-            body.chunks.append(_IntermediateControlBlock(contents))
+            body.chunks.append(_IntermediateControlBlock(contents, line))
-                block = _Statement(contents)
+                block = _Statement(contents, line)
-                block = _IncludeBlock(suffix, reader)
+                block = _IncludeBlock(suffix, reader, line)
-                block = _Statement(suffix)
+                block = _Statement(suffix, line)
-                block = _Expression(suffix, raw=True)
+                block = _Expression(suffix, line, raw=True)
-                block = _Module(suffix)
+                block = _Module(suffix, line)
-                block = _ApplyBlock(suffix, block_body)
+                block = _ApplyBlock(suffix, line, block_body)
-                block = _NamedBlock(suffix, block_body, template)
+                block = _NamedBlock(suffix, block_body, template, line)
-                block = _ControlBlock(contents, block_body)
+                block = _ControlBlock(contents, line, block_body)
-from tornado.util import b, bytes_type
+from tornado.testing import LogHandler, LogTestCase, LogTrapTestCase
-class TemplateTest(LogTrapTestCase):
+class TemplateTest(LogTrapTestCase, LogTestCase):
-    def get_authenticated_user(self, callback):
+    def get_authenticated_user(self, callback, http_client=None):
-        http.fetch(url, self.async_callback(
+        if http_client is None: http_client = httpclient.AsyncHTTPClient()
-    def authorize_redirect(self, callback_uri=None, extra_params=None):
+    def authorize_redirect(self, callback_uri=None, extra_params=None,
-        http = httpclient.AsyncHTTPClient()
+        if http_client is None:
-                extra_params=extra_params),
+            http_client.fetch(
-                self._on_request_token, self._OAUTH_AUTHORIZE_URL, callback_uri))
+            http_client.fetch(
-    def get_authenticated_user(self, callback):
+    def get_authenticated_user(self, callback, http_client=None):
-        request_key = self.get_argument("oauth_token")
+        request_key = escape.utf8(self.get_argument("oauth_token"))
-        cookie_key, cookie_secret = [base64.b64decode(i) for i in request_cookie.split("|")]
+        cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split("|")]
-            self._on_access_token, callback))
+            token["verifier"] = oauth_verifier
-            base64.b64encode(request_token["secret"])])
+        data = (base64.b64encode(request_token["key"]) + b("|") +
-    key = "&".join(key_elems)
+    key_elems = [escape.utf8(consumer_token["secret"])]
-    hash = hmac.new(key, base_string, hashlib.sha1)
+    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)
-    key = "&".join(key_elems)
+    key_elems = [escape.utf8(urllib.quote(consumer_token["secret"], safe='~'))]
-    hash = hmac.new(key, base_string, hashlib.sha1)
+    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)
-    token = dict(key=p["oauth_token"][0], secret=p["oauth_token_secret"][0])
+    p = escape.parse_qs(body, keep_blank_values=False)
-    special = ("oauth_token", "oauth_token_secret")
+    special = (b("oauth_token"), b("oauth_token_secret"))
-from tornado import netutil
+from tornado.netutil import TCPServer
-        TCPServer.__init__(self, self._handle_stream, **kwargs)
+        TCPServer.__init__(self, **kwargs)
-    def _handle_stream(self, stream, address):
+    def handle_stream(self, stream, address):
-a list of results will be returned when they are all finished::
+`Task` works with any function that takes a ``callback`` keyword
-        self.runner.set_result(self.key, arg)
+        return self.runner.result_callback(self.key)
-        self.func = functools.partial(func, *args, **kwargs)
+        self.args = args
-        self.func()
+        self.kwargs["callback"] = runner.result_callback(self.key)
-
+    def result_callback(self, key):
-interfaces, `Task` can be split into two parts: `Callback` and `Wait`::
+(and runs that callback with zero or one arguments).  You can also yield
-operations have started.
+asynchronous operations to be started at different times and proceed
-       outright given that it can be easily forged.
+       names to lists of :class:`HTTPFile`.
-            files.setdefault(name, []).append(dict(
+            files.setdefault(name, []).append(HTTPFile(
-                     "filename": self.request.files["files"][0]["filename"],
+                     "filename": self.request.files["files"][0].filename,
-from tornado.util import b
+from tornado.util import b, ObjectDict
-from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature
+from tornado.util import b, bytes_type, ObjectDict
-        self.application = _O(settings=dict(cookie_secret='0123456789'))
+        self.application = ObjectDict(settings=dict(cookie_secret='0123456789'))
-from tornado.util import b, bytes_type, import_object
+from tornado.util import b, bytes_type, import_object, ObjectDict
-        self.ui = _O((n, self._ui_method(m)) for n, m in
+        self.ui = ObjectDict((n, self._ui_method(m)) for n, m in
-        self.ui["_modules"] = _O((n, self._ui_module(n, m)) for n, m in
+        self.ui["_modules"] = ObjectDict((n, self._ui_module(n, m)) for n, m in
-        self[name] = value
+
-    waiters = []
+    waiters = set()
-        cls.waiters.append(callback)
+        cls.waiters.add(callback)
-        cls.waiters = []
+        cls.waiters = set()
-        self.wait_for_messages(self.async_callback(self.on_new_messages),
+        self.wait_for_messages(self.on_new_messages,
-from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler
+from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler, _create_signature
-                                                   timestamp), sig)
+        self.assertEqual(
-            handler._cookie_signature('foo', '1234', b('5678') + timestamp),
+            _create_signature(handler.application.settings["cookie_secret"],
-        return value
+        self.require_setting("cookie_secret", "secure cookies")
-        return utf8(hash.hexdigest())
+        if value is None: value = self.get_cookie(name)
-    We support three methods: write(), read_until(), and read_bytes().
+    We support a non-blocking ``write()`` and a family of ``read_*()`` methods.
-    of bytes have been read from the socket.
+    non-blocking and asynchronous). 
-        """Call callback when we read the given number of bytes."""
+    def read_bytes(self, num_bytes, callback, streaming_callback=None):
-    def read_until_close(self, callback):
+    def read_until_close(self, callback, streaming_callback=None):
-        Subject to ``max_buffer_size`` limit from `IOStream` constructor.
+        If a ``streaming_callback`` is given, it will be called with chunks
-    r"""A non-blocking, single-threaded HTTP server.
+class TCPServer(object):
-    HTTPServer can serve HTTPS (SSL) traffic with Python 2.6+ and OpenSSL.
+    `TCPServer` can serve SSL traffic with Python 2.6+ and OpenSSL.
-    argument with the arguments required for the ssl.wrap_socket() method,
+    argument with the arguments required for the `ssl.wrap_socket` method,
-       HTTPServer(applicaton, ssl_options={
+       TCPServer(applicaton, ssl_options={
-    HTTPServer initialization follows one of three patterns:
+    `TCPServer` initialization follows one of three patterns:
-            server = HTTPServer(app)
+            server = TCPServer(app)
-            server = HTTPServer(app)
+            server = TCPServer(app)
-       the server on the default singleton ``IOLoop``.
+       When using this interface, an `IOLoop` must *not* be passed
-            server = HTTPServer(app)
+            server = TCPServer(app)
-       flexibility in when the fork happens.  ``add_sockets`` can
+       flexibility in when the fork happens.  `add_sockets` can
-        self.no_keep_alive = no_keep_alive
+    def __init__(self, handle_stream, io_loop=None, ssl_options=None):
-        the ``IOLoop``.
+        `listen` takes effect immediately; it is not necessary to call
-        ``add_sockets`` is typically used in combination with that
+        `add_sockets` is typically used in combination with that
-        sequence of bind() and start() calls.
+        To start the server, call `start`. If you want to run this server
-        or socket.AF_INET6 to restrict to ipv4 or ipv6 addresses, otherwise
+        available interfaces.  Family may be set to either ``socket.AF_INET``
-        ``socket.listen()``.
+        `socket.listen`.
-        This method may be called multiple times prior to start() to listen
+        This method may be called multiple times prior to `start` to listen
-        If num_processes is None or <= 0, we detect the number of cores
+        If num_processes is ``None`` or <= ``0``, we detect the number of cores
-        processes. If num_processes is given and > 1, we fork that
+        processes. If num_processes is given and > ```1``, we fork that
-        module (or the debug=True option to tornado.web.Application).
+        module (or the ``debug=True`` option to `tornado.web.Application`).
-        referenced until after the call to HTTPServer.start(n).
+        referenced until after the call to ``TCPServer.start(n)``.
-                           self.no_keep_alive, self.xheaders)
+            self.handle_stream(stream, address)
-        user = self._oauth_get_user(access_token, self.async_callback(
+        self._oauth_get_user(access_token, self.async_callback(
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase, get_unused_port
+from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
-import os
+import sys
-        self.waiting = None
+        self.finished = False
-        if self.running:
+        if self.running or self.finished:
-                next = self.yield_point.get_result()
+                if self.exc_info is None:
-                    yielded = self.gen.send(next)
+                    if self.exc_info is not None:
-                self.yield_point.start(self)
+                except Exception:
-        May be called repeatedly until it returns True.
+        Returns a boolean; may be called more than once.
-                    self.stream.write("HTTP/1.1 100 (Continue)\r\n\r\n")
+                    self.stream.write(b("HTTP/1.1 100 (Continue)\r\n\r\n"))
-from tornado.escape import json_decode, utf8, _unicode, recursive_unicode
+from tornado.escape import json_decode, utf8, _unicode, recursive_unicode, native_str
-        return Application([("/multipart", MultipartTestHandler)])
+        return Application(self.get_handlers())
-from tornado.test.httpserver_test import HTTPConnectionTest, MultipartTestHandler
+from tornado.test.httpserver_test import HTTPConnectionTest
-                        ("/multipart", MultipartTestHandler)])))
+        return WSGIContainer(validator(WSGIApplication(self.get_handlers())))
-                                                          self._called)
+        self._timeout = self._reactor._io_loop.add_timeout(self._time,
-        self._reactor._ioloop.remove_timeout(self._timeout)
+        self._reactor._io_loop.remove_timeout(self._timeout)
-        self._reactor._ioloop.remove_timeout(self._timeout)
+        self._reactor._io_loop.remove_timeout(self._timeout)
-                                                          self._called)
+        self._timeout = self._reactor._io_loop.add_timeout(self._time,
-        self._reactor._ioloop.remove_timeout(self._timeout)
+        self._reactor._io_loop.remove_timeout(self._timeout)
-                                                          self._called)
+        self._timeout = self._reactor._io_loop.add_timeout(self._time,
-        self._ioloop = ioloop
+    def __init__(self, io_loop=None):
-        self._ioloop.add_callback(p)
+        self._io_loop.add_callback(p)
-                self._ioloop.update_handler(fd, IOLoop.READ | IOLoop.WRITE)
+                self._io_loop.update_handler(fd, IOLoop.READ | IOLoop.WRITE)
-                self._ioloop.add_handler(fd, self._invoke_callback,
+                self._io_loop.add_handler(fd, self._invoke_callback,
-                self._ioloop.update_handler(fd, IOLoop.READ | IOLoop.WRITE)
+                self._io_loop.update_handler(fd, IOLoop.READ | IOLoop.WRITE)
-                self._ioloop.add_handler(fd, self._invoke_callback,
+                self._io_loop.add_handler(fd, self._invoke_callback,
-                self._ioloop.update_handler(fd, IOLoop.WRITE)
+                self._io_loop.update_handler(fd, IOLoop.WRITE)
-                self._ioloop.remove_handler(fd)
+                self._io_loop.remove_handler(fd)
-                self._ioloop.update_handler(fd, IOLoop.READ)
+                self._io_loop.update_handler(fd, IOLoop.READ)
-                self._ioloop.remove_handler(fd)
+                self._io_loop.remove_handler(fd)
-            self._ioloop.close()
+            self._io_loop.stop()
-            self._ioloop.close()
+            self._io_loop.stop()
-        self._ioloop.start()
+        self._io_loop.start()
-def install(ioloop=None):
+def install(io_loop=None):
-    reactor = TornadoReactor(ioloop)
+    if not io_loop:
-            response = yield gen.Task(http_client.fetch("http://example.com"))
+            response = yield gen.Task(http_client.fetch, "http://example.com")
-        os.environ["PYTHONPATH"] = ".:" + os.environ.get("PYTHONPATH", "")
+        not os.environ.get("PYTHONPATH", "").startswith(path_prefix)):
-            stream.write(b("""\
+        with closing(sock):
-        self.assertEqual(resp.body, b("12"))
+            def accept_callback(conn, address):
-if os.name != 'posix':
+if os.name != 'posix' or sys.platform == 'cygwin':
-        self.assertEqual(int(response.request_time * 10), 1)
+        self.assertTrue(0.099 < response.request_time < 0.11, response.request_time)
-import sys
+    import fcntl
-                self._connect_timeout = self.io_loop.add_timeout(
+                self._timeout = self.io_loop.add_timeout(
-            self.io_loop.remove_callback(self._timeout)
+            self.io_loop.remove_timeout(self._timeout)
-           multiple=False):
+           multiple=False, group=None):
-                            multiple=multiple)
+                            multiple=multiple, group_name=group_name)
-    by_file = {}
+    by_group = {}
-        by_file.setdefault(option.file_name, []).append(option)
+        by_group.setdefault(option.group_name, []).append(option)
-    for filename, o in sorted(by_file.items()):
+    for filename, o in sorted(by_group.items()):
-                 multiple=False, file_name=None):
+                 multiple=False, file_name=None, group_name=None):
-        # fixes thath behavior.
+        # arguments and executable name if they contain whitespaces. subprocess
-                  [sys.executable] + sys.argv)
+    if sys.platform == 'win32':
-            self._run_callback(HTTPResponse(self.request, 599, error=e))
+            self._run_callback(HTTPResponse(self.request, 599, error=e, 
-        "text/plain", "text/html", "text/css", "text/xml",
+        "text/plain", "text/html", "text/css", "text/xml", "application/javascript", 
-        writer.write_line("_buffer.append(%s(%s()))" % (
+        writer.write_line("_append(%s(%s()))" % (
-        writer.write_line("_buffer.append(_tmp)")
+        writer.write_line("_append(_tmp)")
-            writer.write_line('_buffer.append(%r)' % escape.utf8(value))
+            writer.write_line('_append(%r)' % escape.utf8(value))
-translated exactly into Python, do you can do complex expressions like::
+translated exactly into Python, you can do complex expressions like::
-            self.deadline = time.time() + deadline.total_seconds()
+            self.deadline = time.time() + _Timeout.timedelta_to_seconds(deadline)
-        self.stream.read_until(b("\r\n\r\n"), self._on_headers)
+        self.stream.read_until_regex(b("\r?\n\r?\n"), self._on_headers)
-        first_line, _, header_data = data.partition("\r\n")
+        first_line, _, header_data = data.partition("\n")
-                                                  key, callback),
+                                functools.partial(self._release_fetch, key),
-    def _on_fetch_complete(self, key, callback, response):
+    def _release_fetch(self, key):
-    def __init__(self, io_loop, client, request, callback, max_buffer_size):
+    def __init__(self, io_loop, client, request, release_callback,
-        self.callback = callback
+        self.release_callback = release_callback
-            callback(response)
+        self._release()
-            self.client.fetch(new_request, callback)
+            final_callback = self.final_callback
-                                        self.stop, 1024*1024)
+                                        None, self.stop,
-    def __init__(self, autoescape=_DEFAULT_AUTOESCAPE):
+    def __init__(self, autoescape=_DEFAULT_AUTOESCAPE, namespace=None):
-        
+
-        response = self.fetch("/typecheck?foo=bar")
+        headers = {"Cookie": "foo=bar"}
-        response = self.fetch("/typecheck", method="POST", body="foo=bar")
+        response = self.fetch("/typecheck", method="POST", body="foo=bar", headers=headers)
-            return self.cookies[name].value
+        if name in self.request.cookies:
-        for name in self.cookies.iterkeys():
+        for name in self.request.cookies.iterkeys():
-            ] + handlers
+            static_handler_args = settings.get("static_handler_args", {})
-from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous, url, HTTPError
+from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous, url, HTTPError, StaticFileHandler
-        return Application([('/static_url/(.*)', StaticUrlHandler)],
+        class AbsoluteStaticUrlHandler(RequestHandler):
-            return base + static_url_prefix + path + "?v=" + hashes[abs_path][:5]
+        static_handler_class = self.settings.get(
-            return base + static_url_prefix + path
+            base = ""
-    for the StaticFileHandler below::
+    for the StaticFileHandler below (note that a StaticFileHandler
-                (re.escape(static_url_prefix) + r"(.*)", StaticFileHandler,
+                (re.escape(static_url_prefix) + r"(.*)", static_handler_class,
-                (r"/(robots\.txt)", StaticFileHandler, dict(path=path)),
+                (r"/(favicon\.ico)", static_handler_class, dict(path=path)),
-        "tornado.test": ["README", "test.crt", "test.key"],
+        "tornado.test": ["README", "test.crt", "test.key", "static/robots.txt"],
-            "openid.realm": self.request.protocol + "://" + self.request.host + "/",
+            "openid.realm": urlparse.urljoin(url, '/'),
-   only by Chrome and Safari.  See this `browser compatibility table 
+   implements the "hixie-76" and "hybi-10" versions of the protocol.  
-    See http://www.w3.org/TR/2009/WD-websockets-20091222/ for details on the
+    See http://dev.w3.org/html5/websockets/ for details on the
-    callback = functools.partial(_reload_on_update, io_loop, modify_times)
+    callback = functools.partial(_reload_on_update, modify_times)
-    global _reload_attempted
+def _reload_on_update(modify_times):
-        _check_file(io_loop, modify_times, path)
+        _check_file(modify_times, path)
-        _check_file(io_loop, modify_times, path)
+        _check_file(modify_times, path)
-                sys.exit(0)
+def _check_file(modify_times, path):
-        self.deadline = deadline
+        if isinstance(deadline, (int, long, float)):
-                raise ValueError("Unsafe header value %r", value)
+        if isinstance(value, bytes_type):
-            value = str(value)
+            return email.utils.formatdate(t, localtime=False, usegmt=True)
-        self._headers[name] = value
+        return value
-        lines.extend([(utf8(n) + b(": ") + utf8(v)) for n, v in self._headers.iteritems()])
+        lines.extend([(utf8(n) + b(": ") + utf8(v)) for n, v in 
-    if sys.path[0] == '':
+    # Conversely, when run as path/to/tornado/autoreload.py, the directory
-            if end == -1 or reader.find("\n", 0, end) != -1:
+            if end == -1:
-        if end == -1 or reader.find("\n", 0, end) != -1:
+        if end == -1:
-                                                      application.ui_modules.iteritems())
+        # UIModules are available as both `modules` and `_modules` in the
-            self._next_timeout += self.callback_time / 1000.0
+            current_time = time.time()
-    def instance(cls):
+    @staticmethod
-        return cls._instance
+        if not hasattr(IOLoop, "_instance"):
-    def initialized(cls):
+    @staticmethod
-        return hasattr(cls, "_instance")
+        return hasattr(IOLoop, "_instance")
-CONVERSIONS = copy.deepcopy(MySQLdb.converters.conversions)
+CONVERSIONS = copy.copy(MySQLdb.converters.conversions)
-    CONVERSIONS[field_type].insert(0, (FLAG.BINARY, str))
+    CONVERSIONS[field_type] = [(FLAG.BINARY, str)] + CONVERSIONS[field_type]
-        super(_Module, self).__init__("modules." + expression,
+        super(_Module, self).__init__("_modules." + expression,
-                                application.ui_modules.iteritems())
+        self.ui["modules"] = self.ui["_modules"] = _O((n, self._ui_module(n, m)) for n, m in
-        self.io_loop.add_timeout(timeout, self._run)
+        self._next_timeout = time.time()
-            self.start()
+            self._next_timeout += self.callback_time / 1000.0
-import xml.sax.saxutils
+_XHTML_ESCAPE_RE = re.compile('[&<>"]')
-    return xml.sax.saxutils.escape(to_basestring(value), {'"': "&quot;"})
+    return _XHTML_ESCAPE_RE.sub(lambda match: _XHTML_ESCAPE_DICT[match.group(0)],
-            self.callback = None
+        self._run_callback(HTTPResponse(self.request, 599,
-            self.client.fetch(new_request, self.callback)
+            callback = self.callback
-            self.compiled = compile(self.code, "<template %s>" % self.name,
+            self.compiled = compile(escape.to_unicode(self.code),
-                                        self.stop)
+                                        self.stop, 1024*1024)
-                   hostname_mapping=None):
+                   hostname_mapping=None, max_buffer_size=104857600):
-                                                  key, callback))
+                                                  key, callback),
-    def __init__(self, io_loop, client, request, callback):
+    def __init__(self, io_loop, client, request, callback, max_buffer_size):
-                                          ssl_options=ssl_options)
+                                          ssl_options=ssl_options,
-                                       io_loop=self.io_loop)
+                                       io_loop=self.io_loop,
-                callback(HTTPResponse(self.request, 599, error=e))
+            self._run_callback(HTTPResponse(self.request, 599, error=e))
-                                  error=HTTPError(599, "Connection closed")))
+        self._run_callback(HTTPResponse(
-        self.callback(response)
+        self._run_callback(response)
-        self.callback = None
+        self.stream.close()
-                self._run_callback(self._close_callback)
+            if self._close_callback and self._pending_callbacks == 0:
-            self._add_io_state(0)
+            if self.socket is None:
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.iostream import IOStream
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase, get_unused_port
+from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
-from tornado.web import Application, RequestHandler, asynchronous, url
+from tornado.web import Application, RequestHandler, url
-
+from __future__ import with_statement
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.test.httpclient_test import HTTPClientCommonTestCase, ChunkHandler, CountdownHandler, HelloWorldHandler
-            ])
+            url("/chunk", ChunkHandler),
-    _async_clients = weakref.WeakKeyDictionary()
+    @classmethod
-            return cls._async_clients[io_loop]
+        if cls is AsyncHTTPClient:
-                cls._async_clients[io_loop] = instance
+                impl._async_clients()[io_loop] = instance
-            del self._async_clients[self.io_loop]
+        if self._async_clients().get(self.io_loop) is self:
-        return CurlAsyncHTTPClient(io_loop=self.io_loop)
+        client = CurlAsyncHTTPClient(io_loop=self.io_loop)
-                                     force_instance=True)
+        client = SimpleAsyncHTTPClient(io_loop=self.io_loop,
-            finbit = 0b10000000
+            finbit = 0x80
-        if not (payloadlen & 0b10000000):
+        self._final_frame = header & 0x80
-        payloadlen = payloadlen & 0b1111111
+        payloadlen = payloadlen & 0x7f
-        return base64.b64encode(sha1.digest())
+        sha1.update(tornado.escape.utf8(
-tornado.platform.twistedreactor.install()
+import tornado.platform.twisted
-        # import tornado.platform.twistedreactor # depends on twisted
+        # import tornado.platform.twisted # depends on twisted
-    'tornado.test.twistedreactor_test',
+    'tornado.test.twisted_test',
-    from tornado.platform.twistedreactor import TornadoReactor
+    from tornado.platform.twisted import TornadoReactor
-            _reactors = ["tornado.platform.twistedreactor._TestReactor"]
+            _reactors = ["tornado.platform.twisted._TestReactor"]
-    def __init__(self, ioloop):
+    def __init__(self, ioloop=None):
-        if self.request.headers.get("Sec-WebSocket-Version") == "8":
+        if (self.request.headers.get("Sec-WebSocket-Version") == "8" or
-        self.assertEqual(self._thread.ident, thread.get_ident())
+        self.assertNotEqual(self._mainThread, thread.get_ident())
-            self._write_frame(True, 0xA, b(""))
+            self._write_frame(True, 0xA, data)
-        self.on_close()
+        if self.ws_connection:
-        self.set_extra_headers(path, modified, mime_type)
+        self.set_extra_headers(path)
-    def set_extra_headers(self, path, modified, mime_type):
+    def set_extra_headers(self, path):
-
+    def close(self):
-        self._fd.close()
+        self.close()
-        self._fd.close()
+        self.close()
-        # unintended effects.
+        # Test that adding the reader twice adds it only once to
-        self._reactor.removeReader(self._reader)
+    def _testNoWriter(self):
-tornado.twisted.reactor.install()
+import tornado.platform.twistedreactor
-import errno, functools, sys
+import functools
-            print "reactor.py _called caught exception: %s" % sys.exc_info()[0]
+            logging.error("_called caught exception", exc_info=True)
-        # self._waker = None
+        self._running = False
-            self._ioloop.add_handler(fd, self._invoke_callback, IOLoop.READ)
+            with NullContext():
-            self._ioloop.add_handler(fd, self._invoke_callback, IOLoop.WRITE)
+            with NullContext():
-        self._ioloop.stop()
+        try:
-        self._ioloop.stop()
+        try:
-        self.running = True
+        self._running = True
-from tornado.platform.auto import Waker
+try:
-log.startLogging(sys.stdout)
+from tornado.platform.auto import set_close_exec
-        self.assertGreater(self._called - self._now, self._timeout)
+        self.assertTrue(self._called - self._now > self._timeout)
-        self.assertGreater(self._called2 - self._now, self._timeout2)
+        self.assertTrue(self._called1 - self._now > self._timeout1)
-        self.assertEqual(self._thread, thread.get_ident())
+    def tearDown(self):
-        self._thread = thread.start_new_thread(self._newThreadRun, (None, None))
+        self._thread = threading.Thread(target=self._newThreadRun)
-        return
+        self._fd.close()
-        return
+        self._fd.close()
-        self._set_close_exec(w)
+        set_close_exec(r)
-            self.assertTrue(fd.read().startswith('x'))
+            self.assertEquals(fd.read(), 'x')
-        self._writer = Writer(self._p2, lambda fd: fd.write('x'))
+        self._writer = Writer(self._p2, writeOnce)
-        self._reactor.removeReader(self._writer)
+        # Test that adding and removing the reader doesn't cause
-        self._reactor.removeWriter(self._reader)
+if twisted is None:
-        _state.contexts = (self.old_contexts + 
+        _state.contexts = (self.old_contexts +
-    '''Returns a callable object that will resore the current StackContext
+    '''Returns a callable object that will restore the current StackContext
-    def write(self, chunk):
+    def write(self, chunk, callback=None):
-    def write(self, chunk):
+    def write(self, chunk, callback=None):
-        self.connection.write(chunk)
+        self.connection.write(chunk, callback=callback)
-        """Flushes the current output buffer to the network."""
+    def flush(self, include_footers=False, callback=None):
-            if headers: self.request.write(headers)
+            if headers: self.request.write(headers, callback=callback)
-            self.request.write(headers + chunk)
+            self.request.write(headers + chunk, callback=callback)
-            logging.error("WebSocket protocol 8 request!")
+
-        self._receive_message()
+        if ("Sec-WebSocket-Version" in self.request.headers and
-        self.stream.write(b("\x00") + message + b("\xff"))
+        self.ws_connection.write_message(message)
-                                time.time() + 5, self._abort)
+        self.ws_connection.close()
-        Catches exceptions properly and closes this Web Socket if an exception
+        Catches exceptions properly and closes this WebSocket if an exception
-    """A single WebSocket request.
+class WebSocketProtocol76(WebSocketProtocol):
-        self.request = request
+    def __init__(self, handler):
-        self._handle_websocket_headers()
+        self._waiting = None
-        """Generates the challange response that's needed in the handshake
+        """Generates the challenge response that's needed in the handshake
-    /static/images/myimage.png?v=xxx.
+    /static/images/myimage.png?v=xxx. Override ``get_cache_time`` method for
-        self.set_extra_headers(path)
+        cache_time = self.get_cache_time(path, modified, mime_type)
-    def set_extra_headers(self, path):
+    def set_extra_headers(self, path, modified, mime_type):
-        return "v" in self.request.arguments
+    def get_cache_time(self, path, modified, mime_type):
-    'tornado.test.twistedreactor_test',
+    'tornado.test.twistedreactor_test',
-
+from tornado.ioloop import IOLoop
-        self._reactor = TornadoReactor()
+        self._reactor = TornadoReactor(IOLoop())
-        self._reactor = TornadoReactor()
+        self._reactor = TornadoReactor(IOLoop())
-        self._reactor = TornadoReactor()
+        self._reactor = TornadoReactor(IOLoop())
-        self._reactor = TornadoReactor()
+        self._reactor = TornadoReactor(IOLoop())
-        self._reactor = TornadoReactor()
+        self._reactor = TornadoReactor(IOLoop())
-        self._reactor = TornadoReactor()
+        self._reactor = TornadoReactor(IOLoop())
-            self.assertEqual(fd.read(), 'x')
+            self.assertTrue(fd.read().startswith('x'))
-    def __init__(self, ioloop=tornado.ioloop.IOLoop.instance()):
+    def __init__(self, ioloop):
-def install(ioloop=tornado.ioloop.IOLoop.instance()):
+def install(ioloop=None):
-# System imports
+# Author: Ovidiu Predescu
-
+from tornado.platform.auto import Waker
-import unittest
+    def _set_close_exec(self, fd):
-        self._reactor._ioloop._set_close_exec(w)
+        self._set_nonblocking(r)
-            self._callbacks = []
+            with self._callback_lock:
-        if not self._callbacks and thread.get_ident() != self._thread_ident:
+        with self._callback_lock:
-            "groups in url regexes must either be all named or all positional"
+            ("groups in url regexes must either be all named or all "
-        self.add(name, value.strip())
+        if line[0].isspace():
-from tornado.httputil import url_concat, parse_multipart_form_data
+from tornado.httputil import url_concat, parse_multipart_form_data, HTTPHeaders
-                ("/set_domain", SetCookieDomainHandler)])
+                ("/set_domain", SetCookieDomainHandler),
-            self._cookies = Cookie.BaseCookie()
+            self._cookies = Cookie.SimpleCookie()
-        new_cookie = Cookie.BaseCookie()
+        new_cookie = Cookie.SimpleCookie()
-           not part.endswith(b("\r\n")):
+        disp_header = headers.get("Content-Disposition", "")
-        if not name_values.get("name"):
+        if not disp_params.get("name"):
-        if name_values.get("filename"):
+        name = disp_params["name"]
-                filename=name_values["filename"], body=value,
+                filename=disp_params["filename"], body=value,
-                    b(""),
+                    b("--1234567890--"),
-from tornado.httputil import url_concat
+from tornado.httputil import url_concat, parse_multipart_form_data
-        if locale not in LOCALE_NAMES:
+        if not re.match("[a-z]+(_[A-Z]+)?$", locale):
-    def xxx_test_default_certificates_exist(self):
+    def test_default_certificates_exist(self):
-            assert self.request.body is not None
+        if not self.request.allow_nonstandard_methods:
-            assert self.request.body is None
+                    self.request.body))
-        if has_body:
+        if self.request.body is not None:
-                                     ioloop.IOLoop.READ)
+            netutil.add_accept_handler(sock, self._handle_connection,
-        while True:
+    def _handle_connection(self, connection, address):
-                    stream = iostream.SSLIOStream(connection, io_loop=self.io_loop)
+                connection = ssl.wrap_socket(connection,
-                logging.error("Error in connection callback", exc_info=True)
+                    raise
-        if "v" in self.request.arguments:
+
-from tornado import httpclient, simple_httpclient
+from tornado import httpclient, simple_httpclient, netutil
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase, AsyncTestCase
-        assert self.request.protocol == "https"
+        assert self.request.protocol == self.expected_protocol
-        return Application([('/', HelloWorldRequestHandler)])
+        return Application([('/', HelloWorldRequestHandler, 
-                        args = [unquote(s) for s in match.groups()]
+                    if spec.regex.groups:
-# python -c 'import pstats; pstats.Stats("/tmp/prof").strip_dirs().sort_stats("time").print_callers(20)'
+# python -m pstats /tmp/prof
-define("n", type=int, default=10000)
+# Increasing --n without --keepalive will eventually run into problems
-    app.listen(options.port)
+    port = random.randrange(options.min_port, options.max_port)
-    proc = subprocess.Popen(args)
+    if options.quiet:
-    packages = ["tornado", "tornado.test"],
+    packages = ["tornado", "tornado.test", "tornado.platform"],
-            self._gzip_pos += len(chunk)
+            self._gzip_value.truncate(0)
-            self._add_io_state(0)
+        self._maybe_add_error_listener()
-                self._add_io_state(0)
+            self._maybe_add_error_listener()
-        self._add_io_state(self.io_loop.WRITE)
+        self._handle_write()
-                self.socket.fileno(), self._handle_events, self._state)
+        self._state = None
-            self.io_loop.remove_handler(self.socket.fileno())
+            if self._state is not None:
-        if not self._state & state:
+        if self._state is None:
-import functools
+import logging
-from tornado.httpclient import HTTPClient
+from tornado.httpclient import HTTPClient, HTTPError
-                            os._exit, int(self.get_argument("exit"))))
+                    os._exit(int(self.get_argument("exit")))
-                            int(self.get_argument("signal"))))
+                    os.kill(os.getpid(),
-            client = HTTPClient()
+        try:
-            client.fetch(get_url("/?exit=3"))
+                def fetch(url, fail_ok=False):
-            #int(client.fetch(get_url("/")).body)
+                # Make two processes exit abnormally
-            self.assertNotEqual(pid, pid2)
+                # They've been restarted, so a new fetch will work
-            os._exit(0)
+                # Now the same with signals
-                {'y':'y', 'z':'z'},
+                [('y','y'), ('z','z')],
-                {'y':'/y', 'z':'z'},
+                [('y','/y'), ('z','z')],
-                {'y':'y', 'z':'z'},
+                [('y','y'), ('z','z')],
-                {'y':'y', 'z':'z'},
+                [('y','y'), ('z','z')],
-                {'y':'y', 'z':'z'},
+                [('y','y'), ('z','z')],
-                {'y':'y', 'z':'z'},
+                [('y','y'), ('z','z')],
-            {},
+            [],
-    def __init__(self, root_directory, autoescape=_DEFAULT_AUTOESCAPE):
+    def __init__(self, autoescape=_DEFAULT_AUTOESCAPE):
-        return name
+        raise NotImplementedError()
-        super(Loader, self).__init__(root_directory, **kwargs)
+        super(Loader, self).__init__(**kwargs)
-        super(DictLoader, self).__init__("", **kwargs)
+        super(DictLoader, self).__init__(**kwargs)
-    
+from tornado.platform.auto import set_close_exec, Waker
-        self.add_handler(r, self._read_waker, self.READ)
+        self._waker = Waker()
-        self._waker_writer.close()
+        self._waker.close()
-        self._wake()
+        self._waker.wake()
-            self._wake()
+            self._waker.wake()
-    from .windows import set_close_exec
+    from tornado.platform.windows import set_close_exec, Waker
-    from .posix import set_close_exec
+    from tornado.platform.posix import set_close_exec, Waker
-class Pipe(object):
+class Waker(interface.Waker):
-        """Emulate a file descriptors read method"""
+    def fileno(self):
-            raise
+            while True:
-        return self.writer.send(data)
+    def close(self):
-        from tornado.platform import windows as fcntl
+    
-            self._set_close_exec(self._impl.fileno())
+            set_close_exec(self._impl.fileno())
-            self._set_close_exec(w)
+            set_close_exec(r)
-        raise
+from tornado.platform.auto import set_close_exec
-        fcntl.fcntl(sock.fileno(), fcntl.F_SETFD, flags)
+        set_close_exec(sock.fileno())
-        raise ValueError("Unsupported op")
+def set_close_exec(fd):
-            success = SetHandleInformation(fd, HANDLE_FLAG_INHERIT, arg)
+            success = SetHandleInformation(fd, HANDLE_FLAG_INHERIT, 0)
-        from tornado import win32_support as fcntl
+        from tornado.platform import windows
-            self._waker_reader = self._waker_writer = win32_support.Pipe()
+            self._waker_reader = self._waker_writer = windows.Pipe()
-        from tornado import win32_support as fcntl
+        from tornado.platform import windows as fcntl
-        # import tornado.win32_support  # depends on windows
+from tornado import process
-_processes_forked = False
+_task_id = None
-def fork_processes(num_processes):
+def fork_processes(num_processes, max_restarts=100):
-    If num_processes is None or <= 0, we detect the number of cores
+    If ``num_processes`` is None or <= 0, we detect the number of cores
-    processes. If num_processes is given and > 0, we fork that
+    processes. If ``num_processes`` is given and > 0, we fork that
-    module (or the debug=True option to tornado.web.Application).
+    module (or the debug=True option to `tornado.web.Application`).
-    referenced until after the call to fork_processes.
+    referenced until after the call to ``fork_processes``.
-    _processes_forked = True
+    global _task_id
-        if os.fork() == 0:
+    logging.info("Starting %d processes", num_processes)
-    os.waitpid(-1, 0)
+            global _task_id
-import tornado.ioloop
+from tornado.ioloop import IOLoop
-        if self.io_loop is not tornado.ioloop.IOLoop.instance():
+        if (not IOLoop.initialized() or
-        return tornado.ioloop.IOLoop()
+        return IOLoop()
-            random.seed(seed)
+            _reseed_random()
-    auto-detection.
+    HTTPServer initialization follows one of three patterns:
-        """
+        self._pending_sockets = []
-        """Binds to the given port and starts the server in a single process.
+        """Starts accepting connections on the given port.
-        This method is a shortcut for:
+        This method may be called more than once to listen on multiple ports.
-            server.start(1)
+    def add_sockets(self, sockets):
-        self.start(1)
+        if self.io_loop is None:
-                                         ioloop.IOLoop.READ)
+        if self._started:
-                                     ioloop.IOLoop.READ)
+        sockets = self._pending_sockets
-            self.http_server.bind(self.get_http_port(), address='::1')
+            self.http_server.listen(self.get_http_port(), address='::1')
-                                         ioloop.IOLoop.READ)
+        if num_processes != 1:
-            sock.listen(backlog)
+        sockets = netutil.bind_sockets(port, address=address,
-        assert not self._finished
+        if self._finished:
-        assert not self._finished
+        if self._finished:
-from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous, url
+from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous, url, HTTPError
-        for your application.
+        If `flush()` has already been called, it is not possible to send
-        self.finish(message)
+        try:
-    def get_error_html(self, status_code, **kwargs):
+    def write_error(self, status_code, **kwargs):
-        "return self.render_string(...)" instead of "self.render()".
+        ``write_error`` may call `write`, `render`, `set_header`, etc
-        exception object can be found in kwargs e.g. kwargs['exception']
+        For historical reasons, if a method ``get_error_html`` exists,
-        if self.settings.get("debug") and "exception" in kwargs:
+        if hasattr(self, 'get_error_html'):
-            return traceback.format_exc()
+            for line in traceback.format_exception(*kwargs["exc_info"]):
-            }
+            self.finish("<html><title>%(code)d: %(message)s</title>" 
-                self.send_error(500, exception=e)
+                self.send_error(500, exc_info=sys.exc_info())
-                self.send_error(e.status_code, exception=e)
+                self.send_error(e.status_code, exc_info=sys.exc_info())
-            self.send_error(500, exception=e)
+            self.send_error(500, exc_info=sys.exc_info())
-    return _StackContextWrapper(wrapped, fn, _state.contexts)
+    if _state.contexts:
-            self._stack_context_handle_exception):
+        try:
-        return method(self, *args, **kwargs)
+        with stack_context.ExceptionStackContext(
-        if self.settings.get("debug"):
+        if self.settings.get("debug") and "exception" in kwargs:
-                 allow_ipv6=None):
+                 allow_ipv6=None,
-from tornado.util import b, bytes_type
+from tornado.util import b, bytes_type, import_object
-                    # Lazy load the Module and instantiate the class
+                    # import the Module and instantiate the class
-                    # The class has now been loaded and we can continue
+                    handler = import_object(handler)
-    def bind(self, port, address=None, family=socket.AF_UNSPEC):
+    def bind(self, port, address=None, family=socket.AF_UNSPEC, backlog=128):
-            sock.listen(128)
+            sock.listen(backlog)
-        self.http_server.bind(self.get_http_port(), address='::1')
+        try:
-            "HTTP/1.1 101 Web Socket Protocol Handshake\r\n"
+            "HTTP/1.1 101 WebSocket Protocol Handshake\r\n"
-
+            if self._callbacks:
-        
+
-        # timeout object in the queue (see discussion in 
+        # timeout object in the queue (see discussion in
-        if not self._callbacks:
+        if not self._callbacks and thread.get_ident() != self._thread_ident:
-    # use __lt__).  
+    # use __lt__).
-       Request body, if present.
+       Request body, if present, as a byte string.
-       for individual names). Names and values are both unicode always.
+       for individual names). Names are of type `str`, while arguments
-from tornado.util import bytes_type
+from tornado.util import bytes_type, b
-        if response.error or u"is_valid:true" not in response.body:
+        if response.error or b("is_valid:true") not in response.body:
-        for name, values in self.request.arguments.iteritems():
+        for name in self.request.arguments.iterkeys():
-               values[-1] == u"http://openid.net/srv/ax/1.0":
+               self.get_argument(name) == u"http://openid.net/srv/ax/1.0":
-                if values[-1] == uri and name.startswith(prefix):
+            for name in self.request.arguments.iterkeys():
-          "expires": cgi.parse_qs(response.body).get("expires")
+          "access_token": args["access_token"][-1],
-        except:
+        except Exception:
-        except:
+        except Exception:
-                except:
+                except Exception:
-        except:
+        except Exception:
-        except:
+        except Exception:
-except: bytes = str
+except Exception: bytes = str
-except:
+except Exception:
-            except:
+            except Exception:
-                except:
+                except Exception:
-        except:
+        except Exception:
-        except:
+        except Exception:
-    except:
+    except Exception:
-        except:
+        except Exception:
-            except:
+            except Exception:
-except:
+except ImportError:
-        except:
+        except Exception:
-            except:
+            except Exception:
-        except:
+        except Exception:
-        except:
+        except Exception:
-        except:
+        except Exception:
-        except:
+        except Exception:
-                    except:
+                    except Exception:
-                except:
+                except Exception:
-        except:
+        except Exception:
-            except:
+            except Exception:
-        except:
+        except Exception:
-                     request.auth_username)
+        logging.debug("%s %s (username: %r)", request.method, request.url,
-        logging.info("%s %s", request.method, request.url)
+        logging.debug("%s %s", request.method, request.url)
-        """
+    def get_secure_cookie(self, name, value=None, max_age_days=31):
-            signature = self._cookie_signature(parts[0], parts[1])
+        signature = self._cookie_signature(name, parts[0], parts[1])
-        You must specify the 'cookie_secret' setting in your Application
+        You must specify the ``cookie_secret`` setting in your Application
-        To read a cookie set with this method, use get_secure_cookie().
+        To read a cookie set with this method, use `get_secure_cookie()`.
-    def get_secure_cookie(self, name, include_name=True, value=None):
+    def get_secure_cookie(self, name, include_name=True, value=None,
-        if timestamp < time.time() - 31 * 86400:
+        if timestamp < time.time() - max_age_days * 86400:
-                print "exec done"
+    else:
-            continue
+            return
-            continue
+            return
-    """A simple test runner with autoreload support.
+    """A simple test runner.
-        python -m tornado.testing --autoreload tornado.test.stack_context_test
+        python -m tornado.testing tornado.test.stack_context_test
-        tornado/test/runtests.py --autoreload
+        tornado/test/runtests.py
-        tornado/test/runtests.py --autoreload tornado.test.stack_context_test
+        tornado/test/runtests.py tornado.test.stack_context_test
-    define('autoreload', type=bool, default=False)
+    define('autoreload', type=bool, default=False,
-        ioloop.start()
+        tornado.autoreload.wait()
-        self._async_client.close()
+        self.close()
-        if self._async_clients[self.io_loop] is self:
+        if self._async_clients.get(self.io_loop) is self:
-            self.io_loop._waker_writer.close()
+            self.io_loop.close(all_fds=True)
-from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient
+from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient, main
-
+    AsyncHTTPClient.configure(SimpleAsyncHTTPClient)
-                            "don't know how to read %s", self.request.url)
+            self.stream.read_until_close(self._on_body)
-        if self._read_bytes:
+        if self._read_bytes is not None:
-        elif self._read_delimiter:
+        elif self._read_delimiter is not None:
-            except Exception, e:
+            except Exception:
-import time
+from tornado.util import bytes_type, b
-        self.stream.write("%s" % challenge)
+        self.stream.write(challenge)
-        self.stream.write("\x00" + message + "\xff")
+        assert isinstance(message, bytes_type)
-            self.stream.read_until("\xff", self._on_end_delimiter)
+            self.stream.read_until(b("\xff"), self._on_end_delimiter)
-            key_number = number / spaces
+            key_number = number // spaces
-    return _json_encode(value).replace("</", "<\\/")
+    return _json_encode(recursive_unicode(value)).replace("</", "<\\/")
-from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode, json_decode
+from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode, json_decode, json_encode
-                u"X-Header-encoding-test: \u00e9".encode("latin1"),
+                b("X-Header-encoding-test: \xe9"),
-# ascii strings.  Once we drop support for 2.5, we can remove this function
+# latin1 strings.  Once we drop support for 2.5, we can remove this function
-        return s.encode('ascii')
+        return s.encode('latin1')
-                                      0, socket.AI_PASSIVE | socket.AI_ADDRCONFIG):
+                                      0, flags):
-version = "2.0"
+version = "2.0git"
-version = "2.0"
+version = "2.0git"
-        }
+        if self.settings.get("debug"):
-version = "2.0rc1"
+version = "2.0"
-version = "2.0rc1"
+version = "2.0"
-                ("/get", GetCookieHandler)])
+                ("/get", GetCookieHandler),
-        self.render(path + ".html")
+        self.render(path + ".html", version=tornado.version)
-        paths = ("overview", "index")
+        paths = ("index",)
-        return ContentHandler._md[path]
+        self.render(path + ".html")
-     dict(url="/documentation/reference/index.html")),
+     dict(url="/documentation/index.html")),
-        """
+    """Exception raised by errors in the options module."""
-           Finance - http://finance.google.com/finance/feeds/
+        * Gmail Contacts - http://www.google.com/m8/feeds/
-            sms
+        * publish_stream
-      """ Handles the login for the Facebook user, returning a user object.
+      """Handles the login for the Facebook user, returning a user object.
-and Google AppEngine.
+and Google AppEngine.  It also will not work correctly when HTTPServer's
-    """Turns on formatted logging output as configured."""
+    """Turns on formatted logging output as configured.
-        '''Establishes the given context as a StackContext that will be transferred.
+    '''Establishes the given context as a StackContext that will be transferred.
-        non-transferable context manager you would say::
+    Note that the parameter is a callable that returns a context
-          with my_context():
+      with my_context():
-        StackContext takes the function itself rather than its result::
+    StackContext takes the function itself rather than its result::
-        '''
+      with StackContext(my_context):
-* AsyncTestCase/AsyncHTTPTestCase:  Subclasses of unittest.TestCase
+* `AsyncTestCase`/`AsyncHTTPTestCase`:  Subclasses of unittest.TestCase
-* LogTrapTestCase:  Subclass of unittest.TestCase that discards log output
+* `LogTrapTestCase`:  Subclass of unittest.TestCase that discards log output
-* main(): A simple test runner (wrapper around unittest.main()) with support
+* `main()`: A simple test runner (wrapper around unittest.main()) with support
-details and documentation.
+WSGI is the Python standard for web servers, and allows for interoperability
-    """A WSGI-equivalent of web.Application.
+    """A WSGI equivalent of `tornado.web.Application`.
-    do not support flush() or asynchronous methods.
+    do not support flush() or asynchronous methods. 
-    """Mimics httpserver.HTTPRequest for WSGI applications."""
+    """Mimics `tornado.httpserver.HTTPRequest` for WSGI applications."""
-    thoroughly tested in production.
+    run on the Tornado HTTP server and I/O loop.
-        """Executes an HTTPRequest, returning an HTTPResponse.
+        """Executes a request, returning an `HTTPResponse`.
-        If an error occurs during the fetch, we raise an HTTPError.
+        If an error occurs during the fetch, we raise an `HTTPError`.
-        """Executes an HTTPRequest, calling callback with an HTTPResponse.
+        """Executes a request, calling callback with an `HTTPResponse`.
-        # that varies by httpclient implementation.
+        """If there was an error on the request, raise an `HTTPError`."""
-"""A level-triggered I/O loop for non-blocking sockets."""
+"""An I/O event loop for non-blocking sockets.
-    use Python 2.6+ to get epoll support.
+    We use epoll (Linux) or kqueue (BSD and Mac OS X; requires python
-    """A utility class to write to and read from a non-blocking socket.
+    """A utility class to write to and read from a non-blocking SSL socket.
-"""Escaping/unescaping methods for HTML, JSON, URLs, and others."""
+"""Escaping/unescaping methods for HTML, JSON, URLs, and others.
-    Hello <a href="http://tornadoweb.org">http://tornadoweb.org</a>!
+    For example: ``linkify("Hello http://tornadoweb.org!")`` would return
-"""A non-blocking, single-threaded HTTP server."""
+"""A non-blocking, single-threaded HTTP server.
-    for individual names). Names and values are both unicode always.
+    .. attribute:: method
-    outright given that it can be easily forged.
+    .. attribute:: connection
-    sequentially on a single connection.
+       An HTTP request is attached to a single HTTP connection, which can
-extensions = ["sphinx.ext.autodoc", "sphinx_coverage"]
+extensions = ["sphinx.ext.autodoc", "sphinx_coverage", "sphinx.ext.viewcode"]
-    return xml.sax.saxutils.escape(native_str(value), {'"': "&quot;"})
+    return xml.sax.saxutils.escape(to_basestring(value), {'"': "&quot;"})
-    return _json_decode(native_str(value))
+    return _json_decode(to_basestring(value))
-            return urllib.unquote_plus(native_str(value), encoding=encoding)
+            return urllib.unquote_plus(to_basestring(value), encoding=encoding)
-from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode
+from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode, json_decode
-                        ("/", HelloHandler)])))
+                        ("/", HelloHandler),
-            "PATH_INFO": request.path,
+            "PATH_INFO": urllib.unquote(request.path),
-version = "1.2.1"
+version = "2.0rc1"
-version_info = (1, 2, 1)
+version = "2.0rc1"
-            ui_modules= {"Post": PostModule},
+            ui_modules={"Post": PostModule},
-_DEFAULT_AUTOESCAPE = None
+_DEFAULT_AUTOESCAPE = "xhtml_escape"
-        if not path: path = "index"
+    def get(self, path="index"):
-    (r"/([a-z]*)", ContentHandler),
+    (r"/", ContentHandler),
-    it should be wrapped with
+    it should be wrapped with::
-Example usage for Google OpenID:
+Example usage for Google OpenID::
-        self.authenticate_redirect()
+    class GoogleHandler(tornado.web.RequestHandler, tornado.auth.GoogleMixin):
-        # Save the user with, e.g., set_secure_cookie()
+        def _on_auth(self, user):
-    to authenticate the user with Twitter and get access to their stream:
+    to authenticate the user with Twitter and get access to their stream::
-            self.authorize_redirect()
+        class TwitterHandler(tornado.web.RequestHandler,
-            # Save the user using, e.g., set_secure_cookie()
+            def _on_auth(self, user):
-                self.finish("Posted a message!")
+        this method. Example usage::
-    to authenticate the user with FriendFeed and get access to their feed:
+    to authenticate the user with FriendFeed and get access to their feed::
-            self.authorize_redirect()
+        class FriendFeedHandler(tornado.web.RequestHandler,
-            # Save the user using, e.g., set_secure_cookie()
+            def _on_auth(self, user):
-                self.finish("Posted a message!")
+        this method. Example usage::
-    Example usage:
+    Example usage::
-        self.authenticate_redirect()
+        class GoogleHandler(tornado.web.RequestHandler, tornado.auth.GoogleMixin):
-            # Save the user with, e.g., set_secure_cookie()
+            def _on_auth(self, user):
-    to authenticate the user with Facebook:
+    to authenticate the user with Facebook::
-            self.authenticate_redirect()
+        class FacebookHandler(tornado.web.RequestHandler,
-            # Save the user using, e.g., set_secure_cookie()
+            def _on_auth(self, user):
-                self.render("stream.html", stream=stream)
+        Here is an example for the stream.get() method::
-                                    extra_params={"scope": "read_stream,offline_access"})
+      Example usage::
-          self.finish()
+          class FacebookGraphLoginHandler(LoginHandler, tornado.auth.FacebookGraphMixin):
-                self.finish("Posted a message!")
+        this method. Example usage::
-    columns can be accessed by name. Typical usage:
+    columns can be accessed by name. Typical usage::
-Each module defines its own options, e.g.,
+Each module defines its own options, e.g.::
-or parse a config file with:
+or parse a config file with::
-Config files are just Python files. Global names become options, e.g.,
+Config files are just Python files. Global names become options, e.g.::
-    command line help string. The help message is formatted like:
+    command line help string. The help message is formatted like::
-Example usage:
+Example usage::
-        non-transferable context manager you would say
+        non-transferable context manager you would say::
-        StackContext takes the function itself rather than its result:
+
-    Example:
+    Example::
-    Example:
+    Example::
-    The easiest way to run a test is via the command line:
+    The easiest way to run a test is via the command line::
-    be overridden by naming a single test on the command line.
+    be overridden by naming a single test on the command line::
-    back to the client:
+    back to the client::
-    invoke it in JavaScript with:
+    invoke it in JavaScript with::
-Example usage:
+Example usage::
-    """Makes a WSGI-compatible function runnable on Tornado's HTTP server.
+    r"""Makes a WSGI-compatible function runnable on Tornado's HTTP server.
-    run it. For example:
+    run it. For example::
-            self.compiled = compile(self.code, self.name, "exec")
+            self.compiled = compile(self.code, "<template %s>" % self.name,
-        import tornado.s3server
+class OptionalPathHandler(RequestHandler):
-from tornado.escape import utf8
+from tornado.escape import utf8, _unicode
-
+
-    Typical usage looks like this:
+    Typical usage looks like this::
-    Example usage:
+    Example usage::
-    """A non-blocking, single-threaded HTTP server.
+    r"""A non-blocking, single-threaded HTTP server.
-    requested:
+    requested::
-    including "certfile" and "keyfile":
+    including "certfile" and "keyfile"::
-    start() instead of listen():
+    start() instead of listen()::
-        with cert_reqs set in ssl_options, e.g.:
+        with cert_reqs set in ssl_options, e.g.::
-    Example usage for a simple TCP server:
+    Example usage for a simple TCP server::
-        but not require the argument for simpler applications:
+        but not require the argument for simpler applications::
-        unit tests), you can start and stop the event loop like this:
+        unit tests), you can start and stop the event loop like this::
-    """A utility class to write to and read from a non-blocking socket.
+    r"""A utility class to write to and read from a non-blocking socket.
-    A very simple (and broken) HTTP client using this class:
+    A very simple (and broken) HTTP client using this class::
-To load a locale and generate a translated string:
+To load a locale and generate a translated string::
-additional arguments to translate(), e.g.:
+additional arguments to translate(), e.g.::
-Basic usage looks like:
+Basic usage looks like::
-the compiled templates:
+the compiled templates::
-interesting. Syntax for the templates
+interesting. Syntax for the templates::
-translated exactly into Python, do you can do complex expressions like:
+translated exactly into Python, do you can do complex expressions like::
-functions in to your template just like any other variable:
+functions in to your template just like any other variable::
-print tornado.__file__
+# For our version of sphinx_coverage.py.  The version in sphinx 1.0.7
-extensions = ["sphinx.ext.autodoc"]
+extensions = ["sphinx.ext.autodoc", "sphinx_coverage"]
-autodoc_default_flags = ["members", "undoc-members"]
+
-
+"""
-Here is the canonical "Hello, world" example app:
+Here is the canonical "Hello, world" example app::
-Thread-safety notes:
+Thread-safety notes
-        Example:
+        Example::
-    automatically finished when the get() or post() method returns.
+    automatically finished when the get() or post() method returns. ::
-    For example, a request to '/foo/' would redirect to '/foo' with this
+    For example, a request to ``'/foo/'`` would redirect to ``'/foo'`` with this
-    like r'/foo/*' in conjunction with using the decorator.
+    like ``r'/foo/*'`` in conjunction with using the decorator.
-    HTTPServer to serve the application:
+    HTTPServer to serve the application::
-    for the StaticFileHandler below:
+    for the StaticFileHandler below::
-    a host regular expression as the first argument:
+    a host regular expression as the first argument::
-    You should provide the keyword argument "url" to the handler, e.g.:
+    You should provide the keyword argument "url" to the handler, e.g.::
-    you would add a line to your application like:
+    you would add a line to your application like::
-    Typical usage:
+    Typical usage::
-    """Loads translations from CSV files in a directory.
+    u"""Loads translations from CSV files in a directory.
-        "%(name)s liked this","A %(name)s le gust\xf3 esto","singular"
+        "%(name)s liked this","A %(name)s les gust\u00f3 esto","plural"
-from tornado.template import Template, DictLoader
+from tornado.template import Template, DictLoader, ParseError
-        if self._read_buffer_size() >= self.max_buffer_size:
+        self._read_buffer_size += len(chunk)
-            if self._read_buffer_size() >= self._read_bytes:
+            if self._read_buffer_size >= self._read_bytes:
-import sys
+import calendar
-import re
+class UIModuleResourceHandler(RequestHandler):
-                "linkify.html": "{% module linkify(message) %}"
+                "linkify.html": "{% module linkify(message) %}",
-            html = html[:sloc] + js + '\n' + html[sloc:]
+            sloc = html.rindex(b('</body>'))
-            html = html[:sloc] + js + '\n' + html[sloc:]
+            js = b('<script type="text/javascript">\n//<![CDATA[\n') + \
-            html = html[:hloc] + css + '\n' + html[hloc:]
+            hloc = html.index(b('</head>'))
-            html = html[:hloc] + css + '\n' + html[hloc:]
+            css = b('<style type="text/css">\n') + b('\n').join(css_embed) + \
-            html = html[:hloc] + ''.join(html_heads) + '\n' + html[hloc:]
+            hloc = html.index(b('</head>'))
-            html = html[:hloc] + ''.join(html_bodies) + '\n' + html[hloc:]
+            hloc = html.index(b('</body>'))
-                           'xsrf_form_html': _xsrf_form_html}
+                           'xsrf_form_html': _xsrf_form_html,
-                          "comment", "autoescape", "raw"):
+                          "comment", "autoescape", "raw", "module"):
-                ])
+        loader = DictLoader({
-        self.ui_modules = {}
+        self.ui_modules = {'linkify': _linkify,
-                        self._parse_mime_body(utf8(v), data)
+                        httputil.parse_multipart_form_data(
-
+from tornado.util import b
-                if boundary: self._parse_mime_body(utf8(boundary))
+                if boundary:
-
+from tornado.escape import json_encode
-from tornado.escape import native_str
+from tornado.escape import native_str, utf8
-                if boundary: self._parse_mime_body(boundary)
+                if boundary: self._parse_mime_body(utf8(boundary))
-        if boundary.startswith('"') and boundary.endswith('"'):
+        if boundary.startswith(b('"')) and boundary.endswith(b('"')):
-        if self.body.endswith("\r\n"):
+        if self.body.endswith(b("\r\n")):
-        parts = self.body[:-footer_length].split("--" + boundary + "\r\n")
+        parts = self.body[:-footer_length].split(b("--") + boundary + b("\r\n"))
-            eoh = part.find("\r\n\r\n")
+            eoh = part.find(b("\r\n\r\n"))
-            headers = httputil.HTTPHeaders.parse(part[:eoh])
+            headers = httputil.HTTPHeaders.parse(part[:eoh].decode("utf-8"))
-               not part.endswith("\r\n"):
+               not part.endswith(b("\r\n")):
-                name_values[name] = name_value.strip('"').decode("utf-8")
+                name_values[name] = name_value.strip('"')
-            environ["CONTENT_TYPE"] = request.headers["Content-Type"]
+            environ["CONTENT_TYPE"] = request.headers.pop("Content-Type")
-            environ["CONTENT_LENGTH"] = request.headers["Content-Length"]
+            environ["CONTENT_LENGTH"] = request.headers.pop("Content-Length")
-            success += 1
+            if self._started:
-            sock.bind(('', port))
+            sock.bind(('127.0.0.1', port))
-        self.http_server.listen(self.get_http_port())
+        self.http_server.listen(self.get_http_port(), address="127.0.0.1")
-from tornado.escape import utf8
+from tornado.escape import utf8, native_str
-from tornado.util import b
+from tornado.util import b, bytes_type
-              template.Loader(template_path)
+            loader = self.create_template_loader(template_path)
-    def __init__(self, expression):
+    def __init__(self, expression, raw=False):
-        if writer.current_template.autoescape is not None:
+        if not self.raw and writer.current_template.autoescape is not None:
-                          "comment", "autoescape"):
+                          "comment", "autoescape", "raw"):
-                 compress_whitespace=None):
+                 compress_whitespace=None, autoescape=_UNSET):
-        self.file = _File(_parse(reader))
+        self.file = _File(_parse(reader, self))
-    def __init__(self, root_directory):
+    def __init__(self, root_directory, autoescape=_DEFAULT_AUTOESCAPE):
-        super(DictLoader, self).__init__("")
+    def __init__(self, dict, **kwargs):
-    def __init__(self, name, body=None):
+    def __init__(self, name, body, template):
-        writer.named_blocks[self.name].generate(writer)
+        block = writer.named_blocks[self.name]
-        named_blocks[self.name] = self.body
+        named_blocks[self.name] = self
-        writer.write_line("else: _buffer.append(_utf8(str(_tmp)))")
+                          " _tmp = _utf8(_tmp)")
-def _parse(reader, in_block=None):
+def _parse(reader, template, in_block=None):
-                          "comment"):
+                          "comment", "autoescape"):
-            block_body = _parse(reader, operator)
+            block_body = _parse(reader, template, operator)
-                block = _NamedBlock(suffix, block_body)
+                block = _NamedBlock(suffix, block_body, template)
-    """
+class BaseLoader(object):
-            f.close()
+            self.templates[name] = self._create_template(name)
-class DictLoader(object):
+class DictLoader(BaseLoader):
-        return self.templates[name]
+    def _create_template(self, name):
-            writer.write_line("return ''.join(_buffer)")
+            writer.write_line("return _utf8('').join(_buffer)")
-            writer.write_line("return ''.join(_buffer)")
+            writer.write_line("return _utf8('').join(_buffer)")
-        writer.write_line("else: _buffer.append(str(_tmp))")
+        writer.write_line("if isinstance(_tmp, _string_types):"
-            writer.write_line('_buffer.append(%r)' % value)
+            writer.write_line('_buffer.append(%r)' % escape.utf8(value))
-                         "Hello Ben!")
+                         b("Hello Ben!"))
-                         "header text\nbody text")
+                         b("header text\nbody text"))
-                         "<title>page title</title>\n<body>page body</body>\n")
+                         b("<title>page title</title>\n<body>page body</body>\n"))
-                    self.set_header("Etag", etag)
+                etag = self.compute_etag()
-# implementations of url_unescape
+# implementations of url_unescape.  We also need our own implementation
-from tornado.escape import utf8, native_str
+from tornado.escape import utf8, native_str, parse_qs_bytes
-                arguments = parse_qs(native_str(self._request.body))
+                arguments = parse_qs_bytes(native_str(self._request.body))
-        arguments = parse_qs(query)
+        arguments = parse_qs_bytes(query)
-from tornado.escape import json_decode, utf8, _unicode
+from tornado.escape import json_decode, utf8, _unicode, recursive_unicode
-        self.write(self.request.arguments)
+        self.write(recursive_unicode(self.request.arguments))
-        self.check_type('arg_value', self.request.arguments.values()[0][0], str)
+        self.check_type('arg_value', self.request.arguments.values()[0][0], bytes_type)
-from tornado.escape import json_decode, utf8
+from tornado.escape import json_decode, utf8, to_unicode, recursive_unicode, native_str
-        # they're left as the native str type.
+        # Type checks: web.py interfaces convert argument values to
-            assert type(key) == type(""), repr(key)
+            assert type(key) == str, repr(key)
-                assert type(value) == type(""), repr(value)
+                assert type(value) == bytes_type, repr(value)
-                        args=self.request.arguments))
+                        args=recursive_unicode(self.request.arguments)))
-        return Application([url("/typecheck/(.*)", TypeCheckHandler, name='typecheck')])
+        return Application([
-            values = [x.strip() for x in values]
+        values = []
-                    # None-safe wrapper around urllib.unquote to handle
+                    # None-safe wrapper around url_unescape to handle
-                        return _unicode(urllib.unquote(s))
+                        return escape.url_unescape(s, encoding=None)
-    return _unicode(urllib.unquote_plus(value))
+# python 3 changed things around enough that we need two separate
-from tornado.escape import utf8, xhtml_escape, xhtml_unescape
+from tornado.escape import utf8, xhtml_escape, xhtml_unescape, url_escape, url_unescape, to_unicode
-    return xml.sax.saxutils.escape(_unicode(value), {'"': "&quot;"})
+    return xml.sax.saxutils.escape(native_str(value), {'"': "&quot;"})
-    return _json_decode(_unicode(value))
+    return _json_decode(native_str(value))
-from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous
+from tornado.util import b, bytes_type
-                arguments = parse_qs(self._request.body)
+                arguments = parse_qs(native_str(self._request.body))
-from tornado.util import b
+from tornado.util import b, bytes_type
-        return Application([("/echo", EchoHandler)])
+        return Application([("/echo", EchoHandler),
-        self.url = utf8(url)
+        self.url = url
-        self.auth_password = utf8(auth_password)
+        self.auth_username = auth_username
-from tornado.escape import utf8, _unicode
+from tornado.escape import utf8, _unicode, native_str
-        data = data.decode("latin1")
+        data = native_str(data.decode("latin1"))
-                                               utf8(self.headers["Location"]))
+                                               self.headers["Location"])
-from tornado.util import b
+from tornado.util import b, bytes_type
-        self.assertTrue(response.effective_url.endswith(b("/countdown/0")))
+        self.assertTrue(response.effective_url.endswith("/countdown/0"))
-        self.assertTrue(response.effective_url.endswith(b("/countdown/2")))
+        self.assertTrue(response.request.url.endswith("/countdown/5"))
-from tornado.web import Application, RequestHandler, asynchronous, url
+from tornado.test.httpclient_test import HTTPClientCommonTestCase
-        self.finish("Hello %s!" % name)
+class SimpleHTTPClientCommonTestCase(HTTPClientCommonTestCase):
-        pass
+# Remove the base class from our namespace so the unittest module doesn't
-        self.assertEqual(str(response.error), "HTTP 599: Timeout")
+            ])
-    def test_default_certificates_exist(self):
+    def xxx_test_default_certificates_exist(self):
-                                      0, socket.AI_PASSIVE):
+                                      0, socket.AI_PASSIVE | socket.AI_ADDRCONFIG):
-from tornado.template import Template
+from tornado.template import Template, DictLoader
-        start_response(status, headers)
+        start_response(status,
-            data = data.decode('latin1')
+            data = native_str(data.decode('latin1'))
-import cStringIO
+from tornado.util import b
-        body = "".join(response)
+        body = b("").join(response)
-        parts = ["HTTP/1.1 " + data["status"] + "\r\n"]
+        parts = [escape.utf8("HTTP/1.1 " + data["status"] + "\r\n")]
-        parts.append("\r\n")
+            parts.append(escape.utf8(key) + b(": ") + escape.utf8(value) + b("\r\n"))
-        request.write("".join(parts))
+        request.write(b("").join(parts))
-            "SERVER_PORT": port,
+            "SERVER_PORT": str(port),
-            "wsgi.input": cStringIO.StringIO(escape.utf8(request.body)),
+            "wsgi.input": BytesIO(escape.utf8(request.body)),
-        reader = _TemplateReader(name, escape.utf8(template_string))
+        reader = _TemplateReader(name, escape.native_str(template_string))
-        unittest.main(module=None, defaultTest='__main__.all', argv=argv)
+        # module must be set to None.  Python 3.2's unittest.main ignores
-              urllib.urlencode(args))
+        self.redirect(
-        return url + urllib.urlencode(args)
+        return url_concat(url, args)
-        self.write(dict(path=path, args=self.request.arguments))
+        # Type checks:  web.py interfaces convert arguments to unicode
-                        return urllib.unquote(s)
+                        return _unicode(urllib.unquote(s))
-                sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)
+                #
-from tornado.escape import utf8
+from tornado.escape import utf8, native_str
-        scheme, netloc, path, query, fragment = urlparse.urlsplit(uri)
+        scheme, netloc, path, query, fragment = urlparse.urlsplit(native_str(uri))
-        
+
-            headers = httputil.HTTPHeaders.parse(part[:eoh].decode("latin1"))
+            headers = httputil.HTTPHeaders.parse(part[:eoh].decode("utf-8"))
-                    u'Content-Disposition: form-data; name="files"; filename="\u00f3"'.encode("latin1"),
+                    u'Content-Disposition: form-data; name="files"; filename="\u00f3"'.encode("utf8"),
-                        self._parse_mime_body(v, data)
+                        self._parse_mime_body(utf8(v), data)
-        if boundary.startswith('"') and boundary.endswith('"'):
+        if boundary.startswith(b('"')) and boundary.endswith(b('"')):
-        if data.endswith("\r\n"):
+        if data.endswith(b("\r\n")):
-        parts = data[:-footer_length].split("--" + boundary + "\r\n")
+        parts = data[:-footer_length].split(b("--") + boundary + b("\r\n"))
-            eoh = part.find("\r\n\r\n")
+            eoh = part.find(b("\r\n\r\n"))
-            headers = httputil.HTTPHeaders.parse(part[:eoh])
+            headers = httputil.HTTPHeaders.parse(part[:eoh].decode("latin1"))
-               not part.endswith("\r\n"):
+               not part.endswith(b("\r\n")):
-                name_values[name] = name_value.strip('"').decode("utf-8")
+                name_values[name] = name_value.strip('"')
-            name = name_values["name"].decode("utf-8")
+            name = name_values["name"]
-    return xml.sax.saxutils.escape(value, {'"': "&quot;"})
+    return xml.sax.saxutils.escape(_unicode(value), {'"': "&quot;"})
-        the Content-Type of the response to be text/javascript.
+        the Content-Type of the response to be application/json.
-            self.set_header("Content-Type", "text/javascript; charset=UTF-8")
+            self.set_header("Content-Type", "application/json; charset=UTF-8")
-        self.stream.write(
+        self.stream.write(tornado.escape.utf8(
-                    uri=self.request.uri)))
+                    uri=self.request.uri))))
-        number, spaces = filter(str.isdigit, key), filter(str.isspace, key)
+        number = int(''.join(c for c in key if c.isdigit()))
-            key_number = int(number) / len(spaces)
+            key_number = number / spaces
-    pycurl = None
+    def setUp(self):
-        self.assertEqual(response.body, "Hello world")
+        self.assertEqual(response.body, b("Hello world"))
-        self.assertEqual(response.body, "Got 5000 bytes in POST")
+        self.assertEqual(response.body, b("Got 5000 bytes in POST"))
-    # the same IOLoop as the server.
+if ssl is None:
-                 validate_cert=True, ca_certs=None):
+                 validate_cert=True, ca_certs=None,
-                port = 443 if parsed.scheme == "https" else 80
+            # urlsplit results have hostname and port results, but they
-                port = parsed.port
+                host = netloc
-                self.stream = SSLIOStream(socket.socket(),
+                self.stream = SSLIOStream(socket.socket(af, socktype, proto),
-                self.stream = IOStream(socket.socket(),
+                self.stream = IOStream(socket.socket(af, socktype, proto),
-            self.stream.connect((host, port),
+            self.stream.connect(sockaddr,
-        self._socket = None
+        self._sockets = {}  # fd -> socket object
-        """Binds this server to the given port on the given IP address.
+    def bind(self, port, address=None, family=socket.AF_UNSPEC):
-        self._socket.listen(128)
+        if address == "":
-                        ioloop.IOLoop.READ)
+                    for fd in self._sockets.keys():
-                                     ioloop.IOLoop.READ)
+            for fd in self._sockets.keys():
-        self._socket.close()
+        for fd, sock in self._sockets.iteritems():
-                connection, address = self._socket.accept()
+                connection, address = self._sockets[fd].accept()
-                    self._cookies.load(self.request.headers["Cookie"])
+                    self._cookies.load(
-        value = utf8(value)
+        # The cookie library only accepts type str, in both python 2 and 3
-                lines.append(b("Set-Cookie: ") + cookie.OutputString(None))
+                lines.append(utf8("Set-Cookie: " + cookie.OutputString(None)))
-
+import binascii
-        self.assertEqual(response.body, utf8(u"\xe9"))
+        response = self.fetch("/echopost", method="POST", body=unicode_body,
-        self.assertEqual(response.body, "\xe9")
+        response = self.fetch("/echopost", method="POST",
-        response = self.fetch("/echopost", method="POST", body="\xe9",
+        response = self.fetch("/echopost", method="POST", body=byte_body,
-        self.assertEqual(response.body, "\xe9")
+        self.assertEqual(response.headers["Content-Length"], "1")
-            raise self.__failure[0], self.__failure[1], self.__failure[2]
+            # 2to3 isn't smart enough to convert three-argument raise
-            if isinstance(extended_permissions, basestring):
+            if isinstance(extended_permissions, (unicode, bytes_type)):
-from tornado.util import import_object
+from tornado.util import import_object, bytes_type
-        if isinstance(impl, basestring):
+        if isinstance(impl, (unicode, bytes_type)):
-        if isinstance(value, basestring):
+        if isinstance(value, (unicode, bytes_type)):
-        if isinstance(value, basestring):
+        if isinstance(value, (unicode, bytes_type)):
-                if isinstance(file_part, basestring):
+                if isinstance(file_part, (unicode, bytes_type)):
-                if isinstance(file_part, basestring):
+                if isinstance(file_part, (unicode, bytes_type)):
-        shell=True)
+    args = ["ab"]
-        self.io_loop.add_callback(wrapper)
+        with stack_context.NullContext():
-        self.body = body
+        self.body = utf8(body)
-            self.stream.write(utf8(self.request.body))
+            self.stream.write(self.request.body)
-    if len(deque) == 1 and len(deque[0]) < size:
+    if len(deque) == 1 and len(deque[0]) <= size:
-
+    if fn is None or fn.__class__ is _StackContextWrapper:
-        else:
+        if isinstance(value, basestring):
-                    # With OpenSSL, after send returns EWOULDBLOCK,
+                if num_bytes == 0:
-                    # merging the write buffer after an EWOULDBLOCK.
+                    # merging the write buffer after an incomplete send.
-                self.close()
+                # We may have queued up a user callback in _handle_read or
-        match = re.match("HTTP/1.[01] ([0-9]+) .*", first_line)
+        match = re.match("HTTP/1.[01] ([0-9]+)", first_line)
-    return value
+    if isinstance(value, _UTF8_TYPES):
-import cgi
+    from urlparse import parse_qs  # Python 2.6+
-                arguments = cgi.parse_qs(self._request.body)
+                arguments = parse_qs(self._request.body)
-        arguments = cgi.parse_qs(query)
+        arguments = parse_qs(query)
-        open(_DEFAULT_CA_CERTS)
+        open(_DEFAULT_CA_CERTS).close()
-        self.assertEquals(self.response.code, 500)
+        self.assertEqual(self.response.code, 500)
-        self.assertEquals(handler.get_secure_cookie('foo'), b('bar'))
+        self.assertEqual(handler.get_secure_cookie('foo'), b('bar'))
-
+NoneType = type(None)
-        return "-".join([w.capitalize() for w in name.split("-")])
+        try:
-      return None
+        if contexts is _state.contexts or not contexts:
-        if (len(_state.contexts) > len(contexts) or
+        elif (len(_state.contexts) > len(contexts) or
-    if getattr(fn, 'stack_context_wrapped', False):
+    if isinstance(fn, (_StackContextWrapper, NoneType)):
-    return result
+    return _StackContextWrapper(wrapped, fn, _state.contexts)
-        self.assertEqual("Basic " + base64.b64encode("me:secret"),
+        self.assertEqual(b("Basic ") + base64.b64encode(b("me:secret")),
-import bisect
+import heapq
-                    poll_timeout = min(milliseconds, poll_timeout)
+                while self._timeouts:
-        bisect.insort(self._timeouts, timeout)
+        heapq.heappush(self._timeouts, timeout)
-        self._timeouts.remove(timeout)
+        # Removing from a heap is complicated, so just leave the defunct
-                (other.deadline, id(other.callback)))
+        return ((self.deadline, id(self)) <
-            raise
+    def _run_callback(self, callback, *args):
-                if not path.startswith("/") and not path.startswith("http:"):
+                if not is_absolute(path):
-                if not path.startswith("/") and not path.startswith("http:"):
+                if not is_absolute(path):
-        required, and we throw an HTTP 404 exception if it is missing.
+        required, and we throw an HTTP 400 exception if it is missing.
-                raise HTTPError(404, "Missing argument %s" % name)
+                raise HTTPError(400, "Missing argument %s" % name)
-        tornado.web.RequestHandler.__init__(self, application, request)
+    def __init__(self, application, request, **kwargs):
-def define(name, default=None, type=str, help=None, metavar=None,
+def define(name, default=None, type=None, help=None, metavar=None,
-    value is always a list.
+    If type is given (one of str, float, int, datetime, or timedelta)
-                                                     auth.encode("base64"))
+                                                     base64.b64encode(auth))
-            request_lines.append("%s: %s" % (k, v))
+            line = "%s: %s" % (k, v)
-            self.headers["Content-Length"] = int(environ["CONTENT_LENGTH"])
+            self.headers["Content-Length"] = environ["CONTENT_LENGTH"]
-                self.headers["Content-Length"])
+                int(self.headers["Content-Length"]))
-        reader = _TemplateReader(name, template_string)
+        reader = _TemplateReader(name, escape.utf8(template_string))
-        curl.setopt(pycurl.HTTPHEADER, [utf8("Expect: ")])
+        request.headers["Expect"] = ""
-        curl.setopt(pycurl.HTTPHEADER, utf8("Expect: "))
+        curl.setopt(pycurl.HTTPHEADER, [utf8("Expect: ")])
-                host = parsed.netloc
+            host = parsed.hostname
-                           parsed.netloc.partition(":")[0])
+                           parsed.hostname)
-                              self.request.auth_password)
+        username, password = None, None
-            headers["Expect"] = ""
+class SetUpTearDownTest(unittest.TestCase):
-    unittest.main
+    unittest.main()
-        If None is returned, we use the Accept-Language header.
+        If None is returned, we fall back to get_browser_locale().
-class MainHandler(BaseHandler, tornado.auth.FacebookMixin):
+class MainHandler(BaseHandler, tornado.auth.FacebookGraphMixin):
-            session_key=self.current_user["session_key"])
+        self.facebook_request("/me/home", self._on_stream,
-class AuthLoginHandler(BaseHandler, tornado.auth.FacebookMixin):
+import logging
-            self.get_authenticated_user(self.async_callback(self._on_auth))
+        my_url = (self.request.protocol + "://" + self.request.host +
-        self.authorize_redirect("read_stream")
+        self.authorize_redirect(redirect_uri=my_url,
-    @tornado.web.asynchronous
+class AuthLogoutHandler(BaseHandler, tornado.auth.FacebookGraphMixin):
-        return self.render_string("modules/post.html", post=post, actor=actor)
+    def render(self, post):
-version = "1.2"
+version = "1.2.1"
-version_info = (1, 2, 0)
+version = "1.2.1"
-          extra_fields = set(extra_fields)
+      fields = set(['id', 'name', 'first_name', 'last_name',
-                              client_secret, callback, extra_fields))
+                              client_secret, callback, fields))
-                        callback, extra_fields, response):
+                        callback, fields, response):
-              self._on_get_user_info, callback, session, extra_fields),
+              self._on_get_user_info, callback, session, fields),
-          fields="picture" # This one's exceptional in that it appends to fields returned
+          fields=",".join(fields)
-    def _on_get_user_info(self, callback, session, extra_fields, user):
+    def _on_get_user_info(self, callback, session, fields, user):
-
+from tornado.escape import _unicode
-        return value.decode("utf-8")
+        return _unicode(value)
-                f = open(abs_path)
+                f = open(abs_path, "rb")
-            b(" (") + utf8(self.request.remote_ip) + b(")")
+        return self.request.method + " " + self.request.uri + \
-    return _json_decode(value)
+    return _json_decode(_unicode(value))
-        self.assertEqual(json_decode(self.fetch('/%3F').body.decode('utf8')),
+        self.assertEqual(json_decode(self.fetch('/%3F').body),
-        self.assertEqual(json_decode(self.fetch('/%3F?%3F=%3F').body.decode('utf8')),
+        self.assertEqual(json_decode(self.fetch('/%3F?%3F=%3F').body),
-        parts = value.split(b("|"))
+        parts = utf8(value).split(b("|"))
-            eol = data.find(b("\r\n"))
+            data = data.decode('latin1')
-            name = name_values["name"]
+            name = name_values["name"].decode("utf-8")
-from tornado.escape import utf8
+from tornado.escape import utf8, _unicode
-            parsed = urlparse.urlsplit(self.request.url)
+            parsed = urlparse.urlsplit(_unicode(self.request.url))
-        self.assertEqual(json_decode(self.fetch('/%3F').body),
+        self.assertEqual(json_decode(self.fetch('/%3F').body.decode('utf8')),
-        self.assertEqual(json_decode(self.fetch('/%3F?%3F=%3F').body),
+        self.assertEqual(json_decode(self.fetch('/%3F?%3F=%3F').body.decode('utf8')),
-            ctype = headers.get("Content-Type", "").split(";")[0]
+            ctype = _unicode(headers.get("Content-Type", "")).split(";")[0]
-            with contextlib.nested(*new_contexts):
+            with _nested(*new_contexts):
-    deque.appendleft(b('').join(prefix))
+    # This data structure normally just contains byte strings, but
-        result |= ord(x) ^ ord(y)
+    if type(a[0]) is int:  # python3 byte strings
-from cStringIO import StringIO
+    from io import BytesIO  # python 3
-            buffer = StringIO()
+            buffer = BytesIO()
-            buffer = StringIO(data) # TODO: don't require one big string?
+            buffer = BytesIO(data) # TODO: don't require one big string?
-import cStringIO
+try:
-            self._gzip_value = cStringIO.StringIO()
+            self._gzip_value = BytesIO()
-        self.stream.read_until("\r\n\r\n", self._header_callback)
+        self.stream.read_until(b("\r\n\r\n"), self._header_callback)
-        self.stream.read_until("\r\n\r\n", self._header_callback)
+        self.stream.read_until(b("\r\n\r\n"), self._header_callback)
-            eol = data.find("\r\n")
+            eol = data.find(b("\r\n"))
-        assert isinstance(chunk, str)
+        assert isinstance(chunk, bytes_type)
-            callback("")
+            callback(b(""))
-    deque.appendleft(''.join(prefix))
+    deque.appendleft(b('').join(prefix))
-                                                     auth.encode("base64"))
+            auth = utf8(self.request.auth_username) + b(":") + \
-                self.request.body)
+            self.request.headers["Content-Length"] = str(len(
-                                             req_path)]
+        request_lines = [utf8("%s %s HTTP/1.1" % (self.request.method,
-        self.stream.write("\r\n".join(request_lines) + "\r\n\r\n")
+            request_lines.append(utf8(k) + b(": ") + utf8(v))
-        self.stream.read_until("\r\n\r\n", self._on_headers)
+            self.stream.write(utf8(self.request.body))
-            self.stream.read_until("\r\n", self._on_chunk_length)
+            self.stream.read_until(b("\r\n"), self._on_chunk_length)
-                                               self.headers["Location"])
+                                               utf8(self.headers["Location"]))
-            self._on_body(''.join(self.chunks))
+            self._on_body(b('').join(self.chunks))
-        assert data[-2:] == "\r\n"
+        assert data[-2:] == b("\r\n")
-        self.stream.read_until("\r\n", self._on_chunk_length)
+        self.stream.read_until(b("\r\n"), self._on_chunk_length)
-        self.stream.write("GET / HTTP/1.0\r\n\r\n")
+        self.stream.write(b("GET / HTTP/1.0\r\n\r\n"))
-        self.assertEqual(data, "HTTP/1.0 ")
+        self.assertEqual(data, b("HTTP/1.0 "))
-        self.assertEqual(data, "")
+        self.assertEqual(data, b(""))
-        self.assertEqual(data, "200")
+        self.assertEqual(data, b("200"))
-        self.assertEqual(response.body, "Hello world!")
+        self.assertEqual(response.body, b("Hello world!"))
-        self.assertEqual(response.body, "Hello Ben!")
+        self.assertEqual(response.body, b("Hello Ben!"))
-        self.assertEqual(chunks, ["Hello world!"])
+        self.assertEqual(chunks, [b("Hello world!")])
-        self.assertEqual(response.body, "Post arg1: foo, arg2: bar")
+        self.assertEqual(response.body, b("Post arg1: foo, arg2: bar"))
-        self.assertEqual(response.body, "asdfqwer")
+        self.assertEqual(response.body, b("asdfqwer"))
-        self.assertEqual(chunks, ["asdf", "qwer"])
+        self.assertEqual(chunks, [b("asdf"), b("qwer")])
-                         "Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==")
+                         b("Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ=="))
-        self.assertNotEqual(response.body, "asdfqwer")
+        self.assertNotEqual(response.body, b("asdfqwer"))
-        self.assertEqual(f.read(), "asdfqwer")
+        self.assertEqual(f.read(), b("asdfqwer"))
-        self.assertEqual("Zero", response.body)
+        self.assertTrue(response.effective_url.endswith(b("/countdown/0")))
-        self.assertTrue(response.effective_url.endswith("/countdown/2"))
+        self.assertTrue(response.request.url.endswith(b("/countdown/5")))
-        self.assertTrue('got expected exception' in self.response.body)
+        self.assertTrue(b('got expected exception') in self.response.body)
-from tornado.escape import json_decode
+from tornado.escape import json_decode, utf8
-        self.assertEquals(handler.get_secure_cookie('foo'), 'bar')
+        handler.set_secure_cookie('foo', b('bar'))
-        handler.set_secure_cookie('foo', '\xd7m\xf8\xe7\xae\xfc')
+        handler.set_secure_cookie('foo', binascii.a2b_hex(b('d76df8e7aefc')))
-        match = re.match(r'12345678\|([0-9]+)\|([0-9a-f]+)', cookie)
+        match = re.match(b(r'12345678\|([0-9]+)\|([0-9a-f]+)'), cookie)
-                                                   '5678' + timestamp), sig)
+        self.assertEqual(
-        handler._cookies['foo'] = '1234|5678%s|%s' % (timestamp, sig)
+        handler._cookies['foo'] = utf8('1234|5678%s|%s' % (timestamp, sig))
-        self.stream.write("GET / HTTP/1.0\r\n\r\n")
+        self.stream.write(b("GET / HTTP/1.0\r\n\r\n"))
-            safe_value = re.sub(r"[\x00-\x1f]", " ", value)[:4000]
+            safe_value = re.sub(b(r"[\x00-\x1f]"), b(" "), value)[:4000]
-        values = [_unicode(x) for x in values]
+        values = [re.sub(r"[\x00-\x08\x0e-\x1f]", " ", _unicode(x)) 
-        value = base64.b64encode(value)
+        timestamp = utf8(str(int(time.time())))
-        value = "|".join([value, timestamp, signature])
+        value = b("|").join([value, timestamp, signature])
-        parts = value.split("|")
+        parts = value.split(b("|"))
-        if parts[1].startswith("0"):
+        if parts[1].startswith(b("0")):
-        hash = hmac.new(self.application.settings["cookie_secret"],
+        hash = hmac.new(utf8(self.application.settings["cookie_secret"]),
-        return hash.hexdigest()
+        for part in parts: hash.update(utf8(part))
-        self.set_header("Location", urlparse.urljoin(self.request.uri, url))
+        url = re.sub(b(r"[\x00-\x20]+"), "", utf8(url))
-        chunk = "".join(self._write_buffer)
+        chunk = b("").join(self._write_buffer)
-            headers = ""
+            headers = b("")
-        lines.extend(["%s: %s" % (n, v) for n, v in self._headers.iteritems()])
+        lines = [utf8(self.request.version + " " +
-        return "\r\n".join(lines) + "\r\n\r\n"
+                lines.append(b("Set-Cookie: ") + cookie.OutputString(None))
-            self.request.remote_ip + ")"
+        return utf8(self.request.method) + b(" ") + utf8(self.request.uri) + \
-                block = ("%x" % len(block)) + "\r\n" + block + "\r\n"
+                block = utf8("%x" % len(block)) + b("\r\n") + block + b("\r\n")
-                block += "0\r\n\r\n"
+                block += b("0\r\n\r\n")
-    if isinstance(s, str):
+    if isinstance(s, bytes_type):
-            value = _utf8(value)
+            value = utf8(value)
-        value = _utf8(value)
+        name = utf8(name)
-        url = re.sub(r"[\x00-\x20]+", "", _utf8(url))
+        url = re.sub(r"[\x00-\x20]+", "", utf8(url))
-        chunk = _utf8(chunk)
+        chunk = utf8(chunk)
-            if embed_part: js_embed.append(_utf8(embed_part))
+            if embed_part: js_embed.append(utf8(embed_part))
-            if embed_part: css_embed.append(_utf8(embed_part))
+            if embed_part: css_embed.append(utf8(embed_part))
-            if head_part: html_heads.append(_utf8(head_part))
+            if head_part: html_heads.append(utf8(head_part))
-            if body_part: html_bodies.append(_utf8(body_part))
+            if body_part: html_bodies.append(utf8(body_part))
-        self.assertEqual(seen, [0, 1])
+        self.assertEqual(set(seen), set([0, 1]))
-            self._waker_writer.write("x")
+            self._waker_writer.write(utf8("x"))
-                self._waker_reader.read()
+                result = self._waker_reader.read()
-                   (other.deadline, id(other.callback)))
+    def __lt__(self, other):
-    assert isinstance(value, str)
+    assert isinstance(value, bytes)
-    if isinstance(value, str):
+    if isinstance(value, bytes):
-            fg_color = curses.tigetstr("setaf") or curses.tigetstr("setf") or ""
+            # The curses module has some str/bytes confusion in python3.
-                logging.ERROR: curses.tparm(fg_color, 1), # Red
+                logging.DEBUG: unicode(curses.tparm(fg_color, 4), # Blue
-            self._normal = curses.tigetstr("sgr0")
+            self._normal = unicode(curses.tigetstr("sgr0"), "ascii")
-                        AsyncHTTPClient._impl_class = CurlAsyncHTTPClient
+                    from tornado.simple_httpclient import SimpleAsyncHTTPClient
-    can execute in parallel on each IOLoop.
+    The constructor for this class is magic in several respects:  It actually
-    _ASYNC_CLIENTS = weakref.WeakKeyDictionary()
+    _async_clients = weakref.WeakKeyDictionary()
-            return cls._ASYNC_CLIENTS[io_loop]
+        if io_loop in cls._async_clients and not force_instance:
-            instance.initialize(io_loop, max_clients, **kwargs)
+                if cls._impl_class is None:
-                cls._ASYNC_CLIENTS[io_loop] = instance
+                cls._async_clients[io_loop] = instance
-            del self._ASYNC_CLIENTS[self.io_loop]
+        if self._async_clients[self.io_loop] is self:
-
+    define('httpclient', type=str, default=None)
-from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, main
+from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient, main
-            return instance
+        try:
-        del AsyncHTTPClient._ASYNC_CLIENTS[self.io_loop]
+        super(CurlAsyncHTTPClient, self).close()
-
+import weakref
-    from tornado.simple_httpclient import AsyncHTTPClient
+    from tornado.simple_httpclient import SimpleAsyncHTTPClient as AsyncImpl
-    from tornado.curl_httpclient import AsyncHTTPClient
+    from tornado.curl_httpclient import CurlAsyncHTTPClient as AsyncImpl
-from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError
+from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, AsyncHTTPClient
-class AsyncHTTPClient(object):
+class SimpleAsyncHTTPClient(AsyncHTTPClient):
-                hostname_mapping=None):
+    def initialize(self, io_loop=None, max_clients=10,
-        pass
+        self.io_loop = io_loop
-    client = AsyncHTTPClient()
+    client = SimpleAsyncHTTPClient()
-        self.http_client = SimpleAsyncHTTPClient(io_loop=self.io_loop)
+        self.http_client = SimpleAsyncHTTPClient(io_loop=self.io_loop,
-            if self.request.method not in ("GET", "HEAD") and \
+            if self.request.method not in ("GET", "HEAD", "OPTIONS") and \
-                events[fd] = events.get(fd, 0) | IOLoop.WRITE
+                if kevent.flags & select.KQ_EV_EOF:
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase, get_unused_port
-            self.body = environ["wsgi.input"].read()
+            self.body = environ["wsgi.input"].read(
-        raise
+import pycurl
-
+import os
-from tornado.curl_httpclient import AsyncHTTPClient
+# If the environment variable USE_SIMPLE_HTTPCLIENT is set to a non-empty
-class SimpleAsyncHTTPClient(object):
+class AsyncHTTPClient(object):
-        """Creates a SimpleAsyncHTTPClient.
+        """Creates a AsyncHTTPClient.
-        Only a single SimpleAsyncHTTPClient instance exists per IOLoop
+        Only a single AsyncHTTPClient instance exists per IOLoop
-            instance = super(SimpleAsyncHTTPClient, cls).__new__(cls)
+            instance = super(AsyncHTTPClient, cls).__new__(cls)
-    client = SimpleAsyncHTTPClient()
+    client = AsyncHTTPClient()
-
+from tornado.httpclient import HTTPRequest, HTTPResponse, HTTPError, main
-            print response.body
+from tornado.ioloop import IOLoop
-from tornado.curl_httpclient import AsyncHTTPClient, HTTPClient
+def main():
-from tornado.curl_httpclient import *
+from tornado.curl_httpclient import AsyncHTTPClient, HTTPClient
-
+from tornado.escape import utf8
-from tornado import escape
+from tornado.escape import utf8
-        self.url = _utf8(url)
+        self.url = utf8(url)
-        self.auth_password = _utf8(auth_password)
+        self.auth_username = utf8(auth_username)
-                    [_utf8("%s: %s" % i) for i in request.headers.get_all()])
+                    [utf8("%s: %s" % i) for i in request.headers.get_all()])
-                    [_utf8("%s: %s" % i) for i in request.headers.iteritems()])
+                    [utf8("%s: %s" % i) for i in request.headers.iteritems()])
-        curl.setopt(pycurl.USERAGENT, _utf8(request.user_agent))
+        curl.setopt(pycurl.USERAGENT, utf8(request.user_agent))
-        request_buffer =  cStringIO.StringIO(escape.utf8(request.body))
+        request_buffer =  cStringIO.StringIO(utf8(request.body))
-
+    if value is None:
-    main()
+from tornado.curl_httpclient import *
-
+major, minor = sys.version_info[:2]
-version = "1.1.1"
+version = "1.2"
-version_info = (1, 1, 1)
+version = "1.2"
-                                               '/ca-certificates.crt')
+                    ssl_options["ca_certs"] = _DEFAULT_CA_CERTS
-from tornado.simple_httpclient import SimpleAsyncHTTPClient
+from tornado.simple_httpclient import SimpleAsyncHTTPClient, _DEFAULT_CA_CERTS
-extensions = []
+
-            if self._read_delimiter or self._read_bytes:
+            if self.reading():
-            if self._write_buffer:
+            if self.writing():
-                self._add_io_state(self.io_loop.READ)
+                self._handshake_reading = True
-                self._add_io_state(self.io_loop.WRITE)
+                self._handshake_writing = True
-        client.fetch(arg, callback)
+            if options.print_headers:
-    curl.setopt(pycurl.SSL_VERIFYPEER, request.validate_cert)
+    if request.validate_cert:
-                self.callback(HTTPResponse(self.request, 599, error=e))
+                callback = self.callback
-                                                       "Connection closed")))
+            callback = self.callback
-        curl.unsetopt(pycurl.CAINFO)
+        # There is no way to restore pycurl.CAINFO to its default value
-    of outstanding requests.
+    This class has not been tested extensively in production and
-                "network interface selection not supported")
+        for key in ('network_interface',
-                _merge_prefix(self._write_buffer, 128 * 1024)
+                if not self._write_buffer_frozen:
-from cStringIO import StringIO
+import sys
-        self._read_buffer = StringIO()
+        self._read_buffer = collections.deque()
-        if self._read_buffer.tell() >= self.max_buffer_size:
+        self._read_buffer.append(chunk)
-            if self._read_buffer.tell() >= self._read_bytes:
+            if self._read_buffer_size() >= self._read_bytes:
-            loc = self._read_buffer.getvalue().find(self._read_delimiter)
+            _merge_prefix(self._read_buffer, sys.maxint)
-        return buffered_string[:loc]
+        _merge_prefix(self._read_buffer, loc)
-        self._write_buffer = StringIO()
+        self._write_buffer = collections.deque()
-        self._write_buffer.write(data)
+        self._write_buffer.append(data)
-        return self._write_buffer.tell() > 0
+        return bool(self._write_buffer)
-            if self._write_buffer.tell():
+            if self._write_buffer:
-        while self._write_buffer.tell():
+        while self._write_buffer:
-                self._write_buffer.write(buffered_string[num_bytes:])
+                _merge_prefix(self._write_buffer, 128 * 1024)
-        if not self._write_buffer.tell() and self._write_callback:
+        if not self._write_buffer and self._write_callback:
-                                buffer=buffer)
+        original_request = getattr(self.request, "original_request",
-from tornado.web import Application, RequestHandler, asynchronous
+from tornado.web import Application, RequestHandler, asynchronous, url
-                                              wake_callback=self.stop)),
+            url("/hello", HelloWorldHandler),
-        self.stream.close()
+        self.stream.close()
-                 proxy_password='', allow_nonstandard_methods=False):
+                 proxy_password='', allow_nonstandard_methods=False,
-                    )
+                ssl_options = {}
-                               prepare_curl_callback=disable_cert_check,
+                               validate_cert=False,
-                                      do_handshake_on_connect=False)
+                                      do_handshake_on_connect=False,
-                # TODO: cert verification, etc
+                ssl_options = dict(
-                                          io_loop=self.io_loop)
+                                          io_loop=self.io_loop,
-        super(SSLIOStream, self)._handle_connect()
+        # Don't call the superclass's _handle_connect (which is responsible
-                force_instance=False):
+                force_instance=False,
-                _HTTPConnection(self.io_loop, request,
+                _HTTPConnection(self.io_loop, self, request,
-    def __init__(self, io_loop, request, callback):
+    def __init__(self, io_loop, client, request, callback):
-            raise HTTPError(404)
+                if uri:  # don't try to redirect '/' to ''
-            if self.request.method == "POST" and \
+            if self.request.method not in ("GET", "HEAD") and \
-    version="1.1",
+    version="1.1.1",
-version_info = (1, 1, 0)
+version = "1.1.1"
-        as a potential forgery.
+        To prevent cross-site request forgery, we set an '_xsrf'
-        token = self.get_argument("_xsrf", None)
+        token = (self.get_argument("_xsrf", None) or
-    {% block %}
+    {% end %}
-            "Sec-WebSocket-Location: %(scheme)s://%(host)s%(path)s\r\n\r\n" % (dict(
+            "Sec-WebSocket-Location: %(scheme)s://%(host)s%(uri)s\r\n\r\n" % (dict(
-                    path=self.request.path)))
+                    uri=self.request.uri)))
-                   self._request_summary(), request_time)
+        """Logs the current request.
-            elif isinstance(connection.stream, iostream.SSLIOStream):
+            elif connection and isinstance(connection.stream, 
-            self.protocol = protocol or "http"
+            if protocol:
-                self, request, "http://" + self.default_host + "/")
+                self, request, url="http://" + self.default_host + "/")
-        except:
+            return self.connection.stream.socket.getpeercert()
-            if self._write_buffer.getvalue():
+            if self._write_buffer.tell():
-        while self._write_buffer.getvalue():
+        while self._write_buffer.tell():
-        if not self._write_buffer.getvalue() and self._write_callback:
+        if not self._write_buffer.tell() and self._write_callback:
-        """Calls the given callback on the next I/O loop iteration."""
+        """Calls the given callback on the next I/O loop iteration.
-                self._write_buffer.reset()
+                self._write_buffer = StringIO()
-        self._read_buffer.reset()
+        self._read_buffer = StringIO()
-        return len(self._write_buffer.getvalue()) > 0
+        return self._write_buffer.tell() > 0
-        if len(self._read_buffer.getvalue()) >= self.max_buffer_size:
+        if self._read_buffer.tell() >= self.max_buffer_size:
-            if len(self._read_buffer.getvalue()) >= self._read_bytes:
+            if self._read_buffer.tell() >= self._read_bytes:
-                self._write_buffer = StringIO()
+                self._write_buffer.reset()
-        self._read_buffer = StringIO()
+        self._read_buffer.reset()
-        self._write_buffer = ""
+        self._read_buffer = StringIO()
-        self._write_buffer += data
+        self._write_buffer.write(data)
-        return len(self._write_buffer) > 0
+        return len(self._write_buffer.getvalue()) > 0
-            if self._write_buffer:
+            if self._write_buffer.getvalue():
-        if len(self._read_buffer) >= self.max_buffer_size:
+        self._read_buffer.write(chunk)
-            if len(self._read_buffer) >= self._read_bytes:
+            if len(self._read_buffer.getvalue()) >= self._read_bytes:
-            loc = self._read_buffer.find(self._read_delimiter)
+            loc = self._read_buffer.getvalue().find(self._read_delimiter)
-        while self._write_buffer:
+        while self._write_buffer.getvalue():
-                self._write_buffer = self._write_buffer[num_bytes:]
+                buffered_string = self._write_buffer.getvalue()
-        if not self._write_buffer and self._write_callback:
+        if not self._write_buffer.getvalue() and self._write_callback:
-        return result
+        buffered_string = self._read_buffer.getvalue()
-        self._callbacks = set()
+        self._callbacks = []
-            callbacks = list(self._callbacks)
+            callbacks = self._callbacks
-                    self._run_callback(callback)
+                self._run_callback(callback)
-        self._callbacks.add(stack_context.wrap(callback))
+        self._callbacks.append(stack_context.wrap(callback))
-        if path not in hashes:
+        abs_path = os.path.join(self.application.settings["static_path"],
-                hashes[path] = hashlib.md5(f.read()).hexdigest()
+                f = open(abs_path)
-                hashes[path] = None
+                hashes[abs_path] = None
-            return base + static_url_prefix + path + "?v=" + hashes[path][:5]
+        if hashes.get(abs_path):
-                          self.request, exc_info=e)
+                          self.request, exc_info=True)
-        self._handle_request_exception(value)
+        try:
-                handler = ErrorHandler(self, request, 404)
+                handler = ErrorHandler(self, request, status_code=404)
-        RequestHandler.__init__(self, application, request)
+    def initialize(self, status_code):
-        RequestHandler.__init__(self, application, request)
+    def initialize(self, url, permanent=True):
-        RequestHandler.__init__(self, application, request)
+    def initialize(self, path, default_filename=None):
-        RequestHandler.__init__(self, app, request)
+    def initialize(self, fallback):
-import tornado.httpserver
+#!/usr/bin/env python
-        _state.contexts = self.old_contexts + (self.context_factory,)
+        # _state.contexts is a tuple of (class, arg) pairs
-    '''Specialization of StackContext for exception handling.
+class ExceptionStackContext(object):
-    exception_handler function.
+        The supplied exception_handler function will be called in the
-        def __exit__(self, type, value, traceback):
+        If the exception handler returns true, the exception will be
-    return StackContext(Context)
+                return self.exception_handler(type, value, traceback)
-            any(a is not b
+            any(a[1] is not b[1]
-                            [StackContext(c) for c in contexts])
+                            [cls(arg) for (cls,arg) in contexts])
-                            for c in contexts[len(_state.contexts):]]
+            new_contexts = [cls(arg)
-      with StackContext(my_context):
+class StackContext(object):
-        _state.contexts = old_contexts
+    class Context(object):
-def NullContext():
+class NullContext(object):
-    try:
+    def __enter__(self):
-        _state.contexts = old_contexts
+
-        if new_contexts:
+        if len(new_contexts) > 1:
-            self._handle_request_exception(e)
+    def _stack_context_handle_exception(self, type, value, traceback):
-        with stack_context.StackContext(self._stack_context):
+        with stack_context.ExceptionStackContext(
-                 "remote_ip", "body")
+                 "body")
-                              code, callback):
+                              code, callback, extra_fields=None):
-                              client_secret, callback))
+                              client_secret, callback, extra_fields))
-                        callback, response):
+                        callback, extra_fields, response):
-      "expires": cgi.parse_qs(response.body).get("expires")
+          "access_token": cgi.parse_qs(response.body)["access_token"][-1],
-              self._on_get_user_info, callback, session),
+              self._on_get_user_info, callback, session, extra_fields),
-          fields="picture"
+          fields="picture" # This one's exceptional in that it appends to fields returned
-    def _on_get_user_info(self, callback, session, user):
+    def _on_get_user_info(self, callback, session, extra_fields, user):
-        })
+
-        callback_uri = callback_uri or self.request.path
+        callback_uri = callback_uri or self.request.uri
-            
+
-        
+
-        callback_uri = callback_uri or self.request.path
+        callback_uri = callback_uri or self.request.uri
-        callback_uri = callback_uri or self.request.path
+        callback_uri = callback_uri or self.request.uri
-            self.stream.read_bytes(content_length, self._on_request_body)
+        try:
-            if (self._status_code == 200 and self.request.method == "GET" and
+            if (self._status_code == 200 and
-            if self.request.method == "GET":
+            if self.request.method in ("GET", "HEAD"):
-            if self.request.method == "GET":
+            if self.request.method in ("GET", "HEAD"):
-            if self.request.method == "GET":
+            if self.request.method in ("GET", "HEAD"):
-            paths = set()
+            paths = []
-                    paths.add(path)
+                    path = self.static_url(path)
-                    k, sep, v = field.partition("=")
+                    k, sep, v = field.strip().partition("=")
-        encountered during the request. You can call response.reraise() to
+        encountered during the request. You can call response.rethrow() to
-                    if boundary: self._parse_mime_body(boundary, data)
+                fields = content_type.split(";")
-    def listen(self, port, **kwargs):
+    def listen(self, port, address="", **kwargs):
-        bind/start methods directly.
+        and calling its listen method.  Keyword arguments not
-        server.listen(port)
+        server.listen(port, address)
-            if e.errno not in (errno.EINPROGRESS, errno.EWOULDBLOCK):
+            if e.args[0] not in (errno.EINPROGRESS, errno.EWOULDBLOCK):
-    
+
-    http_server.listen(options.port)
+    app = Application()
-        http_server.listen(8888)
+        application.listen(8888)
-getting started guide.
+See the Tornado walkthrough on http://tornadoweb.org for more details
-                max_simultaneous_connections=None):
+                max_simultaneous_connections=None,
-        if io_loop in cls._ASYNC_CLIENTS:
+        if io_loop in cls._ASYNC_CLIENTS and not force_instance:
-            cls._ASYNC_CLIENTS[io_loop] = instance
+            instance.queue = collections.deque()
-        _HTTPConnection(self.io_loop, request, callback)
+        self.queue.append((request, callback))
-        self.io_loop = io_loop or IOLoop.instance()
+    _ASYNC_CLIENTS = weakref.WeakKeyDictionary()
-from tornado.web import Application, RequestHandler
+from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase, get_unused_port
-        """Calls the given callback at the time deadline from the I/O loop."""
+        """Calls the given callback at the time deadline from the I/O loop.
-    "ko_KR": {"name_en": u"Korean", "name": u"\xed\xea\xec"},
+    "ja_JP": {"name_en": u"Japanese", "name": u"\u65e5\u672c\u8a9e"},
-    "zh_TW": {"name_en": u"Chinese (Taiwan)", "name": u"\xe4\xe6(\xe5\xe7)"},
+    "zh_CN": {"name_en": u"Chinese (Simplified)", "name": u"\u4e2d\u6587(\u7b80\u4f53)"},
-            self.protocol = self.headers.get("X-Scheme", protocol) or "http"
+            # AWS uses X-Forwarded-Proto
-            "Sec-WebSocket-Location: ws://%(host)s%(path)s\r\n\r\n" % (dict(
+            "Sec-WebSocket-Location: %(scheme)s://%(host)s%(path)s\r\n\r\n" % (dict(
-        elif operator in ("extends", "include", "set", "import", "comment"):
+        elif operator in ("extends", "include", "set", "import", "from",
-            elif operator == "import":
+            elif operator in ("import", "from"):
-        if socket is None:
+        if self.socket is None:
-        self.stream.read_until("\r\n\r\n", self._on_headers)
+        # Save stack context here, outside of any request.  This keeps
-        self.stream.read_until("\r\n\r\n", self._on_headers)
+        self.stream.read_until("\r\n\r\n", self._header_callback)
-_URL_RE = re.compile(ur"""(?i)\b((?:([a-z][\w-]+):(?:(/{1,3})|[a-z0-9%])|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>&]+|&amp;|\(([^\s()<>&]+|(\([^\s()<>&]+\)))*\))+(?:\(([^\s()<>&]+|(\([^\s()<>&]+\)))*\)|[^\s`!()\[\]{};:'".,<>?\xab\xbb\u201c\u201d\u2018\u2019&]))""")
+# I originally used the regex from 
-        self.set_header("Content-Length", stat_result[stat.ST_SIZE])
+            elif err.args[0] == ssl.SSL_ERROR_SSL:
-        if events & self.io_loop.ERROR:
+        try:
-            self.io_loop.update_handler(self.socket.fileno(), self._state)
+            raise
-                          exc_info=True)
+            self.handle_callback_exception(info["callback"])
-            ])
+            ], gzip=True)
-        response = self.fetch(self.get_url("/hello"))
+        response = self.fetch("/hello")
-        response = self.fetch(self.get_url("/hello?name=Ben"))
+        response = self.fetch("/hello?name=Ben")
-        response = self.fetch(self.get_url("/hello"),
+        response = self.fetch("/hello",
-        response = self.fetch(self.get_url("/post"), method="POST",
+        response = self.fetch("/post", method="POST",
-        response = self.fetch(self.get_url("/chunk"))
+        response = self.fetch("/chunk")
-        response = self.fetch(self.get_url("/chunk"),
+        response = self.fetch("/chunk",
-    self.finish("Hello %s!" % name)
+    def get(self):
-        self.get_argument("arg1"), self.get_argument("arg2")))
+    def post(self):
-    self.write("qwer")
+    def get(self):
-    return self.wait()
+    def fetch(self, url, **kwargs):
-        ])
+    def get_app(self):
-    self.http_client = SimpleAsyncHTTPClient(io_loop=self.io_loop)
+    def setUp(self):
-    self.assertEqual(response.body, "Hello world!")
+    def test_hello_world(self):
-    self.assertEqual(response.body, "Hello Ben!")
+        response = self.fetch(self.get_url("/hello?name=Ben"))
-    self.assertFalse(response.body)
+    def test_streaming_callback(self):
-    self.assertEqual(response.body, "Post arg1: foo, arg2: bar")
+    def test_post(self):
-    self.assertFalse(response.body)
+    def test_chunked(self):
-                self.redirect(self.request.path + os.path.sep)
+            if not self.request.path.endswith("/"):
-    packages = ["tornado"],
+    packages = ["tornado", "tornado.test"],
-    def __init__(self, application, request, path):
+    def __init__(self, application, request, path, default_filename=None):
-        if not abspath.startswith(self.root):
+        # os.path.abspath strips a trailing /
-                    challenge=challenge)))
+        self.stream.write("%s" % challenge)
-        stream.read_until("\r\n\r\n", on_headers)
+        stream.connect(("friendfeed.com", 80), send_request)
-        docstring for this class).
+        as soon as the connection is ready.  Calling IOStream read
-            if e.errno != errno.EINPROGRESS:
+            # In non-blocking mode connect() always raises an exception
-        import iostream
+        from tornado import ioloop
-        stream.write("GET / HTTP/1.0\r\n\r\n")
+        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)
-    """Sets up an SSL connection in a non-blocking manner"""
+    """A utility class to write to and read from a non-blocking socket.
-        self._do_ssl_handshake()
+    def _handle_connect(self):
-            self.stream = IOStream(sock, io_loop=self.io_loop)
+
-      sys.exit(1)
+    @contextlib.contextmanager
-  ioloop.start()
+    with StackContext(die_on_error):
-        if date > now: date = now
+        if date > now:
-            callback(*args, **kwargs)
+            # Use a NullContext to ensure that all StackContexts are run
-import pycurl
+try:
-import pycurl
+try:
-if (ssl is None or
+if (ssl is None or pycurl is None or
-                num_bytes = self.socket.send(self._write_buffer)
+                # On windows, socket.send blows up if given a write buffer
-            self.socket.fileno(), self._handle_events, self._state)
+        with stack_context.NullContext():
-        self._read_callback = callback
+        self._read_callback = stack_context.wrap(callback)
-        self._read_callback = callback
+        self._read_callback = stack_context.wrap(callback)
-        self._write_callback = callback
+        self._write_callback = stack_context.wrap(callback)
-        self._close_callback = callback
+        self._close_callback = stack_context.wrap(callback)
-    return utf8(xml.sax.saxutils.escape(value, {'"': "&quot;"}))
+    return xml.sax.saxutils.escape(value, {'"': "&quot;"})
-        self.__stop_args = _arg or kwargs
+        assert _arg is None or not kwargs
-        """Wrap callbacks with this if they are used on asynchronous requests.
+        """Obsolete - catches exceptions from the wrapped function.
-        Catches exceptions and properly finishes the request.
+        This function is unnecessary since Tornado 1.1.
-        if events & IOLoop.ERROR: self.error_fds.add(fd)
+        if events & IOLoop.ERROR:
-
+        if not chunk:
-from tornado.web import RequestHandler, _O, authenticated, Application
+from tornado.web import RequestHandler, _O, authenticated, Application, asynchronous
-        AsyncHTTPTestCase.__next_port = self.__port + 1
+        if self.__port is None:
-            new_contexts.append(StackContext(new))
+        # If we're moving down the stack, _state.contexts is a prefix
-        self.active_contexts = set()
+        self.active_contexts = []
-        self.active_contexts.add(name)
+        self.active_contexts.append(name)
-        self.active_contexts.remove(name)
+        self.assertEqual(self.active_contexts.pop(), name)
-            self.io_loop.add_callback(callback)
+            self.assertEqual(self.active_contexts[-2:],
-            assert 'library' not in self.active_contexts
+            # implementation detail:  the full context stack at this point
-                request, "http://" + self.default_host + "/")
+                self, request, "http://" + self.default_host + "/")
-        if s is not None:
+        self._blocking_signal_threshold = seconds
-        self.set_blocking_signal_threshold(s, self.log_stack)
+        self.set_blocking_signal_threshold(seconds, self.log_stack)
-        self.set_cookie(name, value, expires_days=expires_days, **kwargs)
+        return value
-        self._blocking_log_threshold = None
+        self._blocking_signal_threshold = None
-        Pass None to disable.  Requires python 2.6 on a unixy platform.
+    def set_blocking_signal_threshold(self, seconds, action):
-            logging.error("set_blocking_log_threshold requires a signal module "
+            logging.error("set_blocking_signal_threshold requires a signal module "
-        self._blocking_log_threshold = s
+        self._blocking_signal_threshold = s
-            signal.signal(signal.SIGALRM, self._handle_alarm)
+            signal.signal(signal.SIGALRM,
-    def _handle_alarm(self, signal, frame):
+    def log_stack(self, signal, frame):
-                     ''.join(traceback.format_stack(frame)))
+                        self._blocking_signal_threshold,
-            if self._blocking_log_threshold is not None:
+            if self._blocking_signal_threshold is not None:
-            if self._blocking_log_threshold is not None:
+            if self._blocking_signal_threshold is not None:
-                                 self._blocking_log_threshold, 0)
+                                 self._blocking_signal_threshold, 0)
-        if self._blocking_log_threshold is not None:
+        if self._blocking_signal_threshold is not None:
-        self._check_closed()
+        while True:
-        self._check_closed()
+        while True:
-                return
+                return None
-        if not chunk:
+                raise
-            return
+            raise
-            return
+            raise IOError("Reached maximum read buffer size")
-    def test_ssl(self):
+    def fetch(self, path, **kwargs):
-        self.http_client.fetch(self.get_url('/').replace('http', 'https'),
+        self.http_client.fetch(self.get_url(path).replace('http', 'https'),
-        response = self.wait()
+                               prepare_curl_callback=disable_cert_check,
-        import win32_support as fcntl
+        from tornado import win32_support
-        import win32_support as fcntl
+        from tornado import win32_support as fcntl
-            self._waker_writer = os.fdopen(w, "w", 0)
+            self._waker_reader = os.fdopen(r, "rb", 0)
-                    RequestHandler._templates.values())
+                for loader in RequestHandler._templates.values():
-                ret = e[0]
+                ret = e.args[0]
-                    ret = e[0]
+                    ret = e.args[0]
-                    ret = e[0]
+                    ret = e.args[0]
-                if e[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
+                if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
-                    if e[0] not in (errno.EWOULDBLOCK, errno.EAGAIN):
+                    if e.args[0] not in (errno.EWOULDBLOCK, errno.EAGAIN):
-                    if e[0] == errno.EPIPE:
+                    if e.args[0] == errno.EPIPE:
-            if e[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
+            if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
-                if e[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
+                if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
-      "expires": cgi.parse_qs(response.body)["expires"]
+      "expires": cgi.parse_qs(response.body).get("expires")
-                    (isinstance(getattr(e, 'args'), tuple) and
+                if (getattr(e, 'errno', None) == errno.EINTR or
-    version="1.1",
+    version=version,
-        self.start()
+        if self._running:
-    version="1.0",
+    version="1.1",
-version_info = (1, 0, 1)
+version = "1.1"
-    # Don't try to run ssl tests if we don't have the ssl module
+if (ssl is None or
-    if threading.active_count() > 1:
+    if threading.activeCount() > 1:
-        # threading.active_count.
+        # threading.activeCount.
-    type. The only communication methods available to you are send_message()
+    type. The only communication methods available to you are write_message()
-                    challeng=challenge)))
+                    challenge=challenge)))
-    _json_encode = lambda v: json.dumps(v)
+    _json_decode = json.loads
-    def authorize_redirect(self, callback_uri=None):
+
-            self._on_request_token, self._OAUTH_AUTHORIZE_URL, callback_uri))
+        if getattr(self, "_OAUTH_VERSION", "1.0a") == "1.0a":
-        cookie_key, cookie_secret = request_cookie.split("|")
+        self.clear_cookie("_oauth_request_token")
-    def _oauth_request_token_url(self):
+    def _oauth_request_token_url(self, callback_uri= None, extra_params=None):
-            oauth_version="1.0",
+            oauth_version=getattr(self, "_OAUTH_VERSION", "1.0a"),
-        signature = _oauth_signature(consumer_token, "GET", url, args)
+        if getattr(self, "_OAUTH_VERSION", "1.0a") == "1.0a":
-        data = "|".join([request_token["key"], request_token["secret"]])
+        data = "|".join([base64.b64encode(request_token["key"]),
-            oauth_version="1.0",
+            oauth_version=getattr(self, "_OAUTH_VERSION", "1.0a"),
-                                     request_token)
+        if "verifier" in request_token:
-            oauth_version="1.0",
+            oauth_version=getattr(self, "_OAUTH_VERSION", "1.0a"),
-                                     access_token)
+        if getattr(self, "_OAUTH_VERSION", "1.0a") == "1.0a":
-    _OAUTH_NO_CALLBACKS = True
+    _OAUTH_NO_CALLBACKS = False
-
+class FacebookGraphMixin(OAuth2Mixin):
-        http_server.start() # Forks multiple sub-processes
+        http_server.start(0) # Forks multiple sub-processes
-    start() detects the number of CPUs on this machine and "pre-forks" that
+    start(0) detects the number of CPUs on this machine and "pre-forks" that
-    SUPPORTED_METHODS = ("GET", "HEAD", "POST", "DELETE", "PUT")
+    SUPPORTED_METHODS = ("GET", "HEAD", "POST", "DELETE", "PUT", "OPTIONS")
-            start, stop, step = slice.indices(size)
+            start, stop, step = key.indices(size)
-        """Appends the given handlers to our handler list."""
+        """Appends the given handlers to our handler list.
-            credentials = '%s:%s' % (request.proxy_username, 
+            credentials = '%s:%s' % (request.proxy_username,
-        self._running = True
+        self._running = False
-            "Server": "TornadoServer/1.0",
+            "Server": "TornadoServer/%s" % tornado.version,
-#     This also means that you don't have to explicitly invoke 
+#     This also means that you don't have to explicitly invoke
-    Override on_message to handle incoming messages. You can also override 
+    Override on_message to handle incoming messages. You can also override
- 
+
- 
+
- 
+
- 
+
- 
+
- 
+
- 
+
-             self.request.path, challenge))
+            "Server: TornadoServer/%(version)s\r\n"
-        
+
-        
+
-    
+
-    specified in 
+    specified in
-        fields = ("Origin", "Host", "Sec-Websocket-Key1", 
+        fields = ("Origin", "Host", "Sec-Websocket-Key1",
-            headers.append(("Server", "TornadoServer/0.1"))
+            headers.append(("Server", "TornadoServer/%s" % tornado.version))
-from tornado.web import authenticated, Application, RequestHandler
+from tornado.web import Application, RequestHandler
-from tornado.web import RequestHandler, _O
+from tornado.testing import LogTrapTestCase, AsyncHTTPTestCase
-        self.http_server = HTTPServer(self._app, io_loop=self.io_loop)
+        self.http_server = HTTPServer(self._app, io_loop=self.io_loop,
-                                                 do_handshake_on_connect=False, 
+                    connection = ssl.wrap_socket(connection,
-                    logging.error("SSL Error in SSL wrap:", exc_info=True)
+                    else:
-                    logging.error("Socket Error in SSL wrap:", exc_info=True)
+                    else:
-                    connection, server_side=True, **self.ssl_options)
+                try:
-                stream = iostream.IOStream(connection, io_loop=self.io_loop)
+                if self.ssl_options is not None:
-                 allow_nonstandard_methods=False):
+                 proxy_host=None, proxy_port=None, proxy_username=None,
-        (options.log_to_stderr is None and not options.log_file_prefix)):
+        (options.log_to_stderr is None and not root_logger.handlers)):
-        logging.getLogger().addHandler(channel)
+        root_logger.addHandler(channel)
-             "By default use stderr if --log_file_prefix is not set."))
+             "By default use stderr if --log_file_prefix is not set and "
-        self.io_loop = self.get_new_ioloop()
+    def __init__(self, *args, **kwargs):
-def wrap(fn, *args, **kwargs):
+def wrap(fn):
-    result = functools.partial(wrapped, callback, contexts, *args, **kwargs)
+    result = functools.partial(wrapped, fn, contexts)
-           request = HTTPRequest(url=request, **kwargs)
+            request = HTTPRequest(url=request, **kwargs)
-           request = HTTPRequest(url=request, **kwargs)
+            request = HTTPRequest(url=request, **kwargs)
-                  [_utf8("%s: %s" % i) for i in request.headers.get_all()])
+        curl.setopt(pycurl.HTTPHEADER,
-      self._socket.close()
+        self.io_loop.remove_handler(self._socket.fileno())
-    self.contexts = ()
+    def __init__(self):
-    _state.contexts = old_contexts
+    '''Establishes the given context as a StackContext that will be transferred.
-  '''Resets the StackContext.
+    '''Resets the StackContext.
-    _state.contexts = old_contexts
+    Useful when creating a shared resource on demand (e.g. an AsyncHTTPClient)
-        callback(*args, **kwargs)
+    '''Returns a callable object that will resore the current StackContext
-
+        callback = fn
-      self.templates = {}
+        self.templates = {}
-    self.login_url = login_url
+    def initialize(self, login_url):
-    return self.login_url
+    def get_login_url(self):
-    self.send_error(500)
+    @authenticated
-                         dict(login_url='http://example.com/login'))])
+    def get_app(self):
-    self.assertEqual(response.headers['Location'], '/login?next=%2Frelative')
+    def test_relative_auth_redirect(self):
-        response.headers['Location']), response.headers['Location'])
+    def test_absolute_auth_redirect(self):
-    self.io_loop = io_loop
+    def __init__(self, app, request, io_loop):
-    self.io_loop.add_callback(self.part2)
+    @asynchronous
-    self.io_loop.add_callback(self.part3)
+    def part2(self):
-    raise Exception('test exception')
+    def part3(self):
-      return 'unexpected failure'
+    def get_error_html(self, status_code, **kwargs):
-                         dict(io_loop=self.io_loop))])
+    def get_app(self):
-    self.assertTrue('got expected exception' in self.response.body)
+    def test_stack_context(self):
-    self.stop()
+    def handle_response(self, response):
-    self.active_contexts = set()
+    def setUp(self):
-    self.active_contexts.remove(name)
+    @contextlib.contextmanager
-    self.wait()
+    # Simulates the effect of an asynchronous library that uses its own
-  unittest.main()
+    unittest.main()
-      pass
+    def test_exception_in_callback(self):
-  unittest.main
+    unittest.main
-                  RequestHandler._templates.values())
+                map(lambda loader: loader.reset(),
-      pass
+        """For subclass to add extra headers to the response"""
-
+  if getattr(fn, 'stack_context_wrapped', False):
-    return callback
+  result = functools.partial(wrapped, callback, contexts, *args, **kwargs)
-from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
+from tornado.stack_context import StackContext, wrap
-class StackContextTest(AsyncHTTPTestCase, LogTrapTestCase):
+class HTTPStackContextTest(AsyncHTTPTestCase, LogTrapTestCase):
-    if header_line == "\r\n":
+    if not header_line:
-                instance._multi.socket_all, 1000, io_loop=io_loop)
+                instance._handle_force_timeout, 1000, io_loop=io_loop)
-                        "start_time": time.time(),
+                        "curl_start_time": time.time(),
-                request_time=time.time() - info["start_time"]))
+                request_time=time.time() - info["curl_start_time"],
-                 error=None, request_time=None):
+    """HTTP Response object.
-                    url += "?" + urllib.urlencode(dict(next=self.request.uri))
+                    if urlparse.urlsplit(url).scheme:
-                instance._multi.socket_all, 1000)
+                instance._multi.socket_all, 1000, io_loop=io_loop)
-        url = self._OPENID_ENDPOINT + "?" + urllib.urlencode(args)
+        url = self._OPENID_ENDPOINT
-            self._on_authentication_verified, callback))
+            self._on_authentication_verified, callback),
-        """Flushes the current output buffer to the nextwork."""
+        """Flushes the current output buffer to the network."""
-        if self._request.method == "POST":
+        if self._request.method in ("POST", "PUT"):
-    def __init__(self, host, database, user=None, password=None):
+    def __init__(self, host, database, user=None, password=None,
-        if self._db is None: self.reconnect()
+        self._ensure_connected()
-        if self._db is None: self.reconnect()
+        self._ensure_connected()
-                num_processes = 1
+            num_processes = _cpu_count()
-                ret, num_handles = self._multi.socket_action(fd, action)
+                ret, num_handles = self._socket_action(fd, action)
-                                            pycurl.SOCKET_TIMEOUT, 0)
+                    ret, num_handles = self._socket_action(
-            except Exception, e:
+            except pycurl.error, e:
-                except Exception, e:
+                except pycurl.error, e:
-        '''
+        """Should be overridden by subclasses to return a
-    'tornado.test.stack_context_test',
+    'tornado.test.stack_context_test',
-from tornado.stack_context import StackContext
+from tornado.stack_context import StackContext, NullContext
-                self.io_loop.start()
+                with NullContext():
-    'tornado.test.test_ioloop',
+    'tornado.test.ioloop_test',
-    unittest.main()
+def doctests():
-from tornado.ioloop import IOLoop
+from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase
-  # TODO(bdarnell): better logging setup for unittests
+class StackContextTest(AsyncHTTPTestCase, LogTrapTestCase):
-    self.io_loop.start()
+    self.http_client.fetch(self.get_url('/'), self.handle_response)
-    self.io_loop.stop()
+    self.stop()
-import escape
+from tornado import httpclient
-import ioloop
+from tornado import ioloop
-import stack_context
+from tornado import escape
-import iostream
+from tornado import httputil
-import stack_context
+from tornado import stack_context
-import ioloop
+from tornado import ioloop
-import web
+from tornado import escape
-import escape
+from tornado import escape
-import template
+from tornado import escape
-import escape
+import cgi
-import web
+
-    def __init__(self, application, request):
+    def __init__(self, application, request, **kwargs):
-    def __init__(self, application, request, transforms=None):
+    def __init__(self, application, request):
-        self._transforms = transforms or []
+        self._transforms = None  # will be set in _execute
-        self._requests.append((request, callback))
+        self._requests.append((request, stack_context.wrap(callback)))
-        self._finish_pending_requests()
+        with stack_context.NullContext():
-                break
+        with stack_context.NullContext():
-        self._handlers[fd] = handler
+        self._handlers[fd] = stack_context.wrap(handler)
-        timeout = _Timeout(deadline, callback)
+        timeout = _Timeout(deadline, stack_context.wrap(callback))
-        self._callbacks.add(callback)
+        self._callbacks.add(stack_context.wrap(callback))
-
+#!/usr/bin/env python
-        try:
+        with stack_context.StackContext(self._stack_context):
-        del AsyncHTTPClient2._ASYNC_CLIENTS[self.io_loop]
+        del AsyncHTTPClient._ASYNC_CLIENTS[self.io_loop]
-    version="0.2",
+    version="1.0",
-            "Server": "TornadoServer/0.1",
+            "Server": "TornadoServer/1.0",
-    setattr(WebSocketHandler, method, WebSocketHandler._not_supported)
+                    # None-safe wrapper around urllib.unquote to handle
-                    kwargs = dict((k, urllib.unquote(v))
+                    kwargs = dict((k, unquote(v))
-                        args = [urllib.unquote(s) for s in match.groups()]
+                        args = [unquote(s) for s in match.groups()]
-                            "http://pypi.python.org/pypi/simplejson/")
+            def _json_decode(s):
-                if hasattr(e, 'errno') and e.errno == errno.EINTR:
+                # Depending on python version and IOLoop implementation,
-            for m in list: self._load_ui_methods(m)
+            for m in methods: self._load_ui_methods(m)
-            for m in list: self._load_ui_modules(m)
+            for m in modules: self._load_ui_modules(m)
-                                   instance._handle_timer)
+                                   instance._set_timeout)
-        self.io_loop.add_callback(self._handle_timeout)
+        self._set_timeout(0)
-    def _handle_timer(self, msecs):
+    def _set_timeout(self, msecs):
-        self.io_loop.add_timeout(
+        if self._timeout is not None:
-    field_types.append([FIELD_TYPE.VARCHAR])
+    field_types.append(FIELD_TYPE.VARCHAR)
-        ([FIELD_TYPE.VARCHAR] if 'VARCHAR' in vars(FIELD_TYPE) else []):
+
-            except OSError, e:
+            except OSError:
-    present in versions 7.20.0 and 7.21.0:
+    most common manifestations of the bug, so this class disables IPv6 when
-                    kwargs = match.groupdict()
+                    kwargs = dict((k, urllib.unquote(v))
-                        args = match.groups()
+                        args = [urllib.unquote(s) for s in match.groups()]
-        self.path = urllib.unquote(path)
+        self.path = path
-        self.path = path
+        self.raw_path = path
-        headers = {}
+        headers = httputil.HTTPHeaders()
-                    "headers": {},
+                    "headers": httputil.HTTPHeaders(),
-                    "headers": {},
+                    "headers": httputil.HTTPHeaders(),
-    def __init__(self, url, method="GET", headers={}, body=None,
+    def __init__(self, url, method="GET", headers=None, body=None,
-                [_utf8("%s: %s" % i) for i in request.headers.iteritems()])
+    # Request headers may be either a regular dict or HTTPHeaders object
-
+    headers.parse_line(header_line)
-        headers = HTTPHeaders.parse(data[eol:])
+        headers = httputil.HTTPHeaders.parse(data[eol:])
-            headers = HTTPHeaders.parse(part[:eoh])
+            headers = httputil.HTTPHeaders.parse(part[:eoh])
-        self.headers = headers or HTTPHeaders()
+        self.headers = headers or httputil.HTTPHeaders()
-        return headers
+#!/usr/bin/env python
-        self.headers = HTTPHeaders()
+        self.headers = httputil.HTTPHeaders()
-            headers = HTTPHeaders.parse(part[:eoh])
+            headers = httputil.HTTPHeaders.parse(part[:eoh])
-    def start(self, num_processes=None):
+    def start(self, num_processes=1):
-        fork that specific number of sub-processes.
+        By default, we run the server in this process and do not fork any
-        in this process and do not fork any additional child process.
+        If num_processes is None or <= 0, we detect the number of cores
-        if num_processes is None:
+        if num_processes is None or num_processes <= 0:
-                ["%s: %s" % i for i in request.headers.iteritems()])
+                [_utf8("%s: %s" % i) for i in request.headers.iteritems()])
-        curl.setopt(pycurl.USERAGENT, request.user_agent)
+        curl.setopt(pycurl.USERAGENT, _utf8(request.user_agent))
-            return HTTPResponse(
+            response = HTTPResponse(
-                self.error = HTTPError(self.code)
+                self.error = HTTPError(self.code, response=self)
-    def __init__(self, code, message=None):
+    """Exception thrown for an unsuccessful HTTP request.
-def parse_config_file(path, overwrite=True):
+def parse_config_file(path):
-        Since we run use processes and not threads, there is no shared memory
+        Since we use processes and not threads, there is no shared memory
-                WSGIContainer.environ(request), start_response))
+        app_response = self.wsgi_application(
-            response.close()
+        if hasattr(app_response, "close"):
-            request_time=time.time() - info["start_time"]))
+        try:
-                 header_callback=None, prepare_curl_callback=None):
+                 header_callback=None, prepare_curl_callback=None,
-    elif request.method in custom_methods:
+    elif request.allow_nonstandard_methods or request.method in custom_methods:
-                body=buffer.getvalue(), effective_url=effective_url)
+                buffer=buffer, effective_url=effective_url)
-        finally:
+            raise CurlError(*e)
-        info["buffer"].close()
+            buffer.seek(0)
-            body=body, effective_url=effective_url, error=error,
+            buffer=buffer, effective_url=effective_url, error=error,
-    def __init__(self, request, code, headers={}, body="", effective_url=None,
+    def __init__(self, request, code, headers={}, buffer=None, effective_url=None,
-        self.body = body
+        self.buffer = buffer
-            callback(self._consume(loc + len(delimiter)))
+            self._run_callback(callback, self._consume(loc + len(delimiter)))
-            if self._close_callback: self._close_callback()
+            if self._close_callback:
-                callback(self._consume(num_bytes))
+                self._run_callback(callback, self._consume(num_bytes))
-                callback(self._consume(loc + delimiter_len))
+                self._run_callback(callback,
-            callback()
+            self._run_callback(callback)
-                if boundary: self._parse_mime_body(boundary, data)
+                if 'boundary=' in content_type:
-            if boundary: self._parse_mime_body(boundary)
+            if 'boundary=' in content_type:
-        if values is None:
+        args = self.get_arguments(name, strip=strip)
-        return value
+        values = [re.sub(r"[\x00-\x08\x0e-\x1f]", " ", x) for x in values]
-             self.write_message(u"You said: " + message)
+              self.write_message(u"You said: " + message)
-        self.receive_message(callback)
+        self.set_extra_headers(path)
-        if max(fds.iterkeys()) > 900:
+        if fds and max(fds.iterkeys()) > 900:
-        template_path = self.application.settings.get("template_path")
+        template_path = self.get_template_path()
-        pass
+    if request.header_callback:
-    return _json_encode(value)
+    # JSON permits but does not require forward slashes to be escaped.
-        """Sets the given cookie name/value with the given options."""
+                   expires_days=None, **kwargs):
-            "session_expires": session["expires"],
+            "session_expires": session.get("expires"),
-        """Returns a list of JavaScript files required by this module."""
+        """Returns a list of CSS files required by this module."""
-    _OAUTH_AUTHENTICATE_URL = "http://twitter.com/oauth/authenticate"
+    _OAUTH_REQUEST_TOKEN_URL = "http://api.twitter.com/oauth/request_token"
-        url = "http://twitter.com" + path + ".json"
+        url = "http://api.twitter.com/1" + path + ".json"
-        request_buffer =  cStringIO.StringIO(request.body.encode('utf-8'))
+        request_buffer =  cStringIO.StringIO(escape.utf8(request.body))
-            "wsgi.input": cStringIO.StringIO(request.body.encode('utf-8')),
+            "wsgi.input": cStringIO.StringIO(escape.utf8(request.body)),
-        request_buffer =  cStringIO.StringIO(request.body)
+        request_buffer =  cStringIO.StringIO(request.body.encode('utf-8'))
-            "wsgi.input": cStringIO.StringIO(request.body),
+            "wsgi.input": cStringIO.StringIO(request.body.encode('utf-8')),
-            _log.warning("Invalid OpenID response: %s", response.error or
+            logging.warning("Invalid OpenID response: %s", response.error or
-            _log.warning("Missing OAuth request token cookie")
+            logging.warning("Missing OAuth request token cookie")
-            _log.warning("Request token does not match cookie")
+            logging.warning("Request token does not match cookie")
-            _log.warning("Could not fetch access token")
+            logging.warning("Could not fetch access token")
-            _log.warning("Error response %s fetching %s", response.error,
+            logging.warning("Error response %s fetching %s", response.error,
-            _log.warning("Error response %s fetching %s", response.error,
+            logging.warning("Error response %s fetching %s", response.error,
-            _log.warning("HTTP error from Facebook: %s", response.error)
+            logging.warning("HTTP error from Facebook: %s", response.error)
-            _log.warning("Invalid JSON from Facebook: %r", response.body)
+            logging.warning("Invalid JSON from Facebook: %r", response.body)
-            _log.warning("Facebook error: %d: %r", json["error_code"],
+            logging.warning("Facebook error: %d: %r", json["error_code"],
-            _log.info("%s modified; restarting server", path)
+            logging.info("%s modified; restarting server", path)
-            _log.error("Cannot connect to MySQL on %s", self.host,
+            logging.error("Cannot connect to MySQL on %s", self.host,
-            _log.error("Error connecting to MySQL on %s", self.host)
+            logging.error("Error connecting to MySQL on %s", self.host)
-    if _log.isEnabledFor(logging.DEBUG):
+    if logging.getLogger().isEnabledFor(logging.DEBUG):
-        _log.info("%s %s (username: %r)", request.method, request.url,
+        logging.info("%s %s (username: %r)", request.method, request.url,
-        _log.info("%s %s", request.method, request.url)
+        logging.info("%s %s", request.method, request.url)
-        _log.warning("Invalid HTTP response header line %r", header_line)
+        logging.warning("Invalid HTTP response header line %r", header_line)
-        _log.debug('%s', debug_msg.strip())
+        logging.debug('%s', debug_msg.strip())
-            _log.debug('%s %s', debug_types[debug_type], line)
+            logging.debug('%s %s', debug_types[debug_type], line)
-        _log.debug('%s %r', debug_types[debug_type], debug_msg)
+        logging.debug('%s %r', debug_types[debug_type], debug_msg)
-                _log.error("Could not get num processors from sysconf; "
+                logging.error("Could not get num processors from sysconf; "
-            _log.error("Cannot run in multiple processes: IOLoop instance "
+            logging.error("Cannot run in multiple processes: IOLoop instance "
-            _log.info("Pre-forking %d server processes", num_processes)
+            logging.info("Pre-forking %d server processes", num_processes)
-                _log.error("Error in connection callback", exc_info=True)
+                logging.error("Error in connection callback", exc_info=True)
-                _log.warning("multipart/form-data missing headers")
+                logging.warning("multipart/form-data missing headers")
-                _log.warning("Invalid multipart/form-data")
+                logging.warning("Invalid multipart/form-data")
-                _log.warning("multipart/form-data value missing name")
+                logging.warning("multipart/form-data value missing name")
-            _log.debug("Error deleting fd from IOLoop", exc_info=True)
+            logging.debug("Error deleting fd from IOLoop", exc_info=True)
-                    _log.warning("Interrupted system call", exc_info=1)
+                    logging.warning("Interrupted system call", exc_info=1)
-                        _log.error("Exception in I/O handler for fd %d",
+                        logging.error("Exception in I/O handler for fd %d",
-                    _log.error("Exception in I/O handler for fd %d",
+                    logging.error("Exception in I/O handler for fd %d",
-        _log.error("Exception in callback %r", callback, exc_info=True)
+        logging.error("Exception in callback %r", callback, exc_info=True)
-            _log.error("Error in periodic callback", exc_info=True)
+            logging.error("Error in periodic callback", exc_info=True)
-            _log.warning("epoll module not found; using select()")
+            logging.warning("epoll module not found; using select()")
-            _log.warning("Got events for closed stream %d", fd)
+            logging.warning("Got events for closed stream %d", fd)
-                _log.warning("Read error on %d: %s",
+                logging.warning("Read error on %d: %s",
-            _log.error("Reached maximum read buffer size")
+            logging.error("Reached maximum read buffer size")
-                    _log.warning("Write error on %d: %s",
+                    logging.warning("Write error on %d: %s",
-            _log.error("Unrecognized locale %r (path: %s)", locale,
+            logging.error("Unrecognized locale %r (path: %s)", locale,
-                _log.error("Unrecognized plural indicator %r in %s line %d",
+                logging.error("Unrecognized plural indicator %r in %s line %d",
-    _log.info("Supported locales: %s", sorted(_supported_locales))
+    logging.info("Supported locales: %s", sorted(_supported_locales))
-    _log.info("Supported locales: %s", sorted(_supported_locales))
+    logging.info("Supported locales: %s", sorted(_supported_locales))
-            _log.error("%s code:\n%s", self.name, formatted_code)
+            logging.error("%s code:\n%s", self.name, formatted_code)
-            _log.error("%s code:\n%s", self.name, formatted_code)
+            logging.error("%s code:\n%s", self.name, formatted_code)
-            _log.warning("Invalid cookie signature %r", value)
+            logging.warning("Invalid cookie signature %r", value)
-            _log.warning("Expired cookie %r", value)
+            logging.warning("Expired cookie %r", value)
-            _log.error("Cannot send error response after headers written")
+            logging.error("Cannot send error response after headers written")
-                _log.error("Could not open static file %r", path)
+                logging.error("Could not open static file %r", path)
-                    _log.error("Exception after headers written",
+                    logging.error("Exception after headers written",
-            log_method = _log.info
+            log_method = logging.info
-            log_method = _log.warning
+            log_method = logging.warning
-            log_method = _log.error
+            log_method = logging.error
-                _log.warning(format, *args)
+                logging.warning(format, *args)
-                _log.error("Bad HTTP status code: %d", e.status_code)
+                logging.error("Bad HTTP status code: %d", e.status_code)
-            _log.error("Uncaught exception %s\n%r", self._request_summary(),
+            logging.error("Uncaught exception %s\n%r", self._request_summary(),
-                    _log.warning(
+                    logging.warning(
-                _log.error("Uncaught exception in %s",
+                logging.error("Uncaught exception in %s",
-                _log.warning("multipart/form-data missing headers")
+                logging.warning("multipart/form-data missing headers")
-                _log.warning("Invalid multipart/form-data")
+                logging.warning("Invalid multipart/form-data")
-                _log.warning("multipart/form-data value missing name")
+                logging.warning("multipart/form-data value missing name")
-            log_method = _log.info
+            log_method = logging.info
-            log_method = _log.warning
+            log_method = logging.warning
-            log_method = _log.error
+            log_method = logging.error
-    parts = header_line.split(":")
+    parts = header_line.split(":", 1)
-    parts = header_line.split(": ")
+    parts = header_line.split(":")
-                headers[name] = value
+                name, value = line.split(":", 1)
-                headers[name] = value
+                name, value = line.split(":", 1)
-    
+
-            "openid.claimed_id": 
+            "openid.claimed_id":
-            "openid.identity": 
+            "openid.identity":
-            "openid.realm": "http://" + self.request.host + "/",
+            "openid.realm": self.request.protocol + "://" + self.request.host + "/",
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-            cls._cache[code] = Locale(code, translations)
+            translations = _translations.get(code, None)
-            _("May"), _("June"), _("July"), _("August"), 
+            _("May"), _("June"), _("July"), _("August"),
-        return message_dict.get(message, message)
+        raise NotImplementedError()
-        raise Error("Unrecognized option %r" % name)
+        raise AttributeError("Unrecognized option %r" % name)
-    return utf8(xml.sax.saxutils.escape(value))
+    return utf8(xml.sax.saxutils.escape(value, {'"': "&quot;"}))
-
+        if html_bodies:
-            WSGIContainer.environ(request), start_response)
+            return response.append
-                if e.errno == errno.EINTR:
+                if hasattr(e, 'errno') and e.errno == errno.EINTR:
-                color = True
+                if curses.tigetnum("colors") > 0:
-        self.handlers.append((re.compile(host_pattern), handlers))
+        # The handlers with the wildcard host_pattern are a special
-        raise
+    import fcntl
-    if os.name != 'posix':
+    if os.name == 'nt':
-        if os.name == 'posix':
+        if os.name != 'nt':
-sys.path.insert(0, '..')
+#!/usr/bin/env python
-import ioloop
+from tornado import ioloop
-            r = pipe.reader_fd
+            self._waker_reader = self._waker_writer = win32_support.Pipe()
-                    raise BindError("Cannot bind trigger!")
+                    raise socket.error("Cannot bind trigger!")
-            logging.warning("Invalid OpenID response: %s", response.error or
+            _log.warning("Invalid OpenID response: %s", response.error or
-            logging.warning("Missing OAuth request token cookie")
+            _log.warning("Missing OAuth request token cookie")
-            logging.warning("Request token does not match cookie")
+            _log.warning("Request token does not match cookie")
-            logging.warning("Could not fetch access token")
+            _log.warning("Could not fetch access token")
-            logging.warning("Error response %s fetching %s", response.error,
+            _log.warning("Error response %s fetching %s", response.error,
-            logging.warning("Error response %s fetching %s", response.error,
+            _log.warning("Error response %s fetching %s", response.error,
-            logging.warning("HTTP error from Facebook: %s", response.error)
+            _log.warning("HTTP error from Facebook: %s", response.error)
-            logging.warning("Invalid JSON from Facebook: %r", response.body)
+            _log.warning("Invalid JSON from Facebook: %r", response.body)
-            logging.warning("Facebook error: %d: %r", json["error_code"],
+            _log.warning("Facebook error: %d: %r", json["error_code"],
-            logging.info("%s modified; restarting server", path)
+            _log.info("%s modified; restarting server", path)
-            logging.error("Cannot connect to MySQL on %s", self.host,
+            _log.error("Cannot connect to MySQL on %s", self.host,
-            logging.error("Error connecting to MySQL on %s", self.host)
+            _log.error("Error connecting to MySQL on %s", self.host)
-    if logging.getLogger().isEnabledFor(logging.DEBUG):
+    if _log.isEnabledFor(logging.DEBUG):
-        logging.info("%s %s (username: %r)", request.method, request.url,
+        _log.info("%s %s (username: %r)", request.method, request.url,
-        logging.info("%s %s", request.method, request.url)
+        _log.info("%s %s", request.method, request.url)
-        logging.warning("Invalid HTTP response header line %r", header_line)
+        _log.warning("Invalid HTTP response header line %r", header_line)
-        logging.debug('%s', debug_msg.strip())
+        _log.debug('%s', debug_msg.strip())
-            logging.debug('%s %s', debug_types[debug_type], line)
+            _log.debug('%s %s', debug_types[debug_type], line)
-        logging.debug('%s %r', debug_types[debug_type], debug_msg)
+        _log.debug('%s %r', debug_types[debug_type], debug_msg)
-                logging.error("Could not get num processors from sysconf; "
+                _log.error("Could not get num processors from sysconf; "
-            logging.error("Cannot run in multiple processes: IOLoop instance "
+            _log.error("Cannot run in multiple processes: IOLoop instance "
-            logging.info("Pre-forking %d server processes", num_processes)
+            _log.info("Pre-forking %d server processes", num_processes)
-                logging.error("Error in connection callback", exc_info=True)
+                _log.error("Error in connection callback", exc_info=True)
-                logging.warning("multipart/form-data missing headers")
+                _log.warning("multipart/form-data missing headers")
-                logging.warning("Invalid multipart/form-data")
+                _log.warning("Invalid multipart/form-data")
-                logging.warning("multipart/form-data value missing name")
+                _log.warning("multipart/form-data value missing name")
-            logging.debug("Error deleting fd from IOLoop", exc_info=True)
+            _log.debug("Error deleting fd from IOLoop", exc_info=True)
-                    logging.warning("Interrupted system call", exc_info=1)
+                    _log.warning("Interrupted system call", exc_info=1)
-                        logging.error("Exception in I/O handler for fd %d",
+                        _log.error("Exception in I/O handler for fd %d",
-                    logging.error("Exception in I/O handler for fd %d",
+                    _log.error("Exception in I/O handler for fd %d",
-        logging.error("Exception in callback %r", callback, exc_info=True)
+        _log.error("Exception in callback %r", callback, exc_info=True)
-            logging.error("Error in periodic callback", exc_info=True)
+            _log.error("Error in periodic callback", exc_info=True)
-            logging.warning("epoll module not found; using select()")
+            _log.warning("epoll module not found; using select()")
-            logging.warning("Got events for closed stream %d", fd)
+            _log.warning("Got events for closed stream %d", fd)
-                logging.warning("Read error on %d: %s",
+                _log.warning("Read error on %d: %s",
-            logging.error("Reached maximum read buffer size")
+            _log.error("Reached maximum read buffer size")
-                    logging.warning("Write error on %d: %s",
+                    _log.warning("Write error on %d: %s",
-            logging.error("Unrecognized locale %r (path: %s)", locale,
+            _log.error("Unrecognized locale %r (path: %s)", locale,
-                logging.error("Unrecognized plural indicator %r in %s line %d",
+                _log.error("Unrecognized plural indicator %r in %s line %d",
-    logging.info("Supported locales: %s", sorted(_supported_locales))
+    _log.info("Supported locales: %s", sorted(_supported_locales))
-            logging.error("%s code:\n%s", self.name, formatted_code)
+            _log.error("%s code:\n%s", self.name, formatted_code)
-            logging.error("%s code:\n%s", self.name, formatted_code)
+            _log.error("%s code:\n%s", self.name, formatted_code)
-            logging.warning("Invalid cookie signature %r", value)
+            _log.warning("Invalid cookie signature %r", value)
-            logging.warning("Expired cookie %r", value)
+            _log.warning("Expired cookie %r", value)
-            logging.error("Cannot send error response after headers written")
+            _log.error("Cannot send error response after headers written")
-                logging.error("Could not open static file %r", path)
+                _log.error("Could not open static file %r", path)
-                    logging.error("Exception after headers written",
+                    _log.error("Exception after headers written",
-            log_method = logging.info
+            log_method = _log.info
-            log_method = logging.warning
+            log_method = _log.warning
-            log_method = logging.error
+            log_method = _log.error
-                logging.warning(format, *args)
+                _log.warning(format, *args)
-                logging.error("Bad HTTP status code: %d", e.status_code)
+                _log.error("Bad HTTP status code: %d", e.status_code)
-            logging.error("Uncaught exception %s\n%r", self._request_summary(),
+            _log.error("Uncaught exception %s\n%r", self._request_summary(),
-                logging.error("Uncaught exception in %s",
+                _log.error("Uncaught exception in %s",
-                logging.warning("multipart/form-data missing headers")
+                _log.warning("multipart/form-data missing headers")
-                logging.warning("Invalid multipart/form-data")
+                _log.warning("Invalid multipart/form-data")
-                logging.warning("multipart/form-data value missing name")
+                _log.warning("multipart/form-data value missing name")
-            log_method = logging.info
+            log_method = _log.info
-            log_method = logging.warning
+            log_method = _log.warning
-            log_method = logging.error
+            log_method = _log.error
-        import fcntl_win32 as fcntl
+        import win32_support as fcntl
-        import socket
+        import win32_support
-            self.set_close_exec(self._impl.fileno())
+            self._set_close_exec(self._impl.fileno())
-        self.add_handler(trigger.reader_fd, self._read_waker, self.READ)
+        if os.name == 'posix':
-    def set_nonblocking(fd):
+    def _set_nonblocking(self, fd):
-    def set_close_exec(fd):
+    def _set_close_exec(self, fd):
-            data["headers"] = HTTPHeaders(response_headers)
+            data["headers"] = response_headers
-        headers.setdefault("Server", "TornadoServer/0.1")
+        if "content-length" not in header_set:
-        for key, value in headers.iteritems():
+        for key, value in headers:
-            if self._status_code == 200 and self.request.method == "GET":
+            if (self._status_code == 200 and self.request.method == "GET" and
-                 prepare_curl_callback=None):
+                 header_callback=None, prepare_curl_callback=None):
-                    functools.partial(_curl_header_callback, headers))
+        if request.header_callback:
-    def load(self, name, parent_path=None):
+    def reset(self):
-                template_path)
+            loader = self.application.settings.get("template_loader") or\
-            RequestHandler._templates = None
+            if getattr(RequestHandler, "_templates", None):
-                    args = match.groups()
+                    # Pass matched groups to the handler.  Since
-        handler._execute(transforms, *args)
+        handler._execute(transforms, *args, **kwargs)
-    headers[parts[0].strip()] = parts[1].strip()
+    name = parts[0].strip()
-	
+        
-        file = open(abspath, "r")
+        file = open(abspath, "rb")
-            self._set_posix_nonblocking(w)
+            IOLoop.set_nonblocking(self.reader_fd)
-            self._set_close_exec(self._impl.fileno())
+            self.set_close_exec(self._impl.fileno())
-    def _set_nonblocking(self, fd):
+    @staticmethod
-    def _set_close_exec(self, fd):
+    @staticmethod
-        self.add_handler(r, self._read_waker, self.WRITE)
+        self.add_handler(r, self._read_waker, self.READ)
-        if chunk: self.write(chunk)
+        if chunk is not None: self.write(chunk)
-    _ASYNC_CLIENTS = {}
+    _ASYNC_CLIENTS = weakref.WeakKeyDictionary()
-            return cls._ASYNC_CLIENTS[id(io_loop)]
+        if io_loop in cls._ASYNC_CLIENTS:
-            cls._ASYNC_CLIENTS[id(io_loop)] = instance
+            cls._ASYNC_CLIENTS[io_loop] = instance
-            logging.error("Exception in callback %r", callback, exc_info=True)
+            self.handle_callback_exception(callback)
-                    ioloop.IOLoop.instance().add_handler(
+                    self.io_loop = ioloop.IOLoop.instance()
-                                ioloop.IOLoop.READ)
+            if not self.io_loop:
-            elif ("Content-Length" in self._request.headers 
+            elif ("Content-Length" in self._request.headers
-import logging
+import logging.handlers
-    enable_pretty_logging()
+    if options.logging != 'none':
-    def __init__(self, *args, **kwargs):
+    """Turns on formatted logging output as configured."""
-        self._normal = curses.tigetstr("sgr0")
+        self._color = color
-        formatted = color + prefix + self._normal + " " + record.message
+        if self._color:
-       metavar="info|warning|error")
+define("logging", default="info",
-            WSGIContainer.environ(request), start_response))
+        response = self.wsgi_application(
-        def start_response(status, response_headers):
+        def start_response(status, response_headers, exc_info=None):
-            os.execv(sys.executable, [sys.executable] + sys.argv)
+            try:
-                except KeyboardInterrupt:
+                except (KeyboardInterrupt, SystemExit):
-        self._filters = {}
+        self._active = {}
-        self._kqueue.control([kevent], 0)
+        self._control(fd, events, select.KQ_EV_ADD)
-        self._kqueue.control([kevent], 0)
+        events = self._active.pop(fd)
-        events = []
+        events = {}
-                flags |= IOLoop.WRITE
+            if kevent.filter == select.KQ_FILTER_READ:
-        return events
+                events[fd] = events.get(fd, 0) | IOLoop.ERROR
-            if self.get_argument("auth_token", None):
+            if self.get_argument("session", None):
-    def get_secure_cookie(self, name, include_name=True):
+    def get_secure_cookie(self, name, include_name=True, value=None):
-        value = self.get_cookie(name)
+        if value is None: value = self.get_cookie(name)
-        self.set_header("Content-Length", stat_result[stat.ST_SIZE])
+        self.set_header("Content-Length", stat_result[stat.ST_SIZE])
-        """Returns the given signed cookie if it validates, or None."""
+    def get_secure_cookie(self, name, include_name=True):
-                    self._cookie_signature(name, parts[0], parts[1])):
+        if include_name:
-            paths = {}
+            # Maintain order of JavaScript files given by modules
-
+                    path = self.static_url(path)
-                         for p in resolved_paths)
+                         for p in paths)
-            handlers.extend([
+            handlers = [
-            ])
+            ] + handlers
-        signature = self._cookie_signature(value, timestamp)
+        signature = self._cookie_signature(name, value, timestamp)
-                    self._cookie_signature(parts[0], parts[1])):
+                    self._cookie_signature(name, parts[0], parts[1])):
-        self.root = os.path.abspath(path) + "/"
+        self.root = os.path.abspath(path) + os.path.sep
-            paths = set()
+            paths = {}
-                    paths.add(self.static_url(path))
+                    paths[path] = self.static_url(path)
-                    paths.add(path)
+                    paths[path] = path
-                         for p in paths)
+                         for p in resolved_paths)
-            continue
+            remaining = args[i+1:]
-                if e.args == (4, "Interrupted system call"):
+                if e.errno == errno.EINTR:
-                return
+        # Check the If-Modified-Since, and don't send the result if the
-            return base + "/static/" + path + "?v=" + hashes[path][:5]
+            return base + static_url_prefix + path + "?v=" + hashes[path][:5]
-            return base + "/static/" + path
+            return base + static_url_prefix + path
-    keyword argument. We will serve those files from the /static/ URI,
+    keyword argument. We will serve those files from the /static/ URI
-                (r"/static/(.*)", StaticFileHandler, dict(path=path)),
+                (re.escape(static_url_prefix) + r"(.*)", StaticFileHandler,
-import fcntl
+try:
-import logging
+try:
-        self.add_handler(r, self._read_waker, self.WRITE)
+        trigger = Pipe()
-                 network_interface=None, streaming_callback=None):
+                 network_interface=None, streaming_callback=None,
-                 connect_timeout=None, request_timeout=None,
+                 connect_timeout=20.0, request_timeout=20.0,
-        self.request_timeout = request_timeout or 20.0
+        self.connect_timeout = connect_timeout
-            self.protocol = headers.get("X-Scheme", protocol) or "http"
+            self.remote_ip = self.headers.get(
-        self.host = host or headers.get("Host") or "127.0.0.1"
+        self.host = host or self.headers.get("Host") or "127.0.0.1"
-            return args[i:]
+            remaining = args[i:]
-    return []
+    return remaining
-    logging.getLogger().addHandler(channel)        
+    logging.getLogger().addHandler(channel)
-                self.io_loop.remove_handler(fd)
+                try:
-                except OSError, e:
+                except (OSError, IOError), e:
-        except OSError:
+        except (OSError, IOError):
-                except OSError, e:
+                except (OSError, IOError), e:
-                except OSError, e:
+                except (OSError, IOError), e:
-                
+
-        Use this method instead of passing around IOLoop instances 
+        Use this method instead of passing around IOLoop instances
-        except OSError:
+        except (OSError, IOError):
-            self.on_connection_close)
+        # Check since connection is not available in WSGI
-        if self._cookie_signature(parts[0], parts[1]) != parts[2]:
+        if not _time_independent_equals(parts[2],
-        self.stream.write(chunk, self._on_write_complete)
+        if not self.stream.closed():
-    # up names for every single method
+    # up names for almost every single method
-    curl.setopt(curl_options[request.method], True)
+    if request.method in curl_options:
-        """Stop the loop after the current event loop iteration is complete."""
+        """Stop the loop after the current event loop iteration is complete.
-    def send_error(self, status_code=500):
+    def send_error(self, status_code=500, **kwargs):
-        message = self.get_error_html(status_code)
+        message = self.get_error_html(status_code, **kwargs)
-        """Override to implement custom error pages."""
+    def get_error_html(self, status_code, **kwargs):
-            
+
-            if not self._finished:  
+            if not self._finished:
-                self.send_error(500)
+                self.send_error(500, exception=e)
-                self.send_error(e.status_code)
+                self.send_error(e.status_code, exception=e)
-            self.send_error(500)
+            self.send_error(500, exception=e)
-        if not handlers: 
+        if not handlers:
-        
+
-        
+
-            will be passed in to the handler's get/post/etc methods as 
+            will be passed in to the handler's get/post/etc methods as
-        name (optional): A name for this handler.  Used by 
+        name (optional): A name for this handler.  Used by
-    def __init__(self, pattern, handler_class, kwargs=None, name=None):
+    def __init__(self, pattern, handler_class, kwargs={}, name=None):
-                self.named_handlers[handler.name] = spec
+                self.named_handlers[spec.name] = spec
-    the request path.
+    The constructor for this class takes in a list of URLSpec objects
-            handlers.append((re.compile(pattern), handler, kwargs))
+        for spec in host_handlers:
-                match = pattern.match(request.path)
+            for spec in handlers:
-                    handler = handler_class(self, request, **kwargs)
+                    handler = spec.handler_class(self, request, **spec.kwargs)
-                          "IOLoop.instance() before calling start_multi_cpu()")
+                          "IOLoop.instance() before calling start()")
-        self.io_loop = io_loop or ioloop.IOLoop.instance()
+        self.io_loop = io_loop
-                                 self.io_loop.READ)
+
-        lines.extend(["%s: %s" % (n, v) for n, v in headers.iteritems()])
+        lines.extend(["%s: %s" % (n, v) for n, v in self._headers.iteritems()])
-            self.transforms = [ChunkedTransferEncoding]
+            self.transforms = []
-    See the ChunkedTransferEncoding example below if you want to implement a
+    A new transform instance is created for every request. See the
-        return headers
+    def transform_first_chunk(self, headers, chunk, finishing):
-        return block
+    def transform_chunk(self, chunk, finishing):
-        return None
+
-    def transform_headers(self, headers):
+    def transform_first_chunk(self, headers, chunk, finishing):
-        return headers
+                chunk = self.transform_chunk(chunk, finishing)
-    def transform_chunk(self, block):
+    def transform_chunk(self, block, finishing):
-            return None
+            # Don't write out empty chunks because that means END-OF-STREAM
-            self._environ(request), start_response))
+            WSGIContainer.environ(request), start_response))
-    def _environ(self, request):
+    @staticmethod
-            headers = transform.transform_headers(self._headers)
+            headers = transform.transform_headers(headers)
-        lines.extend(["%s: %s" % (n, v) for n, v in self._headers.iteritems()])
+        lines.extend(["%s: %s" % (n, v) for n, v in headers.iteritems()])
-            self.remote_ip = headers.get("X-Real-Ip", remote_ip)
+            # Squid uses X-Forwarded-For, others use X-Real-Ip
-            fields="uid,first_name,last_name,name,locale,pic_square")
+            fields="uid,first_name,last_name,name,locale,pic_square," \
-        if self._db is not None:
+        if getattr(self, "_db", None) is not None:
-                 xheaders=False):
+                 xheaders=False, ssl_options=None):
-                                 for p in paths)
+            js = ''.join('<script src="' + escape.xhtml_escape(p) +
-            html = html[:sloc] + js_embed + '\n' + html[sloc:]
+            html = html[:sloc] + js + '\n' + html[sloc:]
-            js_embed = '<script type="text/javascript">\n//<![CDATA[\n' + \
+            js = '<script type="text/javascript">\n//<![CDATA[\n' + \
-            html = html[:sloc] + js_embed + '\n' + html[sloc:]
+            html = html[:sloc] + js + '\n' + html[sloc:]
-                                for p in paths)
+            css = ''.join('<link href="' + escape.xhtml_escape(p) + '" '
-            html = html[:hloc] + css_embed + '\n' + html[hloc:]
+            html = html[:hloc] + css + '\n' + html[hloc:]
-            css_embed = '<style type="text/css">\n' + '\n'.join(css_embed) + \
+            css = '<style type="text/css">\n' + '\n'.join(css_embed) + \
-            html = html[:hloc] + css_embed + '\n' + html[hloc:]
+            html = html[:hloc] + css + '\n' + html[hloc:]
-        self._callbacks.pop(callback)
+        self._callbacks.remove(callback)
-            html = html[:hloc] + css_embed + '\n' + html[hloc:]
+        if js_embed:
-    def listen(self, port):
+    def listen(self, port, address=""):
-        self._socket.bind(("", port))
+        self._socket.bind((address, port))
-        self.io_loop = io_loop or ioloop.IOLoop.instance()
+        self.io_loop = io_loop or IOLoop.instance()
-    version="0.1",
+    version="0.2",
-"""A module to automatically restart the server when a module is modified."""
+"""A module to automatically restart the server when a module is modified.
-                 **settings):
+                 wsgi=False, **settings):
-        self._wsgi = False
+        self._wsgi = wsgi
-        if self.settings.get("auto_reload"):
+        if self.settings.get("debug") and not wsgi:
-        self._wsgi = True
+                                 wsgi=True, **settings)
-def start(io_loop=None, check_time=200):
+def start(io_loop=None, check_time=500):
-                "weekday": self.WEEKDAYS[local_date.weekday()],
+                "weekday": self._weekdays[local_date.weekday()],
-                 network_interface=None):
+                 network_interface=None, streaming_callback=None):
-    curl.setopt(pycurl.WRITEFUNCTION, buffer.write)
+    if request.streaming_callback:
-            reloader.start()
+            import autoreload
-        self._db.autocommit(True)
+        self._db_args = args
-            self.close()
+        self.close()
-        self._db = None
+        if self._db is not None:
-            cursor.execute(query, parameters)
+            self._execute(cursor, query, parameters)
-        cursor = self._db.cursor()
+        cursor = self._cursor()
-            cursor.execute(query, parameters)
+            self._execute(cursor, query, parameters)
-        cursor = self._db.cursor()
+        cursor = self._cursor()
-            cursor.execute(query, parameters)
+            self._execute(cursor, query, parameters)
-        cursor = self._db.cursor()
+        cursor = self._cursor()
-            raise web.HTTPError(403)
+            raise tornado.web.HTTPError(403)
-            raise web.HTTPError(403)
+            raise tornado.web.HTTPError(403)
-        self.redirect(self.get_argument("next", "/"))
+        self.write("You are now logged out")
-            if boundary: self._parse_mime_body(boundary, data)
+            if boundary: self._parse_mime_body(boundary)
-class AuthLogoutHandler(BaseHandler, tornado.auth.FacebookMixin):
+class AuthLogoutHandler(BaseHandler):
-                    logging.warning("Read error on %d: %s",
+                    logging.warning("Write error on %d: %s",
-            self.code, "Unknown"))
+        message = message or httplib.responses.get(code, "Unknown")
-See the Tornado walkthrough on Google Code for more details and a good
+See the Tornado walkthrough on GitHub for more details and a good
-        return intern("-".join([w.capitalize() for w in name.split("-")]))
+        return "-".join([w.capitalize() for w in name.split("-")])
-        return intern("-".join([w.capitalize() for w in name.split("-")]))
+        return "-".join([w.capitalize() for w in name.split("-")])
