-        raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '
+    if not is_tensor(x):
-        raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '
+    if not is_tensor(x):
-        raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '
+    if not is_tensor(x):
-            self.add_loss(regularizer(weight))
+            with K.name_scope('weight_regularizer'):
-                    for x in to_list(output)]
+                with K.name_scope('activity_regularizer'):
-        output_layers
+        layers
-        outbound_nodes: list of nodes
+        weights (list of variables)
-    def __init__(self, inputs, outputs, name=None):
+    def __init__(self, *args, **kwargs):
-        self.supports_masking = False
+        # This acts just like the `trainable` attribute of any layer instance.
-        # Network-specific properties.
+        # All layers in order of horizontal graph traversal.
-        self.layers = []
+        self._input_layers = []
-        # every time the Network is called on a set on input tensors,
+        # This is for performance optimization when calling the Network on new
-        # we retrieve it from there instead of recomputing it.
+        # then cache them here. When any of these outputs is queried later, we
-        # Build self.output_layers:
+        # Build self._output_layers:
-            self.output_layers_tensor_indices.append(tensor_index)
+            self._output_layers.append(layer)
-        mask_cache_key += '_' + ','.join([str(id(x)) for x in masks])
+        mask_cache_key = object_list_uid(inputs)
-        for i, layer in enumerate(self.input_layers):
+        for i, layer in enumerate(self._input_layers):
-                self._feed_input_names.append(layer.name)
+                self._feed_input_names.append(layer.name)
-            node = layer._inbound_nodes[node_index]
+        for layer in self._output_layers:
-            if node in nodes_in_progress:
+    def _init_subclassed_network(self, name=None):
-            nodes_in_progress.remove(node)
+                    'It looks like you are subclassing `Model` and you '
-        # self.input_spec
+    @property
-                updates += layer.get_updates_for(None)
+                if self._is_graph_network:
-                losses += layer.get_losses_for(None)
+                if self._is_graph_network:
-        for layer in getattr(self, 'input_layers', []):
+        for layer in getattr(self, '_input_layers', []):
-        cache_key += '_' + ','.join([str(id(x)) for x in masks])
+        cache_key = object_list_uid(inputs)
-        cache_key += '_' + ','.join([str(id(x)) for x in masks])
+        cache_key = object_list_uid(inputs)
-        if len(input_shapes) != len(self.input_layers):
+        if len(input_shapes) != len(self._input_layers):
-                             str(len(self.input_layers)) + ' tensor inputs.')
+                             str(len(self._input_layers)) + ' tensor inputs.')
-        cache_key = ','.join([str(x) for x in input_shapes])
+        cache_key = ', '.join([str(x) for x in input_shapes])
-                layer = self.input_layers[i]
+                layer = self._input_layers[i]
-                        if layer in self.input_layers:
+                        if layer in self._input_layers:
-                tensor_index = self.output_layers_tensor_indices[i]
+            for i in range(len(self._output_layers)):
-                                for x in output_tensors]
+                            with K.name_scope('activity_regularizer'):
-        cache_key += '_' + ','.join([str(id(x)) for x in masks])
+        cache_key = object_list_uid(inputs)
-            cache_key = ','.join([str(x) for x in input_shapes])
+            cache_key = ', '.join([str(x) for x in input_shapes])
-            node_index = self.input_layers_node_indices[i]
+        for i in range(len(self._input_layers)):
-            tensor_index = self.input_layers_tensor_indices[i]
+            tensor_index = self._input_coordinates[i][2]
-            node_index = self.output_layers_node_indices[i]
+        for i in range(len(self._output_layers)):
-            tensor_index = self.output_layers_tensor_indices[i]
+            tensor_index = self._output_coordinates[i][2]
-        if include_optimizer and hasattr(model, 'optimizer'):
+        if include_optimizer and model.optimizer:
-        self.layers = []  # Stack of layers.
+        self._layers = []  # Stack of layers.
-        self.output_layers_tensor_indices = self.model.output_layers_tensor_indices
+        self._input_layers = self.model._input_layers
-        self.loss = loss
+        self.loss = loss or []
-                shape = self._internal_output_shapes[i]
+                shape = K.int_shape(self.outputs[i])
-                    output_shape = self._internal_output_shapes[i]
+                    output_shape = K.int_shape(self.outputs[i])
-                output_shapes.append(None)
+    def _set_inputs(self, inputs, outputs=None, training=None):
-        if check_array_lengths:
+                # Assumed tensor - TODO(fchollet) additional type check?
-                                            self._feed_output_shapes)
+            if self._is_graph_network:
-                                   check_batch_axis=False)
+        x, _, _ = self._standardize_user_data(x)
-                                   self._feed_input_shapes)
+        x, _, _ = self._standardize_user_data(x)
-        for layer in model.input_layers:
+        for layer in model._input_layers:
-        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):
+        for original_input_layer, cloned_input_layer in zip(model._input_layers, input_layers):
-                name = model.input_layers[i].name
+                name = model._input_layers[i].name
-        to_display = ['Layer (type)', 'Output Shape', 'Param #', 'Connected to']
+        to_display = ['Layer (type)',
-        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]
+        fields = [name + ' (' + cls_name + ')',
-                connections.append(inbound_layer + '[' + str(inbound_node_index) + '][' + str(inbound_tensor_index) + ']')
+                connections.append(inbound_layer +
-        fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params(), first_connection]
+        fields = [name +
-    print_fn('Total params: {:,}'.format(trainable_count + non_trainable_count))
+    print_fn(
-    assert [l.name for l in model.output_layers] == ['dense_2', 'dense_3']
+    assert [l.name for l in model._input_layers] == ['input_a', 'input_b']
-    assert [l.name for l in recreated_model.output_layers] == ['dense_2', 'dense_3']
+    assert [l.name for l in recreated_model._input_layers] == ['input_a', 'input_b']
-    with pytest.raises(TypeError):
+    with pytest.raises(ValueError):
-    with pytest.raises(RuntimeError):
+    with pytest.raises(ValueError):
-    with pytest.raises(TypeError):
+    with pytest.raises(ValueError):
-    for depth, layers in model.layers_by_depth.items():
+    for depth, layers in model._layers_by_depth.items():
-                the channels axis should have value 1, and in case
+               x: data. Numpy array of rank 4 or a tuple. If tuple, the first element
-             `y` is a numpy array of corresponding labels."""
+            An Iterator yielding tuples of `(x, y)` where `x` is a numpy array of image data
-        x: Numpy array of input data.
+        x: Numpy array of input data or tuple. If tuple, the second elements is either
-        return batch_x, batch_y
+            return output[0]
-
+from ..utils import layer_utils
-    data format `(width, height, channels)`.
+    Optionally loads weights pre-trained on ImageNet. This model can
-                           'the TensorFlow backend.')
+        if K.backend() == 'theano':
-                    reason='Requires TensorFlow backend')
+    if b_any([isinstance(a, (list, tuple)) for a in axes]):
-        raise TypeError('Not a Keras tensor:', x)
+        return None
-        kernel_shape = None
+    kernel_shape = int_shape(kernel)
-        shape = None
+    shape = int_shape(x)
-        kernel_shape = kernel.eval().shape
+    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)
-        kernel_shape = kernel.eval().shape
+    kernel_shape = int_shape(kernel)
-        depthwise_kernel_shape = depthwise_kernel.eval().shape
+    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)
-        pointwise_kernel_shape = pointwise_kernel.eval().shape
+    pointwise_kernel_shape = int_shape(pointwise_kernel)
-        depthwise_kernel_shape = depthwise_kernel.eval().shape
+    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)
-        kernel_shape = kernel.eval().shape
+    volume_shape = _preprocess_conv3d_volume_shape(int_shape(x), data_format)
-        kernel_shape = kernel.eval().shape
+    kernel_shape = int_shape(kernel)
-from scipy.sparse import issparse
+from .training_utils import collect_metrics
-from .. import callbacks as cbks
+from ..utils.generic_utils import slice_arrays
-                target_tensors=None, **kwargs):
+    def compile(self, optimizer,
-        weighted_losses = [_weighted_masked_objective(fn) for fn in loss_functions]
+        weighted_losses = [
-                                               dtype=K.dtype(self.outputs[i]))
+                        target = K.placeholder(
-                self._feed_sample_weight_modes.append(self.sample_weight_modes[i])
+                self._feed_sample_weight_modes.append(
-        nested_weighted_metrics = _collect_metrics(weighted_metrics, self.output_names)
+        nested_metrics = collect_metrics(metrics, self.output_names)
-            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+            inputs = (self._feed_inputs +
-                updates = self.updates + training_updates + self.metrics_updates
+                updates = (self.updates +
-                                                 **self._function_kwargs)
+                self.train_function = K.function(
-            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+            inputs = (self._feed_inputs +
-                                            **self._function_kwargs)
+            self.test_function = K.function(
-            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+            if self._uses_dynamic_learning_phase():
-        return outs
+    def _uses_dynamic_learning_phase(self):
-        for output_shape, loss_fn in zip(self._feed_output_shapes, self._feed_loss_fns):
+        for output_shape, loss_fn in zip(self._feed_output_shapes,
-        sample_weights = [_standardize_weights(ref, sw, cw, mode)
+        # `check_batch_axis` is set to False since `x`
-                          in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]
+                          in zip(y,
-                                             self._feed_output_shapes)
+            check_array_length_consistency(x, y, sample_weights)
-        """Trains the model for a fixed number of epochs (iterations on a dataset).
+        """Trains the model for a given number of epochs (iterations on a dataset).
-            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+            if self._uses_dynamic_learning_phase():
-            y, val_y = (_slice_arrays(y, 0, split_at), _slice_arrays(y, split_at))
+            x, val_x = (slice_arrays(x, 0, split_at),
-            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+                slice_arrays(sample_weights, 0, split_at),
-            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+            if self._uses_dynamic_learning_phase():
-        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+        if self._uses_dynamic_learning_phase():
-            callback_metrics = copy.copy(out_labels) + ['val_' + n for n in out_labels]
+            callback_metrics = copy.copy(out_labels) + [
-                              validation_steps=validation_steps)
+        # Delegate logic to `fit_loop`.
-        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+        # Prepare inputs, delegate logic to `test_loop`.
-                               steps=steps)
+        return training_arrays.test_loop(self, f, ins,
-                                    check_batch_axis=False)
+        x = standardize_input_data(x,
-        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+        # Prepare inputs, delegate logic to `predict_loop`.
-                                  verbose=verbose, steps=steps)
+        return training_arrays.predict_loop(self, f, ins,
-        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+        if self._uses_dynamic_learning_phase():
-        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+        if self._uses_dynamic_learning_phase():
-        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
+        x = standardize_input_data(x,
-                      generator,
+    def fit_generator(self, generator,
-        """Trains the model on data generated batch-by-batch by a Python generator or an instance of `Sequence`.
+        """Trains the model on data generated batch-by-batch by a Python generator (or an instance of `Sequence`).
-                "pay more attention" to samples from an under-represented class.
+                "pay more attention" to samples
-                Note that because this implementation relies on multiprocessing,
+                Note that because this implementation
-                                steps_per_epoch=10000, epochs=10)
+        def generate_arrays_from_file(path):
-        return self.history
+        return training_generator.fit_generator(
-    def evaluate_generator(self, generator, steps=None,
+    def evaluate_generator(self, generator,
-        return averages
+        return training_generator.evaluate_generator(
-    def predict_generator(self, generator, steps=None,
+    def predict_generator(self, generator,
-            return [np.concatenate(out) for out in all_outs]
+        return training_generator.predict_generator(
-from keras.engine.training import _slice_arrays
+from keras.engine import training_utils
-            np.random.random((self.batch_size, 3))]
+        return ([np.random.random((self.batch_size, 3)),
-    _check_array_lengths(None, None, None)
+def test_check_array_length_consistency():
-    _check_array_lengths([None], [None], [None])
+    training_utils.check_array_length_consistency(a_np, a_np, a_np)
-        _check_array_lengths(a_np, None, None)
+        training_utils.check_array_length_consistency(a_np, None, None)
-        _check_array_lengths(a_np, a_np, None)
+        training_utils.check_array_length_consistency(a_np, a_np, None)
-        _check_array_lengths([a_np], [None], None)
+        training_utils.check_array_length_consistency([a_np], [None], None)
-        _check_array_lengths([a_np], [b_np], None)
+        training_utils.check_array_length_consistency([a_np], [b_np], None)
-        _check_array_lengths([a_np], None, [b_np])
+        training_utils.check_array_length_consistency([a_np], None, [b_np])
-def test_slice_arrays():
+def testslice_arrays():
-    _slice_arrays(input_a, stop=2)
+    slice_arrays(None)
-    _slice_arrays(input_a, stop=2)
+    slice_arrays(input_a, 0)
-    _slice_arrays(input_a, stop=2)
+    slice_arrays(input_a, 0)
-    _slice_arrays(input_a, stop=2)
+    slice_arrays(input_a, 0)
-    weighted_function = _weighted_masked_objective(losses.categorical_crossentropy)
+    weighted_function = training_utils.weighted_masked_objective(
-        model.train_on_batch([input_a_np, input_b_np], [output_a_np, output_b_np])
+        model.train_on_batch([input_a_np, input_b_np],
-                    validation_data=([input_a_np, input_b_np], [output_a_np, output_b_np]))
+                    validation_data=([input_a_np, input_b_np],
-                    validation_data=({'input_a': input_a_np, 'input_b': input_b_np}, [output_a_np, output_b_np]))
+                    validation_data=({'input_a': input_a_np,
-    out = model.predict_on_batch({'input_a': input_a_np, 'input_b': input_b_np})
+    out = model.predict_on_batch({'input_a': input_a_np,
-    out = model.evaluate([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4)
+    out = model.evaluate([input_a_np, input_b_np],
-                   [np.random.random((batch_sz, 4)), np.random.random((batch_sz, 3))])
+            yield ([np.random.random((batch_sz, 3)),
-    out = model.evaluate([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4)
+    out = model.fit([input_a_np, input_b_np],
-                                   sample_weight=[sample_weight[1], sample_weight[1][:2]])
+                                   sample_weight=[sample_weight[1],
-        model.compile(optimizer, loss='mse', sample_weight_mode={'lstm': 'temporal'})
+        model.compile(optimizer, loss='mse',
-        model.compile(optimizer, loss='mse', sample_weight_mode={'dense_1': 'temporal'})
+        model.compile(optimizer, loss='mse',
-    model.compile(optimizer, loss='mse', loss_weights={'dense_1': 0.2, 'dropout': 0.8})
+    model.compile(optimizer, loss='mse', loss_weights={'dense_1': 0.2,
-    model.compile(optimizer, loss='mse', sample_weight_mode={'dense_1': None, 'dropout': 'temporal'})
+    model.compile(optimizer, loss='mse',
-                              validation_steps=3, callbacks=[tracker_cb])
+    out = model.fit_generator(generator=RandomSequence(3),
-                              initial_epoch=0, validation_data=RandomSequence(4),
+    out = model.fit_generator(generator=RandomSequence(3),
-    # fit_generator will throw an exception if steps is unspecified for regular generator
+    # fit_generator will throw an exception
-    # Need range check here as filling of the queue depends on sleep in the enqueuers
+    # Need range check here as filling
-    # Need range check here as filling of the queue depends on sleep in the enqueuers
+    # Need range check here as filling
-                                                 sequence_length=sequence_length))
+    out = model.predict_generator(
-                                                 sequence_length=sequence_length))
+    out = model.predict_generator(
-    single_output_model.compile(optimizer, loss, metrics=[], sample_weight_mode=None)
+    single_output_model.compile(optimizer, loss,
-                                                sequence_length=sequence_length))
+    out = single_output_model.predict_generator(
-                                                sequence_length=sequence_length))
+    out = single_output_model.predict_generator(
-@pytest.mark.skipif(sys.version_info < (3,), reason='Cannot catch warnings in python 2')
+@pytest.mark.skipif(sys.version_info < (3,),
-                   [np.random.random((batch_sz, 4)), np.random.random((batch_sz, 3))])
+            yield ([np.random.random((batch_sz, 3)),
-        out = model.fit_generator(gen_data(4), steps_per_epoch=10, use_multiprocessing=True, workers=2)
+        out = model.fit_generator(gen_data(4),
-        out = model.fit_generator(RandomSequence(3), steps_per_epoch=4, use_multiprocessing=True, workers=2)
+        out = model.fit_generator(RandomSequence(3),
-    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.5)
+    model.fit(test_inputs, test_outputs,
-    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.5)
+    model.fit(test_inputs, test_outputs,
-    _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [(2, None, 3)])
+    training_utils.check_loss_and_target_compatibility(
-        _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [a.shape])
+        training_utils.check_loss_and_target_compatibility(
-        _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [(2, 3, 6)])
+        training_utils.check_loss_and_target_compatibility(
-from keras.engine.training import _make_batches
+from keras.engine.training_utils import make_batches
-            batches = _make_batches(len(x_test), batch_size)
+            batches = make_batches(len(x_test), batch_size)
-from keras.engine.training import _weighted_masked_objective
+from keras.engine.training_utils import weighted_masked_objective
-    weighted_loss = _weighted_masked_objective(losses.get('mae'))
+    weighted_loss = weighted_masked_objective(losses.get('mae'))
-from keras.engine.topology import Layer
+from keras.layers import Layer
-from ..engine.topology import get_source_inputs
+from ..engine import get_source_inputs
-from ..engine.topology import get_source_inputs
+from ..engine import get_source_inputs
-from ..engine.topology import get_source_inputs
+from ..engine import get_source_inputs
-from ..engine import InputSpec
+from ..engine import get_source_inputs
-from ..engine.topology import get_source_inputs
+from ..engine import get_source_inputs
-from ..engine.topology import get_source_inputs
+from ..engine import get_source_inputs
-from ..engine.topology import get_source_inputs
+from ..engine import get_source_inputs
-from ..engine.topology import get_source_inputs
+from ..engine import get_source_inputs
-from ..engine.topology import get_source_inputs
+from ..engine import get_source_inputs
-# note: topology.Node is an internal class,
+# note: `Node` is an internal class,
-from .topology import get_source_inputs
+from .input_layer import Input
-"""Topology-related part of the Keras engine.
+"""This module is deprecated, but kept around for backwards compatibility.
-    K.batch_set_value(weight_value_tuples)
+from .base_layer import Layer, Node, InputSpec
-from .topology import Layer
+from .network import Network
-    """The `Model` class adds training & evaluation routines to a `Container`.
+class Model(Network):
-from ..engine import Layer
+from ..engine.base_layer import Layer
-from ..engine import InputSpec
+from ..engine.base_layer import InputSpec
-from ..engine import InputSpec
+from ..engine.base_layer import Layer
-from ..engine import InputSpec
+from ..engine.base_layer import Layer
-from ..engine import InputSpec, Layer
+from ..engine.base_layer import InputSpec, Layer
-from ..engine import Layer
+from ..engine.base_layer import InputSpec
-from ..engine import Layer
+from ..engine.base_layer import Layer
-from ..engine import InputSpec
+from ..engine.base_layer import Layer
-from ..engine.topology import Layer
+from ..engine.base_layer import Layer
-from ..engine import Layer
+from ..engine.base_layer import Layer
-from ..engine import Layer, InputSpec
+from ..engine.base_layer import Layer, InputSpec
-from ..engine import InputSpec
+from ..engine.base_layer import Layer
-from ..engine import InputSpec
+from ..engine.base_layer import Layer
-from ..engine.topology import _object_list_uid
+from ..engine.base_layer import Layer
-            uid = _object_list_uid(inputs)
+            uid = object_list_uid(inputs)
-            input_uid = _object_list_uid(inputs)
+            input_uid = object_list_uid(inputs)
-from ..engine.topology import Layer, InputSpec
+from ..engine import Layer, InputSpec
-"""Sequential model class and model-related utilities.
+"""Model-related utilities.
-from .utils.io_utils import ask_to_proceed_with_overwrite
+from .utils.generic_utils import to_list
-from .legacy import interfaces
+from .engine.sequential import Sequential
-        input_tensors = topology._to_list(input_tensors)
+        input_tensors = to_list(input_tensors)
-                if isinstance(layer, topology.InputLayer):
+                if isinstance(layer, InputLayer):
-                    output_tensors = topology._to_list(
+                    output_tensors = to_list(
-                    output_masks = topology._to_list(
+                    output_masks = to_list(
-                    output_tensors = topology._to_list(
+                    output_tensors = to_list(
-                    output_masks = topology._to_list(
+                    output_masks = to_list(
-        if len(topology._to_list(input_tensors)) != 1:
+        if len(to_list(input_tensors)) != 1:
-        x = topology._to_list(input_tensors)[0]
+        x = to_list(input_tensors)[0]
-            if isinstance(origin_layer, topology.InputLayer):
+            if isinstance(origin_layer, InputLayer):
-                                                           list(custom_objects.items())))
+                return cls.from_config(
-                    eta_format = '%d:%02d:%02d' % (eta // 3600, (eta % 3600) // 60, eta % 60)
+                    eta_format = ('%d:%02d:%02d' %
-            if node_key in model._container_nodes:
+            if node_key in model._network_nodes:
-from keras.engine import Input, Layer, topology, get_source_inputs
+from keras.engine import Input, Layer, saving, get_source_inputs
-    weight_tensor_td_conv_new = topology.preprocess_weights_for_loading(
+    weight_tensor_td_conv_new = saving.preprocess_weights_for_loading(
-    weight_tensor_bi_convlstm_new = topology.preprocess_weights_for_loading(
+    weight_tensor_bi_convlstm_new = saving.preprocess_weights_for_loading(
-    weights2 = topology.preprocess_weights_for_loading(
+    weights2 = saving.preprocess_weights_for_loading(
-    weights2 = topology.preprocess_weights_for_loading(
+    weights2 = saving.preprocess_weights_for_loading(
-    weights2 = topology.preprocess_weights_for_loading(layer, weights1)
+    weights2 = saving.preprocess_weights_for_loading(layer, weights1)
-from keras.engine.topology import Input
+from keras.engine import Input
-        weights = keras.engine.topology.preprocess_weights_for_loading(target_layer, weights)
+        weights = keras.engine.saving.preprocess_weights_for_loading(target_layer, weights)
-            keras.engine.topology.preprocess_weights_for_loading(
+            keras.engine.saving.preprocess_weights_for_loading(
-from keras.layers.core import Masking
+from keras.engine import Input
-from keras.engine.topology import _object_list_uid, _to_list
+from keras.utils.generic_utils import object_list_uid, to_list
-    uid = _object_list_uid(model.inputs)
+    uid = object_list_uid(model.inputs)
-    f_merged = K.function([inputs], _to_list(layer(inputs)))
+    f_merged = K.function([inputs], to_list(layer(inputs)))
-    y_expected = _to_list(merge_func(f_forward(X)[0], f_backward(X)[0]))
+    y_expected = to_list(merge_func(f_forward(X)[0], f_backward(X)[0]))
-    y_expected = _to_list(merge_func(y_forward[0], y_backward[0]))
+    y_expected = to_list(merge_func(y_forward[0], y_backward[0]))
-    outputs = _to_list(wrapped(inputs, training=True))
+    outputs = to_list(wrapped(inputs, training=True))
-    outputs = _to_list(wrapped(inputs))
+    outputs = to_list(wrapped(inputs))
-    y2 = _to_list(model.predict(X))
+    y1 = to_list(model.predict(X))
-    raise NotImplementedError
+    """2D convolution with separable filters.
-        inconditional, or conditional on inputs to this model
+        unconditional, or conditional on inputs to this model
-        inconditional, or conditional on inputs to this model
+        unconditional, or conditional on inputs to this model
-    # The chunking of layer names array should have happend.
+    # The chunking of layer names array should have happened.
-    # The chunking of layer names array should have happend.
+    # The chunking of layer names array should have happened.
-__version__ = '2.1.5'
+__version__ = '2.1.6'
-      version='2.1.5',
+      version='2.1.6',
-      download_url='https://github.com/keras-team/keras/tarball/2.1.5',
+      download_url='https://github.com/keras-team/keras/tarball/2.1.6',
-        mode: One of "caffe", "tf".
+        mode: One of "caffe", "tf" or "torch".
-import scipy.signal as signal
+import reference_operations
-            last_y1, y1, h1 = ref_rnn(x, [wi, wh, None], h0, **kwargs)
+            last_y1, y1, h1 = reference_operations.rnn(x, [wi, wh, None], h0, **kwargs)
-                                  go_backwards=False, mask=None)
+        last_y1, y1, h1 = reference_operations.rnn(x, [wi, None, None], None,
-        y1 = ref_conv(x, w, padding, data_format)
+        y1 = reference_operations.conv(x, w, padding, data_format)
-        y1 = ref_depthwise_conv(x, w, padding, data_format)
+        y1 = reference_operations.depthwise_conv(x, w, padding, data_format)
-        y1 = ref_pool(x, pool_size, strides, padding, data_format, pool_mode)
+        y1 = reference_operations.pool(x, pool_size, strides, padding, data_format, pool_mode)
-        y1 = ref_separable_conv(x, depthwise, pointwise, padding, data_format)
+        y1 = reference_operations.separable_conv(x, depthwise, pointwise, padding, data_format)
-_LEARNING_PHASE = C.constant(shape=(), dtype=np.float32, value=1.0, name='_keras_learning_phase')
+# LEARNING_PHASE_PLACEHOLDER is the placeholder for dynamic learning phase
-    return _LEARNING_PHASE
+    # If _LEARNING_PHASE is not 0 or 1, return dynamic learning phase tensor
-    _LEARNING_PHASE.value = v
+    _LEARNING_PHASE = value
-        result = C.element_select(training, x, alt)
+        # if _LEARNING_PHASE is static
-                _LEARNING_PHASE.value = np.asarray(value)
+            if tensor == _LEARNING_PHASE_PLACEHOLDER:
-            if self.unrelated_updates is None and _LEARNING_PHASE.value == 1.0:
+            if (self.unrelated_updates is None and
-        if K.backend() == 'tensorflow':
+        if K.backend() == 'tensorflow' or K.backend() == 'cntk':
-
+        with pytest.raises(ValueError):
-                                   k.variable(np.ones((2, 2, 3, 4))),
+                K.separable_conv2d(K.variable(np.ones((2, 3, 4, 5))),
-                        k.pool3d(x, pool_size=pool_size, pool_mode='median')
+            x = K.variable(np.random.random(input_shape))
-        height_shift_range: Float (fraction of total height). Range for random vertical shifts.
+        width_shift_range: float, 1-D array-like or int
-            if self.height_shift_range < 1:
+            try:  # 1-D array-like or int
-            if self.width_shift_range < 1:
+            try:  # 1-D array-like or int
-                         + str(input_shape) + '`.')
+                         '(no None entries). Got: `input_shape=' +
-            (self.end_index - self.start_index) /
+            (self.end_index - self.start_index + 1) /
-                self.start_index, self.end_index, size=self.batch_size)
+                self.start_index, self.end_index + 1, size=self.batch_size)
-                                    self.stride, self.end_index), self.stride)
+                                    self.stride, self.end_index + 1), self.stride)
-from numpy.testing import assert_allclose
+from numpy.testing import assert_allclose, assert_raises
-    assert len(data_gen) == 5
+    assert len(data_gen) == 6
-    assert len(data_gen) == 5
+    assert len(data_gen) == 6
-dataset = Dataset.from_tensor_slices((x_train, y_train))
+dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
-            inputs = reverse(inputs, 1)
+            rnn_inputs = reverse(rnn_inputs, 1)
-        inputs = C.to_sequence(inputs)
+        rnn_inputs = C.to_sequence(rnn_inputs)
-                    i += 1
+        rnn_constants = []
-            j += 1
+                if _get_dynamic_axis_num(constant) == 1:
-        mask = C.to_sequence_like(mask, inputs)
+        mask = C.to_sequence_like(mask, rnn_inputs)
-                x, tuple(past_values) + tuple(constants))
+                x, tuple(past_values) + tuple(rnn_constants))
-        final_output, final_states = _recurrence(inputs, states, mask)
+        final_output, final_states = _recurrence(rnn_inputs, states, mask)
-            inputs, initial_state, constants)
+        inputs, initial_state, constants = _standardize_args(
-            inputs, initial_state, constants)
+        inputs, initial_state, constants = _standardize_args(
-
+
-            inputs = inputs[0]
+    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):
-        if initial_state is None:
+        if initial_state is None and constants is None:
-        self.backward_layer.state_spec = additional_specs[num_states // 2:]
+        # Applies the same workaround as in `RNN.__call__`
-    def call(self, inputs, training=None, mask=None, initial_state=None):
+    def call(self,
-                return [mask, mask]
+                output_mask = [mask, mask]
-                return mask
+                output_mask = mask
-            return None
+            output_mask = [None, None] if not self.merge_mode else None
-from keras.layers import wrappers, Input
+from keras.utils import CustomObjectScope
-                    m.reset_states()
+            for m in self.stateful_metric_functions:
-                    m.reset_states()
+            for m in self.stateful_metric_functions:
-                        m.reset_states()
+                for m in self.stateful_metric_functions:
-                    m.reset_states()
+            for m in self.stateful_metric_functions:
-def test_stateful_metrics():
+@pytest.mark.parametrize('metrics_mode', ['list', 'dict'])
-    outputs = keras.layers.Dense(1, activation='sigmoid')(inputs)
+    outputs = keras.layers.Dense(1, activation='sigmoid', name='out')(inputs)
-                  metrics=['acc', metric_fn])
+
-        return sum(x * y, axis=1, keepdims=True)
+        if axes[0] == axes[1]:
-def multi_gpu_model(model, gpus=None):
+def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):
-    # Example
+    # Example 1 - Training models with weights merge on CPU
-    with tf.device('/cpu:0'):
+    # Merge outputs under expected scope.
-                                  (epoch + 1, self.monitor))
+                            print('\nEpoch %05d: %s did not improve from %0.5f' %
-                 be automatically inferred from the subdirectory names/structure under `directory`,
+                classes: optional list of class subdirectories (e.g. `['dogs', 'cats']`). Default: None.
-                 "sparse" will be 1D integer labels, "input" will be images identical to input images (mainly used to work with autoencoders).
+                class_mode: one of "categorical", "binary", "sparse", "input" or None. Default: "categorical".
-             `y` is a numpy array of corresponding labels.
+            A DirectoryIterator yielding tuples of `(x, y)` where `x` is a numpy array containing a batch
-    import pydot_ng as pydot
+    import pydot
-            pydot = None
+    pydot = None
-                          ' and graphviz for `pydotprint` to work.')
+    except OSError:
-          'visualize': ['pydot>=1.2.0'],
+          'visualize': ['pydot>=1.2.4'],
-    # cntk will init type based on the value type
+
-    return C.element_select(learning_phase(), x, alt)
+def in_test_phase(x, alt, training=None):
-                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),
+                K.ones_like(inputs),
-                _generate_dropout_ones(inputs, self.units),
+                K.ones_like(prev_output),
-                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),
+                K.ones_like(inputs),
-                _generate_dropout_ones(inputs, self.units),
+                K.ones_like(h_tm1),
-                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),
+                K.ones_like(inputs),
-                _generate_dropout_ones(inputs, self.units),
+                K.ones_like(states[0]),
-            `(224, 224, 3)` for NASNetMobile
+        input_shape: Optional shape tuple, the input shape
-                                      require_flatten=include_top or weights,
+                                      require_flatten=False,
-        with codecs.open(self.monogram_file, mode='rt', encoding='utf-8') as f:
+        with codecs.open(self.monogram_file, mode='r', encoding='utf-8') as f:
-        with codecs.open(self.bigram_file, mode='rt', encoding='utf-8') as f:
+        with codecs.open(self.bigram_file, mode='r', encoding='utf-8') as f:
-    """Returns the gradients of `variables` w.r.t. `loss`.
+    """Returns the gradients of `loss` w.r.t. `variables`.
-                        'pyyaml'],
+                        'pyyaml',
-                    if isinstance(x, list):
+                    if x is None or len(x) == 0:
-                if isinstance(x, list):
+                if x is None or len(x) == 0:
-    categorical = np.zeros((n, num_classes))
+    categorical = np.zeros((n, num_classes), dtype=np.float32)
-        X = np.zeros((samples,) + input_shape)
+        X = np.zeros((samples,) + input_shape, dtype=np.float32)
-        y = np.zeros((samples,) + output_shape)
+        X = np.zeros((samples,) + input_shape, dtype=np.float32)
-            (preprocessing.image.ImageDataGenerator, "*")
+            (preprocessing.image.ImageDataGenerator, '*')
-def render_function(function, blocks, method=True):
+def render_function(function, method=True):
-    subblocks.append('#' * level + function.__name__ + '\n')
+    level = 3
-    blocks.append('\n\n'.join(subblocks))
+    return '\n\n'.join(subblocks)
-                render_function(method, subblocks, method=True)
+            subblocks.append('\n---')
-        render_function(function, blocks, method=False)
+        blocks.append(render_function(function, method=False))
-            preprocessing.image.ImageDataGenerator,
+            (preprocessing.image.ImageDataGenerator, "*")
-    for cls in classes:
+    for element in classes:
-        subblocks.append('### ' + cls.__name__ + '\n')
+        if element[1]:
-        blocks.append('\n\n'.join(subblocks))
+        render_function(function, blocks, method=False)
-                           use_multiprocessing=False):
+                           use_multiprocessing=False,
-    current_layout = tuple([i for i in range(dims)])
+    if isinstance(pattern, list):
-    def __init__(self, **kwargs):
+    def __init__(self, data_format='channels_last', **kwargs):
-               input_shape=(3, 2, 4))
+
-        filepath: String, path where to save the model.
+        filepath: one of the following:
-            return
+    if not isinstance(filepath, h5py.File):
-    with h5py.File(filepath, mode='w') as f:
+    try:
-        filepath: String, path to the saved model.
+        filepath: one of the following:
-    with h5py.File(filepath, mode='r') as f:
+
-    return model
+        return model
-    input_length = tf.to_int32(tf.squeeze(input_length))
+    label_length = tf.to_int32(tf.squeeze(label_length, axis=-1))
-            `(samples,time, channels, rows, cols)`
+            `(samples, time, channels, rows, cols)`
-            `(samples,time, rows, cols, channels)`
+            `(samples, time, rows, cols, channels)`
-        shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)
+        shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)
-            This is seful to reserve part of the data for test or validation.
+            This is useful to reserve part of the data for test or validation.
-        field: String; JSON field under which the data will be stored.
+        field: String; JSON field under which the data will be stored. The field is used only if the payload is sent
-                 headers=None):
+                 headers=None,
-                          headers=self.headers)
+            if self.send_as_json:
-        epsilon: threshold for measuring the new optimum,
+        min_delta: threshold for measuring the new optimum,
-                 verbose=0, mode='auto', epsilon=1e-4, cooldown=0, min_lr=0):
+                 verbose=0, mode='auto', min_delta=1e-4, cooldown=0, min_lr=0,
-        self.epsilon = epsilon
+        self.min_delta = min_delta
-            self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)
+            self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)
-            self.monitor_op = lambda a, b: np.greater(a, b + self.epsilon)
+            self.monitor_op = lambda a, b: np.greater(a, b + self.min_delta)
-    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=10, patience=1, cooldown=5)]
+    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=10, patience=1, cooldown=5)]
-    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=0, patience=1, cooldown=5)]
+    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=0, patience=1, cooldown=5)]
-    """Reset graph identifiers."""
+    """Resets graph identifiers.
-                        if isinstance(metric_fn, Layer):
+                        if isinstance(metric_fn, Layer) and metric_fn.stateful:
-                if isinstance(m, Layer):
+                if isinstance(m, Layer) and m.stateful:
-                if isinstance(m, Layer):
+                if isinstance(m, Layer) and m.stateful:
-                            outs[i] = batch_out
+                            outs[i] = float(batch_out)
-        all_outs = []
+        outs_per_batch = []
-                averages.append(np.average([out[i] for out in all_outs],
+        averages = []
-            return averages
+            else:
-                self._values[k] = v
+                # Stateful metrics output a numeric value.  This representation
-                positive class prediction.
+            self.stateful = True
-    model.fit(x, y, epochs=1, batch_size=10)
+
-            channels will be equal to `filterss_in * depth_multiplier`.
+            channels will be equal to `filters_in * depth_multiplier`.
-            channels will be equal to `filterss_in * depth_multiplier`.
+            channels will be equal to `filters_in * depth_multiplier`.
-            channels will be equal to `filterss_in * depth_multiplier`.
+            channels will be equal to `filters_in * depth_multiplier`.
-        split: Sentence split marker (string).
+        filters: list (or concatenation) of characters to filter out, such as
-        split: Sentence split marker (string).
+        n: int. Size of vocabulary.
-        A list of integer word indices (unicity non-guaranteed).
+        List of integers in [1, n]. Each integer encodes a word (unicity non-guaranteed).
-        hash_function: if `None` uses python `hash` function, can be 'md5' or
+        hash_function: defaults to python `hash` function, can be 'md5' or
-            Note that `hash` is not a stable hashing function, so
+            Note that 'hash' is not a stable hashing function, so
-        split: Sentence split marker (string).
+        filters: list (or concatenation) of characters to filter out, such as
-        split: character or string to use for token splitting.
+        split: str. Separator for word splitting.
-modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend', 'keras.preprocessing.image']
+modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend', 'keras.preprocessing.image',
-                return np.ceil(len(self.x) / float(self.batch_size))
+                return int(np.ceil(len(self.x) / float(self.batch_size)))
-    """Generate minibatches of image data with real-time data augmentation.
+    """Generate batches of tensor image data with real-time data augmentation.
-        zca_whitening: apply ZCA whitening.
+        featurewise_center: Boolean. Set input mean to 0 over the dataset, feature-wise.
-            but before any other transformation.
+        zca_whitening: Boolean. Apply ZCA whitening.
-            (the depth) is at index 1, in 'channels_last' mode it is at index 3.
+                The function will run after the image is resized and augmented.
-        validation_split: fraction of images reserved for validation (strictly between 0 and 1).
+        validation_split: Float. Fraction of images reserved for validation (strictly between 0 and 1).
-        and zca_whitening.
+        """Compute the internal data stats related to the data-dependent transformations, based on an array of sample data.
-        """
+            x: sample data. Should have rank 4.
-modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend']
+modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend', 'keras.preprocessing.image']
-    if is_accepted(name, member):
+    if is_accepted(name, member) or member_too_small(member):
-    if doc is None and not member_too_small(member):
+    if doc is None:
-        weight_values = [g[weight_name] for weight_name in weight_names]
+        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]
-        weight_values = [g[weight_name] for weight_name in weight_names]
+        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]
-                             ' Input shape provided = %s' % (input_shape,))
+            if rows is None:
-    x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)
+    x = BatchNormalization(
-    x = BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)
+    x = BatchNormalization(
-            x = self.image_data_generator.preprocessing_function(x)
+            x = self.preprocessing_function(x)
-        generator = image.ImageDataGenerator()
+        generator = image.ImageDataGenerator(preprocessing_function=preprocessing_function)
-    [[1, 3, 4, 5, 1337], [1, 3, 7, 9, 2, 1337, 2018]]
+    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]
-            for ngram_value in range(2, ngram_range + 1):
+        for ngram_value in range(2, ngram_range + 1):
-            layers.StackedRNNCells,
+        if self.preprocessing_function:
-                           target_size=None,
+                           target_size=self.target_size,
-        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.
+        padding: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.
-            - If tuple of 2 ints:
+            - If tuple of 3 ints:
-            - If tuple of 2 tuples of 2 ints:
+            - If tuple of 3 tuples of 2 ints:
-    return T.exp(x) / T.exp(x).sum(axis=axis, keepdims=True)
+    return T.exp(x - x.max()) / T.exp(
-        i = layers.Input(shape=(64, 64, 3))
+        i = layers.Input(shape=(3, 2, 1))
-        assert o2._keras_shape == (None, 64, 64, 3)
+        assert o1._keras_shape == (None, 3, 2, 1)
-        x = np.random.random((4, 64, 64, 3))
+        x = np.random.random((4, 3, 2, 1))
-        assert out2.shape == (4, 64, 64, 3)
+        assert out1.shape == (4, 3, 2, 1)
-        i = layers.Input(shape=(64, 64, 3))
+        i = layers.Input(shape=(3, 2, 1))
-        assert o[1]._keras_shape == (None, 64, 64, 3)
+        assert o[0]._keras_shape == (None, 3, 2, 1)
-        i2 = layers.Input(shape=(64, 64, 3))
+        i2 = layers.Input(shape=(3, 2, 1))
-        x = np.random.random((4, 64, 64, 3))
+        x = np.random.random((4, 3, 2, 1))
-        assert out.shape == (4, 64, 64, 3)
+        assert out.shape == (4, 3, 2, 1)
-    return C.softmax(x)
+def softmax(x, axis=-1):
-def softmax(x):
+def softmax(x, axis=-1):
-    return tf.nn.softmax(x)
+    return tf.nn.softmax(x, axis=axis)
-    return T.nnet.softmax(x)
+def softmax(x, axis=-1):
-        check_single_tensor_operation('softmax', (4, 10), BACKENDS)
+        check_single_tensor_operation('softmax', (4, 10), BACKENDS)
-                                                                       computed_mask))
+                            output_masks = layer.compute_mask(computed_tensor,
-
+                            output_masks = layer.compute_mask(computed_tensors,
-    def test_pool2d(self):
+    def legacy_test_pool2d(self):
-    def test_pool3d(self):
+    def legacy_test_pool3d(self):
-        translate_map = dict((ord(c), unicode(split)) for c in filters)
+    if sys.version_info < (3,):
-        translate_map = maketrans(filters, split * len(filters))
+        translate_dict = dict((c, split) for c in filters)
-    text = text.translate(translate_map)
+def test_text_to_word_sequence_multichar_split():
-        padding = (w_pad, h_pad, d_pad)
+        pad = (w_pad, h_pad, d_pad)
-        padding = (0, 0, 0)
+        pad = (0, 0, 0)
-                                pad=padding,
+                                pad=pad,
-                                pad=padding,
+                                pad=pad,
-__version__ = '2.1.4'
+__version__ = '2.1.5'
-      version='2.1.4',
+      version='2.1.5',
-      download_url='https://github.com/keras-team/keras/tarball/2.1.4',
+      download_url='https://github.com/keras-team/keras/tarball/2.1.5',
-                    assert_allclose(z_tf, z_c, 1e-3)
+    @pytest.mark.skipif(K.backend() == 'theano', reason='Not supported.')
-        return_sequences: Boolean. Whether to return the last output.
+        return_sequences: Boolean. Whether to return the last output
-        return_sequences: Boolean. Whether to return the last output.
+        return_sequences: Boolean. Whether to return the last output
-        return_sequences: Boolean. Whether to return the last output.
+        return_sequences: Boolean. Whether to return the last output
-        return_sequences: Boolean. Whether to return the last output.
+        return_sequences: Boolean. Whether to return the last output
-            x = np.transpose(x, (0, 4, 1, 2, 3))
+def normalize_ref_conv(func):
-            y = np.transpose(y, (0, 2, 3, 4, 1))
+
-    def test_depthwise_conv_2d(self):
+    def legacy_test_depthwise_conv_2d(self):
-
+def ref_rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None):
-    def test_rnn_no_states(self):
+    def legacy_test_rnn_no_states(self):
-    """Pads each sequence to the same length (length of the longest sequence).
+    """Pads sequences to the same length.
-    the end of the sequence.
+    This function transforms a list of
-    Supports post-padding and pre-padding (default).
+    Sequences that are shorter than `num_timesteps`
-    according to the sampling distribution used in word2vec.
+    Used for generating the `sampling_table` argument for `skipgrams`.
-        `p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))`
+    `p(word) = min(1, sqrt(word_frequency / sampling_factor) / (word_frequency / sampling_factor))`
-        where `gamma` is the Euler-Mascheroni constant.
+
-    and `label == 0` if 'other_word' is randomly sampled.
+    This function transforms a sequence of word indexes (list of integers)
-        A `Sequence` instance.
+        A [Sequence](/utils/#sequence) instance.
-        value: float, value to pad the sequences to the desired value.
+        sequences: List of lists, where each element is a sequence.
-        x: numpy array with dimensions (number_of_sequences, maxlen)
+        x: Numpy array with shape `(len(sequences), maxlen)`
-        ValueError: in case of invalid values for `truncating` or `padding`,
+        ValueError: In case of invalid values for `truncating` or `padding`,
-            raise ValueError('Truncating type "%s" not understood' % truncating)
+            raise ValueError('Truncating type "%s" '
-            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %
+            raise ValueError('Shape of sample %s of sequence at position %s '
-        p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))
+        `p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))`
-        where gamma is the Euler-Mascheroni constant.
+       `frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))`
-        sampling_factor: the sampling factor in the word2vec formula.
+        size: Int, number of possible words to sample.
-    and label=0 if 'other_word' is randomly sampled
+    returns couples of samples `[word_index, other_word index]`
-        sequence: a word sequence (sentence), encoded as a list
+        sequence: A word sequence (sentence), encoded as a list
-        shuffle: whether to shuffle the word couples before returning them.
+        vocabulary_size: Int, maximum possible word index + 1
-            if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]
+            integers (eg. `[0, 1, 1 .. ]`),
-        seed: random seed.
+        seed: Random seed.
-                    random.randint(1, vocabulary_size - 1)] for i in range(num_negative_samples)]
+                    random.randint(1, vocabulary_size - 1)]
-        label: list where each element is an integer
+        maxlen: Int, maximum length of the output sequences.
-    stride, length of history etc., to produce batches for
+    stride, length of history, etc., to produce batches for
-            points. For rate `r`, points
+        data: Indexable generator (such as list or Numpy array)
-            (except maybe last one)
+            are used for create a sample sequence.
-                              np.array([[10], [11]])))
+    ```python
-                 length,
+    def __init__(self, data, targets, length,
-    def test_conv1d(self):
+    @pytest.mark.parametrize('op,input_shape,kernel_shape,padding,data_format', [
-    def test_conv2d(self):
+    def legacy_test_conv2d(self):
-    def test_conv3d(self):
+    def legacy_test_conv3d(self):
-                            validation_generator = validation_data
+            if do_validation and not val_gen:
-                        cbk.validation_data = val_data
+                    raise ValueError('`validation_data` should be a tuple '
-                                validation_generator,
+                                validation_data,
-                                workers=0)
+                                workers=workers,
-    assert 3 <= gen_counters[1] <= 5
+    # 12 = (epoch * workers * validation steps * max_queue_size)
-    assert 3 <= gen_counters[0] <= 5
+    assert 3 <= gen_counters[0] <= 12
-        """Trains the model on data yielded batch-by-batch by a Python generator.
+        """Trains the model on data generated batch-by-batch by a Python generator or an instance of `Sequence`.
-                dataset is not divisible by the batch size.
+                length (equal to the size of this batch). Different batches may
-                to yield from `validation_data` generator before stopping.
+                to yield from `validation_data` generator before stopping
-                an under-represented class.
+                (during training only). This can be useful to tell the model to
-                when using process based threading.
+                when using process-based threading.
-                Only used with instances of `Sequence` (`keras.utils.Sequence`).
+            use_multiprocessing: Boolean.
-                while 1:
+                while True:
-    def fit_generator(self, generator,
+    def fit_generator(self,
-            generator: A generator.
+            generator: A generator or an instance of `Sequence`
-                All arrays should contain the same number of samples.
+                - a tuple `(inputs, targets)`
-            callbacks: List of callbacks to be called during training.
+                epoch epochs is reached.
-                - A tuple (inputs, targets, sample_weights).
+                - a generator for the validation data
-                Number of steps to yield from validation generator
+                is a generator. Total number of steps (batches of samples)
-            shuffle: Whether to shuffle the order of the batches at
+            class_weight: Optional dictionary mapping class indices (integers)
-            initial_epoch: Epoch at which to start training
+                of `Sequence` (`keras.utils.Sequence`).
-                while 1:
+                while True:
-Input may optionally be inverted, shown to increase performance in many tasks in:
+Input may optionally be reversed, shown to increase performance in many tasks in:
-Two digits inverted:
+Two digits reversed:
-Three digits inverted:
+Three digits reversed:
-Four digits inverted:
+Four digits reversed:
-Five digits inverted:
+Five digits reversed:
-INVERT = True
+REVERSE = True
-    if INVERT:
+    if REVERSE:
-        print('Q', q[::-1] if INVERT else q, end=' ')
+        print('Q', q[::-1] if REVERSE else q, end=' ')
-        1 - y_true) * K.square(K.relu(y_pred - margin))
+    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (
-from .training_utils import multi_gpu_model
+from .multi_gpu_utils import multi_gpu_model
-        
+
-        assert_allclose(k.eval(xy_batch_dot), np.ones((20, 1)) * 32, atol=1e-05)
+    @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Not supported.')
-        assert_allclose(k.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)
+        x_batch = K.ones(shape=(32, 20))
-    def test_ctc(self, k, ref):
+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')
-        assert_allclose(res[:, 0] if k == KTF else res[0, :], ref, atol=1e-05)
+        k_labels = K.variable(labels, dtype="int32")
-    def test_map(self, k):
+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')
-        kx = k.eval(k.map_fn(k.sum, vx))
+        vx = K.variable(x)
-            dtype=k.floatx()
+        kx2 = K.eval(K.map_fn(
-    def test_foldl(self, k):
+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')
-        kx = k.eval(k.foldl(lambda a, b: a + b, k.variable(x)))
+        kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))
-    def test_foldr(self, k):
+    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')
-        p2 = k.eval(k.foldr(lambda a, b: a * b, vx))
+        vx = K.variable(x)
-                        validation_generator = validation_data
+                        if isinstance(validation_data, Sequence):
-                output_generator = generator
+                if is_sequence:
-                output_generator = generator
+                if is_sequence:
-                output_generator = generator
+                if is_sequence:
-            raise ValueError('Weights for "channels_last" format '
+            raise ValueError('Weights for "channels_first" format '
-    return tf.nn.l2_normalize(x, dim=axis)
+    return tf.nn.l2_normalize(x, axis=axis)
-                                mode=th_avg_pool_mode)
+                                mode='average_exc_pad')
-                k.conv2d(k.variable(xval), k.variable(kernel_val), data_format='channels_middle')
+        for (input_shape, kernel_shape, data_format) in [
-                k.conv3d(k.variable(xval), k.variable(kernel_val), data_format='channels_middle')
+        for (input_shape, kernel_shape, data_format) in [
-                                           ((1, 6, 5, 3), 'channels_last')]:
+        for (input_shape, data_format) in [
-
+    def test_conv_invalid_use(self):
-from .recurrent import Recurrent
+from .recurrent import _generate_dropout_mask
-from ..engine import InputSpec
+import warnings
-    Do not use in a model -- it's not a functional layer!
+class ConvRNN2D(RNN):
-        return_sequences: Boolean. Whether to return the last output
+        cell: A RNN cell instance. A RNN cell is a class that has:
-            If True, rocess the input sequence backwards.
+            If True, process the input sequence backwards and return the
-        5D tensor with shape `(num_samples, timesteps, channels, rows, cols)`.
+        5D tensor with shape:
-        - else, 4D tensor with shape `(num_samples, channels, rows, cols)`.
+        - if `return_state`: a list of tensors. The first tensor is
-        samples in different successive batches.
+        for the samples in the next batch. This assumes a one-to-one mapping
-                It should be a tuple of integers, e.g. `(32, 10, 100)`.
+                 - if sequential model:
-                 dilation_rate=(1, 1),
+    def __init__(self, cell,
-        self.stateful = stateful
+        if unroll:
-        if self.data_format == 'channels_first':
+
-        elif self.data_format == 'channels_last':
+        elif cell.data_format == 'channels_last':
-                                             dilation=self.dilation_rate[0])
+                                             cell.kernel_size[0],
-                                             dilation=self.dilation_rate[1])
+                                             cell.kernel_size[1],
-                                rows, cols, self.filters)
+            output = outputs
-                output_shape = (input_shape[0], rows, cols, self.filters)
+            output = last_output
-                output_shape = [output_shape] + [(input_shape[0], rows, cols, self.filters) for _ in range(2)]
+            if not isinstance(states, (list, tuple)):
-        return output_shape
+    def reset_states(self, states=None):
-        return dict(list(base_config.items()) + list(config.items()))
+        # helper function
-    and recurrent transformations are both convolutional.
+class ConvLSTM2DCell(Layer):
-                                         **kwargs)
+        super(ConvLSTM2DCell, self).__init__(**kwargs)
-        self.activity_regularizer = regularizers.get(activity_regularizer)
+        if K.backend() == 'theano' and (dropout or recurrent_dropout):
-        self.state_spec = [InputSpec(ndim=4), InputSpec(ndim=4)]
+        self.state_size = (self.filters, self.filters)
-            channel_axis = 2
+            channel_axis = 1
-                                        padding=self.padding)
+    def call(self, inputs, states, training=None):
-        return initial_states
+        # dropout matrices for input units
-                output_shape = (input_shape[0],) + output_shape[1:]
+        h_tm1 = states[0]  # previous memory state
-                        np.zeros(output_shape))
+        if 0 < self.dropout < 1.:
-            constants.append(rec_dp_mask)
+            inputs_i = inputs
-        return constants
+            h_tm1_i = h_tm1
-        rec_dp_mask = states[3]
+    def get_config(self):
-        return h, [h, c]
+class ConvLSTM2D(ConvRNN2D):
-        config = {'activation': activations.serialize(self.activation),
+        config = {'filters': self.filters,
-        return []
+            return self.cell.losses + layer_losses
-               padding='same',
+               padding='valid',
-               name='conv1')(inputs)
+               name='conv1')(x)
-                        padding='same',
+                        padding='valid',
-                        name='conv_dw_%d' % block_id)(inputs)
+                        name='conv_dw_%d' % block_id)(x)
-        64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)
+    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)
-    `custom_objects` parameter.
+    objects `relu6` and pass them to the `custom_objects` parameter.
-                       'DepthwiseConv2D': mobilenet.DepthwiseConv2D})
+                       'relu6': mobilenet.relu6})
-    raise NotImplementedError
+    if data_format is None:
-    raise NotImplementedError
+    """2D convolution with separable filters.
-                    reason='MobileNets are supported only on TensorFlow')
+    def test_depthwise_conv_2d(self):
-
+def test_depthwise_conv_2d():
-            x = self.preprocessing_function(x)
+            if self.image_data_generator.preprocessing_function:
-                           target_size=self.target_size,
+                           target_size=None,
-    raise NotImplementedError
+    if data_format is None:
-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')
+@pytest.mark.skipif(K.backend() == 'theano', reason='Theano does not support it yet')
-# the data, shuffled and split between train and test sets
+# the data, split between train and test sets
-# The data, shuffled and split between train and test sets:
+# The data, split between train and test sets:
-# The data, shuffled and split between train and test sets:
+# The data, split between train and test sets:
-# the data, shuffled and split between train and test sets
+# the data, split between train and test sets
-# The data, shuffled and split between train and test sets.
+# The data, split between train and test sets.
-# the data, shuffled and split between train and test sets
+# the data, split between train and test sets
-# the data, shuffled and split between train and test sets
+# the data, split between train and test sets
-# the data, shuffled and split between train and test sets
+# the data, split between train and test sets
-# the data, shuffled and split between train and test sets
+# the data, split between train and test sets
-# the data, shuffled and split between train and test sets
+# the data, split between train and test sets
-        if K.backend() == 'theano':
+        if K.backend() == 'theano' and (dropout or recurrent_dropout):
-        if K.backend() == 'theano':
+        if K.backend() == 'theano' and (dropout or recurrent_dropout):
-        if K.backend() == 'theano':
+        if K.backend() == 'theano' and (dropout or recurrent_dropout):
-
+        validation_split: fraction of images reserved for validation (strictly between 0 and 1).
-                 data_format=None):
+                 data_format=None,
-             save_to_dir=None, save_prefix='', save_format='png'):
+             save_to_dir=None, save_prefix='', save_format='png', subset=None):
-            save_format=save_format)
+            save_format=save_format,
-                 save_to_dir=None, save_prefix='', save_format='png'):
+                 save_to_dir=None, save_prefix='', save_format='png',
-
+        if subset is not None:
-def _count_valid_files_in_directory(directory, white_list_formats, follow_links):
+def _iter_valid_files(directory, white_list_formats, follow_links):
-        the directory.
+    # Yields
-            is_valid = False
+    for root, _, files in _recursive_list(directory):
-    return samples
+                    yield root, fname
-def _list_valid_filenames_in_directory(directory, white_list_formats,
+def _list_valid_filenames_in_directory(directory, white_list_formats, split,
-        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda x: x[0])
+    dirname = os.path.basename(directory)
-                filenames.append(os.path.relpath(absolute_path, basedir))
+    for root, fname in valid_files:
-                 follow_links=False, interpolation='nearest'):
+                 data_format=None,
-                                   follow_links=follow_links)
+                                   follow_links=follow_links,
-                                            (dirpath, white_list_formats,
+                                            (dirpath, white_list_formats, split,
-        assert dir_iterator.filenames == sorted(filenames)
+        assert set(dir_iterator.filenames) == set(filenames)
-        session = tf.get_default_session()
+
-            self.executor_fn = lambda: multiprocessing.Pool(workers)
+            self.executor_fn = lambda seqs: multiprocessing.Pool(workers,
-            self.executor_fn = lambda: ThreadPool(workers)
+            # We do not need the init since it's threads.
-            with closing(self.executor_fn()) as executor:
+            with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:
-
+import multiprocessing as mp
-        raise ValueError('device_type should be either "CPU" or "GPU".')
+        raise ValueError('`device_type` should be either "CPU" or "GPU".')
-        """Add losses to the layer.
+        """Adds losses to the layer.
-        """Add updates to the layer.
+        """Adds updates to the layer.
-        """Count the total number of scalars composing the weights.
+        """Counts the total number of scalars composing the weights.
-        """Retrieve the model's updates.
+        """Retrieves the model's updates.
-        """Retrieve the model's losses.
+        """Retrieves the model's losses.
-        """Call the model on new inputs.
+        """Calls the model on new inputs.
-            """Deserialize a layer, then call it on appropriate inputs.
+            """Deserializes a layer, then call it on appropriate inputs.
-        """Save the model to a single HDF5 file.
+        """Saves the model to a single HDF5 file.
-    """Check if conversion on kernel matrices is required during weight loading.
+    """Checks if conversion on kernel matrices is required during weight loading.
-                                                           use_multiprocessing=use_multiprocessing)
+                            val_enqueuer = OrderedEnqueuer(
-                                                             wait_time=wait_time)
+                            val_enqueuer = GeneratorEnqueuer(
-            raise ValueError('x (images tensor) and y (labels) '
+            raise ValueError('`x` (images tensor) and `y` (labels) '
-num_words = min(MAX_NUM_WORDS, len(word_index))
+num_words = min(MAX_NUM_WORDS, len(word_index) + 1)
-                If unspecified, `workers` will default to False.
+                If unspecified, `use_multiprocessing` will default to False.
-                epoch epochs is reached.
+                epoch of index `epochs` is reached.
-    if layer.__class__.__name__ == 'LSTM' and len(weights) == 3:
+    weights = _convert_rnn_weights(layer, weights)
-            weights[2] = bias[:units * 4] + bias[units * 4:]
+        bias_shape = weights[2].shape
-            self.bias = self.add_weight(shape=(self.units * 3,),
+            if not self.reset_after:
-            self.bias_h = self.bias[self.units * 2:]
+            # bias for inputs
-            self.bias_h = None
+            self.input_bias_z = None
-                x_h = K.bias_add(x_h, self.bias_h)
+                x_z = K.bias_add(x_z, self.input_bias_z)
-                                             self.recurrent_kernel_h))
+            recurrent_z = K.dot(h_tm1_z, self.recurrent_kernel_z)
-                matrix_x = K.bias_add(matrix_x, self.bias)
+                # biases: bias_z_i, bias_r_i, bias_h_i
-            x_r = matrix_x[:, self.units: 2 * self.units]
+            if self.reset_after:
-                                self.recurrent_kernel[:, 2 * self.units:])
+            if self.reset_after:
-                  'implementation': self.implementation}
+                  'implementation': self.implementation,
-                       implementation=implementation)
+                       implementation=implementation,
-                  'implementation': self.implementation}
+                  'implementation': self.implementation,
-])
+], ids=['GRU', 'LSTM', 'ConvLSTM2D'])
-    model = Sequential([layer])
+    # A model is needed to initialize weights.
-])
+], ids=['Conv2D', 'Conv2DTranspose'])
-                 'keras.layers.CuDNNLSTM': keras.layers.CuDNNLSTM}):
+                    {'keras.layers.CuDNNGRU': keras.layers.CuDNNGRU,
-                 'keras.layers.CuDNNLSTM': keras.layers.CuDNNLSTM}):
+                    {'keras.layers.CuDNNGRU': keras.layers.CuDNNGRU,
-def test_load_weights_into_noncudnn_lstm():
+def test_load_weights_between_noncudnn_rnn(rnn_type, to_cudnn, bidirectional, implementation):
-    cudnn_rnn_layer = keras.layers.CuDNNLSTM(units, input_shape=input_shape)
+    rnn_layer_kwargs = {
-    cudnn_model = keras.models.Sequential([cudnn_rnn_layer])
+    def convert_weights(source_layer, target_layer):
-    rnn_layer.set_weights(weights)
+    input_layer = keras.layers.InputLayer(input_shape)
-    assert_allclose(out, cudnn_out, atol=1e-4)
+    layer = rnn_layer_class(units, **rnn_layer_kwargs)
-    cudnn_rnn_layer = keras.layers.Bidirectional(cudnn_rnn_layer, input_shape=input_shape)
+    cudnn_layer = cudnn_rnn_layer_class(units)
-    cudnn_model = keras.models.Sequential([cudnn_rnn_layer])
+    model = keras.models.Sequential([input_layer, layer])
-    rnn_layer.set_weights(weights)
+    if to_cudnn:
-    assert_allclose(out, cudnn_out, atol=1e-4)
+    assert_allclose(model.predict(inputs), cudnn_model.predict(inputs), atol=1e-4)
-                           'because they are larger than %d bytes: %s'
+        raise RuntimeError('The following attributes cannot be saved to HDF5 '
-    deals with an inherent problem of HDF5 file which is not able to store
+    """Loads attributes of the specified name from the HDF5 group.
-            data.extend([n.decode('utf8') for n in group.attrs['%s%d' % (name, chunk_id)]])
+            data.extend([n.decode('utf8')
-    _save_attributes_to_hdf5_group(f, 'layer_names', [layer.name.encode('utf8') for layer in layers])
+    _save_attributes_to_hdf5_group(
-    f.attrs['layer_names'] = [layer.name.encode('utf8') for layer in layers]
+    _save_attributes_to_hdf5_group(f, 'layer_names', [layer.name.encode('utf8') for layer in layers])
-        g.attrs['weight_names'] = weight_names
+        _save_attributes_to_hdf5_group(g, 'weight_names', weight_names)
-    layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]
+    layer_names = _load_attributes_from_hdf5_group(f, 'layer_names')
-        weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]
+        weight_names = _load_attributes_from_hdf5_group(g, 'weight_names')
-        weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]
+        weight_names = _load_attributes_from_hdf5_group(g, 'weight_names')
-    layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]
+    layer_names = _load_attributes_from_hdf5_group(f, 'layer_names')
-        weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]
+        weight_names = _load_attributes_from_hdf5_group(g, 'weight_names')
-from numpy.testing import assert_allclose, assert_raises
+from numpy.testing import assert_allclose
-                or a generator of strings (for memory-efficiency)
+                a generator of strings (for memory-efficiency),
-                                                                     self.split)
+            if self.char_level or isinstance(text, list):
-        self.index_docs = {}
+        self.document_count += len(sequences)
-        """Transforms each text in texts in a sequence of integers.
+        """Transforms each text in `texts` in a sequence of integers.
-                                                                     self.split)
+            if self.char_level or isinstance(text, list):
-                                  stateful_metrics=self.stateful_metric_names)
+                progbar = Progbar(target=steps)
-                                  stateful_metrics=self.stateful_metric_names)
+                progbar = Progbar(target=num_samples)
-    """Long-Short Term Memory layer - Hochreiter 1997.
+    """Long Short-Term Memory layer - Hochreiter 1997.
-so the probelm becomes a 10 two-classification problems
+so the problem becomes a 10 two-classification problem.
-            of values are present but the shape does not match.
+            reshape: Reshape weights to fit the layer when the correct number
-__version__ = '2.1.3'
+__version__ = '2.1.4'
-      version='2.1.3',
+      version='2.1.4',
-      download_url='https://github.com/keras-team/keras/tarball/2.1.3',
+      download_url='https://github.com/keras-team/keras/tarball/2.1.4',
-    correct_size = 2
+
-        return 0
+        return K.sum(x)
-    net_a_input = Input([2])
+    net_a_input = Input((2,))
-    net_a = Dense(correct_size, activity_regularizer=reg)(net_a)
+    net_a = Dense(2, kernel_initializer='ones',
-    net_b = Dense(10)(model_a(net_b_input))
+    net_b_input = Input((2,))
-        order=0,
+        order=1,
-        classes = self.model.predict_classes(x, **kwargs)
+
-        probs = self.model.predict_proba(x, **kwargs)
+        probs = self.model.predict(x, **kwargs)
-            value = np.full(x.shape, value)
+        if isinstance(value, (float, int)):
-                self.totals[k] += v * batch_size
+            if k in self.stateful_metrics:
-                self.totals[k] = v * batch_size
+                if k in self.totals:
-                    logs[k] = self.totals[k] / self.seen
+                    if k in self.stateful_metrics:
-    def __init__(self, count_mode='samples'):
+    def __init__(self, count_mode='samples',
-                                   verbose=self.verbose)
+                                   verbose=self.verbose,
-        self.metrics = metrics
+        self.metrics = metrics or []
-
+        self.metrics_updates = []
-                                    acc_fn = metrics_module.binary_accuracy
+                                    metric_fn = metrics_module.binary_accuracy
-                                    acc_fn = metrics_module.binary_crossentropy
+                                    metric_fn = metrics_module.binary_crossentropy
-                                    acc_fn = metrics_module.sparse_categorical_accuracy
+                                    metric_fn = metrics_module.sparse_categorical_accuracy
-                                    acc_fn = metrics_module.sparse_categorical_crossentropy
+                                    metric_fn = metrics_module.sparse_categorical_crossentropy
-                                    acc_fn = metrics_module.categorical_accuracy
+                                    metric_fn = metrics_module.categorical_accuracy
-                                    acc_fn = metrics_module.categorical_crossentropy
+                                    metric_fn = metrics_module.categorical_crossentropy
-                            weighted_metric_fn = _weighted_masked_objective(acc_fn)
+                            weighted_metric_fn = _weighted_masked_objective(metric_fn)
-                            metric_name = metric_name_prefix + metric_fn.__name__
+                            # Get metric name as string
-                        append_metric(i, metric_name, metric_result)
+
-                updates = self.updates + training_updates
+                updates = self.updates + training_updates + self.metrics_updates
-                                            updates=self.state_updates,
+                                            updates=self.state_updates + self.metrics_updates,
-        callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]
+        _callbacks = [cbks.BaseLogger(
-        callbacks = cbks.CallbackList(callbacks)
+            _callbacks.append(
-                progbar = Progbar(target=steps)
+                progbar = Progbar(target=steps,
-                progbar = Progbar(target=num_samples)
+                progbar = Progbar(target=num_samples,
-                        outs[i] += batch_out
+                        if i in stateful_metric_indices:
-                outs[i] /= steps
+                if i not in stateful_metric_indices:
-                        outs[i] += batch_out * len(batch_ids)
+                        if i in stateful_metric_indices:
-                outs[i] /= num_samples
+                if i not in stateful_metric_indices:
-        out_labels = self._get_deduped_metrics_names()
+        out_labels = self.metrics_names
-        out_labels = self._get_deduped_metrics_names()
+        out_labels = self.metrics_names
-        callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]
+        _callbacks = [cbks.BaseLogger(
-        callbacks = cbks.CallbackList(callbacks)
+            _callbacks.append(
-    return metric.__name__
+    return serialize_keras_object(metric)
-    return deserialize_keras_object(name,
+def deserialize(config, custom_objects=None):
-        return deserialize(identifier)
+    if isinstance(identifier, dict):
-        self.width = width
+    def __init__(self, target, width=30, verbose=1, interval=0.05,
-        self.seen_so_far = 0
+        self.width = width
-                The progress bar will display averages for these values.
+                If `name` is in `stateful_metrics`,
-                self.unique_values.append(k)
+            if k not in self.stateful_metrics:
-        self.seen_so_far = current
+                self._values[k] = v
-        info = ' - %.0fs' % (now - self.start)
+        info = ' - %.0fs' % (now - self._start)
-            if (now - self.last_update < self.interval and
+            if (now - self._last_update < self.interval and
-            prev_total_width = self.total_width
+            prev_total_width = self._total_width
-            self.total_width = len(bar)
+            self._total_width = len(bar)
-                time_per_unit = (now - self.start) / current
+                time_per_unit = (now - self._start) / current
-            for k in self.unique_values:
+            for k in self._values:
-                if isinstance(self.sum_values[k], list):
+                if isinstance(self._values[k], list):
-                        self.sum_values[k][0] / max(1, self.sum_values[k][1]))
+                        self._values[k][0] / max(1, self._values[k][1]))
-                    info += ' %s' % self.sum_values[k]
+                    info += ' %s' % self._values[k]
-                info += (' ' * (prev_total_width - self.total_width))
+            self._total_width += len(info)
-                for k in self.unique_values:
+                for k in self._values:
-                        self.sum_values[k][0] / max(1, self.sum_values[k][1]))
+                        self._values[k][0] / max(1, self._values[k][1]))
-        self.last_update = now
+        self._last_update = now
-        self.update(self.seen_so_far + n, values)
+        self.update(self._seen_so_far + n, values)
-                    reason="keras cntk backend does not support top_k yet")
+                    reason='CNTK backend does not support top_k yet')
-                    reason="keras cntk backend does not support top_k yet")
+                    reason='CNTK backend does not support top_k yet')
-        student_w[(kh - 1) / 2, (kw - 1) / 2, i, i] = 1.
+        student_w[(kh - 1) // 2, (kw - 1) // 2, i, i] = 1.
-    model.add(Activation('relu'))
+        model.add(Activation('relu'))
-index = open('templates/index.md').read()
+def read_file(path):
-f.close()
+with open('sources/index.md', 'w') as f:
-        template = open(path).read()
+        template = read_file(path)
-    open(path, 'w').write(mkdown)
+    with open(path, 'w') as f:
-tar = tarfile.open(path)
+
-test_stories = get_stories(tar.extractfile(challenge.format('test')))
+with tarfile.open(path) as tar:
-tar = tarfile.open(path)
+
-test = get_stories(tar.extractfile(challenge.format('test')))
+with tarfile.open(path) as tar:
-lines = open(data_path, 'r', encoding='utf-8').read().split('\n')
+with open(data_path, 'r', encoding='utf-8') as f:
-lines = open(data_path, 'r', encoding='utf-8').read().split('\n')
+with open(data_path, 'r', encoding='utf-8') as f:
-text = io.open(path, encoding='utf-8').read().lower()
+with io.open(path, encoding='utf-8') as f:
-                open('acgan-history.pkl', 'wb'))
+    with open('acgan-history.pkl', 'wb') as f:
-f.close()
+with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:
-                f.close()
+                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}
-        CLASS_INDEX = json.load(open(fpath))
+        with open(fpath) as f:
-        _config = json.load(open(_config_path))
+        with open(_config_path) as f:
-    f.close()
+    with open(fpath, 'rb') as f:
-    return data
+    with open(path) as f:
-        f.close()
+        with h5py.File(filepath, 'w') as f:
-            f.close()
+        with h5py.File(filepath, mode='r') as f:
-                    f.close()
+                    with open(path) as f:
-            f = f['model_weights']
+        with h5py.File(filepath, mode='r') as f:
-            f.close()
+            # Legacy support
-        f.close()
+        with h5py.File(filepath, 'w') as f:
-                    f.close()
+                    with open(path) as f:
-                fd.write(chunk)
+        with closing(urlopen(url, data)) as response, open(filename, 'wb') as fd:
-    f.close()
+    with h5py.File(h5_path, 'w') as f:
-            learning rate as output (float).
+            (integer, indexed from 0) and current learning rate
-        lr = self.schedule(epoch)
+        lr = float(K.get_value(self.model.optimizer.lr))
-import sys
+import six
-        overwrite = get_input('Enter "y" (overwrite) or "n" (cancel).')
+    overwrite = six.moves.input('[WARNING] %s already exists - overwrite? '
-            assert not ask_to_proceed_with_overwrite('/tmp/not_exists')
+    with patch('six.moves.input') as mock:
-            send[k] = v
+            if isinstance(v, (np.ndarray, np.generic)):
-
+    @pytest.mark.parametrize('k', [KTF], ids=['TensorFlow'])
-            self.progbar.update(self.seen, self.log_values, force=True)
+            self.progbar.update(self.seen, self.log_values)
-    def update(self, current, values=None, force=False):
+    def update(self, current, values=None):
-            values: List of tuples (name, value_for_last_step).
+            values: List of tuples:
-            if (not force and (now - self.last_update) < self.interval and
+            if (now - self.last_update < self.interval and
-                    bar.update(current, values=values, force=force)
+            for current, values in enumerate(values_s):
-            callbacks += [cbks.ProgbarLogger(count_mode)]
+            callbacks.insert(1, cbks.ProgbarLogger(count_mode))
-            callbacks += [cbks.ProgbarLogger(count_mode='steps')]
+            callbacks.insert(1, cbks.ProgbarLogger(count_mode='steps'))
-        strides = (1, 1) + strides + (1,)
+        strides = (1,) + strides * 2 + (1,)
-        strides = (1, 1, 1) + strides
+        strides = (1, 1) + strides * 2
-                    continue
+        for strides in [1, 2]:
-                           input_shape=(num_samples, num_step, stack_size))
+                    layer_test(convolutional.SeparableConv1D,
-                            regularization_losses = [layer.activity_regularizer(x) for x in computed_tensors]
+                            regularization_losses = [layer.activity_regularizer(x) for x in output_tensors]
-    def fit(self, x, y, **kwargs):
+    def fit(self, x, y, sample_weight=None, **kwargs):
-    clf.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)
+    clf.fit(X_train, y_train, sample_weight=np.ones(X_train.shape[0]), batch_size=batch_size, epochs=epochs)
-        is_keras_tensor = hasattr(additional_inputs[0], '_keras_history')
+        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])
-            if hasattr(tensor, '_keras_history') != is_keras_tensor:
+            if K.is_keras_tensor(tensor) != is_keras_tensor:
-                                 ' Keras tensors and non-Keras tensors')
+                                 ' Keras tensors and non-Keras tensors'
-    inputs = Input((timesteps, dim))
+    input1 = Input((timesteps, dim))
-    output, state = outputs[0], outputs[1:]
+    state = layer(input1)[1:]
-        output = wrappers.Bidirectional(rnn(units))(output, initial_state=state[0])
+        output = wrappers.Bidirectional(rnn(units))(input2, initial_state=state[0])
-    inputs = np.random.rand(samples, timesteps, dim)
+    output = wrappers.Bidirectional(rnn(units))(input2, initial_state=state)
-    it is in fact the "stop" argument.
+    it is in fact the "stop" argument and "start" is 0.
-def multi_gpu_model(model, gpus):
+def multi_gpu_model(model, gpus=None):
-        data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]
+        if len(names) == 1 and data and isinstance(data[0], (float, int)):
-        data = [np.expand_dims(data, 1)] if data.ndim == 1 else [data]
+        data = [data]
-            raise ValueError('X (images tensor) and y (labels) '
+            raise ValueError('x (images tensor) and y (labels) '
-                             'Found: X.shape = %s, y.shape = %s' %
+                             'Found: x.shape = %s, y.shape = %s' %
-        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])
+        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda x: x[0])
-        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])
+        return sorted(os.walk(subpath, followlinks=follow_links), key=lambda x: x[0])
-          e.g. true for 50% possiblity to flip image horizontally.
+          e.g. true for 50% possibility to flip image horizontally.
-          e.g. true for 50% possiblity to flip image vertically.
+          e.g. true for 50% possibility to flip image vertically.
-    # Will udpate with gather op in next release
+    # Will update with gather op in next release
-    # Match the behavior of numpy and Theano by returning an empty seqence.
+    # Match the behavior of numpy and Theano by returning an empty sequence.
-    # Defalut, without OOV flag
+    # Default, without OOV flag
-                         '=' + str(expr_ndim))
+                         str(ndim_cond) + ', ndim(then_expression)'
-        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm'}
+        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff'}
-            y_classes = y.argmax(axis=1)
+            y_classes = np.argmax(y, axis=1)
-            self.principal_components = (vt.T / np.sqrt(s_expand ** 2 + self.zca_epsilon)).dot(vt)
+            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]
-            If you pass None, no activation is applied
+            Default: hyperbolic tangent (`tanh`).
-            If you pass None, no activation is applied
+            Default: hyperbolic tangent (`tanh`).
-            If you pass None, no activation is applied
+            Default: hyperbolic tangent (`tanh`).
-            If you pass None, no activation is applied
+            Default: hyperbolic tangent (`tanh`).
-            If you pass None, no activation is applied
+            Default: hyperbolic tangent (`tanh`).
-            If you pass None, no activation is applied
+            Default: hyperbolic tangent (`tanh`).
-        raise ValueError('Invalid data_format:', data_format)
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Invalid data_format:', data_format)
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Invalid padding:', padding)
+        raise ValueError('Invalid padding: ' + str(padding))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Invalid pooling mode:', pool_mode)
+        raise ValueError('Invalid pool_mode: ' + str(pool_mode))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Invalid pooling mode:', pool_mode)
+        raise ValueError('Invalid pool_mode: ' + str(pool_mode))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-        raise ValueError('Unknown data_format ' + str(data_format))
+        raise ValueError('Unknown data_format: ' + str(data_format))
-                         identifier)
+        raise ValueError('Could not interpret constraint identifier: ' +
-                         identifier)
+        raise ValueError('Could not interpret initializer identifier: ' +
-                         identifier)
+        raise ValueError('Could not interpret optimizer identifier: ' +
-                         identifier)
+        raise ValueError('Could not interpret regularizer identifier: ' +
-        """Fits the model on data yielded batch-by-batch by a Python generator.
+        """Trains the model on data yielded batch-by-batch by a Python generator.
-                when using multiprocessing.
+            generator: A generator or an instance of `Sequence`
-                others, if the size of the dataset is not divisible by the batch size.
+                This tuple (a single output of the generator) makes a single
-            steps_per_epoch: Total number of steps (batches of samples)
+            steps_per_epoch: Integer.
-            callbacks: List of callbacks to be called during training.
+            epochs: Integer. Number of epochs to train the model.
-                - a tuple (inputs, targets, sample_weights).
+                - tuple `(x_val, y_val)`
-                to yield from `generator` before stopping.
+                to yield from `validation_data` generator before stopping.
-                for the class.
+            class_weight: Optional dictionary mapping class indices (integers)
-                (useful for resuming a previous training run)
+            shuffle: Boolean. Whether to shuffle the training data
-            A `History` object.
+            A `History` object. Its `History.history` attribute is
-    def load_weights(self, filepath, by_name=False, skip_mismatch=False):
+    def load_weights(self, filepath, by_name=False,
-                f, self.layers, skip_mismatch=skip_mismatch)
+                f, self.layers, skip_mismatch=skip_mismatch,
-            load_weights_from_hdf5_group(f, self.layers)
+            load_weights_from_hdf5_group(
-                                   original_backend=None):
+                                   original_backend=None,
-        if K.int_shape(layer.weights[0]) != weights[0].shape:
+        if reshape and layer_weights_shape != weights[0].shape:
-def load_weights_from_hdf5_group(f, layers):
+def load_weights_from_hdf5_group(f, layers, reshape=False):
-                                                       original_backend)
+                                                       original_backend,
-def load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False):
+def load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False,
-                original_backend)
+                original_backend,
-    def load_weights(self, filepath, by_name=False, skip_mismatch=False):
+    def load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False):
-                                                          skip_mismatch=skip_mismatch)
+                                                          skip_mismatch=skip_mismatch,
-            topology.load_weights_from_hdf5_group(f, layers)
+            topology.load_weights_from_hdf5_group(f, layers, reshape=reshape)
-def test_loading_weights_by_name():
+def test_loading_weights_by_name_and_reshape():
-    model.add(Dense(2, input_shape=(3,), name='rick'))
+    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), name='rick'))
-    x = np.random.random((1, 3))
+    x = np.random.random((1, 1, 1, 1))
-    model.add(Dense(3, name='morty'))
+    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), name='rick'))
-    model.load_weights(fname, by_name=True)
+    with pytest.raises(ValueError):
-    assert_allclose(out, out2, atol=1e-05)
+    assert_allclose(np.squeeze(out), np.squeeze(out2), atol=1e-05)
-            assert_allclose(old_weights[i][j], new_weights[j], atol=1e-05)
+            # only compare layers that have weights, skipping Flatten()
-    """Does user input validation for numpy arrays.
+    """Checks if batch axes are the same for numpy arrays.
-                               check_batch_axis=True, batch_size=None):
+                               check_array_lengths=True, batch_size=None):
-        _check_array_lengths(x, y, sample_weights)
+
-            check_batch_axis=True)
+            class_weight=class_weight)
-            check_batch_axis=True)
+            sample_weight=sample_weight)
-from keras.layers import Input, Dense, Lambda, Layer
+from keras.layers import Input, Dense, Lambda
-vae.compile(optimizer='rmsprop', loss=None)
+vae.add_loss(vae_loss)
-from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer
+from keras.layers import Input, Dense, Lambda, Flatten, Reshape
-
+# Compute VAE loss
-vae.compile(optimizer='rmsprop', loss=None)
+vae.compile(optimizer='rmsprop')
-    def compile(self, optimizer, loss, metrics=None, loss_weights=None,
+    def compile(self, optimizer, loss=None, metrics=None, loss_weights=None,
-Gets to ~99.1% validation accuracy after 5 epochs
+Gets to ~99.1% test accuracy after 5 epochs
-
+import os
-data = mnist.load_mnist()
+cache_dir = os.path.expanduser(
-                steps_per_epoch=steps_per_epoch,
+                steps_per_epoch=int(np.ceil(data.train.num_examples / float(batch_size))),
-y_test = data.validation.labels
+x_test = np.reshape(data.test.images, (data.test.images.shape[0], 28, 28, 1))
-    """Tensorboard basic visualizations.
+    """TensorBoard basic visualizations.
-        from tensorflow.contrib.tensorboard.plugins import projector
+        try:
-        self.sess = K.get_session()
+        if K.backend() == 'tensorflow':
-    return random_normal_variable(shape=shape, mean=mean, scale=1.0)
+    return random_normal_variable(shape=shape, mean=mean, scale=1.0, seed=seed)
-        return losses
+
-            rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std))
+            rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std, seed=1337))
-from keras.layers import Dense
+from keras.models import Sequential, Model
-                             'Common ops without gradient : K.argmax, K.round, K.cast, K.eval.')
+            raise ValueError('An operation has `None` for gradient. '
-        momentum_cache_t_1 = self.beta_1 * (1. - 0.5 * (K.pow(K.cast_to_floatx(0.96), (t + 1) * self.schedule_decay)))
+        momentum_cache_t = self.beta_1 * (
-from keras.layers.core import Dense, Activation
+from keras import optimizers, Input
-        super(Bidirectional, self).__init__(layer, **kwargs)
+        self._trainable = True
-            assert rand.shape == (300, 100)
+            rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std))
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the pointwise convolution).
+            (i.e. the number of output filters in the pointwise convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-    # Will update workaround once CTNK supports it.
+    # Currently, CNTK can't instantiate `ones` with symbolic shapes.
-                    assert y._keras_shape == tuple(y.get_shape().as_list())
+                    assert y._keras_shape == K.int_shape(y)
-            y = KTH.tile(x, n)
+            y = K.tile(x, n)
-        def rnn_step_fn(input_dim, output_dim, k):
+        def rnn_step_fn(k):
-            rnn_fn = rnn_step_fn(input_dim, output_dim, k)
+            rnn_fn = rnn_step_fn(k)
-                assert_allclose(m_l, u_m_l, atol=1e-04)
+            if k == KTF:
-                assert_allclose(m_o, u_m_o, atol=1e-04)
+            if k == KTF:
-                assert_allclose(m_s, u_m_s, atol=1e-04)
+            assert_allclose(m_s, u_m_s, atol=1e-04)
-            W_i = K.variable(W_i_val)
+        def rnn_step_fn(k):
-                output = K.dot(x, W_i)
+                output = k.dot(x, W_i)
-            rnn_fn = rnn_step_fn(input_dim, output_dim, k)
+            rnn_fn = rnn_step_fn(k)
-    def test_ctc(self):
+    # the Theano and TensorFlow CTC code use different methods to ensure
-        assert_allclose(res[0, :], loss_log_probs_th, atol=1e-05)
+        k_labels = k.variable(labels, dtype="int32")
-            k_d = K.eval(K.dot(K.variable(x_dense), t_W))
+        for k in backends:
-            assert K.is_sparse(k_s)
+        for k in backends:
-            k_s_d = K.eval(k_s)
+            k_s_d = k.eval(k_s)
-            k_d = K.eval(K.concatenate([K.variable(x_dense_1), K.variable(x_dense_2)]))
+            k_d = k.eval(k.concatenate([k.variable(x_dense_1), k.variable(x_dense_2)]))
-            assert len(backend.eval(t)) == 0
+            for k in [KTH, KTF]:
-        pool_size: Integer, size of the max pooling windows.
+        pool_size: Integer, size of the average pooling windows.
-'''Trains a denoising autoenconder on MNIST dataset.
+'''Trains a denoising autoencoder on MNIST dataset.
-Weights obtained from the official Tensorflow repository found at
+Weights obtained from the official TensorFlow repository found at
-        raise RuntimeError('Only Tensorflow backend is currently supported, '
+        raise RuntimeError('Only TensorFlow backend is currently supported, '
-    Tensorflow does not support NCHW on CPU. Therefore we check if we are not explicitly put on
+    TensorFlow does not support NCHW on CPU. Therefore we check if we are not explicitly put on
-            # Cast the mask to floatX to avoid float64 upcasting in theano
+            # Cast the mask to floatX to avoid float64 upcasting in Theano
-                        # for theano and cntk
+                        # for Theano and CNTK
-        return shape_or_val, np.random.random(shape_or_val) - 0.5
+        return shape_or_val, np.random.random(shape_or_val).astype(np.float32) - 0.5
-batch_size = 128
+batch_size = 100
-steps_per_epoch = 469
+steps_per_epoch = 600
-                steps_per_epoch=steps_per_epoch)
+                steps_per_epoch=steps_per_epoch,
-                                      padding=((2, 2), (2, 2), (2, 2)))
+        check_single_tensor_operation('temporal_padding', (4, 3, 3),
-                                      BACKENDS, padding=(2, 2))
+                                      BACKENDS, padding=(1, 2))
-    os.environ('APP_CHANGED', 'True') == 'False',
+    os.environ.get('APP_CHANGED', 'True') == 'False',
-    reason='runs only when the relevant files have been modified')
+    os.environ.get('CORE_CHANGED', 'True') == 'False' and
-def clean_run(model_fn):
+def _get_output_shape(model_fn):
-        # is implemented in the CNTK backend
+        # Create model in a subprocess so that
-        # is successfully created by checking if the output shape has been put into the queue
+        # The error in a subprocess won't propagate
-    assert model.output_shape == (None, None, None, 512)
+def _test_application_basic(app, last_dim=1000):
-    assert model.output_shape == (None, 512)
+def _test_application_notop(app, last_dim):
-
+def _test_application_variable_input_channels(app, last_dim):
-    assert model.output_shape == (None, None, None, 512)
+    if K.image_data_format() == 'channels_first':
-    assert model.output_shape == (None, None, None, 512)
+def _test_app_pooling(app, last_dim):
-    assert model.output_shape == output_shape
+def test_resnet50():
-    assert model.output_shape == (None, 512)
+def test_vgg():
-    assert model.output_shape == (None, 1000)
+    app = applications.Xception
-    assert model.output_shape == (None, None, None, 2048)
+    app = applications.InceptionV3
-    assert output_shape == (None, None, None, 1536)
+    app = applications.InceptionResNetV2
-    assert model.output_shape == (None, None, None, 1024)
+    app = applications.MobileNet
-    fun, _ = random.choice(DENSENET_LIST)
+    app, last_dim = random.choice(DENSENET_LIST)
-    assert model.output_shape == (None, None, None, dim)
+    app, last_dim = random.choice(NASNET_LIST)
-                            'DepthwiseConv2D': applications.mobilenet.DepthwiseConv2D}):
+    with CustomObjectScope(
-                               input_shape=(num_samples, num_row, num_col, stack_size))
+                               input_shape=(num_samples,
-                                                                       batch_input_shape=(None, None, 5, None))])
+            Sequential([applications.mobilenet.DepthwiseConv2D(
-            x = AveragePooling2D(7, name='avg_pool')(x)
+            x = GlobalAveragePooling2D(name='avg_pool')(x)
-            x = MaxPooling2D(7, name='max_pool')(x)
+            x = GlobalMaxPooling2D(name='max_pool')(x)
-                return math.ceil(len(self.x) / self.batch_size)
+                return np.ceil(len(self.x) / float(self.batch_size))
-        if loss is None:
+        if y is None or loss is None:
-lines = open(data_path).read().split('\n')
+lines = open(data_path, 'r', encoding='utf-8').read().split('\n')
-    # Take one sequence (part of the training test)
+    # Take one sequence (part of the training set)
-            zero_list.append(k.eval(grad[0]))
+            zero_list.append(k.eval(zero_grad[0]))
-    except (UnicodeEncodeError, binascii.Error):
+        code = marshal.loads(raw_code)
-    code = marshal.loads(raw_code)
+        code = marshal.loads(raw_code)
-    'test_func', [activations.softmax, np.argmax, lambda x: x**2])
+    'test_func', [activations.softmax, np.argmax, lambda x: x**2, lambda x: x])
-    epochs = 50
+    epochs = 100
-            soft_zero, soft_one = 0.1, 0.9
+            # use one-sided soft real/fake labels
-        ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.2f} | {3:<5.2f}'
+        ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.4f} | {3:<5.4f}'
-        assert initial_state[0] in layer.inbound_nodes[0].input_tensors
+        assert initial_state[0] in layer._inbound_nodes[0].input_tensors
-    def call(self, inputs, states, **kwargs):
+    def call(self, inputs, states, constants=None, **kwargs):
-            inputs, states = cell.call(inputs, states, **kwargs)
+            if has_arg(cell.call, 'constants'):
-                cell.build(input_shape)
+                if has_arg(cell.call, 'constants'):
-    (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(
+    (x_train, y_train), _ = test_utils.get_test_data(
-    return (x_train, y_train), (x_test, y_test)
+    return x_train, y_train
-    (x_train, y_train), (x_test, y_test) = get_data()
+    x_train, y_train = get_data()
-                  epochs=epochs, verbose=0)
+        model.train_on_batch(x_train, y_train)
-    (x_train, y_train), (x_test, y_test) = get_data()
+    x_train, y_train = get_data()
-                  epochs=epochs, verbose=0)
+        model.train_on_batch(x_train, y_train)
-            _SEQUENCE_COUNTER = multiprocessing.Value('i', 0)
+            try:
-def resnet_block(inputs,
+def resnet_layer(inputs,
-                   kernel_regularizer=l2(1e-4))(x)
+        x = conv(x)
-        if activation:
+        if activation is not None:
-               kernel_regularizer=l2(1e-4))(x)
+        x = conv(x)
-    is halved.
+    At the beginning of each stage, the feature map size is halved (downsampled)
-    num_sub_blocks = int((depth - 2) / 6)
+    num_res_blocks = int((depth - 2) / 6)
-        for j in range(num_sub_blocks):
+    inputs = Input(shape=input_shape)
-            y = resnet_block(inputs=x,
+            if stack > 0 and res_block == 0:  # first layer but not first stack
-            y = resnet_block(inputs=y,
+            y = resnet_layer(inputs=y,
-                x = resnet_block(inputs=x,
+            if stack > 0 and res_block == 0:  # first layer but not first stack
-        num_filters = 2 * num_filters
+        num_filters *= 2
-    Features maps sizes: 16(input), 64(1st sub_block), 128(2nd), 256(3rd)
+    At the beginning of each stage, the feature map size is halved (downsampled)
-    num_sub_blocks = int((depth - 2) / 9)
+    num_res_blocks = int((depth - 2) / 9)
-    x = resnet_block(inputs=inputs,
+    x = resnet_layer(inputs=inputs,
-        for j in range(num_sub_blocks):
+    # Instantiate the stack of residual units
-            y = resnet_block(inputs=x,
+            if stage == 0:
-            y = resnet_block(inputs=y,
+            y = resnet_layer(inputs=y,
-            y = resnet_block(inputs=y,
+            y = resnet_layer(inputs=y,
-                x = resnet_block(inputs=x,
+            if res_block == 0:
-            input_shape = (input_shape[0], input_shape[1], output_dim)
+            input_shape = (input_shape[0], output_dim)
-def test_densenet(fun):
+def test_densenet():
-def test_densenet_no_top(fun, dim):
+def test_densenet_no_top():
-def test_densenet_pooling(fun, dim):
+def test_densenet_pooling():
-def test_densenet_variable_input_channels(fun, dim):
+def test_densenet_variable_input_channels():
-    model = applications.NASNetLarge(weights=None)
+    random.seed(time.time())
-    assert model.output_shape == (None, None, None, 4032)
+    random.seed(time.time())
-    assert model.output_shape == (None, 4032)
+    random.seed(time.time())
-    assert model.output_shape == (None, None, None, 4032)
+    model = fun(weights=None, include_top=False, input_shape=input_shape)
-    assert model.output_shape == (None, None, None, 4032)
+    model = fun(weights=None, include_top=False, input_shape=input_shape)
-__version__ = '2.1.2'
+__version__ = '2.1.3'
-      version='2.1.2',
+      version='2.1.3',
-      download_url='https://github.com/keras-team/keras/tarball/2.1.2',
+      download_url='https://github.com/keras-team/keras/tarball/2.1.3',
-DENSENET201_WEIGHT_PATH_NO_TOP = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'
+DENSENET121_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet121_weights_tf_dim_ordering_tf_kernels.h5'
-NASNET_LARGE_WEIGHT_PATH_NO_TOP = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large-no-top.h5'
+NASNET_MOBILE_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-mobile.h5'
-        mode: One of "caffe", "tf".
+        mode: One of "caffe", "tf" or "torch".
-        mode: One of "caffe", "tf".
+        mode: One of "caffe", "tf" or "torch".
-        cache_dir = os.path.expanduser(os.path.join('~', '.keras'))
+        cache_dir = os.path.join(os.path.expanduser('~'), '.keras')
-def create_model(stateful: bool):
+def create_model(stateful):
-        amsgrad: boolean. Weather to apply the AMSGrad variant of this
+        amsgrad: boolean. Whether to apply the AMSGrad variant of this
-            output_shape = [output_shape] * 2
+            output_shape = [output_shape, copy.copy(output_shape)]
-            return [output_shape] + state_shape * 2
+                return output_shape + state_shape + copy.copy(state_shape)
-            s_expand = np.hstack((s, np.zeros(vt.shape[0] - num_examples, dtype=flat_x.dtype)))
+            _, s, vt = linalg.svd(flat_x / np.sqrt(num_examples))
-                epochs=10,
+                epochs=30,
-imgs = imgs.reshape((4, 4, image_size, image_size))
+rows, cols = 10, 30
-plt.title('Corrupted Input: top 2 rows, Output is Denoised Input: last 2 rows')
+plt.title('Original images: top rows, '
-plt.savefig('corrupted_and_denoised.png')
+Image.fromarray(imgs).save('corrupted_and_denoised.png')
-                            # custom handling of accuracy
+                        if metric in ('accuracy', 'acc', 'crossentropy', 'ce'):
-                                acc_fn = metrics_module.binary_accuracy
+                                # case: binary accuracy/crossentropy
-                                acc_fn = metrics_module.sparse_categorical_accuracy
+                                # case: categorical accuracy/crossentropy with sparse targets
-
+                                # case: categorical accuracy/crossentropy
-                            metric_name = metric_name_prefix + 'acc'
+                            metric_name = metric_name_prefix + suffix
-        self.updatable = kwargs.get('updatable', True)
+        if not self.trainable and not self.stateful:
-        if not self.updatable:
+        if not self.trainable and not self.stateful:
-                    state_updates += layer.updates
+            if layer.stateful:
-
+@keras_test
-def test_sequential_updatable_attribute():
+def test_sequential_update_disabling():
-    model.updatable = True
+    model.trainable = True
-                    (self.target is not None and current < self.target)):
+                    self.target is not None and current < self.target):
-        bar.update(i, list(arr))
+    values_s = [None,
-            return tuple(shape)
+        output_shape = self.forward_layer.compute_output_shape(input_shape)
-            return [self.forward_layer.compute_output_shape(input_shape)] * 2
+            output_shape = [output_shape] * 2
-    def call(self, inputs, training=None, mask=None):
+        if self.return_state:
-        y_rev = self.backward_layer.call(inputs, **kwargs)
+        if initial_state is not None and has_arg(self.layer.call, 'initial_state'):
-from keras.engine.topology import _object_list_uid
+from keras.engine.topology import _object_list_uid, _to_list
-            assert outputs._uses_learning_phase
+@keras_test
-                    current < self.target):
+                    (self.target is not None and current < self.target)):
-    assert model_output_shape == (None, 1000)
+    def model_fn():
-    assert model_output_shape == (None, None, None, 1536)
+    def model_fn():
-    assert model_output_shape == (None, 1536)
+    def model_fn():
-    assert model_output_shape == (None, None, None, 1536)
+    def model_fn(input_shape):
-    assert model_output_shape == (None, None, None, 1536)
+    output_shape = clean_run(lambda: model_fn((None, None, 4)))
-    assert model_output_shape == (None, 1000)
+    def model_fn():
-    assert model_output_shape == (None, None, None, dim)
+    def model_fn():
-    assert model_output_shape == (None, None, None, dim)
+    def model_fn():
-    assert model_output_shape == (None, None, None, dim)
+    def model_fn(input_shape):
-    x = tf.nn.relu(x)
+        x = tf.nn.leaky_relu(x, alpha)
-        x -= alpha * negative_part
+        x = tf.minimum(x, max_value)
-            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + self.zca_epsilon))), u.T)
+            num_examples = flat_x.shape[0]
-                    'pandas'],
+                    'pandas',
-@pytest.mark.skipif(sys.version_info > (3, 0), reason='pydot-ng currently supports python 3.4')
+    def __repr__(self):
-                    'An initial_state was passed that is not compatible with '
+                    'An `initial_state` was passed that is not compatible with '
-                    'However `cell.state_size` is '
+                    'however `cell.state_size` is '
-    def summary(self, line_length=None, positions=None, print_fn=print):
+    def summary(self, line_length=None, positions=None, print_fn=None):
-# Reference paper:
+# Reference paper
-- [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993) (CVPR 2017 Best Paper Award)
+- [Densely Connected Convolutional Networks]
-# Reference implementation:
+# Reference implementation
-- [TensorNets](https://github.com/taehoonlee/tensornets/blob/master/tensornets/densenets.py)
+- [Torch DenseNets]
-    x = Conv2D(int(x._keras_shape[bn_axis] * reduction), 1, use_bias=False,
+    x = Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1, use_bias=False,
-                    if self.queue is not None and self.queue.qsize() < self.max_queue_size:
+                    if (self.queue is not None and
-        x, value, momentum, zero_debias=False)
+        x, value, momentum, zero_debias=True)
-            if not [spec.shape[-1] for spec in self.state_spec] == state_size:
+            if [spec.shape[-1] for spec in self.state_spec] != state_size:
-    """Count files with extension in `white_list_formats` contained in a directory.
+    """Count files with extension in `white_list_formats` contained in directory.
-        directory: absolute path to the directory containing files to be counted
+        directory: absolute path to the directory
-        """Function to submit request to the executor and queue the `Future` objects."""
+        """Submits request to the executor and queue the `Future` objects."""
-                            # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:
+                        if (self.queue is not None and
-                            # => Serialize calls to infinite iterator/generator's next() function
+                            # => Serialize calls to
-                                    BASE_WEIGHT_URL + weights_filename,
+            fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'
-                                    BASE_WEIGHT_URL + weights_filename,
+            fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'
-# References:
+# References
-Based on the following implementations:
+# Based on the following implementations
-    And the shortcut should have strides=(2,2) as well
+    Note that from stage 3,
-        elif len(shape2) == 0:
+        elif not shape2:
-                or (inputs, targets, sample_weights)
+        # Yields
-        _SHARED_SEQUENCES[self.uid] = self.sequence  # For new processes that may spawn
+        # For new processes that may spawn
-            A generator
+        # Yields
-        input_tensor:Ooptional Keras tensor (i.e. output of
+        input_tensor: Optional Keras tensor (i.e. output of
-    '''Adds a Normal cell for NASNet-A (Fig. 4 in the paper)
+    '''Adds a Normal cell for NASNet-A (Fig. 4 in the paper).
-    '''Adds a Reduction cell for NASNet-A (Fig. 4 in the paper)
+    '''Adds a Reduction cell for NASNet-A (Fig. 4 in the paper).
-        xs = [[w if (skip_top <= w < num_words) else oov_char for w in x] for x in xs]
+        xs = [[w if skip_top <= w < num_words else oov_char for w in x] for x in xs]
-        xs = [[w for w in x if (skip_top <= w < num_words)] for x in xs]
+        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]
-                _target_tensors = []
+                tmp_target_tensors = []
-                target_tensors = _target_tensors
+                    tmp_target_tensors.append(target_tensors.get(name, None))
-    for root, _, files in _recursive_list(directory):
+    for _, _, files in _recursive_list(directory):
-                # if the model has multiple nodes or if the nodes have multiple inbound_layers
+                # if the model has multiple nodes
-    """Preprocesses a tensor encoding a batch of images.
+    """Preprocesses a tensor or Numpy array encoding a batch of images.
-        data_format: data format of the image tensor.
+        x: Input Numpy or symbolic tensor, 3D or 4D.
-        Preprocessed tensor.
+        Preprocessed tensor or Numpy array.
-        top: integer, how many top-guesses to return.
+        top: Integer, how many top-guesses to return.
-        ValueError: in case of invalid shape of the `pred` array
+        ValueError: In case of invalid shape of the `pred` array
-    """Internal utility to compute/validate an ImageNet model's input shape.
+    """Internal utility to compute/validate a model's input shape.
-        input_shape: either None (will return the default network input shape),
+        input_shape: Either None (will return the default network input shape),
-        require_flatten: whether the model is expected to
+        default_size: Default input width/height for the model.
-        weights: one of `None` (random initialization)
+        weights: One of `None` (random initialization)
-        ValueError: in case of invalid argument values.
+        ValueError: In case of invalid argument values.
-'''NASNet-A models for Keras
+'''NASNet-A models for Keras.
-        input_shape: optional shape tuple, only to be specified
+        input_shape: Optional shape tuple, only to be specified
-        penultimate_filters: number of filters in the penultimate layer.
+        penultimate_filters: Number of filters in the penultimate layer.
-        num_blocks: number of repeated blocks of the NASNet model.
+        num_blocks: Number of repeated blocks of the NASNet model.
-        stem_block_filters: number of filters in the initial stem block
+        stem_block_filters: Number of filters in the initial stem block
-        filter_multiplier: controls the width of the network.
+        filter_multiplier: Controls the width of the network.
-        include_top: whether to include the fully-connected
+        include_top: Whether to include the fully-connected
-        input_tensor: optional Keras tensor (i.e. output of
+        input_tensor: Optional Keras tensor (i.e. output of
-        classes: optional number of classes to classify images
+        classes: Optional number of classes to classify images
-        default_size: specifies the default image size of the model
+        default_size: Specifies the default image size of the model
-        ValueError: in case of invalid argument for `weights`,
+        ValueError: In case of invalid argument for `weights`,
-        input_shape: optional shape tuple, only to be specified
+        input_shape: Optional shape tuple, only to be specified
-        include_top: whether to include the fully-connected
+        include_top: Whether to include the fully-connected
-        input_tensor: optional Keras tensor (i.e. output of
+        input_tensor:Ooptional Keras tensor (i.e. output of
-        classes: optional number of classes to classify images
+        classes: Optional number of classes to classify images
-        input_shape: optional shape tuple, only to be specified
+        input_shape: Optional shape tuple, only to be specified
-        include_top: whether to include the fully-connected
+        include_top: Whether to include the fully-connected
-        input_tensor: optional Keras tensor (i.e. output of
+        input_tensor: Optional Keras tensor (i.e. output of
-        classes: optional number of classes to classify images
+        classes: Optional number of classes to classify images
-        ValueError: in case of invalid argument for `weights`,
+        ValueError: In case of invalid argument for `weights`,
-def _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1),
+def _separable_conv_block(ip, filters,
-    '''Adds 2 blocks of [relu-separable conv-batchnorm]
+    '''Adds 2 blocks of [relu-separable conv-batchnorm].
-        block_id: string block_id
+    # Arguments
-        a Keras tensor
+    # Returns
-    or situations where the output number of filters needs to be changed
+    '''Adjusts the input `previous path` to match the shape of the `input`.
-        block_id: string block_id
+    # Arguments
-        an adjusted Keras tensor
+    # Returns
-        block_id: string block_id
+    # Arguments
-        a Keras tensor
+    # Returns
-        block_id: string block_id
+    # Arguments
-        a Keras tensor
+    # Returns
-        paths.append(get_file(file, origin=base + file, cache_subdir=dirname))
+    for fname in files:
-        xs = [[w for w in x if (skip_top <= w < num_words)] for x in xs]
+        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]
-                             'on a list of of at least 2 inputs')
+                             'on a list of at least 2 inputs')
-def print_summary(model, line_length=None, positions=None, print_fn=print):
+def print_summary(model, line_length=None, positions=None, print_fn=None):
-    a node is added to `layer.inbound_nodes`.
+    a node is added to `layer._inbound_nodes`.
-    a node is added to `layer.outbound_nodes`.
+    a node is added to `layer._outbound_nodes`.
-    `input_tensors[i] == inbound_layers[i].inbound_nodes[node_indices[i]].output_tensors[tensor_indices[i]]`
+    `input_tensors[i] == inbound_layers[i]._inbound_nodes[node_indices[i]].output_tensors[tensor_indices[i]]`
-        B.inbound_nodes
+        A._outbound_nodes
-        outbound_layer.inbound_nodes.append(self)
+                layer._outbound_nodes.append(self)
-        self.outbound_nodes = []
+        self._inbound_nodes = []
-        This function is used internally with `self.container_nodes`.
+        This function is used internally with `self._container_nodes`.
-                                                len(self.inbound_nodes) - 1,
+                                                len(self._inbound_nodes) - 1,
-        if not self.inbound_nodes:
+        if not self._inbound_nodes:
-        if not len(self.inbound_nodes) > node_index:
+        if not len(self._inbound_nodes) > node_index:
-        values = getattr(self.inbound_nodes[node_index], attr)
+                             str(len(self._inbound_nodes)) + ' inbound nodes.')
-        if len(self.inbound_nodes) > 1:
+        if len(self._inbound_nodes) > 1:
-        elif not self.inbound_nodes:
+        elif not self._inbound_nodes:
-        if not self.inbound_nodes:
+        if not self._inbound_nodes:
-        if len(self.inbound_nodes) > 1:
+        if len(self._inbound_nodes) > 1:
-        if len(self.inbound_nodes) != 1:
+        if len(self._inbound_nodes) != 1:
-        if len(self.inbound_nodes) != 1:
+        if len(self._inbound_nodes) != 1:
-        if not self.inbound_nodes:
+        if not self._inbound_nodes:
-        all_input_shapes = set([str(node.input_shapes) for node in self.inbound_nodes])
+        all_input_shapes = set([str(node.input_shapes) for node in self._inbound_nodes])
-            input_shapes = self.inbound_nodes[0].input_shapes
+            input_shapes = self._inbound_nodes[0].input_shapes
-        if not self.inbound_nodes:
+        if not self._inbound_nodes:
-        all_output_shapes = set([str(node.output_shapes) for node in self.inbound_nodes])
+        all_output_shapes = set([str(node.output_shapes) for node in self._inbound_nodes])
-            output_shapes = self.inbound_nodes[0].output_shapes
+            output_shapes = self._inbound_nodes[0].output_shapes
-    outputs = input_layer.inbound_nodes[0].output_tensors
+    outputs = input_layer._inbound_nodes[0].output_tensors
-            if len(layer.inbound_nodes) > 1 or (layer.inbound_nodes and layer.inbound_nodes[0].inbound_layers):
+            if len(layer._inbound_nodes) > 1 or (layer._inbound_nodes and layer._inbound_nodes[0].inbound_layers):
-            node = layer.inbound_nodes[node_index]
+            node = layer._inbound_nodes[node_index]
-            node = layer.inbound_nodes[node_index]
+            node = layer._inbound_nodes[node_index]
-        self.internal_output_shapes = [x._keras_shape for x in self.outputs]
+        self._internal_input_shapes = [x._keras_shape for x in self.inputs]
-            node = layer.inbound_nodes[node_index]
+            node = layer._inbound_nodes[node_index]
-                inbound_node = inbound_layer.inbound_nodes[node_index]
+                inbound_node = inbound_layer._inbound_nodes[node_index]
-        self.nodes_by_depth = nodes_by_depth
+        # Set self._container_nodes and self._nodes_by_depth.
-        self.inbound_nodes = []  # Will be appended to below, and by future calls to __call__
+        self._outbound_nodes = []  # Will be appended to by future calls to __call__
-                for node_index, node in enumerate(layer.inbound_nodes):
+                for node_index, node in enumerate(layer._inbound_nodes):
-                    if node_key in self.container_nodes:
+                    if node_key in self._container_nodes:
-                for node_index, node in enumerate(layer.inbound_nodes):
+                for node_index, node in enumerate(layer._inbound_nodes):
-                    if node_key in self.container_nodes:
+                    if node_key in self._container_nodes:
-            depth_keys = list(self.nodes_by_depth.keys())
+            depth_keys = list(self._nodes_by_depth.keys())
-                    nodes = self.nodes_by_depth[depth]
+                    nodes = self._nodes_by_depth[depth]
-                        node_index = layer.inbound_nodes.index(node)
+                        node_index = layer._inbound_nodes.index(node)
-        depth_keys = list(self.nodes_by_depth.keys())
+        depth_keys = list(self._nodes_by_depth.keys())
-            nodes = self.nodes_by_depth[depth]
+            nodes = self._nodes_by_depth[depth]
-            for original_node_index, node in enumerate(layer.inbound_nodes):
+            for original_node_index, node in enumerate(layer._inbound_nodes):
-                if node_key in self.container_nodes:
+                if node_key in self._container_nodes:
-            for original_node_index, node in enumerate(layer.inbound_nodes):
+            for original_node_index, node in enumerate(layer._inbound_nodes):
-                if node_key in self.container_nodes:
+                if node_key in self._container_nodes:
-            if node_key not in self.container_nodes:
+            if node_key not in self._container_nodes:
-            if node_key not in self.container_nodes:
+            if node_key not in self._container_nodes:
-                if len(inbound_layer.inbound_nodes) <= inbound_node_index:
+                if len(inbound_layer._inbound_nodes) <= inbound_node_index:
-                inbound_node = inbound_layer.inbound_nodes[inbound_node_index]
+                inbound_node = inbound_layer._inbound_nodes[inbound_node_index]
-            layer_output_tensors = layer.inbound_nodes[node_index].output_tensors
+            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors
-            layer_output_tensors = layer.inbound_nodes[node_index].output_tensors
+            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors
-    if not layer.inbound_nodes:
+    if not layer._inbound_nodes:
-        node = layer.inbound_nodes[node_index]
+        node = layer._inbound_nodes[node_index]
-            node = inbound_layer.inbound_nodes[node_index]
+            node = inbound_layer._inbound_nodes[node_index]
-                shape = self.internal_output_shapes[i]
+                shape = self._internal_output_shapes[i]
-                            output_shape = self.internal_output_shapes[i]
+                            output_shape = self._internal_output_shapes[i]
-        self.outbound_nodes = []
+        self._inbound_nodes = []
-                inbound_node = layer.inbound_nodes[node_index]
+                inbound_node = layer._inbound_nodes[node_index]
-        return merge_layer.inbound_nodes[0].output_tensors[0]
+        return merge_layer._inbound_nodes[0].output_tensors[0]
-        self.outbound_nodes = []
+        self._inbound_nodes = []
-            if len(layer.inbound_nodes[-1].output_tensors) != 1:
+            if len(layer._inbound_nodes[-1].output_tensors) != 1:
-            self.outputs = [layer.inbound_nodes[-1].output_tensors[0]]
+            self.outputs = [layer._inbound_nodes[-1].output_tensors[0]]
-            self.inbound_nodes[0].output_shapes = [self.outputs[0]._keras_shape]
+            # update self._inbound_nodes
-            self.outbound_nodes = []
+            self._inbound_nodes = []
-            self.layers[-1].outbound_nodes = []
+            self.layers[-1]._outbound_nodes = []
-            self.inbound_nodes[0].output_shapes = [self.outputs[0]._keras_shape]
+            # update self._inbound_nodes
-        self.container_nodes = self.model.container_nodes
+        self._nodes_by_depth = self.model._nodes_by_depth
-    depth_keys = list(model.nodes_by_depth.keys())
+    depth_keys = list(model._nodes_by_depth.keys())
-        nodes = model.nodes_by_depth[depth]
+        nodes = model._nodes_by_depth[depth]
-        nodes_by_depth = model.nodes_by_depth.values()
+        nodes_by_depth = model._nodes_by_depth.values()
-                for node in layer.inbound_nodes:
+                for node in layer._inbound_nodes:
-        for v in model.nodes_by_depth.values():
+        for v in model._nodes_by_depth.values():
-        for node in layer.inbound_nodes:
+        for node in layer._inbound_nodes:
-        for i, node in enumerate(layer.inbound_nodes):
+        for i, node in enumerate(layer._inbound_nodes):
-            if node_key in model.container_nodes:
+            if node_key in model._container_nodes:
-    assert len(a_layer.inbound_nodes) == 1
+    assert len(a_layer._inbound_nodes) == 1
-    node = a_layer.inbound_nodes[a_node_index]
+    node = a_layer._inbound_nodes[a_node_index]
-    assert dense.inbound_nodes[1].outbound_layer == dense
+    assert len(dense._inbound_nodes) == 2
-    assert dense.inbound_nodes[1].input_tensors == [b]
+    assert dense._inbound_nodes[0].input_tensors == [a]
-    assert dense.inbound_nodes[1].get_config()['inbound_layers'] == ['input_b']
+    assert dense._inbound_nodes[0].get_config()['inbound_layers'] == ['input_a']
-    assert len(merge_layer.outbound_nodes) == 0
+    assert len(merge_layer._inbound_nodes) == 1
-    assert len(merge_layer.inbound_nodes[0].inbound_layers) == 2
+    assert len(merge_layer._inbound_nodes[0].input_tensors) == 2
-    assert initial_state[0] in layer.inbound_nodes[0].input_tensors
+    assert initial_state[0] in layer._inbound_nodes[0].input_tensors
-    assert initial_state[0] in layer.inbound_nodes[0].input_tensors
+    assert initial_state[0] in layer._inbound_nodes[0].input_tensors
-        momentum: Momentum for the moving average.
+        momentum: Momentum for the moving mean and the moving variance.
-            raise ValueError('`Subtract` layer should be called '
+            raise ValueError('A `Subtract` layer should be called '
-                             'on inputs of the same shape')
+        self._reshape_required = False
-            raise ValueError('`Concatenate` layer should be called '
+            raise ValueError('A `Concatenate` layer should be called '
-            raise ValueError('`Concatenate` layer requires '
+            raise ValueError('A `Concatenate` layer requires '
-                             'on a list of inputs.')
+    def _merge_function(self, inputs):
-    def call(self, inputs):
+    def _merge_function(self, inputs):
-        subtract_layer([i1, i4])
+    with pytest.raises(ValueError):
-    assert model.output_shape == (None, 1000)
+    def target(queue):
-    assert model.output_shape == (None, None, None, dim)
+    def target(queue):
-    assert model.output_shape == (None, None, None, dim)
+    def target(queue):
-    assert model.output_shape == (None, None, None, dim)
+    def target(queue, input_shape):
-    assert model.output_shape == (None, None, None, dim)
+    queue = Queue()
-      description='Deep Learning for Python',
+      description='Deep Learning for humans',
-        if not isinstance(input_shape, list):
+        if not isinstance(input_shape, list) or len(input_shape) < 2:
-                             'on a list of inputs')
+                             'on a list of of at least 2 inputs')
-                               name='keras_learning_phase')
+        phase = tf.placeholder_with_default(False,
-        if inputs[0]._keras_shape != inputs[1]._keras_shape:
+        if K.int_shape(inputs[0]) != K.int_shape(inputs[1]):
-                cbk.validation_data = val_data
+        val_enqueuer = None
-                                validation_data,
+                                validation_generator,
-                                use_multiprocessing=use_multiprocessing)
+                                workers=0)
-                enqueuer.stop()
+            try:
-            shape = tuple(x if x != -1 else None for x in shape)
+        shape = tuple(x if x != -1 else None for x in shape)
-# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.03     | 93.63     | 165(180)
+# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)
-        x = BatchNormalization()(x)
+                   kernel_regularizer=l2(1e-4))(x)
-    x = BatchNormalization()(inputs)
+    if batch_normalization:
-                                 activation=None)
+                                 activation=None,
-               kernel_regularizer=l2(1e-4))(inputs)
+    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths
-                           kernel_regularizer=l2(1e-4))(x)
+                x = resnet_block(inputs=x,
-                def bias_initializer(shape, *args, **kwargs):
+                def bias_initializer(_, *args, **kwargs):
-                    when using multiprocessing.
+                object in order to avoid duplicate data
-                    when using multiprocessing.
+                or an instance of Sequence (keras.utils.Sequence)
-    """List paths of files in `subdir` relative from `directory` whose extensions are in `white_list_formats`.
+    """List paths of files in `subdir` with extensions in `white_list_formats`.
-"""Advanced activation layers.
+"""Layers that act as activation functions.
-"""Noise regularization layers.
+"""Layers that operate regularization via the addition of noise.
-from ..engine import InputSpec
+    def compute_output_shape(self, input_shape):
-                kept_idx = K.greater_equal(K.random_uniform(noise_shape, seed=seed), rate)
+                kept_idx = K.greater_equal(K.random_uniform(noise_shape,
-    hashing function, unicity of word to index mapping non-guaranteed.
+    hashing function; unicity of word to index mapping non-guaranteed.
-# noinspection SpellCheckingInspection
+
-from keras.utils import OrderedEnqueuer
+from ..utils.data_utils import Sequence
-                    when using multiprocessing.
+                object in order to avoid duplicate data
-    """Scaled Exponential Linear Unit. (Klambauer et al., 2017)
+    """Scaled Exponential Linear Unit. (Klambauer et al., 2017).
-            warnings.warn((
+            warnings.warn(
-            ).format(identifier=identifier.__class__.__name__))
+                'layer in a model.'.format(
-        ```
+
-        ```
+
-        ```
+
-from six.moves import zip
+"""Topology-related part of the Keras engine.
-import six
+"""Built-in weight initializers.
-        standard format.
+        """Standardize `__call__` to a single list of tensor inputs.
-            used for the linear transformation of the inputs.
+            used for the linear transformation of the inputs
-            used for the linear transformation of the recurrent state.
+            used for the linear transformation of the recurrent state
-            used for the linear transformation of the inputs.
+            used for the linear transformation of the inputs
-            used for the linear transformation of the recurrent state.
+            used for the linear transformation of the recurrent state
-            used for the linear transformation of the inputs.
+            used for the linear transformation of the inputs
-            used for the linear transformation of the recurrent state.
+            used for the linear transformation of the recurrent state
-            used for the linear transformation of the inputs.
+            used for the linear transformation of the inputs
-            used for the linear transformation of the recurrent state.
+            used for the linear transformation of the recurrent state
-            used for the linear transformation of the inputs.
+            used for the linear transformation of the inputs
-            used for the linear transformation of the recurrent state.
+            used for the linear transformation of the recurrent state
-
+            data = [data[x].values if data[x].__class__.__name__ == 'DataFrame' else data[x] for x in names]
-
+            raise ValueError(
-                        str(arrays)[:200])
+        data = [x.values if x.__class__.__name__ == 'DataFrame' else x for x in data]
-    arrays = [np.expand_dims(array, 1) if array.ndim == 1 else array for array in arrays]
+        data = data.values if data.__class__.__name__ == 'DataFrame' else data
-                for dim, ref_dim in zip(array_shape[start:], shapes[i][start:]):
+                data_shape = data[i].shape
-    return arrays
+                            ': expected ' + names[i] + ' to have shape ' +
-    tokenizer =  Tokenizer()
+    tokenizer = Tokenizer()
-    tokenizer =  Tokenizer(oov_token='<unk>')
+    tokenizer = Tokenizer(oov_token='<unk>')
-                output = K.bias_add(output, self.bias, data_format=self.data_format)
+            output = K.bias_add(output, self.bias, data_format=self.data_format)
-from __future__ import print_function
+from __future__ import division
-from __future__ import print_function
+from __future__ import division
-from __future__ import print_function
+from __future__ import division
-from __future__ import print_function
+from __future__ import division
-from __future__ import print_function
+from __future__ import division
-from __future__ import print_function
+from __future__ import division
-from __future__ import print_function
+from __future__ import division
-from __future__ import print_function
+from __future__ import division
-May benefit from a fast Cython rewrite.
+from __future__ import print_function
-                             'the time dimension by passing a '
+                             'the batch size by passing a '
-for iteration in range(1, 60):
+
-              epochs=1)
+    print('----- Generating text after Epoch: %d' % epoch)
-        print()
+
-def test_sparse_input_target_evaluate():
+def test_sparse_inputs_targets():
-
+    model.predict(test_inputs, batch_size=2)
-    model.compile('rmsprop', 'mse')
+    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.5)
-            arrays.append(data[name])
+        try:
-            if data and hasattr(data[0], 'shape'):
+        arrays = [x.values if x.__class__.__name__ == 'DataFrame' else x for x in data]
-                                 ' arrays: ' + str(data)[:200] +
+                                 'the following list of ' + str(len(arrays)) +
-                    data = [np.asarray(data)]
+                    arrays = [np.asarray(arrays)]
-        arrays = data
+                        str(arrays)[:200])
-            arrays[i] = array
+    arrays = [np.expand_dims(array, 1) if array.ndim == 1 else array for array in arrays]
-                    if ref_dim != dim:
+            if shapes[i] is not None:
-                            str(array.shape))
+                            str(array_shape))
-            x[2, :, :] -= 123.68
+            x[0, :, :] -= mean[0]
-            x[:, 2, :, :] -= 123.68
+            x[:, 0, :, :] -= mean[0]
-        x[..., 2] -= 123.68
+        x[..., 0] -= mean[0]
-            x = x[:, ::-1, ...]
+    if mode == 'torch':
-        x = x[..., ::-1]
+        if data_format == 'channels_first':
-        _IMAGENET_MEAN = K.constant(-np.array([103.939, 116.779, 123.68]))
+        _IMAGENET_MEAN = K.constant(-np.array(mean))
-batch_size = 32
+batch_size = 32  # orig paper trained all networks with batch_size=128
-#           |      | %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)
+# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti
-# ResNet110 |  18  | 92.65     | 93.39     | 93.03     | 93.63     | 165(180)
+# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)
-depth = n * 6 + 2
+if version == 1:
-    model.compile(loss='mse', optimizer='sgd')
+    model.compile(loss='mse', optimizer='rmsprop')
-    model.fit(x, x, epochs=4, verbose=0)
+    model.fit(x, x, epochs=5, verbose=0)
-    model.compile(loss='mse', optimizer='sgd')
+    model.compile(loss='mse', optimizer='rmsprop')
-    model.fit(x, x, epochs=4, verbose=0)
+    model.fit(x, x, epochs=5, verbose=0)
-    model = Model(in1, out1)
+def test_sparse_placeholder_predict():
-    model.fit(test_input, test_output, epochs=1, batch_size=2, validation_split=0.2)
+    model.predict(test_inputs, batch_size=2)
-    theta = np.pi / 180 * np.random.uniform(-rg, rg)
+    theta = np.deg2rad(np.random.uniform(-rg, rg))
-        intensity: Transformation intensity.
+        intensity: Transformation intensity in degrees.
-    shear = np.random.uniform(-intensity, intensity)
+    shear = np.deg2rad(np.random.uniform(-intensity, intensity))
-        shear_range: shear intensity (shear angle in radians).
+        shear_range: shear intensity (shear angle in degrees).
-            theta = np.pi / 180 * np.random.uniform(-self.rotation_range, self.rotation_range)
+            theta = np.deg2rad(np.random.uniform(-self.rotation_range, self.rotation_range))
-            shear = np.random.uniform(-self.shear_range, self.shear_range)
+            shear = np.deg2rad(np.random.uniform(-self.shear_range, self.shear_range))
-def split_data(x, y, ratio: int = 0.8):
+def split_data(x, y, ratio=0.8):
-    phase = tf.placeholder(dtype='bool', name='keras_learning_phase')
+    phase = tf.placeholder_with_default(False,
-    return tf.reduce_max(x, axis=axis, keep_dims=keepdims)
+    return tf.reduce_max(x, axis, keepdims)
-    return tf.reduce_min(x, axis=axis, keep_dims=keepdims)
+    return tf.reduce_min(x, axis, keepdims)
-    return tf.reduce_sum(x, axis=axis, keep_dims=keepdims)
+    return tf.reduce_sum(x, axis, keepdims)
-    return tf.reduce_prod(x, axis=axis, keep_dims=keepdims)
+    return tf.reduce_prod(x, axis, keepdims)
-    m = tf.reduce_mean(x, axis=axis, keep_dims=True)
+    m = tf.reduce_mean(x, axis, True)
-                          keep_dims=keepdims)
+                          axis,
-            by 1 for each entry in `axis`. If `keep_dims` is `True`,
+            by 1 for each entry in `axis`. If `keepdims` is `True`,
-    return tf.reduce_mean(x, axis=axis, keep_dims=keepdims)
+    return tf.reduce_mean(x, axis, keepdims)
-    return tf.reduce_any(x, axis=axis, keep_dims=keepdims)
+    return tf.reduce_any(x, axis, keepdims)
-    return tf.reduce_all(x, axis=axis, keep_dims=keepdims)
+    return tf.reduce_all(x, axis, keepdims)
-    return tf.reduce_logsumexp(x, axis=axis, keep_dims=keepdims)
+    return tf.reduce_logsumexp(x, axis, keepdims)
-                              shift=None, name=None, keep_dims=False)
+                              None, None, False)
-                              shift=None, name=None, keep_dims=False)
+                              None, None, False)
-                                keep_dims=True)
+                                len(output.get_shape()) - 1,
-                               axis=len(output.get_shape()) - 1)
+                               len(output.get_shape()) - 1)
-            weights = forward_weights + backward_weights
+    if layer.__class__.__name__ == 'Bidirectional':
-    link = ('https://github.com/fchollet/'
+    link = ('https://github.com/keras-team/'
-                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'
+                            print('\nEpoch %05d: %s improved from %0.5f to %0.5f,'
-                            print('Epoch %05d: %s did not improve' %
+                            print('\nEpoch %05d: %s did not improve' %
-                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))
+                    print('\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))
-        alpha: A scalar, slope of positive section.
+        alpha: A scalar, slope of negative section.
-    """Depthwise separable 2D convolution.
+class _SeparableConv(_Conv):
-    def __init__(self, filters,
+    def __init__(self, rank,
-                 strides=(1, 1),
+                 strides=1,
-        super(SeparableConv2D, self).__init__(
+        super(_SeparableConv, self).__init__(
-            raise ValueError('Inputs to `SeparableConv2D` should have rank 4. '
+        if len(input_shape) < self.rank + 2:
-            channel_axis = 3
+        channel_axis = 1 if self.data_format == 'channels_first' else -1
-                             '`SeparableConv2D` '
+            raise ValueError('The channel dimension of the inputs '
-                                  self.filters)
+        depthwise_kernel_shape = self.kernel_size + (input_dim, self.depth_multiplier)
-        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})
+        self.input_spec = InputSpec(ndim=self.rank + 2,
-            dilation_rate=self.dilation_rate)
+        if self.rank == 1:
-        config = super(SeparableConv2D, self).get_config()
+        config = super(_SeparableConv, self).get_config()
-    def __init__(self, schedule):
+    def __init__(self, schedule, verbose=0):
-        K.set_value(self.model.optimizer.lr, lr)
+        if self.verbose > 0:
-                    if old_lr > self.min_lr + self.lr_epsilon:
+                    if old_lr > self.min_lr:
-                            print('\nEpoch %05d: reducing learning rate to %s.' % (epoch + 1, new_lr))
+                            print('\nEpoch %05d: ReduceLROnPlateau reducing learning '
-    def predict(self, x, batch_size=None, verbose=0):
+    def predict(self, x, batch_size=None, verbose=0, steps=None):
-        return self.model.predict(x, batch_size=batch_size, verbose=verbose)
+        return self.model.predict(x, batch_size=batch_size, verbose=verbose,
-    def predict_proba(self, x, batch_size=None, verbose=0):
+    def predict_proba(self, x, batch_size=None, verbose=0, steps=None):
-        preds = self.predict(x, batch_size, verbose)
+        preds = self.predict(x, batch_size, verbose, steps=steps)
-    def predict_classes(self, x, batch_size=None, verbose=0):
+    def predict_classes(self, x, batch_size=None, verbose=0, steps=None):
-        proba = self.predict(x, batch_size=batch_size, verbose=verbose)
+        proba = self.predict(x, batch_size=batch_size, verbose=verbose,
-        start = 0
+    if stop is None:
-        height_shift_range: fraction of total height.
+        width_shift_range: fraction of total width, if < 1, or pixels if >= 1.
-            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[img_row_axis]
+            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range)
-            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[img_col_axis]
+            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range)
-            output_dim = self.cell.state_size[0]
+            state_size = self.cell.state_size
-            output_dim = self.cell.state_size
+            state_size = [self.cell.state_size]
-            state_shape = [(input_shape[0], output_dim) for _ in self.states]
+            state_shape = [(input_shape[0], dim) for dim in state_size]
-    assert_allclose(out.std(axis=(0, 2)), 1.0, atol=1e-1)
+    assert_allclose(out.mean(axis=(0, 2)), 0.0, atol=1.1e-1)
-            return [out for out in all_outs]
+            return [out[0] for out in all_outs]
-    def __init__(self, batch_size):
+    def __init__(self, batch_size, sequence_length=12):
-        return 12
+        return self.sequence_length
-            vhats = [None for p in params]
+            vhats = [K.zeros(1) for _ in params]
-                  optimizer=optimizers.RMSprop(lr=0.0001),
+                  optimizer=optimizers.Adam(),
-    def load_weights(self, filepath, by_name=False):
+    def load_weights(self, filepath, by_name=False, skip_mismatch=False):
-            load_weights_from_hdf5_group_by_name(f, self.layers)
+            load_weights_from_hdf5_group_by_name(
-def load_weights_from_hdf5_group_by_name(f, layers):
+def load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False):
-        layers: a list of target layers.
+        layers: A list of target layers.
-            and weights file.
+            and weights file and skip_mismatch=False.
-                                 ' element(s).')
+                if skip_mismatch:
-    def load_weights(self, filepath, by_name=False):
+    def load_weights(self, filepath, by_name=False, skip_mismatch=False):
-            topology.load_weights_from_hdf5_group_by_name(f, layers)
+            topology.load_weights_from_hdf5_group_by_name(f, layers,
-from numpy.testing import assert_allclose
+from numpy.testing import assert_allclose, assert_raises
-MAX_NB_WORDS = 20000
+MAX_NUM_WORDS = 20000
-tokenizer = Tokenizer(num_words=MAX_NB_WORDS)
+tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)
-num_words = min(MAX_NB_WORDS, len(word_index))
+num_words = min(MAX_NUM_WORDS, len(word_index))
-    if i >= MAX_NB_WORDS:
+    if i >= MAX_NUM_WORDS:
-- [Discussion on parameter tuning](https://github.com/fchollet/keras/issues/3705)
+- [Discussion on parameter tuning](https://github.com/keras-team/keras/issues/3705)
-      download_url='https://github.com/fchollet/keras/tarball/2.1.2',
+      url='https://github.com/keras-team/keras',
-    https://github.com/fchollet/keras/issues/1567
+    https://github.com/keras-team/keras/issues/1567
-    https://github.com/fchollet/keras/issues/1567
+    https://github.com/keras-team/keras/issues/1567
-    return C.one_hot(indices, nb_classes)
+def one_hot(indices, num_classes):
-    """Computes mean and std for batch then apply batch_normalization on batch.
+def _regular_normalize_batch_in_training(x, gamma, beta,
-        target_shape = tf.stack(target_shape)
+    normed = tf.nn.batch_normalization(x, mean, var,
-            broadcast_beta = None
+
-                                           epsilon)
+            target_shape.append(tf.shape(x)[axis])
-                x += reshape(bias, (1, bias_shape[0], 1, 1))
+                if _has_nchw_support():
-    from keras import regularizers
+               kwargs={'momentum': 0.9,
-               input_shape=(3, 4, 2))
+               input_shape=(3, 4, 2, 4))
-def test_batchnorm_correctness():
+def test_batchnorm_correctness_1d():
-     Not comparing the order since it is not guarantee.
+     Not comparing the order since it is not guaranteed.
-    
+
-                and n_features is the number of features.
+                Training samples where `n_samples` is the number of samples
-                True labels for X.
+                True labels for `x`.
-            override: dictionary, values to override sk_params
+            override: dictionary, values to override `sk_params`
-                in both sk_params and fn's arguments.
+                in both `sk_params` and `fn`'s arguments.
-                and n_features is the number of features.
+                Training samples where `n_samples` is the number of samples
-                True labels for X.
+                True labels for `x`.
-                and n_features is the number of features.
+                Test samples where `n_samples` is the number of samples
-                and n_features is the number of features.
+                Test samples where `n_samples` is the number of samples
-                and n_features is the number of features.
+                Test samples where `n_samples` is the number of samples
-                True labels for x.
+                True labels for `x`.
-                Mean accuracy of predictions on X wrt. y.
+                Mean accuracy of predictions on `x` wrt. `y`.
-                and n_features is the number of features.
+                Test samples where `n_samples` is the number of samples
-                and n_features is the number of features.
+                Test samples where `n_samples` is the number of samples
-                True labels for X.
+                True labels for `x`.
-                Mean accuracy of predictions on X wrt. y.
+                Mean accuracy of predictions on `x` wrt. `y`.
-    # this is the z space commonly refered to in GAN papers
+    # this is the z space commonly referred to in GAN papers
-        # accuracy of the auxilary classifier on generated images, so we
+        # accuracy of the auxiliary classifier on generated images, so we
-        # To preserve sum of sample weights for the auxilary classifier,
+        # To preserve sum of sample weights for the auxiliary classifier,
-    Adjusts the input `previou path` to match the shape of the `input`
+    Adjusts the input `previous path` to match the shape of the `input`
-    In particular additonal operations via `fetches` argument and additional
+    In particular additional operations via `fetches` argument and additional
-        self._use_multiprocessing = use_multiprocessing
+        if os.name is 'nt' and use_multiprocessing is True:
-        def data_generator_task():
+    def _data_generator_task(self):
-                    if self._use_multiprocessing or self.queue.qsize() < max_queue_size:
+                    if self.queue is not None and self.queue.qsize() < self.max_queue_size:
-                    # Can't pick tracebacks.
+                    # Can't pickle tracebacks.
-                        setattr(e, '__traceback__', sys.exc_info()[2])
+                    traceback.print_exc()
-                self.queue = queue.Queue()
+                # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:
-                    thread = multiprocessing.Process(target=data_generator_task)
+                    thread = multiprocessing.Process(target=self._data_generator_task)
-                    thread = threading.Thread(target=data_generator_task)
+                    thread = threading.Thread(target=self._data_generator_task)
-                if self._use_multiprocessing:
+            if self._use_multiprocessing:
-                    thread.join(timeout)
+            else:
-                        use_multiprocessing=True)
+    # - Produce data on 4 worker processes, consume on main process:
-                        steps_per_epoch=5,
+                        steps_per_epoch=STEPS_PER_EPOCH,
-                        steps_per_epoch=5,
+                        steps_per_epoch=STEPS_PER_EPOCH,
-                        validation_steps=1)
+                        validation_steps=1,
-                        steps_per_epoch=5,
+                        steps_per_epoch=STEPS_PER_EPOCH,
-                        validation_steps=1)
+                        validation_steps=1,
-                        steps_per_epoch=5,
+                        steps_per_epoch=STEPS_PER_EPOCH,
-                        workers=0)
+                        max_queue_size=10,
-                            validation_data=custom_generator())
+                            steps_per_epoch=STEPS_PER_EPOCH,
-                            steps_per_epoch=5,
+                            steps_per_epoch=STEPS_PER_EPOCH,
-                            validation_steps=1)
+                            validation_steps=1,
-                            steps_per_epoch=5,
+                            steps_per_epoch=STEPS_PER_EPOCH,
-                            validation_steps=1)
+                            validation_steps=1,
-def test_multiprocessing_training_fromfile(in_tmpdir):
+def test_multiprocessing_training_from_file(in_tmpdir):
-                        steps_per_epoch=5,
+                        steps_per_epoch=STEPS_PER_EPOCH,
-                        use_multiprocessing=True)
+                        workers=WORKERS,
-                        steps_per_epoch=5,
+                        steps_per_epoch=STEPS_PER_EPOCH,
-                            steps=5,
+                            steps=STEPS,
-                            use_multiprocessing=True)
+                            workers=WORKERS,
-                            steps=5,
+                            steps=STEPS,
-                            steps=5,
+                            steps=STEPS,
-                            workers=0)
+                            workers=0,
-                             steps=5,
+                             steps=STEPS,
-                             use_multiprocessing=True)
+                             workers=WORKERS,
-                             steps=5,
+                             steps=STEPS,
-                             steps=5,
+                             steps=STEPS,
-                             workers=0)
+                             workers=0,
-    def custom_generator():
+    def custom_generator(use_weights=False):
-                   np.random.randint(batch_size, 12, 50))
+            batch_index = np.random.randint(0, n_samples - batch_size)
-        )
+        model.fit_generator(custom_generator(),
-        )
+        model.fit_generator(custom_generator(),
-                   np.random.randint(batch_size, 12, 50))
+            batch_index = np.random.randint(0, n_samples - batch_size)
-
+        model.evaluate_generator(custom_generator(),
-        )
+        model.evaluate_generator(custom_generator(),
-    workers = 4
+        batch_size = 10
-                   np.random.randint(1, 256, size=(2, 5)))
+            batch_index = np.random.randint(0, n_samples - batch_size)
-    model.add(Dense(1, input_shape=(5,)))
+    model.add(Dense(1, input_shape=(2, )))
-
+        model.predict_generator(custom_generator(),
-
+        model.predict_generator(custom_generator(),
-    raw_code = codecs.decode(code.encode('ascii'), 'base64')
+    try:
-    x /= (x.std() + 1e-5)
+    x /= (x.std() + K.epsilon())
-    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)
+    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())
-grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)
+grads /= K.maximum(K.mean(K.abs(grads)), K.epsilon())
-    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + 1e-8)
+    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())
-    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + 1e-8)
+    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())
-        epsilon: float >= 0. Fuzz factor.
+        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.
-    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-8, decay=0.,
+    def __init__(self, lr=0.001, rho=0.9, epsilon=None, decay=0.,
-        epsilon: float >= 0.
+        epsilon: float >= 0. If `None`, defaults to `K.epsilon()`.
-    def __init__(self, lr=0.01, epsilon=1e-8, decay=0., **kwargs):
+    def __init__(self, lr=0.01, epsilon=None, decay=0., **kwargs):
-        epsilon: float >= 0. Fuzz factor.
+        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.
-    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, decay=0.,
+    def __init__(self, lr=1.0, rho=0.95, epsilon=None, decay=0.,
-        epsilon: float >= 0. Fuzz factor.
+        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.
-                 epsilon=1e-8, decay=0., amsgrad=False, **kwargs):
+                 epsilon=None, decay=0., amsgrad=False, **kwargs):
-        epsilon: float >= 0. Fuzz factor.
+        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.
-                 epsilon=1e-8, decay=0., **kwargs):
+                 epsilon=None, decay=0., **kwargs):
-        epsilon: float >= 0. Fuzz factor.
+        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.
-                 epsilon=1e-8, schedule_decay=0.004, **kwargs):
+                 epsilon=None, schedule_decay=0.004, **kwargs):
-        """Checks for user typos in "params".
+        """Checks for user typos in `params`.
-                Training samples where n_samples in the number of samples
+                Training samples where n_samples is the number of samples
-        """Filters `sk_params` and return those in `fn`'s arguments.
+        """Filters `sk_params` and returns those in `fn`'s arguments.
-            res : dictionary dictionary containing variables
+            res : dictionary containing variables
-                Training samples where n_samples in the number of samples
+                Training samples where n_samples is the number of samples
-                Test samples where n_samples in the number of samples
+                Test samples where n_samples is the number of samples
-                Test samples where n_samples in the number of samples
+                Test samples where n_samples is the number of samples
-                will return an array of shape '(n_samples, 2)'
+                to match the scikit-learn API,
-                Test samples where n_samples in the number of samples
+                Test samples where n_samples is the number of samples
-                Test samples where n_samples in the number of samples
+                Test samples where n_samples is the number of samples
-                Test samples where n_samples in the number of samples
+                Test samples where n_samples is the number of samples
-                 epsilon=1e-8, decay=0., **kwargs):
+                 epsilon=1e-8, decay=0., amsgrad=False, **kwargs):
-        self.weights = [self.iterations] + ms + vs
+        if self.amsgrad:
-        for p, g, m, v in zip(params, grads, ms, vs):
+        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):
-            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)
+            if self.amsgrad:
-                  'epsilon': self.epsilon}
+                  'epsilon': self.epsilon,
-                 sample_weight=None):
+    def evaluate(self, x=None, y=None,
-                                   sample_weight=sample_weight)
+                                   sample_weight=sample_weight,
-                your dataset divided by the batch size.
+                Ignored with the default value of `None`.
-text = open(path).read().lower()
+text = io.open(path, encoding='utf-8').read().lower()
-        `batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal
+        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal
-        if self.model:
+        if self.built:
-    return gamma * ((x - mean) / C.sqrt(var + epsilon)) + beta
+    return (x - mean) / (C.sqrt(var) + epsilon) * gamma + beta
-        momentum: float >= 0. Parameter updates momentum.
+        momentum: float >= 0. Parameter that accelerates SGD
-            x /= np.std(x, keepdims=True) + 1e-7
+            x /= (np.std(x, keepdims=True) + K.epsilon())
-                x /= (self.std + 1e-7)
+                x /= (self.std + K.epsilon())
-_EPSILON = 10e-8
+_EPSILON = 1e-7
-        1e-08
+        1e-07
-        1e-08
+        1e-07
-    # will update it once cntk support generate ones with batch axis.
+    # Currently, CTNK can't instantiate `ones` with symbolic shapes.
-# Global Numpy arrays of imagenet mean for preprocessing symbolic inputs
+# Global tensor of imagenet mean for preprocessing symbolic inputs
-_LEARNING_PHASE = C.constant(shape=(), dtype=np.float32, value=1.0, name="_keras_learning_phase")
+_LEARNING_PHASE = C.constant(shape=(), dtype=np.float32, value=1.0, name='_keras_learning_phase')
-                                                        training=training)
+            self._dropout_mask = _generate_dropout_mask(
-                [K.shape(inputs)[0], self.units],
+                _generate_dropout_ones(inputs, self.units),
-                                                        count=3)
+            self._dropout_mask = _generate_dropout_mask(
-                [K.shape(inputs)[0], self.units],
+                _generate_dropout_ones(inputs, self.units),
-                                                        count=4)
+            self._dropout_mask = _generate_dropout_mask(
-                [K.shape(inputs)[0], self.units],
+                _generate_dropout_ones(inputs, self.units),
-    ones = K.ones(shape)
+def _generate_dropout_ones(inputs, dims):
-@pytest.mark.skipif((K.backend() in ['cntk', 'theano']),
+@pytest.mark.skipif((K.backend() in ['theano']),
-    def evaluate(self, x, y, batch_size=32, verbose=1,
+    def evaluate(self, x, y, batch_size=None, verbose=1,
-            batch_size: integer. Number of samples per gradient update.
+            batch_size: Integer. If unspecified, it will default to 32.
-    def predict(self, x, batch_size=32, verbose=0):
+    def predict(self, x, batch_size=None, verbose=0):
-            batch_size: integer.
+            batch_size: Integer. If unspecified, it will default to 32.
-    def predict_proba(self, x, batch_size=32, verbose=0):
+    def predict_proba(self, x, batch_size=None, verbose=0):
-            batch_size: integer.
+            batch_size: Integer. If unspecified, it will default to 32.
-    def predict_classes(self, x, batch_size=32, verbose=0):
+    def predict_classes(self, x, batch_size=None, verbose=0):
-            batch_size: integer.
+            batch_size: Integer. If unspecified, it will default to 32.
-        self.executor = None
+        self.executor_fn = None
-            self.executor = multiprocessing.Pool(workers)
+            self.executor_fn = lambda: multiprocessing.Pool(workers)
-            self.executor = ThreadPool(workers)
+            self.executor_fn = lambda: ThreadPool(workers)
-            self._wait_queue()
+            with closing(self.executor_fn()) as executor:
-                return
+                # Done with the current epoch, waiting for the final batches
-
+        Note that if `shape` was symbolic, we cannot return a variable,
-                    dtype, name)
+    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)
-    """Instantiates an all-ones tensor variable and returns it.
+    """Instantiates an all-ones variable and returns it.
-                    dtype, name)
+    v = tf.ones(shape=shape, dtype=tf_dtype, name=name)
-
+        if 0 < self.dropout < 1 and self._dropout_mask is None:
-                    'or use a different backend.')
+                    'or use the TensorFlow backend.')
-
+        if 0 < self.dropout < 1 and self._dropout_mask is None:
-
+        if 0 < self.dropout < 1 and self._dropout_mask is None:
-        self.cell._generate_recurrent_dropout_mask(inputs, training=training)
+
-                    reason='Not yet supported.')
+@pytest.mark.skipif((K.backend() in ['cntk', 'theano']),
-            # Dropout is disabled with CNTK for now.
+        if dropout_rate and K.backend() == 'tensorflow':
-__version__ = '2.1.1'
+__version__ = '2.1.2'
-      version='2.1.1',
+      version='2.1.2',
-      download_url='https://github.com/fchollet/keras/tarball/2.1.1',
+      download_url='https://github.com/fchollet/keras/tarball/2.1.2',
-            raise StopIteration(e)
+            six.raise_from(StopIteration(e), e)
-                        self.queue.put(generator_output)
+                        self.queue.put((True, generator_output))
-                except Exception:
+                except Exception as e:
-                    raise
+                    break
-                self.queue = multiprocessing.Queue(maxsize=max_queue_size)
+                self._manager = multiprocessing.Manager()
-                self.queue.close()
+        if self._manager:
-                    yield inputs
+                success, value = self.queue.get()
-    with pytest.raises(StopIteration):
+    with pytest.raises(IndexError):
-    with pytest.raises(StopIteration):
+    with pytest.raises(IndexError):
-                   np.random.randint(batch_size, 2, 50))
+                   np.random.randint(batch_size, 12, 50))
-    with pytest.raises(StopIteration):
+    with pytest.raises(RuntimeError):
-    with pytest.raises(StopIteration):
+    with pytest.raises(RuntimeError):
-                   np.random.randint(batch_size, 2, 50))
+                   np.random.randint(batch_size, 12, 50))
-    with pytest.raises(StopIteration):
+    with pytest.raises(RuntimeError):
-            workers=4, use_multiprocessing=True,
+            custom_generator(), good_batches * workers + 1, 1,
-    with pytest.raises(StopIteration):
+    with pytest.raises(RuntimeError):
-    with pytest.raises(StopIteration):
+    with pytest.raises(RuntimeError):
-    with pytest.raises(StopIteration):
+    with pytest.raises(RuntimeError):
-                              '`featurewise_center`, but it hasn\'t'
+                              '`featurewise_center`, but it hasn\'t '
-                              '`featurewise_std_normalization`, but it hasn\'t'
+                              '`featurewise_std_normalization`, but it hasn\'t '
-                              '`zca_whitening`, but it hasn\'t'
+                              '`zca_whitening`, but it hasn\'t '
-    if input_shape and input_shape[-1] == 1:
+    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:
-    expected_shapes = [(3, num_classes),
+    shapes = [(1,), (3,), (4, 3), (5, 4, 3), (3, 1), (3, 2, 1)]
-    'test_funcion_type',
+    'test_function_type',
-def test_func_dump_and_load(test_funcion_type):
+def test_func_dump_and_load(test_function_type):
-    if test_funcion_type == 'simple function':
+    if test_function_type == 'simple function':
-    elif test_funcion_type == 'closured function':
+
-        return r'\u'
+@pytest.mark.parametrize(
-                callback.set_model(model)
+            callback.set_model(model)
-        maxlen: truncate sequences after this length.
+        maxlen: sequences longer than this will be filtered out.
-    name = '/' + name.lower().split('device:')[1]
+    name = '/' + ':'.join(name.lower().replace('/', '').split(':')[-2:])
-            assert rand.shape == (200, 100)
+            rand = k.eval(k.random_normal((300, 100), mean=mean, stddev=std))
-        # if our output includes timesteps we need to reshape
+    if len(output_shape) >= 3:
-            or `'imagenet'` (pre-training on ImageNet).
+        weights: one of `None` (random initialization),
-    if weights not in {'imagenet', None}:
+    if not (weights in {'imagenet', None} or os.path.exists(weights)):
-                         '(pre-training on ImageNet).')
+                         '`None` (random initialization), `imagenet` '
-            or 'imagenet' (pre-training on ImageNet).
+        weights: one of `None` (random initialization),
-    if weights not in {'imagenet', None}:
+    if not (weights in {'imagenet', None} or os.path.exists(weights)):
-                         '(pre-training on ImageNet).')
+                         '`None` (random initialization), `imagenet` '
-            `imagenet` (ImageNet weights)
+        weights: one of `None` (random initialization),
-    if weights not in {'imagenet', None}:
+    if not (weights in {'imagenet', None} or os.path.exists(weights)):
-                         '(pre-training on ImageNet).')
+                         '`None` (random initialization), `imagenet` '
-            or 'imagenet' (pre-training on ImageNet).
+        weights: one of `None` (random initialization),
-    if weights not in {'imagenet', None}:
+    if not (weights in {'imagenet', None} or os.path.exists(weights)):
-                         '(pre-training on ImageNet).')
+                         '`None` (random initialization), `imagenet` '
-            or 'imagenet' (pre-training on ImageNet).
+        weights: one of `None` (random initialization),
-    if weights not in {'imagenet', None}:
+    if not (weights in {'imagenet', None} or os.path.exists(weights)):
-                         '(pre-training on ImageNet).')
+                         '`None` (random initialization), `imagenet` '
-            or 'imagenet' (pre-training on ImageNet).
+        weights: one of `None` (random initialization),
-    if weights not in {'imagenet', None}:
+    if not (weights in {'imagenet', None} or os.path.exists(weights)):
-                         '(pre-training on ImageNet).')
+                         '`None` (random initialization), `imagenet` '
-            or 'imagenet' (pre-training on ImageNet).
+        weights: one of `None` (random initialization),
-    if weights not in {'imagenet', None}:
+    if not (weights in {'imagenet', None} or os.path.exists(weights)):
-                         '(pre-training on ImageNet).')
+                         '`None` (random initialization), `imagenet` '
-# used for generic graph-specific string UIDs
+# used for generating graph-specific string UIDs
-        x *= 2.
+        x /= 127.5
-        x *= 2.
+        x /= 127.5
-            callback.set_model(model)
+            if callback.model is None:
-        >>> kvar.eval()
+        >>> K.eval(kvar)
-from keras.layers.convolutional import UpSampling2D, Conv2D
+from keras.layers.convolutional import Conv2DTranspose, Conv2D
-    cnn.add(Reshape((7, 7, 128)))
+    cnn.add(Dense(3 * 3 * 384, input_dim=latent_size, activation='relu'))
-                   kernel_initializer='glorot_normal'))
+    cnn.add(Conv2DTranspose(96, 5, strides=2, padding='same',
-                   kernel_initializer='glorot_normal'))
+    cnn.add(Conv2DTranspose(1, 5, strides=2, padding='same',
-    cnn.add(LeakyReLU())
+    cnn.add(LeakyReLU(0.2))
-    cnn.add(LeakyReLU())
+    cnn.add(LeakyReLU(0.2))
-    cnn.add(LeakyReLU())
+    cnn.add(LeakyReLU(0.2))
-    cnn.add(LeakyReLU())
+    cnn.add(LeakyReLU(0.2))
-            soft_zero, soft_one = 0.25, 0.75
+            soft_zero, soft_one = 0.1, 0.9
-            epoch_disc_loss.append(discriminator.train_on_batch(x, [y, aux_y]))
+            epoch_disc_loss.append(discriminator.train_on_batch(
-        noise = np.random.uniform(-1, 1, (num_rows * num_classes, latent_size))
+        num_rows = 40
-    assert data_format in {'channels_last', 'channels_first'}
+def _preprocess_numpy_input(x, data_format, mode):
-    code = marshal.dumps(func.__code__).decode('raw_unicode_escape')
+    raw_code = marshal.dumps(func.__code__)
-    code = marshal.loads(code.encode('raw_unicode_escape'))
+    raw_code = codecs.decode(code.encode('ascii'), 'base64')
-                    batch_size = len(x[0])
+                    batch_size = x[0].shape[0]
-                    batch_size = len(list(x.values())[0])
+                    batch_size = list(x.values())[0].shape[0]
-                    batch_size = len(x)
+                    batch_size = x.shape[0]
-    (Theano or TensorFlow), which we augment with certain
+    (Theano, TensorFlow or CNTK), which we augment with certain
-        ._keras_shape: Integer shape tuple propagated
+        `_keras_shape`: Integer shape tuple propagated
-        ._keras_history: Last layer applied to the tensor.
+        `_keras_history`: Last layer applied to the tensor.
-                        'should be either a list of a dict. '
+                        'should be either a list or a dict. '
-                                 'it should have one entry per model outputs. '
+                                 'it should have one entry per model output. '
-                        'it should have one entry per model outputs. '
+                        'it should have one entry per model output. '
-                                 'it should have one entry per model outputs. '
+                                 'it should have one entry per model output. '
-    input_shape = (img_rows, img_cols, channels)
+input_shape = x_train.shape[1:]
-    if layer.__class__.__name__ == 'LSTM':
+    if layer.__class__.__name__ == 'LSTM' and len(weights) == 3:
-    if shape and not batch_shape:
+        assert shape is not None, ('Please provide to Input either a `shape`'
-                If unspecified, `workers` will default to 1.
+                If unspecified, `workers` will default to 1. If 0, will
-                                           shuffle=shuffle)
+            if workers > 0:
-            output_generator = enqueuer.get()
+                output_generator = generator
-                when using process based threading
+            workers: Integer. Maximum number of processes to spin up
-                                           use_multiprocessing=use_multiprocessing)
+            if workers > 0:
-            output_generator = enqueuer.get()
+                output_generator = generator
-                when using process based threading
+            workers: Integer. Maximum number of processes to spin up
-                                           use_multiprocessing=use_multiprocessing)
+            if workers > 0:
-            output_generator = enqueuer.get()
+                output_generator = generator
-    in the chosen precision.
+    occasional wildly incorrect prediction.
-    return K.mean(K.log(cosh(y_pred - y_true)), axis=-1)
+    def _logcosh(x):
-steps_per_epoch = np.ceil(60000 / 128).astype('int')  # = 469
+steps_per_epoch = int(np.ceil(60000 / float(batch_size)))  # = 469
-        print('T', correct)
+        print('Q', q[::-1] if INVERT else q, end=' ')
-            print(colors.ok + 'â' + colors.close, end=" ")
+            print(colors.ok + 'â' + colors.close, end=' ')
-            print(colors.fail + 'â' + colors.close, end=" ")
+            print(colors.fail + 'â' + colors.close, end=' ')
-model_type = 'ResNet%d v%d' % (depth, version)
+model_type = 'ResNet%dv%d' % (depth, version)
-model_name = 'cifar10_resnet_model.{epoch:02d}.h5'
+model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type
-            elif getattr(losses, loss_fn.__name__, None) is None:
+            elif (not hasattr(loss_fn, '__name__') or
-    x = theano.ifelse.ifelse(training, x, alt)
+    x = ifelse(training, x, alt)
-                            follow_links=False):
+                            follow_links=False,
-            follow_links=follow_links)
+            follow_links=follow_links,
-                 follow_links=False):
+                 data_format=None, save_to_dir=None,
-                           target_size=self.target_size)
+                           target_size=self.target_size,
-    The build_fn should construct, compile and return a Keras model, which
+    The `build_fn` should construct, compile and return a Keras model, which
-    three values could be passed to build_fn:
+    three values could be passed to `build_fn`:
-    2. An instance of a class that implements the __call__ method
+    2. An instance of a class that implements the `__call__` method
-    present class will then be treated as the default build_fn.
+    `KerasClassifier` or `KerasRegressor`. The `__call__` method of the
-    estimators in scikit-learn, 'build_fn' should provide default values for
+    estimators in scikit-learn, `build_fn` should provide default values for
-        for outputs in all_outputs:
+        for name, outputs in zip(model.output_names, all_outputs):
-                                      axis=0))
+                                      axis=0, name=name))
-            model replicas.
+        gpus: Integer >= 2 or list of integers, number of GPUs or
-                         'Received: `gpus=%d`' % gpus)
+    if isinstance(gpus, (list, tuple)):
-    target_devices = ['/cpu:0'] + ['/gpu:%d' % i for i in range(gpus)]
+    target_devices = ['/cpu:0'] + ['/gpu:%d' % i for i in target_gpu_ids]
-        if i == gpus - 1:
+        if i == num_gpus - 1:
-            with tf.name_scope('replica_%d' % i):
+    for i, gpu_id in enumerate(target_gpu_ids):
-                                                'parts': gpus})(x)
+                                                'parts': num_gpus})(x)
-                      steps_per_epoch,
+                      steps_per_epoch=None,
-                divided by the batch size. Not used if using `Sequence`.
+                divided by the batch size.
-                             '`validation_steps`.')
+        if (val_gen and not isinstance(validation_data, Sequence) and
-    def evaluate_generator(self, generator, steps,
+    def evaluate_generator(self, generator, steps=None,
-                Not used if using Sequence.
+                Optional for `Sequence`: if unspecified, will use
-            steps = len(generator)
+        if steps is None:
-    def predict_generator(self, generator, steps,
+    def predict_generator(self, generator, steps=None,
-                Not used if using Sequence.
+                Optional for `Sequence`: if unspecified, will use
-            steps = len(generator)
+        if steps is None:
-                      steps_per_epoch,
+                      steps_per_epoch=None,
-    def evaluate_generator(self, generator, steps,
+    def evaluate_generator(self, generator, steps=None,
-    def predict_generator(self, generator, steps,
+    def predict_generator(self, generator, steps=None,
-    tracker_cb = LambdaCallback(on_epoch_begin=on_epoch_begin)
+    def on_batch_begin(batch, logs):
-    out = model.fit_generator(generator=RandomSequence(3), steps_per_epoch=12, epochs=5,
+    trained_batches = []
-                              validation_steps=12, callbacks=[tracker_cb])
+                              callbacks=[tracker_cb])
-                       (3, num_classes)]
+                       (3, num_classes),
-                the number of unique samples in your dataset divided by
+                the number of samples in your dataset divided by
-                The default `None` is equal to the number of unique samples in
+                The default `None` is equal to the number of samples in
-                be equal to the number of unique samples of your dataset
+                be equal to the number of samples of your dataset
-                the number of unique samples in your dataset divided by
+                the number of samples in your dataset divided by
-                be equal to the number of unique samples of your dataset
+                be equal to the number of samples of your dataset
-                be equal to the number of unique samples of your
+                be equal to the number of samples of your
-                               for r in np.split(generated_images, num_classes)
+                               for r in np.split(img, 2 * num_classes + 1)
-    def fit_generator(self, generator,
+    def fit_generator(self,
-            generator: A generator or an instance of Sequence (keras.utils.Sequence)
+            generator: A generator or an instance of `Sequence` (`keras.utils.Sequence`)
-                All arrays should contain the same number of samples.
+                - a tuple `(inputs, targets)`
-            use_multiprocessing: If True, use process based threading.
+            max_queue_size: Integer. Maximum size for the generator queue.
-_SEQUENCE_COUNTER = multiprocessing.Value('i', 0)
+_SEQUENCE_COUNTER = None
-        global _SEQUENCE_COUNTER
+        global _SEQUENCE_COUNTER
-        arrays = data.values
+        if data.__class__.__name__ == 'DataFrame':
-    out = model.predict([input_a_df, input_b_df], batch_size=4)
+@keras_test
-    predictions = layers.Dense(classes,
+    predictions = layers.Dense(num_classes,
-classes = 10
+num_classes = 10
-y_train = tf.one_hot(y_train, classes)
+y_train = tf.one_hot(y_train, num_classes)
-loss, acc = test_model.evaluate(x_test, y_test, classes)
+loss, acc = test_model.evaluate(x_test, y_test, num_classes)
-    num_batches = int(np.ceil(size / float(batch_size)))
+    num_batches = (size + batch_size - 1) // batch_size  # round up
-        return int(np.ceil(self.n / float(self.batch_size)))
+        return (self.n + self.batch_size - 1) // self.batch_size  # round up
-__version__ = '2.1.0'
+__version__ = '2.1.1'
-      version='2.1.0',
+      version='2.1.1',
-      download_url='https://github.com/fchollet/keras/tarball/2.1.0',
+      download_url='https://github.com/fchollet/keras/tarball/2.1.1',
-        data = data.values
+        arrays = data.values
-                If unspecified, it will default to 32.
+                If unspecified, `batch_size` will default to 32.
-            verbose: 0, 1, or 2. Verbosity mode.
+            verbose: Integer. 0, 1, or 2. Verbosity mode.
-                This will override `validation_split`.
+                `validation_data` will override `validation_split`.
-            initial_epoch: Epoch at which to start training
+            initial_epoch: Integer.
-            steps_per_epoch: Total number of steps (batches of samples)
+            steps_per_epoch: Integer or `None`.
-            steps: Total number of steps (batches of samples)
+            x: Numpy array of test data (if the model has a single input),
-                Ignored with the default value of `None`.
+                The default `None` is equal to the number of unique samples in
-        """Trains the model for a fixed number of epochs.
+        """Trains the model for a fixed number of epochs (iterations on a dataset).
-            validation_split: Float between 0 and 1:
+            validation_split: Float between 0 and 1.
-                                num_classes)
+                                batch_size=batch_size)
-    def predict_proba(self, x, batch_size=32, verbose=1):
+    def predict_proba(self, x, batch_size=32, verbose=0):
-    def predict_classes(self, x, batch_size=32, verbose=1):
+    def predict_classes(self, x, batch_size=32, verbose=0):
-            output._uses_learning_phase = True
+            if self.merge_mode is None:
-    with the template model (the argument you passed to `multi_gpu_model),
+    with the template model (the argument you passed to `multi_gpu_model`),
-    shapes = [(3,), (4, 3), (5, 4, 3)]
+    shapes = [(3,), (4, 3), (5, 4, 3), (3, 1), (3, 2, 1)]
-    for label, one_hot in zip(labels, one_hots):
+    for label, one_hot, expected_shape in zip(labels,
-        assert one_hot.shape == label.shape + (num_classes,)
+        assert one_hot.shape == expected_shape
-        # Make sure there is only one 1 in a row
+        # Make sure there is exactly one 1 in a row
-        assert np.all(np.argmax(one_hot, -1) == label)
+        assert np.all(np.argmax(one_hot, -1).reshape(label.shape) == label)
-__version__ = '2.0.9'
+__version__ = '2.1.0'
-      version='2.0.9',
+      version='2.1.0',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.9',
+      download_url='https://github.com/fchollet/keras/tarball/2.1.0',
-            optimizer: String (name of optimizer) or optimizer object.
+            optimizer: String (name of optimizer) or optimizer instance.
-                are passed into K.function. When using the TensorFlow backend,
+                are passed into `K.function`.
-                `None` (default) if feeding from framework-native tensors.
+            x: Numpy array of training data (if the model has a single input),
-                is reached.
+                An epoch is an iteration over the entire `x` and `y`
-            validation_split: Float between 0 and 1:
+            validation_split: Float between 0 and 1.
-                Will override `validation_split`.
+                This will override `validation_split`.
-                "pay more attention" to samples from an under-represented class.
+                (during training only).
-                you can pass a 2D array with shape `(samples, sequence_length)`,
+                you can pass a 2D array with shape
-            target_tensors: By default, Keras will create placeholders for the
+            target_tensors: By default, Keras will create a placeholder for the
-                target tensors (in turn, Keras will not expect external
+                target tensor (in turn, Keras will not expect external
-                or a dict mapping output names to target tensors.
+                can specify them via the `target_tensors` argument.
-                are passed into K.function. When using the TensorFlow backend,
+                are passed into `K.function`.
-                `None` (default) if feeding from framework-native tensors.
+                If the input layer in the model is named, you can also pass a
-                `None` (default) if feeding from framework-native tensors.
+                If the output layer in the model is named, you can also pass a
-                is reached.
+                An epoch is an iteration over the entire `x` and `y`
-                Will override `validation_split`.
+                This will override `validation_split`.
-                "pay more attention" to samples from an under-represented class.
+                (during training only).
-                you can pass a 2D array with shape `(samples, sequence_length)`,
+                you can pass a 2D array with shape
-                Can be `None` (default) if feeding from framework-native tensors.
+            x: Numpy array of training data, or a list of Numpy arrays.
-                over the training data arrays.
+            epochs: Integer. Number of epochs to train the model.
-            callbacks: List of callbacks to be called during training.
+                0 = silent, 1 = progress bar, 2 = one line per epoch.
-                fraction of the training data to be used as validation data.
+                Fraction of the training data to be used as validation data.
-                with shape (samples, sequence_length),
+            validation_data: tuple `(x_val, y_val)` or tuple
-                sample_weight_mode="temporal" in compile().
+                `sample_weight_mode="temporal"` in `compile()`.
-                (useful for resuming a previous training run)
+                (useful for resuming a previous training run).
-                next epoch. When training with Input Tensors such as
+                next epoch. When training with input tensors such as
-            all information collected during training.
+            A `History` object. Its `History.history` attribute is
-                Can be `None` (default) if feeding from framework-native tensors.
+                `x` can be `None` (default) if feeding from framework-native tensors.
-                Can be `None` (default) if feeding from framework-native tensors.
+                `y` can be `None` (default) if feeding from framework-native tensors.
-            callbacks: list of `keras.callbacks.Callback` instances.
+            x: Numpy array of training data.
-                Whether to shuffle the samples at each epoch.
+            validation_split: Float between 0 and 1:
-                the training samples, used for scaling the loss function
+                Has no effect when `steps_per_epoch` is not `None`.
-                you can pass a 2D array with shape (samples, sequence_length),
+                you can pass a 2D array with shape `(samples, sequence_length)`,
-                sample_weight_mode="temporal" in compile().
+                `sample_weight_mode="temporal"` in `compile()`.
-            RuntimeError: if the model was never compiled.
+            RuntimeError: If the model was never compiled.
-    def fit(self, x=None,
+    def fit(self,
-            class_weight=None, sample_weight=None, initial_epoch=0, **kwargs):
+    def fit(self,
-                              initial_epoch=initial_epoch)
+                              initial_epoch=initial_epoch,
-    hist = model.fit(data, labels, callbacks=[stopper])
+    hist = model.fit(data, labels, callbacks=[stopper], epochs=20)
-    hist = model.fit(data, labels, callbacks=[stopper])
+    hist = model.fit(data, labels, callbacks=[stopper], epochs=20)
-                                     '`batch_input_shape` argument.')
+            # First layer in model: check that it is an input layer.
-                          dtype=layer.dtype, name=layer.name + '_input')
+                x = Input(batch_shape=batch_shape,
-            if len(layer.inbound_nodes[0].output_tensors) != 1:
+            if len(layer.inbound_nodes[-1].output_tensors) != 1:
-            self.outputs = [layer.inbound_nodes[0].output_tensors[0]]
+            self.outputs = [layer.inbound_nodes[-1].output_tensors[0]]
-    y = np.array(y, dtype='int').ravel()
+    y = np.array(y, dtype='int')
-    all of the same shape expect for the concatenation axis,
+    all of the same shape except for the concatenation axis,
-                    'from keras.utils.np_utils import to_categorical\n'
+                    'from keras.utils import to_categorical\n'
-48sec per epoch on GTX 1080Ti
+ResNet v1
-  https://arxiv.org/pdf/1512.03385.pdf
+ResNet v2
-from keras.layers import MaxPooling2D, AveragePooling2D, Input, Flatten
+from keras.layers import AveragePooling2D, Input, Flatten
-from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
+from keras.callbacks import ModelCheckpoint, LearningRateScheduler
-# Training params.
+# Training parameters
-epochs = 100
+epochs = 200
-use_max_pool = False
+
-                   padding='same',
+
-        x = keras.layers.add([x, y])
+                   kernel_regularizer=l2(1e-4))(inputs)
-    num_filters = 2 * num_filters
+    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU
-                kernel_initializer='he_normal')(y)
+    # Arguments
-              optimizer=Adam(),
+              optimizer=Adam(lr=lr_schedule(0)),
-model_name = 'cifar10_resnet_model.h5'
+model_name = 'cifar10_resnet_model.{epoch:02d}.h5'
-# Prepare callbacks for model saving and for learning rate decaying.
+# Prepare callbacks for model saving and for learning rate adjustment.
-callbacks = [checkpoint, lr_reducer]
+
-        vertical_flip=False)  # randomly flip images
+        # set input mean to 0 over the dataset
-                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),
+                        steps_per_epoch=steps_per_epoch,
-        # (here, we do it on CPU, which is optional).
+        # Instantiate the base model (or "template" model).
-    for _ in get_variable_shape(x):
+    for _ in x.shape:
-    return np.prod(get_variable_shape(x))
+    return np.prod(int_shape(x))
-    return x.shape
+    return int_shape(x)
-    return np.prod(get_variable_shape(x))
+    return np.prod(int_shape(x))
-        for function_name in ['get_value', 'count_params', 'get_variable_shape']:
+        for function_name in ['get_value', 'count_params',
-                  'categorical_crossentropy'}
+    key_losses = {losses.mean_squared_error,
-        if loss.__name__ == 'categorical_crossentropy':
+        if loss is losses.categorical_crossentropy:
-        if loss.__name__ in key_losses:
+        if loss in key_losses:
-            if loss_fn.__name__ == 'sparse_categorical_crossentropy':
+            if loss_fn is losses.sparse_categorical_crossentropy:
-                output_shapes.append(None)
+from .utils.generic_utils import serialize_keras_object
-    return loss.__name__
+    return serialize_keras_object(loss)
-    weighted_function = _weighted_masked_objective(K.categorical_crossentropy)
+    weighted_function = _weighted_masked_objective(losses.categorical_crossentropy)
-    _check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [(2, None, 3)])
+    _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [a.shape])
-        _check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [a.shape])
+        _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [a.shape])
-        _check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [(2, 3, 6)])
+        _check_loss_and_target_compatibility([a], [losses.categorical_crossentropy], [(2, 3, 6)])
-Notes:
+# Notes
-It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.
+It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.
-epochs = 200
+epochs = 100
-https://arxiv.org/pdf/1512.03385.pdf
+# Reference
-This script can run on CPU in a few minutes (with the TensorFlow backend).
+This script can run on CPU in a few minutes.
-'''Train a Bidirectional LSTM on the IMDB sentiment classification task.
+'''Trains a Bidirectional LSTM on the IMDB sentiment classification task.
-
+
-Notes:
+
-# Summary of the algorithm:
+# Summary of the algorithm
-# Data download:
+# Data download
-# References:
+# References
-the input is a generated uniformly distributed random sequence of length = "input_len",
+the input is a generated uniformly distributed
-- lahead: the input sequence length that the LSTM is trained on for each output point
+- lahead: the input sequence length that the LSTM
-This is similar to sklearn's "view_as_windows" with "window_shape" being a single number
+This is similar to sklearn's "view_as_windows"
-sentence-level structure of the context.
+"""Example of using Hierarchical RNN (HRNN) to classify MNIST digits.
-        of bidirectional HRNN combined with fully connected layers.
+
-representing the whole image. A final Dense layer is added for prediction.
+column of pixels of shape (28, 1) to a column vector of shape (128,).
-Notes
+# Notes
-Experiments
+# Experiments
-Results
+# Results
-'''Train a Siamese MLP on pairs of digits from the MNIST dataset.
+'''Trains a Siamese MLP on pairs of digits from the MNIST dataset.
-[1] "Dimensionality Reduction by Learning an Invariant Mapping"
+# References
-MNIST dataset.  It exemplifies two influential methods that have been developed
+MNIST dataset. It exemplifies two influential methods that have been developed
-input image.  Therefore, if the 'where' is handed from the encoder
+input image. Therefore, if the 'where' is handed from the encoder
-https://arxiv.org/abs/1311.2901v3
+# References
-https://arxiv.org/abs/1506.02351v8
+- Visualizing and Understanding Convolutional Networks
-The second idea exploited here is that of residual learning.  Residual blocks
+The second idea exploited here is that of residual learning. Residual blocks
-for much deep networks to be easily trained.  The residual element seems to
+for much deep networks to be easily trained. The residual element seems to
-between the encoder and decoder.  Normally, in the decoder, the final
+between the encoder and decoder. Normally, in the decoder, the final
-
+applied as a bias because we know the MNIST digits are mapped to [0, 1].
-'''Transfer learning toy example:
+'''Transfer learning toy example.
-2- Freeze convolutional layers and fine-tune dense layers
+1 - Train a simple convnet on the MNIST dataset the first 5 digits [0..4].
-Resources:
+# Script Usage
-  Klambauer, G., Unterthiner, T., Mayr, A., & Hochreiter, S. (2017).
+# Reference
-Reference: "Auto-Encoding Variational Bayes" https://arxiv.org/abs/1312.6114
+ #Reference
-Reference: "Auto-Encoding Variational Bayes" https://arxiv.org/abs/1312.6114
+# Reference
-             interpolation='bilinear'):
+             interpolation='nearest'):
-            "hamming" are also supported. By default, "bilinear" is used.
+            "hamming" are also supported. By default, "nearest" is used.
-            y = np.array([1] * batch_size + [0] * batch_size)
+
-            trick = np.ones(2 * batch_size)
+            trick = np.ones(2 * batch_size) * soft_one
-import keras.backend as K
+    print('Discriminator model:')
-    x_train = np.expand_dims(x_train, axis=1)
+    x_train = np.expand_dims(x_train, axis=-1)
-    x_test = np.expand_dims(x_test, axis=1)
+    x_test = np.expand_dims(x_test, axis=-1)
-    # label drawn from P_c, to image space (..., 1, 28, 28)
+    # label drawn from P_c, to image space (..., 28, 28, 1)
-    cnn.add(Reshape((128, 7, 7)))
+    cnn.add(Reshape((7, 7, 128)))
-    # upsample to (..., 14, 14)
+    # upsample to (14, 14, ...)
-    # upsample to (..., 28, 28)
+    # upsample to (28, 28, ...)
-                   input_shape=(1, 28, 28)))
+                   input_shape=(28, 28, 1)))
-    image = Input(shape=(1, 28, 28))
+    image = Input(shape=(28, 28, 1))
-    # get our mnist data, and force it to be of shape (..., 1, 28, 28) with
+    # get our mnist data, and force it to be of shape (..., 28, 28, 1) with
-        `_collected_trainable_weights` are consistent (i.e. have the same
+        `_collected_trainable_weights` are inconsistent (i.e. have different
-    y_train = np.zeros((num_train_samples,), dtype='uint8')
+    x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')
-        y_train[(i - 1) * 10000: i * 10000] = labels
+        (x_train[(i - 1) * 10000: i * 10000, :, :, :],
-        self._dynamic_display = (sys.stdout.isatty() or
+        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and
-        if dropout_rate:
+        if dropout_rate and K.backend() != 'cntk':
-                output._uses_learning_phase = True
+        if (getattr(y, '_uses_learning_phase', False) or
-                                     input_shape=(None, dim)))
+    model = keras.Sequential()
-    model = model_from_json(model.to_json())
+    model = keras.models.model_from_json(model.to_json())
-    model.add(wrappers.Bidirectional(rnn(output_dim), merge_mode=mode))
+    model = keras.Sequential()
-    model = Model(inputs, outputs)
+    inputs = keras.Input((timesteps, dim))
-    model = Model(inputs, outputs)
+    inputs = keras.Input(batch_shape=(1, timesteps, dim))
-from keras.layers import core, convolutional, recurrent, embeddings, normalization
+from keras import layers
-    model.add(core.Activation('relu'))
+    model.add(wrappers.TimeDistributed(layers.Dense(2), input_shape=(3, 4)))
-    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 2)), epochs=1, batch_size=10)
+    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 2)),
-    reference.add(core.Activation('relu'))
+    reference.add(wrappers.TimeDistributed(layers.Dense(2),
-    model.add(wrappers.TimeDistributed(embeddings.Embedding(5, 6), batch_input_shape=(10, 3, 4), dtype='int32'))
+    model.add(wrappers.TimeDistributed(layers.Embedding(5, 6),
-    model.fit(np.random.randint(5, size=(10, 3, 4), dtype='int32'), np.random.random((10, 3, 4, 6)), epochs=1, batch_size=10)
+    model.fit(np.random.randint(5, size=(10, 3, 4), dtype='int32'),
-    reference.add(wrappers.TimeDistributed(embeddings.Embedding(5, 6), input_shape=(3, 4), dtype='int32'))
+    reference.add(wrappers.TimeDistributed(layers.Embedding(5, 6),
-    model.add(core.Activation('relu'))
+    model.add(wrappers.TimeDistributed(layers.Conv2D(5, (2, 2),
-    model.train_on_batch(np.random.random((1, 2, 4, 4, 3)), np.random.random((1, 2, 4, 4, 5)))
+    model.train_on_batch(np.random.random((1, 2, 4, 4, 3)),
-    model.add(core.Activation('relu'))
+    model.add(wrappers.TimeDistributed(layers.Dense(2), input_shape=(3, 4)))
-    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 3)), epochs=1, batch_size=10)
+    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 3)),
-    model.add(core.Dense(3, input_dim=2))
+    model.add(layers.Dense(3, input_dim=2))
-    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)), epochs=1, batch_size=10)
+    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)),
-    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)), epochs=1, batch_size=10)
+    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)),
-              name='bn', input_shape=(10, 2)))
+    model.add(wrappers.TimeDistributed(
-    y = wrappers.TimeDistributed(core.Dropout(.999))(x, training=True)
+    y = wrappers.TimeDistributed(layers.Dropout(.999))(x, training=True)
-    model.add(core.Activation('relu'))
+        layers.Dense(2, kernel_regularizer='l1'), input_shape=(3, 4)))
-    model.add(core.Activation('relu'))
+        layers.Dense(2, activity_regularizer='l1'), input_shape=(3, 4)))
-    rnn = recurrent.SimpleRNN
+    rnn = layers.SimpleRNN
-                                         merge_mode=mode, input_shape=(timesteps, dim)))
+                                         merge_mode=mode,
-                                         merge_mode=mode, input_shape=(timesteps, dim)))
+        model.add(wrappers.Bidirectional(rnn(output_dim,
-        outputs = wrappers.Bidirectional(rnn(output_dim, stateful=True), merge_mode=mode)(inputs)
+        outputs = wrappers.Bidirectional(rnn(output_dim, stateful=True),
-# This list queries the devices.
+# This list holds the available devices.
-_LOCAL_DEVICES = device_lib.list_local_devices()
+_LOCAL_DEVICES = None
-                session.run(tf.variables_initializer(uninitialized_vars))
+            if candidate_vars:
-    return [x.name for x in local_device_protos]
+    return [x.name for x in K.get_session().list_devices()]
-    name = name.lower().replace('device:', '')
+    name = '/' + name.lower().split('device:')[1]
-                count_params(self._collected_trainable_weights)):
+        if (len(self.trainable_weights) !=
-        (Optional) 2D tensors with shape `(batch_size, output_dim)`.
+    # Input shape
-from six.moves import zip
+    np.random.seed(seed)
-        feed_dict = {}
+        feed_dict = self.feed_dict.copy()
-                              feed_dict=feed_dict,
+        updated = session.run(fetches=fetches, feed_dict=feed_dict,
-        noise = np.random.uniform(-1, 1, (100, latent_size))
+        num_rows = 10
-            [i] * num_classes for i in range(num_classes)
+            [i] * num_rows for i in range(num_classes)
-                divided by the batch size.
+                divided by the batch size. Not used if using `Sequence`.
-    """Quick fix for Python2, otherwise, it cannot be pickled.
+# Global variables to be shared across processes
-        ds: a Sequence object
+        uid: int, Sequence identifier
-    return ds[i]
+    global _SHARED_SEQUENCES
-                                              (self.sequence, i)), block=True)
+                    self.executor.apply_async(get_index, (self.uid, i)), block=True)
-    out = model.fit_generator(generator=RandomSequence(3), steps_per_epoch=4, epochs=5,
+    out = model.fit_generator(generator=RandomSequence(3), steps_per_epoch=12, epochs=5,
-                              validation_steps=3, callbacks=[tracker_cb])
+                              validation_steps=12, callbacks=[tracker_cb])
-from keras.utils import Sequence
+from keras.utils import Sequence
-    def __init__(self, shape):
+class DummySequence(Sequence):
-        return np.ones(self.shape, dtype=np.uint8) * item
+        return np.ones(self.shape, dtype=np.uint32) * item * self.inner
-        pass
+        self.inner *= 5.0
-        TestSequence([3, 200, 200, 3])), use_multiprocessing=False)
+        DummySequence([3, 200, 200, 3])), use_multiprocessing=False)
-        TestSequence([3, 200, 200, 3])), use_multiprocessing=True)
+        DummySequence([3, 200, 200, 3])), use_multiprocessing=True)
-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=False)
+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=False)
-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]),
+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),
-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=True)
+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)
-        TestSequence([3, 200, 200, 3])), use_multiprocessing=False)
+        DummySequence([3, 200, 200, 3])), use_multiprocessing=False)
-        TestSequence([3, 200, 200, 3])), use_multiprocessing=True)
+        DummySequence([3, 200, 200, 3])), use_multiprocessing=True)
-                      loss='binary_crossentropy')
+        strides: strides in `Conv2D`.
-        strides: strides in `Conv2D`.
+        use_bias: whether to use a bias in `Conv2D`.
-# Importable from root because it's technically not a layer
+
-__version__ = '2.0.8'
+__version__ = '2.0.9'
-      version='2.0.8',
+      version='2.0.9',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.8',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.9',
-            assert np.abs(np.std(rand) - std) < 0.01
+            rand = k.eval(k.random_normal((200, 100), mean=mean, stddev=std))
-            assert np.abs(np.mean(rand)) < 0.01
+            rand = k.eval(k.random_uniform((200, 100), min_val, max_val))
-            assert np.abs(np.mean(rand) - p) < 0.01
+            rand = k.eval(k.random_binomial((200, 100), p))
-        self.is_jupyter = 'ipykernel' in sys.modules
+        self.verbose = verbose
-            if sys.stdout.isatty() or self.is_jupyter:
+            if self._dynamic_display:
-                    avg = np.mean(self.sum_values[k][0] / max(1, self.sum_values[k][1]))
+                    avg = np.mean(
-                    avg = np.mean(self.sum_values[k][0] / max(1, self.sum_values[k][1]))
+                    avg = np.mean(
-        self.verbose = verbose
+        self.verbose = verbose 
-            if sys.stdout.isatty():
+            if sys.stdout.isatty() or self.is_jupyter:
-            while 1:
+            while True:
-                if reporthook:
+                if reporthook is not None:
-                yield chunk
+                if chunk:
-            if self.target is not None and current <= self.target:
+            if self.target is not None and current < self.target:
-
+            else:
-                    reporthook(count, total_size, total_size)
+                    if reporthook:
-    np.random.shuffle(y)
+    indices = np.arange(len(x))
-    np.random.shuffle(labels_test)
+    indices = np.arange(len(x_train))
-    np.random.shuffle(labels)
+    indices = np.arange(len(xs))
-def load_data(path='boston_housing.npz', seed=113, test_split=0.2):
+def load_data(path='boston_housing.npz', test_split=0.2, seed=113):
-        test_split: fraction of the data to reserve as test set.
+'''MNIST classification with TensorFlow's Dataset API.
-            x_o = K.dot(inputs_o, self.kernel_o) + self.bias_o
+            x_i = K.dot(inputs_i, self.kernel_i)
-
+import numpy as np
-                        steps_per_epoch=x_train.shape[0] // batch_size,
+                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),
-                        steps_per_epoch=x_train.shape[0] // batch_size,
+                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),
-    origin = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'
+    origin = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'
-    origin = 'http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'
+    origin = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'
-def process_class_docstring(docstring):
+def count_leading_spaces(s):
-                       docstring)
+    # Strip all leading spaces.
-    docstring = docstring.replace('    ', '')
+    # Reinject code blocks.
-            subblocks.append(process_class_docstring(docstring))
+            subblocks.append(process_docstring(docstring))
-            subblocks.append(process_function_docstring(docstring))
+            subblocks.append(process_docstring(docstring))
-    Consider a custom object `MyObject`
+    Consider a custom object `MyObject` (e.g. a class):
-                                                                  hash=np.random.randint(1e4),
+                                                                  hash=np.random.randint(1e7),
-    return x
+    return tf.convert_to_tensor(x, dtype=dtype)
-                return len(self.x) // self.batch_size
+                return math.ceil(len(self.x) / self.batch_size)
-    return C.alias(x, name=('%s_alias' % (x.name)))
+def identity(x, name=None):
-def identity(x):
+def identity(x, name=None):
-    return tf.identity(x)
+    return tf.identity(x, name)
-def identity(x):
+def identity(x, name=None):
-    return x.copy()
+    return x.copy(name=name)
-    return variable(np.eye(size), dtype, name)
+    if dtype is None:
-                masks.append(K.cast(K.ones_like(input_i), 'bool'))
+                masks.append(K.ones_like(input_i, dtype='bool'))
-                    masks.append(K.cast(K.ones_like(input_i), 'bool'))
+                    masks.append(K.ones_like(input_i, dtype='bool'))
-def ones_like(x, name=None):
+def zeros_like(x, dtype=None, name=None):
-    parts = signature.split('.')
+    parts = re.split('\.(?!\d)', signature)
-(3) wider_net2wider:           0.0271   0.0274   0.0270
+(1) wider_random_pad:          0.0320   0.0317   0.0289
-(5) deeper_random_init:        0.0682   0.0506   0.0468
+(3) deeper_random_init:        0.0682   0.0506   0.0468
-if keras.backend.image_data_format() == 'channels_first':
+if K.image_data_format() == 'channels_first':
-    return x.reshape((-1, ) + input_shape) / 255.
+    return x.astype('float32').reshape((-1,) + input_shape) / 255
-train_y, validation_y = map(preprocess_output, [train_y, validation_y])
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-      'validation_y shape', validation_y.shape)
+print('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)
-    '''Train a simple CNN as teacher model.
+def make_teacher_model(x_train, y_train,
-    return model, history
+    model.fit(x_train, y_train,
-                             validation_data, init, epochs=3):
+def make_wider_student_model(teacher_model,
-    return model, history
+    model.fit(x_train, y_train,
-                              validation_data, init, epochs=3):
+def make_deeper_student_model(teacher_model,
-    return model, history
+    model.fit(x_train, y_train,
-    (3) a wider student model with `Net2WiderNet` initializer
+    (1) a wider student model with `random_pad` initializer
-                             epochs=3)
+    print('\n(1) building wider student model by random padding ...')
-    (3) a deeper student model with `Net2DeeperNet` initializer
+    (3) a deeper student model with `random_init` initializer
-                              epochs=3)
+
-        return sum([K.count_params(p) for p in self.weights])
+        return count_params(self.weights)
-        np.sum([K.count_params(p) for p in set(model.trainable_weights)]))
+    model._check_trainable_weights_consistency()
-    except TypeError:
+    except (TypeError, AttributeError):
-                       r'\n    __\1__\n\n',
+    docstring = re.sub(r'\n(\s+)# (.*)\n',
-                       r'\n    __\1__\n\n',
+    docstring = re.sub(r'\n(\s+)# (.*)\n',
-                               for dim in self.cell.state_size]
+            state_size = self.cell.state_size
-            self.state_spec = InputSpec(shape=(None, self.cell.state_size))
+            state_size = [self.cell.state_size]
-                    ' {}'.format(self.state_spec, self.cell.state_size))
+                    'An initial_state was passed that is not compatible with '
-                `(output_at_t, states_at_t_plus_1)`.
+                `(output_at_t, states_at_t_plus_1)`. The call method of the
-            self.state_spec = InputSpec(shape=(None, self.cell.state_size))
+        self.state_spec = None
-
+        # allow cell (if layer) to build before we set or validate state_spec
-            self.cell.build(step_input_shape)
+            if constants_shape is not None:
-            inputs = inputs[0]
+    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):
-        if initial_state is None:
+        if initial_state is None and constants is None:
-            initial_state = [initial_state]
+        # If any of `initial_state` or `constants` are specified and are Keras
-        for tensor in initial_state:
+        additional_inputs = []
-                                 ' non-Keras tensors')
+                raise ValueError('The initial state or constants of an RNN'
-            self.input_spec = input_spec
+            # Compute the full input spec, including state and constants
-    def call(self, inputs, mask=None, training=None, initial_state=None):
+    def call(self,
-        elif initial_state is not None:
+        if initial_state is not None:
-            step = functools.partial(self.cell.call, training=training)
+            kwargs['training'] = training
-            step = self.cell.call
+            def step(inputs, states):
-        return cls(cell, **config)
+        num_constants = config.pop('num_constants', None)
-            will be incremented by one for each workers.
+            will be incremented by one for each worker.
-                 random_seed=None):
+                 seed=None):
-        self.random_seed = random_seed
+        self.seed = seed
-                    np.random.seed(self.random_seed)
+                    np.random.seed(self.seed)
-                        self.random_seed += 1
+                    if self.seed is not None:
-            x -= np.mean(x, axis=img_channel_axis, keepdims=True)
+            x -= np.mean(x, keepdims=True)
-            x /= (np.std(x, axis=img_channel_axis, keepdims=True) + 1e-7)
+            x /= np.std(x, keepdims=True) + 1e-7
-                info = ' - ETA: %0.fs' % eta
+
-        self.sample_weight_mode = sample_weight_mode
+        self.sample_weight_mode = sample_weight_mode
-        """Configures the learning process.
+        """Configures the model for training.
-            optimizer: str (name of optimizer) or optimizer object.
+            optimizer: String (name of optimizer) or optimizer object.
-            loss: str (name of objective function) or objective function.
+            loss: String (name of objective function) or objective function.
-            metrics: list of metrics to be evaluated by the model
+                If the model has multiple outputs, you can use a different loss
-                passed into `tf.Session.run`.
+                To specify different metrics for different outputs of a
-        self.loss_weights = self.model.loss_weights
+        self.loss_weights = self.model.loss_weights
-        self.targets = self.model.targets
+        self.total_loss = self.model.total_loss
-                the beginning of each epoch. Only used with instances 
+            shuffle: Whether to shuffle the order of the batches at
-                    'pytest-cov'],
+                    'pytest-cov',
-                the beginning of each epoch. Only used with instances 
+            shuffle: Whether to shuffle the order of the batches at
-                keras.utils.Sequence).
+            shuffle: Whether to shuffle the order of the batches at 
-                keras.utils.Sequence).
+            shuffle: Whether to shuffle the order of the batches at 
-data_path = '/Users/fchollet/Downloads/fra-eng/fra.txt'
+data_path = 'fra-eng/fra.txt'
-from keras.layers import Dense, Input, Flatten
+from keras.layers import Dense, Input, GlobalMaxPooling1D
-TEXT_DATA_DIR = BASE_DIR + '/20_newsgroup/'
+GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')
-embedding_matrix = np.zeros((num_words + 1, EMBEDDING_DIM))
+embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))
-x = Flatten()(x)
+x = GlobalMaxPooling1D()(x)
-    for _ in x.shape:
+    for _ in get_variable_shape(x):
-    return np.prod([x.shape[i] for i in range(len(x.shape))])
+    return np.prod(get_variable_shape(x))
-    """Returns the shape tensor or variable as a tuple of int or None entries.
+    """Returns the shape of tensor or variable as a tuple of int or None entries.
-    """Returns the number of scalars in a Keras variable.
+    """Returns the static number of elements in a Keras variable or tensor.
-        x: Keras variable.
+        x: Keras variable or tensor.
-        Integer, the number of scalars in `x`.
+        Integer, the number of elements in `x`, i.e., the product of the
-    return np.prod([shape[i]._value for i in range(len(shape))])
+    return np.prod(get_variable_shape(x))
-            x = np.zeros((1, maxlen, len(chars)))
+            x_pred = np.zeros((1, maxlen, len(chars)))
-                x[0, t, char_indices[char]] = 1.
+                x_pred[0, t, char_indices[char]] = 1.
-            preds = model.predict(x, verbose=0)[0]
+            preds = model.predict(x_pred, verbose=0)[0]
-        print('Epoch {} of {}'.format(epoch, epochs))
+        print('Epoch {}/{}'.format(epoch, epochs))
-        # decoder_target_data is ahead of decoder_target_data by one timestep
+        # decoder_target_data is ahead of decoder_input_data by one timestep
-X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)
+x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)
-        X[i, t, char_indices[char]] = 1
+        x[i, t, char_indices[char]] = 1
-    model.fit(X, y,
+    model.fit(x, y,
-    X_train = np.expand_dims(X_train, axis=1)
+    (x_train, y_train), (x_test, y_test) = mnist.load_data()
-    X_test = np.expand_dims(X_test, axis=1)
+    x_test = (x_test.astype(np.float32) - 127.5) / 127.5
-    num_train, num_test = X_train.shape[0], X_test.shape[0]
+    num_train, num_test = x_train.shape[0], x_test.shape[0]
-        num_batches = int(X_train.shape[0] / batch_size)
+        num_batches = int(x_train.shape[0] / batch_size)
-            image_batch = X_train[index * batch_size:(index + 1) * batch_size]
+            image_batch = x_train[index * batch_size:(index + 1) * batch_size]
-            X = np.concatenate((image_batch, generated_images))
+            x = np.concatenate((image_batch, generated_images))
-            epoch_disc_loss.append(discriminator.train_on_batch(X, [y, aux_y]))
+            epoch_disc_loss.append(discriminator.train_on_batch(x, [y, aux_y]))
-        X = np.concatenate((X_test, generated_images))
+        x = np.concatenate((x_test, generated_images))
-            X, [y, aux_y], verbose=False)
+            x, [y, aux_y], verbose=False)
-    Y = []
+def vectorize_stories(data):
-            pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))
+        inputs.append([word_idx[w] for w in story])
-                                                            query_maxlen)
+inputs_train, queries_train, answers_train = vectorize_stories(train_stories)
-model.compile(optimizer='rmsprop', loss='categorical_crossentropy',
+model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',
-def test_cudnn_rnn_timing():
+def test_cudnn_rnn_timing(rnn_type):
-                    layer = keras.layers.CuDNNGRU(units)
+    for use_cudnn in [True, False]:
-            outputs = layer(inputs)
+                layer = keras.layers.CuDNNGRU(units)
-            model.compile('sgd', 'mse')
+        model = keras.models.Model(inputs, outputs)
-            model.fit(x, y, epochs=4, batch_size=32)
+        x = np.random.random((num_samples, timesteps, input_size))
-            times.append(time.time() - start_time)
+        times.append(time.time() - start_time)
-        keras.backend.clear_session()
+    speedup = times[1] / times[0]
-        print('Epoch {} of {}'.format(epoch + 1, epochs))
+    for epoch in range(1, epochs + 1):
-        print('\nTesting for epoch {}:'.format(epoch + 1))
+            progress_bar.update(index + 1)
-                if all_finished:
+                if all_finished and self.queue.empty():
-    assert len(set(acc) - set(range(100))) == 0, "Output is not the same"
+    assert set(acc) == set(range(100)), "Output is not the same"
-            sys.stdout.write('\r')
+            if sys.stdout.isatty():
-            filepath = self.filepath.format(epoch=epoch, **logs)
+            filepath = self.filepath.format(epoch=epoch + 1, **logs)
-                                  % (epoch, self.monitor, self.best,
+                                  % (epoch + 1, self.monitor, self.best,
-                                  (epoch, self.monitor))
+                                  (epoch + 1, self.monitor))
-                    print('Epoch %05d: saving model to %s' % (epoch, filepath))
+                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))
-            print('Epoch %05d: early stopping' % (self.stopped_epoch))
+            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))
-                            print('\nEpoch %05d: reducing learning rate to %s.' % (epoch, new_lr))
+                            print('\nEpoch %05d: reducing learning rate to %s.' % (epoch + 1, new_lr))
-    os.remove(filepath.format(epoch=3))
+    assert os.path.isfile(filepath.format(epoch=2))
-  + With both methods, student model should immediately perform as well as
+  + With both methods, after 1 epoch, student model should perform as well as
-  + Starting performance of 'net2deeper' is better than 'random-init'.
+  + After 1 epoch, performance of 'net2deeper' is better than 'random-init'.
-- Running on GPU GeForce GTX 980M
+- Tested with TF backend and 'channels_last' image_data_format.
-(5) deeper_net2deeper:         0.032    0.031    0.029
+
-    assert teacher_w1.shape[0] == teacher_b1.shape[0], (
+    assert teacher_w1.shape[3] == teacher_b1.shape[0], (
-    assert new_width > teacher_w1.shape[0], (
+    assert new_width > teacher_w1.shape[3], (
-    n = new_width - teacher_w1.shape[0]
+    n = new_width - teacher_w1.shape[3]
-        new_w1 = np.random.normal(0, 0.1, size=(n, ) + teacher_w1.shape[1:])
+        new_w1 = np.random.normal(0, 0.1, size=teacher_w1.shape[:3] + (n,))
-            teacher_w2.shape[0], n) + teacher_w2.shape[2:])
+        new_w2 = np.random.normal(0, 0.1,
-        index = np.random.randint(teacher_w1.shape[0], size=n)
+        index = np.random.randint(teacher_w1.shape[3], size=n)
-        new_w1 = teacher_w1[index, :, :, :]
+        new_w1 = teacher_w1[:, :, :, index]
-        new_w2 = teacher_w2[:, index, :, :] / factors.reshape((1, -1, 1, 1))
+        new_w2 = teacher_w2[:, :, index, :] / factors.reshape((1, 1, -1, 1))
-    student_w1 = np.concatenate((teacher_w1, new_w1), axis=0)
+    student_w1 = np.concatenate((teacher_w1, new_w1), axis=3)
-        student_w2 = np.concatenate((teacher_w2, new_w2), axis=1)
+        student_w2 = np.concatenate((teacher_w2, new_w2), axis=2)
-        student_w2[:, index, :, :] = new_w2
+        student_w2 = np.concatenate((teacher_w2, new_w2 + noise), axis=2)
-          of shape (filters, num_channel, kh, kw)
+          of shape (kh, kw, num_channel, filters)
-    student_w = np.zeros((filters, filters, kh, kw))
+    kh, kw, num_channel, filters = teacher_w.shape
-        student_w[i, i, (kh - 1) / 2, (kw - 1) / 2] = 1.
+        student_w[(kh - 1) / 2, (kw - 1) / 2, i, i] = 1.
-        generator: a generator function which endlessly yields data
+        generator: a generator function which yields data
-                time.sleep(self.wait_time)
+                all_finished = all([not thread.is_alive() for thread in self._threads])
-            padding=self.padding)
+            padding=self.padding,
-                           input_shape=(num_samples, num_row, num_col, stack_size))
+                for dilation_rate in [(1, 1), (2, 2), (2, 1), (1, 2)]:
-    """Abstract base class for image data iterators.
+    """Base class for image data iterators.
-
+    tf_data_format = 'NHWC'
-    return x
+        if not _has_nchw_support():
-    return kernel
+        if not _has_nchw_support():
-    if data_format not in _DATA_FORMAT_MAP:
+    if data_format not in {'channels_first', 'channels_last'}:
-        x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC
+    x, tf_data_format = _preprocess_conv2d_input(x, data_format)
-
+    if data_format == 'channels_first' and tf_data_format == 'NHWC':
-    output_shape = _preprocess_deconv_output_shape(x, output_shape, data_format)
+    x, tf_data_format = _preprocess_conv2d_input(x, data_format)
-    strides = (1,) + strides + (1,)
+    if tf_data_format == 'NHWC':
-    x = _postprocess_conv2d_output(x, data_format)
+                               padding=padding,
-    x = _preprocess_conv2d_input(x, data_format)
+    x, tf_data_format = _preprocess_conv2d_input(x, data_format)
-    strides = (1,) + strides + (1,)
+    if tf_data_format == 'NHWC':
-    return _postprocess_conv2d_output(x, data_format)
+                               rate=dilation_rate,
-    x = _preprocess_conv2d_input(x, data_format)
+    x, tf_data_format = _preprocess_conv2d_input(x, data_format)
-    strides = (1,) + strides + (1,)
+    if tf_data_format == 'NHWC':
-    return _postprocess_conv2d_output(x, data_format)
+                               rate=dilation_rate,
-    x = _preprocess_conv3d_input(x, data_format)
+    x, tf_data_format = _preprocess_conv3d_input(x, data_format)
-    return _postprocess_conv3d_output(x, data_format)
+        data_format=tf_data_format)
-    output_shape = _preprocess_deconv3d_output_shape(x, output_shape, data_format)
+    x, tf_data_format = _preprocess_conv3d_input(x, data_format)
-    strides = (1,) + strides + (1,)
+    if tf_data_format == 'NDHWC':
-    return _postprocess_conv3d_output(x, data_format)
+                               padding=padding,
-    x = _preprocess_conv2d_input(x, data_format)
+    if tf_data_format == 'NHWC':
-        x = tf.nn.max_pool(x, pool_size, strides, padding=padding)
+        x = tf.nn.max_pool(x, pool_size, strides,
-        x = tf.nn.avg_pool(x, pool_size, strides, padding=padding)
+        x = tf.nn.avg_pool(x, pool_size, strides,
-    return _postprocess_conv2d_output(x, data_format)
+    if data_format == 'channels_first' and tf_data_format == 'NHWC':
-    x = _preprocess_conv3d_input(x, data_format)
+    if tf_data_format == 'NDHWC':
-        x = tf.nn.max_pool3d(x, pool_size, strides, padding=padding)
+        x = tf.nn.max_pool3d(x, pool_size, strides,
-        x = tf.nn.avg_pool3d(x, pool_size, strides, padding=padding)
+        x = tf.nn.avg_pool3d(x, pool_size, strides,
-    return _postprocess_conv3d_output(x, data_format)
+    if data_format == 'channels_first' and tf_data_format == 'NDHWC':
-from keras.layers import Dense, Dropout, Input, Lambda
+from keras.layers import Input, Flatten, Dense, Dropout, Lambda
-def create_base_network(input_dim):
+def create_base_network(input_shape):
-    x = Dense(128, activation='relu')(input)
+    input = Input(shape=input_shape)
-epochs = 20
+input_shape = x_train.shape[1:]
-base_network = create_base_network(input_dim)
+base_network = create_base_network(input_shape)
-input_b = Input(shape=(input_dim,))
+input_a = Input(shape=input_shape)
-        'all_module_functions': [utils],
+        'functions': [utils.to_categorical,
-https://github.com/tensorflow/models/blob/master/slim/nets/inception_resnet_v2.py
+https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py
-https://github.com/tensorflow/models/tree/master/slim#pre-trained-models
+https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models
-        info = ' - %ds' % (now - self.start)
+        info = ' - %.0fs' % (now - self.start)
-                info = ' - ETA: %ds' % eta
+                info = ' - ETA: %0.fs' % eta
-                                                         num_classes=2)
+                                                         num_classes=num_classes)
-        layers.Dense(y_train.shape[-1], activation='softmax')
+        layers.Dense(num_classes, activation='softmax')
-                                                         num_classes=2)
+                                                         num_classes=num_classes)
-    outputs = layers.Dense(y_train.shape[-1], activation='softmax')(x)
+    outputs = layers.Dense(num_classes, activation='softmax')(x)
-                                                         output_shape=(2,),
+                                                         output_shape=(num_classes,),
-        layers.Dense(y_train.shape[-1])
+        layers.Dense(num_classes)
-                                                         num_classes=4)
+                                                         num_classes=num_classes)
-                                                     num_classes=2)
+                                                     num_classes=num_classes)
-    model.add(Dense(2, input_shape=(3,), kernel_constraint=constraints.MaxNorm(1)))
+    model.add(Dense(num_classes, input_shape=(3,), kernel_constraint=constraints.MaxNorm(1)))
-    model.fit(np.random.random((5, 3)), np.random.random((5, 2)),
+    model.fit(np.random.random((5, 3)), np.random.random((5, num_classes)),
-                                                         num_classes=4)
+                                                         num_classes=num_classes)
-        Dense(y_test.shape[-1], activation='softmax')
+        Dense(num_classes, activation='softmax')
-                                                         num_classes=4)
+                                                         num_classes=num_classes)
-    dense_2 = keras.layers.Dense(4,)
+    dense_1 = keras.layers.Dense(4)
-    return signature
+
-    parts = class_signature.split('.')
+
-            class_signature = 'keras.layers.' + '.'.join(parts[3:])
+            signature = 'keras.layers.' + '.'.join(parts[3:])
-    return class_signature
+            signature = 'keras.utils.' + '.'.join(parts[3:])
-num_class = 4
+num_classes = 4
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    model.add(Dense(num_class, name='final_dense'))
+    model.add(Dense(num_classes, name='final_dense'))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-num_class = 2
+num_classes = 2
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-    model.add(Dense(num_class, activation='linear'))
+    model.add(Dense(num_classes, activation='linear'))
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-    model.add(Dense(num_class, activation='linear'))
+    model.add(Dense(num_classes, activation='linear'))
-                yield np.ones([batch_size, input_dim]) * np.nan, np.ones([batch_size, num_class]) * np.nan
+                yield np.ones([batch_size, input_dim]) * np.nan, np.ones([batch_size, num_classes]) * np.nan
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-    model.add(Dense(num_class, activation='softmax'))
+    model.add(Dense(num_classes, activation='softmax'))
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-    model.add(Dense(num_class, activation='softmax'))
+    model.add(Dense(num_classes, activation='softmax'))
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-    model.add(Dense(num_class, activation='softmax'))
+    model.add(Dense(num_classes, activation='softmax'))
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-        model.add(Dense(num_class, activation='softmax'))
+        model.add(Dense(num_classes, activation='softmax'))
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-        model.add(Dense(num_class, activation='softmax'))
+        model.add(Dense(num_classes, activation='softmax'))
-        num_classes=num_class)
+        num_classes=num_classes)
-    output = Dense(num_class, activation='softmax')(hidden)
+    output = Dense(num_classes, activation='softmax')(hidden)
-        num_classes=num_class)
+        num_classes=num_classes)
-    output = Dense(num_class, activation='softmax')(hidden)
+    output = Dense(num_classes, activation='softmax')(hidden)
-        num_classes=num_class)
+        num_classes=num_classes)
-    output2 = Dense(num_class, activation='softmax')(hidden)
+    output1 = Dense(num_classes, activation='softmax')(hidden)
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-    model.add(Dense(num_class, activation='softmax'))
+    model.add(Dense(num_classes, activation='softmax'))
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-    model.add(Dense(num_class, activation='softmax'))
+    model.add(Dense(num_classes, activation='softmax'))
-                                                         num_classes=num_class)
+                                                         num_classes=num_classes)
-    model.add(Dense(num_class, activation='softmax'))
+    model.add(Dense(num_classes, activation='softmax'))
-num_class = 4
+num_classes = 4
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    y = np.random.random((batch_size, num_class))
+    y = np.random.random((batch_size, num_classes))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-    inner.add(Dense(num_class))
+    inner.add(Dense(num_classes))
-    inner.add(Dense(num_class))
+    inner.add(Dense(num_classes))
-num_class = 3
+num_classes = 3
-    classification=True, num_classes=num_class)
+    classification=True, num_classes=num_classes)
-    model.add(Dense(num_class))
+    model.add(Dense(num_classes))
-        assert prediction in range(num_class)
+        assert prediction in range(num_classes)
-    assert proba.shape == (num_test, num_class)
+    assert proba.shape == (num_test, num_classes)
-    string_classes = ['cls{}'.format(x) for x in range(num_class)]
+    string_classes = ['cls{}'.format(x) for x in range(num_classes)]
-    assert proba.shape == (num_test, num_class)
+    assert proba.shape == (num_test, num_classes)
-for filter_index in range(0, 200):
+for filter_index in range(200):
-        for i in range(0, size):
+        for i in range(size):
-            for j in range(0, num_proc):
+            for j in range(num_proc):
-            permutation += list(range(0, len(y_shape) - 2))
+            permutation += list(range(len(y_shape) - 2))
-    label_array = tf.reshape(tf.tile(tf.range(0, label_shape[1]), num_batches_tns),
+    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),
-    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(0, label_shape[0]),
+    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),
-            for i in range(0, num_batches)]
+            for i in range(num_batches)]
-        for k in range(0, num_classes + 1):
+        for k in range(num_classes + 1):
-num_class = 10  # number of class
+num_classes = 10  # number of classes
-    model.add(Dense(num_class, activation='softmax', name='fc2'))
+    model.add(Dense(num_classes, activation='softmax', name='fc2'))
-    model.add(Dense(num_class, activation='softmax', name='fc2'))
+    model.add(Dense(num_classes, activation='softmax', name='fc2'))
-    model.add(Dense(num_class, activation='softmax', name='fc2'))
+    model.add(Dense(num_classes, activation='softmax', name='fc2'))
-        one_hot_matrix = C.ops.one_hot(indices, num_class)
+        num_classes = reference.shape[0]
-        self.num_class = len(classes)
+        self.num_classes = len(classes)
-        print('Found %d images belonging to %d classes.' % (self.samples, self.num_class))
+        print('Found %d images belonging to %d classes.' % (self.samples, self.num_classes))
-            batch_y = np.zeros((len(batch_x), self.num_class), dtype=K.floatx())
+            batch_y = np.zeros((len(batch_x), self.num_classes), dtype=K.floatx())
-    consists in integers in [0, num_class-1].
+    consists in integers in [0, num_classes-1].
-    for i in xrange(filters):
+    for i in range(filters):
-https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md
+https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md
-                    utils.multi_gpu_model]
+                    utils.Sequence],
-        return st[:-2] + ')'
+        signature = st[:-2] + ')'
-        return st + ')'
+        signature = st + ')'
-                                input_shape=(3, 32, 32)))
+                         border_mode='same',
-       'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'
+        >>> from keras.data_utils import _hash_file
-    import numpy as np
+        from skimage.io import imread
-    # and `y_set` are the associated classes.
+        # Here, `x_set` is list of path to the images
-    class CIFAR10Sequence(Sequence):
+        class CIFAR10Sequence(Sequence):
-            self.batch_size = batch_size
+            def __init__(self, x_set, y_set, batch_size):
-            return len(self.x) // self.batch_size
+            def __len__(self):
-            batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
+            def __getitem__(self, idx):
-                   for file_name in batch_x]), np.array(batch_y)
+                return np.array([
-    enqueuer.close()
+        enqueuer = SequenceEnqueuer(...)
-                    utils.Sequence]
+                    utils.Sequence,
-from keras.models import Sequential, Model
+from keras.models import Model
-    return seq
+    input = Input(shape=(input_dim,))
-    sys.setdefaultencoding('utf8')
+import sys
-    except:
+    except TypeError:
-    """Fast GRU implementation backed by CuDNN.
+    """Fast GRU implementation backed by [CuDNN](https://developer.nvidia.com/cudnn).
-    """Fast LSTM implementation backed by CuDNN.
+    """Fast LSTM implementation backed by [CuDNN](https://developer.nvidia.com/cudnn).
-            target = -1
+        info = ' - %ds' % (now - self.start)
-            if self.target is not -1:
+            if self.target is not None:
-            sys.stdout.write(bar)
+            sys.stdout.write(bar)
-                info += ' - %ds' % (now - self.start)
+            if self.target is not None and current <= self.target:
-                info += ((prev_total_width - self.total_width) * ' ')
+                info += (' ' * (prev_total_width - self.total_width))
-                info = '%ds' % (now - self.start)
+            if self.target is None or current >= self.target:
-                sys.stdout.write(info + "\n")
+                info += '\n'
-            self.wait += 1
+def test_EarlyStopping_patience():
-        break
+# Score trained model.
-    48sec per epoch on GTX 1080Ti
+"""Trains a ResNet on the CIFAR10 dataset.
-'''
+Greater than 91% test accuracy (0.52 val_loss) after 50 epochs
-
+# Training params.
-num_classes = 10
+data_augmentation = True
-img_rows, img_cols, channels = x_train.shape[1], x_train.shape[2], x_train.shape[3]
+# Input image dimensions.
-# convert class vectors to binary class matrices
+# Convert class vectors to binary class matrices.
-           kernel_initializer="he_normal", kernel_regularizer=l2(1e-4))(xin)
+# Start model definition.
-# Orig paper uses max pool after 1st conv. Reaches up 87% acc if use_max_pool = True.
+# Orig paper uses max pool after 1st conv.
-    blocks = 3
+    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)
-    for j in range(sub_blocks):
+# Instantiate convolutional base (stack of blocks).
-                   kernel_initializer="he_normal", kernel_regularizer=l2(1e-4))(x)
+        y = Conv2D(num_filters,
-                   kernel_initializer="he_normal", kernel_regularizer=l2(1e-4))(y)
+        y = Conv2D(num_filters,
-                       kernel_initializer="he_normal", kernel_regularizer=l2(1e-4))(x)
+            x = Conv2D(num_filters,
-    filters = 2 * filters
+    num_filters = 2 * num_filters
-model.compile(loss='categorical_crossentropy', optimizer=Adam(),
+outputs = Dense(num_classes,
-# Save model and weights
+# Prepare model model saving directory.
-model_name = "cifar10_resnet_model.hdf5"
+model_name = 'cifar10_resnet_model.h5'
-data_augmentation = True
+# Prepare callbacks for model saving and for learning rate decaying.
-print('Data gen test accuracy:', score[1])
+# Score trained model.
-from keras.layers import embeddings
+from keras.layers import noise
-            pooling.GlobalAveragePooling2D,
+            layers.MaxPooling1D,
-            local.LocallyConnected2D,
+            layers.LocallyConnected1D,
-            recurrent.LSTM,
+            layers.RNN,
-            recurrent.StackedRNNCells,
+            layers.SimpleRNNCell,
-            embeddings.Embedding,
+            layers.Embedding,
-            normalization.BatchNormalization,
+            layers.BatchNormalization,
-    link = 'https://github.com/fchollet/keras/blob/master/' + path + '#L' + str(line)
+    link = ('https://github.com/fchollet/'
-        subblocks.append('<span style="float:right;">' + class_to_source_link(cls) + '</span>')
+        subblocks.append('<span style="float:right;">' +
-    Can only be run on GPU.
+    Can only be run on GPU, with the TensorFlow backend.
-    Can only be run on GPU.
+    Can only be run on GPU, with the TensorFlow backend.
-plt.show()
+''' Trains a ResNet on the CIFAR10 dataset.
-                bar = barstr % (current, self.target)
+                barstr = '%%%dd/%d [' % (numdigits, self.target)
-                self.total_width = len(bar)
+            else:
-            if current >= self.target:
+            if current >= self.target and self.target is not -1:
-            if not force and (now - self.last_update) < self.interval:
+            if (not force and (now - self.last_update) < self.interval and
-            if current < self.target and self.target is not -1:
+            if current <= self.target and self.target is not -1:
-        if self.verbose == 2:
+        elif self.verbose == 2:
-def load_img(path, grayscale=False, target_size=None):
+def load_img(path, grayscale=False, target_size=None,
-            img = img.resize(hw_tuple)
+    if target_size is not None:
-        return inputs * K.cast(boolean_mask, inputs.dtype)
+        return inputs * K.cast(boolean_mask, K.dtype(inputs))
-    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, width=w, height=h)
+    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)
-def text_to_labels(text, num_classes):
+# Translation of characters to unique integer values
-            ret.append(26)
+        ret.append(alphabet.find(char))
-    return not bool(search(in_str))
+    search = re.compile(regex, re.UNICODE).search
-        return 28
+        return len(alphabet) + 1
-        with open(self.monogram_file, 'rt') as f:
+        with codecs.open(self.monogram_file, mode='rt', encoding='utf-8') as f:
-        with open(self.bigram_file, 'rt') as f:
+        with codecs.open(self.bigram_file, mode='rt', encoding='utf-8') as f:
-            self.Y_data[i, 0:len(word)] = text_to_labels(word, self.get_output_size())
+            self.Y_data[i, 0:len(word)] = text_to_labels(word)
-            X_data = np.ones([size, 1, self.img_h, self.img_w])
+            X_data = np.ones([size, 1, self.img_w, self.img_h])
-            X_data = np.ones([size, self.img_h, self.img_w, 1])
+            X_data = np.ones([size, self.img_w, self.img_h, 1])
-                    X_data[i, 0, 0:self.img_h, :] = self.paint_func('')[0, :, :]
+                    X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T
-                    X_data[i, 0:self.img_h, :, 0] = self.paint_func('',)[0, :, :]
+                    X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T
-                    X_data[i, 0, 0:self.img_h, :] = self.paint_func(self.X_text[index + i])[0, :, :]
+                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T
-                    X_data[i, 0:self.img_h, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :]
+                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T
-        if epoch >= 3 and epoch < 6:
+        if 3 <= epoch < 6:
-        elif epoch >= 6 and epoch < 9:
+        elif 6 <= epoch < 9:
-                outstr += ' '
+        outstr = labels_to_text(out_best)
-            pylab.imshow(the_input, cmap='Greys_r')
+            pylab.imshow(the_input.T, cmap='Greys_r')
-        input_shape = (1, img_h, img_w)
+        input_shape = (1, img_w, img_h)
-        input_shape = (img_h, img_w, 1)
+        input_shape = (img_w, img_h, 1)
-    conv_to_rnn_dims = ((img_h // (pool_size ** 2)) * conv_filters, img_w // (pool_size ** 2))
+    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)
-                      shuffle=False,
+                      shuffle=True,
-                    progbar.update(step)
+                    progbar.update(step + 1)
-            if verbose == 1:
+        if verbose == 1:
-                    progbar.update(step)
+                    progbar.update(step + 1)
-    """Get the value from the Sequence at index `i`.
+def get_index(ds, i):
-        _SHARED_DICT[multiprocessing.current_process().pid] = 0
+    return ds[i]
-                    self.executor.apply_async(get_index, (i,)), block=True)
+                    self.executor.apply_async(get_index,
-class DummySequence(Sequence):
+class TestSequence(Sequence):
-        DummySequence([3, 200, 200, 3])), use_multiprocessing=False)
+        TestSequence([3, 200, 200, 3])), use_multiprocessing=False)
-        DummySequence([3, 200, 200, 3])), use_multiprocessing=True)
+        TestSequence([3, 200, 200, 3])), use_multiprocessing=True)
-    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=False)
+    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=False)
-    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),
+    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]),
-    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)
+    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=True)
-    if data_format not in {'channels_first', 'channels_last'}:
+    if data_format not in _DATA_FORMAT_MAP:
-    x = _preprocess_conv2d_input(x, data_format)
+    tf_data_format = _DATA_FORMAT_MAP[data_format]
-    return _postprocess_conv2d_output(x, data_format)
+        data_format=tf_data_format)
-def compute_accuracy(predictions, labels):
+def compute_accuracy(y_true, y_pred):
-    return np.mean(preds == labels)
+    pred = y_pred.ravel() < 0.5
-te_acc = compute_accuracy(pred, te_y)
+y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])
-model.add(layers.Dense(10))
+model.add(layers.Dense(num_classes))
-    cls = Flatten()(Embedding(10, latent_size,
+    cls = Flatten()(Embedding(num_classes, latent_size,
-    aux = Dense(10, activation='softmax', name='auxiliary')(features)
+    aux = Dense(num_classes, activation='softmax', name='auxiliary')(features)
-            sampled_labels = np.random.randint(0, 10, batch_size)
+            sampled_labels = np.random.randint(0, num_classes, batch_size)
-            sampled_labels = np.random.randint(0, 10, 2 * batch_size)
+            sampled_labels = np.random.randint(0, num_classes, 2 * batch_size)
-        sampled_labels = np.random.randint(0, 10, num_test)
+        sampled_labels = np.random.randint(0, num_classes, num_test)
-        sampled_labels = np.random.randint(0, 10, 2 * num_test)
+        sampled_labels = np.random.randint(0, num_classes, 2 * num_test)
-            [i] * 10 for i in range(10)
+            [i] * num_classes for i in range(num_classes)
-                               for r in np.split(generated_images, 10)
+                               for r in np.split(generated_images, num_classes)
-model.add(Dense(10, activation='softmax'))
+model.add(Dense(num_classes, activation='softmax'))
-    for d in range(10):
+    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1
-            dn = (d + inc) % 10
+            inc = random.randrange(1, num_classes)
-digit_indices = [np.where(y_train == i)[0] for i in range(10)]
+digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]
-digit_indices = [np.where(y_test == i)[0] for i in range(10)]
+digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]
-    x_train_out = layers.Dense(classes,
+    x_train_out = layers.Dense(num_classes,
-classes = 10
+num_classes = 10
-y_train_batch = tf.one_hot(y_train_batch, classes)
+y_train_batch = tf.one_hot(y_train_batch, num_classes)
-                                classes)
+                                num_classes)
-    """Quick fix for Python2, otherwise, it cannot be pickled.
+
-    return ds[i]
+    global _SHARED_SEQUENCE
-                                              (self.sequence, i)), block=True)
+                    self.executor.apply_async(get_index, (i,)), block=True)
-class TestSequence(Sequence):
+class DummySequence(Sequence):
-        TestSequence([3, 200, 200, 3])), use_multiprocessing=False)
+        DummySequence([3, 200, 200, 3])), use_multiprocessing=False)
-        TestSequence([3, 200, 200, 3])), use_multiprocessing=True)
+        DummySequence([3, 200, 200, 3])), use_multiprocessing=True)
-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=False)
+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=False)
-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]),
+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),
-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=True)
+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)
-            recurrent.Recurrent,
+            recurrent.RNN,
-    # Arguments:
+    Used to implement efficient stacked RNNs.
-            This argument (or alternatively, the keyword argument `input_shape`)
+            This argument (or alternatively,
-    y = layer(x)
+        # First, let's define a RNN Cell, as a layer subclass.
-        super(SimpleRNN, self).__init__(cell, **kwargs)
+        super(SimpleRNN, self).__init__(cell,
-        super(GRU, self).__init__(cell, **kwargs)
+        super(GRU, self).__init__(cell,
-        super(LSTM, self).__init__(cell, **kwargs)
+        super(LSTM, self).__init__(cell,
-            (np.logical_not(preds) & np.logical_not(labels)).sum()) / float(labels.size)
+    return np.mean(preds == labels)
-model.compile(loss=contrastive_loss, optimizer=rms)
+model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])
-        for v in model.nodes_by_depth.values():
+        nodes_by_depth = model.nodes_by_depth.values()
-decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)
+# We set up our decoder to return full output sequences,
-# 3) Append the target token and repeat
+# 3) Repeat with the current target token and current states
-                               initial_state=decoder_states)
+decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]
-    decoder_outputs)
+    [decoder_inputs] + decoder_states_inputs,
-        output_tokens = decoder_model.predict([target_seq] + states_value)
+        output_tokens, h, c = decoder_model.predict(
-        char_vector[0, 0, sampled_token_index] = 1.
+        # Update the target sequence (of length 1).
-        target_seq = np.concatenate([target_seq, char_vector], axis=1)
+        # Update states
-    if isinstance(n, list):
+    if isinstance(n, int):
-        n = tuple([None for _ in range(len(shape) - len(n))]) + n
+        n = tuple([1 for _ in range(len(shape) - len(n))]) + n
-        condition: scalar tensor (`int` or `bool`).
+        condition: tensor (`int` or `bool`).
-            return else_expression
+    cond_ndim = ndim(condition)
-                else_expression_fn)
+        # tf.where needs its condition tensor
-
+        # non scalar
-        return self.noise_shape
+    def _get_noise_shape(self, inputs):
-        config = {'rate': self.rate}
+        config = {'rate': self.rate,
-        raise NotImplementedError
+        pass
-    num_samples = 2
+    filters = 2
-            input_shape[1:], self.target_shape)
+        if None in input_shape[1:]:
-        return K.reshape(inputs, (-1,) + target_shape)
+        return K.reshape(inputs, (K.shape(inputs)[0],) + self.target_shape)
-                         cache_subdir='models')
+                         cache_subdir='models',
-                                    md5_hash='e693bd0210a403b3192acc6073ad2e96')
+                                    file_hash='e693bd0210a403b3192acc6073ad2e96')
-                                    md5_hash='d19885ff4a710c122648d3b5c3b684e4')
+                                    file_hash='d19885ff4a710c122648d3b5c3b684e4')
-                md5_hash='9a0d58056eeedaa3f26cb7ebd46da564')
+                file_hash='9a0d58056eeedaa3f26cb7ebd46da564')
-                md5_hash='bcbd6486424b2319ff4ef7d526e38f63')
+                file_hash='bcbd6486424b2319ff4ef7d526e38f63')
-                                    cache_subdir='models')
+                                    cache_subdir='models',
-                                    cache_subdir='models')
+                                    cache_subdir='models',
-                                    cache_subdir='models')
+                                    cache_subdir='models',
-                                    cache_subdir='models')
+                                    cache_subdir='models',
-                                    cache_subdir='models')
+                                    cache_subdir='models',
-                                    cache_subdir='models')
+                                    cache_subdir='models',
-    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/imdb.npz')
+    path = get_file(path,
-                    origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json')
+                    origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json',
-    path = get_file(path, origin='https://s3.amazonaws.com/img-datasets/mnist.npz')
+    path = get_file(path,
-    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters.npz')
+    path = get_file(path,
-    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters_word_index.json')
+    path = get_file(path,
-          name=None, dtype=K.floatx(), sparse=False,
+          name=None, dtype=None, sparse=False,
-                initial_states[0] = T.unbroadcast(initial_states[0], 1)
+                initial_states[0] = T.unbroadcast(initial_states[0], 0, 1)
-    return -K.mean(y_true * y_pred, axis=-1)
+    return -K.sum(y_true * y_pred, axis=-1)
-3 seconds per epoch on a Titan X GPU
+Gets to 97.2% test accuracy after 20 epochs.
-                be equal to the number of unique samples if your dataset
+                be equal to the number of unique samples of your dataset
-plt.show()
+    uses_learning_phase = False
-            # Theano likes to make shape==1 dimensions in the initial states (outputs_info) broadcastable
+            # Theano likes to make shape==1 dimensions
-    """Apply `y . w + b` for every temporal slice y of x.
+class StackedRNNCells(Layer):
-        Output tensor.
+    # Arguments:
-    ```
+    def __init__(self, cells, **kwargs):
-        return_sequences: Boolean. Whether to return the last output
+        cell: A RNN cell instance. A RNN cell is a class that has:
-            resulting in a slightly reduced regularization.
+
-    def __init__(self, return_sequences=False,
+    def __init__(self, cell,
-        super(Recurrent, self).__init__(**kwargs)
+        if isinstance(cell, (list, tuple)):
-        self.implementation = implementation
+
-        self.recurrent_dropout = 0
+        if hasattr(self.cell.state_size, '__len__'):
-            output_shape = (input_shape[0], input_shape[1], self.units)
+            output_shape = (input_shape[0], input_shape[1], output_dim)
-            output_shape = (input_shape[0], self.units)
+            output_shape = (input_shape[0], output_dim)
-            state_shape = [(input_shape[0], self.units) for _ in self.states]
+            state_shape = [(input_shape[0], output_dim) for _ in self.states]
-        raise NotImplementedError
+    def build(self, input_shape):
-        return []
+        if self.stateful:
-        return inputs
+        if hasattr(self.cell.state_size, '__len__'):
-            return super(Recurrent, self).__call__(inputs, **kwargs)
+            return super(RNN, self).__call__(inputs, **kwargs)
-            output = super(Recurrent, self).__call__(inputs, **kwargs)
+            output = super(RNN, self).__call__(inputs, **kwargs)
-            return super(Recurrent, self).__call__(inputs, **kwargs)
+            return super(RNN, self).__call__(inputs, **kwargs)
-                                             preprocessed_input,
+
-
+        # Properly set learning phase
-                           for _ in self.states]
+            if hasattr(self.cell.state_size, '__len__'):
-                K.set_value(state, np.zeros((batch_size, self.units)))
+            if hasattr(self.cell.state_size, '__len__'):
-                if value.shape != (batch_size, self.units):
+                if hasattr(self.cell.state_size, '__len__'):
-                                     str((batch_size, self.units)) +
+                                     str((batch_size, dim)) +
-        base_config = super(Recurrent, self).get_config()
+                  'unroll': self.unroll}
-    """Fully-connected RNN where the output is to be fed back to input.
+
-        super(SimpleRNN, self).__init__(**kwargs)
+        super(SimpleRNNCell, self).__init__(**kwargs)
-        self.state_spec = InputSpec(shape=(None, self.units))
+        self.state_size = self.units
-        self.kernel = self.add_weight(shape=(self.input_dim, self.units),
+        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),
-            return inputs
+    def _generate_dropout_mask(self, inputs, training=None):
-            h = inputs
+            self._dropout_mask = None
-                h = K.bias_add(h, self.bias)
+            self._recurrent_dropout_mask = None
-            prev_output *= states[2]
+        dp_mask = self._dropout_mask
-            output._uses_learning_phase = True
+            if training is None:
-                return K.dropout(ones, self.dropout)
+class SimpleRNN(RNN):
-            constants.append(K.cast_to_floatx(1.))
+    # Arguments
-            ones = K.tile(ones, (1, self.units))
+    @interfaces.legacy_recurrent_support
-        return constants
+    def call(self, inputs, mask=None, training=None, initial_state=None):
-    """Gated Recurrent Unit - Cho et al. 2014.
+
-        - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)
+        implementation: Implementation mode, either 1 or 2.
-                 activity_regularizer=None,
+                 implementation=1,
-        super(GRU, self).__init__(**kwargs)
+        super(GRUCell, self).__init__(**kwargs)
-        self.state_spec = InputSpec(shape=(None, self.units))
+        self.implementation = implementation
-        self.kernel = self.add_weight(shape=(self.input_dim, self.units * 3),
+        input_dim = input_shape[-1]
-            ones = K.tile(ones, (1, int(input_dim)))
+    def _generate_dropout_mask(self, inputs, training=None):
-            constants.append(dp_mask)
+            self._dropout_mask = [K.in_train_phase(
-            constants.append([K.cast_to_floatx(1.) for _ in range(3)])
+            self._dropout_mask = None
-            constants.append(rec_dp_mask)
+                return K.dropout(ones, self.dropout)
-        return constants
+            self._recurrent_dropout_mask = None
-    def step(self, inputs, states):
+    def call(self, inputs, states, training=None):
-            matrix_x = K.dot(inputs * dp_mask[0], self.kernel)
+        # dropout matrices for input units
-            matrix_inner = K.dot(h_tm1 * rec_dp_mask[0],
+            if 0. < self.recurrent_dropout < 1.:
-            recurrent_h = K.dot(r * h_tm1 * rec_dp_mask[0],
+            recurrent_h = K.dot(r * h_tm1,
-            h._uses_learning_phase = True
+            if training is None:
-                  'recurrent_dropout': self.recurrent_dropout}
+                  'recurrent_dropout': self.recurrent_dropout,
-    [this tutorial](http://deeplearning.net/tutorial/lstm.html).
+class LSTMCell(Layer):
-        - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)
+        implementation: Implementation mode, either 1 or 2.
-    @interfaces.legacy_recurrent_support
+
-                 activity_regularizer=None,
+                 implementation=1,
-        super(LSTM, self).__init__(**kwargs)
+        super(LSTMCell, self).__init__(**kwargs)
-                           InputSpec(shape=(None, self.units))]
+        self.implementation = implementation
-        self.kernel = self.add_weight(shape=(self.input_dim, self.units * 4),
+        input_dim = input_shape[-1]
-            ones = K.tile(ones, (1, int(input_dim)))
+    def _generate_dropout_mask(self, inputs, training=None):
-            constants.append(dp_mask)
+            self._dropout_mask = [K.in_train_phase(
-            constants.append([K.cast_to_floatx(1.) for _ in range(4)])
+            self._dropout_mask = None
-            constants.append(rec_dp_mask)
+                return K.dropout(ones, self.dropout)
-            z += K.dot(h_tm1 * rec_dp_mask[0], self.recurrent_kernel)
+            if 0. < self.dropout < 1.:
-            h._uses_learning_phase = True
+            if training is None:
-                  'recurrent_dropout': self.recurrent_dropout}
+                  'recurrent_dropout': self.recurrent_dropout,
-
+
-                        batch_input_shape=(num_samples, timesteps, embedding_dim))
+                        batch_input_shape=(num_samples,
-    for mode in [0, 1, 2]:
+    for unroll in [True, False]:
-                           'implementation': mode},
+                           'dropout': 0.1,
-               input_shape=(num_samples, timesteps, embedding_dim))
+
-    layer.reset_states()
+
-
+def test_implementation_mode(layer_class):
-                        batch_input_shape=(num_samples, timesteps, embedding_dim),
+                        input_shape=(timesteps, embedding_dim),
-    layer.build((None, None, 2))
+    layer.build((None, None, embedding_dim))
-    assert len(layer.losses) == 4
+    assert len(layer.cell.losses) == 3
-    model.add(recurrent.LSTM(units=5, return_sequences=True, unroll=False))
+    model.add(recurrent.SimpleRNN(units=5, return_sequences=True, unroll=False))
-    model.add(recurrent.LSTM(units=5, return_sequences=True, unroll=True))
+    model.add(recurrent.SimpleRNN(units=5, return_sequences=True, unroll=True))
-        model.add(recurrent.LSTM(units=5, batch_input_shape=(1, 1, 5), unroll=True))
+def test_minimal_rnn_cell_non_layer():
-    backends (but not CNTK). The data format convention used by the model is
+    The model and the weights are compatible with TensorFlow, Theano and
-
+from multiprocessing import Process, Queue
-    assert model.output_shape == (None, 1000)
+    # Create model in a subprocess so that the memory consumed by InceptionResNetV2 will be
-                    reason='InceptionResNetV2 is not supported on CNTK')
+    def target(queue):
-    assert model.output_shape == (None, 1536, None, None)
+    p = Process(target=target, args=(queue,))
-
+    p = Process(target=target, args=(queue,))
-    assert model.output_shape == (None, 1536)
+    def target(queue):
-    K.set_image_data_format(global_image_data_format)
+    def target(queue, input_shape):
-    return labels[predictions.ravel() < 0.5].mean()
+    preds = predictions.ravel() < 0.5
-        `(batch_size, channels)`
+        `(batch_size, features)`
-        `(batch_size, channels)`
+        `(batch_size, features)`
-        x: A tenor or variable to compute the activation function for.
+        x: A tensor or variable to compute the activation function for.
-        if original_backend and K.backend() != original_backend:
+        if _need_convert_kernel(original_backend):
-    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)
+    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, width=w, height=h)
-            X_data = np.ones([size, 1, self.img_w, self.img_h])
+            X_data = np.ones([size, 1, self.img_h, self.img_w])
-            X_data = np.ones([size, self.img_w, self.img_h, 1])
+            X_data = np.ones([size, self.img_h, self.img_w, 1])
-                    X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T
+                    X_data[i, 0, 0:self.img_h, :] = self.paint_func('')[0, :, :]
-                    X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T
+                    X_data[i, 0:self.img_h, :, 0] = self.paint_func('',)[0, :, :]
-                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T
+                    X_data[i, 0, 0:self.img_h, :] = self.paint_func(self.X_text[index + i])[0, :, :]
-                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T
+                    X_data[i, 0:self.img_h, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :]
-            pylab.imshow(the_input.T, cmap='Greys_r')
+            pylab.imshow(the_input, cmap='Greys_r')
-        input_shape = (1, img_w, img_h)
+        input_shape = (1, img_h, img_w)
-        input_shape = (img_w, img_h, 1)
+        input_shape = (img_h, img_w, 1)
-    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)
+    conv_to_rnn_dims = ((img_h // (pool_size ** 2)) * conv_filters, img_w // (pool_size ** 2))
-        line_length = line_length or 100
+        line_length = line_length or 98
-    cntk_shape = [C.InferredDimension if s is None else s for s in shape]
+    dynamic_dimension = C.FreeDimension if _get_cntk_version() >= 2.2 else C.InferredDimension
-    return C.times(one_hot_matrix, reference, output_rank=len(reference.shape) - 1)
+    if _get_cntk_version() >= 2.2:
-    new_shape = tuple(shape[nones:])
+    new_shape = shape[nones:]
-    if shape.count(C.InferredDimension) > 1:
+    if shape.count(C.InferredDimension) > 1 or shape.count(C.FreeDimension) > 1:
-        shape = tuple(shape)
+        shape = [C.InferredDimension if _ == C.FreeDimension else _ for _ in shape]
-            return C.user_function(ReshapeBatch(x, shape[1:]))
+            return _reshape_batch(x, shape)
-    if n is C.InferredDimension:
+    if n is C.InferredDimension or n is C.FreeDimension:
-                if i != p and p != C.InferredDimension:
+                if i != p and p != C.InferredDimension and p != C.FreeDimension:
-        x = _padding(x, padding, 0)
+        if hasattr(C, 'pad'):
-        x = _padding(x, padding, 1)
+        if hasattr(C, 'pad'):
-            x = _padding(x, padding[1], 2)
+            if hasattr(C, 'pad'):
-            x = _padding(x, padding[1], 3)
+            if hasattr(C, 'pad'):
-            x = _padding(x, padding[1], 1)
+            if hasattr(C, 'pad'):
-            x = _padding(x, padding[1], 2)
+            if hasattr(C, 'pad'):
-            x = _padding(x, padding[2], 3)
+            if hasattr(C, 'pad'):
-            x = _padding(x, padding[2], 4)
+            if hasattr(C, 'pad'):
-            x = _padding(x, padding[2], 2)
+            if hasattr(C, 'pad'):
-            x = _padding(x, padding[2], 3)
+            if hasattr(C, 'pad'):
-                    reason='cntk does not support dropout yet')
+        config = config.copy()
- 
+
- 
+
-     
+
-
+ 
-            _initialize_variables()
+            variables = tf.global_variables()
-
+        global tf, projector
-embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))
+embedding_matrix = np.zeros((num_words + 1, EMBEDDING_DIM))
-    """Callback that terminates training when a NaN loss is encountered."""
+    """Callback that terminates training when a NaN loss is encountered.
-                stop = self.data.shape[0]
+                stop = self.shape[0]
-        for fname in files:
+        for fname in sorted(files):
-        assert sorted(dir_iterator.filenames) == sorted(filenames)
+        assert dir_iterator.filenames == sorted(filenames)
-    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)
+    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)
-    tf_dtype = _convert_string_dtype(dtype)
+    tf_dtype = tf.as_dtype(dtype)
-    tf_dtype = _convert_string_dtype(dtype)
+    tf_dtype = tf.as_dtype(dtype)
-    tf_dtype = _convert_string_dtype(dtype)
+    tf_dtype = tf.as_dtype(dtype)
-    tf_dtype = _convert_string_dtype(dtype)
+    tf_dtype = tf.as_dtype(dtype)
-    tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])
+    tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])
-            tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])
+            tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])
-
+    def test_variable_support_bool_dtype(self):
-def preprocess_input(x, data_format=None):
+def preprocess_input(x, data_format=None, mode='caffe'):
-from ..applications.imagenet_utils import decode_predictions
+from . import imagenet_utils
-    return x
+    return imagenet_utils.preprocess_input(x, mode='tf')
-    return x
+    """Preprocesses a numpy array encoding a batch of images.
-from ..applications.imagenet_utils import decode_predictions
+from . import imagenet_utils
-    return x
+    """Preprocesses a numpy array encoding a batch of images.
-    return x
+    """Preprocesses a numpy array encoding a batch of images.
-BASE_WEIGHT_URL = 'https://github.com/myutwo150/keras-inception-resnet-v2/releases/download/v0.1/'
+BASE_WEIGHT_URL = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.7/'
-                        validation_data=(x_test, y_test))
+                        validation_data=(x_test, y_test),
-
+                                                   batch_size=batch_size,
-                                      steps=x_test.shape[0] // batch_size)
+                                                   batch_size=batch_size,
-class Iterator(object):
+class Iterator(Sequence):
-        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)
+        self.index_array = None
-    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):
+    def _flow_index(self):
-                np.random.seed(seed + self.total_batches_seen)
+            if self.seed is not None:
-                    index_array = np.random.permutation(n)
+                self._set_index_array()
-                current_batch_size = batch_size
+            current_index = (self.batch_index * self.batch_size) % self.n
-                   current_index, current_batch_size)
+            yield self.index_array[current_index:
-        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())
+    def _get_batches_of_transformed_samples(self, index_array):
-            for i in range(current_batch_size):
+            for i, j in enumerate(index_array):
-                                                                  index=current_index + i,
+                                                                  index=j,
-        batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())
+    def _get_batches_of_transformed_samples(self, index_array):
-            for i in range(current_batch_size):
+            for i, j in enumerate(index_array):
-                                                                  index=current_index + i,
+                                                                  index=j,
-            self.X,self.y = x_set,y_set
+            self.x, self.y = x_set, y_set
-            return len(self.X) // self.batch_size
+            return len(self.x) // self.batch_size
-            batch_y = self.y[idx*self.batch_size:(idx+1)*self.batch_size]
+        def __getitem__(self, idx):
-                resize(imread(file_name), (200,200))
+                resize(imread(file_name), (200, 200))
-class TestImage:
+class TestImage(object):
-        img_w = img_h = 20
+        cls.img_w = cls.img_h = 20
-            imarray = np.random.rand(img_w, img_h, 3) * variance + bias
+            bias = np.random.rand(cls.img_w, cls.img_h, 1) * 64
-            imarray = np.random.rand(img_w, img_h, 1) * variance + bias
+            imarray = np.random.rand(cls.img_w, cls.img_h, 1) * variance + bias
-                assert x.shape[1:] == images.shape[1:]
+                                       shuffle=False, save_to_dir=str(tmpdir),
-        assert(sorted(dir_iterator.filenames) == sorted(filenames))
+        assert len(dir_iterator.class_indices) == num_classes
-                        validation_data=(x_test, y_test))
+                        validation_data=(x_test, y_test),
-
+                                                   batch_size=batch_size,
-                                      steps=x_test.shape[0] // batch_size)
+                                                   batch_size=batch_size,
-class Iterator(object):
+class Iterator(Sequence):
-        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)
+        self.index_array = None
-    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):
+    def _flow_index(self):
-                np.random.seed(seed + self.total_batches_seen)
+            if self.seed is not None:
-                    index_array = np.random.permutation(n)
+                self._set_index_array()
-                current_batch_size = batch_size
+            current_index = (self.batch_index * self.batch_size) % self.n
-                   current_index, current_batch_size)
+            yield self.index_array[current_index:
-        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())
+    def _get_batches_of_transformed_samples(self, index_array):
-            for i in range(current_batch_size):
+            for i, j in enumerate(index_array):
-                                                                  index=current_index + i,
+                                                                  index=j,
-        batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())
+    def _get_batches_of_transformed_samples(self, index_array):
-            for i in range(current_batch_size):
+            for i, j in enumerate(index_array):
-                                                                  index=current_index + i,
+                                                                  index=j,
-            self.X,self.y = x_set,y_set
+            self.x, self.y = x_set, y_set
-            return len(self.X) // self.batch_size
+            return len(self.x) // self.batch_size
-            batch_y = self.y[idx*self.batch_size:(idx+1)*self.batch_size]
+        def __getitem__(self, idx):
-                resize(imread(file_name), (200,200))
+                resize(imread(file_name), (200, 200))
-class TestImage:
+class TestImage(object):
-        img_w = img_h = 20
+        cls.img_w = cls.img_h = 20
-            imarray = np.random.rand(img_w, img_h, 3) * variance + bias
+            bias = np.random.rand(cls.img_w, cls.img_h, 1) * 64
-            imarray = np.random.rand(img_w, img_h, 1) * variance + bias
+            imarray = np.random.rand(cls.img_w, cls.img_h, 1) * variance + bias
-                assert x.shape[1:] == images.shape[1:]
+                                       shuffle=True, save_to_dir=str(tmpdir),
-        assert(sorted(dir_iterator.filenames) == sorted(filenames))
+        assert len(dir_iterator.class_indices) == num_classes
-        channel_shift_range: shift range for each channels.
+        channel_shift_range: shift range for each channel.
-    v = np.float32([value])
+    v = np.asarray(value)
-            epochs: integer, the number of epochs to train the model.
+            epochs: integer. Number of epochs to train the model.
-                (useful for resuming a previous training run)
+            initial_epoch: Epoch at which to start training
-                (useful for resuming a previous training run)
+                (useful for resuming a previous training run).
-        ax.text(1, 3, 'Inital trajectory', fontsize=20)
+        ax.text(1, 3, 'Initial trajectory', fontsize=20)
-        # this font list works in Centos 7
+        # this font list works in CentOS 7
-'''Trains a LSTM on the IMDB sentiment classification task.
+'''Trains an LSTM model on the IMDB sentiment classification task.
-HRNNs can learn across multiple levels of temporal hiearchy over a complex sequence.
+HRNNs can learn across multiple levels of temporal hierarchy over a complex sequence.
-                       'supported for all TF ops.')
+                       'supported for all TensorFlow ops.')
-(classication of newsgroup messages into 20 different categories).
+(classification of newsgroup messages into 20 different categories).
-        filters: list of integers, the filterss of 3 conv layer at main path
+        filters: list of integers, the filters of 3 conv layer at main path
-        filters: list of integers, the filterss of 3 conv layer at main path
+        filters: list of integers, the filters of 3 conv layer at main path
-    # Similiar as in_train_phase, use element_select as workaround.
+    # Similar as in_train_phase, use element_select as workaround.
-                         '%d cntk dynamic axis, this is not expected, plesae '
+                         '%d cntk dynamic axis, this is not expected, please '
-            # no collaps, then first need to padding the shape
+            # no collapse, then first need to padding the shape
-                         'rnn with non-static axis, plesae try '
+                         'rnn with non-static axis, please try '
-# used for generatic graph-specific string UIDs
+# used for generic graph-specific string UIDs
-# tensorflow has a native implemenation, but it uses sparse tensors
+# TensorFlow has a native implementation, but it uses sparse tensors
-# in tensorflow's CTC implementation
+# in TensorFlow's CTC implementation
-    return T.patternbroadcast(x, broatcastable)
+def pattern_broadcast(x, broadcastable):
-# Note that tensorflow's native CTC code is significantly
+# Note that TensorFlow's native CTC code is significantly
-            count samples seens or steps (batches) seen.
+            count samples seen or steps (batches) seen.
-            # Infering the output shape is only relevant for Theano.
+            # Inferring the output shape is only relevant for Theano.
-    def reccurent_conv(self, x, w):
+    def recurrent_conv(self, x, w):
-        h_i = self.reccurent_conv(h_tm1 * rec_dp_mask[0],
+        h_i = self.recurrent_conv(h_tm1 * rec_dp_mask[0],
-        h_f = self.reccurent_conv(h_tm1 * rec_dp_mask[1],
+        h_f = self.recurrent_conv(h_tm1 * rec_dp_mask[1],
-        h_c = self.reccurent_conv(h_tm1 * rec_dp_mask[2],
+        h_c = self.recurrent_conv(h_tm1 * rec_dp_mask[2],
-        h_o = self.reccurent_conv(h_tm1 * rec_dp_mask[3],
+        h_o = self.recurrent_conv(h_tm1 * rec_dp_mask[3],
-    to be fed to a LSTM layer.
+    to be fed to an LSTM layer.
-        classes: Optional list of strings, names of sudirectories
+        classes: Optional list of strings, names of subdirectories
-            encodes the probabibily to sample a word of rank i.
+            encodes the probability to sample a word of rank i.
-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')
+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow backend')
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-    warnings.warn('Could not import the Tensorflow backend.')
+    warnings.warn('Could not import the TensorFlow backend.')
-        # so create a seperate test case for valid lable input
+        # so create a separate test case for valid label input
-        # Test invalid use casess
+        # Test invalid use cases
-def test_layer_sharing_at_heterogenous_depth():
+def test_layer_sharing_at_heterogeneous_depth():
-def test_layer_sharing_at_heterogenous_depth_with_concat():
+def test_layer_sharing_at_heterogeneous_depth_with_concat():
-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TF')
+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')
-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')
+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow backend')
-    # test whether impromtu input_shape breaks the model
+    # test whether impromptu input_shape breaks the model
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-                    reason='Requires tensorflow backend')
+                    reason='Requires TensorFlow backend')
-                    reason="Requires tensorflow backend")
+                    reason="Requires TensorFlow backend")
-        return loss
+            return -loss[0]
-    def evaluate(self, x, y,
+    def evaluate(self, x=None, y=None,
-        validation_data=(x_test, x_test))
+        validation_data=(x_test, None))
-        validation_data=(x_test, x_test))
+        validation_data=(x_test, None))
-        dropout: wether to apply dropout (same dropout mask
+        dropout: whether to apply dropout (same dropout mask
-def list_pictures(directory, ext='jpg|jpeg|bmp|png'):
+def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):
-train_model = keras.models.Model(inputs=x_train_input, outputs=x_train_out)
+model_input = layers.Input(tensor=x_train_batch)
-x_train_input = layers.Input(tensor=x_train_batch, batch_shape=x_batch_shape)
+x_train_input = layers.Input(tensor=x_train_batch)
-__version__ = '2.0.7'
+__version__ = '2.0.8'
-      version='2.0.7',
+      version='2.0.8',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.7',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.8',
-(there is still a lot of margin for parameter tuning).
+Gets to ~99.1% validation accuracy after 5 epochs
-
+import keras
-                       'TensorFlow backend for the time being, '
+                       'TensorFlow backend, '
-    x = layers.Dense(128, activation='relu')(x)
+    x = layers.Dense(512, activation='relu')(x)
-epochs = 78
+epochs = 5
-                    metrics=['accuracy'])
+train_model = keras.models.Model(inputs=x_train_input, outputs=x_train_out)
-x_test_inp = layers.Input(batch_shape=(None,) + (x_test.shape[1:]))
+x_test_inp = layers.Input(shape=(x_test.shape[1:]))
-test_model = Model(inputs=x_test_inp, outputs=test_out)
+test_model = keras.models.Model(inputs=x_test_inp, outputs=test_out)
-test_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
+test_model.compile(optimizer='rmsprop',
-loss, acc = test_model.evaluate(x_test, np_utils.to_categorical(y_test), classes)
+loss, acc = test_model.evaluate(x_test,
-                             "provided, and cannot be a generator.")
+            raise ValueError('If printing histograms, validation_data must be '
-      install_requires=['theano', 'pyyaml', 'six'],
+      install_requires=['numpy>=1.9.1',
-    value = np.asarray(value)
+    value = np.asarray(value, dtype=dtype(x))
-            value = np.asarray(value)
+            value = np.asarray(value, dtype=dtype(x))
-                metric_name = self.output_layers[layer_index].name + '_' + metric_name
+                metric_name = self.output_names[layer_index] + '_' + metric_name
-        # the inner layer has update ops that depend on it's inputs (as opposed
+        # the inner layer has update ops that depend on its inputs (as opposed
-            self.iterations = K.variable(0., name='iterations')
+            self.iterations = K.variable(0, dtype='int64', name='iterations')
-        self.updates = []
+        self.updates = [K.update_add(self.iterations, 1)]
-
+            lr *= (1. / (1. + self.decay * K.cast(self.iterations,
-        shapes = [K.get_variable_shape(p) for p in params]
+        shapes = [K.int_shape(p) for p in params]
-            self.iterations = K.variable(0., name='iterations')
+            self.iterations = K.variable(0, dtype='int64', name='iterations')
-        accumulators = [K.zeros(K.get_variable_shape(p), dtype=K.dtype(p)) for p in params]
+        accumulators = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]
-        self.updates = []
+        self.updates = [K.update_add(self.iterations, 1)]
-            self.updates.append(K.update_add(self.iterations, 1))
+            lr *= (1. / (1. + self.decay * K.cast(self.iterations,
-            self.iterations = K.variable(0., name='iterations')
+            self.iterations = K.variable(0, dtype='int64', name='iterations')
-        shapes = [K.get_variable_shape(p) for p in params]
+        shapes = [K.int_shape(p) for p in params]
-        self.updates = []
+        self.updates = [K.update_add(self.iterations, 1)]
-            self.updates.append(K.update_add(self.iterations, 1))
+            lr *= (1. / (1. + self.decay * K.cast(self.iterations,
-            self.iterations = K.variable(0., name='iterations')
+            self.iterations = K.variable(0, dtype='int64', name='iterations')
-        shapes = [K.get_variable_shape(p) for p in params]
+        shapes = [K.int_shape(p) for p in params]
-        self.updates = []
+        self.updates = [K.update_add(self.iterations, 1)]
-            self.updates.append(K.update_add(self.iterations, 1))
+            lr *= (1. / (1. + self.decay * K.cast(self.iterations,
-            self.iterations = K.variable(0, name='iterations')
+            self.iterations = K.variable(0, dtype='int64', name='iterations')
-            lr *= (1. / (1. + self.decay * self.iterations))
+            lr *= (1. / (1. + self.decay * K.cast(self.iterations,
-        t = self.iterations + 1
+        t = K.cast(self.iterations, K.floatx()) + 1
-        vs = [K.zeros(K.get_variable_shape(p), dtype=K.dtype(p)) for p in params]
+        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]
-            self.iterations = K.variable(0., name='iterations')
+            self.iterations = K.variable(0, dtype='int64', name='iterations')
-            lr *= (1. / (1. + self.decay * self.iterations))
+            lr *= (1. / (1. + self.decay * K.cast(self.iterations,
-        t = self.iterations + 1
+        t = K.cast(self.iterations, K.floatx()) + 1
-        shapes = [K.get_variable_shape(p) for p in params]
+        shapes = [K.int_shape(p) for p in params]
-            self.iterations = K.variable(0., name='iterations')
+            self.iterations = K.variable(0, dtype='int64', name='iterations')
-        t = self.iterations + 1
+        t = K.cast(self.iterations, K.floatx()) + 1
-        shapes = [K.get_variable_shape(p) for p in params]
+        shapes = [K.int_shape(p) for p in params]
-            self.iterations = K.variable(0., name='iterations')
+            self.iterations = K.variable(0, dtype='int64', name='iterations')
-from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed
+from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed, LSTM
-            if verbose and ins and hasattr(ins[0], 'shape'):
+            if verbose and ins and hasattr(ins[0], 'shape') and hasattr(val_ins[0], 'shape'):
-
+                                                    steps_per_epoch,
-            val_ins = None
+
-                    steps_per_epoch=1, validation_steps=1)
+        # test fit with validation data
-    model.fit_generator(generator=img_gen.next_train(), 
+    model.fit_generator(generator=img_gen.next_train(),
-                        validation_data=img_gen.next_val(), 
+                        epochs=stop_epoch,
-                        callbacks=[viz_cb, img_gen], 
+                        callbacks=[viz_cb, img_gen],
-                                 minibatch_size=32,
+                                 minibatch_size=minibatch_size,
-                        callbacks=[viz_cb, img_gen], initial_epoch=start_epoch)
+    model.fit_generator(generator=img_gen.next_train(), 
-x = Input(batch_shape=(batch_size, original_dim))
+x = Input(shape=(original_dim,))
-    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,
+    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,
-x = Input(batch_shape=(batch_size,) + original_img_size)
+x = Input(shape=original_img_size)
-    epsilon = K.random_normal(shape=(batch_size, latent_dim),
+    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),
-        if data:
+        if data is not None and hasattr(data, '__len__') and len(data):
-                                       'because it has no loss to optimize.')
+                    raise ValueError('The model cannot be compiled '
-            ValueError when `steps` is `None` and the attribute `ins.shape`
+            ValueError: when `steps` is `None` and the attribute `ins.shape`
-    with pytest.raises(RuntimeError):
+    with pytest.raises(ValueError):
-        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp'}
+        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm'}
-        A sparse tensor representation of the lablels.
+        A sparse tensor representation of the labels.
-    v.constraint = constraint
+    # TODO: move to Variable constructor when supported in public release.
-                        weights='imagenet'):
+                        require_flatten,
-        include_top: whether the model is expected to
+        require_flatten: whether the model is expected to
-    if weights != 'imagenet' and input_shape is not None and len(input_shape) == 3:
+    if weights != 'imagenet' and input_shape and len(input_shape) == 3:
-            if input_shape[0] != 3 and input_shape[0] != 1:
+            if input_shape[0] not in {1, 3}:
-                    'However, it was passed ' + str(input_shape[0]) + ' input channels.')
+                    'However, it was passed an input_shape with ' +
-            if input_shape[-1] != 3 and input_shape[-1] != 1:
+            if input_shape[-1] not in {1, 3}:
-                    'However, it was passed ' + str(input_shape[-1]) + ' input channels.')
+                    'However, it was passed an input_shape with ' +
-    if include_top:
+    if weights == 'imagenet' and require_flatten:
-    else:
+                raise ValueError('When setting`include_top=True` '
-                    raise ValueError('`input_shape` must be a tuple of three integers.')
+                    raise ValueError(
-                                     str(min_size) + 'x' + str(min_size) + ', got '
+                                     str(min_size) + 'x' + str(min_size) + '; got '
-                    raise ValueError('`input_shape` must be a tuple of three integers.')
+                    raise ValueError(
-                                     str(min_size) + 'x' + str(min_size) + ', got '
+                                     str(min_size) + 'x' + str(min_size) + '; got '
-        include_top=include_top,
+        require_flatten=False,
-                                      include_top=include_top or weights,
+                                      require_flatten=include_top,
-                                      include_top=include_top,
+                                      require_flatten=include_top,
-                                      include_top=include_top,
+                                      require_flatten=include_top,
-                                      include_top=include_top,
+                                      require_flatten=include_top,
-                                      include_top=include_top,
+                                      require_flatten=False,
-            include_top=True)
+            require_flatten=True,
-                include_top=False,
+                require_flatten=False,
-                include_top=False)
+                require_flatten=False)
-                include_top=False)
+                require_flatten=False)
-                include_top=False)
+                require_flatten=False)
-        input_shape=None,
+        input_shape=(3, 200, 200),
-        include_top=True,) == (3, None, None)
+        require_flatten=True) == (3, 200, 200)
-        include_top=False) == (None, None, 3)
+        require_flatten=False) == (None, None, 3)
-        include_top=False) == (3, None, None)
+        require_flatten=False) == (3, None, None)
-        include_top=False) == (None, None, 3)
+        require_flatten=False) == (None, None, 3)
-        include_top=False) == (150, 150, 3)
+        require_flatten=False) == (150, 150, 3)
-        include_top=False) == (3, None, None)
+        require_flatten=False) == (3, None, None)
-__version__ = '2.0.6'
+__version__ = '2.0.7'
-      version='2.0.6',
+      version='2.0.7',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.6',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.7',
-            optimizer: str (name of optimizer) or optimizer object.
+            optimizer: String (name of optimizer) or optimizer object.
-            loss: str (name of objective function) or objective function.
+            loss: String (name of objective function) or objective function.
-            metrics: list of metrics to be evaluated by the model
+            metrics: List of metrics to be evaluated by the model
-            sample_weight_mode: if you need to do timestep-wise
+            sample_weight_mode: If you need to do timestep-wise
-            target_tensors: by default, Keras will create placeholders for the
+            target_tensors: By default, Keras will create placeholders for the
-            weighted_metrics: list of metrics to be evaluated and weighted
+            weighted_metrics: List of metrics to be evaluated and weighted
-            **kwargs: when using the Theano/CNTK backends, these arguments
+            **kwargs: When using the Theano/CNTK backends, these arguments
-            batch_size: integer batch size or `None` if not defined.
+            ins: List of tensors to be fed to the Keras function.
-                                 ' is set the batch_size must be None.')
+                                 ' is set, the `batch_size` must be None.')
-                             'please specify ' + steps_name + '.')
+            raise ValueError('Either the input data should have '
-            out_labels: list of strings, display names of
+            ins: List of tensors to be fed to `f`
-            callbacks: list of callbacks to be called during training
+            batch_size: Integer batch size or None if unknown.
-            callback_metrics: list of strings, the display names of the metrics
+            val_ins: List of tensors to be fed to `val_f`
-            initial_epoch: epoch at which to start training
+            initial_epoch: Epoch at which to start training
-                for step_num in range(steps_per_epoch):
+                for step_index in range(steps_per_epoch):
-                    batch_logs['batch'] = step_num
+                    batch_logs['batch'] = step_index
-                    callbacks.on_batch_begin(step_num, batch_logs)
+                    callbacks.on_batch_begin(step_index, batch_logs)
-                    callbacks.on_batch_end(step_num, batch_logs)
+                    callbacks.on_batch_end(step_index, batch_logs)
-    def _predict_loop(self, f, ins, batch_size=32, verbose=0):
+    def _predict_loop(self, f, ins, batch_size=32, verbose=0, steps=None):
-        outs = []
+        num_samples = self._check_num_samples(ins, batch_size,
-                ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]
+            if steps is not None:
-        return outs
+                progbar = Progbar(target=num_samples)
-        if batch_size is None and steps is not None:
+        if steps is not None:
-                f(ins)
+            for step in range(steps):
-
+                    progbar.update(step)
-            index_array = np.arange(samples)
+                progbar = Progbar(target=num_samples)
-            outs[i] /= samples
+            for i in range(len(outs)):
-            epochs: integer, the number of times to iterate
+            batch_size: Integer or `None`.
-            callbacks: list of callbacks to be called during training.
+            callbacks: List of callbacks to be called during training.
-            validation_split: float between 0 and 1:
+            validation_split: Float between 0 and 1:
-            validation_data: data on which to evaluate
+            validation_data: Data on which to evaluate
-            shuffle: boolean, whether to shuffle the training data
+            shuffle: Boolean, whether to shuffle the training data
-            class_weight: optional dictionary mapping
+            class_weight: Optional dictionary mapping
-            sample_weight: optional array of the same length as x, containing
+            sample_weight: Optional array of the same length as x, containing
-            initial_epoch: epoch at which to start training
+            initial_epoch: Epoch at which to start training
-        # backwards compatibility
+        # Backwards compatibility
-
+        if x is None and y is None and steps_per_epoch is None:
-    def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):
+    def evaluate(self, x, y,
-            verbose: verbosity mode, 0 or 1.
+            batch_size: Integer. If unspecified, it will default to 32.
-                               verbose=verbose)
+                               verbose=verbose,
-    def predict(self, x, batch_size=32, verbose=0):
+    def predict(self, x,
-            x: the input data, as a Numpy array
+            x: The input data, as a Numpy array
-            verbose: verbosity mode, 0 or 1.
+            batch_size: Integer. If unspecified, it will default to 32.
-                                  verbose=verbose)
+                                  verbose=verbose, steps=steps)
-                       sample_weight=None, class_weight=None):
+                       sample_weight=None,
-            sample_weight: optional array of the same length as x, containing
+            sample_weight: Optional array of the same length as x, containing
-            class_weight: optional dictionary mapping
+            class_weight: Optional dictionary mapping
-            sample_weight: optional array of the same length as x, containing
+            sample_weight: Optional array of the same length as x, containing
-            generator: a generator or an instance of Sequence (keras.utils.Sequence)
+            generator: A generator or an instance of Sequence (keras.utils.Sequence)
-            validation_data: this can be either
+            epochs: Integer, total number of iterations on the data.
-            class_weight: dictionary mapping class indices to a weight
+            class_weight: Dictionary mapping class indices to a weight
-            workers: maximum number of processes to spin up
+            max_queue_size: Maximum size for the generator queue
-            use_multiprocessing: if True, use process based threading.
+            use_multiprocessing: If True, use process based threading.
-            shuffle: whether to shuffle the data at the beginning of each
+            shuffle: Whether to shuffle the data at the beginning of each
-            initial_epoch: epoch at which to start training
+            initial_epoch: Epoch at which to start training
-    assert out.shape == (10, 4)
+    out = model.predict(None, steps=3)
-    assert out.shape == (10, 4)
+    out = model.predict(None, steps=3)
-        out = model.fit(None, None, epochs=1, batch_size=None, steps_per_epoch=1)
+        with pytest.raises(ValueError):
-        out = model.evaluate(None, None, batch_size=10)
+        with pytest.raises(ValueError):
-        assert out.shape == (10, 4)
+        with pytest.raises(ValueError):
-                    continue
+                    return
-                    continue
+                    return
-        x[:, 2, :, :] -= 123.68
+        if x.ndim == 3:
-        x = x[:, :, :, ::-1]
+        x = x[..., ::-1]
-        x[:, :, :, 2] -= 123.68
+        x[..., 0] -= 103.939
-    x = np.random.uniform(0, 255, (2, 3, 2, 3))
+    # Test image batch
-    out2 = utils.preprocess_input(np.transpose(x, (0, 3, 1, 2)), 'channels_first')
+    out2 = utils.preprocess_input(np.transpose(x, (0, 3, 1, 2)),
-
+                               [output_a_np, output_b_np],
-                      sample_weight_mode=None, target_tensors={'does_not_exist': y2})
+        model.compile(optimizer, loss,
-
+    model.compile(optimizer, loss,
-                               [output_a_np, output_b_np], {y: np.random.random((10, 4)), y1: np.random.random((10, 3))})
+                               [output_a_np, output_b_np],
-        cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.
+        cropping: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.
-            - If tuple of 2 ints:
+                is applied to depth, height, and width.
-                symmetric cropping values for height and width:
+                symmetric cropping values for depth, height, and width:
-            - If tuple of 2 tuples of 2 ints:
+            - If tuple of 3 tuples of 2 ints:
-        elif isinstance(key, int):
+        elif isinstance(key, (int, np.integer)):
-                                           dtype=K.dtype(self.outputs[i]))
+                if target is None or K.is_placeholder(target):
-
+            return
-                          'fallback to auto mode.' % (self.mode),
+                          'fallback to auto mode.' % mode,
-            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):
+            if 'acc' in self.monitor:
-                                                                      k=3))
+    success_result = K.eval(
-                                                                      k=2))
+    partial_result = K.eval(
-                                                                      k=1))
+    failure_result = K.eval(
-def test_softmax():
+def test_get_fn():
-    # cntk can't rebind the input shape, so create the model again to test different batch size
+    # cntk can't rebind the input shape, so create the model again to
-    # cntk can't rebind the input shape, so create the model again to test different batch size
+    # cntk can't rebind the input shape, so create the model again to
-        if isinstance(input, list) and inputs == []:
+        if isinstance(inputs, list) and inputs == []:
-            container_nodes.add(node_key)
+            container_nodes.add(self._node_key(layer, node_index))
-                    node_key = layer.name + '_ib-' + str(node_index)
+                    node_key = self._node_key(layer, node_index)
-                    node_key = layer.name + '_ib-' + str(node_index)
+                    node_key = self._node_key(layer, node_index)
-                node_key = layer.name + '_ib-' + str(original_node_index)
+                node_key = self._node_key(layer, original_node_index)
-                node_key = layer.name + '_ib-' + str(original_node_index)
+                node_key = self._node_key(layer, original_node_index)
-                            new_node_index = node_conversion_map.get(node_key, 0)
+
-            node_key = layer.name + '_ib-' + str(node_index)
+
-            node_key = layer.name + '_ib-' + str(node_index)
+
-                sample_weight_mode=None, weighted_metrics=None, **kwargs):
+                sample_weight_mode=None, weighted_metrics=None,
-        skip_indices = []
+        skip_target_indices = []
-                self._feed_loss_fns.append(self.loss_functions[i])
+                skip_target_indices.append(i)
-                if i in skip_indices:
+                if i in skip_target_weighing_indices:
-                if i in skip_indices:
+                if i in skip_target_weighing_indices:
-                if i in skip_indices:
+                if i in skip_target_weighing_indices:
-            if i not in skip_indices:
+            if i not in skip_target_weighing_indices:
-                if i in skip_indices:
+                if i in skip_target_indices:
-                if i in skip_indices:
+                if i in skip_target_indices:
-            if i not in skip_indices:
+            if i not in skip_target_weighing_indices:
-                    reason="cntk does not support external loss yet")
+                    reason='cntk does not support external loss yet')
-            if input_shape[0] != 3 or input_shape[0] != 1:
+            if input_shape[0] != 3 and input_shape[0] != 1:
-            if input_shape[-1] != 3 or input_shape[-1] != 1:
+            if input_shape[-1] != 3 and input_shape[-1] != 1:
-    text = text.translate(maketrans(filters, split * len(filters)))
+
-from keras.preprocessing.text import Tokenizer, one_hot, hashing_trick
+from keras.preprocessing.text import Tokenizer, one_hot, hashing_trick, text_to_word_sequence
-                                   'All layer names should be unique.')
+                                   'All layer names should be unique. '
-
+
-                                 ' arrays but instead got '
+                                 ' array(s), but instead got '
-        layer = None
+
-            raise ValueError('No such layer: ' + name)
+
-from keras.layers import Dense, Dropout, InputLayer
+from keras.layers import Dense, Dropout, Conv2D, InputLayer
-from keras.engine import Input, Layer, get_source_inputs
+from keras.engine import Input, Layer, topology, get_source_inputs
-                                                               original_keras_version='1')
+    weight_tensor_td_conv_new = topology.preprocess_weights_for_loading(
-                                                                   original_keras_version='1')
+    weight_tensor_bi_convlstm_new = topology.preprocess_weights_for_loading(
-
+import warnings
-from keras.backend import tensorflow_backend as KTF
+from keras.backend import floatx, set_floatx, variable
-BACKENDS = [KTH, KTF, KC]
+BACKENDS = []  # Holds a list of all available back-ends
-                             ' (' + str(self.x.shape[channels_axis]) + ' channels).')
+            warnings.warn('NumpyArrayIterator is set to use the '
-                self.metrics_names.append(self.output_names[i] + '_loss')
+        with K.name_scope('loss'):
-                total_loss = 0.
+                if not self.losses:
-            total_loss += loss_tensor
+            # Add regularization penalties
-        def append_metric(layer_num, metric_name, metric_tensor):
+        def append_metric(layer_index, metric_name, metric_tensor):
-                metric_name = self.output_layers[layer_num].name + '_' + metric_name
+                metric_name = self.output_layers[layer_index].name + '_' + metric_name
-                continue
+        with K.name_scope('metrics'):
-                            acc_fn = metrics_module.sparse_categorical_accuracy
+                y_true = self.targets[i]
-                            acc_fn = metrics_module.categorical_accuracy
+                            metric_fn = metrics_module.get(metric)
-            handle_metrics(output_weighted_metrics, weights=weights)
+                        with K.name_scope(metric_name):
-                                             **self._function_kwargs)
+            with K.name_scope('training'):
-                                name = str(w.name)
+                            if hasattr(w, 'name'):
-        self.decay = K.variable(decay, name='decay')
+        with K.name_scope(self.__class__.__name__):
-        self.rho = K.variable(rho, name='rho')
+        with K.name_scope(self.__class__.__name__):
-        self.lr = K.variable(lr, name='lr')
+        with K.name_scope(self.__class__.__name__):
-        self.lr = K.variable(lr, name='lr')
+        with K.name_scope(self.__class__.__name__):
-        self.beta_2 = K.variable(beta_2, name='beta_2')
+        with K.name_scope(self.__class__.__name__):
-        self.beta_2 = K.variable(beta_2, name='beta_2')
+        with K.name_scope(self.__class__.__name__):
-        self.beta_2 = K.variable(beta_2, name='beta_2')
+        with K.name_scope(self.__class__.__name__):
-        self.iterations = K.variable(0., name='iterations')
+        with K.name_scope(self.__class__.__name__):
-                sample_weight_mode=None, **kwargs):
+                sample_weight_mode=None, weighted_metrics=None, **kwargs):
-                        acc_fn = metrics_module.categorical_accuracy
+            output_weighted_metrics = nested_weighted_metrics[i]
-                        append_metric(i, name, tensor)
+                        acc_fn = _weighted_masked_objective(acc_fn)
-from keras.layers import Dense, Activation, GRU, TimeDistributed
+from keras.models import Sequential, Model
-                        include_top):
+                        include_top,
-        default_shape = (3, default_size, default_size)
+    if weights != 'imagenet' and input_shape is not None and len(input_shape) == 3:
-        default_shape = (default_size, default_size, 3)
+        if data_format == 'channels_first':
-                if input_shape[0] != 3:
+                if input_shape[0] != 3 and weights == 'imagenet':
-                if input_shape[-1] != 3:
+                if input_shape[-1] != 3 and weights == 'imagenet':
-    `image_data_format="channels_last"` in your Keras config
+    `image_data_format='channels_last'` in your Keras config
-            or "imagenet" (pre-training on ImageNet).
+            or 'imagenet' (pre-training on ImageNet).
-        include_top=include_top)
+        include_top=include_top,
-        padding: one of `"valid"` or `"same"` (case-insensitive).
+        padding: one of `'valid'` or `'same'` (case-insensitive).
-            If you never set it, then it will be "channels_last".
+            If you never set it, then it will be 'channels_last'.
-            (ie. "linear" activation: `a(x) = x`).
+            (ie. 'linear' activation: `a(x) = x`).
-            the output of the layer (its "activation").
+            the output of the layer (its 'activation').
-                                      include_top=include_top or weights)
+                                      include_top=include_top or weights,
-    `image_data_format="channels_last"` in your Keras config
+    `image_data_format='channels_last'` in your Keras config
-            or "imagenet" (pre-training on ImageNet).
+            or 'imagenet' (pre-training on ImageNet).
-                                      include_top=include_top)
+                                      include_top=include_top,
-    `image_data_format="channels_last"` in your Keras config
+    `image_data_format='channels_last'` in your Keras config
-            or "imagenet" (pre-training on ImageNet).
+            or 'imagenet' (pre-training on ImageNet).
-                                      include_top=include_top)
+                                      include_top=include_top,
-    `image_data_format="channels_last"` in your Keras config
+    `image_data_format='channels_last'` in your Keras config
-            or "imagenet" (pre-training on ImageNet).
+            or 'imagenet' (pre-training on ImageNet).
-                                      include_top=include_top)
+                                      include_top=include_top,
-    You should set `image_data_format="channels_last"` in your Keras config
+    You should set `image_data_format='channels_last'` in your Keras config
-            or "imagenet" (pre-training on ImageNet).
+            or 'imagenet' (pre-training on ImageNet).
-                                      include_top=include_top)
+                                      include_top=include_top,
-                    reason="cntk does not support padding with non-concrete dimension")
+                    reason='cntk does not support padding with non-concrete dimension')
-                    reason="cntk does not support padding with non-concrete dimension")
+                    reason='cntk does not support padding with non-concrete dimension')
-                    reason="cntk does not support padding with non-concrete dimension")
+                    reason='cntk does not support padding with non-concrete dimension')
-                    reason="cntk does not support padding with non-concrete dimension")
+                    reason='cntk does not support padding with non-concrete dimension')
-                    reason="cntk does not support padding with non-concrete dimension")
+                    reason='cntk does not support padding with non-concrete dimension')
-                    reason="cntk does not support padding with non-concrete dimension")
+                    reason='cntk does not support padding with non-concrete dimension')
-                    reason="cntk does not support padding with non-concrete dimension")
+                    reason='cntk does not support padding with non-concrete dimension')
-                    reason="cntk does not support padding with non-concrete dimension")
+                    reason='cntk does not support padding with non-concrete dimension')
-                    reason="MobileNets are supported only on TensorFlow")
+                    reason='MobileNets are supported only on TensorFlow')
-                    reason="MobileNets are supported only on TensorFlow")
+                    reason='MobileNets are supported only on TensorFlow')
-                    reason="MobileNets are supported only on TensorFlow")
+                    reason='MobileNets are supported only on TensorFlow')
-                    reason="MobileNets are supported only on TensorFlow")
+                    reason='MobileNets are supported only on TensorFlow')
-    cbks = [tsb]
+    # we must generate new callbacks for each test, as they aren't stateless
-              callbacks=cbks, epochs=3)
+              callbacks=callbacks_factory(histogram_freq=0), epochs=3)
-              callbacks=cbks, epochs=2)
+              callbacks=callbacks_factory(histogram_freq=0), epochs=2)
-                        callbacks=cbks)
+                        callbacks=callbacks_factory(histogram_freq=0))
-                        callbacks=cbks)
+                        callbacks=callbacks_factory(histogram_freq=1))
-    cbks = [tsb]
+    # we must generate new callbacks for each test, as they aren't stateless
-              callbacks=cbks, epochs=3)
+              callbacks=callbacks_factory(histogram_freq=0), epochs=3)
-              callbacks=cbks, epochs=2)
+              callbacks=callbacks_factory(histogram_freq=1), epochs=2)
-                        callbacks=cbks)
+                        callbacks=callbacks_factory(histogram_freq=0))
-                        callbacks=cbks)
+                        callbacks=callbacks_factory(histogram_freq=1))
-    def _fit_loop(self, f, ins, out_labels=None, batch_size=32,
+    def _check_num_samples(self, ins, batch_size=None, steps=None, steps_name='steps'):
-                  callback_metrics=None, initial_epoch=0):
+                  callback_metrics=None, initial_epoch=0,
-            batch_size: integer batch size
+            batch_size: integer batch size or None if unknown.
-            if verbose:
+            if steps_per_epoch and not validation_steps:
-        index_array = np.arange(num_train_samples)
+        num_train_samples = self._check_num_samples(ins, batch_size,
-            callbacks += [cbks.ProgbarLogger()]
+            if steps_per_epoch is not None:
-                    batch_logs[l] = o
+            if steps_per_epoch is not None:
-                    break
+                    if not isinstance(outs, list):
-                            epoch_logs['val_' + l] = o
+                    callbacks.on_batch_end(step_num, batch_logs)
-    def _test_loop(self, f, ins, batch_size=32, verbose=0):
+    def _test_loop(self, f, ins, batch_size=None, verbose=0, steps=None):
-            batch_size: integer batch size.
+            batch_size: integer batch size or `None`.
-                ins_batch = _slice_arrays(ins, batch_ids)
+        if batch_size is None and steps is not None:
-                    outs[i] += batch_out * len(batch_ids)
+        else:
-                outs[0] += batch_outs * len(batch_ids)
+                # May happen if we are running `predict` without Numpy input data,
-                progbar.update(batch_end)
+                progbar = Progbar(target=samples)
-            batch_size=32,
+            batch_size=None,
-            batch_size: integer. Number of samples per gradient update.
+            batch_size: integer or `None`. Number of samples per gradient update.
-                before each epoch.
+                before each epoch. Has no effect when `steps_per_epoch`
-                              initial_epoch=initial_epoch)
+                              initial_epoch=initial_epoch,
-                                  batch_size=batch_size, verbose=verbose)
+        return self._predict_loop(f, ins, batch_size=batch_size,
-                    avg = self.sum_values[k][0] / max(1, self.sum_values[k][1])
+                    avg = np.mean(self.sum_values[k][0] / max(1, self.sum_values[k][1]))
-                    avg = self.sum_values[k][0] / max(1, self.sum_values[k][1])
+                    avg = np.mean(self.sum_values[k][0] / max(1, self.sum_values[k][1]))
-                    epochs=1, batch_size=4, validation_split=0.5)
+                    epochs=1, batch_size=None, validation_split=0.5,
-        out = model.fit(None, None, epochs=1, batch_size=10)
+        out = model.fit(None, None, epochs=1, batch_size=None, steps_per_epoch=1)
-from keras.utils.generic_utils import custom_object_scope, has_arg
+import numpy as np
-    # Determine proper input shape.
+    # Determine proper input shape and default size.
-                                      default_size=224,
+                                      default_size=default_size,
-                        p, s))
+                past_values.append(C.sequence.past_value(p, s))
-from keras.engine import Input, get_source_inputs
+from keras.engine import Input, Layer, get_source_inputs
-def variable(value, dtype=None, name=None):
+def variable(value, dtype=None, name=None, constraint=None):
-def variable(value, dtype=None, name=None):
+def variable(value, dtype=None, name=None, constraint=None):
-def variable(value, dtype=None, name=None):
+def variable(value, dtype=None, name=None, constraint=None):
-        weight = K.variable(initializer(shape), dtype=dtype, name=name)
+        weight = K.variable(initializer(shape),
-                self.total_loss)
+                params=self._collected_trainable_weights,
-    def get_updates(self, params, constraints, loss):
+    @interfaces.legacy_get_updates_support
-    def get_updates(self, params, constraints, loss):
+    @interfaces.legacy_get_updates_support
-                new_p = c(new_p)
+            # Apply constraints.
-    def get_updates(self, params, constraints, loss):
+    @interfaces.legacy_get_updates_support
-                new_p = c(new_p)
+            # Apply constraints.
-    def get_updates(self, params, constraints, loss):
+    @interfaces.legacy_get_updates_support
-                new_p = c(new_p)
+
-    def get_updates(self, params, constraints, loss):
+    @interfaces.legacy_get_updates_support
-                new_p = c(new_p)
+
-    def get_updates(self, params, constraints, loss):
+    @interfaces.legacy_get_updates_support
-                new_p = c(new_p)
+
-    def get_updates(self, params, constraints, loss):
+    @interfaces.legacy_get_updates_support
-                new_p = c(new_p)
+
-    def get_updates(self, params, constraints, loss):
+    @interfaces.legacy_get_updates_support
-                new_p = c(new_p)
+            # Apply constraints.
-                             'or use a Keras optimizer.')
+    @interfaces.legacy_get_updates_support
-def get_model(input_dim, num_hidden, output_dim):
+def _test_optimizer(optimizer, target=0.75):
-    model.add(Dense(num_hidden, input_shape=(input_dim,)))
+    model.add(Dense(10, input_shape=(x_train.shape[1],)))
-    model.add(Dense(output_dim))
+    model.add(Dense(y_train.shape[1]))
-    model = get_model(x_train.shape[1], 10, y_train.shape[1])
+
-    optimizer = optimizers.TFOptimizer(train.AdamOptimizer)
+    optimizer = optimizers.TFOptimizer(train.AdamOptimizer())
-        model.fit(np.random.random((5, 3)), np.random.random((5, 2)), epochs=1, batch_size=5, verbose=0)
+    model.fit(np.random.random((5, 3)), np.random.random((5, 2)),
-        return inputs * K.cast(boolean_mask, K.floatx())
+        return inputs * K.cast(boolean_mask, inputs.dtype)
-    else:
+    mapping = {'float16': tf.float16,
-            xtf = KTF.variable(np.random.random(x_shape))
+            x_val = np.random.random(x_shape).astype(np.float32)
-        timesteps = 5
+        num_samples = 4
-        W_o_val = np.random.random((output_dim, output_dim))
+        input_val = np.random.random((num_samples, timesteps, input_dim)).astype(np.float32)
-            W_o = K.variable(W_o_val)
+        def rnn_step_fn(input_dim, output_dim, k):
-                output = K.dot(x, W_i) + K.dot(prev_output, W_o)
+                output = k.dot(x, W_i) + k.dot(prev_output, W_o)
-        unrolled_masked_states_list = []
+        last_output_list = [[], [], [], [], [], []]
-        for l, u_l in zip(last_output_list, unrolled_last_output_list):
+            kwargs_list = [
-        for o, u_o in zip(outputs_list, unrolled_outputs_list):
+        for o, u_o in zip(outputs_list[0], outputs_list[1]):
-        for s, u_s in zip(state_list, unrolled_states_list):
+        for s, u_s in zip(state_list[0], state_list[1]):
-        for b_l, b_u_l in zip(backwards_last_output_list, bwd_unrolled_last_output_list):
+        for b_l, b_u_l in zip(last_output_list[2], last_output_list[3]):
-        for b_o, b_u_o, in zip(backwards_outputs_list, bwd_unrolled_outputs_list):
+        for b_o, b_u_o in zip(outputs_list[2], outputs_list[3]):
-        for b_s, b_u_s in zip(backwards_states_list, bwd_unrolled_states_list):
+        for b_s, b_u_s in zip(state_list[2], state_list[3]):
-        for m_l, u_m_l, k in zip(masked_last_output_list, unrolled_masked_last_output_list, BACKENDS):
+        for m_l, u_m_l, k in zip(last_output_list[4], last_output_list[5], BACKENDS):
-        for m_o, u_m_o, k in zip(masked_outputs_list, unrolled_masked_outputs_list, BACKENDS):
+        for m_o, u_m_o, k in zip(outputs_list[4], outputs_list[5], BACKENDS):
-        for m_s, u_m_s, k in zip(masked_states_list, unrolled_masked_states_list, BACKENDS):
+        for m_s, u_m_s, k in zip(state_list[4], state_list[5], BACKENDS):
-    return categorical_crossentropy(output, target, from_logits)
+    return categorical_crossentropy(target, output, from_logits)
-        return super(Wrapper, self).get_updates_for(inputs)
+        # If the wrapper modifies the inputs, use the modified inputs to
-            # Shape: (num_samples * timesteps, ...)
+            # Shape: (num_samples * timesteps, ...). And track the
-from keras.layers import core, convolutional, recurrent, embeddings
+from keras.layers import core, convolutional, recurrent, embeddings, normalization
-    return categorical_crossentropy(output, target, from_logits)
+    return categorical_crossentropy(target, output, from_logits)
-        assert type(inputs) in {list, tuple}
+        assert isinstance(inputs, (list, tuple))
-                if type(shape[0]) == int or shape[0] is None:
+                if isinstance(shape[0], int) or shape[0] is None:
-    if type(y).__name__ == 'ndarray':
+    if isinstance(y, (np.generic, np.ndarray)):
-    assert type(node.inbound_layers) is list
+    assert isinstance(node.inbound_layers, list)
-    assert type(node.input_tensors) is list
+    assert isinstance(node.input_tensors, list)
-    assert type(node.input_masks) is list
+    assert isinstance(node.input_masks, list)
-    assert type(node.input_shapes) is list
+    assert isinstance(node.input_shapes, list)
-    assert type(node.output_tensors) is list
+    assert isinstance(node.output_tensors, list)
-    assert type(node.output_shapes) is list
+    assert isinstance(node.output_shapes, list)
-    assert type(node.output_masks) is list
+    assert isinstance(node.output_masks, list)
-        x: a potential tensor.
+        x: A candidate tensor.
-        A boolean: whether the argument is a Keras tensor.
+        A boolean: Whether the argument is a Keras tensor.
-        ValueError: in case `x` is not a symbolic tensor.
+        ValueError: In case `x` is not a symbolic tensor.
-        >>> K.is_keras_tensor(keras_input) # An Input layer is a Keras tensor.
+        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.
-        >>> K.is_keras_tensor(keras_layer) # Any Keras layer is a Keras tensor.
+        >>> keras_layer_output = Dense(10)(keras_input)
-        x: a potential tensor.
+        x: A candidate tensor.
-        A boolean: whether the argument is a Keras tensor.
+        A boolean: Whether the argument is a Keras tensor.
-        ValueError: in case `x` is not a symbolic tensor.
+        ValueError: In case `x` is not a symbolic tensor.
-        >>> K.is_keras_tensor(k_var) # A variable created directly from tensorflow/theano is not a Keras tensor.
+        >>> k_var = tf.placeholder('float32', shape=(1,1))
-        >>> K.is_keras_tensor(keras_var) # A variable created with the keras backend is not a Keras tensor.
+        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is not a Keras tensor.
-        >>> K.is_keras_tensor(keras_input) # An Input layer is a Keras tensor.
+        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.
-        >>> K.is_keras_tensor(keras_layer) # Any Keras layer is a Keras tensor.
+        >>> keras_layer_output = Dense(10)(keras_input)
-        True
+        >>> K.is_keras_tensor(keras_var)  # A variable created with the keras backend is not a Keras tensor.
-        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is a Keras tensor.
+        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is not a Keras tensor.
-        True
+        >>> K.is_keras_tensor(keras_var) # A variable created with the keras backend is not a Keras tensor.
-        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is a Keras tensor.
+        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is not a Keras tensor.
-    # Here we use tf.tile to mimic behaviour of np.repeat so that
+    # Here we use tf.tile to mimic behavior of np.repeat so that
-            specifing the learning phase.
+            specifying the learning phase.
-            specifing the learning phase.
+            specifying the learning phase.
-        the tensor after 1d conv with un-shared weights, with shape (batch_size, output_lenght, filters)
+        the tensor after 1d conv with un-shared weights, with shape (batch_size, output_length, filters)
-def resize_images(X, height_factor, width_factor, data_format):
+def resize_images(x, height_factor, width_factor, data_format):
-        output = repeat_elements(X, height_factor, axis=2)
+        output = repeat_elements(x, height_factor, axis=2)
-        output = repeat_elements(X, height_factor, axis=1)
+        output = repeat_elements(x, height_factor, axis=1)
-        raise ValueError('CNTK Backend: Invalid dim_ordering:', data_format)
+        raise ValueError('CNTK Backend: Invalid data_format:', data_format)
-def resize_images(X, height_factor, width_factor, data_format):
+def resize_images(x, height_factor, width_factor, data_format):
-        output = repeat_elements(X, height_factor, axis=2)
+        output = repeat_elements(x, height_factor, axis=2)
-        output = repeat_elements(X, height_factor, axis=1)
+        output = repeat_elements(x, height_factor, axis=1)
-def resize_volumes(X, depth_factor, height_factor, width_factor, data_format):
+def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):
-        output = repeat_elements(X, depth_factor, axis=2)
+        output = repeat_elements(x, depth_factor, axis=2)
-        output = repeat_elements(X, depth_factor, axis=1)
+        output = repeat_elements(x, depth_factor, axis=1)
-    def test_logsumexp(self, x_np, axis, keepdims, K):
+    def test_logsumexp(self, x_np, axis, keepdims):
-                        rtol=1e-5)
+        for k in BACKENDS:
-    def test_logsumexp_optim(self, K):
+    def test_logsumexp_optim(self):
-                        rtol=1e-5)
+        for k in [KTF]:
-                  for k in [KTF, KTH]]
+                  for k in BACKENDS]
-        assert np.abs(z_list[0].mean() - z_list[1].mean()) < 0.05
+        for i in range(len(z_list) - 1):
-        for (input_shape, pool_size) in ([(5, 10, 12, 3), (5, 10, 12, 6, 3)], [(2, 2), (2, 2, 2)]):
+        for (input_shape, pool_size) in zip([(5, 10, 12, 3), (5, 10, 12, 6, 3)], [(2, 2), (2, 2, 2)]):
-                            k.pool3d(x, pool_size=pool_size, pool_mode='median')
+                        k.pool3d(x, pool_size=pool_size, pool_mode='median')
-                                          [KTH, KTF],
+                                          BACKENDS, cntk_dynamicity=True,
-        for k in (KTH, KTF):
+        for k in BACKENDS:
-    return C.ops.gather(reference, indices)
+    # There is a bug in cntk gather op which may cause crash.
-    return C.reshape(x, new_shape)
+    result = C.reshape(x, new_shape)
-                    _axis[i] -= nones
+                _axis[i] = cntk_axis[_axis[i]]
-            initial.append(C.user_function(ConvertToBatch(s)))
+            if hasattr(C, 'to_batch'):
-        def _recurrence(x, states):
+        def _recurrence(x, states, m):
-            place_holders = [C.placeholder() for _ in states]
+            place_holders = [C.placeholder(dynamic_axes=x.dynamic_axes) for _ in states]
-        final_output, final_states = _recurrence(inputs, states)
+        final_output, final_states = _recurrence(inputs, states, mask)
-            f_stats.append(C.user_function(ConvertToStatic(l_s, batch_size=i_s.shape[0])))
+            if hasattr(C, 'unpack_batch'):
-                                     % (tensor.shape, value.shape))
+                                     % (str(tensor.shape), str(value.shape)))
-            if isinstance(a, C.Axis) and a != C.Axis.default_batch_axis():
+            if isinstance(a, C.Axis) \
-        check_single_tensor_operation('reverse', (4, 3, 2), [KTH, KTF], axes=1)
+        check_single_tensor_operation('reverse', (4, 3, 2), BACKENDS, axes=1)
-    ```
+    ```python
-    ```
+    ```python
-        >>> 1
+        1
-        >>> 2
+        2
-    ```
+    ```sh
-                        f.close()
+                    f.close()
-    factor used in numeric expressions.
+    """Returns the value of the fuzz factor used in numeric expressions.
-    factor used in numeric expressions.
+    """Sets the value of the fuzz factor used in numeric expressions.
-from .common import _EPSILON
+from .common import floatx, epsilon
-        output = tf.clip_by_value(output, epsilon, 1. - epsilon)
+        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)
-        output = tf.clip_by_value(output, epsilon, 1 - epsilon)
+        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)
-        output = tf.clip_by_value(output, epsilon, 1 - epsilon)
+        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)
-from .common import _FLOATX, floatx, _EPSILON, image_data_format
+from .common import floatx, epsilon, image_data_format
-theano.config.floatX = _FLOATX
+theano.config.floatX = floatx()
-    output = T.clip(output, _EPSILON, 1.0 - _EPSILON)
+    output = T.clip(output, epsilon(), 1.0 - epsilon())
-    output = T.clip(output, _EPSILON, 1.0 - _EPSILON)
+    output = T.clip(output, epsilon(), 1.0 - epsilon())
-    norm = T.sqrt(T.maximum(square_sum, _EPSILON))
+    norm = T.sqrt(T.maximum(square_sum, epsilon()))
-    return concatenate(x_rep, axis)
+    # For static axis
-                if K.backend() == 'theano':
+                if K.backend() != 'cntk':
-            KTF.repeat_elements(ztf, 5, axis=0)
+                if K.backend() == 'tensorflow':
-        for k in [KTH, KTF]:
+        for k in BACKENDS:
-            try:
+            with pytest.raises(ValueError):
-            assert k.is_keras_tensor(keras_var) is True
+            assert k.is_keras_tensor(keras_var) is False
-            assert k.is_keras_tensor(keras_placeholder) is True
+            assert k.is_keras_tensor(keras_placeholder) is False
-from .common import _FLOATX, _EPSILON, image_dim_ordering, image_data_format
+from .common import floatx, epsilon, image_dim_ordering, image_data_format
-def variable(value, dtype=_FLOATX, name=None):
+def variable(value, dtype=None, name=None):
-        dtype=_FLOATX,
+        dtype=None,
-        dtype = _FLOATX
+        dtype = floatx()
-                            name=None, seed=None):
+def random_uniform_variable(shape, low, high,
-        dtype=_FLOATX,
+        dtype=None,
-def random_normal(shape, mean=0.0, stddev=1.0, dtype=_FLOATX, seed=None):
+def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):
-def zeros(shape, dtype=_FLOATX, name=None):
+def zeros(shape, dtype=None, name=None):
-def ones(shape, dtype=_FLOATX, name=None):
+def ones(shape, dtype=None, name=None):
-def eye(size, dtype=_FLOATX, name=None):
+def eye(size, dtype=None, name=None):
-def classification_error(output, target, axis=-1):
+def classification_error(target, output, axis=-1):
-def binary_crossentropy(output, target, from_logits=False):
+def binary_crossentropy(target, output, from_logits=False):
-    output = C.clip(output, _EPSILON, 1.0 - _EPSILON)
+    output = C.clip(output, epsilon(), 1.0 - epsilon())
-def categorical_crossentropy(output, target, from_logits=False):
+def categorical_crossentropy(target, output, from_logits=False):
-        output = C.clip(output, _EPSILON, 1.0 - _EPSILON)
+        # avoid numerical instability with epsilon clipping
-def sparse_categorical_crossentropy(output, target, from_logits=False):
+def sparse_categorical_crossentropy(target, output, from_logits=False):
-                                     'is constructed.' % g)
+                    raise ValueError(
-                                     '`train_function`.' % argument.name)
+                    raise ValueError(
-                                     'check the model and inputs.' % argument.name)
+                    raise ValueError(
-def categorical_crossentropy(output, target, from_logits=False):
+def categorical_crossentropy(target, output, from_logits=False):
-def sparse_categorical_crossentropy(output, target, from_logits=False):
+def sparse_categorical_crossentropy(target, output, from_logits=False):
-def binary_crossentropy(output, target, from_logits=False):
+def binary_crossentropy(target, output, from_logits=False):
-        output: A tensor.
+        output: A tensor.
-def categorical_crossentropy(output, target, from_logits=False):
+def categorical_crossentropy(target, output, from_logits=False):
-def sparse_categorical_crossentropy(output, target, from_logits=False):
+def sparse_categorical_crossentropy(target, output, from_logits=False):
-def binary_crossentropy(output, target, from_logits=False):
+def binary_crossentropy(target, output, from_logits=False):
-    return theano.foldl(fn2, elems, initializer, name=name)[0]
+    return theano.foldl(lambda x, acc: fn(acc, x),
-    return theano.foldr(fn2, elems, initializer, name=name)[0]
+    return theano.foldr(lambda x, acc: fn(acc, x),
-    return K.categorical_crossentropy(y_pred, y_true)
+    return K.categorical_crossentropy(y_true, y_pred)
-    return K.sparse_categorical_crossentropy(y_pred, y_true)
+    return K.sparse_categorical_crossentropy(y_true, y_pred)
-    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)
+    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)
-        check_two_tensor_operation('categorical_crossentropy', xval, yval,
+        check_two_tensor_operation('categorical_crossentropy', yval, xval,
-    val = np.random.random(input_shape) - 0.5
+def parse_shape_or_val(shape_or_val):
-            z = k.eval(getattr(k, function_name)(k.variable(val), **kwargs))
+
-        assert_allclose(z1, z2, atol=1e-05)
+def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, **kwargs):
-    yval = np.random.random(y_input_shape) - 0.5
+    if shape_or_val:
-                                     y=y_input_shape, **kwargs)([xval, yval])[0]
+        if shape_or_val:
-            assert z._keras_shape == z.shape
+            z = k.eval(getattr(k, function_name)(x_shape_or_val, **kwargs))
-    xc = KC.placeholder((4, 2))
+    if assert_value_with_ref is not None:
-    zth = KTH.eval(KTH.categorical_crossentropy(xth, yth, from_logits=True))
+def check_two_tensor_operation(function_name, x_shape_or_val,
-    zc = zc[0]
+    if shape_or_val:
-    assert_allclose(zth, ztf, atol=1e-05)
+    z_list = []
-    assert_allclose(ztf, zc, atol=1e-05)
+    assert_list_pairwise(z_list)
-        z_list.append(k.eval(getattr(k, second_function_name)(y, **second_function_args)))
+    for k in backend_list:
-        assert_allclose(z_list[i], z_list[i + 1], atol=1e-05)
+    assert_list_pairwise(z_list)
-        for K in [KTH, KTF]:
+        for k in [KTH, KTF]:
-                K.is_keras_tensor(np_var)
+                k.is_keras_tensor(np_var)
-            assert K.is_keras_tensor(keras_placeholder) is True
+            keras_var = k.variable(np_var)
-        for backend in (KTF, KTH):
+        for k in BACKENDS:
-                backend.set_learning_phase(2)
+                k.set_learning_phase(2)
-        assert_allclose(zth, ztf, atol=1e-05)
+        z_list = [k.eval(k.eye(3)) for k in BACKENDS]
-        check_two_tensor_operation('batch_dot', (32, 20), (32, 20), [KTF, KTH, KCTD], axes=(1, 1))
+        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 5, 3),
-        assert zth.shape == ztf.shape
+        check_single_tensor_operation('random_uniform_variable', (2, 3), BACKENDS,
-        assert_allclose(KTF.eval(xy_batch_dot), np.ones((20, 1)) * 32, atol=1e-05)
+    @pytest.mark.parametrize('k', [KTF], ids=['TensorFlow'])
-        assert_allclose(KTF.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)
+        x_batch = k.ones(shape=(32, 20))
-            assert_allclose(z_list[i], z_list[i + 1], atol=1e-05)
+        check_two_tensor_operation('concatenate', (4, 3), (4, 2), BACKENDS,
-        check_single_tensor_operation('batch_flatten', (20, 2, 5), [KTH, KTF, KCSD])
+        check_single_tensor_operation('batch_flatten', (20, 2, 5), BACKENDS,
-                        assert z._keras_shape == z.shape
+                check_single_tensor_operation('repeat_elements', arr, BACKENDS,
-
+        check_single_tensor_operation('tile', arr, BACKENDS, n=[2, 1])
-        assert_allclose(tf_result, th_result, atol=1e-05)
+        z_list = [k.eval(k.gather(k.variable(ref), k.variable(inds, dtype='int32')))
-            assert th_z._keras_shape == th_result.shape
+        assert_list_pairwise(z_list)
-            assert_allclose(value_list[i], value_list[i + 1], atol=1e-05)
+        for function_name in ['get_value', 'count_params', 'get_variable_shape']:
-            assert number_params_list[i] == number_params_list[i + 1]
+            if function_name == 'get_value':
-        # check_single_tensor_operation('all', (4, 2), [KTF, KTH],axis=1, keepdims=True)
+        check_single_tensor_operation('any', (4, 2), BACKENDS)
-        check_single_tensor_operation('all', (4, 2), [KC, KTH], axis=1, keepdims=True)
+        check_single_tensor_operation('all', (4, 2), BACKENDS)
-            assert_allclose(zero_list[i], zero_list[i + 1], atol=1e-05)
+        assert_list_pairwise(z_list)
-            assert_allclose(function_outputs_list[i], function_outputs_list[i + 1], atol=1e-05)
+        assert_list_pairwise(function_outputs_list)
-            assert_allclose(new_val_list[i], new_val_list[i + 1], atol=1e-05)
+        new_val_list = [k.get_value(x) for x, k in zip(x_list, test_backend)]
-            assert_allclose(backwards_outputs_list[i], backwards_outputs_list[i + 1], atol=1e-04)
+        assert_list_pairwise(last_output_list, shape=False, atol=1e-04)
-            assert_allclose(outputs_list[i], outputs_list[i + 1], atol=1e-04)
+        assert_list_pairwise(last_output_list, shape=False)
-            assert_allclose(z_list[i], z_list[i + 1], atol=1e-05)
+            assert np.abs(z_list[i].mean() - z_list[i + 1].mean()) < 0.05
-        check_cross_entropy_with_valid_probability_distribution()
+        xval = np.asarray([[0.26157712, 0.0432167], [-0.43380741, 0.30559841],
-            assert_allclose(res_th, res_tf, atol=1e-05)
+            z_list = [b.eval(b.in_top_k(b.variable(predictions, dtype='float32'),
-            assert_allclose(res_th, res_tf, atol=1e-05)
+            z_list = [b.eval(b.in_top_k(b.variable(predictions, dtype='float32'),
-            assert_allclose(zth, ztf, atol=1e-05)
+            check_two_tensor_operation('conv1d', input_shape, kernel_shape,
-            assert_allclose(ztf, zc, atol=1e-05)
+        xval = np.random.random(input_shape)
-                    assert_allclose(ztf, zc, atol=1e-05)
+                check_two_tensor_operation('conv2d', input_shape, kernel_shape,
-        assert_allclose(ztf, zc, atol=1e-05)
+        for k in BACKENDS:
-                assert_allclose(ztf, zc, atol=1e-05)
+                check_two_tensor_operation('conv3d', input_shape, kernel_shape,
-        assert_allclose(ztf, zc, atol=1e-05)
+        for k in BACKENDS:
-                                      strides=(1, 1), padding='valid')
+        check_single_tensor_operation('pool2d', (5, 10, 12, 3),
-                                      strides=(1, 1), padding='valid')
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3),
-                                      strides=(1, 1), pool_mode='avg')
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3),
-                                      strides=(1, 1), padding='valid')
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3),
-                                      strides=(1, 1, 1), padding='valid')
+        check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3),
-                                      strides=(1, 1, 1), padding='valid')
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3),
-                                      strides=(1, 1, 1), pool_mode='avg')
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3),
-                                      strides=(1, 1, 1), padding='valid')
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3),
-                x = backend.variable(np.random.random(input_shape))
+        for (input_shape, pool_size) in ([(5, 10, 12, 3), (5, 10, 12, 6, 3)], [(2, 2), (2, 2, 2)]):
-                        backend.pool2d(x, pool_size=pool_size, data_format='channels_middle')
+                        k.pool2d(x, pool_size=pool_size, data_format='channels_middle')
-                        backend.pool2d(x, pool_size=pool_size, padding='twice')
+                        k.pool2d(x, pool_size=pool_size, padding='twice')
-                        backend.pool2d(x, pool_size=pool_size, pool_mode='median')
+                        k.pool2d(x, pool_size=pool_size, pool_mode='median')
-                        backend.pool3d(x, pool_size=pool_size, data_format='channels_middle')
+                        k.pool3d(x, pool_size=pool_size, data_format='channels_middle')
-                        backend.pool3d(x, pool_size=pool_size, padding='twice')
+                        k.pool3d(x, pool_size=pool_size, padding='twice')
-                        backend.pool3d(x, pool_size=pool_size, pool_mode='median')
+                        # In the current CNTK backend,
-                                          [KTH, KTF, KCSD],
+                                          BACKENDS, cntk_dynamicity=True,
-            x = backend.variable(np.random.random(x_shape))
+        xval = np.random.random(x_shape)
-                backend.resize_images(x, 2, 2, data_format='channels_middle')
+                k.resize_images(k.variable(xval), 2, 2,
-            x = backend.variable(np.random.random(x_shape))
+        xval = np.random.random(x_shape)
-                backend.resize_volumes(x, 2, 2, 2, data_format='channels_middle')
+                k.resize_volumes(k.variable(xval), 2, 2, 2,
-            assert_allclose(zth, ztf, atol=1e-05)
+            check_single_tensor_operation('spatial_2d_padding', x_shape, BACKENDS,
-            x = backend.variable(np.random.random(x_shape))
+        xval = np.random.random(x_shape)
-                backend.spatial_2d_padding(x, padding=padding, data_format='channels_middle')
+                k.spatial_2d_padding(k.variable(xval), padding=padding,
-                                          data_format=data_format)
+            check_single_tensor_operation('spatial_3d_padding', x_shape, BACKENDS,
-            x = backend.variable(np.random.random(x_shape))
+        xval = np.random.random(x_shape)
-                backend.spatial_3d_padding(x, padding=padding, data_format='channels_middle')
+                k.spatial_3d_padding(k.variable(xval), padding=padding,
-                                           [KTH, KTF, KCSD],
+                                           BACKENDS, cntk_dynamicity=True,
-                                       [KTH, KTF, KCSD],
+                                       BACKENDS, cntk_dynamicity=True,
-            b = backend.variable(np.random.random(bias_shape))
+        for k in BACKENDS:
-                KTF.bias_add(x, b, data_format='channels_middle')
+                k.bias_add(x, b, data_format='channels_middle')
-    def test_map(self):
+    @pytest.mark.parametrize('k', [KTH, KTF], ids=['Theano', 'TensorFlow'])
-    def test_foldl(self):
+        vx = k.variable(x)
-            kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))
+        kx = k.eval(k.foldl(lambda a, b: a + b, k.variable(x)))
-            assert_allclose(x.sum(axis=0), kx, atol=1e-05)
+        assert (3,) == kx.shape
-    def test_foldr(self):
+    @pytest.mark.parametrize('k', [KTH, KTF], ids=['Theano', 'TensorFlow'])
-            p2 = K.eval(K.foldr(lambda a, b: a * b, vx))
+        vx = k.variable(x)
-            assert 9e-38 < p2 <= 1e-37
+        assert p1 < p2
-            assert zth.shape == ztf.shape
+            check_two_tensor_operation('in_train_phase', (3, 3), (2, 2), [KTH, KTF],
-    norm = T.sqrt(T.maximum(square_sum, epsilon=_EPSILON))
+    norm = T.sqrt(T.maximum(square_sum, _EPSILON))
-def l2_normalize(x, axis):
+def l2_normalize(x, axis=None):
-def l2_normalize(x, axis):
+def l2_normalize(x, axis=None):
-def l2_normalize(x, axis, epsilon=1e-12):
+def l2_normalize(x, axis=None):
-    norm = T.sqrt(T.maximum(square_sum, epsilon))
+    norm = T.sqrt(T.maximum(square_sum, epsilon=_EPSILON))
-                '(see keras.io/optimizers).')
+    with h5py.File(filepath, mode='w') as f:
-                            name = str(w.name)
+            model_layers = model.layers
-                            name = str(w.name)
+                            if hasattr(w, 'name') and w.name:
-    f.close()
+                            param_dset[:] = val
-          'visualize': ['pydot-ng'],
+          'visualize': ['pydot>=1.2.0'],
-            the depthwise kernel matrix
+            the pointwise kernel matrix
-            inputs = Input(batch_shape=inputs.shape)
+            x = Input(batch_shape=inputs.shape)
-            outputs = layer(inputs)
+            outputs = layer(x)
-            model = Model(inputs, states[0])
+            model = Model(x, states[0])
-            input = Input(batch_shape=inputs.shape)
+            inputs = Input(batch_shape=inputs.shape)
-            outputs = layer(input)
+            outputs = layer(inputs)
-            model = Model(input, states[0])
+            model = Model(inputs, states[0])
-            np.testing.assert_allclose(K.eval(layer.states[0]), state, atol=1e-4)
+            np.testing.assert_allclose(
-                        self.filters, rows, cols)
+                output_shape = (input_shape[0], input_shape[1],
-                        rows, cols, self.filters)
+                output_shape = (input_shape[0], input_shape[1],
-                return (input_shape[0], self.filters, rows, cols)
+                output_shape = (input_shape[0], self.filters, rows, cols)
-                return (input_shape[0], rows, cols, self.filters)
+                output_shape = (input_shape[0], rows, cols, self.filters)
-            out_row, out_col, out_filter = output_shape[2:]
+            if self.return_state:
-            out_row, out_col, out_filter = output_shape[1:]
+            if self.return_state:
-                                  out_row, out_col, out_filter)))
+                        np.zeros(output_shape))
-                                  out_row, out_col, out_filter)))
+                        np.zeros(output_shape))
-                                    out_row, out_col, out_filter))]
+            self.states = [K.zeros(output_shape),
-    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)
+    x = Conv2D(
-        momentum_cache_t_1 = self.beta_1 * (1. - 0.5 * (K.pow(0.96, (t + 1) * self.schedule_decay)))
+        momentum_cache_t = self.beta_1 * (1. - 0.5 * (K.pow(K.cast_to_floatx(0.96), t * self.schedule_decay)))
-    return C.stop_gradient(C.combine(variables))
+    if isinstance(variables, (list, tuple)):
-        variables: List of variables.
+        variables: tensor or list of tensors to consider constant with respect
-        The same list of variables.
+        A single tensor or a list of tensors (depending on the passed argument)
-    return tf.stop_gradient(variables)
+    if isinstance(variables, (list, tuple)):
-    variables.
+    """Returns `variables` but with zero gradient w.r.t. every other variable.
-    return theano.gradient.disconnected_grad(variables)
+    if isinstance(variables, (list, tuple)):
-        v._keras_shape = tuple(map(int, value.get_shape()))
+        v._keras_shape = int_shape(value)
-        return tuple([i.__int__() for i in shape])
+        return tuple(x.get_shape().as_list())
-        if x.shape[self.channel_axis] not in {3, 4}:
+        if x.shape[self.channel_axis] not in {1, 3, 4}:
-        if self.unroll and input_shape[1] is None:
+        timesteps = input_shape[1]
-                             'time dimension is undefined. \n'
+                             'time dimension is undefined or equal to 1. \n'
-                                             input_length=input_shape[1])
+                                             input_length=timesteps)
-            self.updates .append(K.update_add(self.iterations, 1))
+            self.updates.append(K.update_add(self.iterations, 1))
-                                           use_multiprocessing=use_multiprocessing)
+                                           use_multiprocessing=use_multiprocessing,
-        scheduling: Sequential querying of datas if 'sequential', random otherwise.
+        shuffle: whether to shuffle the data at the beginning of each epoch
-                 scheduling='sequential'):
+                 shuffle=False):
-        self.scheduling = scheduling
+        self.shuffle = shuffle
-            if self.scheduling is not 'sequential':
+            if self.shuffle:
-            It should have exactly 3 inputs channels,
+            It should have exactly 3 input channels,
-                flatx = np.reshape(x, (x.size))
+                flatx = np.reshape(x, (-1, np.prod(x.shape[-3:])))
-                x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))
+                x = np.reshape(whitex, x.shape)
-                        batch_val.append(val_data[3])
+                        # do not slice the learning phase
-from keras.layers.core import Dense, Dropout
+from keras.models import Sequential, Model
-    model.add(Dense(num_class, activation='softmax'))
+    inp = Input((input_dim,))
-    # fit with validation data
+    # fit without validation data
-              validation_data=(X_test, y_test), callbacks=cbks, epochs=3)
+              callbacks=cbks, epochs=3)
-                        callbacks=cbks)
+              validation_data=(X_test, y_test),
-    # fit generator without validation data and accuracy
+    assert os.path.isdir(filepath)
-        # layer instances created during
+        # Layer instances created during
-                        layer(input_tensors, **kwargs)
+                # We don't process nodes (i.e. make layer calls)
-
+@keras_test
-    embedding_layer = Embedding(name="embedding", input_dim=5, output_dim=10)
+    input1 = Input(shape=(10,), name='input1')
-            return tuple(shape)
+                raise ValueError('`output_shape` function must return a tuple or a list of tuples.')
-              categorical=False, sampling_table=None):
+              categorical=False, sampling_table=None, seed=None):
-        seed = random.randint(0, 10e6)
+        if seed is None:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-        if self.model is None:
+        if not self.built:
-    style_mask = np.stack([style_mask_label == r for r in xrange(num_labels)],
+    style_mask = np.stack([style_mask_label == r for r in range(num_labels)],
-    target_mask = np.stack([target_mask_label == r for r in xrange(num_labels)],
+    target_mask = np.stack([target_mask_label == r for r in range(num_labels)],
-    for i in xrange(num_labels):
+    for i in range(num_labels):
-    const._keras_shape = shape
+    const._keras_shape = const.shape
-    states = tuple(initial_states)
+    states = tuple(initial)
-        last_states = final_states
+        last_states = [C.sequence.last(s) for s in final_states]
-    return last_output, final_output, last_states
+    f_stats = []
-            # cntk doesn't support statefulness on LSTM yet, will enable it on cntk later
+            # Tests for statefulness
-                    reason="cntk does not support stateful RNN yet")
+                    reason="cntk does not support mask on RNN yet")
-    stateful_flags = (False, True) if K.backend() != 'cntk' else (False,)
+    stateful_flags = (False, True)
-                    reason="cntk does not support stateful RNN yet")
+
-__version__ = '2.0.5'
+__version__ = '2.0.6'
-      version='2.0.5',
+      version='2.0.6',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.5',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.6',
-        ds: a Holder or Sequence object
+        ds: a Sequence object
-        self.sequence = self.manager.Holder(sequence)
+        self.sequence = sequence
-        pass  # expected behavior is to raise a ValueError with a suitable message
+    with pytest.raises(ValueError):
-_LEARNING_PHASE = C.parameter(shape=(1,), dtype=np.float32)
+_LEARNING_PHASE = C.constant(shape=(), dtype=np.float32, value=1.0, name="_keras_learning_phase")
-    return value[0]
+    return _LEARNING_PHASE
-
+    # CNTK currently don't support cond op, so here we use
-    if callable(alt) and isinstance(x, C.cntk_py.Function) is False:
+    if callable(alt) and isinstance(alt, C.cntk_py.Function) is False:
-    return x
+
-    return x
+    # Similiar as in_train_phase, use element_select as workaround.
-                                 % (tensor.shape, value.shape))
+            if tensor == _LEARNING_PHASE:
-            output_values = self.metrics_func.eval(input_dict, as_numpy=False)
+            # Some ops (like dropout) won't be applied during "eval" in cntk.
-                    reason="cntk does not support add learning_phase() as input")
+import multiprocessing.managers
-        ds: a Sequence object
+        ds: a Holder or Sequence object
-        self.sequence = sequence
+        self.manager = HolderManager()
-    def random_transform(self, x):
+    def random_transform(self, x, seed=None):
-        z_list.append(k.eval(getattr(k, function_name)(x, **kwargs)))
+    for k in backend_list:
-            assert z_list[i]._keras_shape == z_list[i].shape
+    for (z1, z2) in zip(z_list[1:], z_list[:-1]):
-    assert_allclose(ztf, zc, atol=1e-05)
+    for k in backend_list:
-                                                          data_format='channels_first')
+
-        cntk_check_single_tensor_operation('batch_flatten', (20, 2, 5))
+        check_single_tensor_operation('batch_flatten', (20, 2, 5), [KTH, KTF, KCSD])
-        check_single_tensor_operation('pool2d', (5, 10, 12, 3), [KTH, KTF], pool_size=(2, 2),
+        check_single_tensor_operation('pool2d', (5, 10, 12, 3), [KTH, KTF, KCSD], pool_size=(2, 2),
-        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF], pool_size=(2, 2),
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF, KCSD], pool_size=(2, 2),
-        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF], pool_size=(2, 2),
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF, KCSD], pool_size=(2, 2),
-        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF], pool_size=(2, 3),
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF, KCSD], pool_size=(2, 3),
-        check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), [KTH, KTF], pool_size=(2, 2, 2),
+        check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), [KTH, KTF, KCSD], pool_size=(2, 2, 2),
-        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF], pool_size=(2, 2, 2),
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF, KCSD], pool_size=(2, 2, 2),
-        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF], pool_size=(2, 2, 2),
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF, KCSD], pool_size=(2, 2, 2),
-        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF], pool_size=(2, 3, 2),
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF, KCSD], pool_size=(2, 3, 2),
-                                          BACKENDS,
+                                          [KTH, KTF, KCSD],
-            for shape in [(3,), (2, 3), (5, 3, 2)]:
+            for shape in [(), (3,), (2, 3), (5, 3, 2)]:
-                                           [KTH, KTF],
+                                           [KTH, KTF, KCSD],
-from Tensorflow checkpoints found at
+from TensorFlow checkpoints found at
-        raise RuntimeError('Only Tensorflow backend is currently supported, '
+        raise RuntimeError('Only TensorFlow backend is currently supported, '
-        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic yensor.
+        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.
-        >>> K.is_keras_tensor(k_var) # A variable created directly from tensorflow/theano is not a Keras tensor.
+        >>> K.is_keras_tensor(k_var) # A variable indirectly created outside of keras is not a Keras tensor.
-                msg = 'Invalid argument "%s" passed to K.function with Tensorflow backend' % key
+                msg = 'Invalid argument "%s" passed to K.function with TensorFlow backend' % key
-            Whether to use Theano or TensorFlow data format
+            Whether to use Theano or TensorFlow/CNTK data format
-            Whether to use Theano or TensorFlow data format
+            Whether to use Theano or TensorFlow/CNTK data format
-            Whether to use Theano or TensorFlow data format
+            Whether to use Theano or TensorFlow/CNTK data format
-            Whether to use Theano or TensorFlow data format
+            Whether to use Theano or TensorFlow/CNTK data format
-                         'With Theano, set `kernel_size` to an odd number.')
+                         'even kernel sizes are not supported with Theano. '
-                         'With Theano, set `kernel_size` to an odd number.')
+                         'even kernel sizes are not supported with Theano. '
-                are passed into K.function. When using the Tensorflow backend,
+            **kwargs: when using the Theano/CNTK backends, these arguments
-                `tf.Session.run`.
+            **kwargs: for Theano/CNTK backends, these are passed into
-                    reason="MobileNets are supported only on Tensorflow")
+                    reason="MobileNets are supported only on TensorFlow")
-                    reason="MobileNets are supported only on Tensorflow")
+                    reason="MobileNets are supported only on TensorFlow")
-                    reason="MobileNets are supported only on Tensorflow")
+                    reason="MobileNets are supported only on TensorFlow")
-        # the Theano and Tensorflow CTC code use different methods to ensure
+        # the Theano and TensorFlow CTC code use different methods to ensure
-        model.add(Dense(64, init='identity',
+        model.add(Dense(64, kernel_initializer='identity',
-            (before applying any other transformation).
+            otherwise we multiply the data by the value provided. This is
-        weights = np.asarray([class_weight[cls] for cls in y_classes])
+
-    # Two layers of bidirecitonal GRUs
+    # Two layers of bidirectional GRUs
-    # cntk currently not support funciton in this way, so can't test as this
+    # cntk currently not support function in this way, so can't test as this
-            receptive_field_size = np.prod(shape[:2])
+            receptive_field_size = np.prod(shape[:-2])
-BASE_WEIGHT_PATH = 'https://github.com/titu1994/MobileNetworks/releases/download/v1.0/'
+BASE_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.6/'
-from ..applications.imagenet_utils import preprocess_input
+def preprocess_input(x):
-                         ' as true, `classes` should be 1000')
+        raise ValueError('If using `weights` as ImageNet with `include_top` '
-    if weights == 'imagenet' and depth_multiplier != 1:
+    # Determine proper input shape.
-                             'image must have a square shape (one of '
+            raise ValueError('If imagenet weights are being loaded, '
-                             'Image shape provided = (%d, %d)' % (rows, cols))
+                             ' Input shape provided = %s' % (input_shape,))
-                      'config located at ~/.keras/keras.json. '
+                      'data format "channels_first" (channels, width, height).'
-    model = Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, size))
+    model = Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, rows))
-            use_multiprocessing: Ff True, use process based threading.
+            use_multiprocessing: if True, use process based threading.
-        raise NotImplemented
+        raise NotImplementedError
-        raise NotImplemented
+        raise NotImplementedError
-        raise NotImplemented
+        raise NotImplementedError
-        raise NotImplemented
+        raise NotImplementedError
-                    deserialized.append(value)
+                deserialized.append(convert_custom_objects(value))
-                    deserialized[key] = value
+                deserialized[key] = convert_custom_objects(value)
-        if not is_sequence and use_multiprocessing:
+        if not is_sequence and use_multiprocessing and workers > 1:
-                            'the `keras.utils.Sequence` class.'))
+                            ' and multiple workers may duplicate your data.'
-        if not is_sequence and use_multiprocessing:
+        if not is_sequence and use_multiprocessing and workers > 1:
-                            'the `keras.utils.Sequence` class.'))
+                            ' and multiple workers may duplicate your data.'
-        if not is_sequence and use_multiprocessing:
+        if not is_sequence and use_multiprocessing and workers > 1:
-                            'the `keras.utils.Sequence` class.'))
+                            ' and multiple workers may duplicate your data.'
-        >>> input = keras.backend.placeholder(shape=(2, 4, 5))
+        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))
-        >>> K.shape(input)
+        >>> K.shape(inputs)
-        >>> K.shape(input).eval(session=tf_session)
+        >>> K.shape(inputs).eval(session=tf_session)
-        >>> K.int_shape(input)
+        >>> inputs = K.placeholder(shape=(2, 4, 5))
-        >>> input = K.placeholder(shape=(2, 4, 5))
+        >>> inputs = K.placeholder(shape=(2, 4, 5))
-        >>> K.ndim(input)
+        >>> K.ndim(inputs)
-        >>> input
+        >>> inputs = K.placeholder((2, 3))
-        >>> input_transposed = K.transpose(input)
+        >>> input_transposed = K.transpose(inputs)
-                input: tensor with shape `(samples, ...)` (no time dimension),
+                inputs: tensor with shape `(samples, ...)` (no time dimension),
-                output: tensor with shape `(samples, output_dim)`
+                outputs: tensor with shape `(samples, output_dim)`
-                input: tensor with shape (samples, ...) (no time dimension),
+                inputs: tensor with shape (samples, ...) (no time dimension),
-                output: tensor with shape (samples, ...) (no time dimension),
+                outputs: tensor with shape (samples, ...) (no time dimension),
-                output, new_states = step_function(input, states)
+            def _step(inputs, mask, output_tm1, *states):
-                output = T.switch(mask, output, output_tm1)
+                outputs = T.switch(mask, outputs, output_tm1)
-                return [output] + return_states
+                return [outputs] + return_states
-                successive_outputs.append(output)
+                outputs, states = step_function(inputs[i], states + constants)
-                return [output] + new_states
+            def _step(inputs, *states):
-    model = Model(input, output)
+    inputs = Input(shape=(3,))
-    input = np.ones(shape)
+    inputs = np.ones(shape)
-               input_shape=input.shape)
+               input_shape=inputs.shape)
-               input_shape=input.shape)
+               input_shape=inputs.shape)
-    np_output = K.eval(output)
+    outputs = layer(K.variable(inputs))
-    np_output = K.eval(output)
+    outputs = layer(K.variable(inputs))
-        np_output = K.eval(output)
+        outputs = layer(K.variable(inputs))
-        np_output = K.eval(output)
+        outputs = layer(K.variable(inputs))
-        np_output = K.eval(output)
+        outputs = layer(K.variable(inputs))
-        np_output = K.eval(output)
+        outputs = layer(K.variable(inputs))
-                np_output = K.eval(output)
+                outputs = layer(K.variable(inputs))
-                    np_output = K.eval(output)
+                    outputs = layer(K.variable(inputs))
-        np_output = K.eval(output)
+        outputs = layer(K.variable(inputs))
-        np_output = K.eval(output)
+        outputs = layer(K.variable(inputs))
-        np_output = K.eval(output)
+        outputs = layer(K.variable(inputs))
-        np_output = K.eval(output)
+        outputs = layer(K.variable(inputs))
-        model = Model(input, output)
+        inputs = Input((timesteps, dim))
-        model = Model(input, output)
+        inputs = Input(batch_shape=(1, timesteps, dim))
-    output = Dense(3)(x)
+    inputs = Input(shape=(3,))
-    model = Model(input, output)
+    model = Model(inputs, outputs)
-    x = Dense(5)(input)
+    inputs = Input(shape=(5,))
-    model = Model(inputs=input, outputs=[output1, output2])
+    model = Model(inputs=inputs, outputs=[output1, output2])
-    output = Dense(3)(x)
+    inputs = Input(shape=(3,))
-    model = Model(input, output)
+    model = Model(inputs, outputs)
-    model = Model(input, output)
+    inputs = Input(shape=(4, 2, 3))
-    e.g. `input_shape=(128, 128, 128, 3)` for 128x128x128 volumes
+    e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes
-            width and height of the 3D convolution window.
+            depth, height and width of the 3D convolution window.
-                         '(i.e. a 2D array of shape (samples, 1000)).'
+                         '(i.e. a 2D array of shape (samples, 1000)). '
-                          padding='same', name='conv_preds')(x)
+        x = Conv2D(classes, (1, 1),
-                      name='conv1')(inputs)
+    x = Conv2D(filters, kernel,
-                      name='conv_pw_%d' % block_id)(x)
+    x = Conv2D(pointwise_conv_filters, (1, 1),
-def _conv_block(input, filters, alpha, kernel=(3, 3), strides=(1, 1)):
+def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):
-        input: Input tensor of shape `(rows, cols, 3)`
+        inputs: Input tensor of shape `(rows, cols, 3)`
-                      name='conv1')(input)
+                      name='conv1')(inputs)
-def _depthwise_conv_block(input, pointwise_conv_filters, alpha,
+def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,
-        input: Input tensor of shape `(rows, cols, channels)`
+        inputs: Input tensor of shape `(rows, cols, channels)`
-                        name='conv_dw_%d' % block_id)(input)
+                        name='conv_dw_%d' % block_id)(inputs)
-the number of multiply-adds and thereby reduce inference cost on mobile devices.
+the number of multiply-adds and thereby
-of filters in each layer. By altering the image size and `alpha` parameter,
+offering better performance.
-found in https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md
+1.0 (also called 100 % MobileNet), 0.75, 0.5 and 0.25.
-                           'as other backends do not support depthwise convolution.')
+                           'as other backends do not support '
-            raise ValueError('If imagenet weights are being loaded, alpha can be one of'
+            raise ValueError('If imagenet weights are being loaded, '
-    # will be used.
+    # input shape can be anything larger than 32x32
-    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, id=1)
+    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)
-    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, id=3)
+    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier,
-    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, id=5)
+    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier,
-    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, id=11)
+    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier,
-    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, id=13)
+    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier,
-        x = Convolution2D(classes, (1, 1), padding='same', name='conv_preds')(x)
+        x = Convolution2D(classes, (1, 1),
-    return x
+    return Activation(relu6, name='conv1_relu')(x)
-                          depth_multiplier=1, strides=(1, 1), id=1):
+                          depth_multiplier=1, strides=(1, 1), block_id=1):
-        id: Integer, a unique identification designating  the block number.
+        block_id: Integer, a unique identification designating the block number.
-    x = Activation(relu6, name='conv_dw_%d_relu' % id)(x)
+                        name='conv_dw_%d' % block_id)(input)
-    return Activation(relu6, name='conv_pw_%d_relu' % id)(x)
+                      name='conv_pw_%d' % block_id)(x)
-    with pytest.raises(StopIteration):
+    with pytest.raises(ValueError):
-            yield (np.asarray([]), np.asarray([]))
+            while True:
-            In a `Convolution2D` layer with `data_format="channels_last"`,
+            In a `Conv2D` layer with `data_format="channels_last"`,
-            In a `Convolution2D` layer with `data_format="channels_last"`,
+            In a `Conv2D` layer with `data_format="channels_last"`,
-            In a `Convolution2D` layer with `dim_ordering="tf"`,
+            In a `Conv2D` layer with `data_format="channels_last"`,
-        model.add(Convolution2D(64, 3, 3,
+        model.add(Conv2D(64, 3, 3,
-    Instantiate the MobileNet architecture.
+    """Instantiates the MobileNet architecture.
-
+            raise ValueError('Weights for "channels_last" format '
-    x = Convolution2D(filters, kernel, padding='same', use_bias=False, strides=strides,
+    x = Convolution2D(filters, kernel,
-    pointwise convolution, batch normalization and relu6).
+    """Adds a depthwise convolution block.
-                        strides=strides, use_bias=False, name='conv_dw_%d' % id)(input)
+    x = DepthwiseConv2D((3, 3),
-    x = Convolution2D(pointwise_conv_filters, (1, 1), padding='same', use_bias=False, strides=(1, 1),
+    x = Convolution2D(pointwise_conv_filters, (1, 1),
-    return x
+    return Activation(relu6, name='conv_pw_%d_relu' % id)(x)
-                         '(i.e. a 2D array of shape (samples, 1000)). '
+                         '(i.e. a 2D array of shape (samples, 1000)).'
-        # Collected trainable weights and sort them deterministically.
+        # Collected trainable weights, sorted in topological order.
-            model.optimizer.set_weights(optimizer_weight_values)
+            try:
-decoder_deconv_2 = Conv2DTranspose(filters, num_conv,
+decoder_deconv_2 = Conv2DTranspose(filters,
-                          self.monitor, RuntimeWarning)
+            warnings.warn(
-    return tf.reduce_max(x, reduction_indices=axis, keep_dims=keepdims)
+    return tf.reduce_max(x, axis=axis, keep_dims=keepdims)
-    return tf.reduce_min(x, reduction_indices=axis, keep_dims=keepdims)
+    return tf.reduce_min(x, axis=axis, keep_dims=keepdims)
-    return tf.reduce_sum(x, reduction_indices=axis, keep_dims=keepdims)
+    return tf.reduce_sum(x, axis=axis, keep_dims=keepdims)
-    return tf.reduce_prod(x, reduction_indices=axis, keep_dims=keepdims)
+    return tf.reduce_prod(x, axis=axis, keep_dims=keepdims)
-    m = tf.reduce_mean(x, reduction_indices=axis, keep_dims=True)
+    m = tf.reduce_mean(x, axis=axis, keep_dims=True)
-                          reduction_indices=axis,
+                          axis=axis,
-    return tf.reduce_mean(x, reduction_indices=axis, keep_dims=keepdims)
+    return tf.reduce_mean(x, axis=axis, keep_dims=keepdims)
-    return tf.reduce_any(x, reduction_indices=axis, keep_dims=keepdims)
+    return tf.reduce_any(x, axis=axis, keep_dims=keepdims)
-    return tf.reduce_all(x, reduction_indices=axis, keep_dims=keepdims)
+    return tf.reduce_all(x, axis=axis, keep_dims=keepdims)
-                                reduction_indices=len(output.get_shape()) - 1,
+                                axis=len(output.get_shape()) - 1,
-                               reduction_indices=len(output.get_shape()) - 1)
+                               axis=len(output.get_shape()) - 1)
-                    utils.HDF5Matrix]
+                    utils.HDF5Matrix,
-    print_fn('_' * line_length)    
+    print_fn('_' * line_length)
-    return x.dtype.name
+    return x.dtype.base_dtype.name
-            constraint=self.embeddings_constraint)
+            constraint=self.embeddings_constraint,
-        accumulators = [K.zeros(shape) for shape in shapes]
+        accumulators = [K.zeros(K.get_variable_shape(p), dtype=K.dtype(p)) for p in params]
-        vs = [K.zeros(shape) for shape in shapes]
+        ms = [K.zeros(K.get_variable_shape(p), dtype=K.dtype(p)) for p in params]
-                            positions=positions)
+    def summary(self, line_length=None, positions=None, print_fn=print):
-def print_summary(model, line_length=None, positions=None):
+def print_summary(model, line_length=None, positions=None, print_fn=print):
-        positions: relative or absolute positions of log elements in each line.
+        line_length: Total length of printed lines
-        print(line)
+        print_fn(line)
-    print('_' * line_length)
+    print_fn('_' * line_length)
-    print('=' * line_length)
+    print_fn('=' * line_length)
-            print('=' * line_length)
+            print_fn('=' * line_length)
-            print('_' * line_length)
+            print_fn('_' * line_length)
-    print('_' * line_length)
+    print_fn('Total params: {:,}'.format(trainable_count + non_trainable_count))
-def _check_array_lengths(inputs, targets, weights):
+def _check_array_lengths(inputs, targets, weights=None):
-    set_x = set(x_lengths)
+    def set_of_lengths(x):
-                         str([w.shape for w in weights]))
+    if len(set_w) > 1:
-        skip_top: skip the top N most frequently occuring words
+        skip_top: skip the top N most frequently occurring words
-        skip_top: skip the top N most frequently occuring words
+        skip_top: skip the top N most frequently occurring words
-        # if masking is explictly supported, by default
+        # if masking is explicitly supported, by default
-        # then cache them here. When of of these output is queried later,
+        # then cache them here. When one of these output is queried later,
-                # In this case we must explictly broadcast all parameters.
+                # In this case we must explicitly broadcast all parameters.
-            The same structure, where occurences
+            The same structure, where occurrences
-            the 10-th most frequently occuring token).
+            the 10-th most frequently occurring token).
-        # due to the algo difference, we can't guranteen CNTK has the same result on the garbage input.
+        # due to the algo difference, we can't guarantee CNTK has the same result on the garbage input.
-    if isinstance(arrays, list):
+    if arrays is None:
-            return [x[start] for x in arrays]
+            return [None if x is None else x[start] for x in arrays]
-            return [x[start:stop] for x in arrays]
+            return [None if x is None else x[start:stop] for x in arrays]
-        else:
+        elif hasattr(start, '__getitem__'):
-
+            # reduce score_array to same ndim as weight array
-from keras.engine.training import Model, _check_loss_and_target_compatibility
+from keras.engine.training import Model
-                            'numpy.array and list objects')
+            raise TypeError('`shuffle_mats_or_lists` only supports '
-    """conv_block is the block that has a conv layer at shortcut
+    """A block that has a conv layer at shortcut.
-    if type(axis) is tuple:
+    if isinstance(axis, tuple):
-    elif type(axis) is int:
+    elif isinstance(axis, int):
-    elif type(axis) is list:
+    elif isinstance(axis, list):
-    if type(_axis) is list:
+    if isinstance(_axis, list):
-    indices: an int tensor of indices.
+    """Retrieves the elements of indices `indices` in the tensor `reference`.
-    Return: a tensor of same type as reference.
+    # Arguments
-        elif type(n) is int:
+        elif isinstance(n, int):
-                        'If you have an expression instead, use eval().')
+        raise TypeError('`get_value` can only be called on a variable. '
-    """condition: scalar tensor.
+    """Switches between two operations depending on a scalar value.
-        raise ValueError('label_mode must be one of "fine" "coarse".')
+        raise ValueError('`label_mode` must be one of `"fine"`, `"coarse"`.')
-            raise ValueError('class_weight not supported for '
+            raise ValueError('`class_weight` not supported for '
-                raise ValueError('validation_data should be a tuple '
+                raise ValueError('`validation_data` should be a tuple '
-                        raise ValueError('output of generator should be '
+                        raise ValueError('Output of generator should be '
-                        raise ValueError('output of generator should be '
+                        raise ValueError('Output of generator should be '
-                    raise ValueError('output of generator should be a tuple '
+                    raise ValueError('Output of generator should be a tuple '
-                    raise ValueError('output of generator should be a tuple '
+                    raise ValueError('Output of generator should be a tuple '
-                             '{"channels_last", "channels_first"}')
+            raise ValueError('`data_format` must be in '
-                             '{"channels_last", "channels_first"}')
+            raise ValueError('`data_format` must be in '
-                raise ValueError('output_shape function must return a tuple')
+                raise ValueError('`output_shape` function must return a tuple.')
-        raise ValueError('zoom_range should be a tuple or list of two floats. '
+        raise ValueError('`zoom_range` should be a tuple or list of two floats. '
-                             'column) or "channels_first" (channel before row and column). '
+            raise ValueError('`data_format` should be `"channels_last"` (channel after row and '
-            raise ValueError('zoom_range should be a float or '
+            raise ValueError('`zoom_range` should be a float or '
-    rank = np.array(list(range(size)))
+    rank = np.arange(size)
-    assert_allclose(0., y, atol=1e-2)
+    assert_allclose(np.mean(y), 0., atol=1e-1, rtol=1e-1)
-    if signature is None:
+    wrapped = getattr(function, '_original_function', None)
-import inspect
+
-                    key not in inspect.getargspec(Function.__init__)[0]):
+            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):
-import inspect
+
-            if key not in function_args:
+            if not has_arg(theano.function, key, True):
-import inspect
+from ..utils.generic_utils import has_arg
-                if 'mask' in inspect.getargspec(self.call).args:
+                if has_arg(self.call, 'mask'):
-                            if 'mask' in inspect.getargspec(layer.call).args:
+                            if has_arg(layer.call, 'mask'):
-                            if 'mask' in inspect.getargspec(layer.call).args:
+                            if has_arg(layer.call, 'mask'):
-import inspect
+from ..utils.generic_utils import has_arg
-        if 'mask' in arg_spec.args:
+        if has_arg(self.function, 'mask'):
-import inspect
+from ..utils.generic_utils import has_arg
-        if 'training' in func_args:
+        if has_arg(self.layer.call, 'training'):
-        if 'training' in func_args:
+        if has_arg(self.layer.call, 'training'):
-        if 'mask' in func_args:
+        if has_arg(self.layer.call, 'mask'):
-        wrapper._legacy_support_signature = inspect.getargspec(func)
+        wrapper._original_function = func
-from ..utils.generic_utils import func_dump, func_load
+from ..utils.generic_utils import func_dump, func_load, has_arg
-            if 'mask' in arg_spec.args:
+            if has_arg(self.mode, 'mask'):
-from . import data_utils
+from . import data_utils
-            if 'custom_objects' in arg_spec.args:
+            if has_arg(cls.from_config, 'custom_objects'):
-import inspect
+from .generic_utils import has_arg
-    if 'weights' in inspect.getargspec(layer_cls.__init__):
+    # Checking for empty weights array to avoid a problem where some
-import inspect
+from ..utils.generic_utils import has_arg
-            if params_name not in legal_params:
+            for fn in legal_params_fns:
-            if name in fn_args:
+            if has_arg(fn, name):
-from keras.utils.generic_utils import custom_object_scope
+from keras.utils.generic_utils import custom_object_scope, has_arg
-    #     )
+    with pytest.raises(StopIteration):
-                   np.random.randint(1, 256, (2, 50)))
+            yield (np.random.randint(1, 256, size=(2, 5)),
-    model.add(Dense(1, input_shape=(2, )))
+    model.add(Dense(1, input_shape=(5,)))
-        )
+    # with pytest.raises(StopIteration):
-                            'Please consider using the `keras.utils.Sequence` object.'))
+                UserWarning('Using a generator with `use_multiprocessing=True`'
-                enqueuer = OrderedEnqueuer(generator, use_multiprocessing=use_multiprocessing)
+                enqueuer = OrderedEnqueuer(generator,
-                enqueuer = GeneratorEnqueuer(generator, use_multiprocessing=use_multiprocessing,
+                enqueuer = GeneratorEnqueuer(generator,
-                           max_queue_size=10, workers=1, use_multiprocessing=False):
+                           max_queue_size=10,
-                            'Please consider using the `keras.utils.Sequence` object.'))
+                UserWarning('Using a generator with `use_multiprocessing=True`'
-                enqueuer = OrderedEnqueuer(generator, use_multiprocessing=use_multiprocessing)
+                enqueuer = OrderedEnqueuer(generator,
-                enqueuer = GeneratorEnqueuer(generator, use_multiprocessing=use_multiprocessing, wait_time=wait_time)
+                enqueuer = GeneratorEnqueuer(generator,
-                          use_multiprocessing=False, verbose=0):
+                          max_queue_size=10,
-                            'Please consider using the `keras.utils.Sequence` object.'))
+                UserWarning('Using a generator with `use_multiprocessing=True`'
-                enqueuer = OrderedEnqueuer(generator, use_multiprocessing=use_multiprocessing)
+                enqueuer = OrderedEnqueuer(generator,
-                enqueuer = GeneratorEnqueuer(generator, use_multiprocessing=use_multiprocessing,
+                enqueuer = GeneratorEnqueuer(generator,
-                        raise ValueError('output of generator should be '
+                        raise ValueError('Output of generator should be '
-    The task of an Enqueuer is to use parallelism to speed up the preprocessing.
+
-            max_queue_size: queue size (when full, threads could block on `put()`)
+            max_queue_size: queue size
-        """Creates a generator to extract data from the queue. Skip the data if it's None.
+        """Creates a generator to extract data from the queue.
-                or (inputs, targets, sample_weights)
+            Generator yielding tuples `(inputs, targets)`
-    def __init__(self, sequence, use_multiprocessing=False, scheduling='sequential'):
+    def __init__(self, sequence,
-            max_queue_size: queue size (when full, workers could block on put())
+            max_queue_size: queue size
-                    self.executor.apply_async(get_index, (self.sequence, i)), block=True)
+                    self.executor.apply_async(get_index,
-        """Creates a generator to extract data from the queue. Skip the data if it's None.
+        """Creates a generator to extract data from the queue.
-        Should be called by the same thread which called start().
+        Should be called by the same thread which called `start()`.
-            timeout: maximum time to wait on thread.join()
+            timeout: maximum time to wait on `thread.join()`
-        random_seed: Initial seed for workers, will be incremented by one for each workers.
+        random_seed: Initial seed for workers,
-    def __init__(self, generator, use_multiprocessing=False, wait_time=0.05, random_seed=None):
+    def __init__(self, generator,
-            max_queue_size: queue size (when full, threads could block on put())
+            max_queue_size: queue size
-        Should be called by the same thread which called start().
+        Should be called by the same thread which called `start()`.
-            timeout: maximum time to wait on thread.join()
+            timeout: maximum time to wait on `thread.join()`.
-        """Creates a generator to extract data from the queue. Skip the data if it's None.
+        """Creates a generator to extract data from the queue.
-import threading
+from keras.utils import Sequence
-                      max_q_size=10,
+                      max_queue_size=10,
-                      pickle_safe=False,
+                      use_multiprocessing=False,
-            generator: a generator.
+            generator: a generator or an instance of Sequence (keras.utils.Sequence)
-            max_q_size: maximum size for the generator queue
+            max_queue_size: maximum size for the generator queue
-            pickle_safe: if True, use process based threading.
+            use_multiprocessing: if True, use process based threading.
-                   hasattr(validation_data, '__next__'))
+                   hasattr(validation_data, '__next__') or
-            enqueuer.start(max_q_size=max_q_size, workers=workers)
+            if is_sequence:
-                            time.sleep(wait_time)
+                    generator_output = next(output_generator)
-                                max_q_size=max_q_size,
+                                max_queue_size=max_queue_size,
-                                pickle_safe=pickle_safe)
+                                use_multiprocessing=use_multiprocessing)
-                           max_q_size=10, workers=1, pickle_safe=False):
+                           max_queue_size=10, workers=1, use_multiprocessing=False):
-            max_q_size: maximum size for the generator queue
+            max_queue_size: maximum size for the generator queue
-            pickle_safe: if True, use process based threading.
+            use_multiprocessing: if True, use process based threading.
-            enqueuer.start(workers=workers, max_q_size=max_q_size)
+            if is_sequence:
-
+                generator_output = next(output_generator)
-                          pickle_safe=False, verbose=0):
+                          max_queue_size=10, workers=1,
-            generator: Generator yielding batches of input samples.
+            generator: Generator yielding batches of input samples
-            max_q_size: Maximum size for the generator queue.
+            max_queue_size: Maximum size for the generator queue.
-            pickle_safe: If `True`, use process based threading.
+            use_multiprocessing: If `True`, use process based threading.
-            enqueuer.start(workers=workers, max_q_size=max_q_size)
+            if is_sequence:
-
+                generator_output = next(output_generator)
-                 ('nb_worker', 'workers')],
+                 ('nb_worker', 'workers'),
-                      max_q_size=10,
+                      max_queue_size=10,
-                      pickle_safe=False,
+                      use_multiprocessing=False,
-            max_q_size: Maximum size for the generator queue
+            max_queue_size: Maximum size for the generator queue
-            pickle_safe: Ff True, use process based threading.
+            use_multiprocessing: Ff True, use process based threading.
-                                        max_q_size=max_q_size,
+                                        max_queue_size=max_queue_size,
-                                        pickle_safe=pickle_safe,
+                                        use_multiprocessing=use_multiprocessing,
-                           pickle_safe=False):
+                           max_queue_size=10, workers=1,
-            max_q_size: maximum size for the generator queue
+            max_queue_size: maximum size for the generator queue
-            pickle_safe: if True, use process based threading.
+            use_multiprocessing: if True, use process based threading.
-                                             max_q_size=max_q_size,
+                                             max_queue_size=max_queue_size,
-                                             pickle_safe=pickle_safe)
+                                             use_multiprocessing=use_multiprocessing)
-                          pickle_safe=False, verbose=0):
+                          max_queue_size=10, workers=1,
-            max_q_size: maximum size for the generator queue
+            max_queue_size: maximum size for the generator queue
-            pickle_safe: if True, use process based threading.
+            use_multiprocessing: if True, use process based threading.
-                                            max_q_size=max_q_size,
+                                            max_queue_size=max_queue_size,
-                                            pickle_safe=pickle_safe,
+                                            use_multiprocessing=use_multiprocessing,
-import zipfile
+import hashlib
-import sys
+import random
-import hashlib
+import sys
-from six.moves.urllib.error import URLError
+from six.moves.urllib.error import URLError
-from ..utils.generic_utils import Progbar
+try:
-                    validation_data=({'input_a': input_a_np, 'input_b': input_b_np}, {'dense_1': output_a_np, 'dropout': output_b_np}))
+                    validation_data=(
-    with pytest.raises(ValueError):
+    with pytest.raises(StopIteration):
-                        nb_worker=1)
+                        nb_worker=1, pickle_safe=True, max_q_size=3)
-                             nb_worker=1)
+                             nb_worker=1, pickle_safe=False, max_q_size=3)
-                            nb_worker=1)
+                            nb_worker=1, pickle_safe=False, max_q_size=3)
-    model.fit_generator(data_generator(True), 5, epochs, max_q_size=2)
+    model.fit_generator(data_generator(True), 5, epochs, max_queue_size=2)
-    gen_loss = model.evaluate_generator(data_generator(x_test, y_test, 50), 1, max_q_size=2)
+    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_queue_size=2, verbose=1)
-import pytest
+import sys
-from six.moves.urllib.request import pathname2url
+from itertools import cycle
-from keras.utils.data_utils import _hash_file
+
-                        max_q_size=10,
+                        max_queue_size=10,
-                        pickle_safe=True)
+                        use_multiprocessing=True)
-                        pickle_safe=False)
+                        max_queue_size=10,
-                        max_q_size=10,
+                        max_queue_size=10,
-                        pickle_safe=True)
+                        use_multiprocessing=True)
-                        pickle_safe=False)
+                        max_queue_size=10,
-                            max_q_size=10,
+                            max_queue_size=10,
-                            pickle_safe=True)
+                            use_multiprocessing=True)
-                            pickle_safe=False)
+                            max_queue_size=10,
-                             max_q_size=10,
+                             max_queue_size=10,
-                             pickle_safe=True)
+                             use_multiprocessing=True)
-                             pickle_safe=False)
+                             max_queue_size=10,
-    with pytest.raises(ValueError):
+    with pytest.raises(StopIteration):
-            workers=4, pickle_safe=True,
+            workers=4, use_multiprocessing=True,
-    with pytest.raises(ValueError):
+    with pytest.raises(StopIteration):
-            pickle_safe=False,
+            use_multiprocessing=False,
-    with pytest.raises(ValueError):
+    with pytest.raises(StopIteration):
-            workers=4, pickle_safe=True,
+            workers=4, use_multiprocessing=True,
-    with pytest.raises(ValueError):
+    with pytest.raises(StopIteration):
-            pickle_safe=False,
+            use_multiprocessing=False,
-    with pytest.raises(ValueError):
+    with pytest.raises(StopIteration):
-            workers=4, pickle_safe=True,
+            workers=4, use_multiprocessing=True,
-    with pytest.raises(ValueError):
+    with pytest.raises(StopIteration):
-            pickle_safe=False,
+            use_multiprocessing=False,
-import warnings
+    """One-hot encodes a text into a list of word indexes of size n.
-    return [(abs(hash(w)) % (n - 1) + 1) for w in seq]
+    return [(hash_function(w) % (n - 1) + 1) for w in seq]
-import pytest
+import pytest
-                       'Content-Type': 'application/json'}
+
-                   np.random.randint(batch_size, 2, 50))
+            yield (np.random.randint(1, 256, (2, 50)),
-        - [Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf) (original 1997 paper)
+        - [Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf) (original 1997 paper)
-    """Callback for creating simple, custom callbacks on-the-fly.
+    r"""Callback for creating simple, custom callbacks on-the-fly.
-                                                      logs['loss']))
+        # Stream the epoch loss to a file in JSON format. The file content
-                             plot_loss_callback,
+                             json_logging_callback,
-                    tf.summary.histogram(weight.name, weight)
+                    mapped_weight_name = weight.name.replace(':', '_')
-                        tf.summary.histogram('{}_grad'.format(weight.name), grads)
+                        tf.summary.histogram('{}_grad'.format(mapped_weight_name), grads)
-                        tf.summary.image(weight.name, w_img)
+                        tf.summary.image(mapped_weight_name, w_img)
-    @pytest.mark.parametrize('K', [KTH, KTF], ids=["KTH", "KTF"])
+    @pytest.mark.parametrize('K', [KTF], ids=["KTF"])
-from . import utils
+from . import utils
-
+import inspect
-            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):
+            if (key not in inspect.getargspec(tf.Session.run)[0] and
-
+import inspect
-from ..utils.generic_utils import has_arg
+        function_args = inspect.getargspec(theano.function)[0]
-            if not has_arg(theano.function, key, True):
+            if key not in function_args:
-                if has_arg(self.call, 'mask'):
+                if 'mask' in inspect.getargspec(self.call).args:
-                            if has_arg(layer.call, 'mask'):
+                            if 'mask' in inspect.getargspec(layer.call).args:
-                            if has_arg(layer.call, 'mask'):
+                            if 'mask' in inspect.getargspec(layer.call).args:
-        if has_arg(self.function, 'mask'):
+        arg_spec = inspect.getargspec(self.function)
-        if has_arg(self.layer.call, 'training'):
+        func_args = inspect.getargspec(self.layer.call).args
-        if has_arg(self.layer.call, 'mask'):
+        if 'mask' in func_args:
-from ..utils.generic_utils import func_dump, func_load, has_arg
+from ..utils.generic_utils import func_dump, func_load
-            if has_arg(self.mode, 'mask'):
+            arg_spec = inspect.getargspec(self.mode)
-from . import generic_utils
+from . import conv_utils
-from . import conv_utils
+            arg_spec = inspect.getargspec(cls.from_config)
-            if has_arg(cls.from_config, 'custom_objects'):
+            if 'custom_objects' in arg_spec.args:
-
+import inspect
-    if has_arg(layer_cls.__init__, 'weights') and len(weights):
+    if 'weights' in inspect.getargspec(layer_cls.__init__):
-from ..utils.generic_utils import has_arg
+        legal_params = []
-            else:
+            if params_name not in legal_params:
-            if has_arg(fn, name):
+            if name in fn_args:
-from keras.utils.generic_utils import custom_object_scope, has_arg
+from keras.utils.generic_utils import custom_object_scope
-
+from . import utils
-import inspect
+
-                    key not in inspect.getargspec(Function.__init__)[0]):
+            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):
-import inspect
+
-            if key not in function_args:
+            if not has_arg(theano.function, key, True):
-import inspect
+from ..utils.generic_utils import has_arg
-                if 'mask' in inspect.getargspec(self.call).args:
+                if has_arg(self.call, 'mask'):
-                            if 'mask' in inspect.getargspec(layer.call).args:
+                            if has_arg(layer.call, 'mask'):
-                            if 'mask' in inspect.getargspec(layer.call).args:
+                            if has_arg(layer.call, 'mask'):
-import inspect
+from ..utils.generic_utils import has_arg
-        if 'mask' in arg_spec.args:
+        if has_arg(self.function, 'mask'):
-import inspect
+from ..utils.generic_utils import has_arg
-        if 'training' in func_args:
+        if has_arg(self.layer.call, 'training'):
-        if 'mask' in func_args:
+        if has_arg(self.layer.call, 'mask'):
-from ..utils.generic_utils import func_dump, func_load
+from ..utils.generic_utils import func_dump, func_load, has_arg
-            if 'mask' in arg_spec.args:
+            if has_arg(self.mode, 'mask'):
-from . import data_utils
+from . import data_utils
-            if 'custom_objects' in arg_spec.args:
+            if has_arg(cls.from_config, 'custom_objects'):
-import inspect
+from .generic_utils import has_arg
-    if 'weights' in inspect.getargspec(layer_cls.__init__):
+    # Checking for empty weights array to avoid a problem where some
-import inspect
+from ..utils.generic_utils import has_arg
-            if params_name not in legal_params:
+            for fn in legal_params_fns:
-            if name in fn_args:
+            if has_arg(fn, name):
-from keras.utils.generic_utils import custom_object_scope
+from keras.utils.generic_utils import custom_object_scope, has_arg
-    key_losses = {'mean_square_error',
+    key_losses = {'mean_squared_error',
-                              'Update your method calls accordingly.', stacklevel=3)
+
-        String: 'float16', 'float32', or 'float64'.
+        floatx: String, 'float16', 'float32', or 'float64'.
-        x: A Variable.
+        x: A `Variable`.
-        x: A Variable.
+        x: A `Variable`.
-        x: A Variable.
+        x: A `Variable`.
-        value: A tensor with the same shape as `variable`.
+        x: A `Variable`.
-        An Operation to update the variable."""
+        An operation to update the variable.
-        Same type and shape as initializer
+        Tensor with same type and shape as `initializer`.
-            raise ValueError('The model expects ' + str(len(names)) +
+            raise ValueError('The model expects ' + str(len(names)) + ' ' +
-        config = {'alpha': self.alpha}
+        config = {'alpha': float(self.alpha)}
-    [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).
+@pytest.mark.skipif((K.backend() == 'cntk'),
-                    reason="cntk does not support reverse yet")
+                    reason='cntk does not support reverse yet')
-        layer = deserialize_layer(config.pop('layer'), custom_objects=custom_objects)
+        layer = deserialize_layer(config.pop('layer'),
-    """This wrapper allows to apply a layer to every temporal slice of an input.
+    """This wrapper applies a layer to every temporal slice of an input.
-            y = self.layer.call(inputs, **kwargs)  # (num_samples * timesteps, ...)
+            # (num_samples * timesteps, ...)
-        if 'training' in kwargs:
+        if uses_learning_phase:
-        model.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(5, 10)))
+        model.add(Bidirectional(LSTM(10, return_sequences=True),
-    model.predict(np.random.random((10, 3, 2)))
+    x = Input(shape=(3, 2))
-                       'softplus', 'softsign']
+                       'softplus', 'softsign', 'selu']
-    elif data_format == 'channels_last':
+    else:
-    elif data_format == 'channels_last':
+    else:
-        raise ValueError('Unknown data_format:', data_format)
+from ..preprocessing.sequence import _remove_long_seq
-    f.close()
+    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/imdb.npz')
-        labels = new_labels
+        xs, labels = _remove_long_seq(maxlen, xs, labels)
-        xs = [[oov_char if (w >= num_words or w < skip_top) else w for w in x] for x in xs]
+        xs = [[w if (skip_top <= w < num_words) else oov_char for w in x] for x in xs]
-    y_test = np.array(labels[len(x_train):])
+        xs = [[w for w in x if (skip_top <= w < num_words)] for x in xs]
-    y_test = f['y_test']
+    x_train, y_train = f['x_train'], f['y_train']
-    npzfile.close()
+    with np.load(path) as f:
-        labels = new_labels
+        xs, labels = _remove_long_seq(maxlen, xs, labels)
-        xs = [[oov_char if (w >= num_words or w < skip_top) else w for w in x] for x in xs]
+        xs = [[w if (skip_top <= w < num_words) else oov_char for w in x] for x in xs]
-    y_test = np.array(labels[int(len(xs) * (1 - test_split)):])
+        xs = [[w for w in x if (skip_top <= w < num_words)] for x in xs]
-            raise ValueError('Invalid data_format:', self.data_format)
+            noise_shape = (input_shape[0], 1, 1, input_shape[3])
-            raise ValueError('Invalid data_format:', self.data_format)
+            noise_shape = (input_shape[0], 1, 1, 1, input_shape[4])
-        for k in range(1, num_classes + 1):
+        # (k == 0 or k > num_classes) does not raise an error but just return an unmeaningful tensor.
-            with pytest.raises(Exception):
+            with pytest.raises(ValueError):
-    with pytest.raises(Exception):
+    with pytest.raises(AttributeError):
-    with pytest.raises(Exception):
+    with pytest.raises(AttributeError):
-    with pytest.raises(Exception):
+    with pytest.raises(AttributeError):
-    with pytest.raises(Exception):
+    with pytest.raises(AttributeError):
-    with pytest.raises(Exception):
+    with pytest.raises(TypeError):
-    with pytest.raises(Exception) as e:
+    with pytest.raises(RuntimeError):
-    with pytest.raises(Exception):
+    with pytest.raises(ValueError):
-    with pytest.raises(Exception):
+    with pytest.raises(TypeError):
-                  sample_weight_mode=None)
+    # training/testing doesn't work before compiling.
-    with pytest.raises(Exception) as exc:
+    with pytest.raises(ValueError) as exc:
-    with pytest.raises(Exception) as exc:
+    with pytest.raises(ValueError) as exc:
-        with pytest.raises(Exception):
+        with pytest.raises(ValueError):
-                       'dilation_rate': 2},
+                       'dilation_rate': 2,
-               input_shape=(num_samples, num_row, num_col, stack_size))
+               input_shape=(num_samples, stack_size, num_row, num_col))
-               input_shape=(2, 3, 4, 5))
+    for data_format in ['channels_last', 'channels_first']:
-def basic_batchnorm_test():
+def test_basic_batchnorm():
-               input_shape=(3, 3))
+@pytest.mark.skipif(K.backend() == 'cntk', reason='Stateful is not supported with CNTK')
-    def custom_generator():
+    def custom_generator(use_weights=False):
-            yield X, y
+            if use_weights:
-    with pytest.raises(Exception):
+    with pytest.raises(ValueError):
-    with pytest.raises(Exception):
+    with pytest.raises(ValueError):
-    with pytest.raises(Exception):
+    with pytest.raises(ValueError):
-    with pytest.raises(Exception):
+    with pytest.raises(ValueError):
-    with pytest.raises(Exception):
+    with pytest.raises(ValueError):
-    with pytest.raises(Exception):
+    with pytest.raises(ValueError):
-# Compile and train different models while meauring performance.
+# Compile and train different models while measuring performance.
-def test_merge_sum():
+def test_merge_sum(in_tmpdir):
-def test_merge_concat():
+def test_merge_concat(in_tmpdir):
-def test_merge_recursivity():
+def test_merge_recursivity(in_tmpdir):
-def test_merge_overlap():
+def test_merge_overlap(in_tmpdir):
-    def test_image_data_generator(self):
+    def test_image_data_generator(self, tmpdir):
-                                       shuffle=True, save_to_dir=tmp_folder):
+                                       shuffle=True, save_to_dir=str(tmpdir)):
-    def test_directory_iterator(self):
+    def test_directory_iterator(self, tmpdir):
-                os.mkdir(os.path.join(tmp_folder, path))
+                tmpdir.join(path).mkdir()
-                im.save(os.path.join(tmp_folder, filename))
+                im.save(str(tmpdir / filename))
-        dir_iterator = generator.flow_from_directory(tmp_folder)
+        dir_iterator = generator.flow_from_directory(str(tmpdir))
-        os.mkdir(os.path.join(tmp_folder, 'class-1'))
+    def test_directory_iterator_class_mode_input(self, tmpdir):
-                im.save(os.path.join(tmp_folder, filename))
+                filename = str(tmpdir / 'class-1' / 'image-{}.jpg'.format(count))
-        dir_iterator = generator.flow_from_directory(tmp_folder, class_mode='input')
+        dir_iterator = generator.flow_from_directory(str(tmpdir), class_mode='input')
-def test_ModelCheckpoint():
+def test_ModelCheckpoint(tmpdir):
-    filepath = 'checkpoint.h5'
+    filepath = str(tmpdir / 'checkpoint.h5')
-    assert os.path.exists(filepath)
+    assert os.path.isfile(filepath)
-    assert os.path.exists(filepath)
+    assert os.path.isfile(filepath)
-    assert os.path.exists(filepath)
+    assert os.path.isfile(filepath)
-    assert os.path.exists(filepath)
+    assert os.path.isfile(filepath)
-    assert os.path.exists(filepath.format(epoch=3))
+    assert os.path.isfile(filepath.format(epoch=1))
-def test_CSVLogger():
+def test_CSVLogger(tmpdir):
-    filepath = 'log.tsv'
+    filepath = str(tmpdir / 'log.tsv')
-    assert os.path.exists(filepath)
+    assert os.path.isfile(filepath)
-def test_TensorBoard():
+def test_TensorBoard(tmpdir):
-    filepath = './logs_' + str(np.random.randint(1, 1e4))
+    filepath = str(tmpdir / 'logs')
-    assert os.path.exists(filepath)
+    assert os.path.isdir(filepath)
-def test_TensorBoard_convnet():
+def test_TensorBoard_convnet(tmpdir):
-    filepath = './logs_' + str(np.random.randint(1, 1e4))
+    filepath = str(tmpdir / 'logs')
-    assert os.path.exists(filepath)
+    assert os.path.isdir(filepath)
-def test_TensorBoard_with_ReduceLROnPlateau():
+def test_TensorBoard_with_ReduceLROnPlateau(tmpdir):
-    filepath = './logs_' + str(np.random.randint(1, 1e4))
+    filepath = str(tmpdir / 'logs')
-    assert os.path.exists(filepath)
+    assert os.path.isdir(filepath)
-def test_sequential():
+def test_sequential(in_tmpdir):
-def test_nested_sequential():
+def test_nested_sequential(in_tmpdir):
-def test_data_utils():
+@pytest.fixture
-def test_io_utils():
+def test_io_utils(in_tmpdir):
-def test_multiprocessing_training_fromfile():
+def test_multiprocessing_training_fromfile(in_tmpdir):
-                          (self.monitor), RuntimeWarning)
+            warnings.warn(
-__version__ = '2.0.4'
+__version__ = '2.0.5'
-      version='2.0.4',
+      version='2.0.5',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.4',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.5',
-                          'instead to intialize with ones.', stacklevel=3)
+                          'instead to initialize with ones.', stacklevel=3)
-                          'instead to intialize with ones.', stacklevel=3)
+                          'instead to initialize with ones.', stacklevel=3)
-    if c > 0:
+    if c <= 0:  # if clipnorm == 0 no need to add ops to the graph
-from keras import layers
+from keras import layers, optimizers
-                        self.samples += 1
+        pool = multiprocessing.pool.ThreadPool()
-                        self.filenames.append(os.path.relpath(absolute_path, directory))
+        for dirpath in (os.path.join(directory, subdir) for subdir in classes):
-                         '0 or 1.')
+        raise ValueError('CNTK Backend: Set learning phase '
-        raise ValueError('Unsupported dtype:', dtype)
+        raise ValueError('CNTK Backend: Unsupported dtype: %s. '
-        raise ValueError('evaluating %s is not supported' % type(x))
+        raise ValueError('CNTK Backend: `eval` method on '
-                         'is less than the number of dynamic axis')
+        raise ValueError('CNTK backend: creating placeholder with '
-                             'random op on batch axis for now.')
+            raise ValueError('CNTK Backend: randomness op with '
-                             'random op on batch axis for now.')
+            raise ValueError('CNTK Backend: randomness op with '
-                             'random op on batch axis for now.')
+            raise ValueError('CNTK Backend: randomness op with '
-                             'is not supported for now.')
+            raise ValueError('CNTK backend: `count_params` with dynamic '
-                    'Warning: cntk backend does not support '
+                    'Warning: CNTK backend does not support '
-                    'The reshape did not takeplace.')
+                    'The reshape did not take place.')
-                         'permute on dynamic axis is not supported')
+        raise ValueError('CNTK backend: the permute pattern %s '
-        raise ValueError('Invalid dim_ordering:', data_format)
+        raise ValueError('CNTK Backend: Invalid dim_ordering:', data_format)
-                         'second axis as static axis')
+        raise ValueError('CNTK Backend: the input of static rnn '
-        raise ValueError('Input should be at least 3D.')
+        raise ValueError('CNTK Backend: the input of rnn has only rank %d '
-        raise ValueError('Dropout level must be in interval [0, 1[.')
+        raise ValueError('CNTK Backend: Invalid dropout level %s, '
-                                     'parameters when construct trainer.')
+                    raise ValueError('CNTK backend: when constructing trainer, '
-                                     'argument not found in input')
+                    raise ValueError('CNTK backend: argument %s is not found in inputs. '
-                                     'argument not found in input')
+                    raise ValueError('CNTK backend: metrics argument %s '
-                                     'argument not found in input')
+                    raise ValueError('CNTK backend: assign ops argument %s '
-                         'please provide specified input shape.')
+        raise ValueError('CNTK Backend: padding input tensor with '
-    # Note: tf.nn.softmax_cross_entropy_with_logits
+    # Note: tf.nn.sparse_softmax_cross_entropy_with_logits
-    # Note: tf.nn.softmax_cross_entropy_with_logits
+    # Note: tf.nn.sigmoid_cross_entropy_with_logits
-            split_at = int(len(x[0]) * (1. - validation_split))
+            if hasattr(x[0], 'shape'):
-        if input_tensor is not None:
+        if input_tensor is not None and batch_input_shape is None:
-        kernel_size: defualt 3, the kernel size of middle conv layer at main path
+        kernel_size: default 3, the kernel size of middle conv layer at main path
-        kernel_size: defualt 3, the kernel size of middle conv layer at main path
+        kernel_size: default 3, the kernel size of middle conv layer at main path
-    """Does validation on the compatiblity of targets and loss functions.
+    """Does validation on the compatibility of targets and loss functions.
-from keras.applications import vgg16
+from keras.applications import vgg19
-    img = vgg16.preprocess_input(img)
+    img = vgg19.preprocess_input(img)
-model = vgg16.VGG16(input_tensor=input_tensor,
+model = vgg19.VGG19(input_tensor=input_tensor,
-layer_features = outputs_dict['block4_conv2']
+layer_features = outputs_dict['block5_conv2']
-    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.
+x = preprocess_image(base_image_path)
-    np.random.seed(1337)
+    np.random.seed(np.random.randint(1, 1e7))
-    np.random.seed(1337)
+    np.random.seed(np.random.randint(1, 1e7))
-    filepath = './logs'
+    np.random.seed(np.random.randint(1, 1e7))
-    assert _backend in {'theano', 'tensorflow'}
+    assert _backend in {'theano', 'tensorflow', 'cntk'}
-    assert _backend in {'theano', 'tensorflow'}
+    assert _backend in {'theano', 'tensorflow', 'cntk'}
-if _BACKEND == 'theano':
+if _BACKEND == 'cntk':
-        ValueError: In case of invalid `data_format` argument.
+        ValueError: In one of the two cases below:
-            x += reshape(bias, (1, int_shape(bias)[0], 1, 1, 1))
+            if len(bias_shape) == 1:
-            x += reshape(bias, (1, 1, 1, 1, int_shape(bias)[0]))
+            if len(bias_shape) == 1:
-            x += reshape(bias, (1, int_shape(bias)[0], 1, 1))
+            if len(bias_shape) == 1:
-                               data_format='NHWC')
+            if len(bias_shape) == 1:
-            x += reshape(bias, (1, int_shape(bias)[0], 1))
+            if len(bias_shape) == 1:
-            x += reshape(bias, (1, 1, int_shape(bias)[0]))
+            if len(bias_shape) == 1:
-            x += reshape(bias, (1, bias.shape[0], 1, 1, 1))
+            if ndim(bias) == 1:
-            x += reshape(bias, (1, 1, 1, 1, bias.shape[0]))
+            if ndim(bias) == 1:
-            x += reshape(bias, (1, bias.shape[0], 1, 1))
+            if ndim(bias) == 1:
-            x += reshape(bias, (1, 1, 1, bias.shape[0]))
+            if ndim(bias) == 1:
-            x += reshape(bias, (1, bias.shape[0], 1))
+            if ndim(bias) == 1:
-            x += reshape(bias, (1, 1, bias.shape[0]))
+            if ndim(bias) == 1:
-        w *= K.cast(w >= 0., K.floatx())
+        w *= K.cast(K.greater_equal(w, 0.), K.floatx())
-        if inputs == []:
+        if isinstance(input, list) and inputs == []:
-        if inputs == []:
+        if isinstance(inputs, list) and inputs == []:
-        return inputs * K.cast(inputs > self.theta, K.floatx())
+        return inputs * K.cast(K.greater(inputs, self.theta), K.floatx())
-        output = K.permute_dimensions(output, (1, 0, 2))
+        output_length, _, filters = self.kernel_shape
-            output += K.reshape(self.bias, (1, output_length, filters))
+            output = K.bias_add(output, self.bias)
-        _, feature_dim, filters = self.kernel_shape
+        _, _, filters = self.kernel_shape
-            output = K.permute_dimensions(output, (2, 0, 1, 3))
+        output = K.local_conv2d(inputs,
-                                    (1, self.output_row, self.output_col, filters))
+            if self.data_format == 'channels_first' or self.data_format == 'channels_last':
-                    if K.backend() == 'theano':
+                    # Default values of symbolic_weights is /variable for theano and cntk
-        g = K.switch(n >= c, g * c / n, g)
+        g = K.switch(K.greater_equal(n, c), g * c / n, g)
-    model = applications.VGG16(weights=None, include_top=False)
+    model = applications.VGG19(weights=None, include_top=False)
-def check_single_tensor_operation(function_name, input_shape, **kwargs):
+def check_single_tensor_operation(function_name, input_shape, backend_list, **kwargs):
-    xtf = KTF.variable(val)
+    x_list = [k.variable(val) for k in backend_list]
-    ztf = KTF.eval(getattr(KTF, function_name)(xtf, **kwargs))
+    z_list = []
-        assert _zth._keras_shape == zth.shape
+    for i in range(len(z_list) - 1):
-                               y_input_shape, **kwargs):
+                               y_input_shape, backend_list, **kwargs):
-    xth = KTH.variable(xval)
+    yval = np.random.random(y_input_shape) - 0.5
-    yth = KTH.variable(yval)
+    ztf = KTF.eval(getattr(KTF, function_name)(xtf, ytf, **kwargs))
-    zth = KTH.eval(_zth)
+    output_cntk = getattr(KC, function_name)(xc, yc, **kwargs)
-        assert _zth._keras_shape == zth.shape
+
-    '''
+                                     input_shape, backend_list):
-    xtf = KTF.variable(val)
+    x_list = [k.variable(val) for k in backend_list]
-    ytf = getattr(KTF, first_function_name)(xtf, **first_function_args)
+    z_list = []
-    assert_allclose(zth, ztf, atol=1e-05)
+    for i in range(len(z_list) - 1):
-        check_single_tensor_operation('reverse', (4, 3, 2), axes=(1, 2))
+        check_two_tensor_operation('dot', (4, 2), (2, 4), BACKENDS)
-        xtf = KTF.variable(xval)
+        x_list = [k.variable(xval) for k in BACKENDS]
-        assert_allclose(zth, ztf, atol=1e-05)
+        y_list = [k.variable(yval) for k in BACKENDS]
-        check_single_tensor_operation('permute_dimensions', (4, 2, 3),
+        check_single_tensor_operation('reshape', (4, 2), BACKENDS, shape=(8, 1))
-        check_single_tensor_operation('squeeze', (4, 1, 1), axis=1)
+        check_single_tensor_operation('repeat', (4, 1), BACKENDS, n=3)
-                                         (4, 3, 1, 1))
+                                         (4, 3, 1, 1), BACKENDS)
-            arr_tf = KTF.variable(arr)
+            attr_list = [k.variable(arr) for k in BACKENDS]
-                    assert th_z._keras_shape == th_rep.shape
+                z_list = []
-        arr_tf = KTF.variable(arr)
+        attr_list = [k.variable(arr) for k in BACKENDS]
-            assert th_z._keras_shape == th_rep.shape
+        z_list = []
-        xtf = KTF.variable(val)
+        x_list = [k.variable(val) for k in BACKENDS]
-        assert_allclose(valth, valtf, atol=1e-05)
+        value_list = []
-        KTF.set_value(xtf, val)
+        value_list = []
-        assert_allclose(valth, valtf, atol=1e-05)
+        for i in range(len(value_list) - 1):
-        assert KTH.count_params(xth) == KTF.count_params(xtf)
+        number_params_list = []
-        check_single_tensor_operation('print_tensor', (1, 2, 3))
+        check_single_tensor_operation('print_tensor', (), BACKENDS)
-        assert KTH.get_variable_shape(xth) == KTF.get_variable_shape(xtf)
+        x_list = [k.variable(val) for k in BACKENDS]
-        check_single_tensor_operation('max', (4, 2), axis=1, keepdims=True)
+        check_single_tensor_operation('max', (4, 2), BACKENDS)
-        check_single_tensor_operation('min', (4, 2, 3), axis=[1, -1])
+        check_single_tensor_operation('min', (4, 2), BACKENDS)
-        check_single_tensor_operation('mean', (4, 2, 3), axis=[1, -1])
+        check_single_tensor_operation('mean', (4, 2), BACKENDS)
-        check_single_tensor_operation('std', (4, 2, 3), axis=[1, -1])
+        check_single_tensor_operation('std', (4, 2), BACKENDS)
-        check_single_tensor_operation('prod', (4, 2, 3), axis=[1, -1])
+        check_single_tensor_operation('prod', (4, 2), BACKENDS)
-        check_single_tensor_operation('cumsum', (4, 2), axis=1)
+        # cntk does not support cumsum and cumprod yet
-        check_single_tensor_operation('cumprod', (4, 2), axis=1)
+        check_single_tensor_operation('cumprod', (4, 2), [KTF, KTH])
-        # check_single_tensor_operation('any', (4, 2), axis=1, keepdims=True)
+        # check_single_tensor_operation('any', (4, 2), [KTF, KTH])
-        check_single_tensor_operation('clip', (4, 2), min_value=0.4,
+        # check_single_tensor_operation('all', (4, 2), [KTF, KTH])
-
+        check_two_tensor_operation('equal', (4, 2), (4, 2), BACKENDS)
-
+        x_list = [k.variable(val) for k in [KTH, KTF]]
-        assert_allclose(new_val_th, new_val_tf, atol=1e-05)
+        f_list = []
-        assert_allclose(unrolled_masked_th_state, masked_th_state, atol=1e-04)
+        last_output_list = []
-        assert_allclose(tf_outputs, th_outputs, atol=1e-04)
+        last_output_list = []
-        xth = KTH.switch(xth >= 0.5, xth * 0.1, xth * 0.2)
+        z_list = []
-        assert_allclose(zth, ztf, atol=1e-05)
+        for i in range(len(z_list) - 1):
-        check_single_tensor_operation('elu', (4, 10), alpha=0.5)
+        check_single_tensor_operation('relu', (4, 2), BACKENDS, alpha=0.1, max_value=0.5)
-        check_single_tensor_operation('tanh', (4, 2))
+        check_single_tensor_operation('sigmoid', (4, 2), BACKENDS)
-        check_single_tensor_operation('l2_normalize', (4, 3), axis=1)
+        x_list = [k.variable(val) for k in BACKENDS]
-        check_single_tensor_operation('pool2d', (5, 10, 12, 3), pool_size=(2, 2),
+        # cntk need pooling on dynamic axes, can't test in this way, is coverred in a seperate case
-        check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 2),
+        cntk_check_single_tensor_operation('pool2d', (5, 10, 12, 3), pool_size=(2, 2),
-        check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 3),
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), [KTH, KTF], pool_size=(2, 2),
-        check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), pool_size=(2, 2, 2),
+        # cntk need pooling on dynamic axes, can't test in this way, is coverred in a seperate case
-        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 2, 2),
+        cntk_check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), pool_size=(2, 2, 2),
-        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 3, 2),
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), [KTH, KTF], pool_size=(2, 2, 2),
-        assert np.abs(np.std(rand) - std) < 0.01
+        for k in BACKENDS:
-        assert np.min(rand) >= min_val
+        for k in BACKENDS:
-        assert np.min(rand) == 0
+        for k in BACKENDS:
-            koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), num_classes))
+        for k in BACKENDS:
-
+        # cntk not support it yet
-        for K in [KTF, KTH]:
+        for K in [KTH, KTF]:
-        for K in [KTF, KTH]:
+        for K in [KTH, KTF]:
-        for K in [KTF, KTH]:
+        for K in [KTH, KTF]:
-            assert KTF.dtype(t_a) == KTH.dtype(t_b)
+            a_list = []
-            assert np.array_equal(a, b)
+            a_list = []
-            for backend in (KTF, KTH):
+            for backend in [KTH, KTF]:
-    if K.backend() == 'tensorflow':
+    if K.backend() == 'tensorflow' or K.backend() == 'cntk':
-            K.eval(output)
+            # cntk doesn't support statefulness on LSTM yet, will enable it on cntk later
-    for stateful in (False, True):
+    # cntk does not support stateful yet.
-            raise ValueError(
+        if x.shape[self.channel_axis] not in {3, 4}:
-            generator.fit(x)
+
-            generator.flow(np.arange(x.shape[0]))
+
-            `(batch_size, units)`.
+            the output. The remaining tensors are the last states,
-            does not include the samples dimension (batch size).
+        target_shape: target shape. Tuple of integers.
-        (tuple of integers, does not include the samples axis)
+        (tuple of integers, does not include the batch axis)
-        """Find and replace a missing dimension in an output shape.
+        """Finds and replaces a missing dimension in an output shape.
-            output_shape: desired shape of the array with at most
+            input_shape: original shape of array being reshaped
-            The new output shape with a -1 replaced with its computed value.
+            The new output shape with a `-1` replaced with its computed value.
-        # 2) fallback: K.int_shape
+        # we need access to the shape of `inputs`.
-            # target shape not fully defined
+            # Target shape not fully defined.
-            return obj.item()
+            if isinstance(obj, np.ndarray):
-    # Fall back on pydot if necessary.
+    # pydotplus is an improved version of pydot
-        import pydot
+        import pydotplus as pydot
-        pydot = None
+        # Fall back on pydot if necessary.
-    path = get_file(path, origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz')
+    path = get_file(path,
-        N-D tensor with shape: `(batch_size, sequence_length_1, ..., sequence_length_N-1)`.
+        2D tensor with shape: `(batch_size, sequence_length)`.
-        (N+1)-D tensor with shape: `(batch_size, sequence_length_1, ..., sequence_length_N-1, output_dim)`.
+        3D tensor with shape: `(batch_size, sequence_length, output_dim)`.
-    return K.mean(K.maximum(0.0, neg - pos + 1), axis=-1)
+    neg = K.max((1. - y_true) * y_pred, axis=-1)
-          losses.logcosh]
+          losses.logcosh,
-    y_true = K.variable(np.array([[0, 1, 0], [1, 0, 0]]))
+    y_pred = K.variable(np.array([[0.3, 0.2, 0.1],
-    assert np.isclose(expected_loss, loss)
+    assert np.isclose(expected_loss, np.mean(loss))
-    # (float32_ref vs. float32 incomptability)
+    # (float32_ref vs. float32 incompatibility)
-            for inputs/kernels/ouputs.
+            for inputs/kernels/outputs.
-            for inputs/kernels/ouputs.
+            for inputs/kernels/outputs.
-            for inputs/kernels/ouputs.
+            for inputs/kernels/outputs.
-        in inputs/kernels/ouputs.
+        in inputs/kernels/outputs.
-        in inputs/kernels/ouputs.
+        in inputs/kernels/outputs.
-        in inputs/kernels/ouputs.
+        in inputs/kernels/outputs.
-            **params: ignored (exists for API compatiblity).
+            **params: ignored (exists for API compatibility).
-    This layer can add rows and columns or zeros
+    This layer can add rows and columns of zeros
-        2D tensor with shape: `(batch_size, sequence_length)`.
+        N-D tensor with shape: `(batch_size, sequence_length_1, ..., sequence_length_N-1)`.
-        3D tensor with shape: `(batch_size, sequence_length, output_dim)`.
+        (N+1)-D tensor with shape: `(batch_size, sequence_length_1, ..., sequence_length_N-1, output_dim)`.
-            input_length = input_shape[1]
+        if self.input_length is None:
-        return (input_shape[0], input_length, self.output_dim)
+            # input_length can be tuple if input is 3D or higher
-        data_format: One of `channels_first`, `channels_last`.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-            `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither `"channels_last"` or `"channels_first"`.
-        data_format: One of `channels_first`, `channels_last`.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-            `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither `"channels_last"` or `"channels_first"`.
-        data_format: One of `channels_last` or `channels_first`.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-            `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither `"channels_last"` or `"channels_first"`.
-        data_format: One of `channels_last` or `channels_first`.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-            `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither `"channels_last"` or `"channels_first"`.
-        data_format: string, one of 'channels_last', 'channels_first'.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-        data_format: string, one of 'channels_last', 'channels_first'.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-        data_format: string, one of 'channels_last', 'channels_first'.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-        data_format: string, one of 'channels_last', 'channels_first'.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-        data_format: string, one of 'channels_last', 'channels_first'.
+        data_format: string, `"channels_last"` or `"channels_first"`.
-        padding: string, one of 'same' , 'valid'
+        padding: string, `"same"` or `"valid"`.
-        a string, one of 'SAME', 'VALID'.
+        a string, `"SAME"` or `"VALID"`.
-        data_format: string, one of "channels_last", "channels_first".
+        data_format: string, `"channels_last"` or `"channels_first"`.
-        data_format: string, one of "channels_last", "channels_first".
+        data_format: string, `"channels_last"` or `"channels_first"`.
-        data_format: string, one of "channels_last", "channels_first".
+        data_format: string, `"channels_last"` or `"channels_first"`.
-        data_format: `channels_last` or `channels_first`.
+        padding: string, `"same"` or `"valid"`.
-        data_format: `channels_last` or `channels_first`.
+        padding: string, `"same"` or `"valid"`.
-        data_format: data format, `channels_first` or `channels_last`.
+        padding: string, `"same"` or `"valid"`.
-        data_format: `channels_last` or `channels_first`.
+        padding: string, `"same"` or `"valid"`.
-        pool_mode: one of `max`, `avg`.
+        padding: string, `"same"` or `"valid"`.
-        ValueError: if `pool_mode` is neither `max` or `avg`.
+        ValueError: if `data_format` is neither `"channels_last"` or `"channels_first"`.
-        pool_mode: one of `max`, `avg`.
+        padding: string, `"same"` or `"valid"`.
-        ValueError: if `pool_mode` is neither `max` or `avg`.
+        ValueError: if `data_format` is neither `"channels_last"` or `"channels_first"`.
-            one of "channels_first", "channels_last".
+        data_format: string, `"channels_last"` or `"channels_first"`.
-    f.close()
+    with h5py.File(filepath, mode='r') as f:
-        if len(inputs_set) != len(self.inputs):
+        if len(set(self.inputs)) != len(self.inputs):
-    # redudant outputs
+    # redundant outputs
-    # TODO: raise a warning
+    # this should work with a warning
-        ValueError if invalid `dim_ordering`
+        ValueError: if `dim_ordering` is invalid.
-        data_format: One of `"channels_first"`, `"channels_last"`.
+        data_format: One of `channels_first`, `channels_last`.
-        data_format: One of `"channels_first"`, `"channels_last"`.
+        data_format: One of `channels_first`, `channels_last`.
-        ValueError if invalid `padding'`
+        ValueError: if `padding` is invalid.
-        data_format: `"channels_last"` or `"channels_first"`.
+        padding: string, `same` or `valid`.
-        data_format: `"channels_last"` or `"channels_first"`.
+        padding: string, `same` or `valid`.
-        data_format: data format, "channels_first" or "channels_last".
+        padding: padding mode, `valid` or `same`.
-        data_format: `"channels_last"` or `"channels_first"`.
+        padding: string, `same` or `valid`.
-        pool_mode: one of `"max"`, `"avg"`.
+        padding: one of `valid`, `same`.
-        pool_mode: one of `"max"`, `"avg"`.
+        padding: one of `valid`, `same`.
-                for `input_shape` or `input_shape`.
+            ValueError: if `input_shape` and `output_shape` do not match.
-        TypeError if `config` is not a dictionary
+        TypeError: if `config` is not a dictionary.
-print("Pad sequences (samples x time)")
+print('Pad sequences (samples x time)')
-        if type(input_shape) is list:
+        if isinstance(input_shape, list):
-from tensorflow.python.ops import variables
+from tensorflow.python.ops import variables as tf_variables
-import warnings
+
-from .common import set_image_dim_ordering, image_dim_ordering
+from .common import set_image_dim_ordering
-    # Returns:
+    # Returns
-        ValueError if `dtype` is not supported
+        ValueError: if `dtype` is not supported.
-                          variables.Variable)):
+                          tf_variables.Variable,
-            increment: A tensor of same shape as `x`.
+    # Arguments
-        """
+    # Returns
-            decrement: A tensor of same shape as `x`.
+    # Arguments
-        """
+    # Returns
-        for key in kwargs.keys():
+        for key in kwargs:
-            data_format: string, one of "channels_last", "channels_first".
+    # Arguments
-        """
+    # Returns
-        class progress_tracker:
+        class ProgressTracker(object):
-            if progress_tracker.progbar is None:
+            if ProgressTracker.progbar is None:
-                progress_tracker.progbar = Progbar(total_size)
+                ProgressTracker.progbar = Progbar(total_size)
-                progress_tracker.progbar.update(count * block_size)
+                ProgressTracker.progbar.update(count * block_size)
-        progress_tracker.progbar = None
+        ProgressTracker.progbar = None
-        # Attempt to create an image of a blank graph to check the pydot/graphviz installation.
+        # Attempt to create an image of a blank graph
-    except Exception:  # pydot raises a generic Exception here, so no specific class can be caught.
+    except Exception:
-
+            label = '%s\n|{input:|output:}|{{%s}|{%s}}' % (label,
-        to_file: File name of the
+        to_file: File name of the plot image.
-                              'at ~/.keras/keras.json.')
+        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':
-        if layer.__class__.__name__ in conv_layers:
+    conv_layers = ['Conv1D',
-            weights[1] = conv_utils.convert_kernel(weights[1])
+            if layer.__class__.__name__ == 'ConvLSTM2D':
-            return cls.from_config(config['config'])
+            with CustomObjectScope(custom_objects):
-            return cls(**config['config'])
+            custom_objects = custom_objects or {}
-        progbar = None
+        progress_tracker.progbar = None
-    For instance, if a, b and c and Keras tensors,
+    For instance, if a, b and c are Keras tensors,
-          losses.hinge, losses.categorical_crossentropy,
+          losses.hinge,
-    def __init__(self, inputs, outputs, updates=None, name=None):
+    def __init__(self, inputs, outputs, updates=None, name=None, **session_kwargs):
-                              feed_dict=feed_dict)
+                              feed_dict=feed_dict,
-        **kwargs: Not used with TensorFlow.
+        **kwargs: Passed to `tf.Session.run`.
-    return Function(inputs, outputs, updates=updates)
+        for key in kwargs.keys():
-                msg = 'Invalid argument "%s" passed to K.function' % key
+                msg = 'Invalid argument "%s" passed to K.function with Theano backend' % key
-                are passed into K.function. Ignored for Tensorflow backend.
+                are passed into K.function. When using the Tensorflow backend,
-                Ignored for Tensorflow backend.
+                When using the Tensorflow backend, these are passed into
-            total_size = int(total_size)
+            content_type = response.info().get('Content-Length')
-                progbar = Progbar(total_size)
+        class progress_tracker:
-                progbar.update(count * block_size)
+                progress_tracker.progbar.update(count * block_size)
-                            functools.partial(dl_progress, progbar=progbar))
+                urlretrieve(origin, fpath, dl_progress)
-        target: Total number of steps expected.
+        target: Total number of steps expected, None if unknown.
-            self.total_width = len(bar)
+            if self.target is not -1:
-            if current < self.target:
+            if current < self.target and self.target is not -1:
-    """Converts a text to a sequence of word indices.
+    """Converts a text to a sequence of words (or tokens).
-        A list of integer word indices.
+        A list of words (or tokens).
-            or `(3, 224, 244)` (with `channels_first` data format).
+            or `(3, 224, 224)` (with `channels_first` data format).
-            or `(3, 224, 244)` (with `channels_first` data format).
+            or `(3, 224, 224)` (with `channels_first` data format).
-
+def test_shared_layer_depth_is_correct():
-        A tensor with expended dimensions.
+        A tensor with expanded dimensions.
-    """Adds a 1-sized dimension at index "dim".
+    """Adds a 1-sized dimension at index "axis".
-            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 10e-7))), u.T)
+            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + self.zca_epsilon))), u.T)
-             save_to_dir=None, save_prefix='', save_format='jpeg'):
+             save_to_dir=None, save_prefix='', save_format='png'):
-                            save_format='jpeg',
+                            save_format='png',
-                 save_to_dir=None, save_prefix='', save_format='jpeg'):
+                 save_to_dir=None, save_prefix='', save_format='png'):
-                 save_to_dir=None, save_prefix='', save_format='jpeg',
+                 save_to_dir=None, save_prefix='', save_format='png',
-                                 str(type(x)) + ".")
+                raise ValueError('Layer ' + self.name + ' was called with '
-
+from tensorflow.python.ops import variables
-        inputs = _to_list(inputs)
+    def test_is_keras_tensor(self):
-
+            self.saver = tf.train.Saver(list(embeddings.values()))
-            self.embeddings_logs = []
+            self.embeddings_ckpt_path = os.path.join(self.log_dir,
-        if self.embeddings_freq and self.embeddings_logs:
+        if self.embeddings_freq and self.embeddings_ckpt_path:
-                    self.saver.save(self.sess, log, epoch)
+                self.saver.save(self.sess,
-            1, 1), name=name, border_mode='same')(x)
+        x = AveragePooling2D((3, 3), padding='same', strides=(
-        self.wait = 0  # Allow instances to be re-used
+        # Allow instances to be re-used
-                dim1 = input_shape[2] + 2 * self.padding[0][0]
+                dim1 = input_shape[2] + self.padding[0][0] + self.padding[0][1]
-                dim2 = input_shape[3] + 2 * self.padding[1][0]
+                dim2 = input_shape[3] + self.padding[1][0] + self.padding[1][1]
-                dim3 = input_shape[4] + 2 * self.padding[2][0]
+                dim3 = input_shape[4] + self.padding[2][0] + self.padding[2][1]
-                dim1 = input_shape[1] + 2 * self.padding[0][1]
+                dim1 = input_shape[1] + self.padding[0][0] + self.padding[0][1]
-                dim2 = input_shape[2] + 2 * self.padding[1][1]
+                dim2 = input_shape[2] + self.padding[1][0] + self.padding[1][1]
-                dim3 = input_shape[3] + 2 * self.padding[2][1]
+                dim3 = input_shape[3] + self.padding[2][0] + self.padding[2][1]
-               input_shape=inputs.shape)
+    for data_format in ['channels_first', 'channels_last']:
-    assert_allclose(np_output[:, 2:-2, 2:-2, 2:-2, :], 1.)
+        # correctness test
-                self.writer.add_summary(summary_str, epoch)
+                val_size = val_data[0].shape[0]
-                                write_images=True, write_grads=True)
+                                write_images=True, write_grads=True,
-                                write_images=True, write_grads=True)
+                                write_images=True, write_grads=True,
-        self.word_counts = {}
+        self.word_counts = OrderedDict()
-        self.input_spec[0] = InputSpec(shape=(batch_size,) + input_shape[1:])
+        self.input_spec[0] = InputSpec(shape=(batch_size, None) + input_shape[2:])
-        self.input_spec = InputSpec(ndim=5)
+        self.input_spec = [InputSpec(ndim=5)]
-
+        if isinstance(input_shape, list):
-        input_shape = self.input_spec.shape
+        input_shape = self.input_spec[0].shape
-from keras.layers import convolutional_recurrent
+from keras.models import Sequential, Model
-    docstring = re.sub(r'    ([^\s\\]+):(.*)\n',
+    docstring = re.sub(r'    ([^\s\\\(]+):(.*)\n',
-    docstring = re.sub(r'    ([^\s\\]+):(.*)\n',
+    docstring = re.sub(r'    ([^\s\\\(]+):(.*)\n',
-            if not force and (now - self.last_update) < self.interval and current < self.target:
+            if not force and (now - self.last_update) < self.interval:
-            if not force and (now - self.last_update) < self.interval:
+            if not force and (now - self.last_update) < self.interval and current < self.target:
-from keras.layers import Dense, Activation, Input
+from keras.layers import Input
-                   'image_data_format': image_data_format()}
+if not os.path.exists(_keras_dir):
-                raise ValueError('Unknown ' + printable_module_name,
+                raise ValueError('Unknown ' + printable_module_name +
-    """Converts a Keras model to dot format.
+def model_to_dot(model,
-    dot.set('rankdir', 'TB')
+    dot.set('rankdir', rankdir)
-            label = '%s\n|{input:|output:}|{{%s}|{%s}}' % (label, inputlabels, outputlabels)
+            label = '%s\n|{input:|output:}|{{%s}|{%s}}' \
-    dot = model_to_dot(model, show_shapes, show_layer_names)
+               show_layer_names=True,
-        if class_mode not in {'categorical', 'binary', 'sparse', None}:
+        if class_mode not in {'categorical', 'binary', 'sparse',
-                             '"binary", "sparse", or None.')
+                             '"binary", "sparse", "input"'
-        if self.class_mode == 'sparse':
+        if self.class_mode == 'input':
-            if converting a "chnnels_first" model to "channels_last",
+            if converting a "channels_first" model to "channels_last",
-    return tf.reduce_logsumexp(x, reduction_indices=axis, keep_dims=keepdims)
+    return tf.reduce_logsumexp(x, axis=axis, keep_dims=keepdims)
-            models.Sequential.predict_proba,
+            models.Sequential.get_layer,
-    norm = T.sqrt(T.sum(T.square(x), axis=axis, keepdims=True))
+def l2_normalize(x, axis, epsilon=1e-12):
-            files to be parsed by Tensorboard.
+            files to be parsed by TensorBoard.
-        write_graph: whether to visualize the graph in Tensorboard.
+            and weight histograms for the layers of the model. If set to 0,
-            image in Tensorboard.
+            image in TensorBoard.
-                    tensors = self.model.inputs
+                    tensors += [K.learning_phase()]
-                cbk.validation_data = val_x + [val_y, val_sample_weights]
+                cbk.validation_data = val_data
-from keras.layers.core import Dense
+from keras.layers.core import Dense, Dropout
-                                write_images=True)
+                                write_images=True, write_grads=True)
-                                write_images=True)
+                                write_images=True, write_grads=True)
-def test_fuctional_model_saving():
+def test_functional_model_saving():
-        start, stop = key.start, key.stop
+            start, stop = key.start, key.stop
-        char_level: if True, every character will be treated as a word.
+        char_level: if True, every character will be treated as a token.
-        kernel: Numpy array (4D or 5D).
+        kernel: Numpy array (3D, 4D or 5D).
-    if not 4 <= kernel.ndim <= 5:
+    if not 3 <= kernel.ndim <= 5:
-                        w_img = tf.expand_dims(tf.expand_dims(w_img, 0), -1)
+                        shape = K.int_shape(w_img)
-    def __init__(self, inputs, outputs, updates=None):
+    def __init__(self, inputs, outputs, updates=None, name=None):
-    def __init__(self, inputs, outputs, updates=[], **kwargs):
+    def __init__(self, inputs, outputs, updates=[], name=None, **kwargs):
-            if isinstance(k, Iterable) and not is_zero_dim_ndarray:
+            if isinstance(k, six.string_types):
-def load_model(filepath, custom_objects=None):
+def load_model(filepath, custom_objects=None, compile=True):
-        a warning will be displayed.
+        a warning will be displayed. When `compile` is set
-__version__ = '2.0.3'
+__version__ = '2.0.4'
-      version='2.0.3',
+      version='2.0.4',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.3',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.4',
-                with open(self.filename) as f:
+                with open(self.filename, 'r' + self.file_flags) as f:
-            self.csv_file = open(self.filename, 'a')
+            self.csv_file = open(self.filename, 'a' + self.file_flags)
-            self.csv_file = open(self.filename, 'w')
+            self.csv_file = open(self.filename, 'w' + self.file_flags)
-    Noise
+    Core Layers
-    Sequence preprocessing
+    Sequence Preprocessing
-Initializations
+Initializers
-                verbose: 0, 1, or 2. Verbosity mode.
+            verbose: 0, 1, or 2. Verbosity mode.
-        model.add(Conv2D(64, (3, 3), padding='same))
+        model.add(Conv2D(64, (3, 3), padding='same'))
-          losses.cosine_proximity]
+          losses.cosine_proximity,
-        Arguments:
+        # Arguments
-    """Returns the default float type, as a string
+    """Returns the default float type, as a string.
-    convention ('channels_first' or 'channels_last').
+    """Returns the default image data format convention ('channels_first' or 'channels_last').
-        dim_ordering: string. `'tf'` or `'th'`.
+        dim_ordering: string. `tf` or `th`.
-        raise ValueError('Invalid border mode:', padding)
+        raise ValueError('Invalid padding:', padding)
-                if w >= num_words or w < skip_top:
+                if skip_top <= w < num_words:
-                if w >= num_words or w < skip_top:
+                if skip_top <= w < num_words:
-    if not (pydot and pydot.find_graphviz()):
+    try:
-        def build_map_of_graph(tensor, seen_nodes=None, depth=0,
+        def build_map_of_graph(tensor, finished_nodes, nodes_in_progress,
-            Does not try to detect cycles in the graph.
+            This recursively updates the map `layer_indices`,
-                depth: Current depth in the graph (0 = last output).
+                finished_nodes: Set of nodes whose subgraphs have been traversed
-            seen_nodes.add(make_node_marker(node, depth))
+            if node in nodes_in_progress:
-            layers_depths[layer] = current_depth
+
-                                       layer, node_index, tensor_index)
+                build_map_of_graph(x, finished_nodes, nodes_in_progress,
-            build_map_of_graph(x, seen_nodes, depth=0)
+            build_map_of_graph(x, finished_nodes, nodes_in_progress)
-                                 'but it received ' + str(len(values)) +
+                                 'but it received ' + str(len(states)) +
-                                 str(values))
+                                 str(states))
-    def get_initial_states(self, inputs):
+    def get_initial_state(self, inputs):
-        of the RNN layer.
+    # Note on specifying the initial state of RNNs
-        self.input_spec = InputSpec(ndim=3)
+        self.input_spec = [InputSpec(ndim=3)]
-    def get_initial_states(self, inputs):
+    def get_initial_state(self, inputs):
-        return initial_states
+        initial_state = [initial_state for _ in range(len(self.states))]
-        return super(Recurrent, self).__call__(inputs, **kwargs)
+        if initial_state is None:
-    def call(self, inputs, mask=None, initial_state=None, training=None):
+    def call(self, inputs, mask=None, training=None, initial_state=None):
-            initial_states = inputs[1:]
+            initial_state = inputs[1:]
-            initial_states = self.states
+            initial_state = self.states
-            initial_states = self.get_initial_states(inputs)
+            initial_state = self.get_initial_state(inputs)
-        if len(initial_states) != len(self.states):
+        if isinstance(mask, list):
-                             str(len(initial_states)) +
+                             str(len(initial_state)) +
-                                             initial_states,
+                                             initial_state,
-    def reset_states(self, states_value=None):
+    def reset_states(self, states=None):
-        batch_size = self.input_spec.shape[0]
+        batch_size = self.input_spec[0].shape[0]
-                                 ' entries')
+        # initialize state if None
-                value = states_value[i]
+        elif states is None:
-            K.set_value(state, value)
+                    raise ValueError('State ' + str(index) +
-        self.state_spec = InputSpec(shape=(batch_size, self.units))
+        self.input_spec[0] = InputSpec(shape=(batch_size, None, self.input_dim))
-        self.state_spec = InputSpec(shape=(batch_size, self.units))
+        self.input_spec[0] = InputSpec(shape=(batch_size, None, self.input_dim))
-                           InputSpec(shape=(batch_size, self.units))]
+        self.input_spec[0] = InputSpec(shape=(batch_size, None, self.input_dim))
-def test_specify_initial_state(layer_class):
+def test_specify_initial_state_keras_tensor(layer_class):
-    output = layer(inputs, initial_state=initial_state)
+    if len(initial_state) == 1:
-                      for _ in range(num_states)]
+    initial_state = [np.random.random((num_samples, units))
-    model.fit([inputs] + initial_states, targets)
+    model.fit([inputs] + initial_state, targets)
-    initial_state = [K.random_normal_variable((units,), 0, 1) for _ in range(num_states)]
+    initial_state = [K.random_normal_variable((num_samples, units), 0, 1)
-    model = Model([inputs], output)
+
-        'mixed4': 1.,
+        'mixed2': 0.2,
-def gradient_ascent(x, iterations, step):
+def gradient_ascent(x, iterations, step, max_loss=None):
-octave_scale = 1.3  # Size ratio between scales
+# Playing with these hyperparameters will also allow you to achieve new effects
-
+    img = gradient_ascent(img,
-import time
+import scipy
-from keras.applications import vgg16
+from keras.applications import inception_v3
-               'jitter': 0},
+# These are the names of the layers
-    img = load_img(image_path, target_size=(img_height, img_width))
+    # Util function to open, resize and format pictures
-    img = vgg16.preprocess_input(img)
+    img = inception_v3.preprocess_input(img)
-    # util function to convert a tensor into a valid image
+    # Util function to convert a tensor into a valid image.
-        x = x.reshape((3, img_height, img_width))
+        x = x.reshape((3, x.shape[2], x.shape[3]))
-    x = x[:, :, ::-1]
+        x = x.reshape((x.shape[1], x.shape[2], 3))
-                    weights='imagenet', include_top=False)
+K.set_learning_phase(0)
-# get the symbolic outputs of each "key" layer (we gave them unique names).
+# Get the symbolic outputs of each "key" layer (we gave them unique names).
-# define the loss
+# Define the loss.
-    # add the L2 norm of the features of a layer to the loss
+    # Add the L2 norm of the features of a layer to the loss.
-    # we avoid border artifacts by only involving non-border pixels in the loss
+    # We avoid border artifacts by only involving non-border pixels in the loss.
-        loss -= coeff * K.sum(K.square(x[:, :, 2: shape[2] - 2, 2: shape[3] - 2])) / np.prod(shape[1:])
+        loss += coeff * K.sum(K.square(x[:, :, 2: -2, 2: -2])) / scaling
-loss += settings['dream_l2'] * K.sum(K.square(dream)) / np.prod(img_size)
+        loss += coeff * K.sum(K.square(x[:, 2: -2, 2: -2, :])) / scaling
-# feel free to further modify the loss as you see fit, to achieve new effects...
+# Compute the gradients of the dream wrt the loss.
-f_outputs = K.function([dream], outputs)
+# Set up function to retrieve the value
-    outs = f_outputs([x])
+    outs = fetch_loss_and_grads([x])
-        grad_values = np.array(outs[1:]).flatten().astype('float64')
+    grad_values = outs[1]
-    """
+def resize_img(img, size):
-        assert self.loss_value is None
+def gradient_ascent(x, iterations, step):
-    print('Iteration %d completed in %ds' % (i, end_time - start_time))
+        print('..Loss value at', i, ':', loss_value)
-            img = img.resize(wh_tuple)
+        hw_tuple = (target_size[1], target_size[0])
-                                mode='average_exc_pad')
+                                mode=th_avg_pool_mode)
-        normed, mean, variance = K.normalize_batch_in_training(
+        def normalize_inference():
-                        epsilon=self.epsilon)
+        self.add_update([K.moving_average_update(self.moving_mean,
-        return K.in_train_phase(normed,
+        return K.in_train_phase(normed_training,
-    def call(self, inputs, mask=None):
+    def call(self, inputs, training=None, mask=None):
-                output = self.layer.call(x)
+                output = self.layer.call(x, **kwargs)
-            y = self.layer.call(inputs)  # (num_samples * timesteps, ...)
+            y = self.layer.call(inputs, **kwargs)  # (num_samples * timesteps, ...)
-              'Content-Type': 'application/json'}`
+            `{'Accept': 'application/json', 'Content-Type': 'application/json'}`
-            model.fit(X_train, Y_train, callbacks=[reduce_lr])
+        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
-            model.fit(X_train, Y_train, callbacks=[csv_logger])
+        csv_logger = CSVLogger('training.log')
-                                        initializer=self.bias_initializer,
+                                        initializer=bias_initializer,
-                K.set_value(self.bias, bias_value)
+# Importable from root because it's technically not a layer
-            name: String, the name for the weight variable.
+            regularizer: An optional Regularizer instance.
-            if len(v) > 1:
+            if (len(v) > 1) or (len(v) == 1 and len(v[0].inbound_layers) > 1):
-                   trainable=True,
+    @interfaces.legacy_add_weight_support
-        weight = K.variable(initializer(shape), dtype=K.floatx(), name=name)
+        if dtype is None:
-        self.alpha = self.add_weight(param_shape,
+        self.alpha = self.add_weight(shape=param_shape,
-        self.kernel = self.add_weight(kernel_shape,
+        self.kernel = self.add_weight(shape=kernel_shape,
-            self.bias = self.add_weight((self.filters,),
+            self.bias = self.add_weight(shape=(self.filters,),
-        self.kernel = self.add_weight(kernel_shape,
+        self.kernel = self.add_weight(shape=kernel_shape,
-            self.bias = self.add_weight((self.filters,),
+            self.bias = self.add_weight(shape=(self.filters,),
-            depthwise_kernel_shape,
+            shape=depthwise_kernel_shape,
-            pointwise_kernel_shape,
+            shape=pointwise_kernel_shape,
-            self.bias = self.add_weight((self.filters,),
+            self.bias = self.add_weight(shape=(self.filters,),
-        self.kernel = self.add_weight(kernel_shape,
+        self.kernel = self.add_weight(shape=kernel_shape,
-            recurrent_kernel_shape,
+            shape=recurrent_kernel_shape,
-            self.bias = self.add_weight((self.filters * 4,),
+            self.bias = self.add_weight(shape=(self.filters * 4,),
-        self.kernel = self.add_weight((input_dim, self.units),
+        self.kernel = self.add_weight(shape=(input_dim, self.units),
-            self.bias = self.add_weight((self.units,),
+            self.bias = self.add_weight(shape=(self.units,),
-            (self.input_dim, self.output_dim),
+            shape=(self.input_dim, self.output_dim),
-            self.kernel_shape,
+            shape=self.kernel_shape,
-                (output_length, self.filters),
+                shape=(output_length, self.filters),
-        self.kernel = self.add_weight(self.kernel_shape,
+        self.kernel = self.add_weight(shape=self.kernel_shape,
-            self.bias = self.add_weight((output_row, output_col, self.filters),
+            self.bias = self.add_weight(shape=(output_row, output_col, self.filters),
-            self.gamma = self.add_weight(shape,
+            self.gamma = self.add_weight(shape=shape,
-            self.beta = self.add_weight(shape,
+            self.beta = self.add_weight(shape=shape,
-            shape,
+            shape=shape,
-            shape,
+            shape=shape,
-        self.kernel = self.add_weight((self.input_dim, self.units),
+        self.kernel = self.add_weight(shape=(self.input_dim, self.units),
-            (self.units, self.units),
+            shape=(self.units, self.units),
-            self.bias = self.add_weight((self.units,),
+            self.bias = self.add_weight(shape=(self.units,),
-        self.kernel = self.add_weight((self.input_dim, self.units * 3),
+        self.kernel = self.add_weight(shape=(self.input_dim, self.units * 3),
-            (self.units, self.units * 3),
+            shape=(self.units, self.units * 3),
-            self.bias = self.add_weight((self.units * 3,),
+            self.bias = self.add_weight(shape=(self.units * 3,),
-        self.kernel = self.add_weight((self.input_dim, self.units * 4),
+        self.kernel = self.add_weight(shape=(self.input_dim, self.units * 4),
-            (self.units, self.units * 4),
+            shape=(self.units, self.units * 4),
-            self.bias = self.add_weight((self.units * 4,),
+            self.bias = self.add_weight(shape=(self.units * 4,),
-                samples have been seen by the model.
+                batches have been seen by the model.
-                idx = slice(key.start + self.start, key.stop + self.start)
+            if start is None:
-    [here](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html).
+    [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).
-                    continue
+        for node in layer.inbound_nodes:
-                See [objectives](/objectives).
+                See [losses](/losses).
-            layer = Dense(..., W_regularizer="MyObject")
+        with CustomObjectScope({'MyObject':MyObject}):
-            layer = Dense(..., W_regularizer="MyObject")
+        with custom_object_scope({'MyObject':MyObject}):
-        get_custom_objects()["MyObject"] = MyObject
+        get_custom_objects()['MyObject'] = MyObject
-    K.batch_set_value(weight_value_tuples)
+    K.batch_set_value(weight_value_tuples)
-    K.batch_set_value(weight_value_tuples)
+    K.batch_set_value(weight_value_tuples)
-                                        initializer='zero',
+                                        initializer=self.bias_initializer,
-        out_labels = deduped_out_labels
+        out_labels = self._get_deduped_metrics_names()
-        out_labels = self.metrics_names
+        # Prepare display labels.
-        raise TypeError('`model_fom_config` expects a dictionary, not a list. '
+        raise TypeError('`model_from_config` expects a dictionary, not a list. '
-                samples have been seen by the model.
+                indefinitely. An epoch finishes when `steps_per_epoch`
-                                samples_per_epoch=10000, epochs=10)
+                                steps_per_epoch=1000, epochs=10)
-MAxLEN = DIGITS + 1 + DIGITS
+MAXLEN = DIGITS + 1 + DIGITS
-    # Pad the data with spaces such that it is always MAxLEN.
+    # Pad the data with spaces such that it is always MAXLEN.
-    query = q + ' ' * (MAxLEN - len(q))
+    query = q + ' ' * (MAXLEN - len(q))
-x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)
+x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)
-    x[i] = ctable.encode(sentence, MAxLEN)
+    x[i] = ctable.encode(sentence, MAXLEN)
-model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))
+model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))
-        return K.ones_like(x)
+        # We won't actually use the output.
-vae.compile(optimizer='rmsprop', loss=[zero_loss])
+y = CustomVariationalLayer()([x, x_decoded_mean])
-vae.fit(x_train, x_train,
+vae.fit(x_train,
-
+        # We don't use this output.
-vae.compile(optimizer='rmsprop', loss=zero_loss)
+y = CustomVariationalLayer()([x, x_decoded_mean_squash])
-vae.fit(x_train, x_train,
+vae.fit(x_train,
-                raise ValueError('Error when checking ' + exception_prefix +
+                raise ValueError('Error when checking model ' +
-                        'Error when checking ' + exception_prefix +
+                        'Error when checking model ' +
-            raise TypeError('Error when checking ' + exception_prefix +
+            raise TypeError('Error when checking model ' +
-        if len(names) != 1:
+        if len(names) > 1:
-                             ' input arrays, but only received one array. '
+                             exception_prefix +
-                                    exception_prefix='model input')
+                                    exception_prefix='input')
-                                    exception_prefix='model target')
+                                    exception_prefix='target')
-    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))
+    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))
-    trainable_count, non_trainable_count = count_total_params(layers, layer_set=None)
+    trainable_count = int(
-                        # do not slice the training phase flag
+                        # Do not slice the training phase flag.
-                    # validation
+                if batch_index == len(batches) - 1:  # Last batch.
-                        # same labels assumed
+                        # Same labels assumed.
-                # do not slice the training phase flag
+                # Do not slice the training phase flag.
-                # do not slice the training phase flag
+                # Do not slice the training phase flag.
-        # validate user data
+        # Validate user data.
-        # prepare validation data
+        # Prepare validation data.
-        # prepare input arrays and training function
+        # Prepare input arrays and training function.
-        # prepare display labels
+        # Prepare display labels.
-        # (can happen with an output layer shared among multiple dataflows)
+        # Rename duplicated metrics name
-        # delegate logic to _fit_loop
+        # Delegate logic to `_fit_loop`.
-        # validate user data
+        # Validate user data.
-        # prepare inputs, delegate logic to _test_loop
+        # Prepare inputs, delegate logic to `_test_loop`.
-        # validate user data
+        # Validate user data.
-        # prepare inputs, delegate logic to _predict_loop
+        # Prepare inputs, delegate logic to `_predict_loop`.
-__version__ = '2.0.2'
+__version__ = '2.0.3'
-      version='2.0.2',
+      version='2.0.3',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.2',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.3',
-            or `(3, 224, 244)` (with `channels_first` data format).
+            or `(3, 224, 224)` (with `channels_first` data format).
-                    'pytest-xdist'],
+                    'pytest-xdist',
-        # subsequent layers: no need for input_shape
+    In subsequent layers, there is no need for the `input_shape`:
-    The output will then have shape `(32, 10, 8)`.
+    The output will then have shape `(32, 10, 32)`.
-                 embeddings_metadata={}):
+                 embeddings_metadata=None):
-        self.embeddings_metadata = embeddings_metadata
+        self.embeddings_metadata = embeddings_metadata or {}
-                         'Increase maxlen.')
+        if not xs:
-        self.built = False
+        self._losses = []
-            pass
+        if hasattr(self, '_losses'):
-            pass
+        if hasattr(self, '_updates'):
-            return []
+        self._per_input_losses = {}
-        targets: A tensor of shape batch_size and type `int32` or `int64`.
+        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.
-        `targets_i` is within top-k values of `predictions_i`
+        A 1D tensor of length `batch_size` and type `bool`.
-    """Returns whether the `targets` are in the top `k` `predictions`
+    """Returns whether the `targets` are in the top `k` `predictions`.
-        k: An int, number of top elements to consider.
+        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.
-        targets_i is within top-k values of predictions_i
+        A 1D tensor of length `batch_size` and type `bool`.
-    return result
+    # handle k < 1 and k >= predictions.shape[1] cases to match TF behavior
-        img_input = Input(tensor=input_tensor, shape=input_shape)
+        if not K.is_keras_tensor(input_tensor):
-          1 + maximum integer index occurring in the input data.
+      input_dim: int > 0. Size of the vocabulary,
-            (see [initializers](../initializers.md)).
+          (see [initializers](../initializers.md)).
-            (see [regularizer](../regularizers.md)).
+          the `embeddings` matrix
-            (see [constraints](../constraints.md)).
+          the `embeddings` matrix
-          used in the vocabulary (input_dim should equal `|vocabulary| + 2`).
+          used in the vocabulary (input_dim should equal size of
-              optimizer='rmsprop',
+              optimizer=opt,
-    os.makedirs(_keras_dir)
+# Attempt to read Keras config file.
-    _config = json.load(open(_config_path))
+    try:
-        f.write(json.dumps(_config, indent=4))
+# Save config file, if possible.
-# import backend
+# Import backend functions.
-        if losses is None:
+        if losses is None or losses == []:
-        if updates is None:
+        if updates is None or updates == []:
-                    updates += layer.get_updates_for(None)
+                # Collect updates that are dependent on inputs
-                    losses += layer.get_losses_for(None)
+                # Collect losses that are dependent on inputs
-            losses += self._per_input_losses.get(None, [])
+        losses += self.get_losses_for(None)
-                    self.add_update(layer.get_updates_for(layer_inputs), inputs)
+                    self.add_update(layer.get_updates_for(computed_tensors), inputs)
-                    self.add_loss(layer.get_losses_for(layer_inputs), inputs)
+                    self.add_loss(layer.get_losses_for(computed_tensors), inputs)
-        self.constraints = getattr(self.layer, 'constraints', {})
+    @property
-        return weights
+        return self.layer.get_weights()
-    model.add(wrappers.TimeDistributed(core.Dense(2, kernel_regularizer='l1'), input_shape=(3, 4)))
+    model.add(wrappers.TimeDistributed(
-        _initialize_variables()
+        with session.graph.as_default():
-                 write_images=False):
+                 write_images=False,
-                                   arguments=kwargs)
+                                   arguments=user_kwargs)
-                    if output_shape[-1] == 1 or self.loss_functions[i] == losses.binary_crossentropy:
+                    if (output_shape[-1] == 1 or
-    """Extracts an archive if it matches the tar, tar.gz, tar.bz, or zip formats
+    """Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.
-    # Return:
+    # Returns
-                        KeyboardInterrupt) as e:
+                        KeyboardInterrupt):
-             md5_hash=None, cache_subdir='datasets',
+def get_file(fname,
-        length = input_shape[1] + self.padding[0] + self.padding[1] if input_shape[1] is not None else None
+        if input_shape[1] is not None:
-            cols = input_shape[3] + self.padding[1][0] + self.padding[1][1] if input_shape[3] is not None else None
+            if input_shape[2] is not None:
-            cols = input_shape[2] + self.padding[1][0] + self.padding[1][1] if input_shape[2] is not None else None
+            if input_shape[1] is not None:
-            dim3 = input_shape[4] + 2 * self.padding[2][0] if input_shape[4] is not None else None
+            if input_shape[2] is not None:
-            dim3 = input_shape[3] + 2 * self.padding[2][1] if input_shape[3] is not None else None
+            if input_shape[1] is not None:
-            dim3 = input_shape[4] - self.cropping[2][0] - self.cropping[2][1] if input_shape[4] is not None else None
+            if input_shape[2] is not None:
-            dim3 = input_shape[3] - self.cropping[2][0] - self.cropping[2][1] if input_shape[3] is not None else None
+            if input_shape[1] is not None:
-    def save(self, filepath, overwrite=True):
+    def save(self, filepath, overwrite=True, include_optimizer=True):
-        save_model(self, filepath, overwrite)
+        save_model(self, filepath, overwrite, include_optimizer)
-def save_model(model, filepath, overwrite=True):
+def save_model(model, filepath, overwrite=True, include_optimizer=True):
-    if hasattr(model, 'optimizer'):
+    if include_optimizer and hasattr(model, 'optimizer'):
-can vary depending on your device, your model and the size of your data.
+Note that the relative performance of the different implementations can
-                             str(input))
+                             str(inputs))
-                                    origin='http://www.isosemi.com/datasets/wordlists.tgz', untar=True))
+                                    origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))
-                if value in custom_objects:
+                deserialized[key] = []
-             md5_hash=None, cache_subdir='datasets'):
+             md5_hash=None, cache_subdir='datasets',
-    as well as if it is already present in the cache.
+    By default the file at the url `origin` is downloaded to the
-        cache_subdir: directory being used as the cache
+        fname: Name of the file. If an absolute path `/path/to/file.txt` is
-    datadir_base = os.path.expanduser(os.path.join('~', '.keras'))
+    if cache_dir is None:
-            if not validate_file(fpath, md5_hash):
+        if file_hash is not None:
-                      'incomplete or outdated.')
+                      'incomplete or outdated because the ' + hash_algorithm +
-            tfile.close()
+            _extract_archive(fpath, datadir, archive_format='tar')
-    """Validates a file against a MD5 hash.
+def _hash_file(fpath, algorithm='sha256', chunk_size=65535):
-        md5_hash: the MD5 hash being validated against
+        algorithm: hash algorithm, one of 'auto', 'sha256', or 'md5'.
-    if str(hasher.hexdigest()) == str(md5_hash):
+    if ((algorithm is 'sha256') or
-            channel_axis = 1
+            channel_axis = 2
-                at the end of every epoch.
+                Number of steps to yield from validation generator
-            the time dimension in reverse order.
+        go_backwards: boolean. If True, do the iteration over the time
-            the time dimension in reverse order.
+        go_backwards: boolean. If True, do the iteration over the time
-            If True, process the input sequence backwards.
+            If True, process the input sequence backwards and return the
-        # to stack recurrent layers, you must use return_sequences=True on any recurrent layer that feeds into another recurrent layer.
+        # to stack recurrent layers, you must use return_sequences=True
-        # for subsequent layers, not need to specify the input size:
+        # for subsequent layers, no need to specify the input size:
-        if self.implementation == 0 and 0 < self.dropout < 1:
+        if self.implementation != 0 and 0 < self.dropout < 1:
-        if self.implementation == 0 and 0 < self.dropout < 1:
+        if self.implementation != 0 and 0 < self.dropout < 1:
-        if self.implementation == 0 and 0 < self.dropout < 1:
+        if self.implementation != 0 and 0 < self.dropout < 1:
-            raise ValueError('Invalid shape for y')
+            raise ValueError('Invalid shape for y: ' + str(y.shape))
-        fn
+        Tensor with dtype `dtype`.
-        Same type and shape as initializer
+        Tensor with same type and shape as `initializer`.
-            inputs: input tensor, or list/tuple of input tensors.
+            inputs: Input tensor, or list/tuple of input tensors.
-        if type(inputs) is list:
+        if isinstance(inputs, list):
-            element-wise operations
+            ValueError: if shape1 and shape2 are not compatible for
-                kwargs[arg] = eval(arg)
+        func_args = inspect.getargspec(self.layer.call).args
-def test_clasify_build_fn():
+def test_classify_build_fn():
-def test_clasify_class_build_fn():
+def test_classify_class_build_fn():
-def test_clasify_inherit_class_build_fn():
+def test_classify_inherit_class_build_fn():
-    clf.fit(X_train, str_y_train, batch_size=batch_size, nb_epoch=epochs)
+    clf.fit(X_train, str_y_train, batch_size=batch_size, epochs=epochs)
-    def call(self, inputs):
+    def call(self, inputs, **kwargs):
-    """Initializer that generates tensors initialized to 0."""
+    """Initializer that generates tensors initialized to 0.
-    """Initializer that generates tensors initialized to 1."""
+    """Initializer that generates tensors initialized to 1.
-    These values are similar to values from a `random_normal_initializer`
+    These values are similar to values from a `RandomNormal`
-    a fraction `p` of input units to 0 at each update during training time,
+    a fraction `rate` of input units to 0 at each update during training time,
-                    f.close()
+                        f.close()
-    return trainable_count, non_trainable_count
+    return int(trainable_count), int(non_trainable_count)
-    if sorted(reduction_axes) == range(ndim(x))[:-1]:
+    if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:
-        reduction_axes = range(x.ndim - 1)
+        reduction_axes = list(range(x.ndim - 1))
-        needs_broadcasting = (sorted(reduction_axes) != range(ndim)[:-1])
+        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])
-            (i.e. the number output of filters in the convolution).
+            (i.e. the number of output filters in the convolution).
-            output_shape = (batch_sizes[0],) + output_shape
+            output_shape = (list(batch_sizes)[0],) + output_shape
-    a = range(stop_ind)
+    a = list(range(stop_ind))
-    a += range(stop_ind, len_val)
+    a += list(range(stop_ind, len_val))
-            If you don't specify anything, no activation is applied
+            If you pass None, no activation is applied
-            If you don't specify anything, no activation is applied
+            If you pass None, no activation is applied
-            If you don't specify anything, no activation is applied
+            If you pass None, no activation is applied
-    # Compute quantities required for featurewise normalization
+    # Compute quantities required for feature-wise normalization
-            # we want to train the genrator to trick the discriminator
+            # we want to train the generator to trick the discriminator
-- Net2WiderNet exepriment:
+- Net2WiderNet experiment:
-Kaiming He, xiangyu Zhang, Shaoqing Ren, Jian Sun
+Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
-Kaiming He, xiangyu Zhang, Shaoqing Ren, Jian Sun
+Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
-            return _compute_elemwise_op_output_shape(shape2, shape1)
+            return self._compute_elemwise_op_output_shape(shape2, shape1)
-    cnn.add(Conv2D(64, 3, padding='same', strides=2))
+    cnn.add(Conv2D(64, 3, padding='same', strides=1))
-def map_fn(fn, elems, name=None):
+def map_fn(fn, elems, name=None, dtype=None):
-    return tf.map_fn(fn, elems, name=name)
+    return tf.map_fn(fn, elems, name=name, dtype=dtype)
-def map_fn(fn, elems, name=None):
+def map_fn(fn, elems, name=None, dtype=None):
-            kx = K.eval(K.map_fn(K.sum, x))
+            vx = K.variable(x)
-            kx = K.eval(K.foldl(lambda a, b: a + b, x))
+            kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))
-            p2 = K.eval(K.foldr(lambda a, b: a * b, x))
+            vx = K.variable(x)
-                             ' Got input shapes: %s' % input_shape)
+        batch_sizes = [s[0] for s in input_shape if s is not None]
-        return self._merge_function(inputs)
+        if self._reshape_required:
-    def from_config(cls, config):
+    def from_config(cls, config, custom_objects=None):
-            layer = layer_module.deserialize(conf)
+            layer = layer_module.deserialize(conf, custom_objects=custom_objects)
-        y_rev = self.backward_layer.call(inputs, mask)
+    def call(self, inputs, training=None, mask=None):
-            return K.concatenate([y, y_rev])
+            output = K.concatenate([y, y_rev])
-            return y + y_rev
+            output = y + y_rev
-            return (y + y_rev) / 2
+            output = (y + y_rev) / 2
-            return y * y_rev
+            output = y * y_rev
-            return [y, y_rev]
+            output = [y, y_rev]
-        model.add(wrappers.Bidirectional(rnn(output_dim),
+        model.add(wrappers.Bidirectional(rnn(output_dim, dropout=dropout_rate,
-        output = wrappers.Bidirectional(rnn(output_dim), merge_mode=mode)(input)
+        output = wrappers.Bidirectional(rnn(output_dim, dropout=dropout_rate,
-        p: float between 0 and 1. Fraction of the input units to drop.
+        rate: float between 0 and 1. Fraction of the input units to drop.
-    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1,
+    model.fit(x_train, y_train,
-          verbose=1, validation_data=(x_test, y_test))
+          batch_size=batch_size,
-model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,
+model.fit(x_train, y_train,
-model.fit(x_train, y_train, batch_size=batch_size, epochs=15,
+model.fit(x_train, y_train,
-    model.fit(X, y, batch_size=128, epochs=1)
+    model.fit(X, y,
-          verbose=1, validation_data=(x_test, y_test))
+model.fit(x_train, y_train,
-          verbose=1, validation_data=(x_test, y_test))
+          batch_size=batch_size,
-          verbose=1, validation_data=(x_test, y_test))
+model.fit(x_train, y_train,
-                    verbose=1, validation_data=(x_test, y_test))
+                    batch_size=batch_size,
-    history = model.fit(train_x, train_y, epochs=epochs,
+    history = model.fit(train_x, train_y,
-    history = model.fit(train_x, train_y, epochs=epochs,
+    history = model.fit(train_x, train_y,
-    history = model.fit(train_x, train_y, epochs=epochs,
+    history = model.fit(train_x, train_y,
-          epochs=epochs)
+          epochs=epochs,
-          batch_size=batch_size, epochs=epochs)
+model.fit(x_train, x_train,
-              batch_size=batch_size, epochs=epochs,
+              batch_size=batch_size,
-          epochs=10, batch_size=128)
+model.fit(x_train, y_train,
-                    verbose=1, validation_split=0.1)
+                    batch_size=batch_size,
-              expected_output,
+    model.fit(cos, expected_output,
-              verbose=1,
+              verbose=1,
-                       input_shape=(num_samples, num_steps, input_dim))
+    layer_test(local.LocallyConnected1D,
-    num_samples = 8
+    num_samples = 5
-                       input_shape=(num_samples, stack_size, num_row, num_col))
+    num_col = 8
-                outputs = tf.stack(successive_outputs)
+            last_output = successive_outputs[-1]
-                 data_format='channels_last',
+                 data_format=None,
-                `(symmetric_height_pad, symmetrc_width_pad)`.
+                `(symmetric_height_pad, symmetric_width_pad)`.
-                `(symmetric_height_crop, symmetrc_width_crop)`.
+                `(symmetric_height_crop, symmetric_width_crop)`.
-        self.backward_layer.build(input_shape)
+        with K.name_scope(self.forward_layer.name):
-                    outs.append(np.zeros(shape, dtype=K.floatx()))
+                    outs.append(np.zeros(shape, dtype=batch_out.dtype))
-        if len(y.shape) != 1:
+        if len(y.shape) == 2 and y.shape[1] > 1:
-        else:
+        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:
-        raise ImportError('`save_model` requires h5py.')
+        raise ImportError('`load_model` requires h5py.')
-        padding: One of `"valid"` or `"same"` (case-insensitive).
+        padding: Currently only supports `"valid"` (case-insensitive).
-        padding: one of `"valid"` or `"same"` (case-insensitive).
+        padding: Currently only support `"valid"` (case-insensitive).
-            depends solely on input[:t-1]. Useful when modeling temporal data
+            does not depend on input[t+1:]. Useful when modeling temporal data
-__version__ = '2.0.1'
+__version__ = '2.0.2'
-      version='2.0.1',
+      version='2.0.2',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.1',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.2',
-def softmax(x):
+def softmax(x, axis=-1):
-        s = K.sum(e, axis=-1, keepdims=True)
+    elif ndim > 2:
-                         'Here, ndim=' + str(ndim))
+        raise ValueError('Cannot apply softmax to a tensor that is 1D')
-    return tf.cast(x, tf.uint8)
+    return tf.reduce_any(x, reduction_indices=axis, keep_dims=keepdims)
-    return tf.cast(x, tf.uint8)
+    return tf.reduce_all(x, reduction_indices=axis, keep_dims=keepdims)
-                masks.append(K.cast(K.ones_like(input_i), 'uint8'))
+                # but cast it to bool first
-                    masks.append(K.cast(K.ones_like(input_i), 'uint8'))
+                    # but cast it to bool first
-    signature = inspect.getargspec(function)
+    signature = getattr(function, '_legacy_support_signature', None)
-            if n >= current_index + batch_size:
+            if n > current_index + batch_size:
-                indefinitely. An epoch finishes when `samples_per_epoch`
+                indefinitely. An epoch finishes when `steps_per_epoch`
-                                samples_per_epoch=10000, epochs=10)
+                                steps_per_epoch=10000, epochs=10)
-                be equal to the number of unique samples if your dataset
+                be equal to the number of unique samples of your dataset
-                    x_h = K.bias_add(x_r, self.bias_h)
+                    x_h = K.bias_add(x_h, self.bias_h)
-                   K.argmax(y_pred, axis=-1))
+    return K.cast(K.equal(K.argmax(y_true, axis=-1),
-                   K.cast(K.argmax(y_pred, axis=-1), K.floatx()))
+    return K.cast(K.equal(K.max(y_true, axis=-1),
-        y._keras_shape = (l,) + reference._keras_shape[1:]
+        y._keras_shape = indices._keras_shape + reference._keras_shape[1:]
-        y._keras_shape[axis] = x._keras_shape[axis] * rep
+        repeat_dim = x._keras_shape[axis]
-            n = np.append([1] * diff, n)
+        if _is_explicit_shape(n):
-
+            # symbolic n
-        y._keras_shape = (np.prod(x._keras_shape), )
+        if None in x._keras_shape:
-        y._keras_shape = (x._keras_shape[0], np.prod(x._keras_shape[1:]))
+        if None in x._keras_shape[1:]:
-        return self.model.predict_classes(x, **kwargs)
+        classes = self.model.predict_classes(x, **kwargs)
-    def from_config(cls, config):
+    def from_config(cls, config, custom_objects=None):
-        layer = deserialize_layer(config.pop('layer'))
+        layer = deserialize_layer(config.pop('layer'), custom_objects=custom_objects)
-                          max_q_size=10, workers=1, pickle_safe=False):
+                          max_q_size=10, workers=1,
-                          max_q_size=10, workers=1, pickle_safe=False):
+                          max_q_size=10, workers=1,
-                                            pickle_safe=pickle_safe)
+                                            pickle_safe=pickle_safe,
-    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2)
+    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2, verbose=1)
-from keras.layers.convolutional import Convolution2D, MaxPooling2D
+from keras.layers.convolutional import Conv2D, MaxPooling2D
-from keras.layers import Reshape, Lambda, merge
+from keras.layers import Reshape, Lambda
-    filter_size = 3
+    conv_filters = 16
-                          activation=act, init='he_normal', name='conv1')(input_data)
+    inner = Conv2D(conv_filters, kernel_size, padding='same',
-                          activation=act, init='he_normal', name='conv2')(inner)
+    inner = Conv2D(conv_filters, kernel_size, padding='same',
-    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filterss)
+    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)
-    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, init='he_normal', name='gru2_b')(gru1_merged)
+    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)
-                  name='dense2')(merge([gru_2, gru_2b], mode='concat'))
+    inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',
-    Model(input=[input_data], output=y_pred).summary()
+    Model(inputs=input_data, outputs=y_pred).summary()
-    model = Model(input=[input_data, labels, input_length, label_length], output=[loss_out])
+    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)
-                        epochs=stop_epoch, validation_data=img_gen.next_val(), num_val_samples=val_words,
+    model.fit_generator(generator=img_gen.next_train(), steps_per_epoch=(words_per_epoch - val_words),
-                  'e.g. `sum`, `concatenate`, etc.', stacklevel=2)
+                  'e.g. `add`, `concatenate`, etc.', stacklevel=2)
-            layers at the top of the network.
+        include_top: whether to include the fully-connected
-We need to specify two methods: `get_output_shape_for` and `call`.
+We need to specify two methods: `compute_output_shape` and `call`.
-                its new shape (obtained via self.get_output_shape_for).
+                its new shape (obtained via self.compute_output_shape).
-        get_output_shape_for
+        compute_output_shape
-                # It's an input layer: get_output_shape_for is identity,
+                # It's an input layer: compute_output_shape is identity,
-            `get_output_shape_for` method of layers).
+            `compute_output_shape` method of layers).
-            (same convention as the `get_output_shape_for` method of layers).
+            (same convention as the `compute_output_shape` method of layers).
-                                  '" during training.')
+                                  '" during training.', stacklevel=2)
-                          'has been renamed `epochs`.')
+                          'has been renamed `epochs`.', stacklevel=2)
-                              '` call to the Keras 2 API: ' + signature)
+                              '` call to the Keras 2 API: ' + signature, stacklevel=2)
-                      'right after the `Embedding` layer to get the same behavior.')
+                      'right after the `Embedding` layer to get the same behavior.', stacklevel=3)
-                          'instead to intialize with ones.')
+                          'instead to intialize with ones.', stacklevel=3)
-                      'Use `input_shape` instead.')
+                      'Use `input_shape` instead.', stacklevel=3)
-                          'instead to intialize with ones.')
+                          'instead to intialize with ones.', stacklevel=3)
-                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.')
+                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.', stacklevel=3)
-                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`')
+                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`', stacklevel=3)
-                              'Update your method calls accordingly.')
+                              'Update your method calls accordingly.', stacklevel=3)
-                                 ':' + class_name)
+                                 ':' + function_name)
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-            `(batch, width, height, channels)` while `channels_first`
+            `(batch, height, width, channels)` while `channels_first`
-            `(batch, channels, width, height)`.
+            `(batch, channels, height, width)`.
-__version__ = '2.0.0'
+__version__ = '2.0.1'
-      version='2.0.0',
+      version='2.0.1',
-      download_url='https://github.com/fchollet/keras/tarball/2.0.0',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.1',
-            'bias_initializer': initializers.serialize(self.kernel_initializer),
+            'bias_initializer': initializers.serialize(self.bias_initializer),
-            'bias_initializer': initializers.serialize(self.kernel_initializer),
+            'bias_initializer': initializers.serialize(self.bias_initializer),
-            'bias_initializer': initializers.serialize(self.kernel_initializer),
+            'bias_initializer': initializers.serialize(self.bias_initializer),
-            'bias_initializer': initializers.serialize(self.kernel_initializer),
+            'bias_initializer': initializers.serialize(self.bias_initializer),
-    If only_supporting is true, only the sentences that support the answer are kept.
+    If only_supporting is true, only the sentences
-    '''Given a file name, read the file, retrieve the stories, and then convert the sentences into a single story.
+    '''Given a file name, read the file,
-    If max_length is supplied, any stories longer than max_length tokens will be discarded.
+    If max_length is supplied,
-        y = np.zeros(len(word_idx) + 1)  # let's not forget that index 0 is reserved
+        # let's not forget that index 0 is reserved
-vocab = sorted(reduce(lambda x, y: x | y, (set(story + q + [answer]) for story, q, answer in train_stories + test_stories)))
+vocab = set()
-inputs_test, queries_test, answers_test = vectorize_stories(test_stories, word_idx, story_maxlen, query_maxlen)
+inputs_train, queries_train, answers_train = vectorize_stories(train_stories,
-# encode input sequence and questions (which are indices) to sequences of dense vectors
+# encode input sequence and questions (which are indices)
-match = dot([input_encoded_m, question_encoded], axes=(2, 2))  # (samples, story_maxlen, query_maxlen)
+# shape: `(samples, story_maxlen, query_maxlen)`
-               metrics=['accuracy'])
+              metrics=['accuracy'])
-           validation_data=([inputs_test, queries_test], answers_test))
+          batch_size=32,
-    If only_supporting is true, only the sentences that support the answer are kept.
+    If only_supporting is true,
-    '''Given a file name, read the file, retrieve the stories, and then convert the sentences into a single story.
+    '''Given a file name, read the file, retrieve the stories,
-    If max_length is supplied, any stories longer than max_length tokens will be discarded.
+    If max_length is supplied,
-        y = np.zeros(len(word_idx) + 1)  # let's not forget that index 0 is reserved
+        # let's not forget that index 0 is reserved
-QUERy_HIDDEN_SIZE = 100
+QUERY_HIDDEN_SIZE = 100
-print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN, EMBED_HIDDEN_SIZE, SENT_HIDDEN_SIZE, QUERy_HIDDEN_SIZE))
+print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,
-vocab = sorted(reduce(lambda x, y: x | y, (set(story + q + [answer]) for story, q, answer in train + test)))
+vocab = set()
-loss, acc = model.evaluate([tx, txq], ty, batch_size=BATCH_SIZE)
+model.fit([x, xq], y,
-           epochs=3,
+           epochs=120,
-from keras.models import Sequential
+from keras.models import Sequential, Model
-from keras.layers import Activation, Dense, Merge, Permute, Dropout
+from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate
-
+# placeholders
-                              input_length=story_maxlen))
+                              output_dim=64))
-# compute a 'match' between input sequence elements (which are vectors)
+
-response.add(Permute((2, 1)))  # output: (samples, query_maxlen, story_maxlen)
+match = dot([input_encoded_m, question_encoded], axes=(2, 2))  # (samples, story_maxlen, query_maxlen)
-answer.add(LSTM(32))
+answer = LSTM(32)(answer)  # (samples, 32)
-answer.add(Dense(vocab_size))
+answer = Dropout(0.3)(answer)
-answer.add(Activation('softmax'))
+answer = Activation('softmax')(answer)
-answer.compile(optimizer='rmsprop', loss='categorical_crossentropy',
+# build the final model
-answer.fit([inputs_train, queries_train, inputs_train], answers_train,
+
-           validation_data=([inputs_test, queries_test, inputs_test], answers_test))
+           epochs=3,
-                          'weights'}
+                          'weights',
-            dtype = kwargs.get('dtype', K.floatx())
+
-    """Sets the value of the image data format.
+    """Legacy setter for `image_data_format`.
-        data_format: string. `'channels_first'` or `'channels_last'`.
+        dim_ordering: string. `'tf'` or `'th'`.
-    """Legacy getter for data format.
+    """Legacy getter for `image_data_format`.
-        dim_size -= stride_size + kernel_size - 2
+    if dim_size is None:
-        return output
+            return K.in_train_phase(dropped_inputs, inputs,
-        if self.mode in ['sum', 'mul', 'ave']:
+        if self.mode in ['sum', 'mul', 'ave', 'max']:
-            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot'.
+            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'.
-from keras.layers import Input, Dense, Lambda
+from keras.layers import Input, Dense, Lambda, Layer
-    return xent_loss + kl_loss
+# placeholder loss
-from keras.layers import Input, Dense, Lambda, Flatten, Reshape
+from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer
-    return xent_loss + kl_loss
+# placeholder loss
-vae.compile(optimizer='rmsprop', loss=vae_loss)
+
-    
+
-    """                                            
+    """
-    wheres[i] = layers.Lambda(getwhere, output_shape=lambda x: x[0])([y_prepool, y])
+    wheres[i] = layers.Lambda(
-def lstm_args_preprocessor(args, kwargs):
+def recurrent_args_preprocessor(args, kwargs):
-    preprocessor=lstm_args_preprocessor)
+    preprocessor=recurrent_args_preprocessor)
-        low: Float, lower boundary of the output inteval.
+        low: Float, lower boundary of the output interval.
-    """Reverse a tensor along the the specified axes.
+    """Reverse a tensor along the specified axes.
-        p: A float, `0. <= p <= 1`, probability of binomlai distribution.
+        p: A float, `0. <= p <= 1`, probability of binomial distribution.
-    """Reverse a tensor along the the specified axes
+    """Reverse a tensor along the specified axes
-                lass indices (integers) to
+                class indices (integers) to
-    are equal to `mask_value`, then the timestep will masked (skipped)
+    are equal to `mask_value`, then the timestep will be masked (skipped)
-from keras.layers import Input, BatchNormalization
+from keras.layers import Input, BatchNormalization, ELU
-    ''' The proposed residual block from [4]'''
+def convresblock(x, nfeats=8, ksize=3, nskipped=2, elu=True):
-        y = Conv2D(nfeats, ksize, padding='same')(y)
+        if elu:
-      install_requires=['tensorflow', 'pyyaml', 'six'],
+      install_requires=['theano', 'pyyaml', 'six'],
-                      'e.g. `add`, `concatenate`, etc.')
+                      'e.g. `add`, `concatenate`, etc.', stacklevel=2)
-                  'e.g. `sum`, `concatenate`, etc.')
+                  'e.g. `sum`, `concatenate`, etc.', stacklevel=2)
-            files to be parsed by Tensorboard
+            files to be parsed by Tensorboard.
-                    'coverage==3.7.1'],
+                    'pytest-xdist'],
-        original_keras_version = f.attrs['keras_version']
+        original_keras_version = f.attrs['keras_version'].decode('utf8')
-        original_backend = f.attrs['backend']
+        original_backend = f.attrs['backend'].decode('utf8')
-        original_keras_version = f.attrs['keras_version']
+        original_keras_version = f.attrs['keras_version'].decode('utf8')
-        original_backend = f.attrs['backend']
+        original_backend = f.attrs['backend'].decode('utf8')
-        'all_module_classes': [merge],
+        'classes': [
-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-            blocks.append('\n\n'.join(subblocks))
+        blocks.append('\n\n'.join(subblocks))
-def stack(x):
+def stack(x, axis=0):
-        x: Tensor or variable.
+        x: List of tensors.
-    return tf.stack(x)
+    return tf.stack(x, axis=axis)
-    return T.stack(*x)
+def stack(x, axis=0):
-                states =  list(states)
+                states = list(states)
-        'all_module_classes': [keras.merge],
+        'all_module_classes': [merge],
-Objectives
+Losses
-from keras.layers import convolutional
+import keras
-from keras import objectives
+from keras import losses
-            core.MaxoutDense,
+            layers.Dense,
-            convolutional.ZeroPadding3D,
+            layers.Conv1D,
-        'classes': [generic_utils.CustomObjectScope]
+        'page': 'utils.md',
-                          'instead to intialize with ones')
+                          'instead to intialize with ones.')
-                          'instead to intialize with ones')
+                          'instead to intialize with ones.')
-                          '`padding`=(top_pad, bottom_pad, left_pad, right_pad)')
+                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.')
-                          '`padding`=((top_pad, bottom_pad), (left_pad, right_pad))')
+                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`')
-                 char_level=False):
+                 char_level=False,
-                raise ValueError('{} is not a legal parameter'.format(params_name))
+                if params_name != 'nb_epoch':
-              start_char=1, oov_char=2, index_from=3):
+              start_char=1, oov_char=2, index_from=3, **kwargs):
-              start_char=1, oov_char=2, index_from=3):
+              start_char=1, oov_char=2, index_from=3, **kwargs):
-            initial_epoch=0):
+            initial_epoch=0,
-            class_weight=None, sample_weight=None, initial_epoch=0):
+            class_weight=None, sample_weight=None, initial_epoch=0, **kwargs):
-    ordering convention ('channels_first' or 'channels_last').
+    """Sets the value of the data format convention.
-                              value_conversions=None):
+                              value_conversions=None,
-            layer_name = args[0].__class__.__name__
+            if object_type == 'class':
-                                str(list(args[1:])))
+            if check_positional_args:
-                signature = '`' + layer_name + '('
+                signature = '`' + object_name + '('
-                        signature += str(value)
+                        if isinstance(value, np.ndarray):
-                        signature += str(value)
+                        if isinstance(value, np.ndarray):
-                              '` layer call to the Keras 2 API: ' + signature)
+                warnings.warn('Update your `' + object_name +
-    return legacy_support
+generate_legacy_method_interface = functools.partial(generate_legacy_interface,
-def zeropadding2d_preprocessor(args, kwargs):
+def zeropadding2d_args_preprocessor(args, kwargs):
-    preprocessor=zeropadding2d_preprocessor)
+    preprocessor=zeropadding2d_args_preprocessor)
-
+
-        if self.mode in ['sum', 'mul', 'ave']:
+        if self.mode in ['sum', 'mul', 'ave', 'max']:
-            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot'.
+            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'.
-            return (input_shape[0], input_shape[1], self.units)
+            output_shape = (input_shape[0], input_shape[1], self.units)
-            return (input_shape[0], self.units)
+            return output_shape
-            return mask
+        if isinstance(mask, list):
-            return None
+            return output_mask
-            return outputs
+            output = outputs
-            return last_output
+            return output
-                                           K.zeros((self.filters * 2,))])
+                bias_value = np.zeros((self.filters * 4,))
-                                       bo], axis=-1)
+                kernel = np.concatenate([weights[0],
-            Use in combination with `bias_initializer="zeros"`.
+            Setting it to true will also force `bias_initializer="zeros"`.
-                                           K.zeros((self.units * 2,))])
+                bias_value = np.zeros((self.units * 4,))
-                                       weights[11]], axis=-1)
+                wi, ui, bi, wc, uc, bc, wf, uf, bf, wo, uo, bo = weights
-        if self.implementation == 1:
+        if self.implementation == 2:
-            elif self.implementation == 2:
+            elif self.implementation == 1:
-        self.recurrent_kernel_c = self.recurrent_kernel[:, self.units * 2: self.units * 3]
+
-        if self.implementation == 1:
+        if self.implementation == 2:
-            elif self.implementation == 2:
+            elif self.implementation == 1:
-                                          name='zp2d')
+                                           dim_ordering='tf',
-        You can specify the initial state of RNN layers by calling theme with
+        You can specify the initial state of RNN layers by calling them with
-        self.implementation = 0
+        self.implementation = implementation
-                    x_h = K.bias_add(self.bias_h)
+                    x_r = K.bias_add(x_r, self.bias_r)
-                                         weights[3],
+                                         weights[3],
-                                                   weights[4],
+                                                   weights[4],
-                                       weights[5],
+                                       weights[5],
-                                         weights[3],
+                                         weights[3],
-                                                   weights[4],
+                                                   weights[4],
-                                       weights[5],
+                                       weights[5],
-                 ('dropout_U', 'recurrent_dropout')],
+                 ('dropout_U', 'recurrent_dropout'),
-            def normalize_in_training():
+            def normalize_inference():
-                                normed,
+        return K.in_train_phase(normed,
-            if shape[:2] != (layer.filter_length, 1) or shape[3] != layer.filters:
+            if shape[:2] != (layer.kernel_size[0], 1) or shape[3] != layer.filters:
-    return args, kwargs, [('kernel_size', 'kernel_dim*')]
+            converted.append(('kernel_size', 'kernel_dim*'))
-
+
-
+    # util function to open, resize and format pictures
-
+    # util function to convert a tensor into a valid image
-
+    # continuity loss util function
-
+    """Loss and gradients evaluator.
-# run scipy-based optimization (L-BFGS) over the pixels of the generated image
+# Run scipy-based optimization (L-BFGS) over the pixels of the generated image
-    # add a random jitter to the initial image. This will be reverted at decoding time
+    # Add a random jitter to the initial image.
-    # run L-BFGS for 7 steps
+    # Run L-BFGS for 7 steps
-    # decode the dream and save it
+    # Decode the dream and save it
-maxlen = 100  # cut texts after this number of words (among top max_features most common words)
+# cut texts after this number of words
-print(len(X_test), 'test sequences')
+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
-print('X_test shape:', X_test.shape)
+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
-model.fit(X_train, y_train,
+model.fit(x_train, y_train,
-          validation_data=[X_test, y_test])
+          validation_data=[x_test, y_test])
-print(len(X_test), 'test sequences')
+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
-print('X_test shape:', X_test.shape)
+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
-model.fit(X_train, y_train,
+model.fit(x_train, y_train,
-          validation_data=(X_test, y_test))
+          validation_data=(x_test, y_test))
-print(len(X_test), 'test sequences')
+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
-print('X_test shape:', X_test.shape)
+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
-score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)
+model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,
-    Bi-gram : 0.9056 test accuracy after 5 epochs. 2s/epoch on GTX 980M gpu.
+    Bi-gram : 0.9056 test accuracy after 5 epochs. 2s/epoch on GTx 980M gpu.
-print('Average test sequence length: {}'.format(np.mean(list(map(len, X_test)), dtype=int)))
+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
-    for input_list in X_train:
+    for input_list in x_train:
-    print('Average test sequence length: {}'.format(np.mean(list(map(len, X_test)), dtype=int)))
+    # Augmenting x_train and x_test with n-grams features
-print('X_test shape:', X_test.shape)
+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
-model.fit(X_train, y_train,
+model.fit(x_train, y_train,
-          validation_data=(X_test, y_test))
+          validation_data=(x_test, y_test))
-from keras.layers import Dense, Activation, Embedding
+from keras.layers import Dense, Embedding
-    model.add(Embedding(max_features, embedding_dim, input_length=max_length))
+    model.add(Embedding(max_features, embedding_dim,
-    model.add(LSTM(embedding_dim, dropout=0.2, recurrent_dropout=0.2, implementation=mode))
+    model.add(LSTM(embedding_dim,
-path = get_file('nietzsche.txt', origin="https://s3.amazonaws.com/text-datasets/nietzsche.txt")
+path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')
-the compilation time can be a blocker using Theano.
+very slow on the CPU. Prefer the TensorFlow backend if you plan on iterating,
-from keras.layers import Input, Dense, Reshape, Flatten, Embedding, merge, Dropout
+from keras import layers
-from keras.layers.convolutional import UpSampling2D, Convolution2D
+from keras.layers.convolutional import UpSampling2D, Conv2D
-                          activation='relu', kernel_initializer='glorot_normal'))
+    cnn.add(Conv2D(256, 5, padding='same',
-                          activation='relu', kernel_initializer='glorot_normal'))
+    cnn.add(Conv2D(128, 5, padding='same',
-                          activation='tanh', kernel_initializer='glorot_normal'))
+    cnn.add(Conv2D(1, 2, padding='same',
-    h = merge([latent, cls], mode='mul')
+    h = layers.multiply([latent, cls])
-                          input_shape=(1, 28, 28)))
+    cnn.add(Conv2D(32, 3, padding='same', strides=2,
-    cnn.add(Convolution2D(64, 3, padding='same', strides=2))
+    cnn.add(Conv2D(64, 3, padding='same', strides=2))
-    cnn.add(Convolution2D(128, 3, padding='same', strides=2))
+    cnn.add(Conv2D(128, 3, padding='same', strides=2))
-    cnn.add(Convolution2D(256, 3, padding='same', strides=1))
+    cnn.add(Conv2D(256, 3, padding='same', strides=1))
-                [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))
+                [noise, sampled_labels.reshape((-1, 1))],
-Y_test = keras.utils.to_categorical(y_test, num_classes)
+y_train = keras.utils.to_categorical(y_train, num_classes)
-          verbose=1, validation_data=(x_test, Y_test))
+model.fit(x_train, y_train,
-scores = model.evaluate(x_test, Y_test, verbose=0)
+scores = model.evaluate(x_test, y_test, verbose=0)
-    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))
+    return K.mean(y_true * K.square(y_pred) +
-distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])
+distance = Lambda(euclidean_distance,
-from keras.layers import Convolution2D, MaxPooling2D
+from keras.layers import Conv2D, MaxPooling2D
-                            input_shape=input_shape))
+    model.add(Conv2D(filters, kernel_size,
-    model.add(Convolution2D(filters, kernel_size))
+    model.add(Conv2D(filters, kernel_size))
-exact location (the "where") of the maximal value in a pooled receptive field
+The first is the idea of properly 'unpooling.' During any max pool, the
-to the corresponding decoder layer, features being decoded can be "placed" in
+input image.  Therefore, if the 'where' is handed from the encoder
-"Visualizing and Understanding Convolutional Networks"
+'Visualizing and Understanding Convolutional Networks'
-"Stacked What-Where Auto-encoders"
+'Stacked What-Where Auto-encoders'
-Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
+'Deep Residual Learning for Image Recognition'
-Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
+'Identity Mappings in Deep Residual Networks'
-from keras.layers import UpSampling2D, Convolution2D, MaxPooling2D
+from keras.layers import Activation
-    y0 = Convolution2D(nfeats, ksize, ksize, border_mode='same')(x)
+    y0 = Conv2D(nfeats, ksize, padding='same')(x)
-        y = BatchNormalization(mode=0, axis=1)(y)
+        y = BatchNormalization(axis=1)(y)
-    return merge([y0, y], mode='sum')
+        y = Conv2D(nfeats, ksize, padding='same')(y)
-    ''' Calculate the "where" mask that contains switches indicating which
+    ''' Calculate the 'where' mask that contains switches indicating which
-print(X_test.shape[0], 'test samples')
+(x_train, _), (x_test, _) = mnist.load_data()
-    X_train = np.pad(X_train, [[0, 0], [0, 0], [2, 2], [2, 2]],
+    x_train = np.pad(x_train, [[0, 0], [0, 0], [2, 2], [2, 2]],
-    X_test = np.pad(X_test, [[0, 0], [0, 0], [2, 2], [2, 2]], mode='constant')
+    x_test = np.pad(x_test, [[0, 0], [0, 0], [2, 2], [2, 2]], mode='constant')
-    X_test = X_test[:, :, :-1, :-1]
+    x_train = x_train[:, :, :-1, :-1]
-    sys.exit("Script supports pool_size of 2 and 3.")
+    sys.exit('Script supports pool_size of 2 and 3.')
-input_shape = X_train.shape[1:]
+input_shape = x_train.shape[1:]
-# First build the encoder, all the while keeping track of the "where" masks
+# First build the encoder, all the while keeping track of the 'where' masks
-# We push the "where" masks to the following list
+# We push the 'where' masks to the following list
-                      output_shape=lambda x: x[0])
+    wheres[i] = layers.Lambda(getwhere, output_shape=lambda x: x[0])([y_prepool, y])
-# Now build the decoder, and use the stored "where" masks to place the features
+# Now build the decoder, and use the stored 'where' masks to place the features
-    y = merge([y, wheres[ind]], mode='mul')
+    y = layers.multiply([y, wheres[ind]])
-model.fit(X_train, X_train, validation_data=(X_test, X_test),
+model.fit(x_train, x_train, validation_data=(x_test, x_test),
-X_plot = np.vstack([np.hstack(x) for x in X_plot])
+x_recon = model.predict(x_test[:25])
-plt.imshow(X_plot, interpolation='none', cmap='gray')
+plt.imshow(x_plot, interpolation='none', cmap='gray')
-        _, labels, _ = k_means(xs.astype("float64"), k)
+        _, labels, _ = k_means(xs.astype('float64'), k)
-target_mask = K.variable(raw_target_mask.astype("float32"))
+style_mask = K.variable(raw_style_mask.astype('float32'))
-mask_input = Input(tensor=masks, shape=(None, None, None), name="mask_input")
+mask_input = Input(tensor=masks, shape=(None, None, None), name='mask_input')
-            1, 1), name=name, border_mode="same")(x)
+            1, 1), name=name, border_mode='same')(x)
-print('Generating Data')
+print('Generating Data...')
-print(expected_output.shape)
+print('Output shape:', expected_output.shape)
-print('Creating Model')
+print('Creating Model...')
-               batch_input_shape=(batch_size, tsteps, 1),
+               input_shape=(tsteps, 1),
-
+
-    new_layer = keras.layers.UpSampling3D((2, 2, 2), data_format='channels_last', name='us3d')
+    old_layer = keras.layers.UpSampling3D((2, 2, 2),
-                                str(allowed_positional_args) + '), but '
+                                ' positional arguments ' +
-                                str(args[1:]))
+                                str(list(args[1:])))
-                for value in args[1:]:
+                for i, value in enumerate(args[1:]):
-                    signature += ', '
+                    if i < len(args[1:]) - 1 or kwargs:
-    return args, kwargs, [('input_shape', 'input_dim')]
+        converted.append(('input_shape', 'input_dim'))
-    return args, kwargs, [('kernel_size', 'nb_row/nb_col')]
+            converted.append(('kernel_size', 'nb_row/nb_col'))
-
+from ..legacy import interfaces
-    return conv2d_args_preprocessor(args, kwargs)
+        converted.append(('init', 'depthwise_initializer/pointwise_initializer'))
-    return conv2d_args_preprocessor(args, kwargs)
+        converted.append(('output_shape', None))
-            self.states = [None, None, None, None]
+            self.states = [None, None]
-                             ' but was passed ' + str(len(initial_states)) +
+                             ' states but was passed ' +
-                        'instead.')
+                        'this is disallowed. Pass `strides` '
-    conversions=[('nb_filters', 'filters'),
+    conversions=[('nb_filter', 'filters'),
-from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent
+from keras import layers
-RNN = recurrent.LSTM
+RNN = layers.LSTM
-model.add(RepeatVector(DIGITS + 1))
+model.add(layers.RepeatVector(DIGITS + 1))
-model.add(Activation('softmax'))
+model.add(layers.TimeDistributed(layers.Dense(len(chars))))
-from keras.layers import Dense, Dropout, Layer, Activation
+from keras import layers
-class Antirectifier(Layer):
+class Antirectifier(layers.Layer):
-model.add(Dense(256, input_shape=(784,)))
+model.add(layers.Dense(256, input_shape=(784,)))
-model.add(Dense(256))
+model.add(layers.Dropout(0.1))
-model.add(Activation('softmax'))
+model.add(layers.Dropout(0.1))
-                                   W_constraint='max_norm', name='d')
+                                   W_constraint='maxnorm', name='d')
-                                   b_constraint='max_norm', name='d')
+                                   b_constraint='maxnorm', name='d')
-                                       W_constraint='max_norm')
+                                       W_constraint='maxnorm')
-
+    def __call__(self, inputs, initial_state=None, **kwargs):
-        # input shape: (nbias_samples, time (padded with zeros), input_dim)
+    def call(self, inputs, mask=None, initial_state=None, training=None):
-    def reset_states(self):
+    def reset_states(self, states_value=None):
-        else:
+        if states_value is not None:
-    states = 2 if layer_class is recurrent.LSTM else 1
+def test_specify_initial_state(layer_class):
-    initial_state = [Input((units,)) for _ in range(states)]
+    initial_state = [Input((units,)) for _ in range(num_states)]
-                      for _ in range(states)]
+                      for _ in range(num_states)]
-                                normalize_in_training,
+        return K.in_train_phase(normalize_in_training,
-            dtype=inputs.dtype,
+            dtype=outputs.dtype,
-from keras.layers import core, convolutional, recurrent
+from keras.layers import core, convolutional, recurrent, embeddings
-    old_layer = keras.layers.MaxPool2D(pool_size=2, border_mode='valid', name='maxpool2d')
+    old_layer = keras.layers.MaxPooling2D(pool_size=(2, 2), border_mode='valid', name='maxpool2d')
-    old_layer = keras.layers.MaxPool2D(2, 2, 'valid', name='maxpool2d')
+    old_layer = keras.layers.MaxPooling2D((2, 2), 2, 'valid', name='maxpool2d')
-    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='tf', name='maxpool2d')
+    old_layer = keras.layers.MaxPooling2D((2, 2), padding='valid', dim_ordering='tf', name='maxpool2d')
-    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='th', name='maxpool2d')
+    old_layer = keras.layers.MaxPooling2D((2, 2), padding='valid', dim_ordering='th', name='maxpool2d')
-    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='default', name='maxpool2d')
+    old_layer = keras.layers.MaxPooling2D((2, 2), padding='valid', dim_ordering='default', name='maxpool2d')
-    new_layer = keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.AveragePooling2D(pool_size=(2, 2), border_mode='valid', name='avgpooling2d')
-    new_layer = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.AveragePooling2D((2, 2), (2, 2), 'valid', name='avgpooling2d')
-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_last', name='avgpooling2d')
+    old_layer = keras.layers.AveragePooling2D((2, 2), padding='valid', dim_ordering='tf', name='avgpooling2d')
-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_first', name='avgpooling2d')
+    old_layer = keras.layers.AveragePooling2D((2, 2), padding='valid', dim_ordering='th', name='avgpooling2d')
-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.AveragePooling2D((2, 2), padding='valid', dim_ordering='default', name='avgpooling2d')
-        broadcast_beta = tf.reshape(beta, target_shape)
+        if gamma is None:
-        initial states.
+        You can specify the initial state of RNN layers by calling theme with
-        self.input_spec = None
+        self.input_spec = InputSpec(ndim=3)
-        # self.input_spec with a complete input shape.
+        # self.input_spec and self.state_spec with complete input shapes.
-        if not self.batch_size:
+        batch_size = self.input_spec.shape[0]
-                K.set_value(state, np.zeros((self.batch_size, self.units)))
+                K.set_value(state, np.zeros((batch_size, self.units)))
-            self.states = [K.zeros((self.batch_size, self.units))
+            self.states = [K.zeros((batch_size, self.units))
-        self.batch_size = input_shape[0]
+        batch_size = input_shape[0] if self.stateful else None
-        self.batch_size = input_shape[0]
+        batch_size = input_shape[0] if self.stateful else None
-        self.batch_size = input_shape[0]
+        batch_size = input_shape[0] if self.stateful else None
-    initial_states = [Input((units,)) for _ in range(states)]
+    initial_state = [Input((units,)) for _ in range(states)]
-    model = Model([inputs] + initial_states, output)
+    output = layer(inputs, initial_state=initial_state)
-is also different (same as Xception).
+Note that the input image format for this model is different than for
-WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'
+WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'
-              padding='same', strides=(1, 1),
+def conv2d_bn(x,
-    x = BatchNormalization(axis=bn_axis, name=bn_name)(x)
+    x = Conv2D(
-                input_tensor=None, input_shape=None,
+def InceptionV3(include_top=True,
-                                      include_top=include_top)
+    input_shape = _obtain_input_shape(
-            img_input = input_tensor
+        img_input = Input(tensor=input_tensor, shape=input_shape)
-        branch1x1 = conv2d_bn(x, 64, 1, 1)
+    branch1x1 = conv2d_bn(x, 64, 1, 1)
-        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)
+    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)
-        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)
+    # mixed 1: 35 x 35 x 256
-                               name='mixed' + str(i))
+    branch5x5 = conv2d_bn(x, 48, 1, 1)
-                             strides=(2, 2), padding='valid')
+    branch3x3dbl = conv2d_bn(
-                           name='mixed3')
+    x = layers.concatenate(
-                           name='mixed4')
+    x = layers.concatenate(
-                               name='mixed' + str(5 + i))
+        x = layers.concatenate(
-    branch7x7dbl = conv2d_bn(x, 160, 1, 1)
+    branch7x7dbl = conv2d_bn(x, 192, 1, 1)
-                           name='mixed7')
+    x = layers.concatenate(
-                            strides=(2, 2), padding='valid')
+    branch7x7x3 = conv2d_bn(
-                           name='mixed8')
+    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)
-                                       name='mixed9_' + str(i))
+        branch3x3 = layers.concatenate(
-                                          axis=channel_axis)
+        branch3x3dbl = layers.concatenate(
-
+        x = layers.concatenate(
-                                    md5_hash='fe114b3ff2ea4bf891e9353d1bbfb32f')
+            weights_path = get_file(
-                                    md5_hash='2f3609166de1d967d1a481094754f691')
+            weights_path = get_file(
-                            kwargs[key] = new_value
+                    old_value = kwargs[key]
-    value_conversions={'dim_ordering': {'tf': 'channels_last', 'th': 'channels_first', 'default': None}})
+    value_conversions={'dim_ordering': {'tf': 'channels_last',
-    new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.MaxPooling2D(pool_size=(2, 2), border_mode='valid', name='avgpooling2d')
-    new_layer = keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.MaxPooling2D((2, 2), (2, 2), 'valid', name='avgpooling2d')
-    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', data_format='channels_last', name='avgpooling2d')
+    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='tf', name='avgpooling2d')
-    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', data_format='channels_first', name='avgpooling2d')
+    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='th', name='avgpooling2d')
-    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='default', name='avgpooling2d')
-    new_layer = keras.layers.MaxPool1D(pool_size=2, padding='valid', name='maxpool1d')
+    old_layer = keras.layers.MaxPool1D(pool_length=2,
-    new_layer = keras.layers.MaxPool1D(pool_size=2, padding='valid', name='maxpool1d')
+    new_layer = keras.layers.MaxPool1D(pool_size=2,
-    old_layer = keras.layers.AvgPool1D(pool_length=2, border_mode='valid', name='d')
+    old_layer = keras.layers.AvgPool1D(pool_length=2,
-    old_layer = keras.layers.MaxPool2D(pool_length=2, border_mode='valid', name='maxpool2d')
+    old_layer = keras.layers.MaxPool2D(pool_size=2, border_mode='valid', name='maxpool2d')
-    new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', name='maxpool2d')
+    old_layer = keras.layers.MaxPool2D(2, 2, 'valid', name='maxpool2d')
-    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.MaxPool2D(pool_size=2, border_mode='valid', name='avgpooling2d')
-    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.MaxPool2D(2, 2, 'valid', name='avgpooling2d')
-                 ('border_mode', 'padding'),
+    conversions=[('border_mode', 'padding'),
-                               data_format='NCHW')
+            x += reshape(bias, (1, int_shape(bias)[0], 1, 1))
-
+    @interfaces.legacy_recurrent_support
-                              conversions=None):
+                              conversions=None, preprocessor=None):
-            converted = []
+            if preprocessor:
-        return th_sparse_module.basic.structured_dot(x, y)
+        out = th_sparse_module.basic.structured_dot(x, y)
-        return T.dot(x, y)
+        out = T.dot(x, y)
-                      'e.g. `sum`, `concatenate`, etc.')
+                      'e.g. `add`, `concatenate`, etc.')
-            x += reshape(bias, (1, int_shape(bias)[0], 1, 1))
+            x = tf.nn.bias_add(x, bias,
-            x += reshape(bias, (1, 1, 1, int_shape(bias)[0]))
+            x = tf.nn.bias_add(x, bias,
-        x += bias
+        x = tf.nn.bias_add(x, bias)
-            output += self.bias
+            output = K.bias_add(output, self.bias)
-        x += b
+        x = K.bias_add(x, b)
-                h += self.bias
+                h = K.bias_add(h, self.bias)
-                matrix_x += self.bias
+                matrix_x = K.bias_add(matrix_x, self.bias)
-                    x_h += self.bias_h
+                    x_z = K.bias_add(x_z, self.bias_z)
-                z += self.bias
+                z = K.bias_add(z, self.bias)
-                    '`' + new_arg + '`. Stick with the latter!')
+                    '`' + new_arg + '`. Stick to the latter!')
-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2dd')
+    old_layer = keras.layers.MaxPool2D(pool_length=2, border_mode='valid', name='maxpool2d')
-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2d')
+    old_layer = keras.layers.MaxPool2D(2, padding='valid', name='maxpool2d')
-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', data_format='channels_last', name='maxpool2d')
+    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='tf', name='maxpool2d')
-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', data_format='channels_first', name='maxpool2d')
+    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='th', name='maxpool2d')
-    new_layer = keras.layers.MaxPooling2D(pool_size=2, padding='valid', name='maxpool2d')
+    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='default', name='maxpool2d')
-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.AvgPool2D(pool_length=2, border_mode='valid', name='avgpooling2d')
-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.AvgPool2D(2, padding='valid', name='avgpooling2d')
-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_last', name='avgpooling2d')
+    old_layer = keras.layers.AvgPool2D(2, padding='valid', dim_ordering='tf', name='avgpooling2d')
-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_first', name='avgpooling2d')
+    old_layer = keras.layers.AvgPool2D(2, padding='valid', dim_ordering='th', name='avgpooling2d')
-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')
+    old_layer = keras.layers.AvgPool2D(2, padding='valid', dim_ordering='default', name='avgpooling2d')
-            for key in list(value_conversions.keys()):
+            for key in value_conversions:
-                    for old_value, new_value in value_conversions[key]:
+                    for old_value, new_value in value_conversions[key].items():
-    value_conversions={'dim_ordering': [('tf', 'channels_last'), ('th', 'channels_first'), ('default', None)]})
+    value_conversions={'dim_ordering': {'tf': 'channels_last', 'th': 'channels_first', 'default': None}})
-                              conversions=None):
+                              conversions=None,
-def map_fn(fn, elems, name=None):
+def map_fn(fn, elems, name=None, dtype=None):
-    return tf.map_fn(fn, elems, name=name)
+    return tf.map_fn(fn, elems, name=name, dtype=dtype)
-def map_fn(fn, elems, name=None):
+def map_fn(fn, elems, name=None, dtype=None):
-            kx = K.eval(K.map_fn(K.sum, x))
+            vx = K.variable(x)
-            kx = K.eval(K.foldl(lambda a, b: a + b, x))
+            kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))
-            p2 = K.eval(K.foldr(lambda a, b: a * b, x))
+            vx = K.variable(x)
-    return wrapper
+legacy_dense_support = generate_legacy_interface(
-            raise TypeError(args[0].__name__ + ' layer can have at most '
+            raise TypeError(args[0].__class__.__name__ + ' layer can have at most '
-        kwargs = convert_legacy_kwargs(args[0].__name__,
+        kwargs = convert_legacy_kwargs(args[0].__class__.__name__,
-    @interfaces.legacy_maxpooling1d_support
+    @interfaces.legacy_pooling1d_support
-    """Function wrapper to convert the `MaxPooling1D` constructor from Keras 1 to 2.
+def legacy_pooling1d_support(func):
-        func: `__init__` method of `MaxPooling1D`.
+        func: `__init__` method of `MaxPooling1D` or `AvgPooling1D`.
-            raise TypeError('The `MaxPooling1D` layer can have at most '
+            raise TypeError(args[0].__name__ + ' layer can have at most '
-        kwargs = convert_legacy_kwargs('MaxPooling1D',
+        kwargs = convert_legacy_kwargs(args[0].__name__,
-    return reference[indices]
+    y = reference[indices]
-    return T.tile(x, n)
+    y = T.tile(x, n)
-                return inputs + K.random_normal(shape=K.shape(inputs),
+                return inputs * K.random_normal(shape=K.shape(inputs),
-                                       args,
+                                       args[1:],
-
+        kwargs = convert_legacy_kwargs('Dense',
-            signature = '`Dropout(rate=' + str(args[1])
+            signature = '`Dropout(' + str(args[1])
-                signature += ', ' + kwarg + "="
+                signature += ', ' + kwarg + '='
-            warnings.warn('Update your `Dropout` layer call to Keras 2 API: ' + signature)
+            warnings.warn('Update your `Dropout` layer call '
-
+    @interfaces.legacy_dropout_support
-def lesser(x, y):
+def less(x, y):
-def lesser_equal(x, y):
+def less_equal(x, y):
-def lesser(x, y):
+def less(x, y):
-def lesser_equal(x, y):
+def less_equal(x, y):
-        check_two_tensor_operation('lesser_equal', (4, 2), (4, 2))
+        check_two_tensor_operation('less', (4, 2), (4, 2))
-    config['class_name'] = config['class_name'].lower()
+    # Make deserialization case-insensitive for built-in optimizers.
-    # TODO: `keras_shape` inference.
+
-    return T.transpose(x)
+    y = T.transpose(x)
-    return x.dimshuffle(pattern)
+    y = x.dimshuffle(pattern)
-    return T.repeat(x, rep, axis=axis)
+    y = T.repeat(x, rep, axis=axis)
-    return T.extra_ops.repeat(x, n, axis=1)
+    y = x.dimshuffle((0, 'x', 1))
-    return T.flatten(x)
+    y = T.flatten(x)
-    return x
+    y = T.reshape(x, (x.shape[0], T.prod(x.shape[1:])))
-    return x.dimshuffle(pattern)
+    y = x.dimshuffle(pattern)
-    return T.reshape(x, tuple(shape))
+    y = T.reshape(x, tuple(shape))
-    return T.set_subtensor(output[indices], x)
+    y = T.set_subtensor(output[indices], x)
-    zth = KTH.eval(getattr(KTH, function_name)(xth, **kwargs))
+    _zth = getattr(KTH, function_name)(xth, **kwargs)
-    zth = KTH.eval(getattr(KTH, function_name)(xth, yth, **kwargs))
+    _zth = getattr(KTH, function_name)(xth, yth, **kwargs)
-                    KTH.repeat_elements(arr_th, reps, axis=rep_axis))
+                th_z = KTH.repeat_elements(arr_th, reps, axis=rep_axis)
-        th_rep = KTH.eval(KTH.tile(arr_th, n))
+        th_z = KTH.tile(arr_th, n)
-    return np.prod(x.shape.eval())
+    # We don't want those compilation to show up in Theano profiler.
-
+    from ..layers.wrappers import Wrapper
-    assert len(layer.losses) == 3
+    assert len(layer.losses) == 4
-                             'Received input shape:', str(input_shape))
+                             '; Received input shape:', str(input_shape))
-            assert len(layer.losses) == 3
+            assert len(layer.losses) == 4
-                   input_shape=(batch_size, steps, input_dim))
+    # Test dilation
-                       input_shape=(num_samples, num_row, num_col, stack_size))
+    layer_test(convolutional.Conv2D,
-                           fixed_batch_size=True)
+    for padding in _convolution_paddings:
-                           fixed_batch_size=True)
+    layer_test(convolutional.Deconvolution2D,
-                           input_shape=(num_samples, num_row, num_col, stack_size))
+    layer_test(convolutional.SeparableConv2D,
-                                    stack_size))
+    layer_test(convolutional.Convolution3D,
-                                                                    num_classes=num_classes)
+    (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(
-    model.add(Activation('softmax'))
+    model.add(Dense(num_classes,
-        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+        model.compile(loss='categorical_crossentropy', optimizer='sgd')
-        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+        model.compile(loss='categorical_crossentropy', optimizer='sgd')
-        self.kernel = self.add_weight((input_dim, self.units),
+        self.kernel = self.add_weight((self.input_dim, self.units),
-
+
-
+
-    Words that were not seen in the trining set but are in the test set
+    Words that were not seen in the training set but are in the test set
-    Words that were not seen in the trining set but are in the test set
+    Words that were not seen in the training set but are in the test set
-                texts.append(f.read())
+                t = f.read()
-          epochs=2, batch_size=128)
+          epochs=10, batch_size=128)
-        3D tensor with shape `(batch_size, timesteps, input_dim)`.
+    # Input shapes
-        self.input_spec = InputSpec(ndim=3)
+        self.input_spec = None
-        self.input_spec = InputSpec(shape=input_shape)
+        if isinstance(input_shape, list):
-        self.input_spec = InputSpec(shape=input_shape)
+        if isinstance(input_shape, list):
-        self.input_spec = InputSpec(shape=input_shape)
+        if isinstance(input_shape, list):
-                      ' and graphviz for `pydotprint` to work.')
+    try:
-Y_test = np_utils.to_categorical(y_test, num_classes)
+y_train = keras.utils.to_categorical(y_train, num_classes)
-model.fit(x_train, Y_train,
+model.fit(x_train, y_train,
-          verbose=1, validation_data=(x_test, Y_test))
+          verbose=1, validation_data=(x_test, y_test))
-y_test = np_utils.to_categorical(y_test, num_classes)
+y_train = keras.utils.to_categorical(y_train, num_classes)
-y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)
+y_train = keras.utils.to_categorical(y_train, num_classes)
-Y_test = np_utils.to_categorical(y_test, num_classes)
+Y_train = keras.utils.to_categorical(y_train, num_classes)
-arXiv:1504.00941v2 [cs.NE] 7 Apr 2015
+arxiv:1504.00941v2 [cs.NE] 7 Apr 2015
-(X_train, y_train), (X_test, y_test) = mnist.load_data()
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-print(X_test.shape[0], 'test samples')
+x_train = x_train.reshape(x_train.shape[0], -1, 1)
-Y_test = np_utils.to_categorical(y_test, num_classes)
+y_train = keras.utils.to_categorical(y_train, num_classes)
-                    input_shape=X_train.shape[1:]))
+                    input_shape=x_train.shape[1:]))
-          verbose=1, validation_data=(X_test, Y_test))
+model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,
-scores = model.evaluate(X_test, Y_test, verbose=0)
+scores = model.evaluate(x_test, y_test, verbose=0)
-np.random.seed(1337)  # for reproducibility
+import keras
-from keras.layers import Dense, Dropout, Activation
+from keras.layers import Dense, Dropout
-y_test = np_utils.to_categorical(y_test, num_classes)
+y_train = keras.utils.to_categorical(y_train, num_classes)
-
+import keras
-input_shape = (1, 28, 28)  # image shape
+if keras.backend.image_data_format() == 'channels_first':
-    return np_utils.to_categorical(y)
+    return keras.utils.to_categorical(y)
-    model.add(MaxPooling2D(name='pool2'))
+    model.add(Conv2D(64, 3, input_shape=input_shape,
-    model.add(MaxPooling2D(name='pool2'))
+    model.add(Conv2D(new_conv1_width, 3, input_shape=input_shape,
-    model.add(Conv2D(64, 3, 3, border_mode='same', name='conv2'))
+    model.add(Conv2D(64, 3, input_shape=input_shape,
-        model.add(Conv2D(64, 3, 3, border_mode='same',
+        model.add(Conv2D(64, 3, padding='same',
-        model.add(Conv2D(64, 3, 3, border_mode='same', name='conv2-deeper'))
+        model.add(Conv2D(64, 3, padding='same', name='conv2-deeper'))
-    model.add(MaxPooling2D(name='pool2'))
+    model.add(MaxPooling2D(2, name='pool2'))
-np.random.seed(1337)  # for reproducibility
+import keras
-(X_train, y_train), (X_test, y_test) = mnist.load_data()
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
+if K.image_data_format() == 'channels_first':
-    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
+    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
-X_test /= 255
+x_train = x_train.astype('float32')
-y_test = np_utils.to_categorical(y_test, num_classes)
+y_train = keras.utils.to_categorical(y_train, num_classes)
-def make_model(dense_layer_sizes, filterss, num_conv, num_pool):
+def make_model(dense_layer_sizes, filters, kernel_size, pool_size):
-    num_pool: Size of pooling area for max pooling
+    dense_layer_sizes: List of layer sizes.
-                            border_mode='valid',
+    model.add(Convolution2D(filters, kernel_size,
-    model.add(Convolution2D(filterss, num_conv, num_conv))
+    model.add(Convolution2D(filters, kernel_size))
-    model.add(MaxPooling2D(pool_size=(num_pool, num_pool)))
+    model.add(MaxPooling2D(pool_size=pool_size))
-                                     'num_pool': [2]},
+                                     'filters': [8],
-validator.fit(X_train, y_train)
+validator.fit(x_train, y_train)
-metric_values = best_model.evaluate(X_test, y_test)
+metric_values = best_model.evaluate(x_test, y_test)
-np.random.seed(1337)  # for reproducibility
+import datetime
-    y_test = np_utils.to_categorical(test[1], num_classes)
+    y_train = keras.utils.to_categorical(train[1], num_classes)
-x_test_gte5 = x_test[y_test >= 5]         # np_utils.to_categorical
+y_train_gte5 = y_train[y_train >= 5] - 5
-from keras.utils.np_utils import to_categorical
+from keras.utils import to_categorical
-import sys
+
-np.random.seed(1337)  # for reproducibility
+import numpy as np
-print(len(X_test), 'test sequences')
+(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,
-print('Y_test shape:', Y_test.shape)
+x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')
-history = model.fit(X_train, Y_train,
+history = model.fit(x_train, y_train,
-score = model.evaluate(X_test, Y_test,
+score = model.evaluate(x_test, y_test,
-    return np.array([1 if p > 0.5 else 0 for p in y_pred])
+def normalize(x, axis=-1, order=2):
-    return np.argmax(p, axis=1)
+    # Returns
-def plot(model, to_file='model.png', show_shapes=False, show_layer_names=True):
+def plot_model(model,
-from keras import objectives
+from keras import metrics
-                              std=epsilon_std)
+                              stddev=epsilon_std)
-    xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)
+    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)
-from keras.layers import Convolution2D, Deconvolution2D
+from keras.layers import Conv2D, Conv2DTranspose
-from keras import objectives
+from keras import metrics
-filterss = 64
+filters = 64
-                       subsample=(1, 1))(conv_3)
+conv_1 = Conv2D(img_chns,
-                              mean=0., std=epsilon_std)
+                              mean=0., stddev=epsilon_std)
-decoder_upsample = Dense(filterss * 14 * 14, activation='relu')
+decoder_upsample = Dense(filters * 14 * 14, activation='relu')
-    output_shape = (batch_size, filterss, 14, 14)
+    output_shape = (batch_size, filters, 14, 14)
-    output_shape = (batch_size, 14, 14, filterss)
+    output_shape = (batch_size, 14, 14, filters)
-                                   subsample=(1, 1),
+decoder_deconv_1 = Conv2DTranspose(filters,
-                                   subsample=(1, 1),
+decoder_deconv_2 = Conv2DTranspose(filters, num_conv,
-    output_shape = (batch_size, filterss, 29, 29)
+    output_shape = (batch_size, filters, 29, 29)
-                                          subsample=(2, 2),
+    output_shape = (batch_size, 29, 29, filters)
-                                    activation='sigmoid')
+decoder_mean_squash = Conv2D(img_chns,
-    xent_loss = img_rows * img_cols * objectives.binary_crossentropy(x, x_decoded_mean)
+    xent_loss = img_rows * img_cols * metrics.binary_crossentropy(x, x_decoded_mean)
-        neg = -self.alpha * K.relu(-inputs)
+        if K.backend() == 'theano':
-            axes = self.axes
+            axes = []
-merged = layers.sum([encoded_sentence, encoded_question])
+merged = layers.add([encoded_sentence, encoded_question])
-    x = layers.sum([x, input_tensor])
+    x = layers.add([x, input_tensor])
-    x = layers.sum([x, shortcut])
+    x = layers.add([x, shortcut])
-    x = layers.sum([x, residual])
+    x = layers.add([x, residual])
-    x = layers.sum([x, residual])
+    x = layers.add([x, residual])
-    x = layers.sum([x, residual])
+    x = layers.add([x, residual])
-        x = layers.sum([x, residual])
+        x = layers.add([x, residual])
-    x = layers.sum([x, residual])
+    x = layers.add([x, residual])
-        layers.sum([j_tf, k_tf])
+        layers.add([j_tf, k_tf])
-    return Sum(**kwargs)(inputs)
+    return Add(**kwargs)(inputs)
-from keras.layers import Convolution1D, GlobalMaxPooling1D
+from keras.layers import Conv1D, GlobalMaxPooling1D
-filter_length = 3
+kernel_size = 3
-                    dropout=0.2))
+                    input_length=maxlen))
-                        subsample_length=1))
+model.add(Conv1D(filters,
-from keras.layers import Convolution1D, MaxPooling1D
+from keras.layers import Conv1D, MaxPooling1D
-filter_length = 5
+kernel_size = 5
-pool_length = 4
+pool_size = 4
-model.add(MaxPooling1D(pool_length=pool_length))
+model.add(Conv1D(filters,
-consume_less='cpu' preprocesses input to the LSTM which typically results in
+implementation=0 preprocesses input to the LSTM which typically results in
-consume_less='mem' does away with the preprocessing, meaning that it might take
+implementation=1 does away with the preprocessing, meaning that it might take
-consume_less='gpu' concatenates the input, output and forget gate's weights
+implementation=2 concatenates the input, output and forget gate's weights
-from keras.layers import Embedding, Dense, LSTM
+from keras.layers import Embedding, Dense, LSTM, Dropout
-modes = ['cpu', 'mem', 'gpu']
+modes = [0, 1, 2]
-    print('Testing mode: consume_less="{}"'.format(mode))
+    print('Testing mode: implementation={}'.format(mode))
-    model.add(LSTM(embedding_dim, dropout_W=0.2, dropout_U=0.2, consume_less=mode))
+    model.add(Embedding(max_features, embedding_dim, input_length=max_length))
-                          activation='relu', init='glorot_normal'))
+    cnn.add(Convolution2D(256, 5, padding='same',
-                          activation='relu', init='glorot_normal'))
+    cnn.add(Convolution2D(128, 5, padding='same',
-                          activation='tanh', init='glorot_normal'))
+    cnn.add(Convolution2D(1, 2, padding='same',
-                              init='glorot_normal')(image_class))
+                              embeddings_initializer='glorot_normal')(image_class))
-    return Model(input=[latent, image_class], output=fake_image)
+    return Model([latent, image_class], fake_image)
-    cnn.add(Convolution2D(32, 3, 3, border_mode='same', subsample=(2, 2),
+    cnn.add(Convolution2D(32, 3, padding='same', strides=2,
-    cnn.add(Convolution2D(64, 3, 3, border_mode='same', subsample=(1, 1)))
+    cnn.add(Convolution2D(64, 3, padding='same', strides=2))
-    cnn.add(Convolution2D(128, 3, 3, border_mode='same', subsample=(2, 2)))
+    cnn.add(Convolution2D(128, 3, padding='same', strides=2))
-    cnn.add(Convolution2D(256, 3, 3, border_mode='same', subsample=(1, 1)))
+    cnn.add(Convolution2D(256, 3, padding='same', strides=1))
-    return Model(input=image, output=[fake, aux])
+    return Model(image, [fake, aux])
-    epochss = 50
+    epochs = 50
-    combined = Model(input=[latent, image_class], output=[fake, aux])
+    combined = Model([latent, image_class], [fake, aux])
-        print('Epoch {} of {}'.format(epoch + 1, epochss))
+    for epoch in range(epochs):
-epochss = 5
+epochs = 5
-(X_train, y_train), (X_test, y_test) = mnist.load_data()
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-print(X_test.shape[0], 'test samples')
+x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
-row, col, pixel = X_train.shape[1:]
+row, col, pixel = x_train.shape[1:]
-encoded_rows = TimeDistributed(LSTM(output_dim=row_hidden))(x)
+encoded_rows = TimeDistributed(LSTM(row_hidden))(x)
-model = Model(input=x, output=prediction)
+model = Model(x, prediction)
-          verbose=1, validation_data=(X_test, Y_test))
+model.fit(x_train, Y_train, batch_size=batch_size, epochs=epochs,
-scores = model.evaluate(X_test, Y_test, verbose=0)
+scores = model.evaluate(x_test, Y_test, verbose=0)
-epochss = 200
+epochs = 200
-                    inner_init=initializers.Identity(gain=1.0),
+model.add(SimpleRNN(hidden_units,
-model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochss,
+model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,
-X_test /= 255
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-tr_pairs, tr_y = create_pairs(X_train, digit_indices)
+tr_pairs, tr_y = create_pairs(x_train, digit_indices)
-te_pairs, te_y = create_pairs(X_test, digit_indices)
+te_pairs, te_y = create_pairs(x_test, digit_indices)
-model = Model(input=[input_a, input_b], output=distance)
+model = Model([input_a, input_b], distance)
-from keras.layers import Convolution2D, MaxPooling2D
+from keras.layers import Conv2D, MaxPooling2D
-filterss = 32
+filters = 32
-    print(X_test.shape[0], 'test samples')
+    x_train = train[0].reshape((train[0].shape[0],) + input_shape)
-    Y_test = np_utils.to_categorical(test[1], num_classes)
+    y_train = np_utils.to_categorical(train[1], num_classes)
-    model.fit(X_train, Y_train,
+    model.fit(x_train, y_train,
-              validation_data=(X_test, Y_test))
+              validation_data=(x_test, y_test))
-    score = model.evaluate(X_test, Y_test, verbose=0)
+    score = model.evaluate(x_test, y_test, verbose=0)
-(X_train, y_train), (X_test, y_test) = mnist.load_data()
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-X_train_lt5 = X_train[y_train < 5]
+x_train_lt5 = x_train[y_train < 5]
-X_test_lt5 = X_test[y_test < 5]
+x_test_lt5 = x_test[y_test < 5]
-X_train_gte5 = X_train[y_train >= 5]
+x_train_gte5 = x_train[y_train >= 5]
-X_test_gte5 = X_test[y_test >= 5]         # np_utils.to_categorical
+x_test_gte5 = x_test[y_test >= 5]         # np_utils.to_categorical
-                  input_shape=input_shape),
+    Conv2D(filters, kernel_size,
-    Convolution2D(filterss, kernel_size, kernel_size),
+    Conv2D(filters, kernel_size),
-    MaxPooling2D(pool_size=(pool_size, pool_size)),
+    MaxPooling2D(pool_size=pool_size),
-            (X_test_lt5, y_test_lt5), num_classes)
+            (x_train_lt5, y_train_lt5),
-            (X_test_gte5, y_test_gte5), num_classes)
+            (x_train_gte5, y_train_gte5),
-    """Layer that sums a list of inputs.
+class Add(_Merge):
-    """Functional interface to the `Sum` layer.
+def add(inputs, **kwargs):
-def test_merge_sum():
+def test_merge_add():
-    o = layers.sum([i1, i2, i3])
+    o = layers.add([i1, i2, i3])
-        assert y.shape[:sample_weight.ndim] == sample_weight.shape
+        if len(sample_weight.shape) > len(y.shape):
-    history = model.fit(x_train, y_train, epochs=1, batch_size=16, verbose=0)
+    history = model.fit(x_train, y_train, epochs=2, batch_size=16, verbose=0)
-    _test_optimizer(optimizers.Adadelta(decay=1e-3))
+    _test_optimizer(optimizers.Adadelta(), target=0.6)
-                   input_shape=(3, 5, 4))
+    for padding in ['valid', 'same']:
-                        name = str(w.name)
+                    # Default values of symbolic_weights is /variable for theano
-                        name = 'param_' + str(i)
+                        if hasattr(w, 'name') and w.name:
-        padding = (w_pad, h_pad)
+        pad = (w_pad, h_pad)
-        padding = (0, 0)
+        pad = (0, 0)
-                                pad=padding,
+                                pad=pad,
-                                pad=padding,
+                                pad=pad,
-
+  for padding in ['valid', 'same']:
-                           'padding': 'valid'},
+                           'padding': padding},
-                         :]
+                return inputs[:,
-        padding: string, `"same"` or `"valid"`.
+        padding: string, `"same"`, `"causal"` or `"valid"`.
-    # pre-process dtype
+    kernel_shape = kernel.get_shape().as_list()
-    return T.set_subtensor(output[:, padding[0]:x.shape[1] + padding[1], :], x)
+    result = T.set_subtensor(output[:, padding[0]:x.shape[1] + padding[0], :], x)
-def spatial_2d_padding(x, padding=((1, 1),  (1, 1)), data_format=None):
+def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):
-        padding: string, "same" or "valid".
+        padding: string, `"same"`, `"causal"` or `"valid"`.
-        padding: One of `"valid"` or `"same"` (case-insensitive).
+        padding: One of `"valid"`, `"causal"` or `"same"` (case-insensitive).
-    allowed = {'valid', 'same'}
+    allowed = {'valid', 'same', 'causal'}
-        raise ValueError('The `padding` argument must be one of "valid", "same". '
+        raise ValueError('The `padding` argument must be one of "valid", "same" (or "causal" for Conv1D). '
-    assert padding in {'same', 'valid', 'full'}
+    assert padding in {'same', 'valid', 'full', 'causal'}
-
+    else:
-               input_shape=(batch_size, steps, input_dim))
+        # Test dilation
-                        x, y = generator_output
+                        x, _ = generator_output
-                        x, y, _ = generator_output
+                        x, _, _ = generator_output
-                        x, y, sample_weight = generator_output
+                        x, y, _ = generator_output
-            generator: a generator.
+            generator: A generator.
-                number of samples to use from validation generator
+            epochs: Integer, total number of iterations on the data.
-            class_weight: dictionary mapping class indices to a weight
+            class_weight: Dictionary mapping class indices to a weight
-            pickle_safe: if True, use process based threading.
+            max_q_size: Maximum size for the generator queue
-            initial_epoch: epoch at which to start training
+            initial_epoch: Epoch at which to start training
-                      positions=positions)
+        print_layer_summary(self,
-            sequential_like = False
+    if model.__class__.__name__ == 'Sequential':
-                sequential_like = False
+    sequential_like = True
-        if isinstance(layer, (Model, Sequential)):
+        if hasattr(layer, 'layers'):
-        'Deconvolution2D',
+        'Conv1D',
-            to_assign.append((layer.W, converted_w))
+            original_kernel = K.get_value(layer.kernel)
-
+    variables = tf.global_variables()
-            sess.run(tf.initialize_variables(uninitialized_variables))
+        sess.run(tf.variables_initializer(uninitialized_variables))
-        splits = tf.split(value=x, num_split=x_shape[axis], split_dim=axis)
+    splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)
-        return tf.reverse(x, dims)
+    return tf.reverse(x, axes)
-            return tf.nn.softmax_cross_entropy_with_logits(output, target)
+        return tf.nn.softmax_cross_entropy_with_logits(labels=target,
-            logits, targets)
+    res = tf.nn.sparse_softmax_cross_entropy_with_logits(
-        return tf.nn.sigmoid_cross_entropy_with_logits(output, target)
+
-      install_requires=['theano', 'pyyaml', 'six'],
+      install_requires=['tensorflow', 'pyyaml', 'six'],
-    tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1)
+    tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,
-        self.decay = K.variable(decay)
+        self.iterations = K.variable(0., name='iterations')
-        self.rho = K.variable(rho)
+        self.lr = K.variable(lr, name='lr')
-        self.decay = K.variable(decay)
+        self.decay = K.variable(decay, name='decay')
-        self.iterations = K.variable(0.)
+        self.iterations = K.variable(0., name='iterations')
-        self.lr = K.variable(lr)
+        self.lr = K.variable(lr, name='lr')
-        self.decay = K.variable(decay)
+        self.decay = K.variable(decay, name='decay')
-        self.iterations = K.variable(0.)
+        self.iterations = K.variable(0., name='iterations')
-        self.lr = K.variable(lr)
+        self.lr = K.variable(lr, name='lr')
-        self.decay = K.variable(decay)
+        self.decay = K.variable(decay, name='decay')
-        self.iterations = K.variable(0.)
+        self.iterations = K.variable(0., name='iterations')
-        self.beta_2 = K.variable(beta_2)
+        self.iterations = K.variable(0, name='iterations')
-        self.decay = K.variable(decay)
+        self.decay = K.variable(decay, name='decay')
-        self.beta_2 = K.variable(beta_2)
+        self.iterations = K.variable(0., name='iterations')
-        self.decay = K.variable(decay)
+        self.decay = K.variable(decay, name='decay')
-        self.beta_2 = K.variable(beta_2)
+        self.iterations = K.variable(0., name='iterations')
-        self.iterations = K.variable(0.)
+        self.iterations = K.variable(0., name='iterations')
-
+                    tf.summary.histogram(weight.name, weight)
-                            tf.summary.image(weight.name, w_img)
+                        tf.summary.image(weight.name, w_img)
-            self.merged = tf.summary.merge_all()
+                    tf.summary.histogram('{}_out'.format(layer.name),
-                                                     self.sess.graph_def)
+            self.writer = tf.summary.FileWriter(self.log_dir,
-                self.writer = tf.train.SummaryWriter(self.log_dir)
+            self.writer = tf.summary.FileWriter(self.log_dir)
-    from . import __version__ as keras_version
+    from .. import __version__ as keras_version
-TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'
+WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'
-        x = Flatten(name='flatten')(x)
+        x = GlobalAveragePooling2D(name='avg_pool')(x)
-                convert_all_kernels_in_model(model)
+        if include_top:
-                convert_all_kernels_in_model(model)
+            weights_path = get_file('inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',
-from ..utils.layer_utils import convert_all_kernels_in_model
+from ..utils import layer_utils
-TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'
+WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'
-               pading='same', name=conv_name_base + '2b')(x)
+    x = Conv2D(filters2, kernel_size,
-    x = Conv2D(filters2, (kernel_size, kernel_size), pading='same',
+    x = Conv2D(filters2, kernel_size, padding='same',
-            model.load_weights(weights_path)
+                maxpool = model.get_layer(name='avg_pool')
-from ..utils.layer_utils import convert_all_kernels_in_model
+from ..utils import layer_utils
-TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'
+WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'
-            model.load_weights(weights_path)
+                maxpool = model.get_layer(name='block5_pool')
-from ..utils.layer_utils import convert_all_kernels_in_model
+from ..utils import layer_utils
-TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'
+WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'
-            model.load_weights(weights_path)
+                maxpool = model.get_layer(name='block5_pool')
-            self.beta = None
+        if self.center:
-            'keras_version': keras_version
+            'keras_version': keras_version,
-    target = T.extra_ops.to_one_hot(target, num_classes=output.shape[-1])
+    target = T.extra_ops.to_one_hot(target, nb_class=output.shape[-1])
-            height = self.size[1] * input_shape[3] if input_shape[3] is not None else None
+            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None
-                    height)
+                    height,
-            height = self.size[1] * input_shape[2] if input_shape[2] is not None else None
+            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None
-                    width,
+                    width,
-        flat_shape = (shape[0], np.prod(shape[1:]))
+        num_rows = 1
-        # Assuming convolution kernels (2D or 3D).
+    elif len(shape) in {3, 4, 5}:
-        _, output_length, filters = self.compute_output_shape(input_shape)
+        output_length = conv_utils.conv_output_length(input_shape[1],
-                             filters)
+                             self.filters)
-            space = input_shape[1:-1]
+            input_row, input_col = input_shape[1:-1]
-        if space[0] is None or space[1] is None:
+            input_row, input_col = input_shape[2:]
-
+        output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],
-            self.bias = self.add_weight((output_row, output_col, filters),
+            self.bias = self.add_weight((output_row, output_col, self.filters),
-    import tensorflow.contrib.ctc as ctc
+from tensorflow.python.ops import ctc_ops as ctc
-from .common import floatx, _EPSILON, image_data_format
+
-                                shape=sparse_coo.shape)
+        v = tf.SparseTensor(indices=indices,
-                out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])
+        if axes[0] == axes[1]:
-                out = tf.reduce_sum(tf.mul(tf.transpose(x, [1, 0]), y), axes[1])
+            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])
-                return tf.concat(axis, [to_dense(x) for x in tensors])
+        return tf.concat([to_dense(x) for x in tensors], axis)
-
+    decoded_dense = [tf.sparse_to_dense(st.indices, st.dense_shape, st.values, default_value=-1)
-                layers_for_depth.sort(key=lambda x: layer_indices[x])
+            layers_for_depth.sort(key=lambda x: layer_indices[x])
-                        samples_per_epoch=x_train.shape[0],
+                        steps_per_epoch=x_train.shape[0] // batch_size,
-            self.progbar = Progbar(target=self.params['samples'],
+            if self.use_steps:
-        if self.seen < self.params['samples']:
+        if self.seen < self.target:
-        self.seen += batch_size
+        if self.use_steps:
-        if self.verbose and self.seen < self.params['samples']:
+        if self.verbose and self.seen < self.target:
-            class_weight=None, sample_weight=None, initial_epoch=0):
+    def fit(self, x=None,
-                      validation_data=None, num_val_samples=None,
+    def fit_generator(self, generator,
-                      max_q_size=10, workers=1, pickle_safe=False,
+                      max_q_size=10,
-                going to the next epoch.
+            steps_per_epoch: Total number of steps (batches of samples)
-                at the end of every epoch.
+            validation_steps: Only relevant if `validation_data`
-        if val_gen and not num_val_samples:
+        if val_gen and not validation_steps:
-                             'you must specify a value for "num_val_samples".')
+                             'you must specify a value for '
-            callbacks += [cbks.ProgbarLogger()]
+            callbacks += [cbks.ProgbarLogger(count_mode='steps')]
-            'samples': samples_per_epoch,
+            'steps': steps_per_epoch,
-                                 'or (val_x, val_y). Found: ' +
+                                 '`(val_x, val_y, val_sample_weight)` '
-                samples_seen = 0
+                steps_done = 0
-                while samples_seen < samples_per_epoch:
+                while steps_done < steps_per_epoch:
-                                         'or (x, y). Found: ' +
+                        raise ValueError('output of generator should be '
-                                         'or (x, y). Found: ' +
+                        raise ValueError('output of generator should be '
-                    # construct epoch logs
+                    # Construct epoch logs.
-                    if samples_seen >= samples_per_epoch and do_validation:
+                    steps_done += 1
-                                num_val_samples,
+                                validation_steps,
-                            # data has already been validated
+                            # No need for try/except because
-                        # same labels assumed
+                        # Same labels assumed.
-    def evaluate_generator(self, generator, val_samples,
+    def evaluate_generator(self, generator, steps,
-                before returning.
+            steps: Total number of steps (batches of samples)
-        processed_samples = 0
+        steps_done = 0
-
+        batch_sizes = []
-            while processed_samples < val_samples:
+            while steps_done < steps:
-                                     'or (x, y). Found: ' + str(generator_output))
+                                     'or (x, y). Found: ' +
-
+                                     'or (x, y). Found: ' +
-                    sampless = len(x[0])
+                    batch_size = len(x[0])
-                    sampless = len(list(x.values())[0])
+                    batch_size = len(list(x.values())[0])
-                    sampless = len(x)
+                    batch_size = len(x)
-                weights.append(sampless)
+                steps_done += 1
-                              weights=weights)
+                              weights=batch_sizes)
-                                           weights=weights))
+                                           weights=batch_sizes))
-    def predict_generator(self, generator, val_samples,
+    def predict_generator(self, generator, steps,
-            workers: maximum number of processes to spin up
+            generator: Generator yielding batches of input samples.
-            pickle_safe: if True, use process based threading.
+            pickle_safe: If `True`, use process based threading.
-        processed_samples = 0
+        steps_done = 0
-            while processed_samples < val_samples:
+            while steps_done < steps:
-                                         'or (x, y). Found: ' +
+                        raise ValueError('output of generator should be '
-                        all_outs.append(np.zeros(shape, dtype=K.floatx()))
+                        all_outs.append([])
-                processed_samples += samples
+                    all_outs[i].append(out)
-        return all_outs
+            if steps_done == 1:
-                      pickle_safe=False, initial_epoch=0):
+    def fit_generator(self, generator,
-                going to the next epoch.
+            steps_per_epoch: Total number of steps (batches of samples)
-                non picklable arguments to the generator as they can't be passed
+            pickle_safe: if True, use process based threading.
-                                        samples_per_epoch,
+                                        steps_per_epoch,
-                                        num_val_samples=num_val_samples,
+                                        validation_steps=validation_steps,
-    def evaluate_generator(self, generator, val_samples,
+    def evaluate_generator(self, generator, steps,
-                before returning.
+            steps: Total number of steps (batches of samples)
-                                             val_samples,
+                                             steps,
-    def predict_generator(self, generator, val_samples,
+    def predict_generator(self, generator, steps,
-                before returning.
+            steps: Total number of steps (batches of samples)
-        return self.model.predict_generator(generator, val_samples,
+        return self.model.predict_generator(generator, steps,
-    out = model.fit_generator(gen_data(4), samples_per_epoch=10, epochs=5,
+    out = model.fit_generator(gen_data(4), steps_per_epoch=3, epochs=5,
-    model.fit_generator(data_generator(True), len(x_train), epochs, max_q_size=2)
+    model.fit_generator(data_generator(True), 5, epochs)
-    gen_loss = model.evaluate_generator(data_generator(x_test, y_test, 50), x_test.shape[0], max_q_size=2)
+    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2)
-        num_train_samples = ins[0].shape[0]
+        if ins and hasattr(ins[0], 'shape'):
-        samples = ins[0].shape[0]
+        if ins and hasattr(ins[0], 'shape'):
-                  sample_weight_mode=None)
+    model.compile(optimizer, loss, metrics=['mae'])
-     pytest.main([__file__])
+    pytest.main([__file__])
-            elif loss_fn.__name__ == 'sparse_categorical_crossentropy':
+        for output_shape, loss_fn in zip(self._feed_output_shapes, self._feed_loss_fns):
-                                    self._feed_output_shapes,
+                                    output_shapes,
-        for layer in self.input_layers:
+        self._feed_input_names = []
-    if len(set_x) != 1:
+    if len(set_x) > 1:
-                         'the same number of samples.')
+                         'the same number of samples. Got array shapes: ' +
-    if len(set_y) != 1:
+    if len(set_y) > 1:
-                         'the same number of samples.')
+                         'the same number of samples. Got array shapes: ' +
-    if len(set_w) != 1:
+    if len(set_w) > 1:
-    if list(set_x)[0] != list(set_y)[0]:
+                         'the same number of samples. Got array shapes: ' +
-    if list(set_x)[0] != list(set_w)[0]:
+    if set_y and set_w and list(set_y)[0] != list(set_w)[0]:
-                         str(list(set_x)[0]) + ' input samples and ' +
+                         'the same number of samples as target arrays. Got ' +
-                loss_functions.append(losses.get(loss[name]))
+                    warnings.warn('Output "' + name +
-                                           name=name + '_sample_weights')
+            for i, name in enumerate(self.output_names):
-                                           name=name + '_sample_weights')
+            for i in range(len(self.output_names)):
-                sample_weight_modes = [None for name in self.output_names]
+            for i, name in enumerate(self.output_names):
-                                              dtype=K.dtype(self.outputs[i])))
+            if i in skip_indices:
-
+        self._feed_sample_weights = []
-            inputs = self.inputs + self.targets + self.sample_weights
+            inputs = self._feed_inputs + self._feed_targets + self._feed_sample_weights
-            inputs = self.inputs + self.targets + self.sample_weights
+            inputs = self._feed_inputs + self._feed_targets + self._feed_sample_weights
-                inputs = self.inputs + [K.learning_phase()]
+                inputs = self._feed_inputs + [K.learning_phase()]
-                inputs = self.inputs
+                inputs = self._feed_inputs
-        samples = ins[0].shape[0]
+        if ins and hasattr(ins[0], 'shape'):
-            if isinstance(ins[-1], float):
+            if ins and isinstance(ins[-1], float):
-            if loss_fn.__name__ == 'sparse_categorical_crossentropy':
+            if loss_fn is None:
-                                    self.internal_input_shapes,
+        x = _standardize_input_data(x, self._feed_input_names,
-                                    output_shapes,
+        y = _standardize_input_data(y, self._feed_output_names,
-                                                     self.output_names)
+                                                     self._feed_output_names)
-                                                   self.output_names)
+                                                   self._feed_output_names)
-                          in zip(y, sample_weights, class_weights, self.sample_weight_modes)]
+                          in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]
-                                             self.internal_output_shapes)
+                                             self._feed_loss_fns,
-                                    self.internal_input_shapes,
+        x = _standardize_input_data(x, self._feed_input_names,
-                                    self.internal_input_shapes)
+        x = _standardize_input_data(x, self._feed_input_names,
-    assert "You are passing a target array" in str(exc)
+    assert 'You are passing a target array' in str(exc)
-    assert "targets to have the same shape" in str(exc)
+    assert 'targets to have the same shape' in str(exc)
-    pytest.main([__file__])
+     pytest.main([__file__])
-    def __init__(self, inputs, outputs, updates=[]):
+    def __init__(self, inputs, outputs, updates=None):
-            (at least 3D).
+        inputs: tensor of temporal data of shape `(samples, time, ...)`
-    either 0 or 1 (integers).
+    """Sets the learning phase to a fixed value.
-    """Sets the global TF session.
+    """Sets the global TensorFlow session.
-        gamma: Tensor by which to scale the input.
+        gamma: Tensor by which to scale the input.
-            axis = axis % dims
+        rank = ndim(tensors[0])
-def function(inputs, outputs, updates=[], **kwargs):
+def function(inputs, outputs, updates=None, **kwargs):
-        step_function:
+        step_function: RNN step function.
-    and returns it.
+    """Converts a sparse tensor into a dense tensor and returns it.
-    integers or None entries.
+    """Returns the shape tensor or variable as a tuple of int or None entries.
-    of the same shape as another Keras variable or tensor and returns it.
+    """Instantiates an all-zeros variable of the same shape as another tensor.
-    of the same shape as another Keras variable or tensor and returns it.
+    """Instantiates an all-ones variable of the same shape as another tensor.
-    samples drawn from a uniform distribution and returns it.
+    """Instantiates a variable with values drawn from a uniform distribution.
-    samples drawn from a normal distribution and returns it.
+    """Instantiates a variable with values drawn from a normal distribution.
-            variable, value, momentum)
+def moving_average_update(x, value, momentum):
-        axis = axis % len(x.get_shape())
+    axis = _normalize_axis(axis, ndim(x))
-        axis = axis % len(x.get_shape())
+    axis = _normalize_axis(axis, ndim(x))
-    """Applies batch normalization on x given mean, var, beta and gamma:
+    """Applies batch normalization on x given mean, var, beta and gamma.
-    x_rep = [s for s in splits for i in range(rep)]
+    x_rep = [s for s in splits for _ in range(rep)]
-    """Creates a 1-D tensor containing a sequence of integers.
+    """Creates a 1D tensor containing a sequence of integers.
-        updates: list of update tuples (old_tensor, new_tensor).
+        inputs: List of placeholder tensors.
-    if len(kwargs) > 0:
+    if kwargs:
-    with regard to `loss`.
+    """Returns the gradients of `variables` w.r.t. `loss`.
-    variables.
+    """Returns `variables` but with zero gradient w.r.t. every other variable.
-                output, new_states = step_function(input, states + constants)
+            for inp, mask_t in zip(input_list, mask_list):
-                if len(successive_outputs) == 0:
+                if not successive_outputs:
-                output, states = step_function(input, states + constants)
+            for inp in input_list:
-            if len(states) == 0:
+            if not states:
-    from tensorflow.python.ops import functional_ops
+    """Converts CTC labels from dense to sparse.
-    (e.g. (2, 3).(4, 3, 5) = (2, 4, 5))
+
-        x, y: Keras tensors or variables with `ndim >= 2`
+        x: Keras tensor or variable with `ndim >= 2`.
-            axis = axis % ndim
+            axis %= ndim
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        y: input tensor.
+        x: Tensor or variable.
-        y: input tensor.
+        x: Tensor or variable.
-        y: input tensor.
+        x: Tensor or variable.
-        y: input tensor.
+        x: Tensor or variable.
-        y: input tensor.
+        x: Tensor or variable.
-        y: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-
+        x: Input tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-def resize_images(X, height_factor, width_factor, data_format):
+def resize_images(x, height_factor, width_factor, data_format):
-        new_shape = tf.shape(X)[2:]
+        original_shape = int_shape(x)
-        X.set_shape((None, None, original_shape[2] * height_factor if original_shape[2] is not None else None,
+        x = permute_dimensions(x, [0, 2, 3, 1])
-        return X
+        return x
-        new_shape = tf.shape(X)[1:3]
+        original_shape = int_shape(x)
-        X.set_shape((None, original_shape[1] * height_factor if original_shape[1] is not None else None,
+        x = tf.image.resize_nearest_neighbor(x, new_shape)
-        return X
+        return x
-def expand_dims(x, dim=-1):
+def expand_dims(x, axis=-1):
-    return tf.expand_dims(x, dim)
+    return tf.expand_dims(x, axis)
-def temporal_padding(x, padding=1):
+def temporal_padding(x, padding=(1, 1)):
-    pattern = [[0, 0], [left_pad, right_pad], [0, 0]]
+    assert len(padding) == 2
-def spatial_2d_padding(x, padding=(1, 1), data_format=None):
+def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):
-
+        x: Tensor or variable.
-    """
+    assert len(padding) == 2
-                   [left_pad, right_pad]]
+                   list(padding[0]),
-                   [left_pad, right_pad],
+                   list(padding[0]), list(padding[1]),
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: input tensor.
+        x: Tensor or variable.
-        x: Input tensor.
+        x: Tensor or variable.
-    def range_less_than(current_input):
+    def range_less_than(_, current_input):
-def expand_dims(x, dim=-1):
+def expand_dims(x, axis=-1):
-    if dim < 0:
+    if axis < 0:
-            dim = 0
+            axis = 0
-    pattern.insert(dim, 'x')
+            axis = axis % x.type.ndim + 1
-def temporal_padding(x, padding=1):
+def temporal_padding(x, padding=(1, 1)):
-                    input_shape[1] + 2 * padding,
+                    input_shape[1] + padding[0] + padding[1],
-    return T.set_subtensor(output[:, padding:x.shape[1] + padding, :], x)
+    return T.set_subtensor(output[:, padding[0]:x.shape[1] + padding[1], :], x)
-def spatial_2d_padding(x, padding=(1, 1), data_format=None):
+def spatial_2d_padding(x, padding=((1, 1),  (1, 1)), data_format=None):
-    """
+    assert len(padding) == 2
-        length = input_shape[1] + self.left_pad + self.right_pad if input_shape[1] is not None else None
+        length = input_shape[1] + self.padding[0] + self.padding[1] if input_shape[1] is not None else None
-                                             right_pad=self.right_pad)
+        return K.temporal_padding(inputs, padding=self.padding)
-                                               data_format=self.data_format)
+        return K.spatial_2d_padding(inputs,
-        check_single_tensor_operation('expand_dims', (4, 3, 2), dim=1)
+        check_single_tensor_operation('expand_dims', (4, 3), axis=-1)
-    in the tensor `reference`.
+    """Retrieves the elements of indices `indices` in the tensor `reference`.
-        keepdims: whether the drop or broadcast the reduction axes.
+        a: Python integer.
-    output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta
+    `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`
-            dimension indices, e.g. (0, 2, 1).
+        x: input tensor.
-    positive integers.
+    """Resizes the images contained in a 4D tensor.
-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither
-    All three factors should be positive integers.
+def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):
-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither
-        output = repeat_elements(X, depth_factor, axis=2)
+        output = repeat_elements(x, depth_factor, axis=2)
-        output = repeat_elements(X, depth_factor, axis=1)
+        output = repeat_elements(x, depth_factor, axis=1)
-    the first dimension is conserved.
+    """Turn a nD tensor into a 2D tensor with same 0th dimension.
-    with "padding" zeros left and right.
+    """Pads the middle dimension of a 3D tensor.
-    with "left_pad" zeros left and "right_pad" right.
+    """Pad the middle dimension of a 3D tensor.
-    with "padding[0]" and "padding[1]" (resp.) zeros left and right.
+    """Pads the 2nd and 3rd dimensions of a 4D tensor.
-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither
-    with "top_pad", "bottom_pad", "left_pad", "right_pad" (resp.) zeros
+    """Pad the rows and columns of a 4D tensor.
-    "padding[0]", "padding[1]" and "padding[2]" (resp.) zeros left and right
+    """Pads 5D tensor with zeros along the depth, height, width dimensions.
-    For 'channels_first' data_format, the 3rd, 4th and 5th dimension will be padded.
+    # Arguments
-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither
-    with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`
+    """Computes the one-hot representation of an integer tensor.
-    """Reverse a tensor along the the specified axes
+    """Reverse a tensor along the the specified axes.
-def batch_get_value(xs):
+def batch_get_value(ops):
-        x: list of variables.
+        ops: list of ops to run.
-        return get_session().run(xs)
+    if ops:
-    from a Numpy array. It returns `None`.
+    """Sets the value of a variable, from a Numpy array.
-    """Returns shape of a variable.
+    """Returns the shape of a variable.
-        A variable.
+        x: A variable.
-    tensor.
+    """Prints `message` and the tensor value when evaluated.
-        axis = axis % len(x.get_shape())
+        axis %= len(x.get_shape())
-    depending on a scalar value (`int` or `bool`).
+    """Switches between two operations depending on a scalar value.
-        condition: scalar tensor.
+        condition: scalar tensor (`int` or `bool`).
-    shape as the output.
+    """Categorical crossentropy between an output tensor and a target tensor.
-    and a target tensor, where the target is an integer tensor.
+    """Categorical crossentropy with integer targets.
-    """Returns whether the `targets` are in the top `k` `predictions`
+    """Returns whether the `targets` are in the top `k` `predictions`.
-def conv1d(x, kernel, stride=1, padding='valid',
+def conv1d(x, kernel, strides=1, padding='valid',
-        strides=(stride,),
+        strides=(strides,),
-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
+        ValueError: if `data_format` is neither
-        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(max_num_labels_tns, current_input)
+    def range_less_than(current_input):
-                or output of the softmax.
+        y_true: tensor `(samples, max_string_length)`
-                each batch item in `y_pred`.
+            each batch item in `y_pred`.
-                each batch item in `y_true`.
+            each batch item in `y_true`.
-            CTC loss of each element
+            CTC loss of each element.
-       search.
+    """Decodes the output of a softmax.
-                or output of the softmax.
+        y_pred: tensor `(samples, time_steps, num_categories)`
-                not use a dictionary
+            each batch item in `y_pred`.
-        top_paths: if `greedy` is `false`: how many of the most probable paths will be returned
+            with a beam of this width.
-            Tensor `(top_paths, )` that contains the log probability of each decoded sequence
+            List: if `greedy` is `true`, returns a list of one element that
-def conv1d(x, kernel, stride=1, padding='valid',
+def conv1d(x, kernel, strides=1, padding='valid',
-    strides = (stride, 1)
+    strides = (strides, 1)
-                stride=self.strides[0],
+                strides=self.strides[0],
-                generator yielding tuples (inputs, targets)
+            generator: Generator yielding tuples (inputs, targets)
-                total number of samples to generate from `generator`
+            val_samples: Total number of samples to generate from `generator`
-                    sampless = len(x[0])
+                    samples = len(x[0])
-                    sampless = len(list(x.values())[0])
+                    samples = len(list(x.values())[0])
-                    sampless = len(x)
+                    samples = len(x)
-                if len(all_outs) == 0:
+                if not all_outs:
-                processed_samples += sampless
+                    all_outs[i][processed_samples:(processed_samples + samples)] = out
-            A Numpy array of predictions.
+            Numpy array(s) of predictions.
-            globs = dict(globs.items() + custom_objects.items())
+            globs = dict(list(globs.items()) + list(custom_objects.items()))
-                inputs = self.inputs + self.targets + self.sample_weights
+                inputs += [K.learning_phase()]
-                                                          self.total_loss)
+            training_updates = self.optimizer.get_updates(
-
+            inputs = self.inputs + self.targets + self.sample_weights
-                inputs = self.inputs + self.targets + self.sample_weights
+                inputs += [K.learning_phase()]
-        """Abstract fit function for f(ins).
+        """Abstract fit function for `f(ins)`.
-        for i, out in enumerate(outs):
+        for i in range(len(outs)):
-        _check_loss_and_target_compatibility(y, self.loss_functions, self.internal_output_shapes)
+        _check_loss_and_target_compatibility(y,
-        in test mode. Computation is done in batches.
+        """Returns the loss value & metrics values for the model in test mode.
-        processing the samples in a batched way.
+        """Generates output predictions for the input samples.
-        a Python generator.
+        """Fits the model on data yielded batch-by-batch by a Python generator.
-        return the same kind of data as accepted by `test_on_batch`.
+        """Evaluates the model on a data generator.
-            # Returns network outputs. Does not update weights.
+            # Gets network outputs. Does not update weights.
-            # Returns loss and metrics. Updates weights at each call.
+            # Gets loss and metrics. Updates weights at each call.
-                                      image_data_format())
+                                     image_data_format())
-    # ValueError
+    # Raises
-    """Transforms an objective function `fn(y_true, y_pred)`
+    """Adds support for masking to an objective function.
-    # 
+    # Arguments
-            for i in range(workers):
+            for _ in range(workers):
-                "None" defaults to sample-wise weights (1D).
+                sample weighting (2D weights), set this to `"temporal"`.
-            kwargs: when using the Theano backend, these arguments
+            **kwargs: when using the Theano backend, these arguments
-        # prepare loss weights
+        # Prepare loss weights.
-        # prepare loss functions
+        # Prepare loss functions.
-        # prepare output masks
+        # Prepare output masks.
-        # prepare sample weights
+        # Prepare sample weights.
-        # prepare targets of model
+        # Prepare targets of model.
-        # prepare metrics
+        # Prepare metrics.
-        # compute total loss
+        # Compute total loss.
-        # and other layer-specific losses
+        # Add regularization penalties
-        # contains tuples (metrics for output, names of metrics)
+        # List of same size as output_names.
-        # prepare gradient updates and state updates
+        # Prepare gradient updates and state updates.
-        # functions for train, test and predict will
+        # Functions for train, test and predict will
-        # collected trainable weights and sort them deterministically.
+        # Collected trainable weights and sort them deterministically.
-        # Sort weights by name
+        # Sort weights by name.
-            # returns loss and metrics. Updates weights at each call.
+            # Returns loss and metrics. Updates weights at each call.
-            # return loss and metrics, no gradient updates.
+            # Return loss and metrics, no gradient updates.
-            # returns network outputs. Does not update weights.
+            # Returns network outputs. Does not update weights.
-                                                           custom_objects.items()))
+                                       custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +
-
+
-            if len(data) > 0 and hasattr(data[0], 'shape'):
+            if data and hasattr(data[0], 'shape'):
-            # a single Numpy array
+            # Case: model expects multiple inputs but only received
-    """This takes an array-like, or a list of
+    """Slice an array or list of arrays.
-    """Transforms an objective function `fn(y_true, y_pred)`
+    """Adds support for masking and sample-weighting to an objective function.
-        order of horizontal graph traversal (bottom-up).
+        """Retrieves a layer based on either its name (unique) or index.
-    def call(self, input, mask=None):
+    def call(self, inputs, mask=None):
-            input: A tensor or list of tensors.
+            inputs: A tensor or list of tensors.
-        inputs = _to_list(input)
+        inputs = _to_list(inputs)
-            output_tensors, output_masks, output_shapes = self.run_internal_graph(inputs, masks)
+            _, output_masks, _ = self.run_internal_graph(inputs, masks)
-            # then call them on appropriate inputs to create graph nodes
+            """Deserialize a layer, then call it on appropriate inputs.
-        """Save into a single HDF5 file:
+        """Save the model to a single HDF5 file.
-        for kwarg in kwargs.keys():
+        for kwarg in kwargs:
-    def __init__(self, input_shape=None, batch_input_shape=None,
+    def __init__(self, input_shape=None, batch_size=None,
-        self.name = name
+        super(InputLayer, self).__init__(dtype=dtype, name=name)
-                batch_input_shape = (None,) + tuple(input_shape)
+                batch_input_shape = (batch_size,) + tuple(input_shape)
-        # Handle name argument.
+        # Handle `name` argument.
-            assert name, 'Provide either a layer name or layer index.'
+            if not name:
-        stateful.  This is useful for separating training updates and
+        """Returns the `updates` from all layers that are stateful.
-        as a flat list of Numpy arrays.
+        """Retrieves the weights of the model.
-        the output of `model.get_weights()`.
+
-        """`call` just reapplies all ops in the graph to the new inputs
+        """Call the model on new inputs.
-        It is callable on non-Keras tensors.
+        A model is callable on non-Keras tensors.
-            output_tensors, output_masks, output_shapes = self.run_internal_graph(inputs, masks)
+            output_tensors, _, _ = self.run_internal_graph(inputs, masks)
-                        inbound_layer_name, inbound_node_index, inbound_tensor_index, kwargs = input_data
+                        kwargs = input_data[3]
-                    assert inbound_layer_name in created_layers, 'Missing layer: %s' % inbound_layer_name
+                    if inbound_layer_name not in created_layers:
-        """Shared between different serialization methods."""
+        """Util hared between different serialization methods.
-    # Return the output mask(s) of the previous node.
+    """Retrieves the output mask(s) of the previous node.
-        if len(self.inbound_nodes) == 0:
+        if not self.inbound_nodes:
-        if the layer has one inbound node,
+        """Retrieves the output shape tuple(s) of a layer.
-            except:
+            except TypeError:
-        model = Model(input=a, output=b)
+        x = Input(shape=(32,))
-        def build_map_of_graph(tensor, seen_nodes=set(), depth=0,
+        def build_map_of_graph(tensor, seen_nodes=None, depth=0,
-                generator yielding tuples (inputs, targets)
+            generator: Generator yielding tuples (inputs, targets)
-                total number of samples to generate from `generator`
+            val_samples: Total number of samples to generate from `generator`
-from keras import backend as K
+from .utils.generic_utils import Progbar
-    from keras import __version__ as keras_version
+    from . import __version__ as keras_version
-            if layer.inbound_nodes:
+            if not layer.inbound_nodes:
-        """Returns the weights of the model, as a flat list of Numpy arrays.
+        """Retrieves the weights of the model.
-                return new_config
+                return {'class_name': class_name,
-from . import layers
+from . import layers as layer_module
-    return layers.deserialize(config, custom_objects=custom_objects)
+    return layer_module.deserialize(config, custom_objects=custom_objects)
-    return layers.deserialize(config, custom_objects=custom_objects)
+    return layer_module.deserialize(config, custom_objects=custom_objects)
-    return layers.deserialize(config, custom_objects=custom_objects)
+    return layer_module.deserialize(config, custom_objects=custom_objects)
-            if len(layer.inbound_nodes) == 0:
+            if layer.inbound_nodes:
-        """Returns a layer based on either its name (unique)
+        """Retrieve a layer that is part of the model.
-            kwargs: for Theano backend, these are passed into K.function.
+            **kwargs: for Theano backend, these are passed into K.function.
-        """Generates output predictions for the input samples, processing the samples in a batched way.
+        """Generates output predictions for the input samples.
-        """Generates class probability predictions for the input samples batch by batch.
+        """Generates class probability predictions for the input samples.
-        batch by batch.
+        """Generate class predictions for the input samples.
-                easily to children processes.
+            pickle_safe: if True, use process based threading.
-                easily to children processes.
+            pickle_safe: if True, use process based threading.
-            layer = layers.deserialize(conf)
+            layer = layer_module.deserialize(conf)
-        """Returns the model configuration as a Python list.
+        """Retrieves the model configuration as a Python list.
-            layer = layers.deserialize(layer_data)
+            layer = layer_module.deserialize(layer_data)
-                merge_input = layers.deserialize(merge_input_config)
+                merge_input = layer_module.deserialize(merge_input_config)
-        TODO
+        dtype: Expected datatype of the input.
-            Does not try to detect cycles in graph (TODO?)
+            """Builds a map of the graph of layers.
-            # save optimizer weights
+            # Save optimizer weights.
-    def deserialize(obj):
+    def convert_custom_objects(obj):
-    metrics = deserialize(training_config['metrics'])
+    loss = convert_custom_objects(training_config['loss'])
-    """
+    """Instantiates a Keras model from its config.
-    def call(self, x, mask=None):
+    def call(self, inputs, mask=None):
-        return self.model.call(x, mask)
+        return self.model.call(inputs, mask)
-        # make sure child model callbacks will call the parent Sequential model:
+        # Make sure child model callbacks
-        as a flat list of Numpy arrays.
+        """Returns the weights of the model, as a flat list of Numpy arrays.
-        the output of `model.get_weights()`.
+
-        processing the samples in a batched way.
+        """Generates output predictions for the input samples, processing the samples in a batched way.
-        batch by batch.
+        """Generates class probability predictions for the input samples batch by batch.
-        a Python generator.
+        """Fits the model on data generated batch-by-batch by a Python generator.
-        return the same kind of data as accepted by `test_on_batch`.
+        """Evaluates the model on a data generator.
-        """
+    """Save a model to a HDF5 file.
-    # if file exists and should not be overwritten
+    # If file exists and should not be overwritten.
-    # recover loss functions and metrics
+    # Recover loss functions and metrics.
-    # compile model
+    # Compile model.
-    # set optimizer weights
+    # Set optimizer weights.
-        # build train function (to get weight updates)
+        # Build train function (to get weight updates).
-    and returns a model instance.
+    """Parses a yaml model configuration file and returns a model instance.
-    and returns a model instance.
+    """Parses a JSON model configuration file and returns a model instance.
-        self.outputs = []  # tensors (length 1)
+        self.layers = []  # Stack of layers.
-        # model attributes
+        # Model attributes.
-        from keras import __version__ as keras_version
+        from .. import __version__ as keras_version
-        from keras.utils.layer_utils import print_summary
+        from ..utils.layer_utils import print_summary
-
+import pytest
-    """Prints a summary of a layer.
+    """Prints a summary of a model.
-        for k, v in model.nodes_by_depth.items():
+        for v in model.nodes_by_depth.values():
-        for i, s in zip(int_shape(x), unstack(tf.shape(x))):
+        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):
-        for i, s in zip(int_shape(y), unstack(tf.shape(y))):
+        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):
-            out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)
+        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)
-        target_shape = stack(target_shape)
+        target_shape = tf.stack(target_shape)
-    pattern = stack([1, n, 1])
+    pattern = tf.stack([1, n, 1])
-    x = tf.reshape(x, stack([-1, prod(shape(x)[1:])]))
+    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))
-        return tf.pack(x)
+    return tf.stack(x)
-        input_list = unstack(inputs)
+        input_list = tf.unstack(inputs)
-            mask_list = unstack(mask)
+            mask_list = tf.unstack(mask)
-                                       stack([1, tf.shape(output)[1]]))
+                                       tf.stack([1, tf.shape(output)[1]]))
-                                           stack([1, tf.shape(new_state)[1]]))
+                                           tf.stack([1, tf.shape(new_state)[1]]))
-                outputs = stack(successive_outputs)
+                outputs = tf.stack(successive_outputs)
-            outputs = stack(successive_outputs)
+            outputs = tf.stack(successive_outputs)
-            input_ta = input_ta.unpack(inputs)
+        input_ta = input_ta.unstack(inputs)
-                mask_ta = mask_ta.unpack(mask)
+            mask_ta = mask_ta.unstack(mask)
-                                       stack([1, tf.shape(output)[1]]))
+                                       tf.stack([1, tf.shape(output)[1]]))
-            outputs = output_ta.pack()
+        outputs = output_ta.stack()
-    """2-D convolution with separable filters.
+    """2D convolution with separable filters.
-        # TODO
+        x: input tensor
-    max_num_labels_tns = stack([label_shape[1]])
+    num_batches_tns = tf.stack([label_shape[0]])
-        # For python 2.x. Yields the next batch.
+        """For python 2.x.
-        """For python 2.x. Yields the next batch.
+        """For python 2.x.
-from ..layers import *
+import numpy as np
-        for k, v in model.nodes_by_depth.items():
+        for v in model.nodes_by_depth.values():
-            non_trainable_count += py_sum([K.count_params(p) for p in layer.non_trainable_weights])
+            trainable_count += np.sum([K.count_params(p) for p in layer.trainable_weights])
-def apply_transform(x, transform_matrix, channel_axis=0, fill_mode='nearest', cval=0.):
+def apply_transform(x,
-                                                         final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]
+    channel_images = [ndi.interpolation.affine_transform(
-        """TODO
+        """Randomly augment a single image tensor.
-        # ensure self.batch_index is 0
+        # Ensure self.batch_index is 0.
-        # needed if we want to do something like:
+        # Needed if we want to do something like:
-        # for python 2.x.
+        # For python 2.x. Yields the next batch.
-        # see http://anandology.com/blog/using-iterators-and-generators/
+        # the indexing of each batch.
-                 data_format=None,
+                 data_format=None,
-                         scoring='log_loss',
+                         scoring='neg_log_loss',
-        img = img.convert('RGB')
+        if img.mode != 'L':
-        img = img.resize((target_size[1], target_size[0]))
+        wh_tuple = (target_size[1], target_size[0])
-            if re.match('([\w]+\.(?:' + ext + '))', f)]
+            if re.match(r'([\w]+\.(?:' + ext + '))', f)]
-    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,
+    def flow(self, x, y=None, batch_size=32, shuffle=True, seed=None,
-            X, y, self,
+            x, y, self,
-        """Required for featurewise_center, featurewise_std_normalization
+        """Fits internal statistics to some sample data.
-    statement, global custom objects are reverted to state at beginning of the `with` statement.
+    by name. Changes to global custom objects persist
-    def __exit__(self, type, value, traceback):
+    def __exit__(self, *args, **kwargs):
-    statement, global custom objects are reverted to state at beginning of the `with` statement.
+    Convenience wrapper for `CustomObjectScope`.
-        *args: Variable length list of dictionaries of name, class pairs to add to custom objects.
+        *args: Variable length list of dictionaries of name,
-    """Retrieves a live reference to the global dictionary of custom objects (`_GLOBAL_CUSTOM_OBJECTS`).
+    """Retrieves a live reference to the global dictionary of custom objects.
-    Updating and clearing custom objects using `custom_object_scope` is preferred, but `get_custom_objects` can
+    Updating and clearing custom objects using `custom_object_scope`
-                             instantiate=True):
+                             printable_module_name='object'):
-    """The identity_block is the block that has no conv layer at shortcut
+    """The identity block is the block that has no conv layer at shortcut.
-    """Loads the MNIST dataset.
+    """Loads the Boston Housing dataset.
-from ..layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
+from ..layers import Flatten
-from .imagenet_utils import decode_predictions, _obtain_input_shape
+from .imagenet_utils import decode_predictions
-        num_cols: width of the convolution kernel.
+        num_col: width of the convolution kernel.
-from ..layers.convolutional import MaxPooling2D, ZeroPadding2D
+from ..layers.convolutional import MaxPooling2D
-from .audio_conv_utils import decode_predictions, preprocess_input
+from .audio_conv_utils import decode_predictions
-    optionally loading weights pre-trained
+    """Instantiates the MusicTaggerCRNN architecture.
-from ..layers import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
+from ..layers import Dense
-from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape
+from .imagenet_utils import decode_predictions
-    optionally loading weights pre-trained
+    """Instantiates the ResNet50 architecture.
-from ..layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
+from ..layers import Flatten
-from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape
+from .imagenet_utils import decode_predictions
-    optionally loading weights pre-trained
+    """Instantiates the VGG16 architecture.
-from ..layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
+from ..layers import Flatten
-from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape
+from .imagenet_utils import decode_predictions
-    optionally loading weights pre-trained
+    """Instantiates the VGG19 architecture.
-from ..layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
+from ..layers import Dense
-from .imagenet_utils import decode_predictions, _obtain_input_shape
+from .imagenet_utils import decode_predictions
-    optionally loading weights pre-trained
+    """Instantiates the Xception architecture.
-    optionally loading weights pre-trained
+    """Instantiates the Inception v3 architecture.
-            **params: Dictionary of parameter names mapped to their values.
+            Dictionary of parameter names mapped to their values.
-            raise ValueError('If a RNN is stateful, a complete ' +
+            raise ValueError('If a RNN is stateful, a complete '
-    def compute_mask(self, input, mask):
+    def compute_mask(self, inputs, mask):
-                Dictionary of parameter names mapped to their values.
+            **params: Dictionary of parameter names mapped to their values.
-    """TODO
+    """Generic merge layer for elementwise merge functions.
-    """TODO
+    """Layer that sums a list of inputs.
-    """TODO
+    """Layer that multiplies (element-wise) a list of inputs.
-    """TODO
+    """Layer that averages a list of inputs.
-    """TODO
+    """Layer that computes the maximum (element-wise) a list of inputs.
-    """TODO
+    """Layer that concatenates a list of inputs.
-    """TODO
+    """Layer that computes a dot product between samples in two tensors.
-    """TODO
+    """Functional interface to the `Sum` layer.
-    """TODO
+    """Functional interface to the `Multiply` layer.
-    """TODO
+    """Functional interface to the `Average` layer.
-    """TODO
+    """Functional interface to the `Maximum` layer.
-    """TODO
+    """Functional interface to the `Concatenate` layer.
-    """TODO
+    """Functional interface to the `Dot` layer.
-            return True
+            return
-                             '(including batch size).')
+            raise ValueError('If a RNN is stateful, a complete '
-            x: Can be a tensor or list/tuple of tensors.
+            inputs: Can be a tensor or list/tuple of tensors.
-
+                self.add_loss(regularization_losses, _to_list(inputs))
-        to one incoming layer).
+        """Retrieves the input tensor(s) of a layer.
-            TODO
+            Input tensor or list of input tensors.
-        to one incoming layer).
+        """Retrieves the output tensor(s) of a layer.
-            TODO
+            Output tensor or list of output tensors.
-        to one incoming layer).
+        """Retrieves the input mask tensor(s) of a layer.
-            TODO
+            Input mask tensor (potentially None) or list of input
-        to one incoming layer).
+        """Retrieves the output mask tensor(s) of a layer.
-            TODO
+            Output mask tensor (potentially None) or list of output
-        or if all inbound nodes have the same input shape.
+        """Retrieves the input shape tuple(s) of a layer.
-            TODO
+            Input shape tuple
-            TODO
+            Output shape tuple
-        """TODO
+        """Add losses to the layer.
-        """TODO
+        """Add updates to the layer.
-    necessary to compute `tensor`.
+    """Returns the list of input tensors necessary to compute `tensor`.
-        # Optional keyword arguments to layer's `call`:
+        # List of layer instances.
-        weight = K.variable(initializer(shape), dtype=K.floatx())
+        weight = K.variable(initializer(shape), dtype=K.floatx(), name=name)
-        """This checks that the tensor(s) `input`
+        """Checks compatibility between the layer and provided inputs.
-    def call(self, x):
+    def call(self, inputs):
-            x: input tensor, or list/tuple of input tensors.
+            inputs: input tensor, or list/tuple of input tensors.
-        # Returns:
+        # Returns
-        return x
+        return inputs
-        internal Keras references.
+    def __call__(self, inputs, **kwargs):
-                self.assert_input_compatibility(x)
+                self.assert_input_compatibility(inputs)
-                for x_elem in _to_list(x):
+                for x_elem in _to_list(inputs):
-            self.assert_input_compatibility(x)
+            self.assert_input_compatibility(inputs)
-            previous_mask = _collect_previous_mask(x)
+            previous_mask = _collect_previous_mask(inputs)
-            input_shape = _collect_input_shape(x)
+            input_shape = _collect_input_shape(inputs)
-            output_mask = self.compute_mask(x, previous_mask)
+            output = self.call(inputs, **kwargs)
-            self._add_inbound_node(input_tensors=x, output_tensors=output,
+            self._add_inbound_node(input_tensors=inputs, output_tensors=output,
-            TODO
+            input_tensors: list of input tensors.
-        to match that input shape).
+        """Computes the output shape of the layer.
-        (or list thereof) and an input mask (or list thereof).
+        """Computes an output mask tensor.
-            input_mask: Tensor or list of tensors.
+            mask: Tensor or list of tensors.
-    """This normalizes a list/tensor into a list.
+    """Normalizes a list/tensor into a list.
-    # Return the output shape(s) of a list of Keras tensors.
+    """Collects the output shape(s) of a list of Keras tensors.
-        if len(weight_names):
+        if weight_names:
-    """ Name-based weight loading
+    """Implements name-based weight loading.
-        # this is for performance optimization
+        # This is for performance optimization
-        # Arguments validation.
+        # User-provided arguments validation.
-    # Raises:
+    # Raises
-def _check_loss_and_target_compatibility(targets, losses, output_shapes):
+def _check_loss_and_target_compatibility(targets, loss_fns, output_shapes):
-        losses: list of loss functions.
+        loss_fns: list of loss functions.
-    for y, loss, shape in zip(targets, losses, output_shapes):
+    for y, loss, shape in zip(targets, loss_fns, output_shapes):
-def _weighted__masked_objective(fn):
+def _weighted_masked_objective(fn):
-    to a single sample-wise (or timestep-wise) weight array.
+    """Performs sample weight validation and standardization.
-        weighted_losses = [_weighted__masked_objective(fn) for fn in loss_functions]
+        weighted_losses = [_weighted_masked_objective(fn) for fn in loss_functions]
-            c_axis, h_axis, w_axis = 1, 2, 3
+            h_axis, w_axis = 2, 3
-            c_axis, h_axis, w_axis = 3, 1, 2
+            h_axis, w_axis = 1, 2
-from keras.engine.training import Model, check_loss_and_target_compatibility
+from keras.engine.training import Model, _check_loss_and_target_compatibility
-    check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [(2, None, 3)])
+    _check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [a.shape])
-        check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [a.shape])
+        _check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [a.shape])
-        check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [(2, 3, 6)])
+        _check_loss_and_target_compatibility([a], [K.categorical_crossentropy], [(2, 3, 6)])
-from keras.layers import Dense, Activation, Lambda
+from keras.layers import Dense, Activation
-from keras.legacy.layers import Merge
+from keras.engine.training import _make_batches
-            batches = make_batches(len(x_test), batch_size)
+            batches = _make_batches(len(x_test), batch_size)
-from keras.engine.training import weighted_objective
+from keras.engine.training import _weighted_masked_objective
-    weighted_loss = weighted_objective(losses.get('mae'))
+    weighted_loss = _weighted_masked_objective(losses.get('mae'))
-                           exception_prefix=''):
+def _standardize_input_data(data, names, shapes=None,
-    # make arrays at least 2D
+    # Make arrays at least 2D.
-    # check shapes compatibility
+    # Check shapes compatibility.
-def standardize_sample_or_class_weights(x_weight, output_names, weight_type):
+def _standardize_sample_or_class_weights(x_weight, output_names, weight_type):
-                                               'class_weight')
+def _standardize_class_weights(class_weight, output_names):
-                                               'sample_weight')
+def _check_array_lengths(inputs, targets, weights):
-def check_array_lengths(inputs, targets, weights):
+    # Raises:
-def check_loss_and_target_compatibility(targets, losses, output_shapes):
+def _check_loss_and_target_compatibility(targets, losses, output_shapes):
-def collect_metrics(metrics, output_names):
+def _collect_metrics(metrics, output_names):
-    """This shuffles an array in a batch-wise fashion.
+def _batch_shuffle(index_array, batch_size):
-def make_batches(size, batch_size):
+def _make_batches(size, batch_size):
-def slice_X(X, start=None, stop=None):
+def _slice_arrays(arrays, start=None, stop=None):
-        - [x[start:stop] for x in X] if X in a list
+        - arrays[start:stop] if `arrays` is an array-like
-    Can also work on list/array of indices: `slice_X(x, indices)`
+    Can also work on list/array of indices: `_slice_arrays(x, indices)`
-    if isinstance(X, list):
+    if isinstance(arrays, list):
-            return [x[start] for x in X]
+            return [x[start] for x in arrays]
-            return [x[start:stop] for x in X]
+            return [x[start:stop] for x in arrays]
-            return X[start]
+            return arrays[start]
-            return X[start:stop]
+            return arrays[start:stop]
-def weighted_objective(fn):
+def _weighted__masked_objective(fn):
-                        sample_weight_mode=None):
+def _masked_objective(fn):
-        """Kick off threads which add data from the generator into the queue.
+        """Kicks off threads which add data from the generator into the queue.
-        weighted_losses = [weighted_objective(fn) for fn in loss_functions]
+        weighted_losses = [_weighted__masked_objective(fn) for fn in loss_functions]
-        nested_metrics = collect_metrics(metrics, self.output_names)
+        nested_metrics = _collect_metrics(metrics, self.output_names)
-            """Helper function, used in loop below"""
+            """Helper function used in loop below."""
-                    append_metric(i, 'acc', acc_fn(y_true, y_pred))
+                    masked_fn = _masked_objective(acc_fn)
-
+                    masked_metric_fn = _masked_objective(metric_fn)
-                index_array = batch_shuffle(index_array, batch_size)
+                index_array = _batch_shuffle(index_array, batch_size)
-            batches = make_batches(num_train_samples, batch_size)
+            batches = _make_batches(num_train_samples, batch_size)
-                        ins_batch = slice_X(ins[:-1], batch_ids) + [ins[-1]]
+                        ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]
-                        ins_batch = slice_X(ins, batch_ids)
+                        ins_batch = _slice_arrays(ins, batch_ids)
-        batches = make_batches(samples, batch_size)
+        batches = _make_batches(samples, batch_size)
-                ins_batch = slice_X(ins[:-1], batch_ids) + [ins[-1]]
+                ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]
-                ins_batch = slice_X(ins, batch_ids)
+                ins_batch = _slice_arrays(ins, batch_ids)
-        batches = make_batches(samples, batch_size)
+        batches = _make_batches(samples, batch_size)
-                ins_batch = slice_X(ins[:-1], batch_ids) + [ins[-1]]
+                ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]
-                ins_batch = slice_X(ins, batch_ids)
+                ins_batch = _slice_arrays(ins, batch_ids)
-        sample_weights = [standardize_weights(ref, sw, cw, mode)
+        x = _standardize_input_data(x, self.input_names,
-        check_loss_and_target_compatibility(y, self.loss_functions, self.internal_output_shapes)
+        _check_array_lengths(x, y, sample_weights)
-            y, val_y = (slice_X(y, 0, split_at), slice_X(y, split_at))
+            x, val_x = (_slice_arrays(x, 0, split_at), _slice_arrays(x, split_at))
-                slice_X(sample_weights, split_at))
+                _slice_arrays(sample_weights, 0, split_at),
-                                   check_batch_axis=False)
+        x = _standardize_input_data(x, self.input_names,
-                                   self.internal_input_shapes)
+        x = _standardize_input_data(x, self.input_names,
-    return K.mean(K.equal(y_true, K.round(y_pred)))
+    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)
-                          K.argmax(y_pred, axis=-1)))
+    return K.equal(K.argmax(y_true, axis=-1),
-                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())))
+    return K.equal(K.max(y_true, axis=-1),
-    return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k))
+    return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k), axis=-1)
-    return K.mean(K.square(y_pred - y_true))
+    return K.mean(K.square(y_pred - y_true), axis=-1)
-    return K.mean(K.abs(y_pred - y_true))
+    return K.mean(K.abs(y_pred - y_true), axis=-1)
-    return 100. * K.mean(diff)
+    return 100. * K.mean(diff, axis=-1)
-    return K.mean(K.square(first_log - second_log))
+    return K.mean(K.square(first_log - second_log), axis=-1)
-    return K.mean(K.maximum(1. - y_true * y_pred, 0.))
+    return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)
-    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)))
+    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)
-    return K.mean(K.categorical_crossentropy(y_pred, y_true))
+    return K.categorical_crossentropy(y_pred, y_true)
-    return K.mean(K.sparse_categorical_crossentropy(y_pred, y_true))
+    return K.sparse_categorical_crossentropy(y_pred, y_true)
-    return K.mean(K.binary_crossentropy(y_pred, y_true))
+    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)
-    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1))
+    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1), axis=-1)
-    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()))
+    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)
-    return - K.mean(y_true * y_pred)
+    return - K.mean(y_true * y_pred, axis=-1)
-    mse = lambda y_true, y_pred: K.mean(K.pow(y_true - y_pred, 2))
+    def mse(y_true, y_pred):
-    model.compile(optimizer, loss, metrics=[mse, mse_powers],
+    model.compile(optimizer, loss, metrics=[mse],
-    out_len = 1 + 2 * 4  # total loss, per layer: loss + 3 metrics
+    out_len = 1 + 2 * (1 + 1)  # total loss + 2 outputs * (loss + metric)
-        assert K.eval(output).shape == ()
+        print(metric.__name__)
-        assert K.eval(metric(y_a, y_b)).shape == ()
+        assert K.eval(metric(y_a, y_b)).shape == (6,)
-            dilation_rate=self.dilation_rate)
+            padding=self.padding)
-                                             dilation=self.dilation_rate[0])
+                                             self.strides[0])
-                                             dilation=self.dilation_rate[1])
+                                             self.strides[1])
-                            raise TypeError(
+                            warnings.warn(
-                                str(node.arguments) + '. Cannot serialize model.')
+                                str(node.arguments) + '. They will not be included '
-from ..engine.topology import Layer
+from ..engine.topology import Layer, InputSpec
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    pytest.main([__file__])
+import pytest
-    layer_test(layers.Highway,
+    layer_test(legacy_layers.Highway,
-    layer_test(layers.Highway,
+    layer_test(legacy_layers.Highway,
-    layer_test(layers.MaxoutDense,
+    layer_test(legacy_layers.MaxoutDense,
-    layer_test(layers.MaxoutDense,
+    layer_test(legacy_layers.MaxoutDense,
-        model = layers.Model([input_a, input_b], merged)
+        merged = legacy_layers.merge([input_a, input_b], mode=mode)
-        merged = layers.Merge(mode=mode)([input_a, input_b])
+        merged = legacy_layers.Merge(mode=mode)([input_a, input_b])
-                          output_shape=lambda tup: tup[0][:-1] + (tup[0][-1] + tup[1][-1],))
+    merged = legacy_layers.merge(
-                          output_shape=fn_output_shape)
+    merged = legacy_layers.merge([input_a, input_b],
-    merged = layers.merge([a, b], mode=fn_mode, output_shape=fn_output_shape, output_mask=fn_output_mask)
+    merged = legacy_layers.merge([a, b], mode=fn_mode, output_shape=fn_output_shape, output_mask=fn_output_mask)
-                          output_mask=lambda tup: K.concatenate([tup[0], tup[1]]))
+    merged = legacy_layers.merge(
-    merged = layers.merge([input_a, input_b], mode=fn_mode, output_shape=lambda s: s[0], arguments={'a': 0.7, 'b': 0.3})
+    merged = legacy_layers.merge([input_a, input_b], mode=fn_mode, output_shape=lambda s: s[0], arguments={'a': 0.7, 'b': 0.3})
-    merged_concat_mixed = layers.merge([masked_a, input_b], mode='concat', concat_axis=1)
+    merged_sum = legacy_layers.merge([masked_a, masked_b], mode='sum')
-    merged_concat = layers.merge([rnn_a, rnn_b], mode='concat', concat_axis=-1)
+    merged_concat = legacy_layers.merge([rnn_a, rnn_b], mode='concat', concat_axis=-1)
-    seq.add(layers.Dense(input_dim=10, output_dim=10))
+    seq.add(layers.Dense(10, input_shape=(10,)))
-    branch_1_2 = models.Sequential([layers.Merge([branch_1, branch_2], mode='concat')], name='branch_1_2')
+    branch_1_2 = models.Sequential([legacy_layers.Merge([branch_1, branch_2], mode='concat')], name='branch_1_2')
-    model = models.Sequential([layers.Merge([branch_1_2, branch_3], mode='concat')], name='final')
+    model = models.Sequential([legacy_layers.Merge([branch_1_2, branch_3], mode='concat')], name='final')
-    assert(loss == nloss)
+# @keras_test
-    Sequential.from_config(config)
+#     right = models.Sequential()
-    model_from_json(json_str)
+#     model = models.Sequential()
-    model_from_yaml(yaml_str)
+#     model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test], y_test))
-    (x_train, y_train), (x_test, y_test) = _get_test_data()
+#     model.predict([x_test, x_test], verbose=0)
-    left.add(Activation('relu'))
+#     # test weight saving
-    right.add(Activation('relu'))
+#     nloss = model.evaluate([x_test, x_test], y_test, verbose=0)
-    model.add(Activation('softmax'))
+#     # test serialization
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+#     model.summary()
-    left.add(Activation('relu'))
+#     yaml_str = model.to_yaml()
-    model.add(Activation('softmax'))
+# @keras_test
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+#     model = Sequential()
-    (x_train, y_train), (x_test, y_test) = _get_test_data()
+#     left = Sequential()
-    left.add(Activation('relu', name='relu_1'))
+#     right = Sequential()
-    right.add(Activation('relu', name='relu_2'))
+#     model = Sequential()
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+#     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
-    loss = model.evaluate([x_test, x_test], y_test, verbose=0)
+# @keras_test
-    model.get_config()
+#     right = Sequential()
-    os.remove(fname)
+#     righter = Sequential()
-    assert(loss == nloss)
+#     intermediate = Sequential()
-    assert(loss == nloss)
+#     model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test, x_test], y_test))
-    Sequential.from_config(config)
+#     loss = model.evaluate([x_test, x_test, x_test], y_test, verbose=0)
-    model_from_json(json_str)
+#     model.predict([x_test, x_test, x_test], verbose=0)
-    model_from_yaml(yaml_str)
+#     fname = 'test_merge_recursivity_temp.h5'
-    left.add(Activation('relu'))
+#     # test serialization
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+#     model.summary()
-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=False)
+#     yaml_str = model.to_yaml()
-    model.predict_proba(x_test, verbose=0)
+# @keras_test
-    print(model.trainable_weights)
+#     model = Sequential()
-    os.remove(fname)
+#     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
-    assert(loss == nloss)
+#     model.train_on_batch(x_train[:32], y_train[:32])
-    Sequential.from_config(config)
+#     loss = model.evaluate(x_test, y_test, verbose=0)
-    model_from_yaml(yaml_str)
+if __name__ == '__main__':
-      """
+    """
-            output *= inputs[i]
+            output += inputs[i]
-        shape2.pop(self.axes[1])
+        if isinstance(self.axes, int):
-def deserialize(config):
+def deserialize(config, custom_objects=None):
-                                    custom_objects=None,
+                                    custom_objects=custom_objects,
-    fan_in, _ = initializers._compute_fans(tensor_shape, data_format='channels_last')
+    fan_in, _ = initializers._compute_fans(tensor_shape)
-    _runner(initializers.lecun_uniform(data_format='channels_last'), tensor_shape,
+    _runner(initializers.lecun_uniform(), tensor_shape,
-    fan_in, fan_out = initializers._compute_fans(tensor_shape, data_format='channels_last')
+    fan_in, fan_out = initializers._compute_fans(tensor_shape)
-    _runner(initializers.glorot_uniform(data_format='channels_last'), tensor_shape,
+    _runner(initializers.glorot_uniform(), tensor_shape,
-    fan_in, _ = initializers._compute_fans(tensor_shape, data_format='channels_last')
+    fan_in, _ = initializers._compute_fans(tensor_shape)
-    _runner(initializers.he_uniform(data_format='channels_last'), tensor_shape,
+    _runner(initializers.he_uniform(), tensor_shape,
-    fan_in, fan_out = initializers._compute_fans(tensor_shape, data_format='channels_last')
+    fan_in, fan_out = initializers._compute_fans(tensor_shape)
-    _runner(initializers.glorot_normal(data_format='channels_last'), tensor_shape,
+    _runner(initializers.glorot_normal(), tensor_shape,
-    fan_in, _ = initializers._compute_fans(tensor_shape, data_format='channels_last')
+    fan_in, _ = initializers._compute_fans(tensor_shape)
-    _runner(initializers.he_normal(data_format='channels_last'), tensor_shape,
+    _runner(initializers.he_normal(), tensor_shape,
-                 data_format=None):
+                 seed=None):
-        fan_in, fan_out = _compute_fans(shape, self.data_format)
+        fan_in, fan_out = _compute_fans(shape)
-            'data_format': self.data_format
+            'seed': self.seed
-def lecun_uniform(seed=None, data_format=None):
+def lecun_uniform(seed=None):
-    return VarianceScaling(scale=1., mode='fan_in', distribution='uniform')
+    return VarianceScaling(scale=1.,
-def glorot_normal(seed=None, data_format=None):
+def glorot_normal(seed=None):
-    return VarianceScaling(scale=1., mode='fan_avg', distribution='normal')
+    return VarianceScaling(scale=1.,
-def glorot_uniform(seed=None, data_format=None):
+def glorot_uniform(seed=None):
-    return VarianceScaling(scale=1., mode='fan_avg', distribution='uniform')
+    return VarianceScaling(scale=1.,
-def he_normal(seed=None, data_format=None):
+def he_normal(seed=None):
-    return VarianceScaling(scale=2., mode='fan_in', distribution='normal')
+    return VarianceScaling(scale=2.,
-def he_uniform(seed=None, data_format=None):
+def he_uniform(seed=None):
-    return VarianceScaling(scale=2., mode='fan_in', distribution='uniform')
+    return VarianceScaling(scale=2.,
-def _compute_fans(shape, data_format='channels_first'):
+def _compute_fans(shape, data_format='channels_last'):
-            layer = layer_from_config(layer_data,
+            from ..layers import deserialize as deserialize_layer
-        layer = layer_from_config(config.pop('layer'))
+        from . import deserialize as deserialize_layer
-        layers = legacy_models.legacy_sequential_layers(model)
+        model_layers = legacy_models.legacy_sequential_layers(model)
-    topology.save_weights_to_hdf5_group(model_weights_group, layers)
+        model_layers = model.layers
-    return layer_from_config(config, custom_objects=custom_objects)
+    return layers.deserialize(config, custom_objects=custom_objects)
-    return layer_from_config(config, custom_objects=custom_objects)
+    return layers.deserialize(config, custom_objects=custom_objects)
-    return layer_from_config(config, custom_objects=custom_objects)
+    return layers.deserialize(config, custom_objects=custom_objects)
-            layer = layer_from_config(conf)
+            layer = layers.deserialize(conf)
-            layer = layer_from_config(layer_data)
+            layer = layers.deserialize(layer_data)
-                merge_input = layer_from_config(merge_input_config)
+                merge_input = layers.deserialize(merge_input_config)
-from keras.utils.layer_utils import layer_from_config
+from keras.layers import deserialize as deserialize_layer
-    ld = layer_from_config({'class_name': 'Lambda', 'config': config})
+    ld = deserialize_layer({'class_name': 'Lambda', 'config': config})
-    ld = layer_from_config({'class_name': 'Lambda', 'config': config})
+    ld = deserialize_layer({'class_name': 'Lambda', 'config': config})
-
+import json
-    # Attributes
+    # Arguments
-            `input_tensors` and turns them into `output_tensors`.
+            `input_tensors` and turns them into `output_tensors`
-                 input_shapes, output_shapes):
+                 input_shapes, output_shapes,
-                                   input_shapes=input_shape, output_shapes=output_shape)
+                                   input_shapes=input_shape, output_shapes=output_shape,
-        TODO
+                          input_shapes, output_shapes, arguments=None):
-            output_shapes=output_shapes
+            output_shapes=output_shapes,
-                                output_tensors = _to_list(layer.call(computed_tensor))
+                                if 'mask' not in kwargs:
-                                output_tensors = _to_list(layer.call(computed_tensors))
+                                if 'mask' not in kwargs:
-            # TODO: Better error message.
+                    if node.arguments:
-                                              tensor_index])
+                                              tensor_index,
-                    inbound_layer_name, inbound_node_index, inbound_tensor_index = input_data
+                    if len(input_data) == 3:
-                        layer(input_tensors[0])
+                        layer(input_tensors[0], **kwargs)
-                        layer(input_tensors)
+                        layer(input_tensors, **kwargs)
-        import h5py
+        if h5py is None:
-        self.save_weights_to_hdf5_group(f)
+        save_weights_to_hdf5_group(f, self.layers)
-
+
-        import h5py
+        if h5py is None:
-            self.load_weights_from_hdf5_group_by_name(f)
+            load_weights_from_hdf5_group_by_name(f, self.layers)
-            self.load_weights_from_hdf5_group(f)
+            load_weights_from_hdf5_group(f, self.layers)
-        import yaml
+
-
+
-            # we can go with reshape-based implementation for performance
+            # No batch size specified, therefore the layer will be able
-            # (num_samples * timesteps, ...)
+            # Shape: (num_samples * timesteps, ...)
-            # (num_samples, timesteps, ...)
+            # Shape: (num_samples, timesteps, ...)
-from .engine.topology import get_source_inputs, Node, Layer, Input
+from .engine import topology
-    model.save_weights_to_hdf5_group(model_weights_group)
+    if legacy_models.needs_legacy_support(model):
-    model.load_weights_from_hdf5_group(f['model_weights'])
+    topology.load_weights_from_hdf5_group(f['model_weights'], model.layers)
-            self.inputs = get_source_inputs(self.outputs[0])
+            self.inputs = topology.get_source_inputs(self.outputs[0])
-                 output_shapes=[self.outputs[0]._keras_shape])
+            topology.Node(outbound_layer=self,
-    layer_test(core.Highway,
+    layer_test(layers.Highway,
-    layer_test(core.Highway,
+    layer_test(layers.Highway,
-                       'activity_regularizer': regularizers.activity_l2(0.01),
+                       'activity_regularizer': regularizers.l2(0.01),
-                       'activity_regularizer': regularizers.activity_l2(0.01),
+                       'activity_regularizer': regularizers.l2(0.01),
-        model = Model([input_a, input_b], merged)
+        input_a = layers.Input(shape=input_shapes[0][1:])
-        model = Model.from_config(config)
+        model = models.Model.from_config(config)
-        model = Model([input_a, input_b], merged)
+        merged = layers.Merge(mode=mode)([input_a, input_b])
-    model = Model([input_a, input_b], merged)
+    input_a = layers.Input(shape=input_shapes[0][1:])
-    model = Model.from_config(config)
+    model = models.Model.from_config(config)
-    model = Model([input_a, input_b], merged)
+    input_a = layers.Input(shape=input_shapes[0][1:])
-    model = Model.from_config(config)
+    model = models.Model.from_config(config)
-    model = Model([input_a, input_b], merged)
+    input_a = layers.Input(shape=input_shapes[0][1:])
-    model = Model.from_config(config)
+    model = models.Model.from_config(config)
-    model = Model([input_a, input_b], merged)
+    input_a = layers.Input(shape=input_shapes[0][1:])
-    model = Model.from_config(config)
+    model = models.Model.from_config(config)
-    model = Model([input_a, input_b], merged)
+    input_a = layers.Input(shape=input_shapes[0][1:])
-    model = Model.from_config(config)
+    model = models.Model.from_config(config)
-    input_b = Input(shape=(3,))
+    input_a = layers.Input(shape=(3,))
-    masked_b = Masking(mask_value=0)(input_b)
+    masked_a = layers.Masking(mask_value=0)(input_a)
-    merged_concat_mixed = merge([masked_a, input_b], mode='concat', concat_axis=1)
+    merged_sum = layers.merge([masked_a, masked_b], mode='sum')
-    model_sum = Model([input_a, input_b], [merged_sum])
+    model_sum = models.Model([input_a, input_b], [merged_sum])
-    model_concat = Model([input_a, input_b], [merged_concat])
+    model_concat = models.Model([input_a, input_b], [merged_concat])
-    model_concat = Model([input_a, input_b], [merged_concat_mixed])
+    model_concat = models.Model([input_a, input_b], [merged_concat_mixed])
-    embedding = Embedding(3, 4, mask_zero=True)
+    input_a = layers.Input(shape=(3,), dtype='int32')
-    rnn = SimpleRNN(3, return_sequences=True)
+    rnn = layers.SimpleRNN(3, return_sequences=True)
-    model = Model([input_a, input_b], [merged_concat])
+    merged_concat = layers.merge([rnn_a, rnn_b], mode='concat', concat_axis=-1)
-    seq.add(Dense(input_dim=10, output_dim=10))
+    seq = models.Sequential()
-    x = Input(shape=(10,))
+    x = layers.Input(shape=(10,))
-    model = Model(x, y)
+    model = models.Model(x, y)
-    model = Model.from_config(config)
+    model = models.Model.from_config(config)
-    branch_1.add(LSTM(32, name='lstm_1'))
+    branch_1 = models.Sequential(name='branch_1')
-    branch_2.add(Dense(32, input_shape=(8,), name='dense_2'))
+    branch_2 = models.Sequential(name='branch_2')
-    branch_3.add(Dense(32, input_shape=(6,), name='dense_3'))
+    branch_3 = models.Sequential(name='branch_3')
-    branch_1_2.add(Dense(16, name='dense_1_2-0'))
+    branch_1_2 = models.Sequential([layers.Merge([branch_1, branch_2], mode='concat')], name='branch_1_2')
-    branch_1_2.add(Dense(16, input_shape=(16,), name='dense_1_2-1'))
+    branch_1_2.add(layers.Dense(16, input_shape=(16,), name='dense_1_2-1'))
-    model.add(Dense(16, name='dense_final'))
+    model = models.Sequential([layers.Merge([branch_1_2, branch_3], mode='concat')], name='final')
-    c = Input(shape=(6,))
+    a = layers.Input(shape=(2,), dtype='int32')
-    outer_model = Model([a, b, c], o)
+    outer_model = models.Model([a, b, c], o)
-    outer_model = Model.from_config(config)
+    outer_model = models.Model.from_config(config)
-    model.add(Activation('softmax'))
+    left = models.Sequential()
-    def __init__(self, function, output_shape=None, arguments=None, **kwargs):
+    def __init__(self, function, output_shape=None,
-        self.supports_masking = False
+        if mask is not None:
-    for instance with a `Convolution2D` layer:
+    for instance with a `Conv2D` layer:
-                                  input_shape=(10, 3, 299, 299)))
+        model.add(TimeDistributed(Conv2D(64, (3, 3)),
-        self.supports_masking = True
+        self.supports_masking = True
-        return self.model.trainable_weights
+        if not self.trainable:
-        return self.model.non_trainable_weights
+        # Support for legacy behavior
-from .generic_utils import get_custom_objects
+        relevant_nodes = []
-        assert K.int_shape(n_tf) == (None, 5)
+        assert m_tf.get_shape().as_list() == [None, 64]
-        X = np.zeros((num_rows, len(self.chars)))
+        x = np.zeros((num_rows, len(self.chars)))
-        return X
+            x[i, self.char_indices[c]] = 1
-    def decode(self, X, calc_argmax=True):
+    def decode(self, x, calc_argmax=True):
-        return ''.join(self.indices_char[x] for x in X)
+            x = x.argmax(axis=-1)
-MAXLEN = DIGITS + 1 + DIGITS
+MAxLEN = DIGITS + 1 + DIGITS
-    # Also skip any such that X+Y == Y+X (hence the sorting).
+    # Also skip any such that x+Y == Y+x (hence the sorting).
-    # Pad the data with spaces such that it is always MAXLEN.
+    # Pad the data with spaces such that it is always MAxLEN.
-    query = q + ' ' * (MAXLEN - len(q))
+    query = q + ' ' * (MAxLEN - len(q))
-X = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)
+x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)
-    X[i] = ctable.encode(sentence, MAXLEN)
+    x[i] = ctable.encode(sentence, MAxLEN)
-# Shuffle (X, y) in unison as the later parts of X will almost all be larger
+# Shuffle (x, y) in unison as the later parts of x will almost all be larger
-X = X[indices]
+x = x[indices]
-(y_train, y_val) = (y[:split_at], y[split_at:])
+split_at = len(x) - len(x) // 10
-print(X_train.shape)
+print(x_train.shape)
-print(X_val.shape)
+print(x_val.shape)
-model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))
+model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))
-              validation_data=(X_val, y_val))
+    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1,
-        q = ctable.decode(rowX[0])
+        ind = np.random.randint(0, len(x_val))
-        neg = K.relu(-x)
+    def call(self, inputs):
-(X_train, y_train), (X_test, y_test) = mnist.load_data()
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-print(X_test.shape[0], 'test samples')
+x_train = x_train.reshape(60000, 784)
-model.fit(X_train, Y_train,
+model.fit(x_train, Y_train,
-          verbose=1, validation_data=(X_test, Y_test))
+          verbose=1, validation_data=(x_test, Y_test))
-QA6 - Yes/No Questions       | 48               | 50.7
+QA6 - yes/No Questions       | 48               | 50.7
-from keras.layers import Dense, Merge, Dropout, RepeatVector
+from keras import layers
-from keras.models import Sequential
+from keras.models import Model
-    Y = []
+    xs = []
-    return pad_sequences(X, maxlen=story_maxlen), pad_sequences(Xq, maxlen=query_maxlen), np.array(Y)
+        xs.append(x)
-QUERY_HIDDEN_SIZE = 100
+QUERy_HIDDEN_SIZE = 100
-print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN, EMBED_HIDDEN_SIZE, SENT_HIDDEN_SIZE, QUERY_HIDDEN_SIZE))
+print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN, EMBED_HIDDEN_SIZE, SENT_HIDDEN_SIZE, QUERy_HIDDEN_SIZE))
-tX, tXq, tY = vectorize_stories(test, word_idx, story_maxlen, query_maxlen)
+x, xq, y = vectorize_stories(train, word_idx, story_maxlen, query_maxlen)
-print('Y.shape = {}'.format(Y.shape))
+print('x.shape = {}'.format(x.shape))
-sentrnn.add(Dropout(0.3))
+sentence = layers.Input(shape=(story_maxlen,), dtype='int32')
-qrnn.add(RepeatVector(story_maxlen))
+question = layers.Input(shape=(query_maxlen,), dtype='int32')
-model.add(Dense(vocab_size, activation='softmax'))
+merged = layers.sum([encoded_sentence, encoded_question])
-loss, acc = model.evaluate([tX, tXq], tY, batch_size=BATCH_SIZE)
+model.fit([x, xq], y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.05)
-    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10_cnn.py
+    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatx=float32 python cifar10_cnn.py
-from keras.layers import Convolution2D, MaxPooling2D
+from keras.layers import Conv2D, MaxPooling2D
-print(X_test.shape[0], 'test samples')
+(x_train, y_train), (x_test, y_test) = cifar10.load_data()
-Y_test = np_utils.to_categorical(y_test, num_classes)
+y_train = np_utils.to_categorical(y_train, num_classes)
-                        input_shape=X_train.shape[1:]))
+model.add(Conv2D(32, (3, 3), padding='same',
-model.add(Convolution2D(32, 3, 3))
+model.add(Conv2D(32, (3, 3)))
-model.add(Convolution2D(64, 3, 3, border_mode='same'))
+model.add(Conv2D(64, (3, 3), padding='same'))
-model.add(Convolution2D(64, 3, 3))
+model.add(Conv2D(64, (3, 3)))
-X_test /= 255
+x_train = x_train.astype('float32')
-    model.fit(X_train, Y_train,
+    model.fit(x_train, y_train,
-              validation_data=(X_test, Y_test),
+              validation_data=(x_test, y_test),
-    datagen.fit(X_train)
+    datagen.fit(x_train)
-    model.fit_generator(datagen.flow(X_train, Y_train,
+    model.fit_generator(datagen.flow(x_train, y_train,
-                        samples_per_epoch=X_train.shape[0],
+                        samples_per_epoch=x_train.shape[0],
-                        validation_data=(X_test, Y_test))
+                        validation_data=(x_test, y_test))
-from keras.layers.convolutional import Convolution3D
+from keras.layers.convolutional import Conv3D
-seq.add(ConvLSTM2D(filters=40, num_row=3, num_col=3,
+seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
-                   border_mode='same', return_sequences=True))
+                   padding='same', return_sequences=True))
-                   border_mode='same', return_sequences=True))
+seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
-                   border_mode='same', return_sequences=True))
+seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
-                   border_mode='same', return_sequences=True))
+seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
-
+seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),
-model.add(Activation('sigmoid'))
+model.add(Embedding(max_features, 128))
-    lengths = [len(s) for s in sequences]
+    if not hasattr(sequences, '__len__'):
-    def summary(self, line_length=100, positions=[.33, .55, .67, 1.]):
+    def summary(self, line_length=None, positions=None):
-                      getattr(self, 'container_nodes', None),
+        print_summary(self,
-                  line_length=100, positions=None):
+def print_summary(model, line_length=None, positions=None):
-        relevant_nodes: list of relevant nodes
+        model: Keras model instance.
-    to_display = ['Layer (type)', 'Output Shape', 'Param #', 'Connected to']
+
-        print_layer_summary(layers[i])
+        if sequential_like:
-from ..layers import Convolution2D, MaxPooling2D, AveragePooling2D
+from .. import layers
-              border_mode='same', subsample=(1, 1),
+              padding='same', strides=(1, 1),
-                      name=conv_name)(x)
+    x = Conv2D(filters, (num_row, num_col),
-    x = conv2d_bn(x, 32, 3, 3, border_mode='valid')
+    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')
-    x = conv2d_bn(x, 192, 3, 3, border_mode='valid')
+    x = conv2d_bn(x, 80, 1, 1, padding='valid')
-            (3, 3), strides=(1, 1), border_mode='same')(x)
+            (3, 3), strides=(1, 1), padding='same')(x)
-                  name='mixed' + str(i))
+        x = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],
-    branch3x3 = conv2d_bn(x, 384, 3, 3, subsample=(2, 2), border_mode='valid')
+    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')
-                             subsample=(2, 2), border_mode='valid')
+                             strides=(2, 2), padding='valid')
-              name='mixed3')
+    x = layers.concatenate([branch3x3, branch3x3dbl, branch_pool],
-    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(x)
+    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)
-              name='mixed4')
+    x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],
-            (3, 3), strides=(1, 1), border_mode='same')(x)
+            (3, 3), strides=(1, 1), padding='same')(x)
-                  name='mixed' + str(5 + i))
+        x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],
-    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(x)
+    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)
-              name='mixed7')
+    x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],
-                          subsample=(2, 2), border_mode='valid')
+                          strides=(2, 2), padding='valid')
-                            subsample=(2, 2), border_mode='valid')
+                            strides=(2, 2), padding='valid')
-              name='mixed8')
+    x = layers.concatenate([branch3x3, branch7x7x3, branch_pool],
-                          name='mixed9_' + str(i))
+        branch3x3 = layers.concatenate([branch3x3_1, branch3x3_2],
-                             mode='concat', concat_axis=channel_axis)
+        branch3x3dbl = layers.concatenate([branch3x3dbl_1, branch3x3dbl_2],
-            (3, 3), strides=(1, 1), border_mode='same')(x)
+            (3, 3), strides=(1, 1), padding='same')(x)
-                  name='mixed' + str(9 + i))
+        x = layers.concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool],
-from ..layers.convolutional import Convolution2D
+from ..layers import Reshape, Permute
-                    include_top=True, classes=50):
+                    include_top=True,
-    x = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(x)
+    x = Conv2D(64, (3, 3), padding='same', name='conv1')(x)
-    x = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(x)
+    x = Conv2D(128, (3, 3), padding='same', name='conv2')(x)
-    x = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(x)
+    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)
-    x = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(x)
+    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)
-from ..layers import merge, Input
+from ..layers import Input
-from ..layers import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D
+from ..layers import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
-    x = Convolution2D(filters1, 1, 1, name=conv_name_base + '2a')(input_tensor)
+    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)
-                      border_mode='same', name=conv_name_base + '2b')(x)
+    x = Conv2D(filters2, kernel_size, kernel_size,
-    x = Convolution2D(filters3, 1, 1, name=conv_name_base + '2c')(x)
+    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)
-    x = merge([x, input_tensor], mode='sum')
+    x = layers.sum([x, input_tensor])
-    And the shortcut should have subsample=(2,2) as well
+    Note that from stage 3, the first conv layer at main path is with strides=(2,2)
-                      name=conv_name_base + '2a')(input_tensor)
+    x = Conv2D(filters1, (1, 1), strides=strides,
-                      name=conv_name_base + '2b')(x)
+    x = Conv2D(filters2, (kernel_size, kernel_size), pading='same',
-    x = Convolution2D(filters3, 1, 1, name=conv_name_base + '2c')(x)
+    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)
-                             name=conv_name_base + '1')(input_tensor)
+    shortcut = Conv2D(filters3, (1, 1), strides=strides,
-    x = merge([x, shortcut], mode='sum')
+    x = layers.sum([x, shortcut])
-    x = Convolution2D(64, 7, 7, subsample=(2, 2), name='conv1')(x)
+    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)
-from ..layers import Convolution2D, MaxPooling2D
+from ..layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
-    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)
+    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)
-    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)
+    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)
-    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3')(x)
+    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)
-    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)
+    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)
-    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)
+    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)
-from ..layers import Convolution2D, MaxPooling2D, GlobalAveragePooling, GlobalMaxPooling
+from ..layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D
-    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)
+    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)
-    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)
+    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)
-    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv4')(x)
+    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)
-    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv4')(x)
+    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)
-    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv4')(x)
+    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)
-            x = GlobalAveragePooling()(x)
+            x = GlobalAveragePooling2D()(x)
-            x = GlobalMaxPooling()(x)
+            x = GlobalMaxPooling2D()(x)
-from ..layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D
+from .. import layers
-    x = Conv2D(32, 3, 3, subsample=(2, 2), bias=False, name='block1_conv1')(img_input)
+    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')(img_input)
-    x = Conv2D(64, 3, 3, bias=False, name='block1_conv2')(x)
+    x = Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)
-                      border_mode='same', bias=False)(x)
+    residual = Conv2D(128, (1, 1), strides=(2, 2),
-    x = SeparableConv2D(128, 3, 3, border_mode='same', bias=False, name='block2_sepconv1')(x)
+    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)
-    x = SeparableConv2D(128, 3, 3, border_mode='same', bias=False, name='block2_sepconv2')(x)
+    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')(x)
-    x = merge([x, residual], mode='sum')
+    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)
-                      border_mode='same', bias=False)(x)
+    residual = Conv2D(256, (1, 1), strides=(2, 2),
-    x = SeparableConv2D(256, 3, 3, border_mode='same', bias=False, name='block3_sepconv1')(x)
+    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)
-    x = SeparableConv2D(256, 3, 3, border_mode='same', bias=False, name='block3_sepconv2')(x)
+    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')(x)
-    x = merge([x, residual], mode='sum')
+    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)
-                      border_mode='same', bias=False)(x)
+    residual = Conv2D(728, (1, 1), strides=(2, 2),
-    x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block4_sepconv1')(x)
+    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')(x)
-    x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block4_sepconv2')(x)
+    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')(x)
-    x = merge([x, residual], mode='sum')
+    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)
-        x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv1')(x)
+        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')(x)
-        x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv2')(x)
+        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')(x)
-        x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv3')(x)
+        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')(x)
-        x = merge([x, residual], mode='sum')
+        x = layers.sum([x, residual])
-                      border_mode='same', bias=False)(x)
+    residual = Conv2D(1024, (1, 1), strides=(2, 2),
-    x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block13_sepconv1')(x)
+    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block13_sepconv1')(x)
-    x = SeparableConv2D(1024, 3, 3, border_mode='same', bias=False, name='block13_sepconv2')(x)
+    x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, name='block13_sepconv2')(x)
-    x = merge([x, residual], mode='sum')
+    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)
-    x = SeparableConv2D(1536, 3, 3, border_mode='same', bias=False, name='block14_sepconv1')(x)
+    x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, name='block14_sepconv1')(x)
-    x = SeparableConv2D(2048, 3, 3, border_mode='same', bias=False, name='block14_sepconv2')(x)
+    x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)
-        if not isinstance(input_shape, list) or len(input_shape) != 2:
+        if not isinstance(input_shape, list):
-            return
+                             'on a list of inputs')
-                             'on a list of 2 inputs.')
+                             'on a list of inputs.')
-        if not isinstance(input_shape, list) or len(input_shape) != 2:
+        if not isinstance(input_shape, list):
-                             'on a list of 2 inputs.')
+                             'on a list of inputs.')
-        self.strides = conv_utils.normalize_tuple(pool_size, 2, 'strides')
+        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')
-                    reason="Requires tensorflow backend")
+                    reason='Requires tensorflow backend')
-                                    [0, 0, 1]])
+
-                                  zoom_matrix)
+        transform_matrix = None
-                            fill_mode=self.fill_mode, cval=self.cval)
+from __future__ import absolute_import
-import sys
+import json
-def load_data(path='imdb_full.pkl', num_words=None, skip_top=0,
+def load_data(path='imdb.npz', num_words=None, skip_top=0,
-    (x_train, labels_train), (x_test, labels_test) = cPickle.load(f)
+                    origin='https://s3.amazonaws.com/text-datasets/imdb.npz')
-    labels = labels_train + labels_test
+    xs = np.concatenate([x_train, x_test])
-def get_word_index(path='imdb_word_index.pkl'):
+def get_word_index(path='imdb_word_index.json'):
-
+                    origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json')
-import sys
+import numpy as np
-def load_data(path='mnist.pkl.gz'):
+def load_data(path='mnist.npz'):
-
+    path = get_file(path, origin='https://s3.amazonaws.com/img-datasets/mnist.npz')
-    return data  # (x_train, y_train), (x_test, y_test)
+    return (x_train, y_train), (x_test, y_test)
-import sys
+import json
-def load_data(path='reuters.pkl', num_words=None, skip_top=0,
+def load_data(path='reuters.npz', num_words=None, skip_top=0,
-    f.close()
+    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters.npz')
-    y_train = labels[:int(len(xs) * (1 - test_split))]
+    x_train = np.array(xs[:int(len(xs) * (1 - test_split))])
-    y_test = labels[int(len(xs) * (1 - test_split)):]
+    x_test = np.array(xs[int(len(xs) * (1 - test_split)):])
-def get_word_index(path='reuters_word_index.pkl'):
+def get_word_index(path='reuters_word_index.json'):
-
+    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters_word_index.json')
-from keras.datasets import cifar10, cifar100, reuters, imdb, mnist
+from keras.datasets import cifar10
-        (X_train, y_train), (X_test, y_test) = cifar100.load_data('coarse')
+        (x_train, y_train), (x_test, y_test) = cifar10.load_data()
-        (X_train, y_train), (X_test, y_test) = reuters.load_data(maxlen=10)
+        (x_train, y_train), (x_test, y_test) = reuters.load_data()
-        (X_train, y_train), (X_test, y_test) = mnist.load_data()
+        (x_train, y_train), (x_test, y_test) = mnist.load_data()
-        (X_train, y_train), (X_test, y_test) = imdb.load_data(maxlen=40)
+        (x_train, y_train), (x_test, y_test) = imdb.load_data()
-        x._dims = len(shape)
+        x = tf.sparse_placeholder(dtype, shape=shape, name=name)
-    return tuple([i.__int__() for i in shape])
+    try:
-
+from contextlib import contextmanager
-def is_explicit_shape(shape):
+def _is_explicit_shape(shape):
-        variable = th_sparse_module.as_sparse_variable(value)
+        variable = th_sparse_module.as_sparse_variable(
-        variable = theano.shared(value=value, name=name, strict=False)
+        variable = theano.shared(value=value,
-    const = T.constant(np_value, dtype=dtype, name=name)
+    const = T.constant(np_value,
-    if is_explicit_shape(shape):
+    if _is_explicit_shape(shape):
-        pass
+        self.validation_data = None
-        if self.model.validation_data and self.histogram_freq:
+        if self.validation_data and self.histogram_freq:
-                    val_data = self.model.validation_data[:cut_v_data] + [0]
+                    val_data = self.validation_data[:cut_v_data] + [0]
-                    val_data = self.model.validation_data
+                    val_data = self.validation_data
-                if K.ndim(x) > spec.max_ndim:
+                ndim = K.ndim(x)
-                if K.ndim(x) < spec.min_ndim:
+                ndim = K.ndim(x)
-                                     str(spec.max_ndim) + ', found ndim=' +
+                                     str(spec.min_ndim) + ', found ndim=' +
-                                         ' but got shape ' + str(x_shape))
+                    x_shape = None
-                                str(x_shape))
+                    x_shape = None
-        if not self.built:
+        with K.name_scope(self.name):
-            # with the input_spec specified in the layer constructor.
+            # with the input_spec set at build time.
-                self.build(input_shapes[0])
+            # Handle mask propagation.
-            self.add_loss(regularization_losses, _to_list(x))
+                if isinstance(input_shape, list):
-        input_shapes = _to_list(output_shapes)
+        input_shapes = _to_list(input_shapes)
-                break
+                inbound_layers.append(None)
-            uses_lp = any([x._uses_learning_phase for x in input_tensors])
+            uses_lp = any([getattr(x, '_uses_learning_phase', False) for x in input_tensors])
-    def compute_mask(self, input, mask=None):
+    def compute_mask(self, inputs, mask=None):
-            input: Tensor or list of tensors.
+            inputs: Tensor or list of tensors.
-        inputs = _to_list(input)
+    def compute_mask(self, inputs, mask):
-                                                                 mask=computed_mask))
+                    with K.name_scope(layer.name):
-                                                                   computed_masks))
+                            computed_tensors = [x[0] for x in computed_data]
-            raise ValueError('Input tensor is not a Keras tensor:', x)
+        try:
-
+            for cbk in callbacks:
-        self.pointwise_regularizer = regularizers.get(pointwise_constraint)
+        self.pointwise_regularizer = regularizers.get(pointwise_regularizer)
-                                 'should have the same length.')
+        if mask is None:
-            raise ValueError('TODO')
+            raise ValueError('`mask` should be a list.')
-        base_config = super(Dot, self).get_config()
+        base_config = super(Concatenate, self).get_config()
-def sum(inputs):
+def sum(inputs, **kwargs):
-    return Sum()(inputs)
+    return Sum(**kwargs)(inputs)
-def multiply(inputs):
+def multiply(inputs, **kwargs):
-    return Multiply()(inputs)
+    return Multiply(**kwargs)(inputs)
-def average(inputs):
+def average(inputs, **kwargs):
-    return Average()(inputs)
+    return Average(**kwargs)(inputs)
-def maximum(inputs):
+def maximum(inputs, **kwargs):
-    return Maximum()(inputs)
+    return Maximum(**kwargs)(inputs)
-def concatenate(inputs, axis=-1):
+def concatenate(inputs, axis=-1, **kwargs):
-    return Concatenate(axis=axis)(inputs)
+    return Concatenate(axis=axis, **kwargs)(inputs)
-def dot(inputs, axes, normalize=False):
+def dot(inputs, axes, normalize=False, **kwargs):
-    return Dot(axes=axes, normalize=normalize)(inputs)
+    return Dot(axes=axes, normalize=normalize, **kwargs)(inputs)
-from keras.engine import merge, Input, get_source_inputs
+from keras import layers
-    m = merge([a_2, b_2], mode='concat')
+    m = layers.concatenate([a_2, b_2])
-    merged = merge([a_2, b_2], mode='concat', name='merge')
+    merged = layers.concatenate([a_2, b_2], name='merge')
-    model = Model(input=[a, b], output=[c, d], name='model')
+    model = Model(inputs=[a, b], outputs=[c, d], name='model')
-    merged = merge([a_2, b_2], mode='concat', name='merge')
+    merged = layers.concatenate([a_2, b_2], name='merge')
-    model = Model(input=[a, b], output=[c, d], name='model')
+    model = Model(inputs=[a, b], outputs=[c, d], name='model')
-    final_model = Model(input=[e, f], output=[i, g], name='final')
+    final_model = Model(inputs=[e, f], outputs=[i, g], name='final')
-    s = merge([n, q], mode='concat', name='merge_nq')
+    s = layers.concatenate([n, q], name='merge_nq')
-    new_model = Model.from_config(config)
+    Model.from_config(config)
-    new_model = model_from_json(json_str)
+    model_from_json(json_str)
-    new_model = model_from_yaml(yaml_str)
+    model_from_yaml(yaml_str)
-        invalid_model = Model([j, k], [m, n])
+        Model([j, k], [m, n])
-        invalid_model = Model([j], [m, n])
+        Model([j], [m, n])
-    invalid_model = Model([j, k], [m, n, n])
+    Model([j, k], [m, n, n])
-        invalid_model = Model([j, k, j], [m, n])
+        Model([j, k, j], [m, n])
-        invalid_model = Model([j, k], [m, n, 0])
+        Model([j, k], [m, n, 0])
-        o_tf = merge([j_tf, k_tf], mode='concat', concat_axis=1)
+        layers.concatenate([j_tf, k_tf], axis=1)
-        input_layer = InputLayer(input_tensor=x)
+        InputLayer(input_tensor=x)
-    outer_model.fit([x, y, z], labels, epochs=1)
+        Dense(2)(x)
-if __name__ == "__main__":
+if __name__ == '__main__':
-from keras.engine.topology import merge, Input
+from keras.engine.topology import Input
-                                   'depthwise_constraint': 'unitnorm',
+                                   'pointwise_constraint': 'unit_norm',
-
+    # Test dilation
-from keras.layers import Dense, Activation, RepeatVector, TimeDistributedDense, GRU
+from keras.layers import Dense, Activation, GRU, TimeDistributed
-standard_weight = 1
+standard_weight = 1
-sample_weight[y_train == weighted_class] = high_weight
+def _get_test_data():
-temporal_X_test = np.repeat(temporal_X_test, timesteps, axis=1)
+    class_weight = dict([(i, standard_weight) for i in range(num_classes)])
-temporal_Y_test = np.repeat(temporal_Y_test, timesteps, axis=1)
+    sample_weight = np.ones((y_train.shape[0])) * standard_weight
-temporal_sample_weight = np.repeat(temporal_sample_weight, timesteps, axis=1)
+    return (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids)
-    model.add(TimeDistributedDense(num_classes))
+    model.add(TimeDistributed(Dense(num_classes)))
-    score = _test_weights_sequential(model, class_weight=class_weight)
+
-    score = _test_weights_sequential(model, sample_weight=sample_weight)
+
-                                     Y_test=temporal_Y_test)
+    model.fit(temporal_x_train, temporal_y_train, batch_size=batch_size,
-from keras.layers import Dense, Dropout, Lambda, RepeatVector, TimeDistributed
+from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed
-from keras import objectives
+from keras import losses
-    model.compile(loss=objectives.MSE,
+    model.compile(loss=losses.MSE,
-    custom_loss = objectives.mse
+    custom_loss = losses.mse
-    model.compile(loss=objectives.MSE,
+    model.compile(loss=losses.MSE,
-    custom_loss = objectives.mse
+    custom_loss = losses.mse
-    model.add(Dense(3, name="morty"))
+    model.add(Dense(2, input_shape=(3,), name='rick'))
-    model.add(Dense(3, name="morty"))
+    model.add(Dense(2, input_shape=(3,), name='rick'))
-    custom_loss = objectives.mse
+    custom_loss = losses.mse
-    model.add(Dense(3, name="morty"))
+    model.add(Dense(2, input_shape=(3,), name='rick'))
-    morty = Dense(3, name="morty")(jessica)
+    rick = Dense(2, name='rick')(data)
-    model = Model(input=[data], output=[morty])
+    model = Model(inputs=[data], outputs=[morty])
-    model.compile(loss=objectives.MSE,
+    model.compile(loss=losses.MSE,
-    # test get_weights , set_weights
+    # test get_weights , set_weights at layer level
-
+    # test training mode (e.g. useful for dropout tests)
-    model = model_from_json(json_model)
+    # test serialization, weight setting at model level
-            ones = K.tile(ones, (1, int(input_dim)))
+            ones = K.zeros_like(inputs)
-            ones = K.tile(ones, (1, self.filters))
+            shape = list(self.kernel_shape)
-                                 np.ones_like(output))
+                                 np.random.random(out1.shape))
-                      'recurrent_regularizer': regularizers.WeightRegularizer(l1=0.01),
+                      'kernel_regularizer': regularizers.L1L2(l1=0.01),
-                                        K.zeros(self.kernel_shape),
+                                        K.zeros(tuple(shape)),
-        input_shape = self.input_spec[0].shape
+        input_shape = self.input_spec.shape
-                                  self.bias,
+        if b is not None:
-    def reccurent_conv(self, x, w, padding='valid'):
+    def reccurent_conv(self, x, w):
-                            padding=padding,
+                            padding='same',
-                                  padding='same')
+                                  self.recurrent_kernel_i)
-                                  padding='same')
+                                  self.recurrent_kernel_f)
-                                  padding='same')
+                                  self.recurrent_kernel_c)
-                                  padding='same')
+                                  self.recurrent_kernel_o)
-        f = self.inner_activation(x_f + h_f)
+        i = self.recurrent_activation(x_i + h_i)
-        o = self.inner_activation(x_o + h_o)
+        o = self.recurrent_activation(x_o + h_o)
-        # Insert custom objects into globals.
+        globs = globals()
-
+            globs = dict(globs.items() + custom_objects.items())
-            function = get_from_module(config['function'], globs, 'core')
+            # Simple lookup in custom objects
-            output_shape = get_from_module(config['output_shape'], globs, 'core')
+            # Simple lookup in custom objects
-                                 ':', class_name)
+                                 ':' + class_name)
-def test_recurrent_convolutional():
+def test_convolutional_recurrent():
-        else:  # tf
+        else:
-            # test for ouptput shape:
+            # test for output shape:
-            # No need to check statefulness for both
+            # No need to check following tests for both data formats
-from ..layers import Convolution2D, MaxPooling2D
+from ..layers import Convolution2D, MaxPooling2D, GlobalAveragePooling, GlobalMaxPooling
-                                    printable_module_name='regularizer')
+                                    printable_module_name='constraint')
-        self.constraints = {}  # dict {tensor: constraint instance}
+        self._constraints = {}  # dict {tensor: constraint instance}
-                raise ValueError('Input tensor is not a Keras tensor:', x)
+                assert len(input_tensors) == 1
-        self.constraints = {}
+        self._constraints = {}
-                                                                    mask=computed_mask))
+                        if 'mask' in inspect.getargspec(layer.call).args:
-                                                                    mask=computed_masks))
+                        if 'mask' in inspect.getargspec(layer.call).args:
-    tensor_indices = []
+    masks = []
-            tensor_indices.append(tensor_index)
+            node = inbound_layer.inbound_nodes[node_index]
-    masks = [node.output_masks[i] for node, i in zip(nodes, tensor_indices)]
+            masks.append(None)
-                axes[i] = input_shape[i]
+        if self.shared_axes:
-                self.bias += K.concatenate(K.zeros((self.filters,)),
+                self.bias += K.concatenate([K.zeros((self.filters,)),
-                                           K.zeros((self.filters * 2,)))
+                                           K.zeros((self.filters * 2,))])
-        self.recurrent_kernel_o = self.recurrent_kernel[:, :, :, self.units * 3:]
+        self.kernel_i = self.kernel[:, :, :, :self.filters]
-            self.bias_o = self.bias[self.units * 3:]
+            self.bias_i = self.bias[:self.filters]
-            ones = K.tile(ones, (1, self.units))
+            ones = K.tile(ones, (1, self.filters))
-        conv_out = K.conv2d(x, w, strides=self.subsample,
+        conv_out = K.conv2d(x, w, strides=self.strides,
-                  'bias_regularizer': regularizers.serialize(bias_regularizer),
+                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),
-        self.activity_regularizer = regularizers.L1L2Regularizer(l1=l1, l2=l2)
+        self.activity_regularizer = regularizers.L1L2(l1=l1, l2=l2)
-            initializer=self.init,
+            initializer=self.kernel_initializer,
-        self.input_spec = InputSpec(ndim=3, axes={1: input_dim})
+        self.input_spec = InputSpec(ndim=3, axes={2: input_dim})
-                                data_format='channels_last')
+            output += K.reshape(self.bias, (1, output_length, filters))
-        if self.bias:
+        if self.use_bias:
-                                data_format=self.data_format)
+            if self.data_format == 'channels_first':
-                                       stddev=self.stddev)
+        def noised():
-            def noised(x):
+            def noised():
-                                           stddev=stddev)
+                return inputs + K.random_normal(shape=K.shape(inputs),
-            self.add_update([K.moving_average_update(self.running_mean,
+            self.add_update([K.moving_average_update(self.moving_mean,
-                             K.moving_average_update(self.running_std,
+                             K.moving_average_update(self.moving_variance,
-                    broadcast_running_std = K.reshape(self.running_std,
+                    broadcast_moving_mean = K.reshape(self.moving_mean,
-                        broadcast_beta, broadcast_gamma,
+                        inputs,
-                        self.beta, self.gamma,
+                        inputs,
-                                               self.padding, self.strides)
+        length = conv_utils.conv_output_length(input_shape[1],
-                                        strides=self.st,
+                                        pool_size=self.pool_size + (1,),
-        input_shape = self.input_spec[0].shape
+        input_shape = self.input_spec.shape
-            output._uses_learning_phase = uses_learning_phase
+            output._uses_learning_phase = True
-                  'bias_regularizer': regularizers.serialize(bias_regularizer),
+                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),
-        input_shape = self.input_spec[0].shape
+        input_shape = self.input_spec.shape
-                            self.recurrent_kernel[:, 2 * self.units:])
+                                self.recurrent_kernel[:, 2 * self.units:])
-        self.input_spec = [InputSpec(shape=input_shape)]
+        self.input_spec = InputSpec(shape=input_shape)
-        input_shape = self.input_spec[0].shape
+        input_shape = self.input_spec.shape
-                  'bias_regularizer': regularizers.serialize(bias_regularizer),
+                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),
-        super(Bidirectional, self).__init__(layer, **kwargs)
+        self.built = True
-    if padding not in {'valid', 'same'}:
+    allowed = {'valid', 'same'}
-def layer_test(layer_cls, kwargs={}, input_shape=None, dtype=None,
+def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,
-            dtype = K.floatx()
+        if not input_dtype:
-        input_data = input_data.astype(dtype)
+        input_data = input_data.astype(input_dtype)
-        expected_output_dtype = dtype
+        expected_output_dtype = input_dtype
-        x = Input(batch_shape=input_shape, dtype=dtype)
+        x = Input(batch_shape=input_shape, dtype=input_dtype)
-        x = Input(shape=input_shape[1:], dtype=dtype)
+        x = Input(shape=input_shape[1:], dtype=input_dtype)
-    model = Model(input=x, output=y)
+    # check shape inference
-    # test serialization
+    # test serialization, weight setting at model level
-    model.compile('rmsprop', 'mse')
+    recovered_model = Model.from_config(model_config)
-    assert history.history['val_acc'][-1] > 0.8
+    assert history.history['val_acc'][-1] > 0.75
-from keras.utils.test_utils import layer_test, keras_test
+from keras.utils.test_utils import layer_test
-               kwargs={'sigma': 1.},
+               kwargs={'stddev': 1.},
-               kwargs={'p': 0.5},
+               kwargs={'rate': 0.5},
-                                   input_num_row, input_num_col)
+            inputs = np.random.rand(num_samples, sequence_len,
-                                   input_channel)
+            inputs = np.random.rand(num_samples, sequence_len,
-                                input_shape=input.shape)
+                                        'kernel_size': (num_row, num_col),
-                      'num_col': num_col,
+                      'kernel_size': (num_row, num_col),
-                      'border_mode': "same"}
+                      'batch_input_shape': inputs.shape,
-            out1 = model.predict(np.ones_like(input))
+            out1 = model.predict(np.ones_like(inputs))
-            model.train_on_batch(np.ones_like(input),
+            model.train_on_batch(np.ones_like(inputs),
-            out2 = model.predict(np.ones_like(input))
+            out2 = model.predict(np.ones_like(inputs))
-            out3 = model.predict(np.ones_like(input))
+            out3 = model.predict(np.ones_like(inputs))
-            out4 = model.predict(np.ones_like(input))
+            out4 = model.predict(np.ones_like(inputs))
-            out5 = model.predict(np.ones_like(input))
+            out5 = model.predict(np.ones_like(inputs))
-                      'num_col': num_col,
+                      'kernel_size': (num_row, num_col),
-                      'border_mode': "same"}
+                      'batch_input_shape': inputs.shape,
-            output = layer(K.variable(np.ones(input.shape)))
+            layer.build(inputs.shape)
-                       input_shape=input.shape)
+                               'kernel_size': (num_row, num_col),
-from keras.layers import recurrent, embeddings
+from keras.utils.test_utils import keras_test
-num_samples, timesteps, embedding_dim, output_dim = 2, 5, 4, 3
+num_samples, timesteps, embedding_dim, units = 2, 5, 4, 3
-    return pytest.mark.parametrize("layer_class", [
+    return pytest.mark.parametrize('layer_class', [
-               kwargs={'output_dim': output_dim,
+               kwargs={'units': units,
-    layer = layer_class(output_dim, input_dim=embedding_dim)
+    layer = layer_class(units, input_shape=(None, embedding_dim))
-    y = np.random.random((num_samples, output_dim))
+    y = np.random.random((num_samples, units))
-                       'dropout_W': 0.1},
+               kwargs={'units': units,
-    for mode in ['cpu', 'mem', 'gpu']:
+    for mode in [0, 1, 2]:
-                           'consume_less': mode},
+                   kwargs={'units': units,
-    layer = layer_class(output_dim, return_sequences=False,
+    layer = layer_class(units, return_sequences=False,
-    assert(out1.shape == (num_samples, output_dim))
+    assert(out1.shape == (num_samples, units))
-                         np.ones((num_samples, output_dim)))
+                         np.ones((num_samples, units)))
-    layer = layer_class(output_dim, return_sequences=False, weights=None,
+    layer = layer_class(units, return_sequences=False, weights=None,
-        assert len(layer.losses) == 12
+                        kernel_regularizer=regularizers.l1(0.01),
-    V /= V.sum(axis=-1, keepdims=True)
+    inputs = np.random.random((6, 3, 4))
-    model.add(recurrent.LSTM(output_dim=5, return_sequences=True, unroll=False))
+    model.add(recurrent.LSTM(units=5, return_sequences=True, unroll=False))
-    model.fit(I, V, epochs=1, batch_size=100, verbose=1)
+    model.fit(inputs, targets, epochs=1, batch_size=100, verbose=1)
-    model.add(recurrent.LSTM(output_dim=5, return_sequences=True, unroll=True))
+    model.add(recurrent.LSTM(units=5, return_sequences=True, unroll=True))
-    model.fit(I, V, epochs=1, batch_size=100, verbose=1)
+    model.fit(inputs, targets, epochs=1, batch_size=100, verbose=1)
-        l1 = layer_class(output_dim=1, stateful=stateful)
+        l1 = layer_class(units=1, stateful=stateful)
-    # test with Convolution2D
+    # test with Conv2D
-    model.add(wrappers.TimeDistributed(convolutional.Convolution2D(5, 2, 2, border_mode='same'), input_shape=(2, 4, 4, 3)))
+    model.add(wrappers.TimeDistributed(convolutional.Conv2D(5, (2, 2), padding='same'), input_shape=(2, 4, 4, 3)))
-    model.add(wrappers.TimeDistributed(core.Dense(2, W_regularizer='l1'), input_shape=(3, 4)))
+    model.add(wrappers.TimeDistributed(core.Dense(2, kernel_regularizer='l1'), input_shape=(3, 4)))
-from keras.layers.core import TimeDistributedDense, Masking
+from keras.layers import TimeDistributed, Masking, Dense
-from keras import objectives
+from keras import losses
-    X = np.array([[[1], [1]],
+    x = np.array([[[1], [1]],
-    model.add(TimeDistributedDense(1, init='one'))
+    model.add(TimeDistributed(Dense(1, kernel_initializer='one')))
-    loss = model.train_on_batch(X, y)
+    loss = model.train_on_batch(x, y)
-    weighted_loss = weighted_objective(objectives.get('mae'))
+    weighted_loss = weighted_objective(losses.get('mae'))
-    Y = 2 * X
+    x = np.arange(24).reshape(shape)
-                               K.variable(Y),
+    out = K.eval(weighted_loss(K.variable(x),
-        return {'name': self.__class__.__name__}
+        return {}
-        self.m = m
+    def __init__(self, max_value=2, axis=0):
-        return p
+        desired = K.clip(norms, 0, self.max_value)
-                'm': self.m,
+        return {'max_value': self.max_value,
-        return p
+    def __call__(self, w):
-                'axis': self.axis}
+        return {'axis': self.axis}
-        high: the maximum norm for the incoming weights.
+        min_value: the minimum norm for the incoming weights.
-            rescaled to yield (1 - rate) * norm + rate * norm.clip(low, high).
+            rescaled to yield
-        self.high = high
+    def __init__(self, min_value=0.0, max_value=1.0, rate=1.0, axis=0):
-        desired = (self.rate * K.clip(norms, self.low, self.high) +
+        desired = (self.rate * K.clip(norms, self.min_value, self.max_value) +
-                'high': self.high,
+        return {'min_value': self.min_value,
-        f.attrs['layer_names'] = [layer.name.encode('utf8') for layer in flattened_layers]
+        f.attrs['layer_names'] = [layer.name.encode('utf8') for layer in self.layers]
-        for layer in flattened_layers:
+        for layer in self.layers:
-            K.batch_set_value(weight_value_tuples)
+        filtered_layers = []
-            flattened_layers = self.layers
+        # New file format.
-            K.batch_set_value(weight_value_tuples)
+        # Reverse index of layer name to list of layers with name.
-        print_summary(flattened_layers,
+        print_summary(self.layers,
-            self.validation_data = None
+        if 'input_shape' not in kwargs and 'input_dim' in kwargs:
-        if not self.built:
+        if self.model is None:
-        if not self.built:
+        if self.model is None:
-        if not self.built:
+        if self.model is None:
-        return self._gather_list_attr('trainable_weights')
+        if self.model is None:
-        return weights
+        if self.model is None:
-        # support for legacy behavior
+        if self.model is None:
-        return self._gather_list_attr('regularizers')
+        if self.model is None:
-        return self._gather_dict_attr('constraints')
+        if self.model is None:
-        return weights
+        if self.model is None:
-        return self.model.training_data
+        if self.model is None:
-            class_weight=None, sample_weight=None, initial_epoch=0, **kwargs):
+            class_weight=None, sample_weight=None, initial_epoch=0):
-                 sample_weight=None, **kwargs):
+                 sample_weight=None):
-                       sample_weight=None, **kwargs):
+                       sample_weight=None):
-                      sample_weight=None, **kwargs):
+                      sample_weight=None):
-                      pickle_safe=False, initial_epoch=0, **kwargs):
+                      pickle_safe=False, initial_epoch=0):
-                           pickle_safe=False, **kwargs):
+                           pickle_safe=False):
-                             printable_module_name='object'):
+                             printable_module_name='object',
-    '''
+    """A set of floats used for testing the activations.
-    '''
+    """Test using a reference implementation of softmax.
-    '''
+    """Test using a reference softplus implementation.
-    '''
+    """Test using a reference softsign implementation.
-    '''
+    """Test using a numerically stable reference sigmoid implementation.
-    '''
+    """Test using a reference hard sigmoid implementation.
-    xs = [1, 5, True, None, 'foo']
+    xs = [1, 5, True, None]
-from keras import objectives
+from keras import losses
-          objectives.cosine_proximity]
+allobj = [losses.mean_squared_error,
-    objective_output = objectives.sparse_categorical_crossentropy(y_a, y_b)
+    objective_output = losses.sparse_categorical_crossentropy(y_a, y_b)
-    assert K.eval(objectives.sparse_categorical_crossentropy(y_a, y_b)).shape == (6,)
+    assert K.eval(losses.sparse_categorical_crossentropy(y_a, y_b)).shape == (6,)
-if __name__ == "__main__":
+if __name__ == '__main__':
-import sys
+import shutil
-
+from keras.utils.test_utils import keras_test
-    import shutil
+    np.random.seed(1337)
-from keras.layers.core import Dense, Activation, Merge, Lambda
+from keras.layers import Dense, Activation, Lambda
-from keras import objectives
+from keras import losses
-    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
+    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=train_samples,
-    return (X_train, y_train), (X_test, y_test)
+    return (x_train, y_train), (x_test, y_test)
-    (X_train, y_train), (X_test, y_test) = _get_test_data()
+    (x_train, y_train), (x_test, y_test) = _get_test_data()
-            max_batch_index = len(X_train) // batch_size
+            max_batch_index = len(x_train) // batch_size
-            max_batch_index = len(X_test) // batch_size
+            max_batch_index = len(x_test) // batch_size
-                yield (X_train[i * batch_size: (i + 1) * batch_size], y_train[i * batch_size: (i + 1) * batch_size])
+                yield (x_train[i * batch_size: (i + 1) * batch_size], y_train[i * batch_size: (i + 1) * batch_size])
-                yield (X_test[i * batch_size: (i + 1) * batch_size], y_test[i * batch_size: (i + 1) * batch_size])
+                yield (x_test[i * batch_size: (i + 1) * batch_size], y_test[i * batch_size: (i + 1) * batch_size])
-    model.fit_generator(data_generator(True), len(X_train), epochs,
+    model.fit_generator(data_generator(True), len(x_train), epochs)
-    model.evaluate(X_train, y_train)
+    model.fit_generator(data_generator(True), len(x_train), epochs, max_q_size=2)
-    (X_train, y_train), (X_test, y_test) = _get_test_data()
+    (x_train, y_train), (x_test, y_test) = _get_test_data()
-            batches = make_batches(len(X_test), batch_size)
+            batches = make_batches(len(x_test), batch_size)
-    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=False)
+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
-    model.train_on_batch(X_train[:32], y_train[:32])
+    model.train_on_batch(x_train[:32], y_train[:32])
-    loss = model.evaluate(X_test, y_test)
+    loss = model.evaluate(x_test, y_test)
-    pred_loss = K.eval(K.mean(objectives.get(model.loss)(K.variable(y_test), K.variable(prediction))))
+    prediction = model.predict_generator(data_generator(x_test, y_test), x_test.shape[0], max_q_size=2)
-    model.predict_proba(X_test, verbose=0)
+    model.predict(x_test, verbose=0)
-    nloss = model.evaluate(X_test, y_test, verbose=0)
+    nloss = model.evaluate(x_test, y_test, verbose=0)
-    (X_train, y_train), (X_test, y_test) = _get_test_data()
+    (x_train, y_train), (x_test, y_test) = _get_test_data()
-    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=False)
+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
-    model.train_on_batch(X_train[:32], y_train[:32])
+    model.train_on_batch(x_train[:32], y_train[:32])
-    loss = model.evaluate(X_test, y_test, verbose=0)
+    loss = model.evaluate(x_test, y_test, verbose=0)
-    model.predict_proba(X_test, verbose=0)
+    model.predict(x_test, verbose=0)
-    nloss = model.evaluate(X_test, y_test, verbose=0)
+    nloss = model.evaluate(x_test, y_test, verbose=0)
-    (X_train, y_train), (X_test, y_test) = _get_test_data()
+    (x_train, y_train), (x_test, y_test) = _get_test_data()
-    model.fit([X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)
+    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test], y_test))
-    loss = model.evaluate([X_test, X_test], y_test, verbose=0)
+    loss = model.evaluate([x_test, x_test], y_test, verbose=0)
-    model.predict_proba([X_test, X_test], verbose=0)
+    model.predict([x_test, x_test], verbose=0)
-    nloss = model.evaluate([X_test, X_test], y_test, verbose=0)
+    nloss = model.evaluate([x_test, x_test], y_test, verbose=0)
-    (X_train, y_train), (X_test, y_test) = _get_test_data()
+    (x_train, y_train), (x_test, y_test) = _get_test_data()
-    (X_train, y_train), (X_test, y_test) = _get_test_data()
+    (x_train, y_train), (x_test, y_test) = _get_test_data()
-    model.fit([X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)
+    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test], y_test))
-    loss = model.evaluate([X_test, X_test], y_test, verbose=0)
+    loss = model.evaluate([x_test, x_test], y_test, verbose=0)
-    model.predict_proba([X_test, X_test], verbose=0)
+    model.predict([x_test, x_test], verbose=0)
-    model.fit([X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)
+    model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)
-    nloss = model.evaluate([X_test, X_test], y_test, verbose=0)
+    nloss = model.evaluate([x_test, x_test], y_test, verbose=0)
-    (X_train, y_train), (X_test, y_test) = _get_test_data()
+    (x_train, y_train), (x_test, y_test) = _get_test_data()
-    model.fit([X_train, X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=False)
+    model.fit([x_train, x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([x_test, x_test, x_test], y_test))
-    loss = model.evaluate([X_test, X_test, X_test], y_test, verbose=0)
+    loss = model.evaluate([x_test, x_test, x_test], y_test, verbose=0)
-    model.predict_proba([X_test, X_test, X_test], verbose=0)
+    model.predict([x_test, x_test, x_test], verbose=0)
-    nloss = model.evaluate([X_test, X_test, X_test], y_test, verbose=0)
+    nloss = model.evaluate([x_test, x_test, x_test], y_test, verbose=0)
-    (X_train, y_train), (X_test, y_test) = _get_test_data()
+    (x_train, y_train), (x_test, y_test) = _get_test_data()
-    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=False)
+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
-    model.train_on_batch(X_train[:32], y_train[:32])
+    model.train_on_batch(x_train[:32], y_train[:32])
-    model.predict_proba(X_test, verbose=0)
+    loss = model.evaluate(x_test, y_test, verbose=0)
-    nloss = model.evaluate(X_test, y_test, verbose=0)
+    nloss = model.evaluate(x_test, y_test, verbose=0)
-    model.fit(x, y, epochs=1)
+    if callable(x):
-    if data_format == 'channels_first':
+    if data_format == 'channels_last':
-# use input_shape=(None, nb_feature).
+# use input_shape=(None, num_feature).
-    # all the outputs so far in the form of (nb_samples, timesteps,
+    # all the outputs so far in the form of (num_samples, timesteps,
-    model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=1,
+    model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=1,
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-nb_epoch = 40
+num_classes = 10
-Y_test = np_utils.to_categorical(y_test, nb_classes)
+Y_train = np_utils.to_categorical(y_train, num_classes)
-          batch_size=batch_size, nb_epoch=nb_epoch,
+          batch_size=batch_size, epochs=epochs,
-           nb_epoch=120,
+           epochs=120,
-model.fit([X, Xq], Y, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05)
+model.fit([X, Xq], Y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.05)
-nb_epoch = 200
+num_classes = 10
-Y_test = np_utils.to_categorical(y_test, nb_classes)
+Y_train = np_utils.to_categorical(y_train, num_classes)
-model.add(Dense(nb_classes))
+model.add(Dense(num_classes))
-              nb_epoch=nb_epoch,
+              epochs=epochs,
-                        nb_epoch=nb_epoch,
+                        epochs=epochs,
-seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,
+seq.add(ConvLSTM2D(filters=40, num_row=3, num_col=3,
-seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,
+seq.add(ConvLSTM2D(filters=40, num_row=3, num_col=3,
-seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,
+seq.add(ConvLSTM2D(filters=40, num_row=3, num_col=3,
-seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,
+seq.add(ConvLSTM2D(filters=40, num_row=3, num_col=3,
-seq.add(Convolution3D(nb_filter=1, kernel_dim1=1, kernel_dim2=3,
+seq.add(Convolution3D(filters=1, kernel_dim1=1, kernel_dim2=3,
-        nb_epoch=300, validation_split=0.05)
+        epochs=300, validation_split=0.05)
-    conv_num_filters = 16
+    conv_filterss = 16
-    inner = Convolution2D(conv_num_filters, filter_size, filter_size, border_mode='same',
+    inner = Convolution2D(conv_filterss, filter_size, filter_size, border_mode='same',
-    inner = Convolution2D(conv_num_filters, filter_size, filter_size, border_mode='same',
+    inner = Convolution2D(conv_filterss, filter_size, filter_size, border_mode='same',
-    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_num_filters)
+    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filterss)
-                        nb_epoch=stop_epoch, validation_data=img_gen.next_val(), nb_val_samples=val_words,
+                        epochs=stop_epoch, validation_data=img_gen.next_val(), num_val_samples=val_words,
-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)
-          nb_epoch=4,
+          epochs=4,
-nb_filter = 250
+filters = 250
-nb_epoch = 2
+epochs = 2
-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)
-# we add a Convolution1D, which will learn nb_filter
+# we add a Convolution1D, which will learn filters
-model.add(Convolution1D(nb_filter=nb_filter,
+model.add(Convolution1D(filters=filters,
-          nb_epoch=nb_epoch,
+          epochs=epochs,
-nb_filter = 64
+filters = 64
-nb_epoch = 2
+epochs = 2
-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)
-model.add(Convolution1D(nb_filter=nb_filter,
+model.add(Convolution1D(filters=filters,
-model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,
+model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,
-nb_epoch = 5
+epochs = 5
-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)
-          nb_epoch=nb_epoch,
+          epochs=epochs,
-(x_train, y_train), (x_test, y_test) = imdb.load_data(nb_words=max_features)
+(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
-model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=15,
+model.fit(x_train, y_train, batch_size=batch_size, epochs=15,
-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)
-                        nb_epoch=epochs,
+                        epochs=epochs,
-    model.fit(X, y, batch_size=128, nb_epoch=1)
+    model.fit(X, y, batch_size=128, epochs=1)
-    nb_epochs = 50
+    epochss = 50
-    nb_train, nb_test = X_train.shape[0], X_test.shape[0]
+    num_train, num_test = X_train.shape[0], X_test.shape[0]
-        print('Epoch {} of {}'.format(epoch + 1, nb_epochs))
+    for epoch in range(epochss):
-        progress_bar = Progbar(target=nb_batches)
+        num_batches = int(X_train.shape[0] / batch_size)
-        for index in range(nb_batches):
+        for index in range(num_batches):
-        noise = np.random.uniform(-1, 1, (nb_test, latent_size))
+        noise = np.random.uniform(-1, 1, (num_test, latent_size))
-        sampled_labels = np.random.randint(0, 10, nb_test)
+        sampled_labels = np.random.randint(0, 10, num_test)
-        y = np.array([1] * nb_test + [0] * nb_test)
+        y = np.array([1] * num_test + [0] * num_test)
-        sampled_labels = np.random.randint(0, 10, 2 * nb_test)
+        noise = np.random.uniform(-1, 1, (2 * num_test, latent_size))
-        trick = np.ones(2 * nb_test)
+        trick = np.ones(2 * num_test)
-num_epoch = 12
+epochs = 12
-model.fit(x_train, y_train, batch_size=batch_size, num_epoch=num_epoch,
+model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,
-nb_epochs = 5
+num_classes = 10
-Y_test = np_utils.to_categorical(y_test, nb_classes)
+Y_train = np_utils.to_categorical(y_train, num_classes)
-prediction = Dense(nb_classes, activation='softmax')(encoded_columns)
+prediction = Dense(num_classes, activation='softmax')(encoded_columns)
-model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epochs,
+model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochss,
-nb_epochs = 200
+num_classes = 10
-Y_test = np_utils.to_categorical(y_test, nb_classes)
+Y_train = np_utils.to_categorical(y_train, num_classes)
-model.add(Dense(nb_classes))
+model.add(Dense(num_classes))
-model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epochs,
+model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochss,
-num_epoch = 20
+epochs = 20
-                    batch_size=batch_size, num_epoch=num_epoch,
+                    batch_size=batch_size, epochs=epochs,
-nb_class = 10  # number of class
+num_class = 10  # number of class
-    '''Get initial weights for a wider conv2d layer with a bigger nb_filter,
+    '''Get initial weights for a wider conv2d layer with a bigger filters,
-          of shape (nb_filter1, nb_channel1, kh1, kw1)
+          of shape (filters1, num_channel1, kh1, kw1)
-          of shape (nb_filter1, )
+          of shape (filters1, )
-        new_width: new `nb_filter` for the wider conv2d layer
+          of shape (filters2, num_channel2, kh2, kw2)
-        'new width (nb_filter) should be bigger than the existing one')
+        'new width (filters) should be bigger than the existing one')
-          of shape (nb_filter, nb_channel, kh, kw)
+          of shape (filters, num_channel, kh, kw)
-    for i in xrange(nb_filter):
+    filters, num_channel, kh, kw = teacher_w.shape
-    student_b = np.zeros(nb_filter)
+    student_b = np.zeros(filters)
-def make_teacher_model(train_data, validation_data, nb_epoch=3):
+def make_teacher_model(train_data, validation_data, epochs=3):
-    model.add(Dense(nb_class, activation='softmax', name='fc2'))
+    model.add(Dense(num_class, activation='softmax', name='fc2'))
-    history = model.fit(train_x, train_y, nb_epoch=nb_epoch,
+    history = model.fit(train_x, train_y, epochs=epochs,
-                             validation_data, init, nb_epoch=3):
+                             validation_data, init, epochs=3):
-    model.add(Dense(nb_class, activation='softmax', name='fc2'))
+    model.add(Dense(num_class, activation='softmax', name='fc2'))
-    history = model.fit(train_x, train_y, nb_epoch=nb_epoch,
+    history = model.fit(train_x, train_y, epochs=epochs,
-                              validation_data, init, nb_epoch=3):
+                              validation_data, init, epochs=3):
-    model.add(Dense(nb_class, activation='softmax', name='fc2'))
+    model.add(Dense(num_class, activation='softmax', name='fc2'))
-    history = model.fit(train_x, train_y, nb_epoch=nb_epoch,
+    history = model.fit(train_x, train_y, epochs=epochs,
-                                          nb_epoch=3)
+                                          epochs=3)
-                             nb_epoch=3)
+                             epochs=3)
-                             nb_epoch=3)
+                             epochs=3)
-                                          nb_epoch=3)
+                                          epochs=3)
-                              nb_epoch=3)
+                              epochs=3)
-                              nb_epoch=3)
+                              epochs=3)
-nb_epoch = 20
+epochs = 20
-          nb_epoch=nb_epoch)
+          epochs=epochs)
-nb_classes = 10
+num_classes = 10
-y_test = np_utils.to_categorical(y_test, nb_classes)
+y_train = np_utils.to_categorical(y_train, num_classes)
-def make_model(dense_layer_sizes, nb_filters, nb_conv, nb_pool):
+def make_model(dense_layer_sizes, filterss, num_conv, num_pool):
-    nb_pool: Size of pooling area for max pooling
+    filterss: Number of convolutional filters in each convolutional layer
-    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
+    model.add(Convolution2D(filterss, num_conv, num_conv,
-    model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
+    model.add(Convolution2D(filterss, num_conv, num_conv))
-    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
+    model.add(MaxPooling2D(pool_size=(num_pool, num_pool)))
-    model.add(Dense(nb_classes))
+    model.add(Dense(num_classes))
-                                     # nb_epoch is avail for tuning even when not
+                                     # epochs is avail for tuning even when not
-                                     'nb_pool': [2]},
+                                     'epochs': [3, 6],
-nb_epoch = 5
+epochs = 5
-          batch_size=batch_size, nb_epoch=nb_epoch)
+          batch_size=batch_size, epochs=epochs)
-nb_epoch = 5
+num_classes = 5
-nb_filters = 32
+filterss = 32
-def train_model(model, train, test, nb_classes):
+def train_model(model, train, test, num_classes):
-    Y_test = np_utils.to_categorical(test[1], nb_classes)
+    Y_train = np_utils.to_categorical(train[1], num_classes)
-              batch_size=batch_size, nb_epoch=nb_epoch,
+              batch_size=batch_size, epochs=epochs,
-    Convolution2D(nb_filters, kernel_size, kernel_size,
+    Convolution2D(filterss, kernel_size, kernel_size,
-    Convolution2D(nb_filters, kernel_size, kernel_size),
+    Convolution2D(filterss, kernel_size, kernel_size),
-    Dense(nb_classes),
+    Dense(num_classes),
-            (X_test_lt5, y_test_lt5), nb_classes)
+            (X_test_lt5, y_test_lt5), num_classes)
-            (X_test_gte5, y_test_gte5), nb_classes)
+            (X_test_gte5, y_test_gte5), num_classes)
-nb_colors = 3  # RGB
+num_labels = args.nlabels
-    labels = kmeans(mask_vecs, nb_labels)
+    labels = kmeans(mask_vecs, num_labels)
-    style_mask = np.stack([style_mask_label == r for r in xrange(nb_labels)],
+    style_mask = np.stack([style_mask_label == r for r in xrange(num_labels)],
-    target_mask = np.stack([target_mask_label == r for r in xrange(nb_labels)],
+    target_mask = np.stack([target_mask_label == r for r in xrange(num_labels)],
-    shape = (1, nb_colors, img_nrows, img_ncols)
+    shape = (1, num_colors, img_nrows, img_ncols)
-    shape = (1, img_nrows, img_ncols, nb_colors)
+    shape = (1, img_nrows, img_ncols, num_colors)
-        nb_channels = K.shape(style_image)[0]
+        num_channels = K.shape(style_image)[0]
-    c = gram_matrix(masked_target) / K.mean(target_mask) / nb_channels
+        num_channels = K.shape(style_image)[-1]
-    for i in xrange(nb_labels):
+    for i in xrange(num_labels):
-tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)
+tokenizer = Tokenizer(num_words=MAX_NB_WORDS)
-nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])
+num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])
-y_val = labels[-nb_validation_samples:]
+x_train = data[:-num_validation_samples]
-embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))
+num_words = min(MAX_NB_WORDS, len(word_index))
-embedding_layer = Embedding(nb_words,
+embedding_layer = Embedding(num_words,
-          nb_epoch=2, batch_size=128)
+          epochs=2, batch_size=128)
-nb_epoch = 5
+epochs = 5
-(X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=max_words, test_split=0.2)
+(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)
-print(nb_classes, 'classes')
+num_classes = np.max(y_train) + 1
-tokenizer = Tokenizer(nb_words=max_words)
+tokenizer = Tokenizer(num_words=max_words)
-Y_test = np_utils.to_categorical(y_test, nb_classes)
+Y_train = np_utils.to_categorical(y_train, num_classes)
-model.add(Dense(nb_classes))
+model.add(Dense(num_classes))
-                    nb_epoch=nb_epoch, batch_size=batch_size,
+                    epochs=epochs, batch_size=batch_size,
-              nb_epoch=1,
+              epochs=1,
-nb_epoch = 50
+epochs = 50
-        nb_epoch=nb_epoch,
+        epochs=epochs,
-nb_filters = 64
+filterss = 64
-nb_conv = 3
+num_conv = 3
-nb_epoch = 5
+epochs = 5
-conv_2 = Convolution2D(nb_filters, 2, 2,
+conv_2 = Convolution2D(filterss, 2, 2,
-conv_3 = Convolution2D(nb_filters, nb_conv, nb_conv,
+conv_3 = Convolution2D(filterss, num_conv, num_conv,
-conv_4 = Convolution2D(nb_filters, nb_conv, nb_conv,
+conv_4 = Convolution2D(filterss, num_conv, num_conv,
-decoder_upsample = Dense(nb_filters * 14 * 14, activation='relu')
+decoder_upsample = Dense(filterss * 14 * 14, activation='relu')
-    output_shape = (batch_size, nb_filters, 14, 14)
+    output_shape = (batch_size, filterss, 14, 14)
-    output_shape = (batch_size, 14, 14, nb_filters)
+    output_shape = (batch_size, 14, 14, filterss)
-decoder_deconv_1 = Deconvolution2D(nb_filters, nb_conv, nb_conv,
+decoder_deconv_1 = Deconvolution2D(filterss, num_conv, num_conv,
-decoder_deconv_2 = Deconvolution2D(nb_filters, nb_conv, nb_conv,
+decoder_deconv_2 = Deconvolution2D(filterss, num_conv, num_conv,
-    output_shape = (batch_size, nb_filters, 29, 29)
+    output_shape = (batch_size, filterss, 29, 29)
-decoder_deconv_3_upsamp = Deconvolution2D(nb_filters, 2, 2,
+    output_shape = (batch_size, 29, 29, filterss)
-        nb_epoch=nb_epoch,
+        epochs=epochs,
-def conv2d_bn(x, nb_filter, nb_row, nb_col,
+def conv2d_bn(x, filters, num_row, num_col,
-    x = Convolution2D(nb_filter, nb_row, nb_col,
+    x = Convolution2D(filters, num_row, num_col,
-        filters: list of integers, the nb_filters of 3 conv layer at main path
+        filters: list of integers, the filterss of 3 conv layer at main path
-    nb_filter1, nb_filter2, nb_filter3 = filters
+    filters1, filters2, filters3 = filters
-    x = Convolution2D(nb_filter1, 1, 1, name=conv_name_base + '2a')(input_tensor)
+    x = Convolution2D(filters1, 1, 1, name=conv_name_base + '2a')(input_tensor)
-    x = Convolution2D(nb_filter2, kernel_size, kernel_size,
+    x = Convolution2D(filters2, kernel_size, kernel_size,
-    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)
+    x = Convolution2D(filters3, 1, 1, name=conv_name_base + '2c')(x)
-        filters: list of integers, the nb_filters of 3 conv layer at main path
+        filters: list of integers, the filterss of 3 conv layer at main path
-    nb_filter1, nb_filter2, nb_filter3 = filters
+    filters1, filters2, filters3 = filters
-    x = Convolution2D(nb_filter1, 1, 1, subsample=strides,
+    x = Convolution2D(filters1, 1, 1, subsample=strides,
-    x = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',
+    x = Convolution2D(filters2, kernel_size, kernel_size, border_mode='same',
-    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)
+    x = Convolution2D(filters3, 1, 1, name=conv_name_base + '2c')(x)
-    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,
+    shortcut = Convolution2D(filters3, 1, 1, subsample=strides,
-                config = tf.ConfigProto(intra_op_parallelism_threads=nb_thread,
+                num_thread = int(os.environ.get('OMP_NUM_THREADS'))
-                         ' should have a defined dimension, but is None. '
+                         'should have a defined dimension, but is None. '
-def one_hot(indices, nb_classes):
+def one_hot(indices, num_classes):
-    with shape `(batch_size, dim1, dim2, ... dim(n-1), nb_classes)`
+    with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`
-    return tf.one_hot(indices, depth=nb_classes, axis=-1)
+    return tf.one_hot(indices, depth=num_classes, axis=-1)
-def one_hot(indices, nb_classes):
+def one_hot(indices, num_classes):
-    with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)
+    with shape (batch_size, dim1, dim2, ... dim(n-1), num_classes)
-    oh = T.reshape(oh, input_shape + (nb_classes,))
+    oh = T.extra_ops.to_one_hot(indices, num_classes)
-    target = T.extra_ops.to_one_hot(target, nb_class=output.shape[-1])
+    target = T.extra_ops.to_one_hot(target, num_classes=output.shape[-1])
-        self.nb_epoch = self.params['nb_epoch']
+        self.epochs = self.params['epochs']
-            self.progbar = Progbar(target=self.params['nb_sample'],
+            print('Epoch %d/%d' % (epoch + 1, self.epochs))
-        if self.seen < self.params['nb_sample']:
+        if self.seen < self.params['samples']:
-        if self.verbose and self.seen < self.params['nb_sample']:
+        if self.verbose and self.seen < self.params['samples']:
-    nb_train_samples = 50000
+    num_train_samples = 50000
-    y_train = np.zeros((nb_train_samples,), dtype='uint8')
+    x_train = np.zeros((num_train_samples, 3, 32, 32), dtype='uint8')
-def load_data(path='imdb_full.pkl', nb_words=None, skip_top=0,
+def load_data(path='imdb_full.pkl', num_words=None, skip_top=0,
-        nb_words: max number of words to include. Words are ranked
+        num_words: max number of words to include. Words are ranked
-        oov_char: words that were cut out because of the `nb_words`
+        oov_char: words that were cut out because of the `num_words`
-    because they're not making the `nb_words` cut here.
+    because they're not making the `num_words` cut here.
-        nb_words = max([max(x) for x in xs])
+    if not num_words:
-        xs = [[oov_char if (w >= nb_words or w < skip_top) else w for w in x] for x in xs]
+        xs = [[oov_char if (w >= num_words or w < skip_top) else w for w in x] for x in xs]
-                if w >= nb_words or w < skip_top:
+                if w >= num_words or w < skip_top:
-def load_data(path='reuters.pkl', nb_words=None, skip_top=0,
+def load_data(path='reuters.pkl', num_words=None, skip_top=0,
-        nb_words: max number of words to include. Words are ranked
+        num_words: max number of words to include. Words are ranked
-        oov_char: words that were cut out because of the `nb_words`
+        oov_char: words that were cut out because of the `num_words`
-    because they're not making the `nb_words` cut here.
+    because they're not making the `num_words` cut here.
-        nb_words = max([max(x) for x in xs])
+    if not num_words:
-        xs = [[oov_char if (w >= nb_words or w < skip_top) else w for w in x] for x in xs]
+        xs = [[oov_char if (w >= num_words or w < skip_top) else w for w in x] for x in xs]
-                if w >= nb_words or w < skip_top:
+                if w >= num_words or w < skip_top:
-        get_output_shape_for(input_shape)
+        compute_output_shape(input_shape)
-                    if value is not None and x_shape[int(axis)] != value:
+                    if value is not None and x_shape[int(axis)] not in {value, None}:
-                                         ' value ' + str(value) +
+                                         'value ' + str(value) +
-                    if spec_dim is not None:
+                    if spec_dim is not None and dim is not None:
-        output_shape = self.get_output_shape_for(input_shape)
+        output_shape = self.compute_output_shape(input_shape)
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def compute_mask(self, input, input_mask=None):
+    def compute_mask(self, input, mask=None):
-                    if any(mask is not None for mask in input_mask):
+            if mask is not None:
-                                        str(input_mask))
+                                        str(mask))
-                                    str(input_mask))
+                                    str(mask))
-        return input_mask
+        return mask
-            layer_weights = weights[:nb_param]
+            num_param = len(layer.weights)
-            weights = weights[nb_param:]
+            weights = weights[num_param:]
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-                            output_shape = layer.get_output_shape_for(input_shapes[0])
+                            output_shape = layer.compute_output_shape(input_shapes[0])
-                            output_shape = layer.get_output_shape_for(input_shapes)
+                            output_shape = layer.compute_output_shape(input_shapes)
-                            shapes = _to_list(layer.get_output_shape_for(computed_tensors[0]._keras_shape))
+                            shapes = _to_list(layer.compute_output_shape(computed_tensors[0]._keras_shape))
-                            shapes = _to_list(layer.get_output_shape_for([x._keras_shape for x in computed_tensors]))
+                            shapes = _to_list(layer.compute_output_shape([x._keras_shape for x in computed_tensors]))
-        return cls(input=input_tensors, output=output_tensors, name=name)
+        return cls(inputs=input_tensors, outputs=output_tensors, name=name)
-    nb_batch = int(np.ceil(size / float(batch_size)))
+    num_batches = int(np.ceil(size / float(batch_size)))
-            for i in range(0, nb_batch)]
+            for i in range(0, num_batches)]
-    def start(self, nb_worker=1, max_q_size=10, wait_time=0.05):
+    def start(self, workers=1, max_q_size=10, wait_time=0.05):
-            nb_worker: number of worker threads
+            workers: number of worker threads
-            for i in range(nb_worker):
+            for i in range(workers):
-                  nb_epoch=100, verbose=1, callbacks=None,
+                  epochs=100, verbose=1, callbacks=None,
-            nb_epoch: number of times to iterate over the data
+            epochs: number of times to iterate over the data
-        index_array = np.arange(nb_train_sample)
+        num_train_samples = ins[0].shape[0]
-            'nb_sample': nb_train_sample,
+            'epochs': epochs,
-        for epoch in range(initial_epoch, nb_epoch):
+        for epoch in range(initial_epoch, epochs):
-            batches = make_batches(nb_train_sample, batch_size)
+            batches = make_batches(num_train_samples, batch_size)
-        nb_sample = ins[0].shape[0]
+        samples = ins[0].shape[0]
-        index_array = np.arange(nb_sample)
+            progbar = Progbar(target=samples)
-                    shape = (nb_sample,) + batch_out.shape[1:]
+                    shape = (samples,) + batch_out.shape[1:]
-        nb_sample = ins[0].shape[0]
+        samples = ins[0].shape[0]
-        index_array = np.arange(nb_sample)
+            progbar = Progbar(target=samples)
-            outs[i] /= nb_sample
+            outs[i] /= samples
-    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=None,
+    def fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,
-            nb_epoch: integer, the number of times to iterate
+            epochs: integer, the number of times to iterate
-                              batch_size=batch_size, nb_epoch=nb_epoch,
+                              batch_size=batch_size, epochs=epochs,
-    def fit_generator(self, generator, samples_per_epoch, nb_epoch,
+    def fit_generator(self, generator, samples_per_epoch, epochs,
-                      validation_data=None, nb_val_samples=None,
+                      validation_data=None, num_val_samples=None,
-                      max_q_size=10, nb_worker=1, pickle_safe=False,
+                      max_q_size=10, workers=1, pickle_safe=False,
-            nb_epoch: integer, total number of iterations on the data.
+            epochs: integer, total number of iterations on the data.
-            nb_val_samples: only relevant if `validation_data` is a generator.
+            num_val_samples: only relevant if `validation_data` is a generator.
-            nb_worker: maximum number of processes to spin up
+            workers: maximum number of processes to spin up
-                                samples_per_epoch=10000, nb_epoch=10)
+                                samples_per_epoch=10000, epochs=10)
-        if val_gen and not nb_val_samples:
+        if val_gen and not num_val_samples:
-                             'you must specify a value for "nb_val_samples".')
+                             'you must specify a value for "num_val_samples".')
-            'nb_sample': samples_per_epoch,
+            'epochs': epochs,
-            enqueuer.start(max_q_size=max_q_size, nb_worker=nb_worker)
+            enqueuer.start(max_q_size=max_q_size, workers=workers)
-            while epoch < nb_epoch:
+            while epoch < epochs:
-                                nb_val_samples,
+                                num_val_samples,
-                                nb_worker=nb_worker,
+                                workers=workers,
-                           max_q_size=10, nb_worker=1, pickle_safe=False):
+                           max_q_size=10, workers=1, pickle_safe=False):
-            nb_worker: maximum number of processes to spin up
+            workers: maximum number of processes to spin up
-            enqueuer.start(nb_worker=nb_worker, max_q_size=max_q_size)
+            enqueuer.start(workers=workers, max_q_size=max_q_size)
-                    nb_samples = len(x[0])
+                    sampless = len(x[0])
-                    nb_samples = len(list(x.values())[0])
+                    sampless = len(list(x.values())[0])
-                    nb_samples = len(x)
+                    sampless = len(x)
-                weights.append(nb_samples)
+                processed_samples += sampless
-                          max_q_size=10, nb_worker=1, pickle_safe=False):
+                          max_q_size=10, workers=1, pickle_safe=False):
-            nb_worker: maximum number of processes to spin up
+            workers: maximum number of processes to spin up
-            enqueuer.start(nb_worker=nb_worker, max_q_size=max_q_size)
+            enqueuer.start(workers=workers, max_q_size=max_q_size)
-                    nb_samples = len(x[0])
+                    sampless = len(x[0])
-                    nb_samples = len(list(x.values())[0])
+                    sampless = len(list(x.values())[0])
-                    nb_samples = len(x)
+                    sampless = len(x)
-                processed_samples += nb_samples
+                    all_outs[i][processed_samples:(processed_samples + sampless)] = out
-from ..engine import Layer, Input, InputLayer, Merge, merge, InputSpec
+
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-        3D tensor with shape: `(batch_size, new_steps, nb_filter)`
+        3D tensor with shape: `(batch_size, new_steps, filters)`
-        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
+        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
+        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.
-        `(samples, nb_filter, new_conv_dim1, new_conv_dim2, new_conv_dim3)` if data_format='channels_first'
+        `(samples, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)` if data_format='channels_first'
-        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, nb_filter)` if data_format='channels_last'.
+        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)` if data_format='channels_last'.
-        `(batch, nb_filter, new_rows, new_cols)` if data_format='channels_first'
+        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'
-        `(batch, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
+        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-            channels will be equal to `num_filters_in * depth_multiplier`.
+            channels will be equal to `filterss_in * depth_multiplier`.
-        `(batch, nb_filter, new_rows, new_cols)` if data_format='channels_first'
+        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'
-        `(batch, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
+        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-        5D tensor with shape `(nb_samples, timesteps, channels, rows, cols)`.
+        5D tensor with shape `(num_samples, timesteps, channels, rows, cols)`.
-        - else, 4D tensor with shape `(nb_samples, channels, rows, cols)`.
+            `(num_samples, timesteps, channels, rows, cols)`.
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-        output_shape = self.get_output_shape_for(input_shape)
+        output_shape = self.compute_output_shape(input_shape)
-    def compute_mask(self, inputs, input_mask=None):
+    def compute_mask(self, inputs, mask=None):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-                target_shape = self.get_output_shape_for(input_shape)[1:]
+                target_shape = self.compute_output_shape(input_shape)[1:]
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-        2D tensor of shape `(nb_samples, features)`.
+        2D tensor of shape `(num_samples, features)`.
-        3D tensor of shape `(nb_samples, n, features)`.
+        3D tensor of shape `(num_samples, n, features)`.
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-                nb_samples = input_shape[0][0]
+                num_samples = input_shape[0][0]
-            return (nb_samples,) + tuple(self._output_shape)
+                num_samples = input_shape[0] if input_shape else None
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def compute_mask(self, inputs):
+    def compute_mask(self, inputs, mask=None):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-        3D tensor with shape: `(batch_size, new_steps, nb_filter)`
+        3D tensor with shape: `(batch_size, new_steps, filters)`
-        _, output_length, filters = self.get_output_shape_for(input_shape)
+        _, output_length, filters = self.compute_output_shape(input_shape)
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
+        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
+        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.
-        output_shape = self.get_output_shape_for(input_shape)
+        output_shape = self.compute_output_shape(input_shape)
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-            inner_r = matrix_inner[:, self.units: 2 * self.units]
+            recurrent_z = matrix_inner[:, :self.units]
-            r = self.recurrent_activation(x_r + inner_r)
+            z = self.recurrent_activation(x_z + recurrent_z)
-            inner_h = K.dot(r * h_tm1 * rec_dp_mask[0],
+            recurrent_h = K.dot(r * h_tm1 * rec_dp_mask[0],
-            hh = self.activation(x_h + inner_h)
+            hh = self.activation(x_h + recurrent_h)
-                  'bias_regularizer': regularizers.serialize(bias_regularizer),
+                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),
-                self.bias += K.concatenate(K.zeros((self.units,)),
+                self.bias += K.concatenate([K.zeros((self.units,)),
-                                           K.zeros((self.units * 2,)))
+                                           K.zeros((self.units * 2,))])
-            f = self.inner_activation(z1)
+            i = self.recurrent_activation(z0)
-            o = self.inner_activation(z3)
+            o = self.recurrent_activation(z3)
-                                                  self.recurrent_kernel_f))
+            i = self.recurrent_activation(x_i + K.dot(h_tm1 * rec_dp_mask[0],
-                                                  self.recurrent_kernel_o))
+                                                            self.recurrent_kernel_c))
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-        child_output_shape = self.layer.get_output_shape_for(child_input_shape)
+        child_output_shape = self.layer.compute_output_shape(child_input_shape)
-            # (nb_samples * timesteps, ...)
+            # (num_samples * timesteps, ...)
-            output_shape = self.get_output_shape_for(input_shape)
+            y = self.layer.call(inputs)  # (num_samples * timesteps, ...)
-    def get_output_shape_for(self, input_shape):
+    def compute_output_shape(self, input_shape):
-            return self.forward_layer.get_output_shape_for(input_shape)
+            return self.forward_layer.compute_output_shape(input_shape)
-            shape = list(self.forward_layer.get_output_shape_for(input_shape))
+            shape = list(self.forward_layer.compute_output_shape(input_shape))
-            return [self.forward_layer.get_output_shape_for(input_shape)] * 2
+            return [self.forward_layer.compute_output_shape(input_shape)] * 2
-from .engine.topology import get_source_inputs, Node, Layer, Merge, Input
+from .engine.topology import get_source_inputs, Node, Layer, Input
-        return layers
+        return self.model.flattened_layers
-            weights = weights[nb_param:]
+            num_param = len(layer.weights)
-    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=None,
+    def fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,
-            nb_epoch: integer, the number of epochs to train the model.
+            epochs: integer, the number of epochs to train the model.
-                              nb_epoch=nb_epoch,
+                              epochs=epochs,
-    def fit_generator(self, generator, samples_per_epoch, nb_epoch,
+    def fit_generator(self, generator, samples_per_epoch, epochs,
-                      class_weight=None, max_q_size=10, nb_worker=1,
+                      validation_data=None, num_val_samples=None,
-            nb_epoch: integer, total number of iterations on the data.
+            epochs: integer, total number of iterations on the data.
-            nb_val_samples: only relevant if `validation_data` is a generator.
+            num_val_samples: only relevant if `validation_data` is a generator.
-            nb_worker: maximum number of processes to spin up
+            workers: maximum number of processes to spin up
-                                samples_per_epoch=10000, nb_epoch=10)
+                                samples_per_epoch=10000, epochs=10)
-            warnings.warn('The "nb_worker" argument is deprecated '
+        if workers > 1 and not pickle_safe:
-            nb_worker = 1  # For backward compatibility
+            workers = 1  # For backward compatibility
-            warnings.warn('The "nb_val_worker" argument is deprecated, '
+        if 'num_val_worker' in kwargs:
-                                        nb_epoch,
+                                        epochs,
-                                        nb_val_samples=nb_val_samples,
+                                        num_val_samples=num_val_samples,
-                                        nb_worker=nb_worker,
+                                        workers=workers,
-                           max_q_size=10, nb_worker=1,
+                           max_q_size=10, workers=1,
-            nb_worker: maximum number of processes to spin up
+            workers: maximum number of processes to spin up
-            warnings.warn('The "nb_worker" argument is deprecated '
+        if workers > 1 and not pickle_safe:
-            nb_worker = 1  # For backward compatibility
+            workers = 1  # For backward compatibility
-                                             nb_worker=nb_worker,
+                                             workers=workers,
-                          max_q_size=10, nb_worker=1, pickle_safe=False):
+                          max_q_size=10, workers=1, pickle_safe=False):
-            nb_worker: maximum number of processes to spin up
+            workers: maximum number of processes to spin up
-            warnings.warn('The "nb_worker" argument is deprecated '
+        if workers > 1 and not pickle_safe:
-            nb_worker = 1  # For backward compatibility
+            workers = 1  # For backward compatibility
-                                            nb_worker=nb_worker,
+                                            workers=workers,
-        as a Python list.
+        """Returns the model configuration as a Python list.
-        if isinstance(self.layers[0], Merge):
+        if isinstance(self.layers[0], legacy_layers.Merge):
-        """Supports legacy formats
+    def legacy_from_config(cls, config, layer_cache=None):
-            merge = Merge.from_config(first_layer_config)
+            merge = legacy_layers.Merge.from_config(first_layer_config)
-                             printable_module_name='optimizer')
+    config['class_name'] = config['class_name'].lower()
-        self.nb_sample = 0
+        self.samples = 0
-        self.nb_class = len(classes)
+        self.num_class = len(classes)
-        print('Found %d images belonging to %d classes.' % (self.nb_sample, self.nb_class))
+                        self.samples += 1
-        self.classes = np.zeros((self.nb_sample,), dtype='int32')
+        self.classes = np.zeros((self.samples,), dtype='int32')
-        super(DirectoryIterator, self).__init__(self.nb_sample, batch_size, shuffle, seed)
+        super(DirectoryIterator, self).__init__(self.samples, batch_size, shuffle, seed)
-            batch_y = np.zeros((len(batch_x), self.nb_class), dtype=K.floatx())
+            batch_y = np.zeros((len(batch_x), self.num_class), dtype=K.floatx())
-    nb_samples = len(sequences)
+    num_samples = len(sequences)
-    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)
+    x = (np.ones((num_samples, maxlen) + sample_shape) * value).astype(dtype)
-        nb_negative_samples = int(len(labels) * negative_samples)
+        num_negative_samples = int(len(labels) * negative_samples)
-                    random.randint(1, vocabulary_size - 1)] for i in range(nb_negative_samples)]
+                    random.randint(1, vocabulary_size - 1)] for i in range(num_negative_samples)]
-            labels += [[1, 0]] * nb_negative_samples
+            labels += [[1, 0]] * num_negative_samples
-            labels += [0] * nb_negative_samples
+            labels += [0] * num_negative_samples
-            on word frequency. Only the most common `nb_words` words will
+        num_words: the maximum number of words to keep, based
-    def __init__(self, nb_words=None,
+    def __init__(self, num_words=None,
-        self.nb_words = nb_words
+        self.num_words = num_words
-        Only top "nb_words" most frequent words will be taken into account.
+        Only top "num_words" most frequent words will be taken into account.
-        Only top "nb_words" most frequent words will be taken into account.
+        Only top "num_words" most frequent words will be taken into account.
-        nb_words = self.nb_words
+        num_words = self.num_words
-                    if nb_words and i >= nb_words:
+                    if num_words and i >= num_words:
-        if not self.nb_words:
+        if not self.num_words:
-                nb_words = len(self.word_index) + 1
+                num_words = len(self.word_index) + 1
-                raise ValueError('Specify a dimension (nb_words argument), '
+                raise ValueError('Specify a dimension (num_words argument), '
-            nb_words = self.nb_words
+            num_words = self.num_words
-        x = np.zeros((len(sequences), nb_words))
+        x = np.zeros((len(sequences), num_words))
-                if j >= nb_words:
+                if j >= num_words:
-            raise ValueError('Improper config format:', config)
+            raise ValueError('Improper config format: ' + str(config))
-                                 ':', class_name)
+                raise ValueError('Unknown ' + printable_module_name +
-                         printable_module_name, ':', identifier)
+        raise ValueError('Could not interpret serialized ' +
-            non_trainable_count += sum([K.count_params(p) for p in layer.non_trainable_weights])
+            trainable_count += py_sum([K.count_params(p) for p in layer.trainable_weights])
-def to_categorical(y, nb_classes=None):
+def to_categorical(y, num_classes=None):
-        nb_classes: total number of classes.
+            (integers from 0 to num_classes).
-        nb_classes = np.max(y) + 1
+    if not num_classes:
-    categorical = np.zeros((n, nb_classes))
+    categorical = np.zeros((n, num_classes))
-                  classification=True, num_class=2):
+                  classification=True, num_classes=2):
-    num_sample = num_train + num_test
+    samples = num_train + num_test
-        for i in range(num_sample):
+        y = np.random.randint(0, num_classes, size=(samples,))
-        for i in range(num_sample):
+        y_loc = np.random.random((samples,))
-    expected_output_shape = layer.get_output_shape_for(input_shape)
+    expected_output_shape = layer.compute_output_shape(input_shape)
-    `predict_proba`, and `score` methods (e.g., `nb_epoch`, `batch_size`).
+    `predict_proba`, and `score` methods (e.g., `epochs`, `batch_size`).
-    `batch_size` or `nb_epoch` as well as the model parameters.
+    `batch_size` or `epochs` as well as the model parameters.
-from keras.layers.convolutional import Convolution2D, MaxPooling2D
+from keras import layers
-                                                         nb_test=200,
+    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,
-                                                         nb_class=4)
+                                                         num_classes=4)
-        Dense(y_test.shape[-1], activation='softmax')
+        layers.Conv2D(filters=8, kernel_size=3,
-                        validation_data=(X_test, y_test),
+    model.summary()
-    assert(history.history['val_acc'][-1] > 0.85)
+    assert history.history['val_acc'][-1] > 0.8
-from keras.layers import Embedding
+from keras import layers
-                                                         input_shape=(3, 5),
+    np.random.seed(1337)
-                                                         nb_class=2)
+                                                         num_classes=2)
-                  activation='softmax'))
+    model.add(layers.GRU(8,
-                  optimizer='adagrad',
+                  optimizer='rmsprop',
-                        validation_data=(X_test, y_test),
+    history = model.fit(x_train, y_train, epochs=4, batch_size=10,
-    assert(history.history['val_acc'][-1] >= 0.8)
+    assert(history.history['acc'][-1] >= 0.8)
-                                                         nb_test=400,
+    np.random.seed(1337)
-                  input_shape=(X_train.shape[1], X_train.shape[2])))
+    model.add(layers.LSTM(y_train.shape[-1],
-    assert(history.history['val_loss'][-1] < 1.)
+    history = model.fit(x_train, y_train, epochs=5, batch_size=16,
-def test_sequence_to_sequence():
+def test_3d_to_3d():
-                                                         nb_test=200,
+    np.random.seed(1337)
-                                   input_shape=(X_train.shape[1], X_train.shape[2])))
+    model.add(layers.TimeDistributed(
-    assert(history.history['val_loss'][-1] < 0.8)
+    history = model.fit(x_train, y_train, epochs=20, batch_size=16,
-    X = np.zeros((len(sentences), sequence_length, number_of_chars), dtype=np.bool)
+    x = np.zeros((len(sentences), sequence_length, number_of_chars), dtype=np.bool)
-            X[i, t, ord(char) - ord('a')] = 1
+            x[i, t, ord(char) - ord('a')] = 1
-        Dense(number_of_chars, activation='softmax')
+        layers.LSTM(16, return_sequences=True, input_shape=(sequence_length, number_of_chars)),
-    model.fit(X, y, batch_size=1, nb_epoch=60, verbose=1)
+    model.fit(x, y, batch_size=1, epochs=60, verbose=1)
-    model.add(Activation('softmax'))
+    model.add(layers.Embedding(10, 10, mask_zero=True))
-                  sample_weight_mode='temporal')
+                  optimizer='adam')
-        X[rowi, :padding] = 0
+    x = np.random.random_integers(1, 9, (20000, 10))
-    Y = np.zeros((y.size, 10), dtype='int32')
+    y = (x * np.random.random_integers(1, 2, x.shape)) % 10
-                        verbose=1, nb_epoch=2)
+        ys[i, target] = 1
-    assert(np.abs(history.history['val_loss'][-1] - ground_truth) < 0.06)
+    assert(np.abs(history.history['loss'][-1] - ground_truth) < 0.06)
-from keras.layers.core import Dense
+from keras import layers
-                                                         nb_test=200,
+    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,
-                                                         nb_class=2)
+                                                         num_classes=2)
-        Dense(y_train.shape[-1], activation='softmax')
+        layers.Dense(16, input_shape=(x_train.shape[-1],), activation='relu'),
-                        validation_data=(X_test, y_test),
+    model.summary()
-                                                         nb_test=200,
+    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,
-        Dense(y_train.shape[-1])
+        layers.Dense(16, input_shape=(x_train.shape[-1],), activation='tanh'),
-                        validation_data=(X_test, y_test), verbose=0)
+    history = model.fit(x_train, y_train, epochs=20, batch_size=16,
-        nb_classes = 20
+        num_classes = 20
-        oh = np.eye(nb_classes)[indices]
+        indices = np.random.randint(0, num_classes, size=(batch_size, input_length))
-            koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), nb_classes))
+            koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), num_classes))
-    assert model.get_output_shape_for([(None, 32), (None, 32)]) == [(None, 64), (None, 5)]
+    print('output_shape:', model.compute_output_shape([(None, 32), (None, 32)]))
-    assert model.get_output_shape_for([(None, 32), (None, 32)]) == [(None, 64), (None, 5)]
+    print('output_shape:', model.compute_output_shape([(None, 32), (None, 32)]))
-    assert final_model.get_output_shape_for([(10, 32), (10, 32)]) == [(10, 7), (10, 64)]
+    print(final_model.compute_output_shape([(10, 32), (10, 32)]))
-#     model.fit(X_train, Y_train, nb_epoch=2, batch_size=128)
+#     model.fit(X_train, Y_train, epochs=2, batch_size=128)
-#     model.fit([data_a, data_b], labels, nb_epoch=1)
+#     model.fit([data_a, data_b], labels, epochs=1)
-    model.fit([x, y, z], labels, nb_epoch=1)
+    model.fit([x, y, z], labels, epochs=1)
-    outer_model.fit([x, y, z], labels, nb_epoch=1)
+    outer_model.fit([x, y, z], labels, epochs=1)
-    outer_model.fit([x, y, z], labels, nb_epoch=1)
+    outer_model.fit([x, y, z], labels, epochs=1)
-                    [output_a_np, output_b_np], nb_epoch=1, batch_size=4)
+                    [output_a_np, output_b_np], epochs=1, batch_size=4)
-                    [output_a_np, output_b_np], nb_epoch=1, batch_size=4)
+                    [output_a_np, output_b_np], epochs=1, batch_size=4)
-                    nb_epoch=1, batch_size=4)
+                    epochs=1, batch_size=4)
-                    nb_epoch=1, batch_size=4, validation_split=0.5)
+                    epochs=1, batch_size=4, validation_split=0.5)
-                    nb_epoch=1, batch_size=4, validation_split=0.5)
+                    epochs=1, batch_size=4, validation_split=0.5)
-                    nb_epoch=1, batch_size=4, validation_split=0.5)
+                    epochs=1, batch_size=4, validation_split=0.5)
-                    nb_epoch=1, batch_size=4,
+                    epochs=1, batch_size=4,
-                    nb_epoch=1, batch_size=4, validation_split=0.5,
+                    epochs=1, batch_size=4, validation_split=0.5,
-                    nb_epoch=1, batch_size=4, validation_split=0.5,
+                    epochs=1, batch_size=4, validation_split=0.5,
-                    [output_a_np, output_b_np], nb_epoch=5, batch_size=4,
+                    [output_a_np, output_b_np], epochs=5, batch_size=4,
-    out = model.fit_generator(gen_data(4), samples_per_epoch=10, nb_epoch=5,
+    out = model.fit_generator(gen_data(4), samples_per_epoch=10, epochs=5,
-    out = model.fit([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4, nb_epoch=1)
+    out = model.fit([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4, epochs=1)
-    nb_samples = 2
+    num_samples = 2
-    nb_col = 6
+    num_row = 10
-                               'nb_col': 3,
+                               'num_row': 3,
-                       input_shape=(nb_samples, nb_row, nb_col, stack_size))
+                       input_shape=(num_samples, num_row, num_col, stack_size))
-                               'nb_col': 3,
+                               'num_row': 3,
-                       input_shape=(nb_samples, nb_row, nb_col, stack_size))
+                       input_shape=(num_samples, num_row, num_col, stack_size))
-    nb_samples = 2
+    num_samples = 2
-    nb_col = 6
+    num_row = 10
-    for batch_size in [None, nb_samples]:
+    for batch_size in [None, num_samples]:
-                cols = conv_input_length(nb_col, 3, padding, subsample[1])
+                rows = conv_input_length(num_row, 3, padding, subsample[0])
-                                   'nb_col': 3,
+                                   'num_row': 3,
-                           input_shape=(nb_samples, stack_size, nb_row, nb_col),
+                           input_shape=(num_samples, stack_size, num_row, num_col),
-                                   'nb_col': 3,
+                                   'num_row': 3,
-                           input_shape=(nb_samples, stack_size, nb_row, nb_col),
+                           input_shape=(num_samples, stack_size, num_row, num_col),
-    nb_samples = 2
+    num_samples = 2
-    nb_col = 6
+    num_row = 10
-                                   'nb_col': 3,
+                                   'num_row': 3,
-                           input_shape=(nb_samples, nb_row, nb_col, stack_size))
+                           input_shape=(num_samples, num_row, num_col, stack_size))
-                                   'nb_col': 3,
+                                   'num_row': 3,
-                           input_shape=(nb_samples, nb_row, nb_col, stack_size))
+                           input_shape=(num_samples, num_row, num_col, stack_size))
-    nb_samples = 2
+    num_samples = 2
-    nb_col = 6
+    num_row = 10
-                                   'nb_col': 3,
+                                   'num_row': 3,
-                           input_shape=(nb_samples, nb_row, nb_col, stack_size))
+                           input_shape=(num_samples, num_row, num_col, stack_size))
-                                   'nb_col': 3,
+                                   'num_row': 3,
-                           input_shape=(nb_samples, nb_row, nb_col, stack_size))
+                           input_shape=(num_samples, num_row, num_col, stack_size))
-    nb_samples = 2
+    num_samples = 2
-                       input_shape=(nb_samples,
+                       input_shape=(num_samples,
-                       input_shape=(nb_samples,
+                       input_shape=(num_samples,
-    nb_samples = 2
+    num_samples = 2
-    shape = (nb_samples, nb_steps, input_dim)
+    num_steps = 5
-    nb_samples = 2
+    num_samples = 2
-    input_nb_col = 5
+    input_num_row = 4
-        input = np.ones((nb_samples, input_nb_row, input_nb_col, stack_size))
+        input = np.ones((num_samples, input_num_row, input_num_col, stack_size))
-        input = np.ones((nb_samples, stack_size, input_nb_row, input_nb_col))
+        input = np.ones((num_samples, stack_size, input_num_row, input_num_col))
-    nb_samples = 2
+    num_samples = 2
-    input = np.ones((nb_samples,
+    input = np.ones((num_samples,
-    nb_samples = 2
+    num_samples = 2
-    input_nb_col = 12
+    input_num_row = 11
-                                   input_nb_col)
+            input = np.random.rand(num_samples, stack_size, input_num_row,
-            input = np.random.rand(nb_samples, input_nb_row, input_nb_col,
+            input = np.random.rand(num_samples, input_num_row, input_num_col,
-                    assert np_output.shape[3] == length_col * input_nb_col
+                    assert np_output.shape[2] == length_row * input_num_row
-                    assert np_output.shape[2] == length_col * input_nb_col
+                    assert np_output.shape[1] == length_row * input_num_row
-    nb_samples = 2
+    num_samples = 2
-            input = np.random.rand(nb_samples, stack_size, input_len_dim1, input_len_dim2,
+            input = np.random.rand(num_samples, stack_size, input_len_dim1, input_len_dim2,
-            input = np.random.rand(nb_samples, input_len_dim1, input_len_dim2, input_len_dim3,
+            input = np.random.rand(num_samples, input_len_dim1, input_len_dim2, input_len_dim3,
-    nb_samples = 2
+    num_samples = 2
-    input = np.random.rand(nb_samples, time_length, input_len_dim1)
+    input = np.random.rand(num_samples, time_length, input_len_dim1)
-    nb_samples = 2
+    num_samples = 2
-        input = np.random.rand(nb_samples, stack_size,
+        input = np.random.rand(num_samples, stack_size,
-        input = np.random.rand(nb_samples,
+        input = np.random.rand(num_samples,
-    nb_samples = 2
+    num_samples = 2
-        input = np.random.rand(nb_samples, stack_size,
+        input = np.random.rand(num_samples, stack_size,
-        input = np.random.rand(nb_samples,
+        input = np.random.rand(num_samples,
-    nb_samples = 2
+    num_row = 3
-    input_nb_col = 5
+    input_num_row = 5
-            input = np.random.rand(nb_samples, sequence_len,
+            input = np.random.rand(num_samples, sequence_len,
-                                   input_nb_row, input_nb_col)
+                                   input_num_row, input_num_col)
-                                   input_nb_row, input_nb_col,
+            input = np.random.rand(num_samples, sequence_len,
-                                        'nb_col': nb_col,
+                                        'filters': filters,
-            output_shape = [nb_samples, input_nb_row, input_nb_col]
+            output_shape = [num_samples, input_num_row, input_num_col]
-                output_shape.insert(1, nb_filter)
+                output_shape.insert(1, filters)
-                output_shape.insert(3, nb_filter)
+                output_shape.insert(3, filters)
-                      'nb_col': nb_col,
+                      'filters': filters,
-                      'nb_col': nb_col,
+                      'filters': filters,
-                               'nb_col': nb_col,
+                               'filters': filters,
-        expected_output_shape = model.get_output_shape_for(input_shapes)
+        expected_output_shape = model.compute_output_shape(input_shapes)
-        expected_output_shape = model.get_output_shape_for(input_shapes)
+        expected_output_shape = model.compute_output_shape(input_shapes)
-    expected_output_shape = model.get_output_shape_for(input_shapes)
+    expected_output_shape = model.compute_output_shape(input_shapes)
-    expected_output_shape = model.get_output_shape_for(input_shapes)
+    expected_output_shape = model.compute_output_shape(input_shapes)
-    expected_output_shape = model.get_output_shape_for(input_shapes)
+    expected_output_shape = model.compute_output_shape(input_shapes)
-    expected_output_shape = model.get_output_shape_for(input_shapes)
+    expected_output_shape = model.compute_output_shape(input_shapes)
-    model_sum.fit([rand(2, 3), rand(2, 3)], [rand(2, 3)], nb_epoch=1)
+    model_sum.fit([rand(2, 3), rand(2, 3)], [rand(2, 3)], epochs=1)
-    model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], nb_epoch=1)
+    model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], epochs=1)
-    model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], nb_epoch=1)
+    model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], epochs=1)
-    nb_steps = 8
+    num_samples = 2
-    nb_filter = 4
+    filters = 4
-                       kwargs={'nb_filter': nb_filter,
+                       kwargs={'filters': filters,
-                       input_shape=(nb_samples, nb_steps, input_dim))
+                       input_shape=(num_samples, num_steps, input_dim))
-                       kwargs={'nb_filter': nb_filter,
+                       kwargs={'filters': filters,
-                       input_shape=(nb_samples, nb_steps, input_dim))
+                       input_shape=(num_samples, num_steps, input_dim))
-    nb_filter = 3
+    num_samples = 8
-    nb_col = 10
+    num_row = 6
-                               'nb_col': 3,
+                       kwargs={'filters': filters,
-                       input_shape=(nb_samples, nb_row, nb_col, stack_size))
+                       input_shape=(num_samples, num_row, num_col, stack_size))
-                               'nb_col': 3,
+                       kwargs={'filters': filters,
-                       input_shape=(nb_samples, stack_size, nb_row, nb_col))
+                       input_shape=(num_samples, stack_size, num_row, num_col))
-        model.fit(X, X, nb_epoch=4, verbose=0)
+        model.fit(X, X, epochs=4, verbose=0)
-    model.fit(X, X, nb_epoch=1, verbose=0)
+    model.fit(X, X, epochs=1, verbose=0)
-    model.fit(X, X, nb_epoch=4, verbose=0)
+    model.fit(X, X, epochs=4, verbose=0)
-nb_samples, timesteps, embedding_dim, output_dim = 2, 5, 4, 3
+num_samples, timesteps, embedding_dim, output_dim = 2, 5, 4, 3
-               input_shape=(nb_samples, timesteps, embedding_dim))
+               input_shape=(num_samples, timesteps, embedding_dim))
-    y = np.random.random((nb_samples, output_dim))
+    x = np.random.random((num_samples, timesteps, embedding_dim))
-               input_shape=(nb_samples, timesteps, embedding_dim))
+               input_shape=(num_samples, timesteps, embedding_dim))
-                   input_shape=(nb_samples, timesteps, embedding_dim))
+                   input_shape=(num_samples, timesteps, embedding_dim))
-                                   batch_input_shape=(nb_samples, timesteps)))
+                                   batch_input_shape=(num_samples, timesteps)))
-    assert(out1.shape == (nb_samples, output_dim))
+    out1 = model.predict(np.ones((num_samples, timesteps)))
-    out2 = model.predict(np.ones((nb_samples, timesteps)))
+    model.train_on_batch(np.ones((num_samples, timesteps)),
-    out3 = model.predict(np.ones((nb_samples, timesteps)))
+    out3 = model.predict(np.ones((num_samples, timesteps)))
-    out4 = model.predict(np.ones((nb_samples, timesteps)))
+    out4 = model.predict(np.ones((num_samples, timesteps)))
-    out5 = model.predict(np.ones((nb_samples, timesteps)))
+    out5 = model.predict(np.ones((num_samples, timesteps)))
-    left_padded_input = np.ones((nb_samples, timesteps))
+    left_padded_input = np.ones((num_samples, timesteps))
-    right_padded_input = np.ones((nb_samples, timesteps))
+    right_padded_input = np.ones((num_samples, timesteps))
-                        batch_input_shape=(nb_samples, timesteps, embedding_dim),
+                        batch_input_shape=(num_samples, timesteps, embedding_dim),
-    shape = (nb_samples, timesteps, embedding_dim)
+    shape = (num_samples, timesteps, embedding_dim)
-    model.fit(I, V, nb_epoch=1, batch_size=100, verbose=1)
+    model.fit(I, V, epochs=1, batch_size=100, verbose=1)
-    model.fit(I, V, nb_epoch=1, batch_size=100, verbose=1)
+    model.fit(I, V, epochs=1, batch_size=100, verbose=1)
-    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 2)), nb_epoch=1, batch_size=10)
+    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 2)), epochs=1, batch_size=10)
-    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 3)), nb_epoch=1, batch_size=10)
+    model.fit(np.random.random((10, 3, 4)), np.random.random((10, 3, 3)), epochs=1, batch_size=10)
-    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)), nb_epoch=1, batch_size=10)
+    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)), epochs=1, batch_size=10)
-    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)), nb_epoch=1, batch_size=10)
+    outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)), epochs=1, batch_size=10)
-    nb_sample = 2
+    samples = 2
-        x = np.random.random((nb_sample, timesteps, dim))
+        x = np.random.random((samples, timesteps, dim))
-        y = np.random.random((nb_sample, target_dim))
+        y = np.random.random((samples, target_dim))
-        model.fit(x, y, nb_epoch=1, batch_size=1)
+        model.fit(x, y, epochs=1, batch_size=1)
-        model.fit(x, y, nb_epoch=1, batch_size=1)
+        model.fit(x, y, epochs=1, batch_size=1)
-        model.fit(x, y, nb_epoch=1, batch_size=1)
+        model.fit(x, y, epochs=1, batch_size=1)
-        model.fit(x, y, nb_epoch=1, batch_size=1)
+        model.fit(x, y, epochs=1, batch_size=1)
-    tokenizer = Tokenizer(nb_words=10)
+    tokenizer = Tokenizer(num_words=10)
-nb_class = 2
+num_hidden = 4
-                                                         nb_test=test_samples,
+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                         nb_class=nb_class)
+                                                         num_classes=num_class)
-    model.add(Dense(nb_class, activation='softmax'))
+    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=4)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=4)
-                                                         nb_test=test_samples,
+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                         nb_class=nb_class)
+                                                         num_classes=num_class)
-    model.add(Dense(nb_class, activation='softmax'))
+    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))
-                        validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=20)
+                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)
-                        validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=20)
+                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)
-                                                         nb_test=test_samples,
+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                         nb_class=nb_class)
+                                                         num_classes=num_class)
-    model.add(Dense(nb_class, activation='softmax'))
+    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=5)
-                                                         nb_test=test_samples,
+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                         nb_class=nb_class)
+                                                         num_classes=num_class)
-        model.add(Dense(nb_class, activation='softmax'))
+        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5, verbose=2)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5, verbose=2)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)
-                                                         nb_test=test_samples,
+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                         nb_class=nb_class)
+                                                         num_classes=num_class)
-        model.add(Dense(nb_class, activation='softmax'))
+        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=1)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)
-        nb_test=test_samples,
+        num_train=train_samples,
-        nb_class=nb_class)
+        num_classes=num_class)
-    model.add(Dense(nb_class, activation='softmax'))
+    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=3)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=3)
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=2)
-    model.fit_generator(data_generator(True), len(X_train), nb_epoch=2,
+    model.fit_generator(data_generator(True), len(X_train), epochs=2,
-    model.fit_generator(data_generator(True), len(X_train), nb_epoch=2,
+    model.fit_generator(data_generator(True), len(X_train), epochs=2,
-    model.fit_generator(data_generator(True), len(X_train), nb_epoch=2,
+    model.fit_generator(data_generator(True), len(X_train), epochs=2,
-    model.fit_generator(data_generator(True), len(X_train), nb_epoch=2,
+    model.fit_generator(data_generator(True), len(X_train), epochs=2,
-                                                         nb_test=test_samples,
+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                         nb_class=nb_class)
+                                                         num_classes=num_class)
-    model.add(Dense(nb_class, activation='softmax'))
+    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=5)
-                                                         nb_test=test_samples,
+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                         nb_class=nb_class)
+                                                         num_classes=num_class)
-    model.add(Dense(nb_class, activation='softmax'))
+    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)
+              validation_data=(X_test, y_test), callbacks=cbks, epochs=2)
-                        nb_epoch=1,
+                        epochs=1,
-                        nb_worker=4,
+                        workers=4,
-                        nb_epoch=1,
+                        epochs=1,
-                        nb_epoch=1,
+                        epochs=1,
-                        nb_worker=2,
+                        workers=2,
-                        nb_epoch=1,
+                        epochs=1,
-                            nb_worker=2,
+                            workers=2,
-                             nb_worker=2,
+                             workers=2,
-            nb_worker=4, pickle_safe=True,
+            workers=4, pickle_safe=True,
-            nb_worker=4, pickle_safe=True,
+            workers=4, pickle_safe=True,
-            nb_worker=4, pickle_safe=True,
+            workers=4, pickle_safe=True,
-                                                     nb_test=200,
+(X_train, y_train), (X_test, y_test) = get_test_data(num_train=1000,
-                                                     nb_class=2)
+                                                     num_classes=2)
-def get_model(input_dim, nb_hidden, output_dim):
+def get_model(input_dim, num_hidden, output_dim):
-    model.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    model.add(Dense(num_hidden, input_shape=(input_dim,)))
-    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16,
+    history = model.fit(X_train, y_train, epochs=12, batch_size=16,
-nb_classes = 10
+num_classes = 10
-nb_epoch = 5
+epochs = 5
-    Y_test = np_utils.to_categorical(y_test, nb_classes)
+    Y_train = np_utils.to_categorical(y_train, num_classes)
-    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0)
+    model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=0)
-                  nb_epoch=nb_epoch, verbose=0)
+                  epochs=epochs, verbose=0)
-                  nb_epoch=nb_epoch, verbose=0)
+                  epochs=epochs, verbose=0)
-nb_class = 4
+num_hidden = 8
-nb_epoch = 1
+epochs = 1
-    model.add(Dense(nb_class))
+    model.add(Dense(num_hidden, input_dim=input_dim))
-    model.fit(x, y, nb_epoch=1)
+    y = np.random.random((batch_size, num_class))
-    assert model.output_shape == (None, nb_hidden)
+    assert model.output_shape == (None, num_hidden)
-    model.fit(x, y, nb_epoch=1)
+    y = np.random.random((batch_size, num_hidden))
-                                                         nb_test=test_samples,
+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                         nb_class=4)
+                                                         num_classes=4)
-    model.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    model.add(Dense(num_hidden, input_shape=(input_dim,)))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    model.fit_generator(data_generator(True), len(X_train), nb_epoch, max_q_size=2)
+    model.fit_generator(data_generator(True), len(X_train), epochs)
-    model.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    model.add(Dense(num_hidden, input_shape=(input_dim,)))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, shuffle=False)
+    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))
-    model.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    model.add(Dense(num_hidden, input_shape=(input_dim,)))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    inner.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    inner.add(Dense(num_hidden, input_shape=(input_dim,)))
-    inner.add(Dense(nb_class))
+    inner.add(Dense(num_class))
-    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, shuffle=False)
+    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))
-    inner.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    inner.add(Dense(num_hidden, input_shape=(input_dim,)))
-    inner.add(Dense(nb_class))
+    inner.add(Dense(num_class))
-    left.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    left.add(Dense(num_hidden, input_shape=(input_dim,)))
-    right.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    right.add(Dense(num_hidden, input_shape=(input_dim,)))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    model.fit([X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=False)
+    model.fit([X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([X_test, X_test], y_test))
-    left.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    left.add(Dense(num_hidden, input_shape=(input_dim,)))
-    right.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    right.add(Dense(num_hidden, input_shape=(input_dim,)))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    left.add(Dense(input_dim=input_dim, output_dim=nb_hidden))
+    left.add(Dense(input_dim=input_dim, output_dim=num_hidden))
-    right.add(Dense(input_dim=input_dim, output_dim=nb_hidden))
+    right.add(Dense(input_dim=input_dim, output_dim=num_hidden))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    left.add(Dense(input_dim=input_dim, output_dim=nb_hidden))
+    left.add(Dense(input_dim=input_dim, output_dim=num_hidden))
-    right.add(Dense(input_dim=input_dim, output_dim=nb_hidden))
+    right.add(Dense(input_dim=input_dim, output_dim=num_hidden))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    left.add(Dense(nb_hidden, input_shape=(input_dim,), name='dense_1'))
+    left.add(Dense(num_hidden, input_shape=(input_dim,), name='dense_1'))
-    right.add(Dense(nb_hidden, input_shape=(input_dim,), name='dense_2'))
+    right.add(Dense(num_hidden, input_shape=(input_dim,), name='dense_2'))
-    model.add(Dense(nb_class, name='final_dense'))
+    model.add(Dense(num_class, name='final_dense'))
-    model.fit([X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=False)
+    model.fit([X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([X_test, X_test], y_test))
-    model.fit([X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0)
+    model.fit([X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0)
-    left.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    left.add(Dense(num_hidden, input_shape=(input_dim,)))
-    right.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    right.add(Dense(num_hidden, input_shape=(input_dim,)))
-    righter.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    righter.add(Dense(num_hidden, input_shape=(input_dim,)))
-    intermediate.add(Dense(nb_hidden))
+    intermediate.add(Dense(num_hidden))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    model.fit([X_train, X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=False)
+    model.fit([X_train, X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=([X_test, X_test, X_test], y_test))
-    left.add(Dense(nb_hidden, input_shape=(input_dim,)))
+    left.add(Dense(num_hidden, input_shape=(input_dim,)))
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, shuffle=False)
+    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))
-    nb_classes = 2
+    num_units = 10
-    n += nb_units * nb_classes + nb_classes
+    n = input_dim * num_units + num_units
-    model.add(Dense(nb_classes))
+    model.add(Dense(num_units, input_shape=(input_dim,)))
-nb_class = 4
+num_hidden = 8
-nb_epoch = 1
+epochs = 1
-    predictions = Dense(nb_class, activation='sigmoid')(hidden)
+    hidden = Dense(num_hidden, activation='relu')(input)
-    model.fit(x, y, nb_epoch=1)
+    y = np.random.random((batch_size, num_class))
-nb_class = 3
+num_train = 100
-nb_epoch = 1
+epochs = 1
-    classification=True, nb_class=nb_class)
+    num_train=num_train, num_test=num_test, input_shape=(input_dim,),
-    model.add(Dense(nb_class))
+    model.add(Dense(num_class))
-        batch_size=batch_size, nb_epoch=nb_epoch)
+        batch_size=batch_size, epochs=epochs)
-        batch_size=batch_size, nb_epoch=nb_epoch)
+        batch_size=batch_size, epochs=epochs)
-        batch_size=batch_size, nb_epoch=nb_epoch)
+        batch_size=batch_size, epochs=epochs)
-    clf.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch)
+    clf.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)
-    assert preds.shape == (nb_test, )
+    assert preds.shape == (num_test, )
-        assert prediction in range(nb_class)
+        assert prediction in range(num_class)
-    assert np.allclose(np.sum(proba, axis=1), np.ones(nb_test))
+    assert proba.shape == (num_test, num_class)
-        batch_size=batch_size, nb_epoch=nb_epoch)
+        batch_size=batch_size, epochs=epochs)
-        batch_size=batch_size, nb_epoch=nb_epoch)
+        batch_size=batch_size, epochs=epochs)
-        batch_size=batch_size, nb_epoch=nb_epoch)
+        batch_size=batch_size, epochs=epochs)
-    reg.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch)
+    reg.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)
-    assert preds.shape == (nb_test, )
+    assert preds.shape == (num_test, )
-# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128], nb_epoch=[2], verbose=[0])
+# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128], epochs=[2], verbose=[0])
-# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128], nb_epoch=[2], verbose=[0])
+# parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128], epochs=[2], verbose=[0])
-nb_classes = 10
+num_classes = 10
-nb_epoch = 15
+epochs = 15
-                                                     nb_test=test_samples,
+(X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,
-                                                     nb_class=nb_classes)
+                                                     num_classes=num_classes)
-Y_test = np_utils.to_categorical(y_test, nb_classes)
+Y_train = np_utils.to_categorical(y_train, num_classes)
-class_weight = dict([(i, standard_weight) for i in range(nb_classes)])
+class_weight = dict([(i, standard_weight) for i in range(num_classes)])
-    model.add(Dense(nb_classes))
+    model.add(Dense(num_classes))
-    model.add(TimeDistributedDense(nb_classes))
+    model.add(TimeDistributedDense(num_classes))
-                  nb_epoch=nb_epoch // 3, verbose=0,
+                  epochs=epochs // 3, verbose=0,
-                  nb_epoch=nb_epoch // 3, verbose=0,
+                  epochs=epochs // 3, verbose=0,
-                  nb_epoch=nb_epoch // 3, verbose=0,
+                  epochs=epochs // 3, verbose=0,
-                  nb_epoch=nb_epoch // 2, verbose=0,
+                  epochs=epochs // 2, verbose=0,
-                  nb_epoch=nb_epoch // 2, verbose=0,
+                  epochs=epochs // 2, verbose=0,
-from theano.tensor.nnet import conv3d2d
+# -*- coding: utf-8 -*-
-                             'Received input shape:', str(input_shape))
+# -*- coding: utf-8 -*-
-import warnings
+from ..utils import conv_utils
-class ConvRecurrent2D(Layer):
+class ConvRecurrent2D(Recurrent):
-            `[(input_dim, nb_filter), (nb_filter, nb_filter), (nb_filter,)]`.
+        filters: Integer, the dimensionality of the output space
-        input_shape: input_shape
+
-                 data_format=None, **kwargs):
+    def __init__(self, filters,
-            return None
+        self.input_spec = InputSpec(ndim=5)
-
+        rows = conv_utils.conv_output_length(rows,
-                        self.nb_filter, rows, cols)
+                        self.filters, rows, cols)
-                        rows, cols, self.nb_filter)
+                        rows, cols, self.filters)
-                return (input_shape[0], self.nb_filter, rows, cols)
+                return (input_shape[0], self.filters, rows, cols)
-            return last_output
+                return (input_shape[0], rows, cols, self.filters)
-        config = {'return_sequences': self.return_sequences,
+        config = {'filters': self.filters,
-
+    It is similar to an LSTM layer, but the input transformations
-                `(samples, time, nb_filter, output_row, output_col)`
+                `(samples, time, filters, output_row, output_col)`
-                `(samples, time, output_row, output_col, nb_filter)`
+                `(samples, time, output_row, output_col, filters)`
-                `(samples, nb_filter, output_row, output_col)`
+                `(samples, filters, output_row, output_col)`
-                `(samples, output_row, output_col, nb_filter)`
+                `(samples, output_row, output_col, filters)`
-        inner_activation: activation function for the inner cells.
+            the padding
-                 inner_activation='hard_sigmoid',
+    def __init__(self, filters,
-        self.forget_bias_init = initializers.get(forget_bias_init)
+                 dilation_rate=(1, 1),
-            self.uses_learning_phase = True
+        self.recurrent_activation = activations.get(recurrent_activation)
-        self.input_spec = [InputSpec(shape=input_shape)]
+        self.kernel_initializer = initializers.get(kernel_initializer)
-            raise ValueError('Invalid data_format:', self.data_format)
+        self.kernel_regularizer = regularizers.get(kernel_regularizer)
-                             self.nb_filter, self.nb_filter)
+        self.kernel_constraint = constraints.get(kernel_constraint)
-            # initial states: 2 all-zero tensor of shape (nb_filter)
+            # initial states: 2 all-zero tensor of shape (filters)
-        self.built = True
+        if self.data_format == 'channels_first':
-        assert self.stateful, 'Layer must be stateful.'
+        if not self.stateful:
-                raise ValueError('Invalid data_format:', self.data_format)
+    def get_constants(self, inputs, training=None):
-        return conv_out
+        if 0 < self.recurrent_dropout < 1:
-            out_row, out_col, out_filter = output_shape[2:]
+            def dropped_inputs():
-            out_row, out_col, out_filter = output_shape[1:]
+            constants.append([K.cast_to_floatx(1.) for _ in range(4)])
-                            border_mode=border_mode,
+    def input_conv(self, x, w, b=None, padding='valid'):
-                            filter_shape=self.W_shape1)
+                            dilation_rate=self.dilation_rate)
-    def step(self, x, states):
+    def step(self, inputs, states):
-                                    border_mode='same')
+        dp_mask = states[2]
-                  'inner_activation': self.inner_activation.__name__}
+        config = {'activation': activations.serialize(self.activation),
-
+        recurrent_activation: Activation function to use
-                                       (1, self.units, 1, 1))
+                self.bias += K.concatenate(K.zeros((self.units,)),
-        raise Exception('Not a Keras tensor:', x)
+        raise TypeError('Not a Keras tensor:', x)
-                                 'it should have the form "2+", "3+", etc.')
+    def __init__(self, dtype=None,
-        self.shape = shape
+        self.max_ndim = max_ndim
-    def assert_input_compatibility(self, input):
+    def assert_input_compatibility(self, inputs):
-        for input_index, (x, spec) in enumerate(zip(inputs, self.input_spec)):
+        if not isinstance(self.input_spec, (list, tuple)):
-                                         str(K.ndim(x)))
+                if K.ndim(x) != spec.ndim:
-                    # Tensorflow shape inference.
+                try:
-                else:
+                except TypeError:
-    """Normalize inputs and targets provided by users.
+    """Normalizes inputs and targets provided by users.
-        return K.relu(x, alpha=self.alpha)
+    def call(self, inputs):
-        if not isinstance(shared_axes, (list, tuple)):
+        if shared_axes is None:
-        if self.shared_axes[0] is not None:
+        if self.shared_axes is not None:
-            neg = self.alpha * (x - K.abs(x)) * 0.5
+        # Set input spec
-        config = {'init': self.init.__name__}
+        config = {
-        return K.elu(x, self.alpha)
+    def call(self, inputs):
-        return x * K.cast(x > self.theta, K.floatx())
+    def call(self, inputs, mask=None):
-            # TODO: set InputSpec
+        # Set input spec.
-    def call(self, x):
+    def call(self, inputs):
-                x,
+                inputs,
-                x,
+                inputs,
-                x,
+                inputs,
-        self.input_spec = [InputSpec(ndim=3)]
+        self.input_spec = InputSpec(ndim=3)
-        self.input_spec = [InputSpec(ndim=4)]
+        self.input_spec = InputSpec(ndim=4)
-        self.input_spec = [InputSpec(ndim=5)]
+        self.input_spec = InputSpec(ndim=5)
-        self.input_spec = [InputSpec(ndim=4)]
+        self.input_spec = InputSpec(ndim=4)
-        self.input_spec = [InputSpec(ndim=3)]
+        self.input_spec = InputSpec(ndim=3)
-        output = K.repeat_elements(x, self.size, axis=1)
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=4)]
+        self.input_spec = InputSpec(ndim=4)
-        return K.resize_images(x, self.size[0], self.size[1],
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=5)]
+        self.input_spec = InputSpec(ndim=5)
-        return K.resize_volumes(x, self.size[0], self.size[1], self.size[2],
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=3)]
+        self.input_spec = InputSpec(ndim=3)
-            x, left_pad=self.left_pad, right_pad=self.right_pad)
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=4)]
+        self.input_spec = InputSpec(ndim=4)
-        return K.asymmetric_spatial_2d_padding(x,
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=5)]
+        self.input_spec = InputSpec(ndim=5)
-        return K.spatial_3d_padding(x, padding=self.padding,
+    def call(self, inputs):
-        self.built = True
+        self.input_spec = InputSpec(ndim=3)
-    def call(self, x):
+    def call(self, inputs):
-            return x[:, self.cropping[0]:, :]
+            return inputs[:, self.cropping[0]:, :]
-            return x[:, self.cropping[0]:-self.cropping[1], :]
+            return inputs[:, self.cropping[0]: -self.cropping[1], :]
-                                 'Found: ' + str(padding))
+                                 'Found: ' + str(cropping))
-        self.input_spec = [InputSpec(ndim=4)]
+        self.input_spec = InputSpec(ndim=4)
-    def call(self, x):
+    def call(self, inputs):
-                         self.cropping[1][0]:]
+                return inputs[:,
-                         self.cropping[1][0]:-self.cropping[1][1]]
+                return inputs[:,
-                     self.cropping[1][0]:-self.cropping[1][1]]
+                return inputs[:,
-                         :]
+                return inputs[:,
-                         :]
+                return inputs[:,
-                     :]
+                return inputs[:,
-                                 'Found: ' + str(padding))
+                                 'Found: ' + str(cropping))
-        self.input_spec = [InputSpec(ndim=5)]
+        self.input_spec = InputSpec(ndim=5)
-    def call(self, x):
+    def call(self, inputs):
-                         self.cropping[2][0]:]
+                return inputs[:,
-                         self.cropping[2][0]:-self.cropping[2][1]]
+                return inputs[:,
-                         self.cropping[2][0]:]
+                return inputs[:,
-                         self.cropping[2][0]:]
+                return inputs[:,
-                         self.cropping[2][0]:-self.cropping[2][1]]
+                return inputs[:,
-                         self.cropping[2][0]:-self.cropping[2][1]]
+                return inputs[:,
-                     self.cropping[2][0]:-self.cropping[2][1]]
+                return inputs[:,
-                         :]
+                return inputs[:,
-                         :]
+                return inputs[:,
-                         :]
+                return inputs[:,
-                         :]
+                return inputs[:,
-                         :]
+                return inputs[:,
-                     :]
+                return inputs[:,
-        return K.any(K.not_equal(x, self.mask_value), axis=-1)
+    def compute_mask(self, inputs, input_mask=None):
-        boolean_mask = K.any(K.not_equal(x, self.mask_value),
+    def call(self, inputs):
-        return x * K.cast(boolean_mask, K.floatx())
+        return inputs * K.cast(boolean_mask, K.floatx())
-        self.rate = rate
+        self.rate = min(1., max(0., rate))
-    def call(self, x, training=None):
+    def call(self, inputs, training=None):
-            noise_shape = self._get_noise_shape(x)
+            noise_shape = self._get_noise_shape(inputs)
-        return x
+                return K.dropout(inputs, self.rate, noise_shape,
-        input_shape = K.shape(x)
+    def _get_noise_shape(self, inputs):
-        input_shape = K.shape(x)
+    def _get_noise_shape(self, inputs):
-        input_shape = K.shape(x)
+    def _get_noise_shape(self, inputs):
-        return self.activation(x)
+    def call(self, inputs):
-                                                               self.target_shape)
+        return (input_shape[0],) + self._fix_unknown_dimension(
-    def call(self, x, mask=None):
+    def call(self, inputs):
-                input_shape = K.int_shape(x)
+            try:
-        return K.reshape(x, (-1,) + target_shape)
+        return K.reshape(inputs, (-1,) + target_shape)
-        return K.permute_dimensions(x, (0,) + self.dims)
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim='3+')]
+        self.input_spec = InputSpec(min_ndim=3)
-        return K.batch_flatten(x)
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=2)]
+        self.input_spec = InputSpec(ndim=2)
-        return K.repeat(x, self.n)
+    def call(self, inputs):
-    def call(self, x, mask=None):
+    def call(self, inputs, mask=None):
-        return self.function(x, **arguments)
+        return self.function(inputs, **arguments)
-        units: Positive interger, dimensionality of the output space.
+        units: Positive integer, dimensionality of the output space.
-        self.input_spec = [InputSpec(ndim='2+')]
+        self.input_spec = InputSpec(min_ndim=2)
-        output = K.dot(x, self.kernel)
+    def call(self, inputs):
-    """Turn positive integers (indexes) into dense vectors of fixed size.
+    """Turns positive integers (indexes) into dense vectors of fixed size.
-    def compute_mask(self, x, mask=None):
+    def compute_mask(self, inputs):
-            return K.not_equal(x, 0)
+            return K.not_equal(inputs, 0)
-        out = K.gather(self.embeddings, x)
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=3)]
+        self.input_spec = InputSpec(ndim=3)
-    def call(self, x):
+    def call(self, inputs):
-            xs.append(K.reshape(x[:, slice_length, :], (1, -1, feature_dim)))
+            slice_length = slice(i * stride,
-        # (output_length, batch_size, filters)
+        # Shape: `(output_length, batch_size, filters)`.
-        self.input_spec = [InputSpec(ndim=4)]
+        self.input_spec = InputSpec(ndim=4)
-    def call(self, x):
+    def call(self, inputs):
-                        x_flatten = K.reshape(x[:, :, slice_row, slice_col],
+                        x_flatten = K.reshape(inputs[:, :, slice_row, slice_col],
-                        xs.append(K.reshape(x[:, :, slice_row, slice_col],
+                        xs.append(K.reshape(inputs[:, :, slice_row, slice_col],
-                    xs.append(K.reshape(x[:, slice_row, slice_col, :],
+                    xs.append(K.reshape(inputs[:, slice_row, slice_col, :],
-    def call(self, x, training=None):
+    def call(self, inputs, training=None):
-        return K.in_train_phase(noised, x, training=training)
+        return K.in_train_phase(noised, inputs, training=training)
-    def call(self, x, training=None):
+    def call(self, inputs, training=None):
-        return x
+                stddev = np.sqrt(self.rate / (1.0 - self.rate))
-            applied to the beta vector.
+        axis: Integer, the axis that should be normalized
-                 gamma_regularizer=None, beta_regularizer=None, **kwargs):
+    def __init__(self,
-        self.gamma_regularizer = regularizers.get(gamma_regularizer)
+        self.epsilon = epsilon
-        super(BatchNormalization, self).__init__(**kwargs)
+        self.gamma_regularizer = regularizers.get(gamma_regularizer)
-                        self.beta, self.gamma,
+        dim = input_shape[self.axis]
-                        broadcast_beta, broadcast_gamma,
+                    return K.batch_normalization(
-        return x_normed
+        # Pick the normalized form corresponding to the training phase.
-                  'momentum': self.momentum}
+        config = {
-        self.input_spec = [InputSpec(ndim=3)]
+        self.input_spec = InputSpec(ndim=3)
-        output = self._pooling_function(inputs=x, pool_size=self.pool_size,
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=4)]
+        self.input_spec = InputSpec(ndim=4)
-        output = self._pooling_function(inputs=x,
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=5)]
+        self.input_spec = InputSpec(ndim=5)
-        output = self._pooling_function(inputs=x, pool_size=self.pool_size,
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=3)]
+        self.input_spec = InputSpec(ndim=3)
-    def call(self, x):
+    def call(self, inputs):
-        return K.mean(x, axis=1)
+    def call(self, inputs):
-        return K.max(x, axis=1)
+    def call(self, inputs):
-        self.input_spec = [InputSpec(ndim=4)]
+        self.input_spec = InputSpec(ndim=4)
-    def call(self, x):
+    def call(self, inputs):
-    def call(self, x):
+    def call(self, inputs):
-            return K.mean(x, axis=[1, 2])
+            return K.mean(inputs, axis=[1, 2])
-            return K.mean(x, axis=[2, 3])
+            return K.mean(inputs, axis=[2, 3])
-    def call(self, x):
+    def call(self, inputs):
-            return K.max(x, axis=[1, 2])
+            return K.max(inputs, axis=[1, 2])
-            return K.max(x, axis=[2, 3])
+            return K.max(inputs, axis=[2, 3])
-        self.input_spec = [InputSpec(ndim=5)]
+        self.input_spec = InputSpec(ndim=5)
-    def call(self, x):
+    def call(self, inputs):
-    def call(self, x):
+    def call(self, inputs):
-            return K.mean(x, axis=[1, 2, 3])
+            return K.mean(inputs, axis=[1, 2, 3])
-            return K.mean(x, axis=[2, 3, 4])
+            return K.mean(inputs, axis=[2, 3, 4])
-    def call(self, x):
+    def call(self, inputs):
-            return K.max(x, axis=[1, 2, 3])
+            return K.max(inputs, axis=[1, 2, 3])
-            return K.max(x, axis=[2, 3, 4])
+            return K.max(inputs, axis=[2, 3, 4])
-                           input_dim=None, output_dim=None, timesteps=None):
+def _time_distributed_dense(x, w, b=None, dropout=None,
-        x = K.in_train_phase(x * expanded_dropout_matrix, x)
+        x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)
-    if b:
+    if b is not None:
-            Unrolling can speed-up a RNN, although it tends to be more memory-intensive.
+        unroll: Boolean (default False).
-            If set to "cpu", the RNN will use
+        implementation: one of {0, 1, or 2}.
-            If set to "gpu" (LSTM/GRU only), the RNN will combine the input gate,
+            If set to 1, the RNN will use more matrix products,
-            reduced regularization.
+            enabling more time-efficient parallelization on the GPU.
-        3D tensor with shape `(nb_samples, timesteps, input_dim)`.
+        3D tensor with shape `(batch_size, timesteps, input_dim)`.
-        - else, 2D tensor with shape `(nb_samples, output_dim)`.
+            `(batch_size, timesteps, units)`.
-                This is the expected shape of your inputs *including the batch size*.
+                This is the expected shape of your inputs
-            kwargs['input_shape'] = (self.input_length, self.input_dim)
+    def __init__(self, return_sequences=False,
-
+        self.implementation = 0
-        self.input_spec = [InputSpec(ndim=3)]
+        self.input_spec = InputSpec(ndim=3)
-            return (input_shape[0], input_shape[1], self.output_dim)
+            return (input_shape[0], input_shape[1], self.units)
-            return (input_shape[0], self.output_dim)
+            return (input_shape[0], self.units)
-    def compute_mask(self, input, mask):
+    def compute_mask(self, inputs, mask):
-    def step(self, x, states):
+    def step(self, inputs, states):
-    def get_constants(self, x):
+    def get_constants(self, inputs, training=None):
-    def get_initial_states(self, x):
+    def get_initial_states(self, inputs):
-        initial_state = K.zeros_like(x)  # (samples, timesteps, input_dim)
+        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)
-        initial_state = K.tile(initial_state, [1, self.output_dim])  # (samples, output_dim)
+        initial_state = K.tile(initial_state, [1, self.units])  # (samples, output_dim)
-        return x
+    def preprocess_input(self, inputs, training=None):
-        # input shape: (nb_samples, time (padded with zeros), input_dim)
+    def call(self, inputs, mask=None, training=None):
-        input_shape = K.int_shape(x)
+        input_shape = K.int_shape(inputs)
-        last_output, outputs, states = K.rnn(self.step, preprocessed_input,
+            initial_states = self.get_initial_states(inputs)
-            self.add_update(updates, x)
+            self.add_update(updates, inputs)
-
+                  'implementation': self.implementation}
-        dropout_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.
+        units: Positive integer, dimensionality of the output space.
-                 init='glorot_uniform', inner_init='orthogonal',
+    def __init__(self, units,
-                 dropout_W=0., dropout_U=0., **kwargs):
+                 use_bias=True,
-        self.inner_init = initializers.get(inner_init)
+        self.units = units
-        self.dropout_U = dropout_U
+        self.use_bias = use_bias
-            self.uses_learning_phase = True
+        self.kernel_regularizer = regularizers.get(kernel_regularizer)
-        self.input_spec = [InputSpec(shape=input_shape)]
+        # TODO: handle variable-length seqs in input_spec
-            # initial states: all-zero tensor of shape (output_dim)
+            # Initial states: all-zero tensor of shape (output_dim).
-        self.built = True
+        self.kernel = self.add_weight((input_dim, self.units),
-        assert self.stateful, 'Layer must be stateful.'
+        if not self.stateful:
-                        np.zeros((input_shape[0], self.output_dim)))
+                        np.zeros((input_shape[0], self.units)))
-            self.states = [K.zeros((input_shape[0], self.output_dim))]
+            self.states = [K.zeros((input_shape[0], self.units))]
-            input_shape = K.int_shape(x)
+    def preprocess_input(self, inputs, training=None):
-                                          timesteps)
+            return _time_distributed_dense(inputs,
-            return x
+            if 0 < self.dropout < 1:
-        output = self.activation(h + K.dot(prev_output * B_U, self.U))
+        if 0 < self.recurrent_dropout < 1:
-    def get_constants(self, x):
+    def get_constants(self, inputs, training=None):
-            input_shape = K.int_shape(x)
+        if self.implementation == 0 and 0 < self.dropout < 1:
-            ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))
+            ones = K.ones_like(K.reshape(inputs[:, 0, 0], (-1, 1)))
-            constants.append(B_W)
+
-                  'dropout_U': self.dropout_U}
+        config = {'units': self.units,
-        dropout_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.
+        units: Positive integer, dimensionality of the output space.
-                 dropout_W=0., dropout_U=0., **kwargs):
+    def __init__(self, units,
-        self.inner_init = initializers.get(inner_init)
+        self.units = units
-        self.dropout_U = dropout_U
+        self.recurrent_activation = activations.get(recurrent_activation)
-            self.uses_learning_phase = True
+        self.kernel_constraint = constraints.get(kernel_constraint)
-        self.input_spec = [InputSpec(shape=input_shape)]
+        # TODO: handle variable-length sequences in input spec.
-                                     regularizer=self.b_regularizer)
+        self.kernel = self.add_weight((self.input_dim, self.units * 3),
-        self.built = True
+            self.bias_z = None
-        assert self.stateful, 'Layer must be stateful.'
+        if not self.stateful:
-                        np.zeros((input_shape[0], self.output_dim)))
+                        np.zeros((input_shape[0], self.units)))
-            self.states = [K.zeros((input_shape[0], self.output_dim))]
+            self.states = [K.zeros((input_shape[0], self.units))]
-            input_shape = K.int_shape(x)
+    def preprocess_input(self, inputs, training=None):
-                                         input_dim, self.output_dim, timesteps)
+            x_z = _time_distributed_dense(inputs, self.kernel_z, self.bias_z,
-            return x
+            return inputs
-        B_W = states[2]
+    def get_constants(self, inputs, training=None):
-        if self.consume_less == 'gpu':
+            def dropped_inputs():
-            matrix_inner = K.dot(h_tm1 * B_U[0], self.U[:, :2 * self.output_dim])
+            dp_mask = [K.in_train_phase(dropped_inputs,
-            inner_r = matrix_inner[:, self.output_dim: 2 * self.output_dim]
+        if 0 < self.recurrent_dropout < 1:
-            r = self.inner_activation(x_r + inner_r)
+            def dropped_inputs():
-            inner_h = K.dot(r * h_tm1 * B_U[0], self.U[:, 2 * self.output_dim:])
+    def step(self, inputs, states):
-                x_h = K.dot(x * B_W[2], self.W_h) + self.b_h
+            if self.implementation == 0:
-            hh = self.activation(x_h + K.dot(r * h_tm1 * B_U[2], self.U_h))
+                raise ValueError('Unknown `implementation` mode.')
-                  'dropout_U': self.dropout_U}
+        config = {'units': self.units,
-        dropout_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.
+        units: Positive integer, dimensionality of the output space.
-                 dropout_W=0., dropout_U=0., **kwargs):
+    def __init__(self, units,
-        self.forget_bias_init = initializers.get(forget_bias_init)
+        self.units = units
-        self.dropout_U = dropout_U
+        self.recurrent_activation = activations.get(recurrent_activation)
-            self.uses_learning_phase = True
+        self.kernel_initializer = initializers.get(kernel_initializer)
-                                     regularizer=self.b_regularizer)
+        self.kernel = self.add_weight((self.input_dim, self.units * 4),
-        self.built = True
+            self.bias = None
-                             'input_shape must be provided (including batch size).')
+                             'input_shape must be provided '
-                        np.zeros((input_shape[0], self.output_dim)))
+                        np.zeros((input_shape[0], self.units)))
-                        np.zeros((input_shape[0], self.output_dim)))
+                        np.zeros((input_shape[0], self.units)))
-                           K.zeros((input_shape[0], self.output_dim))]
+            self.states = [K.zeros((input_shape[0], self.units)),
-            input_shape = K.int_shape(x)
+    def preprocess_input(self, inputs, training=None):
-                                         input_dim, self.output_dim, timesteps)
+            x_i = _time_distributed_dense(inputs, self.kernel_i, self.bias_i,
-            return x
+            return inputs
-    def step(self, x, states):
+            def dropped_inputs():
-        B_W = states[3]
+        dp_mask = states[2]
-            z = K.dot(x * B_W[0], self.W) + K.dot(h_tm1 * B_U[0], self.U) + self.b
+        if self.implementation == 1:
-            z3 = z[:, 3 * self.output_dim:]
+            z0 = z[:, :self.units]
-                x_o = K.dot(x * B_W[3], self.W_o) + self.b_o
+            if self.implementation == 0:
-
+                raise ValueError('Unknown `implementation` mode.')
-                  'dropout_U': self.dropout_U}
+        config = {'units': self.units,
-        self.input_spec = [InputSpec(shape=input_shape)]
+        self.input_spec = InputSpec(shape=input_shape)
-        config = {"merge_mode": self.merge_mode}
+        config = {'merge_mode': self.merge_mode}
-        inputs = to_list(input)
+        inputs = _to_list(input)
-            for x_elem in to_list(x):
+            for x_elem in _to_list(x):
-            self.add_loss(regularization_losses, to_list(x))
+            regularization_losses = [self.activity_regularizer(x) for x in _to_list(output)]
-        output_shapes = to_list(output_shapes)
+        input_tensors = _to_list(input_tensors)
-        losses = to_list(losses)
+        losses = _to_list(losses)
-        updates = to_list(updates)
+        updates = _to_list(updates)
-    def __init__(self, input, output, name=None):
+    def __init__(self, inputs, outputs, name=None):
-            self.inputs = list(input)  # Tensor or list of tensors.
+        if isinstance(inputs, (list, tuple)):
-            self.outputs = list(output)
+            self.inputs = [inputs]
-            self.outputs = [output]
+            self.outputs = [outputs]
-        inputs = to_list(input)
+        inputs = _to_list(input)
-            masks = to_list(mask)
+            masks = _to_list(mask)
-        inputs = to_list(input)
+        inputs = _to_list(input)
-            masks = to_list(mask)
+            masks = _to_list(mask)
-        input_shapes = to_list(input_shape)
+        input_shapes = _to_list(input_shape)
-                        output_shapes = to_list(output_shape)
+                        output_shapes = _to_list(output_shape)
-                                                                  computed_mask))
+                        output_tensors = _to_list(layer.masked_call(computed_tensor,
-                                                                  computed_masks))
+                        output_tensors = _to_list(layer.masked_call(computed_tensors,
-                            shapes = to_list(layer.get_output_shape_for(computed_tensors[0]._keras_shape))
+                            shapes = _to_list(layer.get_output_shape_for(computed_tensors[0]._keras_shape))
-                            shapes = to_list(layer.get_output_shape_for([x._keras_shape for x in computed_tensors]))
+                            shapes = _to_list(layer.get_output_shape_for([x._keras_shape for x in computed_tensors]))
-        config = {'size': self.size}
+        config = {'size': self.size,
-        config = {'size': self.size}
+        config = {'size': self.size,
-                raise ValueError('TODO')
+                raise ValueError('`padding` should have two elements. '
-        config = {'padding': self.padding}
+        config = {'padding': self.padding,
-                raise ValueError('TODO')
+                raise ValueError('`padding` should have 3 elements. '
-        config = {'padding': self.padding}
+        config = {'padding': self.padding,
-                raise ValueError('TODO')
+                raise ValueError('`cropping` should have two elements. '
-        config = {'cropping': self.cropping}
+        config = {'cropping': self.cropping,
-                raise ValueError('TODO')
+                raise ValueError('`cropping` should have 3 elements. '
-        config = {'cropping': self.cropping}
+        config = {'cropping': self.cropping,
-from keras.utils import np_utils
+from keras.layers import Dense, Dropout, Flatten
-nb_epoch = 12
+num_classes = 10
-(X_train, y_train), (X_test, y_test) = mnist.load_data()
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
+    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
-    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
+    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
-print(X_test.shape[0], 'test samples')
+x_train = x_train.astype('float32')
-Y_test = np_utils.to_categorical(y_test, nb_classes)
+y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)
-model.add(MaxPooling2D(pool_size=pool_size))
+model.add(Conv2D(32, kernel_size=(3, 3),
-model.add(Activation('relu'))
+model.add(Dense(128, activation='relu'))
-model.add(Activation('softmax'))
+model.add(Dense(num_classes, activation='softmax'))
-              optimizer='adadelta',
+model.compile(loss=keras.losses.categorical_crossentropy,
-print('Test score:', score[0])
+model.fit(x_train, y_train, batch_size=batch_size, num_epoch=num_epoch,
-from keras.layers.core import Dense, Dropout, Activation
+from keras.layers import Dense, Dropout, Activation
-nb_epoch = 20
+num_classes = 10
-(X_train, y_train), (X_test, y_test) = mnist.load_data()
+(x_train, y_train), (x_test, y_test) = mnist.load_data()
-print(X_test.shape[0], 'test samples')
+x_train = x_train.reshape(60000, 784)
-Y_test = np_utils.to_categorical(y_test, nb_classes)
+y_train = np_utils.to_categorical(y_train, num_classes)
-model.add(Activation('relu'))
+model.add(Dense(512, activation='relu', input_shape=(784,)))
-model.add(Activation('relu'))
+model.add(Dense(512, activation='relu'))
-model.add(Activation('softmax'))
+model.add(Dense(10, activation='softmax'))
-print('Test score:', score[0])
+history = model.fit(x_train, y_train,
-        # note that 'input_dtype', 'input_shape' and 'batch_input_shape'
+        # note that 'dtype', 'input_shape' and 'batch_input_shape'
-                          'input_dtype',
+                          'dtype',
-                          'trainable'}
+                          'trainable',
-            self.input_dtype = input_dtype
+            dtype = kwargs.get('dtype', K.floatx())
-
+            # Load weights that were specified at layer instantiation.
-            output_tensors[i]._uses_learning_phase = uses_lp
+            uses_lp = any([x._uses_learning_phase for x in input_tensors])
-            config['input_dtype'] = self.input_dtype
+        if hasattr(self, 'dtype'):
-    or `batch_input_shape` as well as `input_dtype`).
+    or `batch_input_shape` as well as `dtype`).
-        input_dtype: Datatype of the input.
+        dtype: Datatype of the input.
-                 input_dtype=None, input_tensor=None, sparse=False, name=None):
+                 dtype=None, input_tensor=None, sparse=False, name=None):
-        if not input_dtype:
+        if not dtype:
-                input_dtype = K.floatx()
+                dtype = K.floatx()
-                input_dtype = K.dtype(input_tensor)
+                dtype = K.dtype(input_tensor)
-        self.input_dtype = input_dtype
+        self.dtype = dtype
-                                         dtype=input_dtype,
+                                         dtype=dtype,
-                  'input_dtype': self.input_dtype,
+                  'dtype': self.dtype,
-                             name=name, input_dtype=dtype,
+                             name=name, dtype=dtype,
-        self.uses_learning_phase = False
+    def uses_learning_phase(self):
-                            uses_learning_phase = computed_tensors[0]._uses_learning_phase or layer.uses_learning_phase
+                            uses_learning_phase = computed_tensors[0]._uses_learning_phase
-                            uses_learning_phase = any([x._uses_learning_phase for x in computed_tensors]) or layer.uses_learning_phase
+                            uses_learning_phase = any([x._uses_learning_phase for x in computed_tensors])
-                            x._uses_learning_phase = uses_learning_phase
+                            x._uses_learning_phase = getattr(x, '_uses_learning_phase', False) or uses_learning_phase
-        kwargs['input_dtype'] = 'int32'
+        kwargs['dtype'] = 'int32'
-from .engine.topology import get_source_inputs, Node, Layer, Merge
+from .engine.topology import get_source_inputs, Node, Layer, Merge, Input
-                layer.create_input_layer(batch_input_shape, input_dtype)
+                # Instantiate the input layer.
-def get_test_data(nb_train=1000, nb_test=500, input_shape=(10,),
+def get_test_data(num_train=1000, num_test=500, input_shape=(10,),
-                  classification=True, nb_class=2):
+                  classification=True, num_class=2):
-    consists in integers in [0, nb_class-1].
+    consists in integers in [0, num_class-1].
-    nb_sample = nb_train + nb_test
+    num_sample = num_train + num_test
-        for i in range(nb_sample):
+        y = np.random.randint(0, num_class, size=(num_sample,))
-        for i in range(nb_sample):
+        y_loc = np.random.random((num_sample,))
-    return (X[:nb_train], y[:nb_train]), (X[nb_train:], y[nb_train:])
+    return (X[:num_train], y[:num_train]), (X[num_train:], y[num_train:])
-def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,
+def layer_test(layer_cls, kwargs={}, input_shape=None, dtype=None,
-            input_dtype = K.floatx()
+        if not dtype:
-        input_data = input_data.astype(input_dtype)
+        input_data = input_data.astype(dtype)
-        expected_output_dtype = input_dtype
+        expected_output_dtype = dtype
-        x = Input(batch_shape=input_shape, dtype=input_dtype)
+        x = Input(batch_shape=input_shape, dtype=dtype)
-        x = Input(shape=input_shape[1:], dtype=input_dtype)
+        x = Input(shape=input_shape[1:], dtype=dtype)
-def preprocess_input(audio_path, data_format='default'):
+def preprocess_input(audio_path, data_format=None):
-    if data_format == 'default':
+    if data_format is None:
-def preprocess_input(x, data_format='default'):
+def preprocess_input(x, data_format=None):
-    if data_format == 'default':
+    if data_format is None:
-              else_expression_fn)
+    x = tf.cond(condition,
-def in_train_phase(x, alt):
+def in_train_phase(x, alt, training=None):
-        Either `x` or `alt` based on `K.learning_phase`.
+        Either `x` or `alt` based on the `training` flag.
-    if learning_phase() is 1:
+    if training is None:
-    elif learning_phase() is 0:
+
-    x._uses_learning_phase = True
+    x = switch(training, x, alt)
-def in_test_phase(x, alt):
+def in_test_phase(x, alt, training=None):
-    return x
+    return in_train_phase(alt, x, training=training)
-    return x
+def in_train_phase(x, alt, training=None):
-    x._uses_learning_phase = True
+    # else: assume learning phase is a placeholder tensor.
-        self.alpha = alpha
+        self.supports_masking = True
-    def call(self, x, mask=None):
+    def call(self, x):
-    `f(x) = alphas * x for x < 0`,
+    `f(x) = alpha * x for x < 0`,
-    where `alphas` is a learned array with the same shape as x.
+    where `alpha` is a learned array with the same shape as x.
-        weights: initial weights, as a list of a single Numpy array.
+        alpha_initializer: initializer function for the weights.
-    def __init__(self, init='zero', weights=None, shared_axes=None, **kwargs):
+    def __init__(self, alpha_initializer='zeros',
-        self.initial_weights = weights
+        self.alpha_initializer = initializers.get(alpha_initializer)
-            del self.initial_weights
+        self.alpha = self.add_weight(param_shape,
-            neg = (K.pattern_broadcast(self.alphas, self.param_broadcast) *
+            neg = (K.pattern_broadcast(self.alpha, self.param_broadcast) *
-            neg = self.alphas * (x - K.abs(x)) * 0.5
+            neg = self.alpha * (x - K.abs(x)) * 0.5
-    def call(self, x, mask=None):
+    def call(self, x):
-
+        super(ThresholdedReLU, self).__init__(**kwargs)
-        if self.bias is not None:
+        if self.use_bias:
-        (if `data_format` is `channels_last`).
+
-                 data_format='default',
+                 data_format=None,
-        if data_format == 'default':
+        if data_format is None:
-    def call(self, x, mask=None):
+    def call(self, x, training=None):
-            x = K.in_train_phase(dropped_inputs, lambda: x)
+            x = K.in_train_phase(dropped_inputs, x, training=training)
-from ..utils.conv_utils import conv_output_length
+from ..utils import conv_utils
-    the `Convolution1D` layer, except that weights are unshared,
+    the `Conv1D` layer, except that weights are unshared,
-            or alternatively, elementwise Theano function.
+        filters: Integer, the dimensionality of the output space
-            (without it, the shape of the dense outputs cannot be computed).
+            (ie. "linear" activation: `a(x) = x`).
-        3D tensor with shape: `(samples, steps, input_dim)`.
+        3D tensor with shape: `(batch_size, steps, input_dim)`
-        `steps` value might have changed due to padding.
+        3D tensor with shape: `(batch_size, new_steps, nb_filter)`
-        self.init = initializers.get(init, data_format='channels_first')
+    def __init__(self, filters,
-        self.b_regularizer = regularizers.get(b_regularizer)
+        self.use_bias = use_bias
-        self.bias = bias
+        self.kernel_constraint = constraints.get(kernel_constraint)
-                                     constraint=self.b_constraint)
+        if input_dim is None:
-        self.built = True
+            self.bias = None
-        return (input_shape[0], length, self.nb_filter)
+        length = conv_utils.conv_output_length(input_shape[1],
-        output_length, feature_dim, nb_filter = self.W_shape
+    def call(self, x):
-            slice_length = slice(i * stride, i * stride + self.filter_length)
+            slice_length = slice(i * stride, i * stride + self.kernel_size[0])
-        output = K.batch_dot(x_aggregate, self.W)
+        # (output_length, batch_size, filters)
-        output = self.activation(output)
+        if self.use_bias:
-                  'input_length': self.input_length}
+        config = {
-    to the `Convolution2D` layer, except that weights are unshared,
+    to the `Conv2D` layer, except that weights are unshared,
-        # apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image:
+        # apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image
-        # now model.output_shape == (None, 64, 30, 30)
+        model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))
-        # now model.output_shape == (None, 32, 28, 28)
+        model.add(LocallyConnected2D(32, (3, 3)))
-            or alternatively, elementwise Theano function.
+        filters: Integer, the dimensionality of the output space
-        bias: whether to include a bias (i.e. make the layer affine rather than linear).
+            (ie. "linear" activation: `a(x) = x`).
-                 border_mode='valid', subsample=(1, 1),
+    def __init__(self, filters,
-        self.init = initializers.get(init, data_format=data_format)
+                 activation=None,
-        self.b_regularizer = regularizers.get(b_regularizer)
+        self.use_bias = use_bias
-        self.bias = bias
+        self.kernel_constraint = constraints.get(kernel_constraint)
-        super(LocallyConnected2D, self).__init__(**kwargs)
+        if self.data_format == 'channels_last':
-            _, nb_filter, output_row, output_col = output_shape
+            _, filters, output_row, output_col = output_shape
-            _, output_row, output_col, nb_filter = output_shape
+            _, output_row, output_col, filters = output_shape
-                                 constraint=self.W_constraint)
+        self.kernel_shape = (output_row * output_col,
-                                     constraint=self.b_constraint)
+            self.bias = self.add_weight((output_row, output_col, filters),
-        self.built = True
+            self.bias = None
-                                  self.border_mode, self.subsample[1])
+        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],
-            return (input_shape[0], self.nb_filter, rows, cols)
+            return (input_shape[0], self.filters, rows, cols)
-            return (input_shape[0], rows, cols, self.nb_filter)
+            return (input_shape[0], rows, cols, self.filters)
-        _, feature_dim, nb_filter = self.W_shape
+    def call(self, x):
-                                          i * stride_row + self.nb_row)
+                                          i * stride_row + self.kernel_size[0])
-                        output.append(K.dot(x_flatten, self.W[i * self.output_col + j, :, :]))
+                                          j * stride_col + self.kernel_size[1])
-                                          i * stride_row + self.nb_row)
+                                          i * stride_row + self.kernel_size[0])
-                        xs.append(K.reshape(x[:, :, slice_row, slice_col], (1, -1, feature_dim)))
+                                          j * stride_col + self.kernel_size[1])
-            output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))
+                output = K.batch_dot(x_aggregate, self.kernel)
-                                      i * stride_row + self.nb_row)
+                                      i * stride_row + self.kernel_size[0])
-                    xs.append(K.reshape(x[:, slice_row, slice_col, :], (1, -1, feature_dim)))
+                                      j * stride_col + self.kernel_size[1])
-            output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))
+            output = K.batch_dot(x_aggregate, self.kernel)
-                output += K.reshape(self.b, (1, self.output_row, self.output_col, nb_filter))
+        if self.use_bias:
-                  'bias': self.bias}
+        config = {
-        sigma: float, standard deviation of the noise distribution.
+        stddev: float, standard deviation of the noise distribution.
-        self.uses_learning_phase = True
+    def __init__(self, stddev, **kwargs):
-        return K.in_train_phase(noise_x, x)
+    def call(self, x, training=None):
-        config = {'sigma': self.sigma}
+        config = {'stddev': self.stddev}
-        p: float, drop probability (as with `Dropout`).
+        rate: float, drop probability (as with `Dropout`).
-            standard deviation `sqrt(p / (1 - p))`.
+            standard deviation `sqrt(rate / (1 - rate))`.
-            self.uses_learning_phase = True
+    def __init__(self, rate, **kwargs):
-            return K.in_train_phase(noise_x, x)
+        self.supports_masking = True
-        config = {'p': self.p}
+        config = {'rate': self.rate}
-__version__ = '1.2.1'
+__version__ = '2.0.0'
-def spatial_3d_padding(x, padding=(1, 1, 1), data_format=None):
+def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):
-                        input_shape[4] + 2 * padding[2])
+                        input_shape[2] + padding[0][0] + padding[0][1],
-                   slice(padding[2], input_shape[4] + padding[2]))
+                   slice(padding[0][0], input_shape[2] + padding[0][0]),
-                        input_shape[3] + 2 * padding[2],
+                        input_shape[1] + padding[0][0] + padding[0][1],
-                   slice(padding[2], input_shape[3] + padding[2]),
+                   slice(padding[0][0], input_shape[1] + padding[0][0]),
-def _preprocess_conv2d_image_shape(data_format, image_shape):
+def _preprocess_conv2d_image_shape(image_shape, data_format):
-def _preprocess_conv3d_volume_shape(data_format, volume_shape):
+def _preprocess_conv3d_volume_shape(volume_shape, data_format):
-def _preprocess_conv2d_filter_shape(data_format, filter_shape):
+def _preprocess_conv2d_filter_shape(filter_shape, data_format):
-                            filter_shape[0], filter_shape[1])
+    if filter_shape:
-def _preprocess_conv3d_filter_shape(data_format, filter_shape):
+def _preprocess_conv3d_filter_shape(filter_shape, data_format):
-                            filter_shape[0], filter_shape[1], filter_shape[2])
+    if filter_shape:
-        dilate_rate: integer.
+        dilation_rate: integer.
-            shape = x._keras_shape
+        if shape is not None:
-            shape = x._keras_shape
+        if shape is not None:
-    kernel = expand_dims(x, 1)
+    kernel = expand_dims(kernel, 1)
-
+    if hasattr(x, '_keras_shape'):
-    kernel_shape = _preprocess_conv2d_filter_shape(data_format, kernel_shape)
+    x = _preprocess_conv2d_input(x, data_format)
-
+    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)
-    filter_shape = tuple(filter_shape[i] for i in (1, 0, 2, 3))
+    x = _preprocess_conv2d_input(x, data_format)
-    op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(imshp=output_shape,
+    th_padding = _preprocess_padding(padding)
-
+    if hasattr(x, '_keras_shape'):
-    kernel_shape = _preprocess_conv3d_filter_shape(data_format, kernel_shape)
+    x = _preprocess_conv3d_input(x, data_format)
-    if ndim(x) == 4:
+    elif ndim(x) == 4:
-    if ndim(x) == 3:
+    elif ndim(x) == 3:
-            output_shape_tensor,
+            output_shape,
-                    input_shape[3] - self.cropping[1][0] - self.cropping[1][1])
+                    input_shape[2] - self.cropping[0][0] - self.cropping[0][1] if input_shape[2] else None,
-                    input_shape[2] - self.cropping[1][0] - self.cropping[1][1],
+                    input_shape[1] - self.cropping[0][0] - self.cropping[0][1] if input_shape[1] else None,
-def convert_kernel(kernel, data_format=None):
+def convert_kernel(kernel):
-
+    slices[-2:] = no_flip
-      version='1.2.1',
+      version='2.0.0',
-      download_url='https://github.com/fchollet/keras/tarball/1.2.1',
+      download_url='https://github.com/fchollet/keras/tarball/2.0.0',
-from keras.utils.np_utils import convert_kernel
+from keras.utils.conv_utils import convert_kernel
-        # TH kernel shape: (depth, input_depth, rows, cols)
+        # channels_first input shape: (n, input_depth, rows, cols)
-                xval = np.random.random(input_shape)
+            for kernel_shape in [(2, 2, 3, 4), (4, 3, 3, 4)]:
-                xtf = KTF.variable(xval)
+                    xth = KTH.variable(xval)
-                kernel_val = np.random.random(kernel_shape) - 0.5
+                    kernel_val = np.random.random(kernel_shape) - 0.5
-                kernel_tf = KTF.variable(kernel_val)
+                    kernel_th = KTH.variable(convert_kernel(kernel_val))
-                ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, data_format='channels_first'))
+                    zth = KTH.eval(KTH.conv2d(xth, kernel_th, data_format='channels_first'))
-                assert_allclose(zth, ztf, atol=1e-05)
+                    assert zth.shape == ztf.shape
-        kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_last'))
+        kernel_th = KTH.variable(convert_kernel(kernel_val))
-        # test in data_format = th
+        # test in data_format = channels_first
-            for kernel_shape in [(4, 3, 2, 2, 2), (4, 3, 3, 2, 4)]:
+            for kernel_shape in [(2, 2, 2, 3, 4), (3, 2, 4, 3, 4)]:
-                kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_first'))
+                kernel_th = KTH.variable(convert_kernel(kernel_val))
-        # test in data_format = tf
+        # test in data_format = channels_last
-        kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_last'))
+        kernel_th = KTH.variable(convert_kernel(kernel_val))
-                                      strides=(1, 1), border_mode='valid')
+                                      strides=(1, 1), padding='valid')
-                                      strides=(1, 1), border_mode='valid')
+                                      strides=(1, 1), padding='valid')
-                                      strides=(1, 1), border_mode='valid')
+                                      strides=(1, 1), padding='valid')
-                                      strides=(1, 1, 1), border_mode='valid')
+                                      strides=(1, 1, 1), padding='valid')
-                                      strides=(1, 1, 1), border_mode='valid')
+                                      strides=(1, 1, 1), padding='valid')
-                                      strides=(1, 1, 1), border_mode='valid')
+                                      strides=(1, 1, 1), padding='valid')
-        rand = KTF.eval(KTF.random_normal((1000, 1000), mean=mean, std=std))
+        rand = KTF.eval(KTF.random_normal((1000, 1000), mean=mean, stddev=std))
-        rand = KTH.eval(KTH.random_normal((1000, 1000), mean=mean, std=std))
+        rand = KTH.eval(KTH.random_normal((1000, 1000), mean=mean, stddev=std))
-__version__ = '1.2.1'
+__version__ = '1.2.2'
-      version='1.2.1',
+      version='1.2.2',
-      download_url='https://github.com/fchollet/keras/tarball/1.2.1',
+      download_url='https://github.com/fchollet/keras/tarball/1.2.2',
-            corresponds to inputs with shape `(batch, channels, width, height)`.
+            corresponds to inputs with shape
-            corresponds to inputs with shape `(batch, channels, width, height)`.
+            corresponds to inputs with shape
-            corresponds to inputs with shape `(batch, channels, width, height)`.
+            corresponds to inputs with shape
-            is at index 1, in 'channels_last' mode is it at index 3.
+        data_format: A string,
-            is at index 1, in 'channels_last' mode is it at index 4.
+        data_format: A string,
-            is at index 1, in 'channels_last' mode is it at index 3.
+        data_format: A string,
-            is at index 1, in 'channels_last' mode is it at index 4.
+        data_format: A string,
-            is at index 1, in 'channels_last' mode is it at index 3.
+        data_format: A string,
-            is at index 1, in 'channels_last' mode is it at index 4.
+        data_format: A string,
-from ..utils.conv_utils import conv_output_length
+from ..utils import conv_utils
-                 border_mode='valid', **kwargs):
+    def __init__(self, pool_size=2, strides=None,
-        self.border_mode = border_mode
+        if strides is None:
-                                    self.border_mode, self.stride)
+        length = conv_utils.conv_output_length(input_shape[1], self.pool_size,
-                          border_mode, data_format):
+                          padding, data_format):
-    def call(self, x, mask=None):
+    def call(self, x):
-                                        border_mode=self.border_mode,
+                                        padding=self.padding,
-                  'border_mode': self.border_mode}
+        config = {'strides': self.strides,
-        3D tensor with shape: `(samples, steps, features)`.
+        3D tensor with shape: `(batch_size, steps, features)`.
-        border_mode: 'valid' or 'same'.
+        3D tensor with shape: `(batch_size, downsampled_steps, features)`.
-                                           border_mode, **kwargs)
+    def __init__(self, pool_size=2, strides=None,
-                          border_mode, data_format):
+                          padding, data_format):
-                          border_mode, data_format, pool_mode='max')
+                          padding, data_format, pool_mode='max')
-        border_mode: 'valid' or 'same'.
+        pool_size: Integer, size of the max pooling windows.
-        3D tensor with shape: `(samples, steps, features)`.
+        3D tensor with shape: `(batch_size, steps, features)`.
-        3D tensor with shape: `(samples, downsampled_steps, features)`.
+        3D tensor with shape: `(batch_size, downsampled_steps, features)`.
-                                               border_mode, **kwargs)
+    def __init__(self, pool_size=2, strides=None,
-                          border_mode, data_format):
+                          padding, data_format):
-                          border_mode, data_format, pool_mode='avg')
+                          padding, data_format, pool_mode='avg')
-                 data_format='default', **kwargs):
+    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',
-        self.pool_size = tuple(pool_size)
+        data_format = conv_utils.normalize_data_format(data_format)
-        self.data_format = data_format
+            strides = pool_size
-
+        rows = conv_utils.conv_output_length(rows, self.pool_size[0],
-                          border_mode, data_format):
+                          padding, data_format):
-    def call(self, x, mask=None):
+    def call(self, x):
-                                        border_mode=self.border_mode,
+                                        padding=self.padding,
-                  'border_mode': self.border_mode,
+                  'padding': self.padding,
-        pool_size: tuple of 2 integers,
+        pool_size: integer or tuple of 2 integers,
-        strides: tuple of 2 integers, or None. Strides values.
+            (2, 2) will halve the input in both spatial dimension.
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        padding: One of `"valid"` or `"same"` (case-insensitive).
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        `(samples, pooled_rows, pooled_cols, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        super(MaxPooling2D, self).__init__(pool_size, strides, border_mode,
+    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',
-                          border_mode, data_format):
+                          padding, data_format):
-                          border_mode, data_format,
+                          padding, data_format,
-        pool_size: tuple of 2 integers,
+        pool_size: integer or tuple of 2 integers,
-        strides: tuple of 2 integers, or None. Strides values.
+            (2, 2) will halve the input in both spatial dimension.
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        padding: One of `"valid"` or `"same"` (case-insensitive).
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        `(samples, pooled_rows, pooled_cols, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        super(AveragePooling2D, self).__init__(pool_size, strides, border_mode,
+    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',
-                          border_mode, data_format):
+                          padding, data_format):
-                          border_mode, data_format, pool_mode='avg')
+                          padding, data_format, pool_mode='avg')
-                 data_format='default', **kwargs):
+    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',
-        self.data_format = data_format
+            strides = pool_size
-                                      self.border_mode, self.strides[2])
+        len_dim1 = conv_utils.conv_output_length(len_dim1, self.pool_size[0],
-                          border_mode, data_format):
+                          padding, data_format):
-    def call(self, x, mask=None):
+    def call(self, x):
-                                        border_mode=self.border_mode,
+                                        padding=self.padding,
-                  'border_mode': self.border_mode,
+                  'padding': self.padding,
-            (the depth) is at index 1, in 'channels_last' mode is it at index 4.
+        padding: One of `"valid"` or `"same"` (case-insensitive).
-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        super(MaxPooling3D, self).__init__(pool_size, strides, border_mode,
+    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',
-                          border_mode, data_format):
+                          padding, data_format):
-                          border_mode, data_format, pool_mode='max')
+                          padding, data_format, pool_mode='max')
-            (the depth) is at index 1, in 'channels_last' mode is it at index 4.
+        padding: One of `"valid"` or `"same"` (case-insensitive).
-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        super(AveragePooling3D, self).__init__(pool_size, strides, border_mode,
+    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',
-                          border_mode, data_format):
+                          padding, data_format):
-                          border_mode, data_format,
+                          padding, data_format,
-    def call(self, x, mask=None):
+    def call(self, x):
-        3D tensor with shape: `(samples, steps, features)`.
+        3D tensor with shape: `(batch_size, steps, features)`.
-        2D tensor with shape: `(samples, features)`.
+        2D tensor with shape:
-    def call(self, x, mask=None):
+    def call(self, x):
-        3D tensor with shape: `(samples, steps, features)`.
+        3D tensor with shape: `(batch_size, steps, features)`.
-        2D tensor with shape: `(samples, features)`.
+        2D tensor with shape:
-    def call(self, x, mask=None):
+    def call(self, x):
-    def __init__(self, data_format='default', **kwargs):
+    def __init__(self, data_format=None, **kwargs):
-        self.data_format = data_format
+        self.data_format = conv_utils.normalize_data_format(data_format)
-    def call(self, x, mask=None):
+    def call(self, x):
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        data_format: A string,
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        `(nb_samples, channels)`
+        `(batch_size, channels)`
-    def call(self, x, mask=None):
+    def call(self, x):
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        data_format: A string,
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        `(nb_samples, channels)`
+        `(batch_size, channels)`
-    def call(self, x, mask=None):
+    def call(self, x):
-    def __init__(self, data_format='default', **kwargs):
+    def __init__(self, data_format=None, **kwargs):
-        self.data_format = data_format
+        self.data_format = conv_utils.normalize_data_format(data_format)
-    def call(self, x, mask=None):
+    def call(self, x):
-            (the depth) is at index 1, in 'channels_last' mode is it at index 4.
+        data_format: A string,
-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        `(nb_samples, channels)`
+        `(batch_size, channels)`
-    def call(self, x, mask=None):
+    def call(self, x):
-            (the depth) is at index 1, in 'channels_last' mode is it at index 4.
+        data_format: A string,
-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.
+        - If `data_format='channels_last'`:
-        `(nb_samples, channels)`
+        `(batch_size, channels)`
-    def call(self, x, mask=None):
+    def call(self, x):
-def spatial_2d_padding(x, padding=(1, 1), data_format='default'):
+def spatial_2d_padding(x, padding=(1, 1), data_format=None):
-    if data_format == 'default':
+    if data_format is None:
-                                  data_format='default'):
+                                  data_format=None):
-    if data_format == 'default':
+    if data_format is None:
-def spatial_3d_padding(x, padding=(1, 1, 1), data_format='default'):
+def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):
-    if data_format == 'default':
+    if data_format is None:
-            [padding[2], padding[2]]
+            [padding[0][0], padding[0][1]],
-            [padding[2], padding[2]],
+            [padding[0][0], padding[0][1]],
-    return x
+        data_format='NHWC')
-    # data_format NCHW, so we transpose the inputs
+    # data_format NDHWC, so we transpose the inputs
-def spatial_2d_padding(x, padding=(1, 1), data_format='default'):
+def spatial_2d_padding(x, padding=(1, 1), data_format=None):
-    if data_format == 'default':
+    if data_format is None:
-                                  data_format='default'):
+                                  data_format=None):
-    if data_format == 'default':
+    if data_format is None:
-def spatial_3d_padding(x, padding=(1, 1, 1), data_format='default'):
+def spatial_3d_padding(x, padding=(1, 1, 1), data_format=None):
-    if data_format == 'default':
+    if data_format is None:
-            strides,
+            self.strides,
-        output_shape = copy.copy(input_shape)
+        output_shape = list(input_shape)
-        return output_shape
+        return tuple(output_shape)
-        config.pop('dilate_rate')
+        config.pop('dilation_rate')
-                 data_format='channels_last',
+                 data_format=None,
-        self.pointwise_constraint = pointwise_constraint
+        self.depthwise_initializer = initializers.get(depthwise_initializer)
-            rate=self.dilation_rate)
+            dilation_rate=self.dilation_rate)
-        rows = conv_utils.conv_output_length(rows, self.nb_row,
+        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],
-        cols = conv_utils.conv_output_length(cols, self.nb_col,
+        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],
-    def call(self, x, mask=None):
+    def call(self, x):
-        size: int, or tuple of 2 integers. The upsampling factors for rows and columns.
+        size: int, or tuple of 2 integers.
-    def __init__(self, size=(2, 2), data_format='default', **kwargs):
+    def __init__(self, size=(2, 2), data_format=None, **kwargs):
-        self.data_format = data_format
+        self.size = conv_utils.normalize_tuple(size, 2, 'size')
-    def call(self, x, mask=None):
+    def call(self, x):
-    def call(self, x, mask=None):
+    def call(self, x):
-        return K.asymmetric_temporal_padding(x, left_pad=self.left_pad, right_pad=self.right_pad)
+    def call(self, x):
-        if hasattr(padding, '__len__'):
+        elif hasattr(padding, '__len__'):
-                             '((top_pad, bottom_pad), (left_pad, right_pad)).'
+                             '((top_pad, bottom_pad), (left_pad, right_pad)). '
-    def call(self, x, mask=None):
+    def call(self, x):
-                                               right_pad=self.right_pad,
+                                               top_pad=self.padding[0][0],
-        if hasattr(padding, '__len__'):
+        elif hasattr(padding, '__len__'):
-    def call(self, x, mask=None):
+    def call(self, x):
-        if hasattr(cropping, '__len__'):
+        elif hasattr(cropping, '__len__'):
-                             '((top_crop, bottom_crop), (left_crop, right_crop)).'
+                             '((top_crop, bottom_crop), (left_crop, right_crop)). '
-        if hasattr(cropping, '__len__'):
+        elif hasattr(cropping, '__len__'):
-print(len(X_test), 'test sequences')
+(x_train, y_train), (x_test, y_test) = imdb.load_data(nb_words=max_features)
-print('X_test shape:', X_test.shape)
+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
-score, acc = model.evaluate(X_test, y_test,
+model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=15,
-from . import objectives
+from . import losses
-from .utils.generic_utils import get_from_module
+from .utils.generic_utils import deserialize_keras_object
-    return get_from_module(identifier, globals(), 'activation function')
+    if isinstance(identifier, six.string_types):
-
+from collections import defaultdict
-from .common import floatx, _EPSILON, image_data_format, reset_uids
+from .common import floatx, _EPSILON, image_data_format
-    if border_mode == 'same':
+def _preprocess_padding(padding):
-    elif border_mode == 'valid':
+    elif padding == 'valid':
-        raise ValueError('Invalid border mode:', border_mode)
+        raise ValueError('Invalid border mode:', padding)
-           image_shape=None, filter_shape=None):
+def conv1d(x, kernel, stride=1, padding='valid',
-        border_mode: string, `"same"` or `"valid"`.
+        padding: string, `"same"` or `"valid"`.
-        x = tf.cast(x, 'float64')
+    padding = _preprocess_padding(padding)
-           image_shape=None, filter_shape=None, filter_dilation=(1, 1)):
+def conv2d(x, kernel, strides=(1, 1), padding='valid',
-        border_mode: string, `"same"` or `"valid"`.
+        padding: string, `"same"` or `"valid"`.
-    if data_format == 'default':
+    if data_format is None:
-        x = tf.nn.conv2d(x, kernel, strides, padding=padding)
+    padding = _preprocess_padding(padding)
-    return _postprocess_conv2d_output(x, data_format)
+        tf_data_format = 'NCHW'
-             image_shape=None, filter_shape=None):
+def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),
-        border_mode: string, `"same"` or `"valid"`.
+        padding: string, `"same"` or `"valid"`.
-    if data_format == 'default':
+    if data_format is None:
-    padding = _preprocess_border_mode(border_mode)
+    padding = _preprocess_padding(padding)
-    return _postprocess_conv2d_output(x, data_format)
+    x = _postprocess_conv2d_output(x, data_format)
-                     border_mode='valid', data_format='default'):
+                     padding='valid', data_format=None, dilation_rate=(1, 1)):
-    if data_format == 'default':
+    if data_format is None:
-    padding = _preprocess_border_mode(border_mode)
+    padding = _preprocess_padding(padding)
-                               strides, padding)
+                               strides=strides,
-           volume_shape=None, filter_shape=None):
+def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',
-        border_mode: string, `"same"` or `"valid"`.
+        padding: string, `"same"` or `"valid"`.
-    if data_format == 'default':
+    if data_format is None:
-    x = tf.nn.conv3d(x, kernel, strides, padding)
+    padding = _preprocess_padding(padding)
-           border_mode='valid', data_format='default',
+           padding='valid', data_format=None,
-        border_mode: one of `"valid"`, `"same"`.
+        padding: one of `"valid"`, `"same"`.
-    if data_format == 'default':
+    if data_format is None:
-    padding = _preprocess_border_mode(border_mode)
+    padding = _preprocess_padding(padding)
-           data_format='default', pool_mode='max'):
+def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',
-        border_mode: one of `"valid"`, `"same"`.
+        padding: one of `"valid"`, `"same"`.
-    if data_format == 'default':
+    if data_format is None:
-    padding = _preprocess_border_mode(border_mode)
+    padding = _preprocess_padding(padding)
-        kernel = kernel.dimshuffle((3, 2, 0, 1))
+    # As of Keras 2.0.0, all kernels are normalized
-        kernel = kernel.dimshuffle((4, 3, 0, 1, 2))
+    # As of Keras 2.0.0, all kernels are normalized
-        th_border_mode = 'full'
+def _preprocess_padding(padding):
-    return th_border_mode
+        raise ValueError('Border mode not supported:', str(padding))
-                               border_mode, kernel_shape,
+                               padding, kernel_shape,
-    if border_mode == 'same':
+    if padding == 'same':
-                               border_mode, kernel_shape,
+                               padding, kernel_shape,
-    if border_mode == 'same':
+    if padding == 'same':
-           image_shape=None, filter_shape=None):
+def conv1d(x, kernel, stride=1, padding='valid',
-        border_mode: string, "same" or "valid".
+        padding: string, "same" or "valid".
-    raise NotImplementedError
+    if data_format is None:
-           filter_shape=None, filter_dilation=(1, 1)):
+def conv2d(x, kernel, strides=(1, 1), padding='valid',
-        border_mode: string, "same" or "valid".
+        padding: string, "same" or "valid".
-    if data_format == 'default':
+    if data_format is None:
-    th_border_mode = _preprocess_border_mode(border_mode)
+    th_padding = _preprocess_padding(padding)
-    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode,
+    kernel_shape = _preprocess_conv2d_filter_shape(data_format, kernel_shape)
-             image_shape=None, filter_shape=None):
+def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),
-        border_mode: string, "same" or "valid".
+        padding: string, "same" or "valid".
-    if data_format == 'default':
+    if data_format is None:
-    th_border_mode = _preprocess_border_mode(border_mode)
+    th_padding = _preprocess_padding(padding)
-
+    filter_shape = _preprocess_conv2d_filter_shape(data_format, kernel_shape)
-                                                        kshp=filter_shape,
+                                                        kshp=kernel_shape,
-                                                        border_mode=th_border_mode,
+                                                        border_mode=th_padding,
-    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode,
+    conv_out = _postprocess_conv2d_output(conv_out, x, padding,
-                     border_mode='valid', data_format='default'):
+                     padding='valid', data_format=None, dilation_rate=(1, 1)):
-           filter_dilation=(1, 1, 1)):
+           padding='valid', data_format=None,
-        border_mode: string, "same" or "valid".
+        padding: string, "same" or "valid".
-    if data_format == 'default':
+    if data_format is None:
-    th_border_mode = _preprocess_border_mode(border_mode)
+    th_padding = _preprocess_padding(padding)
-    filter_shape = _preprocess_conv3d_filter_shape(data_format, filter_shape)
+    kernel_shape = _preprocess_conv3d_filter_shape(data_format, kernel_shape)
-                             border_mode=th_border_mode,
+                             border_mode=th_padding,
-    conv_out = _postprocess_conv3d_output(conv_out, x, border_mode,
+                             filter_shape=kernel_shape,
-    if data_format == 'default':
+def pool2d(x, pool_size, strides=(1, 1), padding='valid',
-    if border_mode == 'same':
+    if padding == 'same':
-    elif border_mode == 'valid':
+    elif padding == 'valid':
-        raise ValueError('Invalid border mode:', border_mode)
+        raise ValueError('Invalid border mode:', padding)
-                                    mode='max')
+        pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,
-                                    mode='average_exc_pad')
+        pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,
-    if border_mode == 'same':
+    if padding == 'same':
-    if data_format == 'default':
+def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',
-    if border_mode == 'same':
+    if padding == 'same':
-    elif border_mode == 'valid':
+    elif padding == 'valid':
-        raise ValueError('Invalid border mode:', border_mode)
+        raise ValueError('Invalid padding:', padding)
-                                    mode='max')
+        pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,
-                                    mode='average_exc_pad')
+        pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,
-    if border_mode == 'same':
+    if padding == 'same':
-    if data_format == 'default':
+def bias_add(x, bias, data_format=None):
-                                mode='average_exc_pad')
+        raise ValueError('Unknown data_format ' + str(data_format))
-    return pool_out
+        x += bias
-from .utils.generic_utils import get_from_module
+from .utils.generic_utils import serialize_keras_object
-        return p
+    def __call__(self, w):
-        norms = K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True))
+    def __call__(self, w):
-        return p / (K.epsilon() + K.sqrt(K.sum(K.square(p),
+    def __call__(self, w):
-        return p
+    def __call__(self, w):
-unitnorm = UnitNorm
+max_norm = MaxNorm
-                           instantiate=True, kwargs=kwargs)
+def get(identifier):
-def object_list_uid(object_list):
+def _object_list_uid(object_list):
-    """This specifies the ndim, dtype and shape of every input to a layer.
+    """Specifies the ndim, dtype and shape of every input to a layer.
-                    `self.add_inbound_node(last_layer)`
+                    `self._add_inbound_node(last_layer)`
-        add_inbound_node(layer, index=0)
+        _add_inbound_node(layer, index=0)
-            self.uses_learning_phase = False
+        self.input_spec = None
-        # to self.add_inbound_node().
+        # to self._add_inbound_node().
-
+                          'batch_size',
-            name = prefix + '_' + str(K.get_uid(prefix))
+            prefix = self.__class__.__name__
-            # In this case we will create an input layer
+        if 'input_shape' in kwargs or 'batch_input_shape' in kwargs:
-                batch_input_shape = (None,) + tuple(kwargs['input_shape'])
+                if 'batch_size' in kwargs:
-            prefix = self.__class__.__name__.lower() + '_input_'
+            prefix = _to_snake_case(self.__class__.__name__) + '_input_'
-    def call(self, x, mask=None):
+    def call(self, x):
-    def __call__(self, x, mask=None):
+    def __call__(self, x, **kwargs):
-            - We call self.add_inbound_node().
+            - We call self._add_inbound_node().
-                This is done as part of add_inbound_node().
+                This is done as part of _add_inbound_node().
-                This is done as part of add_inbound_node().
+                This is done as part of _add_inbound_node().
-            mask: Tensor or list/tuple of tensors.
+            **kwargs: Additional keyword arguments to be passed to `call()`.
-            outputs = to_list(self.call(x, mask))
+        # Handle mask propagation.
-            self.add_loss(regularization_losses, input_tensors)
+            regularization_losses = [self.activity_regularizer(x) for x in to_list(output)]
-            return outputs
+        return output
-                         node_indices=None, tensor_indices=None):
+    def _add_inbound_node(self, input_tensors, output_tensors,
-                (as a list).
+        TODO
-                self.build(input_shape=input_shapes[0])
+        input_tensors = to_list(input_tensors)
-        Node.create_node(self, inbound_layers, node_indices, tensor_indices)
+                raise ValueError('Input tensor is not a Keras tensor:', x)
-        if not hasattr(self, 'supports_masking') or not self.supports_masking:
+        if not self.supports_masking:
-                                         str(input_mask))
+                        raise TypeError('Layer ' + self.name +
-                                     str(input_mask))
+                    raise TypeError('Layer ' + self.name +
-                                 'Use `get_input_mask_at(node_index)` instead.')
+                                 'Use `get_input_mask_at(node_index)` '
-            inputs_hash = object_list_uid(inputs)
+            inputs_hash = _object_list_uid(inputs)
-            inputs_hash = object_list_uid(inputs)
+            inputs_hash = _object_list_uid(inputs)
-            inputs_hash = object_list_uid(inputs)
+            inputs_hash = _object_list_uid(inputs)
-            inputs_hash = object_list_uid(inputs)
+            inputs_hash = _object_list_uid(inputs)
-        as a list of numpy arrays.
+        """Returns the current weights of the layer.
-        """Returns a Python dictionary (serializable)
+        """Returns the config of the layer.
-        by Container (one layer of abstraction above).
+        by `Container` (one layer of abstraction above).
-        """This method is the reverse of get_config,
+        """Creates a layer from its config.
-        composing the weights of the layer.
+        """Count the total number of scalars composing the weights.
-        self.supports_masking = False
+        # TODO: call parent's __init__ instead.
-            self.add_inbound_node(layers, node_indices, tensor_indices)
+            self._add_inbound_node(layers, node_indices, tensor_indices)
-    def call(self, inputs, mask=None):
+    def call(self, inputs):
-    def __call__(self, inputs, mask=None):
+    def __call__(self, inputs, **kwargs):
-            self.add_inbound_node(layers, node_indices, tensor_indices)
+            self._add_inbound_node(layers, node_indices, tensor_indices)
-            return self.call(inputs, mask)
+            return self.masked_call(inputs, **kwargs)
-        supports_masking (boolean)
+        # TODO: call parent's __init__ instead.
-        self.supports_masking = False
+
-                                                            computed_mask))
+                        output_tensors = to_list(layer.masked_call(computed_tensor,
-                                                            computed_masks))
+                        output_tensors = to_list(layer.masked_call(computed_tensors,
-from .. import objectives
+from .. import losses
-                See [objectives](/objectives).
+                See [losses](/losses).
-                on each output by passing a dictionary or a list of objectives.
+                on each output by passing a dictionary or a list of losses.
-                loss_functions.append(objectives.get(loss[name]))
+                loss_functions.append(losses.get(loss[name]))
-            loss_functions = [objectives.get(l) for l in loss]
+            loss_functions = [losses.get(l) for l in loss]
-            loss_function = objectives.get(loss)
+            loss_function = losses.get(loss)
-                    if output_shape[-1] == 1 or self.loss_functions[i] == objectives.binary_crossentropy:
+                    if output_shape[-1] == 1 or self.loss_functions[i] == losses.binary_crossentropy:
-                    elif self.loss_functions[i] == objectives.sparse_categorical_crossentropy:
+                    elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:
-            elif getattr(objectives, loss_fn.__name__, None) is None:
+            elif getattr(losses, loss_fn.__name__, None) is None:
-from .utils.generic_utils import get_from_module
+from .utils.generic_utils import serialize_keras_object
-                           'initializer', instantiate=True, kwargs=kwargs)
+def serialize(initializer):
-from ..utils.np_utils import conv_input_length
+from ..utils import conv_utils
-    """Convolution operator for filtering neighborhoods of 1-D inputs.
+class _Conv(Layer):
-    ```
+    This layer creates a convolution kernel that is convolved
-            or alternatively, elementwise Theano function.
+        rank: An integer, the rank of the convolution,
-        `steps` value might have changed due to padding.
+            (ie. "linear" activation: `a(x) = x`).
-                 W_regularizer=None, b_regularizer=None,
+    def __init__(self, rank,
-        self.init = initializers.get(init, data_format='channels_last')
+                 kernel_constraint=None,
-        self.b_regularizer = regularizers.get(b_regularizer)
+        self.use_bias = use_bias
-        super(Convolution1D, self).__init__(**kwargs)
+        self.kernel_constraint = constraints.get(kernel_constraint)
-                                     constraint=self.b_constraint)
+        if len(input_shape) != self.rank + 2:
-        self.built = True
+            channel_axis = -1
-        return output
+        if self.data_format == 'channels_last':
-        base_config = super(Convolution1D, self).get_config()
+        config = {
-    """Atrous Convolution operator for filtering neighborhoods of 1-D inputs.
+class Conv1D(_Conv):
-    of 10 vectors of 128-dimensional vectors).
+    This layer creates a convolution kernel that is convolved
-    ```
+    When using this layer as the first layer in a model,
-            or alternatively, elementwise Theano function.
+        filters: Integer, the dimensionality of the output space
-            (without it, the shape of the dense outputs cannot be computed).
+            (ie. "linear" activation: `a(x) = x`).
-        3D tensor with shape: `(samples, steps, input_dim)`.
+        3D tensor with shape: `(batch_size, steps, input_dim)`
-        `steps` value might have changed due to padding.
+        3D tensor with shape: `(batch_size, new_steps, nb_filter)`
-                 W_regularizer=None, b_regularizer=None,
+    def __init__(self, filters,
-            W_regularizer=W_regularizer, b_regularizer=b_regularizer,
+                 kernel_constraint=None,
-        return output
+            kernel_constraint=kernel_constraint,
-        return dict(list(base_config.items()) + list(config.items()))
+        config = super(Conv1D, self).get_config()
-    """Convolution operator for filtering windows of two-dimensional inputs.
+    This layer creates a convolution kernel that is convolved
-    ```
+    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        filters: Integer, the dimensionality of the output space
-            (i.e. make the layer affine rather than linear).
+        dilation_rate: an integer or tuple/list of 2 integers, specifying
-                 W_regularizer=None, b_regularizer=None,
+    def __init__(self, filters,
-        self.bias = bias
+                 kernel_constraint=None,
-        return dict(list(base_config.items()) + list(config.items()))
+        config = super(Conv2D, self).get_config()
-    """Transposed convolution operator for filtering windows of 2-D inputs.
+class Conv3D(_Conv):
-    that is compatible with said convolution.
+    This layer creates a convolution kernel that is convolved
-    ```
+    e.g. `input_shape=(128, 128, 128, 3)` for 128x128x128 volumes
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        filters: Integer, the dimensionality of the output space
-            (i.e. make the layer affine rather than linear).
+        dilation_rate: an integer or tuple/list of 3 integers, specifying
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        5D tensor with shape:
-        - [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)
+        5D tensor with shape:
-        return output
+    def __init__(self, filters,
-        return dict(list(base_config.items()) + list(config.items()))
+        config = super(Conv3D, self).get_config()
-    """Atrous Convolution operator for filtering windows of 2-D inputs.
+class Conv2DTranspose(Conv2D):
-    ```
+    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        filters: Integer, the dimensionality of the output space
-            (i.e. make the layer affine rather than linear).
+        dilation_rate: an integer or tuple/list of 2 integers, specifying
-        `(samples, channels, rows, cols)` if data_format='channels_first'
+        `(batch, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        `(batch, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
+        `(batch, nb_filter, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
+        `(batch, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
-        - [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122)
+        - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)
-                 W_regularizer=None, b_regularizer=None,
+    def __init__(self, filters,
-                                                  **kwargs)
+                 kernel_constraint=None,
-    def get_output_shape_for(self, input_shape):
+    def build(self, input_shape):
-            cols = input_shape[2]
+            channel_axis = 1
-                                  dilation=self.atrous_rate[1])
+            channel_axis = -1
-            return (input_shape[0], rows, cols, self.nb_filter)
+            c_axis, h_axis, w_axis = 1, 2, 3
-        return output
+            outputs = K.bias_add(
-        return dict(list(base_config.items()) + list(config.items()))
+        config = super(Conv2DTranspose, self).get_config()
-    """Separable convolution operator for 2D inputs.
+class SeparableConv2D(Conv2D):
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        filters: Integer, the dimensionality of the output space
-            (i.e. make the layer affine rather than linear).
+        dilation_rate: an integer or tuple/list of 2 integers, specifying
-        `(samples, channels, rows, cols)` if data_format='channels_first'
+        `(batch, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        `(batch, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
+        `(batch, nb_filter, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
+        `(batch, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
-        self.subsample = tuple(subsample)
+    def __init__(self, filters,
-        super(SeparableConvolution2D, self).__init__(**kwargs)
+        self.depthwise_initializer = depthwise_initializer
-            pointwise_shape = (1, 1, self.depth_multiplier * stack_size, self.nb_filter)
+            channel_axis = 1
-            raise ValueError('Invalid data_format:', self.data_format)
+            channel_axis = 3
-            self.b = None
+            outputs = K.bias_add(
-        self.built = True
+        if self.activation is not None:
-    def get_output_shape_for(self, input_shape):
+        rows = conv_utils.conv_output_length(rows, self.nb_row,
-            conv_dim3 = input_shape[4]
+            return (input_shape[0], self.filters, rows, cols)
-        return output
+            return (input_shape[0], rows, cols, self.filters)
-        return dict(list(base_config.items()) + list(config.items()))
+        config = super(SeparableConv2D, self).get_config()
-    Repeats each temporal step `length` times along the time axis.
+    Repeats each temporal step `size` times along the time axis.
-        length: integer. Upsampling factor.
+        size: integer. Upsampling factor.
-        3D tensor with shape: `(samples, steps, features)`.
+        3D tensor with shape: `(batch, steps, features)`.
-        3D tensor with shape: `(samples, upsampled_steps, features)`.
+        3D tensor with shape: `(batch, upsampled_steps, features)`.
-        self.input_spec = [InputSpec(ndim=3)]
+    def __init__(self, size=2, **kwargs):
-        return (input_shape[0], length, input_shape[2])
+        size = self.size * input_shape[1] if input_shape[1] is not None else None
-        output = K.repeat_elements(x, self.length, axis=1)
+        output = K.repeat_elements(x, self.size, axis=1)
-        config = {'length': self.length}
+        config = {'size': self.size}
-        size: tuple of 2 integers. The upsampling factors for rows and columns.
+        size: int, or tuple of 2 integers. The upsampling factors for rows and columns.
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        - If `data_format` is `"channels_last"`:
-        `(samples, upsampled_rows, upsampled_cols, channels)` if data_format='channels_last'.
+        - If `data_format` is `"channels_last"`:
-            raise ValueError('data_format must be in {"channels_last", "channels_first"}.')
+        super(UpSampling2D, self).__init__(**kwargs)
-        size: tuple of 3 integers. The upsampling factors for dim1, dim2 and dim3.
+        size: int, or tuple of 3 integers.
-        `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.
+        - If `data_format` is `"channels_last"`:
-        `(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)` if data_format='channels_last'.
+        - If `data_format` is `"channels_last"`:
-        self.data_format = data_format
+    def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):
-            - If tuple of int (length 2)
+            - If tuple of int (length 2):
-            If any key is missing, default value of 0 will be used for the missing key.
+            the padding dimension (`(left_pad, right_pad)`).
-        3D tensor with shape `(samples, axis_to_pad, features)`
+        3D tensor with shape `(batch, axis_to_pad, features)`
-        3D tensor with shape `(samples, padded_axis, features)`
+        3D tensor with shape `(batch, padded_axis, features)`
-            self.right_pad = padding[1]
+        self.padding = conv_utils.normalize_tuple(padding, 2, 'padding')
-            If any key is missing, default value of 0 will be used for the missing key.
+        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.
-        `(samples, rows, cols, channels)` if data_format='channels_last'.
+        - If `data_format` is `"channels_last"`:
-        `(samples, padded_rows, padded_cols, channels)` if data_format='channels_last'.
+        - If `data_format` is `"channels_last"`:
-                 data_format='default',
+                 data_format=None,
-                                 'Found: ' + str(padding.keys()))
+        self.data_format = conv_utils.normalize_data_format(data_format)
-        self.data_format = data_format
+            raise ValueError('`padding` should be either an int, '
-            cols = input_shape[3] + self.left_pad + self.right_pad if input_shape[3] is not None else None
+            rows = input_shape[2] + self.padding[0][0] + self.padding[0][1] if input_shape[2] is not None else None
-            cols = input_shape[2] + self.left_pad + self.right_pad if input_shape[2] is not None else None
+            rows = input_shape[1] + self.padding[0][0] + self.padding[0][1] if input_shape[1] is not None else None
-            Currently only symmetric padding is supported.
+        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.
-        `(samples, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)`
+        - If `data_format` is `"channels_last"`:
-        `(samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)`
+        - If `data_format` is `"channels_last"`:
-    def __init__(self, padding=(1, 1, 1), data_format='default', **kwargs):
+    def __init__(self, padding=(1, 1, 1), data_format=None, **kwargs):
-        self.data_format = data_format
+        self.data_format = conv_utils.normalize_data_format(data_format)
-            dim3 = input_shape[4] + 2 * self.padding[2] if input_shape[4] is not None else None
+            dim1 = input_shape[2] + 2 * self.padding[0][0] if input_shape[2] is not None else None
-            dim3 = input_shape[3] + 2 * self.padding[2] if input_shape[3] is not None else None
+            dim1 = input_shape[1] + 2 * self.padding[0][1] if input_shape[1] is not None else None
-        cropping: tuple of int (length 2)
+        cropping: int or tuple of int (length 2)
-        3D tensor with shape `(samples, axis_to_crop, features)`
+        3D tensor with shape `(batch, axis_to_crop, features)`
-        3D tensor with shape `(samples, cropped_axis, features)`
+        3D tensor with shape `(batch, cropped_axis, features)`
-            raise ValueError('`cropping` must be a tuple length of 2.')
+        self.cropping = conv_utils.normalize_tuple(cropping, 2, 'cropping')
-    def call(self, x, mask=None):
+    def call(self, x):
-            the 2 cropping dimensions (width, height).
+        cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.
-        `(samples, depth, first_axis_to_crop, second_axis_to_crop)`
+        - If `data_format` is `"channels_last"`:
-        `(samples, depth, first_cropped_axis, second_cropped_axis)`
+        - If `data_format` is `"channels_last"`:
-        model.add(Convolution2D(64, 3, 3, border_mode='same))
+        model.add(Cropping2D(cropping=((2, 2), (4, 4)),
-
+        # now model.output_shape == (None, 20, 16. 64)
-    def __init__(self, cropping=((0, 0), (0, 0)), data_format='default', **kwargs):
+    def __init__(self, cropping=((0, 0), (0, 0)),
-        self.data_format = data_format
+        self.data_format = conv_utils.normalize_data_format(data_format)
-    def call(self, x, mask=None):
+    def call(self, x):
-            the 3 cropping dimensions (kernel_dim1, kernel_dim2, kernerl_dim3).
+        cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.
-        `(samples, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)`
+        - If `data_format` is `"channels_last"`:
-
+        - If `data_format` is `"channels_last"`:
-                 data_format='default', **kwargs):
+                 data_format=None, **kwargs):
-        self.data_format = data_format
+        self.data_format = conv_utils.normalize_data_format(data_format)
-    def call(self, x, mask=None):
+    def call(self, x):
-from ..utils.np_utils import conv_output_length
+from ..utils.conv_utils import conv_output_length
-
+        kwargs['nb_filter'] = nb_filter
-                  'forget_bias_init': self.forget_bias_init.__name__,
+                  'init': initializers.get_config(self.init),
-from ..utils.generic_utils import get_from_module
+        super(Masking, self).__init__(**kwargs)
-        p: float between 0 and 1. Fraction of the input units to drop.
+        rate: float between 0 and 1. Fraction of the input units to drop.
-            For instance, if your inputs ahve shape
+            For instance, if your inputs have shape
-        self.p = p
+    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):
-        if 0. < self.p < 1.:
+        if 0. < self.rate < 1.:
-        if 0. < self.p < 1.:
+        if 0. < self.rate < 1.:
-                return K.dropout(x, self.p, noise_shape, seed=self.seed)
+                return K.dropout(x, self.rate, noise_shape, seed=self.seed)
-        config = {'p': self.p}
+        config = {'rate': self.rate}
-        super(SpatialDropout1D, self).__init__(p, **kwargs)
+    def __init__(self, rate, **kwargs):
-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.
+        rate: float between 0 and 1. Fraction of the input units to drop.
-        if data_format == 'default':
+    def __init__(self, rate, data_format=None, **kwargs):
-        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {"channels_last", "channels_first"}'
+        if data_format not in {'channels_last', 'channels_first'}:
-        p: float between 0 and 1. Fraction of the input units to drop.
+        rate: float between 0 and 1. Fraction of the input units to drop.
-        if data_format == 'default':
+    def __init__(self, rate, data_format=None, **kwargs):
-        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {"channels_last", "channels_first"}'
+        if data_format not in {'channels_last', 'channels_first'}:
-        super(SpatialDropout3D, self).__init__(p, **kwargs)
+        super(Activation, self).__init__(**kwargs)
-        config = {'activation': self.activation.__name__}
+        config = {'activation': activations.serialize(self.activation)}
-        self.dims = tuple(dims)
+        self.dims = tuple(dims)
-        self.input_spec = [InputSpec(ndim='3+')]
+        self.input_spec = [InputSpec(ndim='3+')]
-    """Used for evaluating an arbitrary expressions on an input.
+    """Wraps arbitrary expression as a `Layer` object.
-        Specified by `output_shape` argument.
+        Specified by `output_shape` argument
-        super(Lambda, self).__init__(**kwargs)
+    `Dense` implements the operation:
-        model.add(Dense(32, input_dim=16))
+        model.add(Dense(32, input_shape=(16,)))
-            or alternatively, elementwise Theano function.
+        units: Positive interger, dimensionality of the output space.
-            is required when using this layer as the first layer in a model.
+            (ie. "linear" activation: `a(x) = x`).
-        nD tensor with shape: `(nb_samples, ..., input_dim)`.
+        nD tensor with shape: `(batch_size, ..., input_dim)`.
-        a 2D input with shape `(nb_samples, input_dim)`.
+        a 2D input with shape `(batch_size, input_dim)`.
-        the output would have shape `(nb_samples, output_dim)`.
+        nD tensor with shape: `(batch_size, ..., units)`.
-        self.init = initializers.get(init)
+    def __init__(self, units,
-        self.b_regularizer = regularizers.get(b_regularizer)
+        self.use_bias = use_bias
-        self.initial_weights = weights
+        self.kernel_constraint = constraints.get(kernel_constraint)
-        super(Dense, self).__init__(**kwargs)
+        self.supports_masking = True
-        self.input_dim = input_dim
+        # TODO: check last dim in input_dim
-                                     constraint=self.b_constraint)
+        self.kernel = self.add_weight((input_dim, self.units),
-        return self.activation(output)
+            self.bias = None
-        assert input_shape[-1] and input_shape[-1] == self.input_dim
+        assert input_shape[-1]
-        output_shape[-1] = self.output_dim
+        output_shape[-1] = self.units
-                  'input_dim': self.input_dim}
+        config = {
-          (eg. maxnorm, nonneg), applied to the embedding matrix.
+      embeddings_initializer: Initializer for the `embeddings` matrix
-          variable length input. If this is `True` then all subsequent layers
+          This is useful when using [recurrent layers](recurrent.md)
-          used in the vocabulary (input_dim should equal |vocabulary| + 2).
+          used in the vocabulary (input_dim should equal `|vocabulary| + 2`).
-        2D tensor with shape: `(nb_samples, sequence_length)`.
+        2D tensor with shape: `(batch_size, sequence_length)`.
-        3D tensor with shape: `(nb_samples, sequence_length, output_dim)`.
+        3D tensor with shape: `(batch_size, sequence_length, output_dim)`.
-                 W_constraint=None,
+                 embeddings_initializer='uniform',
-                 weights=None, dropout=0., **kwargs):
+                 input_length=None,
-        self.W_regularizer = regularizers.get(W_regularizer)
+        self.embeddings_initializer = initializers.get(embeddings_initializer)
-        super(Embedding, self).__init__(**kwargs)
+        self.embeddings_constraint = constraints.get(embeddings_constraint)
-        self.built = True
+        self.embeddings = self.add_weight(
-        out = K.gather(W, x)
+        out = K.gather(self.embeddings, x)
-                  'input_length': self.input_length,
+                  'embeddings_initializer': initializers.serialize(self.embeddings_initializer),
-                  'dropout': self.dropout}
+                  'input_length': self.input_length}
-from ..utils.np_utils import conv_output_length
+from ..utils.conv_utils import conv_output_length
-                  'init': self.init.__name__,
+                  'init': initializers.get_config(self.init),
-                  'init': self.init.__name__,
+                  'init': initializers.get_config(self.init),
-from ..utils.np_utils import conv_output_length
+from ..utils.conv_utils import conv_output_length
-        super(Recurrent, self).__init__(**kwargs)
+        super(SimpleRNN, self).__init__(**kwargs)
-                  'inner_init': self.inner_init.__name__,
+                  'init': initializers.get_config(self.init),
-                  'inner_init': self.inner_init.__name__,
+                  'init': initializers.get_config(self.init),
-                  'forget_bias_init': self.forget_bias_init.__name__,
+                  'init': initializers.get_config(self.init),
-
+import six
-from .utils.generic_utils import get_from_module
+from .utils.generic_utils import deserialize_keras_object
-    return get_from_module(identifier, globals(), 'objective')
+    if isinstance(identifier, six.string_types):
-from .utils.generic_utils import get_from_module
+from .utils.generic_utils import deserialize_keras_object
-    return get_from_module(identifier, globals(), 'metric')
+    if isinstance(identifier, six.string_types):
-                                      custom_objects=custom_objects)
+    optimizer = optimizers.deserialize(optimizer_config,
-
+import six
-from .utils.generic_utils import get_from_module, get_custom_objects
+from .utils.generic_utils import serialize_keras_object
-def get(identifier, kwargs=None):
+def serialize(optimizer):
-                           instantiate=True, kwargs=kwargs)
+    if isinstance(identifier, dict):
-from .utils.generic_utils import get_from_module
+from .utils.generic_utils import serialize_keras_object
-                'l1': float(self.l1),
+        return {'l1': float(self.l1),
-def l1l2(l1=0.01, l2=0.01):
+def l1_l2(l1=0.01, l2=0.01):
-                           instantiate=True, kwargs=kwargs)
+def serialize(regularizer):
-            return res(**kwargs)
+def serialize_keras_object(instance):
-            return res(**identifier)
+            module_objects = module_objects or {}
-    return identifier
+            # Then `cls` may be a function returning a class.
-from .np_utils import convert_kernel
+from .generic_utils import get_custom_objects
-        return layer_class.from_config(config['config'])
+    # TODO: rename to "deserialize" and move to "layers.__init__.py"
-    _convolution_border_modes = ['valid', 'same', 'full']
+    _convolution_paddings = ['valid', 'same', 'full']
-    _convolution_border_modes = ['valid', 'same']
+    _convolution_paddings = ['valid', 'same']
-    nb_steps = 8
+def test_conv_1d():
-    nb_filter = 3
+    kernel_size = 3
-            if border_mode == 'same' and subsample_length != 1:
+    for padding in _convolution_paddings:
-                               'b_regularizer': 'l2',
+            layer_test(convolutional.Conv1D,
-                           input_shape=(nb_samples, nb_steps, input_dim))
+                               'strides': strides},
-    for border_mode in ['valid', 'same']:
+    for padding in ['valid', 'same']:
-                               'border_mode': border_mode},
+                               'padding': padding},
-                           'border_mode': 'valid'},
+                           'padding': 'valid'},
-    nb_filter = 2
+    filters = 2
-    for border_mode in _convolution_border_modes:
+    for padding in _convolution_paddings:
-            if border_mode == 'same' and subsample != (1, 1):
+            if padding == 'same' and subsample != (1, 1):
-                       kwargs={'nb_filter': nb_filter,
+                       kwargs={'filters': filters,
-                               'border_mode': border_mode,
+                               'padding': padding,
-                       kwargs={'nb_filter': nb_filter,
+                       kwargs={'filters': filters,
-                               'border_mode': border_mode,
+                               'padding': padding,
-    nb_filter = 2
+    filters = 2
-        for border_mode in _convolution_border_modes:
+        for padding in _convolution_paddings:
-                if border_mode == 'same' and subsample != (1, 1):
+                if padding == 'same' and subsample != (1, 1):
-                cols = conv_input_length(nb_col, 3, border_mode, subsample[1])
+                rows = conv_input_length(nb_row, 3, padding, subsample[0])
-                           kwargs={'nb_filter': nb_filter,
+                           kwargs={'filters': filters,
-                                   'border_mode': border_mode,
+                                   'output_shape': (batch_size, filters, rows, cols),
-                           kwargs={'nb_filter': nb_filter,
+                           kwargs={'filters': filters,
-                                   'border_mode': border_mode,
+                                   'output_shape': (batch_size, filters, rows, cols),
-    nb_filter = 2
+    filters = 2
-    for border_mode in _convolution_border_modes:
+    for padding in _convolution_paddings:
-                if border_mode == 'same' and subsample != (1, 1):
+                if padding == 'same' and subsample != (1, 1):
-                           kwargs={'nb_filter': nb_filter,
+                           kwargs={'filters': filters,
-                                   'border_mode': border_mode,
+                                   'padding': padding,
-                           kwargs={'nb_filter': nb_filter,
+                           kwargs={'filters': filters,
-                                   'border_mode': border_mode,
+                                   'padding': padding,
-    nb_filter = 6
+    filters = 6
-    for border_mode in _convolution_border_modes:
+    for padding in _convolution_paddings:
-                if border_mode == 'same' and subsample != (1, 1):
+                if padding == 'same' and subsample != (1, 1):
-                           kwargs={'nb_filter': nb_filter,
+                           kwargs={'filters': filters,
-                                   'border_mode': border_mode,
+                                   'padding': padding,
-                           kwargs={'nb_filter': nb_filter,
+                           kwargs={'filters': filters,
-                                   'border_mode': border_mode,
+                                   'padding': padding,
-                           'border_mode': 'valid',
+                           'padding': 'valid',
-    for border_mode in ['valid', 'same']:
+    for padding in ['valid', 'same']:
-                                   'border_mode': border_mode,
+                                   'padding': padding,
-    nb_filter = 2
+    filters = 2
-    for border_mode in _convolution_border_modes:
+    for padding in _convolution_paddings:
-            if border_mode == 'same' and subsample != (1, 1, 1):
+            if padding == 'same' and subsample != (1, 1, 1):
-                       kwargs={'nb_filter': nb_filter,
+                       kwargs={'filters': filters,
-                               'border_mode': border_mode,
+                               'padding': padding,
-                       kwargs={'nb_filter': nb_filter,
+                       kwargs={'filters': filters,
-                               'border_mode': border_mode,
+                               'padding': padding,
-                           'border_mode': 'valid',
+                           'padding': 'valid',
-                           'border_mode': 'valid',
+                           'padding': 'valid',
-    model.add(Dense(2, input_dim=3))
+    model.add(Dense(2, input_shape=(3,)))
-    model.add(Dense(2, input_dim=3))
+    model.add(Dense(2, input_shape=(3,)))
-    model.add(Dense(2, input_dim=3))
+    model.add(Dense(2, input_shape=(3,)))
-    model.add(Dense(2, input_dim=3))
+    model.add(Dense(2, input_shape=(3,)))
-    model.add(Dense(2, input_dim=3, name="rick"))
+    model.add(Dense(2, input_shape=(3,), name="rick"))
-    model.add(Dense(2, input_dim=3, name="rick"))
+    model.add(Dense(2, input_shape=(3,), name="rick"))
-    model.add(Dense(2, input_dim=3, name="rick"))
+    model.add(Dense(2, input_shape=(3,), name="rick"))
-                  (n_sample + n_sample_wanted) / 2]
+        src = src[(n_sample - n_sample_wanted) // 2:
-        raise ImportError('The use of `save_array` requires '
+        raise ImportError('The use of `load_array` requires '
-            out = tf.reduce_sum(tf.mul(x, y), axes[0])
+        if tf_major_version >= 1:
-            out = tf.reduce_sum(tf.mul(tf.transpose(x, [1, 0]), y), axes[1])
+            if axes[0] == axes[1]:
-def _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel, strides, dim_ordering):
+def _postprocess_conv2d_output(conv_out, x, border_mode, kernel_shape, strides, dim_ordering):
-        if np_kernel.shape[2] % 2 == 0:
+        if kernel_shape[2] % 2 == 0:
-        if np_kernel.shape[3] % 2 == 0:
+        if kernel_shape[3] % 2 == 0:
-def _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel, strides, dim_ordering):
+def _postprocess_conv3d_output(conv_out, x, border_mode, kernel_shape, strides, dim_ordering):
-        if np_kernel.shape[2] % 2 == 0:
+        if kernel_shape[2] % 2 == 0:
-        if np_kernel.shape[3] % 2 == 0:
+        if kernel_shape[3] % 2 == 0:
-        if np_kernel.shape[4] % 2 == 0:
+        if kernel_shape[4] % 2 == 0:
-    np_kernel = kernel.eval()
+
-                                          strides, dim_ordering)
+    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode,
-    np_kernel = kernel.eval()
+
-                                          strides, dim_ordering)
+    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode,
-    np_kernel = kernel.eval()
+
-                                          strides, dim_ordering)
+    conv_out = _postprocess_conv3d_output(conv_out, x, border_mode,
-    def __init__(self, target, width=30, verbose=1, interval=0.01):
+    def __init__(self, target, width=30, verbose=1, interval=0.05):
-                                 str(data.keys()))
+                                 str(names))
-        self.forward_layer = layer
+        self.forward_layer = copy.copy(layer)
-X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
+
-                            input_shape=(1, img_rows, img_cols)))
+                            input_shape=input_shape))
-from keras.engine import InputSpec
+from .. import backend as K
-    x = np.asarray(x)
+    x = np.asarray(x, dtype=K.floatx())
-        A 3D Numpy array (float32).
+        A 3D Numpy array.
-    x = np.asarray(img, dtype='float32')
+    x = np.asarray(img, dtype=K.floatx())
-        x = np.asarray(x)
+        x = np.asarray(x, dtype=K.floatx())
-            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]))
+            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]), dtype=K.floatx())
-        self.x = np.asarray(x)
+        self.x = np.asarray(x, dtype=K.floatx())
-        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]))
+        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())
-            x = self.image_data_generator.random_transform(x.astype('float32'))
+            x = self.image_data_generator.random_transform(x.astype(K.floatx()))
-        batch_x = np.zeros((current_batch_size,) + self.image_shape)
+        batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())
-            batch_y = self.classes[index_array].astype('float32')
+            batch_y = self.classes[index_array].astype(K.floatx())
-            batch_y = np.zeros((len(batch_x), self.nb_class), dtype='float32')
+            batch_y = np.zeros((len(batch_x), self.nb_class), dtype=K.floatx())
-                          volume_shape=input_shape,
+# These two integers contain the tensorflow version for coping with API breaks.
-                            shape=sparse_coo.shape)
+        if tf_major_version >= 1:
-            return tf.concat(axis, [to_dense(x) for x in tensors])
+        if tf_major_version >= 1:
-                     for st in decoded]
+    if tf_major_version >= 1:
-        return x
+        if callable(x):
-        return alt
+        if callable(alt):
-        return alt
+        if callable(alt):
-        return x
+        if callable(x):
-        return alt
+    if _LEARNING_PHASE is 1:
-        return x
+    if _LEARNING_PHASE is 1:
-            out = tf.batch_matmul(x, y, adj_x=adj_x, adj_y=adj_y)
+    if ndim(x) == 2 and ndim(y) == 2:
-        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)
+        if axes is not None:
-            xy_batch_dot = KTF.batch_dot(x_batch, y_batch, axes=1)
+        x_batch = KTF.ones(shape=(32, 20))
-from keras.layers.core import Dense, Activation, Merge, Lambda, Reshape
+from keras.layers.core import Dense, Activation, Merge, Lambda
-embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))
+embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))
-    if i > MAX_NB_WORDS:
+    if i >= MAX_NB_WORDS:
-embedding_layer = Embedding(nb_words + 1,
+embedding_layer = Embedding(nb_words,
-    Given a set of characters:
+    """Given a set of characters:
-    '''
+    """
-    def __init__(self, chars, maxlen):
+        # Arguments
-        X = np.zeros((maxlen, len(self.chars)))
+    def encode(self, C, num_rows):
-# Parameters for the model and dataset
+# Parameters for the model and dataset.
-LAYERS = 1
+
-ctable = CharacterTable(chars, MAXLEN)
+ctable = CharacterTable(chars)
-    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))
+    f = lambda: int(''.join(np.random.choice(list('0123456789'))
-    # Also skip any such that X+Y == Y+X (hence the sorting)
+    # Also skip any such that X+Y == Y+X (hence the sorting).
-    # Pad the data with spaces such that it is always MAXLEN
+    # Pad the data with spaces such that it is always MAXLEN.
-    # Answers can be of maximum size DIGITS + 1
+    # Answers can be of maximum size DIGITS + 1.
-    X[i] = ctable.encode(sentence, maxlen=MAXLEN)
+    X[i] = ctable.encode(sentence, MAXLEN)
-    y[i] = ctable.encode(sentence, maxlen=DIGITS + 1)
+    y[i] = ctable.encode(sentence, DIGITS + 1)
-# Shuffle (X, y) in unison as the later parts of X will almost all be larger digits
+# Shuffle (X, y) in unison as the later parts of X will almost all be larger
-# Explicitly set apart 10% for validation data that we never train over
+# Explicitly set apart 10% for validation data that we never train over.
-# note: in a situation where your input sequences have a variable length,
+# "Encode" the input sequence using an RNN, producing an output of HIDDEN_SIZE.
-# For the decoder's input, we repeat the encoded input for each time step
+# As the decoder RNN's input, repeatedly provide with the last hidden state of
-# The decoder RNN could be multiple layers stacked or a single layer
+# The decoder RNN could be multiple layers stacked or a single layer.
-# For each of step of the output sequence, decide which character should be chosen
+# Apply a dense layer to the every temporal slice of an input. For each of step
-
+model.summary()
-# Train the model each generation and show predictions against the validation dataset
+# Train the model each generation and show predictions against the validation
-    # Select 10 samples from the validation set at random so we can visualize errors
+    # Select 10 samples from the validation set at random so we can visualize
-        print(colors.ok + 'â' + colors.close if correct == guess else colors.fail + 'â' + colors.close, guess)
+        if correct == guess:
-                   (x - abs(x)) * 0.5)
+                   (x - K.abs(x)) * 0.5)
-            neg = self.alphas * (x - abs(x)) * 0.5
+            neg = self.alphas * (x - K.abs(x)) * 0.5
-        self.t_right_actual = self.t_left + abs(self.t_right)
+        self.t_right_actual = self.t_left + K.abs(self.t_right)
-        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>    
+        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>
-        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>    ```
+        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>    
-            can use this boolean flag to unroll the RNN.
+        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).
-        unroll: whether to unroll the RNN or to use a symbolic loop (`scan`).
+        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).
-                raise
+                raise ValueError('When passing validation_data, '
-                    self.append_header = bool(len(f.readline()))
+                    self.append_header = not bool(len(f.readline()))
-                                         fieldnames=['epoch'] + self.keys)
+                                         fieldnames=['epoch'] + self.keys, dialect=CustomDialect)
-img_width = 600
+img_width = 600
-    img = load_img(image_path, target_size=(img_width, img_height))
+    img = load_img(image_path, target_size=(img_height, img_width))
-        x = x.reshape((3, img_width, img_height))
+        x = x.reshape((3, img_height, img_width))
-        x = x.reshape((img_width, img_height, 3))
+        x = x.reshape((img_height, img_width, 3))
-    img_size = (3, img_width, img_height)
+    img_size = (3, img_height, img_width)
-    img_size = (img_width, img_height, 3)
+    img_size = (img_height, img_width, 3)
-                     x[:, :, :img_width - 1, 1:])
+        a = K.square(x[:, :, :img_height - 1, :img_width - 1] -
-                     x[:, :img_width - 1, 1:, :])
+        a = K.square(x[:, :img_height - 1, :img_width - 1, :] -
-    return np.mean(labels == (predictions.ravel() > 0.5))
+    return labels[predictions.ravel() < 0.5].mean()
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-        ValueError: if `dim_ordering` is neither `tf` or `th`.
+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.
-from keras.layers.core import Dense, Activation, Merge, Lambda
+from keras.layers.core import Dense, Activation, Merge, Lambda, Reshape
-    def get_params(self, _):
+    def get_params(self, **params):
-            function = globs[config['function']]
+            function = get_from_module(config['function'], globs, 'core')
-            output_shape = globs[config['output_shape']]
+            output_shape = get_from_module(config['output_shape'], globs, 'core')
-from .utils.generic_utils import get_from_module
+from .utils.generic_utils import get_from_module, get_custom_objects
-    """Retrieves a class of function member of a module.
+    """Retrieves a class or function member of a module.
-        res = module_params.get(identifier)
+        res = None
-        res = module_params.get(name)
+        res = None
-from .generic_utils import get_from_module
+from .generic_utils import get_from_module, get_custom_objects
-            globals()[cls_key] = custom_objects[cls_key]
+        get_custom_objects().update(custom_objects)
-    x = logam(melgram(y=src, sr=sr, hop_lengthgth=hop_length,
+    x = logam(melgram(y=src, sr=sr, hop_length=hop_length,
-    is that it can be used with arbitrary layers, not just `Dense`,
+    `TimeDistributed` can be used with arbitrary layers, not just `Dense`,
-__version__ = '1.2.0'
+__version__ = '1.2.1'
-      version='1.2.0',
+      version='1.2.1',
-      download_url='https://github.com/fchollet/keras/tarball/1.2.0',
+      download_url='https://github.com/fchollet/keras/tarball/1.2.1',
-    
+
-    return T.round(x)
+    return T.round(x, mode='half_to_even')
-                    wait_time=0.05, nb_worker=1, pickle_safe=False):
+class GeneratorEnqueuer(object):
-    If pickle_safe, use a multiprocessing approach. Else, use threading.
+
-    try:
+    def __init__(self, generator, pickle_safe=False):
-            while not _stop.is_set():
+            while not self._stop_event.is_set():
-                        q.put(generator_output)
+                    if self._pickle_safe or self.queue.qsize() < max_q_size:
-                    _stop.set()
+                    self._stop_event.set()
-                thread = multiprocessing.Process(target=data_generator_task)
+        try:
-    return q, _stop, generator_threads
+                self.queue = queue.Queue()
-                        break
+        enqueuer = None
-                callbacks.on_batch_begin(batch_index, batch_logs)
+                        raise ValueError('output of generator should be a tuple '
-                callbacks.on_batch_end(batch_index, batch_logs)
+                    if not isinstance(outs, list):
-                        epoch_logs['val_' + l] = o
+                callbacks.on_epoch_end(epoch, epoch_logs)
-                break
+        finally:
-                    break
+
-            try:
+                    raise ValueError('output of generator should be a tuple '
-                    p.join()
+                if isinstance(x, list):
-                    x, y, sample_weight = generator_output
+        enqueuer = None
-                x = generator_output
+                    x = generator_output
-                    p.join()
+                if isinstance(x, list):
-        x += max(-np.min(x), 0)
+        x = x + max(-np.min(x), 0)
-        for i, s in zip(int_shape(x), tf.unpack(tf.shape(x))):
+        for i, s in zip(int_shape(x), unstack(tf.shape(x))):
-        for i, s in zip(int_shape(y), tf.unpack(tf.shape(y))):
+        for i, s in zip(int_shape(y), unstack(tf.shape(y))):
-        input_list = tf.unpack(inputs)
+        input_list = unstack(inputs)
-            mask_list = tf.unpack(mask)
+            mask_list = unstack(mask)
-        input_ta = input_ta.unpack(inputs)
+        if hasattr(input_ta, 'unstack'):
-            mask_ta = mask_ta.unpack(mask)
+            if hasattr(mask_ta, 'unstack'):
-        outputs = output_ta.pack()
+        if hasattr(output_ta, 'stack'):
-from keras.initializations import normal, identity
+from keras import initializers
-                    inner_init=lambda shape, name: identity(shape, scale=1.0, name=name),
+                    init=initializers.RandomNormal(stddev=0.001),
-from . import initializations
+from . import initializers
-from .. import initializations
+from .. import initializers
-        init: initialization function for the weights.
+        init: initializer function for the weights.
-        self.init = initializations.get(init)
+        self.init = initializers.get(init)
-        a_right_init: initialization function for the right part slope
+        t_left_init: initializer function for the left part intercept
-        a_right_init = initializations.get(self.a_right_init)
+        t_left_init = initializers.get(self.t_left_init)
-from .. import initializations
+from .. import initializers
-            Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-        self.init = initializations.get(init)
+        self.init = initializers.get(init, data_format='channels_last')
-                                                               data_format='channels_first'),
+                                 initializer=self.init,
-            Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-            Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-        self.init = initializations.get(init)
+        self.init = initializers.get(init, data_format=data_format)
-                                                               data_format=self.data_format),
+                                 initializer=self.init,
-            Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-            Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-            Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-        self.init = initializations.get(init)
+        self.init = initializers.get(init, data_format=data_format)
-                                                                              data_format=self.data_format),
+                                                initializer=self.init,
-                                                                              data_format=self.data_format),
+                                                initializer=self.init,
-            Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-        self.init = initializations.get(init)
+        self.init = initializers.get(init, data_format=data_format)
-                                                               data_format=self.data_format),
+                                 initializer=self.init,
-from .. import initializations
+from .. import initializers
-            inner_activation: activation function for the inner cells.
+    # Arguments
-            raise ValueError('data_format must be in {tf,th}', data_format)
+            raise ValueError('data_format must be in '
-        self.forget_bias_init = initializations.get(forget_bias_init)
+        self.init = initializers.get(init, data_format=data_format)
-from .. import initializations
+from .. import initializers
-            (see [initializations](../initializations.md)),
+        init: name of initializer function for the weights of the layer
-            initialization. This parameter is only relevant
+            initializer. This parameter is only relevant
-        self.init = initializations.get(init)
+        self.init = initializers.get(init)
-            (see [initializations](../initializations.md)),
+        init: name of initializer function for the weights of the layer
-            initialization. This parameter is only relevant
+            initializer. This parameter is only relevant
-        self.init = initializations.get(init)
+        self.init = initializers.get(init)
-            (see [initializations](../initializations.md)),
+        init: name of initializer function for the weights of the layer
-            initialization. This parameter is only relevant
+            initializer. This parameter is only relevant
-        self.init = initializations.get(init)
+        self.init = initializers.get(init)
-            (see [initializations](../initializations.md)),
+        init: name of initializer function for the weights of the layer
-            initialization. This parameter is only relevant
+            initializer. This parameter is only relevant
-        self.init = initializations.get(init)
+        self.init = initializers.get(init)
-from .. import initializations
+from .. import initializers
-          or alternatively, Theano function to use for weights initialization.
+      init: name of initializer function for the weights
-        self.init = initializations.get(init)
+        self.init = initializers.get(init)
-from keras.layers import initializations
+from keras.layers import initializers
-            or alternatively, Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-        self.init = initializations.get(init, data_format='channels_first')
+        self.init = initializers.get(init, data_format='channels_first')
-            Theano function to use for weights initialization.
+        init: name of initializer function for the weights of the layer
-        self.init = initializations.get(init, data_format=data_format)
+        self.init = initializers.get(init, data_format=data_format)
-from .. import initializations, regularizers
+from .. import initializers
-            Theano/TensorFlow function to use for weights initialization.
+        beta_init: name of initializer function for shift parameter
-            Theano/TensorFlow function to use for weights initialization.
+        gamma_init: name of initializer function for scale parameter (see
-        self.gamma_init = initializations.get(gamma_init)
+        self.beta_init = initializers.get(beta_init)
-from .. import initializations
+from .. import initializers
-        init: weight initialization function.
+        init: weight initializer function.
-        inner_init: initialization function of the inner cells.
+            or a Theano function (see: [initializers](../initializers.md)).
-        self.inner_init = initializations.get(inner_init)
+        self.init = initializers.get(init)
-        init: weight initialization function.
+        init: weight initializer function.
-        inner_init: initialization function of the inner cells.
+            or a Theano function (see: [initializers](../initializers.md)).
-        self.inner_init = initializations.get(inner_init)
+        self.init = initializers.get(init)
-        init: weight initialization function.
+        init: weight initializer function.
-        forget_bias_init: initialization function for the bias of the forget gate.
+            or a Theano function (see: [initializers](../initializers.md)).
-        self.forget_bias_init = initializations.get(forget_bias_init)
+        self.init = initializers.get(init)
-    return -K.mean(y_true * y_pred)
+    return - K.mean(y_true * y_pred)
-    """Matthews correlation metric.
+# Aliases
-        return 0
+        return 0.
-class L1L2Regularizer(Regularizer):
+class L1L2(Regularizer):
-        regularization = 0
+        regularization = 0.
-    return L1L2Regularizer(l1=l)
+    return L1L2(l1=l)
-    return L1L2Regularizer(l2=l)
+    return L1L2(l2=l)
-    return L1L2Regularizer(l1=l1, l2=l2)
+    return L1L2(l1=l1, l2=l2)
-    """Returns a tensor with normal distribution
+def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):
-        std: A float, standard deviation of the normal distribution
+        stddev: A float, standard deviation of the normal distribution
-    return tf.random_normal(shape, mean=mean, stddev=std,
+    return tf.random_normal(shape, mean=mean, stddev=stddev,
-    """Returns a tensor with uniform distribution
+def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):
-        low: A float, lower boundary of the uniform distribution
+        minval: A float, lower boundary of the uniform distribution
-        high: A float, upper boundary of the uniform distribution
+        maxval: A float, upper boundary of the uniform distribution
-    return tf.random_uniform(shape, minval=low, maxval=high,
+    return tf.random_uniform(shape, minval=minval, maxval=maxval,
-    """Returns a tensor with binomlai distribution
+    """Returns a tensor with random binomial distribution of values.
-def random_normal(shape, mean=0.0, std=1.0, dtype=None, seed=None):
+def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):
-    return rng.normal(size=shape, avg=mean, std=std, dtype=dtype)
+    return rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)
-def random_uniform(shape, low=0.0, high=1.0, dtype=None, seed=None):
+def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):
-    return rng.uniform(shape, low=low, high=high, dtype=dtype)
+    return rng.uniform(shape, low=minval, high=maxval, dtype=dtype)
-from .. import initializations
+from .. import initializers
-    def add_weight(self, shape, initializer, name=None,
+    def add_weight(self, shape, initializer,
-        weight = initializer(shape, name=name)
+        initializer = initializers.get(initializer)
-                           'initialization', kwargs=kwargs)
+from __future__ import absolute_import
-    pytest.main([__file__])
+import pytest
-def zeros_like(x, name=None):
+def zeros_like(x, dtype=None, name=None):
-        A Keras variable, filled with `0.0`.
+        A Keras variable with the shape of x filled with zeros.
-    return tf.zeros_like(x, name=name)
+    return tf.zeros_like(x, dtype=dtype, name=name)
-def ones_like(x, name=None):
+def ones_like(x, dtype=None, name=None):
-        A Keras variable, filled with `1.0`.
+        A Keras variable with the shape of x filled with ones.
-    return tf.ones_like(x, name=name)
+    return tf.ones_like(x, dtype=dtype, name=name)
-    return T.ones_like(x)
+def ones_like(x, dtype=None, name=None):
-    return T.zeros_like(x)
+def zeros_like(x, dtype=None, name=None):
-split_at = len(X) - len(X) / 10
+split_at = len(X) - len(X) // 10
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-                      border_mode='same', dim_ordering='tf'))
+                      border_mode='same', data_format='channels_last'))
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-        if K.image_dim_ordering() == 'th':
+        if K.image_data_format() == 'channels_first':
-                if K.image_dim_ordering() == 'th':
+                if K.image_data_format() == 'channels_first':
-                if K.image_dim_ordering() == 'th':
+                if K.image_data_format() == 'channels_first':
-            if K.image_dim_ordering() == 'th':
+            if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-K.set_image_dim_ordering('th')
+K.set_image_data_format('channels_first')
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-- Tested with 'Theano' backend and 'th' image_dim_ordering.
+- Tested with 'Theano' backend and 'channels_first' image_data_format.
-K.set_image_dim_ordering('th')
+# This example assume 'channels_first' data format.
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    as a 4D boolean tensor: (1, m, nr, nc) for 'th' or (1, nr, nc, m) for 'tf'
+    as a 4D boolean tensor: (1, m, nr, nc) for 'channels_first' or (1, nr, nc, m) for 'channels_last'
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    stack_axis = 0 if K.image_dim_ordering() == 'th' else -1
+    stack_axis = 0 if K.image_data_format() == 'channels_first' else -1
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-        if K.image_dim_ordering() == 'th':
+        if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-if K.image_dim_ordering() == 'th':
+if K.image_data_format() == 'channels_first':
-def preprocess_input(audio_path, dim_ordering='default'):
+def preprocess_input(audio_path, data_format='default'):
-        dim_ordering: data format for the output spectrogram image.
+        data_format: data format for the output spectrogram image.
-    assert dim_ordering in {'tf', 'th'}
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    elif dim_ordering == 'tf':
+    elif data_format == 'channels_last':
-def preprocess_input(x, dim_ordering='default'):
+def preprocess_input(x, data_format='default'):
-        dim_ordering: data format of the image tensor.
+        data_format: data format of the image tensor.
-    assert dim_ordering in {'tf', 'th'}
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-                        dim_ordering,
+                        data_format,
-        dim_ordering: image data format to use.
+        data_format: image data format to use.
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-        if dim_ordering == 'th':
+        if data_format == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    `image_dim_ordering="tf"` in your Keras config
+    `image_data_format="channels_last"` in your Keras config
-    TensorFlow and Theano. The dimension ordering
+    TensorFlow and Theano. The data format
-            or `(3, 299, 299)` (with `th` dim ordering).
+            has to be `(299, 299, 3)` (with `channels_last` data format)
-                                      dim_ordering=K.image_dim_ordering(),
+                                      data_format=K.image_data_format(),
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-        if K.image_dim_ordering() == 'th':
+        if K.image_data_format() == 'channels_first':
-                              '(`image_dim_ordering="th"`). '
+                              'image data format convention '
-                              '`image_dim_ordering="tf"` in '
+                              '`image_data_format="channels_last"` in '
-TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_tf_dim_ordering.h5'
+TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_th_data_format.h5'
-    `image_dim_ordering="tf"` in your Keras config
+    `image_data_format="channels_last"` in your Keras config
-    TensorFlow and Theano. The dimension ordering
+    TensorFlow and Theano. The data format
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-    if K.image_dim_ordering() == 'th':
+    if K.image_data_format() == 'channels_first':
-            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_tf_dim_ordering.h5',
+        if K.image_data_format() == 'channels_last':
-            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5',
+            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_th_data_format.h5',
-    if K.image_dim_ordering() == 'tf':
+    if K.image_data_format() == 'channels_last':
-    if K.image_dim_ordering() == 'tf':
+    if K.image_data_format() == 'channels_last':
-    `image_dim_ordering="tf"` in your Keras config
+    `image_data_format="channels_last"` in your Keras config
-    TensorFlow and Theano. The dimension ordering
+    TensorFlow and Theano. The data format
-            or `(3, 224, 244)` (with `th` dim ordering).
+            has to be `(224, 224, 3)` (with `channels_last` data format)
-                                      dim_ordering=K.image_dim_ordering(),
+                                      data_format=K.image_data_format(),
-    if K.image_dim_ordering() == 'tf':
+    if K.image_data_format() == 'channels_last':
-        if K.image_dim_ordering() == 'th':
+        if K.image_data_format() == 'channels_first':
-                              '(`image_dim_ordering="th"`). '
+                              'image data format convention '
-                              '`image_dim_ordering="tf"` in '
+                              '`image_data_format="channels_last"` in '
-    `image_dim_ordering="tf"` in your Keras config
+    `image_data_format="channels_last"` in your Keras config
-    TensorFlow and Theano. The dimension ordering
+    TensorFlow and Theano. The data format
-            or `(3, 224, 244)` (with `th` dim ordering).
+            has to be `(224, 224, 3)` (with `channels_last` data format)
-                                      dim_ordering=K.image_dim_ordering(),
+                                      data_format=K.image_data_format(),
-        if K.image_dim_ordering() == 'th':
+        if K.image_data_format() == 'channels_first':
-                              '(`image_dim_ordering="th"`). '
+                              'image data format convention '
-                              '`image_dim_ordering="tf"` in '
+                              '`image_data_format="channels_last"` in '
-    `image_dim_ordering="tf"` in your Keras config
+    `image_data_format="channels_last"` in your Keras config
-    TensorFlow and Theano. The dimension ordering
+    TensorFlow and Theano. The data format
-            or `(3, 224, 244)` (with `th` dim ordering).
+            has to be `(224, 224, 3)` (with `channels_last` data format)
-                                      dim_ordering=K.image_dim_ordering(),
+                                      data_format=K.image_data_format(),
-        if K.image_dim_ordering() == 'th':
+        if K.image_data_format() == 'channels_first':
-                              '(`image_dim_ordering="th"`). '
+                              'image data format convention '
-                              '`image_dim_ordering="tf"` in '
+                              '`image_data_format="channels_last"` in '
-    You should set `image_dim_ordering="tf"` in your Keras config
+    data format `(width, height, channels)`.
-    if K.image_dim_ordering() != 'tf':
+    if K.image_data_format() != 'channels_last':
-                      'input dimension ordering "tf" '
+                      'input data format "channels_last" '
-                      'You should set `image_dim_ordering="tf"` in your Keras '
+                      'data format "channels_first" (channels, width, height). '
-        old_dim_ordering = 'th'
+                      'to follow the "channels_last" data format.')
-        old_dim_ordering = None
+        old_data_format = None
-                                      dim_ordering=K.image_dim_ordering(),
+                                      data_format=K.image_data_format(),
-        K.set_image_dim_ordering(old_dim_ordering)
+    if old_data_format:
-from .common import set_image_dim_ordering
+from .common import image_data_format
-    assert _image_dim_ordering in {'tf', 'th'}
+    _image_data_format = _config.get('image_data_format',
-    set_image_dim_ordering(_image_dim_ordering)
+    set_image_data_format(_image_data_format)
-               'image_dim_ordering': image_dim_ordering()}
+               'image_data_format': image_data_format()}
-_IMAGE_DIM_ORDERING = 'tf'
+_IMAGE_DATA_FORMAT = 'channels_last'
-    convention ('th' or 'tf').
+def image_data_format():
-        A string, either `'th'` or `'tf'`
+        A string, either `'channels_first'` or `'channels_last'`
-        'th'
+        >>> keras.backend.image_data_format()
-    return _IMAGE_DIM_ORDERING
+    return _IMAGE_DATA_FORMAT
-def set_image_dim_ordering(dim_ordering):
+def set_image_data_format(data_format):
-    ordering convention ('th' or 'tf').
+    ordering convention ('channels_first' or 'channels_last').
-        dim_ordering: string. `'th'` or `'tf'`.
+        data_format: string. `'channels_first'` or `'channels_last'`.
-        'tf'
+        >>> K.image_data_format()
-    _IMAGE_DIM_ORDERING = str(dim_ordering)
+    global _IMAGE_DATA_FORMAT
-from .common import floatx, _EPSILON, image_dim_ordering, reset_uids
+from .common import floatx, _EPSILON, image_data_format, reset_uids
-def resize_images(X, height_factor, width_factor, dim_ordering):
+def resize_images(X, height_factor, width_factor, data_format):
-    - `[batch, height, width, channels]` (for 'tf' dim_ordering)
+    - `[batch, channels, height, width]` (for 'channels_first' data_format)
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    elif dim_ordering == 'tf':
+    elif data_format == 'channels_last':
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+        raise ValueError('Invalid data_format:', data_format)
-def resize_volumes(X, depth_factor, height_factor, width_factor, dim_ordering):
+def resize_volumes(X, depth_factor, height_factor, width_factor, data_format):
-    - `[batch, depth, height, width, channels]` (for 'tf' dim_ordering)
+    - `[batch, channels, depth, height, width]` (for 'channels_first' data_format)
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    elif dim_ordering == 'tf':
+    elif data_format == 'channels_last':
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+        raise ValueError('Invalid data_format:', data_format)
-def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):
+def spatial_2d_padding(x, padding=(1, 1), data_format='default'):
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-                                  dim_ordering='default'):
+                                  data_format='default'):
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):
+def spatial_3d_padding(x, padding=(1, 1, 1), data_format='default'):
-    For 'th' dim_ordering, the 3rd, 4th and 5th dimension will be padded.
+    For 'channels_last' data_format, the 2nd, 3rd and 4th dimension will be padded.
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    if dim_ordering == 'th':
+def _preprocess_deconv_output_shape(x, shape, data_format):
-def _preprocess_conv2d_input(x, dim_ordering):
+def _preprocess_conv2d_input(x, data_format):
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-def _preprocess_conv3d_input(x, dim_ordering):
+def _preprocess_conv3d_input(x, data_format):
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-def _preprocess_conv2d_kernel(kernel, dim_ordering):
+def _preprocess_conv2d_kernel(kernel, data_format):
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-def _preprocess_conv3d_kernel(kernel, dim_ordering):
+def _preprocess_conv3d_kernel(kernel, data_format):
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    if dim_ordering == 'th':
+def _postprocess_conv2d_output(x, data_format):
-    if dim_ordering == 'th':
+def _postprocess_conv3d_output(x, data_format):
-           dim_ordering='default',
+           data_format='default',
-            Whether to use Theano or TensorFlow dimension ordering
+        data_format: `"channels_last"` or `"channels_first"`.
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)
+    x = _preprocess_conv2d_input(x, data_format)
-    return _postprocess_conv2d_output(x, dim_ordering)
+    return _postprocess_conv2d_output(x, data_format)
-             dim_ordering='default',
+             data_format='default',
-            Whether to use Theano or TensorFlow dimension ordering
+        data_format: `"channels_last"` or `"channels_first"`.
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)
+    x = _preprocess_conv2d_input(x, data_format)
-    return _postprocess_conv2d_output(x, dim_ordering)
+    return _postprocess_conv2d_output(x, data_format)
-                  dim_ordering='default',
+                  data_format='default',
-            Whether to use Theano or TensorFlow dimension ordering
+        data_format: `"channels_last"` or `"channels_first"`.
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-                      dim_ordering=dim_ordering)
+                      data_format=data_format)
-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)
+    x = _preprocess_conv2d_input(x, data_format)
-    return _postprocess_conv2d_output(x, dim_ordering)
+    return _postprocess_conv2d_output(x, data_format)
-                     border_mode='valid', dim_ordering='default'):
+                     border_mode='valid', data_format='default'):
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    x = _preprocess_conv2d_input(x, dim_ordering)
+    x = _preprocess_conv2d_input(x, data_format)
-                                                 dim_ordering)
+                                                 data_format)
-                                                 dim_ordering)
+                                                 data_format)
-    return _postprocess_conv2d_output(x, dim_ordering)
+    return _postprocess_conv2d_output(x, data_format)
-           border_mode='valid', dim_ordering='default',
+           border_mode='valid', data_format='default',
-            Whether to use Theano or TensorFlow dimension ordering
+        data_format: `"channels_last"` or `"channels_first"`.
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    kernel = _preprocess_conv3d_kernel(kernel, dim_ordering)
+    x = _preprocess_conv3d_input(x, data_format)
-    return _postprocess_conv3d_output(x, dim_ordering)
+    return _postprocess_conv3d_output(x, data_format)
-           border_mode='valid', dim_ordering='default',
+           border_mode='valid', data_format='default',
-        dim_ordering: one of `"th"`, `"tf"`.
+        data_format: one of `"channels_first"`, `"channels_last"`.
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    x = _preprocess_conv2d_input(x, dim_ordering)
+    x = _preprocess_conv2d_input(x, data_format)
-    return _postprocess_conv2d_output(x, dim_ordering)
+    return _postprocess_conv2d_output(x, data_format)
-           dim_ordering='default', pool_mode='max'):
+           data_format='default', pool_mode='max'):
-        dim_ordering: one of `"th"`, `"tf"`.
+        data_format: one of `"channels_first"`, `"channels_last"`.
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    x = _preprocess_conv3d_input(x, dim_ordering)
+    x = _preprocess_conv3d_input(x, data_format)
-    return _postprocess_conv3d_output(x, dim_ordering)
+    return _postprocess_conv3d_output(x, data_format)
-from .common import _FLOATX, floatx, _EPSILON, image_dim_ordering
+from .common import _FLOATX, floatx, _EPSILON, image_data_format
-def resize_images(X, height_factor, width_factor, dim_ordering):
+def resize_images(X, height_factor, width_factor, data_format):
-    - [batch, height, width, channels] (for 'tf' dim_ordering)
+    - [batch, channels, height, width] (for 'channels_first' data_format)
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    elif dim_ordering == 'tf':
+    elif data_format == 'channels_last':
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+        raise ValueError('Invalid data_format:', data_format)
-def resize_volumes(X, depth_factor, height_factor, width_factor, dim_ordering):
+def resize_volumes(X, depth_factor, height_factor, width_factor, data_format):
-    - [batch, depth, height, width, channels] (for 'tf' dim_ordering)
+    - [batch, channels, depth, height, width] (for 'channels_first' data_format)
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    elif dim_ordering == 'tf':
+    elif data_format == 'channels_last':
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+        raise ValueError('Invalid data_format:', data_format)
-def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):
+def spatial_2d_padding(x, padding=(1, 1), data_format='default'):
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    elif dim_ordering == 'tf':
+    elif data_format == 'channels_last':
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+        raise ValueError('Invalid data_format:', data_format)
-                                  dim_ordering='default'):
+                                  data_format='default'):
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    elif dim_ordering == 'tf':
+    elif data_format == 'channels_last':
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+        raise ValueError('Invalid data_format:', data_format)
-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):
+def spatial_3d_padding(x, padding=(1, 1, 1), data_format='default'):
-        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-    elif dim_ordering == 'tf':
+    elif data_format == 'channels_last':
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+        raise ValueError('Invalid data_format:', data_format)
-    if dim_ordering == 'tf':
+def _preprocess_conv2d_input(x, data_format):
-    if dim_ordering == 'tf':
+def _preprocess_conv3d_input(x, data_format):
-    if dim_ordering == 'tf':
+def _preprocess_conv2d_kernel(kernel, data_format):
-    if dim_ordering == 'tf':
+def _preprocess_conv3d_kernel(kernel, data_format):
-def _preprocess_conv2d_image_shape(dim_ordering, image_shape):
+def _preprocess_conv2d_image_shape(data_format, image_shape):
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-def _preprocess_conv3d_volume_shape(dim_ordering, volume_shape):
+def _preprocess_conv3d_volume_shape(data_format, volume_shape):
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-def _preprocess_conv2d_filter_shape(dim_ordering, filter_shape):
+def _preprocess_conv2d_filter_shape(data_format, filter_shape):
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-def _preprocess_conv3d_filter_shape(dim_ordering, filter_shape):
+def _preprocess_conv3d_filter_shape(data_format, filter_shape):
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-def _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel, strides, dim_ordering):
+def _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel, strides, data_format):
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-def _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel, strides, dim_ordering):
+def _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel, strides, data_format):
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-           dim_ordering='default', image_shape=None,
+           data_format='default', image_shape=None,
-            Whether to use Theano or TensorFlow dimension ordering
+        data_format: "channels_last" or "channels_first".
-        raise ValueError('Unknown dim_ordering ', dim_ordering)
+    if data_format == 'default':
-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)
+    x = _preprocess_conv2d_input(x, data_format)
-    filter_shape = _preprocess_conv2d_filter_shape(dim_ordering, filter_shape)
+    image_shape = _preprocess_conv2d_image_shape(data_format, image_shape)
-                                          strides, dim_ordering)
+                                          strides, data_format)
-             dim_ordering='default',
+             data_format='default',
-            Whether to use Theano or TensorFlow dimension ordering
+        data_format: "channels_last" or "channels_first".
-        raise ValueError('Unknown dim_ordering ' + dim_ordering)
+    if data_format == 'default':
-    kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)
+    x = _preprocess_conv2d_input(x, data_format)
-    filter_shape = _preprocess_conv2d_filter_shape(dim_ordering, filter_shape)
+    filter_shape = _preprocess_conv2d_filter_shape(data_format, filter_shape)
-                                          strides, dim_ordering)
+                                          strides, data_format)
-                  dim_ordering='default',
+                  data_format='default',
-                     border_mode='valid', dim_ordering='default'):
+                     border_mode='valid', data_format='default'):
-           border_mode='valid', dim_ordering='default',
+           border_mode='valid', data_format='default',
-            Whether to use Theano or TensorFlow dimension ordering
+        data_format: "channels_last" or "channels_first".
-        raise ValueError('Unknown dim_ordering:', dim_ordering)
+    if data_format == 'default':
-                                  dim_ordering, volume_shape, filter_shape)
+                                  data_format, volume_shape, filter_shape)
-    kernel = _preprocess_conv3d_kernel(kernel, dim_ordering)
+    x = _preprocess_conv3d_input(x, data_format)
-    filter_shape = _preprocess_conv3d_filter_shape(dim_ordering, filter_shape)
+    volume_shape = _preprocess_conv3d_volume_shape(data_format, volume_shape)
-                                          strides, dim_ordering)
+                                          strides, data_format)
-                       border_mode='valid', dim_ordering='default',
+                       border_mode='valid', data_format='default',
-        raise ValueError('Unknown dim_ordering:', dim_ordering)
+    if data_format == 'default':
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-        raise ValueError('Unknown dim_ordering:', dim_ordering)
+           data_format='default', pool_mode='max'):
-        raise ValueError('Unknown dim_ordering:', dim_ordering)
+    if data_format not in {'channels_first', 'channels_last'}:
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-        raise ValueError('Unknown dim_ordering:', dim_ordering)
+           data_format='default', pool_mode='max'):
-                                  dim_ordering, pool_mode)
+                                  data_format, pool_mode)
-        raise ValueError('Unknown dim_ordering:', dim_ordering)
+    if data_format not in {'channels_first', 'channels_last'}:
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-        raise ValueError('Unknown dim_ordering:', dim_ordering)
+                       data_format='default', pool_mode='max'):
-        raise ValueError('Unknown dim_ordering:', dim_ordering)
+    if data_format not in {'channels_first', 'channels_last'}:
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-            In a `Convolution2D` layer with `dim_ordering="tf"`,
+            In a `Convolution2D` layer with `data_format="channels_last"`,
-            In a `Convolution2D` layer with `dim_ordering="tf"`,
+            In a `Convolution2D` layer with `data_format="channels_last"`,
-    if K.image_dim_ordering() == 'tf':
+    if K.image_data_format() == 'channels_last':
-    if K.image_dim_ordering() == 'tf':
+    if K.image_data_format() == 'channels_last':
-def get_fans(shape, dim_ordering='th'):
+def get_fans(shape, data_format='channels_first'):
-        if dim_ordering == 'th':
+        if data_format == 'channels_first':
-        elif dim_ordering == 'tf':
+        elif data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering: ' + dim_ordering)
+            raise ValueError('Invalid data_format: ' + data_format)
-def uniform(shape, scale=0.05, name=None, dim_ordering='th'):
+def uniform(shape, scale=0.05, name=None, data_format='channels_first'):
-def normal(shape, scale=0.05, name=None, dim_ordering='th'):
+def normal(shape, scale=0.05, name=None, data_format='channels_first'):
-def lecun_uniform(shape, name=None, dim_ordering='th'):
+def lecun_uniform(shape, name=None, data_format='channels_first'):
-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)
+    fan_in, fan_out = get_fans(shape, data_format=data_format)
-def glorot_normal(shape, name=None, dim_ordering='th'):
+def glorot_normal(shape, name=None, data_format='channels_first'):
-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)
+    fan_in, fan_out = get_fans(shape, data_format=data_format)
-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)
+def glorot_uniform(shape, name=None, data_format='channels_first'):
-def he_normal(shape, name=None, dim_ordering='th'):
+def he_normal(shape, name=None, data_format='channels_first'):
-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)
+    fan_in, fan_out = get_fans(shape, data_format=data_format)
-def he_uniform(shape, name=None, dim_ordering='th'):
+def he_uniform(shape, name=None, data_format='channels_first'):
-    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)
+    fan_in, fan_out = get_fans(shape, data_format=data_format)
-def orthogonal(shape, scale=1.1, name=None, dim_ordering='th'):
+def orthogonal(shape, scale=1.1, name=None, data_format='channels_first'):
-def identity(shape, scale=1, name=None, dim_ordering='th'):
+def identity(shape, scale=1, name=None, data_format='channels_first'):
-def zero(shape, name=None, dim_ordering='th'):
+def zero(shape, name=None, data_format='channels_first'):
-def one(shape, name=None, dim_ordering='th'):
+def one(shape, name=None, data_format='channels_first'):
-                                                               dim_ordering='th'),
+                                                               data_format='channels_first'),
-                          dim_ordering='tf')
+                          data_format='channels_last')
-                          dim_ordering='tf',
+                          data_format='channels_last',
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'
+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.
+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
-                 border_mode='valid', subsample=(1, 1), dim_ordering='default',
+                 border_mode='valid', subsample=(1, 1), data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                                                               dim_ordering=self.dim_ordering),
+                                                               data_format=self.data_format),
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-                          dim_ordering=self.dim_ordering,
+                          data_format=self.data_format,
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+                raise ValueError('Invalid data_format:', self.data_format)
-                  'dim_ordering': self.dim_ordering,
+                  'data_format': self.data_format,
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'
+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.
+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
-                 dim_ordering='default',
+                 data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-                                              dim_ordering=dim_ordering,
+                                              data_format=data_format,
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-                            dim_ordering=self.dim_ordering,
+                            data_format=self.data_format,
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+                raise ValueError('Invalid data_format:', self.data_format)
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'
+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.
+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
-                 atrous_rate=(1, 1), dim_ordering='default',
+                 atrous_rate=(1, 1), data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-                                                  dim_ordering=dim_ordering,
+                                                  data_format=data_format,
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-                          dim_ordering=self.dim_ordering,
+                          data_format=self.data_format,
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+                raise ValueError('Invalid data_format:', self.data_format)
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'
+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.
+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
-                 depth_multiplier=1, dim_ordering='default',
+                 depth_multiplier=1, data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                                                                              dim_ordering=self.dim_ordering),
+                                                                              data_format=self.data_format),
-                                                                              dim_ordering=self.dim_ordering),
+                                                                              data_format=self.data_format),
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                                    dim_ordering=self.dim_ordering)
+                                    data_format=self.data_format)
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+                raise ValueError('Invalid data_format:', self.data_format)
-                  'dim_ordering': self.dim_ordering,
+                  'data_format': self.data_format,
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, conv_dim1, conv_dim2, conv_dim3)` if dim_ordering='th'
+        `(samples, channels, conv_dim1, conv_dim2, conv_dim3)` if data_format='channels_first'
-        `(samples, conv_dim1, conv_dim2, conv_dim3, channels)` if dim_ordering='tf'.
+        `(samples, conv_dim1, conv_dim2, conv_dim3, channels)` if data_format='channels_last'.
-        `(samples, nb_filter, new_conv_dim1, new_conv_dim2, new_conv_dim3)` if dim_ordering='th'
+        `(samples, nb_filter, new_conv_dim1, new_conv_dim2, new_conv_dim3)` if data_format='channels_first'
-        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, nb_filter)` if dim_ordering='tf'.
+        `(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, nb_filter)` if data_format='channels_last'.
-                 border_mode='valid', subsample=(1, 1, 1), dim_ordering='default',
+                 border_mode='valid', subsample=(1, 1, 1), data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                                                               dim_ordering=self.dim_ordering),
+                                                               data_format=self.data_format),
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                          dim_ordering=self.dim_ordering,
+                          data_format=self.data_format,
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+                raise ValueError('Invalid data_format:', self.data_format)
-                  'dim_ordering': self.dim_ordering,
+                  'data_format': self.data_format,
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'.
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, channels, upsampled_rows, upsampled_cols)` if dim_ordering='th'
+        `(samples, channels, upsampled_rows, upsampled_cols)` if data_format='channels_first'
-        `(samples, upsampled_rows, upsampled_cols, channels)` if dim_ordering='tf'.
+        `(samples, upsampled_rows, upsampled_cols, channels)` if data_format='channels_last'.
-            dim_ordering = K.image_dim_ordering()
+    def __init__(self, size=(2, 2), data_format='default', **kwargs):
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                               self.dim_ordering)
+                               self.data_format)
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'.
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, dim1, dim2, dim3)` if dim_ordering='th'
+        `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'
-        `(samples, dim1, dim2, dim3, channels)` if dim_ordering='tf'.
+        `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.
-        `(samples, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)` if dim_ordering='th'
+        `(samples, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)` if data_format='channels_first'
-        `(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)` if dim_ordering='tf'.
+        `(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)` if data_format='channels_last'.
-            dim_ordering = K.image_dim_ordering()
+    def __init__(self, size=(2, 2, 2), data_format='default', **kwargs):
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                                self.dim_ordering)
+                                self.data_format)
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'.
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, channels, padded_rows, padded_cols)` if dim_ordering='th'
+        `(samples, channels, padded_rows, padded_cols)` if data_format='channels_first'
-        `(samples, padded_rows, padded_cols, channels)` if dim_ordering='tf'.
+        `(samples, padded_rows, padded_cols, channels)` if data_format='channels_last'.
-                 dim_ordering='default',
+                 data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                                               dim_ordering=self.dim_ordering)
+                                               data_format=self.data_format)
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'.
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-    def __init__(self, padding=(1, 1, 1), dim_ordering='default', **kwargs):
+    def __init__(self, padding=(1, 1, 1), data_format='default', **kwargs):
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-                                    dim_ordering=self.dim_ordering)
+                                    data_format=self.data_format)
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'.
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-    def __init__(self, cropping=((0, 0), (0, 0)), dim_ordering='default', **kwargs):
+    def __init__(self, cropping=((0, 0), (0, 0)), data_format='default', **kwargs):
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'.
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-                 dim_ordering='default', **kwargs):
+                 data_format='default', **kwargs):
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-                 dim_ordering=None, **kwargs):
+                 data_format=None, **kwargs):
-        self.dim_ordering = dim_ordering
+        self.data_format = data_format
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-        - if dim_ordering='th'
+        - if data_format='channels_first'
-        - if dim_ordering='tf'
+        - if data_format='channels_last'
-             - if dim_ordering='th'
+             - if data_format='channels_first'
-             - if dim_ordering='tf'
+             - if data_format='channels_last'
-            - if dim_ordering ='th'
+            - if data_format ='channels_first'
-            - if dim_ordering='tf'
+            - if data_format='channels_last'
-            dim_ordering: 'tf' if the feature are at the last dimension or 'th'
+            data_format: 'channels_last' if the feature are at the last dimension or 'channels_first'
-                 dim_ordering='default',
+                 data_format='default',
-            raise ValueError('dim_ordering must be in {tf,th}', dim_ordering)
+        if data_format == 'default':
-        if dim_ordering == 'th':
+        if data_format == 'channels_first':
-        self.dim_ordering = dim_ordering
+        self.data_format = data_format
-        kwargs['dim_ordering'] = dim_ordering
+        kwargs['data_format'] = data_format
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-                            dim_ordering=self.dim_ordering,
+                            data_format=self.data_format,
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+                raise ValueError('Invalid data_format:', self.data_format)
-                            dim_ordering=self.dim_ordering,
+                            data_format=self.data_format,
-                  'dim_ordering': self.dim_ordering,
+                  'data_format': self.data_format,
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        self.dim_ordering = dim_ordering
+    def __init__(self, p, data_format='default', **kwargs):
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'.
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, dim1, dim2, dim3)` if dim_ordering='th'
+        `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'
-        `(samples, dim1, dim2, dim3, channels)` if dim_ordering='tf'.
+        `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.
-        self.dim_ordering = dim_ordering
+    def __init__(self, p, data_format='default', **kwargs):
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        self.init = initializations.get(init, dim_ordering='th')
+        self.init = initializations.get(init, data_format='channels_first')
-            (the depth) is at index 1, in 'tf' mode is it at index 3.
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'
+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'
-        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.
+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.
-                 dim_ordering='default',
+                 data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.init = initializations.get(init, dim_ordering=dim_ordering)
+        self.init = initializations.get(init, data_format=data_format)
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-            if self.dim_ordering == 'th':
+            if self.data_format == 'channels_first':
-            elif self.dim_ordering == 'tf':
+            elif self.data_format == 'channels_last':
-                  'dim_ordering': self.dim_ordering,
+                  'data_format': self.data_format,
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                                        dim_ordering='tf')
+                                        data_format='channels_last')
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                          border_mode, dim_ordering, pool_mode='max')
+                          border_mode, data_format, pool_mode='max')
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                          border_mode, dim_ordering, pool_mode='avg')
+                          border_mode, data_format, pool_mode='avg')
-                 dim_ordering='default', **kwargs):
+                 data_format='default', **kwargs):
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                                        dim_ordering=self.dim_ordering)
+                                        data_format=self.data_format)
-                  'dim_ordering': self.dim_ordering}
+                  'data_format': self.data_format}
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(nb_samples, channels, pooled_rows, pooled_cols)` if dim_ordering='th'
+        `(nb_samples, channels, pooled_rows, pooled_cols)` if data_format='channels_first'
-        `(samples, pooled_rows, pooled_cols, channels)` if dim_ordering='tf'.
+        `(samples, pooled_rows, pooled_cols, channels)` if data_format='channels_last'.
-                 dim_ordering='default', **kwargs):
+                 data_format='default', **kwargs):
-                                           dim_ordering, **kwargs)
+                                           data_format, **kwargs)
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                          border_mode, dim_ordering,
+                          border_mode, data_format,
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        `(nb_samples, channels, pooled_rows, pooled_cols)` if dim_ordering='th'
+        `(nb_samples, channels, pooled_rows, pooled_cols)` if data_format='channels_first'
-        `(samples, pooled_rows, pooled_cols, channels)` if dim_ordering='tf'.
+        `(samples, pooled_rows, pooled_cols, channels)` if data_format='channels_last'.
-                 dim_ordering='default', **kwargs):
+                 data_format='default', **kwargs):
-                                               dim_ordering, **kwargs)
+                                               data_format, **kwargs)
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                          border_mode, dim_ordering, pool_mode='avg')
+                          border_mode, data_format, pool_mode='avg')
-                 dim_ordering='default', **kwargs):
+                 data_format='default', **kwargs):
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        if data_format not in {'channels_last', 'channels_first'}:
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
+            raise ValueError('Invalid data_format:', self.data_format)
-        if self.dim_ordering == 'th':
+        if self.data_format == 'channels_first':
-        elif self.dim_ordering == 'tf':
+        elif self.data_format == 'channels_last':
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                                        dim_ordering=self.dim_ordering)
+                                        data_format=self.data_format)
-                  'dim_ordering': self.dim_ordering}
+                  'data_format': self.data_format}
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if dim_ordering='th'
+        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if data_format='channels_first'
-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if dim_ordering='tf'.
+        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.
-        `(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)` if dim_ordering='th'
+        `(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)` if data_format='channels_first'
-        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if dim_ordering='tf'.
+        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if data_format='channels_last'.
-                 dim_ordering='default', **kwargs):
+                 data_format='default', **kwargs):
-                                           dim_ordering, **kwargs)
+                                           data_format, **kwargs)
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                          border_mode, dim_ordering, pool_mode='max')
+                          border_mode, data_format, pool_mode='max')
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if dim_ordering='th'
+        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if data_format='channels_first'
-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if dim_ordering='tf'.
+        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.
-        `(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)` if dim_ordering='th'
+        `(nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3)` if data_format='channels_first'
-        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if dim_ordering='tf'.
+        `(samples, pooled_dim1, pooled_dim2, pooled_dim3, channels)` if data_format='channels_last'.
-                 dim_ordering='default', **kwargs):
+                 data_format='default', **kwargs):
-                                               dim_ordering, **kwargs)
+                                               data_format, **kwargs)
-                          border_mode, dim_ordering):
+                          border_mode, data_format):
-                          border_mode, dim_ordering,
+                          border_mode, data_format,
-    def __init__(self, dim_ordering='default', **kwargs):
+    def __init__(self, data_format='default', **kwargs):
-        self.dim_ordering = dim_ordering
+        if data_format == 'default':
-        if self.dim_ordering == 'tf':
+        if self.data_format == 'channels_last':
-        config = {'dim_ordering': self.dim_ordering}
+        config = {'data_format': self.data_format}
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        if self.dim_ordering == 'tf':
+        if self.data_format == 'channels_last':
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, rows, cols)` if dim_ordering='th'
+        `(samples, channels, rows, cols)` if data_format='channels_first'
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+        `(samples, rows, cols, channels)` if data_format='channels_last'.
-        if self.dim_ordering == 'tf':
+        if self.data_format == 'channels_last':
-    def __init__(self, dim_ordering='default', **kwargs):
+    def __init__(self, data_format='default', **kwargs):
-        self.dim_ordering = dim_ordering
+        if data_format == 'default':
-        if self.dim_ordering == 'tf':
+        if self.data_format == 'channels_last':
-        config = {'dim_ordering': self.dim_ordering}
+        config = {'data_format': self.data_format}
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if dim_ordering='th'
+        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if data_format='channels_first'
-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if dim_ordering='tf'.
+        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.
-        if self.dim_ordering == 'tf':
+        if self.data_format == 'channels_last':
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if dim_ordering='th'
+        `(samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3)` if data_format='channels_first'
-        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if dim_ordering='tf'.
+        `(samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels)` if data_format='channels_last'.
-        if self.dim_ordering == 'tf':
+        if self.data_format == 'channels_last':
-def array_to_img(x, dim_ordering='default', scale=True):
+def array_to_img(x, data_format='default', scale=True):
-        dim_ordering: Image data format.
+        data_format: Image data format.
-        ValueError: if invalid `x` or `dim_ordering` is passed.
+        ValueError: if invalid `x` or `data_format` is passed.
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+    if data_format == 'default':
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-def img_to_array(img, dim_ordering='default'):
+def img_to_array(img, data_format='default'):
-        dim_ordering: Image data format.
+        data_format: Image data format.
-        ValueError: if invalid `img` or `dim_ordering` is passed.
+        ValueError: if invalid `img` or `data_format` is passed.
-        raise ValueError('Unknown dim_ordering: ', dim_ordering)
+    if data_format == 'default':
-        if dim_ordering == 'th':
+        if data_format == 'channels_first':
-        if dim_ordering == 'th':
+        if data_format == 'channels_first':
-            It defaults to the `image_dim_ordering` value found in your
+        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension
-            If you never set it, then it will be "tf".
+            If you never set it, then it will be "channels_last".
-            dim_ordering = K.image_dim_ordering()
+                 data_format='default'):
-        if dim_ordering == 'th':
+        if data_format not in {'channels_last', 'channels_first'}:
-        if dim_ordering == 'tf':
+        if data_format == 'channels_last':
-            dim_ordering=self.dim_ordering,
+            data_format=self.data_format,
-            dim_ordering=self.dim_ordering,
+            data_format=self.data_format,
-                'following the dimension ordering convention "' + self.dim_ordering + '" '
+                'following the data format convention "' + self.data_format + '" '
-                 dim_ordering='default',
+                 data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        channels_axis = 3 if dim_ordering == 'tf' else 1
+        channels_axis = 3 if data_format == 'channels_last' else 1
-                             'dimension ordering convention "' + dim_ordering + '" '
+                             'data format convention "' + data_format + '" '
-        self.dim_ordering = dim_ordering
+        self.data_format = data_format
-                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)
+                img = array_to_img(batch_x[i], self.data_format, scale=True)
-                 dim_ordering='default',
+                 data_format='default',
-            dim_ordering = K.image_dim_ordering()
+        if data_format == 'default':
-        self.dim_ordering = dim_ordering
+        self.data_format = data_format
-            if self.dim_ordering == 'tf':
+            if self.data_format == 'channels_last':
-            if self.dim_ordering == 'tf':
+            if self.data_format == 'channels_last':
-            x = img_to_array(img, dim_ordering=self.dim_ordering)
+            x = img_to_array(img, data_format=self.data_format)
-                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)
+                img = array_to_img(batch_x[i], self.data_format, scale=True)
-def convert_kernel(kernel, dim_ordering=None):
+def convert_kernel(kernel, data_format=None):
-        dim_ordering: the data format.
+        data_format: the data format.
-        ValueError: in case of invalid kernel shape or invalid dim_ordering.
+        ValueError: in case of invalid kernel shape or invalid data_format.
-        dim_ordering = K.image_dim_ordering()
+    if data_format is None:
-    if dim_ordering == 'th':  # (out_depth, input_depth, ...)
+    if data_format == 'channels_first':  # (out_depth, input_depth, ...)
-    elif dim_ordering == 'tf':  # (..., input_depth, out_depth)
+    elif data_format == 'channels_last':  # (..., input_depth, out_depth)
-        raise ValueError('Invalid dim_ordering:', dim_ordering)
+        raise ValueError('Invalid data_format:', data_format)
-                kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='th'))
+                kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_first'))
-                ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, dim_ordering='th'))
+                zth = KTH.eval(KTH.conv2d(xth, kernel_th, data_format='channels_first'))
-        kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='tf'))
+        kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_last'))
-        ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, dim_ordering='tf'))
+        zth = KTH.eval(KTH.conv2d(xth, kernel_th, data_format='channels_last'))
-        # test in dim_ordering = th
+        # test in data_format = th
-                kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='th'))
+                kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_first'))
-                ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf, dim_ordering='th'))
+                zth = KTH.eval(KTH.conv3d(xth, kernel_th, data_format='channels_first'))
-        # test in dim_ordering = tf
+        # test in data_format = tf
-        kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='tf'))
+        kernel_th = KTH.variable(convert_kernel(kernel_val, data_format='channels_last'))
-        ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf, dim_ordering='tf'))
+        zth = KTH.eval(KTH.conv3d(xth, kernel_th, data_format='channels_last'))
-                                   'dim_ordering': 'th'},
+                                   'data_format': 'channels_first'},
-                                   'dim_ordering': 'th',
+                                   'data_format': 'channels_first',
-               kwargs={'dim_ordering': 'th'},
+               kwargs={'data_format': 'channels_first'},
-               kwargs={'dim_ordering': 'tf'},
+               kwargs={'data_format': 'channels_last'},
-               kwargs={'dim_ordering': 'th'},
+               kwargs={'data_format': 'channels_first'},
-               kwargs={'dim_ordering': 'tf'},
+               kwargs={'data_format': 'channels_last'},
-               kwargs={'dim_ordering': 'th'},
+               kwargs={'data_format': 'channels_first'},
-               kwargs={'dim_ordering': 'tf'},
+               kwargs={'data_format': 'channels_last'},
-               kwargs={'dim_ordering': 'th'},
+               kwargs={'data_format': 'channels_first'},
-               kwargs={'dim_ordering': 'tf'},
+               kwargs={'data_format': 'channels_last'},
-    assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+    data_format = K.image_data_format()
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-    elif dim_ordering == 'th':
+    elif data_format == 'channels_first':
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-    elif dim_ordering == 'th':
+    elif data_format == 'channels_first':
-    if dim_ordering == 'tf':
+    if data_format == 'channels_last':
-    elif dim_ordering == 'th':
+    elif data_format == 'channels_first':
-        if dim_ordering == 'th':
+    for data_format in ['channels_first', 'channels_last']:
-                    dim_ordering=dim_ordering)
+                    data_format=data_format)
-                if dim_ordering == 'th':
+                if data_format == 'channels_first':
-                if dim_ordering == 'th':
+                if data_format == 'channels_first':
-        if dim_ordering == 'th':
+    for data_format in ['channels_first', 'channels_last']:
-                        dim_ordering=dim_ordering)
+                        data_format=data_format)
-                    if dim_ordering == 'th':
+                    if data_format == 'channels_first':
-                    if dim_ordering == 'th':
+                    if data_format == 'channels_first':
-    dim_ordering = K.image_dim_ordering()
+    data_format = K.image_data_format()
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-                       'dim_ordering': dim_ordering},
+                       'data_format': data_format},
-                                     dim_ordering=dim_ordering)
+                                     data_format=data_format)
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-                                     dim_ordering=dim_ordering)
+                                     data_format=data_format)
-    dim_ordering = K.image_dim_ordering()
+    data_format = K.image_data_format()
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-                       'dim_ordering': dim_ordering},
+                       'data_format': data_format},
-                                     dim_ordering=dim_ordering)
+                                     data_format=data_format)
-    if dim_ordering == 'th':
+    if data_format == 'channels_first':
-                                     dim_ordering=dim_ordering)
+                                     data_format=data_format)
-    for dim_ordering in ['th', 'tf']:
+    for data_format in ['channels_first', 'channels_last']:
-        if dim_ordering == 'th':
+        if data_format == 'channels_first':
-                                kwargs={'dim_ordering': dim_ordering,
+                                kwargs={'data_format': data_format,
-            if dim_ordering == 'th':
+            if data_format == 'channels_first':
-            if dim_ordering == 'th' or return_sequences:
+            if data_format == 'channels_first' or return_sequences:
-            kwargs = {'dim_ordering': dim_ordering,
+            kwargs = {'data_format': data_format,
-            kwargs = {'dim_ordering': dim_ordering,
+            kwargs = {'data_format': data_format,
-                       kwargs={'dim_ordering': dim_ordering,
+                       kwargs={'data_format': data_format,
-                               'dim_ordering': 'tf'},
+                               'data_format': 'channels_last'},
-                               'dim_ordering': 'th'},
+                               'data_format': 'channels_first'},
-            dim_ordering='tf')
+            data_format='channels_last')
-            dim_ordering='tf')
+            data_format='channels_last')
-            dim_ordering='th')
+            data_format='channels_first')
-        # Test th dim ordering
+        # Test th data format
-        img = image.array_to_img(x, dim_ordering='th')
+        img = image.array_to_img(x, data_format='channels_first')
-        x = image.img_to_array(img, dim_ordering='th')
+        x = image.img_to_array(img, data_format='channels_first')
-        img = image.array_to_img(x, dim_ordering='th')
+        img = image.array_to_img(x, data_format='channels_first')
-        x = image.img_to_array(img, dim_ordering='th')
+        x = image.img_to_array(img, data_format='channels_first')
-        # Test tf dim ordering
+        # Test tf data format
-        img = image.array_to_img(x, dim_ordering='tf')
+        img = image.array_to_img(x, data_format='channels_last')
-        x = image.img_to_array(img, dim_ordering='tf')
+        x = image.img_to_array(img, data_format='channels_last')
-        img = image.array_to_img(x, dim_ordering='tf')
+        img = image.array_to_img(x, data_format='channels_last')
-        x = image.img_to_array(img, dim_ordering='tf')
+        x = image.img_to_array(img, data_format='channels_last')
-from ..utils.np_utils import conv_output_length, conv_input_length
+from .. import activations
-from .pooling import MaxPooling1D, MaxPooling2D, MaxPooling3D
+from .pooling import AveragePooling1D
-from .. import activations, initializations, regularizers
+from .. import activations
-from ..engine import Layer, InputSpec
+from ..engine import Layer
-from ..utils.generic_utils import func_dump, func_load
+from .. import activations
-        return K.any(K.not_equal(input, self.mask_value), axis=-1)
+    def compute_mask(self, x, input_mask=None):
-        given an input shape.
+        """Find and replace a missing dimension in an output shape.
-        _fix_unknown_dimension in numpy/core/src/multiarray/shape.c
+        This is a near direct port of the internal Numpy function
-
+
-                    raise ValueError('can only specify one unknown dimension')
+                    raise ValueError('Can only specify one unknown dimension.')
-from keras.engine import Layer, InputSpec
+from keras.layers import activations
-from ..engine import Layer, InputSpec
+from ..engine import Layer
-from ..engine import Layer, InputSpec
+from .. import activations
-from ..engine import Layer, InputSpec
+from ..engine import Layer
-from ..models import Sequential, model_from_json
+from ..models import Sequential
-                input_tensor=None, input_shape=None):
+                input_tensor=None, input_shape=None,
-        x = Dense(1000, activation='softmax', name='predictions')(x)
+        x = Dense(classes, activation='softmax', name='predictions')(x)
-                    include_top=True):
+                    include_top=True, classes=50):
-
+        classes: optional number of classes to classify images
-        x = Dense(50, activation='sigmoid', name='output')(x)
+        x = Dense(classes, activation='sigmoid', name='output')(x)
-             input_tensor=None, input_shape=None):
+             input_tensor=None, input_shape=None,
-        x = Dense(1000, activation='softmax', name='fc1000')(x)
+        x = Dense(classes, activation='softmax', name='fc1000')(x)
-          input_tensor=None, input_shape=None):
+          input_tensor=None, input_shape=None,
-        x = Dense(1000, activation='softmax', name='predictions')(x)
+        x = Dense(classes, activation='softmax', name='predictions')(x)
-          input_tensor=None, input_shape=None):
+          input_tensor=None, input_shape=None,
-        x = Dense(1000, activation='softmax', name='predictions')(x)
+        x = Dense(classes, activation='softmax', name='predictions')(x)
-             input_tensor=None, input_shape=None):
+             input_tensor=None, input_shape=None,
-        x = Dense(1000, activation='softmax', name='predictions')(x)
+        x = Dense(classes, activation='softmax', name='predictions')(x)
-        """
+        # Assumes that self.layer is already set.
-    temporal slice of an input.
+    """This wrapper allows to apply a layer to every temporal slice of an input.
-    the temporal dimension.
+    Consider a batch of 32 samples,
-    (and the `input_shape`, not including the samples dimension, is `(10, 16)`).
+    You can then use `TimeDistributed` to apply a `Dense` layer
-    Note this is strictly equivalent to using `layers.core.TimeDistributedDense`.
+    Note this is strictly equivalent to
-        model.add(TimeDistributed(Convolution2D(64, 3, 3), input_shape=(10, 3, 299, 299)))
+        model.add(TimeDistributed(Convolution2D(64, 3, 3),
-        input_shape = K.int_shape(X)
+    def call(self, inputs, mask=None):
-            def step(x, states):
+            def step(x, _):
-            _, outputs, _ = K.rnn(step, X,
+            _, outputs, _ = K.rnn(step, inputs,
-            y = self.layer.call(X)  # (nb_samples * timesteps, ...)
+                input_length = K.shape(inputs)[1]
-        if hasattr(self.layer, 'activity_regularizer') and self.layer.activity_regularizer is not None:
+        if (hasattr(self.layer, 'activity_regularizer') and
-            self.add_loss(regularization_loss, X)
+            self.add_loss(regularization_loss, inputs)
-    """ Bidirectional wrapper for RNNs.
+    """Bidirectional wrapper for RNNs.
-        Y_rev = self.backward_layer.call(X, mask)
+    def call(self, inputs, mask=None):
-            Y_rev = K.reverse(Y_rev, 1)
+            y_rev = K.reverse(y_rev, 1)
-            return K.concatenate([Y, Y_rev])
+            return K.concatenate([y, y_rev])
-            return Y + Y_rev
+            return y + y_rev
-            return (Y + Y_rev) / 2
+            return (y + y_rev) / 2
-            return Y * Y_rev
+            return y * y_rev
-            return [Y, Y_rev]
+            return [y, y_rev]
-            return self.forward_layer.trainable_weights + self.backward_layer.trainable_weights
+            return (self.forward_layer.trainable_weights +
-            return self.forward_layer.non_trainable_weights + self.backward_layer.non_trainable_weights
+            return (self.forward_layer.non_trainable_weights +
-        _constraints = {}
+        constraints = {}
-        return _constraints
+            constraints.update(self.forward_layer.constraints)
-                          'Install it via `pip install librosa` \nor visit ' +
+        raise ImportError('Librosa is required to process audio files. '
-    that allows a small gradient when the unit is not active:
+    """Leaky version of a Rectified Linear Unit.
-    """Parametric Rectified Linear Unit:
+    """Parametric Rectified Linear Unit.
-    """Exponential Linear Unit:
+    """Exponential Linear Unit.
-    """Parametric Softplus:
+    """Parametric Softplus.
-    """Thresholded Rectified Linear Unit:
+    """Thresholded Rectified Linear Unit.
-    """S-shaped Rectified Linear Unit:
+    """S-shaped Rectified Linear Unit.
-        Y_left_and_center = t_left + K.relu(x - t_left,
+        y_left_and_center = t_left + K.relu(x - t_left,
-        return Y_left_and_center + Y_right
+        y_right = K.relu(x - t_right_actual) * a_right
-             use different values, it is better to use
+             It is better to use
-             a layer as specified in the examples.
+             a layer, as specified in the examples.
-    """Repeats each temporal step `length` times along the time axis.
+    """Upsampling layer for 1D inputs.
-    """Repeats the rows and columns of the data
+    """Upsampling layer for 2D inputs.
-    by size[0], size[1] and size[2] respectively.
+    """Upsampling layer for 3D inputs.
-            ones = ones + 1
+            ones += 1
-            ones = ones + 1
+            ones += 1
-from .. import initializations, regularizers, constraints
+from .. import initializations
-    """The `LocallyConnected1D` layer works similarly to
+    """Locally-connected layer for 1D inputs.
-    """The `LocallyConnected2D` layer works similarly
+    """Locally-connected layer for 2D inputs.
-            if K._backend == 'theano':
+            if K.backend() == 'theano':
-    def _pooling_function(self, back_end, inputs, pool_size, strides,
+    def _pooling_function(self, inputs, pool_size, strides,
-    """Apply y.w + b for every temporal slice y of x.
+    """Apply `y . w + b` for every temporal slice y of x.
-        x = x + b
+        x += b
-                             'input_shape must be provided (including batch size).')
+            raise ValueError('If a RNN is stateful, a complete '
-        path: where to store the data (in `/.keras/dataset`)
+        path: where to cache the data (relative to `~/.keras/dataset`).
-                if (w >= nb_words or w < skip_top):
+                if w >= nb_words or w < skip_top:
-        path: where to store the data (in `/.keras/dataset`)
+        path: where to cache the data (relative to `~/.keras/dataset`).
-                if (w >= nb_words or w < skip_top):
+                if w >= nb_words or w < skip_top:
-        d = cPickle.load(f, encoding="bytes")
+        d = cPickle.load(f, encoding='bytes')
-            d_decoded[k.decode("utf8")] = v
+            d_decoded[k.decode('utf8')] = v
-    data = d["data"]
+    data = d['data']
-    origin = "http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
+    """Loads CIFAR10 dataset.
-    y_train = np.zeros((nb_train_samples,), dtype="uint8")
+    x_train = np.zeros((nb_train_samples, 3, 32, 32), dtype='uint8')
-        X_train[(i - 1) * 10000: i * 10000, :, :, :] = data
+        x_train[(i - 1) * 10000: i * 10000, :, :, :] = data
-    X_test, y_test = load_batch(fpath)
+    x_test, y_test = load_batch(fpath)
-        X_test = X_test.transpose(0, 2, 3, 1)
+        x_train = x_train.transpose(0, 2, 3, 1)
-    return (X_train, y_train), (X_test, y_test)
+    return (x_train, y_train), (x_test, y_test)
-    X_train, y_train = load_batch(fpath, label_key=label_mode + '_labels')
+    x_train, y_train = load_batch(fpath, label_key=label_mode + '_labels')
-    X_test, y_test = load_batch(fpath, label_key=label_mode + '_labels')
+    x_test, y_test = load_batch(fpath, label_key=label_mode + '_labels')
-        X_test = X_test.transpose(0, 2, 3, 1)
+        x_train = x_train.transpose(0, 2, 3, 1)
-    return (X_train, y_train), (X_test, y_test)
+    return (x_train, y_train), (x_test, y_test)
-    """Loads IMDB dataset.
+    """Loads the IMDB dataset.
-    X = x_train + x_test
+    xs = x_train + x_test
-        X = [[start_char] + [w + index_from for w in x] for x in X]
+        xs = [[start_char] + [w + index_from for w in x] for x in xs]
-        X = [[w + index_from for w in x] for x in X]
+        xs = [[w + index_from for w in x] for x in xs]
-        new_X = []
+        new_xs = []
-        for x, y in zip(X, labels):
+        for x, y in zip(xs, labels):
-                new_X.append(x)
+                new_xs.append(x)
-        X = new_X
+        xs = new_xs
-    if not X:
+    if not xs:
-        nb_words = max([max(x) for x in X])
+        nb_words = max([max(x) for x in xs])
-    # reserve 'index_from' (=3 by default) characters: 0 (padding), 1 (start), 2 (OOV)
+    # reserve 'index_from' (=3 by default) characters:
-        X = [[oov_char if (w >= nb_words or w < skip_top) else w for w in x] for x in X]
+        xs = [[oov_char if (w >= nb_words or w < skip_top) else w for w in x] for x in xs]
-        for x in X:
+        new_xs = []
-        X = nX
+            new_xs.append(nx)
-    X_train = np.array(X[:len(x_train)])
+    x_train = np.array(xs[:len(x_train)])
-    X_test = np.array(X[len(x_train):])
+    x_test = np.array(xs[len(x_train):])
-    return (X_train, y_train), (X_test, y_test)
+    return (x_train, y_train), (x_test, y_test)
-    return data  # (X_train, y_train), (X_test, y_test)
+    return data  # (x_train, y_train), (x_test, y_test)
-    X, labels = cPickle.load(f)
+    xs, labels = cPickle.load(f)
-    np.random.shuffle(X)
+    np.random.shuffle(xs)
-        X = [[start_char] + [w + index_from for w in x] for x in X]
+        xs = [[start_char] + [w + index_from for w in x] for x in xs]
-        X = [[w + index_from for w in x] for x in X]
+        xs = [[w + index_from for w in x] for x in xs]
-        new_X = []
+        new_xs = []
-        for x, y in zip(X, labels):
+        for x, y in zip(xs, labels):
-                new_X.append(x)
+                new_xs.append(x)
-        X = new_X
+        xs = new_xs
-        nb_words = max([max(x) for x in X])
+        nb_words = max([max(x) for x in xs])
-    # reserve 'index_from' (=3 by default) characters: 0 (padding), 1 (start), 2 (OOV)
+    # reserve 'index_from' (=3 by default) characters:
-        X = [[oov_char if (w >= nb_words or w < skip_top) else w for w in x] for x in X]
+        xs = [[oov_char if (w >= nb_words or w < skip_top) else w for w in x] for x in xs]
-        for x in X:
+        new_xs = []
-        X = nX
+            new_xs.append(nx)
-    y_train = labels[:int(len(X) * (1 - test_split))]
+    x_train = xs[:int(len(xs) * (1 - test_split))]
-    y_test = labels[int(len(X) * (1 - test_split)):]
+    x_test = xs[int(len(xs) * (1 - test_split)):]
-    return (X_train, y_train), (X_test, y_test)
+    return (x_train, y_train), (x_test, y_test)
-
+
-                           'http://librosa.github.io/librosa/ for details.')
+    if librosa is None:
-    DURA = 29.12
+    sr = 12000
-    src, sr = librosa.load(audio_path, sr=SR)
+    src, sr = librosa.load(audio_path, sr=sr)
-    n_sample_wanted = int(DURA * SR)
+    n_sample_wanted = int(duration * sr)
-        src = np.hstack((src, np.zeros((int(DURA * SR) - n_sample,))))
+        src = np.hstack((src, np.zeros((int(duration * sr) - n_sample,))))
-                      n_fft=N_FFT, n_mels=N_MELS) ** 2,
+    x = logam(melgram(y=src, sr=sr, hop_lengthgth=hop_length,
-        top_n: integer in [0, 50], number of items to show
+        top_n: integer in [0, 50], number of items to show.
-def _obtain_input_shape(input_shape, default_size, min_size, dim_ordering, include_top):
+def _obtain_input_shape(input_shape,
-    """
+if K.backend() == 'tensorflow':
-        import tensorflow as tf
+    """Regularizer base class.
-        import requests
+        if requests is None:
-        self.sess = KTF.get_session()
+        self.sess = K.get_session()
-        self.reset()
+        self._reset()
-    def reset(self):
+    def _reset(self):
-        self.reset()
+        self._reset()
-            for root, dirs, files in os.walk(directory) for f in files
+            for root, _, files in os.walk(directory) for f in files
-            u, s, v = linalg.svd(sigma)
+            u, s, _ = linalg.svd(sigma)
-            for root, dirs, files in _recursive_list(subpath):
+            for root, _, files in _recursive_list(subpath):
-                    if any(input_mask):
+                    if any(mask is not None for mask in input_mask):
-            if self.monitor.startswith(('acc', 'fmeasure')):
+            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):
-            if self.monitor.startswith(('acc', 'fmeasure')):
+            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):
-def random_rotation(x, rg, row_index=1, col_index=2, channel_index=0,
+
-    h, w = x.shape[row_index], x.shape[col_index]
+    h, w = x.shape[row_axis], x.shape[col_axis]
-    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)
+    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)
-def random_shift(x, wrg, hrg, row_index=1, col_index=2, channel_index=0,
+def random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,
-    h, w = x.shape[row_index], x.shape[col_index]
+    """Performs a random spatial shift of a Numpy image tensor.
-    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)
+    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)
-def random_shear(x, intensity, row_index=1, col_index=2, channel_index=0,
+def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,
-    h, w = x.shape[row_index], x.shape[col_index]
+    h, w = x.shape[row_axis], x.shape[col_axis]
-    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)
+    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)
-def random_zoom(x, zoom_range, row_index=1, col_index=2, channel_index=0,
+def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,
-    h, w = x.shape[row_index], x.shape[col_index]
+    h, w = x.shape[row_axis], x.shape[col_axis]
-    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)
+    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)
-    x = np.rollaxis(x, channel_index, 0)
+def random_channel_shift(x, intensity, channel_axis=0):
-    x = np.rollaxis(x, 0, channel_index + 1)
+    x = np.rollaxis(x, 0, channel_axis + 1)
-    x = np.rollaxis(x, channel_index, 0)
+def apply_transform(x, transform_matrix, channel_axis=0, fill_mode='nearest', cval=0.):
-    x = np.rollaxis(x, 0, channel_index + 1)
+    x = np.rollaxis(x, 0, channel_axis + 1)
-    from PIL import Image
+    """Converts a 3D Numpy array to a PIL Image instance.
-        return Image.fromarray(x.astype('uint8'), 'RGB')
+        return pil_image.fromarray(x.astype('uint8'), 'RGB')
-        return Image.fromarray(x[:, :, 0].astype('uint8'), 'L')
+        return pil_image.fromarray(x[:, :, 0].astype('uint8'), 'L')
-    """Load an image into PIL format.
+    """Loads an image into PIL format.
-            or (img_height, img_width)
+        path: Path to image file
-    img = Image.open(path)
+    if pil_image is None:
-    real-time data augmentation.
+    """Generate minibatches of image data with real-time data augmentation.
-            The function should take one argument: one image (Numpy tensor with rank 3),
+            The function should take one argument:
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-        self.principal_components = None
+        self.featurewise_center = featurewise_center
-            self.col_index = 3
+            self.channel_axis = 1
-            self.col_index = 2
+            self.channel_axis = 3
-            batch_size=batch_size, shuffle=shuffle, seed=seed,
+            batch_size=batch_size,
-            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)
+            save_to_dir=save_to_dir,
-                            save_to_dir=None, save_prefix='', save_format='jpeg',
+                            save_to_dir=None,
-            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format,
+            save_to_dir=save_to_dir,
-        img_channel_index = self.channel_index - 1
+        img_channel_axis = self.channel_axis - 1
-            x -= np.mean(x, axis=img_channel_index, keepdims=True)
+            x -= np.mean(x, axis=img_channel_axis, keepdims=True)
-            x /= (np.std(x, axis=img_channel_index, keepdims=True) + 1e-7)
+            x /= (np.std(x, axis=img_channel_axis, keepdims=True) + 1e-7)
-        img_channel_index = self.channel_index - 1
+        img_row_axis = self.row_axis - 1
-        # use composition of homographies to generate final transform that needs to be applied
+        # use composition of homographies
-            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[img_row_index]
+            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[img_row_axis]
-            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[img_col_index]
+            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[img_col_axis]
-        transform_matrix = np.dot(np.dot(np.dot(rotation_matrix, translation_matrix), shear_matrix), zoom_matrix)
+        transform_matrix = np.dot(np.dot(np.dot(rotation_matrix,
-        h, w = x.shape[img_row_index], x.shape[img_col_index]
+        h, w = x.shape[img_row_axis], x.shape[img_col_axis]
-        x = apply_transform(x, transform_matrix, img_channel_index,
+        x = apply_transform(x, transform_matrix, img_channel_axis,
-
+            x = random_channel_shift(x,
-                x = flip_axis(x, img_col_index)
+                x = flip_axis(x, img_col_axis)
-                x = flip_axis(x, img_row_index)
+                x = flip_axis(x, img_row_axis)
-    def fit(self, X,
+    def fit(self, x,
-            X: Numpy array, the data to fit on. Should have rank 4.
+            x: Numpy array, the data to fit on. Should have rank 4.
-        if X.ndim != 4:
+        x = np.asarray(x)
-        if X.shape[self.channel_index] not in {1, 3, 4}:
+                             'Got array with shape: ' + str(x.shape))
-                ' (' + str(X.shape[self.channel_index]) + ' channels).')
+                '(channels on axis ' + str(self.channel_axis) + '), i.e. expected '
-        X = np.copy(X)
+        x = np.copy(x)
-            aX = np.zeros(tuple([rounds * X.shape[0]] + list(X.shape)[1:]))
+            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]))
-            X = aX
+                for i in range(x.shape[0]):
-            self.mean = np.mean(X, axis=(0, self.row_index, self.col_index))
+            self.mean = np.mean(x, axis=(0, self.row_axis, self.col_axis))
-            broadcast_shape[self.channel_index - 1] = X.shape[self.channel_index]
+            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]
-            X -= self.mean
+            x -= self.mean
-            self.std = np.std(X, axis=(0, self.row_index, self.col_index))
+            self.std = np.std(x, axis=(0, self.row_axis, self.col_axis))
-            broadcast_shape[self.channel_index - 1] = X.shape[self.channel_index]
+            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]
-            X /= (self.std + K.epsilon())
+            x /= (self.std + K.epsilon())
-            self.principal_components = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 10e-7))), U.T)
+            flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))
-        self.N = N
+    def __init__(self, n, batch_size, shuffle, seed):
-        self.index_generator = self._flow_index(N, batch_size, shuffle, seed)
+        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)
-    def _flow_index(self, N, batch_size=32, shuffle=False, seed=None):
+    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):
-                index_array = np.arange(N)
+                index_array = np.arange(n)
-                    index_array = np.random.permutation(N)
+                    index_array = np.random.permutation(n)
-            if N >= current_index + batch_size:
+            current_index = (self.batch_index * batch_size) % n
-                current_batch_size = N - current_index
+                current_batch_size = n - current_index
-    def __init__(self, X, y, image_data_generator,
+    def __init__(self, x, y, image_data_generator,
-        if y is not None and len(X) != len(y):
+        if y is not None and len(x) != len(y):
-                             'Found: X.shape = %s, y.shape = %s' % (np.asarray(X).shape, np.asarray(y).shape))
+                             'Found: X.shape = %s, y.shape = %s' %
-        if self.X.ndim != 4:
+        self.x = np.asarray(x)
-                             'with shape', self.X.shape)
+                             'with shape', self.x.shape)
-        if self.X.shape[channels_axis] not in {1, 3, 4}:
+        if self.x.shape[channels_axis] not in {1, 3, 4}:
-                             ' (' + str(self.X.shape[channels_axis]) + ' channels).')
+                             'However, it was passed an array with shape ' + str(self.x.shape) +
-        super(NumpyArrayIterator, self).__init__(X.shape[0], batch_size, shuffle, seed)
+        super(NumpyArrayIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)
-        batch_x = np.zeros(tuple([current_batch_size] + list(self.X.shape)[1:]))
+        # The transformation of images is not under thread lock
-            x = self.X[j]
+            x = self.x[j]
-            for root, dirs, files in _recursive_list(subpath):
+            for root, _, files in _recursive_list(subpath):
-        # The transformation of images is not under thread lock so it can be done in parallel
+        # The transformation of images is not under thread lock
-# urllib module, known to have issues with proxy management
+        """Replacement for `urlretrive` for Python 2.
-    res = sum(y * sp.log(p) + sp.subtract(1, y) * sp.log(sp.subtract(1, p)))
+    p = np.maximum(epsilon, p)
-        ValueError, in case of invalid values for `truncating`, `padding`,
+        ValueError: in case of invalid values for `truncating` or `padding`,
-        if s:
+        if len(s) > 0:
-            continue  # empty list was found
+        if not len(s):
-        sample_factor: the sampling factor in the word2vec formula.
+        sampling_factor: the sampling factor in the word2vec formula.
-        shape = (tf.shape(x)[0], ) + shape[1:]
+        shape = (tf.shape(x)[0], ) + tuple(shape[1:])
-def uniform(shape, scale=0.05, name=None):
+def uniform(shape, scale=0.05, name=None, dim_ordering='th'):
-def normal(shape, scale=0.05, name=None):
+def normal(shape, scale=0.05, name=None, dim_ordering='th'):
-def orthogonal(shape, scale=1.1, name=None):
+def orthogonal(shape, scale=1.1, name=None, dim_ordering='th'):
-def identity(shape, scale=1, name=None):
+def identity(shape, scale=1, name=None, dim_ordering='th'):
-def zero(shape, name=None):
+def zero(shape, name=None, dim_ordering='th'):
-def one(shape, name=None):
+def one(shape, name=None, dim_ordering='th'):
-from __future__ import absolute_import
+from __future__ import absolute_import
-    the length of the longest sequence.
+    """Pads each sequence to the same length (length of the longest sequence).
-        if len(s) > 0:
+        if s:
-        if len(s) == 0:
+        if not s:
-    """This generates an array where the ith element
+    """Generates a word rank-based probabilistic sampling table.
-    """Take a sequence (list of indexes of words),
+    """Generates skipgram word pairs.
-    # Notes
+    # Note
-        couples += [[words[i % len(words)], random.randint(1, vocabulary_size - 1)] for i in range(nb_negative_samples)]
+        couples += [[words[i % len(words)],
-            modes: one of "binary", "count", "tfidf", "freq".
+            mode: one of "binary", "count", "tfidf", "freq".
-            modes: one of "binary", "count", "tfidf", "freq"
+            mode: one of "binary", "count", "tfidf", "freq"
-def one_hot(text, n, filters=base_filter(), lower=True, split=" "):
+def one_hot(text, n,
-from a fast Cython rewrite.
+"""Utilities for text input preprocessing.
-def text_to_word_sequence(text, filters=base_filter(), lower=True, split=" "):
+def text_to_word_sequence(text,
-    return [_f for _f in seq if _f]
+    return [i for i in seq if i]
-                 lower=True, split=' ', char_level=False):
+    def __init__(self, nb_words=None,
-        according to some vectorization mode.
+        """Convert a list of texts to a Numpy matrix.
-        according to some vectorization mode.
+        """Converts a list of sequences into a Numpy matrix.
-        X = np.zeros((len(sequences), nb_words))
+        x = np.zeros((len(sequences), nb_words))
-                    X[i][j] = c
+                    x[i][j] = c
-                    X[i][j] = c / len(seq)
+                    x[i][j] = c / len(seq)
-                    X[i][j] = 1
+                    x[i][j] = 1
-                    X[i][j] = tf * idf
+                    idf = np.log(1 + self.document_count /
-        return X
+        return x
-class HDF5Matrix():
+class HDF5Matrix(object):
-                  line_length=100, positions=[.33, .55, .67, 1.]):
+                  line_length=100, positions=None):
-        positions: relative or absolute positions of log elements in each line
+        positions: relative or absolute positions of log elements in each line.
-        kerne: Numpy array (4D or 5D).
+        kernel: Numpy array (4D or 5D).
-    slices = [slice(None, None, -1) for i in range(kernel.ndim)]
+    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]
-import copy
+    if max_value is None:
-    Numpy array.
+    """Representation of HDF5 dataset to be used instead of a Numpy array.
-        model.predict(X_data)
+        x_data = HDF5Matrix('input/file.hdf5', 'data')
-    Providing start and end allows use of a slice of the dataset.
+    Providing `start` and `end` allows use of a slice of the dataset.
-        import h5py
+        if h5py is None:
-    import tables
+    if tables is None:
-    import tables
+    if tables is None:
-        except:
+        except AttributeError:
-    to binary class matrix, for use with categorical_crossentropy.
+    """Converts a class vector (integers) to binary class matrix.
-        y: class vector to be converted into a matrix.
+        y: class vector to be converted into a matrix
-    score = -(1. / len(Y)) * np.sum(np.log(npreds))
+def multiclass_logloss(p, y):
-    is its own inverse).
+    """Converts a Numpy kernel matrix from Theano format to TensorFlow format.
-        consists in integers in [0, nb_class-1].
+    """Generates test data to train a model on.
-        Otherwise: float output with shape output_shape.
+    Otherwise: float output with shape output_shape.
-    """Clean up after tensorflow tests.
+    """Function wrapper to clean up after TensorFlow tests.
-        if K._BACKEND == 'tensorflow':
+        if K.backend() == 'tensorflow':
-    # pydot-ng is a fork of pydot that is better maintained
+    # pydot-ng is a fork of pydot that is better maintained.
-    # fall back on pydot if necessary
+    # Fall back on pydot if necessary.
-                       ' and graphviz for `pydotprint` to work.')
+    raise ImportError('Failed to import pydot. You must install pydot'
-            except:
+            except AttributeError:
-        format = 'png'
+    _, extension = os.path.splitext(to_file)
-    dot.write(to_file, format=format)
+        extension = extension[1:]
-    def get_params(self, deep=True):
+    def get_params(self, _):
-            kwargs: dictionary arguments
+            **kwargs: dictionary arguments
-        theano.sandbox.cuda.dnn_available()
+    use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu'))
-        theano.sandbox.cuda.dnn_available()
+    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu'))
-    if max_value < min_value:
+    if max_value is not None and max_value < min_value:
-    if max_value < min_value:
+    if max_value is not None and max_value < min_value:
-from six.moves.urllib.error import URLError, HTTPError
+from six.moves.urllib.error import URLError
-    Passing the MD5 hash will verify the file after download as well as if it is already present in the cache.
+    Passing the MD5 hash will verify the file after download
-        # file found; verify integrity if a hash was provided
+        # File found; verify integrity if a hash was provided.
-            global progbar
+        def dl_progress(count, block_size, total_size, progbar=None):
-                urlretrieve(origin, fpath, dl_progress)
+                urlretrieve(origin, fpath,
-    """Validates a file against a MD5 hash
+    """Validates a file against a MD5 hash.
-    """Serializes user defined function.
+    """Serializes a user defined function.
-    """Deserializes user defined function.
+    """Deserializes a user defined function.
-    def update(self, current, values=[], force=False):
+    def update(self, current, values=None, force=False):
-    def add(self, n, values=[]):
+    def add(self, n, values=None):
-    """Converts class vector (integers from 0 to nb_classes)
+    """Converts a class vector (integers from 0 to nb_classes)
-        nb_classes: total number of classes
+        y: class vector to be converted into a matrix.
-def convert_kernel(kernel, dim_ordering='default'):
+def convert_kernel(kernel, dim_ordering=None):
-    if dim_ordering == 'default':
+    if dim_ordering is None:
-        unwanted usage of default values
+        """Checks for user typos in "params".
-                The parameters to be checked
+            params: dictionary; the parameters to be checked
-                argument.
+            ValueError: if any member of `params` is not a valid argument.
-            Dictionary of parameter names mapped to their values.
+            **params: Dictionary of parameter names mapped to their values.
-        to the given training data.
+        """Constructs a new model with `build_fn` & fit the model to `(x, y)`.
-        """Filters sk_params and return those in fn's arguments
+        """Filters `sk_params` and return those in `fn`'s arguments.
-            kwargs: dictionary arguments
+            **kwargs: dictionary arguments
-            kwargs: dictionary arguments
+            **kwargs: dictionary arguments
-            kwargs: dictionary arguments
+            **kwargs: dictionary arguments
-            X: array-like, shape `(n_samples, n_features)`
+            x: array-like, shape `(n_samples, n_features)`
-            kwargs: dictionary arguments
+            **kwargs: dictionary arguments
-    """Normalize the activations of the previous layer at each batch,
+    """Batch normalization layer (Ioffe and Szegedy, 2014).
-        sk_params: model parameters & fitting parameters
+        **sk_params: model parameters & fitting parameters
-        """Check for user typos in "params" keys to avoid
+        """Checks for user typos in "params" keys to avoid
-        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):
+        elif (not isinstance(self.build_fn, types.FunctionType) and
-        """Get parameters for this estimator.
+        """Gets parameters for this estimator.
-        """Set the parameters of this estimator.
+        """Sets the parameters of this estimator.
-        """Construct a new model with build_fn and fit the model according
+    def fit(self, x, y, **kwargs):
-            X : array-like, shape `(n_samples, n_features)`
+            x : array-like, shape `(n_samples, n_features)`
-        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):
+        elif (not isinstance(self.build_fn, types.FunctionType) and
-        history = self.model.fit(X, y, **fit_args)
+        history = self.model.fit(x, y, **fit_args)
-        """Filter sk_params and return those in fn's arguments
+    def filter_sk_params(self, fn, override=None):
-    def predict(self, X, **kwargs):
+    def predict(self, x, **kwargs):
-            X: array-like, shape `(n_samples, n_features)`
+            x: array-like, shape `(n_samples, n_features)`
-                Legal arguments are the arguments of `Sequential.predict_classes`.
+                Legal arguments are the arguments
-        return self.model.predict_classes(X, **kwargs)
+        return self.model.predict_classes(x, **kwargs)
-    def predict_proba(self, X, **kwargs):
+    def predict_proba(self, x, **kwargs):
-            X: array-like, shape `(n_samples, n_features)`
+            x: array-like, shape `(n_samples, n_features)`
-                Legal arguments are the arguments of `Sequential.predict_classes`.
+                Legal arguments are the arguments
-        probs = self.model.predict_proba(X, **kwargs)
+        probs = self.model.predict_proba(x, **kwargs)
-    def score(self, X, y, **kwargs):
+    def score(self, x, y, **kwargs):
-            X: array-like, shape `(n_samples, n_features)`
+            x: array-like, shape `(n_samples, n_features)`
-                True labels for X.
+                True labels for x.
-        outputs = self.model.evaluate(X, y, **kwargs)
+        outputs = self.model.evaluate(x, y, **kwargs)
-    def predict(self, X, **kwargs):
+    def predict(self, x, **kwargs):
-            kwargs: dictionary arguments
+            **kwargs: dictionary arguments
-        return np.squeeze(self.model.predict(X, **kwargs))
+        return np.squeeze(self.model.predict(x, **kwargs))
-    def score(self, X, y, **kwargs):
+    def score(self, x, y, **kwargs):
-            X: array-like, shape `(n_samples, n_features)`
+            x: array-like, shape `(n_samples, n_features)`
-        loss = self.model.evaluate(X, y, **kwargs)
+        loss = self.model.evaluate(x, y, **kwargs)
-    use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu'))
+    use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu')) and \
-    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu'))
+    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu')) and \
-                                            np.inf))
+                                            None))
-    second_log = K.log(K.clip(y_true, K.epsilon(), np.inf) + 1.)
+    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)
-import numpy as np
+
-                                            np.inf))
+                                            None))
-    second_log = K.log(K.clip(y_true, K.epsilon(), np.inf) + 1.)
+    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)
-    along a tensor axis.
+    """Returns the index of the maximum value along an axis.
-    along a tensor axis.
+    """Returns the index of the minimum value along an axis.
-    """Returns the value of a variable/
+    """Returns the value of a variable.
-        else_expression: TensorFlow operation.
+        then_expression: either a tensor, or a callable that returns a tensor.
-        A tensor
+        A tensor.
-    while scaling the entire tensor.
+    """Sets entries in `x` to zero at random, while scaling the entire tensor.
-    (you could see it as a kind of random data augmentation).
+    """Apply additive zero-centered Gaussian noise.
-    with standard deviation `sqrt(p/(1-p))`.
+    """Apply multiplicative 1-centered Gaussian noise.
-        # Arguments:
+        # Arguments
-    """Serialize user defined function.
+    """Serializes user defined function.
-    """Deserialize user defined function."""
+    """Deserializes user defined function.
-        """Dislays a progress bar.
+    # Arguments
-        """
+    def __init__(self, target, width=30, verbose=1, interval=0.01):
-    """prune: sequence of characters to filter out
+    """Converts a text to a sequence of word indices.
-    seq = text_to_word_sequence(text, filters=filters, lower=lower, split=split)
+    seq = text_to_word_sequence(text,
-        """Required before using texts_to_sequences or texts_to_matrix
+        """Updates internal vocabulary based on a list of texts.
-            seq = text if self.char_level else text_to_word_sequence(text, self.filters, self.lower, self.split)
+            seq = text if self.char_level else text_to_word_sequence(text,
-        (if fit_on_texts was never called)
+        """Updates internal vocabulary based on a list of sequences.
-        Returns a list of sequences.
+        # Arguments
-        Yields individual sequences.
+        # Arguments
-            texts: list of strings.
+        # Yields
-            seq = text if self.char_level else text_to_word_sequence(text, self.filters, self.lower, self.split)
+            seq = text if self.char_level else text_to_word_sequence(text,
-        # Arguments:
+        # Arguments
-            modes: one of "binary", "count", "tfidf", "freq"
+            modes: one of "binary", "count", "tfidf", "freq".
-        # Arguments:
+        # Arguments
-                    #   https://en.wikipedia.org/wiki/Tf%E2%80%93idf
+                    # https://en.wikipedia.org/wiki/Tf%E2%80%93idf
-        y[i, ord(next_chars[i])-ord('a')] = 1
+            X[i, t, ord(char) - ord('a')] = 1
-    for iteration in range(number_of_chars-sequence_length):
+    for iteration in range(number_of_chars - sequence_length):
-                  for t in range(seq_len_0)] +  # Pad to max_time_steps = 8
+                   for t in range(seq_len_0)] +  # Pad to max_time_steps = 8
-            kx = K.eval(K.foldl(lambda a, b: a+b, x))
+            kx = K.eval(K.foldl(lambda a, b: a + b, x))
-            p2 = K.eval(K.foldr(lambda a, b: a*b, x))
+            p1 = K.eval(K.foldl(lambda a, b: a * b, x))
-    
+
-            variance = np.random.rand(img_w, img_h, 1) * (255-64)
+            variance = np.random.rand(img_w, img_h, 1) * (255 - 64)
-                    target_mean=1./SHAPE[0], target_max=1.)
+                    target_mean=1. / SHAPE[0], target_max=1.)
-                target_mean=1./SHAPE[0], target_max=1.)
+                target_mean=1. / SHAPE[0], target_max=1.)
-                            k=3))
+                                                               k=3))
-                            k=2))
+                                                               k=2))
-                            k=1))
+                                                               k=1))
-                        batch_size=batch_size),
+                                     batch_size=batch_size),
-        a = K.square(x[:, :img_width - 1, :img_height-1, :] -
+        a = K.square(x[:, :img_width - 1, :img_height - 1, :] -
-        b = K.square(x[:, :img_width - 1, :img_height-1, :] -
+        b = K.square(x[:, :img_width - 1, :img_height - 1, :] -
-                ngram = tuple(new_list[i:i+ngram_value])
+        for i in range(len(new_list) - ngram_range + 1):
-        for i in range(2, ngram_range+1):
+        for i in range(2, ngram_range + 1):
-    token_indice = {v: k+start_index for k, v in enumerate(ngram_set)}
+    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}
-            z1, z2 = digit_indices[d][i], digit_indices[d][i+1]
+            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]
-        b = K.square(x[:, :, :img_nrows-1, :img_ncols-1] - x[:, :, :img_nrows-1, 1:])
+        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])
-        b = K.square(x[:, :img_nrows-1, :img_ncols-1, :] - x[:, :img_nrows-1, 1:, :])
+        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])
-nb_classes = np.max(y_train)+1
+nb_classes = np.max(y_train) + 1
-    """Stochastic gradient descent, with support for momentum,
+    """Stochastic gradient descent optimizer.
-        
+
-        if mask.ndim == ndim-1:
+        if mask.ndim == ndim - 1:
-                                         keepdims=True)))
+                                               axis=self.axis,
-                                 ' name-based weight loading.')
+            raise ValueError('The weight file you are trying to load is'
-                                dtype=K.dtype(self.outputs[i])))
+                                              name=name + '_target',
-            output_shape[i+1] = target_dim
+            output_shape[i + 1] = target_dim
-                  K.argmax(y_pred, axis=-1)))
+                          K.argmax(y_pred, axis=-1)))
-    x = np.rollaxis(x, 0, channel_index+1)
+    x = np.rollaxis(x, 0, channel_index + 1)
-                      final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]
+                                                         final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]
-    x = np.rollaxis(x, 0, channel_index+1)
+    x = np.rollaxis(x, 0, channel_index + 1)
-    inv_fq = rank * (np.log(rank) + gamma) + 0.5 - 1./(12.*rank)
+    inv_fq = rank * (np.log(rank) + gamma) + 0.5 - 1. / (12. * rank)
-        window_end = min(len(sequence), i+window_size+1)
+        window_start = max(0, i - window_size)
-        couples += [[words[i %len(words)], random.randint(1, vocabulary_size-1)] for i in range(nb_negative_samples)]
+        couples += [[words[i % len(words)], random.randint(1, vocabulary_size - 1)] for i in range(nb_negative_samples)]
-            labels += [[1, 0]]*nb_negative_samples
+            labels += [[1, 0]] * nb_negative_samples
-            labels += [0]*nb_negative_samples
+            labels += [0] * nb_negative_samples
-    text = text.translate(maketrans(filters, split*len(filters)))
+    text = text.translate(maketrans(filters, split * len(filters)))
-                bar += ('=' * (prog_width-1))
+                bar += ('=' * (prog_width - 1))
-                idx = slice(key.start+self.start, key.stop + self.start)
+                idx = slice(key.start + self.start, key.stop + self.start)
-        nb_classes = np.max(y)+1
+        nb_classes = np.max(y) + 1
-    p = sp.minimum(1-epsilon, p)
+    p = sp.minimum(1 - epsilon, p)
-    npreds = [P[i][Y[i]-1] for i in range(len(Y))]
+    npreds = [P[i][Y[i] - 1] for i in range(len(Y))]
-    """Convolution operator for filtering neighborhoods of one-dimensional inputs.
+    """Convolution operator for filtering neighborhoods of 1-D inputs.
-            This parameter is only relevant if you don't pass a `weights` argument.
+            (see [initializations](../initializations.md)), or alternatively,
-        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
+        border_mode: 'valid', 'same' or 'full'
-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,
+                 W_regularizer=None, b_regularizer=None,
-    """Atrous Convolution operator for filtering neighborhoods of one-dimensional inputs.
+    """Atrous Convolution operator for filtering neighborhoods of 1-D inputs.
-        # apply an atrous convolution 1d with atrous rate 2 of length 3 to a sequence with 10 timesteps,
+        # apply an atrous convolution 1d
-        model.add(AtrousConvolution1D(64, 3, atrous_rate=2, border_mode='same', input_shape=(10, 32)))
+        model.add(AtrousConvolution1D(64, 3, atrous_rate=2,
-        model.add(AtrousConvolution1D(32, 3, atrous_rate=2, border_mode='same'))
+        model.add(AtrousConvolution1D(32, 3, atrous_rate=2,
-            This parameter is only relevant if you don't pass a `weights` argument.
+            (see [initializations](../initializations.md)), or alternatively,
-        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
+        border_mode: 'valid', 'same' or 'full'
-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,
+                 W_regularizer=None, b_regularizer=None,
-                                                  bias=bias, **kwargs)
+        super(AtrousConvolution1D, self).__init__(
-        model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 256, 256)))
+        model.add(Convolution2D(64, 3, 3,
-        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
+        border_mode: 'valid', 'same' or 'full'
-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,
+                 W_regularizer=None, b_regularizer=None,
-    while maintaining a connectivity pattern that is compatible with said convolution. [1]
+    """Transposed convolution operator for filtering windows of 2-D inputs.
-        # apply a 3x3 transposed convolution with stride 1x1 and 3 output filters on a 12x12 image:
+        # apply a 3x3 transposed convolution
-        # Note that you will have to change the output_shape depending on the backend used.
+        model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14),
-        # apply a 3x3 transposed convolution with stride 2x2 and 3 output filters on a 12x12 image:
+        # apply a 3x3 transposed convolution
-        model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 25, 25), subsample=(2, 2), border_mode='valid', input_shape=(3, 12, 12)))
+        model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 25, 25),
-            tuple of integers (nb_samples, nb_filter, nb_output_rows, nb_output_cols)
+            tuple of integers
-             the actual output shape of a layer as specified in the examples.
+             use different values, it is better to use
-        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
+        border_mode: 'valid', 'same' or 'full'
-        bias: whether to include a bias (i.e. make the layer affine rather than linear).
+        bias: whether to include a bias
-    """Atrous Convolution operator for filtering windows of two-dimensional inputs.
+    """Atrous Convolution operator for filtering windows of 2-D inputs.
-        # apply a 3x3 convolution with atrous rate 2x2 and 64 output filters on a 256x256 image:
+        # apply a 3x3 convolution with atrous rate 2x2
-        # now the actual kernel size is dilated from 3x3 to 5x5 (3+(3-1)*(2-1)=5)
+        model.add(AtrousConvolution2D(64, 3, 3, atrous_rate=(2,2),
-        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
+        border_mode: 'valid', 'same' or 'full'
-        bias: whether to include a bias (i.e. make the layer affine rather than linear).
+        bias: whether to include a bias
-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,
+                 W_regularizer=None, b_regularizer=None,
-        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
+        border_mode: 'valid', 'same' or 'full'
-            Note: 'subsample' is implemented by slicing the output of conv3d with strides=(1,1,1).
+            Note: 'subsample' is implemented by slicing
-        bias: whether to include a bias (i.e. make the layer affine rather than linear).
+        bias: whether to include a bias
-    """Repeat each temporal step `length` times along the time axis.
+    """Repeats each temporal step `length` times along the time axis.
-    """Repeat the rows and columns of the data
+    """Repeats the rows and columns of the data
-    """Repeat the first, second and third dimension of the data
+    """Repeats the first, second and third dimension of the data
-        3D tensor with shape (samples, axis_to_pad, features)
+        3D tensor with shape `(samples, axis_to_pad, features)`
-        3D tensor with shape (samples, padded_axis, features)
+        3D tensor with shape `(samples, padded_axis, features)`
-        (samples, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)
+        `(samples, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)`
-        (samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)
+        `(samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)`
-        3D tensor with shape (samples, axis_to_crop, features)
+        3D tensor with shape `(samples, axis_to_crop, features)`
-        3D tensor with shape (samples, cropped_axis, features)
+        3D tensor with shape `(samples, cropped_axis, features)`
-        (samples, depth, first_axis_to_crop, second_axis_to_crop)
+        `(samples, depth, first_axis_to_crop, second_axis_to_crop)`
-        (samples, depth, first_cropped_axis, second_cropped_axis)
+        `(samples, depth, first_cropped_axis, second_cropped_axis)`
-        (samples, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)
+        `(samples, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)`
-        (samples, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)
+        `(samples, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)`
-    """Applies Dropout to the input. Dropout consists in randomly setting
+    """Applies Dropout to the input.
-                 or, the input is `None` and the sample dimension is also `None`:
+                 or, the input is `None` and
-                          'If the expected output shape is different, specify it via the `output_shape` argument.'
+                          'and cannot be automatically inferred '
-                        'argument to the first layer in your model.')
+                    raise ValueError('Layer ' + self.name +
-            loop through each dimension in x's shape and y's shape:
+            loop through each dimension in `x`'s shape and `y`'s shape:
-            dimension 1 of x has been summed over. (`dot_axes[0]` = 1)
+            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)
-            always ignore first dimension of y
+            always ignore first dimension of `y`
-        output_shape = `(100, 30)`
+            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)
-    Returns an uint8 tensor (0s and 1s).
+    # Returns
-    Returns an uint8 tensor
+    # Returns
-    Returns a bool tensor.
+
-    Returns a bool tensor.
+
-    Returns a bool tensor.
+
-    Returns a bool tensor.
+
-    Returns a bool tensor.
+
-    Returns a bool tensor.
+
-    output = (x - mean) / sqrt(var + epsilon) * gamma + beta
+    output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta
-    by a factor of (height_factor, width_factor). Both factors should be
+    - `[batch, channels, height, width]` (for 'th' dim_ordering)
-    by a factor of (depth_factor, height_factor, width_factor).
+    - `[batch, channels, depth, height, width]` (for 'th' dim_ordering)
-    """Repeats the elements of a tensor along an axis, like np.repeat
+    """Repeats the elements of a tensor along an axis, like `np.repeat`.
-    will have shape (s1, s2 * rep, s3)
+    # Returns
-    """Repeats a 2D tensor:
+    """Repeats a 2D tensor.
-    the output will have shape (samples, 2, dim)
+    # Returns
-    The default type of the returned tensor is 'int32' to
+    The default type of the returned tensor is `'int32'` to
-    """Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))
+    """Input: nD integer tensor of shape `(batch_size, dim1, dim2, ... dim(n-1))`
-    with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)
+    with shape `(batch_size, dim1, dim2, ... dim(n-1), nb_classes)`
-    as a Numpy array.
+    """Returns the value of a variable/
-    as a list of Numpy arrays.
+    """Returns the value of more than one tensor variable.
-    from a Numpy array.
+    """Sets the value of a variable,
-        inputs: tensor of temporal data of shape (samples, time, ...)
+        inputs: tensor of temporal data of shape `(samples, time, ...)`
-                input: tensor with shape (samples, ...) (no time dimension),
+                input: tensor with shape `(samples, ...)` (no time dimension),
-                output: tensor with shape (samples, output_dim)
+                output: tensor with shape `(samples, output_dim)`
-        mask: binary tensor with shape (samples, time, 1),
+        mask: binary tensor with shape `(samples, time, 1)`,
-        A tuple (last_output, outputs, new_states).
+        A tuple, `(last_output, outputs, new_states)`.
-            the step function, of shape (samples, ...).
+            last_output: the latest output of the rnn, of shape `(samples, ...)`
-    depending on a scalar value (int or bool).
+    depending on a scalar value (`int` or `bool`).
-    """Rectified linear unit
+    """Rectified linear unit.
-        max_value: saturation threshold.
+        x: A tensor or variable.
-        alpha: scalar
+        x: A tenor or variable to compute the activation function for.
-        k: An int, number of top elements to consider.
+        predictions: A tensor of shape `batch_size` x classes and type `float32`.
-        targets_i is within top-k values of predictions_i
+        A tensor of shape `batch_size` and type `bool`. `output_i` is `True` if
-        border_mode: string, "same" or "valid".
+        border_mode: string, `"same"` or `"valid"`.
-        dim_ordering: "tf" or "th".
+        border_mode: string, `"same"` or `"valid"`.
-        dim_ordering: "tf" or "th".
+        border_mode: string, `"same"` or `"valid"`.
-        dim_ordering: "tf" or "th".
+        border_mode: string, `"same"` or `"valid"`.
-        pool_mode: one of "max", "avg".
+        border_mode: one of `"valid"`, `"same"`.
-        pool_mode: one of "max", "avg".
+        border_mode: one of `"valid"`, `"same"`.
-                each batch item in y_true
+        y_true: tensor `(samples, max_string_length)` containing the truth labels.
-        greedy: perform much faster best-path search if true.  This does
+        y_pred: tensor `(samples, time_steps, num_categories)` containing the prediction,
-        beam_width: if greedy is false: a beam search decoder will be used
+        beam_width: if `greedy` is `false`: a beam search decoder will be used
-        top_paths: if greedy is false: how many of the most probable paths will be returned
+        top_paths: if `greedy` is `false`: how many of the most probable paths will be returned
-            Tensor (top_paths,) that contains the log probability of each decoded sequence
+            List: if `greedy` is `true`, returns a list of one element that contains
-            accumulator, for instance lambda acc, x: acc + x
+            accumulator, for instance `lambda acc, x: acc + x`
-        initializer: The first value used (elems[0] in case of None)
+        initializer: The first value used (`elems[0]` in case of None)
-            accumulator, for instance lambda acc, x: acc + x
+            accumulator, for instance `lambda acc, x: acc + x`
-        initializer: The first value used (elems[-1] in case of None)
+        initializer: The first value used (`elems[-1]` in case of None)
-                    tf.histogram_summary(weight.name, weight)
+                    if hasattr(tf, 'histogram_summary'):
-                        tf.image_summary(weight.name, w_img)
+                        if hasattr(tf, 'image_summary'):
-        else:
+                    if hasattr(tf, 'histogram_summary'):
-            if parse_version(tf.__version__) >= parse_version('0.12.0'):
+            if hasattr(tf, 'summary') and hasattr(tf.summary, 'FileWriter'):
-            if parse_version(tf.__version__) >= parse_version('0.12.0'):
+            if hasattr(tf, 'summary') and hasattr(tf.summary, 'FileWriter'):
-        out = tf.batch_matmul(x, y, adj_x=adj_x, adj_y=adj_y)
+    # TODO: remove later.
-                # tf.select needs its condition tensor
+                # tf.where needs its condition tensor
-                output = tf.select(tiled_mask_t, output, prev_output)
+                output = tf.where(tiled_mask_t, output, prev_output)
-                                                   state))
+                    return_states.append(tf.where(tiled_mask_t,
-                new_states = [tf.select(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]
+                output = tf.where(tiled_mask_t, output, states[0])
-        return tf.select(x > 0, res, alpha * res)
+        return tf.where(x > 0, res, alpha * res)
-                     tf.zeros(shape, dtype=dtype))
+    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,
-from six.moves import zip
+def test_clipnorm():
-    def __init__(self, p, **kwargs):
+    def __init__(self, p, noise_shape=None, seed=None, **kwargs):
-        return None
+    def _get_noise_shape(self, _):
-            x = K.in_train_phase(K.dropout(x, self.p, noise_shape), x)
+
-
+        random_tensor = T.patternbroadcast(random_tensor,
-    x_shape = copy.copy(then_expression.get_shape())
+    if not callable(then_expression):
-    x.set_shape(x_shape)
+              then_expression_fn,
-        return tf.nn.softmax_cross_entropy_with_logits(output, target)
+        try:
-        cast(flatten(target), 'int64'))
+    targets = cast(flatten(target), 'int64')
-    return tf.nn.sigmoid_cross_entropy_with_logits(output, target)
+    try:
-    y = np.array(y, dtype='int')
+    y = np.array(y, dtype='int').ravel()
-    return Y
+    n = y.shape[0]
-    identify timesteps to be skipped.
+    """Masks a sequence by using a mask value to skip timesteps.
-    """This version performs the same function as Dropout, however it drops
+    """Spatial 1D version of Dropout.
-    """This version performs the same function as Dropout, however it drops
+    """Spatial 2D version of Dropout.
-    """This version performs the same function as Dropout, however it drops
+    """Spatial 3D version of Dropout.
-    on the output of the previous layer.
+    """Used for evaluating an arbitrary expressions on an input.
-    """Just your regular fully connected NN layer.
+    """Just your regular densely-connected NN layer.
-    to the cost function based on the activity of the input.
+    """Layer that applies an update to the cost function based input activity.
-    a natural extension of LSTMs to feedforward networks.
+    """Densely connected highway network.
-    '''
+    """Reads an audio file and outputs a Mel-spectrogram.
-    '''Decode the output of a music tagger model.
+    """Decode the output of a music tagger model.
-    '''
+    """
-'''Inception V3 model for Keras.
+"""Inception V3 model for Keras.
-# Reference:
+# Reference
-'''
+"""
-    '''
+    """Utility function to apply conv + BN.
-    '''Instantiate the Inception v3 architecture,
+    """Instantiate the Inception v3 architecture,
-    '''
+    """
-'''MusicTaggerCRNN model for Keras.
+"""MusicTaggerCRNN model for Keras.
-'''
+"""
-    '''Instantiate the MusicTaggerCRNN architecture,
+    """Instantiate the MusicTaggerCRNN architecture,
-    '''
+    """
-'''ResNet50 model for Keras.
+"""ResNet50 model for Keras.
-'''
+"""
-    '''The identity_block is the block that has no conv layer at shortcut
+    """The identity_block is the block that has no conv layer at shortcut
-    '''
+    """
-    '''conv_block is the block that has a conv layer at shortcut
+    """conv_block is the block that has a conv layer at shortcut
-    '''
+    """
-    '''Instantiate the ResNet50 architecture,
+    """Instantiate the ResNet50 architecture,
-    '''
+    """
-'''VGG16 model for Keras.
+"""VGG16 model for Keras.
-# Reference:
+# Reference
-'''
+"""
-    '''Instantiate the VGG16 architecture,
+    """Instantiate the VGG16 architecture,
-    '''
+    """
-'''VGG19 model for Keras.
+"""VGG19 model for Keras.
-# Reference:
+# Reference
-'''
+"""
-    '''Instantiate the VGG19 architecture,
+    """Instantiate the VGG19 architecture,
-    '''
+    """
-'''Xception V1 model for Keras.
+"""Xception V1 model for Keras.
-# Reference:
+# Reference
-'''
+"""
-    '''Instantiate the Xception architecture,
+    """Instantiate the Xception architecture,
-    '''
+    """
-    '''Publicly accessible method
+    """Publicly accessible method
-    '''
+    """
-    '''Returns the value of the fuzz
+    """Returns the value of the fuzz
-    '''
+    """
-    '''Sets the value of the fuzz
+    """Sets the value of the fuzz
-    '''
+    """
-    '''Returns the default float type, as a string
+    """Returns the default float type, as a string
-    '''
+    """
-    '''Sets the default float type.
+    """Sets the default float type.
-    '''
+    """
-    '''Cast a Numpy array to the default Keras float type.
+    """Cast a Numpy array to the default Keras float type.
-    '''
+    """
-    '''Returns the default image dimension ordering
+    """Returns the default image dimension ordering
-    '''
+    """
-    '''Sets the value of the image dimension
+    """Sets the value of the image dimension
-    '''
+    """
-    '''Provides a unique UID given a string prefix.
+    """Provides a unique UID given a string prefix.
-    '''
+    """
-    '''Returns whether `x` is a Keras tensor.
+    """Returns whether `x` is a Keras tensor.
-    '''
+    """
-    '''Destroys the current TF graph and creates a new one.
+    """Destroys the current TF graph and creates a new one.
-    '''
+    """
-    '''Sets the manual variable initialization flag.
+    """Sets the manual variable initialization flag.
-    '''
+    """
-    '''Returns the learning phase flag.
+    """Returns the learning phase flag.
-    '''
+    """
-    '''Sets the learning phase to a fixed value,
+    """Sets the learning phase to a fixed value,
-    '''
+    """
-    '''Returns the TF session to be used by the backend.
+    """Returns the TF session to be used by the backend.
-    '''
+    """
-    '''
+    """Sets the global TF session.
-    '''Returns whether a tensor is a sparse tensor.
+    """Returns whether a tensor is a sparse tensor.
-    '''
+    """
-    '''Converts a sparse tensor into a dense tensor
+    """Converts a sparse tensor into a dense tensor
-    '''
+    """
-    '''Instantiates a variable and returns it.
+    """Instantiates a variable and returns it.
-    '''
+    """
-    '''Instantiates a placeholder tensor and returns it.
+    """Instantiates a placeholder tensor and returns it.
-    '''
+    """
-    '''Returns the symbolic shape of a tensor or variable.
+    """Returns the symbolic shape of a tensor or variable.
-    '''
+    """
-    '''Returns the shape of a Keras tensor or a Keras variable as a tuple of
+    """Returns the shape of a Keras tensor or a Keras variable as a tuple of
-    '''
+    """
-    '''Returns the number of axes in a tensor, as an integer.
+    """Returns the number of axes in a tensor, as an integer.
-    '''
+    """
-    '''Returns the dtype of a Keras tensor or variable, as a string.
+    """Returns the dtype of a Keras tensor or variable, as a string.
-    '''
+    """
-    '''Evaluates the value of a variable.
+    """Evaluates the value of a variable.
-    '''
+    """
-    '''Instantiates an all-zeros variable and returns it.
+    """Instantiates an all-zeros variable and returns it.
-    '''
+    """
-    '''Instantiates an all-ones tensor variable and returns it.
+    """Instantiates an all-ones tensor variable and returns it.
-    '''
+    """
-    '''Instantiate an identity matrix and returns it.
+    """Instantiate an identity matrix and returns it.
-    '''
+    """
-    '''Instantiates an all-zeros Keras variable
+    """Instantiates an all-zeros Keras variable
-    '''
+    """
-    '''Instantiates an all-ones Keras variable
+    """Instantiates an all-ones Keras variable
-    '''
+    """
-    '''Instantiates an Keras variable filled with
+    """Instantiates an Keras variable filled with
-    '''
+    """
-    '''Instantiates an Keras variable filled with
+    """Instantiates an Keras variable filled with
-    '''
+    """
-    '''Returns the number of scalars in a Keras variable.
+    """Returns the number of scalars in a Keras variable.
-    '''
+    """
-    '''Casts a tensor to a different dtype and returns it.
+    """Casts a tensor to a different dtype and returns it.
-    '''
+    """
-    '''Multiplies 2 tensors (and/or variables) and returns a *tensor*.
+    """Multiplies 2 tensors (and/or variables) and returns a *tensor*.
-    '''
+    """
-    '''Batchwise dot product.
+    """Batchwise dot product.
-    '''
+    """
-    '''Transposes a tensor and returns it.
+    """Transposes a tensor and returns it.
-    '''
+    """
-    '''Retrieves the elements of indices `indices`
+    """Retrieves the elements of indices `indices`
-    '''
+    """
-    '''
+    """Maximum value in a tensor.
-    '''
+    """Minimum value in a tensor.
-    '''
+    """Sum of the values in a tensor, alongside the specified axis.
-    '''
+    """Multiplies the values in a tensor, alongside the specified axis.
-    '''
+    """Variance of a tensor, alongside the specified axis.
-    '''
+    """Standard deviation of a tensor, alongside the specified axis.
-    '''
+    """Mean of a tensor, alongside the specified axis.
-    '''Bitwise reduction (logical OR).
+    """Bitwise reduction (logical OR).
-    '''
+    """
-    '''Bitwise reduction (logical AND).
+    """Bitwise reduction (logical AND).
-    '''
+    """
-    '''Returns the index of the maximum value
+    """Returns the index of the maximum value
-    '''
+    """
-    '''Returns the index of the minimum value
+    """Returns the index of the minimum value
-    '''
+    """
-    '''
+    """Element-wise square.
-    '''
+    """Element-wise absolute value.
-    '''
+    """Element-wise square root.
-    '''
+    """Element-wise exponential.
-    '''
+    """Element-wise log.
-    '''
+    """Element-wise rounding to the closest integer.
-    '''
+    """Element-wise sign.
-    '''
+    """Element-wise exponentiation.
-    '''
+    """Element-wise value clipping.
-    '''Element-wise equality between two tensors.
+    """Element-wise equality between two tensors.
-    '''
+    """
-    '''Element-wise inequality between two tensors.
+    """Element-wise inequality between two tensors.
-    '''
+    """
-    '''Element-wise truth value of (x > y).
+    """Element-wise truth value of (x > y).
-    '''
+    """
-    '''Element-wise truth value of (x >= y).
+    """Element-wise truth value of (x >= y).
-    '''
+    """
-    '''Element-wise truth value of (x < y).
+    """Element-wise truth value of (x < y).
-    '''
+    """
-    '''Element-wise truth value of (x <= y).
+    """Element-wise truth value of (x <= y).
-    '''
+    """
-    '''
+    """Element-wise maximum of two tensors.
-    '''
+    """Element-wise minimum of two tensors.
-    '''
+    """Computes sin of x element-wise.
-    '''
+    """Computes cos of x element-wise.
-    '''
+    """Computes mean and std for batch then apply batch_normalization on batch.
-    '''Applies batch normalization on x given mean, var, beta and gamma:
+    """Applies batch normalization on x given mean, var, beta and gamma:
-    '''
+    """
-    '''
+    """Concatenates a list of tensors alongside the specified axis.
-    '''
+    """Reshapes a tensor to the specified shape.
-    '''Permutes axes in a tensor.
+    """Permutes axes in a tensor.
-    '''
+    """
-    '''Resizes the images contained in a 4D tensor of shape
+    """Resizes the images contained in a 4D tensor of shape
-    '''
+    """
-    '''Resizes the volume contained in a 5D tensor of shape
+    """Resizes the volume contained in a 5D tensor of shape
-    '''
+    """
-    '''Repeats the elements of a tensor along an axis, like np.repeat
+    """Repeats the elements of a tensor along an axis, like np.repeat
-    '''
+    """
-    '''Repeats a 2D tensor:
+    """Repeats a 2D tensor:
-    '''
+    """
-    '''Creates a 1-D tensor containing a sequence of integers.
+    """Creates a 1-D tensor containing a sequence of integers.
-    '''
+    """
-    '''Turn a n-D tensor into a 2D tensor where
+    """Turn a n-D tensor into a 2D tensor where
-    '''
+    """
-    '''
+    """Adds a 1-sized dimension at index "dim".
-    '''
+    """Removes a 1-dimension from the tensor at index "axis".
-    '''Pads the middle dimension of a 3D tensor
+    """Pads the middle dimension of a 3D tensor
-    '''
+    """
-    '''Pad the middle dimension of a 3D tensor
+    """Pad the middle dimension of a 3D tensor
-    '''
+    """
-    '''Pads the 2nd and 3rd dimensions of a 4D tensor
+    """Pads the 2nd and 3rd dimensions of a 4D tensor
-    '''
+    """
-    '''Pad the rows and columns of a 4D tensor
+    """Pad the rows and columns of a 4D tensor
-    '''
+    """
-    '''Pads 5D tensor with zeros for the depth, height, width dimension with
+    """Pads 5D tensor with zeros for the depth, height, width dimension with
-    '''
+    """
-    '''Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))
+    """Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))
-    '''
+    """
-    '''
+    """Reverse a tensor along the the specified axes
-    '''Returns the value of a tensor variable,
+    """Returns the value of a tensor variable,
-    '''
+    """
-    '''Returns the value of more than one tensor variable,
+    """Returns the value of more than one tensor variable,
-    '''
+    """
-    '''Sets the value of a tensor variable,
+    """Sets the value of a tensor variable,
-    '''
+    """
-    '''Sets the values of many tensor variables at once.
+    """Sets the values of many tensor variables at once.
-    '''
+    """
-    '''Print the message and the tensor when evaluated and return the same
+    """Print the message and the tensor when evaluated and return the same
-    '''
+    """
-    '''Instantiates a Keras function.
+    """Instantiates a Keras function.
-    '''
+    """
-    '''Returns the gradients of `variables` (list of tensor variables)
+    """Returns the gradients of `variables` (list of tensor variables)
-    '''
+    """
-    '''Returns `variables` but with zero gradient with respect to every other
+    """Returns `variables` but with zero gradient with respect to every other
-    '''
+    """
-    '''Iterates over the time dimension of a tensor.
+    """Iterates over the time dimension of a tensor.
-    '''
+    """
-    '''
+    """Backwards compatible interface to tf.cond prior to public introduction.
-    '''Switches between two operations
+    """Switches between two operations
-    '''
+    """
-    '''Selects `x` in train phase, and `alt` otherwise.
+    """Selects `x` in train phase, and `alt` otherwise.
-    '''
+    """
-    '''Selects `x` in test phase, and `alt` otherwise.
+    """Selects `x` in test phase, and `alt` otherwise.
-    '''
+    """
-    '''Rectified linear unit
+    """Rectified linear unit
-    '''
+    """
-    '''Exponential linear unit.
+    """Exponential linear unit.
-    '''
+    """
-    '''
+    """Softmax of a tensor.
-    '''
+    """Softplus of a tensor.
-    '''
+    """Softsign of a tensor.
-    '''Categorical crossentropy between an output tensor
+    """Categorical crossentropy between an output tensor
-    '''
+    """
-    '''Categorical crossentropy between an output tensor
+    """Categorical crossentropy between an output tensor
-    '''
+    """
-    '''
+    """Binary crossentropy between an output tensor and a target tensor.
-    '''
+    """Element-wise sigmoid.
-    '''Segment-wise linear approximation of sigmoid.
+    """Segment-wise linear approximation of sigmoid.
-    '''
+    """
-    '''
+    """Element-wise tanh.
-    '''Sets entries in `x` to zero at random,
+    """Sets entries in `x` to zero at random,
-    '''
+    """
-    '''
+    """Normalizes a tensor wrt the L2 norm alongside the specified axis.
-    '''Returns whether the `targets` are in the top `k` `predictions`
+    """Returns whether the `targets` are in the top `k` `predictions`
-    '''
+    """
-    '''1D convolution.
+    """1D convolution.
-    '''
+    """
-    '''2D convolution.
+    """2D convolution.
-    '''
+    """
-    '''2D deconvolution (i.e. transposed convolution).
+    """2D deconvolution (i.e. transposed convolution).
-    '''
+    """
-    '''3D convolution.
+    """3D convolution.
-    '''
+    """
-    '''2D Pooling.
+    """2D Pooling.
-    '''
+    """
-    '''3D Pooling.
+    """3D Pooling.
-    '''
+    """
-    '''Runs CTC loss algorithm on each batch element.
+    """Runs CTC loss algorithm on each batch element.
-    '''
+    """
-    '''Decodes the output of a softmax using either
+    """Decodes the output of a softmax using either
-    '''
+    """
-    '''Map the function fn over the elements elems and return the outputs.
+    """Map the function fn over the elements elems and return the outputs.
-    '''
+    """
-    '''Reduce elems using fn to combine them from left to right.
+    """Reduce elems using fn to combine them from left to right.
-    '''
+    """
-    '''Reduce elems using fn to combine them from right to left.
+    """Reduce elems using fn to combine them from right to left.
-    '''
+    """
-    '''Instantiates a variable and returns it.
+    """Instantiates a variable and returns it.
-    '''
+    """
-    '''
+    """Instantiate an input data placeholder variable.
-    '''Returns the shape of a tensor.
+    """Returns the shape of a tensor.
-    '''
+    """
-    '''Returns the shape of a Keras tensor or a Keras variable as a tuple of
+    """Returns the shape of a Keras tensor or a Keras variable as a tuple of
-    '''
+    """
-    '''
+    """Returns the value of a tensor.
-    '''
+    """Instantiates an all-zeros variable.
-    '''
+    """Instantiates an all-ones variable.
-    '''
+    """Instantiates an identity matrix.
-    '''Returns the number of scalars in a tensor.
+    """Returns the number of scalars in a tensor.
-    '''
+    """
-'''
+"""
-'''
+"""
-    '''Batchwise dot product.
+    """Batchwise dot product.
-    '''
+    """
-    '''reference: a tensor.
+    """reference: a tensor.
-    '''
+    """
-    '''
+    """Sum of the values in a tensor, alongside the specified axis.
-    '''
+    """Multiply the values in a tensor, alongside the specified axis.
-    '''
+    """Mean of a tensor, alongside the specified axis.
-    '''
+    """Bitwise reduction (logical OR).
-    '''
+    """Bitwise reduction (logical AND).
-    '''
+    """Computes mean and std for batch then apply batch_normalization on batch.
-    '''
+    """Apply batch normalization on x given mean, var, beta and gamma.
-    '''
+    """Computes mean and std for batch then apply batch_normalization on batch.
-    '''
+    """Apply batch normalization on x given mean, var, beta and gamma.
-    '''Transpose dimensions.
+    """Transpose dimensions.
-    '''
+    """
-    '''Repeat the elements of a tensor along an axis, like np.repeat.
+    """Repeat the elements of a tensor along an axis, like np.repeat.
-    '''
+    """
-    '''Resize the images contained in a 4D tensor of shape
+    """Resize the images contained in a 4D tensor of shape
-    '''
+    """
-    '''Resize the volume contained in a 5D tensor of shape
+    """Resize the volume contained in a 5D tensor of shape
-    '''
+    """
-    '''Repeat a 2D tensor.
+    """Repeat a 2D tensor.
-    '''
+    """
-    '''Creates a 1-D tensor containing a sequence of integers.
+    """Creates a 1-D tensor containing a sequence of integers.
-    '''
+    """
-    '''Turn a n-D tensor into a 2D tensor where
+    """Turn a n-D tensor into a 2D tensor where
-    '''
+    """
-    '''
+    """Add a 1-sized dimension at index "dim".
-    '''
+    """Remove a 1-dimension from the tensor at index "axis".
-    '''Pad the middle dimension of a 3D tensor
+    """Pad the middle dimension of a 3D tensor
-    '''
+    """
-    '''Pad the middle dimension of a 3D tensor
+    """Pad the middle dimension of a 3D tensor
-    '''
+    """
-    '''Pad the 2nd and 3rd dimensions of a 4D tensor
+    """Pad the 2nd and 3rd dimensions of a 4D tensor
-    '''
+    """
-    '''Pad the rows and columns of a 4D tensor
+    """Pad the rows and columns of a 4D tensor
-    '''
+    """
-    '''Pad the 2nd, 3rd and 4th dimensions of a 5D tensor
+    """Pad the 2nd, 3rd and 4th dimensions of a 5D tensor
-    '''
+    """
-    '''Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))
+    """Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))
-    '''
+    """
-    '''
+    """Reverse a tensor along the the specified axes
-    '''Returns the value of more than one tensor variable,
+    """Returns the value of more than one tensor variable,
-    '''
+    """
-    '''Print the message and the tensor when evaluated and return the same
+    """Print the message and the tensor when evaluated and return the same
-    '''
+    """
-    '''Returns `variables` but with zero gradient with respect to every other
+    """Returns `variables` but with zero gradient with respect to every other
-    '''
+    """
-    '''Iterates over the time dimension of a tensor.
+    """Iterates over the time dimension of a tensor.
-    '''
+    """
-    '''
+    """condition: scalar tensor.
-    '''Sets entries in `x` to zero at random,
+    """Sets entries in `x` to zero at random,
-    '''
+    """
-    '''Returns whether the `targets` are in the top `k` `predictions`
+    """Returns whether the `targets` are in the top `k` `predictions`
-    '''
+    """
-    '''1D convolution.
+    """1D convolution.
-    '''
+    """
-    '''2D convolution.
+    """2D convolution.
-    '''
+    """
-    '''2D deconvolution (transposed convolution).
+    """2D deconvolution (transposed convolution).
-    '''
+    """
-    '''3D convolution.
+    """3D convolution.
-    '''
+    """
-    '''
+    """
-    '''
+    """
-    '''Runs CTC loss algorithm on each batch element.
+    """Runs CTC loss algorithm on each batch element.
-    '''
+    """
-    '''Map the function fn over the elements elems and return the outputs.
+    """Map the function fn over the elements elems and return the outputs.
-    '''
+    """
-    '''Reduce elems using fn to combine them from left to right.
+    """Reduce elems using fn to combine them from left to right.
-    '''
+    """
-    '''Reduce elems using fn to combine them from right to left.
+    """Reduce elems using fn to combine them from right to left.
-    '''
+    """
-    '''Loads IMDB dataset.
+    """Loads IMDB dataset.
-    '''
+    """
-    '''Loads the Reuters newswire classification dataset.
+    """Loads the Reuters newswire classification dataset.
-    '''
+    """
-    '''This normalizes a list/tensor into a list.
+    """This normalizes a list/tensor into a list.
-    '''
+    """
-    '''This specifies the ndim, dtype and shape of every input to a layer.
+    """This specifies the ndim, dtype and shape of every input to a layer.
-    '''
+    """
-    '''A `Node` describes the connectivity between two layers.
+    """A `Node` describes the connectivity between two layers.
-    '''
+    """
-    '''Abstract base layer class.
+    """Abstract base layer class.
-    '''
+    """
-        '''Adds a weight variable to the layer.
+        """Adds a weight variable to the layer.
-        '''
+        """
-        '''This checks that the tensor(s) `input`
+        """This checks that the tensor(s) `input`
-        '''
+        """
-        '''This is where the layer's logic lives.
+        """This is where the layer's logic lives.
-        '''
+        """
-        '''Wrapper around self.call(), for handling
+        """Wrapper around self.call(), for handling
-        '''
+        """
-        '''
+        """
-        '''
+        """
-        '''Computes the output shape of the layer given
+        """Computes the output shape of the layer given
-        '''
+        """
-        '''Computes an output masking tensor, given an input tensor
+        """Computes an output masking tensor, given an input tensor
-        '''
+        """
-        '''Creates the layer weights.
+        """Creates the layer weights.
-        '''
+        """
-        '''Retrieves an attribute (e.g. input_tensors) from a node.
+        """Retrieves an attribute (e.g. input_tensors) from a node.
-        '''
+        """
-        '''
+        """Retrieves the input shape(s) of a layer at a given node.
-        '''
+        """Retrieves the output shape(s) of a layer at a given node.
-        '''
+        """Retrieves the input tensor(s) of a layer at a given node.
-        '''
+        """Retrieves the output tensor(s) of a layer at a given node.
-        '''
+        """Retrieves the input mask tensor(s) of a layer at a given node.
-        '''
+        """Retrieves the output mask tensor(s) of a layer at a given node.
-        '''Retrieves the input tensor(s) of a layer (only applicable if
+        """Retrieves the input tensor(s) of a layer (only applicable if
-        '''
+        """
-        '''Retrieves the output tensor(s) of a layer (only applicable if
+        """Retrieves the output tensor(s) of a layer (only applicable if
-        '''
+        """
-        '''Retrieves the input mask tensor(s) of a layer (only applicable if
+        """Retrieves the input mask tensor(s) of a layer (only applicable if
-        '''
+        """
-        '''Retrieves the output mask tensor(s) of a layer (only applicable if
+        """Retrieves the output mask tensor(s) of a layer (only applicable if
-        '''
+        """
-        '''Retrieves the input shape tuple(s) of a layer. Only applicable
+        """Retrieves the input shape tuple(s) of a layer. Only applicable
-        '''
+        """
-        '''Retrieves the output shape tuple(s) of a layer. Only applicable
+        """Retrieves the output shape tuple(s) of a layer. Only applicable
-        '''
+        """
-        '''Sets the weights of the layer, from Numpy arrays.
+        """Sets the weights of the layer, from Numpy arrays.
-        '''
+        """
-        '''Returns the current weights of the layer,
+        """Returns the current weights of the layer,
-        '''
+        """
-        '''Returns a Python dictionary (serializable)
+        """Returns a Python dictionary (serializable)
-        '''
+        """
-        '''This method is the reverse of get_config,
+        """This method is the reverse of get_config,
-        '''
+        """
-        '''Returns the total number of floats (or ints)
+        """Returns the total number of floats (or ints)
-        '''
+        """
-    '''Layer to be used as an entry point into a graph.
+    """Layer to be used as an entry point into a graph.
-    '''
+    """
-    '''`Input()` is used to instantiate a Keras tensor.
+    """`Input()` is used to instantiate a Keras tensor.
-    '''
+    """
-    '''A `Merge` layer can be used to merge a list of tensors
+    """A `Merge` layer can be used to merge a list of tensors
-    '''
+    """
-        '''Validates user-passed arguments and raises exceptions
+        """Validates user-passed arguments and raises exceptions
-        '''
+        """
-        '''We disable successive calls to __call__ for Merge layers.
+        """We disable successive calls to __call__ for Merge layers.
-        '''
+        """
-    '''Functional merge, to apply to Keras tensors (NOT layers).
+    """Functional merge, to apply to Keras tensors (NOT layers).
-    '''
+    """
-    '''A Container is a directed acyclic graph of layers.
+    """A Container is a directed acyclic graph of layers.
-    '''
+    """
-            '''This recursively updates the maps nodes_depths,
+            """This recursively updates the maps nodes_depths,
-            '''
+            """
-        '''Returns a layer based on either its name (unique)
+        """Returns a layer based on either its name (unique)
-        '''
+        """
-        '''Returns the `updates` from all layers that are
+        """Returns the `updates` from all layers that are
-        '''
+        """
-        '''Returns the weights of the model,
+        """Returns the weights of the model,
-        '''
+        """
-        '''Sets the weights of the model.
+        """Sets the weights of the model.
-        '''
+        """
-        '''
+        """True if any layer in the graph uses it.
-        '''`call` just reapplies all ops in the graph to the new inputs
+        """`call` just reapplies all ops in the graph to the new inputs
-        '''
+        """
-        '''Computes output tensors for new inputs.
+        """Computes output tensors for new inputs.
-        '''
+        """
-        '''
+        """Instantiates a Model from its config (output of `get_config()`).
-        '''Save into a single HDF5 file:
+        """Save into a single HDF5 file:
-        '''
+        """
-        '''Dumps all layer weights to a HDF5 file.
+        """Dumps all layer weights to a HDF5 file.
-        '''
+        """
-        '''Loads all layer weights from a HDF5 save file.
+        """Loads all layer weights from a HDF5 save file.
-        '''
+        """
-        '''Weight loading is based on layer order in a list
+        """Weight loading is based on layer order in a list
-        '''
+        """
-        ''' Name-based weight loading
+        """ Name-based weight loading
-        '''
+        """
-        '''Shared between different serialization methods.'''
+        """Shared between different serialization methods."""
-        '''Returns a JSON string containing the network configuration.
+        """Returns a JSON string containing the network configuration.
-        '''
+        """
-        '''Returns a yaml string containing the network configuration.
+        """Returns a yaml string containing the network configuration.
-        '''
+        """
-    '''Returns the list of input tensors
+    """Returns the list of input tensors
-    '''
+    """
-        LeCun 98, Efficient Backprop
+    # References
-    # Reference
+    # References
-    # Reference
+    # References
-    # Reference
+    # References
-    '''Special version of a Rectified Linear Unit
+    """Special version of a Rectified Linear Unit
-    '''
+    """
-    '''Parametric Rectified Linear Unit:
+    """Parametric Rectified Linear Unit:
-    '''
+    """
-            neg = K.pattern_broadcast(self.alphas, self.param_broadcast) * (x - abs(x)) * 0.5
+            neg = (K.pattern_broadcast(self.alphas, self.param_broadcast) *
-    '''Exponential Linear Unit:
+    """Exponential Linear Unit:
-    '''
+    """
-    '''Parametric Softplus:
+    """Parametric Softplus:
-    '''
+    """
-            return K.softplus(K.pattern_broadcast(self.betas, self.param_broadcast) * x) * K.pattern_broadcast(self.alphas, self.param_broadcast)
+            return (K.softplus(K.pattern_broadcast(self.betas,
-    '''Thresholded Rectified Linear Unit:
+    """Thresholded Rectified Linear Unit:
-    '''
+    """
-    '''S-shaped Rectified Linear Unit:
+    """S-shaped Rectified Linear Unit:
-    '''
+    """
-                 t_right_init='glorot_uniform', a_right_init='one', shared_axes=None, **kwargs):
+                 t_right_init='glorot_uniform', a_right_init='one',
-            t_right_actual = K.pattern_broadcast(self.t_right_actual, self.param_broadcast)
+            t_right_actual = K.pattern_broadcast(self.t_right_actual,
-    '''Convolution operator for filtering neighborhoods of one-dimensional inputs.
+    """Convolution operator for filtering neighborhoods of one-dimensional inputs.
-    '''
+    """
-    '''Atrous Convolution operator for filtering neighborhoods of one-dimensional inputs.
+    """Atrous Convolution operator for filtering neighborhoods of one-dimensional inputs.
-    '''
+    """
-    '''Convolution operator for filtering windows of two-dimensional inputs.
+    """Convolution operator for filtering windows of two-dimensional inputs.
-    '''
+    """
-    '''Transposed convolution operator for filtering windows of two-dimensional inputs.
+    """Transposed convolution operator for filtering windows of two-dimensional inputs.
-    '''
+        - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)
-    '''Atrous Convolution operator for filtering windows of two-dimensional inputs.
+    """Atrous Convolution operator for filtering windows of two-dimensional inputs.
-    '''
+    """
-    '''Separable convolution operator for 2D inputs.
+    """Separable convolution operator for 2D inputs.
-    '''
+    """
-    '''Convolution operator for filtering windows of three-dimensional inputs.
+    """Convolution operator for filtering windows of three-dimensional inputs.
-    '''
+    """
-    '''Repeat each temporal step `length` times along the time axis.
+    """Repeat each temporal step `length` times along the time axis.
-    '''
+    """
-    '''Repeat the rows and columns of the data
+    """Repeat the rows and columns of the data
-    '''
+    """
-    '''Repeat the first, second and third dimension of the data
+    """Repeat the first, second and third dimension of the data
-    '''
+    """
-    '''Zero-padding layer for 1D input (e.g. temporal sequence).
+    """Zero-padding layer for 1D input (e.g. temporal sequence).
-    '''
+    """
-    '''Zero-padding layer for 2D input (e.g. picture).
+    """Zero-padding layer for 2D input (e.g. picture).
-    '''
+    """
-    '''Zero-padding layer for 3D data (spatial or spatio-temporal).
+    """Zero-padding layer for 3D data (spatial or spatio-temporal).
-    '''
+    """
-    '''Cropping layer for 1D input (e.g. temporal sequence).
+    """Cropping layer for 1D input (e.g. temporal sequence).
-    '''
+    """
-    '''Cropping layer for 2D input (e.g. picture).
+    """Cropping layer for 2D input (e.g. picture).
-    '''
+    """
-    '''Cropping layer for 3D data (e.g. spatial or spatio-temporal).
+    """Cropping layer for 3D data (e.g. spatial or spatio-temporal).
-    '''
+    """
-    '''Abstract base class for convolutional recurrent layers.
+    """Abstract base class for convolutional recurrent layers.
-    '''
+    """
-    '''Convolutional LSTM.
+    """Convolutional LSTM.
-    '''
+    """
-    '''Masks an input sequence by using a mask value to
+    """Masks an input sequence by using a mask value to
-    '''
+    """
-    '''Applies Dropout to the input. Dropout consists in randomly setting
+    """Applies Dropout to the input. Dropout consists in randomly setting
-    '''
+    """
-    '''This version performs the same function as Dropout, however it drops
+    """This version performs the same function as Dropout, however it drops
-    '''
+    """
-    '''This version performs the same function as Dropout, however it drops
+    """This version performs the same function as Dropout, however it drops
-    '''
+    """
-    '''This version performs the same function as Dropout, however it drops
+    """This version performs the same function as Dropout, however it drops
-    '''
+    """
-    '''Applies an activation function to an output.
+    """Applies an activation function to an output.
-    '''
+    """
-    '''Reshapes an output to a certain shape.
+    """Reshapes an output to a certain shape.
-    '''
+    """
-        '''Find and replace a single missing dimension in an output shape
+        """Find and replace a single missing dimension in an output shape
-        '''
+        """
-    '''Permutes the dimensions of the input according to a given pattern.
+    """Permutes the dimensions of the input according to a given pattern.
-    '''
+    """
-    '''Flattens the input. Does not affect the batch size.
+    """Flattens the input. Does not affect the batch size.
-    '''
+    """
-    '''Repeats the input n times.
+    """Repeats the input n times.
-    '''
+    """
-    '''Used for evaluating an arbitrary Theano / TensorFlow expression
+    """Used for evaluating an arbitrary Theano / TensorFlow expression
-    '''
+    """
-    '''Just your regular fully connected NN layer.
+    """Just your regular fully connected NN layer.
-    '''
+    """
-    '''Layer that returns its input unchanged, but applies an update
+    """Layer that returns its input unchanged, but applies an update
-    '''
+    """
-    '''A dense maxout layer.
+    """A dense maxout layer.
-    '''
+    """
-    '''Densely connected highway network,
+    """Densely connected highway network,
-    '''
+    """
-    '''Apply a same Dense layer for each dimension[1] (time_dimension) input.
+    """Apply a same Dense layer for each dimension[1] (time_dimension) input.
-    '''
+    """
-    '''Turn positive integers (indexes) into dense vectors of fixed size.
+    """Turn positive integers (indexes) into dense vectors of fixed size.
-    input_ndim = 2
+    """
-    '''The `LocallyConnected1D` layer works similarly to
+    """The `LocallyConnected1D` layer works similarly to
-    '''
+    """
-    '''The `LocallyConnected2D` layer works similarly
+    """The `LocallyConnected2D` layer works similarly
-    '''
+    """
-    '''Apply to the input an additive zero-centered Gaussian noise with
+    """Apply to the input an additive zero-centered Gaussian noise with
-    '''
+    """
-    '''Apply to the input an multiplicative one-centered Gaussian noise
+    """Apply to the input an multiplicative one-centered Gaussian noise
-    '''
+        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)
-    '''Normalize the activations of the previous layer at each batch,
+    """Normalize the activations of the previous layer at each batch,
-    '''
+    """
-    input_dim = 3
+    """Abstract class for different pooling 1D layers.
-    '''Max pooling operation for temporal data.
+    """Max pooling operation for temporal data.
-    '''
+    """
-    '''Average pooling for temporal data.
+    """Average pooling for temporal data.
-    '''
+    """
-    '''
+    """Abstract class for different pooling 2D layers.
-    '''Max pooling operation for spatial data.
+    """Max pooling operation for spatial data.
-    '''
+    """
-    '''Average pooling operation for spatial data.
+    """Average pooling operation for spatial data.
-    '''
+    """
-    '''
+    """Abstract class for different pooling 3D layers.
-    '''Max pooling operation for 3D data (spatial or spatio-temporal).
+    """Max pooling operation for 3D data (spatial or spatio-temporal).
-    '''
+    """
-    '''Average pooling operation for 3D data (spatial or spatio-temporal).
+    """Average pooling operation for 3D data (spatial or spatio-temporal).
-    '''
+    """
-    '''Global average pooling operation for temporal data.
+    """Global average pooling operation for temporal data.
-    '''
+    """
-    '''Global max pooling operation for temporal data.
+    """Global max pooling operation for temporal data.
-    '''
+    """
-    '''Global average pooling operation for spatial data.
+    """Global average pooling operation for spatial data.
-    '''
+    """
-    '''Global max pooling operation for spatial data.
+    """Global max pooling operation for spatial data.
-    '''
+    """
-    '''Global Average pooling operation for 3D data.
+    """Global Average pooling operation for 3D data.
-    '''
+    """
-    '''Global Max pooling operation for 3D data.
+    """Global Max pooling operation for 3D data.
-    '''
+    """
-    '''
+    """Apply y.w + b for every temporal slice y of x.
-    '''Abstract base class for recurrent layers.
+    """Abstract base class for recurrent layers.
-    '''
+    """
-    '''Fully-connected RNN where the output is to be fed back to input.
+    """Fully-connected RNN where the output is to be fed back to input.
-    '''
+    """
-    '''Gated Recurrent Unit - Cho et al. 2014.
+    """Gated Recurrent Unit - Cho et al. 2014.
-    '''
+    """
-    '''Long-Short Term Memory unit - Hochreiter 1997.
+    """Long-Short Term Memory unit - Hochreiter 1997.
-    '''
+    """
-        '''Assumes that self.layer is already set.
+        """Assumes that self.layer is already set.
-        '''
+        """
-    ''' Bidirectional wrapper for RNNs.
+    """ Bidirectional wrapper for RNNs.
-    '''
+    """
-    '''Parses a yaml model configuration file
+    """Parses a yaml model configuration file
-    '''
+    """
-    '''Parses a JSON model configuration file
+    """Parses a JSON model configuration file
-    '''
+    """
-    '''Linear stack of layers.
+    """Linear stack of layers.
-    '''
+    """
-        '''Adds a layer instance on top of the layer stack.
+        """Adds a layer instance on top of the layer stack.
-        '''
+        """
-        '''
+        """Removes the last layer in the model.
-        '''Returns a layer based on either its name (unique)
+        """Returns a layer based on either its name (unique)
-        '''
+        """
-        '''Returns the weights of the model,
+        """Returns the weights of the model,
-        '''
+        """
-        '''Sets the weights of the model.
+        """Sets the weights of the model.
-        '''
+        """
-        '''Configures the learning process.
+        """Configures the learning process.
-        '''
+        """
-        '''Trains the model for a fixed number of epochs.
+        """Trains the model for a fixed number of epochs.
-        '''
+        """
-        '''Computes the loss on some input data, batch by batch.
+        """Computes the loss on some input data, batch by batch.
-        '''
+        """
-        '''Generates output predictions for the input samples,
+        """Generates output predictions for the input samples,
-        '''
+        """
-        '''
+        """Returns predictions for a single batch of samples.
-        '''Single gradient update over one batch of samples.
+        """Single gradient update over one batch of samples.
-        '''
+        """
-        '''Evaluates the model over a single batch of samples.
+        """Evaluates the model over a single batch of samples.
-        '''
+        """
-        '''Generates class probability predictions for the input samples
+        """Generates class probability predictions for the input samples
-        '''
+        """
-        '''Generate class predictions for the input samples
+        """Generate class predictions for the input samples
-        '''
+        """
-        '''Fits the model on data generated batch-by-batch by
+        """Fits the model on data generated batch-by-batch by
-        '''
+        """
-        '''Evaluates the model on a data generator. The generator should
+        """Evaluates the model on a data generator. The generator should
-        '''
+        """
-        '''Generates predictions for the input samples from a data generator.
+        """Generates predictions for the input samples from a data generator.
-        '''
+        """
-        '''Returns the model configuration
+        """Returns the model configuration
-        '''
+        """
-        '''
+        """Supports legacy formats
-    '''
+    """Expects a binary class matrix instead of a vector of scalar classes.
-    '''Expects an array of integer classes.
+    """Expects an array of integer classes.
-    '''
+    """
-        # Returns:
+        # Returns
-        beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.
+        beta_1: float, 0 < beta < 1. Generally close to 1.
-'''Fairly basic set of tools for real-time data augmentation on image data.
+"""Fairly basic set of tools for real-time data augmentation on image data.
-'''
+"""
-    '''Load an image into PIL format.
+    """Load an image into PIL format.
-    '''
+    """
-    '''Generate minibatches with
+    """Generate minibatches with
-    '''
+    """
-        '''Required for featurewise_center, featurewise_std_normalization
+        """Required for featurewise_center, featurewise_std_normalization
-        '''
+        """
-    '''Pads each sequence to the same length:
+    """Pads each sequence to the same length:
-    '''
+    """
-    '''This generates an array where the ith element
+    """This generates an array where the ith element
-    '''
+    """
-    '''Take a sequence (list of indexes of words),
+    """Take a sequence (list of indexes of words),
-    '''
+    """
-'''These preprocessing utilities would greatly benefit
+"""These preprocessing utilities would greatly benefit
-'''
+"""
-    '''
+    """prune: sequence of characters to filter out
-        '''The class allows to vectorize a text corpus, by turning each
+        """The class allows to vectorize a text corpus, by turning each
-        '''
+        """
-        '''Required before using texts_to_sequences or texts_to_matrix
+        """Required before using texts_to_sequences or texts_to_matrix
-        '''
+        """
-        '''Required before using sequences_to_matrix
+        """Required before using sequences_to_matrix
-        '''
+        """
-        '''Transforms each text in texts in a sequence of integers.
+        """Transforms each text in texts in a sequence of integers.
-        '''
+        """
-        '''Transforms each text in texts in a sequence of integers.
+        """Transforms each text in texts in a sequence of integers.
-        '''
+        """
-        '''Convert a list of texts to a Numpy matrix,
+        """Convert a list of texts to a Numpy matrix,
-        '''
+        """
-        '''Converts a list of sequences into a Numpy matrix,
+        """Converts a list of sequences into a Numpy matrix,
-        '''
+        """
-    '''Downloads a file from a URL if it not already in the cache.
+    """Downloads a file from a URL if it not already in the cache.
-    '''
+    """
-    '''Validates a file against a MD5 hash
+    """Validates a file against a MD5 hash
-    '''
+    """
-    '''Serialize user defined function.'''
+    """Serialize user defined function.
-    '''Deserialize user defined function.'''
+    """Deserialize user defined function."""
-        '''Dislays a progress bar.
+        """Dislays a progress bar.
-        '''
+        """
-        '''Updates the progress bar.
+        """Updates the progress bar.
-        '''
+        """
-    '''Representation of HDF5 dataset which can be used instead of a
+    """Representation of HDF5 dataset which can be used instead of a
-    '''
+    """
-    '''
+    """Instantiate a layer from a config dictionary.
-    '''
+    """
-    '''Prints a summary of a layer
+    """Prints a summary of a layer.
-    '''
+    """
-    '''Convert class vector (integers from 0 to nb_classes) to binary class matrix, for use with categorical_crossentropy.
+    """Converts class vector (integers from 0 to nb_classes)
-    '''
+    """
-    res *= -1.0/len(y)
+    res *= -1.0 / len(y)
-    '''Converts a kernel matrix (Numpy array)
+    """Converts a kernel matrix (Numpy array)
-    '''
+    """
-def conv_output_length(input_length, filter_size, border_mode, stride, dilation=1):
+def conv_output_length(input_length, filter_size,
-    '''
+    """
-    '''
+    """
-    '''Test routine for a layer with a single input tensor
+    """Test routine for a layer with a single input tensor
-    '''
+    """
-    '''
+    """Clean up after tensorflow tests.
-    '''Base class for the Keras scikit-learn wrapper.
+    """Base class for the Keras scikit-learn wrapper.
-    '''
+    """
-        '''Check for user typos in "params" keys to avoid
+        """Check for user typos in "params" keys to avoid
-        '''
+        """
-        '''Get parameters for this estimator.
+        """Get parameters for this estimator.
-        '''
+        """
-        '''Set the parameters of this estimator.
+        """Set the parameters of this estimator.
-        '''
+        """
-        '''Construct a new model with build_fn and fit the model according
+        """Construct a new model with build_fn and fit the model according
-        '''
+        """
-        '''Filter sk_params and return those in fn's arguments
+        """Filter sk_params and return those in fn's arguments
-        '''
+        """
-    '''
+    """Implementation of the scikit-learn classifier API for Keras.
-        '''Returns the class predictions for the given test data.
+        """Returns the class predictions for the given test data.
-        '''
+        """
-        '''Returns class probability estimates for the given test data.
+        """Returns class probability estimates for the given test data.
-        '''
+        """
-        '''Returns the mean accuracy on the given test data and labels.
+        """Returns the mean accuracy on the given test data and labels.
-        '''
+        """
-    '''
+    """Implementation of the scikit-learn regressor API for Keras.
-        '''Returns predictions for the given test data.
+        """Returns predictions for the given test data.
-        '''
+        """
-        '''Returns the mean loss on the given test data and labels.
+        """Returns the mean loss on the given test data and labels.
-        '''
+        """
-    '''Abstract optimizer base class.
+    """Abstract optimizer base class.
-    '''
+    """
-        '''Sets the weights of the optimizer, from Numpy arrays.
+        """Sets the weights of the optimizer, from Numpy arrays.
-        '''
+        """
-        '''
+        """Returns the current value of the weights of the optimizer.
-    '''Stochastic gradient descent, with support for momentum,
+    """Stochastic gradient descent, with support for momentum,
-    '''
+    """
-        self.inital_decay = decay
+        self.initial_decay = decay
-        if self.inital_decay > 0:
+        if self.initial_decay > 0:
-    '''RMSProp optimizer.
+    """RMSProp optimizer.
-    '''
+    """
-        self.__dict__.update(locals())
+        self.epsilon = epsilon
-        self.inital_decay = decay
+        self.initial_decay = decay
-        if self.inital_decay > 0:
+        if self.initial_decay > 0:
-    '''Adagrad optimizer.
+    """Adagrad optimizer.
-    '''
+    """
-        self.__dict__.update(locals())
+        self.epsilon = epsilon
-        self.inital_decay = decay
+        self.initial_decay = decay
-        if self.inital_decay > 0:
+        if self.initial_decay > 0:
-    '''Adadelta optimizer.
+    """Adadelta optimizer.
-    '''
+    """
-        self.__dict__.update(locals())
+        self.rho = rho
-        self.inital_decay = decay
+        self.initial_decay = decay
-        if self.inital_decay > 0:
+        if self.initial_decay > 0:
-    '''Adam optimizer.
+    """Adam optimizer.
-    '''
+    """
-        self.__dict__.update(locals())
+        self.epsilon = epsilon
-        self.inital_decay = decay
+        self.initial_decay = decay
-        if self.inital_decay > 0:
+        if self.initial_decay > 0:
-        lr_t = lr * K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t))
+        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /
-     of Adam based on the infinity norm.
+    """Adamax optimizer from Adam paper's Section 7.
-    '''
+    """
-        self.__dict__.update(locals())
+        self.epsilon = epsilon
-        self.inital_decay = decay
+        self.initial_decay = decay
-        if self.inital_decay > 0:
+        if self.initial_decay > 0:
-    Nesterov Adam optimizer: Much like Adam is essentially RMSprop with momentum,
+    """Nesterov Adam optimizer.
-    '''
+    """
-        self.__dict__.update(locals())
+        self.epsilon = epsilon
-# aliases
+# Aliases.
-        p = p * (desired / (K.epsilon() + norms))
+        p *= (desired / (K.epsilon() + norms))
-                           check_batch_dim=True,
+                           check_batch_axis=True,
-    '''Users may pass data as a list of arrays, dictionary of arrays,
+    """Normalize inputs and targets provided by users.
-    '''
+
-                if not j and not check_batch_dim:
+                if not j and not check_batch_axis:
-    w_lengths = [w.shape[0] for w in W]
+def check_array_lengths(inputs, targets, weights):
-    '''This shuffles an array in a batch-wise fashion.
+    """This shuffles an array in a batch-wise fashion.
-    '''
+    """
-    '''
+    """Returns a list of batch indices (tuples of indices).
-    '''This takes an array-like, or a list of
+    """This takes an array-like, or a list of
-    # Arguments:
+    # Arguments
-    '''
+    """
-    '''Transforms an objective function `fn(y_true, y_pred)`
+    """Transforms an objective function `fn(y_true, y_pred)`
-    '''
+    """
-    '''Performs weight input validation and standardization
+    """Performs weight input validation and standardization
-    '''
+    """
-    '''Builds a queue out of a data generator.
+    """Builds a queue out of a data generator.
-
+    """
-        '''Configures the model for training.
+        """Configures the model for training.
-        '''
+        """
-        '''Abstract fit function for f(ins).
+        """Abstract fit function for f(ins).
-        '''
+        """
-        callbacks._set_params({
+        callbacks.set_model(callback_model)
-        '''Abstract method to loop over some data in batches.
+        """Abstract method to loop over some data in batches.
-        '''
+        """
-        '''Abstract method to loop over some data in batches.
+        """Abstract method to loop over some data in batches.
-        '''
+        """
-                               check_batch_dim=True, batch_size=None):
+                               check_batch_axis=True, batch_size=None):
-                                   check_batch_dim=False,
+                                   check_batch_axis=False,
-                                   check_batch_dim=False,
+                                   check_batch_axis=False,
-        '''Trains the model for a fixed number of epochs (iterations on a dataset).
+        """Trains the model for a fixed number of epochs (iterations on a dataset).
-        '''
+        """
-            check_batch_dim=False,
+            check_batch_axis=False,
-                check_batch_dim=False,
+                check_batch_axis=False,
-        '''Returns the loss value and metrics values for the model
+        """Returns the loss value and metrics values for the model
-        '''
+        """
-            check_batch_dim=False,
+            check_batch_axis=False,
-        '''Generates output predictions for the input samples,
+        """Generates output predictions for the input samples,
-        '''
+        """
-                                   check_batch_dim=False)
+                                   check_batch_axis=False)
-        '''Runs a single gradient update on a single batch of data.
+        """Runs a single gradient update on a single batch of data.
-        '''
+        """
-            check_batch_dim=True)
+            check_batch_axis=True)
-        '''Test the model on a single batch of samples.
+        """Test the model on a single batch of samples.
-        '''
+        """
-            check_batch_dim=True)
+            check_batch_axis=True)
-        '''
+        """Returns predictions for a single batch of samples.
-        '''Fits the model on data generated batch-by-batch by
+        """Fits the model on data generated batch-by-batch by
-        '''
+        """
-        callbacks._set_params({
+        callbacks.set_model(callback_model)
-        '''Evaluates the model on a data generator. The generator should
+        """Evaluates the model on a data generator. The generator should
-        '''
+        """
-        '''Generates predictions for the input samples from a data generator.
+        """Generates predictions for the input samples from a data generator.
-        '''
+        """
-    '''LeCun uniform variance scaling initializer.
+    """LeCun uniform variance scaling initializer.
-    '''
+    """
-    '''Glorot normal variance scaling initializer.
+    """Glorot normal variance scaling initializer.
-    '''
+    """
-    '''He normal variance scaling initializer.
+    """He normal variance scaling initializer.
-    '''
+    """
-    '''
+    """He uniform variance scaling initializer.
-    '''Orthogonal initializer.
+    """Orthogonal initializer.
-    '''
+    """
-    def _set_params(self, params):
+    def set_params(self, params):
-            callback._set_params(params)
+            callback.set_params(params)
-    def _set_model(self, model):
+    def set_model(self, model):
-            callback._set_model(model)
+            callback.set_model(model)
-    def _set_params(self, params):
+    def set_params(self, params):
-    def _set_model(self, model):
+    def set_model(self, model):
-    def _set_model(self, model):
+    def set_model(self, model):
-        # assuming convolution kernels (2D or 3D).
+        # Assuming convolution kernels (2D or 3D).
-        # no specific assumptions
+        # No specific assumptions.
-    ''' Reference: LeCun 98, Efficient Backprop
+    '''LeCun uniform variance scaling initializer.
-    ''' Reference: Glorot & Bengio, AISTATS 2010
+    '''Glorot normal variance scaling initializer.
-    ''' Reference:  He et al., http://arxiv.org/abs/1502.01852
+    '''He normal variance scaling initializer.
-    ''' From Lasagne. Reference: Saxe et al., http://arxiv.org/abs/1312.6120
+    '''Orthogonal initializer.
-    # pick the one with the correct shape
+    # Pick the one with the correct shape.
-    '''Calculates the mean accuracy rate across all predictions for binary
+    """Binary accuracy metric.
-    '''
+    """
-    '''Calculates the mean accuracy rate across all predictions for
+    """Categorical accuracy metric.
-    '''
+    """
-    '''Same as categorical_accuracy, but useful when the predictions are for
+    """Sparse version of the categorical accuracy metric.
-    '''
+    """
-    '''Calculates the top-k categorical accuracy rate, i.e. success when the
+    """Categorical accuracy metric for top-k accuracy.
-    '''
+    """
-    '''Calculates the mean squared error (mse) rate
+    """Mean squared error metric.
-    '''
+    """
-    '''Calculates the mean absolute error (mae) rate
+    """Mean absolute error metric.
-    '''
+    """
-    '''Calculates the mean absolute percentage error (mape) rate
+    """Mean absolute percentage error metric.
-    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K.epsilon(), np.inf))
+    """
-    '''Calculates the mean squared logarithmic error (msle) rate
+    """Mean squared logarithmic error metric.
-    '''
+    """
-    '''Calculates the hinge loss, which is defined as
+    """Hinge loss metric.
-    '''
+    """
-    '''
+    """Computes the squared value of the hinge loss.
-    '''Calculates the cross-entropy value for multiclass classification
+    """Categorical cross-entropy metric.
-    '''
+    """
-    '''Calculates the cross-entropy value for multiclass classification
+    """Sparse version of the categorical cross-entropy metric.
-    '''
+    """
-    '''
+    """Computes the cross-entropy value for binary classification problems.
-    '''
+    """Computes the KLdivergence between prediction and target values.
-    '''
+    """Computes the poisson function over prediction and target values.
-    '''
+    """Computes the cosine similarity between the prediction and target values.
-    '''Calculates the Matthews correlation coefficient measure for quality
+    """Matthews correlation metric.
-    '''
+    """
-    '''Calculates the precision, a metric for multi-label classification of
+    """Precision metric.
-    '''
+    """
-    '''Calculates the recall, a metric for multi-label classification of
+    """Recall metric.
-    '''
+    """
-    '''Calculates the F score, the weighted harmonic mean of precision and recall.
+    """Computes the F score.
-    '''
+    """
-        
+
-    '''
+    """Computes the f-measure, the harmonic mean of precision and recall.
-    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K.epsilon(), np.inf))
+    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),
-    '''expects an array of integer classes.
+    '''Expects an array of integer classes.
-# aliases
+# Aliases.
-    '''
+    """Regularizer based on the eignvalues of a weight matrix.
-if K._BACKEND == 'theano':
+if K.backend() == 'theano':
-@pytest.mark.skipif(K._BACKEND != 'tensorflow', reason="Requires TF backend")
+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')
-    '''Constrain the weights incident to each hidden unit to have a norm less than or equal to a desired value.
+    """MaxNorm weight constraint.
-            to constrain the weights of each filter tensor of size (nb_row, nb_col, stack_size).
+        axis: integer, axis along which to calculate weight norms.
-    '''
+    """
-    '''
+    """Constrains the weights to be non-negative.
-    '''Constrain the weights incident to each hidden unit to have unit norm.
+    """Constrains the weights incident to each hidden unit to have unit norm.
-    '''
+        axis: integer, axis along which to calculate weight norms.
-        return p / (K.epsilon() + K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True)))
+        return p / (K.epsilon() + K.sqrt(K.sum(K.square(p),
-from .utils.generic_utils import get_from_module
+
-    the metrics being monitored.
+    """Callback that accumulates epoch averages of metrics.
-    every Keras model.
+    This callback is automatically applied to every Keras model.
-    into a `History` object.
+    """Callback that records events into a `History` object.
-        headers: Optional custom HTTP headers.
+        root: String; root url of the target server.
-                          'Content-Type': 'application/json'}):
+                 headers=None):
-    """ Tensorboard basic visualizations.
+    """Tensorboard basic visualizations.
-        if K._BACKEND != 'tensorflow':
+        if K.backend() != 'tensorflow':
-from collections import deque, OrderedDict, Iterable
+from collections import deque
-    '''Abstract base class used to build new callbacks.
+    """Abstract base class used to build new callbacks.
-    '''
+    """
-    '''Callback that accumulates epoch averages of
+    """Callback that accumulates epoch averages of
-    '''
+    """
-    '''
+    """Callback that prints metrics to stdout.
-    '''Callback that records events
+    """Callback that records events
-    '''
+    """
-    '''Save the model after every epoch.
+    """Save the model after every epoch.
-    the validation loss.
+    then the model checkpoints will be saved with the epoch number and
-    '''Stop training when a monitored quantity has stopped improving.
+    """Stop training when a monitored quantity has stopped improving.
-    '''
+    """
-        self.wait = 0       # Allow instances to be re-used
+        self.wait = 0  # Allow instances to be re-used
-    '''Callback used to stream events to a server.
+    """Callback used to stream events to a server.
-    '''
+        root: Root url of the target server.
-                  'root server at ' + str(self.root))
+        except requests.exceptions.RequestException:
-    '''Learning rate scheduler.
+    """Learning rate scheduler.
-    '''
+    """
-    ''' Tensorboard basic visualizations.
+    """ Tensorboard basic visualizations.
-    '''
+    """
-    '''Reduce learning rate when a metric has stopped improving.
+    """Reduce learning rate when a metric has stopped improving.
-    '''
+    """
-        super(Callback, self).__init__()
+        super(ReduceLROnPlateau, self).__init__()
-        if self.mode == 'min' or (self.mode == 'auto' and 'acc' not in self.monitor):
+        if (self.mode == 'min' or
-    '''Callback that streams epoch results to a csv file.
+    """Callback that streams epoch results to a csv file.
-    '''
+    """
-                    self.append_header = len(f.readline()) == 0
+                    self.append_header = bool(len(f.readline()))
-                return '"[%s]"' % (', '.join(map(lambda x: str(x), k)))
+                return '"[%s]"' % (', '.join(map(str, k)))
-    def on_train_end(self, logs={}):
+    def on_train_end(self, logs=None):
-     - `on_train_begin` and `on_train_end` expect one positional argument: `logs`
+     - `on_epoch_begin` and `on_epoch_end` expect two positional arguments:
-        batch_print_callback = LambdaCallback(on_batch_begin=lambda batch, logs: print(batch))
+        batch_print_callback = LambdaCallback(
-        plot_loss_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: plt.plot(np.arange(epoch), logs['loss']))
+        plot_loss_callback = LambdaCallback(
-        model.fit(..., callbacks=[batch_print_callback, plot_loss_callback, cleanup_callback])
+        cleanup_callback = LambdaCallback(
-        super(Callback, self).__init__()
+        super(LambdaCallback, self).__init__()
-        self.on_train_end = on_train_end if on_train_end else lambda logs: None
+        if on_epoch_begin is not None:
-    `alpha * log(1 + exp(beta * x))`
+    `f(x) = alpha * log(1 + exp(beta * x))`
-    `f(x) = x for x > theta`
+    `f(x) = x for x > theta`,
-    '''S-shaped Rectified Linear Unit.
+    '''S-shaped Rectified Linear Unit:
-        samples in different successive batches.
+        for the samples in the next batch. This assumes a one-to-one mapping
-                  a `batch_input_shape=(...)` to the first layer in your model.
+                  `batch_input_shape=(...)` to the first layer in your model.
-                  a `batch_shape=(...)` to all the first layers in your model.
+                  `batch_shape=(...)` to all the first layers in your model.
-    - [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://web.stanford.edu/~jurafsky/pubs/P15-1107.pdf)
+    - [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://arxiv.org/abs/1506.01057)
-        - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](http://arxiv.org/pdf/1502.01852v1.pdf)
+        - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)
-        - [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](http://arxiv.org/pdf/1511.07289v1.pdf)
+        - [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289v1)
-        - [Zero-Bias Autoencoders and the Benefits of Co-Adapting Features](http://arxiv.org/pdf/1402.3337.pdf)
+        - [Zero-Bias Autoencoders and the Benefits of Co-Adapting Features](http://arxiv.org/abs/1402.3337)
-        [1] [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285 "arXiv:1603.07285v1 [stat.ML]")
+        [1] [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)
-        Precipitation Nowcasting](http://arxiv.org/pdf/1506.04214v1.pdf)
+        Precipitation Nowcasting](http://arxiv.org/abs/1506.04214v1)
-        - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/pdf/1411.4280.pdf)
+        - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)
-        - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/pdf/1411.4280.pdf)
+        - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)
-        - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/pdf/1411.4280.pdf)
+        - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)
-        - [Maxout Networks](http://arxiv.org/pdf/1302.4389.pdf)
+        - [Maxout Networks](http://arxiv.org/abs/1302.4389)
-        - [Highway Networks](http://arxiv.org/pdf/1505.00387v2.pdf)
+        - [Highway Networks](http://arxiv.org/abs/1505.00387v2)
-        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.pdf)
+        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)
-        - [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](http://arxiv.org/pdf/1412.3555v1.pdf)
+        - [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)
-    def __init__(self, callbacks=[], queue_length=10):
+
-    def on_epoch_begin(self, epoch, logs={}):
+    def on_epoch_begin(self, epoch, logs=None):
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-    def on_batch_begin(self, batch, logs={}):
+    def on_batch_begin(self, batch, logs=None):
-           self._delta_t_batch and delta_t_median > 0.1:
+        if (self._delta_t_batch > 0. and
-    def on_batch_end(self, batch, logs={}):
+    def on_batch_end(self, batch, logs=None):
-        if self._delta_t_batch > 0. and (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):
+        if (self._delta_t_batch > 0. and
-    def on_train_begin(self, logs={}):
+    def on_train_begin(self, logs=None):
-    def on_train_end(self, logs={}):
+    def on_train_end(self, logs=None):
-    def on_epoch_begin(self, epoch, logs={}):
+    def on_epoch_begin(self, epoch, logs=None):
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-    def on_batch_begin(self, batch, logs={}):
+    def on_batch_begin(self, batch, logs=None):
-    def on_batch_end(self, batch, logs={}):
+    def on_batch_end(self, batch, logs=None):
-    def on_train_begin(self, logs={}):
+    def on_train_begin(self, logs=None):
-    def on_train_end(self, logs={}):
+    def on_train_end(self, logs=None):
-    def on_epoch_begin(self, epoch, logs={}):
+    def on_epoch_begin(self, epoch, logs=None):
-    def on_batch_end(self, batch, logs={}):
+    def on_batch_end(self, batch, logs=None):
-                logs[k] = self.totals[k] / self.seen
+    def on_epoch_end(self, epoch, logs=None):
-    def on_train_begin(self, logs={}):
+    def on_train_begin(self, logs=None):
-    def on_epoch_begin(self, epoch, logs={}):
+    def on_epoch_begin(self, epoch, logs=None):
-    def on_batch_begin(self, batch, logs={}):
+    def on_batch_begin(self, batch, logs=None):
-    def on_batch_end(self, batch, logs={}):
+    def on_batch_end(self, batch, logs=None):
-        # will be handled by on_epoch_end
+        # Skip progbar update for the last batch;
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-    def on_train_begin(self, logs={}):
+    def on_train_begin(self, logs=None):
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-    def __init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto'):
+    def __init__(self, monitor='val_loss',
-    def on_train_begin(self, logs={}):
+    def on_train_begin(self, logs=None):
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-    def on_train_end(self, logs={}):
+    def on_train_end(self, logs=None):
-                 headers={'Accept': 'application/json', 'Content-Type': 'application/json'}):
+                 headers={'Accept': 'application/json',
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-            'Optimizer must have a "lr" attribute.'
+    def on_epoch_begin(self, epoch, logs=None):
-    def __init__(self, log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False):
+    def __init__(self, log_dir='./logs',
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-            raise ValueError('ReduceLROnPlateau does not support a factor >= 1.0.')
+            raise ValueError('ReduceLROnPlateau '
-                          'fallback to auto mode.' % (self.mode), RuntimeWarning)
+                          'fallback to auto mode.' % (self.mode),
-    def on_train_begin(self, logs={}):
+    def on_train_begin(self, logs=None):
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-    def on_train_begin(self, logs={}):
+    def on_train_begin(self, logs=None):
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_end(self, epoch, logs=None):
-            self.writer = csv.DictWriter(self.csv_file, fieldnames=['epoch'] + self.keys)
+            self.writer = csv.DictWriter(self.csv_file,
-    output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta
+    output = (x - mean) / sqrt(var + epsilon) * gamma + beta
-        if type(v) == str:
+        if isinstance(v, str):
-if type(grads) in {list, tuple}:
+if isinstance(grads, (list, tuple)):
-if type(loss_grads) in {list, tuple}:
+if isinstance(loss_grads, (list, tuple)):
-if type(grads) in {list, tuple}:
+if isinstance(grads, (list, tuple)):
-        if type(shared_axes) is not list and type(shared_axes) is not tuple:
+        if not isinstance(shared_axes, (list, tuple)):
-        if type(shared_axes) is not list and type(shared_axes) is not tuple:
+        if not isinstance(shared_axes, (list, tuple)):
-        if type(shared_axes) is not list and type(shared_axes) is not tuple:
+        if not isinstance(shared_axes, (list, tuple)):
-        if type(layer) in (Model, Sequential):
+        if isinstance(layer, (Model, Sequential)):
-from keras.layers import Reshape, Lambda, merge, Permute, TimeDistributed
+from keras.layers import Input, Dense, Activation
-from keras.layers import Dense, Dropout, Embedding, LSTM, Input, Bidirectional
+from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional
-from keras.layers import LSTM, SimpleRNN, GRU
+from keras.layers import Dense, Activation, Embedding
-from keras.layers import Dense, Activation, Dropout
+from keras.layers import Dense, Activation
-from keras.models import Sequential, Model
+from keras.models import Model
-from keras.optimizers import SGD, Adam, RMSprop
+from keras.optimizers import RMSprop
-from keras.optimizers import SGD, RMSprop
+from keras.optimizers import RMSprop
-from keras.layers import Input, Convolution2D, MaxPooling2D, AveragePooling2D
+from keras.layers import Input, AveragePooling2D
-                target_shape = self.get_output_shape_for(input_shape)
+                target_shape = self.get_output_shape_for(input_shape)[1:]
-                    original_shape[3] * width_factor if original_shape[3] is not None else None))
+                     original_shape[3] * width_factor if original_shape[3] is not None else None))
-                    original_shape[2] * width_factor if original_shape[2] is not None else None, None))
+                     original_shape[2] * width_factor if original_shape[2] is not None else None, None))
-def _preprocess_deconv_output_shape(shape, dim_ordering):
+def _preprocess_deconv_output_shape(x, shape, dim_ordering):
-    output_shape = _preprocess_deconv_output_shape(output_shape, dim_ordering)
+    output_shape = _preprocess_deconv_output_shape(x, output_shape, dim_ordering)
-                continue
+    for batch_size in [None, nb_samples]:
-                       fixed_batch_size=True)
+                rows = conv_input_length(nb_row, 3, border_mode, subsample[0])
-                       fixed_batch_size=True)
+                layer_test(convolutional.Deconvolution2D,
-    # Arguments:
+    # Arguments
-    # Examples:
+    # Examples
-                return theano.sandbox.cuda.dnn.dnn_batch_normalization_test(
+                result = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(
-                return theano.sandbox.cuda.dnn.dnn_batch_normalization_test(
+                result = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(
-            if 'acc' in self.monitor:
+            if self.monitor.startswith(('acc', 'fmeasure')):
-            if 'acc' in self.monitor:
+            if self.monitor.startswith(('acc', 'fmeasure')):
-            if s is None:
+            if i is not None:
-            if s is None:
+            if i is not None:
-        inputs_shape: optional shape tuple, only to be specified
+        input_shape: optional shape tuple, only to be specified
-        inputs_shape: optional shape tuple, only to be specified
+        input_shape: optional shape tuple, only to be specified
-        inputs_shape: optional shape tuple, only to be specified
+        input_shape: optional shape tuple, only to be specified
-        inputs_shape: optional shape tuple, only to be specified
+        input_shape: optional shape tuple, only to be specified
-        inputs_shape: optional shape tuple, only to be specified
+        input_shape: optional shape tuple, only to be specified
-                    'supported for all TF ops.')
+    raise RuntimeError('This example can only run with the '
-        self.init = initializations.get(init, dim_ordering='th')
+        self.init = initializations.get(init)
-                                 initializer=self.init,
+                                 initializer=functools.partial(self.init,
-        self.init = initializations.get(init, dim_ordering=dim_ordering)
+        self.init = initializations.get(init)
-                                 initializer=self.init,
+                                 initializer=functools.partial(self.init,
-        self.init = initializations.get(init, dim_ordering=dim_ordering)
+        self.init = initializations.get(init)
-                                                initializer=self.init,
+                                                initializer=functools.partial(self.init,
-                                                initializer=self.init,
+                                                initializer=functools.partial(self.init,
-        self.init = initializations.get(init, dim_ordering=dim_ordering)
+        self.init = initializations.get(init)
-                                 initializer=self.init,
+                                 initializer=functools.partial(self.init,
-        return tf.reshape(res, [-1, int(output_shape[-2])])
+        return tf.reshape(res, tf.shape(output)[:-1])
-        inputs_hash = object_list_uid(inputs)
+        if inputs is not None:
-        inputs_hash = object_list_uid(inputs)
+        if inputs is not None:
-                self.param_broadcast[i] = True
+                param_shape[i - 1] = 1
-                self.param_broadcast[i] = True
+                param_shape[i - 1] = 1
-                self.param_broadcast[i] = True
+                param_shape[i - 1] = 1
-
+        if hasattr(x, '_uses_learning_phase'):
-
+def is_explicit_shape(shape):
-    return T.reshape(x, shape)
+    y = T.reshape(x, shape)
-        return x[:, self.cropping[0]:-self.cropping[1], :]
+        if self.cropping[1] == 0:
-    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)
+    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1))
-the wordlist that the generator draws from increases in difficulty.
+This starts off with 4 letter words.  For the first 12 epochs, the
-hyperparameter tuning would be needed to get it to match Tensorflow.
+a slightly different CTC implementation, hence the different results.
-    40   0.023    0.108
+    10   0.027   0.064
-OUTPUT_DIR = "image_ocr"
+
-def paint_text(text, w, h):
+def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):
-        context.set_font_size(40)
+        if multi_fonts:
-        if box[2] > w or box[3] > h:
+        border_w_h = (4, 4)
-
+        if ud:
-                 img_w, img_h, downsample_width, val_split,
+                 img_w, img_h, downsample_factor, val_split,
-        self.downsample_width = downsample_width
+        self.downsample_factor = downsample_factor
-        self.string_list = []
+        self.string_list = [''] * self.num_words
-                if len(self.string_list) == int(self.num_words * mono_fraction):
+                if len(tmp_string_list) == int(self.num_words * mono_fraction):
-                    self.string_list.append(word)
+                    tmp_string_list.append(word)
-                if len(self.string_list) == self.num_words:
+                if len(tmp_string_list) == self.num_words:
-        if len(self.string_list) != self.num_words:
+                    tmp_string_list.append(word)
-            X_data = np.ones([size, 1, self.img_h, self.img_w])
+            X_data = np.ones([size, 1, self.img_w, self.img_h])
-            X_data = np.ones([size, self.img_h, self.img_w, 1])
+            X_data = np.ones([size, self.img_w, self.img_h, 1])
-                    X_data[i, 0, :, :] = paint_text('', self.img_w, self.img_h)
+                    X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T
-                    X_data[i, :, :, 0] = paint_text('', self.img_w, self.img_h)
+                    X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T
-                input_length[i] = self.downsample_width
+                input_length[i] = self.img_w // self.downsample_factor - 2
-                    X_data[i, 0, :, :] = paint_text(self.X_text[index + i], self.img_w, self.img_h)
+                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T
-                    X_data[i, :, :, 0] = paint_text(self.X_text[index + i], self.img_w, self.img_h)
+                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T
-                input_length[i] = self.downsample_width
+                input_length[i] = self.img_w // self.downsample_factor - 2
-        # for the RNN to learn, so start with <= 4 letter words.
+        self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,
-            self.build_word_list(64000, 12, 0.5)
+        # rebind the paint function to implement curriculum learning
-    def __init__(self, test_func, text_img_gen, num_display_words=6):
+    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):
-            OUTPUT_DIR, datetime.datetime.now().strftime('%A, %d. %B %Y %I.%M%p'))
+            OUTPUT_DIR, run_name)
-        os.makedirs(self.output_dir)
+        if not os.path.exists(self.output_dir):
-        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % epoch))
+        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))
-
+        if word_batch['the_input'][0].shape[0] < 256:
-            pylab.subplot(self.num_display_words, 1, i + 1)
+            pylab.subplot(self.num_display_words // cols, cols, i + 1)
-            pylab.xlabel('Truth = \'%s\' Decoded = \'%s\'' % (word_batch['source_str'][i], res[i]))
+            pylab.imshow(the_input.T, cmap='Greys_r')
-        pylab.savefig(os.path.join(self.output_dir, 'e%02d.png' % epoch))
+        fig.set_size_inches(10, 13)
-                    callbacks=[viz_cb, img_gen])
+
-            self.non_trainable_weights = []
+        if not hasattr(self, '_trainable_weights'):
-            self.trainable_weights.append(weight)
+            self._trainable_weights.append(weight)
-            self.non_trainable_weights.append(weight)
+            self._non_trainable_weights.append(weight)
-
+        self._trainable_weights = []
-        self.non_trainable_weights = []
+        self._trainable_weights = []
-    optimizer = optimizer_from_config(optimizer_config, custom_objects=custom_objects)
+    optimizer = optimizer_from_config(optimizer_config,
-        return layer_class.from_config(config['config'], custom_objects=custom_objects)
+        return layer_class.from_config(config['config'],
-    else:
+    if not 4 <= kernel.ndim <= 5:
-    return new_kernel
+
-    def from_config(cls, config, custom_objects={}):
+    def from_config(cls, config, custom_objects=None):
-                 transform_bias=-2,
+        if 'transform_bias' in kwargs:
-                 arguments={}, node_indices=None, tensor_indices=None,
+                 arguments=None, node_indices=None, tensor_indices=None,
-        self.arguments = arguments
+        self.arguments = arguments if arguments else {}
-          arguments={}, name=None):
+          arguments=None, name=None):
-    def from_config(cls, config, custom_objects={}):
+    def from_config(cls, config, custom_objects=None):
-    def compile(self, optimizer, loss, metrics=[], loss_weights=None,
+    def compile(self, optimizer, loss, metrics=None, loss_weights=None,
-                  nb_epoch=100, verbose=1, callbacks=[],
+    def _fit_loop(self, f, ins, out_labels=None, batch_size=32,
-                  callback_metrics=[], initial_epoch=0):
+                  callback_metrics=None, initial_epoch=0):
-        callbacks = [cbks.BaseLogger()] + callbacks + [self.history]
+        callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]
-            'metrics': callback_metrics,
+            'metrics': callback_metrics or [],
-    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[],
+    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=None,
-                      verbose=1, callbacks=[],
+                      verbose=1, callbacks=None,
-                      class_weight={},
+                      class_weight=None,
-        callbacks = [cbks.BaseLogger()] + callbacks + [self.history]
+        callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]
-def load_model(filepath, custom_objects={}):
+def load_model(filepath, custom_objects=None):
-def model_from_config(config, custom_objects={}):
+def model_from_config(config, custom_objects=None):
-def model_from_yaml(yaml_string, custom_objects={}):
+def model_from_yaml(yaml_string, custom_objects=None):
-def model_from_json(json_string, custom_objects={}):
+def model_from_json(json_string, custom_objects=None):
-    def __init__(self, layers=[], name=None):
+    def __init__(self, layers=None, name=None):
-            self.add(layer)
+        if layers:
-                metrics=[],
+                metrics=None,
-    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[],
+    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=None,
-                      verbose=1, callbacks=[],
+                      verbose=1, callbacks=None,
-def optimizer_from_config(config, custom_objects={}):
+def optimizer_from_config(config, custom_objects=None):
-    if class_name in custom_objects:
+    if custom_objects and class_name in custom_objects:
-def layer_from_config(config, custom_objects={}):
+def layer_from_config(config, custom_objects=None):
-        globals()[cls_key] = custom_objects[cls_key]
+    if custom_objects:
-            class_weight=None, sample_weight=None, **kwargs):
+            class_weight=None, sample_weight=None, initial_epoch=0, **kwargs):
-                              sample_weight=sample_weight)
+                              sample_weight=sample_weight,
-                      pickle_safe=False, **kwargs):
+                      pickle_safe=False, initial_epoch=0, **kwargs):
-                                        pickle_safe=pickle_safe)
+                                        pickle_safe=pickle_safe,
-    # Example usage
+    # Example
-    # Example usage
+    # Example
-    merged_model.add(Merge([model1, model2], mode='concat', concat_axis=1)
+    merged_model.add(Merge([model1, model2], mode='concat', concat_axis=1))
-    # Example usage:
+    # Example
-        # Example usage
+        # Example
-    def __init__(self, function, output_shape=None, arguments={}, **kwargs):
+    def __init__(self, function, output_shape=None, arguments=None, **kwargs):
-        self.arguments = arguments
+        self.arguments = arguments if arguments else {}
-    to the cost function based on the activity.
+    '''Layer that returns its input unchanged, but applies an update
-assert img_ncols == img_nrows, 'Due to the use of the Gram matrix, width and height must match.'
+img_ncols = int(width * img_nrows / height)
-__version__ = '1.1.2'
+__version__ = '1.2.0'
-      version='1.1.2',
+      version='1.2.0',
-      download_url='https://github.com/fchollet/keras/tarball/1.1.2',
+      download_url='https://github.com/fchollet/keras/tarball/1.2.0',
-    return labels[predictions.ravel() < 0.5].mean()
+    return np.mean(labels == (predictions.ravel() > 0.5))
-content_weight = 0.025
+total_variation_weight = args.tv_weight
-for i in range(10):
+for i in range(iterations):
-            input_shape = self.input_spec[0].shape
+            input_shape = K.int_shape(x)
-        input_shape = self.input_spec[0].shape
+        input_shape = K.int_shape(x)
-            input_shape = self.input_spec[0].shape
+            input_shape = K.int_shape(x)
-            input_shape = self.input_spec[0].shape
+            input_shape = K.int_shape(x)
-            input_shape = self.input_spec[0].shape
+            input_shape = K.int_shape(x)
-            input_shape = self.input_spec[0].shape
+            input_shape = K.int_shape(x)
-            input_shape = self.input_spec[0].shape
+            input_shape = K.int_shape(x)
-            input_shape = self.input_spec[0].shape
+            input_shape = K.int_shape(x)
-        input_shape = self.input_spec[0].shape
+        input_shape = K.int_shape(X)
-            X = K.reshape(X, (-1, ) + input_shape[2:])  # (nb_samples * timesteps, ...)
+            X = K.reshape(X, (-1,) + input_shape[2:])  # (nb_samples * timesteps, ...)
-        input_data = (10 * np.random.random(input_shape)).astype(input_dtype)
+        input_data_shape = list(input_shape)
-    assert expected_output_shape == actual_output_shape
+    for expected_dim, actual_dim in zip(expected_output_shape,
-    assert expected_output_shape == actual_output_shape
+    for expected_dim, actual_dim in zip(expected_output_shape,
-        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>
+        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>
-        y_shape = int_shape(y)
+        x_shape = []
-    def from_config(cls, config):
+    def from_config(cls, config, custom_objects={}):
-            function = globals()[config['function']]
+            function = globs[config['function']]
-            function = func_load(config['function'], globs=globals())
+            function = func_load(config['function'], globs=globs)
-            output_shape = globals()[config['output_shape']]
+            output_shape = globs[config['output_shape']]
-            output_shape = func_load(config['output_shape'], globs=globals())
+            output_shape = func_load(config['output_shape'], globs=globs)
-    return layer_class.from_config(config['config'])
+
-from keras.layers import Dense, Dropout, RepeatVector, TimeDistributed
+from keras.layers import Dense, Dropout, Lambda, RepeatVector, TimeDistributed
-        A tuple of integers.
+        A tuple of integers (or None entries).
-        in numpy/core/src/multiarray/shape.c
+        A near direct port of the internal Numpy function
-        return (input_shape[0],) + self._fix_unknown_dimension(input_shape[1:], self.target_shape)
+        return (input_shape[0],) + self._fix_unknown_dimension(input_shape[1:],
-        model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 32, 32)))
+        model.add(Convolution2D(64, 3, 3,
-        model.add(Lambda(antirectifier, output_shape=antirectifier_output_shape))
+        model.add(Lambda(antirectifier,
-            # if TensorFlow, we can infer the output shape directly:
+            # With TensorFlow, we can infer the output shape directly:
-            # otherwise, we default to the input shape
+            # Otherwise, we default to the input shape.
-            This argument (or alternatively, the keyword argument `input_shape`)
+        bias: whether to include a bias
-        2D tensor with shape: `(nb_samples, input_dim)`.
+        nD tensor with shape: `(nb_samples, ..., input_dim)`.
-        2D tensor with shape: `(nb_samples, output_dim)`.
+        nD tensor with shape: `(nb_samples, ..., output_dim)`.
-        self.input_spec = [InputSpec(ndim=2)]
+        self.input_spec = [InputSpec(ndim='2+')]
-        input_dim = input_shape[1]
+        assert len(input_shape) >= 2
-                                     shape=(None, input_dim))]
+                                     ndim='2+')]
-        return (input_shape[0], self.output_dim)
+        assert input_shape and len(input_shape) >= 2
-            This argument (or alternatively, the keyword argument `input_shape`)
+        bias: whether to include a bias
-                 bias=True, input_dim=None, **kwargs):
+    def __init__(self, output_dim,
-            This argument (or alternatively, the keyword argument `input_shape`)
+        bias: whether to include a bias
-                 bias=True, input_dim=None, **kwargs):
+    def __init__(self,
-            This argument (or alternatively, the keyword argument `input_shape`)
+        bias: whether to include a bias
-                      'please use TimeDistributed(Dense(...)) instead.')
+                 init='glorot_uniform',
-        # Note: input_length should always be provided when using tensorflow backend.
+               kwargs={'output_dim': 3},
-    '''Instantiates a variable.
+    '''Instantiates a variable and returns it.
-        return th_sparse_module.as_sparse_variable(value)
+        variable = th_sparse_module.as_sparse_variable(value)
-        return theano.shared(value=value, name=name, strict=False)
+        variable = theano.shared(value=value, name=name, strict=False)
-        return x[:, self.cropping[0]:input_shape[1]-self.cropping[1], :]
+        return x[:, self.cropping[0]:-self.cropping[1], :]
-                     self.cropping[1][0]:input_shape[3]-self.cropping[1][1]]
+                     self.cropping[0][0]:-self.cropping[0][1],
-                     self.cropping[1][0]:input_shape[2]-self.cropping[1][1],
+                     self.cropping[0][0]:-self.cropping[0][1],
-                     self.cropping[2][0]:input_shape[4]-self.cropping[2][1]]
+                     self.cropping[0][0]:-self.cropping[0][1],
-                     self.cropping[2][0]:input_shape[3]-self.cropping[2][1],
+                     self.cropping[0][0]:-self.cropping[0][1],
-    def __init__(self, init='zero', weights=None, **kwargs):
+    def __init__(self, init='zero', weights=None, shared_axes=None, **kwargs):
-        self.alphas = self.init(input_shape[1:],
+        param_shape = list(input_shape[1:])
-        neg = self.alphas * (x - abs(x)) * 0.5
+        if K.backend() == 'theano':
-                 weights=None, **kwargs):
+                 weights=None, shared_axes=None, **kwargs):
-        self.alphas = K.variable(self.alpha_init * np.ones(input_shape),
+        param_shape = list(input_shape[1:])
-        self.betas = K.variable(self.beta_init * np.ones(input_shape),
+        self.betas = K.variable(self.beta_init * np.ones(param_shape),
-        return K.softplus(self.betas * x) * self.alphas
+        if K.backend() == 'theano':
-                 t_right_init='glorot_uniform', a_right_init='one', **kwargs):
+                 t_right_init='glorot_uniform', a_right_init='one', shared_axes=None, **kwargs):
-        input_shape = input_shape[1:]
+        param_shape = list(input_shape[1:])
-        self.t_left = t_left_init(input_shape,
+        self.t_left = t_left_init(param_shape,
-        self.a_left = a_left_init(input_shape,
+        self.a_left = a_left_init(param_shape,
-        self.t_right = t_right_init(input_shape,
+        self.t_right = t_right_init(param_shape,
-        self.a_right = a_right_init(input_shape,
+        self.a_right = a_right_init(param_shape,
-        Y_right = K.relu(x - self.t_right_actual) * self.a_right
+        if K.backend() == 'theano':
-                   input_shape=(2, 3, 4))
+    layer_test(ParametricSoftplus,
-from .common import _FLOATX, _EPSILON, image_dim_ordering, reset_uids
+from .common import floatx, _EPSILON, image_dim_ordering, reset_uids
-def variable(value, dtype=_FLOATX, name=None):
+def variable(value, dtype=None, name=None):
-def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):
+def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):
-def zeros(shape, dtype=_FLOATX, name=None):
+def zeros(shape, dtype=None, name=None):
-def ones(shape, dtype=_FLOATX, name=None):
+def ones(shape, dtype=None, name=None):
-def eye(size, dtype=_FLOATX, name=None):
+def eye(size, dtype=None, name=None):
-def random_uniform_variable(shape, low, high, dtype=_FLOATX,
+def random_uniform_variable(shape, low, high, dtype=None,
-def random_normal_variable(shape, mean, scale, dtype=_FLOATX,
+def random_normal_variable(shape, mean, scale, dtype=None,
-        x = tf.cast(x, _FLOATX)
+        x = tf.cast(x, floatx())
-        x = tf.cast(x, _FLOATX)
+        x = tf.cast(x, floatx())
-    if _FLOATX == 'float64':
+    if dtype(x) == 'float64':
-    if _FLOATX == 'float64':
+    if dtype(x) == 'float64':
-    if _FLOATX == 'float64':
+    if dtype(kernel) == 'float64':
-    if _FLOATX == 'float64':
+    if dtype(kernel) == 'float64':
-    if _FLOATX == 'float64':
+    if floatx() == 'float64':
-    if _FLOATX == 'float64':
+    if floatx() == 'float64':
-    if _FLOATX == 'float64':
+    x_dtype = dtype(x)
-    if _FLOATX == 'float64':
+    if x_dtype == 'float64':
-def random_normal(shape, mean=0.0, std=1.0, dtype=_FLOATX, seed=None):
+def random_normal(shape, mean=0.0, std=1.0, dtype=None, seed=None):
-def random_uniform(shape, low=0.0, high=1.0, dtype=_FLOATX, seed=None):
+def random_uniform(shape, low=0.0, high=1.0, dtype=None, seed=None):
-def random_binomial(shape, p=0.0, dtype=_FLOATX, seed=None):
+def random_binomial(shape, p=0.0, dtype=None, seed=None):
-from .common import _FLOATX, _EPSILON, image_dim_ordering
+from .common import _FLOATX, floatx, _EPSILON, image_dim_ordering
-def variable(value, dtype=_FLOATX, name=None):
+def variable(value, dtype=None, name=None):
-def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):
+def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):
-def zeros(shape, dtype=_FLOATX, name=None):
+def zeros(shape, dtype=None, name=None):
-def ones(shape, dtype=_FLOATX, name=None):
+def ones(shape, dtype=None, name=None):
-def eye(size, dtype=_FLOATX, name=None):
+def eye(size, dtype=None, name=None):
-def random_uniform_variable(shape, low, high, dtype=_FLOATX, name=None):
+def random_uniform_variable(shape, low, high, dtype=None, name=None):
-def random_normal_variable(shape, mean, scale, dtype=_FLOATX, name=None):
+def random_normal_variable(shape, mean, scale, dtype=None, name=None):
-        dtype = _FLOATX
+        dtype = floatx()
-def random_normal(shape, mean=0.0, std=1.0, dtype=_FLOATX, seed=None):
+def random_normal(shape, mean=0.0, std=1.0, dtype=None, seed=None):
-def random_uniform(shape, low=0.0, high=1.0, dtype=_FLOATX, seed=None):
+def random_uniform(shape, low=0.0, high=1.0, dtype=None, seed=None):
-def random_binomial(shape, p=0.0, dtype=_FLOATX, seed=None):
+def random_binomial(shape, p=0.0, dtype=None, seed=None):
-from keras.backend import theano_backend as KTH
+from keras import backend as K
-                # tf.where needs its condition tensor
+                # tf.select needs its condition tensor
-                output = tf.where(tiled_mask_t, output, prev_output)
+                output = tf.select(tiled_mask_t, output, prev_output)
-                                                  state))
+                    return_states.append(tf.select(tiled_mask_t,
-                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]
+                output = tf.select(tiled_mask_t, output, states[0])
-        return tf.where(x > 0, res, alpha * res)
+        return tf.select(x > 0, res, alpha * res)
-                    tf.zeros(shape, dtype=dtype))
+    return tf.select(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,
-        target_shape = tf.stack(target_shape)
+        target_shape = stack(target_shape)
-    pattern = tf.stack([1, n, 1])
+    pattern = stack([1, n, 1])
-    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))
+    x = tf.reshape(x, stack([-1, prod(shape(x)[1:])]))
-    return tf.stack(x)
+    try:
-        input_list = tf.unstack(inputs)
+        input_list = tf.unpack(inputs)
-            mask_list = tf.unstack(mask)
+            mask_list = tf.unpack(mask)
-                                       tf.stack([1, tf.shape(output)[1]]))
+                                       stack([1, tf.shape(output)[1]]))
-                                           tf.stack([1, tf.shape(new_state)[1]]))
+                                           stack([1, tf.shape(new_state)[1]]))
-                outputs = tf.stack(successive_outputs)
+                outputs = stack(successive_outputs)
-            outputs = tf.stack(successive_outputs)
+            outputs = stack(successive_outputs)
-                                       tf.stack([1, tf.shape(output)[1]]))
+                                       stack([1, tf.shape(output)[1]]))
-                     tf.zeros(shape, dtype=dtype))
+                    tf.ones(shape, dtype=dtype),
-    max_num_labels_tns = tf.stack([label_shape[1]])
+    num_batches_tns = stack([label_shape[0]])
-    out = tf.batch_matmul(x, y, adj_x=adj_x, adj_y=adj_y)
+    try:
-        target_shape = tf.pack(target_shape)
+        target_shape = tf.stack(target_shape)
-        return tf.concat(axis, [to_dense(x) for x in tensors])
+        try:
-    splits = tf.split(axis, x_shape[axis], x)
+    try:
-    return tf.concat(axis, x_rep)
+    return concatenate(x_rep, axis)
-    pattern = tf.pack([1, n, 1])
+    pattern = tf.stack([1, n, 1])
-    x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))
+    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))
-    return tf.pack(x)
+def stack(x):
-    return tf.reverse(x, dims)
+    try:
-        input_list = tf.unpack(inputs)
+        input_list = tf.unstack(inputs)
-            mask_list = tf.unpack(mask)
+            mask_list = tf.unstack(mask)
-                # tf.select needs its condition tensor
+                # tf.where needs its condition tensor
-                                       tf.pack([1, tf.shape(output)[1]]))
+                                       tf.stack([1, tf.shape(output)[1]]))
-                output = tf.select(tiled_mask_t, output, prev_output)
+                output = tf.where(tiled_mask_t, output, prev_output)
-                                                   state))
+                                           tf.stack([1, tf.shape(new_state)[1]]))
-                outputs = tf.pack(successive_outputs)
+                outputs = tf.stack(successive_outputs)
-            outputs = tf.pack(successive_outputs)
+            outputs = tf.stack(successive_outputs)
-            inputs = tf.reverse(inputs, [True] + [False] * (ndim - 1))
+            inputs = reverse(inputs, 0)
-                mask = tf.reverse(mask, [True] + [False] * (ndim - 1))
+                mask = reverse(mask, 0)
-                new_states = [tf.select(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]
+                                       tf.stack([1, tf.shape(output)[1]]))
-        return tf.select(x > 0, res, alpha * res)
+        return tf.where(x > 0, res, alpha * res)
-    return tf.select(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,
+    return tf.where(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,
-    max_num_labels_tns = tf.pack([label_shape[1]])
+    num_batches_tns = tf.stack([label_shape[0]])
-                                                  max_num_labels_tns), tf.reverse(label_shape, [True])))
+                                                  max_num_labels_tns), reverse(label_shape, 0)))
-    indices = tf.transpose(tf.reshape(tf.concat(0, [batch_ind, label_ind]), [2, -1]))
+    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))
-def pack(x):
+def stack(x):
-        x = K.reshape(x, K.pack([-1, timesteps, output_dim]))
+        x = K.reshape(x, K.stack([-1, timesteps, output_dim]))
-        assert(np.abs(np.std(rand) - std) < 0.01)
+        assert rand.shape == (1000, 1000)
-        assert(np.abs(np.std(rand) - std) < 0.01)
+        assert rand.shape == (1000, 1000)
-        assert(np.min(rand) >= min)
+        min_val = -1.
-        assert(np.min(rand) == 0)
+        assert rand.shape == (1000, 1000)
-        assert(np.min(rand) == 0)
+        assert rand.shape == (1000, 1000)
-            assert(np.array_equal(a, np.arange(test_value)))
+            assert np.array_equal(a, np.arange(test_value))
-            assert(KTF.dtype(t_a) == KTH.dtype(t_b), 'default dtypes are equal')
+            assert np.array_equal(b, np.arange(test_value))
-            assert(np.array_equal(a, np.arange(start, stop, step)))
+            assert np.array_equal(a, np.arange(start, stop, step))
-            assert(np.array_equal(a, b))
+            assert np.array_equal(b, np.arange(start, stop, step))
-                assert(backend.dtype(t) == dtype)
+                assert backend.dtype(t) == dtype
-def ones_like(x):
+def ones_like(x, name=None):
-def zeros_like(x):
+def zeros_like(x, name=None):
-    # v._uses_learning_phase = False
+    if isinstance(value, np.ndarray):
-    v._uses_learning_phase = False
+    # if isinstance(value, np.array):
-    whether variables should be initialized
+    '''Sets the manual variable initialization flag.
-    (e.g. via tf.initialize_all_variables()).
+    (e.g. via `tf.initialize_all_variables()`).
-        tensor: a Keras tensor.
+        tensor: A tensor instance.
-        Boolean.
+        A boolean.
-        >>> print(keras.backend.is_sparse(a))
+        >>> from keras import backend as K
-        >>> print(keras.backend.is_sparse(b))
+        >>> b = K.placeholder((2, 2), sparse=True)
-    '''Converts a Keras tensor into a Keras dense tensor
+    '''Converts a sparse tensor into a dense tensor
-        tensor: Keras tensor.
+        tensor: A tensor instance (potentially sparse).
-        A Keras dense tensor.
+        A dense tensor.
-        >>> print(keras.backend.is_sparse(b))
+        >>> from keras import backend as K
-        >>> print(keras.backend.is_sparse(c))
+        >>> c = K.to_dense(b)
-    '''Instantiates a tensor and returns it.
+    '''Instantiates a variable and returns it.
-        name: optional name string for the tensor.
+        value: Numpy array, initial value of the tensor.
-        A Keras variable instance.
+        A variable instance (with Keras metadata included).
-        >>> kvar = K.variable(value=val, dtype='float64', name='example_kvar')
+        >>> kvar = K.variable(value=val, dtype='float64', name='example_var')
-        example_kvar
+        example_var
-        # SparseTensor doesn't need initialization
+        v._keras_shape = sparse_coo.shape
-    '''Instantiates a placeholder (Keras tensor) and returns it.
+    '''Instantiates a placeholder tensor and returns it.
-        shape: shape of the placeholder
+        shape: Shape of the placeholder
-        ndim: number of axes of the tensor.
+        ndim: Number of axes of the tensor.
-        name: optional name string for the placeholder.
+        dtype: Placeholder type.
-        Keras tensor instance.
+        Tensor instance (with Keras metadata included).
-        >>> input._keras_shape
+        >>> from keras import backend as K
-        >>> input
+        >>> input_ph
-    '''Returns the symbolic shape of a Keras tensor or variable.
+    '''Returns the symbolic shape of a tensor or variable.
-        x: A Keras tensor or variable.
+        x: A tensor or variable.
-        A symbolic shape.
+        A symbolic shape (which is itself a tensor).
-        x: A Keras tensor or variable.
+        x: Tensor or variable.
-        x: Keras tensor or variable.
+        x: Tensor or variable.
-        integer (scalar), number of dimensions.
+        Integer (scalar), number of axes.
-        x: Keras tensor or variable.
+        x: Tensor or variable.
-    '''Evaluates the value of a Keras variable.
+    '''Evaluates the value of a variable.
-        x: A Keras variable.
+        x: A variable.
-    '''Instantiates an all-zeros Keras variable and returns it.
+    '''Instantiates an all-zeros variable and returns it.
-        A Keras variable, filled with `0.0`
+        A variable (including Keras metadata), filled with `0.0`.
-    '''Casts a Keras tensor to a tensor of a different dtype and returns it.
+    '''Casts a tensor to a different dtype and returns it.
-        Keras tensor with dtype of `dtype`.
+        Keras tensor with dtype `dtype`.
-        y: Keras tensor (or variable).
+        x: Tensor or variable.
-        A Keras tensor, dot product of `x` and `y`.
+        A tensor, dot product of `x` and `y`.
-        # dot product between Keras tensors
+        # dot product between tensors
-        # dot product between Keras tensors
+        # dot product between tensors
-        # The Theano behavior example
+        # Theano-like behavior example
-    '''Transposes a matrix and returns it.
+    '''Transposes a tensor and returns it.
-        x: Keras tensor or variable.
+        x: Tensor or variable.
-        Keras tensor or variable, transposed.
+        A tensor.
-    in the 2D tensor `reference`.
+    '''Retrieves the elements of indices `indices`
-        indices: an int tensor of indices.
+        reference: A tensor.
-        A 3D tensor of same type as `reference`.
+        A tensor of same type as `reference`.
-    '''Compute mean and std for batch then apply batch_normalization on batch.
+    '''Computes mean and std for batch then apply batch_normalization on batch.
-    '''Apply batch normalization on x given mean, var, beta and gamma:
+    '''Applies batch normalization on x given mean, var, beta and gamma:
-    '''Concantes a list of tensors alongside the specified axis.
+    '''Concatenates a list of tensors alongside the specified axis.
-    '''Resize the volume contained in a 5D tensor of shape
+    '''Resizes the volume contained in a 5D tensor of shape
-    '''Instantiates a tensor.
+    '''Instantiates a tensor and returns it.
-        Tensor variable instance.
+        A Keras variable instance.
-    '''Instantiates a placeholder.
+    '''Instantiates a placeholder (Keras tensor) and returns it.
-            (integer tuple, may include None entries).
+            (integer tuple, may include `None` entries).
-        Placeholder tensor instance.
+        Keras tensor instance.
-    '''Returns the symbolic shape of a tensor.
+    '''Returns the symbolic shape of a Keras tensor or variable.
-    '''Returns the shape of a tensor as a tuple of
+    '''Returns the shape of a Keras tensor or a Keras variable as a tuple of
-    '''Returns the dtype of a tensor, as a string.
+    '''Returns the dtype of a Keras tensor or variable, as a string.
-    '''Evaluates the value of a tensor.
+    '''Evaluates the value of a Keras variable.
-    '''Instantiates an all-zeros tensor variable.
+    '''Instantiates an all-zeros Keras variable and returns it.
-    '''Instantiates an all-ones tensor variable.
+    '''Instantiates an all-ones tensor variable and returns it.
-    '''Instantiate an identity matrix.
+    '''Instantiate an identity matrix and returns it.
-    of the same shape as another tensor.
+    '''Instantiates an all-zeros Keras variable
-    of the same shape as another tensor.
+    '''Instantiates an all-ones Keras variable
-    '''Returns the number of scalars in a tensor.
+    '''Returns the number of scalars in a Keras variable.
-    '''Casts a tensor to a different dtype.
+    '''Casts a Keras tensor to a tensor of a different dtype and returns it.
-    '''Multiplies 2 tensors.
+    '''Multiplies 2 tensors (and/or variables) and returns a *tensor*.
-    with a ND tensor, reproduces the Theano behavior
+    with a ND tensor, it reproduces the Theano behavior.
-    make sure that ndim is at least 2.
+    `batch_dot` is used to compute dot product of `x` and `y` when
-        axes: list (or single) int with target dimensions
+        x, y: Keras tensors or variables with `ndim >= 2`
-        (less the dimension that was summed over) and y's shape
+        A tensor with shape equal to the concatenation of `x`'s shape
-        If the final rank is 1, we reshape it to (batch_size, 1).
+
-        of x.dot(y.T), although we never have to calculate the off-diagonal
+        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`
-        If dot_axes is (1, 2), to find the output shape of resultant tensor,
+        Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.
-        output_shape = (100, 30)
+        * `x.shape[0]` : 100 : append to output shape
-    '''Transposes a matrix.
+    '''Transposes a matrix and returns it.
-    '''Cropping layer for 3D data (e.g. spatial or saptio-temporal).
+    '''Cropping layer for 3D data (e.g. spatial or spatio-temporal).
-        self.y = np.asarray(y)
+        if y is not None:
-import cPickle as pickle
+try:
-        tensor_indices: a list of integers, the same length as `inbound_layers`.
+        tensor_indices: a list of integers,
-            output of the inbound layer (necessary since each inbound layer might
+            output of the inbound layer
-        # the current node will be added to the inbound_nodes of outbound_layer.
+        # the current node will be added to
-            # TODO: try to auto-infer shape if exception is raised by get_output_shape_for.
+            # TODO: try to auto-infer shape
-
+            if kwarg not in allowed_kwargs:
-        warnings.warn('The `regularizers` property of layers/models is deprecated. '
+        warnings.warn('The `regularizers` property of '
-        warnings.warn('The `regularizers` property of layers/models is deprecated. '
+        warnings.warn('The `regularizers` property of layers/models '
-                (if applicable). "None" means that we take all outputs (as a list).
+                of tensor, and we might only be interested in
-                                 'Use `get_output_mask_at(node_index)` instead.')
+                                 'Use `get_output_mask_at(node_index)` '
-                                 'Use `get_input_shape_at(node_index)` instead.')
+                                 'Use `get_input_shape_at(node_index)` '
-                                 'Use `get_output_shape_at(node_index)` instead.')
+                                 'Use `get_output_shape_at(node_index)` '
-                             ' weights. Provided weights: ' + str(weights)[:50] + '...')
+            raise ValueError('You called `set_weights(weights)` on layer "' +
-                                     'argument.')
+                    raise ValueError('InputLayer was provided '
-                       ' or a `batch_shape` argument. Note that ' +
+        assert shape, ('Please provide to Input either a `shape`'
-            to compute `output_shape` (only if merge mode is a lambda/function).
+        dot_axes: Integer or tuple of integers,
-            batch size (same convention as the `get_output_shape_for` method of layers).
+            If the argument is callable,
-            # Make a list of masks while making sure the dimensionality of each mask
+            # Make a list of masks while making sure
-                    # Input is unmasked. Append all 1s to masks, but cast it to uint8 first
+                    # Input is unmasked. Append all 1s to masks,
-        dot_axes: Integer or tuple of integers, axes to use in mode `dot` or `cos`.
+        dot_axes: Integer or tuple of integers,
-            batch size (same convention as the `get_output_shape_for` method of layers).
+            (1:1 mapping to input tensors) and return a single shape tuple,
-                             'is redundant. All inputs should only appear once.'
+                             'is redundant. '
-        # TODO: probably useless because input layers must be Input layers (node_indices = [0], tensor_indices = [0])
+        # TODO: probably useless because input layers must be Input layers
-        # (not all nodes included in the layers are relevant to the current graph).
+        # (not all nodes included in the layers
-        # Dictionary mapping reference tensors to tuples (computed tensor, compute mask)
+        # Dictionary mapping reference tensors to tuples
-        # TODO: raise exception when a .compute_mask does not return a list the same size as call
+        # TODO: raise exception when a `.compute_mask()` call
-                        output_masks = to_list(layer.compute_mask(computed_tensor, computed_mask))
+                        output_tensors = to_list(layer.call(computed_tensor,
-                        output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks))
+                        output_tensors = to_list(layer.call(computed_tensors,
-                    # Keep track of updates that depend on the inputs (e.g. BN updates).
+                    # Keep track of updates that depend on the inputs
-                    # Keep track of losses that depend on the inputs (e.g. activity regularizers).
+                    # Keep track of losses that depend on the inputs
-                    # Keep track of unconditional losses (e.g. weight regularizers).
+                    # Keep track of unconditional losses
-        # Update cache; keys are based on ids on input tensors and inputs masks.
+        # Update cache;
-                    a list of strings (ordered names of weights tensor of the layer).
+                    a list of strings
-                        # Legacy shape: (self.nb_filter, input_dim, self.filter_length, 1)
+                        # Legacy shape:
-                        weight_value_tuples.append((symbolic_weights[i], weight_values[i]))
+                        weight_value_tuples.append((symbolic_weights[i],
-        print_summary(flattened_layers, getattr(self, 'container_nodes', None), line_length=line_length, positions=positions)
+        print_summary(flattened_layers,
-                                     str(data)[:200])
+                    raise ValueError(
-                                         str(array.shape))
+                        raise ValueError(
-                         str(list(set_y)[0]) + ' target samples.')
+                         'the same number of samples as target arrays. '
-                                 'which does expect integer targets.')
+                raise ValueError(
-                                     'as the output.')
+                    raise ValueError(
-                             'you should specify sample_weight_mode="temporal" '
+                             'you should specify '
-                # Reset random seed else all children processes share the same seed
+                # Reset random seed else all children processes
-                    weight = K.placeholder(ndim=2, name=name + '_sample_weights')
+                    weight = K.placeholder(ndim=2,
-                    weight = K.placeholder(ndim=1, name=name + '_sample_weights')
+                    weight = K.placeholder(ndim=1,
-                                 ' outputs, but you passed sample_weight_mode=' +
+                                 ' outputs, but you passed '
-                    weight = K.placeholder(ndim=2, name=name + '_sample_weights')
+                    weight = K.placeholder(ndim=2,
-                    weight = K.placeholder(ndim=1, name=name + '_sample_weights')
+                    weight = K.placeholder(ndim=1,
-                sample_weights = [K.placeholder(ndim=2, name=name + '_sample_weights')
+                sample_weights = [K.placeholder(ndim=2,
-                sample_weight_modes = ['temporal' for name in self.output_names]
+                sample_weight_modes = ['temporal'
-                sample_weights = [K.placeholder(ndim=1, name=name + '_sample_weights')
+                sample_weights = [K.placeholder(ndim=1,
-                    # custom handling of accuracy (because of class mode duality)
+                    # custom handling of accuracy
-                               ' Use `model.compile(optimizer, loss)`.')
+            raise RuntimeError('You must compile a model before '
-                If all inputs in the model are named, you can also pass a dictionary
+                If all inputs in the model are named,
-                If all outputs in the model are named, you can also pass a dictionary
+                If all outputs in the model are named,
-            verbose: 0, 1, or 2. Verbosity mode. 0 = silent, 1 = verbose, 2 = one log line per epoch.
+            nb_epoch: integer, the number of times to iterate
-                will not train on it, and will evaluate the loss and any model metrics
+                will not train on it, and will evaluate
-            class_weight: optional dictionary mapping class indices (integers) to
+            validation_data: data on which to evaluate
-                In this case you should make sure to specify sample_weight_mode="temporal" in compile().
+                In this case you should make sure to specify
-                                                           batch_size=batch_size)
+        x, y, sample_weights = self._standardize_user_data(
-                                                                           batch_size=batch_size)
+            val_x, val_y, val_sample_weights = self._standardize_user_data(
-                If all inputs in the model are named, you can also pass a dictionary
+                If all inputs in the model are named,
-                If all outputs in the model are named, you can also pass a dictionary
+                If all outputs in the model are named,
-                                                           batch_size=batch_size)
+        x, y, sample_weights = self._standardize_user_data(
-                If all inputs in the model are named, you can also pass a dictionary
+                If all inputs in the model are named,
-                If all outputs in the model are named, you can also pass a dictionary
+                If all outputs in the model are named,
-            class_weight: optional dictionary mapping class indices (integers) to
+                In this case you should make sure to specify
-            Scalar training loss (if the model has a single output and no metrics)
+            Scalar training loss
-                                                           check_batch_dim=True)
+        x, y, sample_weights = self._standardize_user_data(
-                If all inputs in the model are named, you can also pass a dictionary
+                If all inputs in the model are named,
-                If all outputs in the model are named, you can also pass a dictionary
+                If all outputs in the model are named,
-                In this case you should make sure to specify sample_weight_mode="temporal" in compile().
+                In this case you should make sure to specify
-                                                           check_batch_dim=True)
+        x, y, sample_weights = self._standardize_user_data(
-                      class_weight={}, max_q_size=10, nb_worker=1, pickle_safe=False,
+                      class_weight={},
-                non picklable arguments to the generator as they can't be passed
+            nb_worker: maximum number of processes to spin up
-            val_x, val_y, val_sample_weights = self._standardize_user_data(val_x, val_y, val_sample_weight)
+                                 'or (val_x, val_y). Found: ' +
-                                                                   pickle_safe=pickle_safe)
+        data_gen_queue, _stop, generator_threads = generator_queue(
-                                     'or (x, y). Found: ' + str(generator_output))
+                                     'or (x, y). Found: ' +
-                                     'or (x, y). Found: ' + str(generator_output))
+                                     'or (x, y). Found: ' +
-                                                           pickle_safe=pickle_safe)
+                        val_outs = self.evaluate_generator(
-                                                 verbose=0)
+                        val_outs = self.evaluate(
-    def evaluate_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):
+    def evaluate_generator(self, generator, val_samples,
-                non picklable arguments to the generator as they can't be passed
+            nb_worker: maximum number of processes to spin up
-                                                                   pickle_safe=pickle_safe)
+        data_gen_queue, _stop, generator_threads = generator_queue(
-    def predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):
+    def predict_generator(self, generator, val_samples,
-                non picklable arguments to the generator as they can't be passed
+            nb_worker: maximum number of processes to spin up
-                                                                   pickle_safe=pickle_safe)
+        data_gen_queue, _stop, generator_threads = generator_queue(
-                                     'or (x, y). Found: ' + str(generator_output))
+                                     'or (x, y). Found: ' +
-            raise Exception('The `call` method of layer "' +
+            raise TypeError('The `call` method of layer "' +
-                            str(output_shapes))
+            raise ValueError('The `get_output_shape_for` method of layer "' +
-                            str(output_masks))
+            raise ValueError('The `compute_mask` method of layer "' +
-                                         ' does not support masking, ' +
+                                         ' does not support masking, '
-                                     ' does not support masking, ' +
+                                     ' does not support masking, '
-                            'and thus has no defined ' + attr_name + '.')
+            raise RuntimeError('The layer has never been called '
-                            str(len(self.inbound_nodes)) + ' inbound nodes.')
+            raise ValueError('Asked to get ' + attr_name +
-                            'Use `get_input_at(node_index)` instead.')
+            raise AttributeError('Layer ' + self.name +
-                            ' is not connected, no input to return.')
+            raise AttributeError('Layer ' + self.name +
-                            ' has no inbound nodes.')
+            raise AttributeError('Layer ' + self.name +
-                            'Use `get_output_at(node_index)` instead.')
+            raise AttributeError('Layer ' + self.name +
-                            'Use `get_input_mask_at(node_index)` instead.')
+            raise AttributeError('Layer ' + self.name +
-                            'Use `get_output_mask_at(node_index)` instead.')
+            raise AttributeError('Layer ' + self.name +
-                            'and thus has no defined input shape.')
+            raise AttributeError('The layer has never been called '
-                            'Use `get_input_shape_at(node_index)` instead.')
+            raise AttributeError('The layer "' + str(self.name) +
-                            'and thus has no defined output shape.')
+            raise AttributeError('The layer has never been called '
-                            'Use `get_output_shape_at(node_index)` instead.')
+            raise AttributeError('The layer "' + str(self.name) +
-                                self.name + '.build(batch_input_shape)`.')
+                raise RuntimeError('You tried to call `count_params` on ' +
-                            '`merged_tensor = merge([tensor_1, tensor2])`.')
+            raise RuntimeError('A Merge layer cannot be used more than once, '
-                            ' Found: ' + str(self.inputs))
+            raise ValueError('The list of inputs passed to the model '
-                raise Exception('Input tensors to a ' + cls_name + ' ' +
+                raise TypeError('Input tensors to a ' + cls_name + ' ' +
-                raise Exception('Output tensors to a ' + cls_name + ' must be '
+                raise TypeError('Output tensors to a ' + cls_name + ' must be '
-                            raise Exception(
+                            raise RuntimeError(
-                                'All layer names should be unique.')
+                raise RuntimeError('The name "' + name + '" is used ' +
-                                str(len(self.layers)) + ' layers.')
+                raise ValueError('Was asked to retrieve layer at index ' +
-            raise Exception('No such layer: ' + name)
+            raise ValueError('No such layer: ' + name)
-                                    'for one weight tensor: ' + str(key))
+                    raise ValueError('Received multiple constraints '
-                            str(len(self.input_layers)) + ' tensor inputs.')
+            raise ValueError('Invalid input_shape argument ' +
-                                str(len(flattened_layers)) + ' layers.')
+                raise ValueError('You are trying to load a weight file '
-                                str(len(flattened_layers)) + ' layers.')
+                raise ValueError('You are trying to load a weight file '
-                                    ' elements.')
+                    raise ValueError('Layer #' + str(k) +
-                                ' name-based weight loading.')
+                raise ValueError('The weight file you are trying to load is'
-                                        ' element(s).')
+                        raise ValueError('Layer #' + str(k) +
-                                str(data.keys()))
+                raise ValueError('No data provided for "' +
-                                '...')
+                raise ValueError('Error when checking ' + exception_prefix +
-                                    str(data)[:200])
+                    raise ValueError('Error when checking ' + exception_prefix +
-            raise Exception('Error when checking ' + exception_prefix +
+            raise TypeError('Error when checking ' + exception_prefix +
-                            'Found: array with shape ' + str(data.shape))
+            raise ValueError('The model expects ' + str(len(names)) +
-                                str(array.shape))
+                raise ValueError('Error when checking ' + exception_prefix +
-                                        str(array.shape))
+                        raise ValueError('Error when checking ' + exception_prefix +
-                            'array per model output.')
+            raise ValueError('Provided `' + weight_type + '` was a list of ' +
-        raise Exception('The model has multiple outputs, so `' +
+        raise TypeError('The model has multiple outputs, so `' +
-                        'the same number of samples.')
+        raise ValueError('All input arrays (x) should have '
-                        'the same number of samples.')
+        raise ValueError('All target arrays (y) should have '
-                        'the same number of samples.')
+        raise ValueError('All sample_weight arrays should have '
-                        str(list(set_y)[0]) + ' target samples.')
+        raise ValueError('Input arrays should have '
-                        str(list(set_w)[0]) + ' target samples.')
+        raise ValueError('Sample_weight arrays should have '
-                                'which does expect integer targets.')
+                raise ValueError('You are passing a target array of shape ' + str(y.shape) +
-                                    'as the output.')
+                    raise ValueError('A target array with shape ' + str(y.shape) +
-                            'Found: ' + str(sample_weight_mode))
+            raise ValueError('"sample_weight_mode '
-                            'a time dimension.')
+            raise ValueError('Found a sample_weight array for '
-                            'you should pass a 2D sample_weight array.')
+            raise ValueError('Found a sample_weight array with shape ' +
-                            'sample_weight array is 1D.')
+            raise ValueError('Found a sample_weight array with shape ' +
-                            '3+ dimensional targets.')
+            raise ValueError('class_weight not supported for '
-            raise Exception('You must compile your model before using it.')
+            raise RuntimeError('You must compile your model before using it.')
-            raise Exception('You must compile your model before using it.')
+            raise RuntimeError('You must compile your model before using it.')
-                    raise Exception('TypeError while preparing batch. '
+                    raise TypeError('TypeError while preparing batch. '
-                            ' Use `model.compile(optimizer, loss)`.')
+            raise RuntimeError('You must compile a model before training/testing.'
-                                str(x[0].shape[0]) + ' samples')
+                raise ValueError('In a stateful network, '
-                                'Batch size: ' + str(batch_size) + '.')
+                raise ValueError('In a stateful network, '
-                            'you must specify a value for "nb_val_samples".')
+            raise ValueError('When using a generator for validation data, '
-                                'or (val_x, val_y). Found: ' + str(validation_data))
+                raise ValueError('validation_data should be a tuple '
-                                    'or (x, y). Found: ' + str(generator_output))
+                    raise ValueError('output of generator should be a tuple '
-                                    'or (x, y). Found: ' + str(generator_output))
+                    raise ValueError('output of generator should be a tuple '
-                                'or (x, y). Found: ' + str(generator_output))
+                raise ValueError('output of generator should be a tuple '
-                                'or (x, y). Found: ' + str(generator_output))
+                raise ValueError('output of generator should be a tuple '
-                                    'or (x, y). Found: ' + str(generator_output))
+                    raise ValueError('output of generator should be a tuple '
-                        'the TensorFlow backend.')
+        raise RuntimeError('The Xception model is only available with '
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                            '(including batch size).')
+            raise ValueError('If a RNN is stateful, a complete ' +
-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                            '`batch_shape` argument to your Input layer.')
+            raise ValueError('If a RNN is stateful, it needs to know '
-                            'input_shape must be provided (including batch size).')
+            raise ValueError('If a RNN is stateful, a complete ' +
-                raise Exception('Unknown `consume_less` mode.')
+                raise ValueError('Unknown `consume_less` mode.')
-                            'input_shape must be provided (including batch size).')
+            raise ValueError('If a RNN is stateful, a complete ' +
-                raise Exception('Unknown `consume_less` mode.')
+                raise ValueError('Unknown `consume_less` mode.')
-                raise Exception('Unexpected keyword argument '
+                raise TypeError('Unexpected keyword argument '
-                                'provided weight shape ' + str(w.shape))
+                raise ValueError('Optimizer weight shape ' +
-                                'or fit on some text data first.')
+                raise ValueError('Specify a dimension (nb_words argument), '
-                            'before using tfidf mode.')
+            raise ValueError('Fit the Tokenizer on some data '
-                    raise Exception('Unknown vectorization mode: ' + str(mode))
+                    raise ValueError('Unknown vectorization mode:', mode)
-                            'is only available for tensors of rank 2.')
+        if K.ndim(x) != 2:
-            raise Exception('Invalid dim_ordering: ' + str(dim_ordering))
+            raise ValueError('Invalid dim_ordering:', dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + str(dim_ordering))
+            raise ValueError('Invalid dim_ordering:', dim_ordering)
-            raise ValueError('dim_ordering must be in {tf, th}.')
+            raise ValueError('`dim_ordering` must be in {tf, th}.')
-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'
+        if border_mode not in {'valid', 'same'}:
-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'
+        if border_mode not in {'valid', 'same'}:
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-        output = self._pooling_function(inputs=x, pool_size=self.pool_size,
+        output = self._pooling_function(inputs=x,
-                          border_mode, dim_ordering, pool_mode='max')
+                          border_mode, dim_ordering,
-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'
+        if border_mode not in {'valid', 'same'}:
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            return (input_shape[0], input_shape[1], len_dim1, len_dim2, len_dim3)
+            return (input_shape[0],
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            return (input_shape[0],
-                          border_mode, dim_ordering, pool_mode='avg')
+                          border_mode, dim_ordering,
-                            '(only "valid" is supported):', border_mode)
+            raise ValueError('Invalid border mode for LocallyConnected1D '
-
+        self.W_shape = (output_length,
-                            '(only "valid" is supported):', border_mode)
+            raise ValueError('Invalid border mode for LocallyConnected2D '
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-
+        self.W_shape = (output_row * output_col,
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-    print('Total params: %s' % count_total_params(layers))
+    trainable_count, non_trainable_count = count_total_params(layers, layer_set=None)
-                 mode='auto'):
+                 mode='auto', period=1):
-                        self.model.save(filepath, overwrite=True)
+        self.epochs_since_last_save += 1
-                self.model.save_weights(filepath, overwrite=True)
+                    if self.monitor_op(current, self.best):
-                self.model.save(filepath, overwrite=True)
+                if self.verbose > 0:
-            return normed
+                return theano.sandbox.cuda.dnn.dnn_batch_normalization_test(
-    '''Instantiate a tensor variable.
+    '''Instantiates a variable.
-            self.regularizers = []
+        if not hasattr(self, 'losses'):
-            return self.call(x, mask)
+            outputs = to_list(self.call(x, mask))
-    def add_updates(self, updates, inputs):
+    def add_loss(self, losses, inputs=None):
-        inputs_hash = ', '.join([str(abs(id(x))) for x in inputs])
+        if inputs is not None:
-        inputs_hash = ', '.join([str(abs(id(x))) for x in inputs])
+        inputs_hash = object_list_uid(inputs)
-        # self.regularizers
+                    # Collect updates that are dependent on inputs
-        return regs
+        warnings.warn('The `regularizers` attribute of layers/models '
-        return layers_learning_phase or regs_learning_phase
+        return layers_learning_phase
-                    # update model updates
+                    # Update model updates and losses:
-                    self.add_updates(layer.get_updates_for(layer_inputs), inputs)
+                    # Keep track of updates that depend on the inputs (e.g. BN updates).
-            total_loss = r(total_loss)
+        # add regularization penalties
-        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))
+
-            self.trainable_weights = [self.W, self.b]
+            self.b = self.add_weight((self.nb_filter,),
-            self.constraints[self.b] = self.b_constraint
+            self.b = None
-        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))
+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
-            self.trainable_weights = [self.W, self.b]
+            self.b = self.add_weight((self.nb_filter,),
-            self.constraints[self.b] = self.b_constraint
+            self.b = None
-                                          name='{}_pointwise_kernel'.format(self.name))
+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
-                                      self.b]
+            self.b = self.add_weight((self.nb_filter,),
-            self.constraints[self.b] = self.b_constraint
+            self.b = None
-        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))
+        self.W = self.add_weight(self.W_shape,
-            self.trainable_weights = [self.W, self.b]
+            self.b = self.add_weight((self.nb_filter,),
-            self.constraints[self.b] = self.b_constraint
+            self.b = None
-    
+
-                           name='{}_W'.format(self.name))
+        self.W = self.add_weight((input_dim, self.output_dim),
-            self.trainable_weights = [self.W, self.b]
+            self.b = self.add_weight((self.output_dim,),
-            self.constraints[self.b] = self.b_constraint
+            self.b = None
-        self.regularizers = [activity_regularizer]
+        self.activity_regularizer = regularizers.L1L2Regularizer(l1=l1, l2=l2)
-                           name='{}_W'.format(self.name))
+        self.W = self.add_weight((self.nb_feature, input_dim, self.output_dim),
-            self.trainable_weights = [self.W, self.b]
+            self.b = self.add_weight((self.nb_feature, self.output_dim,),
-            self.constraints[self.b] = self.b_constraint
+            self.b = None
-
+        self.W = self.add_weight((input_dim, input_dim),
-            self.trainable_weights = [self.W, self.b, self.W_carry, self.b_carry]
+            self.b = self.add_weight((input_dim,),
-            self.constraints[self.b] = self.b_constraint
+            self.b_carry = None
-                           name='{}_W'.format(self.name))
+        self.W = self.add_weight((input_dim, self.output_dim),
-            self.constraints[self.b] = self.b_constraint
+            self.b = self.add_weight((self.output_dim,),
-            self.regularizers.append(self.activity_regularizer)
+        self.W = self.add_weight((self.input_dim, self.output_dim),
-        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))
+
-            self.trainable_weights = [self.W, self.b]
+            self.b = self.add_weight((output_length, self.nb_filter),
-            self.constraints[self.b] = self.b_constraint
+            self.b = None
-        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))
+        self.W = self.add_weight(self.W_shape,
-            self.trainable_weights = [self.W, self.b]
+            self.b = self.add_weight((output_row, output_col, nb_filter),
-            self.constraints[self.b] = self.b_constraint
+            self.b = None
-        self.non_trainable_weights = [self.running_mean, self.running_std]
+        self.gamma = self.add_weight(shape,
-                                  K.moving_average_update(self.running_std, std, self.momentum)], x)
+                self.add_update([K.moving_average_update(self.running_mean, mean, self.momentum),
-            self.add_updates(updates, x)
+            self.add_update(updates, x)
-        self.dropout_W, self.dropout_U = dropout_W, dropout_U
+        self.dropout_W = dropout_W
-        self.trainable_weights = [self.W, self.U, self.b]
+        self.W = self.add_weight((input_dim, self.output_dim),
-        self.dropout_W, self.dropout_U = dropout_W, dropout_U
+        self.dropout_W = dropout_W
-            self.trainable_weights = [self.W, self.U, self.b]
+            self.W = self.add_weight((self.input_dim, 3 * self.output_dim),
-
+            self.W_z = self.add_weight((self.input_dim, self.output_dim),
-        self.dropout_W, self.dropout_U = dropout_W, dropout_U
+        self.dropout_W = dropout_W
-            self.trainable_weights = [self.W, self.U, self.b]
+            self.W = self.add_weight((self.input_dim, 4 * self.output_dim),
-            self.b_o = K.zeros((self.output_dim,), name='{}_b_o'.format(self.name))
+            self.W_i = self.add_weight((self.input_dim, self.output_dim),
-        self.regularizers = getattr(self.layer, 'regularizers', [])
+        self.losses = getattr(self.layer, 'losses', [])
-            return self.forward_layer.regularizers + self.backward_layer.regularizers
+    def losses(self):
-        return loss
+    def __call__(self, x):
-        WWd = K.dot(WW, main_eigenvect)
+    def __call__(self, x):
-        main_eigenval = (K.dot(K.transpose(WWd), main_eigenvect) /
+        # The corresponding dominant eigenvalue:
-        regularized_loss = loss + (main_eigenval ** 0.5) * self.k
+        # Multiply by the given regularization gain.
-class WeightRegularizer(Regularizer):
+class L1L2Regularizer(Regularizer):
-        regularized_loss = loss
+
-            regularized_loss += K.sum(self.l1 * K.abs(self.p))
+            regularization += K.sum(self.l1 * K.abs(x))
-        return K.in_train_phase(regularized_loss, loss)
+            regularization += K.sum(self.l2 * K.square(x))
-class ActivityRegularizer(Regularizer):
+# Aliases.
-                'l2': float(self.l2)}
+WeightRegularizer = L1L2Regularizer
-    return WeightRegularizer(l1=l)
+    return L1L2Regularizer(l1=l)
-    return WeightRegularizer(l2=l)
+    return L1L2Regularizer(l2=l)
-    return WeightRegularizer(l1=l1, l2=l2)
+    return L1L2Regularizer(l1=l1, l2=l2)
-    return ActivityRegularizer(l1=l)
+    return L1L2Regularizer(l1=l)
-    return ActivityRegularizer(l2=l)
+    return L1L2Regularizer(l2=l)
-    return ActivityRegularizer(l1=l1, l2=l2)
+    return L1L2Regularizer(l1=l1, l2=l2)
-    _BACKEND = 'tensorflow'
+# Default backend: TensorFlow.
-    assert type(_epsilon) == float
+    assert isinstance(_epsilon, float)
-    _image_dim_ordering = _config.get('image_dim_ordering', image_dim_ordering())
+    _image_dim_ordering = _config.get('image_dim_ordering',
-    raise Exception('Unknown backend: ' + str(_BACKEND))
+    raise ValueError('Unknown backend: ' + str(_BACKEND))
-        raise Exception('Unknown floatx type: ' + str(floatx))
+        raise ValueError('Unknown floatx type: ' + str(floatx))
-        raise Exception('Unknown dim_ordering:', dim_ordering)
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-                            'with the TensorFlow backend.')
+            raise RuntimeError('TensorBoard callback only works '
-        raise Exception('label_mode must be one of "fine" "coarse".')
+        raise ValueError('label_mode must be one of "fine" "coarse".')
-    origin = "http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz"
+    dirname = 'cifar-100-python'
-    X_train, y_train = load_batch(fpath, label_key=label_mode+'_labels')
+    X_train, y_train = load_batch(fpath, label_key=label_mode + '_labels')
-    X_test, y_test = load_batch(fpath, label_key=label_mode+'_labels')
+    X_test, y_test = load_batch(fpath, label_key=label_mode + '_labels')
-    '''
+    '''Loads IMDB dataset.
-                        'Increase maxlen.')
+        raise ValueError('After filtering for sequences shorter than maxlen=' +
-                        'for 2D square matrices.')
+        raise ValueError('Identity matrix initialization can only be used '
-            raise Exception('Invalid border mode for Convolution1D:', border_mode)
+            raise ValueError('Invalid border mode for Convolution1D:', border_mode)
-            raise Exception('Invalid border mode for AtrousConv1D:', border_mode)
+            raise ValueError('Invalid border mode for AtrousConv1D:', border_mode)
-            raise Exception('Invalid border mode for Convolution2D:', border_mode)
+            raise ValueError('Invalid border mode for Convolution2D:', border_mode)
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid border mode for Deconvolution2D:', border_mode)
+            raise ValueError('Invalid border mode for Deconvolution2D:', border_mode)
-                                              W_regularizer=W_regularizer, b_regularizer=b_regularizer,
+                                              init=init,
-                                              bias=bias, **kwargs)
+                                              W_constraint=W_constraint,
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid border mode for AtrousConv2D:', border_mode)
+            raise ValueError('Invalid border mode for AtrousConv2D:', border_mode)
-                                                  W_regularizer=W_regularizer, b_regularizer=b_regularizer,
+                                                  init=init,
-                                                  bias=bias, **kwargs)
+                                                  W_constraint=W_constraint,
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                                  self.subsample[0], dilation=self.atrous_rate[0])
+                                  self.subsample[0],
-                                  self.subsample[1], dilation=self.atrous_rate[1])
+                                  self.subsample[1],
-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                            'with TensorFlow for the time being.')
+        if K.backend() != 'tensorflow':
-            raise Exception('Invalid border mode for SeparableConv2D:', border_mode)
+            raise ValueError('Invalid border mode for SeparableConv2D:', border_mode)
-            raise Exception('Invalid border mode for SeparableConv2D:', border_mode)
+            raise ValueError('Invalid border mode for SeparableConv2D:', border_mode)
-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'
+        if border_mode not in {'valid', 'same'}:
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid border mode for Convolution3D:', border_mode)
+            raise ValueError('Invalid border mode for Convolution3D:', border_mode)
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+                raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-        assert dim_ordering in {'tf', 'th'}, '`dim_ordering` must be in {"tf", "th"}.'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if dim_ordering not in {'tf', 'th'}:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-        assert len(self.cropping) == 2, 'cropping must be a tuple length of 2'
+        if len(self.cropping) != 2:
-        length = input_shape[1] - self.cropping[0] - self.cropping[1] if input_shape[1] is not None else None
+        if input_shape[1] is not None:
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if len(self.cropping) != 2:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-    def __init__(self, cropping=((1, 1), (1, 1), (1, 1)), dim_ordering='default', **kwargs):
+    def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        if len(self.cropping) != 3:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-        if hasattr(obj, '__call__'):
+        if callable(obj):
-        if type(obj) is list:
+        if isinstance(obj, list):
-        if type(obj) is dict:
+        if isinstance(obj, dict):
-                        'Maybe you meant to use `Sequential.from_config(config)`?')
+        raise TypeError('`model_fom_config` expects a dictionary, not a list. '
-                             'Found: ' + str(layer))
+            raise TypeError('The added layer must be '
-                                    '`batch_input_shape` argument.')
+                    raise ValueError('The first layer in a '
-                                ' pre-existing inbound connections.')
+                raise ValueError('A layer added to a Sequential model must '
-                                'use the functional API.')
+                raise ValueError('All layers in a Sequential model '
-                raise Exception('All layers in a Sequential model '
+            if isinstance(output_tensor, list):
-            raise Exception('There are no layers in the model.')
+            raise TypeError('There are no layers in the model.')
-            raise Exception('Sequential model cannot be built: model is empty.'
+            raise TypeError('Sequential model cannot be built: model is empty.'
-        self.model = Model(self.inputs, self.outputs[0], name=self.name + '_model')
+        self.model = Model(self.inputs, self.outputs[0],
-            raise Exception('The model needs to be compiled before being used.')
+            raise RuntimeError('The model needs to be compiled '
-            raise Exception('Received unknown keyword arguments: ' +
+            raise TypeError('Received unknown keyword arguments: ' +
-            raise Exception('The model needs to be compiled before being used.')
+            raise RuntimeError('The model needs to be compiled '
-            raise Exception('Received unknown keyword arguments: ' +
+            raise TypeError('Received unknown keyword arguments: ' +
-            raise Exception('The model needs to be compiled before being used.')
+            raise RuntimeError('The model needs to be compiled '
-            raise Exception('Received unknown keyword arguments: ' +
+            raise TypeError('Received unknown keyword arguments: ' +
-            raise Exception('The model needs to be compiled before being used.')
+            raise RuntimeError('The model needs to be compiled '
-            raise Exception('Received unknown keyword arguments: ' +
+            raise TypeError('Received unknown keyword arguments: ' +
-            raise Exception('The model needs to be compiled before being used.')
+            raise RuntimeError('The model needs to be compiled '
-            warnings.warn('The "nb_worker" argument is deprecated when pickle_safe is False')
+            warnings.warn('The "nb_worker" argument is deprecated '
-            raise Exception('Received unknown keyword arguments: ' +
+            raise TypeError('Received unknown keyword arguments: ' +
-            raise Exception('The model needs to be compiled before being used.')
+            raise RuntimeError('The model needs to be compiled '
-            warnings.warn('The "nb_worker" argument is deprecated when pickle_safe is False')
+            warnings.warn('The "nb_worker" argument is deprecated '
-            raise Exception('Received unknown keyword arguments: ' +
+            raise TypeError('Received unknown keyword arguments: ' +
-            warnings.warn('The "nb_worker" argument is deprecated when pickle_safe is False')
+            warnings.warn('The "nb_worker" argument is deprecated '
-                if type(update) is tuple:
+                if isinstance(update, tuple):
-        assert type(inputs) in {list, tuple}
+        if not isinstance(inputs, (list, tuple)):
-                            str(identifier))
+            raise ValueError('Invalid ' + str(module_name) + ': ' +
-    elif type(identifier) is dict:
+    elif isinstance(identifier, dict):
-                            str(identifier))
+            raise ValueError('Invalid ' + str(module_name) + ': ' +
-    return func(values).__closure__
+    return python_types.FunctionType(code, globs,
-            @param interval: minimum visual progress update interval (in seconds)
+        '''Dislays a progress bar.
-            @param force: force visual progress update
+        '''Updates the progress bar.
-                self.sum_values[k] = [v * (current - self.seen_so_far), current - self.seen_so_far]
+                self.sum_values[k] = [v * (current - self.seen_so_far),
-            sys.stdout.write("\r")
+            sys.stdout.write('\b' * prev_total_width)
-                if type(self.sum_values[k]) is list:
+                if isinstance(self.sum_values[k], list):
-                info += ((prev_total_width - self.total_width) * " ")
+                info += ((prev_total_width - self.total_width) * ' ')
-                sys.stdout.write("\n")
+                sys.stdout.write('\n')
-def print_summary(layers, relevant_nodes=None, line_length=100, positions=[.33, .55, .67, 1.]):
+def print_summary(layers, relevant_nodes=None,
-        if type(outputs) is not list:
+        if not isinstance(outputs, list):
-                        'the `model.compile()` method.')
+        raise ValueError('The model is not configured to compute accuracy. '
-        if type(loss) is list:
+        if isinstance(loss, list):
-        v = tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)
+        v = tf.SparseTensor(indices=indices,
-        return tf.reshape(tf.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:])
+        return tf.reshape(tf.matmul(xt, yt),
-    if type(axes) == int:
+    if isinstance(axes, int):
-    if type(axis) is tuple:
+    if isinstance(axis, tuple):
-    if type(axis) is list:
+    if isinstance(axis, list):
-        raise Exception('Invalid dim_ordering: ' + dim_ordering)
+        raise ValueError('Invalid dim_ordering:', dim_ordering)
-        raise Exception('Invalid dim_ordering: ' + dim_ordering)
+        raise ValueError('Invalid dim_ordering:', dim_ordering)
-    if not hasattr(n, 'shape') and not hasattr(n, '__len__') and not hasattr(n, '_shape'):
+    if isinstance(n, int):
-    if type(axes) == int:
+    if isinstance(axes, int):
-                assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)
+                assign_placeholder = tf.placeholder(tf_dtype,
-        assert type(updates) in {list, tuple}, 'Updates in a TensorFlow backend function should be a list or tuple.'
+        if not isinstance(inputs, (list, tuple)):
-        updated = session.run(self.outputs + [self.updates_op], feed_dict=feed_dict)
+        updated = session.run(self.outputs + [self.updates_op],
-        raise Exception('Invalid border mode: ' + str(border_mode))
+        raise ValueError('Invalid border mode:', border_mode)
-        raise Exception('Invalid pooling mode: ' + str(pool_mode))
+        raise ValueError('Invalid pooling mode:', pool_mode)
-        raise Exception('Invalid pooling mode: ' + str(pool_mode))
+        raise ValueError('Invalid pooling mode:', pool_mode)
-        raise Exception('Specify either a shape or ndim value.')
+        raise ValueError('Specify either a shape or ndim value.')
-    if type(axes) == int:
+    if isinstance(axes, int):
-            raise Exception('Invalid concat axis for sparse matrix: ' + axis)
+            raise ValueError('Invalid concat axis for sparse matrix:', axis)
-        raise Exception('Invalid dim_ordering: ' + dim_ordering)
+        raise ValueError('Invalid dim_ordering:', dim_ordering)
-        raise Exception('Invalid dim_ordering: ' + dim_ordering)
+        raise ValueError('Invalid dim_ordering:', dim_ordering)
-        raise Exception('Invalid dim_ordering: ' + dim_ordering)
+        raise ValueError('Invalid dim_ordering:', dim_ordering)
-        raise Exception('Invalid dim_ordering: ' + dim_ordering)
+        raise ValueError('Invalid dim_ordering:', dim_ordering)
-        raise Exception('Invalid dim_ordering: ' + dim_ordering)
+        raise ValueError('Invalid dim_ordering:', dim_ordering)
-    if type(axes) == int:
+    if isinstance(axes, int):
-                        "If you have an expression instead, use eval().")
+        raise TypeError('get_value() can only be called on a variable. '
-        assert type(inputs) in {list, tuple}
+        assert isinstance(inputs, (list, tuple))
-                msg = "Invalid argument '%s' passed to K.function" % key
+                msg = 'Invalid argument "%s" passed to K.function' % key
-                            'must be provided to `rnn`.')
+            raise ValueError('When specifying `unroll=True`, '
-            if type(results) is list:
+            if isinstance(results, list):
-            if type(results) is list:
+            if isinstance(results, list):
-                                   'pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps')
+    if not hasattr(module, func):
-        raise Exception('Dropout level must be in interval [0, 1[.')
+        raise ValueError('Dropout level must be in interval [0, 1[.')
-        raise Exception('Border mode not supported: ' + str(border_mode))
+        raise ValueError('Border mode not supported:', str(border_mode))
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ', dim_ordering)
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ' + dim_ordering)
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-                            '0.9.0dev3 or newer.')
+            raise ValueError('conv3d with filter dilation requires Theano '
-
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-        raise Exception('Invalid border mode: ' + str(border_mode))
+        raise ValueError('Invalid border mode:', border_mode)
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-        raise Exception('Invalid border mode: ' + str(border_mode))
+        raise ValueError('Invalid border mode:', border_mode)
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-        raise Exception('Invalid pooling mode: ' + str(pool_mode))
+        raise ValueError('Invalid pooling mode:', pool_mode)
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-
+        raise ValueError('Invalid border mode:', border_mode)
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-        raise Exception('Invalid pooling mode: ' + str(pool_mode))
+        raise ValueError('Invalid pooling mode:', pool_mode)
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-        raise Exception('border_mode="same" not supported with Theano.')
+        raise ValueError('border_mode="same" not supported with Theano.')
-        raise Exception('Invalid border mode: ' + str(border_mode))
+        raise ValueError('Invalid border mode:', border_mode)
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering:', dim_ordering)
-        raise Exception('Invalid pooling mode: ' + str(pool_mode))
+        raise ValueError('Invalid pooling mode:', pool_mode)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)
-                            'layer in your model.')
+            raise ValueError('The shape of the input to "Flatten" '
-        elif type(output_shape) in {tuple, list}:
+        elif isinstance(output_shape, (tuple, list)):
-                raise Exception('In Lambda, `output_shape` '
+            if not callable(output_shape):
-                if type(input_shape) is list:
+            if K.backend() == 'tensorflow':
-                if type(x) is list:
+                if isinstance(x, list):
-            if type(input_shape) is list:
+        elif isinstance(self._output_shape, (tuple, list)):
-                raise Exception('output_shape function must return a tuple')
+            if not isinstance(shape, (list, tuple)):
-            raise Exception('Unknown function type: ' + function_type)
+            raise TypeError('Unknown function type:', function_type)
-                    raise Exception(
+                    raise ValueError(
-    if type(x) is list:
+    if isinstance(x, list):
-        if type(ndim) is str:
+        if isinstance(ndim, str):
-                                               str(self.input_spec))
+        if not isinstance(self.input_spec, list):
-                                str(input))
+                raise ValueError('Layer ' + self.name + ' expects ' +
-                if type(spec.ndim) is str:
+                if isinstance(spec.ndim, str):
-                                        str(K.ndim(x)))
+                        raise ValueError('Input ' + str(input_index) +
-                                        str(K.ndim(x)))
+                        raise ValueError('Input ' + str(input_index) +
-                                    str(K.dtype(x)))
+                    raise ValueError('Input ' + str(input_index) +
-                                            str(x_shape))
+                            raise ValueError(
-                if type(input_mask) is list:
+                if isinstance(input_mask, list):
-                                        'but was passed an input_mask: ' + str(input_mask))
+                        raise ValueError('Layer ' + self.name +
-                                    'but was passed an input_mask: ' + str(input_mask))
+                    raise ValueError('Layer ' + self.name +
-        if not hasattr(mode, '__call__'):
+        if not callable(mode):
-                            'layers with at least 2 elements. Found: ' + str(layers))
+                raise ValueError('Invalid merge mode: ' + str(mode))
-            if type(layer_output_shape) is list:
+            if isinstance(layer_output_shape, list):
-                                'Layer shapes: %s' % input_shapes)
+                raise ValueError('Only layers of same output shape can '
-                raise Exception(mode + ' merge takes exactly 2 layers')
+                raise ValueError(mode + ' merge takes exactly 2 layers')
-            if type(dot_axes) == int:
+            if isinstance(dot_axes, int):
-                raise Exception('Invalid type for dot_axes - should be a list.')
+            if not isinstance(self.dot_axes, (list, tuple)):
-                raise Exception('Invalid format for dot_axes - list elements should be "int".')
+                raise ValueError('Invalid format for dot_axes - '
-                                'Layer shapes: %s, %s' % (shape1, shape2))
+                raise ValueError('Dimension incompatibility using dot mode: '
-                                'Layer shapes: %s' % (input_shapes))
+                raise ValueError('"concat" mode can only merge '
-            raise Exception('Merge must be called on a list of tensors '
+        if not isinstance(inputs, list) or len(inputs) <= 1:
-        if hasattr(self.mode, '__call__'):
+        if callable(self.mode):
-            raise Exception('Unknown merge mode.')
+            raise ValueError('Unknown merge mode.')
-            raise Exception('Merge can only be called on a list of tensors, '
+        if not isinstance(inputs, list):
-        assert type(input_shape) is list  # Must have multiple input shape tuples.
+        # Must have multiple input shape tuples.
-            if hasattr(self._output_shape, '__call__'):
+        if callable(self.mode):
-                                '`output_shape` to Merge.')
+                raise ValueError('The Merge layer ' + self.name +
-            if hasattr(self._output_mask, '__call__'):
+        elif callable(self.mode):
-            raise Exception('Invalid merge mode: {}'.format(self.mode))
+            raise ValueError('Invalid merge mode: {}'.format(self.mode))
-        if type(input) in {list, tuple}:
+        if isinstance(input, (list, tuple)):
-        if type(output) in {list, tuple}:
+        if isinstance(output, (list, tuple)):
-                    raise Exception('Layer ' + layer.name +
+                if not isinstance(layer.input_spec, list):
-            if type(output_shapes) is list and len(output_shapes) == 1:
+            if isinstance(output_shapes, list) and len(output_shapes) == 1:
-            if type(output_shapes) is list and len(output_shapes) == 1:
+            if isinstance(output_shapes, list) and len(output_shapes) == 1:
-    if type(data) is dict:
+    if isinstance(data, dict):
-    elif type(data) is list:
+    elif isinstance(data, list):
-        if type(x_weight) is list and len(x_weight) == 1:
+        if isinstance(x_weight, list) and len(x_weight) == 1:
-        if type(x_weight) is dict and output_names[0] in x_weight:
+        if isinstance(x_weight, dict) and output_names[0] in x_weight:
-    if type(x_weight) is list:
+    if isinstance(x_weight, list):
-    if type(x_weight) is dict:
+    if isinstance(x_weight, dict):
-    if type(metrics) is list:
+    if isinstance(metrics, list):
-    elif type(metrics) is dict:
+    elif isinstance(metrics, dict):
-            if type(output_metrics) is not list:
+            if not isinstance(output_metrics, list):
-        raise Exception('Type of `metrics` argument not understood. '
+        raise TypeError('Type of `metrics` argument not understood. '
-    if type(X) == list:
+    if isinstance(X, list):
-        elif type(loss_weights) is dict:
+        elif isinstance(loss_weights, dict):
-                                    str(self.output_names))
+                    raise ValueError('Unknown entry in loss_weights '
-        elif type(loss_weights) is list:
+        elif isinstance(loss_weights, list):
-                                str(loss_weights))
+                raise ValueError('When passing a list as loss_weights, '
-                            str(loss_weights))
+            raise TypeError('Could not interpret loss_weights argument: ' +
-        if type(loss) is dict:
+        if isinstance(loss, dict):
-                                    str(self.output_names))
+                    raise ValueError('Unknown entry in loss '
-                                    '" missing from loss dictionary')
+                    raise ValueError('Output "' + name +
-        elif type(loss) is list:
+        elif isinstance(loss, list):
-                                str(loss))
+                raise ValueError('When passing a list as loss, '
-        if type(masks) is not list:
+        if not isinstance(masks, list):
-        if type(sample_weight_mode) is dict:
+        if isinstance(sample_weight_mode, dict):
-                                    str(self.output_names))
+                    raise ValueError('Unknown entry in '
-                                    'dictionary')
+                    raise ValueError('Output "' + name +
-        elif type(sample_weight_mode) is list:
+        elif isinstance(sample_weight_mode, list):
-                                str(sample_weight_mode))
+                raise ValueError('When passing a list as sample_weight_mode, '
-            if self.uses_learning_phase and type(K.learning_phase()) is not int:
+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-            if self.uses_learning_phase and type(K.learning_phase()) is not int:
+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-            if self.uses_learning_phase and type(K.learning_phase()) is not int:
+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-                    if type(ins[-1]) is float:
+                    if isinstance(ins[-1], float):
-                if type(outs) != list:
+                if not isinstance(outs, list):
-                        if type(val_outs) != list:
+                        if not isinstance(val_outs, list):
-            if type(ins[-1]) is float:
+            if isinstance(ins[-1], float):
-            if type(batch_outs) != list:
+            if not isinstance(batch_outs, list):
-            if type(ins[-1]) is float:
+            if isinstance(ins[-1], float):
-            if type(batch_outs) == list:
+            if isinstance(batch_outs, list):
-            if self.uses_learning_phase and type(K.learning_phase()) is not int:
+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-                slice_X(sample_weights, 0, split_at), slice_X(sample_weights, split_at))
+                slice_X(sample_weights, 0, split_at),
-            if self.uses_learning_phase and type(K.learning_phase()) is not int:
+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-        if self.uses_learning_phase and type(K.learning_phase()) is not int:
+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):
-        if self.uses_learning_phase and type(K.learning_phase()) is not int:
+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
-        if self.uses_learning_phase and type(K.learning_phase()) is not int:
+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
-        if self.uses_learning_phase and type(K.learning_phase()) is not int:
+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
-        if self.uses_learning_phase and type(K.learning_phase()) is not int:
+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
-        if self.uses_learning_phase and type(K.learning_phase()) is not int:
+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):
-                if type(x) is list:
+                if isinstance(x, list):
-                elif type(x) is dict:
+                elif isinstance(x, dict):
-                if type(outs) != list:
+                if not isinstance(outs, list):
-                    if type(val_outs) is not list:
+                    if not isinstance(val_outs, list):
-            if type(x) is list:
+            if isinstance(x, list):
-            elif type(x) is dict:
+            elif isinstance(x, dict):
-        if type(outs) is not list:
+        if not isinstance(outs, list):
-            if type(x) is list:
+            if isinstance(x, list):
-            elif type(x) is dict:
+            elif isinstance(x, dict):
-            if type(outs) != list:
+            if not isinstance(outs, list):
-
+if K.backend() == 'tensorflow':
-        self.merged = tf.merge_all_summaries()
+        if parse_version(tf.__version__) >= parse_version('0.12.0'):
-            if parse_version(tf.__version__) >= parse_version('0.8.0'):
+            if parse_version(tf.__version__) >= parse_version('0.12.0'):
-            self.writer = tf.train.SummaryWriter(self.log_dir)
+            if parse_version(tf.__version__) >= parse_version('0.12.0'):
-    model = Model(inputs, x)
+    model = Model(inputs, x, name='inception_v3')
-    model = Model(inputs, x)
+    model = Model(inputs, x, name='music_tagger_crnn')
-    model = Model(inputs, x)
+    model = Model(inputs, x, name='resnet50')
-    model = Model(inputs, x)
+    model = Model(inputs, x, name='vgg16')
-    model = Model(inputs, x)
+    model = Model(inputs, x, name='vgg19')
-    model = Model(inputs, x)
+    model = Model(inputs, x, name='xception')
-sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
+# Let's train the model using RMSprop
-              optimizer=sgd,
+              optimizer='rmsprop',
-        variable, value, momentum, zero_debias=False)
+    try:
-                                reduction_axes, epsilon=0.0001):
+                                reduction_axes, epsilon=1e-3):
-def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):
+def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):
-                                reduction_axes, epsilon=0.0001):
+                                reduction_axes, epsilon=1e-3):
-def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):
+# TODO remove this if statement when Theano without
-    def __init__(self, epsilon=1e-5, mode=0, axis=-1, momentum=0.99,
+    def __init__(self, epsilon=1e-3, mode=0, axis=-1, momentum=0.99,
-                    epsilon=self.epsilon)
+            x_normed, mean, std = K.normalize_batch_in_training(
-                if K.backend() == 'tensorflow' and sorted(reduction_axes) == range(K.ndim(x))[:-1]:
+                if sorted(reduction_axes) == range(K.ndim(x))[:-1]:
-        variable, value, momentum)
+        variable, value, momentum, zero_debias=False)
-        h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1
+        w_pad = pool_size[0] - 2 if pool_size[0] > 2 and pool_size[0] % 2 == 1 else pool_size[0] - 1
-                   input_shape=(3, 5, 4))
+    for border_mode in ['valid', 'same']:
-    if 'int' in x.dtype:
+    # bool is available since theano v0.9dev
-            if os.path.isfile(os.path.join(directory, f)) and re.match('([\w]+\.(?:' + ext + '))', f)]
+    return [os.path.join(root, f)
-                            save_to_dir=None, save_prefix='', save_format='jpeg'):
+                            save_to_dir=None, save_prefix='', save_format='jpeg',
-            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)
+            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format,
-                 save_to_dir=None, save_prefix='', save_format='jpeg'):
+                 save_to_dir=None, save_prefix='', save_format='jpeg',
-                    self.nb_sample += 1
+            for root, dirs, files in _recursive_list(subpath):
-                    i += 1
+            for root, dirs, files in _recursive_list(subpath):
-    '''Cast a Numpy array to floatx.
+    '''Cast a Numpy array to the default Keras float type.
-    '''Returns the image dimension ordering
+    '''Returns the default image dimension ordering
-        - [On the Properties of Neural Machine Translation: EncoderâDecoder Approaches](http://www.aclweb.org/anthology/W14-4012)
+        - [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](http://www.aclweb.org/anthology/W14-4012)
-        if X.shape[self.channel_index] not in {1, 3}:
+        if X.shape[self.channel_index] not in {1, 3, 4}:
-                'either 1 or 3 channels on axis ' + str(self.channel_index) + '. '
+                'either 1, 3 or 4 channels on axis ' + str(self.channel_index) + '. '
-        if self.X.shape[channels_axis] not in {1, 3}:
+        if self.X.shape[channels_axis] not in {1, 3, 4}:
-                             'either 1 or 3 channels on axis ' + str(channels_axis) + '. '
+                             'either 1, 3 or 4 channels on axis ' + str(channels_axis) + '. '
-            x = np.random.random((32, 10, 10, 4))
+            x = np.random.random((32, 10, 10, 5))
-            x = np.random.random((32, 10, 10, 4))
+            x = np.random.random((32, 10, 10, 5))
-GPU run command:
+GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):
-# the CIFAR10 images are RGB
+# The CIFAR10 images are RGB.
-# the data, shuffled and split between train and test sets
+# The data, shuffled and split between train and test sets:
-# convert class vectors to binary class matrices
+# Convert class vectors to binary class matrices.
-# let's train the model using SGD + momentum (how original).
+# Let's train the model using SGD + momentum:
-    # this will do preprocessing and realtime data augmentation
+    # This will do preprocessing and realtime data augmentation:
-    # (std, mean, and principal components if ZCA whitening is applied)
+    # Compute quantities required for featurewise normalization
-    # fit the model on the batches generated by datagen.flow()
+    # Fit the model on the batches generated by datagen.flow().
-    optimizer = optimizer_from_config(optimizer_config)
+    optimizer = optimizer_from_config(optimizer_config, custom_objects=custom_objects)
-                 field='data'):
+                 field='data',
-                          {self.field: json.dumps(send)})
+                          {self.field: json.dumps(send)},
-    import keras.backend.tensorflow_backend as KTF
+
-                                                         nb_class=nb_class)
+    (X_train, y_train), (X_test, y_test) = get_test_data(
-                yield (X_train[i * batch_size: (i + 1) * batch_size], y_train[i * batch_size: (i + 1) * batch_size])
+                yield (X_train[i * batch_size: (i + 1) * batch_size],
-                yield (X_test[i * batch_size: (i + 1) * batch_size], y_test[i * batch_size: (i + 1) * batch_size])
+                yield (X_test[i * batch_size: (i + 1) * batch_size],
-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)
+              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=3)
-                output: tensor with shape (samples, output_dim) (no time dimension),
+                output: tensor with shape (samples, output_dim)
-        initial_states: tensor with shape (samples, output_dim) (no time dimension),
+        initial_states: tensor with shape (samples, output_dim)
-    assert ndim >= 3, 'Input should be at least 3D.'
+    if ndim < 3:
-
+            raise ValueError('Unrolling requires a '
-                tiled_mask_t = tf.tile(mask_t, tf.pack([1, tf.shape(output)[1]]))
+                # tf.select needs its condition tensor
-
+                    tiled_mask_t = tf.tile(mask_t,
-                mask = tf.reverse(mask, [True] + [False] * (ndim - 2))
+                mask = tf.reverse(mask, [True] + [False] * (ndim - 1))
-                tiled_mask_t = tf.tile(mask_t, tf.pack([1, tf.shape(output)[1]]))
+                tiled_mask_t = tf.tile(mask_t,
-            sub_sample: tuple of length 2. Factor by which to subsample output.
+            subsample: tuple of length 2. Factor by which to subsample output.
-                        'Received arg: ', zoom_range)
+        raise ValueError('zoom_range should be a tuple or list of two floats. '
-        raise Exception('Unsupported channel number: ', x.shape[2])
+        raise ValueError('Unsupported channel number: ', x.shape[2])
-    # image has dim_ordering (height, width, channel)
+    if dim_ordering not in {'th', 'tf'}:
-        raise Exception('Unsupported image shape: ', x.shape)
+        raise ValueError('Unsupported image shape: ', x.shape)
-            any other transformation).
+            otherwise we multiply the data by the value provided
-                            'Received arg: ', dim_ordering)
+            raise ValueError('dim_ordering should be "tf" (channel after row and '
-                            'Received arg: ', zoom_range)
+            raise ValueError('zoom_range should be a float or '
-            x -= self.mean
+            if self.mean is not None:
-
+            if self.std is not None:
-
+            if self.principal_components is not None:
-            rounds: if `augment`,
+            X: Numpy array, the data to fit on. Should have rank 4.
-            self.mean = np.mean(X, axis=0)
+            self.mean = np.mean(X, axis=(0, self.row_index, self.col_index))
-            X /= (self.std + 1e-7)
+            self.std = np.std(X, axis=(0, self.row_index, self.col_index))
-                            'Found: X.shape = %s, y.shape = %s' % (np.asarray(X).shape, np.asarray(y).shape))
+            raise ValueError('X (images tensor) and y (labels) '
-        self.y = y
+        self.X = np.asarray(X)
-            img = load_img(os.path.join(self.directory, fname), grayscale=grayscale, target_size=self.target_size)
+            img = load_img(os.path.join(self.directory, fname),
-from keras.preprocessing.image import *
+from keras.preprocessing import image
-                img_list.append(img_to_array(im)[None, ...])
+                img_list.append(image.img_to_array(im)[None, ...])
-            generator = ImageDataGenerator(
+            generator = image.ImageDataGenerator(
-                        (potentially_flipped_x == flip_axis(x, col_index)).all())
+    def test_image_data_generator_invalid_data(self):
-                if input_shape[1] != 3:
+                if input_shape[0] != 3:
-            Currentl only symmetric padding is supported.
+            Currently only symmetric padding is supported.
-        - [Supervised sequence labelling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)
+        - [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)
-        output_shape_type = config.pop('output_shape_type')
+        output_shape_type = config.pop('output_shape_type', None)
-            output_shape = func_load(config['output_shape'], globs=globals())
+            output_shape = func_load(config['output_shape'],
-            output_shape = config['output_shape']
+            output_shape = config.get('output_shape')
-        output_mask_type = config.pop('output_mask_type')
+        output_mask_type = config.pop('output_mask_type', None)
-            output_mask = func_load(config['output_mask'], globs=globals())
+            output_mask = func_load(config['output_mask'],
-            output_mask = config['output_mask']
+            output_mask = config.get('output_mask')
-          dot_axes=-1, output_shape=None, output_mask=None, arguments={}, name=None):
+          dot_axes=-1, output_shape=None, output_mask=None,
-    x = T.switch(_LEARNING_PHASE, x, alt)
+    x = theano.ifelse.ifelse(_LEARNING_PHASE, x, alt)
-    x = T.switch(_LEARNING_PHASE, alt, x)
+    x = theano.ifelse.ifelse(_LEARNING_PHASE, alt, x)
-    model = Model(img_input, x)
+    # Ensure that the model takes into account
-    model = Model(melgram_input, x)
+    # Ensure that the model takes into account
-    model = Model(img_input, x)
+    # Ensure that the model takes into account
-    model = Model(img_input, x)
+    # Ensure that the model takes into account
-    model = Model(img_input, x)
+    # Ensure that the model takes into account
-    model = Model(img_input, x)
+    # Ensure that the model takes into account
-        raise Exception('Tensor must be a Keras tensor. Found: ' + str(tensor))
+        return tensor
-    Arguments
+    # Arguments
-    at the appropiate time. Note that the callbacks expects positional
+    at the appropriate time. Note that the callbacks expects positional
-
+            # we want to train the genrator to trick the discriminator
-
+                for state, new_state in zip(states, new_states):
-    ds = f.createCArray(f.root, 'data', atom, array.shape)
+    ds = f.create_carray(f.root, 'data', atom, array.shape)
-            if self.__class__.__name__ in {'Sequential'}:
+            if self.__class__.__name__ == 'Sequential':
-        return sum([K.count_params(p) for p in self.trainable_weights])
+        return sum([K.count_params(p) for p in self.weights])
-from .imagenet_utils import decode_predictions
+from .imagenet_utils import decode_predictions, _obtain_input_shape
-                input_tensor=None):
+                input_tensor=None, input_shape=None):
-            input_shape = (None, None, 3)
+    input_shape = _obtain_input_shape(input_shape,
-from .imagenet_utils import decode_predictions, preprocess_input
+from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape
-             input_tensor=None):
+             input_tensor=None, input_shape=None):
-        input_tensor: optional Keras tensor (i.e. xput of `layers.Input()`)
+        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)
-            input_shape = (None, None, 3)
+    input_shape = _obtain_input_shape(input_shape,
-from .imagenet_utils import decode_predictions, preprocess_input
+from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape
-          input_tensor=None):
+          input_tensor=None, input_shape=None):
-            input_shape = (None, None, 3)
+    input_shape = _obtain_input_shape(input_shape,
-from .imagenet_utils import decode_predictions, preprocess_input
+from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape
-          input_tensor=None):
+          input_tensor=None, input_shape=None):
-            input_shape = (None, None, 3)
+    input_shape = _obtain_input_shape(input_shape,
-from .imagenet_utils import decode_predictions
+from .imagenet_utils import decode_predictions, _obtain_input_shape
-             input_tensor=None):
+             input_tensor=None, input_shape=None):
-        input_shape = (None, None, 3)
+    input_shape = _obtain_input_shape(input_shape,
-__version__ = '1.1.1'
+__version__ = '1.1.2'
-      version='1.1.1',
+      version='1.1.2',
-      download_url='https://github.com/fchollet/keras/tarball/1.1.1',
+      download_url='https://github.com/fchollet/keras/tarball/1.1.2',
-            self.writer.writeheader()
+            if self.append_header:
-        self.trainable = True
+        self._trainable = True
-@pytest.mark.skipif((K._BACKEND != 'tensorflow'),
+@pytest.mark.skipif((K.backend() != 'tensorflow'),
-    old_session = KTF.get_session()
+    model = Sequential()
-        model.compile(optimizer='sgd', loss={'output': 'mse'})
+    tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1)
-        cbks = [tsb]
+    # fit with validation data
-                  callbacks=cbks, nb_epoch=2)
+    # fit with validation data and accuracy
-                  callbacks=cbks, nb_epoch=2)
+    # fit generator with validation data
-                            callbacks=cbks)
+    # fit generator without validation data
-                            callbacks=cbks)
+    # fit generator with validation data and accuracy
-        shutil.rmtree(filepath)
+    # fit generator without validation data and accuracy
-    KTF.set_session(old_session)
+    assert os.path.exists(filepath)
-@pytest.mark.skipif((K._BACKEND != 'tensorflow'),
+@pytest.mark.skipif((K.backend() != 'tensorflow'),
-        self._collected_trainable_weights = collect_trainable_weights(self)
+        # collected trainable weights and sort them deterministically.
-            if self.__class__.__name__ in {'Sequential', 'Graph'}:
+            if self.__class__.__name__ in {'Sequential'}:
-from ..models import Model, Sequential, Graph
+from ..models import Model, Sequential
-        Layer instance (may be Model, Sequential, Graph, Layer...)
+        Layer instance (may be Model, Sequential, Layer...)
-from keras.models import Graph, Sequential
+from keras.models import Sequential
-    image_class = Input(shape=(1, 1), dtype='int32')
+    image_class = Input(shape=(1,), dtype='int32')
-    cls = Flatten()(Embedding(10, latent_size, input_length=1,
+    cls = Flatten()(Embedding(10, latent_size,
-    image_class = Input(shape=(1, 1), dtype='int32')
+    image_class = Input(shape=(1,), dtype='int32')
-            # (batch_size, 1, 1) so that we can feed them into the embedding
+            # (batch_size, 1) so that we can feed them into the embedding
-                [noise, sampled_labels.reshape((-1, 1, 1))], verbose=0)
+                [noise, sampled_labels.reshape((-1, 1))], verbose=0)
-                [noise, sampled_labels.reshape((-1, 1, 1))], [trick, sampled_labels]))
+                [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))
-            [noise, sampled_labels.reshape((-1, 1, 1))], verbose=False)
+            [noise, sampled_labels.reshape((-1, 1))], verbose=False)
-            [noise, sampled_labels.reshape((-1, 1, 1))],
+            [noise, sampled_labels.reshape((-1, 1))],
-        ]).reshape(-1, 1, 1)
+        ]).reshape(-1, 1)
-            Note: 'same' will only work with TensorFlow for the time being.
+from scipy.stats import norm
-grid_y = np.linspace(-15, 15, n)
+# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian
-plt.imshow(figure)
+plt.imshow(figure, cmap='Greys_r')
-grid_y = np.linspace(-15, 15, n)
+# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian
-plt.imshow(figure)
+plt.imshow(figure, cmap='Greys_r')
-def fbeta_score(y_true, y_pred, beta):
+def fbeta_score(y_true, y_pred, beta=1):
-                 node_indices=None, tensor_indices=None, name=None):
+                 arguments={}, node_indices=None, tensor_indices=None,
-            arguments = {}
+            arguments = self.arguments
-                                'no `output_shape` argument was provided.' +
+                                'no `output_shape` argument was provided. ' +
-                'output_shape_type': output_shape_type}
+                'output_shape_type': output_shape_type,
-          dot_axes=-1, output_shape=None, output_mask=None, name=None):
+          dot_axes=-1, output_shape=None, output_mask=None, arguments={}, name=None):
-    from keras.layers import Input, merge, Merge
+    from keras.layers import Input, merge, Merge, Masking
-                   output_shape=lambda tup: (tup[0][:-1],) + (tup[0][-1] + tup[1][-1],))
+                   output_shape=lambda tup: tup[0][:-1] + (tup[0][-1] + tup[1][-1],))
-        return K.concatenate([x, y])
+        return K.concatenate([x, y], axis=1)
-        return (s1[:-1],) + (s1[-1] + s2[-1],)
+        return (s1[0], s1[1] + s2[1]) + s1[2:]
-    
+
-                if target_dim is not None and target_dim != out_dim:
+                if out_dim is not None and target_dim != out_dim:
-def test_check_not_last_is_one():
+def test_check_not_failing():
-    variables = tf.all_variables()
+    if hasattr(tf, 'global_variables'):
-
+        if hasattr(tf, 'variables_initializer'):
-                  callback_metrics=[]):
+                  callback_metrics=[], initial_epoch=0):
-        for epoch in range(nb_epoch):
+        for epoch in range(initial_epoch, nb_epoch):
-            class_weight=None, sample_weight=None):
+            class_weight=None, sample_weight=None, initial_epoch=0):
-                              callback_metrics=callback_metrics)
+                              callback_metrics=callback_metrics,
-                      class_weight={}, max_q_size=10, nb_worker=1, pickle_safe=False):
+                      class_weight={}, max_q_size=10, nb_worker=1, pickle_safe=False,
-        epoch = 0
+        epoch = initial_epoch
-            if y.shape[1] == 1:
+            if y.shape[-1] == 1:
-                            'as the output.')
+        if loss.__name__ in key_losses:
-from keras.engine.training import Model
+from keras.engine.training import Model, check_loss_and_target_compatibility
-        if self.stateful:
+        if self.stateful and self.input_spec[0].shape:
-        self.updates += updates
+        try:
-
+                    # update model updates
-from keras.layers.core import Dense, Activation
+from keras.layers import Dense, Activation, Input
-from keras.models import Sequential
+from keras.models import Sequential, Model
-               batch_input_shape=(batch_size, tsteps, 1),
+        # Per-input updates.
-                updates += layer.updates
+                if len(layer.inbound_nodes) == 1:
-                                K.moving_average_update(self.running_std, std, self.momentum)]
+                self.add_updates([K.moving_average_update(self.running_mean, mean, self.momentum),
-            self.updates = []
+            updates = []
-                self.updates.append((self.states[i], states[i]))
+                updates.append((self.states[i], states[i]))
-        return self._gather_list_attr('updates')
+        return self.model.updates
-        return self._gather_list_attr('state_updates')
+        return self.model.state_updates
-                        'Here, ndim=' + str(ndim))
+        raise ValueError('Cannot apply softmax to a tensor '
-                          'create_input_layer'}
+                          'trainable'}
-                self.create_input_layer(batch_input_shape, input_dtype)
+from .utils.generic_utils import get_from_module
-            raise Exception('Invalid dim_ordering: ' + dim_ordering)
+            raise ValueError('Invalid dim_ordering: ' + dim_ordering)
-        if index:
+        if index is not None:
-    output = layer(K.variable(input))
+    output = layer(K.variable(input))
-    # TF variables have auto-generated the name, while Theano has auto-generated the auto_name variable. name in Theano is None
+    # TF variables have auto-generated the name, while Theano has auto-generated the auto_name variable.
-            weights.sort(key=lambda x: x.auto_name)
+            weights.sort(key=lambda x: x.name if x.name else x.auto_name)
-    input = np.ones((nb_samples, nb_steps, input_dim))
+    shape = (nb_samples, nb_steps, input_dim)
-    out = K.eval(layer.output)
+    output = layer(K.variable(input))
-    assert_allclose(out[:, 2:-2, :], 1.)
+        assert_allclose(np_output[:, offset, :], 0.)
-    out = K.eval(layer.output)
+    output = layer(K.variable(input))
-        assert_allclose(out[:, left_offset, :], 0.)
+        assert_allclose(np_output[:, left_offset, :], 0.)
-    assert_allclose(out[:, 1:-2, :], 1.)
+        assert_allclose(np_output[:, right_offset, :], 0.)
-    out = K.eval(layer.output)
+    output = layer(K.variable(input))
-        assert_allclose(out[:, 2:-2, 2:-2, :], 1.)
+            assert_allclose(np_output[:, offset, :, :], 0.)
-        assert_allclose(out[:, 2:-2, 2:-2, :], 1.)
+            assert_allclose(np_output[:, :, offset, :], 0.)
-    out = K.eval(layer.output)
+    output = layer(K.variable(input))
-            assert_allclose(out[:, top_offset, :, :], 0.)
+            assert_allclose(np_output[:, top_offset, :, :], 0.)
-            assert_allclose(out[:, bottom_offset, :, :], 0.)
+            assert_allclose(np_output[:, bottom_offset, :, :], 0.)
-            assert_allclose(out[:, :, left_offset, :], 0.)
+            assert_allclose(np_output[:, :, left_offset, :], 0.)
-        assert_allclose(out[:, 1:-2, 3:-4, :], 1.)
+            assert_allclose(np_output[:, :, right_offset, :], 0.)
-            assert_allclose(out[:, :, top_offset, :], 0.)
+            assert_allclose(np_output[:, :, top_offset, :], 0.)
-            assert_allclose(out[:, :, bottom_offset, :], 0.)
+            assert_allclose(np_output[:, :, bottom_offset, :], 0.)
-            assert_allclose(out[:, :, :, left_offset], 0.)
+            assert_allclose(np_output[:, :, :, left_offset], 0.)
-        assert_allclose(out[:, :, 1:-2, 3:-4], 1.)
+            assert_allclose(np_output[:, :, :, right_offset], 0.)
-    out = K.eval(layer.output)
+    output = layer(K.variable(input))
-    assert_allclose(out[:, 2:-2, 2:-2, 2:-2, :], 1.)
+        assert_allclose(np_output[:, offset, :, :, :], 0.)
-                out = K.eval(layer.output)
+                output = layer(K.variable(input))
-                    assert out.shape[3] == length_col * input_nb_col
+                    assert np_output.shape[2] == length_row * input_nb_row
-                    assert out.shape[2] == length_col * input_nb_col
+                    assert np_output.shape[1] == length_row * input_nb_row
-                assert_allclose(out, expected_out)
+                assert_allclose(np_output, expected_out)
-                    out = K.eval(layer.output)
+                    output = layer(K.variable(input))
-                        assert out.shape[4] == length_dim3 * input_len_dim3
+                        assert np_output.shape[2] == length_dim1 * input_len_dim1
-                        assert out.shape[3] == length_dim3 * input_len_dim3
+                        assert np_output.shape[1] == length_dim1 * input_len_dim1
-                    assert_allclose(out, expected_out)
+                    assert_allclose(np_output, expected_out)
-        input = np.random.rand(nb_samples, stack_size, input_len_dim1, input_len_dim2)
+        input = np.random.rand(nb_samples, stack_size,
-        input = np.random.rand(nb_samples, input_len_dim1, input_len_dim2, stack_size)
+        input = np.random.rand(nb_samples,
-    out = K.eval(layer.output)
+    layer = convolutional.Cropping2D(cropping=cropping,
-                             cropping[1][0]:-cropping[1][1]]
+                             cropping[0][0]: -cropping[0][1],
-                             cropping[1][0]:-cropping[1][1],
+                             cropping[0][0]: -cropping[0][1],
-    assert_allclose(out, expected_out)
+    assert_allclose(np_output, expected_out)
-        input = np.random.rand(nb_samples, stack_size, input_len_dim1, input_len_dim2, input_len_dim3)
+        input = np.random.rand(nb_samples, stack_size,
-        input = np.random.rand(nb_samples, input_len_dim1, input_len_dim2, input_len_dim3, stack_size)
+        input = np.random.rand(nb_samples,
-    out = K.eval(layer.output)
+    layer = convolutional.Cropping3D(cropping=cropping,
-                             cropping[2][0]:-cropping[2][1]]
+                             cropping[0][0]: -cropping[0][1],
-                             cropping[2][0]:-cropping[2][1],
+                             cropping[0][0]: -cropping[0][1],
-    assert_allclose(out, expected_out)
+    assert_allclose(np_output, expected_out)
-            K.eval(layer.output)
+            output = layer(K.variable(np.ones(input.shape)))
-    K.eval(layer.output)
+    output = layer(K.variable(np.ones(shape)))
-        if len(self.inbound_nodes) != 1:
+        if len(self.inbound_nodes) == 0:
-from .engine.topology import get_source_inputs, Node, Layer
+from .engine.topology import get_source_inputs, Node, Layer, Merge
-        if model.__class__.__name__ == 'Sequential':
+        if isinstance(model, Sequential):
-            if self.layers[0].__class__.__name__ == 'Merge':
+            if isinstance(self.layers[0], Merge):
-        if self.layers[0].__class__.__name__ == 'Merge':
+        if isinstance(self.layers[0], Merge):
-    if model.__class__.__name__ == 'Sequential':
+    if isinstance(model, Sequential):
-        
+
-            class_name = '{}({})'.format(class_name, layer.layer.__class__.__name__)
+            child_class_name = layer.layer.__class__.__name__
-            d[k.decode("utf8")] = v
+            d_decoded[k.decode("utf8")] = v
-                    print('Epoch %05d: early stopping' % (epoch))
+                self.stopped_epoch = epoch
-            ones = K.tile(ones, (1, input_dim))
+            ones = K.tile(ones, (1, int(input_dim)))
-            ones = K.tile(ones, (1, input_dim))
+            ones = K.tile(ones, (1, int(input_dim)))
-            ones = K.tile(ones, (1, input_dim))
+            ones = K.tile(ones, (1, int(input_dim)))
-                                mode='max')
+        # TODO remove the old call once Theano older than 0.9.0dev4 is deprecated
-                                mode='average_exc_pad')
+        # TODO remove the old call once Theano older than 0.9.0dev4 is deprecated
-                                mode='max')
+        # TODO remove the old call once Theano older than 0.9.0dev4 is deprecated
-                                mode='average_exc_pad')
+        # TODO remove the old call once Theano older than 0.9.0dev4 is deprecated
-        X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))
+        X.set_shape((None, None, original_shape[2] * height_factor if original_shape[2] is not None else None,
-        X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))
+        X.set_shape((None, original_shape[1] * height_factor if original_shape[1] is not None else None,
-                            ' weights. Provided weights: ' + str(weights)[:50] + '...')
+            raise ValueError('You called `set_weights(weights)` on layer "' + self.name +
-                                'provided weight shape ' + str(w.shape))
+                raise ValueError('Layer weight shape ' +
-        # layer instance (NOT a list).
+        # Layer instance (NOT a list).
-        # the current node will be added to the inbound_nodes of outbound_layer
+        # the current node will be added to the inbound_nodes of outbound_layer.
-        # the following 3 properties describe where
+        # The following 3 properties describe where
-        self.output_tensors = output_tensors  # list of tensors, created by outbound_layer.call()
+        self.inbound_layers = inbound_layers  # List of layer instances
-        self.output_masks = output_masks  # list of tensors, created by outbound_layer.compute_mask()
+        self.input_masks = input_masks  # List of tensors, 1:1 mapping with input_tensor.
-        self.output_shapes = output_shapes  # list of shape tuples, shapes of output_tensors
+        self.input_shapes = input_shapes  # List of shape tuples, shapes of input_tensors.
-        # add nodes to all layers involved.
+        # Add nodes to all layers involved.
-            # TODO: try to auto-infer shape if exception is raised by get_output_shape_for
+            # TODO: try to auto-infer shape if exception is raised by get_output_shape_for.
-        # these properties should have been set
+        # These properties should have been set
-        # to self.add_inbound_node()
+        # These lists will be filled via successive calls
-        # these properties will be set upon call of self.build(),
+        # These properties will be set upon call of self.build(),
-        # these properties should be set by the user via keyword arguments.
+        # These properties should be set by the user via keyword arguments.
-            # in this case we will create an input layer
+            # In this case we will create an input layer
-        # instantiate the input layer
+        # Instantiate the input layer.
-        # this will build the current layer
+        # This will build the current layer
-            # check ndim
+            # Check ndim.
-                    # tensorflow shape inference
+                    # Tensorflow shape inference.
-                # this is a Keras tensor
+                # This is a Keras tensor.
-                 init='uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-                 init='uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-                 init='glorot_uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-                 init='glorot_uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-                 init='glorot_uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-                 init='glorot_uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-                 init='glorot_uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-    def __init__(self, output_dim, init='glorot_uniform', activation='linear', weights=None,
+    def __init__(self, output_dim, init='glorot_uniform',
-                 activation='linear', weights=None,
+                 activation=None, weights=None,
-                 init='glorot_uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-                 init='uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-                 init='glorot_uniform', activation='linear', weights=None,
+                 init='glorot_uniform', activation=None, weights=None,
-            assert '+' in ndim, 'When passing a str "ndim", it should have the form "2+", "3+", etc.'
+            if '+' not in ndim:
-            assert int_ndim.isdigit(), 'When passing a str "ndim", it should have the form "2+", "3+", etc.'
+            if not int_ndim.isdigit():
-        input_spec: list of InputSpec class instances
+        name: String, must be unique within a model.
-        trainable: boolean, whether the layer weights
+        trainable: Boolean, whether the layer weights
-        uses_learning_phase: whether any operation
+        uses_learning_phase: Whether any operation
-        input_shape: shape tuple. Provided for convenience,
+        input_shape: Shape tuple. Provided for convenience,
-        input, output: input/output tensor(s). Note that if the layer is used
+        output_shape: Shape tuple. See above.
-        constraints: dict mapping weights to constraints.
+        input_mask, output_mask: Same as above, for masks.
-                - connect current layer with last layer from tensor:
+        call(x, mask=None): Where the layer's logic lives.
-                - build from x._keras_shape
+                - Add layer to tensor history
-            - we update the _keras_shape of every input tensor with
+            - We call self.add_inbound_node().
-            - we update the _keras_history of the output tensor(s)
+            - We update the _keras_history of the output tensor(s)
-            mask: tensor or list/tuple of tensors.
+            x: Can be a tensor or list/tuple of tensors.
-            # with the input_spec specified in the layer constructor
+            # Raise exceptions in case the input is not compatible
-            # collect input shapes to build layer
+            # Collect input shapes to build layer.
-                                    '`layer.build(batch_input_shape)`')
+                    raise ValueError('You tried to call layer "' + self.name +
-        # with the input_spec set at build time
+        # Raise exceptions in case the input is not compatible
-        input_tensors = to_list(x)
+        input_tensors = to_list(x)
-            # this will call layer.build() if necessary
+            # This will call layer.build() if necessary.
-            # output was already computed when calling self.add_inbound_node
+            # Outputs were already computed when calling self.add_inbound_node.
-            # else return a list (at least 2 elements)
+            # If single output tensor: return it,
-            # this case appears if the input was not a Keras tensor
+            # This case appears if the input was not a Keras tensor.
-            inbound_layers: can be a layer instance
+        # Arguments
-            node_indices: integer (or list of integers).
+            node_indices: Integer (or list of integers).
-            tensor_indices: integer or list of integers.
+            tensor_indices: Integer or list of integers.
-            input_shape: shape tuple (tuple of integers)
+            input_shape: Shape tuple (tuple of integers)
-            input_mask: tensor or list of tensors.
+            input: Tensor or list of tensors.
-            attr_name: human-readable attribute name, for error messages
+            node_index: Integer index of the node from which
-            # check that the inbound node is an Input node
+            # Check that the inbound node is an Input node.
-            # auto-infered shape takes priority
+            # Auto-infered shape takes priority.
-        # reset layer connections
+        # Reset layer connections.
-        # set Keras tensor metadata
+        # Set Keras tensor metadata.
-        # create node
+        # Create node.
-            config: a Python dictionary, typically the
+            config: A Python dictionary, typically the
-    '''TODO: dosctring
+    '''Layer to be used as an entry point into a graph.
-            # attempt automatic input shape inference
+            # Attempt automatic input shape inference.
-        # and set output_tensors' _keras_history
+        # Create an input node to add to self.outbound_node
-        ._keras_shape: integer shape tuple propagated
+        ._keras_shape: Integer shape tuple propagated
-        ._keras_history: last layer applied to the tensor.
+        ._keras_history: Last layer applied to the tensor.
-        shape: a shape tuple (integer), not including the batch size.
+        shape: A shape tuple (integer), not including the batch size.
-        batch_shape: a shape tuple (integer), including the batch size.
+        batch_shape: A shape tuple (integer), including the batch size.
-        sparse: a boolean specifying whether this will be a sparse tensor
+        sparse: A boolean specifying whether the placeholder
-    # note that in this case train_output and test_output are the same pointer.
+    # Return tensor including _keras_shape and _keras_history.
-        layers: can be a list of Keras tensors or
+        layers: Can be a list of Keras tensors or
-        mode: string or lambda/function. If string, must be one
+        mode: String or lambda/function. If string, must be one
-        output_shape: either a shape tuple (tuple of integers), or a lambda/function
+        concat_axis: Integer, axis to use in mode `concat`.
-        node_indices: optional list of integers containing
+        node_indices: Optional list of integers containing
-        tensor_indices: optional list of indices of output tensors
+        tensor_indices: Optional list of indices of output tensors
-        output_mask: mask or lambda/function to compute the output mask (only
+        output_mask: Mask or lambda/function to compute the output mask (only
-        # layer parameters
+        # Layer parameters.
-        self.input_spec = None  # compatible with whatever
+        self.input_spec = None  # Compatible with anything.
-            # this exists for backwards compatibility.
+            # This exists for backwards compatibility.
-                # the 1st output stream in the input layer
+                # By default we connect to
-                # and we only need a specific one
+                # Case: the layer has multiple output tensors
-        # case: "mode" is a lambda or function.
+        # Case: "mode" is a lambda or function.
-            return outputs[0]  # merge only returns a single tensor
+            return outputs[0]  # Merge only returns a single tensor.
-        # case: callable self._output_shape
+        assert type(input_shape) is list  # Must have multiple input shape tuples.
-                # TODO: consider shape auto-inference with TF
+                # TODO: consider shape auto-inference with TF.
-        # pre-defined merge modes
+        # Pre-defined merge modes.
-            # all tuples in input_shapes should be the same
+            # All tuples in input_shapes should be the same.
-            # this should have been caught earlier
+            # This should have been caught earlier.
-        mode: string or lambda/function. If string, must be one
+        mode: String or lambda/function. If string, must be one
-        output_shape: shape tuple (tuple of integers), or lambda/function
+        concat_axis: Integer, axis to use in mode `concat`.
-        node_indices: optional list of integers containing
+        node_indices: Optional list of integers containing
-        tensor_indices: optional list of indices of output tensors
+        tensor_indices: Optional list of indices of output tensors
-    '''TODO: dosctring
+    '''A Container is a directed acyclic graph of layers.
-
+        supports_masking (boolean)
-        # handle name argument
+        # Handle name argument.
-        # whether container weights are trainable
+        # Whether container weights are trainable.
-        # Container-specific properties
+        # Container-specific properties.
-            self.inputs = list(input)  # tensor or list of tensors
+            self.inputs = list(input)  # Tensor or list of tensors.
-        # check for redundancy in inputs:
+        # Check for redundancy in inputs.
-        # list of initial layers (1 to 1 mapping with self.inputs,
+        # List of initial layers (1 to 1 mapping with self.inputs,
-        # arguments validation
+        # Arguments validation.
-            # check that x is a Keras tensor
+            # Check that x is a Keras tensor.
-            # check that x is an input tensor
+            # Check that x is an input tensor.
-        # build self.output_layers:
+        # Build self.output_layers:
-        # fill in the output mask cache
+        # Fill in the output mask cache.
-        # build self.input_layers:
+        # Build self.input_layers:
-            # and one tensor output
+            # It's supposed to be an input layer, so only one node
-        # build self.input_names and self.output_names
+        # Build self.input_names and self.output_names.
-        # container_nodes: set of nodes included in the graph
+        # Container_nodes: set of nodes included in the graph
-        layer_indices = {}  # map {layer: index in traversal}
+        nodes_depths = {}  # dict {node: depth value}
-                seen_nodes: set of node ids ("{layer.name}_ib-{node_index}")
+                tensor: Some tensor in a graph.
-                layer: layer from which `tensor` comes from. If not provided,
+                depth: Current depth in the graph (0 = last output).
-                tensor_index: tensor_index from which `tensor` comes from.
+                node_index: Node index from which `tensor` comes from.
-            # prevent cycles
+            # Prevent cycles.
-            # update container_nodes
+            # Update container_nodes.
-            # update nodes_depths
+            # Update nodes_depths.
-            # update layers_depths
+            # Update layers_depths.
-            # propagate to all previous tensors connected to this node
+            # Propagate to all previous tensors connected to this node.
-        # build a map {depth: list of nodes with this depth}
+        # Build a dict {depth: list of nodes with this depth}
-        # build a map {depth: list of layers with this depth}
+        # Build a dict {depth: list of layers with this depth}
-        # get sorted list of layer depths
+        # Get sorted list of layer depths.
-        # set self.layers and self.layers_by_depth
+        # Set self.layers and self.layers_by_depth.
-            # here we order them by traversal order
+            # Container.layers needs to have a deterministic order:
-        # get sorted list of node depths
+        # Get sorted list of node depths.
-        # check that all tensors required are computable.
+        # Check that all tensors required are computable.
-        # that can be computed from the inputs provided
+        # that can be computed from the inputs provided.
-        layers_with_complete_input = []  # to provide a better error msg
+        layers_with_complete_input = []  # To provide a better error msg.
-        # set self.nodes and self.nodes_by_depth
+        # Set self.nodes and self.nodes_by_depth.
-        # ensure name unicity, which will be crucial for serialization
+        # Ensure name unicity, which will be crucial for serialization
-        # the new container starts with a single inbound node
+        # Layer parameters.
-        # create the node linking internal inputs to internal outputs
+        self.outbound_nodes = []  # Will be appended to by future calls to __call__
-             # no container-level masking for now
+             # No container-level masking for now.
-        # the following are implemented as property functions:
+        # The following are implemented as property functions:
-            index: integer, index of layer.
+            name: String, name of layer.
-        # it would be unreliable to build a dictionary
+        # It would be unreliable to build a dictionary
-        # without the container being notified of it
+        # without the container being notified of it.
-            mask: a mask or list of masks. A mask can be
+            input: A tensor or list of tensors.
-            # bad luck, have to run the graph manually
+            # Bad luck, we have to run the graph manually.
-                # it's an input layer: get_output_shape_for is identity,
+                # It's an input layer: get_output_shape_for is identity,
-            # iterate over nodes, by depth level
+            # Iterate over nodes, by depth level.
-                        # this is always a single layer, never a list
+                        # This is always a single layer, never a list.
-                            # a few lines above
+                            # We've already covered the input layers
-                        # same size of node.input_tensors
+                        # Potentially redundant list,
-            # read final output shapes from layers_to_output_shapes
+            # Read final output shapes from layers_to_output_shapes.
-            # store in cache
+            # Store in cache.
-            - can be run on non-Keras tensors.
+            - Expects `inputs` to be a list (potentially with 1 element).
-            masks: list of masks (tensors or None).
+            inputs: List of tensors
-        # dictionary mapping reference tensors to tuples (computed tensor, compute mask)
+        # Dictionary mapping reference tensors to tuples (computed tensor, compute mask)
-                # this is always a single layer, never a list
+                # This is always a single layer, never a list.
-                computed_data = []  # list of tuples (input, mask)
+                # If all previous input tensors are available in tensor_map,
-                    # update _keras_shape
+                    # Update _keras_shape.
-                    # update tensor_map
+                    # Update tensor_map.
-            # todo: better error msg
+            # TODO: Better error message.
-        # update cache; keys are based on ids on input tensors and inputs masks
+        # Update cache; keys are based on ids on input tensors and inputs masks.
-                # linking their input to output
+                # Containers start with a pre-existing node
-        for layer in self.layers:  # from the earliest layers on
+        for layer in self.layers:  # From the earliest layers on.
-                    # add to filtered_inbound_nodes
+                    # The node is relevant to the model:
-        # gather info about inputs and outputs
+        # Gather info about inputs and outputs.
-            # iterate over saved layers, instantiate them,
+            # Iterate over saved layers, instantiate them,
-            # instantiate layer
+            # Instantiate layer.
-            # gather layer inputs
+            # Gather layer inputs.
-                # and building the layer if needed
+                # Call layer on its inputs, thus creating the node
-            - the state of the optimizer, allowing to resume training
+            - The model architecture, allowing to re-instantiate the model.
-                    storing the weight value, named after the weight tensor
+                (ordered names of model layers).
-        # if file exists and should not be overwritten
+        # If file exists and should not be overwritten:
-            # support for legacy Sequential/Merge behavior
+            # Support for legacy Sequential/Merge behavior.
-        '''Load all layer weights from a HDF5 save file.
+        '''Loads all layer weights from a HDF5 save file.
-            # support for legacy Sequential/Merge behavior
+            # Support for legacy Sequential/Merge behavior.
-            # legacy format
+            # Legacy format.
-            # new file format
+            # New file format.
-            # we batch weight value assignments in a single backend call
+            # We batch weight value assignments in a single backend call
-                    # this is for backwards compatibility with
+                    # This is for backwards compatibility with
-                        # legacy shape: (self.nb_filter, input_dim, self.filter_length, 1)
+                        # Legacy shape: (self.nb_filter, input_dim, self.filter_length, 1)
-            # support for legacy Sequential/Merge behavior
+            # Support for legacy Sequential/Merge behavior.
-            # new file format
+            # New file format.
-            # we batch weight value assignments in a single backend call
+            # We batch weight value assignments in a single backend call
-                    # set values
+                    # Set values.
-        '''shared between different serialization methods'''
+        '''Shared between different serialization methods.'''
-            # if obj is any numpy type
+            # If obj is any numpy type
-            # if obj is a python 'type'
+            # If obj is a python 'type'
-            # support for legacy Sequential/Merge behavior
+            # Support for legacy Sequential/Merge behavior.
-        layer: origin layer of the tensor. Will be
+        tensor: The tensor to start from.
-        node_index: origin node index of the tensor.
+        node_index: Origin node index of the tensor.
-            # reached an Input layer, stop recursion
+            # Reached an Input layer, stop recursion.
-                # avoid input redundancy
+                # Avoid input redundancy.
-        assert type(lr) == float, 'The output of the "schedule" function should be float.'
+
-    '''Abstract base class for convolutionnal recurrent layers.
+    '''Abstract base class for convolutional recurrent layers.
-        # Same because must be stable in the ouptut space
+        # Same because must be stable in the output space
-generated movie which contain moving squares.
+""" This script demonstrates the use of a convolutional LSTM network.
-# (n_frames, width, height, channel) and that returns a movie
+# (n_frames, width, height, channels) and returns a movie
-# Generating artificial data:
+# Artificial data generation:
-# and at the end we select a 40x40 window
+# The squares are of shape 1x1 or 2x2 pixels,
-        # add from 3 to 7 moving squares
+        # Add 3 to 7 moving squares
-                # The idea is that if during predict time,
+                # The idea is that if during inference,
-                # consider it is a pixel belonging to a square.
+                # we need to train the network to be robust and still
-                # Shitf the ground truth by 1
+                # Shift the ground truth by 1
-    # Cut to a forty's sized window
+    # Cut to a 40x40 window
-                 border_mode='valid', sub_sample=(1, 1),
+                 border_mode='valid', subsample=(1, 1),
-        self.subsample = sub_sample
+        self.subsample = subsample
-    nb_samples = 5
+    nb_row = 3
-    input_nb_col = 10
+    input_nb_row = 5
-                    param_dset[:] = val
+        if isinstance(model.optimizer, optimizers.TFOptimizer):
-                  "momentum": self.momentum}
+        config = {'epsilon': self.epsilon,
-    classification problems
+    classification problems.
-    multiclass classification problems
+    multiclass classification problems.
-    sparse targets
+    sparse targets.
-    target class is within the top-k predictions provided
+    target class is within the top-k predictions provided.
-    between predicted and target values
+    between predicted and target values.
-    between predicted and target values
+    between predicted and target values.
-    between predicted and target values
+    between predicted and target values.
-    between predicted and target values
+    between predicted and target values.
-    `max(1 - y_true * y_pred, 0)`
+    `max(1 - y_true * y_pred, 0)`.
-    '''Calculates the squared value of the hinge loss
+    '''Calculates the squared value of the hinge loss.
-    and target values
+    and target values.
-    '''Computes the F score, the weighted harmonic mean of precision and recall.
+def precision(y_true, y_pred):
-    tagged with a set of labels. By only using accuracy (precision) a model
+def fbeta_score(y_true, y_pred, beta):
-    if c3 == 0:
+        
-    precision = c1 / c2
+    p = precision(y_true, y_pred)
-    return f_score
+def fmeasure(y_true, y_pred):
-    actual = K.eval(metrics.fbeta_score(y_true, y_pred))
+    actual = K.eval(metrics.fmeasure(y_true, y_pred))
-
+class TFOptimizer(Optimizer):
-                               shape=sparse_coo.shape)
+        v = tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)
-        x = tf.sparse_placeholder(dtype, shape=tf_shape, name=name)
+        x = tf.sparse_placeholder(dtype, name=name)
-        return int(x.shape.get_shape()[0])
+        return x._dims
-            self.targets.append(K.placeholder(ndim=len(shape), name=name + '_target'))
+            self.targets.append(K.placeholder(ndim=len(shape),
-epsilon_std = 0.01
+epsilon_std = 1.0
-epsilon_std = 0.01
+epsilon_std = 1.0
-                state = tf.concat(1, states)
+        states = tuple(initial_states)
-            if len(initial_states) == 0:
+            if len(states) == 0:
-                return output, new_state
+            mask_ta = tensor_array_ops.TensorArray(
-            state,
+            def _step(time, output_ta_t, *states):
-            new_states = []
+            swap_memory=True)
-        last_output = tf.squeeze(last_output, [0])
+        outputs = output_ta.pack()
-    '''Backwards compatible interface to tf.cond prior to public introduction.'''
+    '''Backwards compatible interface to tf.cond prior to public introduction.
-    '''Switches between two operations depending on a scalar value (int or bool).
+    '''Switches between two operations
-        return tf.select(x > 0, res, alpha*res)
+        return tf.select(x > 0, res, alpha * res)
-                                                 initial_states=[], input_length=input_length, unroll=unroll)
+
-    model.compile(loss='categorical_crossentropy', optimizer='adam')
+
-                            'input_shape must be provided (including batch size).')
+            raise Exception('If a RNN is stateful, it needs to know '
-from .recurrent_convolutional import *
+from .convolutional_recurrent import *
-    '''Abstract base class for recurrent layers.
+    '''Abstract base class for convolutionnal recurrent layers.
-    All recurrent layers (GRU, LSTM, SimpleRNN) also
+    ConvLSTM2D
-        5D tensor with shape `(nb_samples, timesteps, channels,rows,cols)`.
+        5D tensor with shape `(nb_samples, timesteps, channels, rows, cols)`.
-        - else, 2D tensor with shape `(nb_samples, channels,rows,cols)`.
+            `(nb_samples, timesteps, channels, rows, cols)`.
-    '''
+    '''Convolutional LSTM.
-                `(samples, time, nb_filter, o_row, o_col)`
+                `(samples, time, nb_filter, output_row, output_col)`
-                `(samples, time, o_row, o_col, nb_filter)`
+                `(samples, time, output_row, output_col, nb_filter)`
-                `(samples, nb_filter, o_row, o_col)`
+                `(samples, nb_filter, output_row, output_col)`
-                `(samples, o_row, o_col, nb_filter)`
+                `(samples, output_row, output_col, nb_filter)`
-from keras.layers import recurrent_convolutional
+from keras.layers import convolutional_recurrent
-    sequence_len = 10
+    input_channel = 2
-            output = layer_test(recurrent_convolutional.ConvLSTM2D,
+            output = layer_test(convolutional_recurrent.ConvLSTM2D,
-            layer = recurrent_convolutional.ConvLSTM2D(**kwargs)
+            layer = convolutional_recurrent.ConvLSTM2D(**kwargs)
-            layer = recurrent_convolutional.ConvLSTM2D(**kwargs)
+            layer = convolutional_recurrent.ConvLSTM2D(**kwargs)
-            layer_test(recurrent_convolutional.ConvLSTM2D,
+            layer_test(convolutional_recurrent.ConvLSTM2D,
-        top_indices = np.argpartition(pred, -top)[-top:][::-1]
+        top_indices = pred.argsort()[-top:][::-1]
-    values
+    '''Calculates the mean squared error (mse) rate
-    values
+    '''Calculates the mean absolute error (mae) rate
-    and target values
+    '''Calculates the mean absolute percentage error (mape) rate
-    and target values
+    '''Calculates the mean squared logarithmic error (msle) rate
-from .utils.generic_utils import get_from_module
+
-from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING, reset_uids
+from .common import _FLOATX, _EPSILON, image_dim_ordering, reset_uids
-        phase = tf.placeholder(dtype='bool', name='keras_learning_phase')
+        phase = tf.placeholder(dtype='bool',
-        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)
+        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),
-
+        return tf.SparseTensor(indices=indices,
-        tf_shape = tf.constant(np.array(list([0 for _ in range(len(shape))]), dtype=np.int64))
+        tf_shape = tf.constant(np.array(list([0 for _ in range(len(shape))]),
-    return variable(tf.constant_initializer(0., dtype=tf_dtype)(shape), dtype, name)
+    return variable(tf.constant_initializer(0., dtype=tf_dtype)(shape),
-    return variable(tf.constant_initializer(1., dtype=tf_dtype)(shape), dtype, name)
+    return variable(tf.constant_initializer(1., dtype=tf_dtype)(shape),
-def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):
+def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):
-def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1, left_pad=1, right_pad=1, dim_ordering=_IMAGE_DIM_ORDERING):
+def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,
-    with "top_pad", "bottom_pad", "left_pad", "right_pad"  (resp.) zeros rows on top, bottom; cols on left, right.
+    with "top_pad", "bottom_pad", "left_pad", "right_pad" (resp.) zeros
-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering=_IMAGE_DIM_ORDERING):
+def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):
-                indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)
+                indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),
-            "kwargs passed to function are ignored with Tensorflow backend"
+            'Expected no kwargs, you passed %s' % len(kwargs),
-           dim_ordering=_IMAGE_DIM_ORDERING,
+           dim_ordering='default',
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
-             dim_ordering=_IMAGE_DIM_ORDERING,
+             dim_ordering='default',
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
-                  dim_ordering=_IMAGE_DIM_ORDERING,
+                  dim_ordering='default',
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
-                     border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING):
+                     border_mode='valid', dim_ordering='default'):
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
-           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,
+           border_mode='valid', dim_ordering='default',
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
-           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,
+           border_mode='valid', dim_ordering='default',
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
-           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):
+           dim_ordering='default', pool_mode='max'):
-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))
-from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING
+from .common import _FLOATX, _EPSILON, image_dim_ordering
-    '''Return the shape of a tensor.
+    '''Returns the shape of a tensor.
-    '''Run a graph.
+    '''Returns the value of a tensor.
-    '''Instantiate an all-zeros variable.
+    '''Instantiates an all-zeros variable.
-    '''Instantiate an all-ones variable.
+    '''Instantiates an all-ones variable.
-    '''Instantiate an identity matrix.
+    '''Instantiates an identity matrix.
-    '''Return number of scalars in a tensor.
+    '''Returns the number of scalars in a tensor.
-    '''Compute mean and std for batch then apply batch_normalization on batch.
+    '''Computes mean and std for batch then apply batch_normalization on batch.
-def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):
+def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):
-def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1, left_pad=1, right_pad=1, dim_ordering=_IMAGE_DIM_ORDERING):
+def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,
-    with "top_pad", "bottom_pad", "left_pad", "right_pad"  (resp.) zeros rows on top, bottom; cols on left, right.
+    with "top_pad", "bottom_pad", "left_pad", "right_pad" (resp.) zeros
-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering=_IMAGE_DIM_ORDERING):
+def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):
-    '''Says whether the `targets` are in the top `k` `predictions`
+    '''Returns whether the `targets` are in the top `k` `predictions`
-           dim_ordering=_IMAGE_DIM_ORDERING, image_shape=None,
+           dim_ordering='default', image_shape=None,
-             dim_ordering=_IMAGE_DIM_ORDERING,
+             dim_ordering='default',
-                  dim_ordering=_IMAGE_DIM_ORDERING,
+                  dim_ordering='default',
-                     border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING):
+                     border_mode='valid', dim_ordering='default'):
-           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,
+           border_mode='valid', dim_ordering='default',
-                       border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,
+                       border_mode='valid', dim_ordering='default',
-           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):
+           dim_ordering='default', pool_mode='max'):
-           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):
+           dim_ordering='default', pool_mode='max'):
-                       dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):
+                       dim_ordering='default', pool_mode='max'):
-    base = T.set_subtensor(zeros[:1], np.float32(1))
+
-        fn = ctc_step,
+        fn=ctc_step,
-        x = K.permute_dimensions(x, (0, 2, 1, 3))
+        x = K.expand_dims(x, 2)   # add dummy last dimension
-        return K.squeeze(output, 3)  # remove dummy last dimension
+                                        dim_ordering='tf')
-_LEARNING_PHASE = tf.placeholder(dtype='uint8', name='keras_learning_phase')  # 0 = test, 1 = train
+# This dictionary holds a mapping {graph: learning_phase}.
-    global _LEARNING_PHASE
+    global _GRAPH_LEARNING_PHASES
-    _LEARNING_PHASE = tf.placeholder(dtype='uint8', name='keras_learning_phase')
+    phase = tf.placeholder(dtype='bool', name='keras_learning_phase')
-    '''Whether variables should be initialized
+    '''Returns a boolean:
-    The learning phase flag is an integer tensor (0 = test, 1 = train)
+    The learning phase flag is a bool tensor (0 = test, 1 = train)
-    return _LEARNING_PHASE
+    graph = tf.get_default_graph()
-    global _LEARNING_PHASE
+    '''Sets the learning phase to a fixed value,
-    _LEARNING_PHASE = value
+    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = value
-    return _SESSION
+        session = tf.get_default_session()
-                      'with Keras via `K.set_session(sess)`.')
+def _initialize_variables():
-              lambda: then_expression, lambda: else_expression)
+    if condition.dtype != tf.bool:
-    if _LEARNING_PHASE is 1:
+    if learning_phase() is 1:
-    elif _LEARNING_PHASE is 0:
+    elif learning_phase() is 0:
-    x = _cond(tf.cast(_LEARNING_PHASE, 'bool'), lambda: x, lambda: alt)
+    # else: assume learning phase is a placeholder tensor.
-    if _LEARNING_PHASE is 1:
+    if learning_phase() is 1:
-    elif _LEARNING_PHASE is 0:
+    elif learning_phase() is 0:
-    x = _cond(tf.cast(_LEARNING_PHASE, 'bool'), lambda: alt, lambda: x)
+    # else: assume learning phase is a placeholder tensor.
-    """ Exponential linear unit
+    '''Exponential linear unit.
-    """
+    '''
-    '''Says whether the `targets` are in the top `k` `predictions`
+    '''Returns whether the `targets` are in the top `k` `predictions`
-        config = {'output_shape': self.output_shape}
+        config = {'output_shape': self.output_shape_}
-        border_mode: 'valid' or 'same'.
+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
-        if border_mode not in {'valid', 'same'}:
+        if border_mode not in {'valid', 'same', 'full'}:
-        border_mode: 'valid' or 'same'.
+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
-        if border_mode not in {'valid', 'same'}:
+        if border_mode not in {'valid', 'same', 'full'}:
-        border_mode: 'valid' or 'same'.
+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
-        if border_mode not in {'valid', 'same'}:
+        if border_mode not in {'valid', 'same', 'full'}:
-        border_mode: 'valid' or 'same'.
+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
-        if border_mode not in {'valid', 'same'}:
+        if border_mode not in {'valid', 'same', 'full'}:
-        border_mode: 'valid' or 'same'.
+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
-        if border_mode not in {'valid', 'same'}:
+        if border_mode not in {'valid', 'same', 'full'}:
-        border_mode: 'valid' or 'same'.
+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)
-        if border_mode not in {'valid', 'same'}:
+        if border_mode not in {'valid', 'same', 'full'}:
-    assert border_mode in {'same', 'valid'}
+    assert border_mode in {'same', 'valid', 'full'}
-    assert border_mode in {'same', 'valid'}
+    assert border_mode in {'same', 'valid', 'full'}
-    for border_mode in ['valid', 'same']:
+    for border_mode in _convolution_border_modes:
-    for border_mode in ['valid', 'same']:
+    for border_mode in _convolution_border_modes:
-    for border_mode in ['valid', 'same']:
+    for border_mode in _convolution_border_modes:
-    for border_mode in ['valid', 'same']:
+    for border_mode in _convolution_border_modes:
-    for border_mode in ['valid', 'same']:
+    for border_mode in _convolution_border_modes:
-    for border_mode in ['valid', 'same']:
+    for border_mode in _convolution_border_modes:
-    for border_mode in ['same', 'valid']:
+    for border_mode in _convolution_border_modes:
-__version__ = '1.1.0'
+__version__ = '1.1.1'
-      version='1.1.0',
+      version='1.1.1',
-      download_url='https://github.com/fchollet/keras/tarball/1.1.0',
+      download_url='https://github.com/fchollet/keras/tarball/1.1.1',
-import functools
+import six
-    @functools.wraps(func)
+    @six.wraps(func)
-
+    f = keras_test(f)
-                                                                        'spatial', epsilon)
+            axis = mean.broadcastable.index(False)
-from keras.layers.recurrent_convolutional import LSTMConv2D
+from keras.layers.recurrent_convolutional import ConvLSTM2D
-seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,
+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,
-seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,
+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,
-seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,
+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,
-seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,
+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,
-from .engine.topology import get_source_inputs, Node
+from .engine.topology import get_source_inputs, Node, Layer
-        'page': 'io_utils.md',
+        'page': 'utils/data_utils.md',
-    # positions: relative or absolute positions of log elements in each line
+    '''Prints a summary of a layer
-    to binary class matrix, for use with categorical_crossentropy.
+    '''Convert class vector (integers from 0 to nb_classes) to binary class matrix, for use with categorical_crossentropy.
-    def __init__(self, monitor='val_loss', patience=0, verbose=0, mode='auto'):
+    def __init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto'):
-        if self.monitor_op(current, self.best):
+        if self.monitor_op(current - self.min_delta, self.best):
-                This could be a tuple (x_val, y_val) or a tuple (val_x, val_y, val_sample_weights).
+                This could be a tuple (x_val, y_val) or a tuple (x_val, y_val, val_sample_weights).
-            validation_data: tuple (X, y) to be used as held-out
+            validation_data: tuple (x_val, y_val) or tuple
-            sigma = np.dot(flatX.T, flatX) / flatX.shape[1]
+            sigma = np.dot(flatX.T, flatX) / flatX.shape[0]
-    # first, populate the nodes of the graph
+    # Create graph nodes.
-            label = str(layer.name) + ' (' + layer.__class__.__name__ + ')'
+            label = '{}: {}'.format(layer_name, class_name)
-            label = layer.__class__.__name__
+            label = class_name
-    # second, add the edges
+    # Connect nodes with edges.
-class RecurrentConv2D(Layer):
+class ConvRecurrent2D(Layer):
-        super(RecurrentConv2D, self).__init__(**kwargs)
+        super(ConvRecurrent2D, self).__init__(**kwargs)
-        base_config = super(RecurrentConv2D, self).get_config()
+        base_config = super(ConvRecurrent2D, self).get_config()
-class LSTMConv2D(RecurrentConv2D):
+class ConvLSTM2D(ConvRecurrent2D):
-        super(LSTMConv2D, self).__init__(**kwargs)
+        super(ConvLSTM2D, self).__init__(**kwargs)
-        base_config = super(LSTMConv2D, self).get_config()
+        base_config = super(ConvLSTM2D, self).get_config()
-            output = layer_test(recurrent_convolutional.LSTMConv2D,
+            output = layer_test(recurrent_convolutional.ConvLSTM2D,
-            layer = recurrent_convolutional.LSTMConv2D(**kwargs)
+            layer = recurrent_convolutional.ConvLSTM2D(**kwargs)
-            layer = recurrent_convolutional.LSTMConv2D(**kwargs)
+            layer = recurrent_convolutional.ConvLSTM2D(**kwargs)
-            layer_test(recurrent_convolutional.LSTMConv2D,
+            layer_test(recurrent_convolutional.ConvLSTM2D,
-                      class_weight=None, max_q_size=10, nb_worker=1, pickle_safe=False, **kwargs):
+                      class_weight=None, max_q_size=10, nb_worker=1,
-    def evaluate_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False, **kwargs):
+    def evaluate_generator(self, generator, val_samples,
-    def predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):
+    def predict_generator(self, generator, val_samples,
-            summary_value.simple_value = value
+            summary_value.simple_value = value.item()
-        return tf.SparseTensor(indices=indices, values=value.data, shape=value.shape)
+        return tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)
-                value = (indices, value.data, value.shape)
+                value = (indices, sparse_coo.data, sparse_coo.shape)
-from keras.layers import Dense, Dropout, Activation, Flatten
+from keras.layers import Dense, Dropout, Activation
-from keras.layers import Convolution1D, MaxPooling1D
+from keras.layers import Convolution1D, GlobalMaxPooling1D
-model.add(Flatten())
+model.add(GlobalMaxPooling1D())
-    weights.sort(key=lambda x: x.name)
+    # TF variables have auto-generated the name, while Theano has auto-generated the auto_name variable. name in Theano is None
-                layers.append(layer)
+        if self.layers:
-                    new_state = output
+                    new_state = state
-                      max_q_size=10, **kwargs):
+                      max_q_size=10, nb_worker=1,
-                                                   max_q_size=max_q_size)
+                                                   max_q_size=max_q_size,
-                           verbose=1, max_q_size=10, **kwargs):
+                           verbose=1, max_q_size=10, nb_worker=1,
-                                                        max_q_size=max_q_size)
+                                                        max_q_size=max_q_size,
-from keras.models import Sequential, Graph
+from keras.models import Sequential
-from keras.models import Sequential, Graph
+from keras.models import Sequential
-from keras.models import Graph, Sequential
+from keras.models import Sequential
-from keras.models import Sequential, Graph
+from keras.models import Sequential
-        elif not isinstance(self.build_fn, types.FunctionType):
+        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):
-        elif not isinstance(self.build_fn, types.FunctionType):
+        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):
-    model2.add(Dense(32))
+    model2.add(Dense(32, input_dim=32))
-    model1.add(Dense(32))
+    model1.add(Dense(32, input_dim=32))
-is also different.
+the VGG16 and ResNet models (299x299 instead of 224x224), and that the input preprocessing function
-            layers at the top of the network.
+        include_top: whether to include the fully-connected
-    return q, _stop
+    return q, _stop, generator_threads
-                                                pickle_safe=pickle_safe)
+        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,
-                                                           max_q_size=max_q_size)
+                                                           max_q_size=max_q_size,
-                                                pickle_safe=pickle_safe)
+        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,
-                                                pickle_safe=pickle_safe)
+        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,
-
+    {
-
+    '''Calculates the hinge loss, which is defined as
-    '''Expects a binary class matrix instead of a vector of scalar classes.
+    '''Calculates the cross-entropy value for multiclass classification
-    If you get a shape error, add a length-1 dimension to labels.
+    '''Calculates the cross-entropy value for multiclass classification
-    ''' Matthews correlation coefficient
+    '''Calculates the Matthews correlation coefficient measure for quality
-    '''Compute F score, the weighted harmonic mean of precision and recall.
+    '''Computes the F score, the weighted harmonic mean of precision and recall.
-from keras.layers import LSTM, GRU, SimpleRNN
+from keras.layers import LSTM
-from tensorflow.python.ops import control_flow_ops
+
-                              lambda: else_expression)
+    x = _cond(tf.cast(condition, 'bool'),
-                              lambda: alt)
+    x = _cond(tf.cast(_LEARNING_PHASE, 'bool'), lambda: x, lambda: alt)
-                              lambda: x)
+    x = _cond(tf.cast(_LEARNING_PHASE, 'bool'), lambda: alt, lambda: x)
-from keras import backend as K
+                  'decay': float(K.get_value(self.decay)),
-    a /= 255
+    a = a.astype(np.float32) / 255
-time_steps = img_w / (pool_size_1 * pool_size_2)
+time_steps = img_w // (pool_size_1 * pool_size_2)
-                             downsample_width=img_w / (pool_size_1 * pool_size_2) - 2,
+                             downsample_width=img_w // (pool_size_1 * pool_size_2) - 2,
-conv_to_rnn_dims = ((img_h / (pool_size_1 * pool_size_2)) * conv_num_filters, img_w / (pool_size_1 * pool_size_2))
+conv_to_rnn_dims = ((img_h // (pool_size_1 * pool_size_2)) * conv_num_filters, img_w // (pool_size_1 * pool_size_2))
-            if dim_ordering == 'th':
+            if dim_ordering == 'th' or return_sequences:
-            config['batch_input_shape'] = self.input_shape
+            config['batch_input_shape'] = self.input_spec[0].shape
-            `(samples,time, rows, cols, channels)` if dim_ordering='tf'.
+            `(samples,time, channels, rows, cols)`
-            `(samples, time, o_row, o_col, nb_filter)` if dim_ordering='tf'.
+        - if `return_sequences`
-
+                Also called strides elsewhere.
-                (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)
+                [Jozefowicz et al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)
-        B_U = states[3]
+        B_U = states[2]
-        h_i = self.conv_step_hidden(h_tm1, self.U_i * B_U[0],
+        h_i = self.conv_step_hidden(h_tm1 * B_U[0], self.U_i,
-        h_f = self.conv_step_hidden(h_tm1, self.U_f * B_U[1],
+        h_f = self.conv_step_hidden(h_tm1 * B_U[1], self.U_f,
-        h_c = self.conv_step_hidden(h_tm1, self.U_c * B_U[2],
+        h_c = self.conv_step_hidden(h_tm1 * B_U[2], self.U_c,
-        h_o = self.conv_step_hidden(h_tm1, self.U_o * B_U[3],
+        h_o = self.conv_step_hidden(h_tm1 * B_U[3], self.U_o,
-            ones = K.concatenate([ones] * self.output_dim, 1)
+            ones = K.zeros_like(x)
-            ones = K.concatenate([ones] * input_dim, 1)
+            ones = K.zeros_like(x)
-    # First test for ouptput shape:
+
-            For symmetric padding: int
+        padding: int, or tuple of int (length 2), or dictionary.
-            For asymmetric padding: tuple of int (length 2)
+            - If tuple of int (length 2)
-            '{'left_pad': left_pad, 'right_pad': right_pad}'.
+            the padding dimension, in order '(left_pad, right_pad)'.
-                                 'Keys have to be in {"left_pad", "right_pad"}')
+                raise ValueError('Unexpected key found in `padding` dictionary. '
-            For symmetric padding tuple of int (length 2)
+        padding: tuple of int (length 2), or tuple of int (length 4), or dictionary.
-            For asymmetric padding tuple of int (length 4)
+            - If tuple of int (length 4):
-            '{'top_pad': top_pad, 'bottom_pad': bottom_pad, 'left_pad': left_pad, 'right_pad': right_pad}'
+            the 2 padding dimensions (rows and cols), in the order
-        try:
+        if isinstance(padding, dict):
-        except AttributeError:
+                raise ValueError('Unexpected key found in `padding` dictionary. '
-                raise TypeError('padding should be tuple of int of length 2 or 4, or dict')
+                raise TypeError('`padding` should be tuple of int '
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'
+        assert dim_ordering in {'tf', 'th'}, '`dim_ordering` must be in {"tf", "th"}.'
-    nb_steps = 11
+    nb_steps = 5
-    input_nb_col = 12
+    input_nb_row = 4
-    input_len_dim3 = 12
+    input_len_dim1 = 4
-    time_length = 10
+    time_length = 4
-        padding: int
+        padding: int or tuple of int (length 2) or dictionary
-        length = input_shape[1] + self.padding * 2 if input_shape[1] is not None else None
+        length = input_shape[1] + self.left_pad + self.right_pad if input_shape[1] is not None else None
-        return K.temporal_padding(x, padding=self.padding)
+        return K.asymmetric_temporal_padding(x, left_pad=self.left_pad, right_pad=self.right_pad)
-        padding: tuple of int (length 2)
+        padding: tuple of int (length 2) or tuple of int (length 4) or dictionary
-            the 2 padding dimensions (axis 3 and 4).
+            the 2 padding dimensions (rows and cols).
-        (samples, depth, first_axis_to_pad, second_axis_to_pad)
+        `(samples, channels, rows, cols)` if dim_ordering='th'
-        (samples, depth, first_padded_axis, second_padded_axis)
+        `(samples, channels, padded_rows, padded_cols)` if dim_ordering='th'
-    def __init__(self, padding=(1, 1), dim_ordering='default', **kwargs):
+    def __init__(self,
-        self.padding = tuple(padding)
+
-            height = input_shape[3] + 2 * self.padding[1] if input_shape[3] is not None else None
+            rows = input_shape[2] + self.top_pad + self.bottom_pad if input_shape[2] is not None else None
-                    height)
+                    rows,
-            height = input_shape[2] + 2 * self.padding[1] if input_shape[2] is not None else None
+            rows = input_shape[1] + self.top_pad + self.bottom_pad if input_shape[1] is not None else None
-                    height,
+                    rows,
-                                    dim_ordering=self.dim_ordering)
+        return K.asymmetric_spatial_2d_padding(x,
-    input = np.ones((nb_samples, input_nb_row, input_nb_col, stack_size))
+    if dim_ordering == 'tf':
-    assert_allclose(out[:, 2:-2, 2:-2, :], 1.)
+    if dim_ordering == 'tf':
-    x = x[:, :, ::-1]
+    # Remove zero-center by mean pixel
-    x = x[:, :, ::-1]
+    # Remove zero-center by mean pixel
-    x = x[:, :, ::-1]
+    # Remove zero-center by mean pixel
-        x = x[:, ::-1, :, :]
+        # 'RGB'->'BGR'
-        x = x[:, :, :, ::-1]
+def _preprocess_conv3d_input(x, dim_ordering):
-def _preprocess_image_shape(dim_ordering, image_shape):
+def _preprocess_conv2d_image_shape(dim_ordering, image_shape):
-def _preprocess_filter_shape(dim_ordering, filter_shape):
+def _preprocess_conv3d_volume_shape(dim_ordering, volume_shape):
-    filter_shape = _preprocess_filter_shape(dim_ordering, filter_shape)
+    image_shape = _preprocess_conv2d_image_shape(dim_ordering, image_shape)
-    filter_shape = _preprocess_filter_shape(dim_ordering, filter_shape)
+    filter_shape = _preprocess_conv2d_filter_shape(dim_ordering, filter_shape)
-           volume_shape=None, filter_shape=None):
+           volume_shape=None, filter_shape=None,
-        lr_t = self.lr / (1. - K.pow(self.beta_1, t))
+        lr_t = lr / (1. - K.pow(self.beta_1, t))
-from .recurrent_convolutional import *
+from .recurrent_convolutional import *
-    def __init__(self, weights=None,nb_row=None, nb_col=None, nb_filter=None,
+    def __init__(self, weights=None, nb_row=None, nb_col=None, nb_filter=None,
-            raise ValueError('dim_ordering must be in {tf,th}',dim_ordering)
+            raise ValueError('dim_ordering must be in {tf,th}', dim_ordering)
-    sequence_len  = 10
+    sequence_len = 10
-        for return_sequences in [True,False]:
+
-         
+                                kwargs={'dim_ordering': dim_ordering,
-                
+
-    def __init__(self, weights=None,
+    def __init__(self, weights=None,nb_row=None, nb_col=None, nb_filter=None,
-
+        self.initial_weights = weights
-        if K._BACKEND == 'tensorflow':
+        if K.backend() == 'tensorflow':
-                  'return_sequences': self.return_sequences,
+        config = {'return_sequences': self.return_sequences,
-                 dim_ordering=K.image_dim_ordering(),
+                 dim_ordering='default',
-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf,th}'
+        
-            out_row, out_col, out_filter = self.output_shape[2:]
+            out_row, out_col, out_filter = output_shape[2:]
-            out_row, out_col, out_filter = self.output_shape[1:]
+            out_row, out_col, out_filter = output_shape[1:]
-                  'nb_filter': self.nb_filter,
+        config = {'nb_filter': self.nb_filter,
-
+from keras.layers import recurrent_convolutional
-                layer_test(convolutional.MaxPooling2D,
+                layer_test(convolutional.AveragePooling2D,
-    Bi-gram : 0.9056 test accuracy after 5 epochs. 5s/epoch on GTX 1080 gpu.
+    Uni-gram: 0.8813 test accuracy after 5 epochs. 8s/epoch on i7 cpu.
-from keras.layers import Dense, Flatten
+from keras.layers import Dense
-from keras.layers import AveragePooling1D
+from keras.layers import GlobalAveragePooling1D
-# we add a AveragePooling1D, which will average the embeddings
+# we add a GlobalAveragePooling1D, which will average the embeddings
-model.add(Flatten())
+model.add(GlobalAveragePooling1D())
-                        self.metrics_tensors.append(metrics_module.binary_accuracy(y_true, y_pred))
+                        acc_fn = metrics_module.binary_accuracy
-                            metrics_module.sparse_categorical_accuracy(y_true, y_pred))
+                        acc_fn = metrics_module.sparse_categorical_accuracy
-                        self.metrics_names.append(self.output_layers[i].name + '_acc')
+                        acc_fn = metrics_module.categorical_accuracy
-                        self.metrics_names.append(self.output_layers[i].name + '_' + metric_fn.__name__)
+                    metric_result = metric_fn(y_true, y_pred)
-    model.compile(optimizer, loss, metrics=[mse],
+
-    assert len(out) == 5
+    out_len = 1 + 2 * 4  # total loss, per layer: loss + 3 metrics
-    assert len(out) == 5
+    assert len(out) == out_len
-            if self.cooldown_counter > 0:
+            if self.in_cooldown():
-            elif self.cooldown_counter <= 0:
+            elif not self.in_cooldown():
-                 input_dim=None, input_length=None, **kwargs):
+                 dim_ordering=None, **kwargs):
-            cols = input_shape[3+1]
+            rows = input_shape[3]
-            cols = input_shape[2+1]
+            rows = input_shape[2]
-
+        unroll = False
-                  "stateful": self.stateful}
+        config = {'name': self.__class__.__name__,
-            `(samples, time,nb_filter, o_row, o_col)` if dim_ordering='th'
+            `(samples, time, nb_filter, o_row, o_col)` if dim_ordering='th'
-                 border_mode="valid", sub_sample=(1, 1),
+                 inner_activation='hard_sigmoid',
-        assert dim_ordering in {'tf', "th"}, 'dim_ordering must be in {tf,"th}'
+        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf,th}'
-                  "first dimention")
+        if dim_ordering == 'th':
-        kwargs["dim_ordering"] = dim_ordering
+        kwargs['nb_filter'] = nb_filter
-            stack_size = input_shape[1+1]
+            stack_size = input_shape[2]
-            stack_size = input_shape[3+1]
+            stack_size = input_shape[4]
-    def conv_step(self, x, W, b=None, border_mode="valid"):
+    def conv_step(self, x, W, b=None, border_mode='valid'):
-    def conv_step_hidden(self, x, W, border_mode="valid"):
+    def conv_step_hidden(self, x, W, border_mode='valid'):
-                                    border_mode="same")
+                                    border_mode='same')
-                                    border_mode="same")
+                                    border_mode='same')
-                                    border_mode="same")
+                                    border_mode='same')
-                                    border_mode="same")
+                                    border_mode='same')
-                  "nb_filter": self.nb_filter,
+        config = {'name': self.__class__.__name__,
-                  "activation": self.activation.__name__,
+                  'init': self.init.__name__,
-                  "inner_activation": self.inner_activation.__name__}
+                  'inner_activation': self.inner_activation.__name__}
-    path = get_file(path, origin="https://s3.amazonaws.com/img-datasets/mnist.pkl.gz")
+def load_data(path='mnist.pkl.gz'):
-    if path.endswith(".gz"):
+    if path.endswith('.gz'):
-        data = cPickle.load(f, encoding="bytes")
+        data = cPickle.load(f, encoding='bytes')
-    '''
+    '''Loads the Reuters newswire classification dataset.
-def fbetascore(y_true, y_pred, beta=1):
+def fbeta_score(y_true, y_pred, beta=1):
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-    
+
-def test_fbetascore():
+def test_fbeta_score():
-    actual = K.eval(metrics.fbetascore(y_true, y_pred))
+    actual = K.eval(metrics.fbeta_score(y_true, y_pred))
-    actual = -0.14907119849998601
+    expected = -0.14907119849998601
-    calc = K.eval(metrics.matthews_correlation(y_true, y_pred))
+    actual = K.eval(metrics.matthews_correlation(y_true, y_pred))
-    assert actual - epsilon <= calc <= actual + epsilon
+    assert expected - epsilon <= actual <= expected + epsilon
-        return tf.expand_dims(tf.range(label_shape[1]), 0) < current_input
+        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(max_num_labels_tns, current_input)
-    init = tf.cast(tf.fill(max_num_labels_tns, 0), tf.bool)
+    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)
-        exec(src)
+        exec(src, globals())
-        print(dim_ordering)
+from tensorflow.python.ops import control_flow_ops
-                                        lambda: else_expression)
+    x = control_flow_ops.cond(tf.cast(condition, 'bool'),
-                                        lambda: alt)
+    x = control_flow_ops.cond(tf.cast(_LEARNING_PHASE, 'bool'),
-                                        lambda: x)
+    x = control_flow_ops.cond(tf.cast(_LEARNING_PHASE, 'bool'),
-            print("Warning, unlike convolution3D the time must be the " +\
+            print("Warning, unlike convolution3D the time must be the "
-        self.b_o = K.zeros((self.nb_filter,))
+        self.W_i = self.init(self.W_shape, name='{}_W_i'.format(self.name))
-    #seq.fit(input_a, gt, nb_epoch=1)
+    seq.fit(input_a, gt, nb_epoch=1)
-    #seq.fit(input_a, gt, nb_epoch=1)
+    # seq.fit(input_a, gt, nb_epoch=1)
-    #seq.fit(input_a, gt, nb_epoch=1)
+    # seq.fit(input_a, gt, nb_epoch=1)
-    #seq.fit(input_a, gt, nb_epoch=1)
+    # seq.fit(input_a, gt, nb_epoch=1)
-    pytest.main([__file__])
+    pytest.main([__file__])
-        #if self.input_dim:
+        # if self.input_dim:
-    def compute_mask(self, input,mask):
+    def compute_mask(self, input, mask):
-    def get_output_shape_for(self,input_shape):
+    def get_output_shape_for(self, input_shape):
-        
+
-       
+    def call(self, x, mask=None):
-       
+
-        
+
-            print "Warning, unlike convolution3D the time must be the first dimention"
+            print("Warning, unlike convolution3D the time must be the " +\
-        self.b_c = K.zeros((self.nb_filter))
+        self.b_c = K.zeros((self.nb_filter,))
- 
+
-            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(4)]
+            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones)
-            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones) for _ in range(4)]
+            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones)
-        
+        return constants
-        return dict(list(base_config.items()) + list(config.items()))
+        return dict(list(base_config.items()) + list(config.items()))
-        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.html)
+        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.pdf)
-    def __init__(self, datapath, dataset, start, end, normalizer=None):
+    def __init__(self, datapath, dataset, start=0, end=None, normalizer=None):
-        self.end = end
+        self.start = start
-                kernel_th = KTH.variable(convert_kernel(kernel_val))
+                kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='th'))
-                kernel_th = KTH.variable(convert_kernel(kernel_val))
+                kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='th'))
-                           'In short, $ pip install librosa\nor visit ' +
+        raise RuntimeError('Librosa is required to process audio files.\n' +
-        x = x[np.newaxis, :]
+        x = np.expand_dims(x, axis=0)
-        x = x[:, np.newaxis]
+        x = np.expand_dims(x, axis=3)
-    '''
+    '''Decode the output of a music tagger model.
-TF_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/raw/master/data/music_tagger_crnn_weights_tensorflow.h5'
+TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5'
-                                    TH_WEIGHTS_PATH,
+            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_tf_dim_ordering.h5',
-                                    TF_WEIGHTS_PATH,
+            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5',
-
+        if K.backend() == 'theano':
-def convert_kernel(kernel, dim_ordering='th'):
+def convert_kernel(kernel, dim_ordering='default'):
-    print('Total params: %s' % total_params)
+    def count_total_params(layers, layer_set=None):
-'''This script demonstrates how to build a variational autoencoder with Keras and deconvolution layers.
+'''This script demonstrates how to build a variational autoencoder
-from keras.layers import Convolution2D, Deconvolution2D, MaxPooling2D
+from keras.layers import Convolution2D, Deconvolution2D
-original_dim = (img_chns, img_rows, img_cols)
+if K.image_dim_ordering() == 'th':
-x = Input(batch_shape=(batch_size,) + original_dim)
+x = Input(batch_shape=(batch_size,) + original_img_size)
-decoder_reshape = Reshape((nb_filters, 14, 14))
+
-                                   (batch_size, nb_filters, 14, 14),
+                                   output_shape,
-                                   (batch_size, nb_filters, 14, 14),
+                                   output_shape,
-                                          (batch_size, nb_filters, 29, 29),
+                                          output_shape,
-decoder_mean_squash = Convolution2D(img_chns, 2, 2, border_mode='valid', activation='sigmoid')
+decoder_mean_squash = Convolution2D(img_chns, 2, 2,
-    # NOTE: binary_crossentropy expects a batch_size by dim for x and x_decoded_mean, so we MUST flatten these!
+    # NOTE: binary_crossentropy expects a batch_size by dim
-(x_train, y_train), (x_test, y_test) = mnist.load_data()
+(x_train, _), (x_test, y_test) = mnist.load_data()
-x_test = x_test.astype('float32')[:, None, :, :] / 255.
+x_train = x_train.astype('float32') / 255.
-print(x_train.shape)
+print('x_train.shape:', x_train.shape)
-
+K.set_image_dim_ordering('th') # this is a Theano oriented example
-    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.)
+    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,
-nb_filters = 32
+nb_filters = 64
-batch_size = 16
+batch_size = 100
-z_log_var = Dense(latent_dim)(h)
+conv_1 = Convolution2D(img_chns, 2, 2, border_mode='same', activation='relu')(x)
-
+decoder_hid = Dense(intermediate_dim, activation='relu')
-    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
+    xent_loss = img_rows * img_cols * objectives.binary_crossentropy(x, x_decoded_mean)
-vae = Model(x, x_decoded_mean)
+vae = Model(x, x_decoded_mean_squash)
-generator = Model(decoder_input, _x_decoded_mean)
+_hid_decoded = decoder_hid(decoder_input)
-        x_decoded = generator.predict(z_sample)
+        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)
-        # output_shape will be (None, 3, 14, 14)
+        # Note that you will have to change the output_shape depending on the backend used.
-        # output_shape will be (None, 3, 25, 25)
+
-            cols = input_shape[3]
+            rows = self.output_shape_[2]
-            cols = input_shape[2]
+            rows = self.output_shape_[1]
-    return [os.path.join(directory, f) for f in os.listdir(directory)
+    return [os.path.join(directory, f) for f in sorted(os.listdir(directory))
-            for fname in os.listdir(subpath):
+            for fname in sorted(os.listdir(subpath)):
-            for fname in os.listdir(subpath):
+            for fname in sorted(os.listdir(subpath)):
-    dot.write_png(to_file)
+    _, format = os.path.splitext(to_file)
-    def __init__(self, lr=0.01, rho=0.95, epsilon=1e-8, decay=0.,
+    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, decay=0.,
-    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, decay=0.,
+    def __init__(self, lr=0.01, rho=0.95, epsilon=1e-8, decay=0.,
-                               "You can set it at ~/.keras/keras.json")
+            raise RuntimeError('Please set `image_dim_ordering` to "th".'
-                       'http://librosa.github.io/librosa/ for details.')
+    if librosa_exists():
-from .audio_conv_utils import decode_predictions, load_preprocess_input
+from .audio_conv_utils import decode_predictions, preprocess_input
-TF_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/data/music_tagger_crnn_weights_tensorflow.h5'
+TH_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/raw/master/data/music_tagger_crnn_weights_theano.h5'
-        if K.image_dim_ordering == 'tf':
+        if K.image_dim_ordering() == 'tf':
-def decode_predictions(preds):
+def decode_predictions(preds, top=5):
-    assert len(preds.shape) == 2 and preds.shape[1] == 1000
+    if len(preds.shape) != 2 or preds.shape[1] != 1000:
-        results.append(CLASS_INDEX[str(i)])
+    for pred in preds:
-from collections import deque
+from collections import deque, OrderedDict, Iterable
-import pytest
+
-        model.add_input(name='X_vars', input_shape=(input_dim, ))
+        model.add_input(name='X_vars', input_shape=(input_dim,))
-    
+
-    
+
-    
+
-    
+
-    '''Cropping layer for 2D input (e.g. picture).
+    '''Cropping layer for 3D data (e.g. spatial or saptio-temporal).
-                                     'pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps')
+    _assert_has_capability(T.nnet, 'relu')
-        return pos + self.alpha * (K.exp(neg) - 1.)
+        return K.elu(x, self.alpha)
-_BACKEND = 'tensorflow'
+# Set theano as default backend for Windows users since tensorflow is not available for Windows yet.
-
+            input_length = input_shape[1]
-                                                 initial_states=[])
+                                                 initial_states=[], input_length=input_length, unroll=unroll)
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-            If you never set it, then it will be "th".
+            If you never set it, then it will be "tf".
-from scipy.misc import imread, imresize, imsave
+from keras.preprocessing.image import load_img, img_to_array
-from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D
+from keras.applications import vgg16
-                              'conv4_3': 0.01},
+    'bad_trip': {'features': {'block4_conv1': 0.05,
-                            'conv5_2': 0.02},
+    'dreamy': {'features': {'block5_conv1': 0.05,
-    img = img.transpose((2, 0, 1)).astype('float64')
+    img = load_img(image_path, target_size=(img_width, img_height))
-    x = x.transpose((1, 2, 0))
+    if K.image_dim_ordering() == 'th':
-f.close()
+if K.image_dim_ordering() == 'th':
-    b = K.square(x[:, :, :img_width-1, :img_height-1] - x[:, :, :img_width-1, 1:])
+    if K.image_dim_ordering() == 'th':
-    loss -= coeff * K.sum(K.square(x[:, :, 2: shape[2]-2, 2: shape[3]-2])) / np.prod(shape[1:])
+    if K.image_dim_ordering() == 'th':
-loss += settings['continuity'] * continuity_loss(dream) / (3 * img_width * img_height)
+loss += settings['continuity'] * continuity_loss(dream) / np.prod(img_size)
-loss += settings['dream_l2'] * K.sum(K.square(dream)) / (3 * img_width * img_height)
+loss += settings['dream_l2'] * K.sum(K.square(dream)) / np.prod(img_size)
-    x = x.reshape((1, 3, img_width, img_height))
+    x = x.reshape((1,) + img_size)
-    random_jitter = (settings['jitter'] * 2) * (np.random.random((3, img_width, img_height)) - 0.5)
+    random_jitter = (settings['jitter'] * 2) * (np.random.random(img_size) - 0.5)
-    x = x.reshape((3, img_width, img_height))
+    x = x.reshape(img_size)
-    img = deprocess_image(x)
+    img = deprocess_image(np.copy(x))
-except ImportError:
+except ImportError:
-    
+    fp = K.sum(y_neg * y_pred_pos)
-def _runner(layer_class):
+def rnn_test(f):
-    # check return_sequences
+    kf = keras_test(f)
-    # check dynamic behavior
+
-    # check dropout
+
-    # check implementation modes
+
-    # check statefulness
+
-    # check regularizers
+
-__version__ = '1.0.8'
+__version__ = '1.1.0'
-      version='1.0.8',
+      version='1.1.0',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.8',
+      download_url='https://github.com/fchollet/keras/tarball/1.1.0',
-        _step.output_size = int(_step(tf.unpack(inputs)[0], state)[0].get_shape()[-1])
+        # recover output size by calling _step on the first input
-        last_output = tf.slice(outputs, begin, size)
+        slice_begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))
-            raise Exception('Regularizers cannot be reused')
+            raise Exception('Regularizers cannot be reused. '
-        regularized_loss = loss + (main_eigenval ** 0.5) * self.k  # multiplied by the given regularization gain
+        main_eigenval = (K.dot(K.transpose(WWd), main_eigenvect) /
-            raise Exception('Regularizers cannot be reused')
+        if self.p is not None:
-        if not hasattr(self, 'p'):
+        if self.p is None:
-        if hasattr(self, 'layer'):
+        if self.layer is not None:
-        if not hasattr(self, 'layer'):
+        if self.layer is None:
-from .utils.generic_utils import get_from_module
+        self._collected_trainable_weights = collect_trainable_weights(self)
-            training_updates = self.optimizer.get_updates(trainable_weights, self.constraints, self.total_loss)
+            training_updates = self.optimizer.get_updates(self._collected_trainable_weights,
-            state = states[0]
+            # use dummy state, otherwise _dynamic_rnn_loop breaks
-        state_size = int(states[0].get_shape()[-1])
+            state_size = int(states[0].get_shape()[-1])
-                else:
+                elif nb_states == 1:
-                if len(new_states) == 1:
+                if len(new_states) > 1:
-                    new_state = tf.concat(1, new_states)
+                    # return dummy state, otherwise _dynamic_rnn_loop breaks
-        else:
+        elif nb_states == 1:
-                                                 unroll=True)
+                                                 initial_states=[])
-    ''' Bidirectional wrapper for RNNs
+    ''' Bidirectional wrapper for RNNs.
-        merge_mode: Mode by which outputs of the forward and backward RNNs will be combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the outputs will not be combined, they will be returned as a list.
+        merge_mode: Mode by which outputs of the
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+        model = Sequential()
-                if sorted(reduction_axes) == range(K.ndim(x))[:-1]:
+                if K.backend() == 'tensorflow' and sorted(reduction_axes) == range(K.ndim(x))[:-1]:
-    _test_optimizer(Adadelta(decay=1e-3))
+    _test_optimizer(Adadelta(), target=0.83)
-    class_table.close()
+        # properly attribute the current layer to
-                    if shape[:2] != (1, layer.filter_length) or shape[3] != layer.nb_filter:
+                    if shape[:2] != (layer.filter_length, 1) or shape[3] != layer.nb_filter:
-                        w = np.transpose(w, (3, 2, 1, 0))
+                        w = np.transpose(w, (2, 3, 1, 0))
-        self.W_shape = (1, self.filter_length, input_dim, self.nb_filter)
+        self.W_shape = (self.filter_length, 1, input_dim, self.nb_filter)
-        x = K.expand_dims(x, 1)  # add a dummy dimension
+        x = K.expand_dims(x, 2)  # add a dummy dimension
-        output = K.squeeze(output, 1)  # remove the dummy dimension
+        output = K.squeeze(output, 2)  # remove the dummy dimension
-        x = K.expand_dims(x, 1)  # add a dummy dimension
+        x = K.expand_dims(x, 2)  # add a dummy dimension
-        output = K.squeeze(output, 1)  # remove the dummy dimension
+        output = K.squeeze(output, 2)  # remove the dummy dimension
-        for subsample_length in [1]:
+        for subsample_length in [1, 2]:
-        self.W_shape = (self.nb_filter, input_dim, self.filter_length, 1)
+        self.W_shape = (1, self.filter_length, input_dim, self.nb_filter)
-        x = K.permute_dimensions(x, (0, 2, 1, 3))
+        x = K.expand_dims(x, 1)  # add a dummy dimension
-                          dim_ordering='th')
+                          dim_ordering='tf')
-        output = K.permute_dimensions(output, (0, 2, 1))
+            output += K.reshape(self.b, (1, 1, self.nb_filter))
-        x = K.permute_dimensions(x, (0, 2, 1, 3))
+        x = K.expand_dims(x, 1)  # add a dummy dimension
-                          dim_ordering='th',
+                          dim_ordering='tf',
-        output = K.permute_dimensions(output, (0, 2, 1))
+            output += K.reshape(self.b, (1, 1, self.nb_filter))
-                 dim_ordering=K.image_dim_ordering(),
+                 dim_ordering='default',
-
+        if dim_ordering == 'default':
-                               'output_shape': (nb_samples, rows, cols, nb_filter),
+                               'output_shape': (nb_samples, nb_filter, rows, cols),
-                       input_shape=(nb_samples, nb_row, nb_col, stack_size),
+                               'subsample': subsample,
-                               'output_shape': (nb_samples, rows, cols, nb_filter),
+                               'output_shape': (nb_samples, nb_filter, rows, cols),
-                       input_shape=(nb_samples, nb_row, nb_col, stack_size),
+                       input_shape=(nb_samples, stack_size, nb_row, nb_col),
-_BACKEND = 'theano'
+_BACKEND = 'tensorflow'
-_IMAGE_DIM_ORDERING = 'th'
+_IMAGE_DIM_ORDERING = 'tf'
-    import tensorflow.contrib.ctc as ctc
+    import tensorflow.contrib.ctc as ctc
-    from tensorflow.python.ops import ctc_ops as ctc
+    from tensorflow.python.ops import ctc_ops as ctc
-def spatial_2d_padding(x, padding=(1, 1), dim_ordering='th'):
+def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):
-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th'):
+def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering=_IMAGE_DIM_ORDERING):
-                                       sequence_length=input_length), 1)
+    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,
-        (decoded, log_prob) = ctc.ctc_greedy_decoder(
+        (decoded, log_prob) = ctc.ctc_greedy_decoder(
-        (decoded, log_prob) = ctc.ctc_beam_search_decoder(
+        (decoded, log_prob) = ctc.ctc_beam_search_decoder(
-def spatial_2d_padding(x, padding=(1, 1), dim_ordering='th'):
+def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):
-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th'):
+def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering=_IMAGE_DIM_ORDERING):
-           border_mode='valid', dim_ordering='th',
+           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,
-           dim_ordering='th', pool_mode='max'):
+           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):
-           dim_ordering='th', pool_mode='max'):
+           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):
-    input_shape = (3, 16, 16)
+    input_shape = (16, 16, 3)
-                ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf))
+                zth = KTH.eval(KTH.conv2d(xth, kernel_th, dim_ordering='th'))
-                ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf))
+                zth = KTH.eval(KTH.conv3d(xth, kernel_th, dim_ordering='th'))
-        check_single_tensor_operation('pool2d', (5, 3, 10, 12), pool_size=(2, 2),
+        check_single_tensor_operation('pool2d', (5, 10, 12, 3), pool_size=(2, 2),
-        check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 2),
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 2),
-        check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 3),
+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 3),
-        check_single_tensor_operation('pool3d', (5, 3, 10, 12, 5), pool_size=(2, 2, 2),
+        check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), pool_size=(2, 2, 2),
-        check_single_tensor_operation('pool3d', (5, 3, 9, 11, 5), pool_size=(2, 2, 2),
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 2, 2),
-        check_single_tensor_operation('pool3d', (5, 3, 9, 11, 5), pool_size=(2, 3, 2),
+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 3, 2),
-                       input_shape=(nb_samples, stack_size, nb_row, nb_col))
+                       input_shape=(nb_samples, nb_row, nb_col, stack_size))
-                       input_shape=(nb_samples, stack_size, nb_row, nb_col))
+                       input_shape=(nb_samples, nb_row, nb_col, stack_size))
-                               'output_shape': (nb_samples, nb_filter, rows, cols),
+                               'output_shape': (nb_samples, rows, cols, nb_filter),
-                       input_shape=(nb_samples, stack_size, nb_row, nb_col),
+                       input_shape=(nb_samples, nb_row, nb_col, stack_size),
-                               'output_shape': (nb_samples, nb_filter, rows, cols),
+                               'output_shape': (nb_samples, rows, cols, nb_filter),
-                       input_shape=(nb_samples, stack_size, nb_row, nb_col),
+                       input_shape=(nb_samples, nb_row, nb_col, stack_size),
-                           input_shape=(nb_samples, stack_size, nb_row, nb_col))
+                           input_shape=(nb_samples, nb_row, nb_col, stack_size))
-                           input_shape=(nb_samples, stack_size, nb_row, nb_col))
+                           input_shape=(nb_samples, nb_row, nb_col, stack_size))
-                           input_shape=(nb_samples, stack_size, nb_row, nb_col))
+                           input_shape=(nb_samples, nb_row, nb_col, stack_size))
-                           input_shape=(nb_samples, stack_size, nb_row, nb_col))
+                           input_shape=(nb_samples, nb_row, nb_col, stack_size))
-                   input_shape=(3, 4, 11, 12))
+                   input_shape=(3, 11, 12, 4))
-                           input_shape=(3, 4, 11, 12))
+                           input_shape=(3, 11, 12, 4))
-                                    input_len_dim1, input_len_dim2, input_len_dim3))
+                       input_shape=(nb_samples,
-                                    input_len_dim1, input_len_dim2, input_len_dim3))
+                       input_shape=(nb_samples,
-    input = np.ones((nb_samples, stack_size, input_nb_row, input_nb_col))
+    input = np.ones((nb_samples, input_nb_row, input_nb_col, stack_size))
-    assert_allclose(out[:, :, 2:-2, 2:-2], 1.)
+    assert_allclose(out[:, 2:-2, 2:-2, :], 1.)
-                     input_len_dim2, input_len_dim3))
+    input = np.ones((nb_samples,
-    assert_allclose(out[:, :, 2:-2, 2:-2, 2:-2], 1.)
+    assert_allclose(out[:, 2:-2, 2:-2, 2:-2, :], 1.)
-    model.add(wrappers.TimeDistributed(convolutional.Convolution2D(5, 2, 2, border_mode='same'), input_shape=(2, 3, 4, 4)))
+    model.add(wrappers.TimeDistributed(convolutional.Convolution2D(5, 2, 2, border_mode='same'), input_shape=(2, 4, 4, 3)))
-    model.train_on_batch(np.random.random((1, 2, 3, 4, 4)), np.random.random((1, 2, 5, 4, 4)))
+    model.train_on_batch(np.random.random((1, 2, 4, 4, 3)), np.random.random((1, 2, 4, 4, 5)))
-_BACKEND = 'tensorflow'
+_BACKEND = 'theano'
-_IMAGE_DIM_ORDERING = 'tf'
+_IMAGE_DIM_ORDERING = 'th'
-_BACKEND = 'theano'
+_BACKEND = 'tensorflow'
-_IMAGE_DIM_ORDERING = 'th'
+_IMAGE_DIM_ORDERING = 'tf'
-        mode: one of {auto, min, max}. In 'min' mode,
+        mode: one of {auto, min, max}. In `min` mode,
-            monitored has stopped decreasing; in 'max'
+            monitored has stopped decreasing; in `max`
-            monitored has stopped increasing.
+            monitored has stopped increasing; in `auto`
-        self.updates = [K.update_add(self.iterations, 1)]
+        self.updates = []
-    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-8, **kwargs):
+    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-8, decay=0.,
-            new_p = p - self.lr * g / (K.sqrt(new_a) + self.epsilon)
+            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)
-    def __init__(self, lr=0.01, epsilon=1e-8, **kwargs):
+    def __init__(self, lr=0.01, epsilon=1e-8, decay=0., **kwargs):
-            new_p = p - self.lr * g / (K.sqrt(new_a) + self.epsilon)
+            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)
-    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, **kwargs):
+    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, decay=0.,
-            new_p = p - self.lr * update
+            new_p = p - lr * update
-                 epsilon=1e-8, **kwargs):
+                 epsilon=1e-8, decay=0., **kwargs):
-        lr_t = self.lr * K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t))
+        lr_t = lr * K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t))
-                 epsilon=1e-8, **kwargs):
+                 epsilon=1e-8, decay=0., **kwargs):
-
+Results on IMDB datasets with uni and bi-gram embeddings:
-# set parameters:
+def create_ngram_set(input_list, ngram_value=2):
-embedding_dims = 20
+embedding_dims = 50
-total_variation_weight = 8.5e-5
+total_variation_weight = 50.
-    return K.sum(K.square(s - c))
+        nb_channels = K.shape(style_image)[-1]
-    return loss / (4. * nb_colors**2 * size**2)
+    return loss
-for i in range(100):
+for i in range(50):
-def placeholder(shape=None, ndim=None, dtype=_FLOATX, name=None):
+def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):
-    x = tf.placeholder(dtype, shape=shape, name=name)
+    if sparse:
-    return x.eval(session=get_session())
+    return to_dense(x).eval(session=get_session())
-    out = tf.matmul(x, y)
+    if is_sparse(x):
-            axis = axis % len(tensors[0].get_shape())
+        dims = ndim(tensors[0])
-    return tf.concat(axis, tensors)
+
-        feed_dict = dict(zip(names, inputs))
+        feed_dict = {}
-
+
-    return theano.shared(value=value, name=name, strict=False)
+    if hasattr(value, 'tocoo'):
-def placeholder(shape=None, ndim=None, dtype=_FLOATX, name=None):
+def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):
-    x = T.TensorType(dtype, broadcast)(name)
+    if sparse:
-    return x.eval()
+    return to_dense(x).eval()
-    return T.dot(x, y)
+    if is_sparse(x):
-    return T.concatenate(tensors, axis=axis)
+    if py_all([is_sparse(x) for x in tensors]):
-                 input_dtype=None, input_tensor=None, name=None):
+                 input_dtype=None, input_tensor=None, sparse=False, name=None):
-          name=None, dtype=K.floatx(),
+          name=None, dtype=K.floatx(), sparse=False,
-                      (len(ins[0]), len(val_ins[0])))
+                      (ins[0].shape[0], val_ins[0].shape[0]))
-        nb_train_sample = len(ins[0])
+        nb_train_sample = ins[0].shape[0]
-        nb_sample = len(ins[0])
+        nb_sample = ins[0].shape[0]
-        nb_sample = len(ins[0])
+        nb_sample = ins[0].shape[0]
-                    batch_size = len(x[0])
+                    batch_size = x[0].shape[0]
-                    batch_size = len(list(x.values())[0])
+                    batch_size = list(x.values())[0].shape[0]
-                    batch_size = len(x)
+                    batch_size = x.shape[0]
-                                                 initial_states=[])
+                                                 initial_states=[],
-        _step.output_size = state_size
+        _step.output_size = int(_step(tf.unpack(inputs)[0], state)[0].get_shape()[-1])
-    def __init__(self, log_dir='./logs', histogram_freq=0, write_graph=True):
+    def __init__(self, log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False):
-                    tf.histogram_summary('{}_b'.format(layer.name), layer.b)
+            for layer in self.model.layers:
-    features = K.batch_flatten(x)
+    if K.image_dim_ordering() == 'th':
-                        input_shape=(img_channels, img_rows, img_cols)))
+                        input_shape=X_train.shape[1:]))
-            raise TypeError('shuffle_mats_or_lists only supports numpy.array and list objects')
+            raise TypeError('shuffle_mats_or_lists only supports '
-                 img_h, downsample_width, val_split,
+    def __init__(self, monogram_file, bigram_file, minibatch_size,
-        X_data = np.ones([size, 1, self.img_h, self.img_w])
+        if K.image_dim_ordering() == 'th':
-                X_data[i, 0, :, :] = paint_text('', self.img_w, self.img_h)
+                if K.image_dim_ordering() == 'th':
-                X_data[i, 0, :, :] = paint_text(self.X_text[index + i], self.img_w, self.img_h)
+                if K.image_dim_ordering() == 'th':
-    def __init__(self, test_func, text_img_gen, num_display_words = 6):
+    def __init__(self, test_func, text_img_gen, num_display_words=6):
-            pylab.imshow(word_batch['the_input'][i, 0, :, :], cmap='Greys_r')
+            if K.image_dim_ordering() == 'th':
-input_data = Input(name='the_input', shape=(1, img_h, img_w), dtype='float32')
+input_data = Input(name='the_input', shape=input_shape, dtype='float32')
-# to train using `fit_generator` (see Keras docs).
+from keras import backend as K
-nb_pool = 2
+pool_size = (2, 2)
-X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
+if K.image_dim_ordering() == 'th':
-                        input_shape=(1, img_rows, img_cols)))
+                        input_shape=input_shape))
-model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
+model.add(MaxPooling2D(pool_size=pool_size))
-
+from keras import backend as K
-nb_pool = 2
+pool_size = 2
-nb_conv = 3
+kernel_size = 3
-    X_test = test[0].reshape(test[0].shape[0], 1, img_rows, img_cols)
+    X_train = train[0].reshape((train[0].shape[0],) + input_shape)
-    Convolution2D(nb_filters, nb_conv, nb_conv,
+    Convolution2D(nb_filters, kernel_size, kernel_size,
-                  input_shape=(1, img_rows, img_cols)),
+                  input_shape=input_shape),
-    Convolution2D(nb_filters, nb_conv, nb_conv),
+    Convolution2D(nb_filters, kernel_size, kernel_size),
-    MaxPooling2D(pool_size=(nb_pool, nb_pool)),
+    MaxPooling2D(pool_size=(pool_size, pool_size)),
-    model.add(l)
+model = Sequential(feature_layers + classification_layers)
-        y_train[(i-1)*10000:i*10000] = labels
+        X_train[(i - 1) * 10000: i * 10000, :, :, :] = data
-
+    if K.image_dim_ordering() == 'tf':
-    
+
-                                '%s != %s. ' % (shape1[dot_axes[0]], shape2[dot_axes[1]]) +
+                                '%s != %s. ' % (shape1[self.dot_axes[0]], shape2[self.dot_axes[1]]) +
-    def load_weights(self, filepath):
+    def load_weights(self, filepath, by_name=False):
-        self.load_weights_from_hdf5_group(f)
+        if by_name:
-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'
+    _, fname = tempfile.mkstemp('.h5')
-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'
+    _, fname = tempfile.mkstemp('.h5')
-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'
+    _, fname = tempfile.mkstemp('.h5')
-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'
+    _, fname = tempfile.mkstemp('.h5')
-    fname = 'tmp_' + str(np.random.randint(10000)) + '.h5'
+    _, fname = tempfile.mkstemp('.h5')
-assert img_height == img_width, 'Due to the use of the Gram matrix, width and height must match.'
+img_nrows = 400
-    img = load_img(image_path, target_size=(img_width, img_height))
+    img = load_img(image_path, target_size=(img_nrows, img_ncols))
-        x = x.reshape((3, img_width, img_height))
+        x = x.reshape((3, img_nrows, img_ncols))
-        x = x.reshape((img_width, img_height, 3))
+        x = x.reshape((img_nrows, img_ncols, 3))
-    combination_image = K.placeholder((1, 3, img_width, img_height))
+    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))
-    combination_image = K.placeholder((1, img_width, img_height, 3))
+    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))
-    size = img_width * img_height
+    size = img_nrows * img_ncols
-        b = K.square(x[:, :, :img_width-1, :img_height-1] - x[:, :, :img_width-1, 1:])
+        a = K.square(x[:, :, :img_nrows-1, :img_ncols-1] - x[:, :, 1:, :img_ncols-1])
-        b = K.square(x[:, :img_width-1, :img_height-1, :] - x[:, :img_width-1, 1:, :])
+        a = K.square(x[:, :img_nrows-1, :img_ncols-1, :] - x[:, 1:, :img_ncols-1, :])
-        x = x.reshape((1, 3, img_width, img_height))
+        x = x.reshape((1, 3, img_nrows, img_ncols))
-        x = x.reshape((1, img_width, img_height, 3))
+        x = x.reshape((1, img_nrows, img_ncols, 3))
-    x = np.random.uniform(0, 255, (1, 3, img_width, img_height)) - 128.
+    x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.
-    x = np.random.uniform(0, 255, (1, img_width, img_height, 3)) - 128.
+    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.
-from .. import initializations
+from .. import initializations, regularizers
-                 weights=None, beta_init='zero', gamma_init='one', **kwargs):
+                 weights=None, beta_init='zero', gamma_init='one',
-               kwargs={'mode': 1},
+               kwargs={'mode': 1,
-            nb_samples = input_shape[0] if input_shape else None
+            if type(input_shape) is list:
-                                                  sequence_length=input_length), 1)
+    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,
-               dict_seq_lens=None, dict_values=None):
+def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,
-        input_length: tensor (samples,1) containing the sequence length for
+        input_length: tensor (samples,) containing the sequence length for
-        greedy:  perform much faster best-path search if true.  This does
+        greedy: perform much faster best-path search if true.  This does
-        dict_values:  list of lists representing the dictionary.
+        beam_width: if greedy is false: a beam search decoder will be used
-            pulls out the argmax and collapses blank labels is still needed.
+        Tuple:
-    input_length = tf.to_int32(tf.squeeze(input_length))
+    input_length = tf.to_int32(input_length)
-        (decoded, log_prob) = tf.contrib.ctc.ctc_greedy_decoder(
+        (decoded, log_prob) = ctc.ctc_greedy_decoder(
-                dict_seq_lens=dict_seq_lens, dict_values=dict_values)
+        (decoded, log_prob) = ctc.ctc_beam_search_decoder(
-    if theano.config.device.startswith('cuda') or theano.config.device.startswith('gpu'):
+    ndim = x.ndim
-                mask = tf.reverse(mask, [True] + [False] * (ndim - 1))
+                mask = tf.reverse(mask, [True] + [False] * (ndim - 2))
-            img_input = Input(tensor=input_tensor)
+            img_input = Input(tensor=input_tensor, shape=input_shape)
-            img_input = Input(tensor=input_tensor)
+            img_input = Input(tensor=input_tensor, shape=input_shape)
-            img_input = Input(tensor=input_tensor)
+            img_input = Input(tensor=input_tensor, shape=input_shape)
-            img_input = Input(tensor=input_tensor)
+            img_input = Input(tensor=input_tensor, shape=input_shape)
-                except:
+            # attempt automatic input shape inference
-import marshal
+from ..utils.generic_utils import func_dump, func_load
-                mode = marshal.dumps(self.mode.func_code).decode('raw_unicode_escape')
+            mode = func_dump(self.mode)
-                output_shape = marshal.dumps(self._output_shape.func_code).decode('raw_unicode_escape')
+            output_shape = func_dump(self._output_shape)
-            mode = python_types.FunctionType(mode, globals())
+            mode = func_load(config['mode'], globs=globals())
-            output_shape = python_types.FunctionType(output_shape, globals())
+            output_shape = func_load(config['output_shape'], globs=globals())
-import sys
+from ..utils.generic_utils import func_dump, func_load
-                function = marshal.dumps(self.function.func_code).decode('raw_unicode_escape')
+            function = func_dump(self.function)
-                output_shape = marshal.dumps(self._output_shape.func_code).decode('raw_unicode_escape')
+            output_shape = func_dump(self._output_shape)
-            function = python_types.FunctionType(function, globals())
+            function = func_load(config['function'], globs=globals())
-            output_shape = python_types.FunctionType(output_shape, globals())
+            output_shape = func_load(config['output_shape'], globs=globals())
-    x = K.reshape(x, K.pack([-1, timesteps, output_dim]))
+        x = K.reshape(x, K.pack([-1, timesteps, output_dim]))
-                    tf.histogram_summary('{}_W'.format(layer), layer.W)
+                    tf.histogram_summary('{}_W'.format(layer.name), layer.W)
-                    tf.histogram_summary('{}_b'.format(layer), layer.b)
+                    tf.histogram_summary('{}_b'.format(layer.name), layer.b)
-                    tf.histogram_summary('{}_out'.format(layer),
+                    tf.histogram_summary('{}_out'.format(layer.name),
-                if key in cons:
+                if key in cons and cons[key] != value:
-    return x.get_value().shape
+    return x.get_value(borrow=True, return_internal_type=True).shape
-    path = get_file('babi-tasks-v1-2.tar.gz', origin='http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz')
+    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')
-    path = get_file('babi-tasks-v1-2.tar.gz', origin='http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz')
+    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')
-            # Make a list of masks while making sure the dimensionality of each mask 
+            # Make a list of masks while making sure the dimensionality of each mask
-        output = K.deconv2d(x, self.W, self.output_shape_, 
+        output = K.deconv2d(x, self.W, self.output_shape_,
-                     :, 
+            return x[:,
-                     self.cropping[0][0]:input_shape[1]-self.cropping[0][1], 
+            return x[:,
-                     self.cropping[1][0]:input_shape[3]-self.cropping[1][1], 
+            return x[:,
-                     self.cropping[2][0]:input_shape[3]-self.cropping[2][1], 
+            return x[:,
-            If a tuple, it only specifies the first dimension onward; 
+            If a tuple, it only specifies the first dimension onward;
-                 the input shape: `output_shape = f(input_shape)`
+            If a function, it specifies the entire shape as a function of the
-                    labels.append([0,1])
+                    labels.append([0, 1])
-            labels += [[1,0]]*nb_negative_samples
+            labels += [[1, 0]]*nb_negative_samples
-        seed = random.randint(0,10e6)
+        seed = random.randint(0, 10e6)
-        print('Downloading data from',  origin)
+        print('Downloading data from', origin)
-    assert_allclose(a, np.asarray([0.00315225,  0.00315225,  0.00547597]),
+    assert_allclose(a, np.asarray([0.00315225, 0.00315225, 0.00547597]),
-    f = K.function([x],  [activations.softplus(x)])
+    f = K.function([x], [activations.softplus(x)])
-    f = K.function([x],  [activations.softsign(x)])
+    f = K.function([x], [activations.softsign(x)])
-    f = K.function([x],  [activations.sigmoid(x)])
+    f = K.function([x], [activations.sigmoid(x)])
-    f = K.function([x],  [activations.hard_sigmoid(x)])
+    f = K.function([x], [activations.hard_sigmoid(x)])
-            Takes one argument: the output of previous layer
+            Takes input tensor as first argument.
-    return tf.gradients(loss, variables)
+    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)
-            convolutional.AveragePooling3D,
+            pooling.MaxPooling1D,
-from keras.layers import convolutional
+from keras.layers import convolutional, pooling
-    input_len_dim2 = 20
+    input_len_dim1 = 8
-    
+
-    # basic test        
+    # basic test
-                             cropping[0][0]:-cropping[0][1], 
+        expected_out = input[:,
-                             cropping[1][0]:-cropping[1][1], 
+        expected_out = input[:,
-    input_len_dim3 = 30
+    input_len_dim1 = 8
-    
+
-    # basic test        
+    # basic test
-                             cropping[1][0]:-cropping[1][1], 
+        expected_out = input[:,
-                             cropping[2][0]:-cropping[2][1], 
+        expected_out = input[:,
-        Arguments:
+        # Arguments
-
+from .vgg16 import VGG16
-def test_sequential_model_saving_3():
+def test_sequential_model_saving_2():
-model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.2))
+model.add(Embedding(max_features, 128, dropout=0.2))
-from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D
+from keras.applications import vgg16
-layer_name = 'conv5_1'
+# the name of the layer we want to visualize
-    x = x.transpose((1, 2, 0))
+    if K.image_dim_ordering() == 'th':
-f.close()
+# build the VGG16 network with ImageNet weights
-layer_dict = dict([(layer.name, layer) for layer in model.layers])
+layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])
-    loss = K.mean(layer_output[:, filter_index, :, :])
+    if K.image_dim_ordering() == 'th':
-    input_img_data = np.random.random((1, 3, img_width, img_height)) * 20 + 128.
+    if K.image_dim_ordering() == 'th':
-from scipy.misc import imread, imresize, imsave
+from keras.preprocessing.image import load_img, img_to_array
-from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D
+from keras.applications import vgg16
-    img = img.transpose((2, 0, 1))
+    img = load_img(image_path, target_size=(img_width, img_height))
-    x = x.transpose((1, 2, 0))
+    if K.image_dim_ordering() == 'th':
-combination_image = K.placeholder((1, 3, img_width, img_height))
+if K.image_dim_ordering() == 'th':
-f.close()
+# the model will be loaded with pre-trained ImageNet weights
-    b = K.square(x[:, :, :img_width-1, :img_height-1] - x[:, :, :img_width-1, 1:])
+    if K.image_dim_ordering() == 'th':
-layer_features = outputs_dict['conv4_2']
+layer_features = outputs_dict['block4_conv2']
-feature_layers = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']
+feature_layers = ['block1_conv1', 'block2_conv1',
-    x = x.reshape((1, 3, img_width, img_height))
+    if K.image_dim_ordering() == 'th':
-x[0, 2, :, :] -= 123.68
+if K.image_dim_ordering() == 'th':
-    img = deprocess_image(x.copy().reshape((3, img_width, img_height)))
+    img = deprocess_image(x.copy())
-__version__ = '1.0.7'
+__version__ = '1.0.8'
-      version='1.0.7',
+      version='1.0.8',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.7',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.8',
-        return tuple([self.end - self.start, self.data.shape[1]])
+        return (self.end - self.start,) + self.data.shape[1:]
-            inputs = tf.reverse(inputs, [True, False, False])
+            inputs = tf.reverse(inputs, [True] + [False] * (ndim - 1))
-                mask = tf.reverse(mask, [True, False, False])
+                mask = tf.reverse(mask, [True] + [False] * (ndim - 1))
-        size = tf.pack([1, -1, -1])
+        begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))
-            convolutional.AtrousConv2D,
+            convolutional.AtrousConvolution2D,
-    # output_shape will be (None, 3, 25, 25)
+        # apply a 3x3 transposed convolution with stride 1x1 and 3 output filters on a 12x12 image:
-        
+
-        
+
-    first layer in a model, either provide the keyword argument `input_dim`
+    '''The `LocallyConnected1D` layer works similarly to
-    layer, since the weights can only be defined with determined output shape.
+    (tuple of integers, e.g. `input_shape=(10, 128)`
-    applied at each different patch of the input. When using this layer as the
+    '''The `LocallyConnected2D` layer works similarly
-    with determined output shape.
+    `input_shape=(3, 128, 128)` for 128x128 RGB pictures.
-        to set `unroll=True` for better performance.
+        You are likely to see better performance with RNNs in Theano compared
-        self.input_spec = [InputSpec(ndim=3)] # redundant due to build()?       
+        self.input_spec = [InputSpec(ndim=3)]
-        self.input_spec = [InputSpec(ndim=4)]        
+        self.input_spec = [InputSpec(ndim=4)]
-    
+
-        self.input_spec = [InputSpec(ndim=4)]        
+        self.input_spec = [InputSpec(ndim=5)]
-    return tf.transpose(stacked, (1, 0, 2))
+    x = tf.expand_dims(x, 1)
-    if not hasattr(n, 'shape') and not hasattr(n, '__len__'):
+    if not hasattr(n, 'shape') and not hasattr(n, '__len__') and not hasattr(n, '_shape'):
-                output: tensor with shape (samples, ...) (no time dimension),
+                output: tensor with shape (samples, output_dim) (no time dimension),
-        initial_states: tensor with shape (samples, ...) (no time dimension),
+                    as 'states'. The first state in the list must be the
-    assert ndim >= 3, "Input should be at least 3D."
+    assert ndim >= 3, 'Input should be at least 3D.'
-    input_list = tf.unpack(inputs)
+
-        input_list.reverse()
+    if unroll:
-        mask_list = tf.unpack(mask)
+        states = initial_states
-            mask_list.reverse()
+            input_list.reverse()
-            output, new_states = step_function(input, states + constants)
+    else:
-            tiled_mask_t = tf.tile(mask_t, tf.pack([1, tf.shape(output)[1]]))
+        if go_backwards:
-                prev_output = successive_outputs[-1]
+                output = tf.select(mask_t, output, states[0])
-            output = tf.select(tiled_mask_t, output, prev_output)
+                if len(new_states) == 1:
-                return_states.append(tf.select(tiled_mask_t, new_state, state))
+                return output, new_state
-    new_states = successive_states[-1]
+                if len(new_states) == 1:
-    x = K.reshape(x, (-1, timesteps, output_dim))
+    x = K.reshape(x, K.pack([-1, timesteps, output_dim]))
-
+    # Note on performance
-                                ': ' + str(input_shape))
+        # test default setup
-    assert shared_lstm.input_shape == (None, 4, 25)
+# @keras_test
-    
+
-        shapes = [x.shape for x in K.batch_get_value(params)]
+        shapes = [K.get_variable_shape(p) for p in params]
-        shapes = [x.shape for x in K.batch_get_value(params)]
+        shapes = [K.get_variable_shape(p) for p in params]
-        shapes = [x.shape for x in K.batch_get_value(params)]
+        shapes = [K.get_variable_shape(p) for p in params]
-        shapes = [x.shape for x in K.batch_get_value(params)]
+        shapes = [K.get_variable_shape(p) for p in params]
-        shapes = [x.shape for x in K.batch_get_value(params)]
+        shapes = [K.get_variable_shape(p) for p in params]
-        shapes = [x.shape for x in K.batch_get_value(params)]
+        shapes = [K.get_variable_shape(p) for p in params]
-        shapes = [x.shape for x in K.batch_get_value(params)]
+        shapes = [K.get_variable_shape(p) for p in params]
-                assert False, '{} is not a legal parameter'.format(params_name)
+                raise ValueError('{} is not a legal parameter'.format(params_name))
-            raise Exception('Invalid border mode for AtrousConv2D:', border_mode)
+            raise Exception('Invalid border mode for Deconvolution2D:', border_mode)
-    x = tf.reshape(x, [-1, prod(shape(x)[1:])])
+    x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))
-                progbar.update(count*block_size)
+                progbar.update(count * block_size)
-            ones = K.concatenate([ones] * self.output_dim, 1)
+            ones = K.tile(ones, (1, self.output_dim))
-            ones = K.concatenate([ones] * input_dim, 1)
+            ones = K.tile(ones, (1, input_dim))
-            ones = K.concatenate([ones] * self.output_dim, 1)
+            ones = K.tile(ones, (1, self.output_dim))
-            ones = K.concatenate([ones] * input_dim, 1)
+            ones = K.tile(ones, (1, input_dim))
-            ones = K.concatenate([ones] * self.output_dim, 1)
+            ones = K.tile(ones, (1, self.output_dim))
-            ones = K.concatenate([ones] * input_dim, 1)
+            ones = K.tile(ones, (1, input_dim))
-        return self._gather_list_attr('non_trainable_weights')
+        weights = self._gather_list_attr('non_trainable_weights')
-from keras.models import Model
+from keras.models import Model, Sequential
-                      activation=act, input_shape=(1, img_h, img_w), name='conv1')(input_data)
+                      activation=act, name='conv1')(input_data)
-        return self.model.predict(X, **kwargs)
+        return np.squeeze(self.model.predict(X, **kwargs))
-input_dim = 10
+input_dim = 5
-def build_fn_clf(hidden_dims=50):
+def build_fn_clf(hidden_dims):
-        return build_fn_clf(hidden_dims)
+def test_clasify_build_fn():
-        return build_fn_clf(hidden_dims)
+
-        return build_fn_reg(hidden_dims)
+def test_regression_build_fn():
-        return build_fn_reg(hidden_dims)
+    assert_regression_works(reg)
-    proba = classifier.predict_proba(X_test, batch_size=batch_size)
+def assert_regression_works(reg):
-            build_fn=fn, hidden_dims=50, batch_size=batch_size, nb_epoch=nb_epoch)
+    preds = reg.predict(X_test, batch_size=batch_size)
-    preds = regressor.predict(X_test, batch_size=batch_size)
+if __name__ == '__main__':
-    return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var) + epsilon,
+    return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var + epsilon),
-    return normed
+    if theano.config.device.startswith('cuda') or theano.config.device.startswith('gpu'):
-    def __init__(self, epsilon=1e-6, mode=0, axis=-1, momentum=0.99,
+    def __init__(self, epsilon=1e-5, mode=0, axis=-1, momentum=0.99,
-# build the model: 2 stacked LSTM
+# build the model: a single LSTM
-    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(0, label_shape[0]), 
+    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(0, label_shape[0]),
-    indices = tf.transpose(tf.reshape(tf.concat(0, [batch_ind, label_ind]), [2,-1]))
+    indices = tf.transpose(tf.reshape(tf.concat(0, [batch_ind, label_ind]), [2, -1]))
-                                                  sequence_length = input_length), 1)
+    return tf.expand_dims(tf.contrib.ctc.ctc_loss(inputs=y_pred,
-               dict_seq_lens = None, dict_values = None):
+
-       search.  
+       search.
-            sequence_length = input_length)
+            inputs=y_pred,
-                dict_seq_lens = dict_seq_lens, dict_values = dict_values)
+                inputs=y_pred,
-                dict_seq_lens = dict_seq_lens, dict_values = dict_values)
+                inputs=y_pred,
-    decoded_dense = [tf.sparse_to_dense(st.indices, st.shape, st.values, default_value = -1)
+    decoded_dense = [tf.sparse_to_dense(st.indices, st.shape, st.values, default_value=-1)
-nb_conv = 3
+kernel_size = (3, 3)
-model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
+model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],
-model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
+model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))
-    nb_sample = 1
+    nb_sample = 2
-        y = np.random.random((nb_sample, output_dim))
+        target_dim = 2 * output_dim if mode == 'concat' else output_dim
-        model.add(wrappers.Bidirectional(rnn(1),
+        model.add(wrappers.Bidirectional(rnn(output_dim),
-        model.add(wrappers.Bidirectional(rnn(1, return_sequences=True),
+        model.add(wrappers.Bidirectional(rnn(output_dim, return_sequences=True),
-        model.add(wrappers.Bidirectional(rnn(1), merge_mode=mode))
+        model.add(wrappers.Bidirectional(rnn(output_dim), merge_mode=mode))
-        output = wrappers.Bidirectional(rnn(1), merge_mode=mode)(input)
+        output = wrappers.Bidirectional(rnn(output_dim), merge_mode=mode)(input)
-        assert merge_mode in ['sum', 'mul', 'ave', 'concat', None], "Invalid merge mode. Merge mode should be one of {'sum', 'mul', 'ave', 'concat', None}"
+        if merge_mode not in ['sum', 'mul', 'ave', 'concat', None]:
-            self.backward_layer.initial_weights = weights[nw//2:]
+            self.forward_layer.initial_weights = weights[:nw // 2]
-        self.backward_layer.set_weights(weights[nw//2:])
+        self.forward_layer.set_weights(weights[:nw // 2])
-            model.fit(x, y, nb_epoch=1, batch_size=5)
+    rnn = recurrent.SimpleRNN
-from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge
+from keras.models import Sequential
-model = Model(input=sequence, output=output)
+model = Sequential()
-        self.constraints = {}  # dict {tensor: constraint instance}
+        if not hasattr(self, 'trainable_weights'):
-from keras.layers import core, convolutional
+from keras.layers import core, convolutional, recurrent
-                    dot_axes = [dot_axes % n1, dot_axes % n2]
+                    self.dot_axes = [dot_axes % n1, dot_axes % n2]
-            if type(dot_axes) not in [list, tuple]:
+                    self.dot_axes = [dot_axes, ] * 2
-            if len(dot_axes) != 2:
+            if len(self.dot_axes) != 2:
-            if type(dot_axes[0]) is not int or type(dot_axes[1]) is not int:
+            if type(self.dot_axes[0]) is not int or type(self.dot_axes[1]) is not int:
-            if shape1[dot_axes[0]] != shape2[dot_axes[1]]:
+            if shape1[self.dot_axes[0]] != shape2[self.dot_axes[1]]:
-                            continue
+                        lock.acquire()
-                this implementation relies on multiprocessing, you should not pass non
+                this implementation relies on multiprocessing, you should not pass
-                this implementation relies on multiprocessing, you should not pass non
+                this implementation relies on multiprocessing, you should not pass
-                this implementation relies on multiprocessing, you should not pass non
+                this implementation relies on multiprocessing, you should not pass
-                this implementation relies on multiprocessing, you should not pass non
+                this implementation relies on multiprocessing, you should not pass
-    f.write(json.dumps(_config, indent=4))
+if not os.path.exists(_config_path):
-import h5py
+        import h5py
-                idx = key+self.start
+                idx = key + self.start
-
+
-def dropout(x, level, seed=None):
+def dropout(x, level, noise_shape=None, seed=None):
-            that will be set to 0
+            that will be set to 0.
-    return tf.nn.dropout(x * 1., retain_prob, seed=seed)
+    return tf.nn.dropout(x * 1., retain_prob, noise_shape, seed=seed)
-def dropout(x, level, seed=None):
+def dropout(x, level, noise_shape=None, seed=None):
-    x *= rng.binomial(x.shape, p=retain_prob, dtype=x.dtype)
+
-            x = K.in_train_phase(K.dropout(x, level=self.p), x)
+            noise_shape = self._get_noise_shape(x)
-    model_concat.fit([rand(2,3), rand(2,3)], [rand(2,6)], nb_epoch=1)
+    model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], nb_epoch=1)
-                    if q.qsize() < max_q_size:
+                    if pickle_safe or q.qsize() < max_q_size:
-This is an example of using Hierarchical RNN (HRNN) to predict MNIST digits.
+"""This is an example of using Hierarchical RNN (HRNN) to classify MNIST digits.
-Usually, the first recurrent layer of an HRNN encodes a sentence(word vectors)
+HRNNs can learn across multiple levels of temporal hiearchy over a complex sequence.
-sentence vectors(encoded by the first layer) into a document vector. This
+such vectors (encoded by the first layer) into a document vector. This
-of bidirectional HRNN combind with fully connected layers.
+# References
-layer encodes then these 28 column vectors(28,128) to a image vector
+column of pixels of shape (28, 1) to a column vector of shape (128,). The second LSTM
-PS: Modified from mnist_irnn.py
+# Training parameters.
-# the data, shuffled and split between train and test sets
+# Embedding dimensions.
-# Reshape to 4D for Hierarchical RNN
+# Reshapes data to 4D for Hierarchical RNN.
-# convert class vectors to binary class matrices
+# Converts class vectors to binary class matrices.
-# 4D input
+# 4D input.
-encoded_pixels = TimeDistributed(LSTM(output_dim=pixel_hidden))(x)
+# Encodes a row of pixels using TimeDistributed Wrapper.
-encoded_columns = LSTM(col_hidden)(encoded_pixels)
+# Encodes columns of encoded rows.
-
+model = Model(input=x, output=prediction)
-print('Hierarchical RNN test accuracy:', scores[1])
+print('Test loss:', scores[0])
-from keras.layers import Dense, Activation, Flatten
+from keras.layers import Dense, Flatten
-model.add(Dense(1, activation = 'sigmoid'))
+model.add(Dense(1, activation='sigmoid'))
-                                         'squeeze', {'axis':2},
+        check_single_tensor_operation('squeeze', (4, 1, 1), axis=1)
-            shape = np.arange(2, 2+ndims)
+            shape = np.arange(2, 2 + ndims)
-        return (input_shape[0], self.length * input_shape[1], input_shape[2])
+        length = self.length * input_shape[1] if input_shape[1] is not None else None
-                    self.size[1] * input_shape[3])
+                    width,
-                    self.size[1] * input_shape[2],
+                    width,
-                    self.size[2] * input_shape[4])
+                    dim1,
-                    self.size[2] * input_shape[3],
+                    dim1,
-    return x
+    shape = list(x.shape)
-            layers_for_depth.sort(key=lambda x: x.name)
+            # container.layers needs to have a deterministic order:
-    assign_op = x.assign(assign_placeholder)
+    if hasattr(x, '_assign_placeholder'):
-            assign_ops.append(x.assign(assign_placeholder))
+            if hasattr(x, '_assign_placeholder'):
-    assert(history.history['val_loss'][-1] < 0.8)
+    assert(history.history['val_loss'][-1] < 1.)
-def random_uniform_variable(shape, low, high, dtype=_FLOATX, name=None):
+def random_uniform_variable(shape, low, high, dtype=_FLOATX,
-    value = tf.random_uniform_initializer(low, high, dtype=tf_dtype)(shape)
+    if seed is None:
-def random_normal_variable(shape, mean, scale, dtype=_FLOATX, name=None):
+def random_normal_variable(shape, mean, scale, dtype=_FLOATX,
-    value = tf.random_normal_initializer(mean, scale, dtype=tf_dtype)(shape)
+    if seed is None:
-    Output: (n + 1)D one hot representation of the input with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)
+    '''Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))
-    Output: (n + 1)D one hot representation of the input with shape (batch_size, dim1, dim2, ... dim(n-1), nb_classes)
+    '''Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))
-    assert(history.history['val_acc'][-1] >= 0.85)
+    assert(history.history['val_acc'][-1] >= 0.8)
-                                                         nb_test=200,
+                                                         nb_test=400,
-    assert(history.history['val_loss'][-1] < 0.75)
+    assert(history.history['val_loss'][-1] < 0.8)
-__version__ = '1.0.6'
+__version__ = '1.0.7'
-      version='1.0.6',
+      version='1.0.7',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.6',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.7',
-        stride: integer, or None. Stride value.
+        pool_length: size of the region to which max pooling is applied
-                f = open(fpath)
+                if sys.version_info < (3,):
-            http://www.cs.toronto.edu/~fritz/absps/momentum.pdf
+        - [Nadam report](http://cs229.stanford.edu/proj2015/054_report.pdf)
-            the validation loss will not be overwritten.
+            the quantity monitored will not be overwritten.
-            minization of the monitored. For `val_acc`,
+            minimization of the monitored quantity. For `val_acc`,
-        x /= np.max(x)
+        x_max = np.max(x)
-        dot_axes: integer or tuple of integers, axes to use in mode `dot`.
+        dot_axes: integer or tuple of integers, axes to use in mode `dot` or `cos`.
-        dot_axes: integer or tuple of integers, axes to use in mode `dot`.
+        dot_axes: integer or tuple of integers, axes to use in mode `dot` or `cos`.
-        params = self.trainable_weights + self.non_trainable_weights
+        params = self.weights
-        params = self.trainable_weights + self.non_trainable_weights
+        params = self.weights
-            symbolic_weights = layer.trainable_weights + layer.non_trainable_weights
+            symbolic_weights = layer.weights
-                weights = layer.trainable_weights + layer.non_trainable_weights
+                weights = layer.weights
-                symbolic_weights = layer.trainable_weights + layer.non_trainable_weights
+                symbolic_weights = layer.weights
-        config = {'alpha': self.alpha}
+        config = {'alpha': float(self.alpha)}
-                  'beta_init': self.beta_init}
+        config = {'alpha_init': float(self.alpha_init),
-        config = {'theta': self.theta}
+        config = {'theta': float(self.theta)}
-    mean, std = tf.nn.moments(x, reduction_axes,
+    mean, var = tf.nn.moments(x, reduction_axes,
-        normed = tf.nn.batch_normalization(x, mean, std,
+        normed = tf.nn.batch_normalization(x, mean, var,
-        broadcast_std = tf.reshape(std, target_shape)
+        broadcast_var = tf.reshape(var, target_shape)
-        normed = tf.nn.batch_normalization(x, broadcast_mean, broadcast_std,
+        normed = tf.nn.batch_normalization(x, broadcast_mean, broadcast_var,
-    return normed, mean, std
+    return normed, mean, var
-    '''Apply batch normalization on x given mean, std, beta and gamma:
+def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):
-    output = (x - mean) / (sqrt(std) + epsilon) * gamma + beta
+    output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta
-    return tf.nn.batch_normalization(x, mean, std, beta, gamma, epsilon)
+    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)
-    std = T.sqrt(x.var(reduction_axes) + epsilon)
+    var = x.var(reduction_axes)
-    broadcast_std = T.reshape(std, target_shape)
+    broadcast_var = T.reshape(var, target_shape)
-    normed = batch_normalization(x, broadcast_mean, broadcast_std,
+    normed = batch_normalization(x, broadcast_mean, broadcast_var,
-    return normed, mean, std
+    return normed, mean, var
-    '''Apply batch normalization on x given mean, std, beta and gamma.
+def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):
-                                           sqrt(std) + epsilon,
+                                           sqrt(var) + epsilon,
-    '''Apply batch normalization on x given mean, std, beta and gamma.
+    '''Apply batch normalization on x given mean, std, beta and gamma:
-    normed = T.nnet.bn.batch_normalization(x, gamma, beta, mean, std + epsilon,
+    normed = T.nnet.bn.batch_normalization(x, gamma, beta, mean,
-                              dim_ordering=dim_ordering, name=conv_name_base + '2b')(out)
+    out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',
-    print lines[np.argmax(resnet_model.predict(test_img1)[0])]
+    print('Result for test 1 is:')
-    print lines[np.argmax(resnet_model.predict(test_img2)[0])]
+    print('Result for test 2 is:')
-                    batch_size=batch_size, nb_epoch=3,
+                    batch_size=batch_size, nb_epoch=nb_epoch,
-                    batch_size=batch_size, nb_epoch=nb_epoch,
+                    batch_size=batch_size, nb_epoch=3,
-get_resne50 returns the deep residual network model (50 layers)
+get_resnet50() returns the deep residual network model (50 layers)
-"Deep Residual Learning for Image Recognition"
+'Deep Residual Learning for Image Recognition'
-http://pan.baidu.com/s/1pLanuTt ('tf' dim ordering, For China)
+http://pan.baidu.com/s/1o8pO2q2 ('th' dim ordering, for China)
-https://drive.google.com/open?id=0B4ChsjFJvew3NWN5THdxcTdSWmc ('tf' dim ordering, For other countries)
+https://drive.google.com/open?id=0B4ChsjFJvew3NVQ2U041Q0xHRHM ('th' dim ordering, for other countries)
-    params:
+    '''The identity_block is the block that has no conv layer at shortcut
-    """
+    '''
-        axis = 3
+        bn_axis = 3
-        axis = 1
+        bn_axis = 1
-    out = BatchNormalization(axis=axis, name=bn_name_base + '2a')(out)
+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(out)
-    out = BatchNormalization(axis=axis, name=bn_name_base + '2b')(out)
+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(out)
-    out = BatchNormalization(axis=axis, name=bn_name_base + '2c')(out)
+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(out)
-    params:
+    '''conv_block is the block that has a conv layer at shortcut
-    """
+    '''
-        axis = 3
+        bn_axis = 3
-        axis = 1
+        bn_axis = 1
-    out = BatchNormalization(axis=axis, name=bn_name_base + '2a')(out)
+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(out)
-    out = BatchNormalization(axis=axis, name=bn_name_base + '2b')(out)
+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(out)
-    out = BatchNormalization(axis=axis, name=bn_name_base + '2c')(out)
+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(out)
-    shortcut = BatchNormalization(axis=axis, name=bn_name_base + '1')(shortcut)
+    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)
-    """
+    '''This function returns a preprocessed image
-    # 'RGB'->'BGR'
+        img[0, :, :] -= mean[0]
-    this function returns the 50-layer residual network model
+    '''This function returns the 50-layer residual network model
-    """
+    '''
-        axis = 3
+        bn_axis = 3
-        axis = 1
+        bn_axis = 1
-    out = BatchNormalization(axis=axis, name='bn_conv1')(out)
+    out = BatchNormalization(axis=bn_axis, name='bn_conv1')(out)
-    class_table = open('synset_words', 'r')
+
-    print "result for test 1 is"
+
-    print "result for test 2 is"
+
-                                '`model.set_input(input_tensor, shape)`')
+        if hasattr(K, 'int_shape'):
-                            ' weights. Provided weights: ' + str(weights))
+                            ' weights. Provided weights: ' + str(weights)[:50] + '...')
-                 border_mode='valid', subsample=(1, 1), dim_ordering=K.image_dim_ordering(),
+                 border_mode='valid', subsample=(1, 1), dim_ordering='default',
-
+        if dim_ordering == 'default':
-                 atrous_rate=(1, 1), dim_ordering=K.image_dim_ordering(),
+                 atrous_rate=(1, 1), dim_ordering='default',
-                 depth_multiplier=1, dim_ordering=K.image_dim_ordering(),
+                 depth_multiplier=1, dim_ordering='default',
-                 border_mode='valid', subsample=(1, 1, 1), dim_ordering=K.image_dim_ordering(),
+                 border_mode='valid', subsample=(1, 1, 1), dim_ordering='default',
-    def __init__(self, size=(2, 2), dim_ordering=K.image_dim_ordering(), **kwargs):
+    def __init__(self, size=(2, 2), dim_ordering='default', **kwargs):
-    def __init__(self, size=(2, 2, 2), dim_ordering=K.image_dim_ordering(), **kwargs):
+    def __init__(self, size=(2, 2, 2), dim_ordering='default', **kwargs):
-    def __init__(self, padding=(1, 1), dim_ordering=K.image_dim_ordering(), **kwargs):
+    def __init__(self, padding=(1, 1), dim_ordering='default', **kwargs):
-    def __init__(self, padding=(1, 1, 1), dim_ordering=K.image_dim_ordering(), **kwargs):
+    def __init__(self, padding=(1, 1, 1), dim_ordering='default', **kwargs):
-            raise Exception('Invalid border mode for Convolution2D '
+            raise Exception('Invalid border mode for LocallyConnected1D '
-                 dim_ordering=K.image_dim_ordering(),
+                 dim_ordering='default',
-            raise Exception('Invalid border mode for Convolution2D '
+            raise Exception('Invalid border mode for LocallyConnected2D '
-                 dim_ordering=K.image_dim_ordering(), **kwargs):
+                 dim_ordering='default', **kwargs):
-                 dim_ordering=K.image_dim_ordering(), **kwargs):
+                 dim_ordering='default', **kwargs):
-                 dim_ordering=K.image_dim_ordering(), **kwargs):
+                 dim_ordering='default', **kwargs):
-                 dim_ordering=K.image_dim_ordering(), **kwargs):
+                 dim_ordering='default', **kwargs):
-                 dim_ordering=K.image_dim_ordering(), **kwargs):
+                 dim_ordering='default', **kwargs):
-                 dim_ordering=K.image_dim_ordering(), **kwargs):
+                 dim_ordering='default', **kwargs):
-            nb_param = len(layer.get_weights())
+            nb_param = len(layer.weights)
-def array_to_img(x, dim_ordering=K.image_dim_ordering(), scale=True):
+def array_to_img(x, dim_ordering='default', scale=True):
-def img_to_array(img, dim_ordering=K.image_dim_ordering()):
+def img_to_array(img, dim_ordering='default'):
-                 dim_ordering=K.image_dim_ordering()):
+                 dim_ordering='default'):
-                 dim_ordering=K.image_dim_ordering(),
+                 dim_ordering='default',
-                 dim_ordering=K.image_dim_ordering,
+                 dim_ordering='default',
-def get_file(fname, origin, untar=False, md5_hash=None):
+def get_file(fname, origin, untar=False,
-    datadir = os.path.join(datadir_base, 'datasets')
+    datadir = os.path.join(datadir_base, cache_subdir)
-    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
+    xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)
-                a `batch_input_shape=(...)` to the first layer in your model.
+                if sequential model:
-                                str(len(flattened_layers)) + '.')
+                                str(len(flattened_layers)) + ' layers.')
-        f.close()
+        if hasattr(f, 'close'):
-    os.remove(fname)
+    # test load_weights on model file
-Gets to 0.88 test accuracy after 2 epochs. 
+Gets to 0.89 test accuracy after 2 epochs.
-compared to simpler, much faster methods such as TF-IDF+LogReg.
+compared to simpler, much faster methods such as TF-IDF + LogReg.
-            if tf.__version__ >= '0.8.0':
+            if parse_version(tf.__version__) >= parse_version('0.8.0'):
-    img = img.transpose((2, 0, 1)).astype('float64')
+    img = img[:, :, ::-1].astype('float64')
-    img = deprocess_image(x.reshape((3, img_width, img_height)))
+    img = deprocess_image(x.copy().reshape((3, img_width, img_height)))
-    tf.assign(x, np.asarray(value)).op.run(session=get_session())
+    value = np.asarray(value)
-        get_session().run(ops)
+        assign_ops = []
-            concatenated = K.concatenate(expanded_dims, axis=self.concat_axis)
+            # Make a list of masks while making sure the dimensionality of each mask 
-    # two different types of merging
+    # three different types of merging
-                                                      test_split=0.2)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
-                                                      test_split=0.2)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
-                                                      test_split=0.2)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)
-              maxlen=None, test_split=0.2, seed=113,
+def load_data(path='imdb_full.pkl', nb_words=None, skip_top=0,
-    path = get_file(path, origin="https://s3.amazonaws.com/text-datasets/imdb.pkl")
+    Note that the 'out of vocabulary' character is only used for
-    if path.endswith(".gz"):
+    if path.endswith('.gz'):
-    X, labels = cPickle.load(f)
+    (x_train, labels_train), (x_test, labels_test) = cPickle.load(f)
-    np.random.shuffle(X)
+    np.random.shuffle(x_train)
-    np.random.shuffle(labels)
+    np.random.shuffle(labels_train)
-    y_train = np.array(labels[:int(len(X) * (1 - test_split))])
+    X_train = np.array(X[:len(x_train)])
-    y_test = np.array(labels[int(len(X) * (1 - test_split)):])
+    X_test = np.array(X[len(x_train):])
-def load_data(path="reuters.pkl", nb_words=None, skip_top=0,
+def load_data(path='reuters.pkl', nb_words=None, skip_top=0,
-    path = get_file(path, origin="https://s3.amazonaws.com/text-datasets/reuters.pkl")
+    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters.pkl')
-    path = get_file(path, origin="https://s3.amazonaws.com/text-datasets/reuters_word_index.pkl")
+def get_word_index(path='reuters_word_index.pkl'):
-        data = cPickle.load(f, encoding="latin1")
+        data = cPickle.load(f, encoding='latin1')
-def get_file(fname, origin, untar=False):
+def get_file(fname, origin, untar=False, md5_hash=None):
-    if not os.path.exists(fpath):
+    download = False
-    model.compile(loss='mse', optimizer='sgd', metrics=['acc'])
+    model.compile(loss='mse', optimizer='rmsprop', metrics=['acc'])
-    assert_allclose(out, out2)
+    assert_allclose(out, out2, atol=1e-05)
-    assert_allclose(out, out2)
+    assert_allclose(out, out2, atol=1e-05)
-    assert_allclose(out, out2)
+    assert_allclose(out, out2, atol=1e-05)
-    assert_allclose(out, out2)
+    assert_allclose(out, out2, atol=1e-05)
-    assert_allclose(out, out2)
+    assert_allclose(out, out2, atol=1e-05)
-    assert_allclose(out, out2)
+    assert_allclose(out, out2, atol=1e-05)
-
+    f.attrs['keras_version'] = str(keras_version).encode('utf8')
-
+                 save_best_only=False, save_weights_only=False,
-                    self.model.save_weights(filepath, overwrite=True)
+                    if self.save_weights_only:
-            self.model.save_weights(filepath, overwrite=True)
+            if self.save_weights_only:
-from keras import backend as K
+from .. import backend as K
-    def save_weights(self, filepath, overwrite=False):
+    def save(self, filepath, overwrite=True):
-            if overwrite == 'n':
+            proceed = ask_to_proceed_with_overwrite(filepath)
-            print('[TIP] Next time specify overwrite=True in save_weights!')
+        f = h5py.File(filepath, 'w')
-        f.close()
+                if not val.shape:
-                    weight_value_tuples += zip(symbolic_weights, weight_values)
+                weight_values = [g[weight_name] for weight_name in weight_names]
-            raise TypeError('Not JSON Serializable')
+            raise TypeError('Not JSON Serializable:', obj)
-        self.metrics = []
+        self.metrics_tensors = []
-                self.metrics.append(output_loss)
+                self.metrics_tensors.append(output_loss)
-                        self.metrics.append(metrics_module.binary_accuracy(y_true, y_pred))
+                        self.metrics_tensors.append(metrics_module.binary_accuracy(y_true, y_pred))
-                        self.metrics.append(
+                        self.metrics_tensors.append(
-                        self.metrics.append(metrics_module.categorical_accuracy(y_true, y_pred))
+                        self.metrics_tensors.append(metrics_module.categorical_accuracy(y_true, y_pred))
-                    self.metrics.append(metric_fn(y_true, y_pred))
+                    self.metrics_tensors.append(metric_fn(y_true, y_pred))
-                                             [self.total_loss] + self.metrics,
+                                             [self.total_loss] + self.metrics_tensors,
-                                            [self.total_loss] + self.metrics,
+                                            [self.total_loss] + self.metrics_tensors,
-    return p_hat - p + p * K.log(p / p_hat)
+def optimizer_from_config(config, custom_objects={}):
-        config = {'name': self.__class__.__name__}
+        config = {}
-def gen_cosine_amp(amp=100, period=25, x0=0, xn=50000, step=1, k=0.0001):
+def gen_cosine_amp(amp=100, period=1000, x0=0, xn=50000, step=1, k=0.0001):
-        cos[i, 0, 0] = amp * np.cos(idx / (2 * np.pi * period))
+        cos[i, 0, 0] = amp * np.cos(2 * np.pi * idx / period)
-    xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)
+    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
-z_log_std = Dense(latent_dim)(h)
+z_log_var = Dense(latent_dim)(h)
-    z_mean, z_log_std = args
+    z_mean, z_log_var = args
-    return z_mean + K.exp(z_log_std) * epsilon
+    return z_mean + K.exp(z_log_var) * epsilon
-z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_std])
+# so you could write `Lambda(sampling)([z_mean, z_log_var])`
-                               (batch_size, img_chns, img_rows, img_cols), border_mode='same')
+                               (batch_size, img_chns, img_rows, img_cols),
-    kl_loss = - 0.5 * K.mean(1 + z_log_std - K.square(z_mean) - K.exp(z_log_std), axis=-1)
+    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
-        z_sample = np.array([[xi, yi]]) * epsilon_std
+        z_sample = np.array([[xi, yi]])
-    return sh
+def _preprocess_deconv_output_shape(shape, dim_ordering):
-    kernel = tf.transpose(kernel, (0, 1, 3, 2))  # tranpose kernel chanels
+    kernel = tf.transpose(kernel, (0, 1, 3, 2))
-               input_data=None, expected_output=None, expected_output_dtype=None, fixed_batch_size=False):
+               input_data=None, expected_output=None,
-
+def _preprocess_conv2d_input(x, dim_ordering):
-                            filter_shape[0], filter_shape[1])
+    return kernel
-        np_kernel = kernel.eval()
+    return th_border_mode
-
+    if dim_ordering == 'tf':
-        conv_out = conv_out.dimshuffle((0, 2, 3, 1))
+    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel,
-    raise NotImplementedError
+    '''2D deconvolution (transposed convolution).
-from ..utils.np_utils import conv_output_length
+from ..utils.np_utils import conv_output_length, conv_input_length
-               input_data=None, expected_output=None, expected_output_dtype=None):
+               input_data=None, expected_output=None, expected_output_dtype=None, fixed_batch_size=False):
-    x = Input(shape=input_shape[1:], dtype=input_dtype)
+    if fixed_batch_size:
-from keras.layers import Input, Dense, merge
+from keras.layers import Input, Dense, Lambda
-nb_epoch = 100
+intermediate_dim = 256
-    return z_mean + K.exp(z_log_var/2) * epsilon
+    return z_mean + K.exp(z_log_var / 2) * epsilon
-z = merge([z_mean, z_log_var], mode=sampling, output_shape=(latent_dim,))
+z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])
-from keras.layers import Input, Dense, Lambda
+from keras.layers import Input, Dense, merge
-batch_size = 16
+batch_size = 100
-nb_epoch = 40
+intermediate_dim = 500
-z_log_std = Dense(latent_dim)(h)
+z_log_var = Dense(latent_dim)(h)
-    return z_mean + K.exp(z_log_std) * epsilon
+    z_mean, z_log_var = args
-z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_std])
+z = merge([z_mean, z_log_var], mode=sampling, output_shape=(latent_dim,))
-    kl_loss = - 0.5 * K.mean(1 + z_log_std - K.square(z_mean) - K.exp(z_log_std), axis=-1)
+    xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)
-        z_sample = np.array([[xi, yi]]) * epsilon_std
+        z_sample = np.array([[xi, yi]])
-embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))
+nb_words = min(MAX_NB_WORDS, len(word_index))
-embedding_layer = Embedding(len(word_index) + 1,
+embedding_layer = Embedding(nb_words + 1,
-@pytest.mark.skipif(K._BACKEND != 'theano', reason="Requires Theano backend")
+def greater(x, y):
-            if K.get_value(p).shape != w.shape:
+        weight_value_tuples = []
-                                str(K.get_value(p).shape) +
+                                str(pv.shape) +
-            K.set_value(p, w)
+            weight_value_tuples.append((p, w))
-        return weights
+        return K.batch_get_value(self.weights)
-        for p, g, m in zip(params, grads, self.weights):
+        shapes = [x.shape for x in K.batch_get_value(params)]
-        self.weights = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
+        shapes = [x.shape for x in K.batch_get_value(params)]
-        for p, g, a in zip(params, grads, self.weights):
+        for p, g, a in zip(params, grads, accumulators):
-        self.weights = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
+        shapes = [x.shape for x in K.batch_get_value(params)]
-        for p, g, a in zip(params, grads, self.weights):
+        for p, g, a in zip(params, grads, accumulators):
-        delta_accumulators = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
+        shapes = [x.shape for x in K.batch_get_value(params)]
-        self.weights = ms + vs
+        shapes = [x.shape for x in K.batch_get_value(params)]
-        ms = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
+        ms = [K.zeros(shape) for shape in shapes]
-        self.weights = ms + us
+        us = [K.zeros(shape) for shape in shapes]
-        vs = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
+        shapes = [x.shape for x in K.batch_get_value(params)]
-        self.weights = ms + vs
+        self.weights = [self.iterations] + ms + vs
-            regularized_loss += K.mean(K.abs(self.p)) * self.l1
+            regularized_loss += K.sum(self.l1 * K.abs(self.p))
-            regularized_loss += K.mean(K.square(self.p)) * self.l2
+            regularized_loss += K.sum(self.l2 * K.square(self.p))
-                regularized_loss += self.l1 * K.mean(K.abs(output))
+                regularized_loss += K.sum(self.l1 * K.abs(output))
-                regularized_loss += self.l2 * K.mean(K.square(output))
+                regularized_loss += K.sum(self.l2 * K.square(output))
-        domin_eigenvect = K.dot(WW, o)
+        main_eigenvect = K.dot(WW, o)
-            domin_eigenvect = K.dot(WW, domin_eigenvect)
+            main_eigenvect = K.dot(WW, main_eigenvect)
-        WWd = K.dot(WW, domin_eigenvect)
+        WWd = K.dot(WW, main_eigenvect)
-        regularized_loss = loss + (domin_eigenval ** 0.5) * self.k  # multiplied by the given regularization gain
+        main_eigenval = K.dot(K.transpose(WWd), main_eigenvect) / K.dot(K.transpose(main_eigenvect), main_eigenvect)
-        regularized_loss += K.sum(K.square(self.p)) * self.l2
+        regularized_loss = loss
-            regularized_loss += self.l2 * K.sum(K.mean(K.square(output), axis=0))
+            if self.l1:
-    
+
-    _LEARNING_PHASE = tf.constant(value, name='keras_learning_phase')
+    if value not in {0, 1}:
-        names = [v.name for v in self.inputs]
+        names = [getattr(v, 'name', None) for v in self.inputs]
-                                        on_unused_input='warn',
+                                        on_unused_input='ignore',
-            if self.uses_learning_phase:
+            if self.uses_learning_phase and type(K.learning_phase()) is not int:
-            if self.uses_learning_phase:
+            if self.uses_learning_phase and type(K.learning_phase()) is not int:
-            if self.uses_learning_phase:
+            if self.uses_learning_phase and type(K.learning_phase()) is not int:
-            if self.uses_learning_phase:
+            if self.uses_learning_phase and type(K.learning_phase()) is not int:
-            if self.uses_learning_phase:
+            if self.uses_learning_phase and type(K.learning_phase()) is not int:
-        if self.uses_learning_phase:
+        if self.uses_learning_phase and type(K.learning_phase()) is not int:
-        if self.uses_learning_phase:
+        if self.uses_learning_phase and type(K.learning_phase()) is not int:
-        if self.uses_learning_phase:
+        if self.uses_learning_phase and type(K.learning_phase()) is not int:
-        if self.uses_learning_phase:
+        if self.uses_learning_phase and type(K.learning_phase()) is not int:
-        if self.uses_learning_phase:
+        if self.uses_learning_phase and type(K.learning_phase()) is not int:
-        if self.uses_learning_phase:
+        if self.uses_learning_phase and type(K.learning_phase()) is not int:
-    return tf.python.training.moving_averages.assign_moving_average(
+    return moving_averages.assign_moving_average(
-    x = tf.python.framework.ops.convert_to_tensor(x)
+    x = tf.convert_to_tensor(x)
-    reset_default_graph()
+    tf.reset_default_graph()
-    shape = map(int, shape)
+    shape = tuple(map(int, shape))
-    shape = map(int, shape)
+    shape = tuple(map(int, shape))
-    shape = map(int, shape)
+    shape = tuple(map(int, shape))
-    shape = map(int, shape)
+    shape = tuple(map(int, shape))
-    pytest.main([__file__])
+    shape = map(int, shape)
-               kwargs={'output_dim': 4., 'input_dim': 10, 'input_length': 2},
+               kwargs={'output_dim': 4, 'input_dim': 10, 'input_length': 2},
-        img = img.resize(target_size)
+        img = img.resize((target_size[1], target_size[0]))
-                    dtype, name)
+    tf_dtype = _convert_string_dtype(dtype)
-                    dtype, name)
+    tf_dtype = _convert_string_dtype(dtype)
-        A tensor with shape equal to the concatenation of x's shape (less the dimension that was summed over) and y's shape (less the batch dimension and the dimension that was summed over). If the final rank is 1, we reshape it to (batch_size, 1).
+        A tensor with shape equal to the concatenation of x's shape
-       
+
-        Let x's shape be (100, 20) and y's shape be (100, 30, 20). If dot_axes is (1, 2), to find the output shape of resultant tensor, loop through each dimension in x's shape and y's shape:
+        Let x's shape be (100, 20) and y's shape be (100, 30, 20).
-        y.shape[0] : 100 : do not append to output shape, always ignore first dimension of y
+        x.shape[1] : 20 : do not append to output shape,
-        y.shape[2] : 20 : do not append to output shape, dimension 2 of y has been summed over. (dot_axes[1] = 2)
+        y.shape[2] : 20 : do not append to output shape,
-        A tensor with shape equal to the concatenation of x's shape (less the dimension that was summed over) and y's shape (less the batch dimension and the dimension that was summed over). If the final rank is 1, we reshape it to (batch_size, 1).
+        A tensor with shape equal to the concatenation of x's shape
-       
+
-        Let x's shape be (100, 20) and y's shape be (100, 30, 20). If dot_axes is (1, 2), to find the output shape of resultant tensor, loop through each dimension in x's shape and y's shape:
+        Let x's shape be (100, 20) and y's shape be (100, 30, 20).
-        y.shape[0] : 100 : do not append to output shape, always ignore first dimension of y
+        x.shape[1] : 20 : do not append to output shape,
-        y.shape[2] : 20 : do not append to output shape, dimension 2 of y has been summed over. (dot_axes[1] = 2)
+        y.shape[2] : 20 : do not append to output shape,
-                      name=name)
+    return K.random_uniform_variable(shape, -scale, scale, name=name)
-                      name=name)
+    return K.random_normal_variable(shape, 0.0, scale, name=name)
-    def __init__(self, epsilon=1e-6, mode=0, axis=-1, momentum=0.9,
+    def __init__(self, epsilon=1e-6, mode=0, axis=-1, momentum=0.99,
-                std_update = self.momentum * self.running_std + (1 - self.momentum) * std
+                x_normed, mean, std = K.normalize_batch_in_training(
-                                (self.running_std, std_update)]
+                x_normed, mean, std = K.normalize_batch_in_training(
-                                                             epsilon=self.epsilon)
+                    x_normed_running = K.batch_normalization(
-                                                             epsilon=self.epsilon)
+                    x_normed_running = K.batch_normalization(
-        self.updates = [(self.iterations, self.iterations + 1.)]
+        self.updates = [K.update_add(self.iterations, 1)]
-            self.updates.append((m, v))
+            self.updates.append(K.update(m, v))
-            self.updates.append((p, new_p))
+
-            self.updates.append((a, new_a))
+            self.updates.append(K.update(a, new_a))
-            self.updates.append((p, new_p))
+            self.updates.append(K.update(p, new_p))
-            self.updates.append((a, new_a))
+            self.updates.append(K.update(a, new_a))
-            self.updates.append((p, new_p))
+            self.updates.append(K.update(p, new_p))
-            self.updates.append((a, new_a))
+            self.updates.append(K.update(a, new_a))
-            self.updates.append((p, new_p))
+            self.updates.append(K.update(p, new_p))
-            self.updates.append((d_a, new_d_a))
+            self.updates.append(K.update(d_a, new_d_a))
-        self.updates = [(self.iterations, self.iterations + 1)]
+        self.updates = [K.update_add(self.iterations, 1)]
-            self.updates.append((v, v_t))
+            self.updates.append(K.update(m, m_t))
-            self.updates.append((p, new_p))
+            self.updates.append(K.update(p, new_p))
-        self.updates = [(self.iterations, self.iterations + 1)]
+        self.updates = [K.update_add(self.iterations, 1)]
-            self.updates.append((u, u_t))
+            self.updates.append(K.update(m, m_t))
-            self.updates.append((p, new_p))
+            self.updates.append(K.update(p, new_p))
-        self.updates = [(self.iterations, self.iterations + 1)]
+        self.updates = [K.update_add(self.iterations, 1)]
-            self.updates.append((v, v_t))
+            self.updates.append(K.update(m, m_t))
-            self.updates.append((p, new_p))
+            self.updates.append(K.update(p, new_p))
-        norm_m0 = normalization.BatchNormalization(mode=mode, input_shape=(10,))
+        norm_m0 = normalization.BatchNormalization(mode=mode, input_shape=(10,), momentum=0.8)
-        model.fit(X, X, nb_epoch=5, verbose=0)
+        model.fit(X, X, nb_epoch=4, verbose=0)
-    norm_m0 = normalization.BatchNormalization(mode=0, axis=1, input_shape=(3, 4, 4))
+    norm_m0 = normalization.BatchNormalization(mode=0, axis=1, input_shape=(3, 4, 4), momentum=0.8)
-    model.fit(X, X, nb_epoch=5, verbose=0)
+    model.fit(X, X, nb_epoch=4, verbose=0)
-from keras.layers import Dense, Dropout, Activation, Lambda
+from keras.layers import Dense, Dropout, Activation, Flatten
-from keras.layers import Convolution1D
+from keras.layers import Convolution1D, MaxPooling1D
-model.add(Lambda(max_1d, output_shape=(nb_filter,)))
+# We flatten the output of the conv layer,
-from keras.utils.test_utils import get_test_data
+from keras.utils.test_utils import get_test_data, keras_test
-from keras.utils.test_utils import get_test_data
+from keras.utils.test_utils import get_test_data, keras_test
-    test_temporal_classification()
+    pytest.main([__file__])
-from keras.utils.test_utils import get_test_data
+from keras.utils.test_utils import get_test_data, keras_test
-    input_dim = 5
+    input_dim = 2
-    nb_filter = 4
+    nb_filter = 3
-    stack_size = 4
+    nb_filter = 2
-    stack_size = 4
+    nb_filter = 2
-    stack_size = 4
+    nb_filter = 6
-    stack_size = 4
+    nb_filter = 2
-    stack_size = 7
+    stack_size = 2
-    stack_size = 7
+    stack_size = 2
-    stack_size = 7
+    stack_size = 2
-    stack_size = 7
+    stack_size = 2
-nb_samples, timesteps, embedding_dim, output_dim = 3, 5, 10, 5
+nb_samples, timesteps, embedding_dim, output_dim = 2, 5, 4, 3
-               input_shape=(3, 2, 3))
+               input_shape=(nb_samples, timesteps, embedding_dim))
-               input_shape=(3, 2, 3))
+               input_shape=(nb_samples, timesteps, embedding_dim))
-                   input_shape=(3, 2, 3))
+                   input_shape=(nb_samples, timesteps, embedding_dim))
-from keras.layers.core import Dense, Activation
+from keras.layers.core import Dense
-    arr_data = np.random.randint(0,256, (500, 200))
+    arr_data = np.random.randint(0, 256, (500, 2))
-    model.add(Activation('linear'))
+    model.add(Dense(1, input_shape=(2, )))
-    arr_data = np.random.randint(0,256, (500, 200))
+    arr_data = np.random.randint(0, 256, (500, 2))
-    model.add(Activation('linear'))
+    model.add(Dense(1, input_shape=(2, )))
-    arr_data = np.random.randint(0,256, (500, 200))
+    arr_data = np.random.randint(0, 256, (500, 2))
-    model.add(Activation('linear'))
+    model.add(Dense(1, input_shape=(2, )))
-    arr_data = np.random.randint(0,256, (500, 200))
+    arr_data = np.random.randint(0, 256, (500, 2))
-    model.add(Activation('linear'))
+    model.add(Dense(1, input_shape=(2, )))
-@keras_test
+@keras_test
-@keras_test
+
-    arr_data = np.random.randint(0, 256, (500, 2))
+
-    model.add(Dense(10, input_shape=(2, )))
+    model.add(Dense(10, input_shape=(200, )))
-    arr_data = np.random.randint(0, 256, (500, 2))
+    arr_data = np.random.randint(0,256, (500, 200))
-    model.add(Dense(10, input_shape=(2, )))
+    model.add(Dense(10, input_shape=(200, )))
-@keras_test
+
-    arr_data = np.random.randint(0, 256, (500, 2))
+
-    model.add(Dense(10, input_shape=(2, )))
+    model.add(Dense(10, input_shape=(200, )))
-@keras_test
+
-    arr_data = np.random.randint(0, 256, (500, 2))
+
-    model.add(Dense(10, input_shape=(2, )))
+    model.add(Dense(10, input_shape=(200, )))
-
+import numpy as np
-                                          std=K.sqrt(self.p / (1.0 - self.p)))
+                                          std=np.sqrt(self.p / (1.0 - self.p)))
-from keras.utils.test_utils import layer_test
+from keras.utils.test_utils import layer_test, keras_test
-from keras.utils.test_utils import layer_test
+from keras.utils.test_utils import layer_test, keras_test
-from keras.utils.test_utils import layer_test
+from keras.utils.test_utils import layer_test, keras_test
-    model_sum.fit([rand(2,3), rand(2,3)], [rand(2,3)], nb_epoch=1)
+    model_sum.fit([rand(2, 3), rand(2, 3)], [rand(2, 3)], nb_epoch=1)
-    model_concat.fit([rand(2,3), rand(2,3)], [rand(2,6)], nb_epoch=1)
+    model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], nb_epoch=1)
-    model.fit([rand(2,3), rand(2,3)], [rand(2,3,6)])
+    model.fit([rand(2, 3), rand(2, 3)], [rand(2, 3, 6)])
-from keras.utils.test_utils import layer_test
+from keras.utils.test_utils import layer_test, keras_test
-from keras.utils.test_utils import layer_test
+from keras.utils.test_utils import layer_test, keras_test
-from keras.utils.test_utils import layer_test
+from keras.utils.test_utils import layer_test, keras_test
-from keras.utils.test_utils import layer_test
+from keras.utils.test_utils import layer_test, keras_test
-
+@keras_test
-
+from keras.utils.test_utils import keras_test
-    arr_data = np.random.randint(0,256, (500, 200))
+    arr_data = np.random.randint(0, 256, (500, 2))
-    model.add(Activation('linear'))
+    model.add(Dense(10, input_shape=(2, )))
-    arr_data = np.random.randint(0,256, (500, 200))
+    arr_data = np.random.randint(0, 256, (500, 2))
-    model.add(Activation('linear'))
+    model.add(Dense(10, input_shape=(2, )))
-    arr_data = np.random.randint(0,256, (500, 200))
+    arr_data = np.random.randint(0, 256, (500, 2))
-    model.add(Activation('linear'))
+    model.add(Dense(10, input_shape=(2, )))
-    arr_data = np.random.randint(0,256, (500, 200))
+    arr_data = np.random.randint(0, 256, (500, 2))
-    model.add(Activation('linear'))
+    model.add(Dense(10, input_shape=(2, )))
-from keras.utils.test_utils import get_test_data
+from keras.utils.test_utils import get_test_data, keras_test
-    model.fit(x, y)
+    model.fit(x, y, nb_epoch=1)
-    model.fit(x, y)
+    model.fit(x, y, nb_epoch=1)
-    loss = model.evaluate(X_train, y_train)
+    model.evaluate(X_train, y_train)
-    new_model = Sequential.from_config(config)
+    Sequential.from_config(config)
-    new_model = model_from_json(json_str)
+    model_from_json(json_str)
-    new_model = model_from_yaml(yaml_str)
+    model_from_yaml(yaml_str)
-    new_model = Sequential.from_config(config)
+    Sequential.from_config(config)
-    new_model = model_from_json(json_str)
+    model_from_json(json_str)
-    new_model = model_from_yaml(yaml_str)
+    model_from_yaml(yaml_str)
-    new_model = Sequential.from_config(config)
+    Sequential.from_config(config)
-    new_model = model_from_json(json_str)
+    model_from_json(json_str)
-    new_model = model_from_yaml(yaml_str)
+    model_from_yaml(yaml_str)
-    new_model = Sequential.from_config(config)
+    Sequential.from_config(config)
-    new_model = model_from_json(json_str)
+    model_from_json(json_str)
-    new_model = model_from_yaml(yaml_str)
+    model_from_yaml(yaml_str)
-    new_model = Sequential.from_config(config)
+    Sequential.from_config(config)
-    new_model = model_from_json(json_str)
+    model_from_json(json_str)
-    new_model = model_from_yaml(yaml_str)
+    model_from_yaml(yaml_str)
-                         tf.cast(np.inf, dtype=_FLOATX))
+    zero = _to_tensor(0., x.dtype.base_dtype)
-                            tf.cast(max_value, dtype=_FLOATX))
+    min_value = _to_tensor(min_value, x.dtype.base_dtype)
-            self.updates_op = tf.group(*updates)
+            updates_ops = []
-    negative_part = tf.nn.relu(-x)
+    if alpha != 0.:
-    x -= alpha * negative_part
+        max_value = _to_tensor(max_value, x.dtype.base_dtype)
-                                  tf.cast(1. - _EPSILON, dtype=_FLOATX))
+        epsilon = _to_tensor(_EPSILON, output.dtype.base_dtype)
-                                  tf.cast(1.-_EPSILON, dtype=_FLOATX))
+        epsilon = _to_tensor(_EPSILON, output.dtype.base_dtype)
-                                  tf.cast(1.-_EPSILON, dtype=_FLOATX))
+        epsilon = _to_tensor(_EPSILON, output.dtype.base_dtype)
-                         tf.cast(1., dtype=_FLOATX))
+    zero = _to_tensor(0., x.dtype.base_dtype)
-print(y_train.shape)
+
-from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING
+from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING, reset_uids
-            self.updates = [tf.assign(p, new_p) for (p, new_p) in updates]
+            updates = [tf.assign(p, new_p) for (p, new_p) in updates]
-        updated = session.run(self.outputs + self.updates, feed_dict=feed_dict)
+        updated = session.run(self.outputs + [self.updates_op], feed_dict=feed_dict)
-                          'fallback to auto mode.' % (self.mode), RuntimeWarning)
+                          'fallback to auto mode.' % (self.mode),
-            HTTP POST, with a `data` argument which is a 
+            `root + '/publish/epoch/end/'` by default. Calls are
-            become quite large when write_graph is set to True.
+        write_graph: whether to visualize the graph in Tensorboard.
-    x = tf.reshape(x, [-1, np.prod(x.get_shape()[1:].as_list())])
+    x = tf.reshape(x, [-1, prod(shape(x)[1:])])
-filter_length = 3
+filter_length = 5
-pool_length = 2
+pool_length = 4
-model.add(Dropout(0.2))
+model.add(LSTM(128, input_shape=(maxlen, len(chars))))
-model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+optimizer = RMSprop(lr=0.01)
-def sample(a, temperature=1.0):
+def sample(preds, temperature=1.0):
-    return np.argmax(np.random.multinomial(1, a, 1))
+    preds = np.asarray(preds).astype('float64')
-        Tensor with ndim >= 2
+        A tensor with shape equal to the concatenation of x's shape (less the dimension that was summed over) and y's shape (less the batch dimension and the dimension that was summed over). If the final rank is 1, we reshape it to (batch_size, 1).
-    '''batchwise dot product
+    '''Batchwise dot product.
-        Tensor with ndim >= 2
+        A tensor with shape equal to the concatenation of x's shape (less the dimension that was summed over) and y's shape (less the batch dimension and the dimension that was summed over). If the final rank is 1, we reshape it to (batch_size, 1).
-                    dot_axes = [n1 - dot_axes, n2-dot_axes]
+                    dot_axes = [n1 - dot_axes, n2 - dot_axes]
-            return (shape1[0],) + shape
+            shape1.pop(self.dot_axes[0])
-    normed = (x - mean) * (gamma * T.inv(std + epsilon)) + beta
+    normed = T.nnet.bn.batch_normalization(x, gamma, beta, mean, std + epsilon,
-__version__ = '1.0.5'
+__version__ = '1.0.6'
-      version='1.0.5',
+      version='1.0.6',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.5',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.6',
-    v = tf.Variable(np.asarray(value, dtype=dtype), name=name)
+    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)
-    return variable(np.zeros(shape), dtype, name)
+    return variable(lambda: tf.cast(tf.constant_initializer(0.)(shape), dtype),
-    return variable(np.ones(shape), dtype, name)
+    return variable(lambda: tf.cast(tf.constant_initializer(1.)(shape), dtype),
-                                           K.get_value(self.forget_bias_init(self.output_dim)),
+                                           K.get_value(self.forget_bias_init((self.output_dim,))),
-        stride: integer or None. Stride value.
+        stride: integer, or None. Stride value.
-        stride: integer or None. Stride value.
+        stride: integer, or None. Stride value.
-class SeparableConv2D(Layer):
+class SeparableConvolution2D(Layer):
-            raise Exception('Invalid border mode for AtrousConv2D:', border_mode)
+            raise Exception('Invalid border mode for SeparableConv2D:', border_mode)
-            raise Exception('Invalid border mode for Convolution2D:', border_mode)
+            raise Exception('Invalid border mode for SeparableConv2D:', border_mode)
-        super(SeparableConv2D, self).__init__(**kwargs)
+        super(SeparableConvolution2D, self).__init__(**kwargs)
-        base_config = super(SeparableConv2D, self).get_config()
+        base_config = super(SeparableConvolution2D, self).get_config()
-class AtrousConv2D(Convolution2D):
+class AtrousConvolution2D(Convolution2D):
-        model.add(AtrousConv2D(64, 3, 3, atrous_rate=(2,2), border_mode='valid', input_shape=(3, 256, 256)))
+        model.add(AtrousConvolution2D(64, 3, 3, atrous_rate=(2,2), border_mode='valid', input_shape=(3, 256, 256)))
-                                           bias=bias, **kwargs)
+        super(AtrousConvolution2D, self).__init__(nb_filter, nb_row, nb_col,
-        base_config = super(AtrousConv2D, self).get_config()
+        base_config = super(AtrousConvolution2D, self).get_config()
-    dilated_filter_size = filter_size + (filter_size -1) * (dilation - 1)
+    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)
-    assert_allclose(zth, ztf, atol=1e-05)   
+    assert_allclose(zth, ztf, atol=1e-05)
-                                         'squeeze', {'axis':2}, 
+        check_composed_tensor_operations('reshape', {'shape':(4,3,1,1)},
-                                       epsilon)
+def normalize_batch_in_training(x, gamma, beta,
-                x_normed_running = K.batch_normalization(x, brodcast_running_mean, brodcast_running_std, self.beta, self.gamma, epsilon=self.epsilon)
+                if sorted(reduction_axes) == range(K.ndim(x))[:-1]:
-            std_update = self.momentum * self.running_std + (1 - self.momentum) * std
+            # # case: train mode (uses stats of the current batch)
-                out = K.reshape(self.gamma, broadcast_shape) * x_normed + K.reshape(self.beta, broadcast_shape)
+                x_normed, mean, std = K.normalize_batch_in_training(x, self.gamma, self.beta, reduction_axes, epsilon=self.epsilon)
-                x_normed_running = ((x - brodcast_running_mean) / (brodcast_running_std + self.epsilon))
+                x_normed_running = K.batch_normalization(x, brodcast_running_mean, brodcast_running_std, self.beta, self.gamma, epsilon=self.epsilon)
-        return out
+            x_normed = self.gamma * x_normed + self.beta
-                           strides, padding)
+    x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,
-        bias: whether to include a bias (i.e. make the layer affine rather than linear).
+        bias: whether to include a bias
-        bias: whether to include a bias (i.e. make the layer affine rather than linear).
+        bias: whether to include a bias
-                 border_mode='valid', subsample=(1, 1), atrous_rate=(1, 1), dim_ordering=K.image_dim_ordering(),
+                 border_mode='valid', subsample=(1, 1),
-    nb_samples = 8
+    nb_samples = 2
-    nb_samples = 8
+    nb_samples = 2
-    nb_samples = 9
+    nb_samples = 2
-    nb_samples = 9
+    nb_samples = 2
-    nb_samples = 9
+    nb_samples = 2
-    nb_samples = 9
+    nb_samples = 2
-                 input_dtype=None, name=None):
+                 input_dtype=None, input_tensor=None, name=None):
-            batch_input_shape = (None,) + tuple(input_shape)
+            if not input_shape:
-            input_dtype = K.floatx()
+            if input_tensor is None:
-                                     name=self.name)
+        if input_tensor is None:
-             output_shapes=[shape])
+             input_shapes=[batch_input_shape],
-          name=None, dtype=K.floatx()):
+          name=None, dtype=K.floatx(),
-    if not batch_shape:
+    if not batch_shape and tensor is None:
-                             name=name, input_dtype=dtype)
+                             name=name, input_dtype=dtype,
-from keras.layers import Dense, Dropout
+from keras.layers import Dense, Dropout, InputLayer
-            convolutional.AveragePooling3D,
+        'page': 'layers/pooling.md',
-           image_shape=None, filter_shape=None):
+           image_shape=None, filter_shape=None, filter_dilation=(1, 1)):
-    x = tf.nn.conv2d(x, kernel, strides, padding=padding)
+    if filter_dilation == (1, 1):
-           image_shape=None, filter_shape=None):
+           dim_ordering=_IMAGE_DIM_ORDERING, image_shape=None,
-                             filter_shape=filter_shape)
+    # TODO: remove the if statement when theano with no filter dilation is deprecated.
-def conv_output_length(input_length, filter_size, border_mode, stride):
+def conv_output_length(input_length, filter_size, border_mode, stride, dilation=1):
-        output_length = input_length - filter_size + 1
+        output_length = input_length - dilated_filter_size + 1
-    test_convolution_3d()
+    pytest.main([__file__])
-                                str(loss))
+                                str(loss_weights))
-                     tf.ones(shape), tf.zeros(shape))
+                     tf.ones(shape, dtype=dtype),
-            return np.ones((y.shape[0],))
+            return np.ones((y.shape[0],), dtype=K.floatx())
-            return np.ones((y.shape[0], y.shape[1]))
+            return np.ones((y.shape[0], y.shape[1]), dtype=K.floatx())
-                    outs.append(np.zeros(shape))
+                    outs.append(np.zeros(shape, dtype=K.floatx()))
-                    all_outs.append(np.zeros(shape))
+                    all_outs.append(np.zeros(shape, dtype=K.floatx()))
-    the original loss (evaluated on the 
+    '''This takes a constant that controls
-        
+
-        
+            domin_eigenvect = K.dot(WW, domin_eigenvect)
-        
+
-        initial_state = K.dot(initial_state, reducer)  # (samples, output_dim)
+        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)
-    def __init__(self, root='http://localhost:9000', path='/publish/epoch/end/'):
+
-                          {'data': json.dumps(send)})
+                          {self.field: json.dumps(send)})
-                return (input_shape[0],) + tuple(self._output_shape)
+                return (input_shape[0][0],) + tuple(self._output_shape)
-        in inputs/kernels/ouputs.
+            for inputs/kernels/ouputs.
-    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, dim_ordering)
+    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel,
-    (X_train, y_train), (X_test, y_test) = cifar100.load_data('coarse')
+    # only run data download tests 20% of the time
-    (X_train, y_train), (X_test, y_test) = reuters.load_data(maxlen=10)
+    # only run data download tests 20% of the time
-    (X_train, y_train), (X_test, y_test) = mnist.load_data()
+    # only run data download tests 20% of the time
-    (X_train, y_train), (X_test, y_test) = imdb.load_data(maxlen=40)
+    # only run data download tests 20% of the time
-_UID_PREFIXES = {}
+_UID_PREFIXES = defaultdict(int)
-        return _UID_PREFIXES[prefix]
+    _UID_PREFIXES[prefix] += 1
-            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot'.
+            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'.
-            if mode not in {'sum', 'mul', 'concat', 'ave', 'cos', 'dot'}:
+            if mode not in {'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'}:
-        if mode in {'sum', 'mul', 'ave', 'cos'}:
+        if mode in {'sum', 'mul', 'ave', 'cos', 'max'}:
-
+        elif self.mode == 'max':
-        if self.mode in ['sum', 'mul', 'ave']:
+        if self.mode in ['sum', 'mul', 'ave', 'max']:
-    for mode in ['sum', 'mul', 'concat', 'ave']:
+    for mode in ['sum', 'mul', 'concat', 'ave', 'max']:
-                    [3, 4]]           [7, 8]]
+        Assume x = [[1, 2], [3, 4]]   and y = [[5, 6], [7, 8]]
-                    [3, 4]]           [7, 8]]
+        Assume x = [[1, 2], [3, 4]]   and y = [[5, 6], [7, 8]]
-            Could be a tuple or a function of the shape of the input
+            Can be a tuple or function.
-                                'as the output.')
+            raise Exception('A target array with shape ' + str(y.shape) +
-    '''Builds a threading queue out of a data generator.
+                    wait_time=0.05, nb_worker=1, pickle_safe=False):
-                raise
+    generator_threads = []
-                         for _ in range(nb_worker)]
+    try:
-        thread.start()
+        def data_generator_task():
-            sample_weights, val_sample_weights = (slice_X(sample_weights, 0, split_at), slice_X(sample_weights, split_at))
+            sample_weights, val_sample_weights = (
-                      class_weight={}, max_q_size=10):
+                      class_weight={}, max_q_size=10, nb_worker=1, pickle_safe=False):
-        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)
+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,
-    def evaluate_generator(self, generator, val_samples, max_q_size=10):
+    def evaluate_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):
-        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)
+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,
-                                weights=weights))
+                                           weights=weights))
-    def predict_generator(self, generator, val_samples, max_q_size=10):
+    def predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):
-        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)
+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,
-                      class_weight=None, max_q_size=10, **kwargs):
+                      class_weight=None, max_q_size=10, nb_worker=1, pickle_safe=False, **kwargs):
-                                        max_q_size=max_q_size)
+                                        max_q_size=max_q_size,
-    def evaluate_generator(self, generator, val_samples, max_q_size=10, **kwargs):
+    def evaluate_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False, **kwargs):
-                                             max_q_size=max_q_size)
+                                             max_q_size=max_q_size,
-    def predict_generator(self, generator, val_samples, max_q_size=10):
+    def predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):
-                                            max_q_size=max_q_size)
+                                            max_q_size=max_q_size,
-    test_locallyconnected_2d()
+    pytest.main([__file__])
-from .common import _FLOATX, _EPSILON
+from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING
-        raise Exception('Invalid border mode: ' + str(border_mode))
+def _preprocess_conv3d_input(x, dim_ordering):
-    strides = (1,) + strides + (1,)
+def _preprocess_conv2d_kernel(kernel, dim_ordering):
-        x = tf.nn.conv2d(x, kernel, strides, padding=padding)
+    return kernel
-        raise Exception('Unknown dim_ordering: ' + str(dim_ordering))
+        raise Exception('Invalid border mode: ' + str(border_mode))
-           border_mode='valid', dim_ordering='th', pool_mode='max'):
+           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,
-        padding = 'VALID'
+    if dim_ordering not in {'th', 'tf'}:
-        raise Exception('Invalid border mode: ' + str(border_mode))
+        raise Exception('Invalid pooling mode: ' + str(pool_mode))
-        x = tf.cast(x, 'float32')
+    x = _preprocess_conv3d_input(x, dim_ordering)
-            x = tf.transpose(x, (0, 3, 1, 2))
+    if pool_mode == 'max':
-        raise Exception('Unknown dim_ordering: ' + str(dim_ordering))
+        raise Exception('Invalid pooling mode: ' + str(pool_mode))
-    return x
+    return _postprocess_conv3d_output(x, dim_ordering)
-from .common import _FLOATX, _EPSILON
+from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING
-def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',
+def conv2d(x, kernel, strides=(1, 1), border_mode='valid',
-    border_mode: string, "same" or "valid".
+    '''2D convolution.
-    return (output_length + stride - 1) // stride
+# imports for backwards namespace compatibility
-
+# -*- coding: utf-8 -*-
-                new_kernel[i, j, :, :] = kernel[w - i - 1, h - j - 1, :, :]
+    if kernel.ndim == 4:
-        raise Exception('Invalid dim_ordering: ' + str(dim_ordering))
+        raise ValueError('Invalid kernel shape:', kernel.shape)
-        if mask is None or not any([m is not None for m in mask]):
+        if mask is None or all([m is None for m in mask]):
-        self.supports_masking = True
+        self.supports_masking = False
-                                    'Layer shapes: %s, %s' % (shape1, shape2))
+            if type(dot_axes) == int:
-        elif self.mode == 'dot':
+        elif self.mode in ['dot', 'cos']:
-            of event data.
+            `root + '/publish/epoch/end/'` by default. Calls are 
-    def __init__(self, root='http://localhost:9000'):
+    def __init__(self, root='http://localhost:9000', path='/publish/epoch/end/'):
-            requests.post(self.root + '/publish/epoch/end/',
+            requests.post(self.root + self.path,
-    test_masking()
+    pytest.main([__file__])
-         [[1, 5], [5, 0], [0, 0], [0, 0]]], dtype=np.int32)
+    X = np.array([[[1], [1]],
-    model.add(Masking(mask_value=0, input_shape=(4, 2)))
+    model.add(Masking(mask_value=0, input_shape=(2, 1)))
-    history = model.fit(X, 4 * y, nb_epoch=1, batch_size=2, verbose=1)
+    y = np.array([[[1], [1]],
-    pytest.main([__file__])
+    # pytest.main([__file__])
-            # also fill in the output mask cache
+        # fill in the output mask cache
-        # output mask cache
+
-                    if output_shape[-1] == 1:
+                    if output_shape[-1] == 1 or self.loss_functions[i] == objectives.binary_crossentropy:
-    assert(loss < 4.0)
+    assert(loss < 5.0)
-__version__ = '1.0.4'
+__version__ = '1.0.5'
-      version='1.0.4',
+      version='1.0.5',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.4',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.5',
-
+            trainable_weights = collect_trainable_weights(self)
-    loss = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph}, verbose=0) 
+    loss = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph}, verbose=0)
-    assert(loss < 3.0)
+    assert(loss < 4.0)
-print('Ploting Results')
+print('Plotting Results')
-        in test mode. Computation in done in batches.
+        in test mode. Computation is done in batches.
-    Note that this function only works with TensorFlow. 
+    Note that this function only works with TensorFlow.
-chars = set(text)
+chars = sorted(list(set(text)))
-def _test_optimizer(optimizer, target=0.9):
+def _test_optimizer(optimizer, target=0.89):
-    assert history.history['val_acc'][-1] > target
+    assert history.history['val_acc'][-1] >= target
-                 dot_axes=-1, output_shape=None,
+                 dot_axes=-1, output_shape=None, output_mask=None,
-        self.supports_masking = False
+        self.supports_masking = True
-        return None
+    def compute_mask(self, inputs, mask=None):
-          dot_axes=-1, output_shape=None, name=None):
+          dot_axes=-1, output_shape=None, output_mask=None, name=None):
-from numpy.testing import assert_allclose
+def test_merge_mask_2d():
-            for subdir in os.listdir(directory):
+            for subdir in sorted(os.listdir(directory)):
-                epoch_logs = {}
+    Note that this function only works with TensorFlow. 
-
+            self.history.setdefault(k, []).append(v)
-        # now model.output_shape == (None, 10, 32)
+        # now model.output_shape == (None, 32)
-                self.best = np.Inf
+
-                                    'but the model expects a '
+                                    'but the model expects '
-                output_shape = marshal.dumps(self._output_shape.__code__)
+                output_shape = marshal.dumps(self._output_shape.__code__).decode('raw_unicode_escape')
-                output_shape = marshal.dumps(self._output_shape.func_code)
+                output_shape = marshal.dumps(self._output_shape.func_code).decode('raw_unicode_escape')
-            output_shape = marshal.loads(config['output_shape'])
+            output_shape = marshal.loads(config['output_shape'].encode('raw_unicode_escape'))
-                output_shape = marshal.dumps(self._output_shape.__code__)
+                output_shape = marshal.dumps(self._output_shape.__code__).decode('raw_unicode_escape')
-                output_shape = marshal.dumps(self._output_shape.func_code)
+                output_shape = marshal.dumps(self._output_shape.func_code).decode('raw_unicode_escape')
-            output_shape = marshal.loads(config['output_shape'])
+            output_shape = marshal.loads(config['output_shape'].encode('raw_unicode_escape'))
-        super(Callback, self).__init__()
+        super(ModelCheckpoint, self).__init__()
-        super(Callback, self).__init__()
+        super(EarlyStopping, self).__init__()
-        super(Callback, self).__init__()
+        super(TensorBoard, self).__init__()
-                    X[i][j] = tf / df
+                    idf = np.log(1 + self.document_count / (1 + self.index_docs.get(j, 0)))
-    return cPickle.load(f)
+
-def standardize_input_data(data, names, shapes=None, check_batch_dim=True,
+def standardize_input_data(data, names, shapes=None,
-            output_shapes = [s[:-1] + (1,) for s in output_shapes]
+        output_shapes = []
-                except Exception as e:
+                except:
-            except Exception as e:
+            except:
-            except Exception as e:
+            except:
-                    df = (1 + np.log(1 + self.index_docs.get(j, 0) / (1 + self.document_count)))
+                    # Use weighting scheme 2 in
-    if layer.__class__.__name__ in ['Sequential', 'Model']:
+    if layer.__class__.__name__ == 'Sequential':
-    '''Standard deviation of a tensor, alongside the specificied axis.
+def var(x, axis=None, keepdims=False):
-                                  keep_dims=keepdims))
+    return tf.reduce_mean(devs_squared,
-            std = K.std(x, axis=-1, keepdims=True)
+            std = K.sqrt(K.var(x, axis=-1, keepdims=True) + self.epsilon)
-        self.grads_values = None
+        self.grad_values = None
-    def from_config(cls, config, layer_cache={}):
+    def from_config(cls, config, layer_cache=None):
-    Nesterov Adam optimizer: Adam ~ RMSProp + momentum, Nadam ~ RMSProp + NAG
+    Nesterov Adam optimizer: Much like Adam is essentially RMSprop with momentum,
-    to keep these values hard-coded and constant.
+    It is recommended to leave the parameters of this optimizer
-        http://www.cs.toronto.edu/~fritz/absps/momentum.pdf
+        [1] Nadam report - http://cs229.stanford.edu/proj2015/054_report.pdf
-                 epsilon=1e-8, **kwargs):
+                 epsilon=1e-8, schedule_decay=0.004, **kwargs):
-        momentum_cache_t_1 = self.beta_1 * (1. - 0.5 * (K.pow(0.96, (t + 1) * schedule_decay)))
+        momentum_cache_t = self.beta_1 * (1. - 0.5 * (K.pow(0.96, t * self.schedule_decay)))
-                  'epsilon': self.epsilon}
+                  'epsilon': self.epsilon,
-from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax
+from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam
-        output = self.activation(output)
+        output = self.activation(output)
-    return T.squeeze(x)
+    broadcastable = x.broadcastable[:axis] + x.broadcastable[axis+1:]
-        new_out_labels = []
+        # (can happen with an output layer shared among multiple dataflows)
-        out_labels = new_out_labels
+                new_label += '_' + str(dup_idx + 1)
-import numpy
+import numpy as np
-                 will return '(n_samples, 2)'
+                In the case of binary classification,
-            probs = numpy.hstack([1 - probs, probs])
+            probs = np.hstack([1 - probs, probs])
-                    if fname.endswith('.' + extension):
+                    if fname.lower().endswith('.' + extension):
-                    if fname.endswith('.' + extension):
+                    if fname.lower().endswith('.' + extension):
-            (1:1 mapping to input tensors) and return a single shape tuple.
+            (1:1 mapping to input tensors) and return a single shape tuple, including the
-        mode: integer, 0 or 1.
+        mode: integer, 0, 1 or 2.
-                                   self.internal_output_shapes,
+                                   output_shapes,
-        return self.model.predict_proba(X, **kwargs)
+        probs = self.model.predict_proba(X, **kwargs)
-    + Decode a vector of probabilties to their character output
+    + Decode a vector of probabilities to their character output
-It is preferrable to run this script on GPU, for speed.
+It is preferable to run this script on GPU, for speed.
-It is preferrable to run this script on GPU, for speed.
+It is preferable to run this script on GPU, for speed.
-L2 distances betwen the Gram matrices of the representations of
+L2 distances between the Gram matrices of the representations of
-    '''Mean of a tensor, alongside the specificied axis.
+    '''Mean of a tensor, alongside the specified axis.
-    '''Normalizes a tensor wrt the L2 norm alonside the specified axis.
+    '''Normalizes a tensor wrt the L2 norm alongside the specified axis.
-    Appologies for the inane API, but Theano makes this
+    Apologies for the inane API, but Theano makes this
-            files to be parsed by tensorboard
+            files to be parsed by Tensorboard
-        write_graph: whether to visualize the graph in tensorboard. The log file can
+        write_graph: whether to visualize the graph in Tensorboard. The log file can
-        # which itself will be calld upon self.add_inbound_node if necessary.
+        # which itself will be called upon self.add_inbound_node if necessary.
-                of tensor, and we might only be interested in one sepcific entry.
+                of tensor, and we might only be interested in one specific entry.
-            (`float32`, `flaot64`, `int32`...)
+            (`float32`, `float64`, `int32`...)
-        (it is just a layer), it would make for a rather unelegant API.
+        making it possible to __call__ a Merge instance many times
-        assert type(input_shape) is list  # must have mutiple input shape tuples
+        assert type(input_shape) is list  # must have multiple input shape tuples
-            Array of prections (if the model has a single output)
+            Array of predictions (if the model has a single output)
-            class_weight: optional dictionary mapping classe indices (integers) to
+            class_weight: optional dictionary mapping class indices (integers) to
-            class_weight: optional dictionary mapping classe indices (integers) to
+            class_weight: optional dictionary mapping class indices (integers) to
-        weights: initial weights, as a list of a single numpy array.
+        weights: initial weights, as a list of a single Numpy array.
-        kernel_dim1: Length of the first dimension in the covolution kernel.
+        kernel_dim1: Length of the first dimension in the convolution kernel.
-        weights: list of numpy arrays to set as initial weights.
+        weights: list of Numpy arrays to set as initial weights.
-                            ' is currently only working with Theano backend.') 
+                            ' is currently only working with Theano backend.')
-        A near direct port of the internal numpy function _fix_unknown_dimension
+        A near direct port of the internal Numpy function _fix_unknown_dimension
-        weights: list of numpy arrays to set as initial weights.
+        weights: list of Numpy arrays to set as initial weights.
-        weights: list of numpy arrays to set as initial weights.
+        weights: list of Numpy arrays to set as initial weights.
-        weights: list of numpy arrays to set as initial weights.
+        weights: list of Numpy arrays to set as initial weights.
-        weights: list of numpy arrays to set as initial weights.
+        weights: list of Numpy arrays to set as initial weights.
-      weights: list of numpy arrays to set as initial weights.
+      weights: list of Numpy arrays to set as initial weights.
-    '''Apply to the input an additive zero-centred gaussian noise with
+    '''Apply to the input an additive zero-centered Gaussian noise with
-    '''Apply to the input an multiplicative one-centred gaussian noise
+    '''Apply to the input an multiplicative one-centered Gaussian noise
-            List of 2 numpy arrays, with shapes:
+            List of 2 Numpy arrays, with shapes:
-        weights: list of numpy arrays to set as initial weights.
+        weights: list of Numpy arrays to set as initial weights.
-                appropriate numpy arrays. All arrays should contain
+                appropriate Numpy arrays. All arrays should contain
-                to appropriate numpy arrays to be used as
+                to appropriate Numpy arrays to be used as
-                to appropriate numpy arrays to be used as
+                to appropriate Numpy arrays to be used as
-                        # create numpy arrays of input data
+                        # create Numpy arrays of input data
-                        # create numpy arrays of input data
+                        # create Numpy arrays of input data
-    and label=0 if 'other_word' is ramdomly sampled
+    and label=0 if 'other_word' is randomly sampled
-        couples, lables: where `couples` are int pairs and
+        couples, labels: where `couples` are int pairs and
-    '''Converts a kernel matrix (numpy array)
+    '''Converts a kernel matrix (Numpy array)
-    estimators in scikit-learn, 'build_fn' should provide defalult values for
+    estimators in scikit-learn, 'build_fn' should provide default values for
-            override: dictionary, values to overrid sk_params
+            override: dictionary, values to override sk_params
-            res : dictionary dictionary containing variabls
+            res : dictionary dictionary containing variables
-__version__ = '1.0.3'
+__version__ = '1.0.4'
-      version='1.0.3',
+      version='1.0.4',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.3',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.4',
-                                                           format=self.save_format)
+                                                                  index=current_index + i,
-def model_to_dot(model, show_shapes=False):
+def model_to_dot(model, show_shapes=False, show_layer_names=True):
-        label = str(layer.name) + ' (' + layer.__class__.__name__ + ')'
+        if show_layer_names:
-    dot = model_to_dot(model, show_shapes)
+def plot(model, to_file='model.png', show_shapes=False, show_layer_names=True):
-    def flow(self, X, y, batch_size=32, shuffle=True, seed=None,
+    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,
-        if len(X) != len(y):
+        if y is not None and len(X) != len(y):
-                                                           format=self.save_format)
+                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,
-                fname = '{prefix}_{index}.{format}'.format(prefix=self.save_prefix,
+                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,
-        self.dim_ordering
+        self.dim_ordering = dim_ordering
-def load_img(path, grayscale=False):
+def load_img(path, grayscale=False, target_size=None):
-        self.lock = threading.Lock()
+        self.rescale = rescale
-        if dim_ordering == "th":
+        if dim_ordering == 'th':
-        if dim_ordering == "tf":
+        if dim_ordering == 'tf':
-    def flow(self, X, y, batch_size=32, shuffle=False, seed=None,
+    def flow(self, X, y, batch_size=32, shuffle=True, seed=None,
-        return self.next()
+        return NumpyArrayIterator(
-            raise Exception('The model needs to be compiled before being used.')
+            self.build()
-        return {'input': bX, 'output': bY}
+from .common import image_dim_ordering
-        f.write(json.dumps(_config) + '\n')
+
-    _FLOATX = floatx
+    _FLOATX = str(floatx)
-                 border_mode='valid', subsample=(1, 1), dim_ordering='th',
+                 border_mode='valid', subsample=(1, 1), dim_ordering=K.image_dim_ordering(),
-                 border_mode='valid', subsample=(1, 1, 1), dim_ordering='th',
+                 border_mode='valid', subsample=(1, 1, 1), dim_ordering=K.image_dim_ordering(),
-                 dim_ordering='th', **kwargs):
+                 dim_ordering=K.image_dim_ordering(), **kwargs):
-                 dim_ordering='th', **kwargs):
+                 dim_ordering=K.image_dim_ordering(), **kwargs):
-                 dim_ordering='th', **kwargs):
+                 dim_ordering=K.image_dim_ordering(), **kwargs):
-                 dim_ordering='th', **kwargs):
+                 dim_ordering=K.image_dim_ordering(), **kwargs):
-                 dim_ordering='th', **kwargs):
+                 dim_ordering=K.image_dim_ordering(), **kwargs):
-                 dim_ordering='th', **kwargs):
+                 dim_ordering=K.image_dim_ordering(), **kwargs):
-    def __init__(self, size=(2, 2), dim_ordering='th', **kwargs):
+    def __init__(self, size=(2, 2), dim_ordering=K.image_dim_ordering(), **kwargs):
-    def __init__(self, size=(2, 2, 2), dim_ordering='th', **kwargs):
+    def __init__(self, size=(2, 2, 2), dim_ordering=K.image_dim_ordering(), **kwargs):
-    def __init__(self, padding=(1, 1), dim_ordering='th', **kwargs):
+    def __init__(self, padding=(1, 1), dim_ordering=K.image_dim_ordering(), **kwargs):
-    def __init__(self, padding=(1, 1, 1), dim_ordering='th', **kwargs):
+    def __init__(self, padding=(1, 1, 1), dim_ordering=K.image_dim_ordering(), **kwargs):
-'''Fairly basic set of tools for realtime data augmentation on image data.
+'''Fairly basic set of tools for real-time data augmentation on image data.
-def array_to_img(x, dim_ordering='th', scale=True):
+def array_to_img(x, dim_ordering=K.image_dim_ordering(), scale=True):
-def img_to_array(img, dim_ordering='th'):
+def img_to_array(img, dim_ordering=K.image_dim_ordering()):
-                 dim_ordering='th'):
+                 dim_ordering=K.image_dim_ordering()):
-            self.progbar.update(self.seen, self.log_values)
+            self.progbar.update(self.seen, self.log_values, force=True)
-    def __init__(self, target, width=30, verbose=1):
+    def __init__(self, target, width=30, verbose=1, interval=0.01):
-    def update(self, current, values=[]):
+    def update(self, current, values=[], force=False):
-        seed = np.random.randint(10e6)
+        seed = np.random.randint(1, 10e6)
-        seed = np.random.randint(10e6)
+        seed = np.random.randint(1, 10e6)
-        seed = np.random.randint(10e6)
+        seed = np.random.randint(1, 10e6)
-        seed = np.random.randint(10e6)
+        seed = np.random.randint(1, 10e6)
-                'l2': self.l2}
+                'l1': float(self.l1),
-                'l2': self.l2}
+                'l1': float(self.l1),
-                return (input_shape[0],) + self._output_shape
+                return (input_shape[0],) + tuple(self._output_shape)
-            (1:1 mapping to input tensors) and return a single shape tuple.
+        output_shape: either a shape tuple (tuple of integers), or a lambda/function
-                              output_shape, node_indices, tensor_indices):
+                              node_indices, tensor_indices):
-                return self._output_shape
+                return (input_shape[0],) + self._output_shape
-            dot_axes = [a-1 for a in self.dot_axes]
+            dot_axes = [a - 1 for a in self.dot_axes]
-                mode = marshal.dumps(self.mode.__code__)
+                mode = marshal.dumps(self.mode.__code__).decode('raw_unicode_escape')
-                mode = marshal.dumps(self.mode.func_code)
+                mode = marshal.dumps(self.mode.func_code).decode('raw_unicode_escape')
-            mode = marshal.loads(config['mode'])
+            mode = marshal.loads(config['mode'].encode('raw_unicode_escape'))
-from keras.layers import Activation, TimeDistributedDense, RepeatVector, recurrent
+from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent
-model.add(TimeDistributedDense(len(chars)))
+model.add(TimeDistributed(Dense(len(chars))))
-        self.uses_learning_phase = True
+        if self.mode == 0:
-        # build self.output_layers:
+
-
+                During training we use per-batch statistics to normalize
-        if self.mode == 0:
+        if self.mode == 0 or self.mode == 2:
-            out = K.reshape(self.gamma, broadcast_shape) * x_normed + K.reshape(self.beta, broadcast_shape)
+
-    model.compile(loss='mse', optimizer='sgd')
+def test_batchnorm_mode_0_or_2():
-    np_out = K.function([K.learning_phase()], [out])([1.])[0]
+        # centered on 5.0, variance 10.0
-    assert_allclose(np_out.std(), 1.0, atol=1e-1)
+        assert_allclose(out.mean(), 0.0, atol=1e-1)
-    np_out = K.function([K.learning_phase()], [out])([1.])[0]
+    out = model.predict(X)
-    assert_allclose(np.std(np_out, axis=(0, 2, 3)), 1.0, atol=1e-1)
+    assert_allclose(np.mean(out, axis=(0, 2, 3)), 0.0, atol=1e-1)
-        def make_node_key(node, depth):
+        def make_node_marker(node, depth):
-            seen_nodes.add(make_node_key(node, depth))
+            seen_nodes.add(make_node_marker(node, depth))
-                layers_depths[layer] = depth
+            previously_seen_depth = layers_depths.get(layer)
-                layers_depths[layer] = max(depth, layer_depth)
+                current_depth = max(depth, previously_seen_depth)
-                    build_map_of_graph(x, seen_nodes, depth + 1,
+                # use node_marker to prevent cycles
-        for layer_data in config['layers']:
+        def process_layer(layer_data):
-            model_config['loss'] = self.loss.__class__.__name__
+            model_config['loss'] = getattr(self.loss, '__name__', self.loss)
-    def from_config(cls, config):
+    def from_config(cls, config, layer_cache={}):
-            layer = layer_from_config(first_layer)
+            layer = get_or_create_layer(first_layer)
-            layer = layer_from_config(conf)
+            layer = get_or_create_layer(conf)
-                        '`load_config` method on Sequential or Graph')
+        raise Exception('`model_fom_config` expects a dictionary, not a list. '
-            for dim, ref_dim in zip(array.shape, shapes[i]):
+            for j, (dim, ref_dim) in enumerate(zip(array.shape, shapes[i])):
-arXiv:1504.00941v2 [cs.NE] 7 Apr 201
+arXiv:1504.00941v2 [cs.NE] 7 Apr 2015
-            fan_out = shape[0]
+            receptive_field_size = np.prod(shape[2:])
-            fan_out = shape[-1]
+            receptive_field_size = np.prod(shape[:2])
-SHAPE = (100, 100)
+# 2D tensor test fixture
-    _runner(initializations.uniform, SHAPE, target_mean=0.,
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    _runner(initializations.normal, SHAPE, target_mean=0., target_std=0.05)
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-def test_lecun_uniform():
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    _runner(initializations.lecun_uniform, SHAPE,
+    _runner(initializations.lecun_uniform, tensor_shape,
-def test_glorot_uniform():
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    _runner(initializations.glorot_uniform, SHAPE, target_mean=0.,
+    _runner(initializations.glorot_uniform, tensor_shape, target_mean=0.,
-def test_glorot_normal():
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    _runner(initializations.glorot_normal, SHAPE,
+    _runner(initializations.glorot_normal, tensor_shape,
-def test_he_uniform():
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    _runner(initializations.he_uniform, SHAPE, target_mean=0.,
+    _runner(initializations.he_uniform, tensor_shape, target_mean=0.,
-def test_he_normal():
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    _runner(initializations.he_normal, SHAPE,
+    _runner(initializations.he_normal, tensor_shape,
-    _runner(initializations.orthogonal, SHAPE,
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-            target_mean=1./SHAPE[0], target_max=1.)
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    _runner(initializations.zero, SHAPE,
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    _runner(initializations.one, SHAPE,
+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])
-    def summary(self):
+    def summary(self, line_length=100, positions=[.33, .55, .67, 1.]):
-        print_summary(flattened_layers, getattr(self, 'container_nodes', None))
+        print_summary(flattened_layers, getattr(self, 'container_nodes', None), line_length=line_length, positions=positions)
-    positions = [35, 55, 67, 100]  # absolute positions of log elements in each line
+def print_summary(layers, relevant_nodes=None, line_length=100, positions=[.33, .55, .67, 1.]):
-                origin='http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz')
+try:
-path = get_file('babi-tasks-v1-2.tar.gz', origin='http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz')
+try:
-            if tf_version >= (0, 8, 0):
+            if tf.__version__ >= '0.8.0':
-z_log_sigma = Dense(latent_dim)(h)
+z_log_std = Dense(latent_dim)(h)
-    z_mean, z_log_sigma = args
+    z_mean, z_log_std = args
-    return z_mean + K.exp(z_log_sigma) * epsilon
+    return z_mean + K.exp(z_log_std) * epsilon
-z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
+# so you could write `Lambda(sampling)([z_mean, z_log_std])`
-    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
+    kl_loss = - 0.5 * K.mean(1 + z_log_std - K.square(z_mean) - K.exp(z_log_std), axis=-1)
-        '''
+    def _updated_config(self):
-        }
+        model_config = self._updated_config()
-        return yaml.dump(model_config, **kwargs)
+        return yaml.dump(self._updated_config(), **kwargs)
-                       '`input_shape` does not include the batch '
+        assert shape, ('Please provide to Input either a `shape`' +
-__version__ = '1.0.2'
+
-      version='1.0.2',
+      version='1.0.3',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.2',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.3',
-            return outputs[0] # merge only returns a single tensor
+            return outputs[0]  # merge only returns a single tensor
-            of: 'sum', 'mul', 'concat', 'ave', 'join', 'cos', 'dot'.
+            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot'.
-        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://arxiv.org/pdf/1502.03167v3.pdf)
+        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.html)
-    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-6, **kwargs):
+    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-8, **kwargs):
-from keras.layers import recurrent
+from keras.layers import Activation, TimeDistributedDense, RepeatVector, recurrent
-from keras.layers.core import Dense, Dropout, Layer, Activation
+from keras.layers import Dense, Dropout, Layer, Activation
-from keras.layers.recurrent import LSTM
+from keras.layers import Activation, Dense, Merge, Permute, Dropout
-from keras.layers.core import Dense, Merge, Dropout, RepeatVector
+from keras.layers import Dense, Merge, Dropout, RepeatVector
-from keras.layers.convolutional import Convolution2D, MaxPooling2D
+from keras.layers import Dense, Dropout, Activation, Flatten
-from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D
+from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D
-from keras.layers.convolutional import Convolution1D
+from keras.layers import Dense, Dropout, Activation, Lambda
-from keras.layers.convolutional import Convolution1D, MaxPooling1D
+from keras.layers import Dense, Dropout, Activation
-from keras.layers.recurrent import LSTM, SimpleRNN, GRU
+from keras.layers import Dense, Dropout, Activation, Embedding
-from keras.layers.recurrent import LSTM
+from keras.layers import Dense, Activation, Dropout
-from keras.layers.convolutional import Convolution2D, MaxPooling2D
+from keras.layers import Dense, Dropout, Activation, Flatten
-from keras.layers.core import Dense, Activation
+from keras.layers import Dense, Activation
-from keras.layers.convolutional import Convolution2D, MaxPooling2D
+from keras.layers import Dense, Dropout, Activation, Flatten
-from keras.layers.convolutional import Convolution2D, MaxPooling2D
+from keras.layers import Dense, Dropout, Activation, Flatten
-from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D
+from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D
-from keras.layers.normalization import BatchNormalization
+from keras.layers import Dense, Dropout, Activation
-from keras.layers.recurrent import LSTM
+from keras.layers import Dense, LSTM
-                                                         nb_test=200,
+                                                         nb_test=500,
-                  optimizer='adadelta',
+                  optimizer='adagrad',
-    history = model.fit(X_train, y_train, nb_epoch=5, batch_size=16,
+    history = model.fit(X_train, y_train, nb_epoch=20, batch_size=32,
-    assert(history.history['val_acc'][-1] > 0.9)
+    assert(history.history['val_acc'][-1] >= 0.85)
-    pytest.main([__file__])
+    # pytest.main([__file__])
-            new_p = p - self.lr * g / K.sqrt(new_a + self.epsilon)
+            new_p = p - self.lr * g / (K.sqrt(new_a) + self.epsilon)
-    def __init__(self, lr=0.01, epsilon=1e-6, **kwargs):
+    def __init__(self, lr=0.01, epsilon=1e-8, **kwargs):
-            new_p = p - self.lr * g / K.sqrt(new_a + self.epsilon)
+            new_p = p - self.lr * g / (K.sqrt(new_a) + self.epsilon)
-    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-6, **kwargs):
+    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-8, **kwargs):
-        return permute_dimensions(X, [0, 3, 1, 2])
+        X = permute_dimensions(X, [0, 3, 1, 2])
-        return tf.image.resize_nearest_neighbor(X, new_shape)
+        X = tf.image.resize_nearest_neighbor(X, new_shape)
-      # the largest integer (i.e. word index) in the input should be no larger than 1000 (vocabulary size).
+      # the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).
-      input_dim: int >= 0. Size of the vocabulary, ie.
+      input_dim: int > 0. Size of the vocabulary, ie.
-    return shape1
+    return (shape1[0], 1)
-            std_update = self.momentum * self.running_std + (1-self.momentum) * std
+            mean_update = self.momentum * self.running_mean + (1 - self.momentum) * mean
-            weight_values = layer.get_weights()
+            weight_values = K.batch_get_value(symbolic_weights)
-            index_array = np.arange(N)
+                index_array = np.arange(N)
-        consume_less: one of "cpu", "mem", or "gpu" (LSTM only).
+        consume_less: one of "cpu", "mem", or "gpu" (LSTM/GRU only).
-            If set to "gpu" (LSTM only), the LSTM will combine the input gate,
+            If set to "gpu" (LSTM/GRU only), the RNN will combine the input gate,
-        self.input_dim = input_dim
+        self.input_dim = input_shape[2]
-        self.b_z = K.zeros((self.output_dim,), name='{}_b_z'.format(self.name))
+            self.W_z = self.init((self.input_dim, self.output_dim),
-        self.b_r = K.zeros((self.output_dim,), name='{}_b_r'.format(self.name))
+            self.W_r = self.init((self.input_dim, self.output_dim),
-        self.b_h = K.zeros((self.output_dim,), name='{}_b_h'.format(self.name))
+            self.W_h = self.init((self.input_dim, self.output_dim),
-                                                        self.W_h]))
+            self.W_regularizer.set_param(self.W)
-                                                        self.U_h]))
+            self.U_regularizer.set_param(self.U)
-                                                        self.b_h]))
+            self.b_regularizer.set_param(self.b)
-            x_h = K.dot(x * B_W[2], self.W_h) + self.b_h
+        if self.consume_less == 'gpu':
-        r = self.inner_activation(x_r + K.dot(h_tm1 * B_U[1], self.U_r))
+            x_h = matrix_x[:, 2 * self.output_dim:]
-        hh = self.activation(x_h + K.dot(r * h_tm1 * B_U[2], self.U_h))
+            hh = self.activation(x_h + K.dot(r * h_tm1 * B_U[2], self.U_h))
-import numpy as np
+    if isinstance(config, list):
-        as a Python dictionary.
+        as a Python list.
-from theano.sandbox import softsign as T_softsign
+try:
-    return T_softsign.softsign(x)
+    return T_softsign(x)
-consume_less='mem'.
+dropout is shared across the gates.
-from keras.layers import Embedding, BatchNormalization, Dense, LSTM
+from keras.layers import Embedding, Dense, LSTM
-batch_size = 256
+embedding_dim = 256
-    print("Testing mode: consume_less='{}'".format(mode))
+    print('Testing mode: consume_less="{}"'.format(mode))
-    model.add(LSTM(embedding, dropout_W=0.2, dropout_U=0.2, consume_less=mode))
+    model.add(Embedding(max_features, embedding_dim, input_length=max_length, dropout=0.2))
-    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
+    model.compile(loss='binary_crossentropy',
-    history = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_data=(X_test, y_test))
+    history = model.fit(X_train, y_train,
-ax1 = plt.subplot2grid((2,2), (0,0))
+ax1 = plt.subplot2grid((2, 2), (0, 0))
-ax2 = plt.subplot2grid((2,2), (1,0))
+ax2 = plt.subplot2grid((2, 2), (1, 0))
-ax3 = plt.subplot2grid((2,2), (0,1), rowspan=2)
+ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)
-ax3.bar(np.arange(len(results)), [x[1] for x in results], tick_label=modes, align='center')
+ax3.bar(np.arange(len(results)), [x[1] for x in results],
-        consume_less: one of "cpu", "mem", or "gpu" (LSTM only).
+        consume_less: one of "cpu", "mem", or "gpu".
-                  "dropout_U": self.dropout_U}
+        config = {'output_dim': self.output_dim,
-                  "dropout_U": self.dropout_U}
+        config = {'output_dim': self.output_dim,
-            self.W = self.init((self.input_dim, 4*self.output_dim),
+            self.W = self.init((self.input_dim, 4 * self.output_dim),
-            self.U = self.inner_init((self.output_dim, 4*self.output_dim),
+            self.U = self.inner_init((self.output_dim, 4 * self.output_dim),
-                  "dropout_U": self.dropout_U}
+        config = {'output_dim': self.output_dim,
-        consume_less: one of "cpu", "mem". If set to "cpu", the RNN will use
+        consume_less: one of "cpu", "mem", or "gpu" (LSTM only).
-            thus running faster (at least on CPU) but consuming more memory.
+            thus running faster on CPU but consuming more memory.
-        self.input_dim = input_dim
+        self.input_dim = input_shape[2]
-        self.b_o = K.zeros((self.output_dim,), name='{}_b_o'.format(self.name))
+        if self.consume_less == 'gpu':
-                                                        self.W_o]))
+            self.W_regularizer.set_param(self.W)
-                                                        self.U_o]))
+            self.U_regularizer.set_param(self.U)
-                                                        self.b_o]))
+            self.b_regularizer.set_param(self.b)
-            x_o = x[:, 3 * self.output_dim:]
+        if self.consume_less == 'gpu':
-        o = self.inner_activation(x_o + K.dot(h_tm1 * B_U[3], self.U_o))
+            if self.consume_less == 'cpu':
-            raise Exception('You must compile your model before using it.')
+            self.predict_function = None
-                                               **self._function_kwargs)
+                                               **kwargs)
-            raise Exception('The model needs to be compiled before being used.')
+            self.build()
-            raise Exception('The model needs to be compiled before being used.')
+def batch_get_value(xs):
-            if K.get_value(p).shape != w.shape:
+        param_values = K.batch_get_value(params)
-                                str(K.get_value(p).shape) +
+                                str(pv.shape) +
-        return weights
+        return K.batch_get_value(params)
-        return {"name": self.__class__.__name__}
+        config = {'name': self.__class__.__name__}
-                 *args, **kwargs):
+    def __init__(self, lr=0.01, momentum=0., decay=0.,
-                "nesterov": self.nesterov}
+        config = {'lr': float(K.get_value(self.lr)),
-    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-6, *args, **kwargs):
+    def __init__(self, lr=0.001, rho=0.9, epsilon=1e-6, **kwargs):
-                "epsilon": self.epsilon}
+        config = {'lr': float(K.get_value(self.lr)),
-    def __init__(self, lr=0.01, epsilon=1e-6, *args, **kwargs):
+    def __init__(self, lr=0.01, epsilon=1e-6, **kwargs):
-                "epsilon": self.epsilon}
+        config = {'lr': float(K.get_value(self.lr)),
-    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-6, *args, **kwargs):
+    def __init__(self, lr=1.0, rho=0.95, epsilon=1e-6, **kwargs):
-                "epsilon": self.epsilon}
+        config = {'lr': float(K.get_value(self.lr)),
-                 *args, **kwargs):
+    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,
-                "epsilon": self.epsilon}
+        config = {'lr': float(K.get_value(self.lr)),
-                 *args, **kwargs):
+    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,
-                "epsilon": self.epsilon}
+        config = {'lr': float(K.get_value(self.lr)),
-    def __init__(self, log_dir='./logs', histogram_freq=0):
+
-                                             self.sess.graph_def)
+        if self.write_graph:
-        regularized_loss += self.l2 * K.sum(K.mean(K.square(output), axis=0))
+        regularized_loss = loss
-            self.metrics_names = ['loss']
+        self.metrics_names = ['loss']
-                sample_weight_mode=None, multi_target_loss=False, **kwargs):
+                sample_weight_mode=None, **kwargs):
-        self.metrics_names = ['loss']
+        if len(self.outputs) > 1:
-            if multi_target_loss:
+            output_loss = weighted_loss(y_true, y_pred,
-                self.metrics_names.append('loss_'+self.output_names[i])
+                self.metrics_names.append(self.output_names[i] + '_loss')
-                total_loss = output_loss
+                total_loss = loss_weight * output_loss
-                total_loss += output_loss
+                total_loss += loss_weight * output_loss
-    assert len(out) == 3
+    assert len(out) == 5
-    assert len(out) == 3
+    assert len(out) == 5
-    assert len(out) == 2
+    assert len(out) == 4
-    assert len(out) == 2
+    assert len(out) == 4
-    assert len(out) == 2
+    assert len(out) == 4
-    assert len(out) == 2
+    assert len(out) == 4
-    assert len(out) == 3
+    assert len(out) == 5
-    assert len(out) == 3
+    assert len(out) == 5
-                 input_dim=None, input_length=None, **kwargs):
+                 bias=True, input_dim=None, input_length=None, **kwargs):
-        self.trainable_weights = [self.W, self.b]
+        if self.bias:
-        if self.b_regularizer:
+        if self.bias and self.b_regularizer:
-        if self.b_constraint:
+        if self.bias and self.b_constraint:
-        output = conv_out + K.reshape(self.b, (1, self.nb_filter, 1, 1))
+        output = K.conv2d(x, self.W, strides=self.subsample,
-                 W_constraint=None, b_constraint=None, **kwargs):
+                 W_constraint=None, b_constraint=None,
-        self.trainable_weights = [self.W, self.b]
+        if self.bias:
-        if self.b_regularizer:
+        if self.bias and self.b_regularizer:
-        if self.b_constraint:
+        if self.bias and self.b_constraint:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+        output = K.conv2d(x, self.W, strides=self.subsample,
-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None}
+                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,
-                 W_constraint=None, b_constraint=None, **kwargs):
+                 W_constraint=None, b_constraint=None,
-        self.regularizers = []
+        if self.bias:
-        if self.b_regularizer:
+        if self.bias and self.b_regularizer:
-        if self.b_constraint:
+        if self.bias and self.b_constraint:
-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)
+        output = K.conv3d(x, self.W, strides=self.subsample,
-                  "b_constraint": self.b_constraint.get_config() if self.b_constraint else None}
+        config = {'nb_filter': self.nb_filter,
-                 W_constraint=None, b_constraint=None, input_dim=None, bias=True, **kwargs):
+                 W_constraint=None, b_constraint=None,
-        if self.b_regularizer and self.bias:
+        if self.bias and self.b_regularizer:
-        if self.b_constraint and self.bias:
+        if self.bias and self.b_constraint:
-                  'bias': self.bias}
+                  'bias': self.bias,
-                 W_constraint=None, b_constraint=None, input_dim=None, **kwargs):
+                 W_constraint=None, b_constraint=None,
-                         name='{}_b'.format(self.name))
+        if self.bias:
-        if self.b_regularizer:
+        if self.bias and self.b_regularizer:
-        if self.b_constraint:
+        if self.bias and self.b_constraint:
-        output = K.max(K.dot(x, self.W) + self.b, axis=1)
+        output = K.dot(x, self.W)
-                 W_constraint=None, b_constraint=None, input_dim=None, **kwargs):
+                 W_constraint=None, b_constraint=None,
-        self.trainable_weights = [self.W, self.b, self.W_carry, self.b_carry]
+        if self.bias:
-        if self.b_regularizer:
+        if self.bias and self.b_regularizer:
-        if self.b_constraint:
+        if self.bias and self.b_constraint:
-        act = self.activation(K.dot(x, self.W) + self.b)
+        y = K.dot(x, self.W_carry)
-                 input_dim=None, input_length=None, **kwargs):
+                 bias=True, input_dim=None, input_length=None, **kwargs):
-        self.trainable_weights = [self.W, self.b]
+        if self.bias:
-        if self.b_regularizer:
+        if self.bias and self.b_regularizer:
-        if self.b_constraint:
+        if self.bias and self.b_constraint:
-        y = K.dot(x, self.W) + self.b  # (samples * timesteps, output_dim)
+        y = K.dot(x, self.W)  # (samples * timesteps, output_dim)
-__version__ = '1.0.1'
+__version__ = '1.0.2'
-      version='1.0.1',
+      version='1.0.2',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.1',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.2',
-                    raise e
+                    raise
-                raise e
+                raise
-                raise e
+                raise
-            raise e
+            raise
-                raise e
+                raise
-            os.mkdir(path)
+class TestImage:
-        im.save('test_images/rgb/rgb_test_image_'+str(n)+'.png')
+    def setup_class(cls):
-        im.save('test_images/gsc/gsc_test_image_'+str(n)+'.png')
+            imarray = np.random.rand(img_w, img_h, 1) * variance + bias
-    shutil.rmtree('test_images')
+    def teardown_class(cls):
-            img_list.append(img_to_array(load_img(f))[None, ...])
+            images = np.vstack(img_list)
-        generator.fit(images, augment=True)
+            tmp_folder = tempfile.mkdtemp(prefix='test_images')
-            break
+    def test_img_flip(self):
-                    (potentially_flipped_x == flip_axis(x, col_index)).all())
+        dim_ordering_and_col_index = (('tf', 2), ('th', 3))
-        
+
-        raise Exception('zoom_range should be a sequence of two. '
+        raise Exception('zoom_range should be a tuple or list of two floats. '
-                            'Receive arg: ', zoom_range)
+            raise Exception('zoom_range should be a float or '
-                img.save(os.path.join(self.save_to_dir, self.save_prefix + '_' + str(current_index + i) + '.' + self.save_format))
+                fname = '{prefix}_{index}.{format}'.format(prefix=self.save_prefix,
-        model = Sequential(Dense(32, input_dim=16))
+        model = Sequential()
-        model = Sequential(Dense(32, input_shape=(16,)))
+        model = Sequential()
-from os.path import isfile, join
+import os
-    transform_matrix = translation_matrix # no need to do offset
+    transform_matrix = translation_matrix  # no need to do offset
-    final_offset = transform_matrix[:2,2]
+    final_affine_matrix = transform_matrix[:2, :2]
-            if isfile(join(directory, f)) and re.match('([\w]+\.(?:' + ext + '))', f)]
+    return [os.path.join(directory, f) for f in os.listdir(directory)
-            in the range [1-z, 1+z]. A sequence of two can be passed instead 
+        zoom_range: amount of zoom. if scalar z, zoom will be randomly picked
-            given mode ('constant', 'nearest', 'reflect' or 'wrap'). Default 
+        fill_mode: points outside the boundaries are filled according to the
-                img.save(self.save_to_dir + '/' + self.save_prefix + '_' + str(current_index + i) + '.' + self.save_format)
+                img.save(os.path.join(self.save_to_dir, self.save_prefix + '_' + str(current_index + i) + '.' + self.save_format))
-            theta = np.pi/180*np.random.uniform(-self.rotation_range, self.rotation_range)
+            theta = np.pi / 180 * np.random.uniform(-self.rotation_range, self.rotation_range)
-        
+
-
+        x = apply_transform(x, transform_matrix, img_channel_index,
-        
+
-
+import scipy.ndimage as ndi
-from six.moves import range
+def random_rotation(x, rg, row_index=1, col_index=2, channel_index=0,
-                                     cval=cval)
+    h, w = x.shape[row_index], x.shape[col_index]
-                                    cval=cval)
+def random_shift(x, wrg, hrg, row_index=1, col_index=2, channel_index=0,
-    x = x.swapaxes(0, axis)
+    h, w = x.shape[row_index], x.shape[col_index]
-                                               cval=cval)
+    if zoom_range[0] == 1 and zoom_range[1] == 1:
-def random_channel_shift(x, rg):
+def random_barrel_transform(x, intensity):
-    return x  # shape of result will be different from shape of input!
+def transform_matrix_offset_center(matrix, x, y):
-def array_to_img(x, scale=True):
+def array_to_img(x, dim_ordering='th', scale=True):
-    x = x.transpose(1, 2, 0)
+    if dim_ordering == 'th':
-    else:
+    elif x.shape[2] == 1:
-def img_to_array(img):
+# only used by tests/keras/preprocessing/test_image.py to convert PIL.Image to numpy array
-        x = x.transpose(2, 0, 1)
+        if dim_ordering == 'th':
-        x = x.reshape((1, x.shape[0], x.shape[1]))
+        raise Exception('Unsupported image shape: ', x.shape)
-
+        zoom_range: amount of zoom. if scalar z, zoom will be randomly picked 
-            column) or "th" (channel before row and column). Received arg: ', dim_ordering)
+            raise Exception('dim_ordering should be "tf" (channel after row and '
-                img = array_to_img(bX[i], scale=True)
+                img = array_to_img(bX[i], self.dim_ordering, scale=True)
-            x -= np.mean(x, axis=self.channel_index, keepdims=True)
+            x -= np.mean(x, axis=img_channel_index, keepdims=True)
-            x /= (np.std(x, axis=self.channel_index, keepdims=True) + 1e-7)
+            x /= (np.std(x, axis=img_channel_index, keepdims=True) + 1e-7)
-        img_col_index = self.col_index - 1
+        img_col_index = self.col_index - 1
-                             row_index=img_row_index, col_index=img_col_index)
+            theta = np.pi/180*np.random.uniform(-self.rotation_range, self.rotation_range)
-            x = random_shear(x, self.shear_range)
+        
-        # zoom
+        # channel-wise normalization
-                    aX[i + r * X.shape[0]] = img_to_array(img)
+                    aX[i + r * X.shape[0]] = self.random_transform(X[i])
-            height_shift_range=10.,
+            width_shift_range=0.1,
-                 W_constraint=None, b_constraint=None, input_dim=None, **kwargs):
+                 W_constraint=None, b_constraint=None, input_dim=None, bias=True, **kwargs):
-
+        
-        self.trainable_weights = [self.W, self.b]
+        if self.bias:
-        if self.b_regularizer:
+        if self.b_regularizer and self.bias:
-        if self.b_constraint:
+        if self.b_constraint and self.bias:
-        return self.activation(K.dot(x, self.W) + self.b)
+        output = K.dot(x, self.W)
-                  'input_dim': self.input_dim}
+                  'input_dim': self.input_dim,
-                      '`tf.initialize_all_variables()`).')
+    if tf.get_default_graph() is get_session().graph:
-    '''Returns the TF session in use by the backend.
+    '''Returns the TF session to be used by the backend.
-            _SESSION = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=nb_thread, allow_soft_placement=True))
+            _SESSION = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=nb_thread,
-    '''Sets the TF session.
+    '''Sets the global TF session.
-    get_session().run(v.initializer)
+    try:
-            outputlabels = str(layer.output_shape)
+            try:
-                inputlabels = ''
+                inputlabels = 'multiple'
-                sample_weight_mode=None, **kwargs):
+                sample_weight_mode=None, multi_target_loss=False, **kwargs):
-def cos(x)
+def cos(x):
-def cos(x)
+def cos(x):
-    # TODO: legacy support?
+import numpy as np
-                          K.argmax(y_pred, axis=-1)))
+                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())))
-test_ids = np.where(y_test == np.array(weighted_class))[0]
+def get_data():
-We need to specify two methods: `output_shape` and `get_output`.
+We need to specify two methods: `get_output_shape_for` and `call`.
-            m = K.variable(np.zeros(K.get_value(p).shape))  # momentum
+        # momentum
-    from keras.layers import Input, merge
+    from keras.layers import Input, merge, Merge
-            constants.append([K.cast_to_floatx(1.) for _ in range(4)])
+            constants.append([K.cast_to_floatx(1.) for _ in range(3)])
-            constants.append([K.cast_to_floatx(1.) for _ in range(4)])
+            constants.append([K.cast_to_floatx(1.) for _ in range(3)])
-                        # case: categorical accuracy
+                        # case: categorical accuracy with dense targets
-branch_pool = conv2D_bn(branch_pool, 32, 1, 1)
+branch_pool = conv2D_bn(branch_pool, 64, 1, 1)
-branch7x7dbl = conv2D_bn(branch7x7dbl, 128, 1, 7)
+branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)
-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)
+branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 1, 7)
-branch7x7dbl = conv2D_bn(branch7x7dbl, 192, 1, 7)
+branch7x7dbl = conv2D_bn(branch7x7dbl, 160, 1, 7)
-branch3x3 = conv2D_bn(branch3x3, 192, 3, 3, subsample=(2, 2), border_mode='valid')
+branch3x3 = conv2D_bn(branch3x3, 320, 3, 3, subsample=(2, 2), border_mode='valid')
-    for mode in ['sum', 'mul', 'concat', 'ave', 'cos', 'dot']:
+    # test functional API
-        merged = merge([input_a, input_b], mode='sum')
+        merged = merge([input_a, input_b], mode=mode)
-    '''expects a 1-D or 2-D array of integer classes.
+    '''expects an array of integer classes.
-        depth_keys = list(nodes_by_depth.keys())
+        # get sorted list of layer depths
-                output, states = step_function(inputs[i], states)
+                output, states = step_function(inputs[i], states + constants)
-        self.layer.build(child_input_shape)
+        if not self.layer.built:
-            raise Exception('A Merge should only be applied to a list of layers. Not a list: ' + str(layers))
+            raise Exception('A Merge should only be applied to a list of '
-        tensor_indices = []
+
-        self.add_inbound_node(layers, node_indices, tensor_indices)
+            if not hasattr(x, '_keras_history'):
-    tensor_indices = []
+    all_keras_tensors = True
-    return merge_layer.inbound_nodes[0].output_tensors[0]
+        if not hasattr(x, '_keras_history'):
-        if loss.__name__ in key_losses and y.shape[1] != shape[1]:
+        if loss.__name__ in key_losses and shape[1] is not None and y.shape[1] != shape[1]:
-
+                    if seed is not None:
-            if current_batch_size == batch_size:
+                current_batch_size = N - current_index
-            y = self.layer.call(X)  # (nb_samples * timesteps, ...)
+            X = K.reshape(X, (-1, ) + input_shape[2:])  # (nb_samples * timesteps, ...)
-    if len(set_x) != 1:
+    if len(set_y) != 1:
-                 featurewise_center=True,
+                 featurewise_center=False,
-                 featurewise_std_normalization=True,
+                 featurewise_std_normalization=False,
-            if b == 0:
+            if self.batch_index == 0:
-                    np.random.seed(seed + total_b)
+                    np.random.seed(seed + self.total_batches_seen)
-            current_index = (b * batch_size) % N
+            current_index = (self.batch_index * batch_size) % N
-                b += 1
+                self.batch_index += 1
-            total_b += 1
+                self.batch_index = 0
-                output, new_states = step_function(inputs[i], states)
+                output, new_states = step_function(inputs[i], states + constants)
-                                    '%s != %s. ' % (shape1[dot_axes[0]], shape2[dot_axes[1][i]]) +
+                                    '%s != %s. ' % (shape1[dot_axes[0]], shape2[dot_axes[1]]) +
-__version__ = '1.0.0'
+__version__ = '1.0.1'
-      version='1.0.0',
+      version='1.0.1',
-      download_url='https://github.com/fchollet/keras/tarball/1.0.0',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.1',
-        if self.histogram_freq and not self.merged:
+        if self.histogram_freq and self.merged is None:
-            B_U = [K.dropout(ones, self.dropout_U) for _ in range(3)]
+            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(3)]
-        if self.consume_less == 'cpu' and 0 < self.dropout_W < 1:
+        if 0 < self.dropout_W < 1:
-            B_W = [K.dropout(ones, self.dropout_W) for _ in range(3)]
+            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones) for _ in range(3)]
-    def preprocess_input(self, x, train=False):
+    def preprocess_input(self, x):
-            if train and (0 < self.dropout_W < 1):
+            if 0 < self.dropout_W < 1:
-            B_U = [K.dropout(ones, self.dropout_U) for _ in range(4)]
+            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(4)]
-        if self.consume_less == 'cpu' and 0 < self.dropout_W < 1:
+        if 0 < self.dropout_W < 1:
-            B_W = [K.dropout(ones, self.dropout_W) for _ in range(4)]
+            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones) for _ in range(4)]
-            K.set_value(p, w)
+            weight_value_tuples.append((p, w))
-                    flattened_layers[k].set_weights(weights)
+                    weight_values = [g[weight_name] for weight_name in weight_names]
-    #                                   strides=(1, 1), border_mode='valid')
+    def test_conv2d(self):
-                                name + '". Input data keys: ' +
+                raise Exception('No data provided for "' +
-        return (input_shape[0], self.input_length, self.output_dim)
+        if not self.input_length:
-def random_rotation(x, rg, fill_mode='nearest', cval=0., axes=(1,2)):
+def random_rotation(x, rg, fill_mode='nearest',
-def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0., row_index=1, col_index=2):
+def random_shift(x, wrg, hrg, fill_mode='nearest',
-    x = x[::-1,...]
+    x = x[::-1, ...]
-    os.mkdir('test_images/gsc')
+    paths = ['test_images', 'test_images/rgb', 'test_images/gsc']
-    x = np.array(range(4)).reshape([1,1,2,2])
+    x = np.array(range(4)).reshape([1, 1, 2, 2])
-                   (potentially_flipped_x==flip_axis(x, col_index)).all()
+            assert ((potentially_flipped_x == x).all() or
-Gets to 0.835 test accuracy after 2 epochs. 100s/epoch on K520 GPU.
+Gets to 0.88 test accuracy after 2 epochs. 
-from keras.layers.core import Dense, Dropout, Activation, Flatten
+from keras.layers.core import Dense, Dropout, Activation, Lambda
-from keras.layers.convolutional import Convolution1D, MaxPooling1D
+from keras.layers.convolutional import Convolution1D
-maxlen = 100
+maxlen = 400
-embedding_dims = 100
+embedding_dims = 50
-model.add(Dropout(0.25))
+model.add(Embedding(max_features,
-model.add(Flatten())
+# we use max over time pooling by defining a python function to use
-model.add(Dropout(0.25))
+model.add(Dropout(0.2))
-              optimizer='rmsprop',
+              optimizer='adam',
-                      class_weight={}, **kwargs):
+                      class_weight={},
-                                                   class_weight=class_weight)
+                                                   class_weight=class_weight,
-                           verbose=1, **kwargs):
+                           verbose=1, max_q_size=10, **kwargs):
-                                                        val_samples)
+                                                        val_samples,
-    gen_loss = graph.evaluate_generator(data_generator_graph(True), 128, verbose=0)    
+    gen_loss = graph.evaluate_generator(data_generator_graph(True), 128, verbose=0)
-                                     self.model.validation_data))
+                if self.model.uses_learning_phase:
-@pytest.mark.skipif((K._BACKEND != 'tensorflow') or (sys.version_info[0] == 3),
+@pytest.mark.skipif((K._BACKEND != 'tensorflow'),
-    test_TensorBoard()
+    pytest.main([__file__])
-    Used in `fit_generator`, `evaluate_generator`.
+    Used in `fit_generator`, `evaluate_generator`, `predict_generator`.
-                      class_weight={}):
+                      class_weight={}, max_q_size=10):
-        data_gen_queue, _stop = generator_queue(generator)
+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)
-                                                           nb_val_samples)
+                                                           nb_val_samples,
-    def evaluate_generator(self, generator, val_samples):
+    def evaluate_generator(self, generator, val_samples, max_q_size=10):
-        data_gen_queue, _stop = generator_queue(generator)
+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)
-    def predict_generator(self, generator, val_samples):
+    def predict_generator(self, generator, val_samples, max_q_size=10):
-        data_gen_queue, _stop = generator_queue(generator)
+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)
-                      **kwargs):
+                      class_weight=None, max_q_size=10, **kwargs):
-                                        class_weight=class_weight)
+                                        class_weight=class_weight,
-                           **kwargs):
+    def evaluate_generator(self, generator, val_samples, max_q_size=10, **kwargs):
-                                             val_samples)
+                                             val_samples,
-    def predict_generator(self, generator, val_samples):
+    def predict_generator(self, generator, val_samples, max_q_size=10):
-        return self.model.predict_generator(generator, val_samples)
+        return self.model.predict_generator(generator, val_samples,
-    gen_loss = model.evaluate_generator(data_generator(X_test, y_test, 50), X_test.shape[0])
+    prediction = model.predict_generator(data_generator(X_test, y_test), X_test.shape[0], max_q_size=2)
-            trainable_weights_set = set()
+            # get trainable weights
-                    trainable_weights.append(w)
+            for layer in self.layers:
-distance = Lambda(euclidean_distance)([processed_a, processed_b])
+distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])
-
+        # prepare input arrays and training function
-def random_rotation(x, rg, fill_mode='nearest', cval=0.):
+def random_rotation(x, rg, fill_mode='nearest', cval=0., axes=(1,2)):
-                                     axes=(1, 2),
+                                     axes=axes,
-def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0.):
+def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0., row_index=1, col_index=2):
-        shift_x = np.random.uniform(-wrg, wrg) * x.shape[2]
+        shift_x = np.random.uniform(-wrg, wrg) * x.shape[col_index]
-        shift_y = np.random.uniform(-hrg, hrg) * x.shape[1]
+        shift_y = np.random.uniform(-hrg, hrg) * x.shape[row_index]
-        x[i] = np.fliplr(x[i])
+def flip_axis(x, axis):
-
+        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension
-                 vertical_flip=False):
+                 vertical_flip=False,
-            x -= np.mean(x, axis=1, keepdims=True)
+            x -= np.mean(x, axis=self.channel_index, keepdims=True)
-            x /= (np.std(x, axis=1, keepdims=True) + 1e-7)
+            x /= (np.std(x, axis=self.channel_index, keepdims=True) + 1e-7)
-            flatx = np.reshape(x, (x.shape[0] * x.shape[1] * x.shape[2]))
+            flatx = np.reshape(x, (x.size))
-            x = random_rotation(x, self.rotation_range)
+            x = random_rotation(x, self.rotation_range,
-            x = random_shift(x, self.width_shift_range, self.height_shift_range)
+            x = random_shift(x, self.width_shift_range, self.height_shift_range,
-                x = horizontal_flip(x)
+                x = flip_axis(x, img_col_index)
-                x = vertical_flip(x)
+                x = flip_axis(x, img_row_index)
-        callbacks._set_model(self)
+        # it's possible to callback a different model than self
-            if self.stop_training:
+            if callback_model.stop_training:
-        callbacks._set_model(self)
+        # it's possible to callback a different model than self:
-        self.stop_training = False
+        callback_model.stop_training = False
-            if self.stop_training:
+            if callback_model.stop_training:
-           self._delta_t_batch and delta_t_median > 0.1:
+        if self._delta_t_batch > 0. and (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):
-        self.uses_learning_phase = True
+        if 0. < self.p < 1.:
-        # self.input_sepc with a complete input shape.
+        # self.input_spec with a complete input shape.
-        self.constraints = [self.W_constraint]
+
-                              metrics=['acccuracy'])
+                              metrics=['accuracy'])
-    y = np.asarray(y, dtype='int32')
+        if self.model is None:
-
+        if self.model is None:
-            updates = self.state_updates + self.updates + training_updates
+            updates = self.updates + training_updates
-            predict_inputs = self.inputs
+        self.total_loss = total_loss
-        self._predict_inputs = predict_inputs
+            if self.uses_learning_phase:
-                                             updates=self._train_updates,
+            self.train_function = K.function(inputs,
-                                            self._all_outputs,
+            # Does update the network states.
-            self.predict_function = K.function(self._predict_inputs,
+            self.predict_function = K.function(inputs,
-            self.W_regularizer.set_param(self.U)
+            self.U_regularizer.set_param(self.U)
-            self.W_regularizer.set_param(self.b)
+            self.b_regularizer.set_param(self.b)
-              optimizer=Adam(),
+              optimizer=RMSprop(),
-                                str(x.name))
+                warnings.warn(cls_name + ' inputs must come from '
-def get_source_inputs(tensor, layer=None, node_index=None, tensor_index=None):
+def get_source_inputs(tensor, layer=None, node_index=None):
-    layer, node_index, tensor_index = tensor._keras_history
+    if layer is None or node_index:
-                                                     tensor_index)
+                                                     node_index)
-    Note that `expression` should have the *same shape* as `x`.
+def in_train_phase(x, alt):
-                                        lambda: expression)
+                                        lambda: alt)
-    Note that `expression` should have the *same shape* as `x`.
+def in_test_phase(x, alt):
-                                        lambda: expression,
+                                        lambda: alt,
-    x = T.switch(_LEARNING_PHASE, x, expression)
+def in_train_phase(x, alt):
-    x = T.switch(_LEARNING_PHASE, expression, x)
+def in_test_phase(x, alt):
-from keras.layers.recurrent import SimpleRNN, LSTM
+from keras.layers.recurrent import SimpleRNN
-                    inner_init=lambda shape: identity(shape, scale=1.0),
+                    init=lambda shape, name: normal(shape, scale=0.001, name=name),
-    def train_on_batch(self, x, y, sample_weight=None, class_weight=None):
+    def train_on_batch(self, x, y,
-        wait_time = 0.05  # in seconds
+        wait_time = 0.01  # in seconds
-                batch_size = len(x[0])
+                if type(x) is list:
-                    if type(val_outs) != list:
+                    if type(val_outs) is not list:
-        wait_time = 0.05
+        wait_time = 0.01
-            nb_samples = len(x[0])
+            if type(x) is list:
-        wait_time = 0.05
+        wait_time = 0.01
-            nb_samples = len(x[0])
+            if type(x) is list:
-            inbound_layer: can be a layer instance
+            inbound_layers: can be a layer instance
-            node_index: integer (or list of integers).
+            node_indices: integer (or list of integers).
-            tensor_index: integer or list of integers.
+            tensor_indices: integer or list of integers.
-    A None entry in a shaple is compatible with any dimension,
+    A None entry in a shape is compatible with any dimension,
-        self.alpha = K.cast_to_floatx(alpha)
+        self.alpha = alpha
-               input_data=None, expected_output=None):
+               input_data=None, expected_output=None, expected_output_dtype=None):
-               input_dtype='int32')
+               input_dtype='int32',
-def get_function_signature(function):
+def get_function_signature(function, method=True):
-    args = signature.args[1:]
+    if method:
-            if inspect.isclass(module_member):
+            if inspect.isfunction(module_member):
-                if function.__module__ == module.__name__:
+                if module.__name__ in function.__module__:
-        signature = get_function_signature(function)
+        signature = get_function_signature(function, method=False)
-        subblocks.append('### ' + function.im_class.__name__ + '.' + function.__name__ + '\n')
+        subblocks.append('### ' + function.__name__ + '\n')
-        blocks.append('\n\n'.join(subblocks))
+            blocks.append('\n\n'.join(subblocks))
-    # Arguments:
+    # Arguments
-    # Returns:
+    # Returns
-                the step function, of shape (samples, ...).
+
-                See [optimizers](optimizers.md).
+                See [optimizers](/optimizers).
-                See [objectives](objectives.md).
+                See [objectives](/objectives).
-                See [callbacks](callbacks.md).
+                See [callbacks](/callbacks).
-    '''Masks an input sequence by using a mask value to identify padding.
+    '''Masks an input sequence by using a mask value to
-    replaced with 0s and creates an output mask in the process.
+    For each timestep in the input tensor (dimension #1 in the tensor),
-    otherwise it is 1.
+    If any downstream layer does not support masking yet receives such
-                See [optimizers](optimizers.md).
+                See [optimizers](/optimizers).
-                See [objectives](objectives.md).
+                See [objectives](/objectives).
-                See [callbacks](callbacks.md).
+                See [callbacks](/callbacks).
-                child_layers = layer.outputs.values()
+    raise RuntimeError('Failed to import pydot. You must install pydot'
-    graph.write_png(to_file)
+                inputlabels = ''
-from keras.layers import containers
+from keras.layers import wrappers
-    signature = inspect.getargspec(method)
+def get_function_signature(function):
-    st = '%s.%s(' % (method.__module__, method.__name__)
+    st = '%s.%s(' % (function.__module__, function.__name__)
-def process_method_docstring(docstring):
+def process_function_docstring(docstring):
-    module_page = '\n----\n\n'.join(class_pages)
+for page_data in PAGES:
-    path = 'sources/' + module_name.replace('.', '/')[6:] + '.md'
+    page_name = page_data['page']
-        module_page = template.replace('{{autogenerated}}', module_page)
+        mkdown = template.replace('{{autogenerated}}', mkdown)
-    open(path, 'w').write(module_page)
+    open(path, 'w').write(mkdown)
-                                           **kwargs)
+        # functions for train, test and predict will
-    # False = test, True = train
+    '''Returns the learning phase flag.
-    # symbolic shape
+    '''Returns the symbolic shape of a tensor.
-    '''Run a graph.
+    '''Evaluates the value of a tensor.
-
+    '''Instantiates an all-zeros tensor
-    '''Return number of scalars in a tensor.
+    '''Returns the number of scalars in a tensor.
-    '''batchwise dot product
+    '''Batchwise dot product.
-    '''
+    '''Retrieves the vectors of indices `indices`
-        reference: a tensor.
+        reference: a 2D tensor.
-        a tensor of same type as `reference`.
+        A 3D tensor of same type as `reference`.
-def normalize_axis(axis, ndim):
+def _normalize_axis(axis, ndim):
-    axis = normalize_axis(axis, ndim(x))
+    '''Maximum value in a tensor.
-    axis = normalize_axis(axis, ndim(x))
+    '''Minimum value in a tensor.
-    axis = normalize_axis(axis, ndim(x))
+    axis = _normalize_axis(axis, ndim(x))
-    '''Multiply the values in a tensor, alongside the specified axis.
+    '''Multiplies the values in a tensor, alongside the specified axis.
-    axis = normalize_axis(axis, ndim(x))
+    axis = _normalize_axis(axis, ndim(x))
-    axis = normalize_axis(axis, ndim(x))
+    '''Standard deviation of a tensor, alongside the specificied axis.
-    axis = normalize_axis(axis, ndim(x))
+    '''Mean of a tensor, alongside the specificied axis.
-    Return array of uint8 (0s and 1s).
+    Returns an uint8 tensor (0s and 1s).
-    axis = normalize_axis(axis, ndim(x))
+    axis = _normalize_axis(axis, ndim(x))
-    '''Transpose dimensions.
+    '''Permutes axes in a tensor.
-            dimension indices, e.g. [0, 2, 1].
+        pattern: should be a tuple of
-    '''Resize the images contained in a 4D tensor of shape
+    '''Resizes the images contained in a 4D tensor of shape
-    '''Repeat a 2D tensor:
+    '''Repeats a 2D tensor:
-    '''Add a 1-sized dimension at index "dim".
+    '''Adds a 1-sized dimension at index "dim".
-    '''Remove a 1-dimension from the tensor at index "axis".
+    '''Removes a 1-dimension from the tensor at index "axis".
-    '''Pad the middle dimension of a 3D tensor
+    '''Pads the middle dimension of a 3D tensor
-    '''Pad the 2nd and 3rd dimensions of a 4D tensor
+    '''Pads the 2nd and 3rd dimensions of a 4D tensor
-    '''Technically the same as eval() for TF.
+    '''Returns the value of a tensor variable,
-            does do anything for the time being.
+        unroll: with TensorFlow the RNN is always unrolled, but with Theano you
-    '''Switch between two operations depending on a scalar value (int or bool).
+    '''Switches between two operations depending on a scalar value (int or bool).
-    '''ReLU.
+    '''Rectified linear unit
-    expects logits, Keras expects probabilities.
+    '''Categorical crossentropy between an output tensor
-    expects logits, Keras expects probabilities.
+    '''Categorical crossentropy between an output tensor
-    expects logits, Keras expects probabilities.
+    '''Binary crossentropy between an output tensor and a target tensor.
-    '''Runs on cuDNN if available.
+    '''2D convolution.
-        dim_ordering: whether to use Theano or TensorFlow dimension ordering
+        dim_ordering: "tf" or "th". Whether to use Theano or TensorFlow dimension ordering
-    '''
+    '''2D Pooling.
-model.add(Dropout(0.5))
+model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.2))
-            ins = x + y + sample_weights + [1.]
+            ins = x + y + sample_weights + [0.]
-            ins = x + [1.]
+            ins = x + [0.]
-            seen_nodes.add(node)
+            seen_nodes.add(make_node_key(node, depth))
-                    build_map_of_graph(x, copy.copy(seen_nodes), depth + 1,
+                next_node = layer.inbound_nodes[node_index]
-            build_map_of_graph(x, seen_nodes=set(), depth=0)
+            seen_nodes = set()
-            if node not in nodes_depths:
+            node_depth = nodes_depths.get(node)
-                nodes_depths[node] = max(depth, nodes_depths[node])
+                nodes_depths[node] = max(depth, node_depth)
-            if layer not in layers_depths:
+            layer_depth = layers_depths.get(layer)
-                layers_depths[layer] = max(depth, layers_depths[layer])
+                layers_depths[layer] = max(depth, layer_depth)
-                                   layer, node_index, tensor_index)
+                if not layer.inbound_nodes[node_index] in seen_nodes:
-        '''Generate predictions for the input samples from a data generator.
+        '''Generates predictions for the input samples from a data generator.
-                total number of samples to generate from `generator`
+        # Arguments
-            A Numpy array of predictions.
+            Numpy array(s) of predictions.
-        '''Generate predictions for the input samples from a data generator.
+        '''Generates predictions for the input samples from a data generator.
-                total number of samples to generate from `generator`
+        # Arguments
-    # Arguments:
+    # Arguments
-    # Arguments:
+    # Arguments
-    # Arguments:
+    # Arguments
-    # References:
+    # References
-    Do not use in a model -- it's not a functional layer!
+    Do not use in a model -- it's not a valid layer!
-    All recurrent layers (GRU, LSTM, SimpleRNN) also
+    All recurrent layers (`LSTM`, `GRU`, `SimpleRNN`) also
-                list of metrics functions. See [metrics](metrics.md).
+            metrics: list of metrics to be evaluated by the model
-        i = 0
+    def data_generator(x, y, batch_size=50):
-            i = i % max_batch_index
+            batches = make_batches(len(X_test), batch_size)
-    gen_loss = model.evaluate_generator(data_generator(True), 256)
+    prediction = model.predict_generator(data_generator(X_test, y_test), X_test.shape[0])
-        input_shape = shape
+        input_shape = tuple(shape)
-    recreated_model = Model.from_config(model_config)
+    json_config = model.to_json()
-        cast(flatten(target), 'int32'))
+        cast(flatten(target), 'int64'))
-        for layer in self.input_layers:
+        for layer in getattr(self, 'input_layers', []):
-    test_srelu()
+    pytest.main([__file__])
-    with a 3D tensor, reproduces the Theano behavior
+    When attempting to multiply a ND tensor
-        return out
+    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):
-        return {"name": self.__class__.__name__}
+        return {'name': self.__class__.__name__}
-                "axis": self.axis}
+        return {'name': self.__class__.__name__,
-                "axis": self.axis}
+        return {'name': self.__class__.__name__,
-                                        str(ndim) + ' found ndim=' +
+                                        str(ndim) + ', found ndim=' +
-                                        str(spec.ndim), ' found ndim=' +
+                                        str(spec.ndim) + ', found ndim=' +
-                                    str(spec.dtype), ' found dtype=' +
+                                    str(spec.dtype) + ', found dtype=' +
-        # raise exceptions in case the input is not compatible with the layer
+        # raise exceptions in case the input is not compatible
-'''
+def check_loss_and_target_compatibility(targets, losses, output_shapes):
-    (or timestep-wise) weight array.
+    '''Performs weight input validation and standardization
-        for y, shape, name in zip(self.outputs, self.internal_output_shapes, self.output_names):
+        for i in range(len(self.outputs)):
-        '''
+        '''Trains the model for a fixed number of epochs (iterations on a dataset).
-            TODO
+            x: Numpy array of test data,
-        '''
+        '''Runs a single gradient update on a single batch of data.
-        '''
+        '''Test the model on a single batch of samples.
-    `f(x) = alpha*x for x < 0`.
+    `f(x) = alpha * x for x < 0`,
-    '''Parametric Rectified Linear Unit.
+    '''Parametric Rectified Linear Unit:
-    # References:
+    # References
-    '''Exponential Linear Unit.
+    '''Exponential Linear Unit:
-    '''Parametric Softplus of the form: alpha * log(1 + exp(beta * X))
+    '''Parametric Softplus:
-    # References:
+    # References
-    '''Thresholded Rectified Linear Unit.
+    '''Thresholded Rectified Linear Unit:
-        [Zero-Bias Autoencoders and the Benefits of Co-Adapting Features](http://arxiv.org/pdf/1402.3337.pdf)
+        - [Zero-Bias Autoencoders and the Benefits of Co-Adapting Features](http://arxiv.org/pdf/1402.3337.pdf)
-        [Deep Learning with S-shaped Rectified Linear Activation Units](http://arxiv.org/abs/1512.07030)
+        - [Deep Learning with S-shaped Rectified Linear Activation Units](http://arxiv.org/abs/1512.07030)
-        3D tensor with shape: `(samples, steps, input_dim)`.
+    # Example
-        `steps` value might have changed due to padding.
+    ```python
-        `(samples, rows, cols, channels)` if dim_ordering='tf'.
+    # Examples
-        `rows` and `cols` values might have changed due to padding.
+    ```python
-
+
-
+
-            (the depth) is at index 1, in 'tf' mode is it at index 3.
+    # Arguments
-            (the depth) is at index 1, in 'tf' mode is it at index 3.
+    # Arguments
-            (the depth) is at index 1, in 'tf' mode is it at index 4.
+    # Arguments
-            (the depth) is at index 1, in 'tf' mode is it at index 4.
+    # Arguments:
-        length: integer. Upsampling factor.
+    # Arguments
-            is at index 1, in 'tf' mode is it at index 3.
+    # Arguments
-            is at index 1, in 'tf' mode is it at index 4.
+    # Arguments
-            the padding dimension (axis 1).
+    # Arguments
-            the 2 padding dimensions (axis 3 and 4).
+    # Arguments
-            the 3 padding dimensions (axis 3, 4 and 5).
+
-    '''Repeat the input n times.
+    '''Repeats the input n times.
-
+
-        2D tensor with shape: `(nb_samples, sequence_length)`.
+    # Example
-        3D tensor with shape: `(nb_samples, sequence_length, output_dim)`.
+    ```python
-        sigma: float, standard deviation of the noise distribution.
+    # Input shape
-
+
-                    - merge them
+        '''Returns the model configuration
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-    angle = random.uniform(-rg, rg)
+    angle = np.random.uniform(-rg, rg)
-        shift_x = random.uniform(-wrg, wrg) * x.shape[2]
+        shift_x = np.random.uniform(-wrg, wrg) * x.shape[2]
-        shift_y = random.uniform(-hrg, hrg) * x.shape[1]
+        shift_y = np.random.uniform(-hrg, hrg) * x.shape[1]
-    shear = random.uniform(-intensity, intensity)
+    shear = np.random.uniform(-intensity, intensity)
-    zoom_h = random.uniform(1.-rg, 1.)
+    zoom_w = np.random.uniform(1.-rg, 1.)
-            if random.random() < 0.5:
+            if np.random.random() < 0.5:
-            if random.random() < 0.5:
+            if np.random.random() < 0.5:
-                                    subsample=strides)
+    if border_mode == 'same':
-                                shift_y: shift_y + expected_height]
+        raise Exception('Border mode not supported: ' + str(border_mode))
-out = model.predict([input_a_np, input_b_np])
+def test_model_methods():
-                function = marshal.dumps(self.function.__code__)
+                function = marshal.dumps(self.function.__code__).decode('raw_unicode_escape')
-                function = marshal.dumps(self.function.func_code)
+                function = marshal.dumps(self.function.func_code).decode('raw_unicode_escape')
-            function = marshal.loads(config['function'])
+            function = marshal.loads(config['function'].encode('raw_unicode_escape'))
-__version__ = '0.3.2'
+__version__ = '1.0.0'
-      version='0.3.2',
+      version='1.0.0',
-      download_url='https://github.com/fchollet/keras/tarball/0.3.2',
+      download_url='https://github.com/fchollet/keras/tarball/1.0.0',
-                   output_shape=lambda (s1, s2): (s1[:-1],) + (s1[-1] + s2[-1],))
+                   mode=lambda tup: K.concatenate([tup[0], tup[1]]),
-    def fn_mode((x, y)):
+    def fn_mode(tup):
-    def fn_output_shape((s1, s2)):
+    def fn_output_shape(tup):
-            '" should return one mask tensor per output tensor of the layer. Found: ' + str(output_masks))
+        if not output_tensors or output_tensors[0] is None:
-                            ': expected ndim >= ' + str(ndim), ' found ndim=' + str(K.ndim(x)))
+                    if K.ndim(x) < ndim:
-                            ': expected ndim=' + str(spec.ndim), ' found ndim=' + str(K.ndim(x)))
+                    if K.ndim(x) != spec.ndim:
-
+                if K.dtype(x) != spec.dtype:
-                                ': expected shape=' + str(spec.shape) + ', found shape=' + str(x_shape))
+                        if spec_dim != dim:
-            'hence the notion of "layer output" is ill-defined. Use `get_output_at(node_index)` instead.')
+        if len(self.inbound_nodes) != 1:
-            'hence the notion of "layer input mask" is ill-defined. Use `get_input_mask_at(node_index)` instead.')
+        if len(self.inbound_nodes) != 1:
-            'hence the notion of "layer output mask" is ill-defined. Use `get_output_mask_at(node_index)` instead.')
+        if len(self.inbound_nodes) != 1:
-    assert len(set_x) == 1, 'All input arrays (x) should have the same number of samples.'
+    if len(set_x) != 1:
-    assert len(set_x) == 1, 'All target arrays (y) should have the same number of samples.'
+    if len(set_x) != 1:
-            ' target samples.')
+    if len(set_w) != 1:
-            str(len(params)) + ' optimizer params vs. ' + str(len(weights)) + ' provided weights)')
+        if len(params) != len(weights):
-from keras.models import Graph, Sequential #, model_from_json, model_from_yaml
+from keras.models import Graph, Sequential
-    decay, and Nesterov momentum.
+    learning rate decay, and Nesterov momentum.
-    at their default values.
+    at their default values
-        lr: float >= 0. Learning rate. It is recommended to leave it at the default value.
+        lr: float >= 0. Learning rate.
-                                   axes=((2,), (2,)))
+                                   axes=(2, 2))
-            all_attrs += getattr(layer, attr)
+            all_attrs += getattr(layer, attr, [])
-            layer_dict = getattr(layer, attr)
+            layer_dict = getattr(layer, attr, {})
-from keras.layers import wrappers
+from keras.layers import wrappers, Input
-from keras.models import Sequential, model_from_json
+from keras.models import Sequential, Model, model_from_json
-        f.attrs['layer_names'] = [layer.name for layer in flattened_layers]
+        for layer in flattened_layers:
-                weight_names.append(name)
+                weight_names.append(name.encode('utf8'))
-            layer_names = f.attrs['layer_names']
+            layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]
-                weight_names = g.attrs['weight_names']
+                weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]
-        return any([layer.uses_learning_phase for layer in self.layers])
+        layers_learning_phase = any([layer.uses_learning_phase for layer in self.layers])
-                regularizers.l1(),
+    for reg in [regularizers.l1(),
-                dot_axes=[(2,), (2,)]))
+                dot_axes=[2, 2]))
-        adj_y = True if axes[1][0] == ndim(y) - 1 else None
+    '''batchwise dot product
-    return tf.batch_matmul(x, y, adj_x=adj_x, adj_y=adj_y)
+    out = tf.batch_matmul(x, y, adj_x=adj_x, adj_y=adj_y)
-    return T.batched_tensordot(x, y, axes=axes)
+        axes = [x.ndim - 1, y.ndim - 2]
-                        dot_axes = [range(dot_axes % n1, n1), range(dot_axes % n2, n2)]
+                        dot_axes = [dot_axes % n1, dot_axes % n2]
-                        dot_axes = [range(n1 - dot_axes, n2), range(1, dot_axes + 1)]
+                        dot_axes = [n1 - dot_axes, n2-dot_axes]
-                                        'Layer shapes: %s, %s' % (shape1, shape2))
+                if type(dot_axes[0]) is not int or type(dot_axes[1]) is not int:
-                dot_axes.append([index-1 for index in axes])
+            dot_axes = [a-1 for a in self.dot_axes]
-    model.add(Merge([left, right], mode='dot', dot_axes=([1], [1])))
+    model.add(Merge([left, right], mode='dot', dot_axes=[1, 1]))
-from keras.models import Sequential, slice_X
+from keras.models import Sequential
-        train_updates = self.optimizer.get_updates(self.trainable_weights,
+        # dedupe trainable weights
-    assert _floatx in {'float32', 'float64'}
+    assert _floatx in {'float16', 'float32', 'float64'}
-    (e.g. 'float32', 'float64').
+    (e.g. 'float16', 'float32', 'float64').
-    if floatx not in {'float32', 'float64'}:
+    if floatx not in {'float16', 'float32', 'float64'}:
-                      input_length=story_maxlen, mask_zero=True))
+                      input_length=story_maxlen))
-qrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, input_length=query_maxlen))
+qrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,
-        return loss
+        regularized_loss = loss + K.sum(K.abs(self.p)) * self.l1
-def get_source_inputs(tensor):
+def get_source_inputs(tensor, layer=None, node_index=None, tensor_index=None):
-                previous_sources = get_source_inputs(x)
+            for i in range(len(node.inbound_layers)):
-        axes = [(x.ndim-1,), (y.ndim-2,)]
+        axes = [(x.ndim - 1,), (y.ndim - 2,)]
-            for i in range(1, len(self.layers)):
+            for i in range(1, len(inputs)):
-                s /= len(self.layers)
+                s /= len(inputs)
-            for i in range(1, len(self.layers)):
+            for i in range(1, len(inputs)):
-            return self._output_shape_cache[cache_key]
+            output_shapes = self._output_shape_cache[cache_key]
-    pass
+    def fn_mode((x, y)):
-                sample_weight_mode=None,
+                sample_weight_modes=None,
-                                   sample_weight_mode=sample_weight_mode,
+                                   sample_weight_mode=sample_weight_modes,
-        if self.model.loss.__name__ == 'categorical_crossentropy' and len(y.shape) != 2:
+        loss_name = self.model.loss
-        return accuracy
+        outputs = self.model.evaluate(X, y, **kwargs)
-        '''Returns the mean accuracy on the given test data and labels.
+        '''Returns the mean loss on the given test data and labels.
-        kwargs.update({'show_accuracy': False})
+        if type(loss) is list:
-    new_graph = model_from_yaml(yaml_str)
+'''Th test below is failing because of a known bug
-                  class_mode='binary')
+                  metrics=['accuracy'])
-    model.compile(optimizer='sgd', loss='mean_absolute_error')
+    model.compile(optimizer='sgd', loss='mean_absolute_error',
-from keras.models import Sequential, weighted_objective
+from keras.models import Sequential
-                            volume_shape=self.input_shape,
+                            volume_shape=input_shape,
-            return self.input_shape
+            return input_shape
-    model.compile('rmsprop', 'mse', mode='FAST_COMPILE')
+    model.compile('rmsprop', 'mse')
-                       input_shape=(nb_samples, stack_size, nb_row, nb_col))
+                       input_shape=(nb_samples, stack_size,
-    test_convolution_1d()
+    test_convolution_3d()
-               input_shape=(3, 2, 3))
+    from keras.engine import Input, Model
-        def build_map_of_graph(tensor, seen_nodes=set(), depth=0):
+        def build_map_of_graph(tensor, seen_nodes=set(), depth=0,
-            layer, node_index, tensor_index = tensor._keras_history
+            if not layer or node_index is None or tensor_index is None:
-                build_map_of_graph(x, copy.copy(seen_nodes), depth + 1)
+            for i in range(len(node.inbound_layers)):
-#     new_graph = model_from_yaml(yaml_str)
+def test_siamese_2():
-                                        allow_input_downcast=True, **kwargs)
+                                        allow_input_downcast=True,
-    return len(x.get_shape())
+    dims = x.get_shape()._dims
-    return tf.matmul(x, y)
+    '''Multiplies 2 tensors.
-        adj_y = True if axes[1][0] == y.ndim-1 else None
+        adj_x = None if axes[0][0] == ndim(x) - 1 else True
-from keras.layers.core import Dense, Activation
+from keras.layers.core import Dense, Activation
-    out = (norm_m0.get_output(train=True) - norm_m0.beta) / norm_m0.gamma
+    out = norm_m0.call(K.variable(X))
-    assert_allclose(K.eval(K.std(out)), 1.0, atol=1e-1)
+    assert_allclose(np_out.mean(), 0.0, atol=1e-1)
-    out = (norm_m0.get_output(train=True) - K.reshape(norm_m0.beta, (1, 3, 1, 1))) / K.reshape(norm_m0.gamma, (1, 3, 1, 1))
+    out = norm_m0.call(K.variable(X))
-    assert_allclose(K.eval(K.std(out, axis=(0, 2, 3))), 1.0, atol=1e-1)
+    assert_allclose(np.mean(np_out, axis=(0, 2, 3)), 0.0, atol=1e-1)
-    np.random.seed(1337)
+    norm_m1.build(input_shape=(None, 10))
-        out = (norm_m1.get_output(train=True) - np.ones(10)) / 1.
+        out = (norm_m1.call(K.variable(inp)) - norm_m1.beta) / norm_m1.gamma
-        self.constraints = [self.W_constraint, self.b_constraint]
+        self.constraints = {}
-        self.constraints = [self.W_constraint, self.b_constraint]
+        self.constraints = {}
-        self.constraints = [self.W_constraint, self.b_constraint]
+        self.constraints = {}
-        super(UpSampling1D, self).__init__(**kwargs)
+        super(UpSampling1D, self).__init__(**kwargs)
-        super(UpSampling2D, self).__init__(**kwargs)
+        super(UpSampling2D, self).__init__(**kwargs)
-        super(UpSampling3D, self).__init__(**kwargs)
+                            ' is currently only working with Theano backend.') 
-    nb_filter = 5
+    nb_samples = 2
-                        layer.get_config()
+    for border_mode in ['valid', 'same']:
-        layer.get_config()
+        layer_test(convolutional.MaxPooling1D,
-        layer.get_config()
+        layer_test(convolutional.AveragePooling1D,
-    stack_size = 7
+    nb_filter = 3
-    assert_allclose(out_tf, np.transpose(out_th, (0, 2, 3, 1)), atol=1e-05)
+    for border_mode in ['valid', 'same']:
-    assert_allclose(out_tf, np.transpose(out_th, (0, 2, 3, 1)), atol=1e-05)
+        layer_test(convolutional.MaxPooling2D,
-    input_nb_col = 12
+    pool_size = (3, 3)
-                layer.get_config()
+                layer_test(convolutional.MaxPooling2D,
-    len_conv_dim3 = 6
+    nb_samples = 2
-                            layer.get_config()
+    for border_mode in ['same', 'valid']:
-        layer.get_config()
+        layer_test(convolutional.MaxPooling3D,
-        layer.get_config()
+        layer_test(convolutional.AveragePooling3D,
-        assert_allclose(out[:, :, 2:-2, 2:-2], 1.)
+    layer.set_input(K.variable(input), shape=input.shape)
-        assert_allclose(out[:, :, 2:-2, 2:-2, 2:-2], 1.)
+    layer.set_input(K.variable(input), shape=input.shape)
-        layer.get_config()
+    layer_test(convolutional.UpSampling1D,
-                        assert out.shape[2] == length_col * input_nb_col
+                layer.set_input(K.variable(input), shape=input.shape)
-                        expected_out = np.repeat(expected_out, length_col, axis=2)
+                out = K.eval(layer.output)
-                    assert_allclose(out, expected_out)
+                # compare with numpy
-                layer.get_config()
+                assert_allclose(out, expected_out)
-                    layer.get_config()
+                    layer.set_input(K.variable(input), shape=input.shape)
-    pytest.main([__file__])
+    # pytest.main([__file__])
-            config['batch_input_shape'] = self.input_shape
+            config['batch_input_shape'] = self.input_spec[0].shape
-        input_shape = self.input_shape
+        input_shape = self.input_spec[0].shape
-from keras.layers.core import Dense, Activation, Flatten
+from keras.utils.test_utils import layer_test
-    assert_allclose(norm, np.ones_like(norm).astype('float32'), rtol=1e-05)
+def test_embedding():
-            mask = layer.get_output_mask(train)
+    # check return_sequences
-            mask = layer.get_output_mask(train)
+    layer_test(layer_class,
-    layer = layer_class(output_dim, return_sequences=ret_seq, weights=None,
+    layer = layer_class(output_dim, return_sequences=False, weights=None,
-    out = K.eval(layer.get_output(train=True))
+    shape = (nb_samples, timesteps, embedding_dim)
-
+from .wrappers import *
-from ..engine import Layer
+from ..engine import Layer, InputSpec
-        return self.layer.updates
+    def build(self, input_shape=None):
-                  'layer': {'class_name': self.layer.__class__.__name__,
+        config = {'layer': {'class_name': self.layer.__class__.__name__,
-        base_config = super(TimeDistributed, self).get_config()
+        base_config = super(Wrapper, self).get_config()
-            if not self.input_shape[1]:
+            if not input_shape[1]:
-        child_input_shape = (input_shape[0], input_shape[2:])
+        child_input_shape = (input_shape[0],) + input_shape[2:]
-        if self.input_shape[0]:
+        input_shape = self.input_spec[0].shape
-            y = self.layer(x, train=False)  # (nb_samples * timesteps, ...)
+            X = K.reshape(X, (-1, ) + input_shape[2:])  # (nb_samples * timesteps, ...)
-            y = K.reshape(y, (-1, input_length) + self.layer.output_shape[1:])
+            output_shape = self.get_output_shape_for(input_shape)
-            if x[0].shape[0] % batch_size != 0:
+            if x[0].shape[0] > batch_size and x[0].shape[0] % batch_size != 0:
-                                str(x[0].shape[0]) + ' samples')
+                                str(x[0].shape[0]) + ' samples. '
-        self.constraints = [self.W_constraint, self.b_constraint]
+        self.constraints = {}
-        self.constraints = [self.W_constraint, self.b_constraint]
+        self.constraints = {}
-        self.constraints = [self.W_constraint, self.b_constraint]
+        self.constraints = {}
-        self.constraints = [self.W_constraint, self.b_constraint]
+        self.constraints = {}
-            output = T.batched_tensordot(l1, l2, self.dot_axes)
+            output = K.batch_dot(l1, l2, self.dot_axes)
-            output = output.dimshuffle((0, 'x'))
+            denominator = K.sqrt(K.batch_dot(l1, l1, self.dot_axes) *
-    return tf.select(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p, 
+    return tf.select(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,
-                                       std=self.sigma)
+    def call(self, x, mask=None):
-                  "sigma": self.sigma}
+        config = {'sigma': self.sigma}
-        return X
+    def call(self, x, mask=None):
-                  "p": self.p}
+        config = {'p': self.p}
-from keras.layers import core
+from keras.utils.test_utils import layer_test
-    _runner(layer)
+    layer_test(noise.GaussianNoise,
-    assert output_np.shape == batch_input_shape
+    layer_test(noise.GaussianDropout,
-        regularized_loss = self.l1 * K.sum(K.mean(K.abs(output), axis=0))
+        regularized_loss = loss + self.l1 * K.sum(K.mean(K.abs(output), axis=0))
-    return get_from_module(identifier, globals(), 'constraint', instantiate=True, kwargs=kwargs)
+    return get_from_module(identifier, globals(), 'constraint',
-            of: 'sum', 'mul', 'concat', 'ave', 'join', 'cos', 'dot'.
+            of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot'.
-        act = self.activation(K.dot(X, self.W) + self.b)
+    def call(self, x, mask=None):
-        output = act + (1 - transform_weight) * X
+        output = act + (1 - transform_weight) * x
-                  'init': self.init.__name__,
+        config = {'init': self.init.__name__,
-                  'output_dim': self.output_dim,
+        config = {'output_dim': self.output_dim,
-def test_layer(layer_cls, kwargs={}, input_shape=None, input_dtype=None,
+def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,
-    model.compile('rmsprop', 'mse')
+    model.compile('rmsprop', 'mse', mode='FAST_COMPILE')
-from keras.utils.test_utils import test_layer
+from keras.utils.test_utils import layer_test
-        test_layer(LeakyReLU, kwargs={'alpha': alpha},
+        layer_test(LeakyReLU, kwargs={'alpha': alpha},
-    test_layer(PReLU, kwargs={},
+    layer_test(PReLU, kwargs={},
-        test_layer(ELU, kwargs={'alpha': alpha},
+        layer_test(ELU, kwargs={'alpha': alpha},
-        test_layer(ParametricSoftplus,
+        layer_test(ParametricSoftplus,
-    test_layer(ThresholdedLinear, kwargs={'theta': 0.5},
+    layer_test(ThresholdedLinear, kwargs={'theta': 0.5},
-    test_layer(ThresholdedReLU, kwargs={'theta': 0.5},
+    layer_test(ThresholdedReLU, kwargs={'theta': 0.5},
-    test_layer(SReLU, kwargs={},
+    layer_test(SReLU, kwargs={},
-from keras.layers import containers
+from keras.utils.test_utils import layer_test
-    _runner(layer)
+def test_masking():
-    _runner(layer)
+    # test modes: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot'.
-    _runner(layer)
+    layer_test(core.Dropout,
-
+    # with string argument
-    _runner(layer)
+    # with function argument
-    _runner(layer)
+def test_reshape():
-    _runner(layer)
+def test_permute():
-    _runner(layer)
+def test_flatten():
-    _runner(layer)
+def test_repeat_vector():
-    _runner(layer)
+def test_lambda():
-    _runner(layer)
+    # test serialization with function
-    layer_2 = core.Layer()
+    ld = Lambda(lambda x: K.concatenate([K.square(x), x]),
-    _runner(layer)
+    # test serialization with output_shape function
-    X_test = np.random.random((100, 10))
+    ld = Lambda(f, output_shape=f_shape)
-    model.fit(X_train, X_train, nb_epoch=1, batch_size=32)
+def test_dense():
-    assert representations.shape == (100, 5)
+    layer_test(core.Dense,
-    model.fit(X_test, representations, nb_epoch=1, batch_size=32)
+    layer_test(core.Dense,
-    assert reconstructions.shape == (100, 10)
+def test_activity_regularization():
-    _runner(layer)
+    from keras import regularizers
-    assert layer.name == 'dense'
+    layer_test(core.MaxoutDense,
-    shared_layer = core.Dense(5,input_dim=7)
+def test_highway():
-            name = self.__class__.__name__.lower() + '_' + str(id(self))
+            prefix = self.__class__.__name__.lower()
-                                'a Keras `Input` layer, '
+                                'a Keras Input layer, '
-                                'input to  "' + self.name +
+                                'Here, a tensor specified as '
-                                'instantiated via `tensor = Input(shape)`.')
+                                'instantiated via `tensor = Input(shape)`.\n'
-        self.alpha = alpha
+        self.alpha = K.cast_to_floatx(alpha)
-        return K.relu(X, alpha=self.alpha)
+    def call(self, x, mask=None):
-                  'alpha': self.alpha}
+        config = {'alpha': self.alpha}
-    '''
+    '''Parametric Rectified Linear Unit.
-        self.alphas = self.init(input_shape,
+    def build(self, input_shape):
-        neg = self.alphas * (X - abs(X)) * 0.5
+    def call(self, x, mask=None):
-                  'init': self.init.__name__}
+        config = {'init': self.init.__name__}
-    '''
+    '''Exponential Linear Unit.
-        self.alpha = alpha
+        self.alpha = K.cast_to_floatx(alpha)
-        neg = (X - abs(X)) * 0.5
+    def call(self, x, mask=None):
-                  'alpha': self.alpha}
+        config = {'alpha': self.alpha}
-        self.beta_init = beta_init
+        self.alpha_init = K.cast_to_floatx(alpha_init)
-        input_shape = self.input_shape[1:]
+    def build(self, input_shape):
-        return K.softplus(self.betas * X) * self.alphas
+    def call(self, x, mask=None):
-                  'alpha_init': self.alpha_init,
+        config = {'alpha_init': self.alpha_init,
-        self.theta = theta
+        self.theta = K.cast_to_floatx(theta)
-        return K.switch(K.abs(X) < self.theta, 0, X)
+    def call(self, x, mask=None):
-                  'theta': self.theta}
+        config = {'theta': self.theta}
-    '''Thresholded Rectified Activation.
+    '''Thresholded Rectified Linear Unit.
-        self.theta = theta
+        self.theta = K.cast_to_floatx(theta)
-        return K.switch(X > self.theta, X, 0)
+    def call(self, x, mask=None):
-                  'theta': self.theta}
+        config = {'theta': self.theta}
-    '''SReLU
+    '''S-shaped Rectified Linear Unit.
-        self.a_right_init = initializations.get(a_right_init)
+        self.t_left_init = t_left_init
-                                         name='{}_a_right'.format(self.name))
+    def build(self, input_shape):
-        Y_left_and_center = self.t_left + K.relu(X - self.t_left,
+    def call(self, x, mask=None):
-        Y_right = K.relu(X - self.t_right_actual) * self.a_right
+        Y_right = K.relu(x - self.t_right_actual) * self.a_right
-                'a_right_init': self.a_right_init}
+        config = {'t_left_init': self.t_left_init,
-from ..models import Sequential
+from ..models import Sequential, model_from_json
-def get_test_data(nb_train=1000, nb_test=500, input_shape=(10,), output_shape=(2,),
+def get_test_data(nb_train=1000, nb_test=500, input_shape=(10,),
-def test_layer(layer, input_shape, input_dtype=None):
+def test_layer(layer_cls, kwargs={}, input_shape=None, input_dtype=None,
-    input_data = (10 * np.random.random(input_shape)).astype(input_dtype)
+    if input_data is None:
-    layer = layer.__class__.from_config(layer_config)
+    # instantiation
-    model = Model(x, y)
+    model = Model(input=x, output=y)
-    actual_output_shape = model.predict(input_data).shape
+    actual_output = model.predict(input_data)
-    actual_output_shape = outer_model.predict(input_data).shape
+    actual_output = outer_model.predict(input_data)
-    actual_output_shape = model.predict(input_data).shape
+    actual_output = model.predict(input_data)
-    return np.array([[0, 0.1, 0.5, 0.9, 1.0, 10, 1e2, 0.01]], dtype=K.floatx())
+from keras.utils.test_utils import test_layer
-        assert config['alpha'] == alpha
+        test_layer(LeakyReLU, kwargs={'alpha': alpha},
-        layer.get_config()
+    test_layer(PReLU, kwargs={},
-                    reason='currently not working with TensorFlow')
+    for alpha in [0., .5, -1.]:
-                    reason='currently not working with TensorFlow')
+    for alpha in [0., .5, -1.]:
-            assert_allclose(outp, inp * (inp > theta))
+    test_layer(ThresholdedLinear, kwargs={'theta': 0.5},
-        assert config['theta'] == theta
+def test_thresholded_relu():
-        layer.get_config()
+    test_layer(SReLU, kwargs={},
-    pytest.main([__file__])
+    # pytest.main([__file__])
-    model.compile(loss='categorical_crossentropy', optimizer=optimizer)
+    model.compile(loss='categorical_crossentropy',
-                        show_accuracy=True, verbose=2)
+                        validation_data=(X_test, y_test), verbose=2)
-        return {"name": self.__class__.__name__}
+        return {'name': self.__class__.__name__}
-        self.l2 = l2
+        self.l1 = K.cast_to_floatx(l1)
-                "l2": self.l2}
+        return {'name': self.__class__.__name__,
-        self.l2 = l2
+        self.l1 = K.cast_to_floatx(l1)
-        return loss
+        output = self.layer.output
-                "l2": self.l2}
+        return {'name': self.__class__.__name__,
-np.random.seed(1337) # for reproducibility
+np.random.seed(1337)
-from keras.layers.embeddings import Embedding
+from keras.layers import Merge
-    for reg in [regularizers.identity(), regularizers.l1(), regularizers.l2(), regularizers.l1l2()]:
+    for reg in [regularizers.identity(),
-                                         cur_layer.get_output())
+            layers = self.model.layers
-                feed_dict = dict(zip(names, self.model.validation_data))
+                feed_dict = dict(zip(self.model.inputs,
-            name = 'graph_' + str(id(self))
+            prefix = 'graph_'
-            name = 'sequential_' + str(id(self))
+            prefix = 'sequential_'
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+    model.compile(loss='categorical_crossentropy',
-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,
+    model.fit(X_train, y_train, batch_size=batch_size,
-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,
+    model.fit(X_train, y_train, batch_size=batch_size,
-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,
+    model.fit(X_train, y_train, batch_size=batch_size,
-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,
+    model.fit(X_train, y_train, batch_size=batch_size,
-
+    model.compile(loss='categorical_crossentropy',
-    history = model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,
+    history = model.fit(X_train, y_train, batch_size=batch_size,
-    history = model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,
+    history = model.fit(X_train, y_train, batch_size=batch_size,
-    model.compile(loss='categorical_crossentropy', optimizer='sgd')
+    model.compile(loss='categorical_crossentropy',
-    model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,
+    model.fit(X_train, y_train, batch_size=batch_size,
-        model.compile(loss='categorical_crossentropy', optimizer='sgd')
+        model.compile(loss='categorical_crossentropy',
-        model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=False,
+        model.fit(X_train, y_train, batch_size=batch_size,
-        model.fit(X_train, y_train, batch_size=batch_size, show_accuracy=True,
+        model.fit(X_train, y_train, batch_size=batch_size,
-    pytest.main([__file__])
+    # pytest.main([__file__])
-model.compile(loss='categorical_crossentropy', optimizer='adam')
+model.compile(loss='categorical_crossentropy',
-              validation_data=(X_val, y_val), show_accuracy=True)
+              validation_data=(X_val, y_val))
-        shape = list(self.input_shape)
+    def get_output_shape_for(self, input_shape):
-        x = self.get_input(train)
+    def call(self, x, mask=None):
-model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+model.compile(loss='categorical_crossentropy',
-          validation_data=(X_test, Y_test))
+          verbose=1, validation_data=(X_test, Y_test))
-'''Train a memory network on the bAbI dataset.
+'''Trains a memory network on the bAbI dataset.
-answer.compile(optimizer='rmsprop', loss='categorical_crossentropy')
+answer.compile(optimizer='rmsprop', loss='categorical_crossentropy',
-sentrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, input_length=story_maxlen, mask_zero=True))
+sentrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,
-model.compile(optimizer='adam', loss='categorical_crossentropy', class_mode='categorical')
+model.compile(optimizer='adam',
-loss, acc = model.evaluate([tX, tXq], tY, batch_size=BATCH_SIZE, show_accuracy=True)
+model.fit([X, Xq], Y, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05)
-model.compile(loss='categorical_crossentropy', optimizer=sgd)
+model.compile(loss='categorical_crossentropy',
-              validation_data=(X_test, Y_test), shuffle=True)
+    model.fit(X_train, Y_train,
-    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),
+    model.fit_generator(datagen.flow(X_train, Y_train,
-                        nb_worker=1)
+                        nb_epoch=nb_epoch,
-
+# build the VGG16 network
-model.add(first_layer)
+model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, img_width, img_height)))
-    layer_output = layer_dict[layer_name].get_output()
+    layer_output = layer_dict[layer_name].output
-
+# build the VGG16 network
-model.add(first_layer)
+model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, img_width, img_height)))
-    x = layer_dict[layer_name].get_output()
+    x = layer_dict[layer_name].output
-from keras.layers.recurrent import LSTM
+from keras.models import Model
-model.add_output(name='output', input='sigmoid')
+
-model.compile('adam', {'output': 'binary_crossentropy'})
+model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])
-model.fit({'input': X_train, 'output': y_train},
+model.fit(X_train, y_train,
-print('Test accuracy:', acc)
+          nb_epoch=4,
-Get to 0.835 test accuracy after 2 epochs. 100s/epoch on K520 GPU.
+Gets to 0.835 test accuracy after 2 epochs. 100s/epoch on K520 GPU.
-          nb_epoch=nb_epoch, show_accuracy=True,
+              optimizer='rmsprop',
-Get to 0.8498 test accuracy after 2 epochs. 41s/epoch on K520 GPU.
+Gets to 0.8498 test accuracy after 2 epochs. 41s/epoch on K520 GPU.
-              class_mode='binary')
+              metrics=['accuracy'])
-                            show_accuracy=True)
+          validation_data=(X_test, y_test))
-'''Train a LSTM on the IMDB sentiment classification task.
+'''Trains a LSTM on the IMDB sentiment classification task.
-from keras.layers.recurrent import LSTM
+from keras.layers.recurrent import LSTM, SimpleRNN, GRU
-maxlen = 100  # cut texts after this number of words (among top max_features most common words)
+maxlen = 80  # cut texts after this number of words (among top max_features most common words)
-model.add(LSTM(128, dropout_W=0.5, dropout_U=0.1))  # try using a GRU instead, for fun
+model.add(LSTM(128, dropout_W=0.5, dropout_U=0.5))  # try using a GRU instead, for fun
-              optimizer='adam')
+              optimizer='adam',
-          validation_data=(X_test, y_test), show_accuracy=True)
+          validation_data=(X_test, y_test))
-                            show_accuracy=True)
+                            batch_size=batch_size)
-maxlen = 20
+maxlen = 40
-'''Train a simple convnet on the MNIST dataset.
+'''Trains a simple convnet on the MNIST dataset.
-Get to 99.25% test accuracy after 12 epochs (there is still a lot of margin for parameter tuning).
+Gets to 99.25% test accuracy after 12 epochs
-model.compile(loss='categorical_crossentropy', optimizer='adadelta')
+model.compile(loss='categorical_crossentropy',
-score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
+          verbose=1, validation_data=(X_test, Y_test))
-                    activation='relu', input_shape=X_train.shape[1:]))
+                    activation='relu',
-model.compile(loss='categorical_crossentropy', optimizer=rmsprop)
+model.compile(loss='categorical_crossentropy',
-          show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))
+          verbose=1, validation_data=(X_test, Y_test))
-scores = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
+scores = model.evaluate(X_test, Y_test, verbose=0)
-model.compile(loss='categorical_crossentropy', optimizer=rmsprop)
+model.compile(loss='categorical_crossentropy',
-          show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))
+          verbose=1, validation_data=(X_test, Y_test))
-scores = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
+scores = model.evaluate(X_test, Y_test, verbose=0)
-'''Train a simple deep NN on the MNIST dataset.
+'''Trains a simple deep NN on the MNIST dataset.
-Get to 98.40% test accuracy after 20 epochs
+Gets to 98.40% test accuracy after 20 epochs
-model.compile(loss='categorical_crossentropy', optimizer=rms)
+model.summary()
-                       show_accuracy=True, verbose=0)
+model.compile(loss='categorical_crossentropy',
-from keras.layers.core import Dense, Dropout, Lambda
+from keras.models import Sequential, Model
-    return K.sqrt(K.sum(K.square(u - v), axis=1, keepdims=True))
+def euclidean_distance(vects):
-def contrastive_loss(y, d):
+def contrastive_loss(y_true, y_pred):
-    return K.mean(y * K.square(d) + (1 - y) * K.square(K.maximum(margin - d, 0)))
+    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))
-g.add_output(name='output', input='d')
+input_a = Input(shape=(input_dim,))
-      nb_epoch=nb_epoch)
+model.compile(loss=contrastive_loss, optimizer=rms)
-pred = g.predict({'input_a': tr_pairs[:, 0], 'input_b': tr_pairs[:, 1]})['output']
+pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])
-pred = g.predict({'input_a': te_pairs[:, 0], 'input_b': te_pairs[:, 1]})['output']
+pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])
-    model.compile(loss='categorical_crossentropy', optimizer='adadelta')
+    model.compile(loss='categorical_crossentropy',
-              show_accuracy=True, verbose=1,
+              verbose=1,
-    score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
+    score = model.evaluate(X_test, Y_test, verbose=0)
-first_layer.input = input_tensor
+first_layer = ZeroPadding2D((1, 1))
-outputs_dict = dict([(layer.name, layer.get_output()) for layer in model.layers])
+outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])
-    python examples/reuters_mlp.py
+'''Trains and evaluate a simple MLP
-model.compile(loss='categorical_crossentropy', optimizer='adam')
+model.compile(loss='categorical_crossentropy',
-score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=1, show_accuracy=True)
+history = model.fit(X_train, Y_train,
-from .common import epsilon, floatx, set_epsilon, set_floatx
+from .common import epsilon
-_LEARNING_PHASE = tf.placeholder(dtype='uint8')  # 0 = test, 1 = train
+_LEARNING_PHASE = tf.placeholder(dtype='uint8', name='keras_learning_phase')  # 0 = test, 1 = train
-        go_backwards=False, mask=None, constants=None):
+        go_backwards=False, mask=None, constants=None,
-    '''Switch between two operations depending on a scalar value.
+    '''Switch between two operations depending on a scalar value (int or bool).
-                                           lambda: else_expression)
+    x_shape = copy.copy(then_expression.get_shape())
-    x = tf.python.control_flow_ops.cond(_LEARNING_PHASE,
+    '''Inserts an expression to be only applied at training time.
-    x = tf.python.control_flow_ops.cond(_LEARNING_PHASE,
+    '''Inserts an expression to be only applied at test time.
-_LEARNING_PHASE = T.scalar(dtype='uint8')  # 0 = test, 1 = train
+_LEARNING_PHASE = T.scalar(dtype='uint8', name='keras_learning_phase')  # 0 = test, 1 = train
-        go_backwards=False, mask=None, constants=None):
+        go_backwards=False, mask=None, constants=None,
-
+        unroll: whether to unroll the RNN or to use a symbolic loop (`scan`).
-        states = results[1:]
+
-        states = []
+        if unroll:
-    y_train = labels[:int(len(X) * (1 - test_split))]
+    X_train = np.array(X[:int(len(X) * (1 - test_split))])
-    y_test = labels[int(len(X) * (1 - test_split)):]
+    X_test = np.array(X[int(len(X) * (1 - test_split)):])
-from ..layers.core import MaskedLayer
+from ..engine import Layer
-class LeakyReLU(MaskedLayer):
+class LeakyReLU(Layer):
-        super(LeakyReLU, self).__init__(**kwargs)
+        self.supports_masking = True
-class PReLU(MaskedLayer):
+class PReLU(Layer):
-class ELU(MaskedLayer):
+class ELU(Layer):
-        super(ELU, self).__init__(**kwargs)
+        self.supports_masking = True
-class ParametricSoftplus(MaskedLayer):
+class ParametricSoftplus(Layer):
-class ThresholdedLinear(MaskedLayer):
+class ThresholdedLinear(Layer):
-        super(ThresholdedLinear, self).__init__(**kwargs)
+        self.supports_masking = True
-class ThresholdedReLU(MaskedLayer):
+class ThresholdedReLU(Layer):
-        super(ThresholdedReLU, self).__init__(**kwargs)
+        self.supports_masking = True
-class SReLU(MaskedLayer):
+class SReLU(Layer):
-from ..layers.core import Layer, Merge, Siamese, SiameseHead
+from ..engine import Layer, Merge, merge
-from ..layers.core import Layer
+from ..engine import Layer, InputSpec
-
+        self.input_spec = [InputSpec(ndim=3)]
-        input_dim = self.input_shape[2]
+    def build(self, input_shape):
-        length = conv_output_length(self.input_shape[1],
+    def get_output_shape_for(self, input_shape):
-        return (self.input_shape[0], length, self.nb_filter)
+        return (input_shape[0], length, self.nb_filter)
-        conv_out = K.conv2d(X, self.W, strides=self.subsample,
+    def call(self, x, mask=None):
-                  'nb_filter': self.nb_filter,
+        config = {'nb_filter': self.nb_filter,
-
+        self.input_spec = [InputSpec(ndim=4)]
-    def build(self):
+    def build(self, input_shape):
-            stack_size = self.input_shape[1]
+            stack_size = input_shape[1]
-            stack_size = self.input_shape[3]
+            stack_size = input_shape[3]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        conv_out = K.conv2d(X, self.W, strides=self.subsample,
+    def call(self, x, mask=None):
-                  'nb_filter': self.nb_filter,
+        config = {'nb_filter': self.nb_filter,
-    input_ndim = 5
+        self.input_spec = [InputSpec(ndim=5)]
-
+    def build(self, input_shape):
-            stack_size = self.input_shape[1]
+            stack_size = input_shape[1]
-            stack_size = self.input_shape[4]
+            stack_size = input_shape[4]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        conv_out = K.conv3d(X, self.W, strides=self.subsample,
+    def call(self, x, mask=None):
-                  "nb_filter": self.nb_filter,
+        config = {"nb_filter": self.nb_filter,
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        output = self._pooling_function(inputs=X, pool_size=self.pool_size,
+    def call(self, x, mask=None):
-                  'stride': self.stride,
+        config = {'stride': self.stride,
-    input_ndim = 4
+        self.input_spec = [InputSpec(ndim=4)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        output = self._pooling_function(inputs=X, pool_size=self.pool_size,
+    def call(self, x, mask=None):
-                  'pool_size': self.pool_size,
+        config = {'pool_size': self.pool_size,
-    input_ndim = 5
+        self.input_spec = [InputSpec(ndim=5)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        output = self._pooling_function(inputs=X, pool_size=self.pool_size,
+    def call(self, x, mask=None):
-                  'pool_size': self.pool_size,
+        config = {'pool_size': self.pool_size,
-    input_ndim = 3
+        self.input_spec = [InputSpec(ndim=3)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        output = K.repeat_elements(X, self.length, axis=1)
+    def call(self, x, mask=None):
-                  'length': self.length}
+        config = {'length': self.length}
-    input_ndim = 4
+        self.input_spec = [InputSpec(ndim=4)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        return K.resize_images(X, self.size[0], self.size[1],
+    def call(self, x, mask=None):
-                  'size': self.size}
+        config = {'size': self.size}
-    input_ndim = 5
+        self.input_spec = [InputSpec(ndim=5)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        return K.resize_volumes(X, self.size[0], self.size[1], self.size[2],
+    def call(self, x, mask=None):
-                  'size': self.size}
+        config = {'size': self.size}
-    input_ndim = 3
+        self.input_spec = [InputSpec(ndim=3)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        return K.temporal_padding(X, padding=self.padding)
+    def call(self, x, mask=None):
-                  'padding': self.padding}
+        config = {'padding': self.padding}
-    input_ndim = 4
+        self.input_spec = [InputSpec(ndim=4)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        return K.spatial_2d_padding(X, padding=self.padding,
+    def call(self, x, mask=None):
-                  'padding': self.padding}
+        config = {'padding': self.padding}
-    input_ndim = 5
+        self.input_spec = [InputSpec(ndim=5)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        return K.spatial_3d_padding(X, padding=self.padding,
+    def call(self, x, mask=None):
-                  'padding': self.padding}
+        config = {'padding': self.padding}
-from six.moves import zip
+import inspect
-    '''Mask an input sequence by using a mask value to identify padding.
+class Masking(Layer):
-        super(Masking, self).__init__(**kwargs)
+        self.supports_masking = True
-        return K.any(K.not_equal(X, self.mask_value), axis=-1)
+    def compute_mask(self, input, input_mask=None):
-        return X * K.cast(K.any(K.not_equal(X, self.mask_value), axis=-1, keepdims=True), K.floatx())
+    def call(self, x, mask=None):
-                  'mask_value': self.mask_value}
+        config = {'mask_value': self.mask_value}
-    '''Apply Dropout to the input. Dropout consists in randomly setting
+class Dropout(Layer):
-        super(Dropout, self).__init__(**kwargs)
+        self.supports_masking = True
-        return X
+    def call(self, x, mask=None):
-                  'p': self.p}
+        config = {'p': self.p}
-    '''Apply an activation function to an output.
+class Activation(Layer):
-        super(Activation, self).__init__(**kwargs)
+        self.supports_masking = True
-        return self.activation(X)
+    def call(self, x, mask=None):
-                  'activation': self.activation.__name__}
+        config = {'activation': self.activation.__name__}
-    '''Reshape an output to a certain shape.
+    '''Reshapes an output to a certain shape.
-            does not include the samples dimension (batch size).
+        `(batch_size,) + target_shape`
-    def __init__(self, dims, **kwargs):
+    def __init__(self, target_shape, **kwargs):
-        self.dims = tuple(dims)
+        self.target_shape = tuple(target_shape)
-        given and input shape.
+        given an input shape.
-            output_shape: desired shaped of the array with at most
+            output_shape: desired shape of the array with at most
-        return K.reshape(X, (-1,) + self.output_shape[1:])
+    def get_output_shape_for(self, input_shape):
-                  'dims': self.dims}
+        config = {'target_shape': self.target_shape}
-    '''Permute the dimensions of the input according to a given pattern.
+    '''Permutes the dimensions of the input according to a given pattern.
-        super(Permute, self).__init__(**kwargs)
+        super(Permute, self).__init__(**kwargs)
-        input_shape = list(self.input_shape)
+    def get_output_shape_for(self, input_shape):
-        return K.permute_dimensions(X, (0,) + self.dims)
+    def call(self, x, mask=None):
-                  'dims': self.dims}
+        config = {'dims': self.dims}
-    '''Flatten the input. Does not affect the batch size.
+    '''Flattens the input. Does not affect the batch size.
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        return K.batch_flatten(X)
+    def call(self, x, mask=None):
-        super(RepeatVector, self).__init__(**kwargs)
+        self.input_spec = [InputSpec(ndim=2)]
-        input_shape = self.input_shape
+    def get_output_shape_for(self, input_shape):
-        return K.repeat(X, self.n)
+    def call(self, x, mask=None):
-                  'n': self.n}
+        config = {'n': self.n}
-    '''Just your regular fully connected NN layer.
+class Lambda(Layer):
-        2D tensor with shape: `(nb_samples, input_dim)`.
+        Arbitrary. Use the keyword argument input_shape
-        2D tensor with shape: `(nb_samples, output_dim)`.
+        Specified by `output_shape` argument.
-    input_ndim = 2
+    # Input shape
-        input_dim = self.input_shape[1]
+    def build(self, input_shape):
-        return (self.input_shape[0], self.output_dim)
+    def call(self, x, mask=None):
-        return output
+    def get_output_shape_for(self, input_shape):
-                  'output_dim': self.output_dim,
+        config = {'output_dim': self.output_dim,
-    Especially useful after a recurrent network with 'return_sequence=True'.
+class ActivityRegularization(Layer):
-        3D tensor with shape `(nb_sample, time_dimension, input_dim)`.
+        Arbitrary. Use the keyword argument `input_shape`
-        3D tensor with shape `(nb_sample, time_dimension, output_dim)`.
+        Same shape as input.
-                 init='glorot_uniform', activation='linear', weights=None,
+    # Input shape
-                 input_dim=None, input_length=None, **kwargs):
+                 W_constraint=None, b_constraint=None, input_dim=None, **kwargs):
-        self.activation = activations.get(activation)
+        self.input_spec = [InputSpec(ndim=2)]
-        super(TimeDistributedDense, self).__init__(**kwargs)
+            kwargs['input_shape'] = (self.input_dim,)
-        input_dim = self.input_shape[2]
+    def build(self, input_shape):
-        self.W = self.init((input_dim, self.output_dim),
+        self.W = self.init((self.nb_feature, input_dim, self.output_dim),
-        self.b = K.zeros((self.output_dim,),
+        self.b = K.zeros((self.nb_feature, self.output_dim),
-        return (input_shape[0], input_shape[1], self.output_dim)
+    def get_output_shape_for(self, input_shape):
-        return Y
+    def call(self, x, mask=None):
-                  'output_dim': self.output_dim,
+        config = {'output_dim': self.output_dim,
-                  'activation': self.activation.__name__,
+                  'nb_feature': self.nb_feature,
-        base_config = super(ActivityRegularization, self).get_config()
+                  'input_dim': self.input_dim}
-        else dim(output) = dim(hidden).
+class Highway(Layer):
-            Otherwise, the output of the final decoder layer is returned.
+        init: name of initialization function for the weights of the layer
-    an `Activation` layer must be added after.
+            The list should have 2 elements, of shape `(input_dim, output_dim)`
-        2D tensor with shape: `(nb_samples, output_dim)`.
+        2D tensor with shape: `(nb_samples, input_dim)`.
-        - [Maxout Networks](http://arxiv.org/pdf/1302.4389.pdf)
+        - [Highway Networks](http://arxiv.org/pdf/1505.00387v2.pdf)
-                 init='glorot_uniform', weights=None,
+    def __init__(self, init='glorot_uniform', transform_bias=-2,
-        self.nb_feature = nb_feature
+        self.transform_bias = transform_bias
-        super(MaxoutDense, self).__init__(**kwargs)
+        super(Highway, self).__init__(**kwargs)
-        input_dim = self.input_shape[1]
+    def build(self, input_shape):
-        self.W = self.init((self.nb_feature, input_dim, self.output_dim),
+        self.W = self.init((input_dim, input_dim),
-                         name='{}_b'.format(self.name))
+        self.W_carry = self.init((input_dim, input_dim),
-        self.regularizers = []
+        self.b = K.zeros((input_dim,), name='{}_b'.format(self.name))
-    def get_output(self, train=False):
+    def call(self, train=False):
-        output = K.max(K.dot(X, self.W) + self.b, axis=1)
+        transform_weight = activations.sigmoid(K.dot(X, self.W_carry) + self.b_carry)
-                  'nb_feature': self.nb_feature,
+                  'transform_bias': self.transform_bias,
-        base_config = super(SiameseHead, self).get_config()
+        base_config = super(Highway, self).get_config()
-
+class TimeDistributedDense(Layer):
-
+        3D tensor with shape `(nb_sample, time_dimension, input_dim)`.
-
+        3D tensor with shape `(nb_sample, time_dimension, output_dim)`.
-                 activation='linear', weights=None,
+    def __init__(self, output_dim,
-                 W_constraint=None, b_constraint=None, input_dim=None, **kwargs):
+                 W_constraint=None, b_constraint=None,
-        self.transform_bias = transform_bias
+        self.input_spec = [InputSpec(ndim=3)]
-        super(Highway, self).__init__(**kwargs)
+            kwargs['input_shape'] = (self.input_length, self.input_dim)
-        input_dim = self.input_shape[1]
+    def build(self, input_shape):
-        self.W = self.init((input_dim, input_dim),
+        self.W = self.init((input_dim, self.output_dim),
-        self.trainable_weights = [self.W, self.b, self.W_carry, self.b_carry]
+        self.b = K.zeros((self.output_dim,),
-        return (self.input_shape[0], self.input_shape[1])
+    def get_output_shape_for(self, input_shape):
-        return output
+    def call(self, x, mask=None):
-        base_config = super(Highway, self).get_config()
+                  'input_dim': self.input_dim,
-from ..layers.core import Layer
+from ..engine import Layer
-        kwargs['input_shape'] = (self.input_dim,)
+        kwargs['input_shape'] = (self.input_length,)
-                                   dtype='int32')
+    def build(self, input_shape):
-        X = self.get_input(train)
+    def compute_mask(self, x, mask=None):
-            return K.not_equal(X, 0)
+            return K.not_equal(x, 0)
-        return (self.input_shape[0], self.input_length, self.output_dim)
+    def get_output_shape_for(self, input_shape):
-            B = K.random_binomial((self.input_dim,), p=retain_p)
+    def call(self, x, mask=None):
-        out = K.gather(self.W * K.expand_dims(B), X)
+            W = self.W
-                  "dropout": self.dropout}
+        config = {'input_dim': self.input_dim,
-from .core import MaskedLayer
+from ..engine import Layer
-class GaussianNoise(MaskedLayer):
+class GaussianNoise(Layer):
-        super(GaussianNoise, self).__init__(**kwargs)
+        self.supports_masking = True
-class GaussianDropout(MaskedLayer):
+class GaussianDropout(Layer):
-        super(GaussianDropout, self).__init__(**kwargs)
+        self.supports_masking = True
-from ..layers.core import Layer
+from ..engine import Layer, InputSpec
-        input_shape = self.input_shape  # starts with samples axis
+    def build(self, input_shape):
-        X = self.get_input(train)
+    def call(self, x, mask=None):
-            input_shape = self.input_shape
+            input_shape = self.input_spec[0].shape
-            out = K.reshape(self.gamma, broadcast_shape) * X_normed + K.reshape(self.beta, broadcast_shape)
+
-            out = self.gamma * X_normed + self.beta
+            # sample-wise normalization
-                  "epsilon": self.epsilon,
+        config = {"epsilon": self.epsilon,
-from ..layers.core import MaskedLayer
+from ..engine import Layer, InputSpec
-    if dropout:
+    if dropout is not None and 0. < dropout < 1.:
-        x *= expanded_dropout_matrix
+        x = K.in_train_phase(x * expanded_dropout_matrix, x)
-class Recurrent(MaskedLayer):
+class Recurrent(Layer):
-
+        unroll: Boolean (default False). If True, the network will be unrolled,
-
+                 unroll=False, consume_less='cpu',
-    def get_output_mask(self, train=False):
+    def get_output_shape_for(self, input_shape):
-            return super(Recurrent, self).get_output_mask(train)
+            return (input_shape[0], input_shape[1], self.output_dim)
-            return None
+            return (input_shape[0], self.output_dim)
-        input_shape = self.input_shape
+    def compute_mask(self, input, mask):
-            return (input_shape[0], input_shape[1], self.output_dim)
+            return mask
-            return (input_shape[0], self.output_dim)
+            return None
-    def get_constants(self, x, train=False):
+    def get_constants(self, x):
-    def preprocess_input(self, x, train=False):
+    def preprocess_input(self, x):
-    def get_output(self, train=False):
+    def call(self, x, mask=None):
-        assert K.ndim(X) == 3
+        # note that the .build() method of subclasses MUST define
-                                'argument, including the time axis.')
+            if not input_shape[1]:
-        preprocessed_input = self.preprocess_input(X, train)
+            initial_states = self.get_initial_states(x)
-                                             constants=constants)
+                                             constants=constants,
-                  "stateful": self.stateful}
+        config = {'return_sequences': self.return_sequences,
-        input_shape = self.input_shape
+    def build(self, input_shape):
-        input_shape = self.input_shape
+        input_shape = self.input_spec[0].shape
-            dropout = self.dropout_W
+    def preprocess_input(self, x):
-                                      input_dim, self.output_dim, timesteps)
+            return x
-    def step(self, h, states):
+    def step(self, x, states):
-            B_U = states[1]
+        B_U = states[1]
-            B_U = 1.
+            h = K.dot(x * B_W, self.W) + self.b
-        if train and (0 < self.dropout_U < 1):
+    def get_constants(self, x):
-        return []
+            B_U = K.in_train_phase(K.dropout(ones, self.dropout_U), ones)
-        input_shape = self.input_shape
+    def build(self, input_shape):
-            dropout = self.dropout_W
+    def preprocess_input(self, x):
-        return K.concatenate([x_z, x_r, x_h], axis=2)
+            return x
-            B_U = [1., 1., 1.]
+        B_U = states[1]  # dropout matrices for recurrent units
-        x_h = x[:, 2 * self.output_dim:]
+        if self.consume_less == 'cpu':
-        if train and (0 < self.dropout_U < 1):
+    def get_constants(self, x):
-        return []
+            constants.append(B_U)
-        input_shape = self.input_shape
+    def build(self, input_shape):
-        input_shape = self.input_shape
+        input_shape = self.input_spec[0].shape
-            dropout = self.dropout_W
+        if self.consume_less == 'cpu':
-        return K.concatenate([x_i, x_f, x_c, x_o], axis=2)
+            return x
-            B_U = states[2]
+        B_U = states[2]
-        x_o = x[:, 3 * self.output_dim:]
+            x_i = K.dot(x * B_W[0], self.W_i) + self.b_i
-        if train and (0 < self.dropout_U < 1):
+    def get_constants(self, x):
-        return []
+            constants.append(B_U)
-from .core import MaskedLayer
+from ..engine import Layer
-class TimeDistributed(MaskedLayer):
+class Wrapper(Layer):
-        input_shape = self.input_shape
+    def build(self, input_shape):
-                                'an "input_shape" or "batch_input_shape" ' +
+                raise Exception('When using TensorFlow, you should define '
-                output = self.layer(x, train=train)
+                output = self.layer.call(x)
-                                                 mask=mask)
+                                                 initial_states=[])
-        return dict(list(base_config.items()) + list(config.items()))
+from collections import OrderedDict
-            return X[start:stop]
+import copy
-            return np.ones((y.shape[0], y.shape[1]))
+from .engine.training import Model
-    '''
+    # TODO: legacy support?
-    return model_from_config(config, custom_objects=custom_objects)
+    return layer_from_config(config, custom_objects=custom_objects)
-    return model_from_config(config, custom_objects=custom_objects)
+    return layer_from_config(config, custom_objects=custom_objects)
-                         for _ in range(nb_worker)]
+class Sequential(Model):
-        thread.start()
+    # Arguments
-    return q, _stop
+    # Note
-    '''Abstract base model class.
+        ```python
-        return yaml.dump(config, **kwargs)
+    def __init__(self, layers=[], name=None):
-        import json
+        # model attributes
-                return obj.item()
+        if not name:
-                return obj.__name__
+        for layer in layers:
-        model_summary(self)
+    def add(self, layer):
-    '''Linear stack of layers.
+    def set_weights(self, weights):
-                class_mode=None,
+                metrics=[],
-        '''Configure the learning process.
+        '''Configures the learning process.
-    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1, callbacks=[],
+        # Example
-        as well as validation loss values (if applicable).
+            class_weight=None, sample_weight=None, **kwargs):
-            nb_epoch: int.
+            x: input data, as a Numpy array or list of Numpy arrays
-            callbacks: `keras.callbacks.Callback` list.
+            callbacks: list of `keras.callbacks.Callback` instances.
-            sample_weight: list or numpy array of weights for
+            sample_weight: Numpy array of weights for
-        batch by batch.
+
-            batch_size: integer.
+            x: input data, as a Numpy array or list of Numpy arrays
-        return self._predict_loop(self._predict, X, batch_size, verbose)[0]
+            Scalar test loss (if the model has no metrics)
-        '''Generate class probability predictions for the input samples
+        # Returns
-            X: the input data, as a numpy array.
+            x: input data, as a Numpy array or list of Numpy arrays
-            warnings.warn('Network returning invalid probability values.')
+            A Numpy array of probability predictions.
-    def predict_classes(self, X, batch_size=128, verbose=1):
+    def predict_classes(self, x, batch_size=32, verbose=1):
-            X: the input data, as a numpy array.
+            x: input data, as a Numpy array or list of Numpy arrays
-        if self.class_mode == 'categorical':
+        proba = self.predict(x, batch_size=batch_size, verbose=verbose)
-                      verbose=1, show_accuracy=False, callbacks=[],
+                      verbose=1, callbacks=[],
-        and can be run by multiple workers at the same time.
+                      **kwargs):
-                yielding either (X, y) or (X, y, sample_weight).
+            generator: a generator.
-                starting a new epoch.
+                going to the next epoch.
-                generator at the end of every epoch.
+            validation_data: this can be either
-        # Examples
+        # Example
-                        yield x, y
+                        yield (x, y)
-        otherwise it returns the loss value.
+        if 'show_accuracy' in kwargs:
-            nb_val_samples:
+                generator yielding tuples (inputs, targets)
-            metrics = ['loss', 'acc', 'val_loss', 'val_acc']
+                before returning.
-            self.validation_data = [data_val[name] for name in self.input_order] + y_val + sample_weight_val_l
+            config.append({'class_name': self.layers[0].__class__.__name__,
-        return self.history
+            layer = layer_from_config(first_layer)
-        lr = self.lr * (1.0 / (1.0 + self.decay * self.iterations))
+        lr = self.lr * (1. / (1. + self.decay * self.iterations))
-        for p, g, c in zip(params, grads, constraints):
+        for p, g in zip(params, grads):
-            self.updates.append((p, c(new_p)))  # apply constraints
+            # apply constraints
-        accumulators = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
+        # accumulators
-        for p, g, a, c in zip(params, grads, accumulators, constraints):
+        for p, g, a in zip(params, grads, self.weights):
-            new_a = self.rho * a + (1 - self.rho) * K.square(g)
+            new_a = self.rho * a + (1. - self.rho) * K.square(g)
-            self.updates.append((p, c(new_p)))  # apply constraints
+
-        accumulators = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
+        # accumulators
-        for p, g, a, c in zip(params, grads, accumulators, constraints):
+        for p, g, a in zip(params, grads, self.weights):
-            self.updates.append((p, c(new_p)))  # apply constraints
+            # apply constraints
-                                   delta_accumulators, constraints):
+        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):
-            new_a = self.rho * a + (1 - self.rho) * K.square(g)
+            new_a = self.rho * a + (1. - self.rho) * K.square(g)
-            self.updates.append((p, c(new_p)))  # apply constraints
+            # apply constraints
-        self.updates = [(self.iterations, self.iterations+1.)]
+        self.updates = [(self.iterations, self.iterations + 1)]
-        lr_t = self.lr * K.sqrt(1 - K.pow(self.beta_2, t)) / (1 - K.pow(self.beta_1, t))
+        lr_t = self.lr * K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t))
-            v = K.variable(np.zeros(K.get_value(p).shape))
+        ms = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
-            v_t = (self.beta_2 * v) + (1 - self.beta_2) * K.square(g)
+        for p, g, m, v in zip(params, grads, ms, vs):
-            self.updates.append((p, c(p_t)))  # apply constraints
+
-        self.iterations = K.variable(0)
+        self.iterations = K.variable(0.)
-        self.updates = [(self.iterations, self.iterations+1.)]
+        self.updates = [(self.iterations, self.iterations + 1)]
-        lr_t = self.lr / (1 - K.pow(self.beta_1, t))
+        lr_t = self.lr / (1. - K.pow(self.beta_1, t))
-            u = K.variable(np.zeros(K.get_value(p).shape))
+        # zero init of 1st moment
-            m_t = (self.beta_1 * m) + (1 - self.beta_1) * g
+        for p, g, m, u in zip(params, grads, ms, us):
-            self.updates.append((p, c(p_t)))  # apply constraints
+
-from .. import constraints
+from .generic_utils import get_from_module
-    name = layer_dict.get('name')
+def layer_from_config(config, custom_objects={}):
-        return graph_layer
+    class_name = config['class_name']
-        return AutoEncoder(**kwargs)
+    if class_name == 'Sequential':
-    param_count = 0  # param count in the model
+def print_summary(layers, relevant_nodes=None):
-    def display(objects, positions):
+    def print_row(fields, positions):
-            line += str(objects[i])
+        for i in range(len(fields)):
-                           instantiate=True, kwargs=kwargs)
+    print('_' * line_length)
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+    model.compile(loss='categorical_crossentropy',
-                        show_accuracy=True, verbose=0)
+                        verbose=0)
-from keras.layers.embeddings import Embedding
+from keras.models import Sequential
-    single layer of GRU units and softmax applied to the last activations of the units
+    Classify temporal sequences of float numbers
-    model.compile(loss='categorical_crossentropy', optimizer='adadelta')
+    model.compile(loss='categorical_crossentropy',
-                        show_accuracy=True, verbose=0)
+                        verbose=0)
-    model.add(Embedding(10, 20, mask_zero=True))
+    model.add(Embedding(10, 20, mask_zero=True, input_length=20))
-                  sample_weight_mode="temporal")
+                  sample_weight_mode='temporal')
-    print("sample_weight shape: ", Y.shape)
+    print('X shape:', X.shape)
-                        sample_weight=sample_weight,
+                        sample_weight=None,
-    assert(np.abs(history.history['val_loss'][-1] - ground_truth) < 0.05)
+    assert(np.abs(history.history['val_loss'][-1] - ground_truth) < 0.06)
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+    model.compile(loss='categorical_crossentropy',
-                        show_accuracy=True, verbose=0)
+                        verbose=0)
-                                                   initial_states,
+        th_inputs = KTH.variable(input_val)
-                                                   initial_states,
+        tf_inputs = KTF.variable(input_val)
-from keras.layers import containers
+from keras.models import Graph, Sequential
-                                                                             nb_test=200,
+(X_train_graph, y_train_graph), (X_test_graph, y_test_graph) = get_test_data(nb_train=100,
-                                                                                 nb_test=200,
+(X2_train_graph, y2_train_graph), (X2_test_graph, y2_test_graph) = get_test_data(nb_train=100,
-    assert(gen_loss < 3.)
+    gen_loss = graph.evaluate_generator(data_generator_graph(True), 128, verbose=0)    
-    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4, show_accuracy=True)
+    graph.compile('rmsprop', {'output1': 'mse'}, metrics=['accuracy'])
-                        validation_data={'input1': X_test_graph, 'output1': y_test_graph}, show_accuracy=True)
+                        validation_data={'input1': X_test_graph, 'output1': y_test_graph})
-                        validation_data=data_generator_graph(False), nb_val_samples=batch_size * 3, show_accuracy=True)
+                        validation_data=data_generator_graph(False), nb_val_samples=batch_size * 3)
-    gen_loss = graph.evaluate_generator(data_generator_graph(True), 128, verbose=0, show_accuracy=True)
+                        validation_data=data_generator_graph(False), nb_val_samples=batch_size * 3)
-    assert(type(out == dict))
+
-    assert(loss < 2.5)
+    loss = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph}, verbose=0) 
-    # test show_accuracy:
+    # test accuracy:
-    loss, acc = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph}, verbose=0, show_accuracy=True)
+              nb_epoch=1)
-    graph.add_node(Dense(16), name='dense1', input='input1')
+    graph.add_node(Dense(4), name='dense1', input='input1')
-    graph.add_node(Dense(16), name='dense3', input='dense2')
+    graph.add_node(Dense(4), name='dense3', input='dense2')
-              nb_epoch=10)
+              nb_epoch=2)
-    graph.get_config(verbose=1)
+    # test serialization
-              nb_epoch=10)
+              nb_epoch=2)
-    assert(len(out) == 1)
+    # test serialization
-    assert(loss < 3.0)
+    graph.summary()
-    graph.get_config(verbose=1)
+    yaml_str = graph.to_yaml()
-def test_siamese_5():
+def test_siamese_1():
-    graph.add_node(Dense(4), name='dense2',  input='shared_output2')
+    graph.add_shared_node(Dense(4), name='shared', inputs=['input1', 'input2'], merge_mode='sum')
-                     merge_mode='sum')
+    # graph.add_output(name='output1', inputs=['dense1', 'shared'], merge_mode='sum')
-
+    # test serialization
-def test_2o_1i_weights():
+    graph.summary()
-    graph = containers.Graph()
+    graph = Graph()
-    seq.get_config(verbose=1)
+    # test serialization
-    graph = model_from_json(config)
+    config = graph.get_config()
-
+    graph.build()
-from keras.layers import containers
+from keras.models import Graph, Sequential #, model_from_json, model_from_yaml
-nb_hidden = 16
+input_dim = 16
-    test_samples = 500
+    train_samples = 100
-    model.fit_generator(data_generator(True), len(X_train), nb_epoch, show_accuracy=True,
+    model.fit_generator(data_generator(True), len(X_train), nb_epoch)
-    assert(loss < 0.9)
+    loss = model.evaluate(X_train, y_train)
-    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1, validation_split=0.1)
+    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_test, y_test))
-    assert(loss < 0.8)
+    gen_loss = model.evaluate_generator(data_generator(True), 256)
-    model = model_from_json(json_data)
+    # test serialization
-    model = model_from_yaml(yaml_data)
+    yaml_str = model.to_yaml()
-    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1, validation_split=0.1)
+    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_test, y_test))
-    model = model_from_json(json_data)
+    # test serialization
-    model = model_from_yaml(yaml_data)
+    yaml_str = model.to_yaml()
-    model.fit([X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_split=0.1)
+    model.fit([X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, validation_data=([X_test, X_test], y_test))
-    model.get_config(verbose=0)
+    # test serialization
-    left.add(Activation('relu'))
+    left = Sequential(name='branch_1')
-    right.add(Activation('relu'))
+    right = Sequential(name='branch_2')
-    model.add(Activation('softmax'))
+    model = Sequential(name='merged_branches')
-    model.fit([X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_split=0.1)
+    model.fit([X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, validation_data=([X_test, X_test], y_test))
-    model.get_config(verbose=0)
+    model.get_config()
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+    model.fit([X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0)
-    model.fit([X_train, X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_split=0.1)
+    model.fit([X_train, X_train, X_train], y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, validation_data=([X_test, X_test, X_test], y_test))
-    model.get_config(verbose=0)
+    # test serialization
-    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1, validation_split=0.1)
+    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_test, y_test))
-    model.get_config(verbose=0)
+    print(model.layers)
-        return input_dict[keys[0]] - input_dict[keys[1]]
+    model.summary()
-    g.compile(loss={'output': 'categorical_crossentropy'}, optimizer='rmsprop')
+    yaml_str = model.to_yaml()
-    expected_output_shape = layer.output_shape[1:]
+    layer.set_input(K.placeholder(ndim=ndim), input_data.shape)
-    function = K.function([layer.input], [layer.get_output()])
+    function = K.function([layer.input], [layer.output])
-    assert output.shape[1:] == expected_output_shape
+    assert output.shape == expected_output_shape, str(output.shape) + ' != ' + str(expected_output_shape)
-    layer = Reshape(dims=(2, 3))
+    layer = Reshape((2, 3))
-    layer = Reshape(dims=(-1,))
+    layer = Reshape((-1,))
-    layer = Reshape(dims=(-1, 2))
+    layer = Reshape((-1, 2))
-    layer = Reshape(dims=(2, -1))
+    layer = Reshape((2, -1))
-__version__ = '0.3.2'
+__version__ = '0.3.3'
-      version='0.3.2',
+      version='0.3.3',
-      download_url='https://github.com/fchollet/keras/tarball/0.3.2',
+      download_url='https://github.com/fchollet/keras/tarball/0.3.3',
-    assert _floatx in {'float32', 'float64'}
+    assert _floatx in {'float16', 'float32', 'float64'}
-    if floatx not in {'float32', 'float64'}:
+    if floatx not in {'float16', 'float32', 'float64'}:
-    x += random_jitter
+    # add a random offset jitter to the initial image. This will be reverted at decoding time
-    x -= random_jitter
+    x = np.roll(np.roll(x, -ox, -1), -oy, -2) # unshift image
-        adj_y = True if axes[1][0] == y.ndim-1 else None
+        adj_x = None if axes[0][0] == ndim(x)-1 else True
-        adj_y = True if axes[1][0] == 2 else None
+        adj_x = None if axes[0][0] == x.ndim-1 else True
-        axes = [(2,), (1,)]
+        axes = [(x.ndim-1,), (y.ndim-2,)]
-            output = K.tensordot(l1, l2, self.dot_axes)  # T.batched_tensordot(l1, l2, self.dot_axes)
+            output = K.batch_dot(l1, l2, self.dot_axes)
-                K.tensordot(l1, l1, self.dot_axes) * K.tensordot(l2, l2, self.dot_axes))
+            output = K.batch_dot(l1, l2, self.dot_axes) / K.sqrt(
-        output = output.dimshuffle((0, 'x'))
+        output = K.batch_dot(l1, l2, self.dot_axes)
-        output = output.dimshuffle((0, 'x'))
+        output = K.batch_dot(l1, l2, self.dot_axes) / K.sqrt(K.batch_dot(l1, l1, self.dot_axes) * K.batch_dot(l2, l2, self.dot_axes))
-    return tf.select(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p, 
+    return tf.select(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,
-            output = T.batched_tensordot(l1, l2, self.dot_axes)
+            output = K.tensordot(l1, l2, self.dot_axes)  # T.batched_tensordot(l1, l2, self.dot_axes)
-            output = output.reshape(tuple(output_shape))
+            output_shape[0] = -1
-            output = T.batched_tensordot(l1, l2, self.dot_axes) / T.sqrt(T.batched_tensordot(l1, l1, self.dot_axes) * T.batched_tensordot(l2, l2, self.dot_axes))
+            output = K.tensordot(l1, l2, self.dot_axes) / K.sqrt(
-text = open(path).read().lower()
+
-            slices[2] = slice((x.shape[2]+strides[0]-1) // strides[0])
+            conv_out = conv_out[:,:,:(x.shape[2]+strides[0]-1) // strides[0],:]
-        conv_out = conv_out[slices]
+            conv_out = conv_out[:,:,:,:(x.shape[3]+strides[1]-1) // strides[1]]
-        except TypeError: return None
+        try:
-
+    '''
-    
+
-            conv_out = conv_out[:,:,:-1,:]
+            slices[2] = slice((x.shape[2]+strides[0]-1) // strides[0])
-            conv_out = conv_out[:,:,:,:-1]
+            slices[3] = slice((x.shape[3]+strides[1]-1) // strides[1])
-    '''
+
-                                    subsample=strides)
+    if border_mode == 'same':
-                                shift_y: shift_y + expected_height]
+        raise Exception('Border mode not supported: ' + str(border_mode))
-        if y.ndim < 3:
+        if len(y.shape) < 3:
-        if sample_weight is not None and sample_weight.ndim != 2:
+        if sample_weight is not None and len(sample_weight.shape) != 2:
-        if sample_weight is not None and sample_weight.ndim != 1:
+        if sample_weight is not None and len(sample_weight.shape) != 1:
-        assert y.shape[:sample_weight.ndim] == sample_weight.shape
+        assert len(sample_weight.shape) <= len(y.shape)
-                    warnings.warn('Epoch contained duplicated samples which might affect learning results. Set "samples_per_epoch" correctly to avoid this warning.')
+                    warnings.warn('Epoch contained too many samples which might affect learning results. Set "samples_per_epoch" correctly to avoid this warning.')
-    return tf.placeholder(dtype, shape=shape, name=name)
+            shape = tuple([None for _ in range(ndim)])
-    return T.TensorType(dtype, broadcast)(name)
+    x = T.TensorType(dtype, broadcast)(name)
-    angle = random.uniform(-rg, rg)
+    angle = np.random.uniform(-rg, rg)
-        shift_x = random.uniform(-wrg, wrg) * x.shape[2]
+        shift_x = np.random.uniform(-wrg, wrg) * x.shape[2]
-        shift_y = random.uniform(-hrg, hrg) * x.shape[1]
+        shift_y = np.random.uniform(-hrg, hrg) * x.shape[1]
-    shear = random.uniform(-intensity, intensity)
+    shear = np.random.uniform(-intensity, intensity)
-    zoom_h = random.uniform(1.-rg, 1.)
+    zoom_w = np.random.uniform(1.-rg, 1.)
-            if random.random() < 0.5:
+            if np.random.random() < 0.5:
-            if random.random() < 0.5:
+            if np.random.random() < 0.5:
-                'a_right_init': self.a_right_init}
+                't_left_init': self.t_left_init.__name__,
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-        self.b_regularizer = b_regularizer
+        self.W_regularizer = regularizers.get(W_regularizer)
-        append_regulariser(self.b_regularizer, self.b, self.regularizers)
+        if self.W_regularizer:
-        self.b_regularizer = b_regularizer
+        self.W_regularizer = regularizers.get(W_regularizer)
-            append_regulariser(self.b_regularizer, b, self.regularizers)
+        if self.W_regularizer:
-        self.b_regularizer = b_regularizer
+        self.W_regularizer = regularizers.get(W_regularizer)
-            append_regulariser(self.b_regularizer, b, self.regularizers)
+        if self.W_regularizer:
-    g.add_node(Lambda(difference),
+    g.add_node(Lambda(difference, output_shape=(2,)),
-import sys
+import inspect
-    def __init__(self, function, output_shape=None, **kwargs):
+    def __init__(self, function, output_shape=None, arguments={}, **kwargs):
-            self.function = marshal.dumps(function.func_code)
+        self.function = function
-                self._output_shape = marshal.dumps(output_shape.func_code)
+            assert hasattr(output_shape, '__call__'), 'In Lambda, `output_shape` must be a list, a tuple, or a function.'
-                x = self.get_input()
+                x = self.get_output()
-        elif type(self._output_shape) == tuple:
+        elif type(self._output_shape) in {tuple, list}:
-            return (nb_samples, ) + self._output_shape
+            return (nb_samples,) + tuple(self._output_shape)
-            shape = output_shape_func(self.input_shape)
+            shape = self._output_shape(self.input_shape)
-        return func(X)
+        arguments = self.arguments
-    def __init__(self, layers, function, output_shape=None):
+    def __init__(self, layers, function, output_shape=None, arguments={}):
-            self.function = marshal.dumps(function.func_code)
+        self.function = function
-                self._output_shape = marshal.dumps(output_shape.func_code)
+            assert hasattr(output_shape, '__call__'), 'In LambdaMerge, `output_shape` must be a list, a tuple, or a function.'
-            return (input_shapes[0][0], ) + self._output_shape
+        elif type(self._output_shape) in {tuple, list}:
-            shape = output_shape_func(input_shapes)
+            shape = self._output_shape(input_shapes)
-                raise Exception('output_shape function must return a tuple.')
+                raise Exception('In LambdaMerge, the `output_shape` function must return a tuple.')
-        return func(inputs)
+        arguments = self.arguments
-                  'output_shape': self._output_shape}
+                  'output_shape': self._output_shape,
-          nb_epoch=4)
+          nb_epoch=4, show_accuracy=True)
-              class_mode='binary')
+              optimizer='rmsprop')
-print("Pad sequences (samples x time)")
+print('Pad sequences (samples x time)')
-              class_mode="binary")
+              optimizer='adam')
-print("Train...")
+print('Train...')
-            model.compile(loss=loss, optimizer=optimizer, sample_weight_modes=sample_weight_modes)
+            loss_weights = config.get('loss_weights', {})
-        for p in ['class_mode', 'sample_weight_mode', 'sample_weight_modes']:
+        for p in ['sample_weight_mode', 'sample_weight_modes', 'loss_weights']:
-                class_mode="categorical",
+                class_mode=None,
-                using the predict_classes method.
+            class_mode: deprecated argument,
-        if hasattr(self.layers[-1], "get_output_mask"):
+        if hasattr(self.layers[-1], 'get_output_mask'):
-        if class_mode == "categorical":
+        # set class_mode, for accuracy computation:
-        elif class_mode == "binary":
+        elif class_mode == 'binary':
-    def compile(self, optimizer, loss, sample_weight_modes={}, **kwargs):
+    def compile(self, optimizer, loss, sample_weight_modes={},
-            test_loss += weighted_loss(y, y_test, weight, mask)
+            train_loss += loss_weights.get(output_name, 1.) * weighted_loss(y, y_train, weight, mask)
-        metrics = ['loss', 'val_loss']
+        if self.class_mode and show_accuracy:
-    def evaluate(self, data, batch_size=128, verbose=0, sample_weight={}):
+    def evaluate(self, data, batch_size=128, show_accuracy=False,
-        return outs[0]
+        if show_accuracy:
-    def train_on_batch(self, data, class_weight={}, sample_weight={}):
+    def train_on_batch(self, data, accuracy=False,
-        '''Compute the loss on a single batch of samples.
+    def test_on_batch(self, data, accuracy=False, sample_weight={}):
-    def evaluate_generator(self, generator, nb_val_samples,
+    def evaluate_generator(self, generator, nb_val_samples, show_accuracy=False,
-            Other argumens are as for `fit`.
+            Other arguments are the same as for `fit`.
-        all_outs = []
+        all_outs = None
-            all_outs.append(outs)
+            if show_accuracy:
-                          weights=weights)
+        if show_accuracy:
-                      verbose=1, callbacks=[],
+                      verbose=1, show_accuracy=False, callbacks=[],
-        metrics = ['loss', 'val_loss']
+        if show_accuracy:
-                                           class_weight=class_weight)
+                                           class_weight=class_weight,
-    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4, validation_data={'input1': X_test_graph, 'output1': y_test_graph})
+    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4,
-
+    # test show_accuracy
-def random_rotation(x, rg, fill_mode="nearest", cval=0.):
+def random_rotation(x, rg, fill_mode='nearest', cval=0.):
-def random_shift(x, wrg, hrg, fill_mode="nearest", cval=0.):
+def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0.):
-def random_shear(x, intensity, fill_mode="nearest", cval=0.):
+def random_shear(x, intensity, fill_mode='nearest', cval=0.):
-def random_zoom(x, rg, fill_mode="nearest", cval=0.):
+def random_zoom(x, rg, fill_mode='nearest', cval=0.):
-        return Image.fromarray(x.astype("uint8"), "RGB")
+        return Image.fromarray(x.astype('uint8'), 'RGB')
-        return Image.fromarray(x[:, :, 0].astype("uint8"), "L")
+        return Image.fromarray(x[:, :, 0].astype('uint8'), 'L')
-    realtime data augmentation.
+    real-time data augmentation.
-                 shear_range=0.,  # shear intensity (shear angle in radians)
+                 featurewise_center=True,
-            yield index_array[current_index: current_index + current_batch_size], current_index, current_batch_size
+            yield (index_array[current_index: current_index + current_batch_size],
-             save_to_dir=None, save_prefix="", save_format="jpeg"):
+             save_to_dir=None, save_prefix='', save_format='jpeg'):
-        self.flow_generator = self._flow_index(X.shape[0], batch_size, shuffle, seed)
+        self.flow_generator = self._flow_index(X.shape[0], batch_size,
-        # needed if we want to do something like for x, y in data_gen.flow(...):
+        # needed if we want to do something like:
-        # Keep under lock only the mechainsem which advance the indexing of each batch
+        # for python 2.x.
-            x = self.random_transform(x.astype("float32"))
+            x = self.random_transform(x.astype('float32'))
-                img.save(self.save_to_dir + "/" + self.save_prefix + "_" + str(current_index + i) + "." + self.save_format)
+                img.save(self.save_to_dir + '/' + self.save_prefix + '_' + str(current_index + i) + '.' + self.save_format)
-        # for python 3.x
+        # for python 3.x.
-            flatx = np.reshape(x, (x.shape[0]*x.shape[1]*x.shape[2]))
+            flatx = np.reshape(x, (x.shape[0] * x.shape[1] * x.shape[2]))
-            rounds=1,  # if augment, how many augmentation passes over the data do we use
+            augment=False,
-        '''Required for featurewise_center, featurewise_std_normalization and zca_whitening.
+        '''Required for featurewise_center, featurewise_std_normalization
-            aX = np.zeros(tuple([rounds*X.shape[0]]+list(X.shape)[1:]))
+            aX = np.zeros(tuple([rounds * X.shape[0]] + list(X.shape)[1:]))
-                    aX[i+r*X.shape[0]] = img_to_array(img)
+                    aX[i + r * X.shape[0]] = img_to_array(img)
-            flatX = np.reshape(X, (X.shape[0], X.shape[1]*X.shape[2]*X.shape[3]))
+            flatX = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))
-#     pytest.main([__file__])
+import pytest
-        the end of the sequence.
+def pad_sequences(sequences, maxlen=None, dtype='int32',
-        Supports post-padding and pre-padding (default).
+    If maxlen is provided, any sequence longer
-        -----------
+    Supports post-padding and pre-padding (default).
-        Returns:
+    # Returns
-    """
+    '''
-            continue # empty list was found
+            continue  # empty list was found
-            raise ValueError("Truncating type '%s' not understood" % truncating)
+            raise ValueError('Truncating type "%s" not understood' % truncating)
-                             % (trunc.shape[1:], idx, sample_shape))
+            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %
-            raise ValueError("Padding type '%s' not understood" % padding)
+            raise ValueError('Padding type "%s" not understood' % padding)
-        according to the sampling distribution used in word2vec.
+    '''This generates an array where the ith element
-            p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))
+    The word2vec formula is:
-           frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))
+    We assume that the word frequencies follow Zipf's law (s=1) to derive
-        size: int, number of possible words to sample. 
+    # Arguments
-        and label=0 if 'other_word' is ramdomly sampled
+    '''Take a sequence (list of indexes of words),
-        -----------
+    # Arguments
-        categorical: bool. if False, labels will be integers (eg. [0, 1, 1 .. ]),
+        window_size: int. actually half-window.
-        --------
+    # Returns
-        By convention, index 0 in the vocabulary is a non-word and will be skipped.
+    # Notes
-    from a fast Cython rewrite.
+'''These preprocessing utilities would greatly benefit
-            required before using texts_to_sequences or texts_to_matrix
+        '''Required before using texts_to_sequences or texts_to_matrix
-            (if fit_on_texts was never called)
+        '''Required before using sequences_to_matrix
-            Only words known by the tokenizer will be taken into account.
+        '''Transforms each text in texts in a sequence of integers.
-            Returns a list of sequences.
+        Returns a list of sequences.
-            Only words known by the tokenizer will be taken into account.
+        '''Transforms each text in texts in a sequence of integers.
-            Yields individual sequences.
+        Yields individual sequences.
-                        pass
+                        continue
-            modes: binary, count, tfidf, freq
+    def texts_to_matrix(self, texts, mode='binary'):
-            modes: binary, count, tfidf, freq
+    def sequences_to_matrix(self, sequences, mode='binary'):
-                raise Exception("Specify a dimension (nb_words argument), or fit on some text data first.")
+                raise Exception('Specify a dimension (nb_words argument), '
-            raise Exception("Fit the Tokenizer on some data before using tfidf mode.")
+        if mode == 'tfidf' and not self.document_count:
-                pass
+                continue
-                    pass
+                    continue
-                if mode == "count":
+                if mode == 'count':
-                elif mode == "freq":
+                elif mode == 'freq':
-                elif mode == "binary":
+                elif mode == 'binary':
-                elif mode == "tfidf":
+                elif mode == 'tfidf':
-                    raise Exception("Unknown vectorization mode: " + str(mode))
+                    raise Exception('Unknown vectorization mode: ' + str(mode))
-    graph = to_graph(model)
+def plot(model, to_file='model.png', **kwargs):
-def function(inputs, outputs, updates=[]):
+def function(inputs, outputs, updates=[], **kwargs):
-    return Function(inputs, outputs, updates=updates)
+def function(inputs, outputs, updates=[], **kwargs):
-                sample_weight_mode=None):
+                sample_weight_mode=None,
-        self._test_with_acc = K.function(test_ins, [test_loss, test_accuracy], updates=self.state_updates)
+        self._train = K.function(train_ins, [train_loss],
-    def compile(self, optimizer, loss, sample_weight_modes={}):
+    def compile(self, optimizer, loss, sample_weight_modes={}, **kwargs):
-        self._test = K.function(test_ins, [test_loss], updates=self.state_updates)
+        self._train = K.function(train_ins, [train_loss],
-                                   updates=self.state_updates)
+                                   updates=self.state_updates, **kwargs)
-        default values
+        '''Check for user typos in "params" keys to avoid
-            _SESSION = tf.Session('')
+            _SESSION = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))
-            _SESSION = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=nb_thread))
+            _SESSION = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=nb_thread, allow_soft_placement=True))
-    test_graph_fit_generator()
+    pytest.main([__file__])
-            the step function, of shape (samples, ...).
+
-def conv3d(x, kernel, strides=(1, 1, 1), border_mode='valid', dim_ordering='th',
+def conv3d(x, kernel, strides=(1, 1, 1),
-def _get_session():
+def get_session():
-def _set_session(session):
+def set_session(session):
-    _get_session().run(v.initializer)
+    get_session().run(v.initializer)
-    return x.get_shape()
+    # symbolic shape
-    return x.eval(session=_get_session())
+    return x.eval(session=get_session())
-        axis = axis % len(tensors[0].get_shape())
+        if len(tensors[0].get_shape()):
-        new_width = shape(X)[3].value * width_factor
+        new_shape = tf.shape(X)[2:]
-        X = tf.image.resize_nearest_neighbor(X, (new_height, new_width))
+        X = tf.image.resize_nearest_neighbor(X, new_shape)
-        return tf.image.resize_nearest_neighbor(X, (new_height, new_width))
+        new_shape = tf.shape(X)[1:3]
-    return x.eval(session=_get_session())
+    return x.eval(session=get_session())
-    tf.assign(x, np.asarray(value)).op.run(session=_get_session())
+    tf.assign(x, np.asarray(value)).op.run(session=get_session())
-        session = _get_session()
+        session = get_session()
-                                reduction_indices=len(output.get_shape())-1,
+                                reduction_indices=len(output.get_shape()) - 1,
-                                  tf.cast(1.-_EPSILON, dtype=_FLOATX))
+                                  tf.cast(1. - _EPSILON, dtype=_FLOATX))
-                               reduction_indices=len(output.get_shape())-1)
+                               reduction_indices=len(output.get_shape()) - 1)
-        self.sess = KTF._get_session()
+        self.sess = KTF.get_session()
-    old_session = KTF._get_session()
+    old_session = KTF.get_session()
-        KTF._set_session(session)
+        KTF.set_session(session)
-        KTF._set_session(session)
+        KTF.set_session(session)
-    KTF._set_session(old_session)
+    KTF.set_session(old_session)
-warnings.warn('data_utils has been moved to keras.utils.data_utils.')
+warnings.warn('data_utils has been moved to keras.utils.data_utils.')
-        assert type(updates) in {list, tuple}
+        assert type(inputs) in {list, tuple}, 'Input to a TensorFlow backend function should be a list or tuple.'
-from keras.datasets.data_utils import get_file
+from keras.utils.data_utils import get_file
-from keras.datasets.data_utils import get_file
+from keras.utils.data_utils import get_file
-from keras.datasets.data_utils import get_file
+from keras.utils.data_utils import get_file
-from .data_utils import get_file
+from ..utils.data_utils import get_file
-from .data_utils import get_file
+from ..utils.data_utils import get_file
-from __future__ import print_function
+from ..utils.data_utils import *
-    return fpath
+warnings.warn('data_utils has been moved to keras.utils.data_utils.')
-from .data_utils import get_file
+from ..utils.data_utils import get_file
-from .data_utils import get_file
+from ..utils.data_utils import get_file
-from .data_utils import get_file
+from ..utils.data_utils import get_file
-        self.non_trainable_weights = self.layer.non_traible_weights
+        self.non_trainable_weights = self.layer.non_trainable_weights
-
+    # test config
-
+    # test stacked layers
-            return output, []
+        if K._BACKEND == 'tensorflow':
-        return outputs
+            last_output, outputs, states = K.rnn(step, X,
-                input_shape[1] + self.padding * 2,
+                length,
-                    input_shape[3] + 2 * self.padding[1])
+                    width,
-                    input_shape[2] + 2 * self.padding[1],
+                    width,
-                    input_shape[4] + 2 * self.padding[2])
+                    dim1,
-                    input_shape[3] + 2 * self.padding[2],
+                    dim1,
-python neural_style.py path_to_your_base_image.jpg path_to_your_reference.jpg prefix_for_results
+python neural_style_transfer.py path_to_your_base_image.jpg path_to_your_reference.jpg prefix_for_results
-python neural_style.py img/tuebingen.jpg img/starry_night.jpg results/my_result
+python neural_style_transfer.py img/tuebingen.jpg img/starry_night.jpg results/my_result
-    img[:, :, 2] -= 123.68
+    img[0, :, :] -= 103.939
-    x[:, :, 2] += 123.68
+    x[0, :, :] += 103.939
-            and (input_dim,) for weights and biases respectively.
+            The list should have 2 elements, of shape `(input_dim, output_dim)`
-            and (input_dim,) for weights and biases respectively.
+            The list should have 2 elements, of shape `(input_dim, output_dim)`
-            and (input_dim,) for weights and biases respectively.
+            The list should have 2 elements, of shape `(input_dim, output_dim)`
-            The list should have 1 element, of shape `(input_dim, output_dim)`.
+            The list should have 2 elements, of shape `(input_dim, output_dim)`,
-            The list should have 1 element, of shape `(input_dim, output_dim)`.
+            The list should have 2 elements, of shape `(input_dim, output_dim)`,
-            The list should have 1 element, of shape `(input_dim, output_dim)`.
+            The list should have 2 elements, of shape `(input_dim, output_dim)`,
-        # needed if we want to do something like for x,y in data_gen.flow(...):
+        # needed if we want to do something like for x, y in data_gen.flow(...):
-            x /= self.std
+            x /= (self.std + 1e-7)
-            x -= np.mean(x)
+            x -= np.mean(x, axis=1, keepdims=True)
-            x /= np.std(x)
+            x /= (np.std(x, axis=1, keepdims=True) + 1e-7)
-            x = random_shear(x,self.shear_range)
+            x = random_shear(x, self.shear_range)
-            X /= self.std
+            X /= (self.std + 1e-7)
-            self.principal_components = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + fudge))), U.T)
+            self.principal_components = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 10e-7))), U.T)
-                                                     wait_time=wait_time)
+                                                     wait_time=wait_time, nb_worker=nb_worker)
-                                                           verbose=0)
+                                                           verbose=0, nb_worker=nb_val_worker,
-                                                     wait_time=wait_time)
+                                                     wait_time=wait_time, nb_worker=nb_worker)
-                                                           verbose=0)
+                                                           verbose=0,
-            is only relevant if you don't pass a `weights` argument.
+            Theano/TensorFlow function to use for weights initialization.
-            relevant if you don't pass a `weights` argument.
+            [initializations](../initializations.md)), or alternatively,
-                 weights=None, beta_init="zero", gamma_init="one", **kwargs):
+                 weights=None, beta_init='zero', gamma_init='one', **kwargs):
-
+        beta_init: name of initialization function for shift parameter
-        self.init = initializations.get("uniform")
+                 weights=None, beta_init="zero", gamma_init="one", **kwargs):
-        self.beta = K.zeros(shape, name='{}_beta'.format(self.name))
+        self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))
-    fan_out = shape[1] if len(shape) == 2 else shape[0]
+def get_fans(shape, dim_ordering='th'):
-def lecun_uniform(shape, name=None):
+def lecun_uniform(shape, name=None, dim_ordering='th'):
-    fan_in, fan_out = get_fans(shape)
+    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)
-def glorot_normal(shape, name=None):
+def glorot_normal(shape, name=None, dim_ordering='th'):
-    fan_in, fan_out = get_fans(shape)
+    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)
-    fan_in, fan_out = get_fans(shape)
+def glorot_uniform(shape, name=None, dim_ordering='th'):
-def he_normal(shape, name=None):
+def he_normal(shape, name=None, dim_ordering='th'):
-    fan_in, fan_out = get_fans(shape)
+    fan_in, fan_out = get_fans(shape, dim_ordering=dim_ordering)
-    fan_in, fan_out = get_fans(shape)
+def he_uniform(shape, name=None, dim_ordering='th'):
-    return get_from_module(identifier, globals(), 'initialization')
+def get(identifier, **kwargs):
-        self.init = initializations.get(init)
+        self.init = initializations.get(init, dim_ordering='th')
-        self.init = initializations.get(init)
+        self.init = initializations.get(init, dim_ordering=dim_ordering)
-        self.init = initializations.get(init)
+        self.init = initializations.get(init, dim_ordering=dim_ordering)
-    model.compile(loss='categorical_crossentropy', optimizer='sgd')
+    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
-        x *= K.concatenate([dropout_matrix] * timesteps, 0)
+
-        initial_state = K.permute_dimensions(initial_state, (1, 0))  # (samples, output_dim)
+        initial_state = K.zeros_like(x)  # (samples, timesteps, input_dim)
-    Use derived classes instead.
+    Use descendant classes instead.
-            Implementing the logic of the model.
+        build_fn: callable function or class instance
-    will then be used to fit data or predict unknow data. One of the following
+    will then be used to fit/predict. One of the following
-    estimators in scikit_learn, 'build_fn' should provide defalult velues for
+    1. A function
-    values to 'sk_params'.
+    values to `sk_params`.
-    fitting (predicting) parameters are adopts in the following order:
+    `sk_params` could also accept parameters for calling `fit`, `predict`,
-    batch_size or nb_epoch as well as the model parameters.
+    `fit`, `predict`, `predict_proba`, and `score` methods
-                contained subobjects that are estimators.
+                contained sub-objects that are estimators.
-            X : array-like, shape = (n_samples, n_features)
+            X : array-like, shape `(n_samples, n_features)`
-            y : array-like, shape = (n_samples) or (n_samples, n_outputs)
+            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`
-                Legal arguments are the arguments of Sequential.fit
+                Legal arguments are the arguments of `Sequential.fit`
-                and len(y.shape) != 2:
+        if self.model.loss.__name__ == 'categorical_crossentropy' and len(y.shape) != 2:
-    '''Implementation of the scikit-learn classifier API for Keras.'''
+    '''Implementation of the scikit-learn classifier API for Keras.
-        '''# Returns the class predictions for the given test data.
+        '''Returns the class predictions for the given test data.
-            X : array-like, shape = (n_samples, n_features)
+            X: array-like, shape `(n_samples, n_features)`
-                Legal arguments are the arguments of Sequential.predict_classes
+                Legal arguments are the arguments of `Sequential.predict_classes`.
-            preds : array-like, shape = (n_samples)
+            preds: array-like, shape `(n_samples,)`
-        '''# Returns class probability estimates for the given test data.
+        '''Returns class probability estimates for the given test data.
-            X : array-like, shape = (n_samples, n_features)
+            X: array-like, shape `(n_samples, n_features)`
-                Legal arguments are the arguments of Sequential.predict_classes
+                Legal arguments are the arguments of `Sequential.predict_classes`.
-            proba : array-like, shape = (n_samples, n_outputs)
+            proba: array-like, shape `(n_samples, n_outputs)`
-        '''# Returns the mean accuracy on the given test data and labels.
+        '''Returns the mean accuracy on the given test data and labels.
-            X : array-like, shape = (n_samples, n_features)
+            X: array-like, shape `(n_samples, n_features)`
-            y : array-like, shape = (n_samples) or (n_samples, n_outputs)
+            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`
-                Legal arguments are the arguments of Sequential.evaluate
+                Legal arguments are the arguments of `Sequential.evaluate`.
-            score : float
+            score: float
-    '''Implementation of the scikit-learn regressor API for Keras.'''
+    '''Implementation of the scikit-learn regressor API for Keras.
-        ''' Returns predictions for the given test data.
+        '''Returns predictions for the given test data.
-            X : array-like, shape = (n_samples, n_features)
+            X: array-like, shape `(n_samples, n_features)`
-                Legal arguments are the arguments of Sequential.predict
+                Legal arguments are the arguments of `Sequential.predict`.
-            preds : array-like, shape = (n_samples)
+            preds: array-like, shape `(n_samples,)`
-            X : array-like, shape = (n_samples, n_features)
+            X: array-like, shape `(n_samples, n_features)`
-            y : array-like, shape = (n_samples)
+            y: array-like, shape `(n_samples,)`
-                Legal arguments are the arguments of Sequential.evaluate
+                Legal arguments are the arguments of `Sequential.evaluate`.
-            score : float
+            score: float
-import abc
+import inspect
-        self.verbose = verbose
+
-        return {'model': self.model, 'optimizer': self.optimizer, 'loss': self.loss}
+        '''Get parameters for this estimator.
-        Set the parameters of this estimator.
+        '''Set the parameters of this estimator.
-        ----------
+        # Arguments
-            setattr(self, parameter, value)
+        # Returns
-                y = to_categorical(y)
+    def fit(self, X, y, **kwargs):
-            self.classes_ = np.arange(0, y.shape[1])
+            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))
-            callbacks=self.callbacks)
+        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))
-        self.weights_ = self.model.get_weights()
+        history = self.model.fit(X, y, **fit_args)
-            X, y, batch_size=self.test_batch_size, show_accuracy=True, verbose=self.verbose)
+
-            X, y, batch_size=self.test_batch_size, show_accuracy=False, verbose=self.verbose)
+
-def test_keras_classifier():
+def build_fn_clf(hidden_dims=50):
-    sklearn_clf.score(X_test, y_test)
+class Inherit_class_build_fn_clf(KerasClassifier):
-def test_keras_regressor():
+def build_fn_reg(hidden_dims=50):
-    model.add(Activation('softmax'))
+    model.add(Activation('linear'))
-    sklearn_regressor.score(X_test_reg, y_test_reg)
+# Usage of sklearn's grid_search
-        self.alphas = self.init(input_shape)
+        self.alphas = self.init(input_shape,
-        self.betas = K.variable(self.beta_init * np.ones(input_shape))
+        self.alphas = K.variable(self.alpha_init * np.ones(input_shape),
-        self.a_right_init = a_right_init
+        self.t_left_init = initializations.get(t_left_init)
-        self.a_right = initializations.get(self.a_right_init)(params_shape)
+        input_shape = self.input_shape[1:]
-        self.trainable_weights = [self.t_left, self.a_left, self.t_right, self.a_right]
+        self.trainable_weights = [self.t_left, self.a_left,
-        Y_left_and_center = self.t_left + K.relu(X - self.t_left, self.a_left, self.t_right_actual - self.t_left)
+        Y_left_and_center = self.t_left + K.relu(X - self.t_left,
-        self.b = K.zeros((self.nb_filter,))
+        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))
-        self.b = K.zeros((self.nb_filter,))
+        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))
-        self.b = K.zeros((self.nb_filter,))
+        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))
-        self.trainable = True
+
-            self.cache_enabled = kwargs['cache_enabled']
+        else:
-        self.b = K.zeros((self.output_dim,))
+        self.W = self.init((input_dim, self.output_dim),
-        self.b = K.zeros((self.output_dim,))
+        self.W = self.init((input_dim, self.output_dim),
-        self.b = K.zeros((self.nb_feature, self.output_dim))
+        self.W = self.init((self.nb_feature, input_dim, self.output_dim),
-        self.W_carry = self.init((input_dim, input_dim))
+        self.W = self.init((input_dim, input_dim),
-        self.b = K.zeros((input_dim,))
+        self.b = K.zeros((input_dim,), name='{}_b'.format(self.name))
-        self.b_carry = K.variable(np.ones((input_dim,)) * self.transform_bias)
+        self.b_carry = K.variable(np.ones((input_dim,)) * self.transform_bias,
-        self.W = self.init((self.input_dim, self.output_dim))
+        self.W = self.init((self.input_dim, self.output_dim),
-        self.beta = K.zeros(shape)
+        self.gamma = self.init(shape,
-        self.running_std = K.ones(shape)
+        self.running_mean = K.zeros(shape,
-        self.b = K.zeros((self.output_dim,))
+        self.W = self.init((input_dim, self.output_dim),
-        self.b_z = K.zeros((self.output_dim,))
+        self.W_z = self.init((input_dim, self.output_dim),
-        self.b_r = K.zeros((self.output_dim,))
+        self.W_r = self.init((input_dim, self.output_dim),
-        self.b_h = K.zeros((self.output_dim,))
+        self.W_h = self.init((input_dim, self.output_dim),
-        self.b_o = K.zeros((self.output_dim,))
+        self.W_i = self.init((input_dim, self.output_dim),
-                            ' and is not an input layer.')
+            self.input = K.placeholder(shape=self.input_shape)
-    layer = core.Masking()
+    layer = core.Masking(input_shape=(4, 1))
-    layer = core.Masking(5)
+    layer = core.Masking(5, input_shape=(4, 2))
-    layer = core.Masking(5)
+    layer = core.Masking(5, input_shape=(4, 2))
-                                    mode='max')
+        pool_out = pool.pool_2d(x, ds=pool_size, st=strides,
-                                    mode='average_exc_pad')
+        pool_out = pool.pool_2d(x, ds=pool_size, st=strides,
-                                 mode='max')
+        output = pool.pool_2d(input=x.dimshuffle(0, 1, 4, 3, 2),
-                                    mode='max')
+        pool_out = pool.pool_2d(input=output.dimshuffle(0, 1, 4, 3, 2),
-                                  mode='average_exc_pad')
+        output = pool.pool_2d(input=x.dimshuffle(0, 1, 4, 3, 2),
-                                    mode='average_exc_pad')
+        pool_out = pool.pool_2d(input=output.dimshuffle(0, 1, 4, 3, 2),
-from theano.tensor.signal import downsample
+from theano.tensor.signal import pool
-                                          mode='max')
+        pool_out = pool.max_pool_2d(x, ds=pool_size, st=strides,
-                                          mode='average_exc_pad')
+        pool_out = pool.max_pool_2d(x, ds=pool_size, st=strides,
-                                        mode='max')
+        output = pool.max_pool_2d(input=x.dimshuffle(0, 1, 4, 3, 2),
-                                          mode='max')
+        pool_out = pool.max_pool_2d(input=output.dimshuffle(0, 1, 4, 3, 2),
-                                        mode='average_exc_pad')
+        output = pool.max_pool_2d(input=x.dimshuffle(0, 1, 4, 3, 2),
-                                          mode='average_exc_pad')
+        pool_out = pool.max_pool_2d(input=output.dimshuffle(0, 1, 4, 3, 2),
-        for W in [self.W_i, self.W_f, self.W_i, self.W_o]:
+        for W in [self.W_i, self.W_f, self.W_c, self.W_o]:
-        for U in [self.U_i, self.U_f, self.U_i, self.U_o]:
+        for U in [self.U_i, self.U_f, self.U_c, self.U_o]:
-        for b in [self.b_i, self.b_f, self.b_i, self.b_o]:
+        for b in [self.b_i, self.b_f, self.b_c, self.b_o]:
-              nb_epoch=1)
+              nb_epoch=1,
-from keras.layers.core import Dense, Merge
+from keras.layers.core import Dense, Merge, Dropout, RepeatVector
-    return T.mean(x, axis=axis, keepdims=keepdims)
+    dtype = None
-QA2 - Two Supporting Facts   | 20               | 37.0
+QA1 - Single Supporting Fact | 50               | 100.0
-  - 37.0% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU)
+  - 100% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)
-RNN = recurrent.GRU
+RNN = recurrent.LSTM
-EPOCHS = 20
+EPOCHS = 40
-sentrnn.add(RNN(SENT_HIDDEN_SIZE, return_sequences=False))
+sentrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, input_length=story_maxlen, mask_zero=True))
-qrnn.add(RNN(QUERY_HIDDEN_SIZE, return_sequences=False))
+qrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, input_length=query_maxlen))
-model.add(Merge([sentrnn, qrnn], mode='concat'))
+model.add(Merge([sentrnn, qrnn], mode='sum'))
-        Y = self.layer(X, mask)
+        Y = self.layer(X, mask=mask, train=train)
-        e = K.exp(x)
+        e = K.exp(x - K.max(x, axis=-1, keepdims=True))
-            return Y
+        X = self.get_input(train)  # (samples, timesteps, input_dim)
-        initial_state = K.dot(initial_state, reducer)  # (samples, output_dim)
+        initial_state = X[:, 0, 0] * 0  # (samples, )
-        x *= K.concatenate([dropout] * timesteps, 0)
+        x *= K.concatenate([dropout_matrix] * timesteps, 0)
-            B_W = K.dropout(ones, self.dropout_W)
+            dropout = self.dropout_W
-            B_W = None
+            dropout = 0
-        return time_distributed_dense(x, self.W, self.b, B_W,
+        timesteps = input_shape[1]
-            B_U = []
+        return []
-            B_W = [K.dropout(ones, self.dropout_W) for _ in range(3)]
+            dropout = self.dropout_W
-            B_W = [None for _ in range(3)]
+            dropout = 0
-                                     B_W[2], input_dim, self.output_dim, timesteps)
+        timesteps = input_shape[1]
-            B_U = []
+        return []
-            B_W = [K.dropout(ones, self.dropout_W) for _ in range(4)]
+            dropout = self.dropout_W
-            B_W = [None for _ in range(4)]
+            dropout = 0
-                                     B_W[3], input_dim, self.output_dim, timesteps)
+        timesteps = input_shape[1]
-            return []
+        return []
-            raise ValueError("Truncating type '%s' not understood" % padding)
+            raise ValueError("Truncating type '%s' not understood" % truncating)
-model.add(LSTM(128, dropout_W=0.5, dropout_U=0.5))  # try using a GRU instead, for fun
+model.add(LSTM(128, dropout_W=0.5, dropout_U=0.1))  # try using a GRU instead, for fun
-        return None
+    def get_constants(self, x, train=False):
-    def get_initial_states(self, X):
+    def get_initial_states(self, x):
-        initial_state = K.zeros_like(X)  # (samples, timesteps, input_dim)
+        initial_state = K.zeros_like(x)  # (samples, timesteps, input_dim)
-        constants = self.get_constants(X, train)
+        constants = self.get_constants(X, train)
-        last_output, outputs, states = K.rnn(self.step, X,
+        last_output, outputs, states = K.rnn(self.step, preprocessed_input,
-        assert len(states) == 3  # 1 state and 2 constants
+    def preprocess_input(self, x, train=False):
-        h = K.dot(x * B_W, self.W) + self.b
+        if len(states) == 2:
-            B_U = K.random_binomial((nb_samples, self.output_dim), p=retain_p_U)
+    def get_constants(self, x, train=False):
-        return [B_W, B_U]
+            B_U = []
-        B_U = states[2]  # dropout matrix for recurrent units
+        if len(states) == 2:
-        x_h = K.dot(x * B_W[2], self.W_h) + self.b_h
+        x_z = x[:, :self.output_dim]
-            B_U = [K.random_binomial((nb_samples, self.output_dim), p=retain_p_U) for _ in range(3)]
+    def get_constants(self, x, train=False):
-        return [B_W, B_U]
+            B_U = []
-        B_U = states[3]
+        if len(states) == 3:
-        x_o = K.dot(x * B_W[3], self.W_o) + self.b_o
+        x_i = x[:, :self.output_dim]
-            B_U = [K.random_binomial((nb_samples, self.output_dim), p=retain_p_U) for _ in range(4)]
+    def get_constants(self, x, train=False):
-        return [B_W, B_U]
+            return []
-        return outputs
+        e = K.exp(x)
-        if input_length and K._BACKEND == 'theano':
+        if K._BACKEND == 'theano':
-            Y = self.activation(z + b)
+            z = T.tensordot(X, self.W, axes=[(2), (0)])
-
+        input_length = self.input_shape[1]
-            layer.get_input_mask = lambda _: mask 
+            layer.get_input_mask = lambda _: mask
-            assert layer.output_shape == self.input_shape, ('Cannot connect layers without resetting weights: ' + 
+            assert layer.output_shape == self.input_shape, ('Cannot connect layers without resetting weights: ' +
-            return (self.input_shape[0], ) + self._output_shape
+            nb_samples = self.input_shape[0] if self.input_shape else None
-        nb_param = len(self.layer.trainable_weights)
+        nb_param = len(self.layer.get_weights())
-                nb_param = len(self.inputs[i].trainable_weights)
+                nb_param = len(self.inputs[i].get_weights())
-        raise Exception('border_mode="same" not supported with Theano.')
+        w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1
-                                          ignore_border=ignore_border,
+                                          ignore_border=True,
-                                          ignore_border=ignore_border,
+                                          ignore_border=True,
-        layer.get_config()
+    for border_mode in ['valid', 'same']:
-        self.cache_enabled = False
+        # reset layer cache temporarily
-        self.cache_enabled = tmp_cache_enabled
+        self.layer_cache = tmp_layer_cache
-            if hasattr(self, 'shape_cache') and self.cache_enabled:
+            if self.shape_cache is not None and self.cache_enabled:
-            if hasattr(self, 'shape_cache') and self.cache_enabled:
+            if self.shape_cache is not None and self.cache_enabled:
-            if hasattr(self, 'layer_cache') and self.cache_enabled:
+            if self.layer_cache is not None and self.cache_enabled:
-            if hasattr(self, 'layer_cache') and self.cache_enabled:
+            if self.layer_cache is not None and self.cache_enabled:
-        self.layers[0].previous = layer
+    def set_previous(self, layer, reset_weights=True):
-    def set_previous(self, layer, connection_map={}):
+    def set_previous(self, layer, connection_map={}, reset_weights=True):
-            self.inputs[self.input_order[0]].set_previous(layer)
+            self.inputs[self.input_order[0]].set_previous(layer, reset_weights)
-                    self.inputs[k].set_previous(layer.outputs[v])
+                    self.inputs[k].set_previous(layer.outputs[v], reset_weights)
-        tmp_mask = None
+        # turn off layer cache temporarily
-        self.get_input = lambda _: X
+            layer.get_input_mask = lambda _: mask 
-        self.get_input = tmp_input
+        # return previous to what it was
-    def set_previous(self, layer):
+    def set_previous(self, layer, reset_weights=True):
-        self.build()
+        if reset_weights:
-        self.encoder.set_previous(node)
+    def set_previous(self, node, reset_weights=True):
-        layer.previous = self.inputs[head]
+        self.layer.set_previous(self.inputs[head], reset_weights=False)
-from keras.models import Sequential
+from keras.models import Sequential, Graph
-model.add(LSTM(128))  # try using a GRU instead, for fun
+model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.5))
-model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3,
+model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,
-model.compile(loss='rmse', optimizer='rmsprop')
+model.compile(loss='mse', optimizer='rmsprop')
-
+def conv3d(x, kernel, strides=(1, 1, 1), border_mode='valid', dim_ordering='th',
-                        size=(length_row, length_col),
+                layer = convolutional.UpSampling2D(
-                            assert out.shape[3] == length_col * input_nb_col
+                            assert out.shape[2] == length_dim1 * input_len_dim1
-                            assert out.shape[2] == length_col * input_nb_col
+                            assert out.shape[1] == length_dim1 * input_len_dim1
-                                                     axis=3)
+                            expected_out = np.repeat(input, length_dim1, axis=2)
-                                                     axis=2)
+                            expected_out = np.repeat(input, length_dim1, axis=1)
-        # states only contains the previous output.
+        # states contains the previous output,
-        B_U = states[2]
+        h_tm1 = states[0]  # previous memory
-            prog_width = int(self.width*prog)
+            prog = float(current) / self.target
-                bar += ('='*(prog_width-1))
+                bar += ('=' * (prog_width-1))
-            bar += ('.'*(self.width-prog_width))
+            bar += ('.' * (self.width - prog_width))
-            eta = time_per_unit*(self.target - current)
+            eta = time_per_unit * (self.target - current)
-                info += ((prev_total_width-self.total_width) * " ")
+                info += ((prev_total_width - self.total_width) * " ")
-        self.update(self.seen_so_far+n, values)
+        self.update(self.seen_so_far + n, values)
-                 activation='sigmoid',
+                 activation='tanh',
-                 activation='sigmoid', inner_activation='hard_sigmoid',
+                 activation='tanh', inner_activation='hard_sigmoid',
-from ..constraints import unitnorm
+from .. import initializations, regularizers, constraints
-        out = K.gather(self.W * K.expand_dims(B), X) # we zero-out rows of W at random
+        # we zero-out rows of W at random
-        assert len(states) == 3 # 1 state and 2 constants
+        assert len(states) == 3  # 1 state and 2 constants
-            B_U = np.ones(1, dtype=_FLOATX) * retain_p_U
+            B_W = np.ones(1, dtype=K.floatx()) * retain_p_W
-        assert len(states) == 3 # 1 state and 2 constants
+        assert len(states) == 3  # 1 state and 2 constants
-            B_U = np.ones(3, dtype=_FLOATX) * retain_p_U
+            B_W = np.ones(3, dtype=K.floatx()) * retain_p_W
-        assert len(states) == 4 # 2 states and 2 constants
+        assert len(states) == 4  # 2 states and 2 constants
-            B_U = np.ones(4, dtype=_FLOATX) * retain_p_U
+            B_W = np.ones(4, dtype=K.floatx()) * retain_p_W
-        val = np.random.random((20, 20))
+        val = np.random.random((100, 100))
-            raise Exception('No loss: ' + loss)
+from ..backend.common import _FLOATX
-                                             mask=mask, 
+                                             mask=mask,
-                 W_regularizer=None, U_regularizer=None, b_regularizer=None, 
+                 activation='sigmoid',
-            B_U = states[2]
+        B_W = states[1]
-            B_U = retain_p_U
+            B_W = np.ones(1, dtype=_FLOATX) * retain_p_W
-                  "dropout_W": self.dropout_W, 
+                  "dropout_W": self.dropout_W,
-                 W_regularizer=None, U_regularizer=None, b_regularizer=None, 
+                 W_regularizer=None, U_regularizer=None, b_regularizer=None,
-            B_U = [K.gather(states[2], i) for i in range(3)]
+        B_W = states[1]
-            B_U = K.random_binomial((3, nb_samples, self.output_dim), p=retain_p_U)
+            B_W = [K.random_binomial((nb_samples, self.input_dim), p=retain_p_W) for _ in range(3)]
-            B_U = K.ones(3) * retain_p_U
+            B_W = np.ones(3, dtype=_FLOATX) * retain_p_W
-                  "dropout_W": self.dropout_W, 
+                  "dropout_W": self.dropout_W,
-                 W_regularizer=None, U_regularizer=None, b_regularizer=None, 
+                 inner_activation='hard_sigmoid',
-            B_U = [K.gather(states[3], i) for i in range(4)]
+        B_W = states[2]
-            B_U = K.random_binomial((4, nb_samples, self.output_dim), p=retain_p_U)
+            B_W = [K.random_binomial((nb_samples, self.input_dim), p=retain_p_W) for _ in range(4)]
-            B_U = K.ones(4) * retain_p_U
+            B_W = np.ones(4, dtype=_FLOATX) * retain_p_W
-                  "dropout_W": self.dropout_W, 
+                  "dropout_W": self.dropout_W,
-                to `samples_per_epoch/5`
+                generator at the end of every epoch.
-                to `samples_per_epoch/5`
+                generator at the end of every epoch.
-                 wait_time=0.05, nb_worker=1):
+def generator_queue(generator, max_q_size=10,
-    def verify_gen_output(self, generator_output, stop):
+    def _check_generator_output(self, generator_output, stop):
-        stop.set() with the passed Event object stop
+        stop.set().
-            Other argumens are as for `fit`.
+            show_accuracy: whether to display accuracy in logs.
-        q, _stop = mk_gen_queue(generator, **kwargs)
+        q, _stop = generator_queue(generator, **kwargs)
-            X, y, sample_weight = self.verify_gen_output(q.get(), _stop)
+            X, y, sample_weight = self._check_generator_output(q.get(), _stop)
-                      validation_data=None, validation_samples=None,
+                      validation_data=None, nb_val_samples=None,
-                at least `validation_samples` examples have been obtained,
+                at least `nb_val_samples` examples have been obtained,
-            validation_samples: number of samples to use from validation
+            nb_val_samples: number of samples to use from validation
-        A `History` object.
+            A `History` object.
-            validation_samples = samples_per_epoch/5
+        if val_gen and not nb_val_samples:
-
+        data_gen_queue, _data_stop = generator_queue(generator, max_q_size=max_data_q_size,
-                                                                     _data_stop)
+            X_val, y_val, sample_weight_val = self._check_generator_output(validation_data,
-
+                X, y, sample_weight = self._check_generator_output(generator_output,
-                                                           validation_samples,
+                                                           nb_val_samples,
-    def evaluate_generator(self, generator, val_samples,
+    def evaluate_generator(self, generator, nb_val_samples,
-        by `evaluate`
+        by `evaluate`.
-            val_samples:
+            nb_val_samples:
-        q, _stop = mk_gen_queue(generator, **kwargs)
+        q, _stop = generator_queue(generator, **kwargs)
-            data, sample_weight = self.verify_gen_output(q.get(), _stop)
+        while done_samples < nb_val_samples:
-    def verify_gen_output(self, generator_output, stop):
+    def _check_generator_output(self, generator_output, stop):
-        the output
+        the output.
-                      validation_data=None, validation_samples=None,
+                      validation_data=None, nb_val_samples=None,
-                `validation_samples` examples have been generated at the
+                `nb_val_samples` examples have been generated at the
-            validation_samples: number of samples to use from validation
+            nb_val_samples: number of samples to use from validation
-        A `History` object.
+            A `History` object.
-            validation_samples = samples_per_epoch/5
+        if val_gen and not nb_val_samples:
-
+        data_gen_queue, _data_stop = generator_queue(generator, max_q_size=max_data_q_size,
-            data_val, sample_weight_val = self.verify_gen_output(validation_data, _data_stop)
+            data_val, sample_weight_val = self._check_generator_output(validation_data, _data_stop)
-                                                             _data_stop)
+                data, sample_weight = self._check_generator_output(generator_output,
-                                                           validation_samples,
+                                                           nb_val_samples,
-    model.fit_generator(data_generator(True), len(X_train), nb_epoch, show_accuracy=True, validation_data=data_generator(False))
+    model.fit_generator(data_generator(True), len(X_train), nb_epoch, show_accuracy=False,
-    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4, validation_data=data_generator_graph(False))
+    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4,
-    pass
+    test_sequential()
-        B_U = states[2]
+        if self.dropout_W == 0 and self.dropout_U == 0: 
-        if train and self.dropout_W > 0 and self.dropout_U > 0:
+        if train and (self.dropout_W > 0 or self.dropout_U > 0):
-        B_U = states[2]
+        if self.dropout_W == 0 and self.dropout_U == 0: 
-        x_h = K.dot(x * K.gather(B_W, 2), self.W_h) + self.b_h
+        x_z = K.dot(x * B_W[0], self.W_z) + self.b_z
-        r = self.inner_activation(x_r + K.dot(h_tm1 * K.gather(B_U, 1), self.U_r))
+        z = self.inner_activation(x_z + K.dot(h_tm1 * B_U[0], self.U_z))
-        hh = self.activation(x_h + K.dot(r * h_tm1 * K.gather(B_U, 2), self.U_h))
+        hh = self.activation(x_h + K.dot(r * h_tm1 * B_U[2], self.U_h))
-        if train and self.dropout_W > 0 and self.dropout_U > 0:
+        if train and (self.dropout_W > 0 or self.dropout_U > 0):
-        o = self.inner_activation(x_o + K.dot(h_tm1 * K.gather(B_U, 3), self.U_o))
+        if self.dropout_W == 0 and self.dropout_U == 0: 
-        if train and self.dropout_W > 0 and self.dropout_U > 0:
+        if train and (self.dropout_W > 0 or self.dropout_U > 0):
-                      validation_data=None, class_weight=None, nb_worker=1):
+                      validation_data=None, validation_samples=None,
-                they are assumed to be (input_data, target_data);
+            validation_data: tuple of 2 or 3 numpy arrays, or a generator.
-                (input_data, target_data, sample weights).
+                (input_data, target_data, sample weights). If generator,
-        max_queue_size = 10  # maximum number of batches in queue
+
-            return X, y, sample_weight
+        # start generator thread storing batches into a queue
-            X_val, y_val, sample_weight_val = input_validation(validation_data)
+        if do_validation and not val_gen:
-                        generator_output = generator_queue.get()
+                while not _data_stop.is_set():
-                X, y, sample_weight = input_validation(generator_output)
+                X, y, sample_weight = self.verify_gen_output(generator_output,
-                            epoch_logs['val_' + l] = o
+
-        _stop.set()
+        _data_stop.set()
-                      validation_data=None, class_weight={}, nb_worker=1):
+                      validation_data=None, validation_samples=None,
-                All arrays should contain the same number of samples.
+                held-out validation data, or a generator yielding such
-        max_queue_size = 10  # maximum number of batches in queue
+        max_data_q_size = 10  # maximum number of batches in queue
-            data_val, sample_weight_val = input_validation(validation_data)
+        # start generator thread storing batches into a queue
-                        generator_output = generator_queue.get()
+                while not _data_stop.is_set():
-
+                data, sample_weight = self.verify_gen_output(generator_output,
-                            epoch_logs['val_' + l] = o
+                # epoch finished
-        _stop.set()
+        _data_stop.set()
-    test_lambda()
+    # test_sequential()
-                            p_W=0.5, p_U=0.5)
+                            dropout_W=0.5, dropout_U=0.5)
-      p: float between 0 and 1. Fraction of the embeddings to drop.
+      dropout: float between 0 and 1. Fraction of the embeddings to drop.
-                 weights=None, p=0., **kwargs):
+                 weights=None, dropout=0., **kwargs):
-        self.p = p
+        self.dropout = dropout
-        if train and self.p > 0:
+        retain_p = 1. - self.dropout
-                  "p": self.p}
+                  "dropout": self.dropout}
-        p_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.
+        dropout_W: float between 0 and 1. Fraction of the input units to drop for input gates.
-                 p_W=0., p_U=0., **kwargs):
+                 dropout_W=0., dropout_U=0., **kwargs):
-        self.p_W, self.p_U = p_W, p_U
+        self.dropout_W, self.dropout_U = dropout_W, dropout_U
-        def appendRegulariser(input_regulariser, param, regularizers_list):
+        def append_regulariser(input_regulariser, param, regularizers_list):
-        appendRegulariser(self.b_regularizer, self.b, self.regularizers)
+        append_regulariser(self.W_regularizer, self.W, self.regularizers)
-        if train and self.p_W > 0 and self.p_U > 0:
+        retain_p_W = 1. - self.dropout_W
-                  "p_U": self.p_U}
+                  "dropout_W": self.dropout_W, 
-        p_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.
+        dropout_W: float between 0 and 1. Fraction of the input units to drop for input gates.
-                 p_W=0., p_U=0., **kwargs):
+                 dropout_W=0., dropout_U=0., **kwargs):
-        self.p_W, self.p_U = p_W, p_U
+        self.dropout_W, self.dropout_U = dropout_W, dropout_U
-        def appendRegulariser(input_regulariser, param, regularizers_list):
+        def append_regulariser(input_regulariser, param, regularizers_list):
-            appendRegulariser(self.W_regularizer, W, self.regularizers)
+            append_regulariser(self.W_regularizer, W, self.regularizers)
-            appendRegulariser(self.U_regularizer, U, self.regularizers)
+            append_regulariser(self.U_regularizer, U, self.regularizers)
-            appendRegulariser(self.b_regularizer, b, self.regularizers)
+            append_regulariser(self.b_regularizer, b, self.regularizers)
-        if train and self.p_W > 0 and self.p_U > 0:
+        retain_p_W = 1. - self.dropout_W
-                  "p_U": self.p_U}
+                  "dropout_W": self.dropout_W, 
-        p_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.
+        dropout_W: float between 0 and 1. Fraction of the input units to drop for input gates.
-                 p_W=0., p_U=0., **kwargs):
+                 dropout_W=0., dropout_U=0., **kwargs):
-        self.p_W, self.p_U = p_W, p_U
+        self.dropout_W, self.dropout_U = dropout_W, dropout_U
-        def appendRegulariser(input_regulariser, param, regularizers_list):
+        def append_regulariser(input_regulariser, param, regularizers_list):
-            appendRegulariser(self.W_regularizer, W, self.regularizers)
+            append_regulariser(self.W_regularizer, W, self.regularizers)
-            appendRegulariser(self.U_regularizer, U, self.regularizers)
+            append_regulariser(self.U_regularizer, U, self.regularizers)
-            appendRegulariser(self.b_regularizer, b, self.regularizers)
+            append_regulariser(self.b_regularizer, b, self.regularizers)
-        if train and self.p_W > 0 and self.p_U > 0:
+        retain_p_W = 1. - self.dropout_W
-                  "p_U": self.p_U}
+                  "dropout_W": self.dropout_W, 
-        batch by batch.
+        '''Generate output predictions for the input samples
-        tf.ones(shape), tf.zeros(shape))
+                     tf.ones(shape), tf.zeros(shape))
-        loss=None, mean_y_train=None, std_y_train=None):
+                 loss=None, mean_y_train=None, std_y_train=None):
-            batch_size=self.batch_size, verbose=self.verbose)
+        model_output = self.model.predict(self.Xt, batch_size=self.batch_size, 
-                batch_size=self.batch_size, verbose=self.verbose)]
+                                                              batch_size=self.batch_size, 
-        self.regularizers = []
+        self.regularizers = []
-        self.regularizers = []
+        self.regularizers = []
-        self.regularizers = []
+        self.regularizers = []
-            B = K.random_binomial((self.input_dim), p=retain_p)
+            B = K.random_binomial((self.input_dim,), p=retain_p)
-                            '(including batch size).')
+                            'input_shape must be provided (including batch size).')
-            nb_samples = int(nb_samples)
+        if K._BACKEND == 'tensorflow' and train and self.p_W > 0 and self.p_U > 0:
-                            '(including batch size).')
+                            'input_shape must be provided (including batch size).')
-            nb_samples = int(nb_samples)
+        if K._BACKEND == 'tensorflow' and train and self.p_W > 0 and self.p_U > 0:
-                            '(including batch size).')
+                            'input_shape must be provided (including batch size).')
-            nb_samples = int(nb_samples)
+        if K._BACKEND == 'tensorflow' and train and self.p_W > 0 and self.p_U > 0:
-                mask = layer.get_output_mask(train)
+    for ret_seq in [True, False]:
-            B = K.random_binomial((1, self.input_dim), p=retain_p)
+            B = K.random_binomial((self.input_dim), p=retain_p)
-        out = K.gather(self.W * B[0][:, None], X) # (self.W * B[0][:, None])[X] - we zero-out rows of W at random
+            B = K.ones((self.input_dim)) * retain_p
-        nb_samples = X.shape[0]
+        nb_samples = K.shape(X)[0]
-        x_h = K.dot(x * B_W[2], self.W_h) + self.b_h
+        x_z = K.dot(x * K.gather(B_W, 0), self.W_z) + self.b_z
-        r = self.inner_activation(x_r + K.dot(h_tm1 * B_U[1], self.U_r))
+        z = self.inner_activation(x_z + K.dot(h_tm1 * K.gather(B_U, 0), self.U_z))
-        hh = self.activation(x_h + K.dot(r * h_tm1 * B_U[2], self.U_h))
+        hh = self.activation(x_h + K.dot(r * h_tm1 * K.gather(B_U, 2), self.U_h))
-        nb_samples = X.shape[0]
+        nb_samples = K.shape(X)[0]
-        x_o = K.dot(x * B_W[3], self.W_o) + self.b_o
+        x_i = K.dot(x * K.gather(B_W, 0), self.W_i) + self.b_i
-        o = self.inner_activation(x_o + K.dot(h_tm1 * B_U[3], self.U_o))
+        i = self.inner_activation(x_i + K.dot(h_tm1 * K.gather(B_U, 0), self.U_i))
-        nb_samples = X.shape[0]
+        nb_samples = K.shape(X)[0]
-            mask = layer.get_output_mask(train)
+    for p in [0., 0.5]:
-        initial_output = step_function(inputs[0], initial_states)[0] * 0
+        initial_output = step_function(inputs[0], initial_states + constants)[0] * 0
-        go_backwards=False, mask=None):
+        go_backwards=False, mask=None, constants=None):
-            output, new_states = step_function(input, states)
+            output, new_states = step_function(input, states + constants)
-            output, states = step_function(input, states)
+            output, states = step_function(input, states + constants)
-        go_backwards=False, mask=None):
+        go_backwards=False, mask=None, constants=None):
-from .. import backend as K
+import numpy as np
-                 weights=None, **kwargs):
+                 weights=None, p=0., **kwargs):
-        out = K.gather(self.W, X)
+        retain_p = 1. - self.p
-                  "W_constraint": self.W_constraint.get_config() if self.W_constraint else None}
+                  "W_constraint": self.W_constraint.get_config() if self.W_constraint else None,
-from .. import activations, initializations
+from .. import activations, initializations, regularizers
-                                             mask=mask)
+                                             mask=mask, 
-    '''Fully-connected RNN where the output is to fed back to input.
+    '''Fully-connected RNN where the output is to be fed back to input.
-                 activation='sigmoid', **kwargs):
+                 activation='sigmoid', 
-        assert len(states) == 1
+        assert len(states) == 3 # 1 state and 2 constants
-        output = self.activation(h + K.dot(prev_output, self.U))
+        B_W = states[1]
-                  "activation": self.activation.__name__}
+                  "activation": self.activation.__name__,
-                 **kwargs):
+                 W_regularizer=None, U_regularizer=None, b_regularizer=None, 
-
+        assert len(states) == 3 # 1 state and 2 constants
-        r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r))
+        B_W = states[1]
-        hh = self.activation(x_h + K.dot(r * h_tm1, self.U_h))
+        hh = self.activation(x_h + K.dot(r * h_tm1 * B_U[2], self.U_h))
-                  "inner_activation": self.inner_activation.__name__}
+                  "inner_activation": self.inner_activation.__name__,
-                 inner_activation='hard_sigmoid', **kwargs):
+                 inner_activation='hard_sigmoid', 
-            # initial states: 2 all-zero tensor of shape (output_dim)
+            # initial states: 2 all-zero tensors of shape (output_dim)
-        assert len(states) == 2
+        assert len(states) == 4 # 2 states and 2 constants
-        o = self.inner_activation(x_o + K.dot(h_tm1, self.U_o))
+        B_W = states[2]
-                  "inner_activation": self.inner_activation.__name__}
+                  "inner_activation": self.inner_activation.__name__,
-        history = cbks.History()
+        self.history = cbks.History()
-            callbacks = [history] + callbacks
+            callbacks += [cbks.ProgbarLogger()]
-        return history
+        return self.history
-        history = cbks.History()
+        self.history = cbks.History()
-            callbacks = [history] + callbacks
+            callbacks += [cbks.ProgbarLogger()]
-        return history
+        return self.history
-                          'fallback to auto mode.' % (self.mode),
+                          'fallback to auto mode.' % (mode),
-            self.layers[i].set_weights(weights[:nb_param])
+        for layer in self.layers:
-        history = cbks.History()
+        self.history = cbks.History()
-            callbacks = [history] + callbacks
+            callbacks += [cbks.ProgbarLogger()]
-        return history
+        return self.history
-        history = cbks.History()
+        self.history = cbks.History()
-            callbacks = [history] + callbacks
+            callbacks += [cbks.ProgbarLogger()]
-        return history
+        return self.history
-from six.moves.urllib.request import urlopen, build_opener, install_opener
+import shutil
-            raise Exception(error_msg.format(url, e.code, e.msg))
+            try:
-            tfile.extractall(path=datadir)
+            try:
-    
+
-        
+            sample_weight_mode = config.get('sample_weight_mode')
-                          class_mode=class_mode)
+                          class_mode=class_mode, sample_weight_mode=sample_weight_mode)
-            model.compile(loss=loss, optimizer=optimizer)
+            sample_weight_modes = config.get('sample_weight_modes', {})
-        for p in ['class_mode']:
+        for p in ['class_mode', 'sample_weight_mode', 'sample_weight_modes']:
-
+                
-        callbacks = [cbks.BaseLogger()] + callbacks + [history]
+        self.history = cbks.History()
-        return history
+        return self.history
-        on_epoch_end: logs optionally include `val_loss`
+        on_epoch_end: logs include `acc` and `loss`, and
-    '''Callback that prints events to the standard output.
+    '''Callback that accumulates epoch averages of
-    in models).
+    every Keras model.
-        for name, value in all_values.items():
+        for name, value in logs.items():
-            callbacks = [history] + callbacks
+            callbacks += [cbks.ProgbarLogger()]
-    x = (np.ones((nb_samples, maxlen)) * value).astype(dtype)
+    # take the sample shape from the first non empty sequence
-        f = h5py.File(filepath,mode="r")
+        f = h5py.File(filepath, mode='r')
-        f = h5py.File(filepath)
+        f = h5py.File(filepath, mode='r')
-    indices: an int tensor of indices.
+    '''
-    Return: a tensor of same type as reference.
+    # Returns
-    dimension indices, e.g. [0, 2, 1].
+    # Arguments
-            the step function, of shape (samples, ...).
+    # Arguments
-    '''condition: scalar tensor.
+    '''Switch between two operations depending on a scalar value.
-    ----------
+    # Arguments
-                  "alpha": self.alpha}
+        config = {'name': self.__class__.__name__,
-                  "init": self.init.__name__}
+        config = {'name': self.__class__.__name__,
-                  "alpha": self.alpha}
+        config = {'name': self.__class__.__name__,
-                  "beta_init": self.beta_init}
+        config = {'name': self.__class__.__name__,
-                  "theta": self.theta}
+        config = {'name': self.__class__.__name__,
-                  "theta": self.theta}
+        config = {'name': self.__class__.__name__,
-        }
+        return {'name': self.__class__.__name__,
-            
+
-            assert_allclose(outp, -inp*alpha)
+            assert_allclose(outp, -inp * alpha)
-        assert_allclose(-alphas*inp, outp)
+        assert_allclose(-alphas * inp, outp)
-        assert_allclose(0., alphas*outp)
+        assert_allclose(0., alphas * outp)
-            assert_allclose(outp, alpha*(np.exp(-inp)-1.), rtol=1e-3)
+            assert_allclose(outp, alpha * (np.exp(-inp) - 1.), rtol=1e-3)
-                assert_allclose(outp, alpha*np.log(1.+np.exp(beta*inp)),
+                assert_allclose(outp, alpha * np.log(1. + np.exp(beta * inp)),
-            assert_allclose(outp, inp*(np.abs(inp) >= theta))
+            assert_allclose(outp, inp * (np.abs(inp) >= theta))
-            assert_allclose(outp, -inp*(np.abs(inp) >= theta))
+            assert_allclose(outp, -inp * (np.abs(inp) >= theta))
-            assert_allclose(outp, inp*(inp > theta))
+            assert_allclose(outp, inp * (inp > theta))
-            assert_allclose(outp, -inp*(-inp > theta))
+            assert_allclose(outp, -inp * (-inp > theta))
-
+        layer.set_weights([ones_proto * -1., ones_proto * 0.5,
-        f = h5py.File(filepath)
+        f = h5py.File(filepath,mode="r")
-        mode: one of {sum, mul, concat, ave, dot}.
+        mode: one of {sum, mul, concat, ave, join, cos, dot}.
-from six.moves.urllib.request import FancyURLopener
+import sys
-        raise Exception('URL fetch failure on {}: {} -- {}'.format(url, errcode, errmsg))
+# Under Python 2, 'urlretrieve' relies on FancyURLopener from legacy
-        ParanoidURLopener().retrieve(origin, fpath, dl_progress)
+        error_msg = 'URL fetch failure on {}: {} -- {}'
-    # Arguments
+    Parameters
-    x -= tf.constant(alpha, dtype=_FLOATX) * negative_part
+    if isinstance(alpha, (tuple, list, np.ndarray)) or np.isscalar(alpha):
-        _SESSION = tf.Session('')
+        if not os.environ.get('OMP_NUM_THREADS'):
-        for nb_row, nb_col in [(3, 3), (4, 4)]:
+        for nb_row, nb_col in [(3, 3), (4, 4), (3, 4)]:
-                raise Exception('Layer shape %s not compatible with weight shape %s.' % (K.get_value(p).shape, w.shape))
+                raise Exception('Layer weight shape %s not compatible with provided weight shape %s.' % (K.get_value(p).shape, w.shape))
-    alpha: slope of negative section.
+    # Arguments
-    in inputs/kernels/ouputs.
+    '''Runs on cuDNN if available.
-    dim_ordering: one of "th", "tf".
+    # Arguments
-            import theano
+                raise Exception('"cos" merge mode will only work with Theano.')
-
+    shift_x = shift_y = 0
-        crop_left_pixels = int(split*crop*x.shape[1])
+        shift_x = random.uniform(-wrg, wrg) * x.shape[2]
-    x = ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels),
+        shift_y = random.uniform(-hrg, hrg) * x.shape[1]
-            return self.previous.output_shape
+            if hasattr(self, 'shape_cache') and self.cache_enabled:
-                       r'    __\1__\n\n',
+    docstring = re.sub(r'\n        # (.*)\n',
-        for nb_row, nb_col in [(2, 2), (3, 3)]:
+        for nb_row, nb_col in [(3, 3), (4, 4)]:
-                for input_data_shape in [(2, 1, 4, 4), (2, 1, 5, 5)]:
+                for input_data_shape in [(2, 1, 5, 5), (2, 1, 6, 6)]:
-                for input_data_shape in [(2, 3, 3, 1)]:
+                for input_data_shape in [(2, 5, 5, 1)]:
-            assert(strides == (1, 1))
+            np_kernel = kernel.eval()
-            shift_y = (np_kernel.shape[3] - 1) // 2
+            shift_x = (np_kernel.shape[2] - strides[0]) // 2
-                                shift_y:x.shape[3] + shift_y]
+                                shift_x: shift_x + expected_width,
-            assert(strides == (1, 1))
+            np_kernel = kernel.eval()
-            shift_y = (np_kernel.shape[3] - 1) // 2
+            shift_x = (np_kernel.shape[2] - strides[0]) // 2
-                                shift_y:x.shape[3] + shift_y]
+                                shift_x: shift_x + expected_width,
-                if (subsample[0] > 1 or subsample[1] > 1) and border_mode == 'same':
+            for subsample in [(1, 1), (2, 2), (3, 3)]:
-                for input_data_shape in [(2, 1, 3, 3), (2, 1, 4, 4)]:
+                for input_data_shape in [(2, 1, 4, 4), (2, 1, 5, 5)]:
-__version__ = '0.3.1'
+__version__ = '0.3.2'
-      description='Theano-based Deep Learning library',
+      version='0.3.2',
-      download_url='https://github.com/fchollet/keras/tarball/0.3.1',
+      download_url='https://github.com/fchollet/keras/tarball/0.3.2',
-        if self.histogram_freq:
+        if self.histogram_freq and not self.merged:
-        
+
-                            val_outs = self.evaluate(X, y,
+                            val_outs = self.evaluate(X_val, y_val,
-                                                     sample_weight=sample_weight,
+                                                     sample_weight=sample_weight_val,
-                                                     sample_weight=sample_weight,
+                            val_outs = self.evaluate(data_val,
-        shutil.rmtree(filepath)
+    def data_generator(train):
-    # case 2 Sequential w accuracy
+
-    # case 3 Graph
+    # case 2 Graph
-    assert ndim >= 3, "Input should be at least 3D."
+    assert ndim >= 3, 'Input should be at least 3D.'
-        go_backwards=go_backwards)
+    if mask is not None:
-        # Input shape
+    # Input shape
-                       r'    __\1__\n\n',
+    docstring = re.sub(r'\n    # (.*)\n',
-    (`f(x) = alpha*x for x < 0`).
+    that allows a small gradient when the unit is not active:
-    left.add(Activation('relu'))
+        left = Sequential()
-    right.add(Activation('relu'))
+        right = Sequential()
-    model.add(Merge([left, right], mode='sum'))
+        model = Sequential()
-    model.add(Activation('softmax'))
+        model.add(Dense(10))
-    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
-              validation_data=([X_test, X_test], Y_test))
+        model.fit([X_train, X_train], Y_train, batch_size=128, nb_epoch=20,
-
+class ActivityRegularization(Layer):
-    from keras.layers import containers
+        from keras.layers import containers, AutoEncoder, Dense
-    decoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])
+        # input shape: (nb_samples, 32)
-    model.add(autoencoder)
+        autoencoder = AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=True)
-    model.fit(X_train, X_train, nb_epoch=10)
+        # training the autoencoder:
-    representations = model.predict(X_test)
+        # predicting compressed representations of inputs:
-    model.fit(X_test, representations, nb_epoch=1)  # in this case the loss will be 0, so it's useless
+        # the model is still trainable, although it now expects compressed representations as targets:
-    model.fit(X_train, X_train, nb_epoch=10)
+        # to keep training against the original inputs, just switch back output_reconstruction to True:
-                            samples_per_epoch=10000, nb_epoch=10)
+            def generate_arrays_from_file(path):
-                            samples_per_epoch=10000, nb_epoch=10)
+            def generate_arrays_from_file(path):
-                name = getattr(self.layers[i], 'name')
+                name = getattr(self.layers[i], 'name', None)
-            name = getattr(self.inputs[i], 'name')
+            name = getattr(self.inputs[i], 'name', None)
-Get to 99.5% test accuracy after 20 epochs.
+Gets to 99.5% test accuracy after 20 epochs.
-from keras.layers.core import *
+from keras.layers.core import Dense, Dropout, Lambda
-        'Euclidean distance needs 2 inputs, %d given' % len(inputs)
+    assert len(inputs) == 2, ('Euclidean distance needs '
-    return K.sqrt((K.square(u - v)).sum(axis=1, keepdims=True))
+    return K.sqrt(K.sum(K.square(u - v), axis=1, keepdims=True))
-    """
+    '''Contrastive loss from Hadsell-et-al.'06
-    """
+    '''Positive and negative pair creation.
-    """
+def create_base_network(input_dim):
-    seq.add(Dense(128, input_shape=(in_dim,), activation='relu'))
+    seq.add(Dense(128, input_shape=(input_dim,), activation='relu'))
-    """
+    '''Compute classification accuracy with a fixed threshold on distances.
-in_dim = 784
+input_dim = 784
-base_network = create_base_network(in_dim)
+base_network = create_base_network(input_dim)
-g.add_input(name='input_b', input_shape=(in_dim,))
+g.add_input(name='input_a', input_shape=(input_dim,))
-      batch_size=128, nb_epoch=nb_epoch)
+      batch_size=128,
-        keys = input_dict.keys()
+        keys = list(input_dict.keys())
-        layer = Layer()  # empty layer
+        layer = Layer(name=name)  # empty layer
-                if X.name is None:
+                name = getattr(self.layers[i], 'name')
-                    inputs[X.name] = X
+                    inputs[name] = X
-            if X.name is None:
+            name = getattr(self.inputs[i], 'name')
-            o[X.name] = X
+            o[name] = X
-    pytest.main([__file__])
+    # pytest.main([__file__])
-    single layer of GRU units
+    Predict float numbers (regression) based on sequences
-                  optimizer='adam', sample_weight_mode="temporal")
+                  optimizer='adam',
-        padding = np.random.random_integers(X.shape[1]/2)
+        padding = np.random.random_integers(X.shape[1] / 2)
-    y = (X * np.random.random_integers(1, 2, X.shape))%10
+    # 50% of the time the correct output is the input.
-    history = model.fit(X, Y, validation_split=0.05, sample_weight=sample_weight,verbose=1, nb_epoch=2)
+    history = model.fit(X, Y, validation_split=0.05,
-    pytest.main([__file__])
+# import pytest
-          objectives.hinge, objectives.categorical_crossentropy, objectives.binary_crossentropy, objectives.poisson,
+allobj = [objectives.mean_squared_error,
-from keras.layers.core import TimeDistributedDense, Dropout, Dense
+from keras.layers.core import TimeDistributedDense, Dropout, Dense, Activation
-        raise Exception('ndim too large: ' + str(ndim))
+    broadcast = (False,) * ndim
-        self.params = [self.alphas]
+        self.trainable_weights = [self.alphas]
-        self.params = [self.alphas, self.betas]
+        self.trainable_weights = [self.alphas, self.betas]
-        params = []
+    def trainable_weights(self):
-        return params
+                weights += l.get_params()[0]
-            nb_param = len(self.layers[i].params) + len(self.layers[i].non_trainable_weights)
+            nb_param = len(self.layers[i].trainable_weights) + len(self.layers[i].non_trainable_weights)
-        params = []
+    def trainable_weights(self):
-        return params
+                weights += l.get_params()[0]
-        self.params = [self.W, self.b]
+        self.trainable_weights = [self.W, self.b]
-        self.params = [self.W, self.b]
+        self.trainable_weights = [self.W, self.b]
-            self.params = []
+        if not hasattr(self, 'trainable_weights'):
-            
+
-        params = self.params + self.non_trainable_weights
+        params = self.trainable_weights + self.non_trainable_weights
-        params = self.params + self.non_trainable_weights
+        params = self.trainable_weights + self.non_trainable_weights
-        if hasattr(self, 'constraints') and len(self.constraints) == len(self.params):
+        if hasattr(self, 'constraints') and len(self.constraints) == len(self.trainable_weights):
-            consts += [self.constraint for _ in range(len(self.params))]
+            consts += [self.constraint for _ in range(len(self.trainable_weights))]
-            consts += [constraints.identity() for _ in range(len(self.params))]
+            consts += [constraints.identity() for _ in range(len(self.trainable_weights))]
-        return self.params, regularizers, consts, updates
+        return self.trainable_weights, regularizers, consts, updates
-        return sum([K.count_params(p) for p in self.params])
+        return sum([K.count_params(p) for p in self.trainable_weights])
-        self.params = []
+        self.trainable_weights = []
-        self.params = []
+        self.trainable_weights = []
-                    self.params.append(p)
+                if p not in self.trainable_weights:
-        return self.params, self.regularizers, self.constraints, self.updates
+        return self.trainable_weights, self.regularizers, self.constraints, self.updates
-            nb_param = len(self.layers[i].params)
+            nb_param = len(self.layers[i].trainable_weights)
-        self.params = [self.W, self.b]
+        self.trainable_weights = [self.W, self.b]
-        self.params = [self.W, self.b]
+        self.trainable_weights = [self.W, self.b]
-        self.params = []
+        self.trainable_weights = []
-                    self.params.append(p)
+                if p not in self.trainable_weights:
-        nb_param = len(self.encoder.params)
+        nb_param = len(self.encoder.trainable_weights)
-        self.params = [self.W, self.b]
+        self.trainable_weights = [self.W, self.b]
-        self.params = []
+        self.trainable_weights = []
-                    self.params.append(p)
+                if p not in self.trainable_weights:
-        return self.params, self.regularizers, self.constraints, self.updates
+        return self.trainable_weights, self.regularizers, self.constraints, self.updates
-            nb_param = len(self.layers[i].params)
+            nb_param = len(self.layers[i].trainable_weights) + len(self.non_trainable_weights)
-        self.params = []
+        self.trainable_weights = []
-                    self.params.append(p)
+                if p not in self.trainable_weights:
-        return self.params, self.regularizers, self.constraints, self.updates
+        return self.trainable_weights, self.regularizers, self.constraints, self.updates
-        nb_param = len(self.layer.params)
+        nb_param = len(self.layer.trainable_weights)
-                nb_param = len(self.inputs[i].params)
+                nb_param = len(self.inputs[i].trainable_weights)
-        self.params = []
+        self.trainable_weights = []
-        self.params = [self.W, self.b, self.W_carry, self.b_carry]
+        self.trainable_weights = [self.W, self.b, self.W_carry, self.b_carry]
-        self.params = [self.W]
+        self.trainable_weights = [self.W]
-        
+        self.trainable_weights = [self.gamma, self.beta]
-        
+
-        self.params = [self.W, self.U, self.b]
+        self.trainable_weights = [self.W, self.U, self.b]
-
+        self.trainable_weights = [self.W_z, self.U_z, self.b_z,
-                       self.W_o, self.U_o, self.b_o]
+        self.trainable_weights = [self.W_i, self.U_i, self.b_i,
-        updates = self.optimizer.get_updates(self.params,
+        updates = self.optimizer.get_updates(self.trainable_weights,
-        updates = self.optimizer.get_updates(self.params,
+        updates = self.optimizer.get_updates(self.trainable_weights,
-    norm = np.linalg.norm(K.get_value(lookup.params[0]), axis=0)
+    norm = np.linalg.norm(K.get_value(lookup.trainable_weights[0]), axis=0)
-            nb_param = len(self.layers[i].params)
+            nb_param = len(self.layers[i].params) + len(self.layers[i].non_trainable_weights)
-        for p, w in zip(self.params, weights):
+        params = self.params + self.non_trainable_weights
-        for p in self.params:
+        for p in params:
-
+        
-
+        self.non_trainable_weights = [self.running_mean, self.running_std]
-                                  'dtype': dtype})
+        config = {'name': name, 'dtype': dtype}
-            self.set_input_shape((None,) + tuple(kwargs['input_shape']))
+        elif 'input_shape' in kwargs:
-                  "input_length": self.input_length,
+        if self.stateful:
-    assert x.ndim == 2
+    assert ndim(x) == 2
-    return stacked.dimshuffle((1, 0, 2))
+    assert x.ndim == 2
-            config['input_shape'] = self._input_shape[1:]
+            input_shape = self._input_shape
-from keras.models import Sequential
+from keras.models import Sequential, model_from_json
-    Return array of int8 (0s and 1s).
+    Return array of uint8 (0s and 1s).
-    return tf.cast(x, tf.int8)
+    return tf.cast(x, tf.uint8)
-        mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), axes), tf.bool)
+        mask = tf.cast(mask, tf.uint8)
-    mask: binary tensor with shape (samples, time, 1),
+    mask: binary tensor with shape (samples, time),
-        self.input = K.placeholder(ndim=3)
+        if (not hasattr(self, 'input')):
-                     axis=-1)
+        return K.any(K.not_equal(X, self.mask_value), axis=-1)
-                         axis=-1, keepdims=True)
+        return X * K.cast(K.any(K.not_equal(X, self.mask_value), axis=-1, keepdims=True), K.floatx())
-            return K.expand_dims(K.not_equal(X, 0))
+            return K.not_equal(X, 0)
-    return K.mean(K.categorical_crossentropy(y_pred, y_true), axis=-1)
+    return K.categorical_crossentropy(y_pred, y_true)
-    return -K.mean(y_true * y_pred, axis=1)
+    y_true = K.l2_normalize(y_true, axis=-1)
-    func = K.function([layer.input], [layer.get_output_mask()])
+    func = K.function([layer.get_input(True)], [layer.get_output_mask()])
-                    reason='currently not working with TensorFlow')
+from keras.models import Sequential
-    model.add(Masking(mask_value=0, input_shape=(None, 2)))
+    model.add(Masking(mask_value=0, input_shape=(4, 2)))
-        successive_states.append(states)
+    if mask is not None:
-                                    mode=fill_mode, cval=cval)
+    x = ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels),
-                                               mode=fill_mode, order=3, cval=cval)
+                                               mode=fill_mode,
-                                   mode=fill_mode, cval=cval)
+                                   mode=fill_mode,
-    """example of how to build a generator for a graph model"""
+    '''Example of how to build a generator for a Graph model
-        bX, bY = super(GraphImageDataGenerator,self).next()
+        bX, bY = super(GraphImageDataGenerator, self).next()
-
+    def _flow_index(self, N, batch_size=32, shuffle=False, seed=None):
-                    index_array = np.random.permutation(X.shape[0])
+                    index_array = np.random.permutation(N)
-                    index_array = np.arange(X.shape[0])
+                    index_array = np.arange(N)
-            if X.shape[0] >= current_index + batch_size:
+            current_index = (b * batch_size) % N
-                    img.save(save_to_dir + "/" + save_prefix + "_" + str(current_index + i) + "." + save_format)
+                current_batch_size = N - current_index
-            yield bX, y[index_array[current_index: current_index + batch_size]]
+            yield index_array[current_index: current_index + current_batch_size], current_index, current_batch_size
-                                output_reconstruction=True))
+    autoencoder = AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=True)
-    autoencoder.fit(X_train, X_train, nb_epoch=10)
+    model.compile(optimizer='sgd', loss='mse')
-    representations = autoencoder.predict(X_test)
+    autoencoder.output_reconstruction = False  # the model has to be recompiled after modifying this property
-    autoencoder.fit(X_test, representations, nb_epoch=1)  # in this case the loss will be 0, so it's useless
+    model.fit(X_test, representations, nb_epoch=1)  # in this case the loss will be 0, so it's useless
-    autoencoder.fit(X_train, X_train, nb_epoch=10)
+    model.compile(optimizer='sgd', loss='mse')
-                                     output_reconstruction=True))
+    model = Sequential()
-    autoencoder.fit(X_train, X_train, nb_epoch=1, batch_size=32)
+    model.compile(optimizer='sgd', loss='mse')
-    representations = autoencoder.predict(X_test)
+    assert not autoencoder.output_reconstruction
-    autoencoder.fit(X_test, representations, nb_epoch=1, batch_size=32)
+    model.fit(X_test, representations, nb_epoch=1, batch_size=32)
-    autoencoder.fit(X_train, X_train, nb_epoch=1)
+    model.compile(optimizer='sgd', loss='mse')
-    autoencoder.output_reconstruction = False
+    autoencoder.output_reconstruction = True
-    autoencoder.output_reconstruction = False
+    autoencoder.output_reconstruction = True
-    def set_previous(self, layer, connection_map={}):
+    def set_previous(self, layer):
-                                output_reconstruction=False))
+                                output_reconstruction=True))
-        self.output_reconstruction = output_reconstruction
+        self._output_reconstruction = output_reconstruction
-        self.decoder.set_previous(self.encoder)
+        if output_reconstruction:
-        for layer in [self.encoder, self.decoder]:
+        if self.output_reconstruction:
-        super(AutoEncoder, self).set_previous(node, connection_map)
+    def set_previous(self, node):
-            return self.encoder.previous.output_shape
+            return self.decoder.output_shape
-            return self.decoder.previous.output_shape
+            return self.encoder.output_shape
-        if not train and not self.output_reconstruction:
+        if self.output_reconstruction:
-
+from keras.layers import containers
-    model.compile(loss='mse', optimizer='sgd')
+def test_autoencoder_advanced():
-    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_lstm.py
+    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_cnn_lstm.py
-Run on GPU: THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python mnist_cnn.py
+Run on GPU: THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python mnist_transfer_cnn.py
-    for i in range(12):
+    # we run gradient ascent for 20 steps
-filter_name = 'conv5_1'
+layer_name = 'conv5_1'
-    layer_output = layer_dict[filter_name].get_output()
+    layer_output = layer_dict[layer_name].get_output()
-        rand = KTF.get_value(KTF.random_normal((1000, 1000), mean=mean, std=std))
+        rand = KTF.eval(KTF.random_normal((1000, 1000), mean=mean, std=std))
-        rand = KTF.get_value(KTF.random_normal((1000, 1000), mean=mean, std=std))
+        rand = KTH.eval(KTH.random_normal((1000, 1000), mean=mean, std=std))
-        rand = KTF.get_value(KTF.random_normal((1000, 1000), mean=mean, std=std))
+        min = -1.
-        assert(np.abs(np.std(rand) - std) < 0.01)
+        assert(np.abs(np.mean(rand)) < 0.01)
-        rand = KTF.get_value(KTF.random_normal((1000, 1000), mean=mean, std=std))
+        rand = KTH.eval(KTH.random_uniform((1000, 1000), min, max))
-        assert(np.abs(np.std(rand) - std) < 0.01)
+        assert(np.abs(np.mean(rand)) < 0.01)
-        y = np.random.randint(0, nb_class, size=(nb_sample, 1))
+        y = np.random.randint(0, nb_class, size=(nb_sample,))
-from keras.datasets import mnist
+from keras.utils.test_utils import get_test_data
-from keras.layers.core import Dense, Activation, RepeatVector, TimeDistributedDense
+from keras.layers import Dense, Activation, RepeatVector, TimeDistributedDense, GRU
-weighted_class = 9
+weighted_class = 5
-max_test_samples = 1000
+high_weight = 10
-X_test = X_test.astype("float32") / 255
+# (X_train, y_train), (X_test, y_test) = mnist.load_data()
-y_test = y_test[:max_test_samples]
+temporal_X_train = np.reshape(X_train, (len(X_train), 1, X_train.shape[1]))
-    model.add(Dense(50, input_shape=(784,)))
+    model.add(Dense(32, input_shape=(input_dim,)))
-    model.add(Dense(10))
+    model.add(Dense(nb_classes))
-    model.add_node(Dense(10, activation='softmax'), name='d2', input='d1')
+    model.add_input(name='input', input_shape=(input_dim,))
-    model.add(TimeDistributedDense(10))
+    model.add(GRU(32, input_shape=(timesteps, input_dim), return_sequences=True))
-    model.add_node(RepeatVector(timesteps),
+    model.add_input(name='input', input_shape=(timesteps, input_dim))
-    model.add_node(TimeDistributedDense(10, activation='softmax'),
+    model.add_node(TimeDistributedDense(nb_classes, activation='softmax'),
-    # just check it runs
+                                     X_train=temporal_X_train,
-    # just check it runs
+                                X_train=temporal_X_train,
-    '''
+def standardize_weights(y, sample_weight=None, class_weight=None,
-        return np.ones((y.shape[0],))
+        if sample_weight_mode is None:
-                class_mode="categorical"):
+                class_mode="categorical",
-        self.weights = K.placeholder(ndim=1)
+
-                                                        sample_weight=sample_weight_val)
+                                                        sample_weight=sample_weight_val,
-                                                        sample_weight=sample_weight_val)
+                                                        sample_weight=sample_weight_val,
-                                            sample_weight=sample_weight)
+                                            sample_weight=sample_weight,
-        sample_weight = standardize_weights(y, sample_weight=sample_weight)
+        sample_weight = standardize_weights(y, sample_weight=sample_weight,
-                                            sample_weight=sample_weight)
+                                            sample_weight=sample_weight,
-        sample_weight = standardize_weights(y, sample_weight=sample_weight)
+        sample_weight = standardize_weights(y, sample_weight=sample_weight,
-    def compile(self, optimizer, loss):
+    def compile(self, optimizer, loss, sample_weight_modes={}):
-            weight = K.placeholder(ndim=1)
+            if sample_weight_modes.get(output_name) == 'temporal':
-                                                  sample_weight=sample_weight.get(self.output_order[i])) for i in range(len(self.output_order))]
+                                                  sample_weight=sample_weight.get(self.output_order[i]),
-                                                  class_weight=class_weight_list[i]) for i in range(len(self.output_order))]
+                                                  class_weight=class_weight_list[i],
-                                             sample_weight=sample_weight.get(name)) for name in self.output_order]
+                                             sample_weight=sample_weight.get(name),
-                                             class_weight=class_weight.get(name)) for name in self.output_order]
+                                             class_weight=class_weight.get(name),
-                                             sample_weight=sample_weight.get(name)) for name in self.output_order]
+                                             sample_weight=sample_weight.get(name),
-from keras.layers.core import Dense, Activation
+from keras.layers.core import Dense, Activation, RepeatVector, TimeDistributedDense
-def _test_weights_sequential(model, class_weight=None, sample_weight=None):
+def create_temporal_sequential_model():
-def _test_weights_graph(model, class_weight=None, sample_weight=None):
+def _test_weights_graph(model, class_weight=None, sample_weight=None,
-        assert(score < standard_score)
+# no weights: reference point
-    x = ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels),
+    x = ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels), order=0,
-
+def random_shear(x, intensity, fill_mode="nearest", cval=0.):
-
+        if self.shear_range:
-        # reduce score_array to 1D
+        # reduce score_array to same ndim as weight array
-            score_array = K.mean(score_array, axis=-1)
+        weight_ndim = K.ndim(weights)
-        return sample_weight.flatten()
+        assert sample_weight.ndim <= y.ndim
-            sample_weight: list or numpy array with 1:1 mapping to
+            sample_weight: list or numpy array of weights for
-                (during training only).
+                (during training only). You can either pass a flat (1D)
-                    img.save(save_to_dir + "/" + save_prefix + "_" + str(i) + "." + save_format)
+                    img.save(save_to_dir + "/" + save_prefix + "_" + str(current_index + i) + "." + save_format)
-            np.random.shuffle(y)
+        total_b = 0
-                x = X[current_index + i]
+                x = X[index_array[current_index + i]]
-            yield bX, y[current_index: current_index + batch_size]
+            total_b += 1
-                                     'pip install git+git://github.com/Theano/Theano.git --upgrade --nodeps')
+                                     'pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps')
-                                     'pip install git+git://github.com/Theano/Theano.git --upgrade')
+                                     'pip install git+git://github.com/Theano/Theano.git --upgrade --nodeps')
-        `(samples, nb_filter, nb_row, nb_col)` if dim_ordering='th'
+        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'
-        `(samples, nb_row, nb_col, nb_filter)` if dim_ordering='tf'.
+        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.
-                in sequence to sequence learning.
+                (during training only).
-    assert(conf == conf_target)
+    norm.get_config()
-    def __init__(self, m=2):
+    '''Constrain the weights incident to each hidden unit to have a norm less than or equal to a desired value.
-        norms = K.sqrt(K.sum(K.square(p), axis=0))
+        norms = K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True))
-        p = p * (desired / (1e-7 + norms))
+        p = p * (desired / (K.epsilon() + norms))
-                "m": self.m}
+                "m": self.m,
-        return p / K.sqrt(K.sum(K.square(p), axis=-1, keepdims=True))
+        return p / (K.epsilon() + K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True)))
-    norm = np.linalg.norm(K.get_value(lookup.params[0]), axis=1)
+    norm = np.linalg.norm(K.get_value(lookup.params[0]), axis=0)
-    norm_of_normalized = np.sqrt(np.sum(K.eval(normalized)**2, axis=1))
+    norm_of_normalized = np.sqrt(np.sum(K.eval(normalized)**2, axis=0))
-        mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), (1, 0, 2)), tf.bool)
+        mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), axes), tf.bool)
-        mask = mask.dimshuffle((1, 0, 2))
+        mask = mask.dimshuffle(axes)
-    return theano.config.device[:3] == 'gpu'
+    return theano.config.device[:3] == 'gpu' or theano.sandbox.cuda.cuda_enabled
-                                'including the samples axis.')
+                                'your sequences.\n' +
-    axes = [1, 0] + range(2, ndim)
+    axes = [1, 0] + list(range(2, ndim))
-    axes = [1, 0] + range(2, len(outputs.get_shape()))
+    axes = [1, 0] + list(range(2, len(outputs.get_shape())))
-    axes = [1, 0] + range(2, ndim)
+    axes = [1, 0] + list(range(2, ndim))
-    axes = [1, 0] + range(2, outputs.ndim)
+    axes = [1, 0] + list(range(2, outputs.ndim))
-        that is masked.
+    mask: binary tensor with shape (samples, time, 1),
-        that is masked.
+    mask: binary tensor with shape (samples, time, 1),
-    np.random.seed(1337)
+def setup_function(func):
-        imarray = np.random.rand(img_w,img_h,3) * variance + bias
+        bias = np.random.rand(img_w, img_h, 1) * 64
-        imarray = np.random.rand(img_w,img_h,1) * variance + bias
+        imarray = np.random.rand(img_w, img_h, 1) * variance + bias
-        file_list = list_pictures('test_images/'+color_mode)
+def test_image_data_generator():
-            img_list.append(img_to_array(load_img(f))[None,...])
+            img_list.append(img_to_array(load_img(f))[None, ...])
-        )
+            vertical_flip=True)
-        for x,y in generator.flow(images,np.arange(images.shape[0]), shuffle=True, save_to_dir='test_images'):
+        for x, y in generator.flow(images, np.arange(images.shape[0]),
-
+            break
-    inputs = tf.transpose(inputs, (1, 0, 2))
+    ndim = len(inputs.get_shape())
-    outputs = tf.transpose(outputs, (1, 0, 2))
+    axes = [1, 0] + range(2, len(outputs.get_shape()))
-    inputs = inputs.dimshuffle((1, 0, 2))
+    ndim = inputs.ndim
-    outputs = outputs.dimshuffle((1, 0, 2))
+    axes = [1, 0] + range(2, outputs.ndim)
-                            'and is not an input layer.')
+                            ' and is not an input layer.')
-                 lower=True, split=' '):
+                 lower=True, split=' ', char_level=False):
-            seq = text_to_word_sequence(text, self.filters, self.lower, self.split)
+            seq = text if self.char_level else text_to_word_sequence(text, self.filters, self.lower, self.split)
-            seq = text_to_word_sequence(text, self.filters, self.lower, self.split)
+            seq = text if self.char_level else text_to_word_sequence(text, self.filters, self.lower, self.split)
-def rnn(step_function, inputs, output_dim, initial_states,
+def rnn(step_function, inputs, initial_states,
-def rnn(step_function, inputs, output_dim, initial_states,
+def rnn(step_function, inputs, initial_states,
-    initial_output = T.zeros((inputs.shape[1], output_dim))
+    initial_output = step_function(inputs[0], initial_states)[0] * 0
-        last_output, outputs, states = K.rnn(self.step, X, self.output_dim,
+        last_output, outputs, states = K.rnn(self.step, X,
-                                 std=self.p / (1.0 - self.p))
+                                 std=K.sqrt(self.p / (1.0 - self.p)))
-mpl.show()
+'''Example script showing how to use stateful RNNs
-from six.moves import range
+from keras.optimizers import SGD
-
+    print('Not using data augmentation.')
-    print('Using real time data augmentation')
+    print('Using real-time data augmentation.')
-        featurewise_center=True,  # set input mean to 0 over the dataset
+        featurewise_center=False,  # set input mean to 0 over the dataset
-        featurewise_std_normalization=True,  # divide inputs by std of the dataset
+        featurewise_std_normalization=False,  # divide inputs by std of the dataset
-        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)
+        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
-            progbar.add(X_batch.shape[0], values=[('test loss', score[0])])
+    # fit the model on the batches generated by datagen.flow()
-                raise Exception('The generator output must be a tuple.')
+                raise Exception('The generator output must be a tuple. Found: ' + str(type(generator_output)))
-                        generator_output = next(generator)
+                        try:
-                    return
+                    raise
-'''
+
-    x = ndimage.interpolation.rotate(x, angle, axes=(1,2), reshape=False, mode=fill_mode, cval=cval)
+    x = ndimage.interpolation.rotate(x, angle,
-    x = ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels), mode=fill_mode, cval=cval)
+    x = ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels),
-    return x # shape of result will be different from shape of input!
+    x = ndimage.interpolation.zoom(x, zoom=(1., zoom_w, zoom_h),
-    x = x.transpose(1, 2, 0) 
+    x = x.transpose(1, 2, 0)
-        return Image.fromarray(x[:,:,0].astype("uint8"), "L")
+        return Image.fromarray(x[:, :, 0].astype("uint8"), "L")
-    if len(x.shape)==3:
+    if len(x.shape) == 3:
-    else: # Assure 3 channel even when loaded image is grayscale
+    else:  # Ensure 3 channel even when loaded image is grayscale
-            if isfile(join(directory,f)) and re.match('([\w]+\.(?:' + ext + '))', f)]
+    return [join(directory, f) for f in listdir(directory)
-                 height_shift_range=0., # fraction of total height
+    def __init__(self,
-                 ):
+                 vertical_flip=False):
-    def flow(self, X, y, batch_size=32, shuffle=False, seed=None, save_to_dir=None, save_prefix="", save_format="jpeg"):
+    def flow(self, X, y, batch_size=32, shuffle=False, seed=None,
-                nb_samples = X.shape[0] - b*batch_size
+        b = 0
-                x = X[b*batch_size+i]
+                current_batch_size = X.shape[0] - current_index
-                for i in range(nb_samples):
+                for i in range(current_batch_size):
-            yield bX, y[b*batch_size:b*batch_size+nb_samples]
+            if current_batch_size == batch_size:
-            Required for featurewise_center, featurewise_std_normalization and zca_whitening.
+        '''Required for featurewise_center, featurewise_std_normalization and zca_whitening.
-        last_output, outputs, states = K.rnn(step, x, [], masking=False)
+        last_output, outputs, states = K.rnn(step, x,
-
+            del reduction_axes[self.axis]
-
+                                   mask_zero=True,
-                        stateful=True, 
+                        stateful=True,
-    left_padded_input[2,:3] = 0 
+    left_padded_input[0, :1] = 0
-    right_padded_input[2,-3:] = 0 
+    right_padded_input[0, -1:] = 0
-        norm_m0 = normalization.BatchNormalization(input_shape=inp.shape, mode=0)
+        norm_m0 = normalization.BatchNormalization(batch_input_shape=inp.shape, mode=0)
-        out = (norm_m0.get_output(train=True) - norm_m0.beta) / norm_m0.gamma
+        out = norm_m0.get_output(train=True)
-        norm_m1 = normalization.BatchNormalization(input_shape=inp.shape, mode=1)
+        norm_m1 = normalization.BatchNormalization(batch_input_shape=inp.shape, mode=1)
-        out = (norm_m1.get_output(train=True) - norm_m1.beta) / norm_m1.gamma
+        out = norm_m1.get_output(train=True)
-    return tf.ones_like(x)
+    return tf.ones_like(x, name=name)
-    return tf.zeros_like(x)
+    return tf.zeros_like(x, name=name)
-        go_backwards=False, masking=True):
+def rnn(step_function, inputs, output_dim, initial_states,
-        be all zeros.
+    mask: binary tensor with shape (samples, time, 1), with a zero for every element
-    for input in input_list:
+
-            states = return_states
+
-            states = new_states
+            prev_output = successive_outputs[-1]
-
+def not_equal(x, y):
-    '''Iterate over the time dimension of a tensor.
+def rnn(step_function, inputs, output_dim, initial_states,
-        be all zeros.
+    mask: binary tensor with shape (samples, time, 1), with a zero for every element
-    def _step(input, *states):
+    def _step(input, mask, output_tm1, *states):
-            return [output] + new_states
+        # output previous output if masked.
-        outputs_info=[None] + initial_states,
+        sequences=[inputs, mask],
-        last_output, outputs, states = K.rnn(step, X, [], masking=False)
+        last_output, outputs, states = K.rnn(step, X,
-            return K.ones_like(X) * (1 - K.equal(X, 0))
+            return K.expand_dims(K.not_equal(X, 0))
-        last_output, outputs, states = K.rnn(self.step, X, initial_states,
+        last_output, outputs, states = K.rnn(self.step, X, self.output_dim,
-                                             masking=masking)
+                                             mask=mask)
-                                                   masking=False)
+                                                   mask=None)
-                                                   masking=False)
+                                                   mask=None)
-from keras.layers import recurrent
+from keras.layers import recurrent, embeddings
-nb_samples, timesteps, input_dim, output_dim = 3, 3, 10, 5
+nb_samples, timesteps, embedding_dim, output_dim = 3, 5, 10, 5
-        layer.input = K.variable(np.ones((nb_samples, timesteps, input_dim)))
+                            weights=None, input_shape=(timesteps, embedding_dim))
-                        batch_input_shape=(nb_samples, timesteps, input_dim))
+    model.add(embeddings.Embedding(embedding_num, embedding_dim,
-    out1 = model.predict(np.ones((nb_samples, timesteps, input_dim)))
+    out1 = model.predict(np.ones((nb_samples, timesteps)))
-    model.train_on_batch(np.ones((nb_samples, timesteps, input_dim)),
+    model.train_on_batch(np.ones((nb_samples, timesteps)),
-    out2 = model.predict(np.ones((nb_samples, timesteps, input_dim)))
+    out2 = model.predict(np.ones((nb_samples, timesteps)))
-    out3 = model.predict(np.ones((nb_samples, timesteps, input_dim)))
+    out3 = model.predict(np.ones((nb_samples, timesteps)))
-    out4 = model.predict(np.ones((nb_samples, timesteps, input_dim)))
+    out4 = model.predict(np.ones((nb_samples, timesteps)))
-    out5 = model.predict(np.ones((nb_samples, timesteps, input_dim)))
+    out5 = model.predict(np.ones((nb_samples, timesteps)))
-            reduction_axes = range(len(input_shape))
+            reduction_axes = list(range(len(input_shape)))
-    norm_m0 = normalization.BatchNormalization(input_shape=(10,))
+    norm_m0 = normalization.BatchNormalization(mode=0, input_shape=(10,))
-                will be normalized separately).
+                Each feature map in the input will
-    def __init__(self, epsilon=1e-6, mode=0, momentum=0.9,
+    def __init__(self, epsilon=1e-6, mode=0, axis=-1, momentum=0.9,
-        input_shape = input_shape[1:]
+        shape = (input_shape[self.axis],)
-        self.beta = K.zeros(input_shape)
+        self.gamma = self.init(shape)
-        self.running_std = K.ones(input_shape)
+        self.running_mean = K.zeros(shape)
-                std = K.mean(K.square(X - m) + self.epsilon, axis=0)
+                m = K.mean(X, axis=reduction_axes)
-                X_normed = (X - m) / (std + self.epsilon)
+                X_normed = (X - brodcast_m) / (brodcast_std + self.epsilon)
-                            (self.running_std + self.epsilon))
+                brodcast_m = K.reshape(self.running_mean, broadcast_shape)
-        out = self.gamma * X_normed + self.beta
+            out = self.gamma * X_normed + self.beta
-        axis = axis % len(x.get_shape())
+    axis = normalize_axis(axis, ndim(x))
-        axis = axis % len(x.get_shape())
+    axis = normalize_axis(axis, ndim(x))
-        axis = axis % len(x.get_shape())
+    axis = normalize_axis(axis, ndim(x))
-        axis = axis % len(x.get_shape())
+    axis = normalize_axis(axis, ndim(x))
-    m = tf.reduce_mean(x, reduction_indices=axis, keep_dims=keepdims)
+    m = tf.reduce_mean(x, reduction_indices=axis, keep_dims=True)
-        axis = axis % len(x.get_shape())
+    axis = normalize_axis(axis, ndim(x))
-        axis = axis % len(x.get_shape())
+    axis = normalize_axis(axis, ndim(x))
-                        (self.running_std + self.epsilon))
+            if train:
-from .advanced_activations import *
+from .advanced_activations import *
-    print('Using Theano backend.')
+    sys.stderr.write('Using Theano backend.\n')
-    print('Using TensorFlow backend.')
+    sys.stderr.write('Using TensorFlow backend.\n')
-    return np.array(f_grads([x])).flatten().astype('float64')
+outputs = [loss]
-def eval_loss(x):
+f_outputs = K.function([combination_image], outputs)
-    return f_loss([x])[0].astype('float64')
+    outs = f_outputs([x])
-                                     fprime=eval_grads, maxfun=20)
+    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),
-def eval_grads(x):
+outputs = [loss]
-x += random_jitter
+    outs = f_outputs([x])
-                                     fprime=eval_grads, maxfun=7)
+
-        if  type(v) == str:
+        if type(v) == str:
-                return obj.item();
+                return obj.item()
-import random, math
+import random
-
+    return [join(directory,f) for f in listdir(directory)
-        ):
+                 featurewise_center=True, # set input mean to 0 over the dataset
-        couples += [[words[i%len(words)], random.randint(1, vocabulary_size-1)] for i in range(nb_negative_samples)]
+        couples += [[words[i %len(words)], random.randint(1, vocabulary_size-1)] for i in range(nb_negative_samples)]
-import string, sys
+import string
-              input_shape=(X_train.shape[1], X_train.shape[2])))
+                  input_shape=(X_train.shape[1], X_train.shape[2])))
-              input_shape=(X_train.shape[1], X_train.shape[2])))
+                                   input_shape=(X_train.shape[1], X_train.shape[2])))
-                          [[0], [4], [5], [0]]], dtype=np.int32)
+                           [[0], [4], [5], [0]]], dtype=np.int32)
-                          [[1, 5], [5, 0], [0, 0], [0, 0]]],
+                           [[1, 5], [5, 0], [0, 0], [0, 0]]],
-                          [[1, 5], [5, 0], [0, 0], [0, 0]]],
+                           [[1, 5], [5, 0], [0, 0], [0, 0]]],
-                        [[1, 5], [5, 0], [0, 0], [0, 0]]])
+                         [[1, 5], [5, 0], [0, 0], [0, 0]]])
-            #TODO: make sure the normalization is working as inteded
+            # TODO: make sure the normalization is working as inteded
-    return im
+    img = imresize(imread(image_path), (img_width, img_height))
-    im = deprocess_image(x.reshape((3, img_width, img_height)))
+    img = deprocess_image(x.reshape((3, img_width, img_height)))
-    imsave(fname, im)
+    imsave(fname, img)
-import cv2
+from scipy.misc import imread, imresize, imsave
-    im = cv2.resize(cv2.imread(image_path), (img_width, img_height))
+    im = imresize(imread(image_path), (img_width, img_height))
-    cv2.imwrite(fname, im)
+    imsave(fname, im)
-# Reference:
+ - The content loss is a L2 distance between the features of the base
-# result_prefix = 'my_result_th'
+'''Neural style transfer with Keras.
-        for name, value in self.totals.items() + logs.items():
+        all_values = self.totals.copy()
-                    loss[l] = custom_objects[c]
+        if model_name == 'Graph':
-    return last_output, outputs, states
+    return last_output, outputs, new_states
-    return K.variable(np.random.uniform(low=-scale, high=scale, size=shape))
+def uniform(shape, scale=0.05, name=None):
-    return K.variable(np.random.normal(loc=0.0, scale=scale, size=shape))
+def normal(shape, scale=0.05, name=None):
-def lecun_uniform(shape):
+def lecun_uniform(shape, name=None):
-    return uniform(shape, scale)
+    return uniform(shape, scale, name=name)
-def glorot_normal(shape):
+def glorot_normal(shape, name=None):
-    return normal(shape, s)
+    return normal(shape, s, name=name)
-def glorot_uniform(shape):
+def glorot_uniform(shape, name=None):
-    return uniform(shape, s)
+    return uniform(shape, s, name=name)
-def he_normal(shape):
+def he_normal(shape, name=None):
-    return normal(shape, s)
+    return normal(shape, s, name=name)
-def he_uniform(shape):
+def he_uniform(shape, name=None):
-    return uniform(shape, s)
+    return uniform(shape, s, name=name)
-def orthogonal(shape, scale=1.1):
+def orthogonal(shape, scale=1.1, name=None):
-    return K.variable(scale * q[:shape[0], :shape[1]])
+    return K.variable(scale * q[:shape[0], :shape[1]], name=name)
-def identity(shape, scale=1):
+def identity(shape, scale=1, name=None):
-        return K.variable(scale * np.identity(shape[0]))
+        return K.variable(scale * np.identity(shape[0]), name=name)
-    return K.zeros(shape)
+def zero(shape, name=None):
-    return K.ones(shape)
+def one(shape, name=None):
-                          'cache_enabled'}
+                          'cache_enabled',
-            self._trainable = kwargs['trainable']
+            self.trainable = kwargs['trainable']
-        self._cache_enabled = True
+        self.cache_enabled = True
-            self._cache_enabled = kwargs['cache_enabled']
+            self.cache_enabled = kwargs['cache_enabled']
-        config['cache_enabled'] =  self.cache_enabled
+        config['cache_enabled'] = self.cache_enabled
-        
+
-        return K.flatten(X)
+        return K.batch_flatten(X)
-    else:
+    else:  # this is a non-topological layer (e.g. Dense, etc.)
-Note that same result can also be achieved via a Lambda layer.
+Note that the same result can also be achieved via a Lambda layer.
-    of the output. The result is a tensor of samples that are
+    positive part of the input with the negative part
-        classification performance as an equivalent ReLU-based network.
+        with twice less parameters yet with comparable
-        return json.dumps(config, **kwargs)
+        return json.dumps(config, default=get_json_type, **kwargs)
-            shape = output_shape_func(self.previous.output_shape)
+            shape = output_shape_func(self.input_shape)
-from __future__ import divisionla
+from __future__ import division
-from __future__ import division
+from __future__ import divisionla
-            return func(self.input)
+        return func(X)
-            shift_y = (kernel.shape[3] - 1) // 2
+            np_kernel = kernel.eval()
-        self._test_with_acc = K.function(test_ins, [test_loss, test_accuracy])
+        self._test = K.function(test_ins, [test_loss], updates=self.state_updates)
-        self._test = K.function(test_ins, [test_loss])
+        self._test = K.function(test_ins, [test_loss], updates=self.state_updates)
-            shift_y = (kernel.shape[3] - 1) // 2
+            np_kernel = kernel.eval()
-def poisson_loss(y_true, y_pred):
+def poisson(y_true, y_pred):
-# CONVOLUTIONS
+def l2_normalize(x, axis):
-
+        check_single_tensor_operation('l2_normalize', (4, 3), axis=-1)
-def resize_images(X, height, width, height_factor, width_factor, dim_ordering):
+def resize_images(X, height_factor, width_factor, dim_ordering):
-    by a factor of (height_factor, width_factor)
+    by a factor of (height_factor, width_factor). Both factors should be
-    new_width = width * width_factor
+        new_height = shape(X)[2].value * height_factor
-def resize_images(X, height, width, height_factor, width_factor, dim_ordering):
+def resize_images(X, height_factor, width_factor, dim_ordering):
-    by a factor of (height_factor, width_factor)
+    by a factor of (height_factor, width_factor). Both factors should be
-        return K.resize_images(X, height, width, self.size[0], self.size[1],
+        return K.resize_images(X, self.size[0], self.size[1],
-        output = K.repeat_elements(output, width_factor, axis=2)
+    if dim_ordering == 'th':
-__version__ = '0.3.0'
+__version__ = '0.3.1'
-      version='0.3.0',
+      version='0.3.1',
-      download_url='https://github.com/fchollet/keras/tarball/0.3.0',
+      download_url='https://github.com/fchollet/keras/tarball/0.3.1',
-    return history.history['val_acc'][-1] > target
+    config = optimizer.get_config()
-    assert(_test_optimizer(sgd))
+    _test_optimizer(sgd)
-    assert(_test_optimizer(RMSprop()))
+    _test_optimizer(RMSprop())
-    assert(_test_optimizer(Adagrad()))
+    _test_optimizer(Adagrad())
-    assert(_test_optimizer(Adadelta()))
+    _test_optimizer(Adadelta())
-    assert(_test_optimizer(Adam()))
+    _test_optimizer(Adam())
-    assert(_test_optimizer(Adamax()))
+    _test_optimizer(Adamax())
-            if len(input_shape) == 1:
+            if (input_shape and len(input_shape) == 1) or (batch_input_shape and len(batch_input_shape) == 2):
-            output = K.repeat_elements(output, self.size[1], axis=3)
+            height, width = input_shape[2], input_shape[3]
-        return output
+            height, width = input_shape[1], input_shape[2]
-        layer.get_config()
+    for dim_ordering in ['th', 'tf']:
-from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam
+from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax
-
+
-                a `batch_input_size=(...)` to the first layer in your model.
+                a `batch_input_shape=(...)` to the first layer in your model.
-
+            m = K.mean(X, axis=0)
-from keras.models import Sequential
+from keras.models import Sequential, Graph
-        self.encoder.set_previous(node)
+    def set_previous(self, node, connection_map={}):
-                                    border_mode=(pad_x, pad_y))
+                                    border_mode='full')
-                    if avg > 1e-3:
+                    if abs(avg) > 1e-3:
-        merge_layer = Merge(layer_list, mode)
+        merge_layer = Merge(layer_list, mode, concat_axis, dot_axes)
-        weighted_loss = weighted_objective(objectives.get(loss))
+        weighted_loss = weighted_objective(self.loss)
-        """
+        '''Find and replace a single missing dimension in an output shape
-        """
+
-        if not unknown is None:
+        if unknown is not None:
-        datadir = os.path.join('/tmp', '.keras', 'datasets')
+    datadir_base = os.path.expanduser(os.path.join('~', '.keras'))
-    _keras_dir = os.path.join('/tmp', '.keras')
+_keras_base_dir = os.path.expanduser('~')
-        return (self.input_shape[0],) + self.dims
+        return (self.input_shape[0],) + self._fix_unknown_dimension(self.input_shape[1:], self.dims)
-        return K.reshape(X, (-1,) + self.dims)
+        return K.reshape(X, (-1,) + self.output_shape[1:])
-    layer = Reshape(dims=(2, 3))
+
-_config_path = os.path.expanduser(os.path.join('~', '.keras', 'keras.json'))
+_config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))
-                raise Exception('The generator output tuple must have 2 or 3 elements.')
+                raise Exception('The generator output tuple must have '
-                except KeyboardInterrupt:
+                except:
-
+        if len(set([len(a) for a in ins])) != 1:
-                except KeyboardInterrupt:
+                except:
-    The function returns the variable that is passed in, so all types work
+    The function returns the variable that is passed in, so all types work.
-    '''Returns whether the session is set to
+    '''Return whether the session is set to
-    not having Cuda install should not
+    not having Cuda installed should not
-    '''Repeats the elements of a tensor along an axis, like np.repeat
+    '''Repeat the elements of a tensor along an axis, like np.repeat.
-    will have shape (s1, s2 * rep, s3)
+    will have shape (s1, s2 * rep, s3).
-    '''Repeat a 2D tensor:
+    '''Repeat a 2D tensor.
-    the output will have shape (samples, 2, dim)
+    If x has shape (samples, dim) and n=2,
-    '''Iterates over the time dimension of a tensor.
+    '''Iterate over the time dimension of a tensor.
-                          'fallback to auto mode' % (self.mode),
+                          'fallback to auto mode.' % (self.mode),
-            mode it will stopped when the quantity
+            mode it will stop when the quantity
-                          'fallback to auto mode' % (self.mode), RuntimeWarning)
+                          'fallback to auto mode.' % (self.mode), RuntimeWarning)
-        root: root url to which the events will be send (at the end
+        root: root url to which the events will be sent (at the end
-                            'with the TensorFlow backend')
+                            'with the TensorFlow backend.')
-                        'for 2D square matrices')
+                        'for 2D square matrices.')
-        Returns the `updates` from all layers in the sequence that are
+        Return the `updates` from all layers in the sequence that are
-        Returns the `updates` from all nodes in that graph for nodes that are
+        Return the `updates` from all nodes in that graph for nodes that are
-    '''Repeats each temporal step `length` times along the time axis.
+    '''Repeat each temporal step `length` times along the time axis.
-    '''Repeats the rows and columns of the data
+    '''Repeat the rows and columns of the data
-            assert self.supports_masked_input(), 'Cannot connect non-masking layer to layer with masked output'
+            assert self.supports_masked_input(), 'Cannot connect non-masking layer to layer with masked output.'
-                    raise ValueError('merge_mode="join" only works with named inputs')
+                    raise ValueError('merge_mode="join" only works with named inputs.')
-            raise Exception('Unknown merge mode')
+            raise Exception('Unknown merge mode.')
-        Arbitrary, although all dimensions in the input shaped must be fixed.
+        Arbitrary, although all dimensions in the input shape must be fixed.
-                            '(or containers) to merge')
+                            '(or containers) to merge.')
-                raise Exception('output_shape function must return a tuple')
+                raise Exception('output_shape function must return a tuple.')
-                raise Exception(merge_mode + ' merge takes exactly 2 layers')
+                raise Exception(merge_mode + ' merge takes exactly 2 layers.')
-                                 'only works with named inputs')
+                                 'only works with named inputs.')
-    with merge_mode = None
+    with merge_mode = None.
-    specified by the head argument
+    specified by the head argument.
-    multiple Sequential models without merging the outputs
+    multiple Sequential models without merging the outputs.
-    a natural extension of LSTMs to feedforward networks
+    a natural extension of LSTMs to feedforward networks.
-    '''Turn positive integers (indexes) into denses vectors of fixed size.
+    '''Turn positive integers (indexes) into dense vectors of fixed size.
-    This layer can only be used as the first layer in  a model.
+    This layer can only be used as the first layer in a model.
-      input_length: Length of input sequences, when it is constantself.
+      input_length: Length of input sequences, when it is constant.
-    close to 0. and the activation standard deviation close to 1.
+    close to 0 and the activation standard deviation close to 1.
-            If True, rocess the input sequence backwards.
+            If True, process the input sequence backwards.
-            in your model, you would need to specify the input Length
+            in your model, you would need to specify the input length
-                                'explicitely the number of timesteps of ' +
+                                'explicitly the number of timesteps of ' +
-            # hdf5 dataset only support list object as indices
+            # hdf5 datasets only support list objects as indices
-            #  to the number of unmasked sampled.
+            #  to the number of unmasked samples.
-        Returns a history object. It `history` attribute is a record of
+        Returns a history object. Its `history` attribute is a record of
-        Returns a history object. It `history` attribute is a record of
+        Returns a history object. Its `history` attribute is a record of
-    '''Expects a binary class matrix instead of a vector of scalar classes
+    '''Expects a binary class matrix instead of a vector of scalar classes.
-        splits into lists of tokens. They will then be indexed or vectorized.
+        split into lists of tokens. They will then be indexed or vectorized.
-                raise Exception("Specify a dimension (nb_words argument), or fit on some text data first")
+                raise Exception("Specify a dimension (nb_words argument), or fit on some text data first.")
-            raise Exception("Fit the Tokenizer on some data before using tfidf mode")
+            raise Exception("Fit the Tokenizer on some data before using tfidf mode.")
-    to binary class matrix, for use with categorical_crossentropy
+    to binary class matrix, for use with categorical_crossentropy.
-    `show_shape` controls wether the shape is shown in the graph
+    `recursive` controls whether we recursively explore container layers
-        for iteration in range(400):
+        for i in range(400):
-        return self._predict(ins)
+        outs = self._predict(ins)
-    return K.variable(np.random.randn(*shape) * scale)
+    return K.variable(np.random.normal(loc=0.0, scale=scale, size=shape))
-        raise Exception("Identity matrix initialization can only be used for 2D square matrices")
+        raise Exception('Identity matrix initialization can only be used '
-    tokenizer = Tokenizer(nb_words=20)
+    tokenizer = Tokenizer(nb_words=10)
-    assert np.max(np.max(sequences)) == 12
+    assert np.max(np.max(sequences)) < 10
-    assert(history.history['val_acc'][-1] > 0.9)
+    assert(history.history['val_acc'][-1] > 0.85)
-    def __init__(self, nb_words=None, filters=base_filter(), lower=True, split=" "):
+    def __init__(self, nb_words=None, filters=base_filter(),
-            @param texts: can be a list or a generator (for memory-efficiency)
+
-                                          skipgrams)
+from keras.preprocessing.sequence import pad_sequences
-def get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None):
+def get_from_module(identifier, module_params, module_name,
-            raise Exception('Invalid ' + str(module_name) + ': ' + str(identifier))
+            raise Exception('Invalid ' + str(module_name) + ': ' +
-    '''Experimental callback used to stream events to a server.
+    '''Callback used to stream events to a server.
-        schedule: a function that gets an epoch index as input
+        schedule: a function that takes an epoch index as input
-            learning rate as output.
+            learning rate as output (float).
-        K.set_value(self.model.optimizer.lr, self.schedule(epoch))
+        lr = self.schedule(epoch)
-    TensorBoard is a visualization tools provided with TensorFlow.
+    This callback writes a log for TensorBoard, which allows
-    https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
+    You can find more information about TensorBoard
-    assert_allclose(norm, np.ones_like(norm).astype('float32'))
+    assert_allclose(norm, np.ones_like(norm).astype('float32'), rtol=1e-05)
-def test_siamese():
+def test_siamese_all():
-    # Merge modes 'dot' and 'cos' requires a different call signature
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-
+def test_siamese():
-  http://arxiv.org/abs/1503.08895
+  http://arxiv.org/abs/1502.05698
-
+    if not X:
-
+import pytest
-@pytest.mark.skipif(K._BACKEND != 'tensorflow',
+@pytest.mark.skipif((K._BACKEND != 'tensorflow') or (sys.version_info[0] == 3),
-        KTF._set_session(old_session)
+    KTF._set_session(old_session)
-            parameters and metrics to the log
+        histogram_freq: frequency (in epochs) at which to compute activation
-                 show_accuracy=False):
+    def __init__(self, log_dir='./logs', histogram_freq=0):
-            'TensorBoard callback only works with the tensorflow backend'
+        if K._BACKEND != 'tensorflow':
-                l_name = " + ".join(losses)
+        if self.histogram_freq:
-                              f_output.outputs[0])
+                raise Exception('Unrecognized model:',
-            self.writer.add_summary(summary_str, epoch)
+        import tensorflow as tf
-@pytest.mark.skipif(_BACKEND != 'tensorflow',
+@pytest.mark.skipif(K._BACKEND != 'tensorflow',
-                                    show_accuracy=False)
+        tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1)
-                  validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5)
+                  validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)
-                                    show_accuracy=False)
+        tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1)
-                  validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=5)
+                  validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)
-                                    show_accuracy=False)
+        tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1)
-        model.fit({'X_vars': X_train, 'output': y_train}, batch_size=batch_size,
+        model.fit({'X_vars': X_train, 'output': y_train},
-                  callbacks=cbks, nb_epoch=5)
+                  callbacks=cbks, nb_epoch=2)
-
+from .backend import _BACKEND
-        if self._delta_t_batch > 0. and delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1:
+        if self._delta_t_batch > 0. and delta_t_median > 0.95 * \
-                          'to the batch update (%f). Check your callbacks.' % delta_t_median)
+                          'to the batch update (%f). Check your callbacks.'
-        if self._delta_t_batch > 0. and delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1:
+        if self._delta_t_batch > 0. and delta_t_median > 0.95 * \
-                          'to the batch update (%f). Check your callbacks.' % delta_t_median)
+                          'to the batch update (%f). Check your callbacks.'
-                          'fallback to auto mode' % (self.mode), RuntimeWarning)
+                          'fallback to auto mode' % (self.mode),
-                        print('Epoch %05d: %s improved from %0.5f to %0.5f, saving model to %s'
+                        print('Epoch %05d: %s improved from %0.5f to %0.5f,'
-        assert hasattr(self.model.optimizer, 'lr'), 'Optimizer must have a "lr" attribute.'
+        assert hasattr(self.model.optimizer, 'lr'), \
-    def __init__(self, monitor='val_loss', patience=0, verbose=0):
+    def __init__(self, monitor='val_loss', patience=0, verbose=0, mode='auto'):
-        self.best = np.Inf
+        if mode not in ['auto', 'min', 'max']:
-        if current < self.best:
+        if self.monitor_op(current, self.best):
-        self.model.optimizer.lr.set_value(self.schedule(epoch))
+        assert hasattr(self.model.optimizer, 'lr'), 'Optimizer must have a "lr" attribute.'
-Reaches 93% accuracy on task 'single_supporting_fact_10k' after 70 epochs.
+Reaches 98.6% accuracy on task 'single_supporting_fact_10k' after 120 epochs.
-answer.add(LSTM(64))
+answer.add(LSTM(32))
-answer.add(Dropout(0.25))
+answer.add(Dropout(0.3))
-           nb_epoch=70,
+           nb_epoch=120,
-        self.b = K.zeros((self.output_dim))
+        self.b = K.zeros((self.output_dim,))
-        self.gamma = self.init((input_shape))
+        self.gamma = self.init(input_shape)
-        self.running_std = K.ones((input_shape))
+        self.running_std = K.ones(input_shape)
-        self.b = K.zeros((self.output_dim))
+        self.b = K.zeros((self.output_dim,))
-        self.b_i = K.zeros((self.output_dim))
+        self.b_i = K.zeros((self.output_dim,))
-        self.b_f = self.forget_bias_init((self.output_dim))
+        self.b_f = self.forget_bias_init((self.output_dim,))
-        self.b_c = K.zeros((self.output_dim))
+        self.b_c = K.zeros((self.output_dim,))
-        self.b_o = K.zeros((self.output_dim))
+        self.b_o = K.zeros((self.output_dim,))
-# that works with python3 such as pydot2 or pydot
+try:
-    assert(loss < 0.7)
+    assert(loss < 0.8)
-    assert(loss < 0.7)
+    assert(loss < 0.8)
-    assert(loss < 0.7)
+    assert(loss < 0.8)
-    assert(loss < 0.7)
+    assert(loss < 0.8)
-                        generator_output = generator.next()
+                        generator_output = next(generator)
-                        generator_output = generator.next()
+                        generator_output = next(generator)
-                batch_size = len(data[data.keys()[0]])
+                batch_size = len(data[list(data.keys())[0]])
-    assert(loss < 0.8)
+    assert(loss < 0.9)
-def load_data(path="imdb.pkl", nb_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113,
+def load_data(path="imdb.pkl", nb_words=None, skip_top=0,
-    y_train = labels[:int(len(X)*(1-test_split))]
+    X_train = X[:int(len(X) * (1 - test_split))]
-    y_test = labels[int(len(X)*(1-test_split)):]
+    X_test = X[int(len(X) * (1 - test_split)):]
-def load_data(path="reuters.pkl", nb_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113,
+def load_data(path="reuters.pkl", nb_words=None, skip_top=0,
-    y_train = labels[:int(len(X)*(1-test_split))]
+    X_train = X[:int(len(X) * (1 - test_split))]
-    y_test = labels[int(len(X)*(1-test_split)):]
+    X_test = X[int(len(X) * (1 - test_split)):]
-    (X_train, y_train), (X_test, y_test) = load_data()
+import time
-    loss = model.evaluate(X_train, y_train, verbose=0)
+    loss = model.evaluate(X_test, y_test, verbose=0)
-    nloss = model.evaluate(X_train, y_train, verbose=0)
+    nloss = model.evaluate(X_test, y_test, verbose=0)
-    loss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    loss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    nloss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    nloss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    loss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    loss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    nloss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    nloss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    loss = model.evaluate([X_train, X_train, X_train], y_train, verbose=0)
+    loss = model.evaluate([X_test, X_test, X_test], y_test, verbose=0)
-    nloss = model.evaluate([X_train, X_train, X_train], y_train, verbose=0)
+    nloss = model.evaluate([X_test, X_test, X_test], y_test, verbose=0)
-    loss = model.evaluate(X_train, y_train, verbose=0)
+    loss = model.evaluate(X_test, y_test, verbose=0)
-    nloss = model.evaluate(X_train, y_train, verbose=0)
+    nloss = model.evaluate(X_test, y_test, verbose=0)
-    loss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    loss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    nloss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    nloss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    loss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    loss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    nloss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    nloss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    loss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    loss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    nloss = model.evaluate([X_train, X_train], y_train, verbose=0)
+    nloss = model.evaluate([X_test, X_test], y_test, verbose=0)
-    loss = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph})
+    loss = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph}, verbose=0)
-            assert kwarg in allowed_kwargs, "Keyword argument not understood: " + kwarg
+            assert kwarg in allowed_kwargs, 'Keyword argument not understood: ' + kwarg
-        assert self.nb_input == layer.nb_output == 1, "Cannot connect layers: input count and output count should be 1."
+        assert self.nb_input == layer.nb_output == 1, 'Cannot connect layers: input count and output count should be 1.'
-                str(self.input_ndim) + " but previous layer has output_shape " + str(layer.output_shape)
+            assert self.input_ndim == len(layer.output_shape), ('Incompatible shapes: layer expected input with ndim=' +
-            assert self.supports_masked_input(), "Cannot connect non-masking layer to layer with masked output"
+            assert self.supports_masked_input(), 'Cannot connect non-masking layer to layer with masked output'
-            str(len(self.params)) + ' layer params vs. ' + str(len(weights)) + ' provided weights)'
+        assert len(self.params) == len(weights), ('Provided weight array does not match layer weights (' +
-                raise Exception("Layer shape %s not compatible with weight shape %s." % (K.get_value(p).shape, w.shape))
+                raise Exception('Layer shape %s not compatible with weight shape %s.' % (K.get_value(p).shape, w.shape))
-        config = {"name": self.__class__.__name__}
+        config = {'name': self.__class__.__name__}
-            raise Exception("Masking is Theano-only for the time being.")
+        if K._BACKEND == 'tensorflow':
-                  "mask_value": self.mask_value}
+        config = {'name': self.__class__.__name__,
-                  "mode": self.mode}
+        config = {'name': self.__class__.__name__,
-                  "n": self.n}
+        config = {'name': self.__class__.__name__,
-                  "l2": self.l2}
+        config = {'name': self.__class__.__name__,
-                  "input_length": self.input_length}
+        config = {'name': self.__class__.__name__,
-                "output_reconstruction": self.output_reconstruction}
+        return {'name': self.__class__.__name__,
-                raise Exception("output_shape function must return a tuple")
+                raise Exception('output_shape function must return a tuple')
-                  "input_dim": self.input_dim}
+        config = {'name': self.__class__.__name__,
-    '''Normalize the activations of the previous layer at each batch.
+    '''Normalize the activations of the previous layer at each batch,
-            - 1: sample-wise normalization.
+                If the input has multiple feature dimensions,
-    x_rep = [s for s in splits for i in xrange(rep)]
+    x_rep = [s for s in splits for i in range(rep)]
-            for rep_axis in xrange(ndims):
+            for rep_axis in range(ndims):
-        self.g.set_node_defaults(shape='record', fontname="Fira Mono")
+        self.g.set_node_defaults(shape='record')
-        output = K.concatenate([X] * self.length, axis=1)
+        output = K.repeat_elements(X, self.length, axis=1)
-            output = K.concatenate([output] * self.size[1], axis=3)
+            output = K.repeat_elements(X, self.size[0], axis=2)
-            output = K.concatenate([output] * self.size[1], axis=2)
+            output = K.repeat_elements(X, self.size[0], axis=1)
-    '''Densely connected highway network, 
+    '''Densely connected highway network,
-    def __init__(self, init='glorot_uniform', transform_bias=-2, activation='linear', weights=None,
+    def __init__(self, init='glorot_uniform', transform_bias=-2,
-        
+
-        # -- initialize with a vector of values `transform_bias`
+        # initialize with a vector of values `transform_bias`
-from keras.utils.layer_utils import model_summary
+
-y_train = np_utils.to_categorical(y_train)
+def _get_test_data():
-        hh = self.inner_activation(x_h + K.dot(r * h_tm1, self.U_h))
+        hh = self.activation(x_h + K.dot(r * h_tm1, self.U_h))
-        assert couple[0] - couple[1] < 3
+        assert couple[0] - couple[1] <= 3
-    assert 0 in labels and 1 in labels
+import numpy as np
-        #turn off layer cache temporarily
+        # turn off layer cache temporarily
-        #recursively search for a layer which is not a Sequential model
+        # recursively search for a layer which is not a Sequential model
-        return  self._cache_enabled
+        return self._cache_enabled
-    F = K.function([X], [Y])
+    f = K.function([X], [Y])
-    y = F([x])[0].astype(K.floatx())
+    y = f([x])[0].astype(K.floatx())
-    F = K.function([X], [Y])
+    f = K.function([X], [Y])
-    y1 = F([x])[0].astype(K.floatx())
+    y1 = f([x])[0].astype(K.floatx())
-        
+
-    F = K.function([X], [Y2])
+    f = K.function([X], [Y2])
-    y1 = F([x])[0].astype(K.floatx())
+    y1 = f([x])[0].astype(K.floatx())
-    assert(loss < 0.7)
+    assert(loss < 0.8)
-
+
-    
+
-        Pad each sequence to the same length: 
+        Pad each sequence to the same length:
-        
+
-        We assume that the word frequencies follow Zipf's law (s=1) to derive 
+        We assume that the word frequencies follow Zipf's law (s=1) to derive
-        Take a sequence (list of indexes of words), 
+def skipgrams(sequence, vocabulary_size,
-        @param categorical: bool. if False, labels will be integers (eg. [0, 1, 1 .. ]), 
+        Paramaters:
-        Note: by convention, index 0 in the vocabulary is a non-word and will be skipped.
+        Returns:
-
+
-        super(Lambda, self).__init__
+        super(Lambda, self).__init__()
-                                         'inputs': [s],
+                                         'inputs': [name],
-    fname = 'test_merge_sum_temp.h5'
+    fname = 'test_siamese_1.h5'
-    fname = 'test_merge_sum_temp.h5'
+    fname = 'test_siamese_2.h5'
-    assert(loss < 0.7)
+    assert(loss < 0.8)
-    assert(loss < 0.7)
+    assert(loss < 0.8)
-    graph.add_output(name='output1', inputs=['dense2', 'dense3'],
+    graph.add_output(name='output1', inputs=['dense1', 'dense2'],
-        self.cache_enabled = True
+        self._cache_enabled = True
-    graph.add_shared_node(Dense(16), name='shared1', inputs['input1', 'input2'])
+    graph.add_shared_node(Dense(16), name='shared1', inputs=['input1', 'input2'])
-    def __call__(self, X, mask, train=False):
+    def __call__(self, X, mask=None, train=False):
-    @propery
+    @property
-    graph.add_shared_node(Dense(16), name='shared1', inputs['input1', 'input2'])
+    graph.add_shared_node(Dense(16), name='shared1', inputs=['input1', 'input2'])
-    def __call__(self, X, train=False):
+    def __call__(self, X, mask, train=False):
-        tmp = self.get_input
+        tmp_input = self.get_input
-        self.get_input = tmp
+        if hasattr(self, 'get_input_mask'):
-            self.cache_enabled = kwargs['cache_enabled']
+            self._cache_enabled = kwargs['cache_enabled']
-                          'batch_input_shape'}
+                          'batch_input_shape',
-            self.get_input_mask = lambda _: mask
+    def __call__(self, X, train=False):
-            self.get_input_mask = tmp_mask
+        # return input to what it was
-            if hasattr(self, 'layer_cache'):
+            if hasattr(self, 'layer_cache') and self.cache_enabled:
-            if hasattr(self, 'layer_cache'):
+            if hasattr(self, 'layer_cache') and self.cache_enabled:
-    graph.add_output(name='output1', inputs=['dense2', 'dense3'],
+    graph.add_output(name='output1', input='dense',
-    model.save_weights(fname, overwrite=True)
+
-    model.add(Merge([left, right], mode='sum'))
+    model.add(Siamese(Dense(nb_hidden), [left, right], merge_mode='sum'))
-from keras.layers.core import Dense, Activation, Merge, Lambda, LambdaMerge
+from keras.layers.core import Dense, Activation, Merge, Lambda, LambdaMerge, Siamese, add_shared_layer
-        Y = self.layer(X), mask)
+        Y = self.layer(X, mask)
-                 concat_axis=1, dot_axes=-1):
+                 concat_axis=1, dot_axes=-1, is_graph=False):
-        self.params = []
+        self.layer.set_previous(inputs[0])
-        layer.set_previous(inputs[0])
+        self.params = []
-        if merge_mode:
+        if merge_mode and not is_graph:
-        l.previous = self.inputs[index]
+    def set_layer_input(self, head):
-        return self.layer.get_output(train)
+        X = self.inputs[head].get_output(train)
-        if self.merge_mode:
+        if self.merge_mode and not self.is_graph:
-        if self.merge_mode:
+        if self.merge_mode and not self.is_graph:
-                  'dot_axes': self.dot_axes}
+                  'dot_axes': self.dot_axes,
-                    dot_axes=dot_axes)
+                    dot_axes=dot_axes,
-    def __call__(self, X, train=False):
+    def __call__(self, X, mask=None, train=False):
-        self.layers[0].get_input = lambda _: X
+        tmp_input = layer.get_input
-        self.layers[0].get_input = tmp
+        # return input from first layer to what it was
-        tmp = self.get_input
+    def __call__(self, X, mask=None, train=False):
-        self.get_input = tmp
+        # return input and mask to what it was
-                                       [[2], [3], [0], [0]]]))
+class TimeDistributedHighway(MaskedLayer):
-                              'saving model to %s'
+                        print('Epoch %05d: %s improved from %0.5f to %0.5f, saving model to %s'
-@pytest.mark.skipif(K._BACKEND == 'tensorflow', reason="currently not working with TensorFlow")
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-@pytest.mark.skipif(K._BACKEND == 'tensorflow', reason="currently not working with TensorFlow")
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-@pytest.mark.skipif(K._BACKEND == 'tensorflow', reason="currently not working with TensorFlow")
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-@pytest.mark.skipif(K._BACKEND=='tensorflow', reason="currently not working with TensorFlow")
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-                                                     output_shape=(4,))
+                                                                             nb_test=200,
-                                                         output_shape=(1,))
+                                                                                 nb_test=200,
-                        nb_epoch=10)
+    graph.fit({'input1': X_train_graph, 'output1': y_train_graph},
-                        validation_split=0.2, nb_epoch=1)
+    graph.fit({'input1': X_train_graph, 'output1': y_train_graph},
-                        nb_epoch=1)
+    graph.fit({'input1': X_train_graph, 'output1': y_train_graph},
-                        nb_epoch=10)
+    graph.fit({'input1': X_train_graph, 'output1': y_train_graph},
-                        nb_epoch=10)
+    graph.fit({'input1': X_train_graph, 'input2': X2_train_graph, 'output1': y_train_graph},
-                        nb_epoch=10)
+    graph.fit({'input1': X_train_graph, 'output1': y_train_graph, 'output2': y2_train_graph},
-                        sample_weight={'output1': weights1, 'output2': weights2})
+    graph.fit({'input1': X_train_graph, 'output1': y_train_graph, 'output2': y2_train_graph},
-    history = seq.fit(X_train_graph, y_train_graph, batch_size=10, nb_epoch=10)
+    seq.fit(X_train_graph, y_train_graph, batch_size=10, nb_epoch=10)
-    pred = seq.predict(X_test_graph)
+    seq.predict(X_test_graph)
-@pytest.mark.skipif(K._BACKEND=='tensorflow', reason="currently not working with TensorFlow")
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-            switch = T.any(input)
+            switch = T.any(input, axis=-1, keepdims=True)
-def class_to_link(cls):
+def class_to_docs_link(cls):
-                            link = '[' + defined_by.__name__ + '](' + class_to_link(defined_by) + ')'
+                            link = '[' + defined_by.__name__ + '](' + class_to_docs_link(defined_by) + ')'
-@pytest.mark.skipif(K._BACKEND == 'tensorflow', reason="currently not working with TensorFlow")
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-    """Test masking sequences with zeroes as padding"""
+    '''Test masking sequences with zeroes as padding'''
-    assert np.all(output == expected), "Output not as expected"
+    assert np.all(output == expected), 'Output not as expected'
-@pytest.mark.skipif(K._BACKEND == 'tensorflow', reason="currently not working with TensorFlow")
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-    """Test masking with non-zero mask value"""
+    '''Test masking with non-zero mask value'''
-    assert np.all(output == expected), "Output not as expected"
+    assert np.all(output == expected), 'Output not as expected'
-@pytest.mark.skipif(K._BACKEND == 'tensorflow', reason="currently not working with TensorFlow")
+@pytest.mark.skipif(K._BACKEND == 'tensorflow',
-    """Test output of masking layer with non-zero mask value"""
+    '''Test output of masking layer with non-zero mask value'''
-    assert np.all(output == expected), "Output not as expected"
+    assert np.all(output == expected), 'Output not as expected'
-
+    '''Abstract base class used to build new callbacks.
-        # skip progbar update for the last batch; will be handled by on_epoch_end
+        # skip progbar update for the last batch;
-    def __init__(self, filepath, monitor='val_loss', verbose=0, save_best_only=False, mode='auto'):
+    '''Save the model after every epoch.
-        
+
-            warnings.warn("ModelCheckpoint mode %s is unknown, fallback to auto mode" % (self.mode), RuntimeWarning)
+            warnings.warn('ModelCheckpoint mode %s is unknown, '
-        if mode == "min":
+
-        elif mode == "max":
+        elif mode == 'max':
-            if "acc" in self.monitor:
+            if 'acc' in self.monitor:
-                warnings.warn("Can save best model only with %s available, skipping." % (self.monitor), RuntimeWarning)
+                warnings.warn('Can save best model only with %s available, '
-                              % (epoch, self.monitor, self.best, current, filepath))
+                        print('Epoch %05d: %s improved from %0.5f to %0.5f, ' +
-                        print("Epoch %05d: %s did not improve" % (epoch, self.monitor))
+                        print('Epoch %05d: %s did not improve' %
-                print("Epoch %05d: saving model to %s" % (epoch, filepath))
+                print('Epoch %05d: saving model to %s' % (epoch, filepath))
-            warnings.warn("Early stopping requires %s available!" % (self.monitor), RuntimeWarning)
+            warnings.warn('Early stopping requires %s available!' %
-                    print("Epoch %05d: early stopping" % (epoch))
+                    print('Epoch %05d: early stopping' % (epoch))
-            r = requests.post(self.root + '/publish/epoch/end/', {'data': json.dumps(send)})
+            requests.post(self.root + '/publish/epoch/end/',
-            print('Warning: could not reach RemoteMonitor root server at ' + str(self.root))
+            print('Warning: could not reach RemoteMonitor '
-    learning rate as output.
+    '''Learning rate scheduler.
-from .utils.generic_utils import Progbar, printv
+from .utils.layer_utils import container_from_config
-        mask: binary
+        '''
-            raise Exception('class_weight not supported for 3+ dimensional targets.')
+            raise Exception('class_weight not supported for '
-                          class_mode=class_mode, theano_mode=theano_mode)
+                          class_mode=class_mode)
-                          theano_mode=theano_mode)
+            model.compile(loss=loss, optimizer=optimizer)
-                print("Train on %d samples, validate on %d samples" % (len(ins[0]), len(val_ins[0])))
+                print('Train on %d samples, validate on %d samples' %
-
+                    raise Exception('TypeError while preparing batch. '
-            Abstract method to loop over some data in batches.
+        '''Abstract method to loop over some data in batches.
-            Abstract method to loop over some data in batches.
+        '''Abstract method to loop over some data in batches.
-        for p in ['class_mode', 'theano_mode']:
+        for p in ['class_mode']:
-        # dump model configuration to yaml string
+        '''Return a yaml string containing the model configuration.
-        # dump model configuration to json string
+        '''Return a JSON string containing the model configuration.
-    '''
+    '''Linear stack of layers.
-                class_mode="categorical", theano_mode=None):
+                class_mode="categorical"):
-
+        '''Train the model for a fixed number of epochs.
-                    X_val may be a numpy array or a list of numpy arrays depending on your model input.")
+                raise Exception('Invalid format for validation data; '
-                sample_weight_val = standardize_weights(y_val, sample_weight=sample_weight_val)
+                sample_weight_val = standardize_weights(y_val,
-        sample_weight = standardize_weights(y, class_weight=class_weight, sample_weight=sample_weight)
+        sample_weight = standardize_weights(y, class_weight=class_weight,
-            warnings.warn("Network returning invalid probability values.")
+            warnings.warn('Network returning invalid probability values.')
-        if self.class_mode == "categorical":
+        if self.class_mode == 'categorical':
-        # Save weights from all layers to HDF5
+        '''Dump all layer weights to a HDF5 file.
-            overwrite = get_input('[WARNING] %s already exists - overwrite? [y/n]' % (filepath))
+            overwrite = get_input('[WARNING] %s already exists - overwrite? '
-                param_dset = g.create_dataset(param_name, param.shape, dtype=param.dtype)
+                param_dset = g.create_dataset(param_name, param.shape,
-        # Loads weights from HDF5 file
+            # This method does not make use of Sequential.set_weights()
-        # loss is a dictionary mapping output name to loss functions
+    '''Arbitrary connection graph.
-        updates = self.optimizer.get_updates(self.params, self.constraints, train_loss)
+        updates = self.optimizer.get_updates(self.params,
-        return self._predict(ins)
+        self._predict = K.function(inputs=ins, outputs=ys_test,
-        history = self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,
+        history = self._fit(f, ins, out_labels=out_labels,
-        # Save weights from all layers to HDF5
+        '''Save weights from all layers to a HDF5 files.
-            overwrite = get_input('[WARNING] %s already exists - overwrite? [y/n]' % (filepath))
+            overwrite = get_input('[WARNING] %s already exists - overwrite? '
-            param_dset = g.create_dataset(param_name, param.shape, dtype=param.dtype)
+            param_dset = g.create_dataset(param_name, param.shape,
-        # Loads weights from HDF5 file
+        '''Load weights from a HDF5 file.
-
+    '''Stochastic gradient descent, with support for momentum,
-        Reference: http://arxiv.org/abs/1212.5701
+    '''Adadelta optimizer.
-        Reference: http://arxiv.org/abs/1412.6980v8
+    '''Adam optimizer.
-        Default parameters follow those provided in the original paper.
+    # References
-    pytest.main([__file__])
+import pytest
-np.random.seed(1337)
+    np.random.seed(1337)
-    assert(loss < 0.7)
+    assert(loss < 0.9)
-import unittest
+import pytest
-import pytest
+
-                assert_allclose(outp, inp)
+def test_leaky_relu():
-                assert_allclose(outp, -inp*alpha)
+        layer.input = K.variable(-inp)
-            assert config['alpha'] == alpha
+        config = layer.get_config()
-            # layer.build()
+def test_prelu():
-            assert_allclose(inp, outp)
+    for train in [True, False]:
-            assert_allclose(-alphas*inp, outp)
+        layer.input = K.variable(inp)
-            assert_allclose(inp, outp)
+        layer.input = K.variable(-inp)
-            outp = K.eval(layer.get_output(train))
+        # test with default weights
-            assert_allclose(0., alphas*outp)
+        layer.input = K.variable(-inp)
-            layer.get_config()
+        assert_allclose(0., alphas*outp)
-                assert_allclose(outp, inp, rtol=1e-3)
+        layer.get_config()
-                assert_allclose(outp, inp*(np.abs(inp) >= theta))
+def test_elu():
-            layer.input = K.variable(-inp)
+        layer.input = K.variable(-inp)
-                assert_allclose(outp, -inp*(np.abs(inp) >= theta))
+                assert_allclose(outp, alpha*np.log(1.+np.exp(beta*inp)),
-                assert_allclose(outp, inp*(inp > theta))
+            assert config['alpha_init'] == alpha
-                assert_allclose(outp, -inp*(-inp > theta))
+        layer.input = K.variable(-inp)
-            assert config['theta'] == theta
+        config = layer.get_config()
-    unittest.main()
+    pytest.main([__file__])
-        ''' Whether or not this layer respects the output mask of its previous
+        '''Whether or not this layer respects the output mask of its previous
-        For some models (such as RNNs) you want a way of being able to mark
+        '''For some models (such as RNNs) you want a way of being able to mark
-                output of `get_weights`).
+        weights: a list of numpy arrays. The number
-        # Returns: list of numpy arrays.
+        '''Return the weights of the layer,
-            A dictionary mapping parameter names to their values.
+        '''Return the parameters of the layer, as a dictionary.
-                    raise ValueError('merge_mode='join' only works with named inputs')
+                    raise ValueError('merge_mode="join" only works with named inputs')
-            raise Exception("Please specify two or more input layers (or containers) to merge")
+            raise Exception('Please specify two or more input layers '
-            raise Exception("Invalid merge mode: " + str(mode))
+            raise Exception('Invalid merge mode: ' + str(mode))
-                                "Layer shapes: %s" % ([l.output_shape for l in layers]))
+                raise Exception('Only layers of same output shape can '
-                raise Exception(mode + " merge takes exactly 2 layers")
+                raise Exception(mode + ' merge takes exactly 2 layers')
-                    raise Exception("Invalid type for dot_axes - should be a list.")
+                    raise Exception('Invalid type for dot_axes - should be a list.')
-                    raise Exception("Invalid format for dot_axes - should contain two elements.")
+                    raise Exception('Invalid format for dot_axes - should contain two elements.')
-                    raise Exception("Invalid format for dot_axes - list elements should have type 'list' or 'tuple'.")
+                    raise Exception('Invalid format for dot_axes - list elements should have type "list" or "tuple".')
-                                        "Layer shapes: %s, %s" % (shape1, shape2))
+                        raise Exception('Dimension incompatibility using dot mode: ' +
-                                "Layer shapes: %s" % ([l.output_shape for l in layers]))
+                raise Exception('"concat" mode can only merge layers with matching ' +
-                  "dot_axes": self.dot_axes}
+        config = {'name': self.__class__.__name__,
-                  "p": self.p}
+        config = {'name': self.__class__.__name__,
-                  "activation": self.activation.__name__}
+        config = {'name': self.__class__.__name__,
-                  "dims": self.dims}
+        config = {'name': self.__class__.__name__,
-                  "dims": self.dims}
+        config = {'name': self.__class__.__name__,
-                  "input_dim": self.input_dim}
+        config = {'name': self.__class__.__name__,
-from ..layers.core import Layer, MaskedLayer
+from ..layers.core import MaskedLayer
-                http://arxiv.org/pdf/1502.01852v1.pdf
+    # Input shape
-        Parametric Softplus of the form: alpha * log(1 + exp(beta * X))
+    '''Parametric Softplus of the form: alpha * log(1 + exp(beta * X))
-            http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003143
+    # Arguments
-        Thresholded Linear Activation
+    '''Thresholded Linear Activation.
-            http://arxiv.org/pdf/1402.3337.pdf
+    # Output shape
-        Thresholded Rectified Activation
+    '''Thresholded Rectified Activation.
-            http://arxiv.org/pdf/1402.3337.pdf
+    # References
-        Simple linear stack of layers.
+    '''The Sequential container is a linear stack of layers.
-    '''
+    This class is also the basis for the `keras.models.Sequential` model.
-                "layers": [layer.get_config() for layer in self.layers]}
+        return {'name': self.__class__.__name__,
-            - set_weights
+    '''Implement a NN graph with arbitrary layer connections,
-            raise Exception('Cannot connect layers: input count does not match output count.')
+            raise Exception('Cannot connect layers: '
-                raise Exception('Cannot attach multi-input layer: no connection_map provided.')
+                raise Exception('Cannot attach multi-input layer: '
-    def add_input(self, name, input_shape=None, batch_input_shape=None, dtype='float'):
+    def add_input(self, name, input_shape=None,
-            Output will be created only if merge_mode is given
+        '''Used to share a same layer across multiple nodes.
-                raise Exception("Invalid merge mode")
+                raise Exception('Invalid merge mode')
-        s = Siamese(layer, layers, merge_mode, concat_axis=concat_axis, dot_axes=dot_axes)
+        s = Siamese(layer, layers, merge_mode,
-                raise Exception("Output can not be of type OrderedDict")
+                raise Exception('Output can not be of type OrderedDict')
-                "nodes": dict([(c["name"], self.nodes[c["name"]].get_config()) for c in self.node_config])}
+        return {'name': self.__class__.__name__,
-                  "input_length": self.input_length}
+        config = {'name': self.__class__.__name__,
-                  "b_constraint": self.b_constraint.get_config() if self.b_constraint else None}
+        config = {'name': self.__class__.__name__,
-class Pooling1D(Layer):
+class _Pooling1D(Layer):
-        super(Pooling1D, self).__init__(**kwargs)
+        super(_Pooling1D, self).__init__(**kwargs)
-                         border_mode, dim_ordering):
+    def _pooling_function(self, back_end, inputs, pool_size, strides,
-                                       dim_ordering='th')
+        output = self._pooling_function(inputs=X, pool_size=self.pool_size,
-        base_config = super(Pooling1D, self).get_config()
+        config = {'name': self.__class__.__name__,
-        super(MaxPooling1D, self).__init__(*args, **kwargs)
+class MaxPooling1D(_Pooling1D):
-                         border_mode, dim_ordering):
+    # Input shape
-        super(AveragePooling1D, self).__init__(*args, **kwargs)
+class AveragePooling1D(_Pooling1D):
-                         border_mode, dim_ordering):
+    def _pooling_function(self, inputs, pool_size, strides,
-class Pooling2D(Layer):
+class _Pooling2D(Layer):
-        super(Pooling2D, self).__init__(**kwargs)
+        super(_Pooling2D, self).__init__(**kwargs)
-                         border_mode, dim_ordering):
+    def _pooling_function(self, inputs, pool_size, strides,
-                                       dim_ordering=self.dim_ordering)
+        output = self._pooling_function(inputs=X, pool_size=self.pool_size,
-        base_config = super(Pooling2D, self).get_config()
+        config = {'name': self.__class__.__name__,
-        super(MaxPooling2D, self).__init__(*args, **kwargs)
+class MaxPooling2D(_Pooling2D):
-                         border_mode, dim_ordering):
+    def _pooling_function(self, inputs, pool_size, strides,
-        super(AveragePooling2D, self).__init__(*args, **kwargs)
+class AveragePooling2D(_Pooling2D):
-                         border_mode, dim_ordering):
+    def _pooling_function(self, inputs, pool_size, strides,
-                  "length": self.length}
+        config = {'name': self.__class__.__name__,
-                  "size": self.size}
+        config = {'name': self.__class__.__name__,
-    """
+    '''Zero-padding layer for 1D input (e.g. temporal sequence).
-                  "padding": self.padding}
+        config = {'name': self.__class__.__name__,
-    """Zero-padding layer for 2D input (e.g. picture).
+    '''Zero-padding layer for 2D input (e.g. picture).
-    4D tensor with shape:
+    # Input shape
-    4D tensor with shape:
+    # Output shape
-    """
+    # Arguments
-                  "padding": self.padding}
+        config = {'name': self.__class__.__name__,
-        an error'''
+        ''' Whether or not this layer respects the output mask of its previous
-        Some layers have an output_mask even if their input is unmasked, notably Embedding which can turn the entry "0" into
+        For some models (such as RNNs) you want a way of being able to mark
-    If your layer trivially supports masking
+    '''If your layer trivially supports masking
-    into your calculation of get_output()
+    into your calculation of get_output().
-    """Mask an input sequence by using a mask value to identify padding.
+    '''Mask an input sequence by using a mask value to identify padding.
-    """
+    '''
-    Tensor output dimensions:  (nb_sample, features)
+
-                    raise ValueError("merge_mode='join' only works with named inputs")
+                    raise ValueError('merge_mode='join' only works with named inputs')
-        Hinton's dropout.
+    '''Apply Dropout to the input. Dropout consists in randomly setting
-    def __init__(self, activation, target=0, beta=0.1, **kwargs):
+    def __init__(self, activation, **kwargs):
-                  "beta": self.beta}
+                  "activation": self.activation.__name__}
-        First dimension is assumed to be nb_samples.
+    '''Reshape an output to a certain shape.
-        Permute the dimensions of the input according to the given tuple.
+    '''Permute the dimensions of the input according to a given pattern.
-        First dimension is assumed to be nb_samples.
+    '''Flatten the input. Does not affect the batch size.
-        Repeat input n times.
+    '''Repeat the input n times.
-        Return tensor of shape (nb_samples, n, dim).
+    # Input shape
-        Just your regular fully connected NN layer.
+    '''Just your regular fully connected NN layer.
-        to the cost function based on the activity.
+    '''Layer that passes through its input unchanged, but applies an update
-
+    '''Apply a same Dense layer for each dimension[1] (time_dimension) input.
-            same as decoder output
+    # Input shape
-    def __init__(self, encoder, decoder, output_reconstruction=True, weights=None, **kwargs):
+    def __init__(self, encoder, decoder, output_reconstruction=True,
-        Refer to http://arxiv.org/pdf/1302.4389.pdf
+    '''A dense maxout layer.
-    def __init__(self, output_dim, nb_feature=4, init='glorot_uniform', weights=None,
+    def __init__(self, output_dim, nb_feature=4,
-                  "input_dim": self.input_dim}
+        config = {'name': self.__class__.__name__,
-
+    '''Used for evaluating an arbitrary Theano / TensorFlow expression
-    """
+    '''LambdaMerge layer for evaluating an arbitrary Theano / TensorFlow
-            raise Exception("Please specify two or more input layers (or containers) to merge")
+            raise Exception('Please specify two or more input layers '
-                raise Exception("output_shape function must return a tuple")
+                raise Exception('output_shape function must return a tuple')
-                  }
+        config = {'name': self.__class__.__name__,
-    dot_axes - Similar to dot_axes argument of Merge layer
+    '''Share a layer accross multiple inputs.
-            raise Exception("Invalid merge mode: " + str(merge_mode))
+            raise Exception('Invalid merge mode: ' + str(merge_mode))
-                raise Exception(merge_mode + " merge takes exactly 2 layers")
+                raise Exception(merge_mode + ' merge takes exactly 2 layers')
-                raise ValueError("merge_mode='join' only works with named inputs")
+                raise ValueError('merge_mode="join" '
-                  }
+        config = {'name': self.__class__.__name__,
-        should be obtained
+    # Arguments
-                  "head": self.head}
+        config = {'name': self.__class__.__name__,
-    without merging the outputs
+    '''Use this function to add a shared layer across
-        @out_dim: size of dense representation
+    '''Turn positive integers (indexes) into denses vectors of fixed size.
-        Corruption process with GaussianNoise
+    '''Apply to the input an additive zero-centred gaussian noise with
-            http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf
+    '''Apply to the input an multiplicative one-centred gaussian noise
-                http://arxiv.org/pdf/1502.03167v3.pdf
+    '''Normalize the activations of the previous layer at each batch.
-                       (may sometimes outperform featurewise mode)
+    # Arguments
-            of a running estimate of the mean and std of the data
+    # References
-            (nb_samples, max_sample_length, output_dim)
+    '''Fully-connected RNN where the output is to fed back to input.
-                http://arxiv.org/pdf/1412.3555v1.pdf
+    '''Gated Recurrent Unit - Cho et al. 2014.
-                http://www.cs.toronto.edu/~graves/preprint.pdf
+    '''Long-Short Term Memory unit - Hochreiter 1997.
-                previous_layer_id = id(self.previous)
+                previous_layer_id = '%s_%s' % (id(self.previous), train)
-                previous_layer_id = id(self.previous)
+                previous_layer_id = '%s_%s' % (id(self.previous), train)
-            return self.previous.get_output(train=train)
+            # to avoid redundant computations,
-        output, new_states = step_function(ins, states)
+    def _step(input, *states):
-            switch = T.any(ins)
+            switch = T.any(input)
-
+    out4 = model.predict(np.ones((nb_samples, timesteps, input_dim)))
-                                              lambda: 0. * output)
+            output = tf.python.control_flow_ops.cond(switch,
-                                                              lambda: state))
+                return_states.append(tf.python.control_flow_ops.cond(switch,
-                                    lambda: else_expression)
+    return tf.python.control_flow_ops.cond(condition,
-            X *= K.expand_dims(mask).astype(X.dtype)
+            X *= K.cast(K.expand_dims(mask), X.dtype)
-            X *= K.expand_dims(mask)
+            X *= K.expand_dims(mask).astype(X.dtype)
-        output = conv_out + K.reshape(self.b, (1, self.nb_filter, 1, 1))
+        if self.dim_ordering == 'th':
-    from keras.backend import tensorflow_backend as KTF
+from keras.backend import theano_backend as KTH
-                ndim = len(K.get_shape(l.input))
+                ndim = K.ndim(l.input)
-        output, new_states = step_function(input, states)
+    def _step(ins, *states):
-            switch = T.any(input)
+            switch = T.any(ins)
-            if l.trainable and getattr(l, 'stateful', False):
+            if getattr(l, 'stateful', False):
-            if l.trainable and getattr(l, 'stateful', False):
+            if getattr(l, 'stateful', False):
-import unittest
+import pytest
-        self.assertTrue(np.all(output == expected))
+def test_input_output():
-            return
+    @pytest.mark.skipif(K._BACKEND=='tensorflow', reason="currently not working with TensorFlow")
-            return
+    @pytest.mark.skipif(K._BACKEND=='tensorflow', reason="currently not working with TensorFlow")
-            return
+@pytest.mark.skipif(K._BACKEND=='tensorflow', reason="currently not working with TensorFlow")
-
+import pytest
-            return
+import pytest
-            return
+    @pytest.mark.skipif(K._BACKEND=='tensorflow', reason="currently not working with TensorFlow")
-import unittest
+import pytest
-class TestBackend(unittest.TestCase):
+class TestBackend(object):
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-    """Test __call__ methods"""
+def test_layer_call():
-        F = K.function([X], [Y])
+    x = np.ones((nb_samples, input_dim)).astype(K.floatx())
-        model.compile('sgd', 'mse')
+def test_sequential_call():
-        F = K.function([X], [Y])
+    X = K.placeholder(ndim=2)
-        assert_allclose(y1, y2)
+    x = np.ones((nb_samples, input_dim)).astype(K.floatx())
-    unittest.main(verbosity=2)
+    pytest.main([__file__])
-import unittest
+import pytest
-                                    input_shape=(None, input_dim))
+def test_convolution_1d():
-                                    assert input.shape[1] == out.shape[1]
+                                if border_mode == 'same' and subsample == (1, 1):
-            layer = convolutional.MaxPooling2D(strides=strides,
+def test_maxpooling_2d():
-            layer.get_config()
+        layer.input = K.variable(input)
-        layer = convolutional.ZeroPadding2D(padding=(2, 2))
+def test_zero_padding_2d():
-            assert_allclose(out[:, :, 2:-2, 2:-2], 1.)
+            assert out.shape[1] == length * nb_steps
-            layer = convolutional.UpSampling1D(length=length)
+def test_upsampling_2d():
-            layer.get_config()
+                assert out.shape[2] == length_row * input_nb_row
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-class TestLayerBase(unittest.TestCase):
+class TestLayerBase(object):
-class TestConfigParams(unittest.TestCase):
+class TestConfigParams(object):
-class TestMasking(unittest.TestCase):
+class TestMasking(object):
-        self.assertTrue(np.all(output == expected))
+        assert(np.all(output == expected))
-        self.assertTrue(np.all(output == expected))
+        assert(np.all(output == expected))
-        self.assertTrue(np.all(output == expected))
+        assert(np.all(output == expected))
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-        _runner(recurrent.SimpleRNN)
+def test_SimpleRNN():
-        _runner(recurrent.LSTM)
+def test_LSTM():
-    unittest.main()
+    pytest.main([__file__])
-from keras import backend as K
+import pytest
-class TestActivations(unittest.TestCase):
+def test_softmax():
-        from keras.activations import softmax as s
+    x = K.placeholder(ndim=2)
-            return e / np.sum(e)
+    result = f([test_values])[0]
-        assert_allclose(result, expected, rtol=1e-05)
+def test_relu():
-        from keras.activations import relu as r
+    test_values = get_standard_values()
-        f = K.function([x], [exp])
+    # because no negatives in test values
-        assert_allclose(result, test_values, rtol=1e-05)
+def test_tanh():
-        test_values = get_standard_values()
+    x = K.placeholder(ndim=2)
-        f = K.function([x], [exp])
+    result = f([test_values])[0]
-        from keras.activations import linear as l
+def test_linear():
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-        self.example_array[0, 0] = 0.  # 0 could possibly cause trouble
+from keras import backend as K
-            assert (np.all(K.eval(normed) < m))
+test_values = [0.1, 0.5, 3, 8, 1e-7]
-        from keras.constraints import nonneg
+def test_maxnorm():
-        nonneg_instance = nonneg()
+    # a more explicit example
-        from keras.constraints import identity
+def test_nonneg():
-        assert (np.all(normed == self.example_array))
+def test_identity():
-        assert(oddball_examples == identity_instance(oddball_examples))
+def test_identity_oddballs():
-        normalized = unitnorm_instance(K.variable(self.example_array))
+def test_unitnorm():
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-        self.input_3 = np.ones((10))
+input_1 = np.arange(10)
-        self.input_shapes = [np.ones((10, 10)), np.ones((10, 10, 10))]
+    assert_allclose(K.eval(K.mean(out)), 0.0, atol=1e-1)
-                          normalization.BatchNormalization(input_shape=(10, 10), mode=3))
+def test_batchnorm_mode_1():
-        model.compile(loss='mse', optimizer='sgd')
+    for inp in [input_1, input_2, input_3]:
-        norm_m0.input = K.variable(X)
+
-        norm.set_weights(weights)
+        norm_m1 = normalization.BatchNormalization(input_shape=inp.shape, mode=1)
-    unittest.main()
+    pytest.main([__file__])
-from .utils.layer_utils import container_from_config
+from .utils.layer_utils import container_from_config, model_summary
-
+    def reset_states(self):
-            self.state_updates = []
+            self.updates = []
-                self.state_updates.append((self.states[i], states[i]))
+                self.updates.append((self.states[i], states[i]))
-        self._predict = K.function(predict_ins, [self.y_test], updates=state_updates)
+        self._predict = K.function(predict_ins, [self.y_test], updates=self.state_updates)
-        self._predict = K.function(inputs=ins, outputs=ys_test, updates=state_updates)
+        self._predict = K.function(inputs=ins, outputs=ys_test, updates=self.state_updates)
-            self.updates = []
+            self.state_updates = []
-                self.updates.append((self.states[i], states[i]))
+                self.state_updates.append((self.states[i], states[i]))
-        self._predict = K.function(predict_ins, [self.y_test], updates=self.updates)
+        self._predict = K.function(predict_ins, [self.y_test], updates=state_updates)
-        self._predict = K.function(inputs=ins, outputs=ys_test)
+        self._predict = K.function(inputs=ins, outputs=ys_test, updates=state_updates)
-        output = self.activation(h * K.dot(prev_output, self.U))
+        output = self.activation(h + K.dot(prev_output, self.U))
-        return dict(list(base_config.items()) + list(config.items()))
+    def reset_states(self):
-        self._predict = K.function(predict_ins, [self.y_test])
+        self._predict = K.function(predict_ins, [self.y_test], updates=self.updates)
-def softmax(values):
+def ref_softmax(values):
-    from keras.activations import softmax as s
+    from keras.activations import softmax
-    f = K.function([x], [exp])
+    softmax_out = softmax(x)
-    expected = softmax(test_values)
+    expected = ref_softplus(test_values)
-
+
-import unittest
+import pytest
-    unittest.main()
+# Reference sigmoid, numerically stable
-An implementation of sequence to sequence learning for performing addition
+'''An implementation of sequence to sequence learning for performing addition
-"""
+'''
-    """
+    '''
-    """
+    '''
-    model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=1, validation_data=(X_val, y_val), show_accuracy=True)
+    model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=1,
-Train a memory network on the bAbI dataset.
+'''Train a memory network on the bAbI dataset.
-"""
+'''
-Trains two recurrent neural networks based upon a story and a question.
+'''Trains two recurrent neural networks based upon a story and a question.
-from __future__ import absolute_import
+'''Train a simple deep CNN on the CIFAR10 small images dataset.
-X_test = X_test.astype("float32")
+X_train = X_train.astype('float32')
-    print("Not using data augmentation or normalization")
+    print('Not using data augmentation or normalization')
-    print("Using real time data augmentation")
+    print('Using real time data augmentation')
-        print("Training...")
+        print('Training...')
-            progbar.add(X_batch.shape[0], values=[("train loss", loss[0])])
+            progbar.add(X_batch.shape[0], values=[('train loss', loss[0])])
-        print("Testing...")
+        print('Testing...')
-            progbar.add(X_batch.shape[0], values=[("test loss", score[0])])
+            progbar.add(X_batch.shape[0], values=[('test loss', score[0])])
-from __future__ import absolute_import
+'''Train a Bidirectional LSTM on the IMDB sentiment classification task.
-print("Loading data...")
+print('Loading data...')
-print("Train...")
+print('Train...')
-from __future__ import absolute_import
+'''This example demonstrates the use of Convolution1D for text classification.
-print("Loading data...")
+print('Loading data...')
-print("Pad sequences (samples x time)")
+print('Pad sequences (samples x time)')
-                        activation="relu",
+                        border_mode='valid',
-              class_mode="binary")
+              class_mode='binary')
-from __future__ import absolute_import
+'''Train a recurrent convolutional network on the IMDB sentiment
-print("Loading data...")
+print('Loading data...')
-print("Pad sequences (samples x time)")
+print('Pad sequences (samples x time)')
-                        activation="relu",
+                        border_mode='valid',
-              class_mode="binary")
+              class_mode='binary')
-print("Train...")
+print('Train...')
-from __future__ import absolute_import
+'''Train a LSTM on the IMDB sentiment classification task.
-print("Loading data...")
+print('Loading data...')
-from __future__ import print_function
+'''This demonstrates how to reach a score of 0.4890 (local validation)
-    print("Wrote submission to file {}.".format(fname))
+    print('Wrote submission to file {}.'.format(fname))
-print("Loading data...")
+print('Loading data...')
-print("Building model...")
+print('Building model...')
-model.compile(loss='categorical_crossentropy', optimizer="adam")
+model.compile(loss='categorical_crossentropy', optimizer='adam')
-print("Training model...")
+print('Training model...')
-print("Generating submission...")
+print('Generating submission...')
-from __future__ import absolute_import
+'''Train a simple convnet on the MNIST dataset.
-X_test = X_test.astype("float32")
+X_train = X_train.astype('float32')
-model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))
+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
-from __future__ import absolute_import
+'''This is a reproduction of the IRNN experiment
-X_test = X_test.astype("float32")
+X_train = X_train.astype('float32')
-from __future__ import absolute_import
+'''Train a simple deep NN on the MNIST dataset.
-X_test = X_test.astype("float32")
+X_train = X_train.astype('float32')
-from __future__ import absolute_import
+'''Transfer learning toy example:
-    X_test = X_test.astype("float32")
+    X_train = X_train.astype('float32')
-from __future__ import absolute_import
+'''Train and evaluate a simple MLP on the Reuters newswire topic classification task.
-print("Loading data...")
+print('Loading data...')
-print("Vectorizing sequence data...")
+print('Vectorizing sequence data...')
-X_test = tokenizer.sequences_to_matrix(X_test, mode="binary")
+X_train = tokenizer.sequences_to_matrix(X_train, mode='binary')
-print("Convert class vector to binary class matrix (for use with categorical_crossentropy)")
+print('Convert class vector to binary class matrix (for use with categorical_crossentropy)')
-print("Building model...")
+print('Building model...')
-                K.set_value(self.states[i], K.eval(states[i]))
+                self.updates.append((self.states[i], states[i]))
-        self.states = [K.zeros((input_shape[0], self.output_dim))]
+        if hasattr(self, 'states'):
-        self.states = [K.zeros((input_shape[0], self.output_dim))]
+        if hasattr(self, 'states'):
-                       K.zeros((input_shape[0], self.output_dim))]
+        if hasattr(self, 'states'):
-    out2 = K.eval(layer.get_output(train))
+    layer = layer_class(output_dim, return_sequences=False,
-    # check that output stays the same when state is reset
+
-    assert_allclose(out1, out3, atol=1e-5)
+    out3 = model.predict(np.ones((nb_samples, timesteps, input_dim)))
-                K.set_value(self.states[i], states[i])
+                K.set_value(self.states[i], K.eval(states[i]))
-            self.states = [K.zeros((input_shape[0], self.output_dim))]
+            self.reset_states()
-            self.states = [K.zeros((input_shape[0], self.output_dim))]
+            self.reset_states()
-                           K.zeros((input_shape[0], self.output_dim))]
+            self.reset_states()
-    layer = layer_class(output_dim, return_sequences=False,
+    layer = layer_class(output_dim, return_sequences=False, stateful=True,
-    out = K.eval(layer.get_output(train))
+    out1 = K.eval(layer.get_output(train))
-                                str(self.input_ndim) + ', was provided with input shape ' + str(input_shape))
+                                str(self.input_ndim) +
-                and is not an input layer.')
+            raise Exception('Layer is not connected' +
-    def __init__(self, pool_length=2, stride=None, border_mode='valid', **kwargs):
+    def __init__(self, pool_length=2, stride=None,
-    def pooling_function(self, back_end, inputs, pool_size, strides, border_mode, dim_ordering):
+    def pooling_function(self, back_end, inputs, pool_size, strides,
-        output = self.pooling_function(back_end=K, inputs=X, pool_size=self.pool_size,
+        output = self.pooling_function(inputs=X, pool_size=self.pool_size,
-        super(MaxPooling1D, self).__init__(**kwargs)
+    def __init__(self, *args, **kwargs):
-                                 border_mode, dim_ordering, pool_mode='max')
+    def pooling_function(self, inputs, pool_size, strides,
-        super(AveragePooling1D, self).__init__(**kwargs)
+    def __init__(self, *args, **kwargs):
-                                 border_mode, dim_ordering, pool_mode='avg')
+    def pooling_function(self, inputs, pool_size, strides,
-    def pooling_function(self, back_end, inputs, pool_size, strides, border_mode, dim_ordering):
+    def pooling_function(self, inputs, pool_size, strides,
-        output = self.pooling_function(back_end=K, inputs=X, pool_size=self.pool_size,
+        output = self.pooling_function(inputs=X, pool_size=self.pool_size,
-        super(MaxPooling2D, self).__init__(**kwargs)
+    def __init__(self, *args, **kwargs):
-                                 border_mode, dim_ordering, pool_mode='max')
+    def pooling_function(self, inputs, pool_size, strides,
-        super(AveragePooling2D, self).__init__(**kwargs)
+    def __init__(self, *args, **kwargs):
-                                 border_mode, dim_ordering, pool_mode='avg')
+    def pooling_function(self, inputs, pool_size, strides,
-                  "layer": self.layer.get_config,
+                  "layer": self.layer.get_config(),
-    pytest.main([__file__])
+from __future__ import absolute_import
-    The values should all be non-negative becasue they and their negative
+    The values should all be non-negative because they and their negatives
-                assert_allclose(outp,inp)
+                assert_allclose(outp, inp)
-                assert_allclose(outp,-inp*alpha)
+                assert_allclose(outp, -inp*alpha)
-            #test with custom weights
+            # test with custom weights
-            assert_allclose(inp,outp)
+            assert_allclose(inp, outp)
-            assert_allclose(-alphas*inp,outp)
+            assert_allclose(-alphas*inp, outp)
-            #test with default weights
+            # test with default weights
-            assert_allclose(inp,outp)
+            assert_allclose(inp, outp)
-                assert_allclose(outp,inp,rtol=1e-3)
+                assert_allclose(outp, inp, rtol=1e-3)
-                assert_allclose(outp,alpha*(np.exp(-inp)-1.),rtol=1e-3)
+                assert_allclose(outp, alpha*(np.exp(-inp)-1.), rtol=1e-3)
-        #large values cause overflow in exp
+        inp = np.vstack((get_standard_values(), -get_standard_values()))
-                layer = ParametricSoftplus(alpha_init=alpha, beta_init=beta, input_shape=inp.shape)
+            for beta in [.5, -1., 1., 2]:
-                    assert_allclose(outp,alpha*np.log(1.+np.exp(beta*inp)),atol=1e-3)
+                    assert_allclose(outp, alpha*np.log(1.+np.exp(beta*inp)),
-                assert_allclose(outp,inp*(np.abs(inp)>=theta))
+                assert_allclose(outp, inp*(np.abs(inp) >= theta))
-                assert_allclose(outp,-inp*(np.abs(inp)>=theta))
+                assert_allclose(outp, -inp*(np.abs(inp) >= theta))
-                assert_allclose(outp,inp*(inp>theta))
+                assert_allclose(outp, inp*(inp > theta))
-                assert_allclose(outp,-inp*(-inp>theta))
+                assert_allclose(outp, -inp*(-inp > theta))
-            return tuple(input_shapes[0][0], 1)
+            return (input_shapes[0][0], 1)
-                                    outputs_info=None)
+            output = T.batched_tensordot(l1, l2, self.dot_axes) / T.sqrt(T.batched_tensordot(l1, l1, self.dot_axes) * T.batched_tensordot(l2, l2, self.dot_axes))
-            return tuple(input_shapes[0][0], 1)
+            return (input_shapes[0][0], 1)
-        output, _ = theano.scan(cos, sequences=[l1, l2], outputs_info=None)
+        output = T.batched_tensordot(l1, l2, self.dot_axes) / T.sqrt(T.batched_tensordot(l1, l1, self.dot_axes) * T.batched_tensordot(l2, l2, self.dot_axes))
-            return self.get_output_dot(train)
+            return self.get_output_cos(train)
-def test_AveragePooling1D(self):
+def test_AveragePooling1D():
-def test_AveragePooling2D(self):
+def test_AveragePooling2D():
-        # Only seems to work with mode='ignore_borders' right now
+    elif pool_mode == 'avg':
-              border_mode='valid', dim_ordering='th', pool_mode='max'):
+           border_mode='valid', dim_ordering='th', pool_mode='max'):
-        if pool_mode=='max':
+    if dim_ordering in {'tf', 'th'}:
-        elif pool_mode=='mean':
+        elif pool_mode == 'avg':
-class MeanPooling1D(Pooling1D):
+class AveragePooling1D(Pooling1D):
-        super(MeanPooling1D, self).__init__(**kwargs)
+        super(AveragePooling1D, self).__init__(**kwargs)
-                                 border_mode, dim_ordering, pool_mode='mean')
+                                 border_mode, dim_ordering, pool_mode='avg')
-class MeanPooling2D(Pooling2D):
+class AveragePooling2D(Pooling2D):
-        super(MeanPooling2D, self).__init__(**kwargs)
+        super(AveragePooling2D, self).__init__(**kwargs)
-                                 border_mode, dim_ordering, pool_mode='mean')
+                                 border_mode, dim_ordering, pool_mode='avg')
-    def test_meanpooling_1d(self):
+    def test_averagepooling_1d(self):
-                                               border_mode='valid')
+            layer = convolutional.AveragePooling1D(stride=stride,
-    def test_meanpooling_2d(self):
+    def test_averagepooling_2d(self):
-                                               pool_size=pool_size)
+            layer = convolutional.AveragePooling2D(strides=strides,
-def test_MeanPooling1D(self):
+def test_AveragePooling1D(self):
-                                          border_mode='valid')
+                    layer = AveragePooling1D(pool_length=pool_length,
-def test_MeanPooling2D(self):
+def test_AveragePooling2D(self):
-                                          dim_ordering='th')
+                    layer = AveragePooling2D(pool_size=pool_size,
-                                          dim_ordering='tf')
+                    layer = AveragePooling2D(pool_size=pool_size,
-                "rho": float(K.get_value(self.rho)),
+                "rho": self.rho,
-                    info += ' - %s: %.4f' % (k, self.sum_values[k][0] / max(1, self.sum_values[k][1]))
+                    avg = self.sum_values[k][0] / max(1, self.sum_values[k][1])
-                    info += ' - %s: %s' % (k, self.sum_values[k])
+                    info += ' %s' % self.sum_values[k]
-                    info += ' - %s: %.4f' % (k, self.sum_values[k][0] / max(1, self.sum_values[k][1]))
+                    info += ' - %s:' % k
-              dim_ordering='th', pool_mode='sum'):
+           dim_ordering='th', pool_mode='max'):
-        pool_out = downsample.max_pool_2d(x,ds=pool_size,st=strides,ignore_border=ignore_border,padding=padding, mode='average_exc_pad')
+        pool_out = downsample.max_pool_2d(x, ds=pool_size, st=strides,
-        pool_out = reshape(pool_out, (x.shape[0], x.shape[1], (x.shape[2]-pool_size[0])/strides[0]+1, (x.shape[3]-pool_size[1])/strides[1]+1))
+        pool_out = downsample.max_pool_2d(x, ds=pool_size, st=strides,
-        pool_out = reshape(pool_out, (x.shape[0], x.shape[1], (x.shape[2]-pool_size[0])/strides[0]+1, (x.shape[3]-pool_size[1])/strides[1]+1))
+        pool_out = downsample.max_pool_2d(x, ds=pool_size, st=strides,
-                             dim_ordering='th')
+                                       strides=self.st,
-                border_mode, dim_ordering, pool_mode='max')
+                                 border_mode, dim_ordering, pool_mode='max')
-                border_mode, dim_ordering, pool_mode='mean')
+                                 border_mode, dim_ordering, pool_mode='mean')
-                dim_ordering='th')
+                                       strides=self.strides,
-                             border_mode, dim_ordering, pool_mode='max')
+                                 border_mode, dim_ordering, pool_mode='max')
-                             border_mode, dim_ordering, pool_mode='max')
+                                 border_mode, dim_ordering, pool_mode='mean')
-                border_mode=self.border_mode, dim_ordering='th', pool_mode='max')
+        output = back_end.pool2d(inputs, pool_size, strides,
-                border_mode=self.border_mode, dim_ordering='th', pool_mode='mean')
+        output = back_end.pool2d(inputs, pool_size, strides,
-                             dim_ordering=self.dim_ordering, pool_mode='max')
+        output = back_end.pool2d(inputs, pool_size, strides,
-                             dim_ordering=self.dim_ordering, pool_mode='mean')
+        output = back_end.pool2d(inputs, pool_size, strides,
-            raise Exception('Invalid pooling mode: ' + str(pool_mode)
+            raise Exception('Invalid pooling mode: ' + str(pool_mode))
-            raise Exception('Invalid pooling mode: ' + str(pool_mode)
+            raise Exception('Invalid pooling mode: ' + str(pool_mode))
-    #    pool_out = images2neibs(x,neib_shape=pool_size,neib_step=strides, mode='ignore_borders').sum(axis=-1)
+        pool_out = reshape(pool_out, (x.shape[0], x.shape[1], (x.shape[2]-pool_size[0])/strides[0]+1, (x.shape[3]-pool_size[1])/strides[1]+1))
-class TestConfigParams(unittest.TestCase):
+class TestBuildConfigParams(unittest.TestCase):
-    Test the constructor, config and params functions of all layers in core.
+    Test the constructor, build, config and params functions of all layers in core.
-        layer = core.MaxoutDense(10, 10)
+        layer = core.MaxoutDense(10, 10, input_shape=(20,))
-                dim_ordering='th')
+        output = back_end.pool2d(inputs, pool_size=self.pool_size, strides=self.st,
-        output = back_end.maxpool2d(inputs, pool_size=self.pool_size,
+        output = back_end.pool2d(inputs, pool_size=self.pool_size,
-                             dim_ordering=self.dim_ordering)
+                             dim_ordering=self.dim_ordering, pool_mode='mean')
-    #     '''maxpool2d works "properly" with Theano and TF but outputs different
+    # def test_pool2d(self):
-    #     check_single_tensor_operation('maxpool2d', (5, 3, 10, 12), pool_size=(2, 2),
+    #     check_single_tensor_operation('pool2d', (5, 3, 10, 12), pool_size=(2, 2),
-    #     check_single_tensor_operation('maxpool2d', (5, 3, 9, 11), pool_size=(2, 2),
+    #     check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 2),
-    #     check_single_tensor_operation('maxpool2d', (5, 3, 9, 11), pool_size=(2, 3),
+    #     check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 3),
-              dim_ordering='th'):
+def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',
-                                      mode='average_exc_pad')
+    if pool_mode == 'max':
-              border_mode='valid', dim_ordering='th'):
+def pool2d(x, pool_size, strides=(1, 1),
-        x = tf.nn.max_pool(x, pool_size, strides, padding=padding)
+        if pool_mode=='max':
-        x = tf.nn.max_pool(x, pool_size, strides, padding=padding)
+        if pool_mode=='max':
-batch_size = 64
+batch_size = 32
-test_samples = 1000
+train_samples = 2000
-            X[i] = np.random.normal(loc=y[i], scale=1.0, size=input_shape)
+            X[i] = np.random.normal(loc=y[i], scale=0.7, size=input_shape)
-            y[i] = np.random.normal(loc=y_loc[i], scale=1.0, size=output_shape)
+            X[i] = np.random.normal(loc=y_loc[i], scale=0.7, size=input_shape)
-    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000,
+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,
-                                                         input_shape=(10,),
+                                                         input_shape=(20,),
-    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000,
+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,
-                                                         input_shape=(10,),
+                                                         input_shape=(20,),
-    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16,
+    history = model.fit(X_train, y_train, nb_epoch=20, batch_size=16,
-    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000,
+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,
-    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16,
+    history = model.fit(X_train, y_train, nb_epoch=20, batch_size=16,
-    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000,
+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,
-    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16,
+    history = model.fit(X_train, y_train, nb_epoch=20, batch_size=16,
-    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000,
+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,
-    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16,
+    history = model.fit(X_train, y_train, nb_epoch=20, batch_size=16,
-    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000,
+    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,
-    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16,
+    history = model.fit(X_train, y_train, nb_epoch=20, batch_size=16,
-        assert_allclose(tf_state, th_state, atol=1e-05)
+        assert_allclose(tf_last_output, th_last_output, atol=1e-04)
-import unittest
+import pytest
-        (X_train, y_train), (X_test, y_test) = imdb.load_data()
+def test_cifar():
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-        self.W1 = np.array([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]], dtype='float32')
+X1 = np.array([[1], [2]], dtype='int32')
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-        self.assertEqual(n, graph.count_params())
+def test_1o_1i():
-    unittest.main()
+    pytest.main([__file__])
-        print(out)
+def test_masking():
-    unittest.main()
+    pytest.main([__file__])
-
+import pytest
-np.random.seed(1336)  # for reproducibility
+np.random.seed(1337)
-nb_epoch = 10
+nb_epoch = 15
-            self.assertTrue(score < standard_score)
+def test_sequential():
-    unittest.main()
+    pytest.main([__file__])
-np.random.seed(1337)
+import pytest
-                                                     classification=True, nb_class=2)
+(X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000,
-    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
+    history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16,
-        self.assertTrue(_test_optimizer(sgd))
+def test_sgd():
-        self.assertTrue(_test_optimizer(Adagrad()))
+def test_rmsprop():
-        self.assertTrue(_test_optimizer(Adam()))
+def test_adagrad():
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-    model.add(Dense(10, W_regularizer=weight_reg, activity_regularizer=activity_reg))
+    model.add(Dense(10, W_regularizer=weight_reg,
-            model.evaluate(X_test[test_ids, :], Y_test[test_ids, :], verbose=0)
+def test_W_reg():
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-        self.assertEqual(n, model.count_params())
+
-    unittest.main()
+    pytest.main([__file__])
-import unittest
+import pytest
-        check_layer_output_shape(layer, input_data)
+    assert output.shape[1:] == expected_output_shape
-    unittest.main()
+    pytest.main([__file__])
-from keras.layers.core import Dense, Activation, TimeDistributedDense, Flatten
+from keras.layers.core import Dense, TimeDistributedDense, Flatten
-    model.add(GRU(y_train.shape[-1], input_shape=(X_train.shape[1], X_train.shape[2]), activation='softmax'))
+    model.add(GRU(y_train.shape[-1],
-    model.add(GRU(y_train.shape[-1], input_shape=(X_train.shape[1], X_train.shape[2])))
+    model.add(GRU(y_train.shape[-1],
-    model.add(TimeDistributedDense(y_train.shape[-1], input_shape=(X_train.shape[1], X_train.shape[2])))
+    model.add(TimeDistributedDense(y_train.shape[-1],
-            progbar.add(X_batch.shape[0], values=[("train loss", loss)])
+            progbar.add(X_batch.shape[0], values=[("train loss", loss[0])])
-            progbar.add(X_batch.shape[0], values=[("test loss", score)])
+            progbar.add(X_batch.shape[0], values=[("test loss", score[0])])
-        W = np.asarray(K.eval(layer.W))
+        W = np.asarray(K.eval(layer.W)).astype(K.floatx())
-        x = np.random.randn(nb_samples, input_dim).astype(K.floatx())
+        x = np.ones((nb_samples, input_dim)).astype(K.floatx())
-        assert_allclose(np.dot(x, W), y)
+        t = np.dot(x, W).astype(K.floatx())
-        x = np.random.randn(nb_samples, input_dim).astype(K.floatx())
+        x = np.ones((nb_samples, input_dim)).astype(K.floatx())
-        y = F([x])[0]
+        y = F([x])[0].astype(K.floatx())
-        y1 = F([x])[0]
+        y1 = F([x])[0].astype(K.floatx())
-        # temporally substitute input of first layer
+        # set temporary input to first layer
-        # temporally substitute input
+        # set temporary input
-"""Test seya.layers.recurrent module"""
+"""Test keras.layers.core.Layer.__call__"""
-        x = np.random.randn(nb_samples, input_dim).astype(floatX)
+        x = np.random.randn(nb_samples, input_dim).astype(K.floatx())
-        x = np.random.randn(nb_samples, input_dim).astype(floatX)
+        x = np.random.randn(nb_samples, input_dim).astype(K.floatx())
-def test_vector_clf():
+def test_vector_classification():
-    model.add(Activation('softmax'))
+    model = Sequential([
-def test_vector_reg():
+def test_vector_regression():
-    model.add(Dense(y_train.shape[-1]))
+    model = Sequential([
-def test_temporal_clf():
+def test_temporal_classification():
-    model.add(Activation('softmax'))
+    model.add(GRU(y_train.shape[-1], input_shape=(X_train.shape[1], X_train.shape[2]), activation='softmax'))
-def test_temporal_reg():
+def test_temporal_regression():
-def test_seq_to_seq():
+def test_sequence_to_sequence():
-def test_img_clf():
+def test_image_classification():
-    model.add(Activation('softmax'))
+    model = Sequential([
-np.random.seed(1337)
+import pytest
-        self.assertTrue(history.history['val_acc'][-1] > 0.9)
+
-    unittest.main()
+    pytest.main([__file__])
-            initial_states = [initial_state for _ in range(len(self.states))]
+            initial_states = self.get_initial_states(X)
-        base_config = super(MaxPooling1D, self).get_config()
+        base_config = super(Pooling1D, self).get_config()
-        base_config = super(MaxPooling2D, self).get_config()
+        base_config = super(Pooling2D, self).get_config()
-                strides=self.st,
+                strides=self.strides,
-        output = K.maxpool2d(X, pool_size=self.pool_size,
+
-    input_ndim = 3
+class Pooling2D(Layer):
-        self.pool_size = (pool_length, 1)
+    def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',
-        return (input_shape[0], length, input_shape[2])
+        if self.dim_ordering == 'th':
-        return K.squeeze(output, 3)  # remove dummy last dimension
+        output = self.pooling_function(back_end=K, inputs=X, pool_size=self.pool_size,
-        base_config = super(MaxPooling1D, self).get_config()
+                  "pool_size": self.pool_size,
-class MaxPooling1D(Layer):
+class Pooling1D(Layer):
-from keras.layers.core import Layer, Dense
+from keras.layers.core import Dense
-        layer = Layer()
+        nb_samples, input_dim, output_dim = 3, 10, 5
-        F = K.function([X], Y)
+        F = K.function([X], [Y])
-        assert_allclose(x, y)
+        y = F([x])[0]
-        F = K.function([X], Y)
+        F = K.function([X], [Y])
-        y1 = F([x, ])
+        y1 = F([x])[0]
-    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K._EPSILON, np.inf))
+    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K.epsilon(), np.inf))
-    second_log = K.log(K.clip(y_true, K._EPSILON, np.inf) + 1.)
+    first_log = K.log(K.clip(y_pred, K.epsilon(), np.inf) + 1.)
-    return K.mean(y_pred - y_true * K.log(y_pred + K._EPSILON), axis=-1)
+    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)
-        F = theano.function([X], Y)
+        F = K.function([X], Y)
-        y = F(x)
+        y = F([x, ])
-        F = theano.function([X], Y)
+        F = K.function([X], Y)
-        y1 = F(x)
+        y1 = F([x, ])
-from ..layers.core import Layer, Merge, Siamese, SiameseHead, Pass
+from ..layers.core import Layer, Merge, Siamese, SiameseHead
-                self.layers[0].input = tmp
+    def __call__(self, X, train=False):
-                self.input = tmp
+    def __call__(self, X, train=False):
-        elif type(output_shape) in {tuple, list} :
+        elif type(output_shape) in {tuple, list}:
-        """Test keras.layers.Layer.__call__"""
+        """Test keras.layers.core.Layer.__call__"""
-        """Test keras.layers.Layer.__call__"""
+        """Test keras.models.Sequential.__call__"""
-            self.layers[0].previous = tmp2
+            tmp = self.layers[0].previous
-                raise Eception("Invalid merge mode")
+                raise Exception("Invalid merge mode")
-        model.save_weights('test_sequential_temp.h5', overwrite=True)
+        fname = 'test_sequential_temp.h5'
-        model.load_weights('test_sequential_temp.h5')
+        model.load_weights(fname)
-        model.save_weights('test_merge_sum_temp.h5', overwrite=True)
+        fname = 'test_merge_sum_temp.h5'
-        model.load_weights('test_merge_sum_temp.h5')
+        model.load_weights(fname)
-        model.save_weights('test_merge_concat_temp.h5', overwrite=True)
+        fname = 'test_merge_concat_temp.h5'
-        model.load_weights('test_merge_concat_temp.h5')
+        model.load_weights(fname)
-        model.load_weights('test_merge_recursivity_temp.h5')
+        fname = 'test_merge_recursivity_temp.h5'
-        model.load_weights('test_merge_overlap_temp.h5')
+        fname = 'test_merge_overlap_temp.h5'
-        model.save_weights('test_lambda_temp.h5', overwrite=True)
+        fname = 'test_lambda_temp.h5'
-        model.load_weights('test_lambda_temp.h5')
+        model.load_weights(fname)
-                        border_mode='same',
+                        border_mode='valid',
-def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th'):
+def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',
-def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th'):
+def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',
-                                      subsample=strides)
+                                      subsample=strides,
-                            border_mode=self.border_mode, dim_ordering='th')
+                            border_mode=self.border_mode,
-                            dim_ordering=self.dim_ordering)
+                            dim_ordering=self.dim_ordering,
-    floatx = floatx.encode('ascii')
+    floatx = str(floatx)
-    floatx = floatx.encode('ascii')
+    floatx = str(floatx)
-        floatx = floatx.encode('ascii')
+    floatx = floatx.encode('ascii')
-class Pass:
+class Pass(object):
-        floatx = floatx.encode('ascii')
+    floatx = floatx.encode('ascii')
-from ..layers.core import Layer, Merge, Siamese, SiameseHead
+from ..layers.core import Layer, Merge, Siamese, SiameseHead, Pass
-    json.dump(_config, open(_config_path, 'w'))
+    with open(_config_path, 'w') as f:
-    raise Exception('Unknown backend: ' + str(backend))
+    raise Exception('Unknown backend: ' + str(_BACKEND))
-        graph.save_weights('temp.h5', overwrite=True)
+        graph.save_weights('test_2o_1i_weights_temp.h5', overwrite=True)
-        graph.load_weights('temp.h5')
+        graph.load_weights('test_2o_1i_weights_temp.h5')
-        model.save_weights('temp.h5', overwrite=True)
+        model.save_weights('test_sequential_temp.h5', overwrite=True)
-        model.load_weights('temp.h5')
+        model.load_weights('test_sequential_temp.h5')
-        model.save_weights('temp.h5', overwrite=True)
+        model.save_weights('test_merge_sum_temp.h5', overwrite=True)
-        model.load_weights('temp.h5')
+        model.load_weights('test_merge_sum_temp.h5')
-        model.save_weights('temp.h5', overwrite=True)
+        model.save_weights('test_merge_concat_temp.h5', overwrite=True)
-        model.load_weights('temp.h5')
+        model.load_weights('test_merge_concat_temp.h5')
-        model.load_weights('temp.h5')
+        model.save_weights('test_merge_recursivity_temp.h5', overwrite=True)
-        model.load_weights('temp.h5')
+        model.save_weights('test_merge_overlap_temp.h5', overwrite=True)
-        model.save_weights('temp.h5', overwrite=True)
+        model.save_weights('test_lambda_temp.h5', overwrite=True)
-        model.load_weights('temp.h5')
+        model.load_weights('test_lambda_temp.h5')
-            self.states = [K.zeros(input_shape[0], self.output_dim)]
+            self.states = [K.zeros((input_shape[0], self.output_dim))]
-                           K.zeros(input_shape[0], self.output_dim)]
+            self.states = [K.zeros((input_shape[0], self.output_dim)),
-            self.states = [K.zeros(input_shape[0], self.output_dim)]
+            self.states = [K.zeros((input_shape[0], self.output_dim))]
-__version__ = '0.2.0'
+__version__ = '0.3.0'
-            pad_y = (kernel.shape[3] - strides[1]) // 2
+            np_kernel = kernel.eval()
-                                'first dimension.')
+                                'has a "batch_input_shape" argument ' +
-    def add_input(self, name, input_shape, dtype='float'):
+    def add_input(self, name, input_shape=None, batch_input_shape=None, dtype='float'):
-        layer.set_input_shape(input_shape)
+        if input_shape:
-            assert kwarg in {'input_shape', 'trainable'}, "Keyword argument not understood: " + kwarg
+            assert kwarg in allowed_kwargs, "Keyword argument not understood: " + kwarg
-            self.set_input_shape(kwargs['input_shape'])
+            self.set_input_shape((None,) + tuple(kwargs['input_shape']))
-        input_shape = (None,) + tuple(input_shape)
+        input_shape = tuple(input_shape)
-        self.input = K.placeholder(shape=(None, self.input_length),
+        self.input = K.placeholder(shape=(self.input_shape[0], self.input_length),
-    assert_allclose(zth, ztf, atol=1e-06)
+    assert_allclose(zth, ztf, atol=1e-05)
-    assert_allclose(zth, ztf, atol=1e-06)
+    assert_allclose(zth, ztf, atol=1e-05)
-        assert_allclose(zth, ztf, atol=1e-06)
+        assert_allclose(zth, ztf, atol=1e-05)
-        assert_allclose(valth, valtf, atol=1e-06)
+        assert_allclose(valth, valtf, atol=1e-05)
-        assert_allclose(valth, valtf, atol=1e-06)
+        assert_allclose(valth, valtf, atol=1e-05)
-        assert_allclose(zth, ztf, atol=1e-06)
+        assert_allclose(zth, ztf, atol=1e-05)
-        assert_allclose(function_outputs_th, function_outputs_tf, atol=1e-06)
+        assert_allclose(function_outputs_th, function_outputs_tf, atol=1e-05)
-        assert_allclose(new_val_th, new_val_tf, atol=1e-06)
+        assert_allclose(new_val_th, new_val_tf, atol=1e-05)
-        assert_allclose(tf_state, th_state, atol=1e-06)
+        assert_allclose(tf_last_output, th_last_output, atol=1e-05)
-        assert_allclose(zth, ztf, atol=1e-06)
+        assert_allclose(zth, ztf, atol=1e-05)
-    layer.set_input_shape(input_data.shape[1:])
+    layer.set_input_shape(input_data.shape)
-      version='0.2.0',
+      version='0.3.0',
-      download_url='https://github.com/fchollet/keras/tarball/0.2.0',
+      download_url='https://github.com/fchollet/keras/tarball/0.3.0',
-    to 1687500 steps in the original paper.)
+    Reaches 0.93 train/test accuracy after 900 epochs
-                    input_shape=(None, 1)))
+                    activation='relu', input_shape=X_train.shape[1:]))
-model.add(LSTM(hidden_units, input_shape=(None, 1)))
+model.add(LSTM(hidden_units, input_shape=X_train.shape[1:]))
-+ One layer JZS1 (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs
++ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs
-+ One layer JZS1 (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs
++ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs
-+ One layer JZS1 (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs
++ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs
-+ One layer JZS1 (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs
++ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs
-RNN = recurrent.JZS1
+# Try replacing GRU, or SimpleRNN
-model.add(RNN(HIDDEN_SIZE, input_shape=(None, len(chars))))
+model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))
-    return K.softmax(x)
+    ndim = K.ndim(x)
-model.add_input(name='input', input_shape=(1,), dtype=int)
+model.add_input(name='input', input_shape=(maxlen,), dtype=int)
-        input_list = input_list.reverse()
+        input_list.reverse()
-            layer.input = K.placeholder(ndim=ndim, name=name)
+            layer.input = K.placeholder(shape=layer.input_shape, name=name)
-                layer.input = K.placeholder(ndim=2, dtype='int32', name=name)
+            if len(input_shape) == 1:
-                 mask_zero=False, weights=None, **kwargs):
+    def __init__(self, input_dim, output_dim,
-@pytest.mark.skipif(sys.version_info < (2, 7), reason="Requires Python 2.7")
+@pytest.mark.skipif(sys.version_info.major != 2, reason="Requires Python 2.7")
-from keras.backend import tensorflow_backend as KTF
+if sys.version_info.major == 2:
-import tarfile, inspect, os
+import tarfile
-    raise Exception('URL fetch failure on {}: {} -- {}'.format(url, errcode, errmsg))
+    def http_error_default(self, url, fp, errcode, errmsg, headers):
-    except:
+    if not os.path.exists(fpath):
-        return ((X + abs(X)) / 2.0) + self.alpha * (T.exp((X - abs(X)) / 2.0) - 1)
+        pos = K.relu(X)
-                 W_constraint=None, b_constraint=None, input_dim=None, input_length=None, **kwargs):
+                 W_constraint=None, b_constraint=None,
-        length = conv_output_length(self.input_shape[1], self.filter_length, self.border_mode, self.subsample[0])
+        length = conv_output_length(self.input_shape[1],
-        self.W_shape = (self.nb_filter, stack_size, self.nb_row, self.nb_col)
+        if self.dim_ordering == 'th':
-        return (input_shape[0], self.nb_filter, rows, cols)
+        if self.dim_ordering == 'th':
-
+        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'
-        rows = conv_output_length(input_shape[2], self.pool_size[0],
+        if self.dim_ordering == 'th':
-        cols = conv_output_length(input_shape[3], self.pool_size[1],
+        cols = conv_output_length(cols, self.pool_size[1],
-        return (input_shape[0], input_shape[1], rows, cols)
+
-class UpSample1D(Layer):
+class UpSampling1D(Layer):
-        super(UpSample1D, self).__init__(**kwargs)
+        super(UpSampling1D, self).__init__(**kwargs)
-        base_config = super(UpSample1D, self).get_config()
+        base_config = super(UpSampling1D, self).get_config()
-class UpSample2D(Layer):
+class UpSampling2D(Layer):
-        super(UpSample2D, self).__init__(**kwargs)
+    def __init__(self, size=(2, 2), dim_ordering='th', **kwargs):
-                self.size[1] * input_shape[3])
+        if self.dim_ordering == 'th':
-        output = K.concatenate([output] * self.size[1], axis=3)
+        if self.dim_ordering == 'th':
-        base_config = super(UpSample2D, self).get_config()
+        base_config = super(UpSampling2D, self).get_config()
-    def __init__(self, padding=(1, 1), **kwargs):
+    def __init__(self, padding=(1, 1), dim_ordering='th', **kwargs):
-                input_shape[3] + 2 * self.padding[1])
+        if self.dim_ordering == 'th':
-        return K.spatial_2d_padding(X, padding=self.padding)
+        return K.spatial_2d_padding(X, padding=self.padding,
-
+            if K._BACKEND == "tensorflow":
-                 stateful=False, **kwargs):
+                 return_sequences=False, go_backwards=False, stateful=False,
-        return h, [h]
+from __future__ import print_function
-_FLOATX = 'float64'
+_FLOATX = 'float32'
-def spatial_2d_padding(x, padding=(1, 1)):
+def spatial_2d_padding(x, padding=(1, 1), dim_ordering='th'):
-               [padding[0], padding[0]], [padding[1], padding[1]]]
+    if dim_ordering == 'th':
-def spatial_2d_padding(x, padding=(1, 1)):
+def spatial_2d_padding(x, padding=(1, 1), dim_ordering='th'):
-               slice(padding[1], input_shape[3] + padding[1]))
+    if dim_ordering == 'th':
-    Get to 0.8330 test accuracy after 3 epochs. 100s/epoch on K520 GPU.
+    Get to 0.835 test accuracy after 2 epochs. 100s/epoch on K520 GPU.
-nb_epoch = 3
+nb_epoch = 2
-# We flatten the output of the conv layer, so that we can add a vanilla dense layer:
+# We flatten the output of the conv layer,
-model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, validation_data=(X_test, y_test))
+model.compile(loss='binary_crossentropy',
-from keras.layers.recurrent import LSTM, GRU
+from keras.layers.recurrent import LSTM
-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,
-model.compile(loss='binary_crossentropy', optimizer='adam', class_mode="binary")
+model.compile(loss='binary_crossentropy',
-score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, show_accuracy=True)
+model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3,
-            y_val = [standardize_y(data[name]) for name in self.output_order]
+            y_val = [standardize_y(validation_data[name]) for name in self.output_order]
-    '''TODO
+def rnn(step_function, inputs, initial_states,
-    pass
+    inputs = tf.transpose(inputs, (1, 0, 2))
-    Wrapper for scan
+def rnn(step_function, inputs, initial_states,
-    pass
+    inputs = inputs.dimshuffle((1, 0, 2))
-        return K.permute_dimensions(output, (1, 0, 2))
+
-import theano.tensor as T
+from .. import backend as K
-from six.moves import range
+from ..layers.core import MaskedLayer
-    def get_output_mask(self, train=None):
+    def __init__(self, weights=None,
-
+    def step(self, x, states):
-            http://deeplearning.net/software/theano/library/scan.html
+    def get_output(self, train=False):
-        return self.activation(x_t + mask_tm1 * T.dot(h_tm1, u))
+        mask = self.get_output_mask(train)
-            go_backwards=self.go_backwards)
+        if self.stateful:
-        return outputs[-1]
+            return outputs
-        base_config = super(SimpleRNN, self).get_config()
+                  "go_backwards": self.go_backwards,
-class SimpleDeepRNN(Recurrent):
+class SimpleRNN(Recurrent):
-        (up to "depth" steps in the past) is fed back to the input:
+        Fully-connected RNN where the output is to fed back to input.
-        output = activation( W.x_t + b + inner_activation(U_1.h_tm1) + inner_activation(U_2.h_tm2) + ... )
+        Takes inputs with shape:
-        Also (probably) not a super useful model.
+        and returns outputs with shape:
-    def __init__(self, output_dim, depth=3,
+    def __init__(self, output_dim,
-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
+                 activation='sigmoid', **kwargs):
-        self.go_backwards = go_backwards
+        super(SimpleRNN, self).__init__(**kwargs)
-        self.params = [self.W] + self.Us + [self.b]
+        self.U = self.inner_init((self.output_dim, self.output_dim))
-        return outputs[-1]
+    def step(self, x, states):
-                  "depth": self.depth,
+        config = {"output_dim": self.output_dim,
-        base_config = super(SimpleDeepRNN, self).get_config()
+                  "activation": self.activation.__name__}
-        (nb_samples, max_sample_length (samples shorter than this are padded with zeros at the end), input_dim)
+        Takes inputs with shape:
-            On the Properties of Neural Machine Translation: EncoderâDecoder Approaches
+            On the Properties of Neural Machine Translation:
-            Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling
+            Empirical Evaluation of Gated Recurrent Neural Networks
-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
+                 **kwargs):
-        self.input = T.tensor3()
+        input_shape = self.input_shape
-        self.b_z = shared_zeros((self.output_dim))
+        self.b_z = K.zeros((self.output_dim,))
-        self.b_r = shared_zeros((self.output_dim))
+        self.b_r = K.zeros((self.output_dim,))
-        ]
+        self.b_h = K.zeros((self.output_dim,))
-        return h_t
+    def step(self, x, states):
-            go_backwards=self.go_backwards)
+        h_tm1 = states[0]
-        return outputs[-1]
+        hh = self.inner_activation(x_h + K.dot(r * h_tm1, self.U_h))
-                  "output_dim": self.output_dim,
+        config = {"output_dim": self.output_dim,
-                  "go_backwards": self.go_backwards}
+                  "inner_activation": self.inner_activation.__name__}
-        (nb_samples, max_sample_length (samples shorter than this are padded with zeros at the end), input_dim)
+        Takes inputs with shape:
-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
+                 init='glorot_uniform', inner_init='orthogonal',
-        self.input = T.tensor3()
+        input_shape = self.input_shape
-        self.b_i = shared_zeros((self.output_dim))
+        self.b_i = K.zeros((self.output_dim))
-        self.b_c = shared_zeros((self.output_dim))
+        self.b_c = K.zeros((self.output_dim))
-        self.b_o = shared_zeros((self.output_dim))
+        self.b_o = K.zeros((self.output_dim))
-        ]
+        self.params = [self.W_i, self.U_i, self.b_i,
-        return h_t, c_t
+    def step(self, x, states):
-            go_backwards=self.go_backwards)
+        x_i = K.dot(x, self.W_i) + self.b_i
-        return outputs[-1]
+        i = self.inner_activation(x_i + K.dot(h_tm1, self.U_i))
-                  "output_dim": self.output_dim,
+        config = {"output_dim": self.output_dim,
-                  "go_backwards": self.go_backwards}
+                  "inner_activation": self.inner_activation.__name__}
-class JZS1(Recurrent):
+class JZS(Recurrent):
-            (nb_samples, max_sample_length, output_dim)
+        Evolved recurrent neural network architectures
-                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
+                 **kwargs):
-        super(JZS1, self).__init__(**kwargs)
+        super(JZS, self).__init__(**kwargs)
-        self.input = T.tensor3()
+        input_shape = self.input_shape
-        self.b_z = shared_zeros((self.output_dim))
+        self.U_z = self.inner_init((self.output_dim, self.output_dim))
-        self.b_r = shared_zeros((self.output_dim))
+        self.b_r = K.zeros((self.output_dim))
-        self.b_h = shared_zeros((self.output_dim))
+        self.b_h = K.zeros((self.output_dim))
-        # P_h used to project X onto different dimension, using sparse random projections
+        # P matrix used to project X onto different dimension,
-            self.Pmat = theano.shared(np.identity(self.output_dim, dtype=theano.config.floatX), name=None)
+            self.P = K.variable(np.identity(self.output_dim))
-            self.Pmat = theano.shared(P, name=None)
+            P = np.random.binomial(1, 0.5, size=(input_dim, self.output_dim))
-        ]
+        self.params = [self.W_z, self.b_z,
-                  "output_dim": self.output_dim,
+        config = {"output_dim": self.output_dim,
-        base_config = super(JZS1, self).get_config()
+                  "inner_activation": self.inner_activation.__name__}
-class JZS2(Recurrent):
+class JZS1(JZS):
-        of models, serving as alternatives to LSTMs and GRUs. See Jozefowicz et al. 2015.
+        Evolved recurrent neural network architectures
-                http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf
+        This corresponds to the `MUT1` architecture described in the paper.
-        self.go_backwards = go_backwards
+    def __init__(self, *args, **kwargs):
-        super(JZS2, self).__init__(**kwargs)
+    def step(self, x, states):
-        self.input = T.tensor3()
+        x_z = K.dot(x, self.W_z) + self.b_z
-        self.b_r = shared_zeros((self.output_dim))
+        z = self.inner_activation(x_z)
-            self.Pmat = theano.shared(P, name=None)
+class JZS2(JZS):
-        ]
+        This corresponds to the `MUT2` architecture described in the paper.
-            del self.initial_weights
+    def step(self, x, states):
-        return h_t
+        x_z = K.dot(x, self.W_z) + self.b_z
-        return dict(list(base_config.items()) + list(config.items()))
+        z = self.inner_activation(x_z + K.dot(h_tm1, self.U_z))
-        of models, serving as alternatives to LSTMs and GRUs. See Jozefowicz et al. 2015.
+        Evolved recurrent neural network architectures
-        return dict(list(base_config.items()) + list(config.items()))
+    def __init__(self, *args, **kwargs):
-        pass
+        # implement a simple RNN
-import theano
+from keras import backend as K
-    function.
+    All the recurrent layers share the same interface,
-        layer.input = theano.shared(value=np.ones((nb_samples, timesteps, input_dim)))
+        layer = layer_class(output_dim, return_sequences=ret_seq,
-            out = layer.get_output(train).eval()
+            out = K.eval(layer.get_output(train))
-        _runner(recurrent.JZS1)
+    # def test_jzs1(self):
-        _runner(recurrent.JZS2)
+    # def test_jzs2(self):
-        _runner(recurrent.JZS3)
+    # def test_jzs3(self):
-            self.layer.layers[0].previous = self.inputs[head]
+        self.set_layer_input(head)
-            self.layer.layers[0].previous = self.inputs[head]
+        self.set_layer_input(head)
-        self.layer.set_previous(self.inputs[head])
+        if hasattr(self.layer, 'previous'):
-from ..layers.core import Layer, Merge
+from ..layers.core import Layer, Merge, Siamese, SiameseHead
-                raise Exception('Unknown identifier: ' + n)
+                raise Exception('Unknown identifier: ' + input)
-                if n.__class__.__name__ = 'Siamese':
+                if n.__class__.__name__ == 'Siamese':
-
+        '''
-                if n.__class__.__name__ == 'Siamese'
+                if n.__class__.__name__ = 'Siamese':
-    
+
-    """LambdaMerge layer for evaluating arbitrary function over multiple inputs
+class Siamese(Layer):
-    None
+    '''Shared layer with multiple inputs
-    Specified by output_shape argument
+    Depends on merge_mode argument
-class Siamese(Layer):
+    layer - The layer to be shared across multiple inputs
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-                        graph.add_edge(pydot.Edge(e, node['name']))
+import itertools
-    return graph
+                    inputlabels = ''
-# and the question vector
+# and the question vector sequence
-# embed the question into a single vector
+# embed the question into a sequence of vectors
-After about 3500 updates, the accuracy becomes jumps from around 50% to >90%.
+
-
+def to_graph(model):
-
+    return graph
-        graph.write_png(to_file)
+def plot(model, to_file='model.png'):
-After 3000 gradients updates, the accuracy becomes >92%.
+After about 3500 updates, the accuracy becomes jumps from around 50% to >90%.
-n_slots = 121
+n_slots = 128
-clipnorm = 10
+clipvalue = 10
-sgd = Adam(lr=lr, clipnorm=clipnorm)
+sgd = Adam(lr=lr, clipvalue=clipvalue)
-sgd = Adam(lr=lr, clipnorm=clipnorm)
+sgd2 = Adam(lr=lr, clipvalue=clipvalue)
-        print("LSTM test acc: {}".format(a))
+        acc2 = test_model(lstm, 'lstm.png')
-Y = ntm.get_full_output()[0:3] # (memory over time, read_vectors, write_vectors)
+Y = ntm.get_full_output()[0:3]  # (memory over time, read_vectors, write_vectors)
-import theano
+from keras import backend as K
-        weights_in = [np.ones((nb_filter, input_dim, filter_length, 1)), np.ones(nb_filter)]
+        weights_in = [np.ones((nb_filter, input_dim, filter_length, 1)),
-                for subsample_length in [1, 3]:
+            for border_mode in ['valid', 'same']:
-                            layer.input = theano.shared(value=input)
+                                    nb_filter, filter_length,
-                                out = layer.get_output(train).eval()
+                                out = K.eval(layer.get_output(train))
-                    layer.get_output(train).eval()
+        for stride in [1, 2]:
-                config = layer.get_config()
+            config = layer.get_config()
-                for subsample in [(1, 1), (2, 3)]:
+            for border_mode in ['valid', 'same']:
-                                layer.input = theano.shared(value=input)
+                                    nb_filter, nb_row, nb_col,
-                                    out = layer.get_output(train).eval()
+                                    out = K.eval(layer.get_output(train))
-                    layer.get_output(train).eval()
+        for strides in [(1, 1), (2, 2)]:
-                config = layer.get_config()
+            config = layer.get_config()
-        layer.input = theano.shared(value=input)
+        layer.input = K.variable(input)
-            out = layer.get_output(train).eval()
+            out = K.eval(layer.get_output(train))
-            layer.input = theano.shared(value=input)
+            layer.input = K.variable(input)
-                assert out.shape[1] == length*nb_steps
+                out = K.eval(layer.get_output(train))
-                layer.input = theano.shared(value=input)
+                layer.input = K.variable(input)
-                    assert out.shape[3] == length_col*input_nb_col
+                    out = K.eval(layer.get_output(train))
-import theano
+from keras import backend as K
-        layer.input = theano.shared(value=input)
+        layer.input = K.variable(input)
-            assert_allclose(layer.get_output(train).eval(), input)
+            assert_allclose(K.eval(layer.get_input(train)), input)
-        layer1.input = theano.shared(value=input)
+        layer1.input = K.variable(input)
-            assert_allclose(layer2.get_output(train).eval(), input)
+            assert_allclose(K.eval(layer2.get_input(train)), input)
-            np.array([[1, 1, 1, 0], [0, 1, 1, 0]])))
+        func = K.function([layer.input], [layer.get_output_mask()])
-            np.array([[1, 1, 1, 0], [1, 1, 1, 1]])))
+        func = K.function([layer.input], [layer.get_output_mask()])
-                     [[1, 5], [5, 0], [0, 0], [0, 0]]])))
+        func = K.function([layer.input], [layer.get_output()])
-    return [0, 0.1, 0.5, 0.9, 1.0]
+    return np.array([[0, 0.1, 0.5, 0.9, 1.0]], dtype=K.floatx())
-            values = np.array(values)
+            m = np.max(values)
-        x = K.placeholder(ndim=1)
+        x = K.placeholder(ndim=2)
-        f = K.function([x], exp)
+        f = K.function([x], [exp])
-        result = f(test_values)
+        result = f([test_values])[0]
-        assert_allclose(result.flatten(), expected)
+        assert_allclose(result, expected, rtol=1e-05)
-        x = K.placeholder(ndim=1)
+        x = K.placeholder(ndim=2)
-        f = K.function([x], exp)
+        f = K.function([x], [exp])
-        result = f(test_values)
+        result = f([test_values])[0]
-        assert_allclose(result.flatten(), test_values)
+        assert_allclose(result, test_values, rtol=1e-05)
-        x = K.placeholder(ndim=1)
+        x = K.placeholder(ndim=2)
-        f = K.function([x], exp)
+        f = K.function([x], [exp])
-        assert_allclose(result.flatten(), expected)
+        result = f([test_values])[0]
-from theano import tensor as T
+from keras import backend as K
-            assert (np.all(normed.eval() < m))
+            normed = norm_instance(K.variable(self.example_array))
-        assert_allclose(x_normed_actual, x_normed_target)
+        x_normed_target = np.array([[0, 0, 0], [1.0, 0, 0],
-        assert (np.all(np.min(normed.eval(), axis=1) == 0.))
+        normed = nonneg_instance(K.variable(self.example_array))
-        normalized = unitnorm_instance(self.example_array)
+        normalized = unitnorm_instance(K.variable(self.example_array))
-        difference = norm_of_normalized - 1.  # in the unit norm constraint, it should be equal to 1.
+        norm_of_normalized = np.sqrt(np.sum(K.eval(normalized)**2, axis=1))
-        self.assertAlmostEqual(largest_difference, 0.)
+        assert np.abs(largest_difference) < 10e-5
-        self.assertRaises(Exception, normalization.BatchNormalization(input_shape=(10, 10), mode=3))
+        self.assertRaises(Exception,
-        assert_allclose(norm_m1.beta.eval(), np.ones(10))
+        assert_allclose(K.eval(norm_m1.gamma), np.ones(10))
-from keras.layers.core import Merge, Dense, Activation, Flatten
+from keras.layers.core import Dense, Activation, Flatten
-from theano import function
+from keras import backend as K
-        lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm(), input_length=1))
+        lookup.add(Embedding(3, 2, weights=[self.W1],
-        lookup.compile(loss='binary_crossentropy', optimizer='sgd', class_mode='binary')
+        lookup.compile(loss='binary_crossentropy', optimizer='sgd',
-        norm = np.linalg.norm(lookup.params[0].get_value(), axis=1)
+        norm = np.linalg.norm(K.get_value(lookup.params[0]), axis=1)
-                                                         classification=False, output_shape=(1,))
+(X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000,
-        graph.add_output(name='output1', inputs=['dense2', 'dense3'], merge_mode='sum')
+        graph.add_output(name='output1',
-        history = graph.fit({'input1': X_train, 'output1': y_train}, nb_epoch=10)
+        history = graph.fit({'input1': X_train, 'output1': y_train},
-        graph.add_node(Dense(4), name='dense4', inputs=['dense1', 'dense3'], merge_mode='sum')
+        graph.add_node(Dense(4), name='dense4', inputs=['dense1', 'dense3'],
-        graph.add_output(name='output1', inputs=['dense2', 'dense4'], merge_mode='sum')
+        graph.add_output(name='output1', inputs=['dense2', 'dense4'],
-        history = graph.fit({'input1': X_train, 'output1': y_train}, nb_epoch=10)
+        history = graph.fit({'input1': X_train, 'output1': y_train},
-        graph.add_output(name='output1', inputs=['dense2', 'dense3'], merge_mode='sum')
+        graph.add_output(name='output1', inputs=['dense2', 'dense3'],
-        history = graph.fit({'input1': X_train, 'input2': X2_train, 'output1': y_train}, nb_epoch=10)
+        history = graph.fit({'input1': X_train, 'input2': X2_train, 'output1': y_train},
-        history = graph.fit({'input1': X_train, 'output1': y_train, 'output2': y2_train}, nb_epoch=10)
+        history = graph.fit({'input1': X_train, 'output1': y_train, 'output2': y2_train},
-        history = graph.fit({'input1': X_train, 'output1': y_train, 'output2': y2_train}, nb_epoch=10,
+        history = graph.fit({'input1': X_train, 'output1': y_train, 'output2': y2_train},
-        graph.add_output(name='output1', inputs=['dense2', 'dense3'], merge_mode='sum')
+        graph.add_output(name='output1', inputs=['dense2', 'dense3'],
-        graph.add_node(Dense(4), name='output1', inputs=['dense2', 'dense3'], merge_mode='sum', create_output=True)
+        graph.add_node(Dense(4), name='output1', inputs=['dense2', 'dense3'],
-        history = graph.fit({'input1': X_train, 'output1': y_train}, nb_epoch=10)
+        history = graph.fit({'input1': X_train, 'output1': y_train},
-        assert loss == 285.
+        history = model.fit(X, 4 * y, nb_epoch=1, batch_size=2, verbose=1)
-        weights[0, 0] = 0
+        # Normally the trailing 1 is added by standardize_weights
-        out2 = K.eval(weighted_loss(X, Y, weights, mask))
+        out = K.eval(weighted_loss(K.variable(X),
-        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch // 3, verbose=0,
+        model.fit(X_train, Y_train, batch_size=batch_size,
-                  class_weight=class_weight, sample_weight=sample_weight, validation_data=(X_train, Y_train, sample_weight))
+        model.fit(X_train, Y_train, batch_size=batch_size,
-        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch // 2, verbose=0,
+        model.fit(X_train, Y_train, batch_size=batch_size,
-                  class_weight=class_weight, sample_weight=sample_weight, validation_split=0.1)
+        model.fit(X_train, Y_train, batch_size=batch_size,
-                         class_weight=class_weight, sample_weight=sample_weight[:32] if sample_weight is not None else None)
+                         class_weight=class_weight,
-              class_weight={'output': class_weight}, sample_weight={'output': sample_weight}, validation_split=0.1)
+    model.fit({'input': X_train, 'output': Y_train},
-                         class_weight={'output': class_weight}, sample_weight={'output': sample_weight[:32] if sample_weight is not None else None})
+                         class_weight={'output': class_weight},
-    score = model.evaluate({'input': X_test[test_ids, :], 'output': Y_test[test_ids, :]}, verbose=0)
+    score = model.evaluate({'input': X_test[test_ids, :],
-from keras.utils.theano_utils import ndim_tensor
+
-    layer.input = ndim_tensor(ndim)
+    layer.input = K.placeholder(ndim=ndim)
-    output = function(input_data)[0]
+    function = K.function([layer.input], [layer.get_output()])
-        for border_mode in ['same', 'full', 'valid']:
+        for border_mode in ['same', 'valid']:
-                                              border_mode=border_mode, subsample_length=subsample_length)
+                        layer = Convolution1D(nb_filter=1,
-        for border_mode in ['same', 'full', 'valid']:
+        for border_mode in ['same', 'valid']:
-                                              border_mode=border_mode, subsample=subsample)
+                        layer = Convolution2D(nb_filter=1, nb_row=nb_row,
-                        layer = MaxPooling1D(pool_length=pool_length, stride=stride, ignore_border=ignore_border)
+                        layer = MaxPooling1D(pool_length=pool_length,
-            for stride in [(1, 1), (2, 2)]:
+            for strides in [(1, 1), (2, 2)]:
-                        layer = MaxPooling2D(pool_size=pool_size, stride=stride, ignore_border=ignore_border)
+                        layer = MaxPooling2D(pool_size=pool_size,
-_FLOATX = 'float32'
+_FLOATX = 'float64'
-    '''
+    if not shape:
-def embedding(reference, indices):
+def gather(reference, indices):
-    if axis is not None:
+    if axis is not None and axis < 0:
-    if axis is not None:
+    if axis is not None and axis < 0:
-    if axis is not None:
+    if axis is not None and axis < 0:
-    if axis is not None:
+    if axis is not None and axis < 0:
-    if axis is not None:
+    if axis is not None and axis < 0:
-    axis = axis % len(x.get_shape())
+    if axis < 0:
-    axis = axis % len(x.get_shape())
+    if axis < 0:
-    axis = axis % len(tensors[0].get_shape())
+    if axis < 0:
-    tf.assign(x, value).op.run(session=_get_session())
+    tf.assign(x, np.asarray(value)).op.run(session=_get_session())
-    x -= alpha * negative_part
+    x -= tf.constant(alpha, dtype=_FLOATX) * negative_part
-def embedding(reference, indices):
+def gather(reference, indices):
-        dim = dim % x.type.ndim + 1
+        if x.type.ndim == 0:
-        return self.function(inputs)
+        return self.function(*inputs)
-        p *= (p >= 0.)
+        p *= K.cast(p >= 0., K.floatx())
-        return p / K.sqrt(K.sum(p**2, axis=-1, keepdims=True))
+        return p / K.sqrt(K.sum(K.square(p), axis=-1, keepdims=True))
-            layer.input = K.placeholder(ndim=ndim)
+            layer.input = K.placeholder(ndim=ndim, name=name)
-                layer.input = K.placeholder(ndim=2, dtype='int32')
+                layer.input = K.placeholder(ndim=2, dtype='int32', name=name)
-
+from .. import backend as K
-    assert border_mode in {'same', 'full', 'valid'}
+    assert border_mode in {'same', 'valid'}
-        if border_mode not in {'valid', 'full', 'same'}:
+        if border_mode not in {'valid', 'same'}:
-        self.b = shared_zeros((self.nb_filter,))
+        self.b = K.zeros((self.nb_filter,))
-        output = T.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)
+        X = K.expand_dims(X, -1)  # add a dimension of the right
-                 border_mode='valid', subsample=(1, 1),
+                 border_mode='valid', subsample=(1, 1), dim_ordering='th',
-        if border_mode not in {'valid', 'full', 'same'}:
+        if border_mode not in {'valid', 'same'}:
-        self.b = shared_zeros((self.nb_filter,))
+        self.b = K.zeros((self.nb_filter,))
-        return self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))
+        conv_out = K.conv2d(X, self.W, strides=self.subsample,
-    def __init__(self, pool_length=2, stride=None, ignore_border=True, **kwargs):
+    def __init__(self, pool_length=2, stride=None,
-        self.input = T.tensor3()
+        self.input = K.placeholder(ndim=3)
-        self.ignore_border = ignore_border
+        self.border_mode = border_mode
-        length = pool_output_length(input_shape[1], self.pool_length, self.ignore_border, self.stride)
+        length = conv_output_length(input_shape[1], self.pool_length,
-        return T.reshape(output, (output.shape[0], output.shape[1], output.shape[2]))
+        X = K.expand_dims(X, -1)   # add dummy last dimension
-                  "ignore_border": self.ignore_border}
+                  "border_mode": self.border_mode}
-    def __init__(self, pool_size=(2, 2), stride=None, ignore_border=True, **kwargs):
+    def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',
-        self.input = T.tensor4()
+        self.input = K.placeholder(ndim=4)
-        self.ignore_border = ignore_border
+        if strides is None:
-        cols = pool_output_length(input_shape[3], self.pool_size[1], self.ignore_border, self.stride[1])
+        rows = conv_output_length(input_shape[2], self.pool_size[0],
-        output = downsample.max_pool_2d(X, ds=self.pool_size, st=self.stride, ignore_border=self.ignore_border)
+        output = K.maxpool2d(X, pool_size=self.pool_size,
-                  "stride": self.stride}
+                  "border_mode": self.border_mode,
-        self.input = T.tensor3()
+        self.input = K.placeholder(ndim=3)
-        output = T.extra_ops.repeat(X, self.length, axis=1)
+        output = K.concatenate([X] * self.length, axis=1)
-        self.input = T.tensor4()
+        self.input = K.placeholder(ndim=4)
-        return (input_shape[0], input_shape[1], self.size[0] * input_shape[2], self.size[1] * input_shape[3])
+        return (input_shape[0], input_shape[1],
-        output = T.extra_ops.repeat(Y, self.size[1], axis=3)
+        output = K.concatenate([X] * self.size[0], axis=2)
-        self.input = T.tensor3()
+        self.input = K.placeholder(ndim=3)
-        return (input_shape[0], input_shape[1] + self.padding * 2, input_shape[2])
+        return (input_shape[0],
-        return T.set_subtensor(output[:, self.padding:X.shape[1] + self.padding, :], X)
+        return K.temporal_padding(X, padding=self.padding)
-    """Zero-padding layer for 1D input (e.g. temporal sequence).
+    """Zero-padding layer for 2D input (e.g. picture).
-    4D tensor with shape (samples, depth, first_axis_to_pad, second_axis_to_pad)
+    4D tensor with shape:
-    4D tensor with shape (samples, depth, first_padded_axis, second_padded_axis)
+    4D tensor with shape:
-        self.input = T.tensor4()
+        self.input = K.placeholder(ndim=4)
-        return T.set_subtensor(output[indices], X)
+        return K.spatial_2d_padding(X, padding=self.padding)
-        self.input = K.placeholder(ndim=len(self._input_shape))
+        self.input = K.placeholder(shape=self._input_shape)
-        return K.reshape(X, new_shape)
+        return K.reshape(X, (-1,) + self.dims)
-        self.input = K.placeholder(ndim=2)
+        self.input = K.placeholder(ndim=3)
-        self.input = K.placeholder(ndim=3)
+        self.input = K.placeholder(ndim=2)
-        self.input = K.placeholder(ndim=2, dtype='int32')
+        self.input = K.placeholder(shape=(None, self.input_length),
-        out = K.embedding(self.W, X)
+        out = K.gather(self.W, X)
-        std = K.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5
+        std = K.mean(K.square(X - m) + self.epsilon, axis=0)
-        extra_channels = K.zeros((b, ch + 2*half_n, r, c))
+        extra_channels = K.zeros((b, ch + 2 * half_n, r, c))
-                                   extra_channels[:, half_n+ch:, :, :]],
+                                   extra_channels[:, half_n + ch:, :, :]],
-            scale += self.alpha * input_sqr[:, i:i+ch, :, :]
+            scale += self.alpha * input_sqr[:, i:i + ch, :, :]
-import warnings, time, copy, pprint
+import warnings
-    batch_count = int(len(index_array)/batch_size)
+    batch_count = int(len(index_array) / batch_size)
-    index_array = index_array[:batch_count*batch_size]
+    last_batch = index_array[batch_count * batch_size:]
-    return [(i*batch_size, min(size, (i+1)*batch_size)) for i in range(0, nb_batch)]
+    nb_batch = int(np.ceil(size / float(batch_size)))
-            	start = start.tolist()
+                start = start.tolist()
-            	start = start.tolist()
+                start = start.tolist()
-            return weighted.sum() / (filtered_mask * filtered_weights).sum()
+        '''To be called only with non-zero weights.
-        return standardize_y(sample_weight)
+        assert len(sample_weight) == len(y)
-        y = np.reshape(y, (-1, yshape[-1]))  # for time-distributed data, collapse time and sample
+        if len(y.shape) > 2:
-        return np.reshape(class_weights, yshape[:-1] + (1,))  # uncollapse initial dimensions
+        weights = np.asarray([class_weight[cls] for cls in y_classes])
-        return np.ones(y.shape[:-1] + (1,))
+        return np.ones((y.shape[0],))
-        which is either created by hand or from to_yaml method of Sequential or Graph
+        which is either created by hand or from to_yaml method
-            model.compile(loss=loss, optimizer=optimizer, class_mode=class_mode, theano_mode=theano_mode)
+            model.compile(loss=loss, optimizer=optimizer,
-
+            model.compile(loss=loss, optimizer=optimizer,
-    def _fit(self, f, ins, out_labels=[], batch_size=128, nb_epoch=100, verbose=1, callbacks=[],
+    def _fit(self, f, ins, out_labels=[], batch_size=128,
-            Abstract fit function for f(*ins). Assume that f returns a list, labelled by out_labels.
+            Abstract fit function for f(ins).
-                except TypeError as err:
+                except TypeError:
-                outs = f(*ins_batch)
+                outs = f(ins_batch)
-                        val_outs = self._test_loop(val_f, val_ins, batch_size=batch_size, verbose=0)
+                        val_outs = self._test_loop(val_f, val_ins,
-            batch_outs = f(*ins_batch)
+            batch_outs = f(ins_batch)
-            batch_outs = f(*ins_batch)
+            batch_outs = f(ins_batch)
-    def compile(self, optimizer, loss, class_mode="categorical", theano_mode=None):
+    def compile(self, optimizer, loss,
-        self.weights = T.ones_like(self.y_train)
+        self.y = K.placeholder(ndim=K.ndim(self.y_train))
-            test_accuracy = T.mean(T.eq(T.argmax(self.y, axis=-1), T.argmax(self.y_test, axis=-1)))
+            train_accuracy = K.mean(K.equal(K.argmax(self.y, axis=-1),
-            test_accuracy = T.mean(T.eq(self.y, T.round(self.y_test)))
+            train_accuracy = K.mean(K.equal(self.y, K.round(self.y_train)))
-        updates = self.optimizer.get_updates(self.params, self.constraints, train_loss)
+        updates = self.optimizer.get_updates(self.params,
-    def train_on_batch(self, X, y, accuracy=False, class_weight=None, sample_weight=None):
+        self._train = K.function(train_ins, [train_loss], updates=updates)
-
+        sample_weight = standardize_weights(y, class_weight=class_weight,
-            return self._train_with_acc(*ins)
+            return self._train_with_acc(ins)
-            return self._train(*ins)
+            return self._train(ins)
-            return self._test_with_acc(*ins)
+            return self._test_with_acc(ins)
-            return self._test(*ins)
+            return self._test(ins)
-        return self._predict(*ins)
+        return self._predict(ins)
-            class_weight=None, sample_weight=None):
+            validation_split=0., validation_data=None, shuffle=True,
-                sample_weight_val = np.ones(y_val.shape[:-1] + (1,))
+                sample_weight_val = standardize_weights(y_val)
-                sample_weight_val = standardize_weights(y_val, sample_weight=sample_weight_val)
+                sample_weight_val = standardize_weights(y_val,
-                sample_weight_val = np.ones(y_val.shape[:-1] + (1,))
+                sample_weight_val = standardize_weights(y_val)
-        return self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,
+        return self._fit(f, ins, out_labels=out_labels,
-    def evaluate(self, X, y, batch_size=128, show_accuracy=False, verbose=1, sample_weight=None):
+    def evaluate(self, X, y, batch_size=128, show_accuracy=False,
-            y = T.zeros_like(y_test)
+            y = K.placeholder(ndim=K.ndim(y_train))
-            weight = T.ones_like(y_test)
+            weight = K.placeholder(ndim=1)
-                                        allow_input_downcast=True, mode=theano_mode)
+        self._train = K.function(train_ins, [train_loss], updates=updates)
-        return self._train(*ins)
+        return self._train(ins)
-        return self._test(*ins)
+        return self._test(ins)
-        return self._predict(*ins)
+        return self._predict(ins)
-            validation_split=0., validation_data=None, shuffle=True, class_weight={}, sample_weight={}):
+            validation_split=0., validation_data=None, shuffle=True,
-    return K.mean(K.square(K.square(y_pred - y_true), axis=-1))
+    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))
-            norm = K.sqrt(sum([K.sum(g ** 2) for g in grads]))
+            norm = K.sqrt(sum([K.sum(K.square(g)) for g in grads]))
-            new_a = self.rho * a + (1 - self.rho) * g ** 2
+            new_a = self.rho * a + (1 - self.rho) * K.square(g)
-            new_a = a + g ** 2  # update accumulator
+            new_a = a + K.square(g)  # update accumulator
-            new_a = self.rho * a + (1 - self.rho) * g ** 2
+            new_a = self.rho * a + (1 - self.rho) * K.square(g)
-            new_d_a = self.rho * d_a + (1 - self.rho) * update ** 2
+            new_d_a = self.rho * d_a + (1 - self.rho) * K.square(update)
-        lr_t = self.lr * K.sqrt(1 - self.beta_2 ** t) / (1 - self.beta_1 ** t)
+        lr_t = self.lr * K.sqrt(1 - K.pow(self.beta_2, t)) / (1 - K.pow(self.beta_1, t))
-            v_t = (self.beta_2 * v) + (1 - self.beta_2) * (g ** 2)
+            v_t = (self.beta_2 * v) + (1 - self.beta_2) * K.square(g)
-                "beta_2": self.beta_2,
+                "beta_1": float(K.get_value(self.beta_1)),
-        loss += K.sum(self.p ** 2) * self.l2
+        loss += K.sum(K.square(self.p)) * self.l2
-        loss += self.l2 * K.sum(K.mean(output ** 2, axis=0))
+        loss += self.l2 * K.sum(K.mean(K.square(output), axis=0))
-model.add(Convolution2D(32, 3, 3, border_mode='full',
+model.add(Convolution2D(32, 3, 3, border_mode='same',
-model.add(Convolution2D(64, 3, 3, border_mode='full'))
+model.add(Convolution2D(64, 3, 3, border_mode='same'))
-                        border_mode='full',
+                        border_mode='same',
-    2 seconds per epoch on a GRID K520 GPU.
+    Get to 98.40% test accuracy after 20 epochs
-model.add(Dense(128, input_shape=(784,)))
+model.add(Dense(512, input_shape=(784,)))
-model.add(Dense(128))
+model.add(Dense(512))
-score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
+model.fit(X_train, Y_train,
-        2- Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9].
+        2- Freeze convolutional layers and fine-tune dense layers
-    Get to 99.8% test accuracy after 5 epochs for the first five digits classifier
+    Get to 99.8% test accuracy after 5 epochs
-    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1,
+    model.fit(X_train, Y_train,
-                  border_mode='full',
+                  border_mode='valid',
-train_model(model, (X_train_lt5, y_train_lt5), (X_test_lt5, y_test_lt5), nb_classes)
+train_model(model,
-train_model(model, (X_train_gte5, y_train_gte5), (X_test_gte5, y_test_gte5), nb_classes)
+train_model(model,
-        super(Lambda, self).__init__()
+    def __init__(self, function, output_shape=None, **kwargs):
-        if self._ouput_shape is None:
+        if self._output_shape is None:
-
+from keras.models import Sequential, Graph
-from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute
+from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute, Lambda, MaskedLambda, LambdaMerge
-        assert round(i, round_to) == round(j, round_to)
+from keras import backend as K
-    test_values = get_standard_values()
+class TestActivations(unittest.TestCase):
-    expected = softmax(test_values)
+    def test_softmax(self):
-    print(str(expected))
+        # Test using a reference implementation of softmax
-    list_assert_equal(result, expected)
+        x = K.placeholder(ndim=1)
-    f = theano.function([x], exp)
+    def test_relu(self):
-    result = f(test_values)
+        assert r(5) == 5
-    list_assert_equal(result, test_values)  # because no negatives in test values
+        x = K.placeholder(ndim=1)
-    test_values = get_standard_values()
+        # because no negatives in test values
-    f = theano.function([x], exp)
+    def test_tanh(self):
-    expected = [math.tanh(v) for v in test_values]
+        x = K.placeholder(ndim=1)
-    '''
+        result = f(test_values)
-    from keras.activations import linear as l
+    def test_linear(self):
-    xs = [1, 5, True, None, 'foo']
+        xs = [1, 5, True, None, 'foo']
-        assert x == l(x)
+if __name__ == '__main__':
-from theano import tensor as T
+from keras import backend as K
-        norm_m0.input = X
+        norm_m0.input = K.variable(X)
-        self.assertAlmostEqual(out.std().eval(), 1.0, places=1)
+        self.assertAlmostEqual(K.eval(K.mean(out)), 0.0, places=1)
-            norm_m1.input = inp
+            norm_m1.input = K.variable(inp)
-            self.assertAlmostEqual(out.mean().eval(), 0.0)
+            self.assertAlmostEqual(K.eval(K.mean(out)), 0.0)
-                self.assertAlmostEqual(out.std().eval(), 1.0, places=2)
+                self.assertAlmostEqual(K.eval(K.std(out)), 1.0, places=2)
-                self.assertAlmostEqual(out.std().eval(), 0.0, places=2)
+                self.assertAlmostEqual(K.eval(K.std(out)), 0.0, places=2)
-            norm_m0.input = inp
+            norm_m0.input = K.variable(inp)
-            norm_m1.input = inp
+            norm_m1.input = K.variable(inp)
-            norm_m1.input = inp
+            norm_m1.input = K.variable(inp)
-            self.assertAlmostEqual(out.mean().eval(), 0.0)
+            self.assertAlmostEqual(K.eval(K.mean(out)), 0.0)
-                self.assertAlmostEqual(out.std().eval(), 1.0, places=2)
+                self.assertAlmostEqual(K.eval(K.std(out)), 1.0, places=2)
-                self.assertAlmostEqual(out.std().eval(), 0.0, places=2)
+                self.assertAlmostEqual(K.eval(K.std(out)), 0.0, places=2)
-        norm = normalization.BatchNormalization(input_shape=(10, 10), mode=1, epsilon=0.1, momentum=0.9)
+        norm = normalization.BatchNormalization(input_shape=(10, 10), mode=1,
-        conf_target = {"input_shape": (10, 10), "name": normalization.BatchNormalization.__name__,
+        conf_target = {"input_shape": (10, 10),
-        norm = normalization.BatchNormalization(input_shape=(10, 10), mode=1, epsilon=0.1)
+        norm = normalization.BatchNormalization(input_shape=(10, 10), mode=1,
-import theano
+from keras import backend as K
-        weighted_loss = weighted_objective(objectives.get('categorical_crossentropy'))
+        weighted_loss = weighted_objective(objectives.get('mae'))
-        out = weighted_loss(X, Y, weights, mask).eval()
+        out = K.eval(weighted_loss(X, Y, weights, mask))
-        out2 = weighted_loss(X, Y, weights, mask).eval()
+        out2 = K.eval(weighted_loss(X, Y, weights, mask))
-nb_epoch = 8
+nb_epoch = 10
-        for loss in ['mae', 'mse', 'categorical_crossentropy']:
+        for loss in ['mae', 'mse']:
-            model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+            model.compile(loss=loss, optimizer='rmsprop')
-        for loss in ['mae', 'mse', 'categorical_crossentropy']:
+        for loss in ['mae', 'mse']:
-            model.compile(loss={'output': 'categorical_crossentropy'}, optimizer='rmsprop')
+            model.compile(loss={'output': loss}, optimizer='rmsprop')
-            model.compile(loss={'output': 'categorical_crossentropy'}, optimizer='rmsprop')
+            model.compile(loss={'output': loss}, optimizer='rmsprop')
-            model.compile(loss={'output': 'categorical_crossentropy'}, optimizer='rmsprop')
+            model.compile(loss={'output': loss}, optimizer='rmsprop')
-import theano.tensor as T
+from .. import backend as K
-                self.layers[0].input = ndim_tensor(ndim)
+                ndim = len(K.get_shape(l.input))
- 
+
-    
+
-            layer.input = ndim_tensor(ndim)
+            layer.input = K.placeholder(ndim=ndim)
-                layer.input = T.imatrix()
+                layer.input = K.placeholder(ndim=2, dtype='int32')
-            layer.set_name(name)
+                 merge_mode='concat', concat_axis=-1, dot_axes=-1,
-            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis, dot_axes=dot_axes)
+            merge = Merge(to_merge, mode=merge_mode,
-            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis, dot_axes=dot_axes)
+            merge = Merge(to_merge, mode=merge_mode,
-import theano.tensor as T
+from six.moves import zip
-from six.moves import zip
+from ..regularizers import ActivityRegularizer
-        self.input = ndim_tensor(len(self._input_shape))
+        self.input = K.placeholder(ndim=len(self._input_shape))
-            p.set_value(floatX(w))
+            if K.get_value(p).shape != w.shape:
-            weights.append(p.get_value())
+            weights.append(K.get_value(p))
-        return sum([np.prod(p.shape.eval()) for p in self.params])
+        return sum([K.count_params(p) for p in self.params])
-    instead of Layer, and make sure that you incorporate the input mask into your calculation of get_output()
+    If your layer trivially supports masking
-        implementations if, for instance, you are reshaping the input'''
+        ''' The default output mask is just the input mask unchanged.
-        self.input = T.tensor3()
+        self.input = K.placeholder(ndim=3)
-        return T.any(T.ones_like(X) * (1. - T.eq(X, self.mask_value)), axis=-1)
+        return K.any(K.ones_like(X) * (1. - K.equal(X, self.mask_value)),
-        return X * T.shape_padright(T.any((1. - T.eq(X, self.mask_value)), axis=-1))
+        return X * K.any((1. - K.equal(X, self.mask_value)),
-            s = theano.tensor.mean(X, axis=1)
+            s = K.mean(X, axis=1)
-            s = theano.tensor.sum(X, axis=1)
+            s = K.sum(X, axis=1)
-            s = theano.tensor.mul(X, axis=1)
+            s = K.prod(X, axis=1)
-            return T.concatenate(inputs, axis=self.concat_axis)
+            return K.concatenate(inputs, axis=self.concat_axis)
-            output, _ = theano.scan(lambda v1, v2: T.dot(v1, v2) / T.sqrt(T.dot(v1, v1) * T.dot(v2, v2)),
+            output, _ = theano.scan(lambda v1, v2: K.dot(v1, v2) / K.sqrt(K.dot(v1, v1) * K.dot(v2, v2)),
-                X *= self.srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX) / retain_prob
+                X = K.dropout(X, level=self.p)
-        return theano.tensor.reshape(X, new_shape)
+        return K.reshape(X, new_shape)
-        return X.dimshuffle((0,) + self.dims)
+        return K.permute_dimensions(X, (0,) + self.dims)
-        return theano.tensor.reshape(X, nshape)
+        return K.flatten(X)
-        return stacked.dimshuffle((1, 0, 2))
+        return K.repeat(X, self.n)
-        self.input = T.matrix()
+        self.input = K.placeholder(ndim=2)
-        self.b = shared_zeros((self.output_dim,))
+        self.b = K.zeros((self.output_dim,))
-        output = self.activation(T.dot(X, self.W) + self.b)
+        output = self.activation(K.dot(X, self.W) + self.b)
-        self.input = T.tensor3()
+        self.input = K.placeholder(ndim=3)
-        self.b = shared_zeros((self.output_dim))
+        self.b = K.zeros((self.output_dim))
-        return output.dimshuffle(1, 0, 2)
+        output = self.activation(K.dot(K.permute_dimensions(X, (1, 0, 2)),
-        self.input = T.matrix()
+        self.input = K.placeholder(ndim=2)
-        self.b = shared_zeros((self.nb_feature, self.output_dim))
+        self.b = K.zeros((self.nb_feature, self.output_dim))
-        output = T.max(T.dot(X, self.W) + self.b, axis=1)
+        output = K.max(K.dot(X, self.W) + self.b, axis=1)
-import theano.tensor as T
+from .. import backend as K
-            Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
+            Batch Normalization: Accelerating Deep Network Training
-                  1 -> samplewise normalization (may sometimes outperform featurewise mode)
+                  1 -> samplewise normalization
-            momentum: momentum term in the computation of a running estimate of the mean and std of the data
+            momentum: momentum term in the computation
-    def __init__(self, epsilon=1e-6, mode=0, momentum=0.9, weights=None, **kwargs):
+    def __init__(self, epsilon=1e-6, mode=0, momentum=0.9,
-        self.input = ndim_tensor(len(input_shape) + 1)
+        self.input = K.placeholder(ndim=len(input_shape) + 1)
-        self.beta = shared_zeros(input_shape)
+        self.beta = K.zeros(input_shape)
-        self.running_std = shared_ones((input_shape))
+        self.running_mean = K.zeros(input_shape)
-        std = T.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5
+        m = K.mean(X, axis=0)
-        self.updates = [(self.running_mean, mean_update), (self.running_std, std_update)]
+        self.updates = [(self.running_mean, mean_update),
-        return super(BatchNormalization, self).get_weights() + [self.running_mean.get_value(), self.running_std.get_value()]
+        super_weights = super(BatchNormalization, self).get_weights()
-        self.running_std.set_value(floatX(weights[-1]))
+        K.set_value(self.running_mean, weights[-2])
-
+            X_normed = ((X - self.running_mean) /
-            std = X.std(axis=-1, keepdims=True)
+            m = K.mean(X, axis=-1, keepdims=True)
-        b, ch, r, c = X.shape
+        b, ch, r, c = K.shape(X)
-        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :], input_sqr)
+        input_sqr = K.square(X)
-from ..layers.recurrent import SimpleRNN, SimpleDeepRNN, GRU, LSTM, JZS1, JZS2, JZS3
+from ..layers.core import *
-    # Insert custom layers into globals so they can be accessed by `get_from_module`.
+    # Insert custom layers into globals so they can
-                else: # not a regularizer of constraint, don't touch it
+                else:
-    return get_from_module(identifier, globals(), 'layer', instantiate=True, kwargs=kwargs)
+    return get_from_module(identifier, globals(), 'layer',
-def mul(x, axis=None, keepdims=False):
+def prod(x, axis=None, keepdims=False):
-    return tf.tile(x, tiling_pattern)
+def repeat(x, n):
-    '''ReLU. 
+    '''ReLU.
-def maxpool2d(x, pool_size, strides=(1, 1), border_mode='valid', dim_ordering='th'):
+def maxpool2d(x, pool_size, strides=(1, 1),
-        # TF uses the last dimension as channel dimension, instead of the 2nd one.
+        # TF uses the last dimension as channel dimension,
-def mul(x, axis=None, keepdims=False):
+def prod(x, axis=None, keepdims=False):
-    return T.mul(x, axis=axis, keepdims=keepdims)
+    return T.prod(x, axis=axis, keepdims=keepdims)
-    return T.extra_ops.repeat(x, n, axis=axis)
+def repeat(x, n):
-def maxpool2d(x, pool_size, strides=(1, 1), border_mode='valid', dim_ordering='th'):
+def maxpool2d(x, pool_size, strides=(1, 1), border_mode='valid',
-batched_tensordot
+tensordot -> soon to be introduced in TF
-            	start = start.tolist()
+                start = start.tolist()
-            	start = start.tolist()
+                start = start.tolist()
-        y = np.reshape(y, (-1, yshape[-1]))  # for time-distributed data, collapse time and sample
+        # for time-distributed data, collapse time and sample
-            sample_weight = [standardize_weights(validation_data[name]) for name in self.output_order]
+            y_val = [standardize_y(data[name]) for name in self.output_order]
-        norms = K.sqrt(K.sum(K.sqr(p), axis=0))
+        norms = K.sqrt(K.sum(K.square(p), axis=0))
-import theano.tensor as T
+from .. import backend as K
-        return T.nnet.relu(X, self.alpha)
+        return K.relu(X, alpha=self.alpha)
-            Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification
+            Delving Deep into Rectifiers: Surpassing Human-Level
-        pos = T.nnet.relu(X)
+        pos = K.relu(X)
-            Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs
+            Inferring Nonlinear Neuronal Computation
-        self.betas = sharedX(self.beta_init * np.ones(input_shape))
+        self.alphas = K.variable(self.alpha_init * np.ones(input_shape))
-        return T.nnet.softplus(self.betas * X) * self.alphas
+        return K.softplus(self.betas * X) * self.alphas
-        return T.switch(abs(X) < self.theta, 0, X)
+        return K.switch(K.abs(X) < self.theta, 0, X)
-        return T.switch(X > self.theta, X, 0)
+        return K.switch(X > self.theta, X, 0)
-import theano.tensor as T
+from .. import backend as K
-        self.input = T.imatrix()
+        self.input = K.placeholder(ndim=2, dtype='int32')
-            return T.ones_like(X) * (1 - T.eq(X, 0))
+            return K.ones_like(X) * (1 - K.equal(X, 0))
-        out = self.W[X]
+        out = K.embedding(self.W, X)
-from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams
+from .. import backend as K
-                                        dtype=theano.config.floatX)
+            return X + K.random_normal(shape=K.shape(X),
-            X *= self.srng.normal(size=X.shape, avg=1.0, std=T.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)
+            # self.p refers to drop probability rather than
-    return tf.placeholder(dtype, shape=shape, name=name)
+def ones_like(x, name=None):
-    x = tf.clip_by_value(x, 0., np.inf)
+    x = tf.clip_by_value(x, tf.cast(0., dtype=_FLOATX),
-    return tf.clip_by_value(x, min_value, max_value)
+    return tf.clip_by_value(x, tf.cast(min_value, dtype=_FLOATX),
-    return tf.maximum(x, y)
+    return tf.minimum(x, y)
-        x = tf.clip_by_value(x, 0., max_value)
+        x = tf.clip_by_value(x, tf.cast(0., dtype=_FLOATX),
-        output = tf.clip_by_value(output, _EPSILON, 1.-_EPSILON)
+        output = tf.clip_by_value(output, tf.cast(_EPSILON, dtype=_FLOATX),
-        output = tf.clip_by_value(output, _EPSILON, 1.-_EPSILON)
+        output = tf.clip_by_value(output, tf.cast(_EPSILON, dtype=_FLOATX),
-    x = tf.clip_by_value(x, 0., 1.)
+    x = tf.clip_by_value(x, tf.cast(0., dtype=_FLOATX),
-    return theano.shared(np.asarray(value, dtype=dtype), name=name)
+    value = np.asarray(value, dtype=dtype)
-        raise Exception('ndim too large: ' + str(ndim))
+def ones_like(x):
-    return T.maximum(x, y)
+    return T.minimum(x, y)
-        self.W_c_read = self.rnn.init((self.output_dim, 3))  # 3 = beta, g, gamma see eq. 5, 7, 9
+        self.W_c_read = self.rnn.init((self.output_dim, 3))  # 3 = beta, g, gamma see eq. 5, 7, 9 in Graves et. al 2014
-        self.b_s_read = shared_zeros((self.shift_range))  # b_s lol! not intentional
+        self.b_s_read = shared_zeros((self.shift_range)) 
-    is the function to do it. Pretty much copy+pasta from Keras
+    """ Update inner RNN controler
-    I confess, I'm actually proud of this hack. I hope you enjoy!
+    """ Generate circulant copies of a vector.
-    everything is done with inner products, everything is differentiable.
+    everything is done with inner products, this operation is differentiable.
-    ----------------------
+    
-    -------------
+    Known issues and TODO:
-        This method is for research and visualization purposes. Use it as
+        This method is for research and visualization purposes. Use it as:
-        if inner_rnn == "lstm" use it as
+        if inner_rnn == "lstm" use it as:
-from seya.sandbox.ntm import NeuralTuringMachine as NTM
+from keras.layers.ntm import NeuralTuringMachine as NTM
-# model4.compile(loss='binary_crossentropy', optimizer=sgd)
+sgd = Adam(lr=lr, clipnorm=clipnorm)
-    loss = trained.train_on_batch(I, V, sample_weight=sw)
+    loss1 = model.train_on_batch(I, V, sample_weight=sw)
-    progbar.add(1, values=[("loss", loss)])
+    progbar.add(1, values=[("NTM", loss1), ("LSTM", loss2)])
-        ACC.append(l)
+        acc1 = test_model(model, 'ntm.png')
-import theano.tensor as T
+from . import backend as K
-    return softmax(x)
+    return K.softmax(x)
-    return T.nnet.softplus(x)
+    return K.softplus(x)
-    return T.nnet.relu(x)
+def relu(x, alpha=0., max_value=None):
-    return T.tanh(x)
+    return K.tanh(x)
-    return T.nnet.sigmoid(x)
+    return K.sigmoid(x)
-    return T.nnet.hard_sigmoid(x)
+    return K.hard_sigmoid(x)
-import time, json, warnings
+import time
-import numpy as np
+from . import backend as K
-        desired = T.clip(norms, 0, self.m)
+        norms = K.sqrt(K.sum(K.sqr(p), axis=0))
-        p *= T.ge(p, 0.)
+        p = K.variable(p)
-        return p / T.sqrt(T.sum(p**2, axis=-1, keepdims=True))
+        return p / K.sqrt(K.sum(p**2, axis=-1, keepdims=True))
-from .utils.theano_utils import sharedX, shared_zeros, shared_ones
+from . import backend as K
-    return sharedX(np.random.uniform(low=-scale, high=scale, size=shape))
+    return K.variable(np.random.uniform(low=-scale, high=scale, size=shape))
-    return sharedX(np.random.randn(*shape) * scale)
+    return K.variable(np.random.randn(*shape) * scale)
-    return sharedX(scale * q[:shape[0], :shape[1]])
+    return K.variable(scale * q[:shape[0], :shape[1]])
-        return sharedX(scale * np.identity(shape[0]))
+        return K.variable(scale * np.identity(shape[0]))
-    return shared_zeros(shape)
+    return K.zeros(shape)
-    return shared_ones(shape)
+    return K.ones(shape)
-    epsilon = 1.0e-7
+from . import backend as K
-    return T.sqr(y_pred - y_true).mean(axis=-1)
+    return K.mean(K.square(y_pred - y_true), axis=-1)
-    return T.sqrt(T.sqr(y_pred - y_true).mean(axis=-1))
+    return K.mean(K.square(K.square(y_pred - y_true), axis=-1))
-    return T.abs_(y_pred - y_true).mean(axis=-1)
+    return K.mean(K.abs(y_pred - y_true), axis=-1)
-    return T.abs_((y_true - y_pred) / T.clip(T.abs_(y_true), epsilon, np.inf)).mean(axis=-1) * 100.
+    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K._EPSILON, np.inf))
-    return T.sqr(T.log(T.clip(y_pred, epsilon, np.inf) + 1.) - T.log(T.clip(y_true, epsilon, np.inf) + 1.)).mean(axis=-1)
+    first_log = K.log(K.clip(y_pred, K._EPSILON, np.inf) + 1.)
-    return T.sqr(T.maximum(1. - y_true * y_pred, 0.)).mean(axis=-1)
+    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)
-    return T.maximum(1. - y_true * y_pred, 0.).mean(axis=-1)
+    return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)
-    return cce
+    return K.mean(K.categorical_crossentropy(y_pred, y_true), axis=-1)
-    return bce
+    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)
-    return T.mean(y_pred - y_true * T.log(y_pred + epsilon), axis=-1)
+    return K.mean(y_pred - y_true * K.log(y_pred + K._EPSILON), axis=-1)
-from .utils.theano_utils import shared_zeros, shared_scalar, floatX
+from . import backend as K
-        g = T.switch(T.ge(n, c), g * c / n, g)
+        g = K.switch(n >= c, g * c / n, g)
-    return p_hat - p + p * T.log(p / p_hat)
+    return p_hat - p + p * K.log(p / p_hat)
-        return [u[0].get_value() for u in self.updates]
+        return [K.get_value(u[0]) for u in self.updates]
-            u[0].set_value(floatX(v))
+            K.set_value(u[0], v)
-
+        grads = K.gradients(loss, params)
-            norm = T.sqrt(sum([T.sum(g ** 2) for g in grads]))
+            norm = K.sqrt(sum([K.sum(g ** 2) for g in grads]))
-
+            grads = [K.clip(g, -self.clipvalue, self.clipvalue) for g in grads]
-    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args, **kwargs):
+    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False,
-        self.decay = shared_scalar(decay)
+        self.iterations = K.variable(0.)
-            m = shared_zeros(p.get_value().shape)  # momentum
+            m = K.variable(np.zeros(K.get_value(p).shape))  # momentum
-                "decay": float(self.decay.get_value()),
+                "lr": float(K.get_value(self.lr)),
-        self.rho = shared_scalar(rho)
+        self.lr = K.variable(lr)
-        accumulators = [shared_zeros(p.get_value().shape) for p in params]
+        accumulators = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
-            new_a = self.rho * a + (1 - self.rho) * g ** 2  # update accumulator
+            # update accumulator
-            new_p = p - self.lr * g / T.sqrt(new_a + self.epsilon)
+            new_p = p - self.lr * g / K.sqrt(new_a + self.epsilon)
-                "rho": float(self.rho.get_value()),
+                "lr": float(K.get_value(self.lr)),
-        self.lr = shared_scalar(lr)
+        self.lr = K.variable(lr)
-        accumulators = [shared_zeros(p.get_value().shape) for p in params]
+        accumulators = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
-            new_p = p - self.lr * g / T.sqrt(new_a + self.epsilon)
+            new_p = p - self.lr * g / K.sqrt(new_a + self.epsilon)
-                "lr": float(self.lr.get_value()),
+                "lr": float(K.get_value(self.lr)),
-        self.lr = shared_scalar(lr)
+        self.lr = K.variable(lr)
-        delta_accumulators = [shared_zeros(p.get_value().shape) for p in params]
+        accumulators = [K.variable(np.zeros(K.get_value(p).shape)) for p in params]
-            new_a = self.rho * a + (1 - self.rho) * g ** 2  # update accumulator
+            # update accumulator
-                                                             self.epsilon)
+            update = g * K.sqrt(d_a + self.epsilon) / K.sqrt(new_a + self.epsilon)
-                "rho": self.rho,
+                "lr": float(K.get_value(self.lr)),
-    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args, **kwargs):
+    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8,
-        self.lr = shared_scalar(lr)
+        self.iterations = K.variable(0)
-        lr_t = self.lr * T.sqrt(1-self.beta_2**t)/(1-self.beta_1**t)
+        lr_t = self.lr * K.sqrt(1 - self.beta_2 ** t) / (1 - self.beta_1 ** t)
-            v = theano.shared(p.get_value() * 0.)  # zero init of velocity
+            # zero init of moment
-            p_t = p - lr_t * m_t / (T.sqrt(v_t) + self.epsilon)
+            v_t = (self.beta_2 * v) + (1 - self.beta_2) * (g ** 2)
-                "lr": float(self.lr.get_value()),
+                "lr": float(K.get_value(self.lr)),
-                           kwargs=kwargs)
+    return get_from_module(identifier, globals(), 'optimizer',
-import theano.tensor as T
+from . import backend as K
-        loss += T.sum(self.p ** 2) * self.l2
+        loss += K.sum(K.abs(self.p)) * self.l1
-        loss += self.l2 * T.sum(T.mean(self.layer.get_output(True) ** 2, axis=0))
+        output = self.layer.get_output(True)
-    return get_from_module(identifier, globals(), 'regularizer', instantiate=True, kwargs=kwargs)
+    return get_from_module(identifier, globals(), 'regularizer',
-    x = tf.clip_by_value(x, _EPSILON, np.inf)
+    x = tf.clip_by_value(x, 0., np.inf)
-    x = T.clip(x, _EPSILON, np.inf)
+    x = T.clip(x, 0., np.inf)
-        output = theano.tensor.extra_ops.repeat(X, self.length, axis=1)
+        output = T.extra_ops.repeat(X, self.length, axis=1)
-        output = theano.tensor.extra_ops.repeat(Y, self.size[1], axis=3)
+        Y = T.extra_ops.repeat(X, self.size[0], axis=2)
-from __future__ import absolute_import, division
+from __future__ import absolute_import
-        if self.mode == 'sum' or self.mode == 'ave':
+        if self.mode == 'ave':
-                s /= X.shape[1]
+        # TODO: use concatenate instead
-from six.moves import range
+
-    
+
-        ):
+    def fit(self, X,
-
+from __future__ import absolute_import
-        if self.return_sequences:
+        if self.return_sequences and self.go_backwards:
-        if self.return_sequences:
+        if self.return_sequences and self.go_backwards:
-        if self.return_sequences:
+        if self.return_sequences and self.go_backwards:
-        if self.return_sequences:
+        if self.return_sequences and self.go_backwards:
-        if self.return_sequences:
+        if self.return_sequences and self.go_backwards:
-        if self.return_sequences:
+        if self.return_sequences and self.go_backwards:
-        if self.return_sequences:
+        if self.return_sequences and self.go_backwards:
-            shape = output_shape_func(self.previous.output_shape[1:])
+            shape = output_shape_func(self.previous.output_shape)
-            return (self.input_shape[0], ) + tuple(shape)
+            return tuple(shape)
-            shape = output_shape_func([shape[1:] for shape in input_shapes])
+            shape = output_shape_func(input_shapes)
-            return (input_shapes[0][0], ) + tuple(shape)
+            return tuple(shape)
- 
+
-    
+
-        if self.mode == 'sum' or self.mode == 'ave':
+        if self.mode == 'ave':
-                s /= X.shape[1]
+from functools import reduce
-def vectorize_stories(data):
+def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):
-        y = np.zeros(vocab_size)
+        y = np.zeros(len(word_idx) + 1)  # let's not forget that index 0 is reserved
-tX, tXq, tY = vectorize_stories(test)
+X, Xq, Y = vectorize_stories(train, word_idx, story_maxlen, query_maxlen)
-def vectorize_stories(data):
+def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):
-        y = np.zeros(vocab_size)
+        y = np.zeros(len(word_idx) + 1)  # let's not forget that index 0 is reserved
-tX, tXq, tY = vectorize_stories(test)
+X, Xq, Y = vectorize_stories(train, word_idx, story_maxlen, query_maxlen)
-        activation = None
+        del func, activation # Make sure that the model has the function code, not just the function name.
- 
+
-            return self.input_shape[0] + self._output_shape
+            return (self.input_shape[0], ) + self._output_shape
-            return self.input_shape[0] + tuple(shape)
+            return (self.input_shape[0], ) + tuple(shape)
-            return input_shapes[0][0] + self._output_shape
+            return (input_shapes[0][0], ) + self._output_shape
-            return input_shapes[0][0] + tuple(shape)
+            return (input_shapes[0][0], ) + tuple(shape)
-    def __init__(self, function, output_shape=None, ndim=2):
+    def __init__(self, function, output_shape=None):
-            return self._output_shape
+            return self.input_shape[0] + self._output_shape
-            shape = output_shape_func(self.previous.output_shape)
+            shape = output_shape_func(self.previous.output_shape[1:])
-            return tuple(shape)
+            return self.input_shape[0] + tuple(shape)
-            return self.layers[0].input_shape
+            return input_shapes[0]
-            return self._output_shape
+            return input_shapes[0][0] + self._output_shape
-            shape = output_shape_func(input_shapes)
+            shape = output_shape_func([shape[1:] for shape in input_shapes])
-            return tuple(shape)
+            return input_shapes[0][0] + tuple(shape)
-          show_accuracy=True)
+          nb_epoch=4)
-    Output after 4 epochs on CPU: ~0.8146 
+    Output after 4 epochs on CPU: ~0.8146
-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)
+(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,
-model.add_node(LSTM(64, go_backwards=True), name='backward', input='embedding' )
+model.add_node(Embedding(max_features, 128, input_length=maxlen),
-model.compile('adam', {'output':'binary_crossentropy'})
+model.compile('adam', {'output': 'binary_crossentropy'})
-acc = accuracy(y_test, np.round(np.array(model.predict({'input':X_test}, batch_size=batch_size)['output'])))
+model.fit({'input': X_train, 'output': y_train},
-model.compile('adam',{'output':'binary_crossentropy'})
+model.compile('adam', {'output':'binary_crossentropy'})
-                  "input_length": self.input_length}
+                  "input_length": self.input_length,
-                  "input_length": self.input_length}
+                  "input_length": self.input_length,
-                  "input_length": self.input_length}
+                  "input_length": self.input_length,
-                  "input_length": self.input_length}
+                  "input_length": self.input_length,
-                  "input_length": self.input_length}
+                  "input_length": self.input_length,
-                  "input_length": self.input_length}
+                  "input_length": self.input_length,
-                  "input_length": self.input_length}
+                  "input_length": self.input_length,
-                 truncate_gradient=-1, return_sequences=False, input_dim=None, input_length=None, **kwargs):
+                 truncate_gradient=-1, return_sequences=False, input_dim=None,
-            truncate_gradient=self.truncate_gradient)
+            truncate_gradient=self.truncate_gradient,
-                 input_dim=None, input_length=None, **kwargs):
+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
-        )
+            truncate_gradient=self.truncate_gradient,
-                 input_dim=None, input_length=None, **kwargs):
+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
-            truncate_gradient=self.truncate_gradient)
+            truncate_gradient=self.truncate_gradient,
-                 input_dim=None, input_length=None, **kwargs):
+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
-            truncate_gradient=self.truncate_gradient)
+            truncate_gradient=self.truncate_gradient,
-                 input_dim=None, input_length=None, **kwargs):
+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
-            truncate_gradient=self.truncate_gradient)
+            truncate_gradient=self.truncate_gradient,
-                 input_dim=None, input_length=None, **kwargs):
+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
-            truncate_gradient=self.truncate_gradient)
+            truncate_gradient=self.truncate_gradient,
-                 input_dim=None, input_length=None, **kwargs):
+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):
-        )
+            truncate_gradient=self.truncate_gradient,
-        self.encoder.previous.output_shape
+        return self.encoder.input_shape
-                if type(dot_axes[0]) not in [list, tuple] or type(dot_axes[1]) not in [list, tuple]:
+                if type(dot_axes[0]) not in [list, tuple, range] or type(dot_axes[1]) not in [list, tuple, range]:
-        
+
-        
+
-        model.add(Merge([left, right], mode='dot', dot_axes=([1],[1])))
+        model.add(Merge([left, right], mode='dot', dot_axes=([1], [1])))
-                raise Exception("Only layers of same output shape can be merged using " + mode + " mode")
+                raise Exception("Only layers of same output shape can be merged using " + mode + " mode. " +
-                        raise Exception(" Dot incompatible layers can not be merged using dot mode")
+                        raise Exception("Dimension incompatibility using dot mode: " +
-            input_shapes = set([list(l.output_shape).pop(concat_axis) for l in layers])
+            input_shapes = set()
-                raise Exception("'concat' mode can only merge layers with matching output shapes except for the concat axis")
+                raise Exception("'concat' mode can only merge layers with matching " +
-            return tuple(shape)
+            dot_axes = []
-            output = output.dimshuffle((0, 'x'))
+            output, _ = theano.scan(lambda v1, v2: T.dot(v1, v2) / T.sqrt(T.dot(v1, v1) * T.dot(v2, v2)),
-from ..layers.core import ActivityRegularization, TimeDistributedDense, AutoEncoder, MaxoutDense
+from ..layers.core import ActivityRegularization, TimeDistributedDense, TimeDistributedMerge, AutoEncoder, MaxoutDense
-            input_shapes = set([list(l.output_shape).pop(concat_axis) for l in layers])
+            input_shapes = set()
-                    inputs[X.name] = self.layers[i].get_output(train)
+                    inputs[X.name] = X
-        self._input_shape = input_shape
+from six.moves import range
-    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in xrange(np.random.randint(1, DIGITS + 1))))
+    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))
-for _ in xrange(LAYERS):
+for _ in range(LAYERS):
-    for i in xrange(10):
+    for i in range(10):
-        self.input_shape = input_shape
+        self._input_shape = input_shape
-        indentified by their index in a vocabulary, into two dense reprensentations
+        identified by their index in a vocabulary, into two dense representations
-            Efficient Estimation of Word reprensentations in Vector Space
+            Efficient Estimation of Word representations in Vector Space
-
+    
-        self.assertTrue(history.history['val_acc'][-1] > 0.9)
+        self.assertTrue(history.history['val_acc'][-1] > 0.8)
-                        dot_axes = [range(dot_axes % n1,n1), range(dot_axes % n2,n2)]
+                        dot_axes = [range(dot_axes % n1, n1), range(dot_axes % n2, n2)]
-                    dot_axes = [range(len(shape1) - dot_axes, len(shape2)), range(1, dot_axes + 1)]
+                        dot_axes = [range(dot_axes % n1,n1), range(dot_axes % n2,n2)]
-                X *= retain_prob
+                X *= self.srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX) / retain_prob
-def model_from_yaml(yaml_string, custom_layers={}):
+def model_from_yaml(yaml_string, custom_objects={}):
-    return model_from_config(config, custom_layers=custom_layers)
+    return model_from_config(config, custom_objects=custom_objects)
-def model_from_json(json_string, custom_layers={}):
+def model_from_json(json_string, custom_objects={}):
-    return model_from_config(config, custom_layers=custom_layers)
+    return model_from_config(config, custom_objects=custom_objects)
-def model_from_config(config, custom_layers={}):
+def model_from_config(config, custom_objects={}):
-    model = container_from_config(config, custom_layers=custom_layers)
+    model = container_from_config(config, custom_objects=custom_objects)
-def container_from_config(original_layer_dict, custom_layers={}):
+def container_from_config(original_layer_dict, custom_objects={}):
-            init_layer = container_from_config(layer, custom_layers=custom_layers)
+            init_layer = container_from_config(layer)
-            init_layer = container_from_config(layer, custom_layers=custom_layers)
+            init_layer = container_from_config(layer)
-                                          custom_layers=custom_layers)
+            layer = container_from_config(layer_dict['nodes'].get(node['name']))
-                                                   custom_layers=custom_layers)}
+        kwargs = {'encoder': container_from_config(layer_dict.get('encoder_config')),
-        base_layer = get_layer(name, layer_dict, custom_layers=custom_layers)
+        base_layer = get_layer(name, layer_dict)
-        globals()[cls_key] = custom_layers[cls_key]
+def get_layer(identifier, kwargs=None):
-            return self.input_shape
+            return self.layers[0].input_shape
-        elif type(output_shape) in {tuple, list}:
+            self._output_shape = None
-        if type(self._output_shape) == tuple:
+        if self._ouput_shape is None:
-            output_shape = input_shape
+            self._output_shape = None
-        if type(self._output_shape) == tuple:
+        if self._output_shape is None:
-            output_shape = input_shape
+            output_shape = self.input_shape
-
+            
-        model.add(Activation('softmax'))
+        model.add(Lambda(activation))
-        model.add(Activation('softmax'))
+        model.add(Lambda(activation))
-            return layers[0].output_shape
+        def output_shape(input_shapes):
-    output_shape - Expected output shape from function. Could be a tuple or a function of input layer
+    function - The function to be evaluated. Takes one argument : output of previous layer
-            shape = output_shape_func(self.previous)
+            shape = output_shape_func(self.previous.output_shape)
-    output_shape - Expected output shape from function. Could be a tuple or a function of list of input layers
+    output_shape - Expected output shape from function. Could be a tuple or a function of list of input shapes
-            shape = output_shape_func(self.layers)
+            input_shapes = [layer.output_shape for layer in self.layers]
-                 merge_mode='concat', concat_axis=-1, create_output=False):
+                 merge_mode='concat', concat_axis=-1, dot_axes=-1, create_output=False):
-            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis)
+            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis, dot_axes=dot_axes)
-                   merge_mode='concat', concat_axis=-1):
+                   merge_mode='concat', concat_axis=-1, dot_axes=-1):
-            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis)
+            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis, dot_axes=dot_axes)
-                                   'concat_axis': concat_axis})
+                                   'concat_axis': concat_axis,
-        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
+        history = model.fit(X_train, y_train, nb_epoch=15, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
-                        dot_axes = len(shape1) - 1
+                        dot_axes = dot_axes % len(shape1)
-                    inputs['input' + str(i)] = self.layers[i].get_output(train)
+                    raise ValueError("merge_mode='join' only works with named inputs")
-import marshal, types
+import marshal
-    def __init__(self, layers, mode='sum', concat_axis=-1, auto_name=False):
+    def __init__(self, layers, mode='sum', concat_axis=-1):
-                        raise ValueError("merge_mode='join' only works with named inputs")
+                    inputs['input' + str(i)] = self.layers[i].get_output(train)
-                  "auto_name": self.auto_name}
+                  "concat_axis": self.concat_axis}
-			return func(self.input)
+
-	pass
+    pass
-class LambdaMerge(Layer):
+    Input shape
-                raise Exception ("output_shape function must return a tuple")
+            if type(shape) not in {list, tuple}:
-        inputs=[layer.get_output(train) for layer in self.layers]
+        inputs = [layer.get_output(train) for layer in self.layers]
-                  "output_shape":self._output_shape
+                  "function": self.function,
-        model.add(Lambda(function=func,output_shape=output_shape))
+        model.add(LambdaMerge([left, right], function=func, output_shape=output_shape))
-    def __init__(self, layers, mode='sum', concat_axis=-1):
+    def __init__(self, layers, mode='sum', concat_axis=-1, dot_axes=-1):
-        if mode not in {'sum', 'mul', 'concat', 'ave', 'join'}:
+        if mode not in {'sum', 'mul', 'concat', 'ave', 'join', 'cos', 'dot'}:
-        if mode in {'sum', 'mul', 'ave'}:
+        if mode in {'sum', 'mul', 'ave', 'cos'}:
-
+        if mode in {'cos', 'dot'}:
-                  "concat_axis": self.concat_axis}
+                  "concat_axis": self.concat_axis,
-            shape = output_shape_func(layers)
+            shape = output_shape_func(self.layers)
-    def __init__(self, layers, function, output_shape=None, ndim=2):
+    def __init__(self, layers, function, output_shape=None):
-class LambdaMerge(Lambda):
+class LambdaMerge(Layer):
-    def __init__(self, layers, function, output_shape=None, ndim=2)
+    def __init__(self, layers, function, output_shape=None, ndim=2):
-from keras.layers.core import Dense, Activation, Merge, Lambda
+from keras.layers.core import Dense, Activation, Merge, Lambda, LambdaMerge
-            return previous.layers[0].output_shape
+        def output_shape(layers):
-        model.add(Lambda(function=func,output_shape=output_shape))
+        model.add(LambdaMerge([left, right], function=func, output_shape=output_shape))
-                  "concat_axis": self.concat_axis}
+                  "concat_axis": self.concat_axis,
-                    if self.auto_name:
+                    if self.auto_name == True:
-
+ 
-                    if auto_name:
+                    if self.auto_name:
-        model.add(Merge([left, right], mode='join'))
+        model.add(Merge([left, right], mode='join', auto_name=True))
-    def __init__(self, layers, mode='sum', concat_axis=-1):
+    def __init__(self, layers, mode='sum', concat_axis=-1, auto_name=False):
-                    raise ValueError("merge_mode='join' only works with named inputs")
+                    if auto_name:
-                    #raise ValueError("merge_mode='join' only works with named inputs")
+                    raise ValueError("merge_mode='join' only works with named inputs")
-			return output_shape_func(self.previous)
+			shape = output_shape_func(self.previous)
-    Specified by output_argument
+	"""Lambda layer for evaluating arbitrary function
-    """
+	Arguments
-                    raise ValueError("merge_mode='join' only works with named inputs")
+                    inputs['input' + str(i)] = self.layers[i].get_output(train)
-    def __init__(self, filepath, monitor='val_loss', verbose=0, save_best_only=False):
+    def __init__(self, filepath, monitor='val_loss', verbose=0, save_best_only=False, mode='auto'):
-        self.best = np.Inf
+        
-                if current < self.best:
+                if self.monitor_op(current, self.best):
-                v.pop('name')
+                vname = v.pop('name')
-                if vname in [x for x, y in inspect.getmembers(regularizers, predicate=inspect.isclass)]:
+                elif vname in [x for x, y in inspect.getmembers(regularizers, predicate=inspect.isclass)]:
-			output_shape = self.previous.output_shape
+			output_shape = input_shape
-                    #raise ValueError("merge_mode='join' only works with named inputs")
+                    raise ValueError("merge_mode='join' only works with named inputs")
-
+        left.set_name('left')
-
+        right.set_name('right')
-	def __init__(self, function, output_shape, ndim=2):
+	def __init__(self, function, output_shape=None, ndim=2):
-		if type(output_shape) in {tuple, list}:
+		if output_shape is None:
-import cPickle
+import pickle
-        model = cPickle.loads(model_str)
+        model_str = pickle.dumps(model)
-
+import cPickle
-          
+        
-
+import sys
-		self.function = marshal.dumps(function.func_code)
+		py3 = sys.version_info[0] == 3
-
+			if py3:
-                    raise ValueError("merge_mode='join' only works with named inputs")
+                    inputs['input' + str(i)] = self.layers[i].get_output(train)	    
-            return previous.previous.output_shape
+            return previous.layers[0].output_shape
-            return layers[0].output_shape
+        def output_shape(previous):
-from keras.layers.core import Dense, Activation, Merge
+from keras.layers.core import Dense, Activation, Merge, Lambda
-
+ 
-		if type(output_shape) in [tuple,list]:
+		if type(output_shape) in {tuple, list}:
-		if hasattr(self,'previous'):
+		if hasattr(self, 'previous'):
-class MaskedLambda(Lambda,MaskedLayer):
+class MaskedLambda(MaskedLayer, Lambda):
-			output_shape_func = marshal.loads.dumps(self._output_shape)
+			output_shape_func = marshal.loads(self._output_shape)
-class Lambda(MaskedLayer):
+class Lambda(Layer):
-		self._output_shape = marshal.dumps(output_shape.func_code)
+			self._output_shape = marshal.dumps(output_shape.func_code)
-      install_requires=['theano', 'pyyaml'],
+      install_requires=['theano', 'pyyaml', 'six'],
-            return (None,)
+        return self.input_shape
-                raise Exception("Only layers with same dimensions across all axes except concat axis can me merged using concat mode")
+                raise Exception("'concat' mode can only merge layers with matching output shapes except for the concat axis")
-            return None 
+            return None
-        
+
-#Embedding
+# Embedding
-maxlen = 100 
+maxlen = 100
-#Convolution
+# Convolution
-#LSTM
+# LSTM
-#Training
+# Training
-Only 2 epoches are done as the dataset is too small.
+Only 2 epochs are needed as the dataset is very small.
-model.add(LSTM(lstm_output_size)) 
+model.add(LSTM(lstm_output_size))
-model.compile(loss='binary_crossentropy', optimizer='adam', class_mode="binary")
+model.compile(loss='binary_crossentropy',
-score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, show_accuracy=True)
+model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,
-    Reach 84.98% accuracy in 2 epoches
+
-    Better results compared to CNN and LSTM examples
+    Train a recurrent convolutional network on the IMDB sentiment classification task.
-embedding_size=128
+embedding_size = 128
-pool_length=2
+pool_length = 2
-lstm_output_size=70
+lstm_output_size = 70
-nb_epoch=2
+nb_epoch = 2
-import warnings
+
-            input_shapes = set([l.output_shape.pop(concat_axis) for l in layers])
+            input_shapes = set([list(l.output_shape).pop(concat_axis) for l in layers])
-            if len(input_shapes)>1:
+            input_shapes = set([l.output_shape for l in layers])
-
+        try:
-        self.updates += updates
+    @property
-        self.nodes = {}  # layer-like
+        self.nodes = OrderedDict()  # layer-like
-
+    @property
-            assert kwarg in {'input_shape'}, "Keyword argument not understood: " + kwarg
+            assert kwarg in {'input_shape', 'trainable'}, "Keyword argument not understood: " + kwarg
-            mode: {'sum', 'mul', 'concat', 'ave'}
+            mode: {'sum', 'mul', 'concat', 'ave', 'join'}
-        if mode not in {'sum', 'mul', 'concat', 'ave'}:
+        if mode not in {'sum', 'mul', 'concat', 'ave', 'join'}:
-                "decay": float(self.decay),
+                "decay": float(self.decay.get_value()),
-from ..layers.normalization import BatchNormalization
+from ..layers.normalization import BatchNormalization, LRN2D
-                "decay": float(self.decay.get_value()),
+                "decay": float(self.decay),
-      version='0.1.2',
+      version='0.2.0',
-      download_url='https://github.com/fchollet/keras/tarball/0.1.2',
+      download_url='https://github.com/fchollet/keras/tarball/0.2.0',
-      extras_require = {
+      extras_require={
-        p *= T.ge(p, 0)
+        p = theano.shared(p)
-from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking
+from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute
-model.add(Embedding(max_features, 128))
+model.add(Embedding(max_features, 128, input_length=maxlen))
-                  "max_lenght": self.max_lenght,
+                  "input_length": self.input_length,
-model.add(Convolution2D(32, 1, 3, 3, border_mode='full')) 
+model.add(Convolution2D(32, 1, 3, 3, border_mode='full'))
-model.add(MaxPooling2D(poolsize=(2, 2)))
+model.add(MaxPooling2D(pool_size=(2, 2)))
-model.add(Convolution2D(64, 32, 3, 3, border_mode='full')) 
+model.add(Convolution2D(64, 32, 3, 3, border_mode='full'))
-model.add(MaxPooling2D(poolsize=(2, 2)))
+model.add(MaxPooling2D(pool_size=(2, 2)))
-left.add(MaxPooling2D(poolsize=(2, 2)))
+left.add(MaxPooling2D(pool_size=(2, 2)))
-                                        filter_shape=self.W_shape)
+                                        subsample=self.subsample)
-                                          subsample=self.subsample)
+                                          subsample=self.subsample,
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        return dict(base_config.items() + config.items())
+        return dict(list(base_config.items()) + list(config.items()))
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5, 10),
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(3, 5),
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5, 10), output_shape=(2,),
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(3, 5), output_shape=(2,),
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5, 10), output_shape=(5, 10),
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(3, 5), output_shape=(3, 5),
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(3, 32, 32),
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(3, 8, 8),
-        model.add(Convolution2D(32, 32, 32, input_shape=(3, 32, 32)))
+        model.add(Convolution2D(8, 8, 8, input_shape=(3, 8, 8)))
-model.add(Embedding(max_features, embedding_dims, max_length=maxlen))
+model.add(Embedding(max_features, embedding_dims, input_length=maxlen))
-                                          subsample=self.subsample)
+                                          subsample=self.subsample,
-                                        subsample=self.subsample)
+                                        subsample=self.subsample,
-model.add(BatchNormalization((512,)))
+model.add(BatchNormalization())
-    def add_input(self, name, ndim=2, dtype='float'):
+    def add_input(self, name, input_shape, dtype='float'):
-        self.input_config.append({'name': name, 'ndim': ndim, 'dtype': dtype})
+        self.input_config.append({'name': name,
-        graph.add_input(name='input1', ndim=2)
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
+        graph.add_node(Dense(16), name='dense1', input='input1')
-        graph.add_input(name='input1', ndim=2)
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
+        graph.add_node(Dense(16), name='dense1', input='input1')
-        graph.add_input(name='input2', ndim=2)
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
+        graph.add_node(Dense(16), name='dense1', input='input1')
-        graph.add_input(name='input1', ndim=2)
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
+        graph.add_node(Dense(16), name='dense1', input='input1')
-        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_input(name='input1', ndim=2)
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
+        graph.add_node(Dense(16), name='dense1', input='input1')
-        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_input(name='input1', ndim=2)
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
+        graph.add_node(Dense(16), name='dense1', input='input1')
-        graph.add_node(Dense(nb_units, input_shape=(nb_units,)),
+        graph.add_input(name='input1', input_shape=(32,))
-        graph.add_node(Dense(nb_classes, input_shape=(nb_units,)),
+        graph.add_node(Dense(nb_classes),
-        n += nb_units * nb_classes + nb_classes
+        n = 32 * nb_units + nb_units
-    model.add_node(Dense(50, activation='relu', input_shape=(784,)), name='d1', input='input')
+    model.add_input(name='input', input_shape=(784,))
-model.add(Embedding(max_features, embedding_dims, max_lenght=maxlen))
+model.add(Embedding(max_features, embedding_dims, max_length=maxlen))
-                "alpha": self.alpha}
+        config = {"name": self.__class__.__name__,
-                "init": self.init.__name__}
+        config = {"name": self.__class__.__name__,
-                "beta_init": self.beta_init}
+        config = {"name": self.__class__.__name__,
-                "theta": self.theta}
+        config = {"name": self.__class__.__name__,
-class ThresholdedReLu(MaskedLayer):
+class ThresholdedReLU(MaskedLayer):
-        super(ThresholdedReLu, self).__init__(**kwargs)
+        super(ThresholdedReLU, self).__init__(**kwargs)
-                "theta": self.theta}
+        config = {"name": self.__class__.__name__,
-                 W_constraint=None, b_constraint=None, **kwargs):
+                 W_constraint=None, b_constraint=None, input_dim=None, input_length=None, **kwargs):
-                "b_constraint": self.b_constraint.get_config() if self.b_constraint else None}
+        config = {"name": self.__class__.__name__,
-                "b_constraint": self.b_constraint.get_config() if self.b_constraint else None}
+        config = {"name": self.__class__.__name__,
-                "ignore_border": self.ignore_border}
+        config = {"name": self.__class__.__name__,
-                "stride": self.stride}
+        config = {"name": self.__class__.__name__,
-                "length": self.length}
+        config = {"name": self.__class__.__name__,
-                "size": self.size}
+        config = {"name": self.__class__.__name__,
-        self.input = T.tensor4()
+        self.input = T.tensor3()
-        return T.set_subtensor(output[:, self.padding:X.shape[1]+self.padding, :], X)
+        input_shape = X.shape
-                "padding": self.padding}
+        config = {"name": self.__class__.__name__,
-        out = T.zeros(out_shape)
+        output_shape = (input_shape[0],
-        return T.set_subtensor(out[indices], X)
+        return T.set_subtensor(output[indices], X)
-                "padding": self.padding}
+        config = {"name": self.__class__.__name__,
-            raise Exception("Cannot connect non-masking layer to layer with masked output")
+        if hasattr(self, 'input_ndim'):
-        assert len(self.params) == len(weights), 'Provided weight array does not match layer weights.'
+        assert len(self.params) == len(weights), 'Provided weight array does not match layer weights (' + \
-        return {"name": self.__class__.__name__}
+        config = {"name": self.__class__.__name__}
-                "mask_value": self.mask_value}
+        config = {"name": self.__class__.__name__,
-                "mode": self.mode}
+        config = {"name": self.__class__.__name__,
-                "concat_axis": self.concat_axis}
+        config = {"name": self.__class__.__name__,
-                "p": self.p}
+        config = {"name": self.__class__.__name__,
-                "beta": self.beta}
+        config = {"name": self.__class__.__name__,
-                "dims": self.dims}
+        config = {"name": self.__class__.__name__,
-                "dims": self.dims}
+        config = {"name": self.__class__.__name__,
-                "n": self.n}
+        config = {"name": self.__class__.__name__,
-                 W_constraint=None, b_constraint=None, **kwargs):
+                 W_constraint=None, b_constraint=None, input_dim=None, **kwargs):
-                "b_constraint": self.b_constraint.get_config() if self.b_constraint else None}
+        config = {"name": self.__class__.__name__,
-                "l2": self.l2}
+        config = {"name": self.__class__.__name__,
-                 W_constraint=None, b_constraint=None, **kwargs):
+                 W_constraint=None, b_constraint=None, input_dim=None, input_length=None, **kwargs):
-        input_dim = self.input_shape[1]
+        input_dim = self.input_shape[2]
-                "b_constraint": self.b_constraint.get_config() if self.b_constraint else None}
+        config = {"name": self.__class__.__name__,
-                 W_constraint=None, b_constraint=None, **kwargs):
+                 W_constraint=None, b_constraint=None, input_dim=None, **kwargs):
-                "b_constraint": self.b_constraint.get_config() if self.b_constraint else None}
+        config = {"name": self.__class__.__name__,
-    def __init__(self, input_dim, output_dim, init='uniform', max_lenght=None,
+    def __init__(self, input_dim, output_dim, init='uniform', input_length=None,
-        self.max_lenght = max_lenght
+        self.input_length = input_length
-        return (self.input_shape[0], self.max_lenght, self.output_dim)
+        return (self.input_shape[0], self.input_length, self.output_dim)
-                "W_constraint": self.W_constraint.get_config() if self.W_constraint else None}
+        config = {"name": self.__class__.__name__,
-                "activation": self.activation.__name__}
+        config = {"name": self.__class__.__name__,
-                "sigma": self.sigma}
+        config = {"name": self.__class__.__name__,
-                "p": self.p}
+        config = {"name": self.__class__.__name__,
-                "momentum": self.momentum}
+        config = {"name": self.__class__.__name__,
-                "n": self.n}
+        config = {"name": self.__class__.__name__,
-                 truncate_gradient=-1, return_sequences=False, **kwargs):
+                 truncate_gradient=-1, return_sequences=False, input_dim=None, input_length=None, **kwargs):
-                "return_sequences": self.return_sequences}
+        config = {"name": self.__class__.__name__,
-                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
+                 weights=None, truncate_gradient=-1, return_sequences=False,
-                "return_sequences": self.return_sequences}
+        config = {"name": self.__class__.__name__,
-                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
+                 weights=None, truncate_gradient=-1, return_sequences=False,
-                "return_sequences": self.return_sequences}
+        config = {"name": self.__class__.__name__,
-                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
+                 weights=None, truncate_gradient=-1, return_sequences=False,
-                "return_sequences": self.return_sequences}
+        config = {"name": self.__class__.__name__,
-                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
+                 weights=None, truncate_gradient=-1, return_sequences=False,
-                "return_sequences": self.return_sequences}
+        config = {"name": self.__class__.__name__,
-                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
+                 weights=None, truncate_gradient=-1, return_sequences=False,
-                "return_sequences": self.return_sequences}
+        config = {"name": self.__class__.__name__,
-                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
+                 weights=None, truncate_gradient=-1, return_sequences=False,
-                "return_sequences": self.return_sequences}
+        config = {"name": self.__class__.__name__,
-                                    input_dim, nb_filter, filter_length, weights=weight,
+                                    nb_filter, filter_length, weights=weight,
-                                    subsample_length=subsample_length)
+                                    subsample_length=subsample_length, input_shape=(None, input_dim))
-                                    nb_filter, stack_size, nb_row, nb_col, weights=weight,
+                                    nb_filter, nb_row, nb_col, weights=weight,
-                                    subsample=subsample)
+                                    subsample=subsample, input_shape=(stack_size, None, None))
-        layer = core.Dense(10, 10)
+        layer = core.Dense(10, input_shape=(10,))
-        layer = core.TimeDistributedDense(10, 10)
+        layer = core.TimeDistributedDense(10, input_shape=(None, 10))
-                mask = layer.get_output_mask(train)
+    for ret_seq in [True, False]:
-    test_values=get_standard_values()
+    test_values = get_standard_values()
-    list_assert_equal(result, test_values) # because no negatives in test values
+    list_assert_equal(result, test_values)  # because no negatives in test values
-        difference = norm_of_normalized - 1. #in the unit norm constraint, it should be equal to 1.
+        difference = norm_of_normalized - 1.  # in the unit norm constraint, it should be equal to 1.
-        norm_m1 = normalization.BatchNormalization((10, 10), mode=1)
+        norm_m0 = normalization.BatchNormalization(input_shape=(10, 10))
-        self.assertRaises(Exception, normalization.BatchNormalization((10, 10), mode=3))
+        self.assertRaises(Exception, normalization.BatchNormalization(input_shape=(10, 10), mode=3))
-        norm_m0 = normalization.BatchNormalization((10,))
+        norm_m0 = normalization.BatchNormalization(input_shape=(10,))
-        norm_m1.init_updates()
+        norm_m1 = normalization.BatchNormalization(input_shape=(10,), mode=1)
-            norm_m0.init_updates()
+            norm_m0 = normalization.BatchNormalization(input_shape=inp.shape, mode=0)
-            norm_m1 = normalization.BatchNormalization(inp.shape, mode=1)
+            norm_m1 = normalization.BatchNormalization(input_shape=inp.shape, mode=1)
-        norm_m1.init_updates()
+        norm_m1 = normalization.BatchNormalization(input_shape=(10,), mode=1,
-        norm = normalization.BatchNormalization((10, 10), mode=1, epsilon=0.1)
+        norm = normalization.BatchNormalization(input_shape=(10, 10), mode=1, epsilon=0.1, momentum=0.9)
-
+                       "epsilon": 0.1, "mode": 1, "momentum": 0.9}
-        norm = normalization.BatchNormalization((10, 10), mode=1, epsilon=0.1)
+        norm = normalization.BatchNormalization(input_shape=(10, 10), mode=1, epsilon=0.1)
-        lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm()))
+        lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm(), input_length=1))
-        lookup.add(Dense(2, 1))
+        lookup.add(Dense(1))
-        graph.add_node(Dense(16, 4), name='dense3', input='dense1')
+        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
-        graph.add_node(Dense(32, 4), name='dense2-0', input='input1')
+        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
-        graph.add_node(Dense(16, 4), name='dense4', inputs=['dense1', 'dense3'], merge_mode='sum')
+        graph.add_node(Dense(16), name='dense3', input='dense2')
-        graph.add_node(Dense(16, 4), name='dense3', input='dense1')
+        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
-        graph.add_node(Dense(16, 1), name='dense3', input='dense1')
+        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
-        graph.add_node(Dense(16, 1), name='dense3', input='dense1')
+        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
-        graph.add_node(Dense(16, 1), name='dense3', input='dense1')
+        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
-        graph.add_node(Dense(16, 4), name='dense3', input='dense1')
+        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
-        seq.add(Dense(32, 32, name='first_seq_dense'))
+        seq.add(Dense(32, input_shape=(32,)))
-        seq.add(Dense(4, 4, name='last_seq_dense'))
+        seq.add(Dense(4))
-        graph.add_node(Dense(4, 4), name='output1', inputs=['dense2', 'dense3'], merge_mode='sum', create_output=True)
+        graph.add_node(Dense(16, input_shape=(32,)), name='dense1', input='input1')
-                name='dense3', input='dense1')
+        graph.add_node(Dense(nb_units, input_shape=(nb_units,)),
-                merge_mode='sum')
+                         merge_mode='sum')
-        model.add(TimeDistributedDense(2, 1, init='one'))
+        model.add(Masking(mask_value=0, input_shape=(None, 2)))
-    model.add(Dense(784, 50))
+    model.add(Dense(50, input_shape=(784,)))
-    model.add(Dense(50, 10))
+    model.add(Dense(10))
-    model.add_node(Dense(50, 10, activation='softmax'), name='d2', input='d1')
+    model.add_node(Dense(50, activation='relu', input_shape=(784,)), name='d1', input='input')
-    model.add(Dense(input_dim, nb_hidden))
+    model.add(Dense(nb_hidden, input_shape=(input_dim,)))
-    model.add(Dense(nb_hidden, output_dim))
+    model.add(Dense(output_dim))
-    model.add(Dense(784, 50))
+    model.add(Dense(50, input_shape=(784,)))
-    model.add(Dense(50, 10, W_regularizer=weight_reg, activity_regularizer=activity_reg))
+    model.add(Dense(10, W_regularizer=weight_reg, activity_regularizer=activity_reg))
-        model.add(Dense(input_dim, nb_hidden))
+        model.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        model.add(Dense(nb_hidden, nb_class))
+        model.add(Dense(nb_class))
-        model.add(Dense(input_dim, nb_hidden))
+        model.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        model.add(Dense(nb_hidden, nb_class))
+        model.add(Dense(nb_class))
-        left.add(Dense(input_dim, nb_hidden))
+        left.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        right.add(Dense(input_dim, nb_hidden))
+        right.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        model.add(Dense(nb_hidden, nb_class))
+        model.add(Dense(nb_class))
-        left.add(Dense(input_dim, nb_hidden))
+        left.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        right.add(Dense(input_dim, nb_hidden))
+        right.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        model.add(Dense(nb_hidden, nb_class))
+        model.add(Dense(nb_class))
-        left.add(Dense(input_dim, nb_hidden))
+        left.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        right.add(Dense(input_dim, nb_hidden))
+        right.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        model.add(Dense(nb_hidden * 2, nb_class))
+        model.add(Dense(nb_class))
-        left.add(Dense(input_dim, nb_hidden))
+        left.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        right.add(Dense(input_dim, nb_hidden))
+        right.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        model.add(Dense(nb_hidden * 2, nb_class))
+        model.add(Dense(nb_class))
-        left.add(Dense(input_dim, nb_hidden))
+        left.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        right.add(Dense(input_dim, nb_hidden))
+        right.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        righter.add(Dense(input_dim, nb_hidden))
+        righter.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        intermediate.add(Dense(nb_hidden, nb_hidden))
+        intermediate.add(Dense(nb_hidden))
-        model.add(Dense(nb_hidden, nb_class))
+        model.add(Dense(nb_class))
-        left.add(Dense(input_dim, nb_hidden))
+        left.add(Dense(nb_hidden, input_shape=(input_dim,)))
-        model.add(Dense(nb_hidden, nb_class))
+        model.add(Dense(nb_class))
-        nb_units = 100
+        input_dim = 20
-        n = nb_units * nb_units + nb_units
+        n = input_dim * nb_units + nb_units
-        model.add(Dense(nb_units, nb_classes))
+        model.add(Dense(nb_units, input_shape=(input_dim,)))
-    expected_output_shape = layer.output_shape
+    layer.set_input_shape(input_data.shape[1:])
-    assert output.shape == expected_output_shape
+    assert output.shape[1:] == expected_output_shape
-        layer = Dense(2, 3)
+        layer = Dense(3)
-        layer = TimeDistributedDense(3, 2)
+        layer = TimeDistributedDense(2)
-                        layer = Convolution1D(input_dim=2, nb_filter=1, filter_length=filter_length,
+                        layer = Convolution1D(nb_filter=1, filter_length=filter_length,
-                        layer = Convolution2D(nb_filter=1, stack_size=1, nb_row=nb_row, nb_col=nb_row,
+                        layer = Convolution2D(nb_filter=1, nb_row=nb_row, nb_col=nb_row,
-        layer = SimpleRNN(3, 2)
+        layer = SimpleRNN(2)
-class TestRegularizers(unittest.TestCase):
+class TestTasks(unittest.TestCase):
-        model.add(Dense(X_train.shape[-1], nb_hidden))
+        model.add(Dense(nb_hidden, input_shape=(X_train.shape[-1],)))
-        model.add(Dense(nb_hidden, y_train.shape[-1]))
+        model.add(Dense(y_train.shape[-1]))
-        model.add(Dense(X_train.shape[-1], nb_hidden))
+        model.add(Dense(nb_hidden, input_shape=(X_train.shape[-1],)))
-        model.add(Dense(nb_hidden, y_train.shape[-1]))
+        model.add(Dense(y_train.shape[-1]))
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5,10), 
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5, 10),
-        model.add(GRU(X_train.shape[-1], y_train.shape[-1]))
+        model.add(GRU(y_train.shape[-1], input_shape=(None, X_train.shape[-1])))
-        model.add(GRU(X_train.shape[-1], y_train.shape[-1]))
+        model.add(GRU(y_train.shape[-1], input_shape=(None, X_train.shape[-1])))
-        model.add(TimeDistributedDense(X_train.shape[-1], y_train.shape[-1]))
+        model.add(TimeDistributedDense(y_train.shape[-1], input_shape=(None, X_train.shape[-1])))
-        model.add(Convolution2D(32, 3, 32, 32))
+        model.add(Convolution2D(32, 32, 32, input_shape=(3, 32, 32)))
-        model.add(Dense(32, y_test.shape[-1]))
+        model.add(Dense(y_test.shape[-1]))
-from keras.layers.core import Activation, Dense, RepeatVector
+from keras.layers.core import Activation, TimeDistributedDense, RepeatVector
-X, y = shuffle(X, y)
+indices = np.arange(len(y))
-model.add(RNN(len(chars), HIDDEN_SIZE))
+# note: in a situation where your input sequences have a variable length,
-    model.add(RNN(HIDDEN_SIZE, HIDDEN_SIZE, return_sequences=True))
+    model.add(RNN(HIDDEN_SIZE, return_sequences=True))
-model.add(Dense(HIDDEN_SIZE, len(chars)))
+model.add(TimeDistributedDense(len(chars)))
-    model.fit(X, y, batch_size=BATCH_SIZE, nb_epoch=1, validation_data=(X_val, y_val), show_accuracy=True)
+    model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=1, validation_data=(X_val, y_val), show_accuracy=True)
-sentrnn.add(RNN(EMBED_HIDDEN_SIZE, SENT_HIDDEN_SIZE, return_sequences=False))
+sentrnn.add(RNN(SENT_HIDDEN_SIZE, return_sequences=False))
-qrnn.add(RNN(EMBED_HIDDEN_SIZE, QUERY_HIDDEN_SIZE, return_sequences=False))
+qrnn.add(RNN(QUERY_HIDDEN_SIZE, return_sequences=False))
-model.add(Dense(SENT_HIDDEN_SIZE + QUERY_HIDDEN_SIZE, vocab_size, activation='softmax'))
+model.add(Dense(vocab_size, activation='softmax'))
-nb_conv = [3, 3]
+# input image dimensions
-image_dimensions = 3
+img_channels = 3
-model.add(Convolution2D(nb_filters[0], image_dimensions, nb_conv[0], nb_conv[0], border_mode='full'))
+model.add(Convolution2D(32, 3, 3, border_mode='full',
-model.add(Convolution2D(nb_filters[0], nb_filters[0], nb_conv[0], nb_conv[0]))
+model.add(Convolution2D(32, 3, 3))
-model.add(MaxPooling2D(pool_size=(nb_pool[0], nb_pool[0])))
+model.add(MaxPooling2D(pool_size=(2, 2)))
-model.add(Convolution2D(nb_filters[1], nb_filters[0], nb_conv[0], nb_conv[0], border_mode='full'))
+model.add(Convolution2D(64, 3, 3, border_mode='full'))
-model.add(Convolution2D(nb_filters[1], nb_filters[1], nb_conv[1], nb_conv[1]))
+model.add(Convolution2D(64, 3, 3))
-model.add(MaxPooling2D(pool_size=(nb_pool[1], nb_pool[1])))
+model.add(MaxPooling2D(pool_size=(2, 2)))
-model.add(Dense(nb_filters[-1] * (shapex / nb_pool[0] / nb_pool[1]) * (shapey / nb_pool[0] / nb_pool[1]), 512))
+model.add(Dense(512))
-model.add(Dense(512, nb_classes))
+model.add(Dense(nb_classes))
-np.random.seed(1337) # for reproducibility
+np.random.seed(1337)  # for reproducibility
-nb_filters = 250
+nb_filter = 250
-model.add(Embedding(max_features, embedding_dims))
+model.add(Embedding(max_features, embedding_dims, max_lenght=maxlen))
-# we add a Convolution1D, which will learn nb_filters
+# we add a Convolution1D, which will learn nb_filter
-                        nb_filter=nb_filters,
+model.add(Convolution1D(nb_filter=nb_filter,
-model.add(Dense(output_size, hidden_dims))
+model.add(Dense(hidden_dims))
-model.add(Dense(hidden_dims, 1))
+model.add(Dense(1))
-model.add(LSTM(128, 128))  # try using a GRU instead, for fun
+model.add(LSTM(128))  # try using a GRU instead, for fun
-model.add(Dense(128, 1))
+model.add(Dense(1))
-    Recommended to run on GPU: 
+    Recommended to run on GPU:
-    Best validation score at epoch 21: 0.4881 
+    Best validation score at epoch 21: 0.4881
-model.add(PReLU((512,)))
+model.add(Dense(512, input_shape=(dims,)))
-model.add(BatchNormalization((512,)))
+model.add(Dense(512))
-model.add(BatchNormalization((512,)))
+model.add(Dense(512))
-model.add(Dense(512, nb_classes, init='glorot_uniform'))
+model.add(Dense(nb_classes))
-import random, sys
+import random
-    If you try this script on new data, make sure your corpus 
+    If you try this script on new data, make sure your corpus
-    sentences.append(text[i : i + maxlen])
+    sentences.append(text[i: i + maxlen])
-model.add(LSTM(len(chars), 512, return_sequences=True))
+model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))
-model.add(LSTM(512, 512, return_sequences=False))
+model.add(LSTM(512, return_sequences=False))
-model.add(Dense(512, len(chars)))
+model.add(Dense(len(chars)))
-# helper function to sample an index from a probability array
+
-    return np.argmax(np.random.multinomial(1,a,1))
+    # helper function to sample an index from a probability array
-        sentence = text[start_index : start_index + maxlen]
+        sentence = text[start_index: start_index + maxlen]
-shapex, shapey = 28, 28
+# input image dimensions
-# level of pooling to perform (POOL x POOL)
+# size of pooling area for max pooling
-# level of convolution to perform (CONV x CONV)
+# convolution kernel size
-X_test = X_test.reshape(X_test.shape[0], 1, shapex, shapey)
+X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
-model.add(Convolution2D(nb_filters, 1, nb_conv, nb_conv, border_mode='full'))
+model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
-model.add(Convolution2D(nb_filters, nb_filters, nb_conv, nb_conv))
+model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
-model.add(Dense(nb_filters * (shapex / nb_pool) * (shapey / nb_pool), 128))
+model.add(Dense(128))
-model.add(Dense(128, nb_classes))
+model.add(Dense(nb_classes))
-model.add(SimpleRNN(input_dim=1, output_dim=hidden_units,
+model.add(SimpleRNN(output_dim=hidden_units,
-model.add(Dense(hidden_units, nb_classes))
+                    activation='relu', truncate_gradient=BPTT_truncate,
-model.add(Dense(hidden_units, nb_classes))
+model.add(LSTM(hidden_units, input_shape=(None, 1)))
-model.add(Dense(784, 128))
+model.add(Dense(128, input_shape=(784,)))
-model.add(Dense(128, 128))
+model.add(Dense(128))
-model.add(Dense(128, 10))
+model.add(Dense(10))
-model.add(Dense(max_words, 512))
+model.add(Dense(512, input_shape=(max_words,)))
-model.add(Dense(512, nb_classes))
+model.add(Dense(nb_classes))
-        super(PReLU, self).__init__(**kwargs)
+    def __init__(self, init='zero', weights=None, **kwargs):
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-        super(ParametricSoftplus, self).__init__(**kwargs)
+    def __init__(self, alpha_init=0.2, beta_init=5.0,
-        self.betas = sharedX(beta_init * np.ones(input_shape))
+        self.initial_weights = weights
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, nb_filter, filter_length,
+    def __init__(self, nb_filter, filter_length,
-        self.W_shape = (nb_filter, input_dim, filter_length, 1)
+        self.W_shape = (self.nb_filter, input_dim, self.filter_length, 1)
-        self.b = shared_zeros((nb_filter,))
+        self.b = shared_zeros((self.nb_filter,))
-        self.W_shape = (nb_filter, stack_size, nb_row, nb_col)
+        self.W_shape = (self.nb_filter, stack_size, self.nb_row, self.nb_col)
-        self.b = shared_zeros((nb_filter,))
+        self.b = shared_zeros((self.nb_filter,))
-        self.params = []
+        if not hasattr(self, 'params'):
-            raise Exception('Layer is not connected.')
+            raise Exception('Layer is not connected. Did you forget to set "input_shape"?')
-                output_shape[self.concat_axis] += shape[concat_axis]
+                output_shape[self.concat_axis] += shape[self.concat_axis]
-        self.b = shared_zeros((self.output_dim))
+        self.b = shared_zeros((self.output_dim,))
-    def __init__(self, input_dim, output_dim, init='uniform',
+    def __init__(self, input_dim, output_dim, init='uniform', max_lenght=None,
-        self.W = self.init((self.input_dim, self.output_dim))
+        self.init = initializations.get(init)
-
+        self.activity_regularizer = regularizers.get(activity_regularizer)
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-        return (self.input_shape[0], None, self.output_dim)
+        return (self.input_shape[0], self.max_lenght, self.output_dim)
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-        self.subsample = (subsample_length, 1)
+        self.subsample_length = subsample_length
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, nb_filter, stack_size, nb_row, nb_col,
+    def __init__(self, nb_filter, nb_row, nb_col,
-        super(Convolution2D, self).__init__(**kwargs)
+        self.nb_filter = nb_filter
-        self.stack_size = stack_size
+        self.subsample = tuple(subsample)
-        self.nb_col = nb_col
+        self.W_regularizer = regularizers.get(W_regularizer)
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-                "stack_size": self.stack_size,
+        self.build()
-            raise NotImplementedError
+            raise Exception('Layer is not connected.')
-    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, name=None,
+    def __init__(self, output_dim, init='glorot_uniform', activation='linear', weights=None,
-        self.input_dim = input_dim
+        self.W_regularizer = regularizers.get(W_regularizer)
-        self.W = self.init((self.input_dim, self.output_dim))
+        self.W = self.init((input_dim, self.output_dim))
-        self.b.name = '%s_b' % name
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None,
+    def __init__(self, output_dim, init='glorot_uniform', activation='linear', weights=None,
-        super(TimeDistributedDense, self).__init__(**kwargs)
+        self.output_dim = output_dim
-        self.output_dim = output_dim
+
-        self.W = self.init((self.input_dim, self.output_dim))
+        self.W = self.init((input_dim, self.output_dim))
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, output_dim, nb_feature=4, init='glorot_uniform', weights=None,
+    def __init__(self, output_dim, nb_feature=4, init='glorot_uniform', weights=None,
-        self.input_dim = input_dim
+        self.init = initializations.get(init)
-        self.W = self.init((self.nb_feature, self.input_dim, self.output_dim))
+        self.W = self.init((self.nb_feature, input_dim, self.output_dim))
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-        super(BatchNormalization, self).__init__(**kwargs)
+    def __init__(self, epsilon=1e-6, mode=0, momentum=0.9, weights=None, **kwargs):
-        self._input_shape = input_shape
+        super(BatchNormalization, self).__init__(**kwargs)
-                "mode": self.mode}
+                "mode": self.mode,
-    def __init__(self, input_dim, output_dim,
+    def __init__(self, output_dim,
-        super(SimpleRNN, self).__init__(**kwargs)
+        self.output_dim = output_dim
-        self.output_dim = output_dim
+        self.initial_weights = weights
-        self.W = self.init((self.input_dim, self.output_dim))
+        self.W = self.init((input_dim, self.output_dim))
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, output_dim, depth=3,
+    def __init__(self, output_dim, depth=3,
-        super(SimpleDeepRNN, self).__init__()
+        self.output_dim = output_dim
-        self.input = T.tensor3()
+        self.initial_weights = weights
-        self.W = self.init((self.input_dim, self.output_dim))
+    def build(self):
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, output_dim=128,
+    def __init__(self, output_dim,
-
+        self.truncate_gradient = truncate_gradient
-        self.W_z = self.init((self.input_dim, self.output_dim))
+        self.W_z = self.init((input_dim, self.output_dim))
-        self.W_r = self.init((self.input_dim, self.output_dim))
+        self.W_r = self.init((input_dim, self.output_dim))
-        self.W_h = self.init((self.input_dim, self.output_dim))
+        self.W_h = self.init((input_dim, self.output_dim))
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, output_dim=128,
+    def __init__(self, output_dim,
-
+        self.truncate_gradient = truncate_gradient
-        self.W_i = self.init((self.input_dim, self.output_dim))
+        self.W_i = self.init((input_dim, self.output_dim))
-        self.W_f = self.init((self.input_dim, self.output_dim))
+        self.W_f = self.init((input_dim, self.output_dim))
-        self.W_c = self.init((self.input_dim, self.output_dim))
+        self.W_c = self.init((input_dim, self.output_dim))
-        self.W_o = self.init((self.input_dim, self.output_dim))
+        self.W_o = self.init((input_dim, self.output_dim))
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, output_dim=128,
+    def __init__(self, output_dim,
-
+        self.truncate_gradient = truncate_gradient
-        self.W_z = self.init((self.input_dim, self.output_dim))
+        self.W_z = self.init((input_dim, self.output_dim))
-        self.W_r = self.init((self.input_dim, self.output_dim))
+        self.W_r = self.init((input_dim, self.output_dim))
-        if self.input_dim == self.output_dim:
+        if input_dim == self.output_dim:
-            P = 1 / np.sqrt(self.input_dim) * P
+            P = np.random.binomial(1, 0.5, size=(input_dim, self.output_dim)).astype(theano.config.floatX) * 2 - 1
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, output_dim=128,
+    def __init__(self, output_dim,
-
+        self.truncate_gradient = truncate_gradient
-        self.W_z = self.init((self.input_dim, self.output_dim))
+        self.W_z = self.init((input_dim, self.output_dim))
-        self.W_h = self.init((self.input_dim, self.output_dim))
+        self.W_h = self.init((input_dim, self.output_dim))
-        if self.input_dim == self.output_dim:
+        if input_dim == self.output_dim:
-            P = 1 / np.sqrt(self.input_dim) * P
+            P = np.random.binomial(1, 0.5, size=(input_dim, self.output_dim)).astype(theano.config.floatX) * 2 - 1
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-    def __init__(self, input_dim, output_dim=128,
+    def __init__(self, output_dim,
-
+        self.truncate_gradient = truncate_gradient
-        self.W_z = self.init((self.input_dim, self.output_dim))
+        self.W_z = self.init((input_dim, self.output_dim))
-        self.W_r = self.init((self.input_dim, self.output_dim))
+        self.W_r = self.init((input_dim, self.output_dim))
-        self.W_h = self.init((self.input_dim, self.output_dim))
+        self.W_h = self.init((input_dim, self.output_dim))
-            self.set_weights(weights)
+        if self.initial_weights is not None:
-def get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None, custom_layers={}):
+def get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None):
-        res = module_params.get(identifier, custom_layers.get(identifier))
+        res = module_params.get(identifier)
-                
+
-    return get_from_module(identifier, globals(), 'layer', instantiate=True, kwargs=kwargs, custom_layers=custom_layers)
+    # Insert custom layers into globals so they can be accessed by `get_from_module`.
-        super(LeakyReLU, self).__init__()
+    def __init__(self, alpha=0.3, **kwargs):
-        super(PReLU, self).__init__()
+    def __init__(self, input_shape, init='zero', weights=None, **kwargs):
-    def __init__(self, input_shape, alpha_init=0.2, beta_init=5.0, weights=None):
+    def __init__(self, input_shape, alpha_init=0.2,
-        super(ParametricSoftplus, self).__init__()
+        super(ParametricSoftplus, self).__init__(**kwargs)
-        super(ThresholdedLinear, self).__init__()
+    def __init__(self, theta=1.0, **kwargs):
-        super(ThresholdedReLu, self).__init__()
+    def __init__(self, theta=1.0, **kwargs):
-                 W_constraint=None, b_constraint=None):
+                 W_constraint=None, b_constraint=None, **kwargs):
-        super(Convolution1D, self).__init__()
+        super(Convolution1D, self).__init__(**kwargs)
-                 W_constraint=None, b_constraint=None):
+                 W_constraint=None, b_constraint=None, **kwargs):
-        super(Convolution2D, self).__init__()
+        super(Convolution2D, self).__init__(**kwargs)
-        super(MaxPooling1D, self).__init__()
+    input_ndim = 3
-        super(MaxPooling2D, self).__init__()
+    input_ndim = 4
-        super(UpSample1D, self).__init__()
+    input_ndim = 3
-        super(UpSample2D, self).__init__()
+    input_ndim = 4
-        super(ZeroPadding1D, self).__init__()
+    input_ndim = 3
-        super(ZeroPadding2D, self).__init__()
+    input_ndim = 4
-from ..utils.theano_utils import shared_zeros, floatX
+from ..utils.theano_utils import shared_zeros, floatX, ndim_tensor
-    def __init__(self):
+    def __init__(self, **kwargs):
-        super(Masking, self).__init__()
+    def __init__(self, mask_value=0., **kwargs):
-    def __init__(self, mode='sum'):
+    input_ndim = 3
-        super(Dropout, self).__init__()
+    def __init__(self, p, **kwargs):
-        super(Activation, self).__init__()
+    def __init__(self, activation, target=0, beta=0.1, **kwargs):
-        super(Reshape, self).__init__()
+    def __init__(self, dims, **kwargs):
-        super(Permute, self).__init__()
+    def __init__(self, dims, **kwargs):
-        super(Flatten, self).__init__()
+    def __init__(self, **kwargs):
-        super(RepeatVector, self).__init__()
+    def __init__(self, n, **kwargs):
-                 W_constraint=None, b_constraint=None):
+                 W_constraint=None, b_constraint=None, **kwargs):
-        super(Dense, self).__init__()
+        super(Dense, self).__init__(**kwargs)
-        super(ActivityRegularization, self).__init__()
+    def __init__(self, l1=0., l2=0., **kwargs):
-                 W_constraint=None, b_constraint=None):
+                 W_constraint=None, b_constraint=None, **kwargs):
-        super(TimeDistributedDense, self).__init__()
+        super(TimeDistributedDense, self).__init__(**kwargs)
-        super(AutoEncoder, self).__init__()
+    def __init__(self, encoder, decoder, output_reconstruction=True, weights=None, **kwargs):
-                 W_constraint=None, b_constraint=None):
+                 W_constraint=None, b_constraint=None, **kwargs):
-        super(MaxoutDense, self).__init__()
+        super(MaxoutDense, self).__init__(**kwargs)
-                 mask_zero=False, weights=None):
+                 mask_zero=False, weights=None, **kwargs):
-        super(Embedding, self).__init__()
+        super(Embedding, self).__init__(**kwargs)
-                 init='uniform', activation='sigmoid', weights=None):
+                 init='uniform', activation='sigmoid', weights=None, **kwargs):
-        super(WordContextProduct, self).__init__()
+        super(WordContextProduct, self).__init__(**kwargs)
-        super(GaussianNoise, self).__init__()
+    def __init__(self, sigma, **kwargs):
-        super(GaussianDropout, self).__init__()
+    def __init__(self, p, **kwargs):
-        super(BatchNormalization, self).__init__()
+    def __init__(self, input_shape, epsilon=1e-6, mode=0, momentum=0.9, weights=None, **kwargs):
-    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5):
+    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):
-        super(LRN2D, self).__init__()
+        super(LRN2D, self).__init__(**kwargs)
-                 truncate_gradient=-1, return_sequences=False):
+                 truncate_gradient=-1, return_sequences=False, **kwargs):
-        super(SimpleRNN, self).__init__()
+        super(SimpleRNN, self).__init__(**kwargs)
-                 weights=None, truncate_gradient=-1, return_sequences=False):
+                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
-                 weights=None, truncate_gradient=-1, return_sequences=False):
+                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
-                 weights=None, truncate_gradient=-1, return_sequences=False):
+                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
-                 weights=None, truncate_gradient=-1, return_sequences=False):
+                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
-        super(JZS1, self).__init__()
+        super(JZS1, self).__init__(**kwargs)
-                 weights=None, truncate_gradient=-1, return_sequences=False):
+                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
-        super(JZS2, self).__init__()
+        super(JZS2, self).__init__(**kwargs)
-                 weights=None, truncate_gradient=-1, return_sequences=False):
+                 weights=None, truncate_gradient=-1, return_sequences=False, **kwargs):
-        super(JZS3, self).__init__()
+        super(JZS3, self).__init__(**kwargs)
-    def __init__(self, pool_length=2, stride=1, ignore_border=True):
+    def __init__(self, pool_length=2, stride=None, ignore_border=True):
-    def __init__(self, poolsize=(2, 2), stride=(2, 2), ignore_border=True):
+    def __init__(self, poolsize=(2, 2), stride=None, ignore_border=True):
-        if type(stride) is not int or not stride:
+        if stride is None:
-    def __init__(self, poolsize=(2, 2), stride=(1, 1), ignore_border=True):
+    def __init__(self, poolsize=(2, 2), stride=(2, 2), ignore_border=True):
-        super(ZeroPadding2D, self).__init__()
+        super(ZeroPadding1D, self).__init__()
-                   slice(pad[1], input_shape[3] + self.padding[1]))
+                   slice(self.padding[0], input_shape[2] + self.padding[0]),
-        poolsize = (3, 3)
+        pool_size = (3, 3)
-                layer = convolutional.MaxPooling2D(stride=stride, ignore_border=ignore_border, poolsize=poolsize)
+                layer = convolutional.MaxPooling2D(stride=stride, ignore_border=ignore_border, pool_size=pool_size)
-        layer = convolutional.ZeroPadding2D(pad=(2,2))
+        layer = convolutional.ZeroPadding2D(padding=(2, 2))
-            for offset in [0,1,-1,-2]:
+            for offset in [0, 1, -1, -2]:
-        for length in [2,3,9]:
+        for length in [2, 3, 9]:
-                layer = convolutional.UpSample2D(size=(length_row,length_col))
+        for length_row in [2, 3, 9]:
-        layer = core.Reshape(10, 10)
+        layer = core.Reshape(dims=(10, 10))
-             [[0], [4], [5], [0]]], dtype=np.int32)) ==
+            func(np.array([[[1], [2], [3], [0]],
-             [[1, 5], [5, 0], [0, 0], [0, 0]]], dtype=np.int32)) ==
+            func(np.array([[[1, 1], [2, 1], [3, 1], [5, 5]],
-             [[1, 5], [5, 0], [0, 0], [0, 0]]], dtype=np.int32)) ==
+            func(np.array([[[1, 1], [2, 1], [3, 1], [5, 5]],
-             [[1, 5], [5, 0], [0, 0], [0, 0]]])))
+                     [[1, 5], [5, 0], [0, 0], [0, 0]]])))
-        layer = Reshape(2, 3)
+        layer = Reshape(dims=(2, 3))
-                for poolsize in [(2, 2), (3, 3), (4, 4)]:
+                for pool_size in [(2, 2), (3, 3), (4, 4)]:
-                        layer = MaxPooling2D(poolsize=poolsize, stride=stride, ignore_border=ignore_border)
+                        layer = MaxPooling2D(pool_size=pool_size, stride=stride, ignore_border=ignore_border)
-            border_mode = 'full'
+        if on_gpu() and dnn.dnn_available():
-            conv_out = conv_out[:, :, shift_x:X.shape[2] + shift_x, :]
+            conv_out = T.nnet.conv.conv2d(X, self.W,
-    def __init__(self, pad=(1, 1)):
+    """Zero-padding layer for 1D input (e.g. temporal sequence).
-        self.pad = tuple(pad)
+        self.padding = tuple(padding)
-        return (input_shape[0], input_shape[1], input_shape[2] + 2 * self.pad[0], input_shape[3] + 2 * self.pad[1])
+        return (input_shape[0],
-        out_shape = (in_shape[0], in_shape[1], in_shape[2] + 2 * pad[0], in_shape[3] + 2 * pad[1])
+        input_shape = X.shape
-        indices = (slice(None), slice(None), slice(pad[0], in_shape[2] + pad[0]), slice(pad[1], in_shape[3] + pad[1]))
+        indices = (slice(None),
-                "pad": self.pad}
+                "padding": self.padding}
-    def __init__(self, *dims):
+    def __init__(self, dims):
-        return make_tuple(self.input_shape[0], *self.dims)
+        return (self.input_shape[0],) + self.dims
-        return theano.tensor.reshape(X, nshape)
+        new_shape = (X.shape[0],) + self.dims
-        self.poolsize = (pool_length, 1)
+        self.pool_size = (pool_length, 1)
-        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.st, ignore_border=self.ignore_border)
+        output = downsample.max_pool_2d(X, ds=self.pool_size, st=self.st, ignore_border=self.ignore_border)
-    def __init__(self, poolsize=(2, 2), stride=(1, 1), ignore_border=True):
+    def __init__(self, pool_size=(2, 2), stride=(1, 1), ignore_border=True):
-        self.poolsize = tuple(poolsize)
+        self.pool_size = tuple(pool_size)
-        cols = pool_output_length(input_shape[3], self.poolsize[1], self.ignore_border, self.stride[1])
+        rows = pool_output_length(input_shape[2], self.pool_size[0], self.ignore_border, self.stride[0])
-        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)
+        output = downsample.max_pool_2d(X, ds=self.pool_size, st=self.stride, ignore_border=self.ignore_border)
-                "poolsize": self.poolsize,
+                "pool_size": self.pool_size,
-                    conv_out = conv_out[:, :, shift_x:X.shape[2] + shift_x, shift_y:X.shape[3] + shift_y]
+                shift_x = (self.nb_row - 1) // 2
-                        print 'input_data_shape:', input_data_shape
+    @property
-        self.subsample = (1, subsample_length)
+        self.subsample = (subsample_length, 1)
-    def get_output(self, train):
+    @property
-    def get_output(self, train):
+    @property
-                conv_out = conv_out[:, :, shift_x:X.shape[2] + shift_x, shift_y:X.shape[3] + shift_y]
+                    shift_x = (self.nb_row - 1) // 2
-    def __init__(self, pool_length=2, stride=None, ignore_border=True):
+    def __init__(self, pool_length=2, stride=1, ignore_border=True):
-            self.st = None
+        self.st = (self.stride, 1)
-    def get_output(self, train):
+    @property
-    def __init__(self, poolsize=(2, 2), stride=None, ignore_border=True):
+    def __init__(self, poolsize=(2, 2), stride=(1, 1), ignore_border=True):
-        self.stride = stride
+        self.stride = tuple(stride)
-    def get_output(self, train):
+    @property
-    def get_output(self, train):
+    @property
-    def get_output(self, train):
+    @property
-    def get_output(self, train):
+    @property
-        else:
+        elif hasattr(self, 'input'):
-        '''
+    @property
-        Permute the dimensions of the data according to the given tuple
+        Permute the dimensions of the input according to the given tuple.
-    def get_output(self, train):
+    @property
-       Tensor output dimensions:  (nb_sample, shared_dimension, output_dim)
+       Apply a same Dense layer for each dimension[1] (time_dimension) input.
-        else dim(output) = dim(hidden)
+    '''A customizable autoencoder model.
-        self.input_shape = input_shape
+        self._input_shape = input_shape
-        self.input = ndim_tensor(len(self.input_shape) + 1)
+        self.input = ndim_tensor(len(input_shape) + 1)
-        self.beta = shared_zeros(self.input_shape)
+        self.gamma = self.init((input_shape))
-        self.running_std = shared_ones((self.input_shape))
+        self.running_mean = shared_zeros(input_shape)
-                "input_shape": self.input_shape,
+                "input_shape": self._input_shape,
-            for stride in [None, 2]:
+            for stride in [1, 2]:
-            for stride in [None, (2, 2)]:
+            for stride in [(1, 1), (2, 2)]:
-
+import unittest
-    def __init__(self, *dims):
+    def __init__(self, *dims, **kwargs):
-        if type(dims[0]) in [list, tuple]:
+        if len(dims) > 0 and type(dims[0]) in [list, tuple]:
-def model_from_yaml(yaml_string):
+def model_from_yaml(yaml_string, custom_layers={}):
-    return model_from_config(config)
+    return model_from_config(config, custom_layers=custom_layers)
-def model_from_json(json_string):
+def model_from_json(json_string, custom_layers={}):
-    return model_from_config(config)
+    return model_from_config(config, custom_layers=custom_layers)
-def model_from_config(config):
+def model_from_config(config, custom_layers={}):
-    model = container_from_config(config)
+    model = container_from_config(config, custom_layers=custom_layers)
-def get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None):
+def get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None, custom_layers={}):
-        res = module_params.get(identifier)
+        res = module_params.get(identifier, custom_layers.get(identifier))
-def container_from_config(original_layer_dict):
+def container_from_config(original_layer_dict, custom_layers={}):
-            init_layer = container_from_config(layer)
+            init_layer = container_from_config(layer, custom_layers=custom_layers)
-            init_layer = container_from_config(layer)
+            init_layer = container_from_config(layer, custom_layers=custom_layers)
-            layer = container_from_config(layer_dict['nodes'].get(node['name']))
+            layer = container_from_config(layer_dict['nodes'].get(node['name']),
-                  'decoder': container_from_config(layer_dict.get('decoder_config'))}
+        kwargs = {'encoder': container_from_config(layer_dict.get('encoder_config'),
-        base_layer = get_layer(name, layer_dict)
+        base_layer = get_layer(name, layer_dict, custom_layers=custom_layers)
-    return get_from_module(identifier, globals(), 'layer', instantiate=True, kwargs=kwargs)
+def get_layer(identifier, kwargs=None, custom_layers={}):
-    def to_yaml(self):
+    def to_yaml(self, **kwargs):
-        return yaml.dump(config)
+        return yaml.dump(config, **kwargs)
-    def to_json(self):
+    def to_json(self, **kwargs):
-        return json.dumps(config)
+        return json.dumps(config, **kwargs)
-        self.dims = dims
+        if type(dims[0]) in [list, tuple]:
-        self.dims = dims
+        self.dims = tuple(dims)
-        the length of the longuest sequence.
+        the length of the longest sequence.
-        self.subsample = subsample
+        self.subsample = tuple(subsample)
-        self.poolsize = poolsize
+        self.poolsize = tuple(poolsize)
-        self.size = size
+        self.size = tuple(size)
-        self.pad = pad
+        self.pad = tuple(pad)
-                    print('TypeError while preparing batch. \
+                    raise Exception('TypeError while preparing batch. \
-                                                  sample_weight=sample_weight.get(name)) for name in self.output_order]
+
-            grads = [T.clip(g, self.clipvalue, -self.clipvalue) for g in grads]
+            grads = [T.clip(g, -self.clipvalue, self.clipvalue) for g in grads]
-    return T.nnet.relu(X)
+    return T.nnet.relu(x)
-    return (x + abs(x)) / 2.0
+    return T.nnet.relu(X)
-        return ((X + abs(X)) / 2.0) + self.alpha * ((X - abs(X)) / 2.0)
+        return T.nnet.relu(X, self.alpha)
-        neg = self.alphas * ((X - abs(X)) / 2.0)
+        pos = T.nnet.relu(X)
-    
+
-        return T.switch( abs(X) < self.theta, 0, X )
+        return T.switch(abs(X) < self.theta, 0, X)
-            "theta": self.theta}
+                "theta": self.theta}
-    
+
-        return T.switch( X > self.theta, X, 0 )
+        return T.switch(X > self.theta, X, 0)
-            "theta": self.theta}
+                "theta": self.theta}
-            grads = [clip_value(g, self.clipvalue) for g in grads]
+            grads = [T.clip(g, self.clipvalue, -self.clipvalue) for g in grads]
-word_index = tokenizer.word_index
+
-                    raise ValueError('merge_mode=`join` only works with named inputs')
+                    raise ValueError("merge_mode='join' only works with named inputs")
-                    inputs[self.layers[i].get_output(train).name] = self.layers[i].get_output(train)
+                    inputs[X.name] = self.layers[i].get_output(train)
-                inputs[self.layers[i].get_output(train).name] = self.layers[i].get_output(train)
+                if X.name is None:
-        mask = T.addbroadcast(mask, -1)  # (time, nb_samples, 1) matrix.
+        mask = T.addbroadcast(mask, -1)  # the new dimension (the '1') is made broadcastable
-            inputs = [self.layers[i].get_output(train) for i in range(len(self.layers))]
+            inputs = OrderedDict()
-        self.subsample = (1, subsample_length)
+        self.subsample = (subsample_length, 1)
-            print('Epoch %d/%d' % (epoch + 1, self.nb_epoch + 1))
+            print('Epoch %d/%d' % (epoch + 1, self.nb_epoch))
-            print('Epoch %d out of %d' % (epoch, self.nb_epoch))
+            print('Epoch %d/%d' % (epoch + 1, self.nb_epoch + 1))
-
+                if type(self.sum_values[k]) is list:
-            print('Epoch %d' % epoch)
+            print('Epoch %d out of %d' % (epoch, self.nb_epoch))
-# use https://github.com/erocarrera/pydot
+# old pydot will not work with python3, must use one
-            mode: {'sum', 'mul', 'concat'}
+            mode: {'sum', 'mul', 'concat', 'ave'}
-        if self.mode == 'sum':
+        if self.mode == 'sum' or self.mode == 'ave':
-    img = Image.open(open(path))
+    img = Image.open(path)
-      install_requires=['theano', 'pyyaml', 'h5py'],
+      install_requires=['theano', 'pyyaml'],
-from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder
+from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking
-        self.assertTrue(history.history['val_loss'][-1] < 0.75)
+        self.assertTrue(history.history['val_loss'][-1] < 0.8)
-        output = T.signal.downsample.max_pool_2d(X, ds=self.poolsize, st=self.st, ignore_border=self.ignore_border)
+        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.st, ignore_border=self.ignore_border)
-        output = T.signal.downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)
+        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)
-        layer = Layer() # empty layer
+        layer = Layer()  # empty layer
-    def add_node(self, layer, name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, create_output=False):
+    def add_node(self, layer, name, input=None, inputs=[],
-                                 'merge_mode': merge_mode})
+                                 'merge_mode': merge_mode,
-    def add_output(self, name, input=None, inputs=[], merge_mode='concat', concat_axis=-1):
+    def add_output(self, name, input=None, inputs=[],
-from ..utils.theano_utils import shared_zeros
+from ..utils.theano_utils import shared_zeros, on_gpu
-        if dnn.dnn_available() and theano.config.device[:3] == 'gpu':
+        if on_gpu() and dnn.dnn_available():
-from ..utils.theano_utils import shared_zeros, shared_ones, ndim_tensor
+from ..utils.theano_utils import shared_zeros, shared_ones, ndim_tensor, floatX
-        norm_m1 = normalization.BatchNormalization((10,), mode=1, weights=[np.ones(10), np.ones(10)])
+        norm_m1 = normalization.BatchNormalization((10,), mode=1, weights=[np.ones(10), np.ones(10), np.zeros(10), np.zeros(10)])
-
+    def test_save_weights(self):
-from theano.sandbox.cuda import dnn
+if theano.config.device[:3] == 'gpu':
-        layer = Layer()  # empty layer
+        layer = Layer() # empty layer
-    def add_node(self, layer, name, input=None, inputs=[], merge_mode='concat', create_output=False):
+    def add_node(self, layer, name, input=None, inputs=[], merge_mode='concat', concat_axis=-1, create_output=False):
-            merge = Merge(to_merge, mode=merge_mode)
+            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis)
-    def add_output(self, name, input=None, inputs=[], merge_mode='concat'):
+    def add_output(self, name, input=None, inputs=[], merge_mode='concat', concat_axis=-1):
-            merge = Merge(to_merge, mode=merge_mode)
+            merge = Merge(to_merge, mode=merge_mode, concat_axis=concat_axis)
-                                   'merge_mode': merge_mode})
+                                   'merge_mode': merge_mode,
-    def __init__(self, layers, mode='sum'):
+    def __init__(self, layers, mode='sum', concat_axis=-1):
-            return T.concatenate(inputs, axis=-1)
+            return T.concatenate(inputs, axis=self.concat_axis)
-                "mode": self.mode}
+                "mode": self.mode,
-import cPickle
+from six.moves import cPickle
-            for border_mode in ['valid', 'full']:
+            for border_mode in ['valid', 'full', 'same']:
-                                layer.get_output(train).eval()
+                                out = layer.get_output(train).eval()
-                                b_regularizer=b_regularizer, subsample_length=subsample_length)
+                            for act_regularizer in [None, 'l2']:
-                                b_regularizer=b_regularizer, subsample=subsample)
+                            for act_regularizer in [None, 'l2']:
-                                    assert out.shape[2:] == input.shape[2:]
+                                layer.input = theano.shared(value=input)
-                            config = layer.get_config()
+                                config = layer.get_config()
-                loss = model.fit(X, labels)
+                loss = model.train_on_batch(X, labels)
-import six.moves.cPickle
+from six.moves import cPickle
-    tokenizer = six.moves.cPickle.load(open(os.path.join(save_dir, tokenizer_fname), 'rb'))
+    tokenizer = cPickle.load(open(os.path.join(save_dir, tokenizer_fname), 'rb'))
-        six.moves.cPickle.dump(tokenizer, open(os.path.join(save_dir, tokenizer_fname), "wb"))
+        cPickle.dump(tokenizer, open(os.path.join(save_dir, tokenizer_fname), "wb"))
-        model = six.moves.cPickle.load(open(os.path.join(save_dir, model_load_fname), 'rb'))
+        model = cPickle.load(open(os.path.join(save_dir, model_load_fname), 'rb'))
-                loss = model.train(X, labels)
+                loss = model.fit(X, labels)
-        six.moves.cPickle.dump(model, open(os.path.join(save_dir, model_save_fname), "wb"))
+        cPickle.dump(model, open(os.path.join(save_dir, model_save_fname), "wb"))
-        model.lr.set_value(self.schedule(epoch))
+        self.model.optimizer.lr.set_value(self.schedule(epoch))
-model.add(Convolution2D(32, 3, 3, 3, border_mode='full'))
+model.add(Convolution2D(nb_filters[0], image_dimensions, nb_conv[0], nb_conv[0], border_mode='full'))
-model.add(Convolution2D(32, 32, 3, 3))
+model.add(Convolution2D(nb_filters[0], nb_filters[0], nb_conv[0], nb_conv[0]))
-model.add(MaxPooling2D(poolsize=(2, 2)))
+model.add(MaxPooling2D(poolsize=(nb_pool[0], nb_pool[0])))
-model.add(Convolution2D(64, 32, 3, 3, border_mode='full'))
+model.add(Convolution2D(nb_filters[1], nb_filters[0], nb_conv[0], nb_conv[0], border_mode='full'))
-model.add(Convolution2D(64, 64, 3, 3))
+model.add(Convolution2D(nb_filters[1], nb_filters[1], nb_conv[1], nb_conv[1]))
-model.add(MaxPooling2D(poolsize=(2, 2)))
+model.add(MaxPooling2D(poolsize=(nb_pool[1], nb_pool[1])))
-model.add(Dense(64*8*8, 512))
+# the image dimensions are the original dimensions divided by any pooling
-X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)
+X_train = X_train.reshape(X_train.shape[0], 1, shapex, shapey)
-model.add(Convolution2D(32, 1, 3, 3, border_mode='full'))
+model.add(Convolution2D(nb_filters, 1, nb_conv, nb_conv, border_mode='full'))
-model.add(Convolution2D(32, 32, 3, 3))
+model.add(Convolution2D(nb_filters, nb_filters, nb_conv, nb_conv))
-model.add(MaxPooling2D(poolsize=(2, 2)))
+model.add(MaxPooling2D(poolsize=(nb_pool, nb_pool)))
-model.add(Dense(32*196, 128))
+# the resulting image after conv and pooling is the original shape
-    ''' From Lasagne
+    ''' From Lasagne. Reference: Saxe et al., http://arxiv.org/abs/1312.6120
-import six.moves.cPickle
+from six.moves import cPickle
-        d = six.moves.cPickle.load(f)
+        d = cPickle.load(f)
-        d = six.moves.cPickle.load(f, encoding="bytes")
+        d = cPickle.load(f, encoding="bytes")
-import six.moves.cPickle
+import cPickle
-    X, labels = six.moves.cPickle.load(f)
+    X, labels = cPickle.load(f)
-import six.moves.cPickle
+from six.moves import cPickle
-        data = six.moves.cPickle.load(f)
+        data = cPickle.load(f)
-        data = six.moves.cPickle.load(f, encoding="bytes")
+        data = cPickle.load(f, encoding="bytes")
-import six.moves.cPickle
+from six.moves import cPickle
-    six.moves.cPickle.dump(tokenizer.word_index, open(os.path.join('datasets', 'data', 'reuters_word_index.pkl'), 'w'))
+    cPickle.dump(dataset, open(os.path.join('datasets', 'data', 'reuters.pkl'), 'w'))
-    X, labels = six.moves.cPickle.load(f)
+    X, labels = cPickle.load(f)
-    return six.moves.cPickle.load(f)
+    return cPickle.load(f)
-            s = self.layers[0].get_output(train) * self.layers[1].get_output(train)
+            s = self.layers[0].get_output(train)
-                              % (epoch, self.monitor, self.best, current, self.filepath))
+                              % (epoch, self.monitor, self.best, current, filepath))
-                    self.model.save_weights(self.filepath, overwrite=True)
+                    self.model.save_weights(filepath, overwrite=True)
-            self.model.save_weights(self.filepath, overwrite=True)
+                print("Epoch %05d: saving model to %s" % (epoch, filepath))
-raise Exception("Modelcheckpoint tests did not pass")
+    passed = True
-            mode: {'sum', 'concat'}
+            mode: {'sum', 'mul', 'concat'}
-        # it's important that 0 * Inf == 0, not NaN, so I need to filter
+        # it's important that 0 * Inf == 0, not NaN, so we need to filter
-        y = np.reshape(y, (-1,yshape[-1])) # for time-distributed data, collapse time and sample
+        y = np.reshape(y, (-1, yshape[-1]))  # for time-distributed data, collapse time and sample
-        return np.reshape(class_weights, yshape[:-1] + (1,)) # uncollapse initial dimensions
+        return np.reshape(class_weights, yshape[:-1] + (1,))  # uncollapse initial dimensions
-             validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):
+             val_f=None, val_ins=None, shuffle=True, metrics=[]):
-            try:
+            if len(validation_data) == 2:
-                raise Exception("Invalid format for validation data; provide a tuple (X_val, y_val). \
+                sample_weight_val = np.ones(y_val.shape[:-1] + (1,))
-            val_ins = X_val + [y_val, np.ones(y_val.shape[:-1] + (1,))]
+            sample_weight_val = standardize_weights(y_val, sample_weight=sample_weight_val)
-                         validation_split=validation_split, val_f=val_f, val_ins=val_ins,
+                         val_f=val_f, val_ins=val_ins,
-
+        sample_weight = [standardize_weights(data[name],
-        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight
+        X = [data[name] for name in self.input_order]
-                            validation_split=validation_split, val_f=val_f, val_ins=val_ins,
+                            val_f=val_f, val_ins=val_ins,
-        sample_weight = [standardize_weights(data[name], sample_weight.get(name)) for name in self.output_order]
+        sample_weight = [standardize_weights(data[name],
-                                   sample_weight={'output1': weights1, 'output2': weights2})
+                                   sample_weight={'output1': weights1_test, 'output2': weights2_test})
-nb_epoch = 5
+nb_epoch = 8
-              class_weight=class_weight, sample_weight=sample_weight)
+    if sample_weight is not None:
-    model.fit({'input': X_train, 'output': Y_train}, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0,
+    model.fit({'input': X_train, 'output': Y_train}, batch_size=batch_size, nb_epoch=nb_epoch // 2, verbose=0,
-        if dnn.dnn_available() and theano.config.device == 'gpu':
+        if dnn.dnn_available() and theano.config.device[:3] == 'gpu':
-             val_f=None, val_ins=None, shuffle=True, metrics=[]):
+             validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):
-            if len(validation_data) == 2:
+            try:
-                raise Exception("Invalid format for validation data; provide a tuple (X_val, y_val) or (X_val, y_val, sample_weight). \
+            except:
-            val_ins = X_val + [y_val, sample_weight_val]
+            val_ins = X_val + [y_val, np.ones(y_val.shape[:-1] + (1,))]
-                         val_f=val_f, val_ins=val_ins,
+                         validation_split=validation_split, val_f=val_f, val_ins=val_ins,
-                                             sample_weight=sample_weight.get(name)) for name in self.output_order]
+        sample_weight = [standardize_weights(data[name]) for name in self.output_order]
-        class_weight_list = [class_weight.get(name) for name in self.output_order]
+        sample_weight = [standardize_weights(data[name],
-                            val_f=val_f, val_ins=val_ins,
+                            validation_split=validation_split, val_f=val_f, val_ins=val_ins,
-                                             sample_weight=sample_weight.get(name)) for name in self.output_order]
+        sample_weight = [standardize_weights(data[name], sample_weight.get(name)) for name in self.output_order]
-                                   sample_weight={'output1': weights1_test, 'output2': weights2_test})
+                                   sample_weight={'output1': weights1, 'output2': weights2})
-             validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):
+             val_f=None, val_ins=None, shuffle=True, metrics=[]):
-            try:
+            if len(validation_data) == 2:
-                raise Exception("Invalid format for validation data; provide a tuple (X_val, y_val). \
+                sample_weight_val = np.ones(y_val.shape[:-1] + (1,))
-            val_ins = X_val + [y_val, np.ones(y_val.shape[:-1] + (1,))]
+            val_ins = X_val + [y_val, sample_weight_val]
-                         validation_split=validation_split, val_f=val_f, val_ins=val_ins,
+                         val_f=val_f, val_ins=val_ins,
-
+        sample_weight = [standardize_weights(data[name],
-        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight
+        X = [data[name] for name in self.input_order]
-                            validation_split=validation_split, val_f=val_f, val_ins=val_ins,
+                            val_f=val_f, val_ins=val_ins,
-        sample_weight = [standardize_weights(data[name], sample_weight.get(name)) for name in self.output_order]
+        sample_weight = [standardize_weights(data[name],
-                                   sample_weight={'output1': weights1, 'output2': weights2})
+                                   sample_weight={'output1': weights1_test, 'output2': weights2_test})
-        if dnn.dnn_available():
+        if dnn.dnn_available() and theano.config.device == 'gpu':
-        assert loss == 282.375
+        assert loss == 285.
-        Y = 2*X
+        Y = 2 * X
-        weights[0,0] = 0
+        weights = np.ones((3, 4, 1))  # Normally the trailing 1 is added by standardize_weights
-        mask[1,0] = 0
+        mask[1, 0] = 0
-        weights[0,0] = 1e-9 # so that nonzero() doesn't remove this weight
+        weights[0, 0] = 1e-9  # so that nonzero() doesn't remove this weight
-        assert abs(out-out2) < 1e-8
+        assert abs(out - out2) < 1e-8
-            return (filtered_weights.flatten() * obj_output.flatten()).sum() / filtered_weights.sum()
+            return weighted.sum() / filtered_weights.sum()
-            return (wc * filtered_mask).sum() / (filtered_mask * filtered_weights).sum()
+            return weighted.sum() / (filtered_mask * filtered_weights).sum()
-            return wc.mean()
+            return (wc * filtered_mask).sum() / (filtered_mask * filtered_weights).sum()
-        obj_output = fn(masked_y_true, masked_y_pred)
+        '''
-            return (masked_weights.flatten() * obj_output.flatten()).mean()
+            # Instead of calling mean() here, we divide by the sum of filtered_weights.
-            wc = wc.sum(axis=1) / mask.sum(axis=1)
+            filtered_mask = mask[weights.nonzero()[:-1]]
-from keras.models import Sequential
+from keras.models import Sequential, weighted_objective
-    return T.mean(y_pred - y_true * T.log(y_pred), axis=-1)
+    return T.mean(y_pred - y_true * T.log(y_pred + epsilon), axis=-1)
-                "decay": self.decay,
+                "lr": float(self.lr.get_value()),
-                "rho": self.rho,
+                "lr": float(self.lr.get_value()),
-                "lr": self.lr,
+                "lr": float(self.lr.get_value()),
-                "lr": self.lr,
+                "lr": float(self.lr.get_value()),
-                "lr": self.lr,
+                "lr": float(self.lr.get_value()),
-from keras.models import Sequential
+from keras.models import Sequential, model_from_json, model_from_yaml
-        Parametric Softplus of the form: alpha * (1 + exp(beta * X))
+        Parametric Softplus of the form: alpha * log(1 + exp(beta * X))
-            return dict([k, v.get_input(train) for k, v in self.inputs.items()])
+            return dict([(k, v.get_input(train)) for k, v in self.inputs.items()])
-            return dict([k, v.get_output(train) for k, v in self.outputs.items()])
+            return dict([(k, v.get_output(train)) for k, v in self.outputs.items()])
-    func is a function that gets an epoch number as input and returns a new
+    schedule is a function that gets an epoch number as input and returns a new
-    def __init__(self, func):
+    def __init__(self, schedule):
-        self.func = func
+        self.schedule = schedule
-        model.lr.set_value(self.func(epoch))
+        model.lr.set_value(self.schedule(epoch))
-                 **kwargs):
+    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args, **kwargs):
-                 **kwargs):
+    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args, **kwargs):
-        return self.inputs[self.input_order[0]].get_input(train)
+        if len(self.inputs) == len(self.outputs) == 1:
-        return self.outputs[self.output_order[0]].get_output(train)
+        if len(self.inputs) == len(self.outputs) == 1:
-                "subsample_length": self.subsample_length}
+                "ignore_border": self.ignore_border}
-    value
+class LearningRateScheduler(Callback):
-        self.epoch_lr = epoch_lr
+    def __init__(self, func):
-            self.model.lr.set_value(self.epoch_lr[str(epoch)])
+        model.lr.set_value(self.func(epoch))
-    def on_epoch_end(self, epoch, logs={}):
+    def on_epoch_begin(self, epoch, logs={}):
-import time, json, warnings
+import time
-    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args, **kwargs):
+    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args,
-        for p, g, a, d_a, c in zip(params, grads, accumulators, delta_accumulators, constraints):
+        for p, g, a, d_a, c in zip(params, grads, accumulators,
-            update = g * T.sqrt(d_a + self.epsilon) / T.sqrt(new_a + self.epsilon)
+            update = g * T.sqrt(d_a + self.epsilon) / T.sqrt(new_a +
-    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args, **kwargs):
+    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args,
-    return get_from_module(identifier, globals(), 'optimizer', instantiate=True, kwargs=kwargs)
+    return get_from_module(identifier, globals(), 'optimizer', instantiate=True,
-    def __init__(self, model, optimizer, loss):
+    def __init__(self, model, optimizer, loss,
-            validation_split=0, validation_data=None, callbacks=[]):
+    def fit(self, X, y):
-                                           callbacks=callbacks)
+        history = self.compiled_model_.fit(
-        super(KerasClassifier, self).__init__(model, optimizer, loss)
+    def __init__(self, model, optimizer='adam', loss='categorical_crossentropy', **kwargs):
-    def predict(self, X, batch_size=128, verbose=0):
+    def predict(self, X):
-        return self.compiled_model_.predict_classes(X, batch_size=batch_size, verbose=verbose)
+        return self.compiled_model_.predict_classes(
-    def predict_proba(self, X, batch_size=128, verbose=0):
+    def predict_proba(self, X):
-        return self.compiled_model_.predict_proba(X, batch_size=batch_size, verbose=verbose)
+        return self.compiled_model_.predict_proba(
-    def score(self, X, y, batch_size=128, verbose=0):
+    def score(self, X, y):
-        loss, accuracy = self.compiled_model_.evaluate(X, y, batch_size=batch_size, show_accuracy=True, verbose=verbose)
+        loss, accuracy = self.compiled_model_.evaluate(
-        super(KerasRegressor, self).__init__(model, optimizer, loss)
+    def __init__(self, model, optimizer='adam', loss='mean_squared_error', **kwargs):
-    def predict(self, X, batch_size=128, verbose=0):
+    def predict(self, X):
-        return self.compiled_model_.predict(X, batch_size=batch_size, verbose=verbose).ravel()
+        return self.compiled_model_.predict(
-    def score(self, X, y, batch_size=128, verbose=0):
+    def score(self, X, y):
-        loss = self.compiled_model_.evaluate(X, y, batch_size=batch_size, show_accuracy=False, verbose=verbose)
+        loss = self.compiled_model_.evaluate(
-classifier = KerasClassifier(model)
+classifier = KerasClassifier(model, train_batch_size=batch_size, nb_epoch=nb_epoch)
-classifier.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch)
+classifier.fit(X_train, Y_train)
-regressor = KerasRegressor(model)
+regressor = KerasRegressor(model, train_batch_size=batch_size, nb_epoch=nb_epoch)
-regressor.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch)
+regressor.fit(X_train, y_train)
-                                    border_mode=(pad_x, pad_y))
+        if dnn.dnn_available():
-                                    subsample=self.subsample)
+            if border_mode == 'same':
-    def __init__(self, input_shape):
+    def __init__(self, input_shape, init='zero', weights=None):
-        self.alphas = shared_zeros(input_shape)
+        self.init = initializations.get(init)
-                "input_shape": self.input_shape}
+                "input_shape": self.input_shape,
-    def __init__(self, input_shape, alpha_init=0.2, beta_init=5.0):
+    def __init__(self, input_shape, alpha_init=0.2, beta_init=5.0, weights=None):
-        return self.compiled_model_.predict(X, batch_size=batch_size, verbose=verbose)
+        return self.compiled_model_.predict(X, batch_size=batch_size, verbose=verbose).ravel()
-y_test = np.random(1000)
+X_train = np.random.random((5000, 100))
-model.add(Dense(50, 10))
+model.add(Dense(50, 1))
-from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer
+from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder
-from keras.models import Sequential
+from keras.models import Sequential, model_from_config
-    autoencoder.get_config(verbose=1)
+
-            for k, v in connection_map:
+            for k, v in connection_map.items():
-from keras.wrappers.scikit_learn import KerasClassifier
+from keras.wrappers.scikit_learn import *
-nb_classes = 10
+nb_classes = 10
-# the data, shuffled and split between tran and test sets
+############################################
-X_test = X_test.reshape(10000,784)[:max_test_samples]
+X_train = X_train.reshape(60000, 784)[:max_train_samples]
-classifier.set_params(optimizer='sgd', loss='mse')
+classifier.set_params(optimizer='sgd', loss='binary_crossentropy')
-+ One layer JZS1 (128 HN) with 55 iterations = 99% train/test accuracy
++ One layer JZS1 (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs
-+ One layer JZS1 (128 HN) with 19 iterations = 99% train/test accuracy
++ One layer JZS1 (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs
-+ One layer JZS1 (128 HN) with 20 iterations = 99% train/test accuracy
++ One layer JZS1 (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs
-+ One layer JZS1 (128 HN) with 28 iterations = 99% train/test accuracy
++ One layer JZS1 (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs
-TRAINING_SIZE = 800000
+TRAINING_SIZE = 50000
-for i in xrange(TRAINING_SIZE):
+while len(questions) < TRAINING_SIZE:
-for iteration in range(1, 60):
+for iteration in range(1, 200):
-        print('â' if correct == guess else 'â', guess)
+        print(colors.ok + 'â' + colors.close if correct == guess else colors.fail + 'â' + colors.close, guess)
-                self.ouputs[name] = self.inputs[input]
+                self.outputs[name] = self.inputs[input]
-        self.input = ndim_tensor(len(self.input_shape))
+        self.input = ndim_tensor(len(self.input_shape) + 1)
-                mask = self.layers[-1].get_output_mask()
+            if hasattr(output, "get_output_mask"):
-        self.refs = defaultdict(int)
+    refs = defaultdict(int)
-    def __init__(self, width=1):
+    def __init__(self, pad=(1, 1)):
-        self.width = width
+        self.pad = pad
-        width = self.width
+        pad = self.pad
-        out_shape = (in_shape[0], in_shape[1], in_shape[2] + 2 * width, in_shape[3] + 2 * width)
+        out_shape = (in_shape[0], in_shape[1], in_shape[2] + 2 * pad[0], in_shape[3] + 2 * pad[1])
-        indices = (slice(None), slice(None), slice(width, in_shape[2] + width), slice(width, in_shape[3] + width))
+        indices = (slice(None), slice(None), slice(pad[0], in_shape[2] + pad[0]), slice(pad[1], in_shape[3] + pad[1]))
-                "width": self.width}
+                "pad": self.pad}
-
+class MaxPooling1D(Layer):
-        super(UpSample2D,self).__init__()
+    def __init__(self, size=(2, 2)):
-
+        self.size = size
-        output = theano.tensor.extra_ops.repeat(Y, self.upsample_size[1], axis = 3)
+        Y = theano.tensor.extra_ops.repeat(X, self.size[0], axis=2)
-                "upsample_size":self.upsample_size}
+        return {"name": self.__class__.__name__,
-        output = theano.tensor.extra_ops.repeat(Y, self.upsample_size[1], axis = -1)
+        Y = theano.tensor.extra_ops.repeat(X, self.upsample_size[0], axis = 2)
-    return [(abs(hash(w))%(n-1)+1) for w in seq]
+    return [(abs(hash(w)) % (n - 1) + 1) for w in seq]
-        wcounts.sort(key = lambda x: x[1], reverse=True)
+        wcounts.sort(key=lambda x: x[1], reverse=True)
-        self.word_index = dict(list(zip(sorted_voc, list(range(0, len(sorted_voc))))))
+        self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))))
-            required before using sequences_to_matrix 
+            required before using sequences_to_matrix
-                nb_words = len(self.word_index)
+                nb_words = len(self.word_index) + 1
-                    X[i][j] = c/len(seq)
+                    X[i][j] = c / len(seq)
-                    df = (1 + np.log(1 + self.index_docs.get(j, 0)/(1 + self.document_count)))
+                    tf = np.log(c / len(seq))
-    
+
-class KerasClassifier(object):
+
-    Implementation of the scikit-learn classifier API for Keras.
+    Base class for the Keras scikit-learn wrapper.
-        Loss function used by the model during compilation/training.
+    Warning: This class should not be used directly. Use derived classes instead.
-    def __init__(self, model, optimizer='adam', loss='categorical_crossentropy'):
+    __metaclass__ = abc.ABCMeta
-    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=0, shuffle=True):
+    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=0, shuffle=True, show_accuracy=False,
-            Indicator to shuffle the training data.
+            Whether to shuffle the samples at each epoch.
-            Returns self.
+        history : object
-        self.compiled_model_.fit(X, y, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose, shuffle=shuffle)
+        history = self.compiled_model_.fit(X, y, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose,
-        return self
+        return history
-    def score(self, X, y, batch_size=128, verbose=0):
+
-        Returns the mean accuracy on the given test data and labels.
+        Returns the class predictions for the given test data.
-            Mean accuracy of self.predict(X) wrt. y.
+        preds : array-like, shape = (n_samples)
-        return accuracy
+        return self.compiled_model_.predict_classes(X, batch_size=batch_size, verbose=verbose)
-    def predict(self, X, batch_size=128, verbose=0):
+    def predict_proba(self, X, batch_size=128, verbose=0):
-        Returns the class predictions for the given test data.
+        Returns class probability estimates for the given test data.
-            Class predictions.
+        proba : array-like, shape = (n_samples, n_outputs)
-        return self.compiled_model_.predict_classes(X, batch_size=batch_size, verbose=verbose)
+        return self.compiled_model_.predict_proba(X, batch_size=batch_size, verbose=verbose)
-    def predict_proba(self, X, batch_size=128, verbose=0):
+    def score(self, X, y, batch_size=128, verbose=0):
-        Returns class probability estimates for the given test data.
+        Returns the mean accuracy on the given test data and labels.
-            Class probability estimates.
+        score : float
-        return self.compiled_model_.predict_proba(X, batch_size=batch_size, verbose=verbose)
+        loss, accuracy = self.compiled_model_.evaluate(X, y, batch_size=batch_size, show_accuracy=True, verbose=verbose)
-                mask_cost=False):
+    def compile(self, optimizer, loss, class_mode="categorical", theano_mode=None):
-        if mask_cost:
+        if hasattr(self.layers[-1], "get_output_mask"):
-    def compile(self, optimizer, loss, theano_mode=None, mask_cost=False):
+    def compile(self, optimizer, loss, theano_mode=None):
-                mask = None
+            if hasattr(self.layers[-1], "get_output_mask"):
-                mask = output.get_output_mask()
+                mask = None
-        return json.dump(config)
+        return json.dumps(config)
-    def compile(self, optimizer, loss, theano_mode=None):
+    def compile(self, optimizer, loss, theano_mode=None, mask_cost=False):
-            test_loss += weighted_loss(y, y_test, weight)
+            train_loss += weighted_loss(y, y_train, weight, mask)
-    if ndim == 2:
+    if ndim == 1:
-        metrics = self.output_order + ['val_' + m for m in self.output_order]
+        out_labels = ['loss']
-            conv_out = conv_out[:, :, shift_x:X.shape[2] + shift_x, shift_y:X.shape[3] + shift_y]
+            assert(self.subsample == (1, 1))
-        self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc)+1)))))
+        self.word_index = dict(list(zip(sorted_voc, list(range(0, len(sorted_voc))))))
-         [[1, 5], [5, 0], [0, 0], [0, 0]]], dtype=np.int32)
+class TestLossMasking(unittest.TestCase):
-    y = model.predict(X)
+        model = Sequential()
-    assert loss == 213.75
+        loss = model.fit(X, 4*y, nb_epoch=1, batch_size=2, verbose=1).history['loss'][0]
-    assert loss == 282.375
+        model = Sequential()
-        self.inputs[self.input_order[0]].set_previous(layer)
+    @property
-    def set_previous(self, layer):
+    def set_previous(self, layer, connection_map={}):
-            raise Exception("Attached non-masking layer to layer with masked output")
+            raise Exception("Cannot connect non-masking layer to layer with masked output")
-                raise Exception('Type "int" can only be used with ndim==2.')
+                raise Exception('Type "int" can only be used with ndim==2 (Embedding).')
-    def add_node(self, layer, name, input=None, inputs=[], merge_mode='concat'):
+    def add_node(self, layer, name, input=None, inputs=[], merge_mode='concat', create_output=False):
-                raise Exception('Unknown identifier: ' + input)
+                raise Exception('Unknown node/input identifier: ' + input)
-            raise Exception('Duplicate node identifier: ' + name)
+        if name in self.output_order:
-                raise Exception('Unknown identifier: ' + input)
+                raise Exception('Unknown node/input identifier: ' + input)
-        self.namespace.add(name)
+
-        if border_mode not in {'valid', 'full'}:
+        if border_mode not in {'valid', 'full', 'same'}:
-        conv_out = T.nnet.conv.conv2d(X, self.W, border_mode=self.border_mode, subsample=self.subsample)
+
-        return T.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)
+        output = T.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)
-
+                                      border_mode=border_mode,
-        std = std = T.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5
+        std = T.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5
-
+        self.updates = []
-        params, regularizers, constraints = layer.get_params()
+        params, regularizers, constraints, updates = layer.get_params()
-        layer = Layer() # empty layer
+        layer = Layer()  # empty layer
-        params, regularizers, constraints = layer.get_params()
+        layer.init_updates()
-        return self.params, regularizers, consts
+        if hasattr(self, 'updates') and self.updates:
-class Merge(object):
+class Merge(Layer):
-            params, regs, consts = l.get_params()
+            params, regs, consts, updates = l.get_params()
-        return self.params, self.regularizers, self.constraints
+        return self.params, self.regularizers, self.constraints, self.updates
-            params, regularizers, constraints = layer.get_params()
+            params, regularizers, constraints, updates = layer.get_params()
-from ..utils.theano_utils import shared_zeros
+from ..utils.theano_utils import shared_zeros, shared_ones, ndim_tensor
-        super(BatchNormalization,self).__init__()
+        super(BatchNormalization, self).__init__()
-
+    def init_updates(self):
-                X_normed = (X - self.running_mean) / (self.running_std + self.epsilon)
+            X_normed = (X - self.running_mean) / (self.running_std + self.epsilon)
-            "mode":self.mode}
+        return {"name": self.__class__.__name__,
-            "n": self.n}
+        return {"name": self.__class__.__name__,
-            updates=updates, allow_input_downcast=True, mode=theano_mode)
+        self._train = theano.function(train_ins, train_loss, updates=updates,
-            allow_input_downcast=True, mode=theano_mode)
+                                        allow_input_downcast=True, mode=theano_mode)
-            allow_input_downcast=True, mode=theano_mode)
+                                     allow_input_downcast=True, mode=theano_mode)
-            allow_input_downcast=True, mode=theano_mode)
+                                              allow_input_downcast=True, mode=theano_mode)
-            updates=updates, allow_input_downcast=True, mode=theano_mode)
+        self._train = theano.function(train_ins, train_loss, updates=updates,
-            allow_input_downcast=True, mode=theano_mode)
+                                     allow_input_downcast=True, mode=theano_mode)
-            allow_input_downcast=True, mode=theano_mode)
+                                        allow_input_downcast=True, mode=theano_mode)
-        self.input_shapes = [np.ones((10,10)), np.ones((10,10,10))]
+        self.input_shapes = [np.ones((10, 10)), np.ones((10, 10, 10))]
-        norm_m1 = normalization.BatchNormalization((10,10), mode=1)
+        norm_m0 = normalization.BatchNormalization((10, 10))
-        self.assertRaises(Exception,normalization.BatchNormalization((10,10),mode=3))
+        self.assertRaises(Exception, normalization.BatchNormalization((10, 10), mode=3))
-        self.assertAlmostEqual(out.std().eval(), 1.0, places=2)
+        model = Sequential()
-        self.assertAlmostEqual(norm_m0.running_std.eval(), np.arange(10).std(), places=2)
+        # centered on 5.0, variance 10.0
-        self.assertAlmostEqual(out.std().eval(), 0.0, places=2)
+        self.assertAlmostEqual(out.mean().eval(), 0.0, places=1)
-            out = (norm_m1.get_output(train=True) - norm_m1.beta)/norm_m1.gamma
+            out = (norm_m1.get_output(train=True) - norm_m1.beta) / norm_m1.gamma
-            out = (norm_m0.get_output(train=True) - norm_m0.beta)/norm_m0.gamma
+            out = (norm_m0.get_output(train=True) - norm_m0.beta) / norm_m0.gamma
-            out = (norm_m1.get_output(train=True) - norm_m1.beta)/norm_m1.gamma
+            out = (norm_m1.get_output(train=True) - norm_m1.beta) / norm_m1.gamma
-        norm_m1 = normalization.BatchNormalization((10,), mode=1, weights=[np.ones(10),np.ones(10)])
+        norm_m1 = normalization.BatchNormalization((10,), mode=1, weights=[np.ones(10), np.ones(10)])
-            out = (norm_m1.get_output(train=True) - np.ones(10))/1.
+            out = (norm_m1.get_output(train=True) - np.ones(10)) / 1.
-        self.assertRaises(Exception,normalization.BatchNormalization(10,), weights = np.ones(10))
+        assert_allclose(norm_m1.gamma.eval(), np.ones(10))
-        norm = normalization.BatchNormalization((10,10), mode=1, epsilon=0.1)
+        norm = normalization.BatchNormalization((10, 10), mode=1, epsilon=0.1)
-                       "epsilon":0.1, "mode": 1}
+        conf_target = {"input_shape": (10, 10), "name": normalization.BatchNormalization.__name__,
-        line = line.strip()
+        line = line.decode('utf-8').strip()
-vocab = sorted(reduce(lambda x, y: x | y, (set(story + q) for story, q, answer in train + test)))
+vocab = sorted(reduce(lambda x, y: x | y, (set(story + q + [answer]) for story, q, answer in train + test)))
-            self.st = (1, self.stride)
+            self.st = (self.stride, 1)
-        self.poolsize = (1, pool_length)
+        self.poolsize = (pool_length, 1)
-        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 1, 3, 2)
+        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 2, 1, 3)
-        output = output.dimshuffle(0, 1, 3, 2)
+        output = output.dimshuffle(0, 2, 1, 3)
-            raise Exception('class_weight not supported for 3+ dimensional targets.')
+        if len(y.shape) > 3:
-        return np.expand_dims(np.array(list(map(lambda x: class_weight[x], y_classes))), 1)
+        class_weights = np.asarray([class_weight[cls] for cls in y_classes])
-from six.moves.urllib.request import urlretrieve
+from six.moves.urllib.request import FancyURLopener
-        urlretrieve(origin, fpath, dl_progress)
+        ParanoidURLopener().retrieve(origin, fpath, dl_progress)
-#challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'
+# challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'
-#challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'
+# challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'
-#challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'
+# QA2 with 10,000 samples
-        for k, v in logs:
+        for k, v in logs.items():
-        r = requests.post(self.root + '/publish/epoch/end/', {'data': json.dumps(send)})
+        try:
-        for k, v in self.logs:
+        for k, v in logs:
-srng = RandomStreams(seed=np.random.randint(10e6))
+        self.srng = RandomStreams(seed=np.random.randint(10e6))
-                X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)
+                X *= self.srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)
-            for p, r in zip(params, regularizers):
+            self.regularizers += regularizers
-                    self.regularizers.append(r)
+                    self.constraints.append(c)
-from .core import srng, MaskedLayer
+import numpy as np
-                                   dtype=theano.config.floatX)
+            return X + self.srng.normal(size=X.shape, avg=0.0, std=self.sigma,
-            X *= srng.normal(size=X.shape, avg=1.0, std=T.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)
+            X *= self.srng.normal(size=X.shape, avg=1.0, std=T.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)
-        optimizer_params = config.get('optimizer')
+        optimizer_params = dict([(k, v) for k, v in config.get('optimizer').items()])
-                    epoch_logs = {}
+import copy
-def container_from_config(layer_dict):
+def container_from_config(original_layer_dict):
-This is essentially the IMDB test. Deserialized models should yield 
+This is essentially the IMDB test. Deserialized models should yield
-maxlen = 100 
+maxlen = 100
-model.add(LSTM(128, 128)) 
+model.add(LSTM(128, 128))
-    classification=False, output_shape=(4,))
+                                                     classification=False, output_shape=(4,))
-graph.compile('rmsprop', {'output1':'mse'})
+graph.compile('rmsprop', {'output1': 'mse'})
-original_pred = graph.predict({'input1':X_test})
+history = graph.fit({'input1': X_train, 'output1': y_train}, nb_epoch=10)
-new_pred = reloaded_graph.predict({'input1':X_test})
+reloaded_graph.compile('rmsprop', {'output1': 'mse'})
-assert(new_pred['output1'][3][1] == original_pred['output1'][3][1])
+assert(np.sum(new_pred['output1'] - original_pred['output1']) == 0)
-            p_t = p - self.lr * m_b_t / (T.sqrt(v_b_t) + self.epsilon)
+            lr_t = self.lr * T.sqrt(1-self.beta_2**t)/(1-self.beta_1**t)
-        t = self.iterations
+        t = self.iterations + 1
-        Reference: http://arxiv.org/abs/1412.6980
+        Reference: http://arxiv.org/abs/1412.6980v8
-        lambda is renamed kappa.
+        Default parameters follow those provided in the original paper.
-    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, kappa=1-1e-8, *args, **kwargs):
+    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args, **kwargs):
-        beta_2_t = self.beta_2 * (self.kappa**i)
+        t = self.iterations
-            v_t = (beta_2_t * v) + (1 - beta_2_t) * (g**2)
+            m_t = (self.beta_1 * m) + (1 - self.beta_1) * g
-            v_b_t = v_t / (1 - beta_2_t)
+            m_b_t = m_t / (1 - self.beta_1**t)
-                "kappa": self.kappa}
+                "epsilon": self.epsilon}
-            return (masked_weights.flatten() * obj_output.flatten()).sum() / mask.sum()
+            # We assume the time index to be masked is axis=1
-    assert loss == 285.0
+    assert loss == 282.375
-    def weighted(y_true, y_pred, weights):
+    def weighted(y_true, y_pred, weights, mask=None):
-        return (masked_weights.flatten() * obj_output.flatten()).mean()
+        if mask is None:
-    def compile(self, optimizer, loss, class_mode="categorical", theano_mode=None):
+    def compile(self, optimizer, loss, class_mode="categorical", theano_mode=None,
-        test_loss = weighted_loss(self.y, self.y_test, self.weights)
+        if mask_cost:
-    while creating an output mask in the process.
+    This layer copies the input to the output layer with identified padding
-    (nb_samples, timesteps).
+    This layer copies the input to the output layer,
-    mask is zero (skipped), otherwise it is 1.
+    At each timestep, if the values all equal `mask_value`,
-    def __init__(self, mask_value=0):
+    def __init__(self, mask_value=0.):
-        return T.any(T.ones_like(X) * (1 - T.eq(X, self.mask_value)), axis=-1)
+        return T.any(T.ones_like(X) * (1. - T.eq(X, self.mask_value)), axis=-1)
-                    mask_value=self.mask_value)
+        return {"name": self.__class__.__name__,
-        vertical_flip=False) # randomly flip images
+        featurewise_center=True,  # set input mean to 0 over the dataset
-np.random.seed(1337) # for reproducibility
+np.random.seed(1337)  # for reproducibility
-maxlen = 100 # cut texts after this number of words (among top max_features most common words)
+maxlen = 100  # cut texts after this number of words (among top max_features most common words)
-model.add(LSTM(128, 128)) # try using a GRU instead, for fun
+model.add(LSTM(128, 128))  # try using a GRU instead, for fun
-np.random.seed(1337) # for reproducibility
+np.random.seed(1337)  # for reproducibility
-        np.random.shuffle(X) # https://youtu.be/uyUXoap67N8
+        np.random.shuffle(X)  # https://youtu.be/uyUXoap67N8
-np.random.seed(1337) # for reproducibility
+np.random.seed(1337)  # for reproducibility
-np.random.seed(1337) # for reproducibility
+np.random.seed(1337)  # for reproducibility
-np.random.seed(1337) # for reproducibility
+np.random.seed(1337)  # for reproducibility
-np.random.seed(1337) # for reproducibility
+np.random.seed(1337)  # for reproducibility
-skip_top = 100 # ignore top 100 most common words
+max_features = 50000  # vocabulary size: top 50,000 most common words in data
-dim_proj = 256 # embedding space dimension
+dim_proj = 256  # embedding space dimension
-    "here", # hn, post, comments
+    "article",  # post, story, hn, read, comments
-                verbose=self.verbose)
+            self.progbar = Progbar(target=self.params['nb_sample'],
-                            % (epoch, self.monitor, self.best, current, self.filepath))
+                              % (epoch, self.monitor, self.best, current, self.filepath))
-    
+
-    return (X_train, y_train), (X_test, y_test) 
+    return (X_train, y_train), (X_test, y_test)
-    return (X_train, y_train), (X_test, y_test) 
+    return (X_train, y_train), (X_test, y_test)
-    start_char=1, oov_char=2, index_from=3):
+
-
+
-    return data # (X_train, y_train), (X_test, y_test)
+    return data  # (X_train, y_train), (X_test, y_test)
-                if topics and not '</D><D>' in topics:
+                if topics and '</D><D>' not in topics:
-    items.sort(key = lambda x: x[1])
+    items.sort(key=lambda x: x[1])
-    dataset = (X, labels) 
+    dataset = (X, labels)
-    start_char=1, oov_char=2, index_from=3):
+              start_char=1, oov_char=2, index_from=3):
-        self.node_config = [] # dicts
+        self.namespace = set()  # strings
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+                 init='uniform', activation='linear', weights=None,
-        conv_out = theano.tensor.nnet.conv.conv2d(X, self.W, border_mode=self.border_mode, subsample=self.subsample)
+        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 2, 1, 3)
-        return theano.tensor.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)
+        return T.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)
-        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.st, ignore_border=self.ignore_border)
+        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 1, 3, 2)
-        return theano.tensor.reshape(output, (output.shape[0], output.shape[1], output.shape[2]))
+        return T.reshape(output, (output.shape[0], output.shape[1], output.shape[2]))
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+                 init='glorot_uniform', activation='linear', weights=None,
-        conv_out = theano.tensor.nnet.conv.conv2d(X, self.W,
+        conv_out = T.nnet.conv.conv2d(X, self.W,
-        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)
+        output = T.signal.downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)
-        c = self.W_c[X[:, 1]] # nb_samples, proj_dim
+        w = self.W_w[X[:, 0]]  # nb_samples, proj_dim
-            mask = T.ones_like(X.sum(axis=-1)) # is there a better way to do this without a sum?
+            mask = T.ones_like(X.sum(axis=-1))  # is there a better way to do this without a sum?
-        mask = mask.dimshuffle(1, 0, 2) # (time, nb_samples, 1)
+        mask = T.shape_padright(mask)  # (nb_samples, time, 1)
-        X = self.get_input(train) # shape: (nb_samples, time (padded with zeros), input_dim)
+        X = self.get_input(train)  # shape: (nb_samples, time (padded with zeros), input_dim)
-            sequences=[x, dict(input=padded_mask, taps=[-1])], # tensors to iterate over, inputs to _step
+            self._step,  # this will be called with arguments (sequences[i], outputs[i-1], non_sequences[i])
-            non_sequences=self.U, # static inputs to _step
+            non_sequences=self.U,  # static inputs to _step
-                if batch_index == len(batches) - 1: # last batch
+                if batch_index == len(batches) - 1:  # last batch
-            v = self.momentum * m - lr * g # velocity
+            m = shared_zeros(p.get_value().shape)  # momentum
-            self.updates.append((p, c(new_p))) # apply constraints
+            self.updates.append((p, c(new_p)))  # apply constraints
-            new_a = self.rho * a + (1 - self.rho) * g ** 2 # update accumulator
+            new_a = self.rho * a + (1 - self.rho) * g ** 2  # update accumulator
-            self.updates.append((p, c(new_p))) # apply constraints
+            self.updates.append((p, c(new_p)))  # apply constraints
-            new_a = a + g ** 2 # update accumulator
+            new_a = a + g ** 2  # update accumulator
-            self.updates.append((p, c(new_p))) # apply constraints
+            self.updates.append((p, c(new_p)))  # apply constraints
-            new_a = self.rho * a + (1 - self.rho) * g ** 2 # update accumulator
+            new_a = self.rho * a + (1 - self.rho) * g ** 2  # update accumulator
-            self.updates.append((p, c(new_p))) # apply constraints
+            self.updates.append((p, c(new_p)))  # apply constraints
-            v = theano.shared(p.get_value() * 0.) # zero init of velocity
+            m = theano.shared(p.get_value() * 0.)  # zero init of moment
-            self.updates.append((p, c(p_t))) # apply constraints
+            self.updates.append((p, c(p_t)))  # apply constraints
-np.random.seed(1336) # for reproducibility
+np.random.seed(1336)  # for reproducibility
-    config.json.loads(json_string)
+    config = json.loads(json_string)
-        self.update = []
+        self.updates = []
-        return [u[0].get_value() for u in self.update]
+        return [u[0].get_value() for u in self.updates]
-        for u, v in zip(self.update, value_list):
+        assert len(self.updates) == len(value_list)
-        loss = objectives.get(config.get('loss'))
+        loss = config.get('loss')
-        for p in ['class_mode', 'theano_mode', 'loss']:
+        for p in ['class_mode', 'theano_mode']:
-def test_optimizer(optimizer, target=0.9):
+def _test_optimizer(optimizer, target=0.9):
-        self.assertTrue(test_optimizer(sgd))
+        self.assertTrue(_test_optimizer(sgd))
-        self.assertTrue(test_optimizer(RMSprop()))
+        self.assertTrue(_test_optimizer(RMSprop()))
-        self.assertTrue(test_optimizer(Adagrad()))
+        self.assertTrue(_test_optimizer(Adagrad()))
-        self.assertTrue(test_optimizer(Adadelta()))
+        self.assertTrue(_test_optimizer(Adadelta()))
-        self.assertTrue(test_optimizer(Adam()))
+        self.assertTrue(_test_optimizer(Adam()))
-    model_name = model_params.get('name')
+    config = yaml.load(yaml_string)
-    model = container_from_config(model_params)
+    model = container_from_config(config)
-    if 'optimizer' in model_params:
+    if 'optimizer' in config:
-        theano_mode = model_params.get('theano_mode')
+        loss = objectives.get(config.get('loss'))
-        optimizer_params = model_params.get('optimizer')
+        optimizer_params = config.get('optimizer')
-        self.loss = weighted_objective(objectives.get(loss))
+        self.loss = objectives.get(loss)
-        test_loss = self.loss(self.y, self.y_test, self.weights)
+        train_loss = weighted_loss(self.y, self.y_train, self.weights)
-        lookup.train(self.X1, np.array([[1], [0]], dtype='int32'))
+        lookup.train_on_batch(self.X1, np.array([[1], [0]], dtype='int32'))
-import keras.utils.model_utils as model_utils
+import keras.utils.layer_utils as layer_utils
-model_utils.print_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])
+layer_utils.print_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])
-    {'input1':(1, 32), 'input2':(1, 1, 28, 28)})
+layer_utils.print_layer_shapes(graph, {'input1': (1, 32), 'input2': (1, 1, 28, 28)})
-        input_shapes: A dict that gives a shape for each input to the Graph
+def print_layer_shapes(model, input_shapes):
-    Utility function that prints the shape of the output at each layer.
+    Utility function to print the shape of the output at each layer of a Model
-                     Either a tuple (for a single input) or a list of tuple
+        model: instance of Model / Merge
-                        " for other models")
+    if model.__class__.__name__ in ['Sequential', 'Merge']:
-                   for shape in input_shapes]
+        inputs = model.get_input(train=False)
-        print('shape after', l.get_config()['name'], ":", out_shape)
+    for l in layers:
-model_utils.print_model_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])
+model_utils.print_layer_shapes(model, [(1, 1, 28, 28), (1, 784)])
-model_utils.print_graph_layer_shapes(graph,
+model_utils.print_layer_shapes(graph,
-        self.assertTrue(history.history['val_loss'][-1] < 0.75)
+        self.assertTrue(history.history['val_loss'][-1] < 0.8)
-from .utils.theano_utils import shared_zeros, shared_scalar
+from .utils.theano_utils import shared_zeros, shared_scalar, floatX
-        self.__dict__.update(kwargs)
+        super(SGD, self).__init__(**kwargs)
-        updates = [(self.iterations, self.iterations + 1.)]
+        self.updates = [(self.iterations, self.iterations + 1.)]
-            updates.append((m, v))
+            self.updates.append((m, v))
-        return updates
+            self.updates.append((p, c(new_p))) # apply constraints
-        self.__dict__.update(kwargs)
+        super(RMSprop, self).__init__(**kwargs)
-        updates = []
+        self.updates = []
-            updates.append((a, new_a))
+            self.updates.append((a, new_a))
-        return updates
+            self.updates.append((p, c(new_p))) # apply constraints
-        self.__dict__.update(kwargs)
+        super(Adagrad, self).__init__(**kwargs)
-        updates = []
+        self.updates = []
-            updates.append((a, new_a))
+            self.updates.append((a, new_a))
-        return updates
+            self.updates.append((p, c(new_p))) # apply constraints
-        self.__dict__.update(kwargs)
+        super(Adadelta, self).__init__(**kwargs)
-        updates = []
+        self.updates = []
-            updates.append((a, new_a))
+            self.updates.append((a, new_a))
-            updates.append((p, c(new_p))) # apply constraints
+            self.updates.append((p, c(new_p))) # apply constraints
-        return updates
+            self.updates.append((d_a, new_d_a))
-        self.__dict__.update(kwargs)
+        super(Adam, self).__init__(**kwargs)
-        updates = [(self.iterations, self.iterations+1.)]
+        self.updates = [(self.iterations, self.iterations+1.)]
-        return updates
+            self.updates.append((m, m_t))
-    seq = text_to_word_sequence(text)
+    seq = text_to_word_sequence(text, filters=filters, lower=lower, split=split)
-def print_layer_shapes(model, input_shape):
+def print_model_layer_shapes(model, input_shapes):
-    print("input shape : ", input_shape)
+    # We allow the shortcut input_shapes=(1, 1, 28) instead of
-        out_shape = shape_f(input_tmp)
+        shape_f = theano.function(input_vars,
-    def test_on_batch(self, X, y, accuracy=False):
+    def test_on_batch(self, X, y, accuracy=False, sample_weight=None):
-        sample_weight = np.ones(y.shape[:-1] + (1,))
+        sample_weight = standardize_weights(y, sample_weight=sample_weight)
-from keras.models import Sequential
+from keras.models import Sequential, Graph
-def create_model():
+sample_weight = np.ones((y_train.shape[0])) * standard_weight
-def _test_weights(model, class_weight=None, sample_weight=None):
+def create_graph_model():
-        class_weight[weighted_class] = high_weight
+def _test_weights_graph(model, class_weight=None, sample_weight=None):
-        sample_weight[y_train == weighted_class] = high_weight
+class TestLossWeighting(unittest.TestCase):
-            model = create_model()
+            model = create_sequential_model()
-            standard_score = _test_weights(model)
+            standard_score = _test_weights_sequential(model)
-            model = create_model()
+            model = create_sequential_model()
-            score = _test_weights(model, class_weight=class_weight)
+            score = _test_weights_sequential(model, class_weight=class_weight)
-            model = create_model()
+            model = create_sequential_model()
-            score = _test_weights(model, sample_weight=sample_weight)
+            score = _test_weights_sequential(model, sample_weight=sample_weight)
-    def train(self, X, y, accuracy=False, sample_weight=None):
+    def train(self, X, y, accuracy=False, class_weight=None, sample_weight=None):
-        return self.train_on_batch(X, y, accuracy, sample_weight)
+        return self.train_on_batch(X, y, accuracy, class_weight, sample_weight)
-    def train_on_batch(self, X, y, accuracy=False, sample_weight=None):
+    def train_on_batch(self, X, y, accuracy=False, class_weight=None, sample_weight=None):
-            sample_weight = standardize_y(sample_weight)
+        sample_weight = standardize_weights(y, class_weight=class_weight, sample_weight=sample_weight)
-    def train_on_batch(self, data, sample_weight={}):
+    def train_on_batch(self, data, class_weight={}, sample_weight={}):
-
+        sample_weight = [standardize_weights(data[name],
-    def test_on_batch(self, data):
+    def test_on_batch(self, data, sample_weight={}):
-        sample_weight = [standardize_weights(data[name], sample_weight.get(name)) for name in self.output_order]
+            validation_split=0., validation_data=None, shuffle=True, class_weight={}, sample_weight={}):
-        loss = graph.test_on_batch({'input1': X_test, 'output1': y_test, 'output2': y2_test})
+        loss = graph.test_on_batch({'input1': X_test, 'output1': y_test, 'output2': y2_test},
-
+        weights = []
-            test_loss += objectives.get(loss_fn)(y, y_test).mean()
+            weight = T.ones_like(y_test)
-        test_ins = ins + ys
+        train_ins = ins + ys + weights
-    def train_on_batch(self, data):
+    def train_on_batch(self, data, sample_weight={}):
-        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order]
+        sample_weight = [standardize_weights(data[name], sample_weight.get(name)) for name in self.output_order]
-        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order]
+        sample_weight = [standardize_weights(data[name]) for name in self.output_order]
-        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order]
+            validation_split=0., validation_data=None, shuffle=True, sample_weight={}):
-            val_ins = [validation_data[name] for name in self.input_order] + [standardize_y(validation_data[name]) for name in self.output_order]
+            sample_weight = [standardize_weights(validation_data[name]) for name in self.output_order]
-        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order]
+    def evaluate(self, data, batch_size=128, verbose=0, sample_weight={}):
-    def __init__(self, input_shape):
+    def __init__(self, input_shape, alpha_init=0.2, beta_init=5.0):
-        self.betas = shared_scalars(input_shape, 5.0)
+        self.alpha_init = alpha_init
-            "input_shape":self.input_shape}
+            "input_shape":self.input_shape,
-from ..layers.core import Layer
+from ..layers.core import Layer, MaskedLayer
-class LeakyReLU(Layer):
+class LeakyReLU(MaskedLayer):
-class PReLU(Layer):
+class PReLU(MaskedLayer):
-class Psoftplus(Layer):
+class ParametricSoftplus(MaskedLayer):
-        Parametric softplus of the form: alpha * (1 + exp(beta * X))
+        Parametric Softplus of the form: alpha * (1 + exp(beta * X))
-        super(Psoftplus,self).__init__()
+        super(ParametricSoftplus,self).__init__()
-      install_requires = ['theano', 'pyyaml'],
+      install_requires = ['theano', 'pyyaml', 'h5py'],
-)
+)
-    layer.input = theano.shared(value=np.ones((10,10,10)))
+nb_samples, timesteps, input_dim, output_dim = 3, 3, 10, 5
-        mask = layer.get_output_mask(train)
+def _runner(layer_class):
-                recursive_runner(layer)
+        _runner(recurrent.SimpleRNN)
-                recursive_runner(layer)
+        _runner(recurrent.SimpleDeepRNN)
-                recursive_runner(layer)
+        _runner(recurrent.GRU)
-
+        _runner(recurrent.LSTM)
-                recursive_runner(layer)
+        _runner(recurrent.JZS1)
-                recursive_runner(layer)
+        _runner(recurrent.JZS2)
-                recursive_runner(layer)
+        _runner(recurrent.JZS3)
-        layer.get_output(train).eval()
+        out = layer.get_output(train).eval()
-                layer = recurrent.SimpleRNN(10, 5, return_sequences=rer_seq, weights=weights)
+            for ret_seq in [True, False]:
-                layer = recurrent.SimpleDeepRNN(10, 5, return_sequences=rer_seq, weights=weights)
+            for ret_seq in [True, False]:
-                layer = recurrent.GRU(10, 5, return_sequences=rer_seq, weights=weights)
+            for ret_seq in [True, False]:
-                layer = recurrent.LSTM(10, 5, return_sequences=rer_seq, weights=weights)
+            for ret_seq in [True, False]:
-                layer = recurrent.JZS1(10, 5, return_sequences=rer_seq, weights=weights)
+            for ret_seq in [True, False]:
-                layer = recurrent.JZS2(10, 5, return_sequences=rer_seq, weights=weights)
+            for ret_seq in [True, False]:
-                layer = recurrent.JZS3(10, 5, return_sequences=rer_seq, weights=weights)
+            for ret_seq in [True, False]:
-    from loading it in Python 3. You might have to load it in Python 2, 
+    from loading it in Python 3. You might have to load it in Python 2,
-model.add(Convolution2D(32, 3, 3, 3, border_mode='full')) 
+model.add(Convolution2D(32, 3, 3, 3, border_mode='full'))
-model.add(Convolution2D(64, 32, 3, 3, border_mode='full')) 
+model.add(Convolution2D(64, 32, 3, 3, border_mode='full'))
-model.add(Convolution2D(64, 64, 3, 3)) 
+model.add(Convolution2D(64, 64, 3, 3))
-    # compute quantities required for featurewise normalization 
+    # compute quantities required for featurewise normalization
-    The dataset is actually too small for LSTM to be of any advantage 
+    The dataset is actually too small for LSTM to be of any advantage
-    Notes: 
+    Notes:
-    choice of loss and optimizer is critical, etc. 
+    - RNNs are tricky. Choice of batch size is important,
-    from what you see with CNNs/MLPs/etc. 
+    - LSTM loss decrease patterns during training can be quite different
-model.add(Convolution2D(32, 1, 3, 3, border_mode='full')) 
+model.add(Convolution2D(32, 1, 3, 3, border_mode='full'))
-    We loop over words in a dataset, and for each word, we look at a context window around the word. 
+    We loop over words in a dataset, and for each word, we look at a context window around the word.
-    and demonstrate that the geometry of the embedding space 
+    We then use the weights computed by WordContextProduct to encode words
-    Read more about skip-gram in this particularly gnomic paper by Mikolov et al.: 
+    Read more about skip-gram in this particularly gnomic paper by Mikolov et al.:
-    Note: you should run this on GPU, otherwise training will be quite slow. 
+    Note: you should run this on GPU, otherwise training will be quite slow.
-        https://mega.co.nz/#F!YohlwD7R!wec0yNO86SeaNGIYQBOR0A 
+    Dataset: 5,845,908 Hacker News comments.
-        
+
-    if (not i) or (i<skip_top) or (i>=max_features):
+    if (not i) or (i < skip_top) or (i >= max_features):
-    return [(reverse_word_index.get(t[0]), t[1]) for t in tups[:nb_closest]]  
+    return [(reverse_word_index.get(t[0]), t[1]) for t in tups[:nb_closest]]
-    if (not i) or (i<skip_top) or (i>=max_features):
+    if (not i) or (i < skip_top) or (i >= max_features):
-''' the resuls in comments below were for: 
+''' the resuls in comments below were for:
-    and frequency subsampling of factor 10e-5. 
+    and frequency subsampling of factor 10e-5.
-"here", # hn, post, comments
+words = [
-
+
-import time, json
+
-class CallbackList(object):
+class CallbackList(object):
-            and delta_t_median > 0.1:
+        if self._delta_t_batch > 0. and delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1:
-                'to the batch update (%f). Check your callbacks.' % delta_t_median)
+                          'to the batch update (%f). Check your callbacks.' % delta_t_median)
-            and delta_t_median > 0.1:
+        if self._delta_t_batch > 0. and delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1:
-                'to the batch update (%f). Check your callbacks.' % delta_t_median)
+                          'to the batch update (%f). Check your callbacks.' % delta_t_median)
-class BaseLogger(Callback):
+class BaseLogger(Callback):
- 
+
-        r = requests.post(self.root + '/publish/epoch/end/', {'data':json.dumps(send)})
+        r = requests.post(self.root + '/publish/epoch/end/', {'data': json.dumps(send)})
-        return {"name":self.__class__.__name__}
+        return {"name": self.__class__.__name__}
-            "m":self.m}
+        return {"name": self.__class__.__name__,
-    return get_from_module(identifier, globals(), 'constraint', instantiate=True, kwargs=kwargs)
+    return get_from_module(identifier, globals(), 'constraint', instantiate=True, kwargs=kwargs)
-
+
-    
+
-    q = u if u.shape == flat_shape else v # pick the one with the correct shape
+    # pick the one with the correct shape
-        super(LeakyReLU,self).__init__()
+        super(LeakyReLU, self).__init__()
-            "alpha":self.alpha}
+        return {"name": self.__class__.__name__,
-        Reference: 
+        Reference:
-        super(PReLU,self).__init__()
+        super(PReLU, self).__init__()
-        "input_shape":self.input_shape}
+        return {"name": self.__class__.__name__,
-            "layers":[layer.get_config() for layer in self.layers]}
+        return {"name": self.__class__.__name__,
-        self.input_config.append({'name':name, 'ndim':ndim, 'dtype':dtype})
+        self.input_config.append({'name': name, 'ndim': ndim, 'dtype': dtype})
-        self.node_config.append({'name':name, 'input':input, 'inputs':inputs, 'merge_mode':merge_mode})
+        self.node_config.append({'name': name,
-        self.output_config.append({'name':name, 'input':input, 'inputs':inputs, 'merge_mode':merge_mode})
+        self.output_config.append({'name': name,
-            "nodes":dict([(c["name"], self.nodes[c["name"]].get_config()) for c in self.node_config])}
+        return {"name": self.__class__.__name__,
-        super(Convolution1D,self).__init__()
+        super(Convolution1D, self).__init__()
-            "b_constraint":self.b_constraint.get_config() if self.b_constraint else None}
+        return {"name": self.__class__.__name__,
-        super(MaxPooling1D,self).__init__()
+        super(MaxPooling1D, self).__init__()
-                "ignore_border":self.ignore_border,
+        return {"name": self.__class__.__name__,
-        super(Convolution2D,self).__init__()
+        super(Convolution2D, self).__init__()
-            "b_constraint":self.b_constraint.get_config() if self.b_constraint else None}
+        return {"name": self.__class__.__name__,
-        super(MaxPooling2D,self).__init__()
+        super(MaxPooling2D, self).__init__()
-                "ignore_border":self.ignore_border,
+        return {"name": self.__class__.__name__,
-        width =  self.width
+        width = self.width
-                "width":self.width}
+        return {"name": self.__class__.__name__,
-        return {"name":self.__class__.__name__}
+        return {"name": self.__class__.__name__}
-class Merge(object): 
+class Merge(object):
-                if not p in self.params:
+                if p not in self.params:
-        return res   
+        return res
-  
+        return {"name": self.__class__.__name__,
-            "p":self.p}
+        return {"name": self.__class__.__name__,
-            "beta":self.beta}
+        return {"name": self.__class__.__name__,
-            "dims":self.dims}
+        return {"name": self.__class__.__name__,
-        super(Permute,self).__init__()
+        super(Permute, self).__init__()
-            "dims":self.dims}
+        return {"name": self.__class__.__name__,
-            "n":self.n}
+        return {"name": self.__class__.__name__,
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,
-            "b_constraint":self.b_constraint.get_config() if self.b_constraint else None}
+        return {"name": self.__class__.__name__,
-            "l2":self.l2}
+        return {"name": self.__class__.__name__,
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None,
-            "b_constraint":self.b_constraint.get_config() if self.b_constraint else None}
+        return {"name": self.__class__.__name__,
-
+        return {"name": self.__class__.__name__,
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+    def __init__(self, input_dim, output_dim, nb_feature=4, init='glorot_uniform', weights=None,
-            "b_constraint":self.b_constraint.get_config() if self.b_constraint else None}
+        return {"name": self.__class__.__name__,
-        Turn positive integers (indexes) into denses vectors of fixed size. 
+        Turn positive integers (indexes) into denses vectors of fixed size.
-        mask_zero=False, weights=None):
+                 W_regularizer=None, activity_regularizer=None, W_constraint=None,
-        super(Embedding,self).__init__()
+        super(Embedding, self).__init__()
-            return T.ones_like(X) * (1 - T.eq(X,0))
+            return T.ones_like(X) * (1 - T.eq(X, 0))
-            "W_constraint":self.W_constraint.get_config() if self.W_constraint else None}
+        return {"name": self.__class__.__name__,
-        This layer turns a pair of words (a pivot word + a context word, 
+        This layer turns a pair of words (a pivot word + a context word,
-        which can be trained to encode the probability 
+        which can be trained to encode the probability
-        super(WordContextProduct,self).__init__()
+    def __init__(self, input_dim, proj_dim=128,
-
+        return {"name": self.__class__.__name__,
-                             dtype=theano.config.floatX)
+                                   dtype=theano.config.floatX)
-            "sigma":self.sigma}
+        return {"name": self.__class__.__name__,
-        Reference: 
+        Reference:
-        super(GaussianDropout,self).__init__()
+        super(GaussianDropout, self).__init__()
-            "p":self.p}
+        return {"name": self.__class__.__name__,
-        included for demonstration purposes 
+        Not a particularly useful model,
-        truncate_gradient=-1, return_sequences=False):
+    def __init__(self, input_dim, output_dim,
-        super(SimpleRNN,self).__init__()
+        super(SimpleRNN, self).__init__()
-            Variable names follow the conventions from: 
+            Variable names follow the conventions from:
-        X = X.dimshuffle((1, 0, 2)) 
+        X = X.dimshuffle((1, 0, 2))
-        
+
-        )
+            truncate_gradient=self.truncate_gradient)
-            "return_sequences":self.return_sequences}
+        return {"name": self.__class__.__name__,
-        Fully connected RNN where the output of multiple timesteps 
+        Fully connected RNN where the output of multiple timesteps
-        This demonstrates how to build RNNs with arbitrary lookback. 
+        This demonstrates how to build RNNs with arbitrary lookback.
-        weights=None, truncate_gradient=-1, return_sequences=False):
+                 init='glorot_uniform', inner_init='orthogonal',
-        super(SimpleDeepRNN,self).__init__()
+        super(SimpleDeepRNN, self).__init__()
-        X = X.dimshuffle((1, 0, 2)) 
+        X = X.dimshuffle((1, 0, 2))
-        
+
-                taps = [(-i) for i in range(self.depth)]
+                input=padded_mask,
-                taps = [(-i-1) for i in range(self.depth)]
+                initial=initial,
-            "return_sequences":self.return_sequences}
+        return {"name": self.__class__.__name__,
-        weights=None, truncate_gradient=-1, return_sequences=False):
+    def __init__(self, input_dim, output_dim=128,
-        super(GRU,self).__init__()
+        super(GRU, self).__init__()
-        self.W_h = self.init((self.input_dim, self.output_dim)) 
+        self.W_h = self.init((self.input_dim, self.output_dim))
-        u_z, u_r, u_h):
+    def _step(self,
-        X = self.get_input(train) 
+        X = self.get_input(train)
-        X = X.dimshuffle((1, 0, 2)) 
+        X = X.dimshuffle((1, 0, 2))
-            sequences=[x_z, x_r, x_h, padded_mask], 
+            self._step,
-        )
+            truncate_gradient=self.truncate_gradient)
-
+        return {"name": self.__class__.__name__,
-        super(LSTM,self).__init__()
+    def __init__(self, input_dim, output_dim=128,
-        u_i, u_f, u_o, u_c): 
+    def _step(self,
-        X = self.get_input(train) 
+        X = self.get_input(train)
-        
+
-            self._step, 
+            self._step,
-        )
+            ],
-
+        return {"name": self.__class__.__name__,
-        
+
-        
+
-        
+
-        
+
-        weights=None, truncate_gradient=-1, return_sequences=False):
+    def __init__(self, input_dim, output_dim=128,
-        super(JZS1,self).__init__()
+        super(JZS1, self).__init__()
-        u_r, u_h):
+    def _step(self,
-        X = self.get_input(train) 
+        X = self.get_input(train)
-            self._step, 
+            self._step,
-        )
+            truncate_gradient=self.truncate_gradient)
-
+        return {"name": self.__class__.__name__,
-        
+
-        
+
-        
+
-        
+
-        weights=None, truncate_gradient=-1, return_sequences=False):
+    def __init__(self, input_dim, output_dim=128,
-        super(JZS2,self).__init__()
+        super(JZS2, self).__init__()
-        u_z, u_r, u_h):
+    def _step(self,
-        X = X.dimshuffle((1, 0, 2)) 
+        X = X.dimshuffle((1, 0, 2))
-            self._step, 
+            self._step,
-        )
+            truncate_gradient=self.truncate_gradient)
-
+        return {"name": self.__class__.__name__,
-        
+
-        
+
-        
+
-        
+
-        weights=None, truncate_gradient=-1, return_sequences=False):
+    def __init__(self, input_dim, output_dim=128,
-        super(JZS3,self).__init__()
+        super(JZS3, self).__init__()
-        u_z, u_r, u_h):
+    def _step(self,
-        X = X.dimshuffle((1, 0, 2)) 
+        X = X.dimshuffle((1, 0, 2))
-            self._step, 
+            self._step,
-
+        return {"name": self.__class__.__name__,
-import warnings, time, copy, yaml
+import warnings, time, copy, pprint
-import time, copy, pprint
+
-    if not model_name in {'Graph', 'Sequential'}:
+    if model_name not in {'Graph', 'Sequential'}:
-    model.__class__ = get(model_name)
+    if model_name == 'Graph':
-    if 'optimizer' in model_params: # if it has an optimizer, the model is assumed to be compiled
+    if 'optimizer' in model_params:
-        validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):
+    def _fit(self, f, ins, out_labels=[], batch_size=128, nb_epoch=100, verbose=1, callbacks=[],
-            'metrics':metrics,
+            'metrics': metrics,
-                
+
-            - add 
+            - add
-
+        return self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,
-        '''
+        # dump model configuration to yaml string
-            
+
-        self._train = theano.function(train_ins, train_loss, 
+        self._train = theano.function(train_ins, train_loss,
-        self._test = theano.function(test_ins, test_loss, 
+        self._test = theano.function(test_ins, test_loss,
-        self._predict = theano.function(inputs=ins, outputs=ys_test, 
+        self._predict = theano.function(inputs=ins, outputs=ys_test,
-            validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle, metrics=metrics)
+        history = self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,
-        '''
+        # dump model configuration to yaml string
-    return get_from_module(identifier, globals(), 'model')
+
-    y_pred /= y_pred.sum(axis=-1, keepdims=True) 
+    y_pred /= y_pred.sum(axis=-1, keepdims=True)
-
+
-        return {"name":self.__class__.__name__}
+        return {"name": self.__class__.__name__}
-            updates.append((m, v)) 
+            updates.append((m, v))
-            "nesterov":self.nesterov}
+        return {"name": self.__class__.__name__,
-            "epsilon":self.epsilon}
+        return {"name": self.__class__.__name__,
-class Adagrad(Optimizer):
+class Adagrad(Optimizer):
-            "epsilon":self.epsilon}
+        return {"name": self.__class__.__name__,
-            "epsilon":self.epsilon}
+        return {"name": self.__class__.__name__,
-        beta_2_t = self.beta_2 * (self.kappa**i) 
+        beta_2_t = self.beta_2 * (self.kappa**i)
-            
+
-            "kappa":self.kappa}
+        return {"name": self.__class__.__name__,
-        return {"name":self.__class__.__name__}
+        return {"name": self.__class__.__name__}
-            "l2":self.l2}
+        return {"name": self.__class__.__name__,
-    
+
-            "l2":self.l2}
+        return {"name": self.__class__.__name__,
-            printv(nv, prefix) 
+            printv(nv, prefix)
-                self.sum_values[k] = [v * (current-self.seen_so_far), current-self.seen_so_far]
+                self.sum_values[k] = [v * (current - self.seen_so_far), current - self.seen_so_far]
-                self.sum_values[k][1] += (current-self.seen_so_far)
+                self.sum_values[k][0] += v * (current - self.seen_so_far)
-            
+
-                info += ' - %s: %.4f' % (k, self.sum_values[k][0]/ max(1, self.sum_values[k][1]))
+                info += ' - %s: %.4f' % (k, self.sum_values[k][0] / max(1, self.sum_values[k][1]))
-                    info += ' - %s: %.4f' % (k, self.sum_values[k][0]/ max(1, self.sum_values[k][1]))
+                    info += ' - %s: %.4f' % (k, self.sum_values[k][0] / max(1, self.sum_values[k][1]))
-    refs = defaultdict(int)
+
-    
+
-    a[:]=array[:]
+    a = np.empty(shape=array.shape, dtype=array.dtype)
-    else: # The case in which layer_dict represents an "atomic" layer
+    else:
-        	# For now, this can only happen for regularizers and constraints
+            # For now, this can only happen for regularizers and constraints
-                
+                if vname in [x for x, y in inspect.getmembers(constraints, predicate=inspect.isclass)]:
-    return get_from_module(identifier, globals(), 'layer', instantiate=True, kwargs=kwargs)
+    return get_from_module(identifier, globals(), 'layer', instantiate=True, kwargs=kwargs)
-    l2[l2==0] = 1
+    l2[l2 == 0] = 1
-    res = sum(y*sp.log(p) + sp.subtract(1,y)*sp.log(sp.subtract(1,p)))
+    res = sum(y * sp.log(p) + sp.subtract(1, y) * sp.log(sp.subtract(1, p)))
-    score = -(1./len(Y)) * np.sum(np.log(npreds))
+    score = -(1. / len(Y)) * np.sum(np.log(npreds))
-    return np.mean([a==b for a, b in zip(p, y)])
+    return np.mean([a == b for a, b in zip(p, y)])
-    classification=True, nb_class=2):
+
-        (i.e. output_shape is set to (1,)) and the output 
+        classification=True overrides output_shape
-)
+setup(name='Keras',
-class TestConcatenation(unittest.TestCase):
+class TestEmbedding(unittest.TestCase):
-    unittest.main()
+    unittest.main()
-    classification=False, output_shape=(4,))
+                                                     classification=False, output_shape=(4,))
-    classification=False, output_shape=(1,))
+                                                         classification=False, output_shape=(1,))
-        graph.compile('rmsprop', {'output1':'mse'})
+        graph.compile('rmsprop', {'output1': 'mse'})
-        out = graph.predict({'input1':X_test})
+        history = graph.fit({'input1': X_train, 'output1': y_train}, nb_epoch=10)
-        loss = graph.evaluate({'input1':X_test, 'output1':y_test})
+        loss = graph.test_on_batch({'input1': X_test, 'output1': y_test})
-        graph.compile('rmsprop', {'output1':'mse'})
+        graph.compile('rmsprop', {'output1': 'mse'})
-        out = graph.predict({'input1':X_train})
+        history = graph.fit({'input1': X_train, 'output1': y_train}, nb_epoch=10)
-        loss = graph.evaluate({'input1':X_test, 'output1':y_test})
+        loss = graph.test_on_batch({'input1': X_test, 'output1': y_test})
-        graph.compile('rmsprop', {'output1':'mse'})
+        graph.compile('rmsprop', {'output1': 'mse'})
-        out = graph.predict({'input1':X_test, 'input2':X2_test})
+        history = graph.fit({'input1': X_train, 'input2': X2_train, 'output1': y_train}, nb_epoch=10)
-        loss = graph.evaluate({'input1':X_test, 'input2':X2_test, 'output1':y_test})
+        loss = graph.test_on_batch({'input1': X_test, 'input2': X2_test, 'output1': y_test})
-        graph.compile('rmsprop', {'output1':'mse', 'output2':'mse'})
+        graph.compile('rmsprop', {'output1': 'mse', 'output2': 'mse'})
-        out = graph.predict({'input1':X_test})
+        history = graph.fit({'input1': X_train, 'output1': y_train, 'output2': y2_train}, nb_epoch=10)
-        loss = graph.evaluate({'input1':X_test, 'output1':y_test, 'output2':y2_test})
+        loss = graph.test_on_batch({'input1': X_test, 'output1': y_test, 'output2': y2_test})
-        graph.compile('rmsprop', {'output1':'mse', 'output2':'mse'})
+        graph.compile('rmsprop', {'output1': 'mse', 'output2': 'mse'})
-        nloss = graph.evaluate({'input1':X_test, 'output1':y_test, 'output2':y2_test})
+        nloss = graph.evaluate({'input1': X_test, 'output1': y_test, 'output2': y2_test})
-    unittest.main()
+    unittest.main()
-        class_weight=class_weight, sample_weight=sample_weight)
+    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0,
-class TestConcatenation(unittest.TestCase):
+class TestConcatenation(unittest.TestCase):
-    unittest.main()
+    unittest.main()
-    classification=True, nb_class=4)
+                                                     classification=True, nb_class=4)
-
+
-            classification=True, nb_class=2)
+                                                             classification=True, nb_class=2)
-            classification=False)
+                                                             classification=False)
-            classification=True, nb_class=2)
+                                                             classification=True, nb_class=2)
-            classification=False)
+                                                             classification=False)
-            classification=False)
+                                                             classification=False)
-            classification=True, nb_class=2)
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(3, 32, 32),
-    unittest.main()
+    unittest.main()
-	return autoencoder, X_train, X_test
+    X_train = X_train[:, np.newaxis, :]
-	return autoencoder
+    # The TimeDistributedDense isn't really necessary, however you need a lot of GPU memory to do 784x394-394x784
-
+    print(autoencoder_type)
-                        'If using HDF5 input data, pass shuffle=\'batch\'.\n')
+                    print('TypeError while preparing batch. \
-from ..utils.theano_utils import shared_zeros, shared_ones
+from ..utils.theano_utils import shared_zeros, shared_ones, shared_scalars
-        self.betas = shared_ones(input_shape)
+        self.alphas = shared_scalars(input_shape, 0.2)
-            "input_shape":self.input_shape}
+            "input_shape":self.input_shape}
-from ..utils.theano_utils import shared_zeros
+from ..utils.theano_utils import shared_zeros, shared_ones
-            return i
+def sample(a, temperature=1.0):
-    for diversity in [0.2, 0.4, 0.6, 0.8]:
+    for diversity in [0.2, 0.5, 1.0, 1.2]:
-        print()
+        print()
-                ins_batch = slice_X(ins, batch_ids)
+                try:
-        return X.dimshuffle(self.dims)
+        return X.dimshuffle((0,) + self.dims)
-      version = '0.1.1',
+      version = '0.1.2',
-      download_url = 'https://github.com/fchollet/keras/tarball/0.1.1',
+      download_url = 'https://github.com/fchollet/keras/tarball/0.1.2',
-        return output
+            shift_x = (self.nb_row - 1) // 2
-        return graph_config
+            "output_config":self.output_config,
-        return merge_conf     
+  
-from .utils.layer_utils import container_from_yaml
+from .utils.layer_utils import container_from_config
-    model = container_from_yaml(model_params)
+    model = container_from_config(model_params)
-    def to_yaml(self, store_params=True):
+    def to_yaml(self):
-        model_params = super(Sequential, self).to_yaml(store_params)
+        model_params = self.get_config()
-    def to_yaml(self, store_params=True):
+    def to_yaml(self):
-        model_params = super(Graph, self).to_yaml(store_params)
+        model_params = self.get_config()
-def container_from_yaml(layer_dict):
+def container_from_config(layer_dict):
-            init_layer = container_from_yaml(layer)
+            init_layer = container_from_config(layer)
-            init_layer = container_from_yaml(layer)
+            init_layer = container_from_config(layer)
-        inputs = layer_dict.get('inputs')
+        inputs = layer_dict.get('input_config')
-        nodes = layer_dict.get('nodes')
+        nodes = layer_dict.get('node_config')
-            layer = container_from_yaml(layer_conf)
+            layer = container_from_config(layer_dict['nodes'].get(node['name']))
-        outputs = layer_dict.get('outputs')
+        outputs = layer_dict.get('output_config')
-yaml_no_params = model.to_yaml(store_params=False)
+yaml_no_params = model.to_yaml()
-merge_yaml = seq.to_yaml(store_params=False)
+merge_yaml = seq.to_yaml()
-large_model.to_yaml(store_params=False)
+large_model.to_yaml()
-graph_yaml = graph.to_yaml(store_params=True)
+graph_yaml = graph.to_yaml()
-print(new_pred['output1'][3][1] == original_pred['output1'][3][1])
+assert(new_pred['output1'][3][1] == original_pred['output1'][3][1])
-    def layer_to_yaml(self, store_params=True):
+    def to_yaml(self, store_params=True):
-            layer_conf = layer.layer_to_yaml(store_params)
+            layer_conf = layer.to_yaml(store_params)
-    def layer_to_yaml(self, store_params=True):
+    def to_yaml(self, store_params=True):
-            layer_conf = layer.layer_to_yaml(store_params)
+            layer_conf = layer.to_yaml(store_params)
-    def layer_to_yaml(self, store_params=True):
+    def to_yaml(self, store_params=True):
-    def layer_to_yaml(self, store_params=True):
+    def to_yaml(self, store_params=True):
-            layer_conf = layer.layer_to_yaml(store_params)
+            layer_conf = layer.to_yaml(store_params)
-from .utils.layer_utils import from_yaml
+from .utils.layer_utils import container_from_yaml
-    model = from_yaml(model_dict)
+    model_params = yaml.load(yaml_string)
-        theano_mode = model_dict.get('theano_mode')
+    if 'optimizer' in model_params: # if it has an optimizer, the model is assumed to be compiled
-        model.compile(loss=loss, optimizer=optimizer, class_mode=class_mode, theano_mode=theano_mode)
+        optimizer_params = model_params.get('optimizer')
-            If the model is compiled, it will also serialize the necessary components 
+            If the model is compiled, it will also serialize the necessary components
-        model_dict = self.layer_to_yaml(store_params)    
+        model_params = super(Sequential, self).to_yaml(store_params)
-        return yaml.dump(model_dict)
+            model_params['class_mode'] = self.class_mode
-    def compile(self, optimizer, loss, theano_mode=None, class_mode=None):
+    def compile(self, optimizer, loss, theano_mode=None):
-            If the model is compiled, it will also serialize the necessary components 
+            If the model is compiled, it will also serialize the necessary components
-        model_dict = self.layer_to_yaml(store_params)    
+        model_params = super(Graph, self).to_yaml(store_params)
-        return yaml.dump(model_dict)
+            model_params['theano_mode'] = self.theano_mode
-        g = T.switch(T.ge(n, c), g*c/n, g)
+        g = T.switch(T.ge(n, c), g * c / n, g)
-    return p_hat - p + p*T.log(p/p_hat)
+    return p_hat - p + p * T.log(p / p_hat)
-            norm = T.sqrt(sum([T.sum(g**2) for g in grads]))
+            norm = T.sqrt(sum([T.sum(g ** 2) for g in grads]))
-        updates = [(self.iterations, self.iterations+1.)]
+        updates = [(self.iterations, self.iterations + 1.)]
-def from_yaml(layer_dict):
+def container_from_yaml(layer_dict):
-            init_layer = from_yaml(layer)
+            init_layer = container_from_yaml(layer)
-            init_layer = from_yaml(layer)
+            init_layer = container_from_yaml(layer)
-            layer = from_yaml(layer_conf)
+            layer = container_from_yaml(layer_conf)
-        if layer_dict.has_key('parameters'):
+        if 'parameters' in layer_dict:
-        for k, v in layer_dict.iteritems():
+
-                #layer_dict[k] = globals()[vname](**v)
+                
-      install_requires = ['theano'],
+      install_requires = ['theano', 'pyyaml'],
-        super(Convolution1D,self).__init__()
+        if border_mode not in {'valid', 'full'}:
-                                    # output will be bigger but then we crop from it
+        border_mode = self.border_mode
-            border_mode=temp_mode, subsample=self.subsample)
+            border_mode=border_mode, subsample=self.subsample)
-
+            clip_row = (self.nb_row - 1) // 2
-# class MaxPooling3D: TODO
+        temp_mode = self.border_mode
-            border_mode=self.border_mode, subsample=self.subsample)
+            border_mode=temp_mode, subsample=self.subsample)
-        self.progbar.update(self.seen, self.log_values)
+        if self.verbose:
-    def get_updates(self, params, regularizers, constraints,  loss):
+    def get_updates(self, params, constraints, loss):
-        assert(loss < 1.4)
+        assert(loss < 2.5)
-        assert(loss < 1.4)
+        assert(loss < 2.5)
-        assert(loss < 1.4)
+        assert(loss < 3.0)
-        assert(loss < 2.7)
+        assert(loss < 4.)
-        assert(loss < 1.4)
+        assert(loss < 2.5)
-from keras.layers.core import Dense, Dropout, Activation
+from keras.models import Sequential, Graph
-from keras.models import sequential_from_yaml
+from keras.models import model_from_yaml
-model.add(Dense(128, 1))
+model.add(Dense(128, 1, W_regularizer='identity', b_constraint='maxnorm'))
-model.compile(loss='binary_crossentropy', optimizer='adam', class_mode="binary")
+#model.compile(loss='binary_crossentropy', optimizer='adam', class_mode="binary")
-yamlString = model.to_yaml()
+#yaml_string = model.to_yaml()
-recovered_model.get_config(verbose=1)
+#recovered_model = model_from_yaml(yaml_string)
-yaml_no_params = model.to_yaml(storeParams=False)
+yaml_no_params = model.to_yaml(store_params=False)
-no_param_model.get_config(verbose=1)
+no_param_model = model_from_yaml(yaml_no_params)
-def get_from_module(identifier, module_params, module_name, instantiate=False):
+def get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None):
-        if instantiate:
+        if instantiate and not kwargs:
-    return get_from_module(identifier, globals(), 'regularizer', instantiate=True)
+def get(identifier, kwargs=None):
-    return get_from_module(identifier, globals(), 'optimizer', instantiate=True)
+def get(identifier, kwargs=None):
-
+
-def sequential_from_yaml(yaml_string):
+def model_from_yaml(yaml_string):
-        which is either created by hand or from Sequential.to_yaml
+        Returns a model generated from a local yaml file,
-    model.compile(loss=loss, optimizer=optimizer, class_mode=class_mode, theano_mode=theano_mode)
+    model_dict = yaml.load(yaml_string)
-            Stores compiled Sequential model to yaml string, optionally storing all learnable parameters
+            Stores a model to yaml string, optionally with all learnable parameters
-
+        model_dict = self.layer_to_yaml(store_params)    
-    def compile(self, optimizer, loss, theano_mode=None):
+    def compile(self, optimizer, loss, theano_mode=None, class_mode=None):
-
+    def layer_to_yaml(self, store_params=True):
-        return res
+        return res   
-        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers.append(self.W_regularizer)
+        if self.W_regularizer:
-        self.regularizers.append(self.b_regularizer)
+        if self.b_regularizer:
-        self.regularizers.append(self.activity_regularizer)
+        if self.activity_regularizer:
-            "b_constraint":self.b_constraint.get_config()}
+            "W_regularizer":self.W_regularizer.get_config() if self.W_regularizer else None,
-        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers.append(self.W_regularizer)
+        if self.W_regularizer:
-        self.regularizers.append(self.b_regularizer)
+        if self.b_regularizer:
-        self.regularizers.append(self.activity_regularizer)
+        if self.activity_regularizer:
-            "b_constraint":self.b_constraint.get_config()}
+            "W_regularizer":self.W_regularizer.get_config() if self.W_regularizer else None,
-        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers.append(self.W_regularizer)
+        if self.W_regularizer:
-        self.regularizers.append(self.b_regularizer)
+        if self.b_regularizer:
-        self.regularizers.append(self.activity_regularizer)
+        if self.activity_regularizer:
-            "b_constraint":self.b_constraint.get_config()}
+            "W_regularizer":self.W_regularizer.get_config() if self.W_regularizer else None,
-        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers.append(self.W_regularizer)
+        if self.W_regularizer:
-        self.regularizers.append(self.b_regularizer)
+        if self.b_regularizer:
-        self.regularizers.append(self.activity_regularizer)
+        if self.activity_regularizer:
-            "b_constraint":self.b_constraint.get_config()}
+            "W_regularizer":self.W_regularizer.get_config() if self.W_regularizer else None,
-        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers.append(self.W_regularizer)
+        if self.W_regularizer:
-        self.regularizers.append(self.b_regularizer)
+        if self.b_regularizer:
-        self.regularizers.append(self.activity_regularizer)
+        if self.activity_regularizer:
-            "b_constraint":self.b_constraint.get_config()}
+            "W_regularizer":self.W_regularizer.get_config() if self.W_regularizer else None,
-        W_regularizer='identity', activity_regularizer='identity', W_constraint='identity',
+        W_regularizer=None, activity_regularizer=None, W_constraint=None,
-        self.regularizers.append(self.W_regularizer)
+        if self.W_regularizer:
-        self.regularizers.append(self.activity_regularizer)
+        if self.activity_regularizer:
-            "W_constraint":self.W_constraint.get_config()}
+            "activity_regularizer":self.activity_regularizer.get_config() if self.activity_regularizer else None,
-        self.output_config.append({'name':name, 'ndim':ndim, 'dtype':dtype})
+        self.input_config.append({'name':name, 'ndim':ndim, 'dtype':dtype})
-
+    
-    return get_from_module(identifier, globals(), 'constraint', instantiate=True)
+def get(identifier, kwargs=None):
-    def __init__(self, encoder, decoder, output_reconstruction=True, tie_weights=False, weights=None):
+    def __init__(self, encoder, decoder, output_reconstruction=True, weights=None):
-                self.constraints += layer.constraints
+            params, regularizers, constraints = layer.get_params()
-        return decoded
+        return self.decoder.get_output(train)
-                "tie_weights":self.tie_weights}
+                "output_reconstruction":self.output_reconstruction}
-from keras.layers.core import DenoisingAutoEncoder, AutoEncoder, Dense, Activation, TimeDistributedDense, Flatten
+from keras.layers.core import AutoEncoder, Dense, Activation, TimeDistributedDense, Flatten
-								output_reconstruction=False, tie_weights=True))
+								output_reconstruction=False))
-	autoencoder.add(DenoisingAutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=False, tie_weights=True))
+	autoencoder.add(AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=False))
-for autoencoder_type in ['classical', 'denoising', 'deep_denoising', 'lstm']:
+for autoencoder_type in ['classical', 'lstm']:
-	    autoencoder = build_deep_denoising_autoencoder(autoencoder)
+'''
-batch_size = 10
+batch_size = 32
-nb_epochs = 10
+nb_epoch = 3
-output_size = nb_filters * (((maxlen - filter_length)/1)+1)/2
+# for a good tutorial, see: http://cs231n.github.io/convolutional-networks/
-model.add(Dropout(0.5))
+model.add(Dropout(0.25))
-    print('\t- Test accuracy:', acc)
+model.compile(loss='binary_crossentropy', optimizer='rmsprop', class_mode="binary")
-            s = open(path + fname).read()
+            s = open(os.path.join(path, fname)).read()
-    six.moves.cPickle.dump(tokenizer.word_index, open(os.path.join('datasets','data', 'reuters_word_index.pkl'), 'w'))
+    six.moves.cPickle.dump(tokenizer.word_index, open(os.path.join('datasets', 'data', 'reuters_word_index.pkl'), 'w'))
-            if shuffle:
+            if shuffle == 'batch':
-    def to_yaml(self, storeParams=True):
+    def to_yaml(self, store_params=True):
-        modelDict['optimizer'] = self.optimizer.get_config()
+        model_dict = {}
-        modelDict['layers'] = layers
+            layer_conf = layer.get_config()
-        return yaml.dump(modelDict)
+        return yaml.dump(model_dict)
-def sequential_from_yaml(yamlString):
+def sequential_from_yaml(yaml_string):
-    modelYaml = yaml.load(yamlString)
+    model_yaml = yaml.load(yaml_string)
-    loss = globals()[modelYaml.get('loss')]
+    class_mode = model_yaml.get('class_mode')
-    optimName = optim.get('name')
+    optim = model_yaml.get('optimizer')
-    optimizer = globals()[optimName](**optim)
+    optimizer = globals()[optim_name](**optim)
-    layers = modelYaml.get('layers')
+    layers = model_yaml.get('layers')
-        initLayer = globals()[name](**layer)
+        init_layer = globals()[name](**layer)
-            shapedParams = []
+            shaped_params = []
-        model.add(initLayer)
+                shaped_params.append(data.reshape(shape))
-def sequential_from_yaml(pathToYaml):
+def sequential_from_yaml(yamlString):
-    modelYaml = yaml.load(stream)
+    modelYaml = yaml.load(yamlString)
-    def to_yaml(self, fileName, storeParams=True):
+    def to_yaml(self, storeParams=True):
-            Stores compiled Sequential model to local file, optionally storing all learnable parameters
+            Stores compiled Sequential model to yaml string, optionally storing all learnable parameters
-            outfile.write(yaml.dump(modelDict, default_flow_style=True))
+        return yaml.dump(modelDict)
-                        val_outs = val_f(*val_ins)
+                        val_outs = self._test_loop(val_f, val_ins, batch_size=batch_size, verbose=0)
-epsilon = 1.0e-9
+if theano.config.floatX == 'float64':
-    scale = 1./np.sqrt(fan_in)
+    scale = np.sqrt(3. / fan_in)
-    s = np.sqrt(2. / (fan_in + fan_out))
+    s = np.sqrt(6. / (fan_in + fan_out))
-    s = np.sqrt(2. / fan_in)
+    s = np.sqrt(6. / fan_in)
-from .. import activations, initializations
+from .. import activations, initializations, regularizers, constraints
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
-        self.constraints = [W_constraint, b_constraint]
+
-            "subsample_length":self.subsample_length}
+            "subsample_length":self.subsample_length,
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
-        self.constraints = [W_constraint, b_constraint]
+
-            "subsample":self.subsample}
+            "subsample":self.subsample,
-from .. import activations, initializations
+from .. import activations, initializations, regularizers, constraints
-from .. import constraints
+from ..regularizers import ActivityRegularizer, Regularizer
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
-        self.constraints = [W_constraint, b_constraint]
+        
-            "activation":self.activation.__name__}
+            "activation":self.activation.__name__,
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
-        self.constraints = [W_constraint, b_constraint]
+
-            "activation":self.activation.__name__}
+            "activation":self.activation.__name__,            
-        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer='identity', b_regularizer='identity', activity_regularizer='identity', W_constraint='identity', b_constraint='identity'):
-        self.constraints = [W_constraint, b_constraint]
+
-            "nb_feature" : self.nb_feature}
+            "nb_feature" : self.nb_feature,
-from .. import activations, initializations
+from .. import activations, initializations, regularizers, constraints
-        W_regularizer=None, activity_regularizer=None, W_constraint=None,
+        W_regularizer='identity', activity_regularizer='identity', W_constraint='identity',
-        self.constraints = [W_constraint]
+
-            self.regularizers.append(activity_regularizer)
+
-            "init":self.init.__name__}
+            "init":self.init.__name__,
-class GaussianDropout(Layer):
+class GaussianDropout(MaskedLayer):
-import warnings, time, copy
+import warnings, time, copy, yaml
-    bce = T.nnet.binary_crossentropy(y_pred, y_true)
+    bce = T.nnet.binary_crossentropy(y_pred, y_true).mean(axis=-1)
-            X *= srng.normal(size=X.shape, avg=1.0, std=theano.tensor.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)
+            X *= srng.normal(size=X.shape, avg=1.0, std=T.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)
-
+    
-            X *= srng.normal(size=X.shape, avg=1.0, std=T.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)
+            X *= srng.normal(size=X.shape, avg=1.0, std=theano.tensor.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)
-class GaussianDropout(Layer):
+class GaussianDropout(MaskedLayer):
-        assert(loss < 2.5)
+        assert(loss < 2.7)
-def test_weights(model, class_weight=None, sample_weight=None):
+def _test_weights(model, class_weight=None, sample_weight=None):
-            standard_score = test_weights(model)
+            standard_score = _test_weights(model)
-            score = test_weights(model, class_weight=class_weight)
+            score = _test_weights(model, class_weight=class_weight)
-            score = test_weights(model, sample_weight=sample_weight)
+            score = _test_weights(model, sample_weight=sample_weight)
-        self.assertTrue(history.validation_accuracy[-1] > 0.9)
+        print(history.history)
-        model.add(Activation('relu'))
+        model.add(Activation('tanh'))
-        model.compile(loss='hinge', optimizer='rmsprop')
+        model.compile(loss='hinge', optimizer='adagrad')
-        self.assertTrue(history.validation_loss[-1] < 0.75)
+        self.assertTrue(history.history['val_loss'][-1] < 0.9)
-        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+        model.compile(loss='categorical_crossentropy', optimizer='adadelta')
-        self.assertTrue(history.validation_accuracy[-1] > 0.9)
+        self.assertTrue(history.history['val_acc'][-1] > 0.9)
-        model.compile(loss='hinge', optimizer='rmsprop')
+        model.compile(loss='hinge', optimizer='adam')
-        self.assertTrue(history.validation_loss[-1] < 0.75)
+        self.assertTrue(history.history['val_loss'][-1] < 0.75)
-        self.assertTrue(history.validation_loss[-1] < 0.75)
+        self.assertTrue(history.history['val_loss'][-1] < 0.75)
-        model.add(Activation('relu'))
+        model.add(Activation('sigmoid'))
-        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
+        model.compile(loss='categorical_crossentropy', optimizer='sgd')
-        self.assertTrue(history.validation_accuracy[-1] > 0.9)
+        self.assertTrue(history.history['val_acc'][-1] > 0.9)
-            self.history[k] = v / self.seen
+            if k not in self.history:
-            self.history[k] = v
+            if k not in self.history:
-    This is a reproduction of the IRNN experiment 
+    This is a reproduction of the IRNN experiment
-    (it's still underfitting at that point, though).
+    Reaches 0.93 train/test accuracy after 900 epochs (which roughly corresponds
-model.fit(X_train, Y_train, batch_size=16, nb_epoch=nb_epochs,
+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epochs,
-model.fit(X_train, Y_train, batch_size=16, nb_epoch=nb_epochs,
+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epochs,
-print('LSTM test accuracy:', scores[1])
+print('LSTM test accuracy:', scores[1])
-            X *= srng.normal(size=X.shape, avg = 1., std=T.sqrt(self.p/(1-self.p)), dtype=theano.config.floatX)
+            X *= srng.normal(size=X.shape, avg=1.0, std=T.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)
-            "p":self.p}
+            "p":self.p}
-            "sigma":self.sigma}
+            "sigma":self.sigma}
-        ins = [data[name] for name in self.input_order] + [data[name] for name in self.output_order]
+        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order]
-        ins = [data[name] for name in self.input_order] + [data[name] for name in self.output_order]
+        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order]
-        ins = [data[name] for name in self.input_order] + [data[name] for name in self.output_order]
+        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order]
-            val_ins = [validation_data[name] for name in self.input_order] + [validation_data[name] for name in self.output_order]
+            val_ins = [validation_data[name] for name in self.input_order] + [standardize_y(validation_data[name]) for name in self.output_order]
-        ins = [data[name] for name in self.input_order] + [data[name] for name in self.output_order]
+        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order]
-y2 = np.random.random((100, 4))
+y2 = np.random.random((100,))
-    classification=False, output_shape=(4,))
+    classification=False, output_shape=(1,))
-        graph.add_node(Dense(16, 4), name='dense3', input='dense1')
+        graph.add_node(Dense(16, 1), name='dense3', input='dense1')
-        graph.add_node(Dense(16, 4), name='dense3', input='dense1')
+        graph.add_node(Dense(16, 1), name='dense3', input='dense1')
-        
+
-                ndim = l.input.ndim 
+                ndim = l.input.ndim
-        (connect, input, get_input, get_output) 
+        (connect, input, get_input, get_output)
-                if n not in self.nodes:
+                if n in self.nodes:
-
+from __future__ import absolute_import
-    def add_input(self, name, ndim=2):
+    def add_input(self, name, ndim=2, dtype='float'):
-        layer.input = ndim_tensor(ndim)
+        if dtype == 'float':
-        self.output_config.append({'name':name, 'ndim':ndim})
+        self.output_config.append({'name':name, 'ndim':ndim, 'dtype':dtype})
-    Compatible Python 2.7-3.4 
+    Compatible Python 2.7-3.4. Requires Scikit-Learn and Pandas.
-    Optimizer is replaced with RMSprop which give more stable and steady
+    Optimizer is replaced with RMSprop which yields more stable and steady
-        ''' Merge the output of a list of models into a single tensor.
+    def __init__(self, layers, mode='sum'):
-            raise Exception("Please specify two or more input models to merge")
+        if len(layers) < 2:
-        self.models = models
+        self.layers = layers
-            params, regs, consts = m.get_params()
+        for l in self.layers:
-                s += self.models[i].get_output(train)
+            s = self.layers[0].get_output(train)
-            inputs = [self.models[i].get_output(train) for i in range(len(self.models))]
+            inputs = [self.layers[i].get_output(train) for i in range(len(self.layers))]
-            o = self.models[i].get_input(train)
+        for i in range(len(self.layers)):
-            weights += m.get_weights()
+        for l in self.layers:
-            self.models[i].set_weights(weights[:nb_param])
+        for i in range(len(self.layers)):
-            "models":[m.get_config() for m in self.models],
+            "layers":[l.get_config() for l in self.layers],
-from keras.layers.core import Dense
+from keras.layers.core import Dense, Activation
-class TestRegularizers(unittest.TestCase):
+class TestGraph(unittest.TestCase):
-        graph.add_node(Dense(32, 4), name='dense2', input='input1')
+        graph.add_node(Dense(32, 4), name='dense2-0', input='input1')
-        if train or self.sigma == 0:
+        if not train or self.sigma == 0:
-                    self.constraints.append(m.constraints[i])
+            params, regs, consts = m.get_params()
-        self.monitor
+        self.monitor = monitor
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    return T.abs_((y_true - y_pred) / y_true).mean(axis=-1) * 100
+    return T.abs_((y_true - y_pred) / T.clip(T.abs_(y_true), epsilon, np.inf)).mean(axis=-1) * 100.
-                    outs[i] += batch_out
+                    outs[i] += batch_out * len(batch_ids)
-    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=10)
+    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch)
-            loss = model.train(X_batch, Y_batch)
+            loss = model.train_on_batch(X_batch, Y_batch)
-            score = model.test(X_batch, Y_batch)
+            score = model.test_on_batch(X_batch, Y_batch)
-        layer = Layer() # empty layer 
+        layer = Layer() # empty layer
-        layer.set_name(name)
+        if hasattr(layer, 'set_name'):
-        pass
+        return {"name":self.__class__.__name__,
-import time, copy
+import time, copy, pprint
-            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False, 
+            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False,
-    return T.abs_((y_true - y_pred) / y_true).mean() * 100
+    return T.abs_((y_true - y_pred) / y_true).mean(axis=-1) * 100
-        # input of model 
+        # input of model
-        
+
-        self._train = theano.function(train_ins, train_loss, 
+        self._train = theano.function(train_ins, train_loss,
-        self._train_with_acc = theano.function(train_ins, [train_loss, train_accuracy], 
+        self._train_with_acc = theano.function(train_ins, [train_loss, train_accuracy],
-        self._predict = theano.function(predict_ins, self.y_test, 
+        self._predict = theano.function(predict_ins, self.y_test,
-        self._test = theano.function(test_ins, test_loss, 
+        self._test = theano.function(test_ins, test_loss,
-        self._test_with_acc = theano.function(test_ins, [test_loss, test_accuracy], 
+        self._test_with_acc = theano.function(test_ins, [test_loss, test_accuracy],
-        return dict(zip(self.output_order, outs))
+        return outs[0]
-    def save_weights(self):
+    def save_weights(self, filepath, overwrite=False):
-    def load_weights(self):
+    def load_weights(self, filepath):
-pred = seq.predict_classes(X_test)
+def mean_absolute_percentage_error(y_true, y_pred):
-                for batch_out in enumerate(batch_outs):
+                for batch_out in batch_outs:
-                outs[0] += batch_outs
+                outs[0] += batch_outs * len(batch_ids)
-class Graph(containers.Graph):
+class Graph(Model, containers.Graph):
-print 'test a non-sequential graph with 1 input and 1 output'
+(X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(32,),
-print loss
+history = graph.fit({'input1':X_train, 'output1':y_train}, nb_epoch=10)
-print 'test a more complex non-sequential graph with 1 input and 1 output'
+print('test a more complex non-sequential graph with 1 input and 1 output')
-
+history = graph.fit({'input1':X_train, 'output1':y_train}, nb_epoch=4)
-print 'test a non-sequential graph with 2 inputs and 1 output'
+print('test a non-sequential graph with 2 inputs and 1 output')
-
+history = graph.fit({'input1':X_train, 'input2':X2_train, 'output1':y_train}, nb_epoch=4)
-print 'test a non-sequential graph with 1 input and 2 outputs'
+print('test a non-sequential graph with 1 input and 2 outputs')
-print loss
+history = graph.fit({'input1':X_train, 'output1':y_train, 'output2':y2_train}, nb_epoch=4)
-print 'test layer-like API'
+print('test layer-like API')
-print loss
+history = seq.fit(X_train, y_train, batch_size=10, nb_epoch=4)
-            self.log_values.append((k, v))
+        for k in self.params['metrics']:
-            self.log_values.append((k, v))
+        for k in self.params['metrics']:
-        validation_split=0., val_f=None, val_ins=None, shuffle=True):
+        validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):
-                (ins, ins_val) = (slice_X(ins, 0, split_at), slice_X(ins, split_at))
+                (ins, val_ins) = (slice_X(ins, 0, split_at), slice_X(ins, split_at))
-            progbar = Progbar(target=len(X[0]))
+            progbar = Progbar(target=nb_sample)
-            progbar = Progbar(target=len(X[0]))
+            progbar = Progbar(target=nb_sample)
-        return out
+        return outs
-
+        metrics = ['loss', 'acc', 'val_loss', 'val_acc']
-            validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle)
+            validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle, metrics=metrics)
-        return self._predict_loop(self._predict, X, batch_size, verbose)
+        return self._predict_loop(self._predict, X, batch_size, verbose)[0]
-        return self._test_loop(f, ins, batch_size, verbose)
+        outs = self._test_loop(f, ins, batch_size, verbose)
-    def compile(self, optimizer, loss, theano_mode='DebugMode'):
+    def compile(self, optimizer, loss, theano_mode=None):
-            validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle)
+            validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle, metrics=metrics)
-    def __init__(self, nb_filter, stack_size, filter_length,
+    def __init__(self, input_dim, nb_filter, filter_length,
-        nb_col = filter_length
+
-        self.stack_size = stack_size
+        self.input_dim = input_dim
-        self.W_shape = (nb_filter, stack_size, nb_row, nb_col)
+        self.input = T.tensor3()
-            border_mode=self.border_mode, subsample=self.subsample)
+        X = theano.tensor.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 2, 1, 3)
-        return output
+        return theano.tensor.reshape(output, (output.shape[0], output.shape[1], output.shape[2])).dimshuffle(0, 2, 1)
-            self.stride = (1, stride)
+        self.stride = stride
-        self.input = T.tensor4()
+        self.input = T.tensor3()
-        return output
+        X = theano.tensor.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 1, 3, 2)
-        super(Convolution2D,self).__init__()
+        super(Convolution2D,self).__init__()
-        indices = (slice(None), slice(None), slice(width, in_shape[2] + width),slice(width, in_shape[3] + width))
+        indices = (slice(None), slice(None), slice(width, in_shape[2] + width), slice(width, in_shape[3] + width))
-        input_dim = X.shape
+        b, ch, r, c = X.shape
-        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :],input_sqr)
+        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :], input_sqr)
-    def _get_corrupted_input(self, input):
+    def _corrupt_input(self, X):
-        return srng.binomial(size=(self.input_dim, 1), n=1,
+        return X * srng.binomial(size=X.shape, n=1,
-                             dtype=theano.config.floatX) * input
+                             dtype=theano.config.floatX)
-        return self._get_corrupted_input(uncorrupted_input)
+        return self._corrupt_input(uncorrupted_input)
-        history = model.fit(X_train, y_train, nb_epoch=10, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
+        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
-        history = model.fit(X_train, y_train, nb_epoch=10, batch_size=16, validation_data=(X_test, y_test), verbose=2)
+        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), verbose=2)
-        history = model.fit(X_train, y_train, nb_epoch=10, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
+        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
-        history = model.fit(X_train, y_train, nb_epoch=10, batch_size=16, validation_data=(X_test, y_test), verbose=2)
+        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), verbose=2)
-        history = model.fit(X_train, y_train, nb_epoch=10, batch_size=16, validation_data=(X_test, y_test), verbose=2)
+        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), verbose=2)
-        history = model.fit(X_train, y_train, nb_epoch=10, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
+        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)
-    def __init__(self, pool_length=2, ignore_border=True):
+    def __init__(self, pool_length=2, stride=None, ignore_border=True):
-        output = downsample.max_pool_2d(X, self.poolsize, ignore_border=self.ignore_border)
+        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)
-            "ignore_border":self.ignore_border}
+                "pool_length":self.pool_length,
-        init='glorot_uniform', activation='linear', weights=None, 
+    def __init__(self, nb_filter, stack_size, nb_row, nb_col,
-            
+
-        conv_out = theano.tensor.nnet.conv.conv2d(X, self.W, 
+        conv_out = theano.tensor.nnet.conv.conv2d(X, self.W,
-    def __init__(self, poolsize=(2, 2), ignore_border=True):
+    def __init__(self, poolsize=(2, 2), stride=None, ignore_border=True):
-        output = downsample.max_pool_2d(X, self.poolsize, ignore_border=self.ignore_border)
+        output = downsample.max_pool_2d(X, ds=self.poolsize, st=self.stride, ignore_border=self.ignore_border)
-            "ignore_border":self.ignore_border}
+                "poolsize":self.poolsize,
-        Reference: 
+        Reference:
-    model.add(Dense(50, 10, W_regularizer=weight_reg))
+    model.add(Dense(50, 10, W_regularizer=weight_reg, activity_regularizer=activity_reg))
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=1000, input_shape=(10,),
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(10,),
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=1000, input_shape=(10,), output_shape=(2,),
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(10,), output_shape=(2,),
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=1000, input_shape=(5,10), 
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5,10), 
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=1000, input_shape=(5, 10), output_shape=(2,),
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5, 10), output_shape=(2,),
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=1000, input_shape=(5, 10), output_shape=(5, 10),
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5, 10), output_shape=(5, 10),
-        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=1000, input_shape=(3, 32, 32), 
+        (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(3, 32, 32), 
-        raise Exception("binary_crossentropy can only be used with scalar outputs.")
+from __future__ import absolute_import
-        return e / T.sqrt(T.sum(e**2, axis=-1, keepdims=True))
+        return p / T.sqrt(T.sum(p**2, axis=-1, keepdims=True))
-        lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm))
+        lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm()))
-        normed = nonneg(self.example_array)
+        nonneg_instance = nonneg()
-        normed = identity(self.example_array)
+        identity_instance = identity()
-        assert(oddball_examples == identity(oddball_examples))
+        assert(oddball_examples == identity_instance(oddball_examples))
-        normalized = unitnorm(self.example_array)
+        normalized = unitnorm_instance(self.example_array)
-        norm_of_normalized = np.sqrt(np.sum(normalized.eval()**2))
+        norm_of_normalized = np.sqrt(np.sum(normalized.eval()**2, axis=1))
-
+    def test_identity_oddballs(self):
-            , 0.)
+        normalized = unitnorm(self.example_array)
-        self.example_array[0,0] = 0. # 0 could possibly cause trouble
+        self.some_values = [0.1, 0.5, 3, 8, 1e-7]
-            assert(np.all(normed.eval() < m))
+            assert (np.all(normed.eval() < m))
-        assert(np.all(np.min(normed.eval(),axis=1) == 0.))
+        assert (np.all(np.min(normed.eval(), axis=1) == 0.))
-        assert(np.all(normed == self.example_array))
+        assert (np.all(normed == self.example_array))
-            ,0.)
+            np.max(np.abs(np.sqrt(np.sum(normed.eval() ** 2, axis=1)) - 1.))
-from keras.layers.recurrent import SimpleRNN
+from keras.layers.recurrent import SimpleRNN, LSTM
-    This is a variant of IRNN experiment with sequential MNIST in
+    This is a reproduction of the IRNN experiment 
-    Reaches to 80% train/test accuracy and 0.55 train/test loss after 70 epochs
+    0.80 train/test accuracy and 0.55 train/test loss after 70 epochs
-batch_size = 16
+batch_size = 32
-BPTT_trancate = 28*28
+BPTT_truncate = 28*28
-# the data, shuffled and split between tran and test sets
+# the data, shuffled and split between train and test sets
-                    activation='relu', truncate_gradient=BPTT_trancate))
+                    activation='relu', truncate_gradient=BPTT_truncate))
-print('Test accuracy:', score[1])
+scores = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
-def UnitNorm(Constraint):
+class UnitNorm(Constraint):
-unitnorm = UnitNorm
+unitnorm = UnitNorm
-            return T.ones_like(X)
+            return None
-        if not hasattr(self, "get_output_mask") and layer.get_output_mask() is not None:
+        if not self.supports_masked_input() and layer.get_output_mask() is not None:
-    20-25 minuts per epoch on a GRID K520 GPU.
+    About 15 minuts per epoch on a GRID K520 GPU.
-nb_epochs = 100000
+nb_epochs = 200
-        ins = X + [y]
+        sample_weight = np.ones(y.shape[:-1] + (1,))
-        self.tot_acc = 0.
+        self.seen = 0
-        if self.current < self.params['nb_sample']:
+        if self.seen < self.params['nb_sample']:
-            self.tot_acc += accuracy * batch_size
+        self.seen += batch_size
-            self.progbar.update(self.current, self.log_values)
+        if self.verbose and self.seen < self.params['nb_sample']:
-        self.progbar.update(self.current, self.log_values)
+        for k, v in self.totals.items():
-                self.validation_accuracy = []
+        self.history = {}
-        self.tot_accuracy = 0.
+        self.totals = {}
-            self.tot_accuracy += logs.get('accuracy', 0.) * batch_size
+        for k, v in logs.items():
-                self.validation_accuracy.append(val_acc)
+        for k, v in self.totals.items():
-    def __init__(self, filepath, verbose=0, save_best_only=False):
+    def __init__(self, filepath, monitor='val_loss', verbose=0, save_best_only=False):
-        self.best_val_loss = np.Inf
+        self.best = np.Inf
-                self.model.save_weights(self.filepath, overwrite=True)
+        if self.save_best_only:
-        elif not self.save_best_only:
+                if current < self.best:
-    def __init__(self, patience=0, verbose=0):
+    def __init__(self, monitor='val_loss', patience=0, verbose=0):
-        self.best_val_loss = np.Inf
+        self.best = np.Inf
-            self.best_val_loss = cur_val_loss
+        current = logs.get(self.monitor)
-        self.tot_accuracy = 0.
+        self.totals = {}
-            self.tot_accuracy += logs.get('accuracy', 0.) * batch_size
+        for k, v in logs.items():
-        r = requests.post(self.root + '/publish/epoch/end/', {'data':json.dumps(logs)})
+        send = {}
-from ..layers.core import Layer
+from ..layers.core import Layer, Merge
-    def connect(self, layer):
+    def set_previous(self, layer):
-            self.layers[-1].connect(self.layers[-2])
+            self.layers[-1].set_previous(self.layers[-2])
-        Implement a NN graph with arbitrary layer connections.
+        Implement a NN graph with arbitrary layer connections,
-        input, get_input, get_output are lists of tensors instead of single tensors.
+        Note: Graph can only be used as a layer
-            - connect
+            - get_weights
-        raise Exception('The Graph container does not implement the connect method.')
+    def set_previous(self, layer):
-
+        layer.set_name(name)
-                layer.connect(self.nodes(input))
+                layer.set_previous(self.nodes[input])
-                layer.input = self.inputs[input]
+                layer.set_previous(self.inputs[input])
-            layer.connect(merge)
+            merge = Merge(to_merge, mode=merge_mode)
-                self.outputs[name] = self.nodes[inputs]
+                self.outputs[name] = self.nodes[input]
-            
+                self.ouputs[name] = self.inputs[input]
-        pass
+            merge = Merge(to_merge, mode=merge_mode)
-    def set_weights(self):
+    def get_config(self):
-    def connect(self, layer):
+    def set_previous(self, layer):
-        return self.input
+    def get_output(self, train=False):
-    def get_input(self, train):
+    def get_input(self, train=False):
-    def get_input_mask(self, train=None):
+    def get_input_mask(self, train=False):
-    def get_output_mask(self, train=None):
+    def get_output_mask(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, 
+    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, name=None,
-    def get_output(self, train):
+        if name is not None:
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-        self.decoder.connect(self.encoder)
+        self.decoder.set_previous(self.encoder)
-        self.encoder.connect(node)
+    def set_previous(self, node):
-    def _get_hidden(self, train):
+    def _get_hidden(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-    def get_output(self, train):
+    def get_output(self, train=False):
-        test_score = self.loss(self.y, self.y_test, self.weights)
+        test_loss = self.loss(self.y, self.y_test, self.weights)
-        self._test = theano.function(test_ins, test_score, 
+        self._test = theano.function(test_ins, test_loss, 
-        self._test_with_acc = theano.function(test_ins, [test_score, test_accuracy], 
+        self._test_with_acc = theano.function(test_ins, [test_loss, test_accuracy], 
-        do_validation = False
+        val_f = None
-                    print("Train on %d samples, validate on %d samples" % (len(y), len(y_val)))
+            val_ins = X_val + [y_val, np.ones(y_val.shape[:-1] + (1,))]
-                        epoch_logs['val_loss'] = val_loss
+        if show_accuracy:
-                break
+        ins = X + [y, sample_weight]
-        return callbacks.callbacks[0] # return history
+        return self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose, callbacks=callbacks, \
-
+
-            "layers":[layer.get_config() for layer in self.layers]}
+            "layers":[layer.get_config() for layer in self.layers]}
-        raise NotImplementedError
+        return self.input
-from .utils.theano_utils import sharedX, shared_zeros
+from .utils.theano_utils import sharedX, shared_zeros, shared_ones
-        init='glorot_uniform', inner_init='orthogonal', 
+        init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one',
-        self.b_f = shared_zeros((self.output_dim))
+        self.b_f = self.forget_bias_init((self.output_dim))
-def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', value=0.):
+def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.):
-        than maxlen is truncated to maxlen.
+        than maxlen is truncated to maxlen. Truncation happens off either the beginning (default) or
-        Support post-padding and pre-padding (default).
+        if truncating == 'pre':
-            x[idx, :lengths[idx]] = s[:maxlen]
+            x[idx, :len(trunc)] = trunc
-            x[idx, -min(maxlen, lengths[idx]):] = s[:maxlen]
+            raise ValueError("Padding type '%s' not understood" % padding)
-        if layer.get_output_mask() is not None and not self.supports_masked_input():
+        if not hasattr(self, "get_output_mask") and layer.get_output_mask() is not None:
-    def __init__(self, input_dim, output_dim, init='uniform', weights=None, W_regularizer=None, W_constraint=None, mask_zero=False):
+    def __init__(self, input_dim, output_dim, init='uniform',
-        self.regularizers = [W_regularizer]
+
-model.add(LSTM(256, 128)) # try using a GRU instead, for fun
+model.add(Embedding(max_features, 128))
-score = model.evaluate(X_test, y_test, batch_size=batch_size)
+model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=4, validation_data=(X_test, y_test), show_accuracy=True)
-
+if not os.path.exists(save_dir):
-from .. import regularizers
+from ..regularizers import ActivityRegularizer
-    def __init__(self, activity_regularizer=None):
+    def __init__(self, l1=0., l2=0.):
-            self.regularizers = [activity_regularizer]
+        activity_regularizer = ActivityRegularizer(l1=l1, l2=l2)
-            "activity_regularizer":self.activity_regularizer.__name__}
+            "l1":self.l1,
-        image_shape=None, border_mode='valid', subsample_length=1,
+        border_mode='valid', subsample_length=1,
-            border_mode=self.border_mode, subsample=self.subsample, image_shape=self.image_shape)
+            border_mode=self.border_mode, subsample=self.subsample)
-        image_shape=None, border_mode='valid', subsample=(1,1),
+        border_mode='valid', subsample=(1, 1),
-            border_mode=self.border_mode, subsample=self.subsample, image_shape=self.image_shape)
+            border_mode=self.border_mode, subsample=self.subsample)
-        W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers = [W_regularizer, b_regularizer]
+        self.regularizers = []
-        W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers = [W_regularizer, b_regularizer]
+        self.regularizers = []
-            self.layers[0].input = ndim_tensor(ndim)
+            self.set_input()
-            regs += [self.regularizer for _ in range(len(self.params))]
+        if hasattr(self, 'regularizers'):
-            regs += [regularizers.identity() for _ in range(len(self.params))]
+            regularizers = []
-        return self.params, regs, consts
+        return self.params, regularizers, consts
-        W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers = [W_regularizer, b_regularizer]
+        self.regularizers = []
-    def __init__(self, activity_regularizer = None):
+    def __init__(self, activity_regularizer=None):
-            self.loss_update = activity_regularizer
+            self.regularizers = [activity_regularizer]
-        W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers = [W_regularizer, b_regularizer]
+        self.regularizers = []
-        W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):
-        self.regularizers = [W_regularizer, b_regularizer]
+        self.regularizers = []
-        updates = self.optimizer.get_updates(self.params, self.regularizers, self.constraints,  train_loss)
+        for r in self.regularizers:
-    def get_gradients(self, loss, params, regularizers):
+    def get_gradients(self, loss, params):
-        return new_grads
+        return grads
-        grads = self.get_gradients(loss, params, regularizers)
+    def get_updates(self, params, constraints, loss):
-        grads = self.get_gradients(loss, params, regularizers)
+    def get_updates(self, params, constraints, loss):
-        grads = self.get_gradients(loss, params, regularizers)
+    def get_updates(self, params, constraints, loss):
-        grads = self.get_gradients(loss, params, regularizers)
+    def get_updates(self, params, constraints, loss):
-        grads = self.get_gradients(loss, params, regularizers)
+    def get_updates(self, params, constraints, loss):
-        return loss
+    def set_param(self, p):
-        self.l = l
+    def __call__(self, loss):
-        return gradient
+class WeightRegularizer(Regularizer):
-        self.l = l
+    def set_param(self, p):
-        return gradient
+    def __call__(self, loss):
-    def __init__(self, l1=0.01, l2=0.01):
+class ActivityRegularizer(Regularizer):
-        return loss + self.l * T.sum(T.mean(abs(self.layer.get_output(True)), axis=0))
+    def __call__(self, loss):
-        self.layer = None
+def l1(l=0.01):
-        self.layer = layer
+def l2(l=0.01):
-        return loss + self.l * T.sum(T.mean(self.layer.get_output(True) ** 2, axis=0))
+def l1l2(l1=0.01, l2=0.01):
-identity = Regularizer
+def activity_l2(l=0.01):
-l1l2 = weights_l1l2 = WeightsL1L2
+def activity_l1l2(l1=0.01, l2=0.01):
-activity_l2 = ActivityL2
+identity = Regularizer
-                    regs.append(regularizers.identity)
+                    regs.append(regularizers.identity())
-            regs += [regularizers.identity for _ in range(len(self.params))]
+            regs += [regularizers.identity() for _ in range(len(self.params))]
-                    consts.append(constraints.identity)
+                    consts.append(constraints.identity())
-            consts += [constraints.identity for _ in range(len(self.params))]
+            consts += [constraints.identity() for _ in range(len(self.params))]
-        self.loss_updates = [] # size can vary, no 1-to-1 mapping to params
+from . import callbacks as cbks
-class Model(object):
+class Model(object):
-        for reg in [regularizers.identity, regularizers.l1(), regularizers.l2(), regularizers.l1l2()]:
+        for reg in [regularizers.identity(), regularizers.l1(), regularizers.l2(), regularizers.l1l2()]:
-model.add(Dense(20, 20, W_constraint=nonneg))
+model.add(Dense(20, 20, W_constraint=nonneg()))
-        raise NotImplementedError
+        return gradient
-        raise NotImplementedError
+        return loss
-    def __init__(self, l = 0.01):
+    def __init__(self, l=0.01):
-    def __init__(self, l = 0.01):
+    def __init__(self, l=0.01):
-#old style variables for backwards compatibility
+identity = Regularizer
-    def maxnorm_wrap(p):
+class Constraint(object):
-        desired = T.clip(norms, 0, m)
+        desired = T.clip(norms, 0, self.m)
-    return p
+class NonNeg(Constraint):
-    return g
+def UnitNorm(Constraint):
-    return e / T.sqrt(T.sum(e**2, axis=-1, keepdims=True))
+identity = Constraint
-class JZS1(Layer):
+class JZS1(Recurrent):
-        h_t = hh_t * z + h_tm1 * (1 - z)
+        r = self.inner_activation(xr_t + T.dot(h_mask_tm1, u_r))
-        X = X.dimshuffle((1, 0, 2)) 
+        X = X.dimshuffle((1, 0, 2))
-            sequences=[x_z, x_r, x_h, padded_mask], 
+            sequences=[x_z, x_r, x_h, padded_mask],
-class JZS2(Layer):
+class JZS2(Recurrent):
-        xz_t, xr_t, xh_t, 
+        xz_t, xr_t, xh_t, mask_tm1,
-        h_t = hh_t * z + h_tm1 * (1 - z)
+        h_mask_tm1 = mask_tm1 * h_tm1
-        X = self.get_input(train) 
+        X = self.get_input(train)
-            sequences=[x_z, x_r, x_h], 
+            sequences=[x_z, x_r, x_h, padded_mask],
-class JZS3(Layer):
+class JZS3(Recurrent):
-        xz_t, xr_t, xh_t, 
+        xz_t, xr_t, xh_t, mask_tm1,
-        h_t = hh_t * z + h_tm1 * (1 - z)
+        h_mask_tm1 = mask_tm1 * h_tm1
-        X = self.get_input(train) 
+        X = self.get_input(train)
-            sequences=[x_z, x_r, x_h], 
+            sequences=[x_z, x_r, x_h, padded_mask],
-def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre'):
+def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', value=0.):
-    x = np.zeros((nb_samples, maxlen)).astype(dtype)
+    x = (np.ones((nb_samples, maxlen)) * value).astype(dtype)
-    random.shuffle(labels)
+    np.random.seed(seed)
-    X = [[0 if (w >= nb_words or w < skip_top) else w for w in x] for x in X]
+    # by convention, use 2 as OOV word
-def load_data(path="reuters.pkl", nb_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113):
+def load_data(path="reuters.pkl", nb_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113,
-    random.shuffle(labels)
+
-    X = [[0 if (w >= nb_words or w < skip_top) else w for w in x] for x in X]
+    # by convention, use 2 as OOV word
-np.random.seed(1337)
+batch_size = 32
-model.add(Embedding(max_features, 256, mask_zero=True))
+model.add(Embedding(max_features, 256))
-import numpy as np
+import numpy as np
-np.random.seed(1337) # for reproducibility
+
-        return stacked.dimshuffle((1,0,2))
+        return stacked.dimshuffle((1, 0, 2))
-        return output.dimshuffle(1,0,2)
+        output = self.activation(T.dot(X.dimshuffle(1, 0, 2), self.W) + self.b)
-class BaseRecurrent(MaskedLayer):
+class Recurrent(MaskedLayer):
-            return super(BaseRecurrent, self).get_output_mask(train)
+            return super(Recurrent, self).get_output_mask(train)
-        mask = mask.dimshuffle(1,0,2) # (time, nb_samples, 1)
+        mask = mask.dimshuffle(1, 0, 2) # (time, nb_samples, 1)
-class SimpleRNN(BaseRecurrent):
+class SimpleRNN(Recurrent):
-        X = self.get_input(train) # shape: (nb_samples, time (padded with zeros at the end), input_dim)
+        X = self.get_input(train) # shape: (nb_samples, time (padded with zeros), input_dim)
-
+        X = X.dimshuffle((1, 0, 2)) 
-            return outputs.dimshuffle((1,0,2))
+            return outputs.dimshuffle((1, 0, 2))
-class SimpleDeepRNN(BaseRecurrent):
+class SimpleDeepRNN(Recurrent):
-        X = X.dimshuffle((1,0,2)) 
+        X = X.dimshuffle((1, 0, 2)) 
-            return outputs.dimshuffle((1,0,2))
+            return outputs.dimshuffle((1, 0, 2))
-class GRU(BaseRecurrent):
+class GRU(Recurrent):
-        X = X.dimshuffle((1,0,2)) 
+        X = X.dimshuffle((1, 0, 2)) 
-            return outputs.dimshuffle((1,0,2))
+            return outputs.dimshuffle((1, 0, 2))
-class LSTM(BaseRecurrent):
+class LSTM(Recurrent):
-        X = X.dimshuffle((1,0,2))
+        X = X.dimshuffle((1, 0, 2))
-            return outputs.dimshuffle((1,0,2))
+            return outputs.dimshuffle((1, 0, 2))
-        xz_t, xr_t, xh_t, 
+        xz_t, xr_t, xh_t, mask_tm1,
-        X = X.dimshuffle((1,0,2)) 
+        X = X.dimshuffle((1, 0, 2)) 
-            sequences=[x_z, x_r, x_h], 
+            sequences=[x_z, x_r, x_h, padded_mask], 
-            return outputs.dimshuffle((1,0,2))
+            return outputs.dimshuffle((1, 0, 2))
-        X = X.dimshuffle((1,0,2)) 
+        X = X.dimshuffle((1, 0, 2)) 
-            return outputs.dimshuffle((1,0,2))
+            return outputs.dimshuffle((1, 0, 2))
-        X = X.dimshuffle((1,0,2)) 
+        X = X.dimshuffle((1, 0, 2)) 
-            return outputs.dimshuffle((1,0,2))
+            return outputs.dimshuffle((1, 0, 2))
-def weighted_obj_fn(fn):
+def weighted_objective(fn):
-        self.loss = weighted_obj_fn(objectives.get(loss))
+        self.loss = weighted_objective(objectives.get(loss))
-theano.config.exception_verbosity='high' 
+theano.config.exception_verbosity = 'high' 
-X = np.random.random_integers(1, 4, size=(500000,15))
+X = np.random.random_integers(1, 4, size=(500000, 15))
-model.add(SimpleRNN(4,4, activation='relu', return_sequences=True))
+model.add(TimeDistributedDense(4, 4)) # obviously this is redundant. Just testing.
-model.add(SimpleDeepRNN(4,4, depth=2, activation='relu')) 
+model.add(SimpleDeepRNN(4, 4, depth=2, activation='relu')) 
-model.add(Dense(4,4, activation='softmax'))
+model.add(Dense(4, 4, activation='softmax'))
-X[:,:10] = 0
+X[:, : 10] = 0
-Xmask0[:,10] = 0
+Xmask0[:, 10] = 0
-Xmask12[:,12] = 0
+Xmask12[:, 11] = 0
-    X1_onehot[i, row[11]-1] = 1
+    X0_onehot[i, row[10] - 1] = 1
-if score > uniform_score*0.9:
+if score > uniform_score * 0.9:
-if score > uniform_score*0.9:
+model.fit(X[: , 1:], X1_onehot, nb_epoch=1, batch_size=batch_size)
-if score < uniform_score*0.9:
+if score < uniform_score * 0.9:
-if score > uniform_score*0.9:
+if score > uniform_score * 0.9:
-if score < uniform_score*0.9:
+if score < uniform_score * 0.9:
-model2.add(TimeDistributedDense(4,4))
+model2.add(TimeDistributedDense(4, 4))
-model2.add(LSTM(4,4, return_sequences=True))
+model2.add(LSTM(4, 4, return_sequences=True))
-model2.add(SimpleRNN(4,4, activation='relu', return_sequences=True))
+model2.add(GRU(4, 4, activation='softmax', return_sequences=True))
-y2 = np.random.random((X2.shape[0],X2.shape[1],4))
+X2 = np.random.random_integers(1, 4, size=(2, 5))
-for pre_zeros in range(1,10):
+for pre_zeros in range(1, 10):
-    if not np.allclose(ref[:,-1,:], pred[:,-1,:]):
+    if not np.allclose(ref[:, -1, :], pred[:, -1, :]):
-    Most configurations won't converge.
+    Some configurations won't converge.
-    instead of an inverse exponential.
+    - LSTM loss decrease patterns during training can be quite different 
-    250s/epoch on GPU (GT 650M), vs. 400s/epoch on CPU (2.4Ghz Core i7).
+    250s/epoch on GPU (GT 650M), vs. 400s/epoch on CPU (2.4Ghz Core i7). 
-max_features=20000
+max_features = 20000
-model.add(Embedding(max_features, 256))
+model.add(Embedding(max_features, 256, mask_zero=True))
-model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=5, validation_split=0.1, show_accuracy=True)
+model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=4, validation_split=0.1, show_accuracy=True)
-                                outputs_info=None)
+        output = self.activation(T.dot(X.dimshuffle(1,0,2), self.W) + self.b)
-        return (masked_weights * fn(masked_y_true, masked_y_pred)).mean()
+        obj_output = fn(masked_y_true, masked_y_pred)
-        if hasattr(self, 'cost_updates'):
+        if hasattr(self, 'loss_update'):
-        return mask
+            padding = alloc_zeros_matrix(pad, mask.shape[1], 1)
-            return 0.
+        class ZeroGrad(regularizers.Regularizer):
-        self.modifies_loss = True
+    '''
-    test_values=[0,0.1,0.5,0.9,1.0]
+    test_values=get_standard_values()
-                    train_loss = u(train_loss)
+                train_loss = u.update_loss(train_loss)
-            g = r(g, p)
+            g = r.update_gradient(g, p)
-        return [dist]
+        return dist
-    list_assert_equal(result[0], expected[0])
+    print(str(result))
-        if layer.get_output_mask() is not None and not self.supports_mask():
+        if layer.get_output_mask() is not None and not self.supports_masked_input():
-    def supports_mask(self):
+    def supports_masked_input(self):
-    def supports_mask(self):
+    def supports_masked_input(self):
-        return self.previous.get_output_mask(train)
+        if hasattr(self, 'previous'):
-class Embedding(MaskedLayer):
+class Embedding(Layer):
-            model.evaluate(X_test[test_ids, :], Y_test[test_ids, :], verbose=0)
+            model.evaluate(X_test[test_ids, :], Y_test[test_ids, :], verbose=0)
-            self.Pmat = theano.shared(np.identity(self.output_dim), name=None)
+            self.Pmat = theano.shared(np.identity(self.output_dim, dtype=theano.config.floatX), name=None)
-            P = np.random.binomial(1, 0.5, size=(self.input_dim, self.output_dim)) * 2 - 1
+            P = np.random.binomial(1, 0.5, size=(self.input_dim, self.output_dim)).astype(theano.config.floatX) * 2 - 1
-            self.Pmat = theano.shared(np.identity(self.output_dim), name=None)
+            self.Pmat = theano.shared(np.identity(self.output_dim, dtype=theano.config.floatX), name=None)
-            P = np.random.binomial(1, 0.5, size=(self.input_dim, self.output_dim)) * 2 - 1
+            P = np.random.binomial(1, 0.5, size=(self.input_dim, self.output_dim)).astype(theano.config.floatX) * 2 - 1
-        self.Pmat = theano.shared(P, name=None)
+        # P_h used to project X onto different dimension, using sparse random projections
-        self.Pmat = theano.shared(P, name=None)
+        # P_h used to project X onto different dimension, using sparse random projections
-        self.cost_updates = []
+        self.loss_updates = []
-            self.cost_updates.append(layer.cost_update)
+            self.loss_updates.append(layer.loss_update)
-            self.cost_update = activity_regularizer
+            self.loss_update = activity_regularizer
-                if u.modifies_cost:
+            for u in self.loss_updates:
-        self.cost_updates = [] # size can vary, no 1-to-1 mapping to params
+        self.loss_updates = [] # size can vary, no 1-to-1 mapping to params
-    def get_updates(self, params, regularizers, constraints,  cost):
+    def get_updates(self, params, regularizers, constraints,  loss):
-    def get_gradients(self, cost, params, regularizers):
+    def get_gradients(self, loss, params, regularizers):
-        grads = T.grad(cost, params)
+        grads = T.grad(loss, params)
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, loss):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, loss):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, loss):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, loss):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, loss):
-        self.modifies_cost = False
+        self.modifies_loss = False
-    def update_cost(self, cost):
+    def update_loss(self, loss):
-class RegularizerWeightsL1(Regularizer):
+class WeightsL1(Regularizer):
-class RegularizerWeightsL2(Regularizer):
+class WeightsL2(Regularizer):
-class RegularizerWeightsL1L2(Regularizer):
+class WeightsL1L2(Regularizer):
-class RegularizerIdentity(Regularizer):
+class Identity(Regularizer):
-class RegularizerActivityL1(Regularizer):
+class ActivityL1(Regularizer):
-        self.modifies_cost = True
+        self.modifies_loss = True
-        return cost + self.l * T.sum(T.mean(abs(self.layer.get_output(True)), axis=0))
+    def update_loss(self, loss):
-        return self.update_cost(cost)
+    def __call__(self, loss):
-class RegularizerActivityL2(Regularizer):
+class ActivityL2(Regularizer):
-        self.modifies_cost = True
+        self.modifies_loss = True
-        return cost + self.l * T.sum(T.mean(self.layer.get_output(True) ** 2, axis=0))
+    def update_loss(self, loss):
-        return self.update_cost(cost)
+    def __call__(self, loss):
-identity = RegularizerIdentity()
+l1 = weights_l1 = WeightsL1
-activity_l2 = RegularizerActivityL2
+activity_l1 = ActivityL1
-from ..utils.theano_utils import shared_zeros, floatX, shared_scalar
+from ..utils.theano_utils import shared_zeros, floatX
-    def get_padded_shuffled_mask(self, train, X, pad = 0):
+    def get_padded_shuffled_mask(self, train, X, pad=0):
-from ..utils.theano_utils import shared_zeros, floatX, shared_scalar, get_mask, default_mask_val
+from ..utils.theano_utils import shared_zeros, floatX, shared_scalar
-class Dropout(Layer):
+class Dropout(MaskedLayer):
-    def __init__(self, p, mask_val=default_mask_val):
+    def __init__(self, p):
-        mask = get_mask(X, self.mask_val)
+        mask = self.get_output_mask(train)
-        return mask * X + (1 - mask) * self.mask_val
+        return X
-            "mask_val":self.mask_val.eval()}
+            "p":self.p}
-class Activation(Layer):
+class Activation(MaskedLayer):
-    def __init__(self, activation, target=0, beta=0.1, mask_val=default_mask_val):
+    def __init__(self, activation, target=0, beta=0.1):
-        return mask * self.activation(X) + (1 - mask) * self.mask_val
+        return self.activation(X)
-            "mask_val":self.mask_val.eval()}
+            "beta":self.beta}
-class TimeDistributedDense(Layer):
+class TimeDistributedDense(MaskedLayer):
-        W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None, mask_val=default_mask_val):
+            W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
-            return mask * self.activation(T.dot(X, self.W) + self.b) + (1 - mask) * self.mask_val
+        def act_func(X):
-                                sequences = [X, mask],
+                                sequences = X,
-            "mask_val":self.mask_val.eval()}
+            "activation":self.activation.__name__}
-from ..layers.core import Layer, default_mask_val
+from ..layers.core import Layer, MaskedLayer
-class Embedding(Layer):
+class Embedding(MaskedLayer):
-    def __init__(self, input_dim, output_dim, init='uniform', weights=None, W_regularizer=None, W_constraint=None, zero_is_mask=False, mask_val=default_mask_val):
+    def __init__(self, input_dim, output_dim, init='uniform', weights=None, W_regularizer=None, W_constraint=None, mask_zero=False):
-            self.W = sharedX(T.set_subtensor(self.W[0, :], mask_val).eval())
+        self.mask_zero = mask_zero
-from ..layers.core import Layer
+from ..utils.theano_utils import shared_scalar, shared_zeros, alloc_zeros_matrix
-class SimpleRNN(Layer):
+class BaseRecurrent(MaskedLayer):
-        truncate_gradient=-1, return_sequences=False, mask_val=default_mask_val):
+        truncate_gradient=-1, return_sequences=False):
-        self.mask_val = shared_scalar(mask_val)
+        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)
-        outputs = mask * outputs + (1 - mask) * self.mask_val
+
-            "mask_val":self.mask_val.eval()}
+            "return_sequences":self.return_sequences}
-class SimpleDeepRNN(Layer):
+class SimpleDeepRNN(BaseRecurrent):
-        weights=None, truncate_gradient=-1, return_sequences=False, mask_val=default_mask_val):
+        weights=None, truncate_gradient=-1, return_sequences=False):
-        self.mask_val = shared_scalar(mask_val)
+        padded_mask = self.get_padded_shuffled_mask(train, X, pad=self.depth)
-        outputs = mask * outputs + (1 - mask) * self.mask_val
+
-            "mask_val":self.mask_val.eval()}
+            "return_sequences":self.return_sequences}
-class GRU(Layer):
+class GRU(BaseRecurrent):
-        weights=None, truncate_gradient=-1, return_sequences=False, mask_val=default_mask_val):
+        weights=None, truncate_gradient=-1, return_sequences=False):
-        self.mask_val = shared_scalar(default_mask_val)
+        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)
-            "mask_val":self.mask_val.eval()}
+            "return_sequences":self.return_sequences}
-class LSTM(Layer):
+class LSTM(BaseRecurrent):
-        weights=None, truncate_gradient=-1, return_sequences=False, mask_val=default_mask_val):
+        weights=None, truncate_gradient=-1, return_sequences=False):
-        self.mask_val = shared_scalar(mask_val)
+        padded_mask = self.get_padded_shuffled_mask(train, X, pad=1)
-            "mask_val":self.mask_val.eval()}
+            "return_sequences":self.return_sequences}
-model.add(Embedding(5, 4, zero_is_mask=True))
+model.add(Embedding(5, 4, mask_zero=True))
-model2.add(Embedding(5, 4, zero_is_mask=True))
+model2.add(Embedding(5, 4, mask_zero=True))
-class MutatedRNN_1(Layer):
+class JZS1(Layer):
-        super(MutatedRNN_1,self).__init__()
+        super(JZS1,self).__init__()
-            raise Exception('input_dim must equal output_dim for this architecture')
+        # P_h used to project X onto different dimension
-        x_h = T.tanh(X) + self.b_h
+        x_h = T.tanh(T.dot(X, self.Pmat)) + self.b_h
-class MutatedRNN_2(Layer):
+class JZS2(Layer):
-        super(MutatedRNN_2,self).__init__()
+        super(JZS2,self).__init__()
-            raise Exception('input_dim must equal output_dim for this architecture')
+        # P_h used to project X onto different dimension
-        x_r = X + self.b_r
+        x_r = T.dot(X, self.Pmat) + self.b_r
-class MutatedRNN_3(Layer):
+class JZS3(Layer):
-        super(MutatedRNN_3,self).__init__()
+        super(JZS3,self).__init__()
-            self.cost_update = activity_regularizer(self)
+            activity_regularizer.set_layer(self)
-                train_loss += u()
+                if u.modifies_cost:
-    return l2wrap
+
-    def __init__(self, activity_regularizer):
+    def __init__(self, activity_regularizer = None):
-        self.cost_update = activity_regularizer(self)
+        if activity_regularizer is not None:
-        self.loss = objectives.get(loss)
+        self.loss = weighted_obj_fn(objectives.get(loss))
-    return weighted_obj_fun
+    return get_from_module(identifier, globals(), 'objective')
-        y = np.reshape(y, (len(y), 1))
+        y = np.expand_dims(y, 1)
-        test_score = self.loss(self.y, self.y_test)
+        self.weights = T.ones_like(self.y_train)
-            test_ins = self.X_test + [self.y]
+            train_ins = self.X_train + [self.y, self.weights]
-            test_ins = [self.X_test, self.y]
+            train_ins = [self.X_train, self.y, self.weights]
-    def train(self, X, y, accuracy=False):
+    def train(self, X, y, accuracy=False, weights=None):
-        ins = X + [y]
+        if weights is None:
-            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False):
+            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False, weights=None):
-                    X_val may be a numpy array or a list of numpy arrays depending on your model input.")
+                try:
-                (y, y_val) = (y[0:split_at], y[split_at:])
+                (y, y_val) = (y[:split_at], y[split_at:])
-                ins = X_batch + [y_batch]
+                ins = X_batch + [y_batch, weight_batch]
-                            val_loss, val_acc = self.evaluate(X_val, y_val, batch_size=batch_size, \
+                            val_loss, val_acc = self.evaluate(X_val, y_val, weights=weight_val, batch_size=batch_size, \
-                            val_loss = self.evaluate(X_val, y_val, batch_size=batch_size, verbose=0)
+                            val_loss = self.evaluate(X_val, y_val, weights=weight_val, batch_size=batch_size, verbose=0)
-    def evaluate(self, X, y, batch_size=128, show_accuracy=False, verbose=1):
+    def evaluate(self, X, y, batch_size=128, show_accuracy=False, verbose=1, weights=None):
-            ins = X_batch + [y_batch]
+            ins = X_batch + [y_batch, weight_batch]
-        f.close()
+        f.close()
-    return T.sqr(y_pred - y_true).mean()
+    return T.sqr(y_pred - y_true).mean(axis=-1)
-    return T.abs_(y_pred - y_true).mean()
+    return T.abs_(y_pred - y_true).mean(axis=-1)
-    return T.sqr(T.maximum(1. - y_true * y_pred, 0.)).mean()
+    return T.sqr(T.maximum(1. - y_true * y_pred, 0.)).mean(axis=-1)
-    return T.maximum(1. - y_true * y_pred, 0.).mean()
+    return T.maximum(1. - y_true * y_pred, 0.).mean(axis=-1)
-    y_pred /= y_pred.sum(axis=1, keepdims=True) 
+    y_pred /= y_pred.sum(axis=-1, keepdims=True) 
-    return cce.mean()
+    return cce
-    return bce.mean()
+    return bce
-    return get_from_module(identifier, globals(), 'objective')
+    obj_fn = get_from_module(identifier, globals(), 'objective')
-model2.add(SimpleRNN(4,4, activation='relu', return_sequences=False))
+model2.add(SimpleRNN(4,4, activation='relu', return_sequences=True))
-        optimizer='rmsprop', theano_mode=theano.compile.mode.FAST_COMPILE)
+        optimizer='rmsprop', theano_mode=theano.compile.mode.FAST_RUN)
-    if not np.allclose(ref, pred):
+    padded_X2 = np.concatenate((np.zeros((X2.shape[0], pre_zeros)), X2), axis=1)
-            self.constraints += m.constraints
+            for i in range(len(m.params)):
-                res.append(o)
+            if not type(o) == list:
-            "p":self.p}
+            "p":self.p,
-            "beta":self.beta}
+            "beta":self.beta,
-            "activation":self.activation.__name__}
+            "activation":self.activation.__name__,
-            "return_sequences":self.return_sequences}
+            "return_sequences":self.return_sequences,
-            "return_sequences":self.return_sequences}
+            "return_sequences":self.return_sequences,
-            "return_sequences":self.return_sequences}
+            "return_sequences":self.return_sequences,
-            "return_sequences":self.return_sequences}
+            "return_sequences":self.return_sequences,
-    return T.nnet.softmax(x.reshape((-1,x.shape[-1]))).reshape(x.shape)
+    return T.nnet.softmax(x.reshape((-1, x.shape[-1]))).reshape(x.shape)
-
+
-print('Accuracy change:', (score[1] - classical_score[1])/classical_score[1], '%')
+# Try different things here: 'lstm' or 'classical' or 'denoising'
-    return T.nnet.softmax(x)
+    return T.nnet.softmax(x.reshape((-1,x.shape[-1]))).reshape(x.shape)
-    return T.nnet.softmax(X).reshape(xshape)
+    import warnings
-    return get_from_module(identifier, globals(), 'activation function')
+    return get_from_module(identifier, globals(), 'activation function')
-def time_distributed_softmax(x, mask_val=default_mask_val):
+def time_distributed_softmax(x):
-    return r.reshape(xshape)
+    return T.nnet.softmax(X).reshape(xshape)
-    def __init__(self, activation, target=0, beta=0.1):
+    def __init__(self, activation, target=0, beta=0.1, mask_val=default_mask_val):
-        return self.activation(X)
+        mask = get_mask(X, self.mask_val)
-        optimizer='rmsprop', theano_mode=theano.compile.mode.FAST_RUN)
+        optimizer='rmsprop', theano_mode=theano.compile.mode.FAST_COMPILE)
-        self.encoder.previous = node
+        self.encoder.connect(node)
-autoencoder_type = 'denoising'
+# or 'deep_denoising'
-    if isinstance(identifier, basestring):
+    if isinstance(identifier, six.string_types):
-y = np.zeros((len(sentences), len(chars)))
+X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)
-    y[i, char_indices[next_chars[i]]] = 1.
+        X[i, t, char_indices[char]] = 1
-        train_loss = self.loss(self.y, self.y_train, self.loss_weights)
+        train_loss = self.loss(self.y, self.y_train)
-            train_ins = self.X_train + [self.y, self.loss_weights]
+            train_ins = self.X_train + [self.y]
-            train_ins = [self.X_train, self.y, self.loss_weights]
+            train_ins = [self.X_train, self.y]
-    def train(self, X, y, accuracy=False, sample_weight=None, class_weight=None):
+    def train(self, X, y, accuracy=False):
-        ins = X + [y, w]
+        ins = X + [y]
-            sample_weight=None, class_weight=None):
+            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False):
-                ins = X_batch + [y_batch, w]
+                ins = X_batch + [y_batch]
-def categorical_crossentropy(y_true, y_pred, weight=None):
+def mean_squared_error(y_true, y_pred):
-        return cce.mean()
+    return cce.mean()
-def binary_crossentropy(y_true, y_pred, weight=None):
+def binary_crossentropy(y_true, y_pred):
-        return bce.mean()
+    return bce.mean()
-def time_distributed_softmax(x):
+def time_distributed_softmax(x, mask_val=default_mask_val):
-    return T.nnet.softmax(X).reshape(xshape)
+    mask = get_mask(X, mask_val)
-    return get_from_module(identifier, globals(), 'activation function')
+    return get_from_module(identifier, globals(), 'activation function')
-from ..utils.theano_utils import shared_zeros, floatX, shared_scalar, get_mask
+from ..utils.theano_utils import shared_zeros, floatX, shared_scalar, get_mask, default_mask_val
-from ..layers.core import Layer, default_mask_val
+from ..utils.theano_utils import shared_scalar, shared_zeros, alloc_zeros_matrix, get_mask, default_mask_val
-model2.add(TimeDistributedDense(4,4)) # obviously this is redundant. Just testing.
+model2.add(TimeDistributedDense(4,4))
-X2 = np.random.random_integers(1, 4, size=(1,5))
+X2 = np.random.random_integers(1, 4, size=(2,5))
-    padded = np.concatenate((np.zeros((1, pre_zeros)), X2), axis=1)
+    padded = np.concatenate((np.zeros((2, pre_zeros)), X2), axis=1)
-y = np.zeros((len(sentences), len(chars)))
+X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)
-    y[i, char_indices[next_chars[i]]] = 1.
+        X[i, t, char_indices[char]] = 1
-        weights=None, truncate_gradient=-1, return_sequences=False):
+        weights=None, truncate_gradient=-1, return_sequences=False, mask_val=default_mask_val):
-        xz_t, xr_t, xh_t, 
+        xz_t, xr_t, xh_t, mask_tm1,
-        h_t = z * h_tm1 + (1 - z) * hh_t
+        h_mask_tm1 = mask_tm1 * h_tm1
-            sequences=[x_z, x_r, x_h], 
+            sequences=[x_z, x_r, x_h, padded_mask], 
-        weights=None, truncate_gradient=-1, return_sequences=False):
+        weights=None, truncate_gradient=-1, return_sequences=False, mask_val=default_mask_val):
-        xi_t, xf_t, xo_t, xc_t, 
+        xi_t, xf_t, xo_t, xc_t, mask_tm1,
-        o_t = self.inner_activation(xo_t + T.dot(h_tm1, u_o))
+        h_mask_tm1 = mask_tm1 * h_tm1
-            sequences=[xi, xf, xo, xc],
+            sequences=[xi, xf, xo, xc, padded_mask],
-from keras.layers.recurrent import SimpleRNN, SimpleDeepRNN
+from keras.layers.recurrent import SimpleRNN, SimpleDeepRNN, LSTM, GRU
-    def _step(self, x_t, mask_t, mask_tm1, h_tm1, u):
+    def _step(self, x_t, mask_tm1, h_tm1, u):
-        return mask_t * normal_output
+        return self.activation(x_t + mask_tm1 * T.dot(h_tm1, u))
-            sequences=[x, dict(input=padded_mask,taps=[0, -1])], # tensors to iterate over, inputs to _step
+            sequences=[x, dict(input=padded_mask, taps=[-1])], # tensors to iterate over, inputs to _step
-        outputs = mask*outputs + (1-mask)*self.mask_val
+        outputs = mask * outputs + (1 - mask) * self.mask_val
-    def _step(self, x_t, mask_t, *args):
+    def _step(self, x_t, *args):
-        return mask_t*self.activation(o)
+        return self.activation(o)
-                taps = [(-i) for i in range(self.depth+1)]
+                taps = [(-i) for i in range(self.depth)]
-        outputs = mask*outputs + (1-mask)*self.mask_val
+        outputs = mask * outputs + (1 - mask) * self.mask_val
-default_mask_val = -999.
+default_mask_val = -999
-        return mask*X + (1-mask)*self.mask_val
+        return mask * X + (1 - mask) * self.mask_val
-        W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
+        W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None, mask_val=default_mask_val):
-            return self.activation(T.dot(X, self.W) + self.b)
+        def act_func(X, mask):
-                                sequences = X.dimshuffle(1,0,2),
+                                sequences = [X, mask],
-from keras.layers.core import Dense, Activation, Merge, Dropout
+from keras.layers.core import Dense, Activation, Merge, Dropout, TimeDistributedDense
-        train_loss = self.loss(self.y, self.y_train, self.loss_weights)
+        train_loss = self.loss(self.y, self.y_train)
-            train_ins = self.X_train + [self.y, self.loss_weights]
+            train_ins = self.X_train + [self.y]
-            train_ins = [self.X_train, self.y, self.loss_weights]
+            train_ins = [self.X_train, self.y]
-    def train(self, X, y, accuracy=False, sample_weight=None, class_weight=None):
+    def train(self, X, y, accuracy=False):
-        ins = X + [y, w]
+        ins = X + [y]
-            sample_weight=None, class_weight=None):
+            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False):
-                ins = X_batch + [y_batch, w]
+                ins = X_batch + [y_batch]
-def categorical_crossentropy(y_true, y_pred, weight=None):
+def mean_squared_error(y_true, y_pred):
-        return cce.mean()
+    return cce.mean()
-def binary_crossentropy(y_true, y_pred, weight=None):
+def binary_crossentropy(y_true, y_pred):
-        return bce.mean()
+    return bce.mean()
-from ..utils.theano_utils import shared_zeros, floatX
+from ..utils.theano_utils import shared_zeros, floatX, shared_scalar, get_mask
-    def __init__(self, p):
+    def __init__(self, p, mask_val=default_mask_val):
-        return X
+        return mask*X + (1-mask)*self.mask_val
-from ..utils.theano_utils import shared_scalar, shared_zeros, alloc_zeros_matrix
+from ..utils.theano_utils import shared_scalar, shared_zeros, alloc_zeros_matrix, get_mask
-
+
-from keras.layers.core import Dense, Activation, Merge
+from keras.layers.core import Dense, Activation, Merge, Dropout
-X = np.random.random_integers(1, 4, size=(400000,4))
+X = np.random.random_integers(1, 4, size=(500000,15))
-model.add(Dense(3,4, activation='softmax'))
+model.add(Embedding(5, 4, zero_is_mask=True))
-Xmask0[:,0] = 0
+Xmask0[:,10] = 0
-Xmask12[:,2] = 0
+Xmask12[:,11] = 0
-    X1_onehot[i, row[1]-1] = 1
+    X0_onehot[i, row[10]-1] = 1
-    if type(identifier) is str:
+    if isinstance(identifier, basestring):
-        self.cost_updates = [] # NOT the same size as params
+        self.cost_updates = [] # size can vary, no 1-to-1 mapping to params
-import time
+import time, json
-    def __init__(self, patience=1, verbose=0):
+    def __init__(self, patience=0, verbose=0):
-max_test_samples = 10000
+max_train_samples = 5000
-X_test = X_test.reshape(10000,784)[:max_test_samples]
+X_train = X_train.reshape(60000, 784)[:max_train_samples]
-class_weight[weighted_class] = high_weight
+class TestConcatenation(unittest.TestCase):
-sample_weight[y_train == weighted_class] = high_weight
+    def test_loss_weighting(self):
-    assert(score < standard_score)
+        sample_weight = np.ones((y_train.shape[0])) * standard_weight
-        w = np.array(map(lambda x: class_weight[x], y_classes))
+        w = np.array(list(map(lambda x: class_weight[x], y_classes)))
-
+        f.close()
-        return T.sqr(weight.reshape((weight.shape[0], 1))*(y_pred - y_true)).mean()
+        return T.sqr(weight.reshape((weight.shape[0], 1)) * (y_pred - y_true)).mean()
-        return T.abs_(weight.reshape((weight.shape[0], 1))*(y_pred - y_true)).mean()
+        return T.abs_(weight.reshape((weight.shape[0], 1)) * (y_pred - y_true)).mean()
-        return T.sqr(weight*T.maximum(1. - (y_true * y_pred), 0.)).mean()
+        return T.sqr(weight * T.maximum(1. - (y_true * y_pred), 0.)).mean()
-        return (weight*T.maximum(1. - (y_true * y_pred), 0.)).mean()
+        return (weight * T.maximum(1. - (y_true * y_pred), 0.)).mean()
-        return (weight*cce).mean()
+        return (weight * cce).mean()
-        return (weight.reshape((weight.shape[0], 1))*bce).mean()
+        return (weight.reshape((weight.shape[0], 1)) * bce).mean()
-    return Y
+    return get_from_module(identifier, globals(), 'objective')
-from keras.optimizers import SGD
+from keras.layers.core import Dense, Activation
-max_test_samples = 1000
+nb_epoch = 5
-X_test /= 255
+X_train = X_train.astype("float32") / 255
-def createMNISTModel():
+def create_model():
-print("hinge: %0.2f VS %0.2f" % (neg_preds, pos_preds))
+def test_weights(model, class_weight=None, sample_weight=None):
-print("sqr hinge: %0.2f VS %0.2f" % (neg_preds, pos_preds))
+class_weight = dict([(i, standard_weight) for i in range(nb_classes)])
-
+for loss in ['mae', 'mse', 'categorical_crossentropy']:
-srng = RandomStreams()
+srng = RandomStreams(seed=np.random.randint(10e6))
-            import warnings
+
-        callbacks.append(cbks.History())
+            callbacks = [cbks.BaseLogger()] + callbacks
-        return callbacks.callbacks[-1]
+        return callbacks.callbacks[0] # return history
-model.add(Dense(64*8*8, 512, init='normal'))
+model.add(Dense(64*8*8, 512))
-model.add(Dense(512, nb_classes, init='normal'))
+model.add(Dense(512, nb_classes))
-from keras.constraints import maxnorm
+
-X_test = X_test.reshape(10000,784)
+X_train = X_train.reshape(60000, 784)
-model.add(Dense(max_words, 256, init='normal'))
+model.add(Dense(max_words, 512))
-model.add(Dense(256, nb_classes, init='normal'))
+model.add(Dense(512, nb_classes))
-history = model.fit(X_train, Y_train, nb_epoch=4, batch_size=batch_size, verbose=1, show_accuracy=True, validation_split=0.1)
+history = model.fit(X_train, Y_train, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1, show_accuracy=True, validation_split=0.1)
-batch_size = 64
+batch_size = 128
-        w = sample_weight
+        if isinstance(sample_weight, list):
-        sample_weight = standardize_sample_weights(sample_weight)
+        sample_weight = calculate_loss_weights(y, sample_weight=sample_weight, class_weight=class_weight)
-                    w = calculate_loss_weights(y_batch, class_weight=class_weight)
+                w = sample_weight[batch_ids]
-        vector in X that has every entry equal to mask_val.
+        tensor and, if steps_back>0, a padded_mask tensor  with dimension (timesteps + steps_back, nb_samples, 1).
-        mask = T.concatenate([pad, mask], axis=0)
+        return mask, T.concatenate([pad, mask], axis=0)
-        return mask_t * normal_output + (1 - mask_t) * self.mask_val
+        return mask_t * normal_output
-        mask = get_mask(X, self.mask_val, steps_back=1)
+        mask, padded_mask = get_mask(X, self.mask_val, steps_back=1)
-            sequences=[x, dict(input=mask,taps=[0, -1])], # tensors to iterate over, inputs to _step
+            sequences=[x, dict(input=padded_mask,taps=[0, -1])], # tensors to iterate over, inputs to _step
-        return result
+        return mask_t*self.activation(o)
-        mask = get_mask(X, self.mask_val, steps_back=self.depth)
+        mask, padded_mask = get_mask(X, self.mask_val, steps_back=self.depth)
-                input = mask,
+                input = padded_mask,
-        weights=None, truncate_gradient=-1, return_sequences=False):
+        weights=None, truncate_gradient=-1, return_sequences=False, mask_val=default_mask_val):
-        return self.activation(o)
+    def _step(self, x_t, mask_t, *args):
-            sequences=x,
+            sequences=[x, dict(
-                initial=T.alloc(np.cast[theano.config.floatX](0.), self.depth, X.shape[1], self.output_dim),
+                initial = initial,
-from keras.layers.recurrent import SimpleRNN
+from keras.layers.recurrent import SimpleRNN, SimpleDeepRNN
-X = np.random.random_integers(1, 4, size=(400000,3))
+X = np.random.random_integers(1, 4, size=(400000,4))
-model.add(SimpleRNN(3,3, activation='relu'))
+# This next one is basically just a SimpleRNN, but I'm testing that the masking is
-Xmask1[:,1] = 0
+Xmask12 = X.copy()
-# Finally, make sure the mask is actually blocking input, mask out timestep 1, and see if
+# Finally, make sure the mask is actually blocking input, mask out timesteps 1 and 2, and see if
-model.fit(Xmask1, X0_onehot, nb_epoch=1, batch_size=batch_size)
+model.fit(Xmask12, X0_onehot, nb_epoch=1, batch_size=batch_size)
-score = model.evaluate(Xmask1, X0_onehot, batch_size=batch_size)
+score = model.evaluate(Xmask12, X0_onehot, batch_size=batch_size)
-        mask_tm1 = T.addbroadcast(T.set_subtensor(mask_tm1[1:, :, :], mask[:-1, :, :]), 2)
+        mask = get_mask(X, self.mask_val, steps_back=1)
-            sequences=[x, mask, mask_tm1], # tensors to iterate over, inputs to _step
+            sequences=[x, dict(input=mask,taps=[0, -1])], # tensors to iterate over, inputs to _step
-
+
-        w = instance_weight
+def standardize_sample_weights(sample_weight):
-        w = instance_weight
+def calculate_loss_weights(Y, sample_weight=None, class_weight=None):
-    def train(self, X, y, accuracy=False, instance_weight=None, class_weight=None):
+    def train(self, X, y, accuracy=False, sample_weight=None, class_weight=None):
-        w = calculate_loss_weights(y, instance_weight=instance_weight, class_weight=class_weight)
+        sample_weight = standardize_sample_weights(sample_weight)
-            instance_weight=None, class_weight=None):
+            sample_weight=None, class_weight=None):
-        instance_weight = standardize_instance_weights(instance_weight)
+        sample_weight = standardize_sample_weights(sample_weight)
-                    w = calculate_loss_weights(y_batch, instance_weight=instance_weight[batch_ids])
+                if sample_weight is not None:
-            T.set_subtensor(self.W[0, :], mask_val)
+            # This doesn't seem particularly elegant
-        return mask_t * self.activation(x_t + mask_tm1 * T.dot(h_tm1, u))
+        normal_output = self.activation(x_t + mask_tm1 * T.dot(h_tm1, u))
-if model.layers[0].W.get_value()[0,:] != default_mask_val:
+W0 = model.layers[0].W.get_value()[0,:]
-            model.layers[0].W.get_value()[0,:]
+            W0)
-score = model.evaluate(X, X0_onehot)
+model.fit(X, X0_onehot, nb_epoch=1, batch_size=batch_size)
-            model.layers[0].W.get_value()[0,:]
+W0 = model.layers[0].W.get_value()[0,:]
-score = model.evaluate(X[:,1:], X1_onehot)
+model.fit(X[:,1:], X1_onehot, nb_epoch=1, batch_size=batch_size)
-score = model.evaluate(Xmask0, X0_onehot)
+model.fit(Xmask0, X0_onehot, nb_epoch=1, batch_size=batch_size)
-score = model.evaluate(Xmask0, X1_onehot)
+model.fit(Xmask0, X1_onehot, nb_epoch=1, batch_size=batch_size)
-    def __init__(self, input_dim, output_dim, init='uniform', weights=None, W_regularizer=None, W_constraint=None, mask_val=default_mask_val):
+    def __init__(self, input_dim, output_dim, init='uniform', weights=None, W_regularizer=None, W_constraint=None, zero_is_mask=False, mask_val=default_mask_val):
-        T.set_subtensor(self.W[0, :], mask_val)
+        self.zero_is_mask = zero_is_mask
-model.add(Embedding(5, 2))
+model.add(Embedding(5, 2, zero_is_mask=True))
-        mask_tm1 = alloc_zeros_matrix(*mask.shape)
+        mask_tm1 = alloc_zeros_matrix(*mask.shape).astype('int8')
-        mask = T.neq(x, self.mask_val).sum(axis=2) > 0 # (time, nb_samples) matrix with a 1 for every unmasked entry
+        mask = T.neq(X, self.mask_val).sum(axis=2) > 0 # (time, nb_samples) matrix with a 1 for every unmasked entry
-        mask_tm1 = T.addbroadcast(T.set_subtensor(mask[1:, :, :], mask[:-1, :, :]), 2)
+        mask_tm1 = T.addbroadcast(T.set_subtensor(mask_tm1[1:, :, :], mask[:-1, :, :]), 2)
-    def _step(self, x_t, mask_t, h_tm1, u):
+    def _step(self, x_t, mask_t, mask_tm1, h_tm1, u):
-        return mask_t * self.activation(x_t + T.dot(h_tm1, u))
+        return mask_t * self.activation(x_t + mask_tm1 * T.dot(h_tm1, u))
-            sequences=[x, mask], # tensors to iterate over, inputs to _step
+            sequences=[x, mask, mask_tm1], # tensors to iterate over, inputs to _step
-        mask = T.neq(x,self.mask_val).sum(axis=2)>0 # (time, nb_samples) matrix with a 1 for every unmasked entry
+        mask = T.neq(x, self.mask_val).sum(axis=2) > 0 # (time, nb_samples) matrix with a 1 for every unmasked entry
-        T.set_subtensor(self.W[0,:], mask_val)
+        T.set_subtensor(self.W[0, :], mask_val)
-        return mask_t*self.activation(x_t + T.dot(h_tm1, u))
+        return mask_t * self.activation(x_t + T.dot(h_tm1, u))
-        mask = T.addbroadcast(mask[:,:,np.newaxis], 2)
+        mask = T.addbroadcast(mask[:, :, np.newaxis], 2)
-from ..layers.core import Layer
+from ..layers.core import Layer, default_mask_val
-    def __init__(self, input_dim, output_dim, init='uniform', weights=None, W_regularizer=None, W_constraint=None):
+    def __init__(self, input_dim, output_dim, init='uniform', weights=None, W_regularizer=None, W_constraint=None, mask_val=default_mask_val):
-from ..layers.core import Layer
+from ..utils.theano_utils import shared_scalar, shared_zeros, alloc_zeros_matrix
-        truncate_gradient=-1, return_sequences=False):
+        truncate_gradient=-1, return_sequences=False, mask_val=default_mask_val):
-    def _step(self, x_t, h_tm1, u):
+    def _step(self, x_t, mask_t, h_tm1, u):
-        return self.activation(x_t + T.dot(h_tm1, u))
+        return mask_t*self.activation(x_t + T.dot(h_tm1, u))
-            sequences=x, # tensors to iterate over, inputs to _step
+            sequences=[x, mask], # tensors to iterate over, inputs to _step
-def pad_sequences(sequences, maxlen=None, dtype='int32'):
+def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre'):
-        x[idx, :lengths[idx]] = s[:maxlen]
+        if padding == 'post':
-    if isinstance(class_weight, dict):
+def standardize_instance_weights(instance_weight):
-        self.class_weights = T.vector()
+        self.loss_weights = T.vector()
-        train_loss = self.loss(self.y, self.y_train, self.class_weights)
+        train_loss = self.loss(self.y, self.y_train, self.loss_weights)
-            train_ins = self.X_train + [self.y, self.class_weights]
+            train_ins = self.X_train + [self.y, self.loss_weights]
-            train_ins = [self.X_train, self.y, self.class_weights]
+            train_ins = [self.X_train, self.y, self.loss_weights]
-    def train(self, X, y, accuracy=False, class_weight=None):
+    def train(self, X, y, accuracy=False, instance_weight=None, class_weight=None):
-        w = calculate_class_weights(y, class_weight)
+
-            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False, class_weight=None):
+            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False,
-                w = calculate_class_weights(y_batch, class_weight)
+                if instance_weight is not None:
-            return l * T.sum(T.mean(T.abs(layer.get_output(True)), axis=0))
+            return l * T.sum(T.mean(abs(layer.get_output(True)), axis=0))
-            return l * T.sum(T.mean(layer.get_output(True)**2, axis=0))
+            return l * T.sum(T.mean(T.abs(layer.get_output(True)), axis=0))
-            self.cost_updates.append(layer.activity_regularizer)
+        if hasattr(layer, 'cost_update'):
-        self.activity_regularizer = activity_regularizer(self.get_output())
+        super(ActivityRegularization, self).__init__()
-        if hasattr(self,'cost_updates'):
+        if hasattr(self, 'cost_updates'):
-                train_loss += u
+                train_loss += u()
-    return g
+    return g
-        updates = self.optimizer.get_updates(self.params, self.regularizers, self.constraints, train_loss)
+        if hasattr(self,'cost_updates'):
-    def get_updates(self, params, grads):
+    def get_updates(self, params, regularizers, constraints,  cost):
-                    print("Epoch %05d: valdidation loss improved from %0.5f to %0.5f, saving model to %s"
+                    print("Epoch %05d: validation loss improved from %0.5f to %0.5f, saving model to %s"
-from keras.layers.core import Dense, Activation
+from keras.layers.core import Dense, Activation, Dropout
-step = 5
+# cut the text in semi-redundant sequences of maxlen characters
-for iteration in range(1, 30):
+# train the model, output generated text after each iteration
-    for diversity in [0.4, 0.7, 1.]:
+    for diversity in [0.2, 0.4, 0.6, 0.8]:
-
+        print()
-from keras.layers.core import Dense, Activation, Merge
+from keras.layers.core import Dense, Activation, Merge, Dropout
-########################
+############################
-        return T.sqr(T.maximum(1. - weight.reshape((weight.shape[0], 1))*(y_true * y_pred), 0.)).mean()
+        weight = weight.reshape((weight.shape[0], 1))
-        return T.maximum(1. - weight.reshape((weight.shape[0], 1))*(y_true * y_pred), 0.).mean()
+        weight = weight.reshape((weight.shape[0], 1))
-        return T.sqr(weight*(y_pred - y_true)).mean()
+        return T.sqr(weight.reshape((weight.shape[0], 1))*(y_pred - y_true)).mean()
-        return T.abs_(weight*(y_pred - y_true)).mean()
+        return T.abs_(weight.reshape((weight.shape[0], 1))*(y_pred - y_true)).mean()
-        return T.sqr(T.maximum(1. - weight*(y_true * y_pred), 0.)).mean()
+        return T.sqr(T.maximum(1. - weight.reshape((weight.shape[0], 1))*(y_true * y_pred), 0.)).mean()
-        return T.maximum(1. - weight*(y_true * y_pred), 0.).mean()
+        return T.maximum(1. - weight.reshape((weight.shape[0], 1))*(y_true * y_pred), 0.).mean()
-        return (weight*bce).mean()
+        return (weight.reshape((weight.shape[0], 1))*bce).mean()
-epsilon = 1.0e-15
+epsilon = 1.0e-9
-    bce = T.nnet.binary_crossentropy(y_pred, y_true).mean()
+    bce = T.nnet.binary_crossentropy(y_pred, y_true)
-      version = '0.1.0',
+      version = '0.1.1',
-      download_url = 'https://github.com/fchollet/keras/tarball/0.1.0',
+      download_url = 'https://github.com/fchollet/keras/tarball/0.1.1',
-)
+setup(name = 'Keras',
-        image_shape=None, border_mode='valid', subsample=(1,1)):
+        image_shape=None, border_mode='valid', subsample=(1,1),
-        image_shape=None, border_mode='valid', subsample_length=1):
+        image_shape=None, border_mode='valid', subsample_length=1,
-score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=1, show_accuracy=False)
+history = model.fit(X_train, Y_train, nb_epoch=4, batch_size=batch_size, verbose=1, show_accuracy=True, validation_split=0.1)
-        subsample=(1,subsample_length)
+        
-        self.subsample = subsample
+        self.subsample = (1, subsample_length)
-    def output(self, train):
+    def get_output(self, train):
-        self.poolsize = poolsize
+        self.pool_length = pool_length
-    def output(self, train):
+    def get_output(self, train):
-        self.callbacks = callbacks
+    def __init__(self, callbacks=[], queue_length=10):
-model_fit.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=3, validation_data=(X_test, Y_test))
+model_classweights_fit.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_data=(X_test, Y_test), class_weight=class_weight)
-print('Classification accuracies on test set:')
+print('MNIST Classification accuracies on test set for fitted models:')
-        self.U = self.init((self.output_dim, self.output_dim))
+        self.U = self.inner_init((self.output_dim, self.output_dim))
-          - If output_reconstruction then dim(input) = dim(output) else dim(output) = dim(hidden)
+        If output_reconstruction then dim(input) = dim(output)
-    def __init__(self, encoders=[], decoders=[], output_reconstruction=True, tie_weights=False, weights=None):
+    def __init__(self, encoder, decoder, output_reconstruction=True, tie_weights=False, weights=None):
-        self.decoders = decoders
+        self.encoder = encoder
-                self.constraints += m.constraints
+        for layer in [self.encoder, self.decoder]:
-        self.encoders[0].previous = node
+        self.encoder.previous = node
-            weights += m.get_weights()
+        for layer in [self.encoder, self.decoder]:
-            weights = weights[nb_param:]
+        nb_param = len(self.encoder.params)
-            return self.encoders[0].input
+        return self.encoder.get_input(train)
-        return self.get_input()
+        return self.encoder.input
-            dest = src.T
+        return self.encoder.get_output(train)
-            return self._get_hidden(train)
+        decoded = self.decoder.get_output(train)
-                map(self._tranpose_weights, e.get_weights(), d.get_weights())
+            encoder_params = self.encoder.get_weights()
-        return self.decoders[-1].get_output(train)
+        return decoded
-                "decoder_config":[d.get_config() for d in self.decoders],
+                "encoder_config":self.encoder.get_config(),
-        super(DenoisingAutoEncoder, self).__init__(encoders, decoders, output_reconstruction, tie_weights, weights)
+    def __init__(self, encoder=None, decoder=None, output_reconstruction=True, tie_weights=False, weights=None, corruption_level=0.3):
-                "decoder_config":[d.get_config() for d in self.decoders],
+                "encoder_config":self.encoder.get_config(),
-autoencoder_type = 'classical'
+autoencoder_type = 'denoising'
-nb_epoch = 10
+nb_epoch = 5
-classical_score = model_classical.evaluate(X_test, Y_test, verbose=0)
+classical_score = model_classical.evaluate(X_test, Y_test, verbose=0, show_accuracy=True)
-								decoders=[LSTM(8, input_dim, activation=activation, return_sequences=True)],
+	autoencoder.add(AutoEncoder(encoder=LSTM(16, 8, activation=activation, return_sequences=True),
-	autoencoder.add(AutoEncoder(encoders=encoders, decoders=decoders, output_reconstruction=False, tie_weights=True))
+	encoder = containers.Sequential([Dense(input_dim, hidden_dim, activation=activation), Dense(hidden_dim, hidden_dim/2, activation=activation)])
-										 decoders=[Dense(hidden_dim, input_dim, activation=activation)],
+	autoencoder.add(DenoisingAutoEncoder(encoder=Dense(input_dim, hidden_dim, activation=activation),
-	model.add(TimeDistributedDense(8, 10, activation=activation))
+	model.add(TimeDistributedDense(8, nb_classes, activation=activation))
-	model.add(Dense(196, 10, activation=activation))
+	model.add(Dense(prefilter_train.shape[1], nb_classes, activation=activation))
-	model.add(Dense(392, 10, activation=activation))
+	model.add(Dense(prefilter_train.shape[1], nb_classes, activation=activation))
-score = model.evaluate(prefilter_test, Y_test, verbose=0, show_accuracy=False)
+score = model.evaluate(prefilter_test, Y_test, verbose=0, show_accuracy=True)
-	print("autoencoder improvement: ", 100.0*(float(score)-float(classical_score))/float(classical_score), "%")
+print('Loss change:', (score[0] - classical_score[0])/classical_score[0], '%')
-            overwrite = input('[WARNING] %s already exists - overwrite? [y/n]' % (filepath))
+            import sys
-                overwrite = input('Enter "y" (overwrite) or "n" (cancel).')
+                overwrite = get_input('Enter "y" (overwrite) or "n" (cancel).')
-print('Running model checkpointer test')
+print('Running ModelCheckpoint test')
-raise Exception("Tests did not pass")
+raise Exception("Modelcheckpoint tests did not pass")
-
+import keras.callbacks as cbks
-max_train_samples = 5000
+max_train_samples = 512
-    def on_train_begin(self):
+    def on_train_begin(self, logs={}):
-    def on_epoch_begin(self, epoch):
+    def on_epoch_begin(self, epoch, logs={}):
-    def on_batch_end(self, batch):
+    def on_batch_end(self, batch, logs={}):
-    def on_train_end(self):
+    def on_train_end(self, logs={}):
-        
+
-    return T.sqr(y_pred - y_true).mean()
+    if weight is not None:
-    return T.abs_(y_pred - y_true).mean()
+    if weight is not None:
-    return T.sqr(T.maximum(1. - y_true * y_pred, 0.)).mean()
+    if weight is not None:
-    return T.maximum(1. - y_true * y_pred, 0.).mean()
+    if weight is not None:
-        return T.sqr(y_pred - y_true).mean()
+    return T.sqr(y_pred - y_true).mean()
-        return T.abs_(y_pred - y_true).mean()
+    return T.abs_(y_pred - y_true).mean()
-        return T.sqr(T.maximum(1. - y_true * y_pred, 0.)).mean()
+    return T.sqr(T.maximum(1. - y_true * y_pred, 0.)).mean()
-        return T.maximum(1. - y_true * y_pred, 0.).mean()
+    return T.maximum(1. - y_true * y_pred, 0.).mean()
-    return T.sqr(y_pred - y_true).mean()
+def mean_squared_error(y_true, y_pred, weight=None):
-    return T.abs_(y_pred - y_true).mean()
+def mean_absolute_error(y_true, y_pred, weight=None):
-    return T.sqr(T.maximum(1. - y_true * y_pred, 0.)).mean()
+def squared_hinge(y_true, y_pred, weight=None):
-    return T.maximum(1. - y_true * y_pred, 0.).mean()
+def hinge(y_true, y_pred, weight=None):
-    def __init__(self, filename="model_weights.hdf5", path=".", verbose=0, save_best_only=False):
+    def __init__(self, filepath, verbose=0, save_best_only=False):
-        self.store_filename = os.path.join(path, filename)
+        
-
+        self.filepath = filepath
-                        % (epoch, self.best_val_loss, cur_val_loss, self.store_filename))
+                        % (epoch, self.best_val_loss, cur_val_loss, self.filepath))
-                self.model.save_weights(self.store_filename, overwrite=True)
+                self.model.save_weights(self.filepath, overwrite=True)
-            self.model.save_weights(self.store_filename, overwrite=True)
+                print("Epoch %05d: saving model to %s" % (epoch, self.filepath))
-checkpointer = cbks.ModelCheckpoint(filename=filename, path=path, verbose=1, save_best_only=True)
+checkpointer = cbks.ModelCheckpoint(filepath=f, verbose=1, save_best_only=True)
-            raise IOError('%s already exists' % (filepath))
+            overwrite = input('[WARNING] %s already exists - overwrite? [y/n]' % (filepath))
-from . import constraints
+# -*- coding: utf-8 -*-
-        self.previous = node
+    def connect(self, layer):
-        return self.get_input()    
+        return self.get_input()
-import warnings
+import warnings, time, copy
-import time, copy
+from .layers import containers
-
+
-            weights = weights[nb_param:]
+        elif Y.shape[1] == 1:
-def binary_crossentropy(y_true, y_pred):
+def binary_crossentropy(y_true, y_pred, weight=None):
-    return T.nnet.binary_crossentropy(y_pred, y_true).mean()
+    bce = T.nnet.binary_crossentropy(y_pred, y_true).mean()
-            train_ins = self.X_train + [self.y] + [self.class_weights]
+            train_ins = self.X_train + [self.y, self.class_weights]
-        w = self.calculate_class_weights(y, class_weight)
+        w = calculate_class_weights(y, class_weight)
-        ins = X + [y] + [w]
+        ins = X + [y, w]
-                w = self.calculate_class_weights(y_batch, class_weight)
+                w = calculate_class_weights(y_batch, class_weight)
-                ins = X_batch + [y_batch] + [w]
+                ins = X_batch + [y_batch, w]
-        for m in encoders + decoders:
+        for m in self.encoders + self.decoders:
-        models = encoders + decoders
+        models = self.encoders + self.decoders
-        for i in xrange(len(encoders)-1, 0, -1):
+        for i in range(len(encoders)-1, 0, -1):
-    def __init__(self, encoders=None, decoders=None, output_reconstruction=True, tie_weights=False, weights=None, corruption_level=0.3):
+    def __init__(self, encoders=[], decoders=[], output_reconstruction=True, tie_weights=False, weights=None, corruption_level=0.3):
-X_test = X_test.reshape(10000,input_dim)[:max_test_samples]
+X_train = X_train.reshape(60000, input_dim)[:max_train_samples]
-								, output_reconstruction=False, tie_weights=True))
+	autoencoder.add(AutoEncoder(encoders=[LSTM(16, 8, activation=activation, return_sequences=True)],
-										, output_reconstruction=False, tie_weights=True, corruption_level=0.3))
+	autoencoder.add(DenoisingAutoEncoder(encoders=[Dense(input_dim, hidden_dim, activation=activation)],
-            callbacks.append(cbks.History())
+        callbacks.append(cbks.History())
-        if verbose==1:
+        if verbose == 1:
-            if verbose==1:
+            if verbose == 1:
-        if preds.min()<0 or preds.max()>1:
+        if preds.min() < 0 or preds.max() > 1:
-            return (proba>0.5).astype('int32')
+            return (proba > 0.5).astype('int32')
-        if len(dest.shape) > 1:
+        if len(dest.shape) > 1 and len(src.shape) > 1:
-        return decode
+        return self.decoders[-1].get_output(train)
-        else dim(output) = dim(hidden)
+          - Supports deep architectures by passing appropriate encoders/decoders list
-    def __init__(self, encoder=None, decoder=None, output_reconstruction=True, tie_weights=False, weights=None):
+    def __init__(self, encoders=[], decoders=[], output_reconstruction=True, tie_weights=False, weights=None):
-        if encoder is None or decoder is None:
+        if not encoders or not decoders:
-            raise Exception("Only Layer types are supported as inputs for autoencoders")
+        if not len(encoders) == len(decoders):
-        self.hidden_dim = decoder.input_dim
+        # connect all encoders & decoders to their previous (respectively)
-        self.decoder.connect(self.encoder)
+        self.encoders = encoders
-        for m in [encoder, decoder]:
+        for m in encoders + decoders:
-        self.encoder.previous = node
+        self.encoders[0].previous = node
-        for m in [encoder, decoder]:
+        for m in encoders + decoders:
-        models = [encoder, decoder]
+        models = encoders + decoders
-            return  self.encoder.previous.get_output(train=train)
+        if hasattr(self.encoders[0], 'previous'):
-            return self.encoder.input
+            return self.encoders[0].input
-        return self.encoder.get_output(train)
+        return self.encoders[-1].get_output(train)
-        decode = self.decoder.get_output(train)
+        decode = self.decoders[-1].get_output(train)
-                    enc_param = dec_param.T
+            for e,d in zip(self.encoders, self.decoders):
-                "decoder_config":self.decoder.get_config(),
+                "encoder_config":[e.get_config() for e in self.encoders],
-        super(DenoisingAutoEncoder, self).__init__(encoder, decoder, output_reconstruction, tie_weights, weights)
+    def __init__(self, encoders=None, decoders=None, output_reconstruction=True, tie_weights=False, weights=None, corruption_level=0.3):
-                "decoder_config":self.decoder.get_config(),
+                "encoder_config":[e.get_config() for e in self.encoders],
-autoencoder_type = 'lstm'
+autoencoder_type = 'classical'
-								, output_reconstruction=False))
+	autoencoder.add(AutoEncoder(encoders=[LSTM(16, 8, activation=activation, return_sequences=True)]
-								, output_reconstruction=False, tie_weights=True))
+def build_deep_classical_autoencoder(autoencoder):
-										, decoder=Dense(hidden_dim, input_dim, activation=activation)
+	autoencoder.add(DenoisingAutoEncoder(encoders=[Dense(input_dim, hidden_dim, activation=activation)]
-	autoencoder = build_classical_autoencoder(autoencoder)
+	autoencoder = build_deep_classical_autoencoder(autoencoder)
-autoencoder.fit(X_train, X_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0)
+autoencoder.fit(X_train, X_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1)
-        train_loss = self.loss(self.y, self.y_train)
+        # parameter for rescaling the objective function
-            train_ins = self.X_train + [self.y]
+            train_ins = self.X_train + [self.y] + [self.class_weights]
-            train_ins = [self.X_train, self.y]
+            train_ins = [self.X_train, self.y, self.class_weights]
-    def train(self, X, y, accuracy=False):
+    def train(self, X, y, accuracy=False, class_weight=None):
-        ins = X + [y]
+
-            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False):
+            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False, class_weight=None):
-                ins = X_batch + [y_batch]
+                ins = X_batch + [y_batch] + [w]
-def categorical_crossentropy(y_true, y_pred):
+def categorical_crossentropy(y_true, y_pred, weight=None):
-    return T.nnet.categorical_crossentropy(y_pred, y_true).mean()
+    cce = T.nnet.categorical_crossentropy(y_pred, y_true)
-                 weights=None, W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
+    def __init__(self, encoder=None, decoder=None, output_reconstruction=True, tie_weights=False, weights=None):
-                                                   weights, W_regularizer, b_regularizer, W_constraint, b_constraint)
+    def __init__(self, encoder=None, decoder=None, output_reconstruction=True, tie_weights=False, weights=None, corruption_level=0.3):
-            decoder = f(W'.encoder + b_decoder)
+        A customizable autoencoder model.
-                 W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None):
+    def __init__(self, encoder=None, decoder=None, output_reconstruction=True, tie_weights=False,
-        self.hidden_dim = hidden_dim
+        if encoder is None or decoder is None:
-        self.decoder_bias = shared_zeros((self.input_dim))
+        if not isinstance(encoder, Layer) or not isinstance(decoder, Layer):
-        self.params = [self.W, self.encoder_bias, self.decoder_bias]
+        self.input_dim = encoder.input_dim
-        self.constraints = [W_constraint, b_constraint]
+        self.decoder.connect(self.encoder)
-        return encode
+    def connect(self, node):
-        decode = self.decoder_activation(T.dot(encode, self.W.T) + self.decoder_bias)
+        if not train and not self.output_reconstruction:
-            "decoder_activation":self.decoder_activation.__name__,}
+                "encoder_config":self.encoder.get_config(),
-            decoder = f(W'.encoder + b_decoder)
+        A denoising autoencoder model that inherits the base features from autoencoder
-                             W_constraint, b_constraint)
+    def __init__(self, encoder=None, decoder=None, output_reconstruction=True, tie_weights=False,
-    def get_corrupted_input(self, input):
+    def _get_corrupted_input(self, input):
-                             p=1 - self.corruption_level,
+        return srng.binomial(size=(self.input_dim, 1), n=1,
-        return decode
+    def get_input(self, train=False):
-            "decoder_activation":self.decoder_activation.__name__,}
+                "encoder_config":self.encoder.get_config(),
-max_words = 10000
+max_words = 1000
-score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=1, show_accuracy=True)
+history = model.fit(X_train, Y_train, nb_epoch=3, batch_size=batch_size, verbose=1, show_accuracy=False, validation_split=0.1)
-    def on_epoch_begin(self, epoch):
+    def on_epoch_begin(self, epoch, logs={}):
-            callback.on_epoch_begin(epoch)
+            callback.on_epoch_begin(epoch, logs)
-    def on_epoch_end(self, epoch):
+    def on_epoch_end(self, epoch, logs={}):
-            callback.on_epoch_end(epoch)
+            callback.on_epoch_end(epoch, logs)
-    def on_batch_begin(self, batch):
+    def on_batch_begin(self, batch, logs={}):
-            callback.on_batch_begin(batch)
+            callback.on_batch_begin(batch, logs)
-    def on_batch_end(self, batch):
+    def on_batch_end(self, batch, logs={}):
-            callback.on_batch_end(batch)
+            callback.on_batch_end(batch, logs)
-    def on_train_begin(self):
+    def on_train_begin(self, logs={}):
-            callback.on_train_begin()
+            callback.on_train_begin(logs)
-    def on_train_end(self):
+    def on_train_end(self, logs={}):
-            callback.on_train_end()
+            callback.on_train_end(logs)
-    def on_epoch_begin(self, epoch):
+    def on_epoch_begin(self, epoch, logs={}):
-    def on_epoch_end(self, epoch):
+    def on_epoch_end(self, epoch, logs={}):
-    def on_batch_begin(self, batch):
+    def on_batch_begin(self, batch, logs={}):
-    def on_batch_end(self, batch):
+    def on_batch_end(self, batch, logs={}):
-    def on_train_begin(self):
+    def on_train_begin(self, logs={}):
-    def on_train_end(self):
+    def on_train_end(self, logs={}):
-    def on_train_begin(self):
+    def on_train_begin(self, logs={}):
-    def on_epoch_begin(self, epoch):
+    def on_epoch_begin(self, epoch, logs={}):
-        # skip progbar update for the last batch; will be handled by on_epoch_end
+    def on_batch_begin(self, batch, logs={}):
-                self.progbar.update(self.current, self.log_values)
+            self.log_values = []
-        self.log_values.append(('loss', loss))
+    def on_batch_end(self, batch, logs={}):
-            accuracy = self.model.batch_history['accuracy'][-1]
+            accuracy = logs.get('accuracy')
-            val_loss = self.model.epoch_history['val_loss'][-1]
+            val_loss = logs.get('val_loss')
-                val_acc = self.model.epoch_history['val_accuracy'][-1]
+                val_acc = logs.get('val_accuracy')
-                callbacks.on_batch_begin(batch_index)
+                batch_logs = {}
-                    self.batch_history['accuracy'].append(acc)
+                    batch_logs['accuracy'] = acc
-                self.batch_history['loss'].append(loss)
+                batch_logs['loss'] = loss
-                callbacks.on_batch_end(batch_index)
+                callbacks.on_batch_end(batch_index, batch_logs)
-                            self.epoch_history['val_accuracy'].append(val_acc)
+                            epoch_logs['val_accuracy'] = val_acc
-                        self.epoch_history['val_loss'].append(val_loss)
+                        epoch_logs['val_loss'] = val_loss
-            callbacks.on_epoch_end(epoch)
+            callbacks.on_epoch_end(epoch, epoch_logs)
-        return self.epoch_history
+        # return history
-                tot_acc += acc
+                tot_acc += acc * len(y_batch)
-            tot_score += loss
+            tot_score += loss * len(y_batch)
-            return tot_score/len(batches), tot_acc/len(batches)
+            return tot_score / seen, tot_acc / seen
-            return tot_score/len(batches)
+            return tot_score / seen
-                self.sum_values[k] = [v * max(1, current-self.seen_so_far), current-self.seen_so_far]
+                self.sum_values[k] = [v * (current-self.seen_so_far), current-self.seen_so_far]
-    def on_batch_end(self, batch, indices, loss, accuracy):
+    def on_batch_end(self, batch):
-(X_train, y_train), (X_test, y_test) = cifar10.load_data(test_split=0.1)
+(X_train, y_train), (X_test, y_test) = cifar10.load_data()
-# -*- coding: utf-8 -*-
+from .cifar import load_batch
-from six.moves import range
+import os
-def load_data(test_split=0.1, seed=113):
+def load_data():
-        y[(i-1)*10000:i*10000] = labels
+    nb_test_samples = 10000
-    np.random.shuffle(y)
+    X_train = np.zeros((nb_train_samples, 3, 32, 32), dtype="uint8")
-    y_train = y[:int(len(X)*(1-test_split))]
+    for i in range(1, 6):
-    y_test = y[int(len(X)*(1-test_split)):]
+    y_train = np.reshape(y_train, (len(y_train), 1))
-    return (X_train, y_train), (X_test, y_test)
+    return (X_train, y_train), (X_test, y_test) 
-            print 'Epoch %d' % epoch
+            print('Epoch %d' % epoch)
-    def on_epoch_end(self, epoch, val_loss, val_acc):
+    def on_epoch_end(self, epoch):
-            callback.on_epoch_end(epoch, val_loss, val_acc)
+            callback.on_epoch_end(epoch)
-    def on_batch_end(self, batch, indices, loss, accuracy):
+    def on_batch_end(self, batch):
-            callback.on_batch_end(batch, indices, loss, accuracy)
+            callback.on_batch_end(batch)
-    def on_epoch_end(self, epoch, val_loss, val_acc):
+    def on_epoch_end(self, epoch):
-    def on_batch_end(self, batch, indices, loss, accuracy):
+    def on_batch_end(self, batch):
-        self.cum_accuracy = 0.
+        self.tot_loss = 0.
-        self.cum_loss += loss * batch_length
+    def on_batch_end(self, batch):
-            self.cum_accuracy += accuracy * batch_length
+            self.tot_accuracy += self.model.batch_history['accuracy'][-1] * batch_size
-    def on_epoch_end(self, epoch, val_loss, val_acc):
+    def on_epoch_end(self, epoch):
-        self.losses.append(self.cum_loss / self.seen)
+        self.losses.append(self.tot_loss / self.seen)
-            self.accuracies.append(self.cum_accuracy / self.seen)
+            self.accuracies.append(self.tot_accuracy / self.seen)
-class Logger(Callback):
+class BaseLogger(Callback):
-    def on_batch_end(self, batch, indices, loss, accuracy):
+    def on_batch_end(self, batch_index):
-        # TODO: Show validation scores in the logger
+        if self.params['show_accuracy']:
-        callbacks.append(cbks.Logger())
+        if verbose:
-
+        self.batch_history = {
-            if do_validation:
+                ins = X_batch + [y_batch]
-                        verbose=0, show_accuracy=True)
+                    loss, acc = self._train_with_acc(*ins)
-            callbacks.on_epoch_end(epoch, val_loss, val_acc)
+                    loss = self._train(*ins)
-        return True
+        return self.epoch_history
-                self.sum_values[k] = [v * (current-self.seen_so_far), current-self.seen_so_far]
+                self.sum_values[k] = [v * max(1, current-self.seen_so_far), current-self.seen_so_far]
-                info += ' - %s: %.4f' % (k, self.sum_values[k][0]/self.sum_values[k][1])
+                info += ' - %s: %.4f' % (k, self.sum_values[k][0]/ max(1, self.sum_values[k][1]))
-                    info += ' - %s: %.4f' % (k, self.sum_values[k][0]/self.sum_values[k][1])
+                    info += ' - %s: %.4f' % (k, self.sum_values[k][0]/ max(1, self.sum_values[k][1]))
-    def save_weights(self, filepath):
+    def save_weights(self, filepath, overwrite=False):
-        # FIXME: fail if file exists, or add option to overwrite!
+        import os.path
-        
+        
-        cls = model.__class__.__name__
+        clz = model.__class__.__name__
-            self.names[model] = cls + str(self.class_counts[cls])
+            self.class_counts[clz] += 1
-X_test=X_test.reshape(10000,784)
+X_train = X_train.reshape(60000,784)
-    def __init__(self, callbacks):
+
-            and delta_t_callbacks > 0.1:
+        self._delta_ts_batch_begin.append(time.time() - t_before_callbacks)
-                'to the batch update. Check your callbacks.')
+                'to the batch update (%f). Check your callbacks.' % delta_t_median)
-            and delta_t_callbacks > 0.1:
+        self._delta_ts_batch_end.append(time.time() - t_before_callbacks)
-                'to the batch update. Check your callbacks.')
+                'to the batch update (%f). Check your callbacks.' % delta_t_median)
-    """docstring for Callback"""
+
-            warnings.warn('Warning!!')
+        if self._delta_t_batch > 0. and delta_t_callbacks > 0.95 * self._delta_t_batch \
-            warnings.warn('Warning!!')
+        if self._delta_t_batch > 0. and delta_t_callbacks > 0.95 * self._delta_t_batch \
-                val_loss, val_acc = self.evaluate(X_val, y_val, batch_size=batch_size, verbose=0, show_accuracy=True)
+                if show_accuracy:
-            return tot_score/len(batches), None
+            return tot_score/len(batches)
-                self.log_values.append(('val. acc.', val_acc))
+                self.log_values.append(('val. acc.', val_acc))
-nb_epoch = 5
+nb_epoch = 10
-        self.imgs = [self.axes[i].imshow(frames._framedata[i][0], interpolation='nearest') for i in range(self.n_plots)]
+        self.imgs = [self.axes[i].imshow(frames._framedata[i][0], interpolation='nearest', cmap='bone') for i in range(self.n_plots)]
-        if batch % 10 == 0:
+        if batch % 5 == 0:
-        anim.save('test_gif.mp4', fps=15)
+        # anim.save('test_gif.gif', fps=15, writer='imagemagick')
-model.add(Dense(256, 10))
+model.add(Dense(256, 10, W_regularizer = l2(0.1)))
-model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, callbacks=[draw_weights])
+draw_weights = DrawActivations(figsize=(5.4, 1.35))
-                    raise KeyboardInterrupt # TODO: Raise a more explicit Excpetion (?)
+                    raise KeyboardInterrupt # TODO: Raise a more explicit Exception (?)
-        self.ax = self.fig.add_subplot(1, 1, 1)
+class Frames(object):
-        # self.test = theano.function([self.model.get_input()], self.model.layers[10].get_output(train=False))
+        self.imgs = Frames(n_plots=5)
-            self.imgs.append([img])
+            self.imgs.add_frame(0, X_test[0,0])
-        anim = animation.ArtistAnimation(self.fig, self.imgs, interval=10, blit=False, repeat_delay=1000)
+        # anim = animation.ArtistAnimation(self.fig, self.imgs, interval=10, blit=False, repeat_delay=1000)
-draw_weights = DrawWeight()
+draw_weights = DrawActivations(figsize=(15, 3))
-                    acc = None
+                try:
-        self.val_accuracy = 0.
+import time
-    def on_epoch_end(self, epoch):
+    def on_epoch_end(self, epoch, val_loss, val_acc):
-            callback.on_epoch_end(epoch)
+            callback.on_epoch_end(epoch, val_loss, val_acc)
-    def on_batch_end(self, batch, indices, loss, accuracy, val_loss, val_acc):
+    def on_batch_end(self, batch, indices, loss, accuracy):
-            callback.on_batch_end(batch, indices, loss, accuracy, val_loss, val_acc)
+            callback.on_batch_end(batch, indices, loss, accuracy)
-    def on_epoch_end(self, epoch):
+    def on_epoch_end(self, epoch, val_loss, val_acc):
-    def on_batch_end(self, batch, indices, loss, accuracy, val_loss, val_acc):
+    def on_batch_end(self, batch, indices, loss, accuracy):
-    def on_batch_end(self, batch, indices, loss, accuracy, val_loss, val_acc):
+    def on_batch_end(self, batch, indices, loss, accuracy):
-    def on_epoch_end(self, epoch):
+    def on_epoch_end(self, epoch, val_loss, val_acc):
-            self.validation_losses.append(self.val_loss)
+            self.validation_losses.append(val_loss)
-                self.validation_accuracies.append(self.val_accuracy)
+                self.validation_accuracies.append(val_acc)
-    def on_batch_end(self, batch, indices, loss, accuracy, val_loss, val_acc):
+    def on_batch_end(self, batch, indices, loss, accuracy):
-            self.progbar.update(self.current, self.log_values)
+                self.log_values.append(('val. acc.', val_acc))
-                        val_loss = self.evaluate(X_val, y_val, batch_size=batch_size, verbose=0)
+                callbacks.on_batch_end(batch_index, batch_ids, loss, acc)
-            callbacks.on_epoch_end(epoch)
+            callbacks.on_epoch_end(epoch, val_loss, val_acc)
-            return tot_score/len(batches)
+            return tot_score/len(batches), None
-nb_epoch = 1
+nb_epoch = 5
-            img = self.ax.imshow(self.test(X_test)[0,:].reshape(16,16), interpolation='nearest')
+        self.activations = np.zeros((4 * 30, 4 * 30))
-    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1,
+    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1, callbacks=[],
-                history['val_acc'] = []
+
-                progbar = Progbar(target=len(y), verbose=verbose)
+            callbacks.on_epoch_begin(epoch)
-
+                callbacks.on_batch_begin(batch_index)
-                    av_loss += loss * len(batch_ids)
+                    acc = None
-        return history
+                callbacks.on_batch_end(batch_index, batch_ids, loss, acc, val_loss, val_acc)
-      install_requires=['theano', 'h5py'],
+      install_requires=['theano'],
-            outputs_info=alloc_zeros_matrix(X.shape[1], self.output_dim), 
+            outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),
-                initial=T.alloc(np.cast[theano.config.floatX](0.), self.depth, X.shape[1], self.output_dim), 
+                initial=T.alloc(np.cast[theano.config.floatX](0.), self.depth, X.shape[1], self.output_dim),
-            outputs_info=alloc_zeros_matrix(X.shape[1], self.output_dim),
+            outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),
-                alloc_zeros_matrix(X.shape[1], self.output_dim)
+                T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),
-        A pre-compiled Keras model is required to use the scikit-learn wrapper.
+    model : object
-    def __init__(self, model=None):
+    def __init__(self, model, optimizer='adam', loss='categorical_crossentropy'):
-        return {'model': self.model}
+        return {'model': self.model, 'optimizer': self.optimizer, 'loss': self.loss}
-            self.setattr(parameter, value)
+            setattr(self, parameter, value)
-        self.model.fit(X, y, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose, shuffle=shuffle)
+
-        loss, accuracy = self.model.evaluate(X, y, batch_size=batch_size, show_accuracy=True, verbose=verbose)
+        loss, accuracy = self.compiled_model_.evaluate(X, y, batch_size=batch_size,
-        return self.model.predict_classes(X, batch_size=batch_size, verbose=verbose)
+        return self.compiled_model_.predict_classes(X, batch_size=batch_size, verbose=verbose)
-        return self.model.predict_proba(X, batch_size=batch_size, verbose=verbose)
+        return self.compiled_model_.predict_proba(X, batch_size=batch_size, verbose=verbose)
-        where gamma is the EulerâMascheroni constant.
+        where gamma is the Euler-Mascheroni constant.
-            if sampling_table[i] < random.random():
+            if sampling_table[wi] < random.random():
-    return g
+    return g
-    def __init__(self, input_dim, output_dim, init='uniform', weights=None):
+    def __init__(self, input_dim, output_dim, init='uniform', weights=None, W_regularizer=None, W_constraint=None):
-        
+
-            raise Exception("Please specify two or more input models to merge")
+    def connect(self, node, which=0):
-            if sampling_table[i] < random.random():
+            if sampling_table[wi] < random.random():
-            sys.stdout.write("\b" * (self.total_width+1))
+            sys.stdout.write("\b" * prev_total_width)
-                        val_loss, val_acc = self.test(X_val, y_val, accuracy=True)
+                        val_loss, val_acc = self.evaluate(X_val, y_val, batch_size=batch_size, verbose=0, show_accuracy=True)
-                        val_loss = self.test(X_val, y_val)
+                        val_loss = self.evaluate(X_val, y_val, batch_size=batch_size, verbose=0)
-            bar = '%d/%d [' % (current, self.target)
+            numdigits = int(np.floor(np.log10(self.target))) + 1
-            grads = [clip_norm(g, c, norm) for g in grads]
+            grads = [clip_norm(g, self.clipnorm, norm) for g in grads]
-class Maxout(Layer):
+class MaxoutDense(Layer):
-        Max-out layer, n_features is the number of pieces in the piecewise linear approx.
+        Max-out layer, nb_feature is the number of pieces in the piecewise linear approx.
-    def __init__(self, input_dim, output_dim, n_features=4, init='glorot_uniform', weights=None, 
+    def __init__(self, input_dim, output_dim, nb_feature=4, init='glorot_uniform', weights=None, 
-        super(Maxout,self).__init__()
+        super(MaxoutDense,self).__init__()
-        self.n_features = n_features
+        self.nb_feature = nb_feature
-        self.b = shared_zeros((self.n_features, self.output_dim))
+        self.W = self.init((self.nb_feature, self.input_dim, self.output_dim))
-            "n_features" : self.n_features}
+            "nb_feature" : self.nb_feature}
-                    np.random.shuffle(index_array)
+            av_loss = 0.
-                seen = 0
+            batches = make_batches(len(X), batch_size)
-                    y_batch = y[batch_ids]
+                if show_accuracy:
-                        av_acc += acc * len(batch_ids)
+                        val_loss, val_acc = self.test(X_val, y_val, accuracy=True)
-                history['loss'].append(av_loss/seen)
+                        val_loss = self.test(X_val, y_val)
-            print('Terminating on KeyboardInterrupt at Epoch', epoch)
+                    history['val_acc'].append(float(val_acc))
-from .utils.generic_utils import Progbar
+from .utils.generic_utils import Progbar, printv
-class Sequential(object):
+def standardize_X(X):
-        self.constraints = []
+        self.params = [] # learnable
-    def get_output(self, train):
+
-        # input of model 
+    def get_input(self, train=False):
-            allow_input_downcast=True, mode=theano_mode)
+        return self.layers[0].get_input(train)
-            return self._train_with_acc(X, y)
+            return self._train_with_acc(*ins)
-            return self._train(X, y)
+            return self._train(*ins)
-            return self._test_with_acc(X, y)
+            return self._test_with_acc(*ins)
-            return self._test(X, y)
+            return self._test(*ins)
-                raise Exception("Invalid format for validation data; provide a tuple (X_val, y_val).")
+                raise Exception("Invalid format for validation data; provide a tuple (X_val, y_val). \
-                (X, X_val) = (X[0:split_at], X[split_at:])
+                split_at = int(len(y) * (1 - validation_split))
-        index_array = np.arange(len(X))
+        index_array = np.arange(len(y))
-                progbar = Progbar(target=len(X), verbose=verbose)
+                progbar = Progbar(target=len(y), verbose=verbose)
-            batches = make_batches(len(X), batch_size)
+            batches = make_batches(len(y), batch_size)
-                X_batch = X[batch_ids]
+                X_batch = slice_X(X, batch_ids)
-                    loss, acc = self._train_with_acc(X_batch, y_batch)
+                    loss, acc = self._train_with_acc(*ins)
-                    loss = self._train(X_batch, y_batch)
+                    loss = self._train(*ins)
-        batches = make_batches(len(X), batch_size)
+        X = standardize_X(X)
-            progbar = Progbar(target=len(X))
+            progbar = Progbar(target=len(X[0]))
-            batch_preds = self._predict(X_batch)
+            X_batch = slice_X(X, batch_start, batch_end)
-                shape = (len(X),) + batch_preds.shape[1:]
+                shape = (len(X[0]),) + batch_preds.shape[1:]
-        proba = self.predict_proba(X, batch_size=batch_size, verbose=verbose)
+        proba = self.predict(X, batch_size=batch_size, verbose=verbose)
-        batches = make_batches(len(X), batch_size)
+        batches = make_batches(len(y), batch_size)
-            progbar = Progbar(target=len(X), verbose=verbose)
+            progbar = Progbar(target=len(y), verbose=verbose)
-            X_batch = X[batch_start:batch_end]
+            X_batch = slice_X(X, batch_start, batch_end)
-                loss, acc = self._test_with_acc(X_batch, y_batch)
+                loss, acc = self._test_with_acc(*ins)
-                loss = self._test(X_batch, y_batch)
+                loss = self._test(*ins)
-    def describe(self, verbose=1):
+    def get_config(self, verbose=0):
-                        print('... ' + k + ' = ' + str(v))
+        if verbose:
-                param_dset = g.create_dataset(param_name, param.shape, dtype='float64')
+                param_dset = g.create_dataset(param_name, param.shape, dtype=param.dtype)
-
+        
-                    batch_ids = slice(batch_start, batch_end)
+                batch_ids = index_array[batch_start:batch_end]
-    def compile(self, optimizer, loss, class_mode="categorical", y_dim_components=1):
+    def compile(self, optimizer, loss, class_mode="categorical", y_dim_components=1, theano_mode=None):
-            updates=updates, allow_input_downcast=True)
+            updates=updates, allow_input_downcast=True, mode=theano_mode)
-            updates=updates, allow_input_downcast=True)
+            updates=updates, allow_input_downcast=True, mode=theano_mode)
-            allow_input_downcast=True)
+            allow_input_downcast=True, mode=theano_mode)
-            allow_input_downcast=True)
+            allow_input_downcast=True, mode=theano_mode)
-            allow_input_downcast=True)
+            allow_input_downcast=True, mode=theano_mode)
-        f.close()
+        f.close()
-    def __init__(self, input_shape, epsilon=1e-6, mode=0, weights=None):
+    def __init__(self, input_shape, epsilon=1e-6, mode=0, momentum=0.9, weights=None):
-            X_normed = (X - m) / (std + self.epsilon)
+            if train:
-model.fit(X, y, nb_epoch=20, batch_size=16, validation_split=0.15)
+model.fit(X, y, nb_epoch=20, batch_size=128, validation_split=0.15)
-            for batch_index, (batch_start, batch_end) in enumerate(batches):
+        # -- allow user to terminate training
-                y_batch = y[batch_ids]
+                    np.random.shuffle(index_array)
-                    av_loss += loss * len(batch_ids)
+                av_loss = 0.
-                        log_values += [('val. loss', val_loss), ('val. acc.', val_acc)]
+                batches = make_batches(len(X), batch_size)
-                    progbar.update(batch_end, log_values)
+                        batch_ids = slice(batch_start, batch_end)
-                history['acc'].append(av_acc/seen)
+                    if show_accuracy:
-                    history['val_acc'].append(float(val_acc))
+                    history['val_loss'].append(float(val_loss))
-    def predict_proba(self, X, batch_size=128, verbose=1):
+    def predict(self, X, batch_size=128, verbose=1):
-        self.Us = [self.init((self.output_dim, self.output_dim)) for _ in range(self.depth)]
+        self.Us = [self.inner_init((self.output_dim, self.output_dim)) for _ in range(self.depth)]
-def preprocess_labels(y, encoder=None, categorical=True):
+def preprocess_labels(labels, encoder=None, categorical=True):
-                self.sum_values[k] = [v, 1]
+                self.sum_values[k] = [v * (current-self.seen_so_far), current-self.seen_so_far]
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-        self.previous_layer = previous_layer
+    def connect(self, node):
-    def output(self, train):
+    def get_output(self, train):
-            return self.previous_layer.output(train=train)
+        if hasattr(self, 'previous'):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train=False):
+    def get_output(self, train=False):
-    def output(self, train=False):
+    def get_output(self, train=False):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-    def output(self, train):
+    def get_output(self, train):
-        
+
-        self.y_test = self.layers[-1].output(train=False)
+        self.y_train = self.get_output(train=True)
-        the lenght of the longuest sequence.
+        Pad each sequence to the same length: 
-        model.compile(loss='hinge', optimizer='adam')
+        model.add(WordContextProduct(max_features, proj_dim=dim_proj, init="uniform"))
-    def compile(self, optimizer, loss, class_mode="categorical"):
+    def compile(self, optimizer, loss, class_mode="categorical", y_dim_components=1):
-        # (first layer must have an "input" attribute!)
+        # input of model 
-        self.y = T.matrix() # TODO: support for custom output shapes
+        self.y = ndim_tensor(y_dim_components+1)
-    p *= T.ge(p,0)
+    p *= T.ge(p, 0)
-    def l1wrap(g,p):
+    def l1wrap(g, p):
-    def l2wrap(g,p):
+    def l2wrap(g, p):
-        return Image.fromarray(x.astype("uint8"), "L")
+        return Image.fromarray(x[:,:,0].astype("uint8"), "L")
-    return x.transpose(2, 0, 1)
+    if len(x.shape)==3:
-        if hasattr(layer, 'regularizers'):
+        if hasattr(layer, 'regularizers') and len(layer.regularizers) == len(layer.params):
-        if hasattr(layer, 'constraints'):
+        if hasattr(layer, 'constraints') and len(layer.constraints) == len(layer.params):
-
+        self.__dict__.update(kwargs)
-        for p, g in zip(params, grads):
+        for p, g, c in zip(params, grads, constraints):
-        for p, g, a in zip(params, grads, accumulators):
+        for p, g, a, c in zip(params, grads, accumulators, constraints):
-
+        self.__dict__.update(kwargs)
-        for p, g, a in zip(params, grads, accumulators):
+        for p, g, a, c in zip(params, grads, accumulators, constraints):
-        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):
+        for p, g, a, d_a, c in zip(params, grads, accumulators, delta_accumulators, constraints):
-        for p, g in zip(params, grads):
+        for p, g, c in zip(params, grads, constraints):
-
+            
-    return p
+    return p
-    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=identity, b_regularizer=identity, W_constraint=identity, b_constraint=identity):
+    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, 
-        self.constraint = [W_constraint, b_constraint]
+        self.regularizers = [W_regularizer, b_regularizer]
-    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=identity, b_regularizer=identity, W_constraint=identity, b_constraint=identity):
+    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, 
-        self.constraint = [W_constraint, b_constraint]
+        self.regularizers = [W_regularizer, b_regularizer]
-        self.constraint = []
+        self.regularizers = []
-        self.constraint += [c for c in layer.constraint]
+        
-        updates = self.optimizer.get_updates(self.params, self.regularizer, self.constraint, self.layers, train_loss)
+        updates = self.optimizer.get_updates(self.params, self.regularizers, self.constraints, train_loss)
-                cost = cost + T.sum(kl_div)
+    def get_gradients(self, cost, params, regularizers):
-            g = r(g,p)
+            g = r(g, p)
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, regularizers, constraints, cost):
-            self.update_params(p, new_p, updates, c)
+            updates.append((p, c(new_p))) # apply constraints
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, regularizers, constraints, cost):
-            self.update_params(p, new_p, updates, c)
+            updates.append((p, c(new_p))) # apply constraints
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, regularizers, constraints, cost):
-            self.update_params(p, new_p, updates, c)
+            updates.append((p, c(new_p))) # apply constraints
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, regularizers, constraints, cost):
-            self.update_params(p, new_p, updates, c)
+            updates.append((p, c(new_p))) # apply constraints
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, regularizers, constraints, cost):
-            self.update_params(p, p_t, updates, c)
+            updates.append((p, c(p_t))) # apply constraints
-def l1(lam=.01):
+def l1(l=.01):
-        g += T.sgn(p) * lam
+        g += T.sgn(p) * l
-def l2(lam=.01):
+def l2(l=.01):
-        g += p * lam
+        g += p * l
-def identity(g,*l):
+def identity(g, p):
-        updates = self.optimizer.get_updates(self.params, self.regularizer, self.constraint, self.layers, train_loss)
+        updates = self.optimizer.get_updates(self.params, train_loss)
-
+        f.close()
-
+    def get_gradients(self, cost, params):
-            new_grads.append(g)
+        for p, g in zip(params, grads):
-        return new_grads
+            if hasattr(self, 'l2') and self.l2 > 0:
-        return updates
+            if hasattr(self, 'maxnorm') and self.maxnorm > 0:
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, cost):
-        for p, g, c in zip(params, grads, constraints):
+        for p, g in zip(params, grads):
-            self.update_params(p, new_p, updates, c)
+            updates.append((p, new_p))
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, cost):
-        for p, g, a, c in zip(params, grads, accumulators, constraints):
+        for p, g, a in zip(params, grads, accumulators):
-            self.update_params(p, new_p, updates, c)
+            updates.append((p, new_p))
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, cost):
-        for p, g, a, c in zip(params, grads, accumulators, constraints):
+        for p, g, a in zip(params, grads, accumulators):
-            self.update_params(p, new_p, updates, c)
+            updates.append((p, new_p))
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, cost):
-        for p, g, a, d_a, c in zip(params, grads, accumulators, delta_accumulators, constraints):
+        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):
-            self.update_params(p, new_p, updates, c)
+            updates.append((p, new_p))
-        grads = self.get_gradients(cost, params, layers, regularizers)
+    def get_updates(self, params, cost):
-        for p, g, c in zip(params, grads, constraints):
+        for p, g in zip(params, grads):
-            
+
-            self.update_params(p, p_t, updates, c)
+            updates.append((p, p_t))
-    return get_from_module(identifier, globals(), 'optimizer', instantiate=True)
+    return get_from_module(identifier, globals(), 'optimizer', instantiate=True)
-from keras.utils import np_utils, generic_utils
+from keras.utils import np_utils
-
+    Train a simple deep NN on the MNIST dataset.
-batch_size = 100
+batch_size = 64
-model.add(Dense(784, 100, W_constraint=maxnorm(3)))
+model.add(Dense(784, 128))
-model.add(Dense(100, 100))
+model.add(Dropout(0.2))
-model.add(Dense(100, 10, W_constraint=maxnorm(3)))
+model.add(Dropout(0.2))
-print('Test score:', score)
+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=2, validation_data=(X_test, Y_test))
-import numpy as np
+from .data_utils import get_file
-    (X_test, y_test) = load(set_name='test')
+def load_data(path="mnist.pkl.gz"):
-        return open(cache_path, 'rb')
+    if path.endswith(".gz"):
-        raise RuntimeError("Invalid magic number: [{}]".format('-'.join(['{:02x}'.format(_) for _ in magic])))
+        f = open(path, 'rb')
-        )
+    if sys.version_info < (3,):
-    labels = read_data_from_url(labels_url, cache_dir=cache_dir)
+        data = six.moves.cPickle.load(f, encoding="bytes")
-    return data, labels
+    f.close()
-            "activation":self.activation.__name__}
+            "activation":self.activation.__name__,
-            "p":self.p}
+            "dims":self.dims}
-nb_epoch = 200
+nb_epoch = 20
-(X_train, y_train), (X_test, y_test) = mnist.load_data(test_split=0.1)
+(X_train, y_train), (X_test, y_test) = mnist.load_data()
-model.add(Dropout(0.25))
+model.add(Dropout(0.1))
-model.add(Dropout(0.25))
+model.add(Dropout(0.1))
-model.compile(loss='categorical_crossentropy', optimizer=sgd)
+rms = RMSprop()
-score = model.evaluate(X_test, Y_test, batch_size=batch_size)
+
-            self.std = np.std(X)
+            self.std = np.std(X, axis=0)
-from ..regularizers import ident
+from ..regularizers import identity
-    def __init__(self, activation):
+    def __init__(self, activation, target=0, beta=0.1):
-    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=ident, b_regularizer=ident, W_constraint=ident, b_constraint=ident):
+    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=identity, b_regularizer=identity, W_constraint=identity, b_constraint=identity):
-    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=ident, b_regularizer=ident, W_constraint=ident, b_constraint=ident):
+    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=identity, b_regularizer=identity, W_constraint=identity, b_constraint=identity):
-        updates = self.optimizer.get_updates(self.params, self.regularizer, self.constraint, train_loss)
+        updates = self.optimizer.get_updates(self.params, self.regularizer, self.constraint, self.layers, train_loss)
-    def get_gradients(self, cost, params, regularizers):
+    def get_gradients(self, cost, params, layers, regularizers):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, layers, cost):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, layers, cost):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, layers, cost):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, layers, cost):
-        grads = self.get_gradients(cost, params, regularizers)
+    def get_updates(self, params, regularizers, constraints, layers, cost):
-def ident(g,*l):
+def identity(g,*l):
-    def get_gradients(self, cost, params, regularizers, constraints):
+    def get_gradients(self, cost, params, regularizers):
-        for p, g, r, c in zip(params, grads, regularizers, constraints):
+        new_grads = []
-            p = c(p)
+            new_grads.append(g)
-        return grads, params
+        return new_grads
-        grads, params = self.get_gradients(cost, params, regularizers, constraints)
+        grads = self.get_gradients(cost, params, regularizers)
-        for p, g in zip(params, grads):
+        for p, g, c in zip(params, grads, constraints):
-            updates.append((p, new_p))
+            self.update_params(p, new_p, updates, c)
-        grads, params = self.get_gradients(cost, params, regularizers, constraints)
+        grads = self.get_gradients(cost, params, regularizers)
-        for p, g, a in zip(params, grads, accumulators):
+        for p, g, a, c in zip(params, grads, accumulators, constraints):
-            updates.append((p, new_p))
+            self.update_params(p, new_p, updates, c)
-        grads, params = self.get_gradients(cost, params, regularizers, constraints)
+        grads = self.get_gradients(cost, params, regularizers)
-        for p, g, a in zip(params, grads, accumulators):
+        for p, g, a, c in zip(params, grads, accumulators, constraints):
-            updates.append((p, new_p))
+            self.update_params(p, new_p, updates, c)
-        grads, params = self.get_gradients(cost, params, regularizers, constraints)
+        grads = self.get_gradients(cost, params, regularizers)
-        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):
+        for p, g, a, d_a, c in zip(params, grads, accumulators, delta_accumulators, constraints):
-            updates.append((p, new_p))
+            self.update_params(p, new_p, updates, c)
-        grads, params = self.get_gradients(cost, params, regularizers, constraints)
+        grads = self.get_gradients(cost, params, regularizers)
-        for p, g in zip(params, grads):
+        for p, g, c in zip(params, grads, constraints):
-            updates.append((p, p_t))
+            self.update_params(p, p_t, updates, c)
-        self.params = []
+        super(PReLU,self).__init__()
-        self.params = []
+    def __init__(self):
-        self.constraint = []
+        super(Activation,self).__init__()
-        self.constraint = []
+        super(Reshape,self).__init__()
-        self.constraint = []
+        super(Flatten,self).__init__()
-        self.constraint = []
+        super(Dense,self).__init__()
-
+    
-    def get_gradients(self, cost, params):
+    def get_gradients(self, cost, params, regularizers, constraints):
-        return grads
+        for p, g, r, c in zip(params, grads, regularizers, constraints):
-        grads = self.get_gradients(cost, params)
+        grads, params = self.get_gradients(cost, params, regularizers, constraints)
-            g = r(g,p)
+        for p, g in zip(params, grads):
-        grads = self.get_gradients(cost, params)
+        grads, params = self.get_gradients(cost, params, regularizers, constraints)
-            g = r(g,p)
+        for p, g, a in zip(params, grads, accumulators):
-        grads = self.get_gradients(cost, params)
+        grads, params = self.get_gradients(cost, params, regularizers, constraints)
-            g = r(g,p)
+        for p, g, a in zip(params, grads, accumulators):
-        grads = self.get_gradients(cost, params)
+        grads, params = self.get_gradients(cost, params, regularizers, constraints)
-            g = r(g,p)
+        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):
-        grads = self.get_gradients(cost, params)
+        grads, params = self.get_gradients(cost, params, regularizers, constraints)
-            g = r(g,p)
+        for p, g in zip(params, grads):
-            p_t = c(p_t)
+import theano.tensor as T
-    def __init__(self, input_shape, epsilon=1e-6, weights=None):
+    def __init__(self, input_shape, epsilon=1e-6, mode=0, weights=None):
-        X_normed = (X - X.mean(keepdims=True)) / (X.std(keepdims=True) + self.epsilon)
+
-            "epsilon":self.epsilon}
+            "epsilon":self.epsilon,
-print('Test accuracy:', acc)
+print('Test score:', score[0])
-
+model.fit(X_train, Y_train, nb_epoch=4, batch_size=batch_size, verbose=1, show_accuracy=True, validation_split=0.1)
-        X = np.zeros((len(sequences), nb_words+1))
+        X = np.zeros((len(sequences), nb_words))
-        init='uniform', activation='linear', weights=None, 
+        init='glorot_uniform', activation='linear', weights=None, 
-    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None):
+    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None):
-    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None):
+    def __init__(self, input_dim, output_dim, init='glorot_uniform', activation='linear', weights=None):
-        init='uniform', inner_init='orthogonal', activation='sigmoid', weights=None,
+        init='glorot_uniform', inner_init='orthogonal', activation='sigmoid', weights=None,
-        init='uniform', inner_init='orthogonal', 
+        init='glorot_uniform', inner_init='orthogonal', 
-        init='uniform', inner_init='orthogonal',
+        init='glorot_uniform', inner_init='orthogonal',
-        init='uniform', inner_init='orthogonal', 
+        init='glorot_uniform', inner_init='orthogonal', 
-        f.write(','.join(encoder.classes_))
+        f.write(','.join([str(i) for i in encoder.classes_]))
-        return {"name":self.__class__.__name__}
+        return {"name":self.__class__.__name__,
-            "input_shape":self.input_shape}
+        return {"name":self.__class__.__name__}
-    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None, regularizer=[ident, ident], constraint=[ident, ident]):
+    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None, W_regularizer=ident, b_regularizer=ident, W_constraint=ident, b_constraint=ident):
-        self.constraint = constraint
+        self.regularizer = [W_regularizer, b_regularizer]
-    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None, regularizer=[ident, ident], constraint=[ident, ident]):
+    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None, W_regularizer=ident, b_regularizer=ident, W_constraint=ident, b_constraint=ident):
-        self.constraint = constraint
+        self.regularizer = [W_regularizer, b_regularizer]
-    import os
+def make_reuters_dataset(path=os.path.join('datasets', 'temp', 'reuters21578'), min_samples_per_topic=15):
-    six.moves.cPickle.dump(tokenizer.word_index, open('datasets/data/reuters_word_index.pkl', 'w'))
+    six.moves.cPickle.dump(dataset, open(os.path.join('datasets', 'data', 'reuters.pkl'), 'w'))
-import sys
+import sys, os
-        fpath = path + '/data_batch_' + str(i)
+        fpath = os.path.join(path, 'data_batch_' + str(i))
-    datadir = os.path.expanduser("~/.keras/datasets")
+    datadir = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))
-    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None):
+    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None, regularizer=[ident, ident], constraint=[ident, ident]):
-    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None):
+    def __init__(self, input_dim, output_dim, init='uniform', activation='linear', weights=None, regularizer=[ident, ident], constraint=[ident, ident]):
-        updates = self.optimizer.get_updates(self.params, train_loss)
+        updates = self.optimizer.get_updates(self.params, self.regularizer, self.constraint, train_loss)
-        return new_grads
+        return grads
-    def get_updates(self, params, cost):
+    def get_updates(self, params, regularizers, constraints, cost):
-        for p, g in zip(params, grads):
+        for p, g, r, c in zip(params, grads, regularizers, constraints):
-    def get_updates(self, params, cost):
+    def get_updates(self, params, regularizers, constraints, cost):
-        for p, g, a in zip(params, grads, accumulators):
+        for p, g, a, r, c in zip(params, grads, accumulators, regularizers, constraints):
-    def get_updates(self, params, cost):
+    def get_updates(self, params, regularizers, constraints, cost):
-        for p, g, a in zip(params, grads, accumulators):
+        for p, g, a, r, c in zip(params, grads, accumulators, regularizers, constraints):
-    def get_updates(self, params, cost):
+    def get_updates(self, params, regularizers, constraints, cost):
-        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):
+        for p, g, a, d_a, r, c in zip(params, grads, accumulators, delta_accumulators, regularizers, constraints):
-    def get_updates(self, params, cost):
+    def get_updates(self, params, regularizers, constraints, cost):
-        for p, g in zip(params, grads):
+        for p, g, r, c in zip(params, grads, regularizers, constraints):
-
+            
-X_test, _ = preprocess_data(X_test)
+X_test, _ = preprocess_data(X_test, scaler)
-        On EC2 g2.2xlarge instance: 10s/epoch. 6-7 minutes total training time.
+        On EC2 g2.2xlarge instance: 19s/epoch. 6-7 minutes total training time.
-        X = np.zeros((len(sequences), nb_words))
+        X = np.zeros((len(sequences), nb_words+1))
-load = False
+save = True
-model_save_fname = "HN_skipgram_model_full_256.pkl"
+model_load_fname = "HN_skipgram_model.pkl"
-if load:
+if load_tokenizer:
-    model = six.moves.cPickle.load(open(os.path.join(save_dir, model_load_fname)))
+    tokenizer = six.moves.cPickle.load(open(os.path.join(save_dir, tokenizer_fname), 'rb'))
-        six.moves.cPickle.dump(tokenizer, open(os.path.join(save_dir, tokenizer_fname), "w"))
+        six.moves.cPickle.dump(tokenizer, open(os.path.join(save_dir, tokenizer_fname), "wb"))
-    if not load:
+    if load_model:
-        model.compile(loss='mse', optimizer='rmsprop')
+        model.compile(loss='hinge', optimizer='adam')
-        six.moves.cPickle.dump(model, open(os.path.join(save_dir, model_save_fname), "w"))
+        six.moves.cPickle.dump(model, open(os.path.join(save_dir, model_save_fname), "wb"))
-                g.attrs[k] = v
+                if v is not None:
-
+            
-import string
+import string, sys
-    text = text.translate(string.maketrans(filters, split*len(filters)))
+    text = text.translate(maketrans(filters, split*len(filters)))
-# class Convolution1D(Layer): TODO
+class Convolution1D(Layer):
-            sys.stdout.write("\b" * (self.total_width+1))
+            sys.stdout.write("\r")
-            
+
-model.save('testsave.m')
+for v in range(3):
-        
+        self.nb_filter = nb_filter
-        return out
+        return out
-from __future__ import absolute_import
+from __future__ import absolute_import, division
-        Hinton's dropout. 
+        Hinton's dropout.
-        size = theano.tensor.prod(X.shape) / X.shape[0]
+        size = theano.tensor.prod(X.shape) // X.shape[0]
-       Apply a same DenseLayer for each dimension[1] (shared_dimension) input 
+       Apply a same DenseLayer for each dimension[1] (shared_dimension) input
-
+import sys
-        d = six.moves.cPickle.load(f)
+        if sys.version_info < (3,):
-        
+
-    def save(self, filepath):
+    def save_weights(self, filepath):
-        f.attrs['n_layers'] = len(self.layers)
+        f.attrs['nb_layers'] = len(self.layers)
-            g.attrs['n_params'] = len(weights)
+            g.attrs['nb_params'] = len(weights)
-    def load(self, filepath):
+    def load_weights(self, filepath):
-        for k in range(f.attrs['n_layers']):
+        for k in range(f.attrs['nb_layers']):
-            weights = [g['param_{}'.format(p)] for p in range(g.attrs['n_params'])]
+            weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]
-
+    def save(self, filepath):
-import inspect, os
+import tarfile, inspect, os
-        urllib.urlretrieve(origin, fpath, dl_progress)
+        urlretrieve(origin, fpath, dl_progress)
-)
+)
-import inspect, os
+import tarfile, inspect, os
-        urllib.urlretrieve(origin, fpath, dl_progress)
+        urlretrieve(origin, fpath, dl_progress)
-print('Test score:', score)
+# import cPickle
-classes = model.predict_classes(X_test, batch_size=batch_size)
+classes = model.predict_classes(X_test, batch_size=batch_size, verbose=2)
-                progbar = Progbar(target=len(X))
+                    log_values = [('loss', loss), ('acc.', acc)]
-                                print("loss: %.4f - val. loss: %.4f" % (loss, val_loss))
+                    progbar.update(batch_end, log_values)
-        progbar = Progbar(target=len(X))
+        if verbose:
-                        print("loss: %.4f")
+                progbar.update(batch_end, log_values)
-    def __init__(self, target, width=30):
+    def __init__(self, target, width=30, verbose=1):
-        sys.stdout.write("\b" * (self.total_width+1))
+        now = time.time()
-            bar += ('='*(prog_width-1))
+            bar = '%d/%d [' % (current, self.target)
-                bar += '>'
+                info += ' - ETA: %ds' % eta
-        self.total_width = len(bar)
+                info += ' - %ds' % (now - self.start)
-            info += ' - %s: %.4f' % (k, self.sum_values[k][0]/self.sum_values[k][1])
+            self.total_width += len(info)
-            info += ((prev_total_width-self.total_width) * " ")
+            if current >= self.target:
-        self.seen_so_far = current
+        if self.verbose == 2:
-            v_t = (self.beta_2 * v) + (1 - self.beta_2) * (g**2)
+            m_t = (beta_1_t * m) + (1 - beta_1_t) * g
-                                print("loss: %.4f - acc.: %.4f" % (loss, acc))
+                                print("loss: %.4f - val. loss: %.4f" % (loss, val_loss))
-    scale = 1./np.sqrt(m)
+    fan_in, fan_out = get_fans(shape)
-    fan_out = shape[1] if len(shape) == 2 else shape[0]
+    fan_in, fan_out = get_fans(shape)
-    fan_in = shape[1] if len(shape) == 2 else np.prod(shape[1:])
+    fan_in, fan_out = get_fans(shape)
-            progbar = Progbar(target=len(X))
+            if verbose==1:
-                            progbar.update(batch_end, [('loss', loss)])
+                    if (not is_last_batch or not do_validation):
-                            progbar.update(batch_end, [('loss', loss), ('acc.', acc), ('val. loss', val_loss), ('val. acc.', val_acc)])
+                            if verbose==1:
-                            progbar.update(batch_end, [('loss', loss), ('val. loss', val_loss)])
+                            if verbose==1:
-        if verbose:
+        if verbose==1:
-            if verbose:
+            if verbose==1:
-                    progbar.update(batch_end, [('loss', loss)])
+                if verbose==1:
-from distutils.core import setup
+try:
-)
+)
-model.add(Flatten(64*8*8))
+model.add(Flatten())
-import h5py, numpy
+from __future__ import absolute_import
-        if datapath not in self.refs.keys():
+        if datapath not in list(self.refs.keys()):
-            if numpy.max(key) + self.start < self.end:
+        elif isinstance(key, np.ndarray):
-                idx = map(lambda x: x + self.start, key)
+                idx = [x + self.start for x in key]
-    return a
+from __future__ import absolute_import
-print X_test.shape[0], 'test samples'
+print(X_train.shape[0], 'train samples')
-    print "Not using data augmentation or normalization"
+    print("Not using data augmentation or normalization")
-    print 'Test score:', score
+    print('Test score:', score)
-    print "Using real time data augmentation"
+    print("Using real time data augmentation")
-        print "Training..."
+        print('-'*40)
-        print "Testing..."
+        print("Testing...")
-    180s/epoch on GPU (GT 650M), vs. 400s/epoch on CPU (2.4Ghz Core i7).
+    250s/epoch on GPU (GT 650M), vs. 400s/epoch on CPU (2.4Ghz Core i7).
-print "Loading data..."
+print("Loading data...")
-print len(X_test), 'test sequences'
+print(len(X_train), 'train sequences')
-print "Pad sequences (samples x time)"
+print("Pad sequences (samples x time)")
-print 'X_test shape:', X_test.shape
+print('X_train shape:', X_train.shape)
-print 'Build model...'
+print('Build model...')
-model.compile(loss='binary_crossentropy', optimizer='adam')
+model.compile(loss='binary_crossentropy', optimizer='adam', class_mode="binary")
-model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=5, verbose=1)
+print("Train...")
-print 'Test score:', score
+print('Test score:', score)
-print 'Test accuracy:', acc
+print('Test accuracy:', acc)
-print "Loading data..."
+print("Loading data...")
-print len(X_test), 'test sequences'
+print(len(X_train), 'train sequences')
-print nb_classes, 'classes'
+print(nb_classes, 'classes')
-print "Vectorizing sequence data..."
+print("Vectorizing sequence data...")
-print 'X_test shape:', X_test.shape
+print('X_train shape:', X_train.shape)
-print "Convert class vector to binary class matrix (for use with categorical_crossentropy)"
+print("Convert class vector to binary class matrix (for use with categorical_crossentropy)")
-print 'Y_test shape:', Y_test.shape
+print('Y_train shape:', Y_train.shape)
-print "Building model..."
+print("Building model...")
-print "Training..."
+model.compile(loss='categorical_crossentropy', optimizer='adam')
-print 'Test score:', score
+print('Test score:', score)
-print 'Test accuracy:', acc
+print('Test accuracy:', acc)
-import cPickle
+import six.moves.cPickle
-            print i
+            print(i)
-    model = cPickle.load(open(os.path.join(save_dir, model_load_fname)))
+    print('Load tokenizer...')
-    print "Fit tokenizer..."
+    print("Fit tokenizer...")
-        print "Save tokenizer..."
+        print("Save tokenizer...")
-        cPickle.dump(tokenizer, open(os.path.join(save_dir, tokenizer_fname), "w"))
+        six.moves.cPickle.dump(tokenizer, open(os.path.join(save_dir, tokenizer_fname), "w"))
-        print 'Build model...'
+        print('Build model...')
-        print '-'*40
+        print('-'*40)
-    print "Training completed!"
+        print('Samples seen:', samples_seen)
-        print "Saving model..."
+        print("Saving model...")
-        cPickle.dump(model, open(os.path.join(save_dir, model_save_fname), "w"))
+        six.moves.cPickle.dump(model, open(os.path.join(save_dir, model_save_fname), "w"))
-print "It's test time!"
+print("It's test time!")
-reverse_word_index = dict([(v, k) for k, v in word_index.items()])
+reverse_word_index = dict([(v, k) for k, v in list(word_index.items())])
-    tups = zip(range(len(proximities)), proximities)
+    tups = list(zip(list(range(len(proximities))), proximities))
-    print '====', w
+    print('====', w)
-        print r
+        print(r)
-from utils.generic_utils import get_from_module
+from .utils.generic_utils import get_from_module
-from data_utils import get_file
+# -*- coding: utf-8 -*-
-from PIL import Image
+import six.moves.cPickle
-        d = cPickle.load(f)
+        d = six.moves.cPickle.load(f)
-        print 'Downloading data from',  origin
+        print('Downloading data from',  origin)
-            print 'Untaring file...'
+            print('Untaring file...')
-import cPickle
+from __future__ import absolute_import
-from data_utils import get_file
+from .data_utils import get_file
-    X, labels = cPickle.load(f)
+    X, labels = six.moves.cPickle.load(f)
-from data_utils import get_file
+from __future__ import absolute_import
-import cPickle
+import six.moves.cPickle
-    items = topic_counts.items()
+    items = list(topic_counts.items())
-        print x[0] + ': ' + str(x[1])
+        print(x[0] + ': ' + str(x[1]))
-    print 'Kept topics:', len(kept_topics)
+    print('-')
-    print 'Sanity check:'
+    print('Sanity check:')
-        print '...index of', w, ':', tokenizer.word_index.get(w)
+        print('...index of', w, ':', tokenizer.word_index.get(w))
-    cPickle.dump(tokenizer.word_index, open('datasets/data/reuters_word_index.pkl', 'w'))
+    print('-')
-    X, labels = cPickle.load(f)
+    X, labels = six.moves.cPickle.load(f)
-    return cPickle.load(f)
+    return six.moves.cPickle.load(f)
-from utils.theano_utils import sharedX, shared_zeros
+from .utils.theano_utils import sharedX, shared_zeros
-from utils.generic_utils import get_from_module
+from .utils.generic_utils import get_from_module
-import objectives
+from . import optimizers
-from utils.generic_utils import Progbar
+from .utils.generic_utils import Progbar
-                print "Train on %d samples, validate on %d samples" % (len(y), len(y_val))
+                print("Train on %d samples, validate on %d samples" % (len(y), len(y_val)))
-                    print "Train on %d samples, validate on %d samples" % (len(y), len(y_val))
+                    print("Train on %d samples, validate on %d samples" % (len(y), len(y_val)))
-                print 'Epoch', epoch
+                print('Epoch', epoch)
-from utils.generic_utils import get_from_module
+from .utils.generic_utils import get_from_module
-from utils.theano_utils import shared_zeros, shared_scalar
+from .utils.theano_utils import shared_zeros, shared_scalar
-from utils.generic_utils import get_from_module
+from .utils.generic_utils import get_from_module
-from PIL import Image
+from __future__ import absolute_import
-    rank = np.array(range(size))
+    rank = np.array(list(range(size)))
-    return filter(None, seq)
+    return [_f for _f in seq if _f]
-        wcounts = self.word_counts.items()
+        wcounts = list(self.word_counts.items())
-        self.word_index = dict(zip(sorted_voc, range(1, len(sorted_voc)+1)))
+        self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc)+1)))))
-        for w, c in self.word_docs.items():
+        for w, c in list(self.word_docs.items()):
-            for j, c in counts.items():
+            for j, c in list(counts.items()):
-from distutils.core import setup
+from setuptools import setup
-      ],
+      packages=find_packages(),
-    def compile(self, optimizer, loss):
+    def compile(self, optimizer, loss, class_mode="categorical"):
-        self.Y = T.matrix() # TODO: support for custom output shapes
+        self.y = T.matrix() # TODO: support for custom output shapes
-        self._train = theano.function([self.X, self.Y], train_loss, 
+        self._train = theano.function([self.X, self.y], train_loss, 
-        self._test = theano.function([self.X, self.Y], test_score, 
+        self._test = theano.function([self.X, self.y], test_score, 
-    def train(self, X, y):
+    def train(self, X, y, accuracy=False):
-        return loss
+        if accuracy:
-    def test(self, X, y):
+    def test(self, X, y, accuracy=False):
-        return score
+        if accuracy:
-        # and split y into smaller y and y_val.
+            validation_split=0., validation_data=None, shuffle=True, show_accuracy=False):
-        if validation_split > 0 and validation_split < 1:
+        if validation_data:
-            (y, y_val) = (y[0:split_at], y[split_at:])
+            y_val = standardize_y(y_val)
-            nb_batch = int(np.ceil(len(X)/float(batch_size)))
+            batches = make_batches(len(X), batch_size)
-                batch_end = min(len(X), (batch_index+1)*batch_size)
+            for batch_index, (batch_start, batch_end) in enumerate(batches):
-                loss = self._train(X_batch, y_batch)
+
-                    is_last_batch = (batch_index == nb_batch - 1)
+                    is_last_batch = (batch_index == len(batches) - 1)
-                        progbar.update(batch_end, [('loss', loss)])
+                        if show_accuracy:
-                        progbar.update(batch_end, [('loss', loss), ('val. loss', self.test(X_val, y_val))])
+                        if show_accuracy:
-            batch_preds = self._predict(X[batch])
+    def predict_proba(self, X, batch_size=128, verbose=1):
-            preds[batch] = batch_preds
+            preds[batch_start:batch_end] = batch_preds
-            return proba.argmax(axis=classes_dim)
+
-    def evaluate(self, X, y, batch_size=128):
+
-        return av_score/samples
+
-    y = np.asarray(y)
+    if not hasattr(y, 'shape'):
-                batch_ids = index_array[batch_start:batch_end]
+                if shuffle:
-model.compile(loss='binary_crossentropy', optimizer='rmsprop')
+model.compile(loss='binary_crossentropy', optimizer='adam')
-model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10, verbose=1)
+model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=5, verbose=1)
-            p_t = p - self.lr * m_b_t / (T.sqrt(v_t) + self.epsilon)
+            p_t = p - self.lr * m_b_t / (T.sqrt(v_b_t) + self.epsilon)
-    
+    '''
-"android", # ios, release, os, mobible, beta
+"android", # ios, release, os, mobile, beta
-        eg. [4, 50, 123, 26] -> [0.25, 0.1]
+        Turn positive integers (indexes) into denses vectors of fixed size. 
-    that the geometry of the embedding space captures certain useful semantic properties.
+    We then use the weights computed by WordContextProduct to encode words 
-model_save_fname = "HN_skipgram_model_full_256-0.pkl"
+model_save_fname = "HN_skipgram_model_full_256.pkl"
-def closest_to_word(word, nb_closest=10):
+def closest_to_word(w, nb_closest=10):
-from keras.layers.core import Dense, Dropout, Activation, Embedding
+from keras.layers.core import Dense, Dropout, Activation
-#model.add(BatchNormalization(input_shape=(256,))) # try without batch normalization (doesn't work as well!)
+model.add(BatchNormalization(input_shape=(256,))) # try without batch normalization (doesn't work as well!)
-        return self.W[X]
+import theano
-def one_hot(text, n):
+def one_hot(text, n, filters=base_filter(), lower=True, split=" "):
-    return [abs(hash(w))%n for w in seq]
+    return [(abs(hash(w))%(n-1)+1) for w in seq]
-    def __init__(self, filters=base_filter(), lower=True, nb_words=None):
+    def __init__(self, nb_words=None, filters=base_filter(), lower=True, split=" "):
-            seq = text_to_word_sequence(text, self.filters, self.lower)
+            seq = text_to_word_sequence(text, self.filters, self.lower, self.split)
-            seq = text_to_word_sequence(text, self.filters, self.lower)
+            seq = text_to_word_sequence(text, self.filters, self.lower, self.split)
-def pad_sequences(seqs, maxlen=None, dtype='int32'):
+def pad_sequences(sequences, maxlen=None, dtype='int32'):
-    lengths = [len(s) for s in seqs]
+    lengths = [len(s) for s in sequences]
-    nb_samples = len(seqs)
+    nb_samples = len(sequences)
-    for idx, s in enumerate(seqs):
+    for idx, s in enumerate(sequences):
-    window_size=4, negative_samples=1., shuffle=True, categorical=False, seed=None, sampling_table=None):
+    window_size=4, negative_samples=1., shuffle=True, 
-            seed = random.randint(0,10e6)
+        seed = random.randint(0,10e6)
-        self.input = T.matrix()
+        self.input = T.tensor3()
-    s = np.sqrt(2. / (fan_in + fan_out)
+    s = np.sqrt(2. / (fan_in + fan_out))
-    return get_from_module(identifier, globals(), 'initialization')
+    return get_from_module(identifier, globals(), 'initialization')
-        return o        
+        return self.activation(o)
-        truncate_gradient=-1, weights=None, return_sequences=False):
+        weights=None, truncate_gradient=-1, return_sequences=False):
-        truncate_gradient=-1, weights=None, return_sequences=False):
+        weights=None, truncate_gradient=-1, return_sequences=False):
-    window_size=4, negative_samples=1., shuffle=True, categorical=False, seed=None):
+    window_size=4, negative_samples=1., shuffle=True, categorical=False, seed=None, sampling_table=None):
-            pass
+            continue
-                    pass
+                    continue
-        
+
-        self.size = size
+    def __init__(self):
-        nshape = (X.shape[0], self.size)
+        size = theano.tensor.prod(X.shape) / X.shape[0]
-    return x
+    return x
-    return text.split(split)
+    text = text.translate(string.maketrans(filters, split*len(filters)))
-        self.word_index = dict(zip(sorted_voc, range(len(sorted_voc))))
+        self.word_index = dict(zip(sorted_voc, range(1, len(sorted_voc)+1)))
-            Only words know by the tokenizer will be taken into account.
+            Only words known by the tokenizer will be taken into account.
-        nb_words = self.nb_words
+        for vect in self.texts_to_sequences_generator(texts):
-        return res
+            yield vect
-    y = np.zeros((nb_samples,))
+    y = np.zeros((nb_samples,), dtype="uint8")
-def load_data(path="imdb.pkl", nb_words=100000, maxlen=None, test_split=0.2, seed=113):
+def load_data(path="imdb.pkl", nb_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113):
-    X = [[1 if w >= nb_words else w for w in x] for x in X]
+    if not nb_words:
-def load_data(path="reuters.pkl", nb_words=100000, maxlen=None, test_split=0.2, seed=113):
+def load_data(path="reuters.pkl", nb_words=None, skip_top=0, maxlen=None, test_split=0.2, seed=113):
-    X = [[1 if w >= nb_words else w for w in x] for x in X]
+    if not nb_words:
-            raise Exception('Invalid', module_name, ': ' + identifier)
+            raise Exception('Invalid ' + str(module_name) + ': ' + str(identifier))
-from utils.theano_utils import sharedX
+from utils.theano_utils import sharedX, shared_zeros
-            nb_batch = np.ceil(len(X)/float(batch_size))
+            nb_batch = int(np.ceil(len(X)/float(batch_size)))
-            nb_batch = len(X)/batch_size+1
+            nb_batch = np.ceil(len(X)/float(batch_size))
-    datadir = os.path.join(datadir, 'data')
+    datadir = os.path.expanduser("~/.keras/datasets")
-                preds = np.zeros((len(X), batch_preds.shape[1]))
+                shape = (len(X),) + batch_preds.shape[1:]
-            return proba.argmax(axis=1)
+        # The last dimension is the one containing the class probas
-            return np.array([1 if p > 0.5 else 0 for p in proba])
+            return (proba>0.5).astype('int32')
-    from preprocessing.text import Tokenizer
+    from ..preprocessing.text import Tokenizer
-    X = tokenizer.transform(kept_wires)
+    tokenizer.fit_on_texts(kept_wires)
-    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1, shuffle=True):
+    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1,
-                loss = self._train(X[batch], y[batch])
+                batch_start = batch_index*batch_size
-                    progbar.update(prog, [('loss', loss)])
+                    is_last_batch = (batch_index == nb_batch - 1)
-sgd = SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=True)
+sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
-    X_test = X_train.astype("float32")
+    X_test = X_test.astype("float32")
-        lr = self.lr - self.decay * self.iterations
+        lr = self.lr * (1.0 / (1.0 + self.decay * self.iterations))
-    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1):
+    def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1, shuffle=True):
-            
+            if shuffle:
-                    progbar.update(batch[-1]+1, [('loss', loss)])
+                if verbose:
-    from distutils.core import setup
+from distutils.core import setup
-          'keras.utils',
+        'keras', 
-      }
+      # TODO: dependencies
-    It gets to 0.65 test logloss in 25 epochs (still way underfitting at that point, though)
+    It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.
-        self.Y = Y
+        # output of model
-        self.input = T.matrix()
+        self.input = T.tensor3()
-        self.input = T.matrix()
+        self.input = T.tensor3()
-        self.input = T.matrix()
+        self.input = T.tensor3()
-        self.input = T.matrix()
+        self.input = T.tensor3()
-        'keras.utils',
+          'keras',
-      install_requires=['numpy', 'scipy', 'theano']
+      install_requires=['numpy', 'scipy', 'theano'],
-from setuptools import setup
+try:
-from distutils.core import setup
+from setuptools import setup
-      # TODO: dependencies
+      install_requires=['numpy', 'scipy', 'theano']
-        Just your regular fully connecter NN layer.
+        Just your regular fully connected NN layer.
-        Turns a list of integers into a dense vector of fixed size. 
+        Turn a list of integers >=0 into a dense vector of fixed size. 
-    return Y
+    return Y
-        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python examples/cifar10_cnn.py
+        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10_cnn.py
-from datasets import data_utils
+from data_utils import get_file
-    path = data_utils.get_file(dirname, origin=origin, untar=True)
+    path = get_file(dirname, origin=origin, untar=True)
-from utils.generic_utils import Progbar
+from ..utils.generic_utils import Progbar
-from utils.theano_utils import shared_zeros
+from ..layers.core import Layer
-from layers.core import Layer
+from .. import activations, initializations
-    pass
+# class ZeroPadding2D(Layer): TODO
-from utils.generic_utils import make_tuple
+from .. import activations, initializations
-import initializations
+from ..layers.core import Layer
-from layers.core import Layer
+from .. import activations, initializations
-        for w, c in self.word_docs:
+        for w, c in self.word_docs.items():
-            modes: binary, count, tfidf
+            modes: binary, count, tfidf, freq
-        sequences = self.to_sequences(texts)
+        sequences = self.texts_to_sequences(texts)
-            raise Exception("Specify a dimension (nb_words argument")
+            if self.word_index:
-        X = np.zeros((len(sequences), self.nb_words))
+        X = np.zeros((len(sequences), nb_words))
-                if j >= self.nb_words:
+                if j >= nb_words:
-            print 'Unraring file...'
+        if not os.path.exists(untar_fpath):
-        Y = T.matrix() # ouput of model
+        Y = T.matrix() # output of model
-        if os.path.exists(fpath):
+        if os.path.exists(untar_fpath):
